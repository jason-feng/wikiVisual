<doc id="21511" url="http://en.wikipedia.org/wiki?curid=21511" title="Niccolò Paganini">
Niccolò Paganini

Niccolò (or Nicolò) Paganini (27 October 1782 – 27 May 1840) was an Italian violinist, violist, guitarist, and composer. He was the most celebrated violin virtuoso of his time, and left his mark as one of the pillars of modern violin technique. His "Caprice No. 24 in A minor", Op. 1, is among the best known of his compositions, and has served as an inspiration for many prominent composers.
Biography.
Childhood.
Niccolò Paganini was born in Genoa, then capital of the Republic of Genoa, the third of the six children of Antonio and Teresa (née Bocciardo) Paganini. Paganini's father was an unsuccessful trader, but he managed to supplement his income through playing music on the mandolin. At the age of five, Paganini started learning the mandolin from his father, and moved to the violin by the age of seven. His musical talents were quickly recognized, earning him numerous scholarships for violin lessons. The young Paganini studied under various local violinists, including Giovanni Servetto and Giacomo Costa, but his progress quickly outpaced their abilities. Paganini and his father then traveled to Parma to seek further guidance from Alessandro Rolla. But upon listening to Paganini's playing, Rolla immediately referred him to his own teacher, Ferdinando Paer and, later, Paer's own teacher, Gasparo Ghiretti. Though Paganini did not stay long with Paer or Ghiretti, the two had considerable influence on his composition style.
Early career.
The French invaded northern Italy in March 1796, and Genoa was not spared. The Paganinis sought refuge in their country property in Romairone, near Bolzaneto. By 1800, Paganini and his father traveled to Livorno, where Paganini played in concerts and his father resumed his maritime work. In 1801, the 18-year-old Paganini was appointed first violin of the Republic of Lucca, but a substantial portion of his income came from freelancing. His fame as a violinist was matched only by his reputation as a gambler and womanizer.
In 1805, Lucca was annexed by Napoleonic France, and the region was ceded to Napoleon's sister, Elisa Baciocchi. Paganini became a violinist for the Baciocchi court, while giving private lessons to her husband, Felice. In 1807, Baciocchi became the Grand Duchess of Tuscany and her court was transferred to Florence. Paganini was part of the entourage, but, towards the end of 1809, he left Baciocchi to resume his freelance career.
Travelling virtuoso.
For the next few years, Paganini returned to touring in the areas surrounding Parma and Genoa. Though he was very popular with the local audience, he was still not very well known in the rest of Europe. His first break came from an 1813 concert at La Scala in Milan. The concert was a great success. As a result, Paganini began to attract the attention of other prominent, albeit more conservative, musicians across Europe. His early encounters with Charles Philippe Lafont and Louis Spohr created intense rivalry. His concert activities, however, were still limited to Italy for the next few years.
His fame spread across Europe with a concert tour that started in Vienna in August 1828, stopping in every major European city in Germany, Poland, and Bohemia until February 1831 in Strasbourg. This was followed by tours in Paris and Britain. His technical ability and his willingness to display it received much critical acclaim. In addition to his own compositions, theme and variations being the most popular, Paganini also performed modified versions of works (primarily concertos) written by his early contemporaries, such as Rodolphe Kreutzer and Giovanni Battista Viotti.
Late career and health decline.
Throughout his life, Paganini was no stranger to chronic illnesses. Although no definite medical proof exists, he was reputed to have been affected by Marfan syndrome. In addition, his frequent concert schedule, as well as his extravagant lifestyle, took their toll on his health. He was diagnosed with syphilis as early as 1822, and his remedy, which included mercury and opium, came with serious physical and psychological side effects. In 1834, while still in Paris, he was treated for tuberculosis. Though his recovery was reasonably quick, after the illness his career was marred by frequent cancellations due to various health problems, from the common cold to depression, which lasted from days to months.
In September 1834, Paganini put an end to his concert career and returned to Genoa. Contrary to popular beliefs involving his wishing to keep his music and techniques secret, Paganini devoted his time to the publication of his compositions and violin methods. He accepted students, of whom two enjoyed moderate success: violinist Camillo Sivori and cellist Gaetano Ciandelli. Neither, however, considered Paganini helpful or inspirational. In 1835, Paganini returned to Parma, this time under the employ of Archduchess Marie Louise of Austria, Napoleon's second wife. He was in charge of reorganizing her court orchestra. However, he eventually conflicted with the players and court, so his visions never saw completion. In Paris, he befriended the 11-year-old Polish virtuoso Apollinaire de Kontski, giving him some lessons and a signed testimonial. It was widely put about, falsely, that Paganini was so impressed with de Kontski's skills that he bequeathed him his violins and manuscripts.
Final years, death, and burial.
In 1836, Paganini returned to Paris to set up a casino. Its immediate failure left him in financial ruin, and he auctioned off his personal effects, including his musical instruments, to recoup his losses. At Christmas of 1838, he left Paris for Marseilles and, after a brief stay, travelled to Nice where his condition worsened. In May 1840, the Bishop of Nice sent Paganini a local parish priest to perform the last rites. Paganini assumed the sacrament was premature, and refused.
A week later, on 27 May 1840, Paganini died from internal hemorrhaging before a priest could be summoned. Because of this, and his widely rumored association with the devil, the Church denied his body a Catholic burial in Genoa. It took four years and an appeal to the Pope before the Church let his body be transported to Genoa, but it was still not buried. His remains were finally laid to rest in 1876, in a cemetery in Parma. In 1893, the Czech violinist, František Ondříček, persuaded Paganini's grandson, Attila, to allow a viewing of the violinist's body. After this bizarre episode, Paganini's body was finally reinterred in a new cemetery in Parma in 1896.
Personal and professional relationships.
Though having no shortage of romantic conquests, Paganini was seriously involved with a singer named Antonia Bianchi from Como, whom he met in Milan in 1813. The two gave concerts together throughout Italy. They had a son, Achilles Cyrus Alexander, born on 23 July 1825 in Palermo and baptized at San Bartolomeo's. They never legalized their union and it ended around April 1828 in Vienna. Paganini brought Achilles on his European tours, and Achilles later accompanied his father until the latter's death. He was instrumental in dealing with his father's burial, years after his death.
Throughout his career, Paganini also became close friends with composers Gioachino Rossini and Hector Berlioz. Rossini and Paganini met in Bologna in the summer of 1818. In January 1821, on his return from Naples, Paganini met Rossini again in Rome, just in time to become the composer's substitute conductor for his opera "Mathilde de Sharbran", upon the sudden death of the original conductor. The violinist's efforts earned gratitude from the composer.
Meanwhile, Paganini was introduced to Berlioz in Paris in 1833. Though Paganini also commissioned from him "Harold en Italie" for viola and orchestra, he never performed it, and instead it was premiered a year later by violist Christian Urhan. Despite his alleged lack of interest in "Harold", Paganini often referred to Berlioz as the resurrection of Beethoven and, towards the end of his life, he gave large sums to the composer.
Paganini's instruments.
Paganini was in possession of a number of fine string instruments. More legendary than these were the circumstances under which he obtained (and lost) some of them. While Paganini was still a teenager in Livorno, a wealthy businessman named Livron lent him a violin, made by the master luthier Giuseppe Guarneri, for a concert. Livron was so impressed with Paganini's playing that he refused to take it back. This particular violin came to be known as "Il Cannone Guarnerius". On a later occasion in Parma, he won another valuable violin (also by Guarneri) after a difficult sight-reading challenge from a man named Pasini.
Other instruments associated with Paganini include the "Antonio Amati" 1600, the "Nicolò Amati" 1657, the "Paganini-Desaint" 1680 Stradivari, the Guarneri-filius "Andrea" 1706, the "Le Brun" 1712 Stradivari, the "Vuillaume" c. 1720 Bergonzi, the "Hubay" 1726 Stradivari, and the "Comte Cozio di Salabue" 1727 violins; the "Countess of Flanders" 1582 da Salò-di Bertolotti, and the "Mendelssohn" 1731 Stradivari violas; the "Piatti" 1700 Goffriller, the "Stanlein" 1707 Stradivari, and the "Ladenburg" 1736 Stradivari cellos; and the "Grobert of Mirecourt" 1820 (guitar). Four of these instruments were played by the Tokyo String Quartet.
Compositions.
Paganini composed his own works to play exclusively in his concerts, all of which profoundly influenced the evolution of violin technique. His 24 Caprices were likely composed in the period between 1805 to 1809, while he was in the service of the Baciocchi court. Also during this period, he composed the majority of the solo pieces, duo-sonatas, trios and quartets for the guitar. These chamber works may have been inspired by the publication, in Lucca, of the guitar quintets of Boccherini. Many of his variations, including "Le Streghe", "The Carnival of Venice", and "Nel cor più non mi sento", were composed, or at least first performed, before his European concert tour.
Generally speaking, Paganini's compositions were technically imaginative, and the timbre of the instrument was greatly expanded as a result of these works. Sounds of different musical instruments and animals were often imitated. One such composition was titled "Il Fandango Spanolo" (The Spanish Dance), which featured a series of humorous imitations of farm animals. Even more outrageous was a solo piece "Duetto Amoroso", in which the sighs and groans of lovers were intimately depicted on the violin. There survives a manuscript of the "Duetto", which has been recorded. The existence of the "Fandango" is known only through concert posters.
However, his works were criticized for lacking characteristics of true polyphonism, as pointed out by Eugène Ysaÿe. Yehudi Menuhin, on the other hand, suggested that this might have been the result of his reliance on the guitar (in lieu of the piano) as an aid in composition. The orchestral parts for his concertos were often polite, unadventurous, and clearly supportive of the soloist. In this, his style is consistent with that of other Italian composers such as Paisiello, Rossini and Donizetti, who were influenced by the guitar-song milieu of Naples during this period.
Paganini was also the inspiration of many prominent composers. Both "La Campanella" and the A minor Caprice (No. 24) have been an object of interest for a number of composers. Franz Liszt, Robert Schumann, Johannes Brahms, Sergei Rachmaninoff, Boris Blacher, Andrew Lloyd Webber, George Rochberg and Witold Lutosławski, among others, wrote well-known variations on these themes.
Paganini and violin technique.
The Israeli violinist Ivry Gitlis once referred to Paganini as a phenomenon rather than a development. Though some of the techniques frequently employed by Paganini were already present, most accomplished violinists of the time focused on intonation and bowing techniques. Arcangelo Corelli (1653–1713) was considered a pioneer in transforming the violin from an ensemble instrument to a solo instrument. In the meantime, the polyphonic capability of the violin was firmly established through the Sonatas and Partitas BWV 1001–1006 of Johann Sebastian Bach (1685–1750). Other notable violinists included Antonio Vivaldi (1678–1741) and Giuseppe Tartini (1692–1770), who, in their compositions, reflected the increasing technical and musical demands on the violinist. Although the role of the violin in music drastically changed through this period, progress in violin technique was steady but slow. Techniques requiring agility of the fingers and the bow were still considered unorthodox and discouraged by the established community of violinists.
Much of Paganini's playing (and his violin composition) was influenced by two violinists, Pietro Locatelli (1693–1746) and August Duranowski (1770–1834). During Paganini's study in Parma, he came across the 24 Caprices of Locatelli (entitled "L'arte di nuova modulazione – Capricci enigmatici" or "The art of the new style – the enigmatic caprices"). Published in the 1730s, they were shunned by the musical authorities for their technical innovations, and were forgotten by the musical community at large. Around the same time, Durand, a former student of Giovanni Battista Viotti (1755–1824), became a celebrated violinist. He was renowned for his use of harmonics and the left hand pizzicato in his performance. Paganini was impressed by Durand's innovations and showmanship, which later also became the hallmarks of the young violin virtuoso. Paganini was instrumental in the revival and popularization of these violinistic techniques, which are now incorporated into regular compositions.
Another aspect of Paganini's violin techniques concerned his flexibility. He had exceptionally long fingers and was capable of playing three octaves across four strings in a hand span, an extraordinary feat even by today's standards. His seemingly unnatural ability may have been a result of Marfan syndrome.
Works inspired by Paganini.
Notable works inspired by compositions of Paganini include:
The "Caprice No. 24 in A minor", Op. 1, ("Tema con variazioni") has been the basis of works by many other composers. Notable examples include Brahms's "Variations on a Theme of Paganini" and Rachmaninoff's "Rhapsody on a Theme of Paganini".
Memorials.
The Paganini Competition ("Premio Paganini") is an international violin competition created in 1954 in his home city of Genoa and named in his honour.
In 1972 the State of Italy purchased a large collection of Niccolò Paganini manuscripts from the W. Heyer Library of Cologne. They are housed at the Biblioteca Casanatense in Rome.
In 1982 the city of Genoa commissioned a thematic catalogue of music by Paganini, edited by Maria Rosa Moretti and Anna Sorrento, hence the abbreviation "MS" assigned to his catalogued works.
A minor planet 2859 Paganini discovered in 1978 by Soviet astronomer Nikolai Chernykh is named after him.
Dramatic portrayals.
Paganini has been portrayed by a number of actors in film and television productions, including Stewart Granger in the 1946 biographical portrait "The Magic Bow", Roxy Roth in "A Song to Remember" (1945), Klaus Kinski in "Kinski Paganini" (1989) and David Garrett in "The Devil's Violinist" (2013).
In the Soviet 1982 miniseries "Niccolo Paganini" the musician is portrayed by the Armenian actor Vladimir Msryan. The series focuses on Paganini's relationship with the Roman Catholic Church. Another Soviet actor, Armen Dzhigarkhanyan, plays Paganini's fictionalized arch-rival, an insidious Jesuit official. The information in the series is generally spurious and it also plays to some of the myths and legends rampant during the musician's lifetime. One memorable scene shows Paganini's adversaries sabotaging his violin before a high-profile performance, causing all strings but one to break during the concert. An undeterred Paganini continues to perform on three, two, and finally on a single string. In actuality, Paganini occasionally broke strings during a performance on purpose so he could further display his virtuosity. In 1827, Pope Leo XII honoured Paganini with the Order of the Golden Spur.
In Don Nigro's satirical comedy "Paganini" (1995), the great violinist seeks vainly for his salvation, claiming that he unknowingly sold his soul to the Devil. "Variation upon variation," he cries at one point, "but which variation leads to salvation and which to damnation? Music is a question for which there is no answer." Paganini is portrayed as having killed three of his lovers and sinking repeatedly into poverty, prison, and drink. Each time he is "rescued" by the Devil who appears in different guises, returning Paganini's violin so he can continue playing. In the end, Paganini's salvation—administered by a god-like Clockmaker—turns out to be imprisonment in a large bottle where he plays his music for the amusement of the public through all eternity. "Do not pity him, my dear," the Clockmaker tells Antonia, one of Paganini's murdered wives. "He is alone with the answer for which there is no question. The saved and the damned are the same."
References.
Notes
Sources
External links.
Images

</doc>
<doc id="21512" url="http://en.wikipedia.org/wiki?curid=21512" title="North Atlantic Current">
North Atlantic Current

The North Atlantic Current (also known as North Atlantic Drift and North Atlantic Sea Movement) is a powerful warm ocean current that continues the Gulf Stream northeast. West of Continental Europe it splits into two major branches. One branch goes southeast, later to become the Canary Current as it passes northwest Africa and turns southwest. The other major branch continues north along the coast of northwestern Europe. It is thought to have a considerable warming influence on the climate, although a minority have disputed this. Other branches include the Irminger Current and the Norwegian Current. Driven by the global thermohaline circulation (THC), the North Atlantic Current is part of the wind-driven Gulf Stream which goes further east and north from the North American coast, across the Atlantic and into the Arctic Ocean.

</doc>
<doc id="21513" url="http://en.wikipedia.org/wiki?curid=21513" title="North Atlantic Deep Water">
North Atlantic Deep Water

North Atlantic Deep Water (NADW) is a deep water mass formed in the North Atlantic Ocean. Thermohaline circulation of the world's oceans involves the flow of warm surface waters from the southern hemisphere into the North Atlantic. Water flowing northward becomes modified through evaporation and mixing with other water masses, leading to increased salinity. When this water reaches the North Atlantic it cools and sinks through convection, due to its decreased temperature and increased salinity resulting in increased density. NADW is the outflow of this thick deep layer, which can be detected by its high salinity, high oxygen content, nutrient minima, and chlorofluorocarbons (CFCs). CFCs are anthropogenic substances that enter the surface of the ocean from gas exchange with the atmosphere. This distinct composition allows its path to be traced as it mixes with Circumpolar Deep water, which in turn fills the deep Indian Ocean and part of the South Pacific. NADW and its formation is essential to the Atlantic Meridional Overturning Circulation (AMOC), which is responsible for transporting large amounts of water, heat, salt, carbon, nutrients and other substances around the globe. In the conveyor belt model of thermohaline circulation of the world's oceans, the sinking of NADW pulls the waters of the North Atlantic drift northward; however, this is almost certainly an oversimplification of the actual relationship between NADW formation and the strength of the Gulf Stream/North Atlantic drift. 
NADW has a temperature of 2-4°C with a salinity of 34.9-35.0 psu found at a depth between 1500 to 4000m.
Formation and sources.
The NADW is a complex of several water masses formed by deep convection and also by overflow of dense water across the Greenland-Iceland-Scotland Ridge.
The upper layers are formed by deep open ocean convection during winter. Labrador Sea Water (LSW), formed in the Labrador Sea can reach depths of 2000 m as dense water sinks downward. Classical Labrador Sea Water (CLSW) production is dependent on preconditioning of water in the Labrador Sea from the previous year, and the strength of the North Atlantic Oscillation. During a positive NAO phase, conditions exist for strong winter storms to develop. These storms freshen the surface water, and their winds increase cyclonic flow, which allows denser waters to sink. As a result the temperature, salinity, and density vary yearly. In some years these conditions do not exist and CLSW is not formed. CLSW has characteristic potential temperature of 3°C, salinity of 34.88 psu, and density of 34.66. Another component of LSW is the Upper Labrador Sea Water (ULSW). ULSW forms at a density lower than CLSW and has a CFC maximum between 1200 to 1500 m in the subtropical North Atlantic. Eddies of cold less saline ULSW have similar densities of warmer saltier water and flow along the DWBC, but maintain their high CFCs. The ULSW eddies erode rapidly as they mix laterally with this warmer saltier water.
The lower waters mass of NADW form from overflow of the Greenland-Iceland-Scotland Ridge. They are Iceland-Scotland Overflow Water (ISOW) and Denmark Strait Overflow Water (DSOW). The overflows are a combination of dense Arctic Ocean water (18%), modified Atlantic water (32%), and intermediate water from the Nordic seas (20%), that entrain and mix with other water masses (contributing 30%) as they flow over the Greenland-Iceland-Scotland Ridge. The formation of both of these waters involves the conversion of warm salty northward flowing surface waters to cold dense deep waters behind the Greenland-Iceland-Scotland Ridge. Water flow from the North Atlantic current enters the Arctic Ocean through the Norwegian Current which splits into the Fram Strait and Barents Sea Branch. Water from the Fram Strait recirculates, reaching a density of DSOW, sinks, and flows towards the Denmark Strait. Water flowing into the Barent Sea feeds ISOW.
ISOW enters the eastern North Atlantic over the Iceland-Scotland Ridge through the Faeroe Bank Channel at a depth of 850 m, with some water flowing over the shallower Iceland-Faeroe Rise. ISOW has a low CFC concentrations and it has been estimated from these concentrations that ISOW resides behind the ridge for 45 years. As the water flows southward at the bottom of the channel, it entrains surrounding water of the eastern North Atlantic, and flows to the western North Atlantic through the Charlie-Gibbs Fracture Zone, entraining with LSW. This water is less dense than (DSOW) and lays above it as it flows cyclonically in the Irminger Basin.
DSOW is the coldest, densest, and freshest water mass of NADW. DSOW formed behind the ridge flows over the Denmark Strait at a depth of 600m. The most significant water mass contributing to DSOW is Arctic Intermediate Water (AIW). Winter cooling and convection allow AIW to sink and pool behind the Denmark Strait. Upper AIW has a high amount of anthropogenic tracers due its exposure to the atmosphere. AIW's tritium and CFC signature is observed in DSOW at the base of the Greenland continental slope. This also showed that the DSOW flowing 450 km to the south was no older than 2 years. Both the DSOW and ISOW flow around the Irminger Basin and Labrador Sea in a deep boundary current. Leaving the Greenland Sea with 2.5 Sv its flow increases to 10 Sv south of Greenland. It is cold and relatively fresh, flowing below 3500 m in the DWBC and spreading inward the deep Atlantic basins.
Spreading pathways.
The southward spread of NADW along the Deep Western Boundary current (DWBC) can be traced by its high oxygen content, high CFCs, and density. 
ULSW is the major source of upper NADW. ULSW advects southward from the Labrador Sea in small eddies that mix into the DWBC. A CFC maxima associated with ULSW has been observed along 24°N in the DWBC at 1500 m. Some of the upper ULSW recirculates into the Gulf Stream, while some remains in the DWBC. High CFCs in the subtropics indicate recirculation in the subtropics. ULSW that remains in the DWBC dilutes as it moves equatorward. Deep convection in the Labrador Sea during the late 1980s and early 1990s resulted in CLSW with a lower CFC concentration due to downward mixing. However, convection allowed the CFCs to penetrate further downward to 2000m. These minimum could be tracked, and were first observed in the subtropics in the early 1990s. 
ISOW and DSOW flow around the Irminger Basin and DSOW entering the DWBC. These are the two lower porions of the NADW. Another CFC maximum is seen at 3500 in the subtropics from the DSOW contribution to NADW. Some of the NADW recirculates with the northern recirculation gyre. To the south of the gyre NADW flows under the Gulf Stream where it continues along the DWBC until it reaches another recirculation gyre in the subtropics. 
Variability.
It is believed that North Atlantic Deep Water formation has been dramatically reduced at times during the past (such as during the Younger Dryas or during Heinrich events), and that this might correlate with a decrease in the strength of the Gulf Stream and the North Atlantic drift, in turn cooling the climate of northwestern Europe. There is concern that global warming might cause this to happen again. It is also hypothesized that during the Last Glacial Maximum (LGM), NADW was replaced with an analogous watermass that occupied a shallower depth known as Glacial North Atlantic Intermediate Water (GNAIW).

</doc>
<doc id="21514" url="http://en.wikipedia.org/wiki?curid=21514" title="Nanomedicine">
Nanomedicine

Nanomedicine is the medical application of nanotechnology. Nanomedicine ranges from the medical applications of nanomaterials, to nanoelectronic biosensors, and even possible future applications of molecular nanotechnology. Current problems for nanomedicine involve understanding the issues related to toxicity and environmental impact of nanoscale materials (materials whose structure is on the scale of nanometers, i.e. billionths of a meter).
Functionalities can be added to nanomaterials by interfacing them with biological molecules or structures. The size of nanomaterials is similar to that of most biological molecules and structures; therefore, nanomaterials can be useful for both in vivo and in vitro biomedical research and applications.
Thus far, the integration of nanomaterials with biology has led to the development of diagnostic devices, contrast agents, analytical tools, physical therapy applications, and drug delivery vehicles.
Nanomedicine seeks to deliver a valuable set of research tools and clinically useful devices in the near future. The National Nanotechnology Initiative expects new commercial applications in the pharmaceutical industry that may include advanced drug delivery systems, new therapies, and in vivo imaging. Nanomedicine research is receiving funding from the US National Institutes of Health, including the funding in 2005 of a five-year plan to set up four nanomedicine centers.
Nanomedicine is a large industry, with nanomedicine sales reaching $6.8 billion in 2004, and with over 200 companies and 38 products worldwide, a minimum of $3.8 billion in nanotechnology R&D is being invested every year. In April 2006, the journal Nature Materials estimated that 130 nanotech-based drugs and delivery systems were being developed worldwide. As the nanomedicine industry continues to grow, it is expected to have a significant impact on the economy.
Drug delivery.
Nanotechnology has provided the possibility of delivering drugs to specific cells using nanoparticles.
The overall drug consumption and side-effects may be lowered significantly by depositing the active agent in the morbid region only and in no higher dose than needed. Targeted drug delivery is intended to reduce the side effects of drugs with concomitant decreases in consumption and treatment expenses. Drug delivery focuses on maximizing bioavailability both at specific places in the body and over a period of time. This can potentially be achieved by molecular targeting by nanoengineered devices. More than $65 billion are wasted each year due to poor bioavailability. A benefit of using nanoscale for medical technologies is that smaller devices are less invasive and can possibly be implanted inside the body, plus biochemical reaction times are much shorter. These devices are faster and more sensitive than typical drug delivery. The efficacy of drug delivery through nanomedicine is largely based upon: a) efficient encapsulation of the drugs, b) successful delivery of drug to the targeted region of the body, and c) successful release of the drug.
Drug delivery systems, lipid- or polymer-based nanoparticles, can be designed to improve the pharmacokinetics and biodistribution of the drug. However, the pharmacokinetics and pharmacodynamics of nanomedicine is highly variable among different patients. When designed to avoid the body's defence mechanisms, nanoparticles have beneficial properties that can be used to improve drug delivery. Complex drug delivery mechanisms are being developed, including the ability to get drugs through cell membranes and into cell cytoplasm. Triggered response is one way for drug molecules to be used more efficiently. Drugs are placed in the body and only activate on encountering a particular signal. For example, a drug with poor solubility will be replaced by a drug delivery system where both hydrophilic and hydrophobic environments exist, improving the solubility. Drug delivery systems may also be able to prevent tissue damage through regulated drug release; reduce drug clearance rates; or lower the volume of distribution and reduce the effect on non-target tissue. However, the biodistribution of these nanoparticles is still imperfect due to the complex host's reactions to nano- and microsized materials and the difficulty in targeting specific organs in the body. Nevertheless, a lot of work is still ongoing to optimize and better understand the potential and limitations of nanoparticulate systems. While advancement of research proves that targeting and distribution can be augmented by nanoparticles, the dangers of nanotoxicity become an important next step in further understanding of their medical uses.
Nanoparticles can be used in combination therapy for decreasing antibiotic resistance or for their antimicrobial properties. Nanoparticles might also used to circumvent multidrug resistance (MDR) mechanisms.
Types of systems used.
Two forms of nanomedicine that have already been tested in mice and are awaiting human trials that will be using gold nanoshells to help diagnose and treat cancer, and using liposomes as vaccine adjuvants and as vehicles for drug transport. Similarly, drug detoxification is also another application for nanomedicine which has shown promising results in rats. Advances in Lipid nanotechnology was also instrumental in engineering medical nanodevices and novel drug delivery systems as well as in developing sensing applications. Another example can be found in dendrimers and nanoporous materials. Another example is to use block co-polymers, which form micelles for drug encapsulation.
Polymeric nano-particles are a competing technology to lipidic (based mainly on Phospholipids) nano-particles. There is an additional risk of toxicity associated with polymers not widely studied or understood. The major advantages of polymers is stability, lower cost and predictable characterisation. However, in the patient's body this very stability (slow degradation) is a negative factor. Phospholipids on the other hand are membrane lipids (already present in the body and surrounding each cell), have a GRAS (Generally Recognised As Safe) status from FDA and are derived from natural sources without any complex chemistry involved. They are not metabolised but rather absorbed by the body and the degradation products are themselves nutrients (fats or micronutrients).
Protein and peptides exert multiple biological actions in the human body and they have been identified as showing great promise for treatment of various diseases and disorders. These macromolecules are called biopharmaceuticals. Targeted and/or controlled delivery of these biopharmaceuticals using nanomaterials like nanoparticles and Dendrimers is an emerging field called nanobiopharmaceutics, and these products are called nanobiopharmaceuticals.
Another vision is based on small electromechanical systems; nanoelectromechanical systems are being investigated for the active release of drugs. Some potentially important applications include cancer treatment with iron nanoparticles or gold shells.Nanotechnology is also opening up new opportunities in implantable delivery systems, which are often preferable to the use of injectable drugs, because the latter frequently display first-order kinetics (the blood concentration goes up rapidly, but drops exponentially over time). This rapid rise may cause difficulties with toxicity, and drug efficacy can diminish as the drug concentration falls below the targeted range.
Applications.
Some nanotechnology-based drugs that are commercially available or in human clinical trials include:
Cancer.
Existing and potential drug nanocarriers have been reviewed.
Nanoparticles have high surface area to volume ratio, allows many functional groups to be attached to a nanoparticle, which can seek out and bind to certain tumor cells. Additionally, the small size of nanoparticles (10 to 100 nanometers), allows them to preferentially accumulate at tumor sites (because tumors lack an effective lymphatic drainage system). Limitations to conventional cancer chemotherapy include drug resistance, lack of selectivity, and lack of solubility. Nanoparticles have the potential to overcome these problems.
In photodynamic therapy, a particle is placed within the body and is illuminated with light from the outside. The light gets absorbed by the particle and if the particle is metal, energy from the light will heat the particle and surrounding tissue. Light may also be used to produce high energy oxygen molecules which will chemically react with and destroy most organic molecules that are next to them (like tumors). This therapy is appealing for many reasons. It does not leave a "toxic trail" of reactive molecules throughout the body (chemotherapy) because it is directed where only the light is shined and the particles exist. Photodynamic therapy has potential for a noninvasive procedure for dealing with diseases, growth and tumors. Kanzius RF therapy is one example of such therapy. Also, gold nanoparticles have the potential to join numerous therapeutic functions into a single platform, by targeting specific tumor cells, tissues and organs.
Visualization.
"In vivo" imaging is another area where tools and devices are being developed. Using nanoparticle contrast agents, images such as ultrasound and MRI have a favorable distribution and improved contrast. This might be accomplished by self assembled biocompatible nanodevices that will detect, evaluate, treat and report to the clinical doctor automatically.
The small size of nanoparticles endows them with properties that can be very useful in oncology, particularly in imaging. Quantum dots (nanoparticles with quantum confinement properties, such as size-tunable light emission), when used in conjunction with MRI (magnetic resonance imaging), can produce exceptional images of tumor sites. Nanoparticles of cadmium selenide (quantum dots) glow when exposed to ultraviolet light. When injected, they seep into cancer tumors. The surgeon can see the glowing tumor, and use it as a guide for more accurate tumor removal.These nanoparticles are much brighter than organic dyes and only need one light source for excitation. This means that the use of fluorescent quantum dots could produce a higher contrast image and at a lower cost than today's organic dyes used as contrast media. The downside, however, is that quantum dots are usually made of quite toxic elements.
Tracking movement can help determine how well drugs are being distributed or how substances are metabolized. It is difficult to track a small group of cells throughout the body, so scientists used to dye the cells. These dyes needed to be excited by light of a certain wavelength in order for them to light up. While different color dyes absorb different frequencies of light, there was a need for as many light sources as cells. A way around this problem is with luminescent tags. These tags are quantum dots attached to proteins that penetrate cell membranes. The dots can be random in size, can be made of bio-inert material, and they demonstrate the nanoscale property that color is size-dependent. As a result, sizes are selected so that the frequency of light used to make a group of quantum dots fluoresce is an even multiple of the frequency required to make another group incandesce. Then both groups can be lit with a single light source. They have also found a way to insert nanoparticles into the affected parts of the body so that those parts of the body will glow showing the tumor growth or shrinkage or also organ trouble.
Sensing.
Nanotechnology-on-a-chip is one more dimension of lab-on-a-chip technology. Magnetic nanoparticles, bound to a suitable antibody, are used to label specific molecules, structures or microorganisms. Gold nanoparticles tagged with short segments of DNA can be used for detection of genetic sequence in a sample. Multicolor optical coding for biological assays has been achieved by embedding different-sized quantum dots into polymeric microbeads. Nanopore technology for analysis of nucleic acids converts strings of nucleotides directly into electronic signatures.
Sensor test chips containing thousands of nanowires, able to detect proteins and other biomarkers left behind by cancer cells, could enable the detection and diagnosis of cancer in the early stages from a few drops of a patient's blood.Nanotechnology is helping to advance the use of arthroscopes, which are pencil-sized devices that are used in surgeries with lights and cameras so surgeons can do the surgeries with smaller incisions. The smaller the incisions the faster the healing time which is better for the patients. It is also helping to find a way to make an arthroscope smaller than a strand of hair.
Blood purification.
Magnetic micro particles are proven research instruments for the separation of cells and proteins from complex media. The technology is available under the name Magnetic-activated cell sorting or Dynabeads among others. More recently it was shown in animal models that magnetic nanoparticles can be used for the removal of various noxious compounds including toxins, pathogens, and proteins from whole blood in an extracorporeal circuit similar to dialysis. In contrast to dialysis, which works on the principle of the size related diffusion of solutes and ultrafiltration of fluid across a semi-permeable membrane, the purification with nanoparticles allows specific targeting of substances. Additionally larger compounds which are commonly not dialyzable can be removed.
The purification process is based on functionalized iron oxide or carbon coated metal nanoparticles with ferromagnetic or superparamagnetic properties. Binding agents such as proteins, antibodies, antibiotics, or synthetic ligands are covalently linked to the particle surface. These binding agents are able to interact with target species forming an agglomerate. Applying an external magnetic field gradient allows exerting a force on the nanoparticles. Hence the particles can be separated from the bulk fluid, thereby cleaning it from the contaminants.
The small size (< 100 nm) and large surface area of functionalized nanomagnets leads to advantageous properties compared to hemoperfusion, which is a clinically used technique for the purification of blood and is based on surface adsorption. These advantages are high loading and accessibility of the binding agents, high selectivity towards the target compound, fast diffusion, small hydrodynamic resistance, and low dosage.
This approach offers new therapeutic possibilities for the treatment of systemic infections such as sepsis by directly removing the pathogen. It can also be used to selectively remove cytokines or endotoxins or for the dialysis of compounds which are not accessible by traditional dialysis methods. However the technology is still in a preclinical phase and first clinical trials are not expected before 2017.
Tissue engineering.
Nanotechnology may be used as part of tissue engineering to help reproduce or repair damaged tissue using suitable nanomaterial-based scaffolds and growth factors. Tissue engineering if successful may replace conventional treatments like organ transplants or artificial implants. Nanoparticles such as graphene, carbon nanotubes, molybdenum disulfide and tungsten disulfide are being used as reinforcing agents to fabricate mechanically strong biodegradable polymeric nanocomposites for bone tissue engineering applications. The addition of these nanoparticles in the polymer matrix at low concentrations (~0.2 weight %) leads to significant improvements in the compressive and flexural mechanical properties of polymeric nanocomposites. Potentially, these nanocomposites may be used as a novel, mechanically strong, light weight composite as bone implants.
For example, a flesh welder was demonstrated to fuse two pieces of chicken meat into a single piece using a suspension of gold-coated nanoshells activated by an infrared laser. This could be used to weld arteries during surgery.
Another example is nanonephrology, the use of nanomedicine on the kidney.
Medical devices.
Neuro-electronic interfacing is a visionary goal dealing with the construction of nanodevices that will permit computers to be joined and linked to the nervous system. This idea requires the building of a molecular structure that will permit control and detection of nerve impulses by an external computer. A refuelable strategy implies energy is refilled continuously or periodically with external sonic, chemical, tethered, magnetic, or biological electrical sources, while a nonrefuelable strategy implies that all power is drawn from internal energy storage which would stop when all energy is drained. A nanoscale enzymatic biofuel cell for self-powered nanodevices have been developed that uses glucose from biofluids including human blood and watermelons. One limitation to this innovation is the fact that electrical interference or leakage or overheating from power consumption is possible. The wiring of the structure is extremely difficult because they must be positioned precisely in the nervous system. The structures that will provide the interface must also be compatible with the body's immune system.
Molecular nanotechnology is a speculative subfield of nanotechnology regarding the possibility of engineering molecular assemblers, machines which could re-order matter at a molecular or atomic scale. Nanomedicine would make use of these nanorobots, introduced into the body, to repair or detect damages and infections. Molecular nanotechnology is highly theoretical, seeking to anticipate what inventions nanotechnology might yield and to propose an agenda for future inquiry. The proposed elements of molecular nanotechnology, such as molecular assemblers and nanorobots are far beyond current capabilities.

</doc>
<doc id="21518" url="http://en.wikipedia.org/wiki?curid=21518" title="NMR (disambiguation)">
NMR (disambiguation)

NMR may refer to:
Applications of nuclear magnetic resonance
History and culture studies
Entertainment media

</doc>
<doc id="21520" url="http://en.wikipedia.org/wiki?curid=21520" title="Null set">
Null set

In mathematics, a null set is a set that is negligible "in some sense". For different applications, the meaning of "negligible" varies. In measure theory, any set of measure 0 is called a null set (or simply a measure-zero set). More generally, whenever an ideal is taken as understood, then a null set is any element of that ideal.
The remainder of this article discusses the measure-theoretic notion.
Definition.
Let "X" be a measurable space, let μ be a measure on "X", and let "N" be a measurable set in "X". If μ is a positive measure, then "N" is null (or "zero measure") if its measure μ("N") is zero. If μ is not a positive measure, then "N" is μ-null if "N" is |μ|-null, where |μ| is the total variation of μ; equivalently, if every measurable subset "A" of "N" satisfies μ("A") = 0. For positive measures, this is equivalent to the definition given above; but for signed measures, this is stronger than simply saying that μ("N") = 0.
A nonmeasurable set is considered null if it is a subset of a null measurable set. Some references require a null set to be measurable; however, subsets of null sets are still negligible for measure-theoretic purposes. 
When talking about null sets in Euclidean "n"-space R"n", it is usually understood that the measure being used is Lebesgue measure.
Properties.
The empty set is always a null set. More generally, any countable union of null sets is null. Any measurable subset of a null set is itself a null set. Together, these facts show that the "m"-null sets of "X" form a sigma-ideal on "X". Similarly, the measurable "m"-null sets form a sigma-ideal of the sigma-algebra of measurable sets. Thus, null sets may be interpreted as negligible sets, defining a notion of almost everywhere.
Lebesgue measure.
The Lebesgue measure is the standard way of assigning a length, area or volume to subsets of Euclidean space.
A subset "N" of R has null Lebesgue measure and is considered to be a null set in R if and only if:
This condition can be generalised to R"n", using "n"-cubes instead of intervals. In fact, the idea can be made to make sense on any topological manifold, even if there is no Lebesgue measure there.
For instance:
Uses.
Null sets play a key role in the definition of the Lebesgue integral: if functions "f" and "g" are equal except on a null set, then "f" is integrable if and only if "g" is, and their integrals are equal.
A measure in which all subsets of null sets are measurable is "complete". Any non-complete measure can be completed to form a complete measure by asserting that subsets of null sets have measure zero. Lebesgue measure is an example of a complete measure; in some constructions, it's defined as the completion of a non-complete Borel measure.
A subset of the Cantor set which is not Borel measurable.
The Borel measure is not complete. One simple construction is to start with the standard Cantor set "K", which is closed hence Borel measurable, and which has measure zero, and to find a subset "F" of "K" which is not Borel measurable. (Since the Lebesgue measure is complete, this "F" is of course Lebesgue measurable.)
First, we have to know that every set of positive measure contains a nonmeasurable subset. Let "f" be the Cantor function, a continuous function which is locally constant on "Kc", and monotonically increasing on [0, 1], with "f"(0) = 0 and "f"(1) = 1. Obviously, "f"("Kc") is countable, since it contains one point per component of "Kc". Hence "f"("Kc") has measure zero, so "f"("K") has measure one. We need a strictly monotonic function, so consider "g"("x") = "f"("x") + "x". Since "g"("x") is strictly monotonic and continuous, it is a homeomorphism. Furthermore, "g"("K") has measure one. Let "E" ⊂ "g"("K") be non-measurable, and let "F" = "g"−1("E"). Because "g" is injective, we have that "F" ⊂ "K", and so "F" is a null set. However, if it were Borel measurable, then "g"("F") would also be Borel measurable (here we use the fact that the preimage of a Borel set by a continuous function is measurable; "g"("F") = ("g"−1)−1("F") is the preimage of "F" through the continuous function "h" = "g"−1.) Therefore, "F" is a null, but non-Borel measurable set.

</doc>
<doc id="21522" url="http://en.wikipedia.org/wiki?curid=21522" title="November 24">
November 24

November 24 is the day of the year in the Gregorian calendar.

</doc>
<doc id="21523" url="http://en.wikipedia.org/wiki?curid=21523" title="Artificial neural network">
Artificial neural network

In machine learning and cognitive science, artificial neural networks (ANNs) are a family of statistical learning models inspired by biological neural networks (the central nervous systems of animals, in particular the brain) and are used to estimate or approximate functions that can depend on a large number of inputs and are generally unknown. Artificial neural networks are generally presented as systems of interconnected "neurons" which send messages to each other. The connections have numeric weights that can be tuned based on experience, making neural nets adaptive to inputs and capable of learning.
For example, a neural network for handwriting recognition is defined by a set of input neurons which may be activated by the pixels of an input image. After being weighted and transformed by a function (determined by the network's designer), the activations of these neurons are then passed on to other neurons. This process is repeated until finally, an output neuron is activated. This determines which character was read.
Like other machine learning methods - systems that learn from data - neural networks have been used to solve a wide variety of tasks that are hard to solve using ordinary rule-based programming, including computer vision and speech recognition.
Background.
Examinations of the human's central nervous system inspired the concept of neural networks. In an Artificial Neural Network, simple artificial nodes, known as "neurons", "neurodes", "processing elements" or "units", are connected together to form a network which mimics a biological neural network.
There is no single formal definition of what an artificial neural network is. However, a class of statistical models may commonly be called "Neural" if they possess the following characteristics:
The adaptive weights are conceptually connection strengths between neurons, which are activated during training and prediction.
Neural networks are similar to biological neural networks in performing functions collectively and in parallel by the units, rather than there being a clear delineation of subtasks to which various units are assigned. The term "neural network" usually refers to models employed in statistics, cognitive psychology and artificial intelligence. Neural network models which emulate the central nervous system are part of theoretical neuroscience and computational neuroscience.
In modern software implementations of artificial neural networks, the approach inspired by biology has been largely abandoned for a more practical approach based on statistics and signal processing. In some of these systems, neural networks or parts of neural networks (like artificial neurons) form components in larger systems that combine both adaptive and non-adaptive elements. While the more general approach of such systems is more suitable for real-world problem solving, it has little to do with the traditional artificial intelligence connectionist models. What they do have in common, however, is the principle of non-linear, distributed, parallel and local processing and adaptation. Historically, the use of neural networks models marked a paradigm shift in the late eighties from high-level (symbolic) AI, characterized by expert systems with knowledge embodied in "if-then" rules, to low-level (sub-symbolic) machine learning, characterized by knowledge embodied in the parameters of a dynamical system.
History.
Warren McCulloch and Walter Pitts (1943) created a computational model for neural networks based on mathematics and algorithms called threshold logic. This model paved the way for neural network research to split into two distinct approaches. One approach focused on biological processes in the brain and the other focused on the application of neural networks to artificial intelligence.
In the late 1940s psychologist Donald Hebb created a hypothesis of learning based on the mechanism of neural plasticity that is now known as Hebbian learning. Hebbian learning is considered to be a 'typical' unsupervised learning rule and its later variants were early models for long term potentiation. These ideas started being applied to computational models in 1948 with Turing's B-type machines.
Farley and Wesley A. Clark (1954) first used computational machines, then called calculators, to simulate a Hebbian network at MIT. Other neural network computational machines were created by Rochester, Holland, Habit, and Duda (1956).
Frank Rosenblatt (1958) created the perceptron, an algorithm for pattern recognition based on a two-layer learning computer network using simple addition and subtraction. With mathematical notation, Rosenblatt also described circuitry not in the basic perceptron, such as the exclusive-or circuit, a circuit whose mathematical computation could not be processed until after the backpropagation algorithm was created by Paul Werbos (1975).
Neural network research stagnated after the publication of machine learning research by Marvin Minsky and Seymour Papert (1969), who discovered two key issues with the computational machines that processed neural networks. The first was that single-layer neural networks were incapable of processing the exclusive-or circuit. The second significant issue was that computers were not sophisticated enough to effectively handle the long run time required by large neural networks. Neural network research slowed until computers achieved greater processing power. Also key later advances was the backpropagation algorithm which effectively solved the exclusive-or problem (Werbos 1975).
The parallel distributed processing of the mid-1980s became popular under the name connectionism. The text by David E. Rumelhart and James McClelland (1986) provided a full exposition on the use of connectionism in computers to simulate neural processes.
Neural networks, as used in artificial intelligence, have traditionally been viewed as simplified models of neural processing in the brain, even though the relation between this model and brain biological architecture is debated, as it is not clear to what degree artificial neural networks mirror brain function.
Neural networks were gradually overtaken in popularity in machine learning by support vector machines and other, much simpler methods such as linear classifiers. Renewed interest in neural nets was sparked in the late 2000s by the advent of deep learning.
Improvements since 2006.
Computational devices have been created in CMOS, for both biophysical simulation and neuromorphic computing. More recent efforts show promise for creating nanodevices for very large scale principal components analyses and convolution. If successful, these efforts could usher in a new era of neural computing that is a step beyond digital computing, because it depends on learning rather than programming and because it is fundamentally analog rather than digital even though the first instantiations may in fact be with CMOS digital devices.
Between 2009 and 2012, the recurrent neural networks and deep feedforward neural networks developed in the research group of Jürgen Schmidhuber at the Swiss AI Lab IDSIA have won eight international competitions in pattern recognition and machine learning. For example, the bi-directional and multi-dimensional long short term memory (LSTM) of Alex Graves et al. won three competitions in connected handwriting recognition at the 2009 International Conference on Document Analysis and Recognition (ICDAR), without any prior knowledge about the three different languages to be learned.
Fast GPU-based implementations of this approach by Dan Ciresan and colleagues at IDSIA have won several pattern recognition contests, including the IJCNN 2011 Traffic Sign Recognition Competition, the ISBI 2012 Segmentation of Neuronal Structures in Electron Microscopy Stacks challenge, and others. Their neural networks also were the first artificial pattern recognizers to achieve human-competitive or even superhuman performance
on important benchmarks such as traffic sign recognition (IJCNN 2012), or the MNIST handwritten digits problem of Yann LeCun at NYU.
Deep, highly nonlinear neural architectures similar to the 1980 neocognitron by Kunihiko Fukushima
and the "standard architecture of vision", inspired by the simple and complex cells identified by David H. Hubel and Torsten Wiesel in the primary visual cortex, can also be pre-trained by unsupervised methods
of Geoff Hinton's lab at University of Toronto. A team from this lab won a 2012 contest sponsored by Merck to design software to help find molecules that might lead to new drugs.
Models.
Neural network models in artificial intelligence are usually referred to as artificial neural networks (ANNs); these are essentially simple mathematical models defining a function formula_1 or a distribution over formula_2 or both formula_2 and formula_4, but sometimes models are also intimately associated with a particular learning algorithm or learning rule. A common use of the phrase ANN model really means the definition of a "class" of such functions (where members of the class are obtained by varying parameters, connection weights, or specifics of the architecture such as the number of neurons or their connectivity).
Network function.
The word "network" in the term 'artificial neural network' refers to the inter–connections between the neurons in the different layers of each system. An example system has three layers. The first layer has input neurons which send data via synapses to the second layer of neurons, and then via more synapses to the third layer of output neurons. More complex systems will have more layers of neurons with some having increased layers of input neurons and output neurons. The synapses store parameters called "weights" that manipulate the data in the calculations.
An ANN is typically defined by three types of parameters:
Mathematically, a neuron's network function formula_5 is defined as a composition of other functions formula_6, which can further be defined as a composition of other functions. This can be conveniently represented as a network structure, with arrows depicting the dependencies between variables. A widely used type of composition is the "nonlinear weighted sum", where formula_7, where formula_8 (commonly referred to as the activation function) is some predefined function, such as the hyperbolic tangent. It will be convenient for the following to refer to a collection of functions formula_9 as simply a vector formula_10.
This figure depicts such a decomposition of formula_11, with dependencies between variables indicated by arrows. These can be interpreted in two ways.
The first view is the functional view: the input formula_12 is transformed into a 3-dimensional vector formula_13, which is then transformed into a 2-dimensional vector formula_14, which is finally transformed into formula_11. This view is most commonly encountered in the context of optimization.
The second view is the probabilistic view: the random variable formula_16 depends upon the random variable formula_17, which depends upon formula_18, which depends upon the random variable formula_2. This view is most commonly encountered in the context of graphical models.
The two views are largely equivalent. In either case, for this particular network architecture, the components of individual layers are independent of each other (e.g., the components of formula_14 are independent of each other given their input formula_13). This naturally enables a degree of parallelism in the implementation.
Networks such as the previous one are commonly called feedforward, because their graph is a directed acyclic graph. Networks with cycles are commonly called recurrent. Such networks are commonly depicted in the manner shown at the top of the figure, where formula_11 is shown as being dependent upon itself. However, an implied temporal dependence is not shown.
Learning.
What has attracted the most interest in neural networks is the possibility of "learning". Given a specific "task" to solve, and a "class" of functions formula_23, learning means using a set of "observations" to find formula_24 which solves the task in some "optimal" sense.
This entails defining a cost function formula_25 such that, for the optimal solution formula_26, formula_27 formula_28 – i.e., no solution has a cost less than the cost of the optimal solution (see Mathematical optimization).
The cost function formula_29 is an important concept in learning, as it is a measure of how far away a particular solution is from an optimal solution to the problem to be solved. Learning algorithms search through the solution space to find a function that has the smallest possible cost.
For applications where the solution is dependent on some data, the cost must necessarily be a "function of the observations", otherwise we would not be modelling anything related to the data. It is frequently defined as a statistic to which only approximations can be made. As a simple example, consider the problem of finding the model formula_11, which minimizes formula_31, for data pairs formula_32 drawn from some distribution formula_33. In practical situations we would only have formula_34 samples from formula_33 and thus, for the above example, we would only minimize formula_36. Thus, the cost is minimized over a sample of the data rather than the entire data set.
When formula_37 some form of online machine learning must be used, where the cost is partially minimized as each new example is seen. While online machine learning is often used when formula_33 is fixed, it is most useful in the case where the distribution changes slowly over time. In neural network methods, some form of online machine learning is frequently used for finite datasets.
Choosing a cost function.
While it is possible to define some arbitrary ad hoc cost function, frequently a particular cost will be used, either because it has desirable properties (such as convexity) or because it arises naturally from a particular formulation of the problem (e.g., in a probabilistic formulation the posterior probability of the model can be used as an inverse cost). Ultimately, the cost function will depend on the desired task. An overview of the three main categories of learning tasks is provided below:
Learning paradigms.
There are three major learning paradigms, each corresponding to a particular abstract learning task. These are supervised learning, unsupervised learning and reinforcement learning.
Supervised learning.
In supervised learning, we are given a set of example pairs formula_39 and the aim is to find a function formula_1 in the allowed class of functions that matches the examples. In other words, we wish to "infer" the mapping implied by the data; the cost function is related to the mismatch between our mapping and the data and it implicitly contains prior knowledge about the problem domain.
A commonly used cost is the mean-squared error, which tries to minimize the average squared error between the network's output, formula_5, and the target value formula_42 over all the example pairs. When one tries to minimize this cost using gradient descent for the class of neural networks called multilayer perceptrons, one obtains the common and well-known backpropagation algorithm for training neural networks.
Tasks that fall within the paradigm of supervised learning are pattern recognition (also known as classification) and regression (also known as function approximation). The supervised learning paradigm is also applicable to sequential data (e.g., for speech and gesture recognition). This can be thought of as learning with a "teacher", in the form of a function that provides continuous feedback on the quality of solutions obtained thus far.
Unsupervised learning.
In unsupervised learning, some data formula_12 is given and the cost function to be minimized, that can be any function of the data formula_12 and the network's output, formula_11.
The cost function is dependent on the task (what we are trying to model) and our "a priori" assumptions (the implicit properties of our model, its parameters and the observed variables).
As a trivial example, consider the model formula_46 where formula_47 is a constant and the cost formula_48. Minimizing this cost will give us a value of formula_47 that is equal to the mean of the data. The cost function can be much more complicated. Its form depends on the application: for example, in compression it could be related to the mutual information between formula_12 and formula_5, whereas in statistical modeling, it could be related to the posterior probability of the model given the data (note that in both of those examples those quantities would be maximized rather than minimized).
Tasks that fall within the paradigm of unsupervised learning are in general estimation problems; the applications include clustering, the estimation of statistical distributions, compression and filtering.
Reinforcement learning.
In reinforcement learning, data formula_12 are usually not given, but generated by an agent's interactions with the environment. At each point in time formula_53, the agent performs an action formula_54 and the environment generates an observation formula_55 and an instantaneous cost formula_56, according to some (usually unknown) dynamics. The aim is to discover a "policy" for selecting actions that minimizes some measure of a long-term cost; i.e., the expected cumulative cost. The environment's dynamics and the long-term cost for each policy are usually unknown, but can be estimated.
More formally the environment is modelled as a Markov decision process (MDP) with states formula_57 and actions formula_58 with the following probability distributions: the instantaneous cost distribution formula_59, the observation distribution formula_60 and the transition formula_61, while a policy is defined as conditional distribution over actions given the observations. Taken together, the two then define a Markov chain (MC). The aim is to discover the policy that minimizes the cost; i.e., the MC for which the cost is minimal.
ANNs are frequently used in reinforcement learning as part of the overall algorithm. Dynamic programming has been coupled with ANNs (Neuro dynamic programming) by Bertsekas and Tsitsiklis and applied to multi-dimensional nonlinear problems such as those involved in vehicle routing, natural resources management or medicine because of the ability of ANNs to mitigate losses of accuracy even when reducing the discretization grid density for numerically approximating the solution of the original control problems.
Tasks that fall within the paradigm of reinforcement learning are control problems, games and other sequential decision making tasks.
Learning algorithms.
Training a neural network model essentially means selecting one model from the set of allowed models (or, in a Bayesian framework, determining a distribution over the set of allowed models) that minimizes the cost criterion. There are numerous algorithms available for training neural network models; most of them can be viewed as a straightforward application of optimization theory and statistical estimation.
Most of the algorithms used in training artificial neural networks employ some form of gradient descent, using backpropagation to compute the actual gradients. This is done by simply taking the derivative of the cost function with respect to the network parameters and then changing those parameters in a gradient-related direction.
Evolutionary methods, gene expression programming, simulated annealing, expectation-maximization, non-parametric methods and particle swarm optimization are some commonly used methods for training neural networks. 
Employing artificial neural networks.
Perhaps the greatest advantage of ANNs is their ability to be used as an arbitrary function approximation mechanism that 'learns' from observed data. However, using them is not so straightforward, and a relatively good understanding of the underlying theory is essential.
With the correct implementation, ANNs can be used naturally in online learning and large data set applications. Their simple implementation and the existence of mostly local dependencies exhibited in the structure allows for fast, parallel implementations in hardware.
Applications.
The utility of artificial neural network models lies in the fact that they can be used to infer a function from observations. This is particularly useful in applications where the complexity of the data or task makes the design of such a function by hand impractical.
Real-life applications.
The tasks artificial neural networks are applied to tend to fall within the following broad categories:
Application areas include the system identification and control (vehicle control, process control, natural resources management), quantum chemistry, game-playing and decision making (backgammon, chess, poker), pattern recognition (radar systems, face identification, object recognition and more), sequence recognition (gesture, speech, handwritten text recognition), medical diagnosis, financial applications (e.g. automated trading systems), data mining (or knowledge discovery in databases, "KDD"), visualization and e-mail spam filtering.
Artificial neural networks have also been used to diagnose several cancers. An ANN based hybrid lung cancer detection system named HLND improves the accuracy of diagnosis and the speed of lung cancer radiology. These networks have also been used to diagnose prostate cancer. The diagnoses can be used to make specific models taken from a large group of patients compared to information of one given patient. The models do not depend on assumptions about correlations of different variables. Colorectal cancer has also been predicted using the neural networks. Neural networks could predict the outcome for a patient with colorectal cancer with more accuracy than the current clinical methods. After training, the networks could predict multiple patient outcomes from unrelated institutions.
Neural networks and neuroscience.
Theoretical and computational neuroscience is the field concerned with the theoretical analysis and the computational modeling of biological neural systems. Since neural systems are intimately related to cognitive processes and behavior, the field is closely related to cognitive and behavioral modeling.
The aim of the field is to create models of biological neural systems in order to understand how biological systems work. To gain this understanding, neuroscientists strive to make a link between observed biological processes (data), biologically plausible mechanisms for neural processing and learning (biological neural network models) and theory (statistical learning theory and information theory).
Types of models.
Many models are used in the field, defined at different levels of abstraction and modeling different aspects of neural systems. They range from models of the short-term behavior of individual neurons, models of how the dynamics of neural circuitry arise from interactions between individual neurons and finally to models of how behavior can arise from abstract neural modules that represent complete subsystems. These include models of the long-term, and short-term plasticity, of neural systems and their relations to learning and memory from the individual neuron to the system level.
Neural network software.
Neural network software is used to simulate, research, develop and apply artificial neural networks, biological neural networks and, in some cases, a wider array of adaptive systems.
Types of artificial neural networks.
Artificial neural network types vary from those with only one or two layers of single direction logic, to complicated multi–input many directional feedback loops and layers. On the whole, these systems use algorithms in their programming to determine control and organization of their functions. 
Most systems use "weights" to change the parameters of the throughput and the varying connections to the neurons. Artificial neural networks can be autonomous and learn by input from outside "teachers" or even self-teaching from written-in rules.
Theoretical properties.
<section begin=theory />
Computational power.
The multi-layer perceptron (MLP) is a universal function approximator, as proven by the universal approximation theorem. However, the proof is not constructive regarding the number of neurons required or the settings of the weights.
Work by Hava Siegelmann and Eduardo D. Sontag has provided a proof that a specific recurrent architecture with rational valued weights (as opposed to full precision real number-valued weights) has the full power of a Universal Turing Machine using a finite number of neurons and standard linear connections. Further, it has been shown that the use of irrational values for weights results in a machine with super-Turing power.
Capacity.
Artificial neural network models have a property called 'capacity', which roughly corresponds to their ability to model any given function. It is related to the amount of information that can be stored in the network and to the notion of complexity.
Convergence.
Nothing can be said in general about convergence since it depends on a number of factors. Firstly, there may exist many local minima. This depends on the cost function and the model. Secondly, the optimization method used might not be guaranteed to converge when far away from a local minimum. Thirdly, for a very large amount of data or parameters, some methods become impractical. In general, it has been found that theoretical guarantees regarding convergence are an unreliable guide to practical application. 
Generalization and statistics.
In applications where the goal is to create a system that generalizes well in unseen examples, the problem of over-training has emerged. This arises in convoluted or over-specified systems when the capacity of the network significantly exceeds the needed free parameters. There are two schools of thought for avoiding this problem: The first is to use cross-validation and similar techniques to check for the presence of overtraining and optimally select hyperparameters such as to minimize the generalization error. The second is to use some form of "regularization". This is a concept that emerges naturally in a probabilistic (Bayesian) framework, where the regularization can be performed by selecting a larger prior probability over simpler models; but also in statistical learning theory, where the goal is to minimize over two quantities: the 'empirical risk' and the 'structural risk', which roughly corresponds to the error over the training set and the predicted error in unseen data due to overfitting.
Supervised neural networks that use a mean squared error (MSE) cost function can use formal statistical methods to determine the confidence of the trained model. The MSE on a validation set can be used as an estimate for variance. This value can then be used to calculate the confidence interval of the output of the network, assuming a normal distribution. A confidence analysis made this way is statistically valid as long as the output probability distribution stays the same and the network is not modified.
By assigning a softmax activation function, a generalization of the logistic function, on the output layer of the neural network (or a softmax component in a component-based neural network) for categorical target variables, the outputs can be interpreted as posterior probabilities. This is very useful in classification as it gives a certainty measure on classifications.
The softmax activation function is:
<section end=theory />
Controversies.
Training issues.
A common criticism of neural networks, particularly in robotics, is that they require a large diversity of training for real-world operation . This is not surprising, since any learning machine needs sufficient representative examples in order to capture the underlying structure that allows it to generalize to new cases. Dean Pomerleau, in his research presented in the paper "Knowledge-based Training of Artificial Neural Networks for Autonomous Robot Driving," uses a neural network to train a robotic vehicle to drive on multiple types of roads (single lane, multi-lane, dirt, etc.). A large amount of his research is devoted to (1) extrapolating multiple training scenarios from a single training experience, and (2) preserving past training diversity so that the system does not become overtrained (if, for example, it is presented with a series of right turns – it should not learn to always turn right). These issues are common in neural networks that must decide from amongst a wide variety of responses, but can be dealt with in several ways, for example by randomly shuffling the training examples, by using a numerical optimization algorithm that does not take too large steps when changing the network connections following an example, or by grouping examples in so-called mini-batches.
A. K. Dewdney, a former "Scientific American" columnist, wrote in 1997, "Although neural nets do solve a few toy problems, their powers of computation are so limited that I am surprised anyone takes them seriously as a general problem-solving tool." (Dewdney, p. 82)
Hardware issues.
To implement large and effective software neural networks, considerable processing and storage resources need to be committed . While the brain has hardware tailored to the task of processing signals through a graph of neurons, simulating even a most simplified form on Von Neumann technology may compel a neural network designer to fill many millions of database rows for its connections – which can consume vast amounts of computer memory and hard disk space. Furthermore, the designer of neural network systems will often need to simulate the transmission of signals through many of these connections and their associated neurons – which must often be matched with incredible amounts of CPU processing power and time. While neural networks often yield "effective" programs, they too often do so at the cost of "efficiency" (they tend to consume considerable amounts of time and money).
Computing power continues to grow roughly according to Moore's Law, which may provide sufficient resources to accomplish new tasks. Neuromorphic engineering addresses the hardware difficulty directly, by constructing non-Von-Neumann chips with circuits designed to implement neural nets from the ground up.
Practical counterexamples to criticisms.
Arguments against Dewdney's position are that neural networks have been successfully used to solve many complex and diverse tasks, ranging from autonomously flying aircraft to detecting credit card fraud .
Technology writer Roger Bridgman commented on Dewdney's statements about neural nets:
Neural networks, for instance, are in the dock not only because they have been hyped to high heaven, (what hasn't?) but also because you could create a successful net without understanding how it worked: the bunch of numbers that captures its behaviour would in all probability be "an opaque, unreadable table...valueless as a scientific resource".
In spite of his emphatic declaration that science is not technology, Dewdney seems here to pillory neural nets as bad science when most of those devising them are just trying to be good engineers. An unreadable table that a useful machine could read would still be well worth having.
Although it is true that analyzing what has been learned by an artificial neural network is difficult, it is much easier to do so than to analyze what has been learned by a biological neural network. Furthermore, researchers involved in exploring learning algorithms for neural networks are gradually uncovering generic principles which allow a learning machine to be successful. For example, Bengio and LeCun (2007) wrote an article regarding local vs non-local learning, as well as shallow vs deep architecture.
Hybrid approaches.
Some other criticisms come from advocates of hybrid models (combining neural networks and symbolic approaches), who believe that the intermix of these two approaches can better capture the mechanisms of the human mind.
Bibliography.
</dl>

</doc>
<doc id="21525" url="http://en.wikipedia.org/wiki?curid=21525" title="Nutrition">
Nutrition

Nutrition is the science that interprets the interaction of nutrients and other substances in food (e.g. phytonutrients, anthocyanins, tannins, etc.) in relation to maintenance, growth, reproduction, health and disease of an organism. It includes food intake, absorption, assimilation, biosynthesis, catabolism and excretion.
The diet of an organism is what it eats, which is largely determined by the availability, processing and palatability of foods. A healthy diet includes preparation of food and storage methods that preserve nutrients from oxidation, heat or leaching, and that reduce risk of food-born illnesses.
Registered dietitian nutritionists (RDs or RDNs) are health professionals qualified to provide safe, evidence-based dietary advice which includes a review of what is eaten, a thorough review of nutritional health, and a personalized nutritional treatment plan. They also provide preventive and therapeutic programs at work places, schools and similar institutions. Certified Clinical Nutritionists or CCNs, are trained health professionals who also offer dietary advice on the role of nutrition in chronic disease, including possible prevention or remediation by addressing nutritional deficiencies before resorting to drugs. Government regulation especially in terms of licensing, is currently less universal for the CCN than that of RD or RDN.
A poor diet may have an injurious impact on health, causing deficiency diseases such as blindness, anemia, scurvy, preterm birth, stillbirth and cretinism; health-threatening conditions like obesity and metabolic syndrome; and such common chronic systemic diseases as cardiovascular disease, diabetes, and osteoporosis. A poor diet can cause the wasting of kwashiorkor in acute cases, and the stunting of marasmus in chronic cases of malnutrition.
History.
Antiquity.
The first recorded dietary advice, carved into a Babylonian stone tablet in about 2500 BC, cautioned those with pain inside to avoid eating onions for three days. Scurvy, later found to be a vitamin C deficiency, was first described in 1500 BC in the Ebers Papyrus.
According to Walter Gratzer, the study of nutrition probably began during the 6th century BC. In China, the concept of "Qi" developed, a spirit or "wind" similar to what Western Europeans later called "pneuma". Food was classified into "hot" (for example, meats, blood, ginger, and hot spices) and "cold" (green vegetables) in China, India, Malaya, and Persia. "Humours" developed perhaps first in China alongside "qi". Ho the Physician concluded that diseases are caused by deficiencies of elements (Wu Xing: fire, water, earth, wood, and metal), and he classified diseases as well as prescribed diets. About the same time in Italy, Alcmaeon of Croton (a Greek) wrote of the importance of equilibrium between what goes in and what goes out, and warned that imbalance would result disease marked by obesity or emaciation.
Around 475 BC, Anaxagoras stated that food is absorbed by the human body and, therefore, contains "homeomerics" (generative components), suggesting the existence of nutrients. Around 400 BC, Hippocrates, who recognized and was concerned with obesity, which may have been common in southern Europe at the time, said, "Let food be your medicine and medicine be your food." The works that are still attributed to him, "Corpus Hippocraticum", called for moderation and emphasized exercise.
Salt, pepper and other spices were prescribed for various ailments in various preparations for example mixed with vinegar. In the 2nd century BC, Cato the Elder believed that cabbage (or the urine of cabbage-eaters) could cure digestive diseases, ulcers, warts, and intoxication. Living about the turn of the millennium, Aulus Celsus, an ancient Roman doctor, believed in "strong" and "weak" foods (bread for example was strong, as were older animals and vegetables).
Galen to Lind.
One mustn't overlook the doctrines of Galen: In use from his life in the 1st century AD until the 17th century, it was heresy to disagree with him for 1500 years. Galen was physician to gladiators in Pergamon, and in Rome, physician to Marcus Aurelius and the three emperors who succeeded him. Most of Galen's teachings were gathered and enhanced in the late 11th century by Benedictine monks at the School of Salerno in "Regimen sanitatis Salernitanum", which still had users in the 17th century. Galen believed in the bodily "humours" of Hippocrates, and he taught that "pneuma" is the source of life. Four elements (earth, air, fire and water) combine into "complexion", which combines into states (the four temperaments: sanguine, phlegmatic, choleric, and melancholic). The states are made up of pairs of attributes (hot and moist, cold and moist, hot and dry, and cold and dry), which are made of four humours: blood, phlegm, green (or yellow) bile, and black bile (the bodily form of the elements). Galen thought that for a person to have gout, kidney stones, or arthritis was scandalous, which Gratzer likens to Samuel Butler's "Erehwon" (1872) where sickness is a crime.
In the 1500s, Paracelsus was probably the first to criticize Galen publicly. Also in the 16th century, scientist and artist Leonardo da Vinci compared metabolism to a burning candle. Leonardo did not publish his works on this subject, but he was not afraid of thinking for himself and he definitely disagreed with Galen. Ultimately, 16th century works of Andreas Vesalius, sometimes called the father of modern medicine, overturned Galen's ideas. He was followed by piercing thought amalgamated with the era's mysticism and religion sometimes fueled by the mechanics of Newton and Galileo. Jan Baptist van Helmont, who discovered several gases such as carbon dioxide, performed the first quantitative experiment. Robert Boyle advanced chemistry. Sanctorius measured body weight. Physician Herman Boerhaave modeled the digestive process. Physiologist Albrecht von Haller worked out the difference between nerves and muscles.
Sometimes overlooked during his life, James Lind, a physician in the British navy, performed the first scientific nutrition experiment in 1747. Lind discovered that lime juice saved sailors that had been at sea for years from scurvy, a deadly and painful bleeding disorder. Between 1500 and 1800, an estimated two million sailors had died of scurvy. The discovery was ignored for forty years, after which British sailors became known as "limeys." The essential vitamin C within citrus fruits would not be identified by scientists until 1932.
Lavoisier and modern science.
Around 1770, Antoine Lavoisier discovered the details of metabolism, demonstrating that the oxidation of food is the source of body heat. He discovered the principle of conservation of mass. His ideas made the phlogiston theory of combustion obsolete.
In 1790, George Fordyce recognized calcium as necessary for fowl survival. In the early 19th century, the elements carbon, nitrogen, hydrogen, and oxygen were recognized as the primary components of food, and methods to measure their proportions were developed.
In 1816, François Magendie discovered that dogs fed only carbohydrates (sugar), fat (olive oil), and water died evidently of starvation, but dogs also fed protein survived, identifying protein as an essential dietary component. William Prout in 1827 was the first person to divide foods into carbohydrates, fat, and protein. During the 19th century, Jean-Baptiste Dumas and Justus von Liebig quarrelled over their shared belief that animals get their protein directly from plants (animal and plant protein are the same and that humans do not create organic compounds). With a reputation as the leading organic chemist of his day but with no credentials in animal physiology, Liebig grew rich making food extracts like beef bouillon and infant formula that were later found to be of questionable nutritious value. In the 1860s, Claude Bernard discovered that body fat can be synthesized from carbohydrate and protein, showing that the energy in blood glucose can be stored as fat or as glycogen.
In the early 1880s, Kanehiro Takaki observed that Japanese sailors (whose diets consisted almost entirely of white rice) developed beriberi (or endemic neuritis, a disease causing heart problems and paralysis), but British sailors and Japanese naval officers did not. Adding various types of vegetables and meats to the diets of Japanese sailors prevented the disease, (not because of the increased protein as Takaki supposed but because it introduced a few parts per million of thiamine to the diet, later understood as a cure).
In 1896, Eugen Baumann observed iodine in thyroid glands. In 1897, Christiaan Eijkman worked with natives of Java, who also suffered from beriberi. Eijkman observed that chickens fed the native diet of white rice developed the symptoms of beriberi but remained healthy when fed unprocessed brown rice with the outer bran intact. Eijkman cured the natives by feeding them brown rice, discovering that food can cure disease. Over two decades later, nutritionists learned that the outer rice bran contains vitamin B1, also known as thiamine.
From 1900 to the present.
In the early 20th century, Carl von Voit and Max Rubner independently measured caloric energy expenditure in different species of animals, applying principles of physics in nutrition. In 1906, Wilcock and Hopkins showed that the amino acid tryptophan is necessary for the survival of rats. He fed them a special mixture of food containing all the nutrients he believed to be essential for survival, but the rats died. A second group of rats were fed an amount of milk containing vitamins. Sir Frederick Hopkins recognized that there exist "accessory food factors" other than calories, protein, and minerals, as organic materials essential to health but that the body cannot synthesize. In 1907, Stephen M. Babcock and Edwin B. Hart conducted the single-grain experiment, which took nearly four years to complete.
Oxford University closed down its nutrition department after World War II because the subject seemed to have been completed between 1912 and 1944.
In 1912, Casimir Funk coined the term vitamin, a vital factor in the diet, from the words "vital" and "amine," because these unknown substances preventing scurvy, beriberi, and pellagra, were thought then to be derived from ammonia. The vitamins were studied in the first half of the 20th century.
In 1913, Elmer McCollum discovered the first vitamins, fat soluble vitamin A, and water soluble vitamin B (in 1915; now known to be a complex of several water-soluble vitamins) and named vitamin C as the then-unknown substance preventing scurvy. Lafayette Mendel and Thomas Osborne also performed pioneering work on vitamins A and B. In 1919, Sir Edward Mellanby incorrectly identified rickets as a vitamin A deficiency because he could cure it in dogs with cod liver oil. In 1922, Elmer McCollum destroyed the vitamin A in cod liver oil, but found that it still cured rickets. Also in 1922, H.M. Evans and L.S. Bishop discover vitamin E as essential for rat pregnancy, originally calling it "food factor X" until 1925.
In 1925, Hart discovered that trace amounts of copper are necessary for iron absorption. In 1927, Adolf Otto Reinhold Windaus synthesized vitamin D, for which he won the Nobel Prize in Chemistry in 1928. In 1928, Albert Szent-Györgyi isolated ascorbic acid, and in 1932 proved that it is vitamin C by preventing scurvy. In 1935, he synthesized it, and in 1937, he won a Nobel Prize for his efforts. Szent-Györgyi concurrently elucidated much of the citric acid cycle.
In the 1930s, William Cumming Rose identified essential amino acids, necessary protein components that the body cannot synthesize. In 1935, Underwood and Marston independently discovered the necessity of cobalt. In 1936, Eugene Floyd DuBois showed that work and school performance are related to caloric intake. In 1938, Erhard Fernholz discovered the chemical structure of vitamin E and then he tragically disappeared. It was synthesised the same year by Paul Karrer.
In 1940, rationing in the United Kingdom during and after World War II took place according to nutritional principles drawn up by Elsie Widdowson and others. In 1941, the first Recommended Dietary Allowances (RDAs) were established by the National Research Council.
In 1992, The U.S. Department of Agriculture introduced the Food Guide Pyramid. In 2002, a Natural Justice study showed a relation between nutrition and violent behavior. In 2005, one inconclusive study found that obesity could be caused by adenovirus in addition to bad nutrition.
World leaders are looking at alternatives like genetically modified foods to tackle the problem of world hunger and food shortages.
Nutrients.
The list of nutrients that people are known to require is, in the words of Marion Nestle, "almost certainly incomplete". As of 2014, nutrients are thought to be of two types: macro-nutrients which are needed in relatively large amounts, and micronutrients which are needed in smaller quantities. A type of carbohydrate, dietary fiber, i.e. non-digestible material such as cellulose, is required, for both mechanical and biochemical reasons, although the exact reasons remain unclear. Other micronutrients include antioxidants and phytochemicals, which are said to influence (or protect) some body systems. Their necessity is not as well established as in the case of, for instance, vitamins.
Most foods contain a mix of some or all of the nutrient types, together with other substances, such as toxins of various sorts. Some nutrients can be stored internally (e.g., the fat soluble vitamins), while others are required more or less continuously. Poor health can be caused by a lack of required nutrients or, in extreme cases, too much of a required nutrient. For example, both salt and water (both absolutely required) will cause illness or even death in excessive amounts.
Macronutrients.
The macronutrients are carbohydrates, fats, protein, and water.
The macronutrients (excluding fiber and water) provide structural material (amino acids from which proteins are built, and lipids from which cell membranes and some signaling molecules are built) and energy. Some of the structural material can be used to generate energy internally, and in either case it is measured in Joules or kilocalories (often called "Calories" and written with a capital "C" to distinguish them from little 'c' calories). Carbohydrates and proteins provide 17 kJ approximately (4 kcal) of energy per gram, while fats provide 37 kJ (9 kcal) per gram, though the net energy from either depends on such factors as absorption and digestive effort, which vary substantially from instance to instance. Vitamins, minerals, fiber, and water do not provide energy, but are required for other reasons.
Molecules of carbohydrates and fats consist of carbon, hydrogen, and oxygen atoms. Carbohydrates range from simple monosaccharides (glucose, fructose, galactose) to complex polysaccharides (starch). Fats are triglycerides, made of assorted fatty acid monomers bound to a glycerol backbone. Some fatty acids, but not all, are essential in the diet: they cannot be synthesized in the body. Protein molecules contain nitrogen atoms in addition to carbon, oxygen, and hydrogen. The fundamental components of protein are nitrogen-containing amino acids, some of which are essential in the sense that humans cannot make them internally. Some of the amino acids are convertible (with the expenditure of energy) to glucose and can be used for energy production, just as ordinary glucose, in a process known as gluconeogenesis. By breaking down existing protein, the carbon skeleton of the various amino acids can be metabolized to intermediates in cellular respiration; the remaining ammonia is discarded primarily as urea in urine. This occurs normally only during prolonged starvation.
Carbohydrates.
Carbohydrates may be classified as monosaccharides, disaccharides, or polysaccharides depending on the number of monomer (sugar) units they contain. They constitute a large part of foods such as rice, noodles, bread, and other grain-based products.
Monosaccharides, disaccharides, and polysaccharides contain one, two, and three or more sugar units, respectively. Polysaccharides are often referred to as "complex" carbohydrates because they are typically long, multiple branched chains of sugar units.
Traditionally, simple carbohydrates are believed to be absorbed quickly, and therefore to raise blood-glucose levels more rapidly than complex carbohydrates. This, however, is not accurate. Some simple carbohydrates (e.g., fructose) follow different metabolic pathways (e.g., fructolysis) that result in only a partial catabolism to glucose, while, in essence, many complex carbohydrates may be digested at the same rate as simple carbohydrates.
Glucose stimulates the production of insulin through food entering the bloodstream, which is grasped by the beta cells in the pancreas.
Fiber.
Dietary fiber is a carbohydrate that is incompletely absorbed in humans and in some animals. Like all carbohydrates, when it is metabolized it can produce four Calories (kilocalories) of energy per gram. However, in most circumstances it accounts for less than that because of its limited absorption and digestibility. Dietary fiber consists mainly of cellulose, a large carbohydrate polymer is indigestible as humans do not have the required enzymes to disassemble it. There are two subcategories: soluble and insoluble fiber. Whole grains, fruits (especially plums, prunes, and figs), and vegetables are good sources of dietary fiber. There are many health benefits of a high-fiber diet. Dietary fiber helps reduce the chance of gastrointestinal problems such as constipation and diarrhea by increasing the weight and size of stool and softening it. Insoluble fiber, found in whole wheat flour, nuts and vegetables, especially stimulates peristalsis – the rhythmic muscular contractions of the intestines, which move digesta along the digestive tract. Soluble fiber, found in oats, peas, beans, and many fruits, dissolves in water in the intestinal tract to produce a gel that slows the movement of food through the intestines. This may help lower blood glucose levels because it can slow the absorption of sugar. Additionally, fiber, perhaps especially that from whole grains, is thought to possibly help lessen insulin spikes, and therefore reduce the risk of type 2 diabetes. The link between increased fiber consumption and a decreased risk of colorectal cancer is still uncertain.
Fat.
A molecule of dietary fat typically consists of several fatty acids (containing long chains of carbon and hydrogen atoms), bonded to a glycerol. They are typically found as triglycerides (three fatty acids attached to one glycerol backbone). Fats may be classified as saturated or unsaturated depending on the detailed structure of the fatty acids involved. Saturated fats have all of the carbon atoms in their fatty acid chains bonded to hydrogen atoms, whereas unsaturated fats have some of these carbon atoms double-bonded, so their molecules have relatively fewer hydrogen atoms than a saturated fatty acid of the same length. Unsaturated fats may be further classified as monounsaturated (one double-bond) or polyunsaturated (many double-bonds). Furthermore, depending on the location of the double-bond in the fatty acid chain, unsaturated fatty acids are classified as omega-3 or omega-6 fatty acids. Trans fats are a type of unsaturated fat with "trans"-isomer bonds; these are rare in nature and in foods from natural sources; they are typically created in an industrial process called (partial) hydrogenation. There are nine kilocalories in each gram of fat. Fatty acids such as conjugated linoleic acid, catalpic acid, eleostearic acid and punicic acid, in addition to providing energy, represent potent immune modulatory molecules.
Saturated fats (typically from animal sources) have been a staple in many world cultures for millennia. Unsaturated fats (e. g., vegetable oil) are considered healthier, while trans fats are to be avoided. Saturated and some trans fats are typically solid at room temperature (such as butter or lard), while unsaturated fats are typically liquids (such as olive oil or flaxseed oil). Trans fats are very rare in nature, and have been shown to be highly detrimental to human health, but have properties useful in the food processing industry, such as rancidity resistance.
Essential fatty acids.
Most fatty acids are non-essential, meaning the body can produce them as needed, generally from other fatty acids and always by expending energy to do so. However, in humans, at least two fatty acids are essential and must be included in the diet. An appropriate balance of essential fatty acids—omega-3 and omega-6 fatty acids—seems also important for health, although definitive experimental demonstration has been elusive. Both of these "omega" long-chain polyunsaturated fatty acids are substrates for a class of eicosanoids known as prostaglandins, which have roles throughout the human body. They are hormones, in some respects. The omega-3 eicosapentaenoic acid (EPA), which can be made in the human body from the omega-3 essential fatty acid alpha-linolenic acid (ALA), or taken in through marine food sources, serves as a building block for series 3 prostaglandins (e.g., weakly inflammatory PGE3). The omega-6 dihomo-gamma-linolenic acid (DGLA) serves as a building block for series 1 prostaglandins (e.g. anti-inflammatory PGE1), whereas arachidonic acid (AA) serves as a building block for series 2 prostaglandins (e.g. pro-inflammatory PGE 2). Both DGLA and AA can be made from the omega-6 linoleic acid (LA) in the human body, or can be taken in directly through food. An appropriately balanced intake of omega-3 and omega-6 partly determines the relative production of different prostaglandins, which is one reason why a balance between omega-3 and omega-6 is believed important for cardiovascular health. In industrialized societies, people typically consume large amounts of processed vegetable oils, which have reduced amounts of the essential fatty acids along with too much of omega-6 fatty acids relative to omega-3 fatty acids.
The conversion rate of omega-6 DGLA to AA largely determines the production of the prostaglandins PGE1 and PGE2. Omega-3 EPA prevents AA from being released from membranes, thereby skewing prostaglandin balance away from pro-inflammatory PGE2 (made from AA) toward anti-inflammatory PGE1 (made from DGLA). Moreover, the conversion (desaturation) of DGLA to AA is controlled by the enzyme delta-5-desaturase, which in turn is controlled by hormones such as insulin (up-regulation) and glucagon (down-regulation). The amount and type of carbohydrates consumed, along with some types of amino acid, can influence processes involving insulin, glucagon, and other hormones; therefore, the ratio of omega-3 versus omega-6 has wide effects on general health, and specific effects on immune function and inflammation, and mitosis (i.e., cell division).
Protein.
Proteins are structural materials in much of the animal body (e.g. muscles, skin, and hair). They also form the enzymes that control chemical reactions throughout the body. Each protein molecule is composed of amino acids, which are characterized by inclusion of nitrogen and sometimes sulphur (these components are responsible for the distinctive smell of burning protein, such as the keratin in hair). The body requires amino acids to produce new proteins (protein retention) and to replace damaged proteins (maintenance). As there is no protein or amino acid storage provision, amino acids must be present in the diet. Excess amino acids are discarded, typically in the urine. For all animals, some amino acids are "essential" (an animal cannot produce them internally) and some are "non-essential" (the animal can produce them from other nitrogen-containing compounds). About twenty amino acids are found in the human body, and about ten of these are essential and, therefore, must be included in the diet. A diet that contains adequate amounts of amino acids (especially those that are essential) is particularly important in some situations: during early development and maturation, pregnancy, lactation, or injury (a burn, for instance). A "complete" protein source contains all the essential amino acids; an "incomplete" protein source lacks one or more of the essential amino acids.
It is possible with protein combinations of two incomplete protein sources (e.g., rice and beans) to make a complete protein source, and characteristic combinations are the basis of distinct cultural cooking traditions. However, complementary sources of protein do not need to be eaten at the same meal to be used together by the body. Excess amino acids from protein can be converted into glucose and used for fuel through a process called gluconeogenesis. The amino acids remaining after such conversion are discarded.
Water.
Water is excreted from the body in multiple forms; including urine and feces, sweating, and by water vapour in the exhaled breath. Therefore it is necessary to adequately rehydrate to replace lost fluids.
Early recommendations for the quantity of water required for maintenance of good health suggested that 6–8 glasses of water daily is the minimum to maintain proper hydration. However the notion that a person should consume eight glasses of water per day cannot be traced to a credible scientific source. The original water intake recommendation in 1945 by the Food and Nutrition Board of the National Research Council read: "An ordinary standard for diverse persons is 1 milliliter for each calorie of food. Most of this quantity is contained in prepared foods." More recent comparisons of well-known recommendations on fluid intake have revealed large discrepancies in the volumes of water we need to consume for good health. Therefore, to help standardize guidelines, recommendations for water consumption are included in two recent European Food Safety Authority (EFSA) documents (2010): (i) Food-based dietary guidelines and (ii) Dietary reference values for water or adequate daily intakes (ADI). These specifications were provided by calculating adequate intakes from measured intakes in populations of individuals with “desirable osmolarity values of urine and desirable water volumes per energy unit consumed.” For healthful hydration, the current EFSA guidelines recommend total water intakes of 2.0 L/day for adult females and 2.5 L/day for adult males. These reference values include water from drinking water, other beverages, and from food. About 80% of our daily water requirement comes from the beverages we drink, with the remaining 20% coming from food. Water content varies depending on the type of food consumed, with fruit and vegetables containing more than cereals, for example. These values are estimated using country-specific food balance sheets published by the Food and Agriculture Organisation of the United Nations. Other guidelines for nutrition also have implications for the beverages we consume for healthy hydration- for example, the World Health Organization (WHO) recommend that added sugars should represent no more than 10% of total energy intake.
The EFSA panel also determined intakes for different populations. Recommended intake volumes in the elderly are the same as for adults as despite lower energy consumption, the water requirement of this group is increased due to a reduction in renal concentrating capacity. Pregnant and breastfeeding women require additional fluids to stay hydrated. The EFSA panel proposes that pregnant women should consume the same volume of water as non-pregnant women, plus an increase in proportion to the higher energy requirement, equal to 300 mL/day. To compensate for additional fluid output, breastfeeding women require an additional 700 mL/day above the recommended intake values for non-lactating women.
For those who have healthy kidneys, it is somewhat difficult to drink too much water, but (especially in warm humid weather and while exercising) it is dangerous to drink too little. While overhydration is much less common than dehydration, it is also possible to drink far more water than necessary, which can result in water intoxication, a serious and potentially fatal condition. In particular, large amounts of de-ionized water are dangerous.
Micronutrients.
The micronutrients are minerals, vitamins, and others.
Minerals.
Dietary minerals are inorganic chemical elements required by living organisms, other than the four elements carbon, hydrogen, nitrogen, and oxygen that are present in nearly all organic molecules. The term "mineral" is archaic, since the intent is to describe simply the less common elements in the diet. Some are heavier than the four just mentioned, including several metals, which often occur as ions in the body. Some dietitians recommend that these be supplied from foods in which they occur naturally, or at least as complex compounds, or sometimes even from natural inorganic sources (such as calcium carbonate from ground oyster shells). Some minerals are absorbed much more readily in the ionic forms found in such sources. On the other hand, minerals are often artificially added to the diet as supplements; the most famous is likely iodine in iodized salt which prevents goiter.
Macrominerals.
Many elements are essential in relative quantity; they are usually called "bulk minerals". Some are structural, but many play a role as electrolytes. Elements with recommended dietary allowance (RDA) greater than 150  mg/day are, in alphabetical order (with informal or folk-medicine perspectives in parentheses):
Trace minerals.
Many elements are required in trace amounts, usually because they play a catalytic role in enzymes. Some trace mineral elements (RDA < 200 mg/day) are, in alphabetical order:
Vitamins.
As with the minerals discussed above, some vitamins are recognized as organic essential nutrients, necessary in the diet for good health. (Vitamin D is the exception: it can be synthesized in the skin, in the presence of UVB radiation.) Certain vitamin-like compounds that are recommended in the diet, such as carnitine, are thought useful for survival and health, but these are not "essential" dietary nutrients because the human body has some capacity to produce them from other compounds. Moreover, thousands of different phytochemicals have recently been discovered in food (particularly in fresh vegetables), which may have desirable properties including antioxidant activity (see below); however, experimental demonstration has been suggestive but inconclusive. Other essential nutrients that are not classified as vitamins include essential amino acids (see above), choline, essential fatty acids (see above), and the minerals discussed in the preceding section.
Vitamin deficiencies may result in disease conditions, including goitre, scurvy, osteoporosis, impaired immune system, disorders of cell metabolism, certain forms of cancer, symptoms of premature aging, and poor psychological health (including eating disorders), among many others. Excess levels of some vitamins are also dangerous to health (notably vitamin A).
Deficient or excess levels of minerals can also have serious health consequences.
Other nutrients.
In general, other micronutrients are more recent discoveries that have not yet been recognized as vitamins or as required. Phytochemicals may act as antioxidants, but not all phytochemicals are antioxidants.
Phytochemicals.
Phytochemicals are chemical compounds that occur naturally in plants (phyto means "plant" in Greek). In general, the term is used to refer to those chemicals that may have biological significance, for example antioxidants.
There is research interest in the health effects of phytochemicals, but to date there is no conclusive evidence. While many fruits and vegetables that happen to contain phytochemicals are thought to be components of a healthy diet, by comparison dietary supplements based on them have no proven health benefit.
Antioxidants.
As cellular metabolism/energy production requires oxygen, potentially damaging (e.g., mutation causing) compounds known as free radicals can form. Most of these are oxidizers (i.e., acceptors of electrons) and some react very strongly. For the continued normal cellular maintenance, growth, and division, these free radicals must be sufficiently neutralized by antioxidant compounds. Recently, some researchers suggested an interesting theory of evolution of dietary antioxidants. Some are produced by the human body with adequate precursors (glutathione, Vitamin C), and those the body cannot produce may only be obtained in the diet via direct sources (Vitamin C in humans, Vitamin A, Vitamin K) or produced by the body from other compounds (Beta-carotene converted to Vitamin A by the body, Vitamin D synthesized from cholesterol by sunlight). Phytochemicals ("Section Below") and their subgroup, polyphenols, make up the majority of antioxidants; about 4,000 are known. Different antioxidants are now known to function in a cooperative network. For example, Vitamin C can reactivate free radical-containing glutathione or Vitamin E by accepting the free radical itself. Some antioxidants are more effective than others at neutralizing different free radicals. Some cannot neutralize certain free radicals. Some cannot be present in certain areas of free radical development (Vitamin A is fat-soluble and protects fat areas, Vitamin C is water-soluble and protects those areas). When interacting with a free radical, some antioxidants produce a different free radical compound that is less dangerous or more dangerous than the previous compound. Having a variety of antioxidants allows any byproducts to be safely dealt with by more efficient antioxidants in neutralizing a free radical's butterfly effect.
Although initial studies suggested that antioxidant supplements might promote health, later large clinical trials did not detect any benefit and suggested instead that excess supplementation may be harmful.
Intestinal bacterial flora.
Animal intestines contain a large population of gut flora. In humans, the four dominant phyla are Firmicutes, Bacteroidetes, Actinobacteria, and Proteobacteria. They are essential to digestion and are also affected by food that is consumed. Bacteria in the gut perform many important functions for humans, including breaking down and aiding in the absorption of otherwise indigestible food; stimulating cell growth; repressing the growth of harmful bacteria, training the immune system to respond only to pathogens; producing vitamin B12; and defending against some infectious diseases.
Healthy diets.
Whole plant food diet.
Heart disease, cancer, obesity, and diabetes are commonly called "Western" diseases because these maladies were once rarely seen in developing countries. An international study in China found some regions had virtually no cancer or heart disease, while in other areas they reflected "up to a 100-fold increase" coincident with shifts from diets that were found to be entirely plant-based to heavily animal-based, respectively. In contrast, diseases of affluence like cancer and heart disease are common throughout the developed world, including the United States. Adjusted for age and exercise, large regional clusters of people in China rarely suffered from these "Western" diseases possibly because their diets are rich in vegetables, fruits, and whole grains, and have little dairy and meat products. Some studies show these to be, in high quantities, possible causes of some cancers. There are arguments for and against this controversial issue.
The United Healthcare/Pacificare nutrition guideline recommends a whole plant food diet, and recommends using protein only as a condiment with meals. A "National Geographic" cover article from November 2005, entitled "The Secrets of Living Longer", also recommends a whole plant food diet. The article is a lifestyle survey of three populations, Sardinians, Okinawans, and Adventists, who generally display longevity and "suffer a fraction of the diseases that commonly kill people in other parts of the developed world, and enjoy more healthy years of life." In sum, they offer three sets of 'best practices' to emulate. The rest is up to you. In common with all three groups is to "Eat fruits, vegetables, and whole grains."
The "National Geographic" article noted that an NIH funded study of 34,000 Seventh-day Adventists between 1976 and 1988 "...found that the Adventists' habit of consuming beans, soy milk, tomatoes, and other fruits lowered their risk of developing certain cancers. It also suggested that eating whole grain bread, drinking five glasses of water a day, and, most surprisingly, consuming four servings of nuts a week reduced their risk of heart disease."
The French "paradox".
The French paradox is the observation that the French suffer a relatively low incidence of coronary heart disease, despite having a diet relatively rich in saturated fats. A number of explanations have been suggested:
However, statistics collected by the World Health Organization from 1990–2000 show that the incidence of heart disease in France may have been underestimated and, in fact, may be similar to that of neighboring countries.
Animal nutrition.
Nutritional science investigates the metabolic and physiological responses of the body to diet. With advances in the fields of molecular biology, biochemistry, nutritional immunology, molecular medicine and genetics, the study of nutrition is increasingly concerned
with metabolism and metabolic pathways: the sequences of biochemical steps through which substances in living things change from one form to another.
Carnivore and herbivore diets are contrasting, with basic nitrogen and carbon proportions vary for their particular foods. "The nitrogen content of plant tissues averages about 2%, while in fungi, animals, and bacteria it averages about 5% to 10%." Many herbivores rely on bacterial fermentation to create digestible nutrients from indigestible plant cellulose, while obligate carnivores must eat animal meats to obtain certain vitamins or nutrients their bodies cannot otherwise synthesize. All animals' diets must provide sufficient amounts of the basic building blocks they need, up to the point where their particular biology can synthesize the rest.
Animal tissue contains chemical compounds, such as water, carbohydrates (sugar, starch, and fiber), amino acids (in proteins), fatty acids (in lipids), and nucleic acids (DNA and RNA). These compounds in turn consist of elements such as carbon, hydrogen, oxygen, nitrogen, phosphorus, calcium, iron, zinc, magnesium, manganese, and so on. All of these chemical compounds and elements occur in various forms and combinations (e.g. hormones, vitamins, phospholipids, hydroxyapatite).
Animal tissue consists of elements and compounds ingested, digested, absorbed, and circulated through the bloodstream to feed the cells of the body. Except in the unborn fetus, the digestive system is the first system involved . Digestive juices break chemical bonds in ingested molecules, and modify their conformations and energy states. Though some molecules are absorbed into the bloodstream unchanged, digestive processes release them from the matrix of foods. Unabsorbed matter, along with some waste products of metabolism, is eliminated from the body in the feces.
Studies of nutritional status must take into account the state of the body before and after experiments, as well as the chemical composition of the whole diet and of all material excreted and eliminated from the body (in urine and feces). Comparing the food to the waste can help determine the specific compounds and elements absorbed and metabolized in the body. The effects of nutrients may only be discernible over an extended period, during which all food and waste must be analyzed. The number of variables involved in such experiments is high, making nutritional studies time-consuming and expensive, which explains why the science of animal nutrition is still slowly evolving.
In particular, the consumption of whole-plant foods slows digestion and allows better absorption, and a more favorable balance of essential nutrients per Calorie, resulting in better management of cell growth, maintenance, and mitosis (cell division), as well as better regulation of appetite and blood sugar . Regularly scheduled meals (every few hours) have also proven more wholesome than infrequent or haphazard ones.
Plant nutrition.
Plant nutrition is the study of the chemical elements that are necessary for plant growth. There are several principles that apply to plant nutrition. Some elements are directly involved in plant metabolism. However, this principle does not account for the so-called beneficial elements, whose presence, while not required, has clear positive effects on plant growth.
A nutrient that is able to limit plant growth according to Liebig's law of the minimum is considered an essential plant nutrient if the plant cannot complete its full life cycle without it. There are 16 essential plant soil nutrients, besides the three major elemental nutrients carbon and oxygen that are obtained by photosynthetic plants from carbon dioxide in air, and hydrogen, which is obtained from water.
Plants uptake essential elements from the soil through their roots and from the air (consisting of mainly nitrogen and oxygen) through their leaves. Green plants obtain their carbohydrate supply from the carbon dioxide in the air by the process of photosynthesis.Carbon and oxygen are absorbed from the air, while other nutrients are absorbed from the soil.
.Nutrient uptake in the soil is achieved by cation exchange, wherein root hairs pump hydrogen ions (H+) into the soil through proton pumps. These hydrogen ions displace cations attached to negatively charged soil particles so that the cations are available for uptake by the root. In the leaves, stomata open to take in carbon dioxide and expel oxygen. The carbon dioxide molecules are used as the carbon source in photosynthesis.
Although nitrogen is plentiful in the Earth's atmosphere, very few plants can use this directly. Most plants, therefore, require nitrogen compounds to be present in the soil in which they grow. This is made possible by the fact that largely inert atmospheric nitrogen is changed in a nitrogen fixation process to biologically usable forms in the soil by bacteria.
Plant nutrition is a difficult subject to understand completely, partially because of the variation between different plants and even between different species or individuals of a given clone. Elements present at low levels may cause deficiency symptoms, and toxicity is possible at levels that are too high. Furthermore, deficiency of one element may present as symptoms of toxicity from another element, and vice versa.
Environmental Nutrition.
Research in the field of nutrition has greatly contributed in finding out the essential facts about how environmental depletion can lead to crucial nutrition-related health problems like contamination, spread of contagious diseases, malnutrition, etc. Moreover, environmental contamination due to discharge of agricultural as well as industrial chemicals like organocholrines, heavy metal, and radionucleotides may adversely affect the human and the ecosystem as a whole. As far as safety of the human health is concerned, then these environmental contaminants can reduce people's nutritional status and health. This could directly or indirectly cause drastic changes in their diet habits. Hence, food-based remedial as well as preventive strategies are essential to address global issues like hunger and malnutrition and to enable the susceptible people to adapt themselves to all these environmental as well as socio-economic alterations.
Advice and guidance.
U.S. Government policies.
In the US, dietitians are registered (RD) or licensed (LD) with the Commission for Dietetic Registration and the American Dietetic Association, and are only able to use the title "dietitian," as described by the business and professions codes of each respective state, when they have met specific educational and experiential prerequisites and passed a national registration or licensure examination, respectively. In California, registered dietitians must abide by the Anyone may call themselves a nutritionist, including unqualified dietitians, as this term is unregulated. Some states, such as the State of Florida, have begun to include the title "nutritionist" in state licensure requirements. Most governments provide guidance on nutrition, and some also impose mandatory disclosure/labeling requirements for processed food manufacturers and restaurants to assist consumers in complying with such guidance.
In the US, nutritional standards and recommendations are established jointly by the US Department of Agriculture and US Department of Health and Human Services. Dietary and physical activity guidelines from the USDA are presented in the concept of MyPlate, which superseded the food pyramid, which replaced the Four Food Groups. The Senate committee currently responsible for oversight of the USDA is the "Agriculture, Nutrition and Forestry Committee". Committee hearings are often televised on C-SPAN.
The U.S. Department of Health and Human Services provides a sample week-long menu that fulfills the nutritional recommendations of the government. Canada's Food Guide is another governmental recommendation.
Government programs.
Federal and state governmental organizations have been working on nutrition literacy interventions in non-primary health care settings to address the nutrition information problem in the U.S. Some programs include:
The Family Nutrition Program (FNP) is a free nutrition education program serving low-income adults around the U.S. This program is funded by the Food Nutrition Service’s (FNS) branch of the United States Department of Agriculture (USDA) usually through a local state academic institution that runs the program. The FNP has developed a series of tools to help families participating in the Food Stamp Program stretch their food dollar and form healthful eating habits including nutrition education.
 (ENFEP) is a unique program that currently operates in all 50 states and in American Samoa, Guam, Micronesia, Northern Marianas, Puerto Rico, and the Virgin Islands. It is designed to assist limited-resource audiences in acquiring the knowledge, skills, attitudes, and changed behavior necessary for nutritionally sound diets, and to contribute to their personal development and the improvement of the total family diet and nutritional well-being.
An example of a state initiative to promote nutrition literacy is , a public-private partnership between the state’s largest university system and largest health insurer, Louisiana State Agricultural Center and Blue Cross and Blue Shield of Louisiana Foundation. Launched in 2005, this program promotes lifelong healthful eating patterns and physically active lifestyles for children and their families. It is an interactive educational program designed to help prevent childhood obesity through classroom activities that teach children healthful eating habits and physical exercise.
Education.
Nutrition is taught in schools in many countries. In England and Wales, the Personal and Social Education and Food Technology curricula include nutrition, stressing the importance of a balanced diet and teaching how to read nutrition labels on packaging. In many schools, a Nutrition class will fall within the Family and Consumer Science or Health departments. In some American schools, students are required to take a certain number of FCS or Health related classes. Nutrition is offered at many schools, and, if it is not a class of its own, nutrition is included in other FCS or Health classes such as: Life Skills, Independent Living, Single Survival, Freshmen Connection, Health etc. In many Nutrition classes, students learn about the food groups, the food pyramid, Daily Recommended Allowances, calories, vitamins, minerals, malnutrition, physical activity, healthful food choices, portion sizes, and how to live a healthy life.
A 1985, US National Research Council report entitled "Nutrition Education in US Medical Schools" concluded that nutrition education in medical schools was inadequate. Only 20% of the schools surveyed taught nutrition as a separate, required course. A 2006 survey found that this number had risen to 30%.
Nutrition literacy.
At the time of this entry, we were not able to identify any specific nutrition literacy studies in the U.S. at a national level. However, the findings of the 2003 National Assessment of Adult Literacy (NAAL) provide a basis upon which to frame the nutrition literacy problem in the U.S. NAAL introduced the first ever measure of "the degree to which individuals have the capacity to obtain, process and understand basic health information and services needed to make appropriate health decisions" – an objective of Healthy People 2010 and of which nutrition literacy might be considered an important subset. On a scale of below basic, basic, intermediate and proficient, NAAL found 13 percent of adult Americans have proficient health literacy, 44% have intermediate literacy, 29 percent have basic literacy and 14 percent have below basic health literacy. The study found that health literacy increases with education and people living below the level of poverty have lower health literacy than those above it.
Another study examining the health and nutrition literacy status of residents of the lower Mississippi Delta found that 52 percent of participants had a high likelihood of limited literacy skills. While a precise comparison between the NAAL and Delta studies is difficult, primarily because of methodological differences, Zoellner et al. suggest that health literacy rates in the Mississippi Delta region are different from the U.S. general population and that they help establish the scope of the problem of health literacy among adults in the Delta region. For example, only 12 percent of study participants identified the My Pyramid graphic two years after it had been launched by the USDA. The study also found significant relationships between nutrition literacy and income level and nutrition literacy and educational attainment further delineating priorities for the region.
These statistics point to the complexities surrounding the lack of health/nutrition literacy and reveal the degree to which they are embedded in the social structure and interconnected with other problems. Among these problems are the lack of information about food choices, a lack of understanding of nutritional information and its application to individual circumstances, limited or difficult access to healthful foods, and a range of cultural influences and socioeconomic constraints such as low levels of education and high levels of poverty that decrease opportunities for healthful eating and living.
The links between low health literacy and poor health outcomes has been widely documented and there is evidence that some interventions to improve health literacy have produced successful results in the primary care setting. More must be done to further our understanding of nutrition literacy specific interventions in non-primary care settings in order to achieve better health outcomes.
Malnutrition.
Malnutrition refers to insufficient, excessive, or imbalanced consumption of nutrients by an organism. In developed countries, the diseases of malnutrition are most often associated with nutritional imbalances or excessive consumption. In developing countries, malnutrition is more likely to be caused by poor access to a range of nutritious foods or inadequate knowledge. In Mali the International Crops Research Institute for the Semi-Arid Tropics (ICRISAT) and the Aga Khan Foundation, trained women's groups to make "equinut", a healthy and nutritional version of the traditional recipe "di-dèguè" (comprising peanut paste, honey and millet or rice flour). The aim was to boost nutrition and livelihoods by producing a product that women could make and sell, and which would be accepted by the local community because of its local heritage.
Although there are more organisms in the world who are malnourished due to insufficient consumption, increasingly more organisms suffer from excessive over-nutrition; a problem caused by an over abundance of sustenance coupled with the instinctual desire (by animals in particular) to consume all that it can.
Nutritionism is the view that excessive reliance on food science and the study of nutrition can lead to poor nutrition and to ill health. It was originally credited to Gyorgy Scrinis, and was popularized by Michael Pollan. Since nutrients are invisible, policy makers rely on nutrition experts to advise on food choices. Because science has an incomplete understanding of how food affects the human body, Pollan argues, nutritionism can be blamed for many of the health problems relating to diet in the Western World today.
Insufficient.
In general, "under-consumption" refers to the long-term consumption of insufficient sustenance in relation to the energy that an organism expends or expels, leading to poor health.
Excessive.
In general, "over-consumption" refers to the long-term consumption of excess sustenance in relation to the energy that an organism expends or expels, leading to poor health and, in animals, obesity. It can cause excessive hair loss, brittle nails, and irregular premenstrual cycles for females.
Unbalanced.
When too much of one or more nutrients is present in the diet to the exclusion of the proper amount of other nutrients, the diet is said to be unbalanced.
Mental agility.
Research indicates that improving the awareness of nutritious meal choices and establishing long-term habits of healthy eating have a positive effect on cognitive and spatial memory capacity, with potential to increase a student's ability to process and retain academic information.
Some organizations have begun working with teachers, policymakers, and managed foodservice contractors to mandate improved nutritional content and increased nutritional resources in school cafeterias from primary to university level institutions. Health and nutrition have been proven to have close links with overall educational success. Currently, less than 10% of American college students report that they eat the recommended five servings of fruit and vegetables daily. Better nutrition has been shown to have an impact on both cognitive and spatial memory performance; a study showed those with higher blood sugar levels performed better on certain memory tests. In another study, those who consumed yogurt performed better on thinking tasks when compared to those that consumed caffeine-free diet soda or confections. Nutritional deficiencies have been shown to have a negative effect on learning behavior in mice as far back as 1951.
There is limited research available that directly links a student's Grade Point Average (G.P.A.) to their overall nutritional health. Additional substantive data is needed to prove that overall intellectual health is closely linked to a person's diet, rather than just another correlation fallacy.
Mental disorders.
Nutritional supplement treatment may be appropriate for major depression, bipolar disorder, schizophrenia, and obsessive compulsive disorder, the four most common mental disorders in developed countries. Supplements that have been studied most for mood elevation and stabilization include eicosapentaenoic acid and docosahexaenoic acid (each of which an omega-3 fatty acid contained in fish oil but not in flaxseed oil), vitamin B12, folic acid, and inositol.
Cancer.
Cancer is now common in developing countries. According to a study by the International Agency for Research on Cancer, "In the developing world, cancers of the liver, stomach and esophagus were more common, often linked to consumption of carcinogenic preserved foods, such as smoked or salted food, and parasitic infections that attack organs." Lung cancer rates are rising rapidly in poorer nations because of increased use of tobacco. Developed countries "tended to have cancers linked to affluence or a 'Western lifestyle' — cancers of the colon, rectum, breast and prostate — that can be caused by obesity, lack of exercise, diet and age."
Metabolic syndrome.
Several lines of evidence indicate lifestyle-induced hyperinsulinemia and reduced insulin function (i.e., insulin resistance) as a decisive factor in many disease states. For example, hyperinsulinemia and insulin resistance are strongly linked to chronic inflammation, which in turn is strongly linked to a variety of adverse developments such as arterial microinjuries and clot formation (i.e., heart disease) and exaggerated cell division (i.e., cancer). Hyperinsulinemia and insulin resistance (the so-called metabolic syndrome) are characterized by a combination of abdominal obesity, elevated blood sugar, elevated blood pressure, elevated blood triglycerides, and reduced HDL cholesterol. The negative impact of hyperinsulinemia on prostaglandin PGE1/PGE2 balance may be significant.
The state of obesity clearly contributes to insulin resistance, which in turn can cause type 2 diabetes. Virtually all obese and most type 2 diabetic individuals have marked insulin resistance. Although the association between overweight and insulin resistance is clear, the exact (likely multifarious) causes of insulin resistance remain less clear. It is important to note that it has been demonstrated that appropriate exercise, more regular food intake, and reducing glycemic load (see below) all can reverse insulin resistance in overweight individuals (and thereby lower blood sugar levels in those with type 2 diabetes).
Obesity can unfavourably alter hormonal and metabolic status via resistance to the hormone leptin, and a vicious cycle may occur in which insulin/leptin resistance and obesity aggravate one another. The vicious cycle is putatively fuelled by continuously high insulin/leptin stimulation and fat storage, as a result of high intake of strongly insulin/leptin stimulating foods and energy. Both insulin and leptin normally function as satiety signals to the hypothalamus in the brain; however, insulin/leptin resistance may reduce this signal and therefore allow continued overfeeding despite large body fat stores. In addition, reduced leptin signalling to the brain may reduce leptin's normal effect to maintain an appropriately high metabolic rate.
There is a debate about how and to what extent different dietary factors— such as intake of processed carbohydrates, total protein, fat, and carbohydrate intake, intake of saturated and trans fatty acids, and low intake of vitamins/minerals—contribute to the development of insulin and leptin resistance. In any case, analogous to the way modern man-made pollution may possess the potential to overwhelm the environment's ability to maintain homeostasis, the recent explosive introduction of high glycemic index and processed foods into the human diet may possess the potential to overwhelm the body's ability to maintain homeostasis and health (as evidenced by the metabolic syndrome epidemic).
Hyponatremia.
Excess water intake, without replenishment of sodium and potassium salts, leads to hyponatremia, which can further lead to water intoxication at more dangerous levels. A well-publicized case occurred in 2007, when Jennifer Strange died while participating in a water-drinking contest. More usually, the condition occurs in long-distance endurance events (such as marathon or triathlon competition and training) and causes gradual mental dulling, headache, drowsiness, weakness, and confusion; extreme cases may result in coma, convulsions, and death. The primary damage comes from swelling of the brain, caused by increased osmosis as blood salinity decreases.
Effective fluid replacement techniques include water aid stations during running/cycling races, trainers providing water during team games, such as soccer, and devices such as Camel Baks, which can provide water for a person without making it too hard to drink the water.
Antinutrient.
Antinutrients are natural or synthetic compounds that interfere with the absorption of nutrients. Nutrition studies focus on antinutrients commonly found in food sources and beverages.
Sugar consumption in the United States
The relatively recent increased consumption of sugar has been linked to the rise of some afflictions such as diabetes, obesity, and more recently heart disease. Increased consumption of sugar has been tied to these three, among others. Obesity levels have more than doubled in the last 30 years among adults, going from 15% to 35% in the United States. Obesity and diet also happen to be high risk factors for diabetes. In the same time span that obesity doubled, diabetes numbers quadrupled in America. Increased weight, especially in the form of belly fat, and high sugar intake are also high risk factors for heart disease. Both sugar intake and fatty tissue increase the probability of elevated LDL cholesterol in the bloodstream. Elevated amounts of Low-density lipoprotein (LDL) cholesterol, is the primary factor in heart disease. In order to avoid all the dangers of sugar, moderate consumption is paramount.
Processed foods.
Since the Industrial Revolution some two hundred years ago, the food processing industry has invented many technologies that both help keep foods fresh longer and alter the fresh state of food as they appear in nature. Cooling is the primary technology used to maintain freshness, whereas many more technologies have been invented to allow foods to last longer without becoming spoiled. These latter technologies include pasteurisation, autoclavation, drying, salting, and separation of various components, all of which appearing to alter the original nutritional contents of food. Pasteurisation and autoclavation (heating techniques) have no doubt improved the safety of many common foods, preventing epidemics of bacterial infection. But some of the (new) food processing technologies have downfalls as well.
Modern separation techniques such as milling, centrifugation, and pressing have enabled concentration of particular components of food, yielding flour, oils, juices, and so on, and even separate fatty acids, amino acids, vitamins, and minerals. Inevitably, such large-scale concentration changes the nutritional content of food, saving certain nutrients while removing others. Heating techniques may also reduce food's content of many heat-labile nutrients such as certain vitamins and phytochemicals, and possibly other yet-to-be-discovered substances. Because of reduced nutritional value, processed foods are often 'enriched' or 'fortified' with some of the most critical nutrients (usually certain vitamins) that were lost during processing. Nonetheless, processed foods tend to have an inferior nutritional profile compared to whole, fresh foods, regarding content of both sugar and high GI starches, potassium/sodium, vitamins, fiber, and of intact, unoxidized (essential) fatty acids. In addition,
processed foods often contain potentially harmful substances such as oxidized fats and trans fatty acids.
A dramatic example of the effect of food processing on a population's health is the history of epidemics of beri-beri in people subsisting on polished rice. Removing the outer layer of rice by polishing it removes with it the essential vitamin thiamine, causing beri-beri. Another example is the development of scurvy among infants in the late 19th century in the United States. It turned out that the vast majority of sufferers were being fed milk that had been heat-treated (as suggested by Pasteur) to control bacterial disease. Pasteurisation was effective against bacteria, but it destroyed the vitamin C.
As mentioned, lifestyle- and obesity-related diseases are becoming increasingly prevalent all around the world. There is little doubt that the increasingly widespread application of some modern food processing technologies has contributed to this development. The food processing industry is a major part of modern economy, and as such it is influential in political decisions (e.g., nutritional recommendations, agricultural subsidising). In any known profit-driven economy, health considerations are hardly a priority; effective production of cheap foods with a long shelf-life is more the trend. In general, whole, fresh foods have a relatively short shelf-life and are less profitable to produce and sell than are more processed foods. Thus, the consumer is left with the choice between more expensive, but nutritionally superior, whole, fresh foods, and cheap, usually nutritionally inferior, processed foods. Because processed foods are often cheaper, more convenient (in both purchasing, storage, and preparation), and more available, the consumption of nutritionally inferior foods has been increasing throughout the world along with many nutrition-related health complications.
See also.
Balanced Eating:
Biology:
 Dangers of poor nutrition
Food:
Healthy diet: 
Lists:
Nutrients:
Profession:
Tools:
Organizations:
Related topics

</doc>
<doc id="21526" url="http://en.wikipedia.org/wiki?curid=21526" title="November 22">
November 22

November 22 is the day of the year in the Gregorian calendar.

</doc>
<doc id="21527" url="http://en.wikipedia.org/wiki?curid=21527" title="Number theory">
Number theory

Number theory (or arithmetic) is a branch of pure mathematics devoted primarily to the study of the integers, sometimes called "The Queen of Mathematics" because of its foundational place in the discipline. Number theorists study prime numbers as well as the properties of objects made out of integers (e.g., rational numbers) or defined as generalizations of the integers (e.g., algebraic integers).
Integers can be considered either in themselves or as solutions to equations (Diophantine geometry). Questions in number theory are often best understood through the study of analytical objects (e.g., the Riemann zeta function) that encode properties of the integers, primes or other number-theoretic objects in some fashion (analytic number theory). One may also study real numbers in relation to rational numbers, e.g., as approximated by the latter (Diophantine approximation).
The older term for number theory is "arithmetic". By the early twentieth century, it had been superseded by "number theory". (The word "arithmetic" is used by the general public to mean "elementary calculations"; it has also acquired other meanings in mathematical logic, as in "Peano arithmetic", and computer science, as in "floating point arithmetic".) The use of the term "arithmetic" for "number theory" regained some ground in the second half of the 20th century, arguably in part due to French influence. In particular, "arithmetical" is preferred as an adjective to "number-theoretic".
History.
Origins.
Dawn of arithmetic.
The first historical find of an arithmetical nature is a fragment of a table: the broken clay tablet Plimpton 322 (Larsa, Mesopotamia, ca. 1800 BCE) contains a list of "Pythagorean triples", i.e., integers formula_1 such that formula_2.
The triples are too many and too large to have been obtained by brute force. The heading over the first column reads: "The "takiltum" of the diagonal which has been subtracted such that the width..."
The table's layout suggests that it was constructed by means of what amounts, in modern language, to the identity
formula_3
which is implicit in routine Old Babylonian exercises. If some other method was used, the triples were first constructed and then reordered by formula_4, presumably for actual use as a "table", i.e., with a view to applications.
It is not known what these applications may have been, or whether there could have been any; Babylonian astronomy, for example, truly flowered only later. It has been suggested instead that the table was a source of numerical examples for school problems.
While Babylonian number theory—or what survives of Babylonian mathematics that can be called thus—consists of this single, striking fragment, Babylonian algebra (in the secondary-school sense of "algebra") was exceptionally well developed. Late Neoplatonic sources state that Pythagoras learned mathematics from the Babylonians. Much earlier sources state that Thales and Pythagoras traveled and studied in Egypt.
Euclid IX 21—34 is very probably Pythagorean; it is very simple material ("odd times even is even", "if an odd number measures [= divides] an even number, then it also measures [= divides] half of it"), but it is all that is needed to prove that formula_5
is irrational. Pythagorean mystics gave great importance to the odd and the even.
The discovery that formula_5 is irrational is credited to the early Pythagoreans (pre-Theodorus). By revealing (in modern terms) that numbers could be irrational, this discovery seems to have provoked the first foundational crisis in mathematical history; its proof or its divulgation are sometimes credited to Hippasus, who was expelled or split from the Pythagorean sect. This forced a distinction between "numbers" (integers and the rationals—the subjects of arithmetic), on the one hand, and "lengths" and "proportions" (which we would identify with real numbers, whether rational or not), on the other hand.
The Pythagorean tradition spoke also of so-called polygonal or figurate numbers. While square numbers, cubic numbers, etc., are seen now as more natural than triangular numbers, pentagonal numbers, etc., the study of the sums
of triangular and pentagonal numbers would prove fruitful in the early modern period (17th to early 19th century).
We know of no clearly arithmetical material in ancient Egyptian or Vedic sources, though there is some algebra in both. The Chinese remainder theorem appears as an exercise in Sun Zi's "Suan Ching", also known as "The Mathematical Classic of Sun Zi" (3rd, 4th or 5th century CE.) (There is one important step glossed over in Sun Zi's solution: it is the problem that was later solved by Āryabhaṭa's kuṭṭaka – see below.)
There is also some numerical mysticism in Chinese mathematics, but, unlike that of the Pythagoreans, it seems to have
led nowhere. Like the Pythagoreans' perfect numbers, magic squares have passed from superstition into recreation.
Classical Greece and the early Hellenistic period.
Aside from a few fragments, the mathematics of Classical Greece is known to us either through the reports of contemporary non-mathematicians or through mathematical works from the early Hellenistic period. In the case of number theory, this means, by and large, "Plato" and "Euclid", respectively.
Plato had a keen interest in mathematics, and distinguished clearly between arithmetic and calculation. (By "arithmetic" he meant, in part, theorising on number, rather than what "arithmetic" or "number theory" have come to mean.) It is through one of Plato's dialogues—namely, "Theaetetus"—that we know that Theodorus had proven that formula_7 are irrational. Theaetetus was, like Plato, a disciple of Theodorus's; he worked on distinguishing different kinds of incommensurables, and was thus arguably a pioneer in the study of number systems. (Book X of Euclid's Elements is described by Pappus as being largely based on Theaetetus's work.)
Euclid devoted part of his "Elements" to prime numbers and divisibility, topics that belong unambiguously to number theory and are basic to it (Books VII to IX of Euclid's Elements). In particular, he gave an algorithm for computing the greatest common divisor of two numbers (the Euclidean algorithm; "Elements", Prop. VII.2) and the first known proof of the infinitude of primes ("Elements", Prop. IX.20).
In 1773, Lessing published an epigram he had found in a manuscript during his work as a librarian; it claimed to be a letter sent by Archimedes to Eratosthenes. The epigram proposed what has become known as
Archimedes' cattle problem; its solution (absent from the manuscript) requires solving an indeterminate quadratic equation (which reduces to what would later be misnamed Pell's equation). As far as we know, such equations were first successfully treated by the Indian school. It is not known whether Archimedes himself had a method of solution.
Diophantus.
Very little is known about Diophantus of Alexandria; he probably lived in the third century CE, that is, about five hundred years after Euclid. Six out of the thirteen books of Diophantus's "Arithmetica" survive in the original Greek; four more books survive in an Arabic translation. The "Arithmetica" is a collection of worked-out problems where the task is invariably to find rational solutions to a system of polynomial equations, usually of the form formula_8 or formula_9. Thus, nowadays, we speak of "Diophantine equations" when we speak of polynomial equations to which rational or integer solutions must be found.
One may say that Diophantus was studying rational points — i.e., points whose coordinates are rational — on curves and algebraic varieties; however, unlike the Greeks of the Classical period, who did what we would now call basic algebra in geometrical terms, Diophantus did what we would now call basic algebraic geometry in purely algebraic terms. In modern language, what Diophantus did was to find rational parametrizations of varieties; that is, given an equation of the form (say) 
formula_10, his aim was to find (in essence) three rational functions formula_11 such that, for all values of formula_12 and formula_13, setting 
formula_14 for formula_15 gives a solution to formula_16
Diophantus also studied the equations of some non-rational curves, for which no rational parametrisation is possible. He managed to find some rational points on these curves (elliptic curves, as it happens, in what seems to be their first known occurrence) by means of what amounts to a tangent construction: translated into coordinate geometry
While Diophantus was concerned largely with rational solutions, he assumed some results on integer numbers, in particular that every integer is the sum of four squares (though he never stated as much explicitly).
Āryabhaṭa, Brahmagupta, Bhāskara.
While Greek astronomy probably influenced Indian learning, to the point of introducing trigonometry, it seems to be the case that Indian mathematics is otherwise an indigenous tradition; in particular, there is no evidence that Euclid's Elements reached India before the 18th century.
Āryabhaṭa (476–550 CE) showed that pairs of simultaneous congruences formula_17, formula_18 could be solved by a method he called "kuṭṭaka", or "pulveriser"; this is a procedure close to (a generalisation of) the Euclidean algorithm, which was probably discovered independently in India. Āryabhaṭa seems to have had in mind applications to astronomical calculations.
Brahmagupta (628 CE) started the systematic study of indefinite quadratic equations—in particular, the misnamed Pell equation, in which Archimedes may have first been interested, and which did not start to be solved in the West until the time of Fermat and Euler. Later Sanskrit authors would follow, using Brahmagupta's technical terminology. A general procedure (the chakravala, or "cyclic method") for solving Pell's equation was finally found by Jayadeva (cited in the eleventh century; his work is otherwise lost); the earliest surviving exposition appears in Bhāskara II's Bīja-gaṇita (twelfth century).
Unfortunately, Indian mathematics remained largely unknown in the West until the late eighteenth century; Brahmagupta and Bhāskara's work was translated into English in 1817 by Henry Colebrooke.
Arithmetic in the Islamic golden age.
In the early ninth century, the caliph Al-Ma'mun ordered translations of many Greek mathematical works and at least one Sanskrit work (the "Sindhind",
which may or may not be Brahmagupta's Brāhmasphuţasiddhānta).
Diophantus's main work, the "Arithmetica", was translated into Arabic by Qusta ibn Luqa (820–912).
Part of the treatise "al-Fakhri" (by al-Karajī, 953 – ca. 1029) builds on it to some extent. According to Rashed Roshdi, Al-Karajī's contemporary Ibn al-Haytham knew what would later be called Wilson's theorem.
Western Europe in the Middle Ages.
Other than a treatise on squares in arithmetic progression by Fibonacci — who lived and studied in north Africa and Constantinople during his formative years, ca. 1175–1200 — no number theory to speak of was done in western Europe during the Middle Ages. Matters started to change in Europe in the late Renaissance, thanks to a renewed study of the works of Greek antiquity. A catalyst was the textual emendation and translation into Latin of Diophantus's "Arithmetica" (Bachet, 1621, following a first attempt by Xylander, 1575).
Early modern number theory.
Fermat.
Pierre de Fermat (1601–1665) never published his writings; in particular, his work on number theory is contained almost entirely in letters to mathematicians and in private marginal notes. He wrote down nearly no proofs in number theory; he had no models in the area. He did make repeated use of mathematical induction, introducing the method of infinite descent.
One of Fermat's first interests was perfect numbers (which appear in Euclid, "Elements" IX) and amicable numbers; this led him to work on integer divisors, which were from the beginning among the subjects of the
correspondence (1636 onwards) that put him in touch with the mathematical community of the day. He had already studied Bachet's edition of Diophantus carefully; by 1643, his interests had shifted largely to Diophantine problems and sums of squares (also treated by Diophantus).
Fermat's achievements in arithmetic include:
Fermat's claim ("Fermat's last theorem") to have shown there are no solutions to
formula_25 for all formula_26 (a fact the only known proof of which is far beyond his methods) appears only in his annotations on the margin of his copy of Diophantus; he never claimed this to others and thus would have had no need to retract it if he found any mistake in his supposed proof.
Euler.
The interest of Leonhard Euler (1707–1783) in number theory was first spurred in 1729, when a friend of his, the amateur Goldbach, pointed him towards some of Fermat's work on the subject. This has been called the "rebirth" of modern number theory, after Fermat's relative lack of success in getting his contemporaries' attention for the subject. Euler's work on number theory includes the following:
Lagrange, Legendre and Gauss.
Joseph-Louis Lagrange (1736–1813) was the first to give full proofs of some of Fermat's and Euler's work and observations - for instance, the four-square theorem and the basic theory of the misnamed "Pell's equation" (for which an algorithmic solution was found by Fermat and his contemporaries, and also by Jayadeva and Bhaskara II before them.) He also studied quadratic forms in full generality (as opposed to formula_31) — defining their equivalence relation, showing how to put them in reduced form, etc.
Adrien-Marie Legendre (1752–1833) was the first to state the law of quadratic reciprocity. He also
conjectured what amounts to the prime number theorem and Dirichlet's theorem on arithmetic progressions. He gave a full treatment of the equation formula_32 and worked on quadratic forms along the lines later developed fully by Gauss. In his old age, he was the first to prove "Fermat's last theorem" for formula_33 (completing work by Peter Gustav Lejeune Dirichlet, and crediting both him and Sophie Germain).
In his "Disquisitiones Arithmeticae" (1798), Carl Friedrich Gauss (1777–1855) proved the law of quadratic reciprocity and developed the theory of quadratic forms (in particular, defining their composition). He also introduced some basic notation (congruences) and devoted a section to computational matters, including primality tests. The last section of the "Disquisitiones" established a link between roots of unity and number theory:
The theory of the division of the circle...which is treated in sec. 7 does not belong
by itself to arithmetic, but its principles can only be drawn from higher arithmetic.
In this way, Gauss arguably made a first foray towards both Évariste Galois's work and algebraic number theory.
Maturity and division into subfields.
Starting early in the nineteenth century, the following developments gradually took place:
Algebraic number theory may be said to start with the study of reciprocity and cyclotomy, but truly came into its own with the development of abstract algebra and early ideal theory and valuation theory; see below. A conventional starting point for analytic number theory is Dirichlet's theorem on arithmetic progressions (1837), whose proof introduced L-functions and involved some asymptotic analysis and a limiting process on a real variable. The first use of analytic ideas in number theory actually
goes back to Euler (1730s), who used formal power series and non-rigorous (or implicit) limiting arguments. The use of "complex" analysis in number theory comes later: the work of Bernhard Riemann (1859) on the zeta function is the canonical starting point; Jacobi's four-square theorem (1839), which predates it, belongs to an initially different strand that has by now taken a leading role in analytic number theory (modular forms).
The history of each subfield is briefly addressed in its own section below; see the main article of each subfield for fuller treatments. Many of the most interesting questions in each area remain open and are being actively worked on.
Main subdivisions.
Elementary tools.
The term "elementary" generally denotes a method that does not use complex analysis. For example, the prime number theorem was first proven using complex analysis in 1896, but an elementary proof was found only in 1949 by Erdős and Selberg. The term is somewhat ambiguous: for example, proofs based on complex Tauberian theorems (e.g. Wiener–Ikehara) are often seen as quite enlightening but not elementary, in spite of using Fourier analysis, rather than complex analysis as such. Here as elsewhere, an "elementary" proof may be longer and more difficult for most readers than a non-elementary one.
Number theory has the reputation of being a field many of whose results can be stated to the layperson. At the same time, the proofs of these results are not particularly accessible, in part because the range of tools they use is, if anything, unusually broad within mathematics.
Analytic number theory.
"Analytic number theory" may be defined
Some subjects generally considered to be part of analytic number theory, e.g., sieve theory, are better covered by the second rather than the first definition: some of sieve theory, for instance, uses little analysis, yet it does belong to analytic number theory.
The following are examples of problems in analytic number theory: the prime number theorem, the Goldbach conjecture (or the twin prime conjecture, or the Hardy–Littlewood conjectures), the Waring problem and the Riemann Hypothesis. Some of the most important tools of analytic number theory are the circle method, sieve methods and L-functions (or, rather, the study of their properties). The theory of modular forms (and, more generally, automorphic forms) also occupies an increasingly central place in the toolbox of analytic number theory.
One may ask analytic questions about algebraic numbers, and use analytic means to answer such questions; it is thus that algebraic and analytic number theory intersect. For example, one may define prime ideals (generalizations of prime numbers in the field of algebraic numbers) and ask how many prime ideals there are up to a certain size. This question can be answered by means of an examination of Dedekind zeta functions, which are generalizations of the Riemann zeta function, a key analytic object at the roots of the subject. This is an example of a general procedure in analytic number theory: deriving information about the distribution of a sequence (here, prime ideals or prime numbers) from the analytic behavior of an appropriately constructed complex-valued function.
Algebraic number theory.
An "algebraic number" is any complex number that is a solution to some polynomial equation formula_34 with rational coefficients; for example, every solution formula_35 of formula_36 (say) is an algebraic number. Fields of algebraic numbers are also called "algebraic number fields", or shortly "number fields". Algebraic number theory studies algebraic number fields. Thus, analytic and algebraic number theory can and do overlap: the former is defined by its methods, the latter by its objects of study.
It could be argued that the simplest kind of number fields (viz., quadratic fields) were already studied by Gauss, as the discussion of quadratic forms in "Disquisitiones arithmeticae" can be restated in terms of ideals and
norms in quadratic fields. (A "quadratic field" consists of all
numbers of the form formula_37, where
formula_38 and formula_39 are rational numbers and formula_40
is a fixed rational number whose square root is not rational.)
For that matter, the 11th-century chakravala method amounts—in modern terms—to an algorithm for finding the units of a real quadratic number field. However, neither Bhāskara nor Gauss knew of number fields as such.
The grounds of the subject as we know it were set in the late nineteenth century, when "ideal numbers", the "theory of ideals" and "valuation theory" were developed; these are three complementary ways of dealing with the lack of unique factorisation in algebraic number fields. (For example, in the field generated by the rationals
and formula_41, the number formula_42 can be factorised both as formula_43 and
formula_44; all of formula_45, formula_46, formula_47 and
formula_48
are irreducible, and thus, in a naïve sense, analogous to primes among the integers.) The initial impetus for the development of ideal numbers (by Kummer) seems to have come from the study of higher reciprocity laws,i.e., generalisations of quadratic reciprocity.
Number fields are often studied as extensions of smaller number fields: a field "L" is said to be an "extension" of a field "K" if "L" contains "K".
Classifying the possible extensions of a given number field is a difficult and partially open problem. Abelian extensions—that is, extensions "L" of "K" such that the Galois group Gal("L"/"K") of "L" over "K" is an abelian group—are relatively well understood.
Their classification was the object of the programme of class field theory, which was initiated in the late 19th century (partly by Kronecker and Eisenstein) and carried out largely in 1900—1950.
An example of an active area of research in algebraic number theory is Iwasawa theory. The Langlands program, one of the main current large-scale research plans in mathematics, is sometimes described as an attempt to generalise class field theory to non-abelian extensions of number fields.
Diophantine geometry.
The central problem of "Diophantine geometry" is to determine when a Diophantine equation has solutions, and if it does, how many. The approach taken is to think of the solutions of an equation as a geometric object.
For example, an equation in two variables defines a curve in the plane. More generally, an equation, or system of equations, in two or more variables defines a curve, a surface or some other such object in "n"-dimensional space. In Diophantine geometry, one asks whether there are any "rational points" (points all of whose coordinates are rationals) or
"integral points" (points all of whose coordinates are integers) on the curve or surface. If there are any such points, the next step is to ask how many there are and how they are distributed. A basic question in this direction is: are there finitely
or infinitely many rational points on a given curve (or surface)? What about integer points?
An example here may be helpful. Consider the Pythagorean equation formula_49;
we would like to study its rational solutions, i.e., its solutions
formula_50 such that
"x" and "y" are both rational. This is the same as asking for all integer solutions
to formula_51; any solution to the latter equation gives
us a solution formula_52, formula_53 to the former. It is also the
same as asking for all points with rational coordinates on the curve
described by formula_54. (This curve happens to be a circle of radius 1 around the origin.)
The rephrasing of questions on equations in terms of points on curves turns out to be felicitous. The finiteness or not of the number of rational or integer points on an algebraic curve—that is, rational or integer solutions to an equation formula_55, where formula_56 is a polynomial in two variables—turns out to depend crucially on the "genus" of the curve. The "genus" can be defined as follows: allow the variables in formula_55 to be complex numbers; then formula_55 defines a 2-dimensional surface in (projective) 4-dimensional space (since two complex variables can be decomposed into four real variables, i.e., four dimensions). Count
the number of (doughnut) holes in the surface; call this number the "genus" of formula_55. Other geometrical notions turn out to be just as crucial.
There is also the closely linked area of Diophantine approximations: given a number formula_35, how well can it be approximated by rationals? (We are looking for approximations that are good relative to the amount of space that it takes to write the rational: call formula_61 (with formula_62) a good approximation to formula_35 if formula_64, where formula_65 is large.) This question is of special interest if formula_35 is an algebraic number. If formula_35 cannot be well approximated, then some equations do not have integer or rational solutions. Moreover, several concepts (especially that of height) turn out to be crucial both in Diophantine geometry and in the study of Diophantine approximations. This question is also of special interest in transcendence theory: if a number can be better approximated than any algebraic number, then it is a transcendental number. It is by this argument that π and e have been shown to be transcendental.
Diophantine geometry should not be confused with the geometry of numbers, which is a collection of graphical methods for answering certain questions in algebraic number theory. "Arithmetic geometry", on the other hand, is a contemporary term
for much the same domain as that covered by the term "Diophantine geometry". The term "arithmetic geometry" is arguably used
most often when one wishes to emphasise the connections to modern algebraic geometry (as in, for instance, Faltings' theorem) rather than to techniques in Diophantine approximations.
Recent approaches and subfields.
The areas below date as such from no earlier than the mid-twentieth century, even if they are based on older material. For example, as is explained below, the matter of algorithms in number theory is very old, in some sense older than the concept of proof; at the same time, the modern study of computability dates only from the 1930s and 1940s, and computational complexity theory from the 1970s.
Probabilistic number theory.
Take a number at random between one and a million. How likely is it to be prime? This is just another way of asking how many primes there are between one and a million. Further: how many prime divisors will it have, on average? How many divisors will it have altogether, and with what likelihood? What is the probability that it have many more or many fewer divisors or prime divisors than the average?
Much of probabilistic number theory can be seen as an important special case of the study of variables that are almost, but not quite, mutually independent. For example, the event that a random integer between one and a million be divisible by two and the event that it be divisible by three are almost independent, but not quite.
It is sometimes said that probabilistic combinatorics uses the fact that whatever happens with probability greater than formula_68 must happen sometimes; one may say with equal justice that many applications of probabilistic number theory hinge on the fact that whatever is unusual must be rare. If certain algebraic objects (say, rational or integer solutions to certain equations) can be shown to be in the tail of certain sensibly defined distributions, it follows that there must be few of them; this is a very concrete non-probabilistic statement following from a probabilistic one.
At times, a non-rigorous, probabilistic approach leads to a number of heuristic algorithms and open problems, notably Cramér's conjecture.
Arithmetic combinatorics.
Let "A" be a set of "N" integers. Consider the set "A" + "A" = { "m" + "n" | "m", "n" ∈ "A" } consisting of all sums of two elements of "A". Is "A + A" much larger than "A"? Barely larger? If "A + A" is barely larger than "A", must "A" have plenty of arithmetic structure, for example, does "A" resemble an arithmetic progression?
If we begin from a fairly "thick" infinite set formula_69, does it contain many elements in arithmetic progression: formula_38,
formula_71, formula_72, formula_73, formula_74 , formula_75, say? Should it be possible to write large integers as sums of elements of formula_69?
These questions are characteristic of "arithmetic combinatorics". This is a presently coalescing field; it subsumes "additive number theory" (which concerns itself with certain very specific sets formula_69 of arithmetic significance, such as the primes or the squares) and, arguably, some of the "geometry of numbers",
together with some rapidly developing new material. Its focus on issues of growth and distribution accounts in part for its developing links with ergodic theory, finite group theory, model theory, and other fields. The term "additive combinatorics" is also used; however, the sets formula_69 being studied need not be sets of integers, but rather subsets of non-commutative groups, for which the multiplication symbol, not the addition symbol, is traditionally used; they can also be subsets of rings, in which case the growth of formula_79 and formula_69·formula_69 may be
compared.
Computations in number theory.
While the word "algorithm" goes back only to certain readers of al-Khwārizmī, careful descriptions of methods of solution are older than proofs: such methods (that is, algorithms) are as old as any recognisable mathematics—ancient Egyptian, Babylonian, Vedic, Chinese—whereas proofs appeared only with the Greeks of the classical period.
An interesting early case is that of what we now call the Euclidean algorithm. In its basic form (namely, as an algorithm for computing the greatest common divisor) it appears as Proposition 2 of Book VII in "Elements", together with a proof of correctness. However, in the form that is often used in number theory (namely, as an algorithm for finding integer solutions to an equation formula_82,
or, what is the same, for finding the quantities whose existence is assured by the Chinese remainder theorem) it first appears in the works of Āryabhaṭa (5th–6th century CE) as an algorithm called
"kuṭṭaka" ("pulveriser"), without a proof of correctness.
There are two main questions: "can we compute this?" and "can we compute it rapidly?". Anybody can test whether a number is prime or, if it is not, split it into prime factors; doing so rapidly is another matter. We now know fast algorithms for testing primality, but, in spite of much work (both theoretical and practical), no truly fast algorithm for factoring.
The difficulty of a computation can be useful: modern protocols for encrypting messages (e.g., RSA) depend on functions that are known to all, but whose inverses (a) are known only to a chosen few, and (b) would take one too long a time to figure out on one's own. For example, these functions can be such that their inverses can be computed only if certain large integers are factorized. While many difficult computational problems outside number theory are known, most working encryption protocols nowadays are based on the difficulty of a few number-theoretical problems.
On a different note — some things may not be computable at all; in fact, this can be proven in some instances. For instance, in 1970, it was proven, as a solution to Hilbert's 10th problem, that there is no Turing machine which can solve all Diophantine equations. In particular, this means that, given a computably enumerable set of axioms, there are Diophantine equations for which there is no proof, starting from the axioms, of whether the set of equations has or does not have integer solutions. (We would necessarily be speaking of Diophantine equations for which there are no integer solutions, since, given a Diophantine equation with at least one solution, the solution itself provides a proof of the fact that a solution exists. We cannot prove, of course, that a particular Diophantine equation is of this kind, since this would imply that it has no solutions.)
Applications.
The number-theorist Leonard Dickson (1874-1954) said "Thank God that number theory is unsullied by any application". Such a view is no longer applicable to number theory. In 1974, Donald Knuth said "...virtually every theorem in elementary number theory arises in a natural, motivated way in connection with the problem of making computers do high-speed numerical calculations".
Elementary number theory is taught in discrete mathematics courses for computer scientists; and, on the other hand, number theory also has applications to the continuous in numerical analysis. As well as the well-known applications to cryptography, there are also applications to many other areas of mathematics.
Literature.
Two of the most popular introductions to the subject are:
Hardy and Wright's book is a comprehensive classic, though its clarity sometimes suffers due to the authors' insistence on elementary methods.
Vinogradov's main attraction consists in its set of problems, which quickly lead to Vinogradov's own research interests; the text itself is very basic and close to minimal. Other popular first introductions are:
Popular choices for a second textbook include:
Prizes.
The American Mathematical Society awards the "Cole Prize in Number Theory". Moreover number theory is one of the three mathematical subdisciplines rewarded by the "Fermat Prize".
Sources.
 
 |last=Hopkins
 |first=J. F. P.
 |editor1-last=Young
 |editor1-first=M. J. L.
 |editor2-last=Latham
 |editor2-first=J. D.
 |editor3-last=Serjeant
 |editor3-first=R. B.
 |year=1990
 |author-link=
 |author2-link=
 |chapter=Geographical and navigational literature
 |title=Religion, learning and science in the `Abbasid period
 |series=The Cambridge history of Arabic literature
 |publisher=Cambridge University Press
 |isbn=978-0-521-32763-3
 |last=Huffman
 |first=Carl A.
 |editor1-last=Zalta
 |editor1-first=Edward N.
 |date=8 August 2011
 |title=Pythagoras
 |work=Stanford Encyclopaedia of Philosophy
 |edition=Fall 2011
 |url=http://plato.stanford.edu/archives/fall2011/entries/pythagoras/
 |accessdate=7 February 2012
 |last=Iwaniec
 |first=Henryk
 |author-link=Henryk Iwaniec
 |last2=Kowalski
 |first2=Emmanuel
 |author2-link=
 |year=2004
 |title=Analytic number theory
 |series=American Mathematical Society Colloquium Publications
 |volume=53
 |location=Providence, RI,
 |publisher=American Mathematical Society
 |isbn=0-8218-3633-1
 |url=
 |last2=Jowett
 |first2=Benjamin (trans.)
 |author2-link=Benjamin Jowett
 |year=1871
 |last1=Plato
 |author1-link=Plato
 |title=Theaetetus
 |last=Lam
 |first=Lay Yong
 |last2=Ang
 |first2=Tian Se
 |year=2004
 |author-link=Lam Lay Yong
 |author2-link=
 |title=Fleeting Footsteps: Tracing the conception of arithmetic and algebra in ancient China
 |edition=revised
 |location=Singapore
 |publisher=World Scientific
 |isbn=978-981-238-696-0
 |url=http://books.google.co.uk/books?id=fGYmpWE5UZgC
 | last = Long
 | first = Calvin T.
 | year = 1972
 | title = Elementary Introduction to Number Theory
 | edition = 2nd
 | publisher = D. C. Heath and Company
 | location = Lexington
 |last=Mahoney
 |first=M. S.
 |year=1994
 |author-link=
 |title=The mathematical career of Pierre de Fermat, 1601–1665
 |edition=Reprint, 2nd
 |publisher=Princeton University Press
 |isbn=978-0-691-03666-3
 |url=http://books.google.co.uk/books?id=My19IcewAnoC
 |last=Montgomery
 |first=Hugh L.
 |author-link=Hugh Montgomery (mathematician)
 |year=2007
 |last2=Vaughan
 |first2=Robert C.
 |author2-link=Bob Vaughan
 |title=Multiplicative number theory: I, Classical Theory,
 |publisher=Cambridge University Press
 |isbn=978-0-521-84903-6
 |url=http://books.google.co.uk/books?id=nGb1NADRWgcC
 |last=Morrow
 |first=Glenn Raymond (trans., ed.)
 |year=1992
 |author-link=
 |last2=Proclus
 |author2-link=Proclus
 |title=A commentary on Book 1 of Euclid's Elements
 |publisher=Princeton University Press
 |isbn=978-0-691-02090-7
 |last=Mumford
 |first=David
 |title=Mathematics in India: reviewed by David Mumford
 |journal=Notices of the American Mathematical Society
 |date=March 2010
 |volume=57
 |issue=3
 |page=387
 |issn=1088-9477
 |url=http://www.ams.org/notices/201003/rtx100300385p.pdf
 |last=Neugebauer
 |first=Otto E.
 |year=1969
 |author-link=Otto E. Neugebauer
 |title=The exact sciences in antiquity
 |edition=corrected reprint of the 1957
 |location=New York
 |publisher=Dover Publications
 |isbn=978-0-486-22332-2
 |url=http://books.google.co.uk/books?id=JVhTtVA2zr8C
 |last=Neugebauer
 |first=Otto E.
 |last2=Sachs
 |first2=Abraham Joseph
 |last3=Götze
 |first3= Albrecht
 |year=1945
 |author-link=Otto E. Neugebauer
 |author2-link=Abraham Sachs
 |title=Mathematical cuneiform texts
 |series=American Oriental Series
 |volume=29
 |location=
 |publisher=American Oriental Society etc.
 |isbn=
 |last=O'Grady
 |first=Patricia
 |date=September 2004
 |title=Thales of Miletus
 |url=http://www.iep.utm.edu/thales/
 |publisher=The Internet Encyclopaedia of Philosophy
 |ref=harv
 |last=Pingree
 |first=David
 |last2=Ya'qub
 |first2=ibn Tariq
 |author1-link=David Pingree
 |author2-link=Yaʿqūb ibn Ṭāriq
 |year=1968
 |title=The fragments of the works of Ya'qub ibn Tariq
 |journal=Journal of Near Eastern Studies
 |publisher=University of Chicago Press
 |volume=26
 |isbn=
 |last=Pingree
 |first=D.
 |last2=al-Fazari
 |first2=
 |year=1970
 |author-link=
 |author2-link=al-Fazari
 |title=The fragments of the works of al-Fazari
 |journal=Journal of Near Eastern Studies
 |publisher=University of Chicago Press
 |volume=28
 |isbn=
 |last=Plofker
 |first=Kim
 |year=2008
 |title=Mathematics in India
 |publisher=Princeton University Press
 |isbn=978-0-691-12067-6
 |editor1-last=Qian
 |editor1-first=Baocong
 |year=1963
 |language=Chinese
 |title=Suanjing shi shu (Ten mathematical classics)
 |location=Beijing
 |publisher=Zhonghua shuju
 |isbn=
 |url=http://www.scribd.com/doc/53797787/Jigu-Suanjing%E3%80%80%E7%B7%9D%E5%8F%A4%E7%AE%97%E7%B6%93-Qian-Baocong-%E9%8C%A2%E5%AF%B6%E7%90%AE
 |last=Rashed
 |first=Roshdi
 |last2=
 |first2=
 |year=1980
 |author-link=
 |author2-link=
 |chapter=
 |title=Ibn al-Haytham el le théorème de Wilson
 |journal=Archive for History of Exact Sciences
 |volume=22
 |issue=4
 |pages=305–321
 |doi=10.1007/BF00717654
 |last=Robson
 |first=Eleanor
 |year=2001
 |title=Neither Sherlock Holmes nor Babylon: a reassessment of Plimpton 322
 |volume=28
 |journal=Historia Mathematica
 |issue=28
 |pages=167–206
 |location=
 |publisher=Elsevier
 |isbn=
 |doi=10.1006/hmat.2001.2317
 |url=http://www.hps.cam.ac.uk/people/robson/neither-sherlock.pdf
 |last=Sachau
 |first=Eduard
 |author-link=Eduard Sachau
 |last2=Bīrūni 
 |first2=̄Muḥammad ibn Aḥmad
 |author2-link= Abū Rayḥān al-Bīrūnī
 |year=1888
 |title=Alberuni's India: An account of the religion, philosophy, literature, geography, chronology, astronomy and astrology of India, Vol. 1
 |location=London
 |publisher=Kegan, Paul, Trench, Trübner & Co.
 |url=http://onlinebooks.library.upenn.edu/webbin/book/lookupname?key=Sachau%2C%20Eduard%2C%201845-1930
 |last=Serre
 |first=Jean-Pierre
 |year=1996
 |origyear=1973
 |author-link=Jean-Pierre Serre
 |author2-link=
 |title=A course in arithmetic
 |series=Graduate texts in mathematics
 |volume=7
 |publisher=Springer
 |isbn=978-0-387-90040-7
 |url=
 |last=Smith
 |first=D. E.
 |author-link=
 |year=1958
 |title=History of Mathematics, Vol I
 |location=New York
 |publisher=Dover Publications
 |isbn=
 |url=
 |last=Tannery
 |first=Paul
 |author1-link=Paul Tannery
 |last2=Henry
 |first2=Charles (eds.)
 |author2-link=Charles Henry (librarian)
 |year=1891
 |last3=Fermat
 |first3=Pierre de
 |author3-link=Pierre de Fermat
 |language=French, Latin
 |chapter=
 |title=Oeuvres de Fermat
 |series=(4 Vols.)
 |volume=
 |location=Paris
 |publisher=Imprimerie Gauthier-Villars et Fils
 |url=}} 
 |last2=Taylor
 |first2=Thomas (trans.)
 |author2-link=Thomas Taylor (neoplatonist)
 |year=1818
 |last1=Iamblichus
 |first1=
 |author1-link=Iamblichus
 |title=Life of Pythagoras or, Pythagoric life
 |location=London
 |publisher=J. M. Watkins
 |isbn=
 |url=http://www.aurumsolis.info/index.php?option=com_phocadownload&view=category&download=1%3Aiamblichus-the-pythagorean-life&id=19%3Awritings-from-the-founders&Itemid=143&lang=en}} For other editions, see Iamblichus#List of editions and translations
 |last=Truesdell
 |first=C. A.
 |author-link=Clifford Truesdell
 |year=1984
 |last2=
 |first2=
 |author2-link=
 |editor1-last=Hewlett
 |editor1-first=John (trans.)
 |editor1-link=
 |chapter=Leonard Euler, supreme geometer
 |title=Leonard Euler, Elements of Algebra
 |series=
 |edition=reprint of 1840 5th
 |volume=
 |issue=
 |location=New York
 |publisher=Springer-Verlag
 |isbn=978-0-387-96014-2
 |url=http://books.google.co.uk/books?id=mkOhy6v7kIsC
 |ref=harv}} This Google books preview of "Elements of algebra" lacks Truesdell's intro, which is reprinted (slightly abridged) in the following book:
 |last=Truesdell
 |first=C. A.
 |author-link=Clifford Truesdell
 |year=2007
 |last2=
 |first2=
 |author2-link=
 |editor1-last=Dunham
 |editor1-first=William
 |editor1-link=
 |chapter=Leonard Euler, supreme geometer
 |title=The Genius of Euler: reflections on his life and work
 |series=Volume 2 of MAA tercentenary Euler celebration
 |location=New York
 |publisher=Mathematical Association of America
 |isbn=978-0-88385-558-4
 |url=http://books.google.co.uk/books?id=M4-zUnrSxNoC
 |last=Varadarajan
 |first=V. S.
 |author-link=
 |year=2006
 |title=Euler through time: a new look at old themes
 |location=
 |publisher=American Mathematical Society
 |isbn=978-0-8218-3580-7
 |url=http://books.google.co.uk/books?id=CYyKTREGYd0C
 |last=Vardi
 |first=Ilan
 |title=Archimedes' cattle problem
 |date=April 1998
 |journal=American Mathematical Monthly
 |volume=105
 |issue=4
 |pages=305–319
 |isbn=
 |url=https://www.cs.drexel.edu/~crorres/Archimedes/Cattle/cattle_vardi.pdf
 |ref=harv
 |last=van der Waerden
 |first=Bartel L.
 |last2=Dresden
 |first2=Arnold (trans)
 |year=1961
 |author-link=Bartel Leendert van der Waerden
 |author2-link=
 |title=Science Awakening
 |volume=Vol. 1 or Vol 2
 |location=New York
 |publisher=Oxford University Press
 |isbn=
 |last=Weil
 |first=André
 |year=1984
 |author-link=André Weil
 |title=Number theory: an approach through history – from Hammurapi to Legendre,
 |location=Boston
 |publisher=Birkhäuser
 |isbn=978-0-8176-3141-3
 |url=http://books.google.co.uk/books?id=XSV0hDFj3loC

</doc>
<doc id="21530" url="http://en.wikipedia.org/wiki?curid=21530" title="Nitroglycerin">
Nitroglycerin

Nitroglycerin (NG), also known as nitroglycerine, trinitroglycerin (TNG), trinitroglycerine, nitro, glyceryl trinitrate (GTN), or 1,2,3-trinitroxypropane, is a heavy, colorless, oily, explosive liquid most commonly produced by nitrating glycerol with white fuming nitric acid under conditions appropriate to the formation of the nitric acid ester. Chemically, the substance is an organic nitrate compound rather than a nitro compound, yet the traditional name is often retained. Invented in 1847, nitroglycerin has been used as an active ingredient in the manufacture of explosives, mostly dynamite, and as such it is employed in the construction, demolition, and mining industries. Since the 1880s, it has been used by the military as an active ingredient, and a gelatinizer for nitrocellulose, in some solid propellants, such as cordite and ballistite.
Nitroglycerin is also a major component in double-based smokeless gunpowders used by reloaders. Combined with nitrocellulose, there are hundreds of (powder) combinations used by rifle, pistol, and shotgun reloaders.
For over 130 years, nitroglycerin has been used medically as a potent vasodilator to treat heart conditions, such as angina pectoris and chronic heart failure. Though it was previously known that these beneficial effects are due to nitroglycerin being converted to nitric oxide, a potent vasodilator, it was not until 2002 that the enzyme for this conversion was discovered to be mitochondrial aldehyde dehydrogenase. Nitroglycerin is available in sublingual tablets, sprays, and patches. Other potential suggested uses include adjunct therapy in prostate cancer.
History.
Nitroglycerin was the first practical explosive produced that was stronger than black powder. It was first synthesized by the Italian chemist Ascanio Sobrero in 1847, working under Théophile-Jules Pelouze at the University of Turin. Sobrero initially called his discovery "pyroglycerine" and warned vigorously against its use as an explosive.
Nitroglycerin was later adopted as a commercially useful explosive by Alfred Nobel, who experimented with safer ways to handle the dangerous compound after his younger brother, Emil Oskar Nobel, and several factory workers were killed in an explosion at the Nobels' armaments factory in 1864 in Heleneborg, Sweden.
One year later, Nobel founded Alfred Nobel & Company in Germany and built an isolated factory in the Krümmel hills of Geesthacht near Hamburg. This business exported a liquid combination of nitroglycerin and gunpowder called "Blasting Oil", but this was extremely unstable and difficult to handle, as evidenced in numerous catastrophes. The buildings of the Krümmel factory were destroyed twice.
In April 1866, three crates of nitroglycerin were shipped to California for the Central Pacific Railroad, which planned to experiment with it as a blasting explosive to expedite the construction of the 1659 ft-long Summit Tunnel through the Sierra Nevada Mountains. One of the crates exploded, destroying a Wells Fargo company office in San Francisco and killing 15 people. This led to a complete ban on the transportation of liquid nitroglycerin in California. The on-site manufacture of nitroglycerin was thus required for the remaining hard-rock drilling and blasting required for the completion of the First Transcontinental Railroad in North America.
Liquid nitroglycerin was widely banned elsewhere as well, and these legal restrictions led to Alfred Nobel and his company's developing dynamite in 1867. This was made by mixing nitroglycerin with diatomaceous earth ("kieselgur" in German) found in the Krümmel hills. Similar mixtures, such as "dualine" (1867), "lithofracteur" (1869), and "gelignite" (1875), were formed by mixing nitroglycerin with other inert absorbents, and many combinations were tried by other companies in attempts to get around Nobel's tightly held patents for dynamite.
Dynamite mixtures containing nitrocellulose, which increases the viscosity of the mix, are commonly known as "gelatins".
Following the discovery that amyl nitrite helped alleviate chest pain, Dr. William Murrell experimented with the use of nitroglycerin to alleviate angina pectoris and to reduce the blood pressure. He began treating his patients with small diluted doses of nitroglycerin in 1878, and this treatment was soon adopted into widespread use after Murrell published his results in the journal "The Lancet" in 1879. A few months before his death in 1896, Alfred Nobel was prescribed nitroglycerine for this heart condition, writing to a friend: "Isn't it the irony of fate that I have been prescribed nitro-glycerin, to be taken internally! They call it Trinitrin, so as not to scare the chemist and the public." The medical establishment also used the name "glyceryl trinitrate" for the same reason.
Wartime production rates.
Large quantities of nitroglycerin were manufactured during World War I and World War II for use as military propellants and in military engineering work. During World War I, HM Factory, Gretna, the largest propellant factory in Great Britain, produced about 800 long tons (812 tonnes) of Cordite RDB per week. This amount took at least 336 tons of nitroglycerin per week (assuming no losses in production). The Royal Navy had its own factory at the Royal Navy Cordite Factory, Holton Heath in Dorset, England. A large cordite factory was also built in Canada during World War I. The Canadian Explosives Limited cordite factory at Nobel, Ontario, was designed to produce 1500000 lb of cordite per month, requiring about 286 tonnes of nitroglycerin per month.
Instability and desensitization.
In its pure form, nitroglycerin is a primary contact explosive, with physical shock causing it to explode, and it degrades over time to even more unstable forms. This makes nitroglycerin highly dangerous to transport or use. In its undiluted form, it is one of the world's most powerful explosives, comparable to the more recently developed RDX and PETN.
Early in its history, it was discovered that liquid nitroglycerin can be "desensitized" by cooling it to about 5 to. At this temperature nitroglycerin freezes, contracting upon solidification. Thawing it out can be extremely sensitizing, especially if impurities are present or the warming is too rapid. It is possible to chemically "desensitize" nitroglycerin to a point where it can be considered approximately as "safe" as modern high explosives, such as by the addition of approximately 10% to 30% ethanol, acetone, or dinitrotoluene. (The percentage varies with the desensitizing agent used.) Desensitization requires extra effort to reconstitute the "pure" product. Failing this, it must be assumed that desensitized nitroglycerin is substantially more difficult to detonate, possibly rendering it useless as an explosive for practical application.
A serious problem in the use of nitroglycerin results from its high freezing point 13 C. Solid nitroglycerin is much less sensitive to shock than the liquid, a feature that is common in explosives. In the past, nitroglycerin was often shipped in the frozen state, but this resulted in a high number of accidents during the thawing process just before its use. This disadvantage is overcome by using mixtures of nitroglycerin with other polynitrates. For example, a mixture of nitroglycerin and ethylene glycol dinitrate freezes at -29 C.
Detonation.
Nitroglycerin and any diluents can certainly deflagrate, i.e., burn. The explosive power of nitroglycerin derives from detonation: energy from the initial decomposition causes a strong pressure wave that detonates the surrounding fuel. This is a self-sustained shock wave that propagates through the explosive medium at some 30 times the speed of sound as a near-instantaneous pressure-induced decomposition of the fuel into a white-hot gas. Detonation of nitroglycerin generates gases that would occupy more than 1,200 times the original volume at ordinary room temperature and pressure. The heat liberated raises the temperature to about 5000 C. This is entirely different from deflagration, which depends solely upon available fuel regardless of pressure or shock. The decomposition results in much higher ratio of energy to gas moles released compared to other explosives, making it one of the hottest detonating high explosives.
Manufacturing.
The industrial manufacturing process often uses a nearly 1:1 mixture of concentrated sulfuric acid and concentrated nitric acid. This can be produced by mixing white fuming nitric acid—a quite expensive pure nitric acid in which the oxides of nitrogen have been removed, as opposed to red fuming nitric acid, which contains nitrogen oxides—and concentrated sulfuric acid. More often, this mixture is attained by the cheaper method of mixing fuming sulfuric acid, also known as oleum—sulfuric acid containing excess sulfur trioxide—and azeotropic nitric acid (consisting of about 70 percent nitric acid, with the rest being water).
The sulfuric acid produces protonated nitric acid species, which are attacked by glycerin's nucleophilic oxygen atoms. The nitro group is thus added as an ester C-O-NO2 and water is produced. This is different from an electrophilic aromatic substitution reaction in which nitronium ions are the electrophile.
The addition of glycerin results in an exothermic reaction (i.e., heat is produced), as usual for mixed-acid nitrations. However, if the mixture becomes too hot, it results in "runaway", a state of accelerated nitration accompanied by the destructive oxidation of organic materials by the hot nitric acid and the release of poisonous nitrogen dioxide gas at high risk of an explosion. Thus, the glycerin mixture is added slowly to the reaction vessel containing the mixed acid (not acid to glycerin). The nitrator is cooled with cold water or some other coolant mixture and maintained throughout the glycerin addition at about 22 C, much below which the esterification occurs too slowly to be useful. The nitrator vessel, often constructed of iron or lead and generally stirred with compressed air, has an emergency trap door at its base, which hangs over a large pool of very cold water and into which the whole reaction mixture (called the charge) can be dumped to prevent an explosion, a process referred to as drowning. If the temperature of the charge exceeds about 30 C (actual value varying by country) or brown fumes are seen in the nitrator's vent, then it is immediately drowned.
Use as an explosive and a propellant.
The main use of nitroglycerin, by tonnage, is in explosives such as dynamite and in propellants.
Nitroglycerin is an oily liquid that may explode when subjected to heat, shock or flame. It is dangerously sensitive and dropping or bumping a container may cause it to explode.
Alfred Nobel developed the use of nitroglycerin as a blasting explosive by mixing the nitroglycerin with inert absorbents, particularly "kieselguhr," or diatomaceous earth. He named this explosive dynamite and patented it in 1867. It was supplied ready for use in the form of sticks, individually wrapped in greased waterproof paper. Dynamite and similar explosives were widely adopted for civil engineering tasks, such as in drilling highway and railroad tunnels, for mining, for clearing farmland of stumps, in quarrying, and in demolition work. Likewise, military engineers have used dynamite for construction and demolition work.
Nitroglycerin was also used as an ingredient in military propellants for use in firearms.
Nitroglycerin has been used in conjunction with hydraulic fracturing, a process used to recover oil and gas from shale formations. The technique involves displacing and detonating nitroglycerin in natural or hydraulically induced fracture systems, or displacing and detonating nitroglycerin in hydraulically induced fractures followed by wellbore shots using pelletized TNT.
Nitroglycerin has an advantage over some other high explosives, that on detonation it produces practically no visible smoke. Therefore it is useful as an ingredient in the formulation of various kinds of "smokeless powder".
Its sensitivity has limited the usefulness of nitroglycerin as a military explosive, and less sensitive explosives such as TNT, RDX, and HMX have largely replaced it in munitions. It remains important in military engineering, and combat engineers still use dynamite.
Alfred Nobel then developed ballistite, by combining nitroglycerin and guncotton. He patented it in 1887. Ballistite was adopted by a number of European governments, as a military propellant. Italy was the first to adopt it. The British Government and the Commonwealth governments adopted cordite instead, which had been developed by Sir Frederick Abel and Sir James Dewar of the United Kingdom in 1889. The original Cordite Mk I consisted of 58% nitroglycerin, 37% guncotton, and 5.0% petroleum jelly. Ballistite and cordite were both manufactured in the forms of "cords".
Smokeless powders were originally developed using nitrocellulose as the sole explosive ingredient. Therefore, they were known as "single-base" propellants. A range of smokeless powders that contain both nitrocellulose and nitroglycerin, known as "double-base" propellants, were also developed. Smokeless powders were originally supplied only for military use, but they were also soon developed for civilian use and were quickly adopted for sports. Some are known as sporting powders. "Triple-base" propellants contain nitrocellulose, nitroglycerin, and nitroguanidine, but are reserved mainly for extremely high-caliber ammunition rounds such as those used in tank cannons and naval artillery.
Blasting gelatin, also known as "gelignite", was invented by Nobel in 1875, using nitroglycerin, wood pulp, and sodium or potassium nitrates. This was an early low-cost, flexible explosive.
Medical use.
Nitroglycerin belongs to a group of drugs called nitrates, which includes many other nitrates like isosorbide dinitrate (Isordil) and isosorbide mononitrate (Imdur, Ismo, Monoket). These agents all exert their effect by being converted to nitric oxide in the body by mitochondrial aldehyde dehydrogenase, and nitric oxide is a potent natural vasodilator.
In medicine, nitroglycerin is used as a medicine for angina pectoris, a painful symptom of ischemic heart disease caused by inadequate flow of blood and oxygen to the heart. Nitroglycerin corrects the imbalance between the flow of oxygen and blood to the heart. The principal action of nitroglycerin is vasodilation (widening of the blood vessels). At low doses, nitroglycerin will dilate veins more than arteries, thereby reducing preload; this is thought to be its primary mechanism of action. But at higher doses, it also dilates arteries, thereby reducing afterload. It is also a potent antihypertensive agent. In cardiac treatment, the lowering of pressure in the arteries reduces the pressure against which the heart must pump, thereby decreasing afterload. Dilating the veins decreases cardiac preload and lowers the oxygen requirement of the heart, which leads to the following therapeutic effects during episodes of angina pectoris: subsiding of chest pain, decrease of blood pressure, increase of heart rate, and orthostatic hypotension. Patients experiencing angina when doing certain physical activities can often prevent symptoms by taking nitroglycerin 5 to 10 minutes before the activity.
Nitroglycerin is available in tablets, ointment, solution for intravenous use, transdermal patches, or sprays administered sublingually. Some forms of nitroglycerin last much longer in the body than others. It has been shown that continuous exposure to nitrates can cause the body to stop responding normally to this medicine. Experts recommend that the patches be removed at night, allowing the body a few hours to restore its responsiveness to nitrates. Shorter-acting preparations can be used several times a day with less risk of the body's getting used to this drug. Nitroglycerin was first used by William Murrell to treat anginal attacks in 1878, with the discovery published that same year.
Industrial exposure.
Infrequent exposure to high doses of nitroglycerin can cause severe headaches known as "NG head" or "bang head". These headaches can be severe enough to incapacitate some people; however, humans develop a tolerance to and dependence on nitroglycerin after long-term exposure. Withdrawal can (rarely) be fatal; withdrawal symptoms include headaches and heart problems and if unacceptable may be treated with re-exposure to nitroglycerin or other suitable organic nitrates.
For workers in nitroglycerin (NTG) manufacturing facilities, the effects of withdrawal sometimes include a "Monday morning headache" in those experiencing regular nitroglycerin exposure in the workplace, leading to the development of tolerance for the vasodilating effects. Over the weekend, the workers lose the tolerance and, when they are re-exposed on Monday, the drastic vasodilation produces a fast heart rate, dizziness, and a headache.

</doc>
<doc id="21533" url="http://en.wikipedia.org/wiki?curid=21533" title="Navy">
Navy

A navy (or maritime force) is a fleet of waterborne military vessels (watercraft) and its associated naval aviation, both sea-based and land-based. It is the branch of a nation's armed forces principally designated for naval and amphibious warfare; namely, lake-borne, riverine, littoral, or ocean-borne combat operations and related functions. It includes anything conducted by surface ships, amphibious ships, submarines, and seaborne aviation, as well as ancillary support, communications, training, and other fields; recent developments have included space-related operations. The strategic offensive role of a navy is projection of force into areas beyond a country's shores (for example, to protect sea-lanes, ferry troops, or attack other navies, ports, or shore installations). The strategic defensive purpose of a navy is to frustrate seaborne projection-of-force by enemies. The strategic task of the navy also may incorporate nuclear deterrence by use of Submarine-launched ballistic missiles. Naval operations can be broadly divided between riverine and littoral applications (brown-water navy), open-ocean applications (blue-water navy), and something in between (green-water navy), although these distinctions are more about strategic scope than tactical or operational division.
In most nations, the term "naval", as opposed to "navy", is interpreted as encompassing all maritime military forces, e.g., navy, marine / marine corps, and coast guard forces.
Etymology and meanings.
First attested in English in the early 14th century, the word "navy" came via Old French "navie", "fleet of ships", from the Latin "navigium", "a vessel, a ship, bark, boat", from "navis", "ship". The word "naval" came from Latin "navalis", "pertaining to ship"; cf. Greek ναῦς ("naus"), "ship", ναύτης ("nautes"), "seaman, sailor". The earliest attested form of the word is in the Mycenaean Greek compound word 𐀙𐀄𐀈𐀗, "na-u-do-mo" (*"naudomoi"), "shipbuilders", written in Linear B syllabic script. There is also a possible connection to the tamil word "Navai" for boat/ship.
The word formerly denoted fleets of both commercial and military nature. In modern usage "navy" used alone always denotes a military fleet, although the term "merchant navy" for a commercial fleet still incorporates the non-military word sense. This overlap in word senses between commercial and military fleets grew out of the inherently dual-use nature of fleets; centuries ago, nationality was a trait that unified a fleet across both civilian and military uses. Although nationality of commercial vessels has little importance in peacetime trade other than for tax avoidance, it can have greater meaning during wartime, when supply chains become matters of patriotic attack and defense, and when in some cases private vessels are even temporarily converted to military vessels. The latter was especially important, and common, before 20th-century military technology existed, when merely adding artillery and naval infantry to any sailing vessel could render it fully as martial as any military-owned vessel. Such privateering has been rendered obsolete in blue-water strategy since modern missile and aircraft systems grew to leapfrog over artillery and infantry in many respects; but privateering nevertheless remains potentially relevant in littoral warfare of a limited and asymmetric nature.
History.
Naval warfare developed when humans first fought from water-borne vessels. Prior to the introduction of the cannon and ships with sufficient capacity to carry the large guns, navy warfare primarily involved ramming and boarding actions. In the time of ancient Greece and the Roman Empire, naval warfare centered on long, narrow vessels powered by banks of oarsmen (such as triremes and quinqueremes) designed to ram and sink enemy vessels or come alongside the enemy vessel so its occupants could be attacked hand-to-hand. Naval warfare continued in this vein through the Middle Ages until the cannon became commonplace and capable of being reloaded quickly enough to be reused in the same battle. The Chola Dynasty of medieval India was known as one of the greatest naval powers of its time from 300 BC to 1279 AD. The Chola Navy, Chola kadarpadai comprised the naval forces of the Chola Empire along with several other Naval-arms of the country. The Chola navy played a vital role in the expansion of the Chola Tamil kingdom, including the conquest of the Sri Lanka islands, Kadaaram (Present day Burma), Sri Vijaya (present day Southeast Asia), the spread of Hinduism, Tamil architecture and Tamil culture to Southeast Asia and in curbing the piracy in Southeast Asia in 900 CE. In ancient China, large naval battles were known since the Qin Dynasty ("also see" Battle of Red Cliffs, 208), employing the war junk during the Han Dynasty. However, China's first official standing navy was not established until the Southern Song Dynasty in the 12th century, a time when gunpowder was a revolutionary new application to warfare.
The mass and deck space required to carry a large number of cannon made oar-based propulsion impossible, and ships came to rely primarily on sails. Warships were designed to carry increasing numbers of cannon and naval tactics evolved to bring a ship's firepower to bear in a broadside, with ships-of-the-line arranged in a line of battle.
The development of large capacity, sail-powered ships carrying cannon led to a rapid expansion of European navies, especially the Spanish and Portuguese navies which dominated in the 16th and early 17th centuries, and helped propel the age of exploration and colonialism. The repulsion of the Spanish Armada (1588) by the English fleet revolutionized naval warfare by the success of a guns-only strategy and caused a major overhaul of the Spanish Navy, partly along English lines, which resulted in even greater dominance by the Spanish. From the beginning of the 17th century the Dutch cannibalized the Portuguese Empire in the East and, with the immense wealth gained, challenged Spanish hegemony at sea. From the 1620s, Dutch raiders seriously troubled Spanish shipping and, after a number of battles which went both ways, the Dutch Navy finally broke the long dominance of the Spanish Navy in the Battle of the Downs (1639).
England emerged as a major naval power in the mid-17th century in the first Anglo-Dutch war with a technical victory. Successive decisive Dutch victories in the second and third Anglo-Dutch Wars confirmed the Dutch mastery of the seas during the Dutch Golden Age, financed by the expansion of the Dutch Empire. The French Navy won some important victories near the end of the 17th century but a focus upon land forces led to the French Navy's relative neglect, which allowed the Royal Navy to emerge with an ever-growing advantage in size and quality, especially in tactics and experience, from 1695. Throughout the 18th century the Royal Navy gradually gained ascendancy over the French Navy, with victories in the War of Spanish Succession (1701–1714), inconclusive battles in the War of Austrian Succession (1740–1748), victories in the Seven Years' War (1754–1763), a partial reversal during the American War of Independence (1775–1783), and consolidation into uncontested supremacy during the 19th century from the Battle of Trafalgar in 1805. These conflicts saw the development and refinement of tactics which came to be called the line of battle.
The next stage in the evolution of naval warfare was the introduction of metal plating along the hull sides. The increased mass required steam-powered engines, resulting in an arms race between armor and weapon thickness and firepower. The first armored vessels, the French "Gloire" and British HMS "Warrior", made wooden vessels obsolete. Another significant improvement came with the invention of the rotating turrets, which allowed the guns to be aimed independently of ship movement. The battle between the CSS "Virginia" and the USS "Monitor" during the American Civil War (1861–1865) is often cited as the beginning of this age of maritime conflict. The Russian Navy was considered the third strongest in the world on the eve of the Russo-Japanese War, which turned to be a catastrophe for the Russian military in general and the Russian Navy in particular. Although neither party lacked courage, the Russians were defeated by the Japanese in the Battle of Port Arthur, which was the first time in warfare that mines were used for offensive purposes. The warships of the Baltic Fleet sent to the Far East were lost in the Battle of Tsushima. A further step change in naval firepower occurred when the United Kingdom launched HMS "Dreadnought" (1906), but naval tactics still emphasized the line of battle.
The first practical military submarines were developed in the late 19th century and by the end of World War I had proven to be a powerful arm of naval warfare. During World War II, Nazi Germany's submarine fleet of U-boats almost starved the United Kingdom into submission and inflicted tremendous losses on U.S. coastal shipping. The , a sister ship of the "Bismarck", was almost put out of action by miniature submarines known as X-Craft. The X-Craft severely damaged her and kept her in port for some months.
A major paradigm shift in naval warfare occurred with the introduction of the aircraft carrier. First at Taranto in 1940 and then at Pearl Harbor in 1941, the carrier demonstrated its ability to strike decisively at enemy ships out of sight and range of surface vessels. The Battle of Leyte Gulf (1944) was arguably the largest naval battle in history; it was also the last battle in which battleships played a significant role. By the end of World War II, the carrier had become the dominant force of naval warfare.
World War II also saw the United States become by far the largest Naval power in the world. In the late 20th and early 21st centuries, the United States Navy possessed over 70% of the world's total numbers and total tonnage of naval vessels of 1,000 tons or greater. Throughout the rest of the 20th century, the United States Navy would maintain a tonnage greater than that of the next 17 largest navies combined. During the Cold War, the Soviet Navy became a significant armed force, with large numbers of large, heavily armed ballistic missile submarines and extensive use of heavy, long-ranged antisurface missiles to counter the numerous United States carrier battle groups. Only 3 nations (United States, France, and Brazil) presently operate CATOBAR carriers of any size, while Russia, China and India operate sizeable STOBAR carriers (although all three are originally of Russian design). The UK is also currently constructing two Queen Elizabeth class carriers, which will be the largest STOVL vessels in service, and India is currently building one Vikrant-class aircraft carrier and considering another. France is also looking at a new carrier, probably using a CATOBAR system and possibly based on the British Queen Elizabeth design.
Operations.
A navy typically operates from one or more naval bases. The base is a port that is specialized in naval operations, and often includes housing, a munitions depot, docks for the vessels, and various repair facilities. During times of war temporary bases may be constructed in closer proximity to strategic locations, as it is advantageous in terms of patrols and station-keeping. Nations with historically strong naval forces have found it advantageous to obtain basing rights in other countries in areas of strategic interest.
Navy ships can operate independently or with a group, which may be a small squadron of comparable ships, or a larger naval fleet of various specialized ships. The commander of a fleet travels in the flagship, which is usually the most powerful vessel in the group. Prior to the invention of radio, commands from the flagship were communicated by means of flags. At night signal lamps could be used for a similar purpose. Later these were replaced by the radio transmitter, or the flashing light when radio silence was needed.
A "blue water navy" is designed to operate far from the coastal waters of its home nation. These are ships capable of maintaining station for long periods of time in deep ocean, and will have a long logistical tail for their support. Many are also nuclear powered to save having to refuel. By contrast a "brown water navy" operates in the coastal periphery and along inland waterways, where larger ocean-going naval vessels can not readily enter. Regional powers may maintain a "green water navy" as a means of localized force projection. Blue water fleets may require specialized vessels, such as mine sweepers, when operating in the littoral regions along the coast.
Traditions.
A basic tradition is that all ships commissioned in a navy are referred to as ships rather than vessels, with the exception of submarines, which are known as boats. The prefix on a ship's name indicates that it is a commissioned ship.
An important tradition on board naval vessels of some nations has been the ship's bell. This was historically used to mark the passage of time, as warning devices in heavy fog, and for alarms and ceremonies.
The ship's captain, and more senior officers are "piped" aboard the ship using a Boatswain's call.
In the United States, the First Navy Jack is a flag that has the words, "Don't Tread on Me" on the flag.
By English tradition, ships have been referred to as a "she". However, it was long considered bad luck to permit women to sail on board naval vessels. To do so would invite a terrible storm that would wreck the ship. The only women that were welcomed on board were figureheads mounted on the prow of the ship.
Firing a cannon salute partially disarms the ship, so firing a cannon for no combat reason showed respect and trust. As the tradition evolved, the number of cannon fired became an indication of the rank of the official being saluted.
Naval organization.
Ships.
Historically, navy ships were primarily intended for warfare. They were designed to withstand damage and to inflict the same, but only carried munitions and supplies for the voyage (rather than merchant cargo). Often, other ships which were not built specifically for warfare, such as the galleon or the armed merchant ships in World War II, did carry armaments. In more recent times, navy ships have become more specialized and have included supply ships, troop transports, repair ships, oil tankers and other logistics support ships as well as combat ships. So long as they are commissioned, however, they are all "ships"...
Modern navy combat ships are generally divided into seven main categories: aircraft carriers, cruisers, destroyers, frigates, corvettes, submarines, and amphibious assault ships. There are also support and auxiliary ships, including the oiler, minesweeper, patrol boat, hydrographic and oceanographic survey ship and tender. During the age of sail, the ship categories were divided into the ship of the line, frigate, and sloop-of-war.
Naval ship names are typically prefixed by an abbreviation indicating the national navy in which they serve. For a list of the prefixes used with ship names (HMS, USS, LÉ, etc.) see ship prefix.
Today ships are significantly faster than in former times, thanks to much improved propulsion systems. Also, the efficiency of the engines has improved, in terms of fuel, and of how many sailors it takes to operate them. In World War II, ships needed to refuel very often. However, today ships can go on very long journeys without refueling. Also, in World War II, the engine room needed about a dozen sailors to work the many engines, however, today, only about 4–5 are needed (depending on the class of the ship). Today, naval strike groups on longer missions are always followed by a range of support and replenishment ships supplying them with anything from fuel and munitions, to medical treatment and postal services. This allows strike groups and combat ships to remain at sea for several months at a time.
Boats.
The term "boat" refers to small craft limited in their use by size and usually not capable of making lengthy independent voyages at sea. The old navy adage to differentiate between ships and boats is that boats are capable of being carried by ships. (Submarines by this rule are ships rather than boats, but are customarily referred to as boats reflecting their previous smaller size.)
Navies use many types of boat, ranging from 9 ft dinghies to 135 ft landing craft. They are powered by either diesels, out-board gasoline engines, or waterjets. Most boats are built of aluminum, fiberglass, or steel. Rigid-hulled inflatable boats are also used.
Patrol boats are used for patrols of coastal areas, lakes and large rivers.
Landing craft are designed to carry troops, vehicles, or cargo from ship to shore under combat conditions, to unload, to withdraw from the beach, and to return to the ship. They are rugged, with powerful engines, and usually armed. There are many types in today's navies including hovercraft. They will typically have a power-operated bow ramp, a cargo well and after structures that house engine rooms, pilot houses, and stowage compartments. These boats are sometimes carried by larger ships.
Special operations craft are high-speed craft used for insertion and extraction of special forces personnel and some may be transportable (and deployed) by air.
Boats used in non-combat roles include lifeboats, mail boats, line handling boats, buoy boats, aircraft rescue boats, torpedo retrievers, explosive ordnance disposal craft, utility boats, dive boats, targets, and work boats. Boats are also used for survey work, tending divers, and minesweeping operations. Boats for carrying cargo and personnel are sometimes known as launches, gigs, barges or shore party boats.
Units.
Naval forces are typically arranged into units based on the number of ships included, a single ship being the smallest operational unit. Ships may be combined into squadrons or flotillas, which may be formed into fleets. The largest unit size may be the whole Navy or Admiralty.
A task force can be assembled using ships from different fleets for an operational task.
Personnel.
Despite their acceptance in many areas of naval service, women sailors were not permitted to serve on board U.S. submarines until the U.S. Navy lifted the ban in April 2010. The major reasons historically cited by the U.S. Navy were the extended duty tours and close conditions which afford almost no privacy. The United Kingdom's Royal Navy has had similar restrictions. Australia, Canada, Norway, and Spain previously opened submarine service to women sailors.
Ranks.
A navy will typically have two sets of ranks, one for enlisted personnel and one for officers.
Typical ranks for commissioned officers include the following, in ascending order (Commonwealth ranks are listed first on each line; USA ranks are listed second in those instances where they differ from Commonwealth ranks):
"Flag officers" include any rank that includes the word "admiral" (or commodore in services other than the US Navy), and are generally in command of a battle group, strike group or similar flotilla of ships, rather than a single ship or aspect of a ship. However, commodores can also be temporary or honorary positions. For example, during World War II, a Navy captain was assigned duty as a convoy commodore, which meant that he was still a captain, but in charge of all the merchant vessels in the convoy.
The most senior rank employed by a navy will tend to vary depending on the size of the navy and whether it is wartime or peacetime, for example, few people have ever held the rank of Fleet Admiral in the U.S. Navy, the chief of the Royal Australian Navy holds the rank of Vice Admiral, and the chief of the Irish Naval Service holds the rank of Commodore.
Naval infantry.
Naval infantry, commonly known as marines, are a category of infantry that form part of a state’s naval forces and perform roles on land and at sea, including amphibious operations, as well as other, naval roles. They also perform other tasks, including land warfare, separate from naval operations.
During the era of the Roman empire, naval forces included marine legionaries for maritime boarding actions. These were troops primarily trained in land warfare, and did not need to be skilled at handling a ship. Much later during the age of sail, a component of marines served a similar role, being ship-borne soldiers who were used either during boarding actions, as sharp-shooters, or in raids along shorelines.
The Spanish "Infantería de Marina" was formed in 1537, making it the oldest, current marine force in the world. The British, Royal Marines combine being both a ship-based force and also being specially trained in commando-style operations and tactics, operating in some cases separately from the rest of the Royal Navy. The Royal Marines also have their own special forces unit. 
In the majority of countries, the marine force is part of the navy. The United States Marine Corps is a separate armed service within the United States Department of the Navy, with its own leadership structure.
Naval aviation.
In World War I several navies used floatplanes and flying boats - mainly for scouting. By World War II the aircraft carrier could carry bomber aircraft capable of attacking naval and land targets as well as fighter aircraft for defence. Since World War II helicopters have been embarked on smaller ships in roles such as anti-submarine warfare. Some navies have also operated land-based patrol aircraft.
Notes and references.
http://linguistlist.org/issues/26/26-1302.html

</doc>
<doc id="21538" url="http://en.wikipedia.org/wiki?curid=21538" title="Normed vector space">
Normed vector space

In mathematics, with 2- or 3-dimensional vectors with real-valued entries, the idea of the "length" of a vector is intuitive and can easily be extended to any real vector space R"n". The following properties of "vector length" are crucial.
The generalization of these three properties to more abstract vector spaces leads to the notion of norm. A vector space on which a norm is defined is then called a normed vector space.
Normed vector spaces are central to the study of linear algebra and functional analysis.
Definition.
A normed vector space is a pair ("V", ‖·‖ ) where "V" is a vector space and ‖·‖ a norm on "V".
A seminormed vector space is a pair ("V","p") where "V" is a vector space and "p" a seminorm on "V".
We often omit "p" or ‖·‖ and just write "V" for a space if it is clear from the context what (semi) norm we are using.
In a more general sense, a vector norm can be taken to be any real-valued function that satisfies these three properties. The properties 1. and 2. together imply that
A useful variation of the triangle inequality is
This also shows that a vector norm is a continuous function.
Note that property 2 depends on a choice of norm formula_9 on the field of scalars. When the scalar field is formula_10 (or more generally a subset of formula_11), this is usually taken to be the ordinary absolute value, but other choices are possible. For example, for a vector space over formula_12 one could take formula_9 to be the "p"-adic norm, which gives rise to a different class of normed vector spaces.
Topological structure.
If ("V", ‖·‖) is a normed vector space, the norm ‖·‖ induces a metric (a notion of "distance") and therefore a topology on "V". This metric is defined in the natural way: the distance between two vectors u and v is given by ‖u−v‖. This topology is precisely the weakest topology which makes ‖·‖ continuous and which is compatible with the linear structure of "V" in the following sense:
Similarly, for any semi-normed vector space we can define the distance between two vectors u and v as ‖u−v‖. This turns the seminormed space into a pseudometric space (notice this is weaker than a metric) and allows the definition of notions such as continuity and convergence.
To put it more abstractly every semi-normed vector space is a topological vector space and thus carries a topological structure which is induced by the semi-norm.
Of special interest are complete normed spaces called Banach spaces. Every normed vector space "V" sits as a dense subspace inside a Banach space; this Banach space is essentially uniquely defined by "V" and is called the "completion" of "V".
All norms on a finite-dimensional vector space are equivalent from a topological viewpoint as they induce the same topology (although the resulting metric spaces need not be the same). And since any Euclidean space is complete, we can thus conclude that all finite-dimensional normed vector spaces are Banach spaces. A normed vector space "V" is locally compact if and only if the unit ball "B" = {"x" : ‖"x"‖ ≤ 1} is compact, which is the case if and only if "V" is finite-dimensional; this is a consequence of Riesz's lemma. (In fact, a more general result is true: a topological vector space is locally compact if and only if it is finite-dimensional.
The point here is that we don't assume the topology comes from a norm.)
The topology of a seminormed vector space has many nice properties. Given a neighbourhood system formula_14 around 0 we can construct all other neighbourhood systems as
with
Moreover there exists a neighbourhood basis for 0 consisting of absorbing and convex sets. As this property is very useful in functional analysis, generalizations of normed vector spaces with this property are studied under the name locally convex spaces.
Linear maps and dual spaces.
The most important maps between two normed vector spaces are the continuous linear maps. Together with these maps, normed vector spaces form a category.
The norm is a continuous function on its vector space. All linear maps between finite dimensional vector spaces are also continuous.
An "isometry" between two normed vector spaces is a linear map "f" which preserves the norm (meaning ‖"f"(v)‖ = ‖v‖ for all vectors v). Isometries are always continuous and injective. A surjective isometry between the normed vector spaces "V" and "W" is called an "isometric isomorphism", and "V" and "W" are called "isometrically isomorphic". Isometrically isomorphic normed vector spaces are identical for all practical purposes.
When speaking of normed vector spaces, we augment the notion of dual space to take the norm into account. The dual "V" ' of a normed vector space "V" is the space of all "continuous" linear maps from "V" to the base field (the complexes or the reals) — such linear maps are called "functionals". The norm of a functional φ is defined as the supremum of |φ(v)| where v ranges over all unit vectors (i.e. vectors of norm 1) in "V". This turns "V" ' into a normed vector space. An important theorem about continuous linear functionals on normed vector spaces is the Hahn–Banach theorem.
Normed spaces as quotient spaces of seminormed spaces.
The definition of many normed spaces (in particular, Banach spaces) involves a seminorm defined on a vector space and then the normed space is defined as the quotient space by the subspace of elements of seminorm zero. For instance, with the L"p" spaces, the function defined by
is a seminorm on the vector space of all functions on which the Lebesgue integral on the right hand side is defined and finite. However, the seminorm is equal to zero for any function supported on a set of Lebesgue measure zero. These functions form a subspace which we "quotient out", making them equivalent to the zero function.
Finite product spaces.
Given "n" seminormed spaces "X""i" with seminorms "q""i" we can define the product space as
with vector addition defined as
and scalar multiplication defined as
We define a new function "q"
for example as
which is a seminorm on "X". The function "q" is a norm if and only if all "q""i" are norms.
More generally, for each real "p"≥1 we have the seminorm:
For each p this defines the same topological space.
A straightforward argument involving elementary linear algebra shows that the only finite-dimensional seminormed spaces are those arising as the product space of a normed space and a space with trivial seminorm. Consequently, many of the more interesting examples and applications of seminormed spaces occur for infinite-dimensional vector spaces.

</doc>
<doc id="21541" url="http://en.wikipedia.org/wiki?curid=21541" title="Nicene Creed">
Nicene Creed

The Nicene Creed (Greek: Σύμβολον τῆς Νίκαιας, Latin: Symbolum Nicaenum) is a profession of faith widely used in Christian liturgy.
It is called Nicene because originally adopted in the city of Nicaea (present day Iznik, Turkey) by the First Council of Nicaea in 325. In 381, it was amended at the First Council of Constantinople, and the amended form is referred to as the Nicene or the Niceno-Constantinopolitan Creed.
The churches of Oriental Orthodoxy use this profession of faith with the verbs in the original plural ("we believe") form. The Eastern Orthodox Church and the Roman Catholic Church use it with the verbs of believing changed to the singular ("I believe") form. The Anglican Communion and many Protestant denominations also use it, sometimes with the verbs of believing in the plural form but generally in the singular.
The Apostles' Creed is also used in the Latin West, but not in the Eastern liturgies. On Sundays and some other days, one or other of these two creeds is recited in the Roman Rite Mass after the homily. The Nicene Creed is also part of the profession of faith required of those undertaking important functions within the Catholic Church. 
In the Byzantine Rite, the Nicene Creed is sung or recited at the Divine Liturgy, immediately preceding the Anaphora (Eucharistic Prayer), and is also recited daily at compline.
Nomenclature.
There are several designations for the two forms of the Nicene creed, some with overlapping meanings:
In musical settings, particularly when sung in Latin, this Creed is usually referred to by its first word, "Credo".
History.
The purpose of a creed is to provide a doctrinal statement of correct belief, or Orthodoxy. The creeds of Christianity have been drawn up at times of conflict about doctrine: acceptance or rejection of a creed served to distinguish believers and deniers of a particular doctrine or set of doctrines. For that reason a creed was called in Greek a σύμβολον (Eng. "symbolon"), a word that meant half of a broken object which, when placed together with the other half, verified the bearer's identity. The Greek word passed through Latin "symbolum" into English "symbol", which only later took on the meaning of an outward sign of something.
The Nicene Creed was adopted in the face of the Arian controversy. Arius, a Libyan presbyter in Alexandria, had declared that although the Son was divine, he was a created being and therefore not co-essential with the Father, and "there was when he was not," This made Jesus less than the Father, which posed soteriological challenges for the nascent doctrine of the Trinity. Arius's teaching provoked a serious crisis.
The Nicene Creed of 325 explicitly affirms the co-essential divinity of the Son, applying to him the term "consubstantial". The 381 version speaks of the Holy Spirit as worshipped and glorified with the Father and the Son. The Athanasian Creed (not used in Eastern Christianity) describes in much greater detail the relationship between Father, Son and Holy Spirit. The Apostles' Creed makes no explicit statements about the divinity of the Son and the Holy Spirit, but, in the view of many who use it, the doctrine is implicit in it.
The original Nicene Creed of 325.
The original Nicene Creed was first adopted in 325 at the First Council of Nicaea. At that time, the text ended after the words "We believe in the Holy Spirit", after which an anathema was added. (For other differences, see Comparison between Creed of 325 and Creed of 381, below.)
The Coptic Church has the tradition that the original creed was authored by Pope Athanasius I of Alexandria. F.J.A. Hort and Adolf Harnack argued that the Nicene creed was the local creed of Caesarea (an important center of Early Christianity) brought to the council by Eusebius of Caesarea. J.N.D. Kelly sees as its basis a baptismal creed of the Syro-Phoenician family, related to (but not dependent on) the creed cited by Cyril of Jerusalem and to the creed of Eusebius.
Soon after the Council of Nicaea, new formulae of faith were composed, most of them variations of the Nicene Symbol, to counter new phases of Arianism. The "Catholic Encyclopedia" identifies at least four before the Council ofSerdika 341), where a new form was presented and inserted in the Acts of the Council, though it was not agreed on.
The Niceno–Constantinopolitan Creed.
What is known as the "Niceno-Constantinopolitan Creed" or the "Nicene-Constantinopolitan Creed" received this name because of a belief that it was adopted at the Second Ecumenical Council held in Constantinople in 381 as a modification of the original Nicene Creed of 325. In that light, it also came to be very commonly known simply as the "Nicene Creed". It is the only authoritative "ecumenical" statement of the Christian faith accepted by the Roman Catholic, Eastern Orthodox, Oriental Orthodox, Anglican, and the major Protestant denominations. (The Apostles' and Athanasian creeds are not as widely accepted.)
It differs in a number of respects, both by addition and omission, from the creed adopted at the First Council of Nicaea. The most notable difference is the additional section "And [we believe] in the Holy Spirit, the Lord and Giver-of-Life, who proceedeth from the Father, who with the Father and the Son together is worshipped and glorified, who spake by the prophets. And [we believe] in one, holy, Universal and Apostolic Church. We acknowledge one Baptism for the remission of sins, [and] we look for the resurrection of the dead and the life of the world to come. Amen."
Since the end of the 19th century, scholars have questioned the traditional explanation of the origin of this creed, which has been passed down in the name of the council, whose official acts have been lost over time. A local council of Constantinople in 382 and the third ecumenical council (Ephesus, 431) made no mention of it, with the latter affirming the 325 creed of Nicaea as a valid statement of the faith and using it to denounce Nestorianism. Though some scholarship claims that hints of the later creed's existence are discernible in some writings, no extant document gives its text or makes explicit mention of it earlier than the fourth ecumenical council at Chalcedon in 451. Many of the bishops of the 451 council themselves had never heard of it and initially greeted it skeptically, but it was then produced from the episcopal archives of Constantinople, and the council accepted it "not as supplying any omission but as an authentic interpretation of the faith of Nicaea". In spite of the questions raised, it is considered most likely that this creed was in fact adopted at the 381 second ecumenical council.
On the basis of evidence both internal and external to the text, it has been argued that this creed originated not as an editing of the original Creed proposed at Nicaea in 325, but as an independent creed (probably an older baptismal creed) modified to make it more like the Nicene Creed. Some scholars have argued that the creed may have been presented at Chalcedon as "a precedent for drawing up new creeds and definitions to supplement the Creed of Nicaea, as a way of getting round the ban on new creeds in Canon 7 of Ephesus". It is generally agreed that the Niceno-Constantinopolitan Creed is not simply an expansion of the Creed of Nicaea, and was probably based on another traditional creed independent of the one from Nicaea.
The third Ecumenical Council (Council of Ephesus of 431) reaffirmed the original 325 version of the Nicene Creed and declared that "it is unlawful for any man to bring forward, or to write, or to compose a different (ἑτέραν – more accurately translated as used by the Council to mean “different,” “contradictory,” and not “another”) faith as a rival to that established by the holy Fathers assembled with the Holy Spirit in Nicaea" (i.e. the 325 creed) This statement has been interpreted as a prohibition against changing this creed or composing others, but not all accept this interpretation. This question is connected with the controversy whether a creed proclaimed by an Ecumenical Council is definitive in excluding not only excisions from its text but also additions to it.
In one respect, the Eastern Orthodox Church's received text of the Niceno-Constantinopolitan Creed differs from the earliest text, which is included in the acts of the Council of Chalcedon of 451: The Eastern Orthodox Church uses the singular forms of verbs such as "I believe", in place of the plural form ("we believe") used by the council. Byzantine Rite Eastern Catholic Churches use exactly the same form of the Creed, since the Catholic Church teaches that it is wrong to add "and the Son" to the Greek verb "ἐκπορευόμενον", though correct to add it to the Latin "qui procedit", which does not have precisely the same meaning. The form generally used in Western churches does add "and the Son" and also the phrase "God from God", which is found in the original 325 Creed.
Comparison between Creed of 325 and Creed of 381.
The following table, which indicates by [square brackets] the portions of the 325 text that were omitted or moved in 381, and uses "italics" to indicate what phrases, absent in the 325 text, were added in 381, juxtaposes the earlier (325 AD) and later (381 AD) forms of this Creed in the English translation given in Schaff's work, "Creeds of Christendom".
The texts in Greek, as given on the Web site , can be presented in a similar way, as follows:
Filioque controversy.
In the late 6th century, some Latin-speaking churches added the words "and from the Son" ("Filioque") to the description of the procession of the Holy Spirit, in what many Eastern Orthodox Christians have at a later stage argued is a violation of of the Third Ecumenical Council, since the words were not included in the text by either the Council of Nicaea or that of Constantinople.
The Vatican stated in 1995 that, while the words καὶ τοῦ Υἱοῦ ("and the Son") would indeed be heretical if used with the Greek verb ἐκπορεύομαι — which is one of the terms used by St. Gregoryof Nazianuzus and the one adopted by the Council of Constantinople — the word "Filioque" is not heretical when associated with the Latin verb "procedo" and the related word "processio." Whereas the verb ἐκπόρευμαι (from ἐκ, "out of" and πορεύομαι "to come or go") in Gregory and other Fathers necessarily means "to originate from a cause or principle," the Latin term "procedo" (from "pro", "forward;" and "cedo", "to go") has no such connotation and simply denotes the communication of the Divine Essence or Substance. In this sense, "processio" is similar in meaning to the Greek term προϊέναι, used by the Fathers from Alexandria (especially Cyril of Alexandria) as well as others. Partly due to the influence of the Latin translations of the New Testament (especially of John 15:26), the term ἐκπορευόμενον (the present participle of ἐκπορεύομαι) in the creed was translated into Latin as "procedentem". In time, the Latin version of the Creed came to be interpreted in the West in the light of the Western concept of "processio", which required the affirmation of the "Filioque" to avoid the heresy of Arianism.
Views on the importance of this creed.
The view that the Nicene Creed can serve as a touchstone of true Christian faith is reflected in the name "symbol of faith", which was given to it in Greek and Latin, when in those languages the word "symbol" meant a "token for identification (by comparison with a counterpart)", and which continues in use even in languages in which "symbol" no longer has that meaning.
In the Roman Rite Mass, the Latin text of the Niceno-Constantinopolitan Creed, with "Deum de Deo" (God from God) and "Filioque" (and from the Son), phrases absent in the original text, was previously the only form used for the "profession of faith". The Roman Missal now refers to it jointly with the Apostles' Creed as "the Symbol or Profession of Faith or Creed", describing the second as "the baptismal Symbol of the Roman Church, known as the Apostles' Creed".
The liturgies of the ancient Churches of Eastern Christianity (Eastern Orthodox Church, Oriental Orthodoxy, Assyrian Church of the East and the Eastern Catholic Churches), use the Niceno-Constantinopolitan Creed, never the Western Apostles' Creed.
While in certain places where the Byzantine Rite is used, the choir or congregation sings the Creed at the Divine Liturgy, in many places the Creed is typically recited by the cantor, who in this capacity represents the whole congregation although many, and sometimes all, members of the congregation may join in rhythmic recitation. Where the latter is the practice, it is customary to invite, as a token of honor, any prominent lay member of the congregation who happens to be present, "e.g.", royalty, a visiting dignitary, the Mayor, etc., to recite the Creed in lieu of the cantor. This practice stems from the tradition that the prerogative to recite the Creed belonged to the Emperor, speaking for his populace.
Some evangelical and other Christians consider the Nicene Creed helpful and to a certain extent authoritative, but not infallibly so in view of their belief that only Scripture is truly authoritative. Other groups, such as the Church of the New Jerusalem, The Church of Jesus Christ of Latter-day Saints, and the Jehovah's Witnesses explicitly reject some of the statements in the Creed.
Ancient liturgical versions.
This section is not meant to collect the texts of all liturgical versions of the Nicene Creed, and provides only three, the Greek, the Latin, and the Armenian, of special interest. Others are mentioned separately, but without the texts. All ancient liturgical versions, even the Greek, differ at least to some small extent from the text adopted by the First Councils of Nicaea and Constantinople. The Creed was originally written in Greek, owing to the location of the two councils.
But though the councils' texts have "Πιστεύομεν ... ὁμολογοῦμεν ... προσδοκοῦμεν" ("we" believe ... confess ... await), the Creed that the Churches of Byzantine tradition use in their liturgy has "Πιστεύω ... ὁμολογῶ ... προσδοκῶ" ("I" believe ... confess ... await), accentuating the personal nature of recitation of the Creed. The Latin text, as well as using the singular, has two additions: "Deum de Deo" (God from God) and "Filioque" (and from the Son). The Armenian text has many more additions, and is included as showing how that ancient church has chosen to recite the Creed with these numerous elaborations of its contents.
An English translation of the Armenian text is added; English translations of the Greek and Latin liturgical texts are given at English versions of the Nicene Creed in current use.
Latin liturgical version.
The Latin text adds "Deum de Deo" and "Filioque" to the Greek. On the latter see The Filioque Controversy above. Inevitably also, the overtones of the terms used, such as "παντοκράτορα" (pantokratora) and "omnipotentem" differ ("pantokratora" meaning Ruler of all; "omnipotentem" meaning omnipotent, Almighty). The implications of this for the interpretation of "ἐκπορευόμενον" and "qui ... procedit" was the object of the study "The Greek and the Latin Traditions regarding the Procession of the Holy Spirit" published by the Pontifical Council for Promoting Christian Unity in 1996.
Again, the terms "ὁμοούσιον" and "consubstantialem", translated as "of one being" or "consubstantial", have different overtones, being based respectively on Greek οὐσία (stable being, immutable reality, substance, essence, true nature), and Latin "substantia" (that of which a thing consists, the being, essence, contents, material, substance).
"Credo", which in classical Latin is used with the accusative case of the thing held to be true (and with the dative of the person to whom credence is given), is here used three times with the preposition "in", a literal translation of the Greek "εἰς" (in unum Deum ..., in unum Dominum ..., in Spiritum Sanctum ...), and once in the classical preposition-less construction (unam, sanctam, catholicam et apostolicam Ecclesiam).
Armenian liturgical text.
Հաւատամք ի մի Աստուած` ի Հայրն ամենակալ, յարարիչն երկնի եւ երկրի, երեւելեաց եւ աներեւութից: Եւ ի մի Տէր Յիսուս Քրիստոս յՈրդին Աստուծոյ. ծնեալն յԱստուծոյ Հօրէ` միածին, այսինքն յէութենէ Հօր: Աստուած յԱստուծոյ, լոյս ի լուսոյ, Աստուած ճշմարիտ յԱստուծոյ ճշմարտէ` ծնունդ եւ ո°չ արարած: Նոյն ինքն ի բնութենէ Հօր. որով ամենայն ինչ եղեւ յերկինս եւ ի վերայ երկրի, երեւելիք եւ աներեւոյթք: Որ յաղագս մեր մարդկան եւ վասն մերոյ փրկութեան իջեալ յերկնից` մարմնացաւ, մարդացաւ, ծնաւ կատարելապէս ի Մարիամայ սրբոյ կուսէն Հոգւովն սրբով. որով էառ զմարմին, զհոգի եւ զմիտ, եւ զամենայն որ ինչ է ի մարդ, ճշմարտապէս եւ ո°չ կարծեօք: Չարչարեալ, խաչեալ, թաղեալ յերրորդ աւուր յարուցեալ, ելեալ ի յերկինս նովին մարմնով` նստաւ ընդ աջմէ Հօր: Գալոց է նովին մարմնովն եւ փառօք Հօր ի դատել զկենդանիս եւ զմեռեալս, որոյ թագաւորութեանն ո°չ գոյ վախճան:
Հաւատամք եւ ի սուրբ Հոգին, յանեղն եւ ի կատարեալն. որ խօսեցաւ յօրէնս եւ ի մարգարէս եւ յաւետարանս. որ էջն ի Յորդանան, քարոզեաց զառաքեալսն, եւ բնակեցաւ ի սուրբսն:
Հաւատամք եւ ի մի միայն ընդհանրական եւ առաքելական Սուրբ Եկեղեցի. ի մի մկրտութիւն, յապաշխարհութիւն, ի քաւութիւն եւ ի թողութիւն մեղաց. ի յարութիւնն մեռելոց, ի դատաստանն յաւիտենից հոգւոց եւ մարմնոց` յարքայութիւնն երկնից, եւ ի կեանսն յաւիտենականս:
English translation of the Armenian version
Other ancient liturgical versions.
The version in the Church Slavonic language, used by several Eastern Orthodox Churches is practically identical with the Greek liturgical version.
This version is used also by some Byzantine Rite Eastern Catholic Churches. Although the Union of Brest excluded addition of the "Filioque", this was sometimes added by Ruthenian Catholics, whose liturgical books now give the phrase in brackets, and by Ukrainian Catholics. Writing in 1971, the Ruthenian Scholar Fr. Casimir Kucharek noted, "In Eastern Catholic Churches, the "Filioque" may be omitted except when scandal would ensue. Most of the Eastern Catholic Rites use it." However, in the decades that followed 1971 it has come to be used more rarely.
The versions used by Oriental Orthodoxy differ from the Greek liturgical version in having "We believe", as in the original text, instead of "I believe".
The Church of the East, which is in communion neither with the Eastern Orthodox Church nor with Oriental Orthodoxy also uses "We believe".
English translations.
The version found in the 1662 "Book of Common Prayer" is still commonly used by some English speakers, but more modern translations are now more common.
International Consultation on English Texts.
The International Consultation on English Texts published an English translation of the Nicene Creed, first in 1970 and then in successive revisions in 1971 and 1975. These texts were adopted by several churches.
The Roman Catholic Church in the United States, which adopted the 1971 version in 1973, and the Catholic Church in other English-speaking countries, which in 1975 adopted the version published in that year, continued to use them until 2011 upon the introduction of the "Roman Missal third edition".
The 1975 version was included in the 1979 Episcopal Church (United States) "Book of Common Prayer", though with one variation: in the line "For us men and for our salvation", it omitted the word "men".
Other English translations.
For the text of the Nicene Creed published in 1988 by the English Language Liturgical Consultation, the successor body of the International Consultation on English Texts, see . For the text as recited in the Roman Rite of the Catholic Church, see the of the Australian National Catholic Education Commission or , section 29.

</doc>
<doc id="21544" url="http://en.wikipedia.org/wiki?curid=21544" title="Nuclear fusion">
Nuclear fusion

In nuclear physics, nuclear fusion is a nuclear reaction in which two or more atomic nuclei come very close and then collide at a very high speed and join to form a new type of atomic nucleus. During this process, matter is not conserved because some of the matter of the fusing nuclei is converted to photons (energy). Fusion is the process that powers active or "main sequence" stars.
The fusion of two nuclei with lower masses than iron (which, along with nickel, has the largest binding energy per nucleon) generally releases energy, while the fusion of nuclei heavier than iron "absorbs" energy. The opposite is true for the reverse process, nuclear fission. This means that fusion generally occurs for lighter elements only, and likewise, that fission normally occurs only for heavier elements. There are extreme astrophysical events that can lead to short periods of fusion with heavier nuclei. This is the process that gives rise to nucleosynthesis, the creation of the heavy elements during events such as supernovae.
Following the discovery of quantum tunneling by Friedrich Hund, in 1929 Robert Atkinson and Fritz Houtermans used the measured masses of light elements to predict that large amounts of energy could be released by fusing small nuclei. Building upon the nuclear transmutation experiments by Ernest Rutherford, carried out several years earlier, the laboratory fusion of hydrogen isotopes was first accomplished by Mark Oliphant in 1932. During the remainder of that decade the steps of the main cycle of nuclear fusion in stars were worked out by Hans Bethe. Research into fusion for military purposes began in the early 1940s as part of the Manhattan Project. Fusion was accomplished in 1951 with the Greenhouse Item nuclear test. Nuclear fusion on a large scale in an explosion was first carried out on November 1, 1952, in the Ivy Mike hydrogen bomb test.
Research into developing controlled thermonuclear fusion for civil purposes also began in earnest in the 1950s, and it continues to this day. The present article is about the theory of fusion. For details of the quest for controlled fusion and its history, see the article Fusion power.
Overview.
The origin of the energy released in fusion of light elements is due to interplay of two opposing forces, the nuclear force which combines together protons and neutrons, and the Coulomb force which causes protons to repel each other. The protons are positively charged and repel each other but they nonetheless stick together, demonstrating the existence of another force referred to as nuclear attraction. This force, called the strong nuclear force, overcomes electric repulsion in a very close range. The effect of this force is not observed outside the nucleus, hence the force has a strong dependence on distance, making it a short-range force. The same force also pulls the nucleons together, or neutrons and protons together. Because the nuclear force is stronger than the Coulomb force for atomic nuclei smaller than iron and nickel, building up these nuclei from lighter nuclei by fusion releases the extra energy from the net attraction of these particles. For larger nuclei, however, no energy is released, since the nuclear force is short-range and cannot continue to act across still larger atomic nuclei. Thus, energy is no longer released when such nuclei are made by fusion; instead, energy is absorbed in such processes.
Fusion reactions of light elements power the stars and produce virtually all elements in a process called nucleosynthesis. The fusion of lighter elements in stars releases energy (and the mass that always accompanies it). For example, in the fusion of two hydrogen nuclei to form helium, 0.7% of the mass is carried away from the system in the form of kinetic energy or other forms of energy (such as electromagnetic radiation).
Research into controlled fusion, with the aim of producing fusion power for the production of electricity, has been conducted for over 60 years. It has been accompanied by extreme scientific and technological difficulties, but has resulted in progress. At present, controlled fusion reactions have been unable to produce break-even (self-sustaining) controlled fusion reactions. Workable designs for a reactor that theoretically will deliver ten times more fusion energy than the amount needed to heat up plasma to required temperatures are in development (see ITER). The ITER facility is expected to finish its construction phase in 2019. It will start commissioning the reactor that same year and initiate plasma experiments in 2020, but is not expected to begin full deuterium-tritium fusion until 2027.
It takes considerable energy to force nuclei to fuse, even those of the lightest element, hydrogen. This is because all nuclei have a positive charge due to their protons, and as like charges repel, nuclei strongly resist being put close together. Accelerated to high speeds, they can overcome this electrostatic repulsion and be forced close enough for the attractive nuclear force to be sufficiently strong to achieve fusion. The fusion of lighter nuclei, which creates a heavier nucleus and often a free neutron or proton, generally releases more energy than it takes to force the nuclei together; this is an exothermic process that can produce self-sustaining reactions. The US National Ignition Facility, which uses laser-driven inertial confinement fusion, is thought to be capable of break-even fusion.
The first large-scale laser target experiments were performed in June 2009 and ignition experiments began in early 2011.
Energy released in most nuclear reactions is much larger than in chemical reactions, because the binding energy that holds a nucleus together is far greater than the energy that holds electrons to a nucleus. For example, the ionization energy gained by adding an electron to a hydrogen nucleus is —less than one-millionth of the released in the deuterium–tritium (D–T) reaction shown in the diagram to the right (one gram of matter would release of energy). Fusion reactions have an energy density many times greater than nuclear fission; the reactions produce far greater energy per unit of mass even though "individual" fission reactions are generally much more energetic than "individual" fusion ones, which are themselves millions of times more energetic than chemical reactions. Only direct conversion of mass into energy, such as that caused by the annihilatory collision of matter and antimatter, is more energetic per unit of mass than nuclear fusion.
Requirements.
Details and supporting references on the material in this section can be found in textbooks on nuclear physics or nuclear fusion.
A substantial energy barrier of electrostatic forces must be overcome before fusion can occur. At large distances, two naked nuclei repel one another because of the repulsive electrostatic force between their positively charged protons. If two nuclei can be brought close enough together, however, the electrostatic repulsion can be overcome by the attractive nuclear force, which is stronger at close distances.
When a nucleon such as a proton or neutron is added to a nucleus, the nuclear force attracts it to other nucleons, but primarily to its immediate neighbours due to the short range of the force. The nucleons in the interior of a nucleus have more neighboring nucleons than those on the surface. Since smaller nuclei have a larger surface area-to-volume ratio, the binding energy per nucleon due to the nuclear force generally increases with the size of the nucleus but approaches a limiting value corresponding to that of a nucleus with a diameter of about four nucleons. It is important to keep in mind that the above picture is a toy model because nucleons are quantum objects, and so, for example, since two neutrons in a nucleus are identical to each other, distinguishing one from the other, such as which one is in the interior and which is on the surface, is in fact meaningless, and the inclusion of quantum mechanics is necessary for proper calculations.
The electrostatic force, on the other hand, is an inverse-square force, so a proton added to a nucleus will feel an electrostatic repulsion from "all" the other protons in the nucleus. The electrostatic energy per nucleon due to the electrostatic force thus increases without limit as nuclei get larger.
The net result of these opposing forces is that the binding energy per nucleon generally increases with increasing size, up to the elements iron and nickel, and then decreases for heavier nuclei. Eventually, the binding energy becomes negative and very heavy nuclei (all with more than 208 nucleons, corresponding to a diameter of about 6 nucleons) are not stable. The four most tightly bound nuclei, in decreasing order of binding energy per nucleon, are 62Ni, 58Fe, 56Fe, and 60Ni. Even though the nickel isotope, 62Ni, is more stable, the iron isotope 56Fe is an order of magnitude more common. This is due to the fact that there is no easy way for stars to create 62Ni through the alpha process.
An exception to this general trend is the helium-4 nucleus, whose binding energy is higher than that of lithium, the next heaviest element. This is because protons and neutrons are fermions, which according to the Pauli exclusion principle cannot exist in the same nucleus in exactly the same state. Each proton or neutron energy state in a nucleus can accommodate both a spin up particle and a spin down particle. Helium-4 has an anomalously large binding energy because its nucleus consists of two protons and two neutrons, so all four of its nucleons can be in the ground state. Any additional nucleons would have to go into higher energy states. Indeed, the helium-4 nucleus is so tightly bound that it is commonly treated as a single particle in nuclear physics, namely, the alpha particle.
The situation is similar if two nuclei are brought together. As they approach each other, all the protons in one nucleus repel all the protons in the other. Not until the two nuclei actually come in contact can the strong nuclear force take over. Consequently, even when the final energy state is lower, there is a large energy barrier that must first be overcome. It is called the Coulomb barrier.
The Coulomb barrier is smallest for isotopes of hydrogen, as their nuclei contain only a single positive charge. A diproton is not stable, so neutrons must also be involved, ideally in such a way that a helium nucleus, with its extremely tight binding, is one of the products.
Using deuterium-tritium fuel, the resulting energy barrier is about 0.1 MeV. In comparison, the energy needed to remove an electron from hydrogen is 13.6 eV, about 7500 times less energy. The (intermediate) result of the fusion is an unstable 5He nucleus, which immediately ejects a neutron with 14.1 MeV. The recoil energy of the remaining 4He nucleus is 3.5 MeV, so the total energy liberated is 17.6 MeV. This is many times more than what was needed to overcome the energy barrier.
The reaction cross section σ is a measure of the probability of a fusion reaction as a function of the relative velocity of the two reactant nuclei. If the reactants have a distribution of velocities, e.g. a thermal distribution, then it is useful to perform an average over the distributions of the product of cross section and velocity. This average is called the 'reactivity', denoted <σv>. The reaction rate (fusions per volume per time) is <σv> times the product of the reactant number densities:
If a species of nuclei is reacting with itself, such as the DD reaction, then the product formula_2 must be replaced by formula_3.
formula_4 increases from virtually zero at room temperatures up to meaningful magnitudes at temperatures of 10–100 keV. At these temperatures, well above typical ionization energies (13.6 eV in the hydrogen case), the fusion reactants exist in a plasma state.
The significance of formula_4 as a function of temperature in a device with a particular energy confinement time is found by considering the Lawson criterion. This is an extremely challenging barrier to overcome on Earth, which explains why fusion research has taken many years to reach the current high state of technical prowess.
Methods for achieving fusion.
Thermonuclear fusion.
If the matter is sufficiently heated (hence being plasma), the fusion reaction may occur due to collisions with extreme thermal kinetic energies of the particles. In the form of thermonuclear weapons, thermonuclear fusion is the only fusion technique so far to yield undeniably large amounts of useful fusion energy. Usable amounts of thermonuclear fusion energy released in a controlled manner have yet to be achieved. In nature, this is what produces energy in stars through stellar nucleosynthesis.
Inertial confinement fusion.
Inertial confinement fusion (ICF) is a type of fusion energy research that attempts to initiate nuclear fusion reactions by heating and compressing a fuel target, typically in the form of a pellet that most often contains a mixture of deuterium and tritium.
Inertial electrostatic confinement.
Inertial electrostatic confinement is a set of devices that use an electric field to heat ions to fusion conditions. The most well known is the fusor. Starting in 1999, a number of amateurs have been able to do amateur fusion using these homemade devices. Other IEC devices include: the Polywell, MIX POPS and Marble concepts.
Beam-beam or beam-target fusion.
If the energy to initiate the reaction comes from accelerating one of the nuclei, the process is called "beam-target" fusion; if both nuclei are accelerated, it is "beam-beam" fusion.
Accelerator-based light-ion fusion is a technique using particle accelerators to achieve particle kinetic energies sufficient to induce light-ion fusion reactions. Accelerating light ions is relatively easy, and can be done in an efficient manner—all it takes is a vacuum tube, a pair of electrodes, and a high-voltage transformer; fusion can be observed with as little as 10 kV between electrodes. The key problem with accelerator-based fusion (and with cold targets in general) is that fusion cross sections are many orders of magnitude lower than Coulomb interaction cross sections. Therefore the vast majority of ions end up expending their energy on bremsstrahlung and ionization of atoms of the target. Devices referred to as sealed-tube neutron generators are particularly relevant to this discussion. These small devices are miniature particle accelerators filled with deuterium and tritium gas in an arrangement that allows ions of these nuclei to be accelerated against hydride targets, also containing deuterium and tritium, where fusion takes place. Hundreds of neutron generators are produced annually for use in the petroleum industry where they are used in measurement equipment for locating and mapping oil reserves.
Muon-catalyzed fusion.
Muon-catalyzed fusion is a well-established and reproducible fusion process that occurs at ordinary temperatures. It was studied in detail by Steven Jones in the early 1980s. Net energy production from this reaction cannot occur because of the high energy required to create muons, their short 2.2 µs half-life, and the high chance that a muon will bind to the new alpha particle and thus stop catalyzing fusion.
Other principles.
Some other confinement principles have been investigated.
Antimatter-initialized fusion uses small amounts of antimatter to trigger a tiny fusion explosion. This has been studied primarily in the context of making nuclear pulse propulsion, and pure fusion bombs feasible. This is not near becoming a practical power source, due to the cost of manufacturing antimatter alone.
Pyroelectric fusion was reported in April 2005 by a team at UCLA. The scientists used a pyroelectric crystal heated from −34 to 7 °C (−29 to 45 °F), combined with a tungsten needle to produce an electric field of about 25 gigavolts per meter to ionize and accelerate deuterium nuclei into an erbium deuteride target. At the estimated energy levels, the D-D fusion reaction may occur, producing helium-3 and a 2.45 MeV neutron. Although it makes a useful neutron generator, the apparatus is not intended for power generation since it requires far more energy than it produces.
Hybrid nuclear fusion-fission (hybrid nuclear power) is a proposed means of generating power by use of a combination of nuclear fusion and fission processes. The concept dates to the 1950s, and was briefly advocated by Hans Bethe during the 1970s, but largely remained unexplored until a revival of interest in 2009, due to the delays in the realization of pure fusion.
Project PACER, carried out at Los Alamos National Laboratory (LANL) in the mid-1970s, explored the possibility of a fusion power system that would involve exploding small hydrogen bombs (fusion bombs) inside an underground cavity. As an energy source, the system is the only fusion power system that could be demonstrated to work using existing technology. However it would also require a large, continuous supply of nuclear bombs, making the economics of such a system rather questionable.
Important reactions.
Astrophysical reaction chains.
The most important fusion process in nature is the one that powers stars. The net result is the fusion of four protons into one alpha particle, with the release of two positrons, two neutrinos (which changes two of the protons into neutrons), and energy, but several individual reactions are involved, depending on the mass of the star. For stars the size of the sun or smaller, the proton-proton chain dominates. In heavier stars, the CNO cycle is more important. Both types of processes are responsible for the creation of new elements as part of stellar nucleosynthesis.
At the temperatures and densities in stellar cores the rates of fusion reactions are notoriously slow. For example, at solar core temperature ("T" ≈ 15 MK) and density (160 g/cm3), the energy release rate is only 276 μW/cm3—about a quarter of the volumetric rate at which a resting human body generates heat. Thus, reproduction of stellar core conditions in a lab for nuclear fusion power production is completely impractical. Because nuclear reaction rates strongly depend on temperature (exp(−"E"/"kT")), achieving reasonable power levels in terrestrial fusion reactors requires 10–100 times higher temperatures (compared to stellar interiors): "T" ≈ 0.1–1.0 GK.
Criteria and candidates for terrestrial reactions.
In artificial fusion, the primary fuel is not constrained to be protons and higher temperatures can be used, so reactions with larger cross-sections are chosen. Another concern is the production of neutrons, which activate the reactor structure radiologically, but also have the advantages of allowing volumetric extraction of the fusion energy and tritium breeding. Reactions that release no neutrons are referred to as "aneutronic".
To be a useful energy source, a fusion reaction must satisfy several criteria. It must:
Few reactions meet these criteria. The following are those with the largest cross sections:
For reactions with two products, the energy is divided between them in inverse proportion to their masses, as shown. In most reactions with three products, the distribution of energy varies. For reactions that can result in more than one set of products, the branching ratios are given.
Some reaction candidates can be eliminated at once. The D-6Li reaction has no advantage compared to p+-115B because it is roughly as difficult to burn but produces substantially more neutrons through 21D-21D side reactions. There is also a p+-73Li reaction, but the cross section is far too low, except possibly when "T"i > 1 MeV, but at such high temperatures an endothermic, direct neutron-producing reaction also becomes very significant. Finally there is also a p+-94Be reaction, which is not only difficult to burn, but 94Be can be easily induced to split into two alpha particles and a neutron.
In addition to the fusion reactions, the following reactions with neutrons are important in order to "breed" tritium in "dry" fusion bombs and some proposed fusion reactors:
The latter of the two equations was unknown when the U.S. conducted the Castle Bravo fusion bomb test in 1954. Being just the second fusion bomb ever tested (and the first to use lithium), the designers of the Castle Bravo "Shrimp" had understood the usefulness of Lithium-6 in tritium production, but had failed to recognize that Lithium-7 fission would greatly increase the yield of the bomb. While Li-7 has a small neutron cross-section for low neutron energies, it has a higher cross section above 5 MeV. Li-7 also undergoes a chain reaction due to its release of a neutron after fissioning. The 15 Mt yield was 150% greater than the predicted 6 Mt and caused casualties from the fallout generated.
To evaluate the usefulness of these reactions, in addition to the reactants, the products, and the energy released, one needs to know something about the cross section. Any given fusion device has a maximum plasma pressure it can sustain, and an economical device would always operate near this maximum. Given this pressure, the largest fusion output is obtained when the temperature is chosen so that <σv>/T2 is a maximum. This is also the temperature at which the value of the triple product "nT"τ required for ignition is a minimum, since that required value is inversely proportional to <σv>/T2 (see Lawson criterion). (A plasma is "ignited" if the fusion reactions produce enough power to maintain the temperature without external heating.) This optimum temperature and the value of <σv>/T2 at that temperature is given for a few of these reactions in the following table.
Note that many of the reactions form chains. For instance, a reactor fueled with 31T and 32He creates some 21D, which is then possible to use in the 21D-32He reaction if the energies are "right". An elegant idea is to combine the reactions (8) and (9). The 32He from reaction (8) can react with 63Li in reaction (9) before completely thermalizing. This produces an energetic proton, which in turn undergoes reaction (8) before thermalizing. Detailed analysis shows that this idea would not work well, but it is a good example of a case where the usual assumption of a Maxwellian plasma is not appropriate.
Neutronicity, confinement requirement, and power density.
Any of the reactions above can in principle be the basis of fusion power production. In addition to the temperature and cross section discussed above, we must consider the total energy of the fusion products "E"fus, the energy of the charged fusion products "E"ch, and the atomic number "Z" of the non-hydrogenic reactant.
Specification of the 21D-21D reaction entails some difficulties, though. To begin with, one must average over the two branches (2i) and (2ii). More difficult is to decide how to treat the 31T and 32He products. 31T burns so well in a deuterium plasma that it is almost impossible to extract from the plasma. The 21D-32He reaction is optimized at a much higher temperature, so the burnup at the optimum 21D-21D temperature may be low, so it seems reasonable to assume the 31T but not the 32He gets burned up and adds its energy to the net reaction. Thus the total reaction would be the sum of (2i), (2ii), and (1):
We count the 21D-21D fusion energy "per D-D reaction" (not per pair of deuterium atoms) as "E"fus = (4.03 MeV + 17.6 MeV)×50% + (3.27 MeV)×50% = 12.5 MeV and the energy in charged particles as "E"ch = (4.03 MeV + 3.5 MeV)×50% + (0.82 MeV)×50% = 4.2 MeV. (Note: if the tritium ion reacts with a deuteron while it still has a large kinetic energy, then the kinetic energy of the helium-4 produced may be quite different from 3.5 MeV, so this calculation of energy in charged particles is only approximate.)
Another unique aspect of the 21D-21D reaction is that there is only one reactant, which must be taken into account when calculating the reaction rate.
With this choice, we tabulate parameters for four of the most important reactions
The last column is the neutronicity of the reaction, the fraction of the fusion energy released as neutrons. This is an important indicator of the magnitude of the problems associated with neutrons like radiation damage, biological shielding, remote handling, and safety. For the first two reactions it is calculated as ("E"fus-"E"ch)/"E"fus. For the last two reactions, where this calculation would give zero, the values quoted are rough estimates based on side reactions that produce neutrons in a plasma in thermal equilibrium.
Of course, the reactants should also be mixed in the optimal proportions. This is the case when each reactant ion plus its associated electrons accounts for half the pressure. Assuming that the total pressure is fixed, this means that density of the non-hydrogenic ion is smaller than that of the hydrogenic ion by a factor 2/("Z"+1). Therefore the rate for these reactions is reduced by the same factor, on top of any differences in the values of <σv>/T2. On the other hand, because the 21D-21D reaction has only one reactant, its rate is twice as high as when the fuel is divided between two different hydrogenic species, thus creating a more efficient reaction.
Thus there is a "penalty" of (2/(Z+1)) for non-hydrogenic fuels arising from the fact that they require more electrons, which take up pressure without participating in the fusion reaction. (It is usually a good assumption that the electron temperature will be nearly equal to the ion temperature. Some authors, however discuss the possibility that the electrons could be maintained substantially colder than the ions. In such a case, known as a "hot ion mode", the "penalty" would not apply.) There is at the same time a "bonus" of a factor 2 for 21D-21D because each ion can react with any of the other ions, not just a fraction of them.
We can now compare these reactions in the following table.
The maximum value of <σv>/T2 is taken from a previous table. The "penalty/bonus" factor is that related to a non-hydrogenic reactant or a single-species reaction. The values in the column "reactivity" are found by dividing 1.24×10-24 by the product of the second and third columns. It indicates the factor by which the other reactions occur more slowly than the 21D-31T reaction under comparable conditions. The column "Lawson criterion" weights these results with "E"ch and gives an indication of how much more difficult it is to achieve ignition with these reactions, relative to the difficulty for the 21D-31T reaction. The last column is labeled "power density" and weights the practical reactivity with "E"fus. It indicates how much lower the fusion power density of the other reactions is compared to the 21D-31T reaction and can be considered a measure of the economic potential.
Bremsstrahlung losses in quasineutral, isotropic plasmas.
The ions undergoing fusion in many systems will essentially never occur alone but will be mixed with electrons that in aggregate neutralize the ions' bulk electrical charge and form a plasma. The electrons will generally have a temperature comparable to or greater than that of the ions, so they will collide with the ions and emit x-ray radiation of 10–30 keV energy (Bremsstrahlung). The Sun and stars are opaque to x-rays, but essentially any terrestrial fusion reactor will be optically thin for x-rays of this energy range. X-rays are difficult to reflect but they are effectively absorbed (and converted into heat) in less than mm thickness of stainless steel (which is part of a reactor's shield). The ratio of fusion power produced to x-ray radiation lost to walls is an important figure of merit. This ratio is generally maximized at a much higher temperature than that which maximizes the power density (see the previous subsection). The following table shows estimates of the optimum temperature and the power ratio at that temperature for several reactions.
The actual ratios of fusion to Bremsstrahlung power will likely be significantly lower for several reasons. For one, the calculation assumes that the energy of the fusion products is transmitted completely to the fuel ions, which then lose energy to the electrons by collisions, which in turn lose energy by Bremsstrahlung. However, because the fusion products move much faster than the fuel ions, they will give up a significant fraction of their energy directly to the electrons. Secondly, the ions in the plasma are assumed to be purely fuel ions. In practice, there will be a significant proportion of impurity ions, which will then lower the ratio. In particular, the fusion products themselves "must" remain in the plasma until they have given up their energy, and "will" remain some time after that in any proposed confinement scheme. Finally, all channels of energy loss other than Bremsstrahlung have been neglected. The last two factors are related. On theoretical and experimental grounds, particle and energy confinement seem to be closely related. In a confinement scheme that does a good job of retaining energy, fusion products will build up. If the fusion products are efficiently ejected, then energy confinement will be poor, too.
The temperatures maximizing the fusion power compared to the Bremsstrahlung are in every case higher than the temperature that maximizes the power density and minimizes the required value of the fusion triple product. This will not change the optimum operating point for 21D-31T very much because the Bremsstrahlung fraction is low, but it will push the other fuels into regimes where the power density relative to 21D-31T is even lower and the required confinement even more difficult to achieve. For 21D-21D and 21D-32He, Bremsstrahlung losses will be a serious, possibly prohibitive problem. For 32He-32He, p+-63Li and p+-115B the Bremsstrahlung losses appear to make a fusion reactor using these fuels with a quasineutral, isotropic plasma impossible. Some ways out of this dilemma are considered—and rejected—in . This limitation does not apply to non-neutral and anisotropic plasmas; however, these have their own challenges to contend with.

</doc>
<doc id="21550" url="http://en.wikipedia.org/wiki?curid=21550" title="National Geographic Society">
National Geographic Society

The National Geographic Society (NGS), headquartered in Washington, D.C. in the United States of America, is one of the largest nonprofit scientific and educational institutions in the world. Its interests include geography, archaeology and natural science, the promotion of environmental and historical conservation, and the study of world culture and history. The National Geographic Society’s logo is a yellow portrait frame – rectangular in shape – which appears on the margins surrounding the front covers of its magazines and as its television channel logo. It also has its own that features extra content and worldwide events.
Overview.
The National Geographic Society was founded in 1888 "to increase and diffuse geographic knowledge." The Society believes in the power of science, exploration and storytelling to change the world, and its purpose is to inspire, illuminate and teach. National Geographic is governed by a board of trustees, whose 21 members include distinguished educators, business executives, former government officials and conservationists.
The organization sponsors and funds scientific research and exploration. The Society publishes an official journal, "National Geographic", in English and nearly 40 local-language editions. It also publishes other magazines, books, school products, maps, and Web and film products in numerous languages and countries. Its Education Foundation gives grants to education organizations and individuals to improve geography education. Its Committee for Research and Exploration has awarded more than 11,000 grants for scientific research and exploration.
National Geographic's various media properties reach more than 700 million people monthly. National Geographic maintains a museum for the public in its Washington, D.C., headquarters. It has helped to sponsor popular traveling exhibits, such as an early 2010s "King Tut" exhibit featuring magnificent artifacts from the tomb of the young Egyptian Pharaoh; "The Cultural Treasures of Afghanistan" which opened in May 2008 and traveled to other cities for 18 months; and an exhibition of China's Terracotta Warriors in its Washington headquarters in 2009–10.
National Geographic has retail stores in Washington, D.C, London, Madrid, and Sydney.
History.
The National Geographic Society began as a club for an elite group of academics and wealthy patrons interested in travel. On January 13, 1888, 33 explorers and scientists gathered at the Cosmos Club, a private club then located on Lafayette Square in Washington, D.C., to organize "a society for the increase and diffusion of geographical knowledge." After preparing a constitution and a plan of organization, the National Geographic Society was incorporated two weeks later on January 27. Gardiner Greene Hubbard became its first president and his son-in-law, Alexander Graham Bell, succeeded him in 1897. In 1899, Bell's son-in-law Gilbert Hovey Grosvenor was named the first full-time editor of National Geographic magazine and served the organization for fifty-five years (until 1954), and members of the Grosvenor family have played important roles in the organization since.
Bell and Gilbert Hovey Grosvenor devised the successful marketing notion of Society membership and the first major use of photographs to tell stories in magazines. The current National Geographic Society president and CEO is Gary E. Knell. The chairman of the board of trustees is John Fahey. The editor in chief of National Geographic magazine is Susan Goldberg. Gilbert Melville Grosvenor, a former chairman of the Society board of trustees received the Presidential Medal of Freedom in 2005 for his leadership in geography education. In 2004, the National Geographic Society headquarters in Washington, D.C., was one of the first buildings to receive a "Green" certification from Global Green USA. The National Geographic received the prestigious Prince of Asturias Award for Communication and Humanities in October 2006 in Oviedo, Spain.
Founders.
There were 33 founders.
Publications.
"National Geographic".
"National Geographic Magazine", later shortened to "National Geographic", published its first issue in October 1888, nine months after the Society was founded, as the Society's official journal, a benefit for joining the tax-exempt National Geographic Society. Starting with the February 1910 (Vol XXI., No. 2) issue, the magazine began using it's now famous trademarked yellow border around the edge of its covers.
There are 12 monthly issues of "National Geographic" per year. The magazine contains articles about geography, popular science, world history, culture, current events and photography of places and things all over the world and universe. "National Geographic" magazine is currently published in 40 local-language editions in many countries around the world. Combined English and other language circulation is around 6.8 million monthly, with some 60 million readers.
Other publications.
In addition to its flagship magazine, the Society publishes several other periodicals:
The Society also runs an online news outlet called "National Geographic Daily News".
The Society also publishes maps, atlases and books. It previously published other magazines, including National Geographic Adventure, a research journal, and others, and continues to publish special issues of various magazines.
Television.
Programs by the National Geographic Society are also broadcast on television. National Geographic television specials as well as television series have been aired on PBS and other networks in the United States and globally for many years. The "Geographic" series in the U.S. started on CBS in 1964, moved to ABC in 1973, shifted to PBS (produced by WQED, Pittsburgh) in 1975, shifted to TBS in 1995, and returned to PBS in 2000. National Geographic Channel, launched in January 2001, is a joint venture of National Geographic and Fox Cable Networks. It has featured stories on numerous scientific figures such as Louis Leakey, Jacques Cousteau, or Jane Goodall that not only featured their work but helped make them world-famous and accessible to millions. A majority of the specials were narrated by various actors, including Glenn Close, Linda Hunt, Stacy Keach, Richard Kiley, Burgess Meredith, Susan Sarandon, Alexander Scourby, Martin Sheen and Peter Strauss. The specials' theme music, by Elmer Bernstein, was also adopted by the National Geographic Channel. The National Geographic Channel has begun to launch a number of subbranded channels in international markets, such as Nat Geo WILD, Nat Geo Adventure, and Nat Geo Music.
National Geographic Films, a wholly owned taxable subsidiary of the National Geographic Society, has also produced a feature film based on the diary of a Russian submarine commander starring Harrison Ford in "", and most recently retooling a French-made documentary for U.S. distribution with a new score and script narrated by Morgan Freeman called "March of the Penguins", which received an Academy Award for the Best Documentary in 2006. After a record $77 million theatrical gross in the United States, over four million DVD copies of "March of the Penguins" have been sold. National Geographic Films launched a new feature film in July 2007 called "Arctic Tale", featuring the story of two families of walrus and polar bears. Queen Latifah is the narrator of this film. Inspired by a National Geographic Magazine article, National Geographic opened a 3-D large format and Reality 3-D film called "Sea Monsters", with a musical score by Peter Gabriel, in October of that year. National Geographic Films is co-producing with Edward Norton and Brad Pitt the 10-hour mini series of Steven Ambrose's award-winning "Undaunted Courage: Meriwether Lewis, Thomas Jefferson and the Opening of the American West" for HBO. In 2013, the network began airing the reality show Are You Tougher Than a Boy Scout?.
National Geographic Museum.
The Society operates the National Geographic Museum, located at 1145 17th Street, NW (17th and M), in Washington, D.C. The museum features changing photography exhibitions featuring the work of National Geographic explorers, photographers, and scientists. There are also changing exhibits related to natural history, culture, history or society.
Support for research and projects.
The Society has helped sponsor many expeditions and research projects over the years, including:
The Society supports many socially based projects including AINA, a Kabul-based organization dedicated to developing an independent Afghan media, which was founded by one of the Society's most famous photographers, Reza.
The Society also organizes the National Geographic Bee, an annual geographic contest for U.S. fourth- through eighth-graders. About 4 million students a year begin the geography competition locally, which culminates in a national competition of the winners of each state each May in Washington, D.C. Journalist Soledad O'Brien is the moderator of the Bee. She succeeded Alex Trebek, host of "Jeopardy!", who moderated the final round of the competition for 25 years, from its inception in 1989 to 2013. Every two years, the Society conducts an international geography competition of competing teams from all over the world. The most recent was held in St. Petersburg, Russia, in July 2013, and had representatives from 19 national teams. The team from the United States emerged as the winner, with teams from Canada and India in second and third place.
Awards.
Hubbard Medal.
The Hubbard Medal is awarded by the National Geographic Society for distinction in exploration, discovery, and research. The medal is named for Gardiner Greene Hubbard, the first National Geographic Society president. The Hubbard Medal has been presented 35 times as of 2010, the most recent award going to Don Walsh.
Alexander Graham Bell Medal.
The National Geographic Society also awards, rarely, the Alexander Graham Bell Medal, for exceptional contributions to geographic research. The award is named after Alexander Graham Bell, scientist, inventor and the second president of the NGS. Up to mid-2011, the medal has been twice presented:

</doc>
<doc id="21556" url="http://en.wikipedia.org/wiki?curid=21556" title="Norns">
Norns

The Norns (Old Norse: "norn", plural: "nornir") in Norse mythology are female beings who rule the destiny of gods and men, possibly a kind of dísir (see below), and comparable to the Moirai (also called "The Fates") in Greek mythology.
According to Snorri Sturluson's interpretation of the "Völuspá", the three most important norns, Urðr (Wyrd), Verðandi and Skuld come out from a hall standing at the Well of Urðr (well of fate) and they draw water from the well and take sand that lies around it, which they pour over Yggdrasill so that its branches will not rot. These norns are described as three powerful maiden giantesses (Jotuns) whose arrival from Jötunheimr ended the golden age of the gods. They may be the same as the maidens of Mögþrasir who are described in "Vafþrúðnismál" (see below).
Beside these three norns, there are many other norns who arrive when a person is born in order to determine his or her future. There were both malevolent and benevolent norns, and the former caused all the malevolent and tragic events in the world while the latter were kind and protective goddesses. Recent research has discussed the relation between the myths associated with norns and valkyries and traveling Völvas ("seiðr"-workers). The norns were thought to have visited newborn children in the pre-Christian Norse societies.
Norns within skaldic references are often seen as negative beings that are mostly associated with transitional situations such as violent death and battle. In Egil's Saga, Kveldulf composes a poem lamenting the loss of his eldest son Thorolf. Here, what is stressed is the personal tragedy felt by Kveldulf and the sense that what happened was out of his control or in the hands of fate. It is presumed that Óðinn has chosen Thorolf to be among his einherjar so Bek-Pedersen suggests that since Óðinn has caused the death then the norn has caused the emotional turmoil. Another negative aspect associated with the norns is that they are associated with death (see Skaldic Poetry). Not all aspects of the norns were negative, however, as they were associated with life and birth as well (see "Helgakviða Hundingsbana I" and "Gylfaginning").
Etymology.
The origin of the name "norn" is uncertain, it may derive from a word meaning "to twine" and which would refer to their twining the thread of fate. Bek-Pedersen suggests that the word "norn" has relation to the Swedish dialect word "norna (nyrna)", a verb that means "secretly communicate". This relates to the perception of norns as shadowy, background figures who only really ever reveal their fateful secrets to men as their fates come to pass.
The name "Urðr" ( Old EnglishWyrd, Weird) means "fate". It should be noted that "wyrd" and "urðr" are etymological cognates, which does not guarantee that "wyrd" and "urðr" share the same semantic quality of "fate" over time. Both "Urðr" and "Verðandi" are derived from the Old Norse verb "verða", "to be". While "Urðr" derives from the past tense ("that which became or happened"), "Verðandi" derives from the present tense of "verða" ("that which is happening"). "Skuld" is derived from the Old Norse verb "skulla", "need/ought to be/shall be"; its meaning is "that which should become, or that needs to occur".
Relation to other Germanic female deities.
There is no clear distinction between norns, fylgjas, hamingjas and valkyries, nor with the generic term dísir. Moreover, artistic license permitted such terms to be used for mortal women in Old Norse poetry, or to quote Snorri Sturluson's "Skáldskaparmál" on the various names used for women:
These unclear distinctions among norns and other Germanic female deities are discussed in Bek-Pedersen's book "Norns in old Norse Mythology", as well as, in Lionarons article "Disir, Valkyries, Volur, and Norns: The Weise Frauen of the Deutsche Mythologie"(See references).
Attestations.
There are a number of surviving Old Norse sources that relate to the norns. The most important sources are the Prose Edda and the Poetic Edda. The latter contains pagan poetry where the norns are frequently referred to, while the former contains, in addition to pagan poetry, retellings, descriptions and commentaries by the 12th and 13th century Icelandic chieftain and scholar Snorri Sturluson.
Skaldic poetry.
A skaldic reference to the norns appears in Hvini's poem in "Ynglingatal" 24 found in "Ynglingasaga" 47, where King Halfdan is put to rest by his men at Borró. This reference brings in the phrase "norna dómr" which means "judgment of the nornir". In most cases, when the norns pass judgment, it means death to those who have been judged - in this case, Halfdan. Along with being associated with being bringers of death, Bek-Pedersen suggests that this phrase brings in a quasi-legal aspect to the nature of the norns. This legal association is employed quite frequently within skaldic and eddic sources. This phrase can also be seen as a threat, as death is the final and inevitable decision that the norns can make with regard to human life.
Poetic Edda.
The Poetic Edda is valuable in representing older material in poetry from which Snorri tapped information in the "Prose Edda". Like "Gylfaginning", the "Poetic Edda" mentions the existence of many lesser norns beside the three main norns. Moreover, it also agrees with "Gylfaginning" by telling that they were of several races and that the dwarven norns were the daughters of Dvalin. It also suggests that the three main norns were giantesses (female Jotuns).
"Fáfnismál" contains a discussion between the hero Sigurd and the dragon Fafnir who is dying from a mortal wound from Sigurd. The hero asks Fafnir of many things, among them the nature of the norns. Fafnir explains that they are many and from several races:
It appears from "Völuspá" and "Vafþrúðnismál" that the three main norns were not originally goddesses but giantesses (Jotuns), and that their arrival ended the early days of bliss for the gods, but that they come for the good of mankind.
"Völuspá" relates that three giantesses of huge might are reported to have arrived to the gods from Jotunheim:
"Vafþrúðnismál" probably refers to the norns when it talks of maiden giantesses who arrive to protect the people of earth as protective spirits (hamingjas):
The "Völuspá" contains the names of the three main Norns referring to them as maidens like "Vafþrúðnismál" probably does:
"Helgakviða Hundingsbana I".
The norns visited each newly born child to allot his or her future, and in "Helgakviða Hundingsbana I", the hero Helgi Hundingsbane has just been born and norns arrive at the homestead:
"Helgakviða Hundingsbana II".
In "Helgakviða Hundingsbana II", Helgi Hundingsbane blames the norns for the fact that he had to kill Sigrún's father Högni and brother Bragi in order to wed her:
"Reginsmál".
Like Snorri Sturluson stated in "Gylfaginning", people's fate depended on the benevolence or the malevolence of particular norns. In "Reginsmál", the water dwelling dwarf Andvari blames his plight on an evil norn, presumably one of the daughters of Dvalin:
"Sigurðarkviða hin skamma".
Another instance of Norns being blamed for an undesirable situation appears in "Sigurðarkviða hin skamma", where the valkyrie Brynhild blames malevolent norns for her long yearning for the embrace of Sigurd:
"Guðrúnarkviða II".
Brynhild's solution was to have Gunnarr and his brothers, the lords of the Burgundians, kill Sigurd and afterwards to commit suicide in order to join Sigurd in the afterlife. Her brother Atli (Attila the Hun) avenged her death by killing the lords of the Burgundians, but since he was married to their sister Guðrún, Atli would soon be killed by her. In "Guðrúnarkviða II", the Norns actively enter the series of events by informing Atli in a dream that his wife would kill him. The description of the dream begins with this stanza:
"Guðrúnarhvöt".
After having killed both her husband Atli and their sons, Guðrún blames the Norns for her misfortunes, as in "Guðrúnarhvöt", where Guðrún talks of trying to escaping the wrath of the norns by trying to kill herself:
"Hamðismál".
"Guðrúnarhvöt" deals with how Guðrún incited her sons to avenge the cruel death of their sister Svanhild. In "Hamðismál", her sons' expedition to the Gothic king Ermanaric to exact vengeance is fateful. Knowing that he is about to die at the hands of the Goths, her son Sörli talks of the cruelty of the norns:
"Sigrdrífumál".
Since the norns were beings of ultimate power who were working in the dark, it should be no surprise that they could be referred to in charms, as they are by Sigrdrífa in "Sigrdrífumál":
"Prose Edda".
In the part of Snorri Sturluson's "Prose Edda" which is called "Gylfaginning", Gylfi, the king of Sweden, has arrived at Valhalla calling himself Gangleri. There, he receives an education in Norse mythology from what is Odin in the shape of three men. They explain to Gylfi that there are three main norns, but also many others of various races, æsir, elves and dwarves:
The three main norns take water out of the well of Urd and water Yggdrasil:
Snorri furthermore informs the reader that the youngest norn, Skuld, is in effect also a valkyrie, taking part in the selection of warriors from the slain:
Legendary sagas.
Some of the legendary sagas also contain references to the norns. The "Hervarar saga" contains a poem named "Hlöðskviða", where the Gothic king Angantýr defeats a Hunnish invasion led by his Hunnish half-brother Hlöðr. Knowing that his sister, the shieldmaiden Hervör, is one of the casualties, Angantýr looks at his dead brother and laments the cruelty of the norns:
In younger legendary sagas, such as "Norna-Gests þáttr" and "Hrólfs saga kraka", the norns appear to have been synonymous with völvas (witches, female shamans). In "Norna-Gests þáttr", where they arrive at the birth of the hero to shape his destiny, the norns are not described as weaving the web of fate, instead "Norna" appears to be interchangeable and possibly a synonym of "vala" (völva).
One of the last legendary sagas to be written down, the "Hrólfs saga kraka" talks of the norns simply as evil witches. When the evil half-elven princess Skuld assembles her army to attack Hrólfr Kraki, it contains in addition to undead warriors, elves and norns.
Runic inscription N 351 M.
The belief in the norns as bringers of both gain and loss would last beyond Christianization, as testifies the runic inscription N 351 M from the Borgund stave church:
Franks Casket.
Three women carved on the right panel of Franks Casket, an Anglo-Saxon whalebone chest from the eighth century, have been identified by some scholars as being three norns.
Theories.
A number of theories have been proposed regarding the norns.
Matres and Matrones.
The Germanic Matres and Matrones, female deities venerated in North-West Europe from the 1st to the 5th century AD depicted on votive objects and altars almost entirely in groups of three from the first to the fifth century AD have been proposed as connected with the later Germanic dísir, valkyries, and norns, potentially stemming from them.
Three norns.
Theories have been proposed that there is no foundation in Norse mythology for the notion that the three main norns should each be associated exclusively with the past, the present, and the future; rather, all three represent "destiny" as it is twined with the flow of time. Moreoever, theories have been proposed that the idea that there are three main norns may be due to a late influence from Greek and Roman mythology, where there are also spinning fate goddesses (Moirai and Parcae).
Appearances in media and popular culture.
Music.
Viking death metal band Amon Amarth has an album titled "Fate of Norns". The band itself has many songs involving Norse mythology.
Opera.
Norns feature in the prologue of Richard Wagner's opera Götterdämmerung.
Television.
The 1990s Disney Cartoon Gargoyles features Three sisters (Referred to by the cast as the "Weird Sisters") that are inferred to be Norns.
In the 2010 series Lost Girl, there was a Norn who could be petitioned to change fate, for a price. Her price was always the one thing her petitioner values most, whether they realize it or not.
Anime and manga.
The main love interest of Oh My Goddess! is the Norn Verðandi, rendered as Belldandy. Her elder sister Urðr (rendered as Urd) and younger sister Skuld also show up, living with the protagonist Keichii Morisato and their sister Belldandy. Aside from sticking loosely to the theme of Belldandy representing the present, Urd the past and Skuld the future, they are only loosely related to their mythic namesakes in this media.
The terminals that Yggdrasil from Digimon created for the New Digital World experiments consisting 3 layers are named Ulud, Versandi, and Skuld which are representing for past, present, and future. Ulud Urðr is a past plain which is a volcanic wasteland, inhabited by Dinosaur type and draconic Digimon. Versandi Verðandi is the "present" region which is a world of lush greenery and is home to beast, bird, plant and other nature Digimon. Skuld is the "future" region, a high-tech city where machine and insect Digimon inhabit.
The three Norns also appear as antagonists in Mythical Detective Loki Ragnarok, along with various other figures from Norse mythology, including Thor, Heimdallr, Freyr, Freyja, Fenrir, Jormungandr, and the eponymous Loki.
References.
</dl>

</doc>
<doc id="21557" url="http://en.wikipedia.org/wiki?curid=21557" title="Niflheim">
Niflheim

Niflheim (or Niflheimr) ("Mist Home", the "Abode of Mist" or "Mist World") is one of the Nine Worlds and is a location in Norse mythology which overlaps with the notions of Niflhel and Hel. The name "Niflheimr" only appears in two extant sources, "Gylfaginning" and the much debated "Hrafnagaldr Óðins".
Niflheim was primarily a realm of primordial ice and cold, with nine frozen rivers. Two classes of legendary beings were often labeled by scholars as the inhabitants of Niflheim — the Hrímthursar, widely known as the Frost Giants (or Rime-Giants) of Norse legend; and the Niflungar ("children of the mist"), a race of treasure-hoarding spirits better remembered as the Nibelungs, the titular creatures in Richard Wagner's opera "Der Ring des Nibelungen". According to "Gylfaginning", Niflheim was one of the two primordial realms, the other one being Muspelheim, the realm of fire. Between these two realms of cold and heat, creation began when its waters mixed with the heat of Muspelheim to form a "creating steam". Later, it became the abode of Hel, a goddess daughter of Loki, and the afterlife for her subjects, those who did not die a heroic or notable death.
Etymology.
"Nifl" (whence the Icelandic "nifl") being cognate with the Anglo-Saxon "Nifol" ("dark"), Dutch "nevel" and German "nebel" ("fog").
"Gylfaginning".
In "Gylfaginning" by Snorri Sturluson, Gylfi, the king of ancient Scandinavia, receives an education in Norse mythology from Odin in the guise of three men. Gylfi learns from Odin (as "Jafnhárr") that Niflheimr was the first world to be created after Muspelheim:
It was many ages before the earth was shaped that the Mist-World [Niflheimr] was made; and midmost within it lies the well that is called Hvergelmir, from which spring the rivers called Svöl, Gunnthrá, Fjörm, Fimbulthul, Slídr and Hríd, Sylgr and Ylgr, Víd, Leiptr; Gjöll is hard by Hel-gates.
Odin (as "Þriði") further tells Gylfi that it was when the ice from Niflheimr met the flames from Muspelheimr that creation began and Ymir was formed:
Just as cold arose out of Niflheim, and all terrible things, so also all that looked toward Múspellheim became hot and glowing; but Ginnungagap was as mild as windless air, and when the breath of heat met the rime, so that it melted and dripped, life was quickened from the yeast-drops, by the power of that which sent the heat, and became a man's form. And that man is named Ymir, but the Rime-Giants call him Aurgelmir; [...]
In relation to the world tree Yggdrasill, "Jafnhárr" (Odin) tells Gylfi that Jötunheimr is located under the second root, where Ginnungagap ("Yawning Void") once was:
The Ash is greatest of all trees and best: its limbs spread out over all the world and stand above heaven. Three roots of the tree uphold it and stand exceeding broad: one is among the Æsir; another among the Rime-Giants, in that place where aforetime was the Yawning Void; the third stands over Niflheim, and under that root is Hvergelmir, and Nídhöggr gnaws the root from below.
Gylfi is furthermore informed that when Loki had engendered Hel, she was cast into Niflheimr by Odin:
Hel he cast into Niflheim, and gave to her power over nine worlds, to apportion all abodes among those that were sent to her: that is, men dead of sickness or of old age. She has great possessions there; her walls are exceeding high and her gates great.
Hel thus became the mistress of the world of those dead in disease and old age. One last mention of Niflheimr appears where it is the last destination of the "jötunn" who was killed by Thor after he had built Asgard:
Now that the Æsir saw surely that the hill-giant was come thither, they did not regard their oaths reverently, but called on Thor, who came as quickly. And straightway the hammer Mjöllnir was raised aloft; he paid the wright's wage, and not with the sun and the moon. Nay, he even denied him dwelling in Jötunheim, and struck but the one first blow, so that his skull was burst into small crumbs, and sent him down below under Niflhel [Niflheim].
"Hrafnagaldr Óðins".
In "Hrafnagaldr Óðins", there is a brief mention of Niflheimr as a location in the North, towards which the sun (Alfr's illuminator) chased the night as it rose:

</doc>
<doc id="21558" url="http://en.wikipedia.org/wiki?curid=21558" title="Nanna">
Nanna

Nanna may refer to:

</doc>
<doc id="21559" url="http://en.wikipedia.org/wiki?curid=21559" title="NASDAQ">
NASDAQ

The NASDAQ Stock Market (), commonly known as the NASDAQ (currently stylized as Nasdaq), is an American stock exchange. It is the second-largest exchange in the U.S. and world by market capitalization and trading volume. The exchange platform is owned by The NASDAQ OMX Group, which also owns the OMX stock market network and several other US stock and options exchanges.
History.
In 1972, "NASDAQ" stood for National Association of Securities Dealers Automated Quotations. NASDAQ was founded in 1971 by the National Association of Securities Dealers (NASD), which divested itself of NASDAQ in a series of sales in 2000 and 2001. NASDAQ is owned and operated by the The NASDAQ OMX Group, the stocks of which were listed on its own stock exchange beginning July 2, 2002, under the ticker symbol . 
When the NASDAQ began trading on February 8, 1971, it was the world's first electronic stock market. At first, it was merely a "quotation system" and did not provide a way to perform electronic trades. The NASDAQ helped lower the spread (the difference between the bid price and the ask price of the stock) but was unpopular among brokerages which made much of their money on the spread.
NASDAQ eventually assumed the majority of major trades formerly executed by the over-the-counter (OTC) system of trading, although there are still numerous securities traded in this fashion. As late as 1987, the NASDAQ exchange was still commonly referred to as "OTC" in media and also in the monthly Stock Guides issued by Standard & Poor's Corporation.
Over the years, NASDAQ became more of a stock market by adding trade and volume reporting and automated trading systems. NASDAQ was also the first stock market in the United States to start trading online, highlighting NASDAQ-traded companies (usually in technology) and closing with the declaration that NASDAQ is "the stock market for the next hundred years." Its main index is the NASDAQ Composite, which has been published since its inception. However, its exchange-traded fund tracks the large-cap NASDAQ-100 index, which was introduced in 1985 alongside the NASDAQ 100 Financial Index.
Until 1987, most trading occurred via the telephone. During the October 1987 stock market crash, however, market makers often did not answer their phones. To remedy this, the Small Order Execution System (SOES) was established. SOES provides an electronic method for dealers to enter their trades. NASDAQ requires market makers to honor trades executed using SOES.
In 1992, NASDAQ joined with the London Stock Exchange to form the first intercontinental linkage of securities markets. The National Association of Securities Dealers spun off NASDAQ in 2000 to form a publicly traded company, the NASDAQ Stock Market, Inc.
In 2006, the status of NASDAQ was changed from a stock market to a licensed national securities exchange.
To qualify for listing on the exchange, a company must be registered with the United States Securities and Exchange Commission (SEC), must have at least three market makers (financial firms that act as brokers or dealers for specific securities) and must meet minimum requirements for assets, capital, public shares, and shareholders.
In February 2011, in the wake of an announced merger of NYSE Euronext with Deutsche Börse, speculation developed that NASDAQ OMX and Intercontinental Exchange (ICE) could mount a counter-bid of their own for NYSE. NASDAQ OMX could be looking to acquire the American exchange's cash equities business, ICE the derivatives business. As of the time of the speculation, "NYSE Euronext’s market value was $9.75 billion. Nasdaq was valued at $5.78 billion, while ICE was valued at $9.45 billion." Late in the month, Nasdaq was reported to be considering asking either ICE or the Chicago Merc to join in what would probably have to be, if it proceeded, an $11–12 billion counterbid.
The European Association of Securities Dealers Automatic Quotation System (EASDAQ) was founded originally as a European equivalent to NASDAQ. It was purchased by NASDAQ in 2001 and became NASDAQ Europe. Operations were shut down, however, as a result of the burst of the dot-com bubble. In 2007, NASDAQ Europe was revived as Equiduct, and is currently operating under Börse Berlin.
On June 18, 2012, NASDAQ became a founding member of the United Nations Sustainable Stock Exchanges initiative on the eve of the United Nations Conference on Sustainable Development (Rio+20).
In 2013, NASDAQ OMX was approached by private equity firm Carlyle Group about taking the exchange operator private, but the talks fell apart over a disagreement on price.
Quote availability.
NASDAQ quotes are available at three levels:
Trading schedule.
NASDAQ has a pre-market session from 4:00 AM to 9:30 AM Eastern, a normal trading session from 9:30 AM to 4:00 PM, and a post-market session from 4:00 PM to 8:00 PM.
Market tiers.
NASDAQ has three different market tiers:

</doc>
<doc id="21560" url="http://en.wikipedia.org/wiki?curid=21560" title="New York Stock Exchange">
New York Stock Exchange

The New York Stock Exchange (NYSE), sometimes known as the "Big Board", is an American stock exchange located at 11 Wall Street, Lower Manhattan, New York City, New York, United States. It is by far the world's largest stock exchange by market capitalization of its listed companies at US$16.6 trillion as of February 2015. Average daily trading value was approximately US$169 billion in 2013.
The NYSE trading floor is located at 11 Wall Street and is composed of 21 rooms used for the facilitation of trading. A fifth trading room, located at 30 Broad Street, was closed in February 2007. The main building, located at 18 Broad Street, between the corners of Wall Street and Exchange Place, was designated a National Historic Landmark in 1978, as was the 11 Wall Street building.
The NYSE is owned by Intercontinental Exchange, an American holding company it also lists (#redirect). Previously, it was part of NYSE Euronext (NYX), which was formed by the NYSE's 2007 merger with the fully electronic stock exchange Euronext. NYSE and Euronext now operate as divisions of Intercontinental Exchange.
The NYSE has been the subject of several lawsuits regarding fraud or breach of duty and was sued by its former CEO for breach of contract and defamation.
History.
The earliest recorded organization of securities trading in New York among brokers directly dealing with each other can be traced to the Buttonwood Agreement. Previously securities exchange had been intermediated by the auctioneers who also conducted more mundane auctions of commodities such as wheat and tobacco. On May 17, 1792 twenty four brokers signed the Buttonwood Agreement which set a floor commission rate charged to clients and bound the signers to give preference to the other signers in securities sales. The earliest securities traded were mostly governmental securities such as War Bonds from the Revolutionary War and First Bank of the United States stock, although Bank of New York stock was a non-governmental security traded in the early days.
In 1817 the stockbrokers of New York operating under the Buttonwood Agreement instituted new reforms and reorganized. After sending a delegation to Philadelphia to observe the organization of their board of brokers, restrictions on manipulative trading were adopted as well as formal organs of governance. After re-forming as the New York Stock and Exchange Board the broker organization began renting out space exclusively for securities trading, which previously had been taking place at the Tontine Coffee House. Several locations were used between 1817 and 1865, when the present location was adopted.
The invention of the electrical telegraph consolidated markets, and New York's market rose to dominance over Philadelphia after weathering some market panics better than other alternatives. The Civil War greatly stimulated speculative securities trading in New York. By 1869 membership had to be capped, and has been sporadically increased since. The latter half of the nineteenth century saw rapid growth in securities trading.
Securities trade in the latter nineteenth and early twentieth centuries was prone to panics and crashes. Government regulation of securities trading was eventually seen as necessary, with arguably the most dramatic changes occurring in the 1930s after a major stock market crash precipitated an economic depression.
The Stock Exchange Luncheon Club was situated on the seventh floor from 1898 until its closure in 2006.
The NYSE announced its plans to merge with Archipelago on April 21, 2005, in a deal intended to reorganize the NYSE as a publicly traded company. NYSE's governing board voted to merge with rival Archipelago on December 6, 2005, and become a for-profit, public company. It began trading under the name NYSE Group on March 8, 2006. A little over one year later, on April 4, 2007, the NYSE Group completed its merger with Euronext, the European combined stock market, thus forming the NYSE Euronext, the first transatlantic stock exchange.
Wall Street is the leading US money centre for international financial activities and the foremost US location for the conduct of wholesale financial services. "It comprises a matrix of wholesale financial sectors, financial markets, financial institutions, and financial industry firms" (Robert, 2002). The principal sectors are securities industry, commercial banking, asset management, and insurance.
Prior to the acquisition of NYSE Euronext by the ICE in 2013, Marsh Carter was the Chairman of the NYSE and the CEO was Duncan Niederauer. Presently, the Chairman is Jeffrey Sprecher.
Notable events.
The exchange was closed shortly after the beginning of World War I (July 31, 1914), but it partially re-opened on November 28 of that year in order to help the war effort by trading bonds, and completely reopened for stock trading in mid-December.
On September 16, 1920, a bomb exploded on Wall Street outside the NYSE building, killing 33 people and injuring more than 400. The perpetrators were never found. The NYSE building and some buildings nearby, such as the JP Morgan building, still have marks on their façades caused by the bombing.
The Black Thursday crash of the Exchange on October 24, 1929, and the sell-off panic which started on Black Tuesday, October 29, are often blamed for precipitating the Great Depression. In an effort to try to restore investor confidence, the Exchange unveiled a fifteen-point program aimed to upgrade protection for the investing public on October 31, 1938.
On October 1, 1934, the exchange was registered as a national securities exchange with the U.S. Securities and Exchange Commission, with a president and a thirty-three member board. On February 18, 1971 the non-profit corporation was formed, and the number of board members was reduced to twenty-five.
One of Abbie Hoffman's well-known publicity stunts took place in 1967, when he led members of the Yippie movement to the Exchange's gallery. The provocateurs hurled fistfuls of real dollars mixed with fake dollars toward the trading floor below. Some traders booed, and some collected the apparent bounty. The press was quick to respond and, by evening, the event had been reported around the world. (The stock exchange later spent $20,000 to enclose the gallery with bulletproof glass.) Hoffman wrote a decade later, "We didn't call the press; at that time we really had no notion of anything called a media event".
On October 19, 1987, the Dow Jones Industrial Average (DJIA) dropped 508 points, a 22.6% loss in a single day, the second-biggest one-day drop the exchange had experienced. Black Monday was followed by Terrible Tuesday, a day in which the Exchange's systems did not perform well and some people had difficulty completing their trades.
Subsequently, there was another major drop for the Dow on October 13, 1989; the Mini-Crash of 1989. The crash was apparently caused by a reaction to a news story of a $6.75 billion leveraged buyout deal for UAL Corporation, the parent company of United Airlines, which broke down. When the UAL deal fell through, it helped trigger the collapse of the junk bond market causing the Dow to fall 190.58 points, or 6.91 percent.
Similarly, there was a panic in the financial world during the year of 1997; the Asian Financial Crisis. Like the fall of many foreign markets, the Dow suffered a 7.18% drop in value (554.26 points) on October 27, 1997, in what later became known as the 1997 Mini-Crash but from which the DJIA recovered quickly. This was the first time that the "circuit breaker" rule had operated.
On January 26, 2000, an altercation during filming of the music video for "Sleep Now in the Fire", which was directed by Michael Moore, caused the doors of the exchange to be closed and the band Rage Against the Machine to be escorted from the site by security after band members attempted to gain entry into the exchange.
Trading on the exchange floor, however, continued uninterrupted.
In the aftermath of the September 11, 2001 terrorist attacks, the NYSE was closed for 4 trading sessions, one of the rare times the NYSE was closed for more than one session and only the third time since March 1933.
On May 6, 2010, the Dow Jones Industrial Average posted its largest intraday percentage drop since the October 19, 1987 crash, with a 998-point loss later being called the 2010 Flash Crash (as the drop occurred in minutes before rebounding). The SEC and CFTC published a report on the event, although it did not come to a conclusion as to the cause. The regulators found no evidence that the fall was caused by erroneous ("fat finger") orders.
On October 29, 2012, the stock exchange was shut down for 2 days due to Hurricane Sandy.
The last time the stock exchange was closed due to weather for a full two days was on March 12 and 13 in 1888.
On May 1, 2014 the stock exchange was fined $4.5 million by the Securities and Exchange Commission to settle charges it violated market rules.
On 14 August 2014 Berkshire Hathaway's A Class shares, the highest priced shares on the NYSE, hit $200,000 a share for the first time.
On 18 August 2014 Sam Jordan most recently served as CFO. In 2013, Mr. Sam Jordan responsibilities were expanded to also include oversight for global operations and information technology. He held a variety of positions in corporate finance in America and abroad while at The Dun & Bradstreet Corporation.
Mr. Sam Jordan has served on the boards of ProQuest, the Madison Square Boys and Girls Club, and Westchester County Association. He earned an MBA in Finance from the McCombs School of Business of The University of Texas at Austin, with CPA Certification in the State of New York, and holds a Corporate Law in Accounting from the University of Delaware.
Trading.
The New York Stock Exchange (sometimes referred to as "the Big Board") provides a means for buyers and sellers to trade shares of stock in companies registered for public trading. The NYSE is open for trading Monday through Friday from 9:30 am – 4:00 pm ET, with the exception of holidays declared by the Exchange in advance.
The NYSE trades in a continuous auction format, where traders can execute stock transactions on behalf of investors. They will gather around the appropriate post where a specialist broker, who is employed by a NYSE member firm (that is, he/she is not an employee of the New York Stock Exchange), acts as an auctioneer in an open outcry auction market environment to bring buyers and sellers together and to manage the actual auction. They do on occasion (approximately 10% of the time) facilitate the trades by committing their own capital and as a matter of course disseminate information to the crowd that helps to bring buyers and sellers together. The auction process moved toward automation in 1995 through the use of wireless hand held computers (HHC). The system enabled traders to receive and execute orders electronically via wireless transmission. On September 25, 1995, NYSE member Michael Einersen, who designed and developed this system, executed 1000 shares of IBM through this HHC ending a 203-year process of paper transactions and ushering in an era of automated trading.
As of January 24, 2007, all NYSE stocks can be traded via its electronic hybrid market (except for a small group of very high-priced stocks). Customers can now send orders for immediate electronic execution, or route orders to the floor for trade in the auction market. In the first three months of 2007, in excess of 82% of all order volume was delivered to the floor electronically. NYSE works with US regulators like the SEC and CFTC to coordinate risk management measures in the electronic trading environment through the implementation of mechanisms like circuit breakers and liquidity replenishment points.
Until 2005, the right to directly trade shares on the exchange was conferred upon owners of the 1366 "seats". The term comes from the fact that up until the 1870s NYSE members sat in chairs to trade. In 1868, the number of seats was fixed at 533, and this number was increased several times over the years. In 1953, the number of seats was set at 1,366. These seats were a sought-after commodity as they conferred the ability to directly trade stock on the NYSE, and seat holders were commonly referred to as members of the NYSE. The Barnes family is the only known lineage to have five generations of NYSE members: Winthrop H. Barnes (admitted 1894), Richard W.P. Barnes (admitted 1926), Richard S. Barnes (admitted 1951), Robert H. Barnes (admitted 1972), Derek J. Barnes (admitted 2003). Seat prices varied widely over the years, generally falling during recessions and rising during economic expansions. The most expensive inflation-adjusted seat was sold in 1929 for $625,000, which, today, would be over six million dollars. In recent times, seats have sold for as high as $4 million in the late 1990s and as low as $1 million in 2001. In 2005, seat prices shot up to $3.25 million as the exchange entered into an agreement to merge with Archipelago and become a for-profit, publicly traded company. Seat owners received $500,000 in cash per seat and 77,000 shares of the newly formed corporation. The NYSE now sells one-year licenses to trade directly on the exchange. Licences for floor trading are available for $40,000 and a licence for bond trading is available for as little as $1,000 as of 2010. Neither are resell-able, but may be transferable in during the change of ownership of a cooperation holding a trading licence.
Following the Black Monday market crash in 1987, NYSE imposed trading curbs to reduce market volatility and massive panic sell-offs. Following the 2011 rule change, at the start of each trading day, the NYSE sets three circuit breaker levels at levels of 7% (Level 1), 13% (Level 2), and 20% (Level 3) of the average closing price of the S&P 500 for the preceding trading day. Level 1 and Level 2 declines result in a 15-minute trading halt unless they occur after 3:25pm, when no trading halts apply. A Level 3 decline results in trading being suspended for the remainder of the day. (The biggest one-day decline in the S&P 500 since 1987 was the 9.0% drop on October 15, 2008.)
NYSE Composite Index.
In the mid-1960s, the NYSE Composite Index (NYSE: [ NYA]) was created, with a base value of 50 points equal to the 1965 yearly close. This was done to reflect the value of all stocks trading at the exchange instead of just the 30 stocks included in the Dow Jones Industrial Average. To raise the profile of the composite index, in 2003 the NYSE set its new base value of 5,000 points equal to the 2002 yearly close. Its close at the end of 2013 was 10,400.32.
Merger, acquisition, and control.
On February 15, 2011 NYSE and Deutsche Börse announced their merger to form a new company, as yet unnamed, wherein Deutsche Börse shareholders will have 60% ownership of the new entity, and NYSE Euronext shareholders will have 40%.
On February 1, 2012, the European Commission blocked the merger of NYSE with Deutsche Börse, after commissioner Joaquin Almunia stated that the merger "would have led to a near-monopoly in European financial derivatives worldwide". Instead, Deutsche Börse and NYSE will have to sell either their Eurex derivatives or LIFFE shares in order to not create a monopoly. On February 2, 2012, NYSE Euronext and Deutsche Börse agreed to scrap the merger.
In April 2011, Intercontinental Exchange (ICE), an American futures exchange, and NASDAQ OMX Group had together made an unsolicited proposal to buy NYSE Euronext for approximately , a deal in which NASDAQ would have taken control of the stock exchanges. NYSE Euronext rejected this offer twice, but it was finally terminated after the United States Department of Justice indicated their intention to block the deal due to antitrust concerns.
In December 2012, it was announced that ICE had proposed to buy NYSE Euronext in a stock swap with a valuation of $8 billion. NYSE Euronext shareholders would receive either $33.12 in cash, or $11.27 in cash and approximately a sixth of a share of ICE. The Chairman and CEO of ICE, Jeffrey Sprecher, will retain those positions, but four members of the NYSE Board of Directors will be added to the ICE board.
Opening and closing bells.
The NYSE's opening and closing bells mark the beginning and the end of each trading day. The 'opening bell' is rung at 9:30 AM ET to mark the start of the day's trading session. At 4 PM ET the 'closing bell' is rung and trading for the day stops. There are bells located in each of the four main sections of the NYSE that all ring at the same time once a button is pressed. There are three buttons that control the bells, located on the control panel behind the podium which overlooks the trading floor. The main bell, which is rung at the beginning and end of the trading day, is controlled by a green button. The second button, colored orange, activates a single-stroke bell that is used to signal a moment of silence. A third, red button controls a backup bell which is used in case the main bell fails to ring.
History.
The signal to start and stop trading wasn't always a bell. The original signal was a gavel (which is still in use today along with the bell), but during the late 1800s, the NYSE decided to switch the gavel for a gong to signal the day's beginning and end. After the NYSE changed to its present location at 18 Broad Street in 1903, the gong was switched to the bell format that we see today.
A common sight today is the highly publicized events in which a celebrity or executive from a corporation stands behind the NYSE podium and pushes the button that signals the bells to ring. Many consider the act of ringing the bells to be quite an honor and a symbol of a lifetime of achievement. Furthermore, due to the amount of coverage that the opening/closing bells receive, many companies coordinate new product launches and other marketing-related events to start on the same day as when the company's representatives ring the bell. This daily tradition wasn't always this highly publicized either. In fact, it was only in 1995 that the NYSE began having special guests ring the bells on a regular basis. Prior to that, ringing the bells was usually the responsibility of the exchange's floor managers.
Notable bell-ringers.
Many of the people who ring the bell are business executives whose companies trade on the exchange. However, there have also been many famous people from outside the world of business that have rung the bell. Athletes such as Joe DiMaggio of the New York Yankees and Olympic swimming champion Michael Phelps, entertainers such as rapper Snoop Dogg and members of the band Kiss, and politicians such as Mayor of New York City Rudy Giuliani and President of South Africa Nelson Mandela have all had the honor of ringing the bell. Two United Nations Secretary Generals have also rung the bell. On April 27, 2006, Secretary-General Kofi Annan rang the opening bell to launch the United Nations Principles for Responsible Investment. On July 24, 2013, Secretary-General Ban Ki-moon rang the closing bell to celebrate the NYSE joining the United Nations Sustainable Stock Exchanges initiative.
In addition there have been many bell-ringers who are famous for heroic deeds, such as members of the New York police and fire departments following the events of 9/11, members of the United States Armed Forces serving overseas, and participants in various charitable organizations. The reception they receive is often significantly more vocal than that accorded to even the most famous celebrities.
There have also been several fictional characters that have rung the bell, including Mickey Mouse, the Pink Panther, Mr. Potato Head, the Aflac Duck, and Darth Vader.
References.
Notes
Bibliography

</doc>
<doc id="21561" url="http://en.wikipedia.org/wiki?curid=21561" title="Nanoengineering">
Nanoengineering

Nanoengineering is the practice of engineering on the nanoscale. It derives its name from the nanometre, a unit of measurement equalling one billionth of a meter.
Nanoengineering is largely a synonym for nanotechnology, but emphasizes the engineering rather than the pure science aspects of the field.
Degree programs.
The first nanoengineering program in the world was started at the University of Toronto within the Engineering Science program as one of the Options of study in the final years. In 2003, the Lund Institute of Technology started a program in Nanoengineering. In 2004, the College of Nanoscale Science and Engineering at SUNY Polytechnic Institute was established on the campus of the University at Albany. In 2005, the University of Waterloo established a unique program which offers a full degree in Nanotechnology Engineering. Louisiana Tech University started the first program in the U.S. in 2005. In 2006 the University of Duisburg-Essen started a Bachelor and a Master program NanoEngineering. The University of California, San Diego followed shortly thereafter in 2007 with its own department of Nanoengineering.
In 2009, the University of Toronto began offering all Options of study in Engineering Science as degrees, bringing the second nanoengineering degree to Canada.
DTU Nanotech - the Department of Micro- and Nanotechnology - is a department at the Technical University of Denmark established in 1990.
External links.
 

</doc>
<doc id="21562" url="http://en.wikipedia.org/wiki?curid=21562" title="NP (complexity)">
NP (complexity)

In computational complexity theory, NP is one of the most fundamental complexity classes.
The abbreviation NP refers to "nondeterministic polynomial time."
Intuitively, NP is the set of all decision problems for which the instances where the answer is "yes" have efficiently verifiable proofs of the fact that the answer is indeed "yes". More precisely, these proofs have to be "verifiable" in polynomial time by a deterministic Turing machine.
In an equivalent formal definition, NP is the set of decision problems where the "yes"-instances can be accepted in polynomial time by a non-deterministic Turing machine. The equivalence of the two definitions follows from the fact that an algorithm on such a non-deterministic machine consists of two phases, the first of which consists of a guess about the solution, which is generated in a non-deterministic way, while the second consists of a deterministic algorithm that verifies or rejects the guess as a valid solution to the problem. 
The complexity class P is contained in NP, but NP contains many important problems, the hardest of which are called NP-complete problems, whose solutions are sufficient to deal with any other NP problem in polynomial time. The most important open question in complexity theory, the P = NP problem, asks whether polynomial time algorithms actually exist for NP-complete, and by corollary, all NP problems. It is widely believed that this is not the case.
Formal definition.
The complexity class NP can be defined in terms of NTIME as follows:
Alternatively, NP can be defined using deterministic Turing machines as verifiers. A language "L" is in NP if and only if there exist polynomials "p" and "q", and a deterministic Turing machine "M", such that
Introduction.
Many natural computer science problems are covered by the class NP.
In particular, the decision versions of many interesting search problems and optimization problems are contained in NP.
Verifier-based definition.
In order to explain the verifier-based definition of NP, let us consider the subset sum problem:
Assume that we are given some integers, such as {−7, −3, −2, 5, 8}, and we wish to know whether some of these integers sum up to zero. In this example, the answer is "yes", since the subset of integers {−3, −2, 5} corresponds to the sum (−3) + (−2) + 5 = 0. The task of deciding whether such a subset with sum zero exists is called the "subset sum problem".
To answer if some of the integers add to zero we can create an algorithm which obtains all the possible subsets. As the number of integers that we feed into the algorithm becomes larger, the number of subsets grows exponentially and so does the computation time. However, notice that, if we are given a particular subset (often called a certificate), we can easily check or "verify" whether the subset sum is zero, by just summing up the integers of the subset. So if the sum is indeed zero, that particular subset is the "proof" or witness for the fact that the answer is "yes". An algorithm that verifies whether a given subset has sum zero is called "verifier".
More generally, a problem is said to be in NP if there exists a verifier V for the problem.
Given any instance I of problem P, where the answer is "yes", there must exist a certificate (also called a witness) W such that, given the ordered pair (I,W) as input, V returns the answer "yes" in polynomial time. Furthermore, if the answer to I is "no", the verifier will return "no" with input (I,W) for all possible W. Note that V could return the answer "No" even if the answer to I is "yes", if W is not a valid witness. For example, in the subset sum problem, if there is a subset whose sum is zero, but we select W to be a subset whose sum is not zero, the verifier will return "No", while if there is no subset whose sum is zero, the verify will return "no" regardless of the choice of W. The verifier needs only polynomial time (it just needs to check whether W is really a subset of I, and whether the sum of W is zero), so the subset sum problem is in NP.
The "no"-answer version of this problem is stated as: "given a finite set of integers, does every non-empty subset have a nonzero sum?". The verifier-based definition of NP does "not" require an easy-to-verify certificate for the "no"-answers. The class of problems with such certificates for the "no"-answers is called co-NP. In fact, it is an open question whether all problems in NP also have certificates for the "no"-answers and thus are in co-NP.
Machine-definition.
Equivalent to the verifier-based definition is the following characterization: NP is the set of decision problems solvable by a non-deterministic Turing machine that runs in polynomial time. (This means that there is an accepting computation path if a word is in the language – co-NP is defined dually with rejecting paths.) This definition is equivalent to the verifier-based definition because a non-deterministic Turing machine could solve an NP problem in polynomial time by non-deterministically selecting a certificate and running the verifier on the certificate. Similarly, if such a machine exists, then a polynomial time verifier can naturally be constructed from it.
Examples.
This is an incomplete list of problems that are in NP.
Properties.
NP is closed under:
It is not known whether NP is closed under complement (this question so-called "NP versus co-NP" question)
Why some NP problems are hard to solve.
Because of the many important problems in this class, there have been extensive efforts to find polynomial-time algorithms for problems in NP. However, there remain a large number of problems in NP that defy such attempts, seeming to require super-polynomial time. Whether these problems are not decidable in polynomial time is one of the greatest open questions in computer science (see P = NP problem for an in-depth discussion).
An important notion in this context is the set of NP-complete decision problems, which is a subset of NP and might be informally described as the "hardest" problems in NP. If there is a polynomial-time algorithm for even "one" of them, then there is a polynomial-time algorithm for "all" the problems in NP. Because of this, and because dedicated research has failed to find a polynomial algorithm for any NP-complete problem, once a problem has been proven to be NP-complete this is widely regarded as a sign that a polynomial algorithm for this problem is unlikely to exist.
However, in practical uses, instead of spending computational resources looking for an optimal solution, a good enough (but potentially suboptimal) solution may often be found in polynomial time. Also, the real life applications of some problems are easier than their theoretical equivalents.
Equivalence of definitions.
The two definitions of NP as the class of problems solvable by a nondeterministic Turing machine (TM) in polynomial time and the class of problems verifiable by a deterministic Turing machine in polynomial time are equivalent. The proof is described by many textbooks, for example Sipser's "Introduction to the Theory of Computation", section 7.3.
To show this, first suppose we have a deterministic verifier. A nondeterministic machine can simply nondeterministically run the verifier on all possible proof strings (this requires only polynomially many steps because it can nondeterministically choose the next character in the proof string in each step, and the length of the proof string must be polynomially bounded). If any proof is valid, some path will accept; if no proof is valid, the string is not in the language and it will reject.
Conversely, suppose we have a nondeterministic TM called A accepting a given language L. At each of its polynomially many steps, the machine's computation tree branches in at most a constant number of directions. There must be at least one accepting path, and the string describing this path is the proof supplied to the verifier. The verifier can then deterministically simulate A, following only the accepting path, and verifying that it accepts at the end. If A rejects the input, there is no accepting path, and the verifier will always reject.
Relationship to other classes.
NP contains all problems in P, since one can verify any instance of the problem by simply ignoring the proof and solving it. NP is contained in PSPACE—to show this, it suffices to construct a PSPACE machine that loops over all proof strings and feeds each one to a polynomial-time verifier. Since a polynomial-time machine can only read polynomially many bits, it cannot use more than polynomial space, nor can it read a proof string occupying more than polynomial space (so we do not have to consider proofs longer than this). NP is also contained in EXPTIME, since the same algorithm operates in exponential time.
The complement of NP, co-NP, contains those problems which have a simple proof for "no" instances, sometimes called counterexamples. For example, primality testing trivially lies in co-NP, since one can refute the primality of an integer by merely supplying a nontrivial factor. NP and co-NP together form the first level in the polynomial hierarchy, higher only than P.
NP is defined using only deterministic machines. If we permit the verifier to be probabilistic (this however, is not necessarily a BPP machine ), we get the class MA solvable using an Arthur-Merlin protocol with no communication from Merlin to Arthur.
NP is a class of decision problems; the analogous class of function problems is FNP.
The only known strict inclusions came from the space hierarchy theorem and the time hierarchy theorem, and respectively they are NP formula_2 NEXPTIME and NP formula_2 EXPSPACE.
Other characterizations.
In terms of descriptive complexity theory, NP corresponds precisely to the set of languages definable by existential second-order logic (Fagin's theorem).
NP can be seen as a very simple type of interactive proof system, where the prover comes up with the proof certificate and the verifier is a deterministic polynomial-time machine that checks it. It is complete because the right proof string will make it accept if there is one, and it is sound because the verifier cannot accept if there is no acceptable proof string.
A major result of complexity theory is that NP can be characterized as the problems solvable by probabilistically checkable proofs where the verifier uses O(log "n") random bits and examines only a constant number of bits of the proof string (the class PCP(log "n", 1)). More informally, this means that the NP verifier described above can be replaced with one that just "spot-checks" a few places in the proof string, and using a limited number of coin flips can determine the correct answer with high probability. This allows several results about the hardness of approximation algorithms to be proven.
Example.
The decision version of the travelling salesman problem is in NP. Given an input matrix of distances between "n" cities, the problem is to determine if there is a route visiting all cities with total distance less than "k".
A proof certificate can simply be a list of the cities. Then verification can clearly be done in polynomial time by a deterministic Turing machine. It simply adds the matrix entries corresponding to the paths between the cities.
A non-deterministic Turing machine can find such a route as follows:
One can think of each guess as "forking" a new copy of the Turing machine to follow each of the possible paths forward, and if at least one machine finds a route of distance less than "k", that machine accepts the input. (Equivalently, this can be thought of as a single Turing machine that always guesses correctly)
A binary search on the range of possible distances can convert the decision version of Traveling Salesman to the optimization version, by calling the decision version repeatedly (a polynomial number of times).

</doc>
<doc id="21565" url="http://en.wikipedia.org/wiki?curid=21565" title="November 5">
November 5

November 5 is the day of the year in the Gregorian calendar.

</doc>
<doc id="21566" url="http://en.wikipedia.org/wiki?curid=21566" title="Noam Chomsky">
Noam Chomsky

Avram Noam Chomsky (; born December 7, 1928) is an American linguist, philosopher, cognitive scientist, logician, political commentator, social justice activist, and anarcho-syndicalist advocate. Sometimes described as the "father of modern linguistics", Chomsky is also a major figure in analytic philosophy. He has spent most of his career at the Massachusetts Institute of Technology (MIT), where he is currently Professor Emeritus, and has authored over 100 books. He has been described as a prominent cultural figure, and was voted the "world's top public intellectual" in a 2005 poll.
Born to a middle-class Ashkenazi Jewish family in Philadelphia, Chomsky developed an early interest in anarchism from relatives in New York City. He later undertook studies in linguistics at the University of Pennsylvania, where he obtained his BA, MA, and PhD, while from 1951 to 1955 he was appointed to Harvard University's Society of Fellows. In 1955 he began work at MIT, soon becoming a significant figure in the field of linguistics for his publications and lectures on the subject. He is credited as the creator or co-creator of the Chomsky hierarchy, the universal grammar theory, the Chomsky–Schützenberger representation theorem, and the Chomsky–Schützenberger enumeration theorem. Chomsky also played a major role in the decline of behaviorism, and was especially critical of the work of B.F. Skinner. In 1967 he gained public attention for his vocal opposition to U.S. involvement in the Vietnam War, in part through his essay "The Responsibility of Intellectuals", and came to be associated with the New Left while being arrested on multiple occasions for his anti-war activism. While expanding his work in linguistics over subsequent decades, he also developed the propaganda model of media criticism with Edward S. Herman. Following his retirement from active teaching, he has continued his vocal public activism, for instance supporting the anti-Iraq War and Occupy movements.
Chomsky has been a highly influential academic figure throughout his career, and was cited within the field of Arts and Humanities more often than any other living scholar between 1980 and 1992. He was also the eighth most cited scholar overall within the Arts and Humanities Citation Index during the same period. His work has influenced fields such as artificial intelligence, cognitive science, computer science, logic, mathematics, music theory and analysis, political science, programming language theory and psychology. Chomsky continues to be well known as a political activist, and a leading critic of U.S. foreign policy, neoliberal capitalism, and the mainstream news media. Ideologically, he aligns himself with anarcho-syndicalism and libertarian socialism.
Early life.
Childhood: 1928–45.
Avram Noam Chomsky was born on December 7, 1928, in the affluent East Oak Lane neighborhood of Philadelphia. His father was the Ukrainian-born William "Zev" Chomsky, who had fled to the United States in 1913 and his mother was the Lithuanian-born Elsie Simonofsky. Both of his parents were Ashkenazi Lithuanian Jews. Having studied at Johns Hopkins University, his father went on to become school principal of the Congregation Mikveh Israel religious school, and in 1924 was appointed to the faculty at Gratz College in Philadelphia. Independently, William researched Medieval Hebrew, and would publish a series of books on the subject. William's wife, Elsie, was born in Belarus. They met at Mikveh Israel, where both taught Hebrew language classes. Described as a "very warm, gentle, and engaging" individual, William placed a great emphasis on educating people so that they would be "well integrated, free and independent in their thinking, and eager to participate in making life more meaningful and worthwhile for all", a view subsequently adopted by his son.
"What motivated his [political] interests? A powerful curiosity, exposure to divergent opinions, and an unorthodox education have all been given as answers to this question. He was clearly struck by the obvious contradictions between his own readings and mainstream press reports. The measurement of the distance between the realities presented by these two sources, and the evaluation of why such a gap exists, remained a passion for Chomsky."
Biographer Robert F. Barsky, 1997.
Noam was the Chomsky family's first child. His younger brother, David Eli Chomsky, was born five years later. The brothers remained close, although David was more easy-going while Noam could be very competitive. Chomsky's parents' first language was Yiddish, but Chomsky said it was "taboo" in his family to speak it. Unlike her husband, Elsie spoke "ordinary New York English". The brothers were raised in this Jewish environment, being taught Hebrew and regularly discussing the political theories of Zionism; the family were particularly influenced by the Left Zionist writings of Ahad Ha'am. Being Jewish, Noam Chomsky faced anti-semitism as a child, particularly from the Irish and German communities living in Philadelphia; he recalls German "beer parties" celebrating the fall of Paris to the Nazis.
Noam described his parents as "normal Roosevelt Democrats", having a centre-left position on the political spectrum, but he was exposed to far left politics through other members of the family, a number of whom were socialists involved in the International Ladies' Garment Workers' Union. He was influenced largely by his uncle who owned a newspaper stand in New York City where Jewish leftists came to debate the issues of the day. Whenever visiting his relatives in New York City, Chomsky frequented left-wing and anarchist bookstores, voraciously reading political literature. He later described his discovery of anarchism as a "lucky accident", allowing him to become critical of other radical left-wing ideologies, namely Marxism-Leninism. Chomsky's primary education was at Oak Lane Country Day School, an independent institution that focused on allowing its pupils to pursue their own interests in a non-competitive atmosphere. It was here that he wrote his first article, aged 10, on the spread of fascism, following the fall of Barcelona in the Spanish Civil War. From the age of 12 or 13, he identified more fully with anarchist politics. Aged 12, he moved on to secondary education at Central High School, where he joined various clubs and societies but was troubled by the hierarchical and regimented method of teaching that they employed.
University: 1945–55.
Aged 16, in 1945 Chomsky embarked on a general program of study at the University of Pennsylvania, where his primary interest was in learning Arabic. Living at home, he funded his undergraduate degree by teaching Hebrew. Although dissatisfied with the university's strict structure, he was encouraged to continue by the Russian-born linguist Zellig Harris, who convinced Chomsky to major in the subject. Chomsky's BA honor's thesis was titled "Morphophonemics of Modern Hebrew", and revised it for his MA thesis, which he attained at Penn in 1951; it would subsequently be published as a book. From 1951 to 1955 he was named to the Society of Fellows at Harvard University while undertaking his doctoral research. Being highly critical of the established behaviourist currents in linguistics, in 1954 he presented his ideas at lectures given at the University of Chicago and Yale University. In 1955 he was awarded his PhD from the University of Pennsylvania for a thesis setting out his ideas on transformational grammar; it would be published in 1975 as "The Logical Structure of Linguistic Theory".
In 1947, Chomsky entered into a romantic relationship with Carol Doris Schatz, whom he had known since they were toddlers. They were married in 1949, and remained together until her death in 2008. They considered moving to Israel, and in 1953 spent six weeks at the HaZore'a kibbutz; although enjoying himself, Chomsky was appalled by the Jewish nationalism and anti-Arab racism he encountered in the country, and the pro-Stalinist trend that he thought pervaded the kibbutz's leftist community.
On visits to New York City, Chomsky frequented the office of Yiddish anarchist journal "Freie Arbeiter Stimme", becoming enamored with the work of contributor Rudolf Rocker, whose work introduced him to the link between anarchism and classical liberalism. Other political thinkers whose work Chomsky read included the anarchist Diego Abad de Santillán, democratic socialists George Orwell, Bertrand Russell, and Dwight Macdonald, and works by Marxists Karl Liebknecht, Karl Korsch, and Rosa Luxemburg. His readings convinced him of the desirability of an anarcho-syndicalist society, and he became fascinated by the anarcho-syndicalist communes set up during the Spanish Civil War documented in Orwell's "Homage to Catalonia" (1938). He avidly read leftist journal "Politics", remarking that it "answered to and developed" his interest in anarchism, as well as the periodical "Living Marxism", published by council communist Paul Mattick. Although rejecting its Marxist basis, Chomsky was heavily influenced by council communism, voraciously reading articles in "Living Marxism" written by Antonie Pannekoek. He was greatly interested in the Marlenite ideas of the Leninist League, an anti-Stalinist Marxist-Leninist group, sharing their views that the Second World War was orchestrated by Western capitalists and the Soviet Union's "state capitalists" to crush Europe's proletariat.
Early career: 1955–1966.
In 1955, Chomsky obtained a job as an assistant professor at the Massachusetts Institute of Technology (MIT), spending half his time on a mechanical translation project and the other half teaching linguistics and philosophy. He later described MIT as "a pretty free and open place, open to experimentation and without rigid requirements. It was just perfect for someone of my idiosyncratic interests and work." In 1957 MIT promoted him to the position of associate professor, while from 1957–58 he was also employed by New York City's Columbia University as a visiting professor. That same year, the Chomskys' first child was born, and he published his first work on linguistics, "Syntactic Structures", a book that radically opposed the dominant Harris-Bloomfield trend in the field. The response to Chomsky's ideas ranged from indifference to hostility, and his work proved divisive and caused "significant upheaval" in the discipline. Linguist John Lyons later asserted that it "revolutionized the scientific study of language." From 1958–59 Chomsky was a National Science Foundation fellow at Princeton University's Institute for Advanced Study.
In 1959 he attracted further attention for his review of B.F. Skinner's 1957 book "Verbal Behavior" in the journal "Language", in which he argued that Skinner ignored the role of human creativity in linguistics. Becoming an "established intellectual", with his colleague Morris Halle, he founded the MIT's Graduate Program in linguistics, and in 1961 he was made professor of foreign language and linguistics, thereby gaining academic tenure. He was appointed plenary speaker at the Ninth International Congress of Linguists, held in 1962 at Cambridge, Massachusetts; the event established him as the "de facto" spokesperson of American linguistics. He continued to publish his linguistic ideas throughout the decade, as "Aspects of the Theory of Syntax" (1966), "Topics in the Theory of Generative Grammar" (1966), and "Cartesian Linguistics: A Chapter in the History of Linguistic Thought" (1966). Along with Halle, he also edited the Studies in Language Series of books for Harper and Row. He continued to receive academic recognition and honors for his work, in 1966 visiting a variety of Californian institutions, first as the Linguistics Society of America Professor at the University of California, and then as the Beckman Professor at the University of California, Berkeley. His Beckman lectures would be assembled and published as "Language and Mind" in 1968.
Rise to prominence.
Anti-Vietnam War activism: 1967–1975.
"[I]t does not require very far-reaching, specialized knowledge to perceive that the United States was invading South Vietnam. And, in fact, to take apart the system of illusions and deception which functions to prevent understanding of contemporary reality [is] not a task that requires extraordinary skill or understanding. It requires the kind of normal scepticism and willingness to apply one's analytical skills that almost all people have and that they can exercise."
Chomsky on the Vietnam War.
1967 marked Chomsky's entry into the public debate on the United States' foreign policy. In February he published an influential essay in "The New York Review of Books" titled "The Responsibility of Intellectuals", in which he criticized the country's involvement in the Vietnam War. He expanded on his argument to produce his first political book, "American Power and the New Mandarins," which was published in 1969 and soon established him at the forefront of American dissent. In 1971 he gave the Bertrand Russell Memorial Lectures in Cambridge, which were published as "Problems of Knowledge and Freedom" later that year, while other political books at the time included "At War with Asia" (1970) and "For Reasons of State" (1973). Coming to be associated with the American New Left movement, he nevertheless thought little of prominent New Left intellectuals Herbert Marcuse and Erich Fromm, and preferred the company of activists to intellectuals. Although he had initially arisen to attention for his political views in "The New York Review of Books", throughout the late 1960s and early 1970s, he was virtually ignored by the mainstream press.
Along with his writings, Chomsky also became actively involved in left-wing activism. Refusing to pay half his taxes, in 1967 he publicly supported students who refused the draft, and was arrested for being part of an anti-war teach-in outside the Pentagon. During this time Chomsky founded the anti-war collective RESIST along with Mitchell Goodman, Denise Levertov, William Sloane Coffin, and Dwight Macdonald. Supporting the student protest movement, he gave many lectures to student activist groups, though questioned the objectives of the 1968 student protests. Along with colleague Louis Kampf, he also began running undergraduate courses on politics at MIT, independent of the conservative-dominated political science department. His public talks often generated considerable controversy, particularly when he criticized actions of the Israeli government and military. His political views came under attack from right-wing and centrist figures, the most prominent of whom was Alan Dershowitz; Chomsky considered Dershowitz "a complete liar" and accused him of actively misrepresenting his position on issues. As a result of his anti-war activism, Chomsky was arrested on multiple occasions, and U.S. President Richard Nixon included him on his Enemies' List. He was aware of the potential repercussions of his activism, and so his wife began training to become an academic in order to support the family in the event of Chomsky's unemployment or imprisonment.
Although under some pressure to do so, MIT refused to fire him due to his influential standing in the field of linguistics. His work in this area continued to gain international recognition: in 1967 the University of London awarded him an honorary D. Litt while the University of Chicago gave him an honorary D.H.L. In 1970, Loyola University and Swarthmore College also awarded him honorary D.H.L.'s, as did Bard College in 1971, Delhi University in 1972, and the University of Massachusetts in 1973. In 1974 he became a corresponding fellow of the British Academy.
Chomsky continued to write on the subject, publishing "Studies on Semantics in Generative Grammar" (1972).
In 1971 he carried out a televised interview with French philosopher Michel Foucault on Dutch television; he largely agreed with Foucault's ideas, but was critical of post-modernism and French philosophy generally, lambasting France as having "a highly parochial and remarkably illiterate culture."
Work on the media: 1976–1989.
Throughout the late 1970s and 1980s, Chomsky's publications expanded and clarified his earlier work, addressing his critics and updating his grammatical theory.
In 1979, Chomsky and Herman published the two-volume "The Political Economy of Human Rights", in which they compared U.S. media reactions to the Cambodian genocide and the Indonesian occupation of East Timor. They argued that because Indonesia was a U.S. ally, U.S. media ignored the East Timorian situation while focusing on that in Cambodia, a U.S. enemy. The following year, Steven Lukas authored an article for the "Times Higher Education Supplement" accusing Chomsky of betraying his anarchist ideals and acting as an apologist for Cambodian leader Pol Pot. Although Laura J. Summers and Robin Woodsworth Carlsen replied to the article, arguing that Lukas completely misunderstood Chomsky and Herman's work, Chomsky himself did not. The controversy damaged his reputation.
Chomsky maintained that his critics printed lies about him to discredit his reputation.
Although Chomsky had long publicly criticised Nazism and totalitarianism more generally, his commitment to freedom of speech led him to defend the right of French historian Robert Faurisson to advocate a position widely characterised as Holocaust denial. Chomsky's plea for the historian's freedom of speech would be published as the preface to Faurisson's 1980 book "Mémoire en défense contre ceux qui m'accusent de falsifier l'histoire". Chomsky was widely condemned for defending Faurisson. France's mainstream press accused Chomsky of being a Holocaust denier himself, and refused to publish his rebuttals to their accusations. The Faurrison Affair had a lasting, damaging effect on Chomsky's career; Werner Cohn's "Partners in Hate: Noam Chomsky and the Holocaust Deniers" contained numerous falsified claims.
Increased political activism: 1990–present.
In the 1990s, Chomsky embraced political activism to a greater degree than before.
His far-reaching criticisms of U.S. foreign policy and the legitimacy of U.S. power have raised controversy. Chomsky has received death threats because of his criticisms of U.S. foreign policy. He has often received undercover police protection at MIT and when speaking on the Middle East, although he has refused uniformed police protection. The Electronic Intifada website claims that the Anti-Defamation League "spied on" Chomsky's appearances, and quotes Chomsky as being unsurprised at that discovery or the use of what Chomsky claims is "fantasy material" provided to Alan Dershowitz for debating him. Amused, Chomsky compares the ADL's reports to FBI files.
Chomsky resides in Lexington, Massachusetts, and travels, giving lectures on politics and linguistics.
Linguistic theory.
The basis to Chomsky's linguistic theory is that the principles underlying the structure of language are biologically determined in the human mind and hence genetically transmitted. He therefore argues that all humans share the same underlying linguistic structure, irrespective of socio-cultural difference. In this he opposes the radical behaviourist psychology of B.F. Skinner, instead arguing that human language is unlike modes of communication used by any other animal species.
Chomskyan linguistics, beginning with his "Syntactic Structures", a distillation of his "Logical Structure of Linguistic Theory" (1955, 75), challenges structural linguistics and introduces transformational grammar. This approach takes utterances (sequences of words) to have a syntax characterized by a formal grammar; in particular, a context-free grammar extended with transformational rules.
Perhaps his most influential and time-tested contribution to the field is the claim that modeling knowledge of language using a formal grammar accounts for the "productivity" or "creativity" of language. In other words, a formal grammar of a language can explain the ability of a hearer-speaker to produce and interpret an infinite number of utterances, including novel ones, with a limited set of grammatical rules and a finite set of terms. He has always acknowledged his debt to Pāṇini for his modern notion of an explicit generative grammar, although it is also related to Cartesian approach and rationalist ideas of a priori knowledge.
Chomsky has argued that linguistic structures are at least partly innate, and that they reflect a "universal grammar" (UG) that underlies and can account for all human grammatical systems (in general known as mentalism). Chomsky based his argument on observations about human language acquisition. For example, while a human baby and a kitten are both capable of inductive reasoning, if they are exposed to exactly the same linguistic data, the human will always acquire the ability to understand and produce language, while the kitten will never acquire either ability. Chomsky labeled whatever the relevant capacity the human has that the cat lacks as the language acquisition device (LAD), and he suggested that one of the tasks for linguistics should be to determine what the LAD is and what constraints it imposes on the range of possible human languages. The universal features that would result from these constraints are often termed "universal grammar" or UG.
Chomsky's ideas have had a strong influence on researchers of language acquisition in children, though many researchers in this area such as Elizabeth Bates and Michael Tomasello argue very strongly against Chomsky's theories, and instead advocate emergentist or connectionist theories, explaining language with a number of general processing mechanisms in the brain that interact with the extensive and complex social environment in which language is used and learned.
Generative grammar.
The Chomskyan approach towards syntax, often termed generative grammar, studies grammar as a body of knowledge possessed by language users. Since the 1960s, Chomsky has maintained that much of this knowledge is innate, implying that children need only learn certain parochial features of their native languages. The innate body of linguistic knowledge is often termed universal grammar. From Chomsky's perspective, the strongest evidence for the existence of Universal Grammar is simply the fact that children successfully acquire their native languages in so little time. Furthermore, he argues that there is an enormous gap between the linguistic stimuli to which children are exposed and the rich linguistic knowledge they attain (the "poverty of the stimulus" argument). The knowledge of Universal Grammar would serve to bridge that gap.
Chomsky's theories have been immensely influential within linguistics, but they have also received criticism. One recurring criticism of the Chomskyan variety of generative grammar is that it is Anglocentric and Eurocentric, and that often linguists working in this tradition have a tendency to base claims about Universal Grammar on a very small sample of languages, sometimes just one. Initially, the Eurocentrism was exhibited in an overemphasis on the study of English. However, hundreds of different languages have now received at least some attention within Chomskyan linguistic analyses. In spite of the diversity of languages that have been characterized by UG derivations, critics continue to argue that the formalisms within Chomskyan linguistics are Anglocentric and misrepresent the properties of languages that are structurally different from English. Thus, Chomsky's approach has been criticized as a form of linguistic imperialism. In addition, Chomskyan linguists rely heavily on the intuitions of native speakers regarding which sentences of their languages are well-formed. This practice has been criticized on general methodological grounds. Some psychologists and psycholinguists, though sympathetic to Chomsky's overall program, have argued that Chomskyan linguists pay insufficient attention to experimental data from language processing, with the consequence that their theories are not psychologically plausible. Other critics (see language learning) have questioned whether it is necessary to posit Universal Grammar to explain child language acquisition, arguing that domain-general learning mechanisms are sufficient.
Today there are many different branches of generative grammar. One can view grammatical frameworks such as head-driven phrase structure grammar, lexical functional grammar, and combinatory categorial grammar as broadly Chomskyan and generative in orientation, but with significant differences in execution.
Chomsky hierarchy.
Chomsky is famous for investigating various kinds of formal languages and whether or not they might be capable of capturing key properties of human language. His Chomsky hierarchy partitions formal grammars into classes/types, or groups, with increasing expressive power, i.e., each successive class can generate a broader set of formal languages than the one before. Interestingly, Chomsky argues that modeling some aspects of human language requires a more complex formal grammar (as measured by the Chomsky hierarchy) than modeling others. For example, while a regular language is powerful enough to model English morphology, it is not powerful enough to model English syntax. In addition to being relevant in linguistics, the Chomsky hierarchy has also become important in computer science (especially in programming language, compiler construction, and automata theory). Indeed, there is an equivalence between the Chomsky language hierarchy and the different kinds of automata. Thus theorems about languages are often dealt with as either languages (grammars) or automata.
Political views.
Chomsky's political views have changed little since his childhood. His ideological position revolves around "nourishing the libertarian and creative character of the human being", and he has described his beliefs as "fairly traditional anarchist ones, with origins in the Enlightenment and classical liberalism." He has praised libertarian socialism, and has described himself as an anarcho-syndicalist. He is a member of the Campaign for Peace and Democracy and the Industrial Workers of the World international union. Chomsky is also a member of the interim consultative committee of the International Organization for a Participatory Society, which he describes as having the potential to "...carry us a long way towards unifying the many initiatives here and around the world and molding them into a powerful and effective force." He advocates popular struggle for greater democracy.
He has stated his opposition to ruling elites, among them institutions like the IMF, World Bank, and GATT.
Authority.
Chomsky asserts that authority, unless justified, is inherently illegitimate, and that the burden of proof is on those in authority. If this burden can't be met, the authority in question should be dismantled. Authority for its own sake is inherently unjustified. An example given by Chomsky of a legitimate authority is that exerted by an adult to prevent a young child from wandering into traffic. He contends that there is little moral difference between chattel slavery and renting one's self to an owner or "wage slavery". He feels that it is an attack on personal integrity that undermines individual freedom. He holds that workers should own and control their workplace.
Capitalism and socialism.
"If you care about other people, that’s now a very dangerous idea. If you care about other people, you might try to organize to undermine power and authority. That’s not going to happen if you care only about yourself. Maybe you can become rich, but you don’t care whether other people’s kids can go to school, or can afford food to eat, or things like that. In the United States, that’s called “libertarian” for some wild reason. I mean, it’s actually highly authoritarian, but that doctrine is extremely important for power systems as a way of atomizing and undermining the public."
Chomsky on class war in the United States
Chomsky is critical of both the American state capitalist system and the authoritarian branches of socialism. He argues that libertarian socialist values are the proper extension of classical liberalism to an advanced industrial context, and that society should be highly organized and based on democratic control of communities and work places. He views the radical humanist ideas of his two major influences, Bertrand Russell and John Dewey, as "rooted in the Enlightenment and classical liberalism, while retaining their revolutionary character."
United States foreign policy.
Chomsky has strongly criticized the foreign policy of the United States. He claims double standards in a foreign policy preaching democracy and freedom for all while allying itself with non-democratic and repressive states and organizations such as Chile under Augusto Pinochet and argues that this results in massive human rights violations. He often argues that America's intervention in foreign nations — including secret aid the U.S. gave to the Contras in Nicaragua, an event he has been critical of — fits any standard description of terrorism, including "official definitions in the US Code and Army Manuals in the early 1980s." Before its collapse, Chomsky also condemned Soviet imperialism; for example in 1986 during a question–answer session following a lecture he gave at Universidad Centroamericana in Nicaragua, when challenged about how he could "talk about North American imperialism and Russian imperialism in the same breath," Chomsky responded: "One of the truths about the world is that there are two superpowers, one a huge power which happens to have its boot on your neck; another, a smaller power which happens to have its boot on other people's necks. I think that anyone in the Third World would be making a grave error if they succumbed to illusions about these matters." Martha Nussbaum criticizes Chomsky for failing to condemn atrocities by leftist insurgents because "for some leftists … one should not criticize one's friends, that solidarity is more important than ethical correctness."
Free speech.
Chomsky has a broad view of free-speech rights, especially in the mass media, and opposes censorship. He has stated that "with regard to freedom of speech there are basically two positions: you defend it vigorously for views you hate, or you reject it and prefer Stalinist/fascist standards". With reference to the United States diplomatic cables leak, Chomsky suggested that "perhaps the most dramatic revelation … is the bitter hatred of democracy that is revealed both by the U.S. Government – Hillary Clinton, others – and also by the diplomatic service." Chomsky refuses to take legal action against those who may have libeled him and prefers to counter libels through open letters in newspapers. One example of this approach is his response to an article by Emma Brockes in "The Guardian" at the end of October 2005, which alleged that he had denied the Srebrenica massacre in 1995. At issue was Chomsky's attitude to the writings of journalist Diana Johnstone on the subject. His complaint prompted "The Guardian" to publish an apologetic correction and to withdraw the article from the paper's website, which remains available on his own website.
Nick Cohen has criticised Chomsky for frequently making overly critical statements about Western governments, especially the US, and for allegedly refusing to retract his speculations when facts become available that disprove them.
Debates.
Chomsky has been known to defend vigorously and debate his views and opinions, in philosophy, linguistics (Linguistics Wars), and politics. He has had notable debates with Jean Piaget, Michel Foucault, William F. Buckley, Jr., Christopher Hitchens, George Lakoff, Richard Perle, Hilary Putnam, Willard Van Orman Quine, John Maynard Smith, and Alan Dershowitz, to name a few. "The Guardian" said of Chomsky's debating ability, "His boldness and clarity infuriates opponents—academe is crowded with critics who have made twerps of themselves taking him on." In response to his speaking style being criticized as boring, Chomsky said, "I'm a boring speaker and I like it that way. ... I doubt that people are attracted to whatever the persona is. ... People are interested in the issues, and they're interested in the issues because they are important." "We don't want to be swayed by superficial eloquence, by emotion and so on."
Personal life.
Chomsky endeavors to keep his family life strictly separate from his political activism and career, and considers himself "scrupulous at keeping my politics out of the classroom."
He is uninterested in appearances and the fame that his work has brought him. He also has little interest in modern art and music. He has been banned from entering Israel since 2010.
Chomsky is known for his "dry, laconic wit", although he has attracted controversy for labeling established political and academic figures with terms like "corrupt", "fascist", and "fraudulent". When asked if he is an atheist, Chomsky replied, "What is it that I'm supposed to not believe in? Until you can answer that question I can't tell you whether I'm an atheist."
Chomsky was married to Carol Doris Schatz (Chomsky) from 1949 until her death in 2008. They had three children together: Aviva, Diane and Harry. In 2014, Chomsky remarried to Valeria Wasserman.
Influence.
Chomsky's legacy is as both a "leader in the field" of linguistics and "a figure of enlightenment and inspiration" for political dissenters. Linguist John Lyons remarked that within a few decades of publication, Chomskyan linguistics had become "the most dynamic and influential" school of thought in the field.
Chomskyan models have been used as a theoretical basis in various fields of study. The Chomsky hierarchy is often taught in fundamental computer science courses as it confers insight into the various types of formal languages. This hierarchy can also be discussed in mathematical terms and has generated interest among mathematicians, particularly combinatorialists. Some arguments in evolutionary psychology are derived from his research results.
Chomsky's work in linguistics has had implications for modern psychology.
Nim Chimpsky, a chimpanzee who was the subject of a study in animal language acquisition at Columbia University, was named after Chomsky in reference to his view of language acquisition as a uniquely human ability. The 1984 Nobel Prize laureate in Medicine and Physiology, Niels Kaj Jerne, used Chomsky's generative model to explain the human immune system, equating "components of a generative grammar … with various features of protein structures". The title of Jerne's Stockholm Nobel Lecture was "The Generative Grammar of the Immune System". Computer scientist Donald Knuth read "Syntactic Structures" during his honeymoon and was influenced by it. "I must admit to taking a copy of Noam Chomsky's "Syntactic Structures" along with me on my honeymoon in 1961 ... Here was a marvelous thing: a mathematical theory of language in which I could use a computer programmer's intuition!"
Academic achievements, awards, and honors.
In early 1969, he delivered the John Locke Lectures at Oxford University; in January 1970, the Bertrand Russell Memorial Lecture at University of Cambridge; in 1972, the Nehru Memorial Lecture in New Delhi; in 1977, the Huizinga Lecture in Leiden; in 1988 the Massey Lectures at the University of Toronto, titled "Necessary Illusions: Thought Control in Democratic Societies"; in 1997, The Davie Memorial Lecture on Academic Freedom in Cape Town, in 2011, the Rickman Godlee Lecture at University College, London many others.
Chomsky has received many honorary degrees from universities around the world, including from the following:
He is a member of the American Academy of Arts and Sciences, the National Academy of Sciences, and the American Philosophical Society. In addition, he is a member of other professional and learned societies in the United States and abroad, and is a recipient of the Distinguished Scientific Contribution Award of the American Psychological Association, the Kyoto Prize in Basic Sciences, the Helmholtz Medal, the Dorothy Eldridge Peacemaker Award, the 1999 Benjamin Franklin Medal in Computer and Cognitive Science, and others. He is twice winner of The Orwell Award, granted by The National Council of Teachers of English for "Distinguished Contributions to Honesty and Clarity in Public Language" (in 1987 and 1989).
He is a member of the Serbian Academy of Sciences and Arts in Department of Social Sciences.
In 2004 Chomsky received the Carl-von-Ossietzky Prize from the city of Oldenburg (Germany) for his life work as political analyst and media critic. In 2005, Chomsky received an honorary fellowship from the Literary and Historical Society. In 2007, Chomsky received The Uppsala University (Sweden) Honorary Doctor's degree in commemoration of Carolus Linnaeus. In February 2008, he received the President's Medal from the Literary and Debating Society of the National University of Ireland, Galway. Since 2009 he is an honorary member of IAPTI.
In 2010, Chomsky received the Erich Fromm Prize in Stuttgart, Germany. In April 2010, Chomsky became the third scholar to receive the University of Wisconsin's A.E. Havens Center's Award for Lifetime Contribution to Critical Scholarship.
Chomsky has an Erdős number of four.
Chomsky was voted the leading living public intellectual in The 2005 Global Intellectuals Poll conducted by the British magazine "Prospect". He reacted, saying "I don't pay a lot of attention to polls". In a list compiled by the magazine "New Statesman" in 2006, he was voted seventh in the list of "Heroes of our time".
Actor Viggo Mortensen with avant-garde guitarist Buckethead dedicated their 2006 album, called "Pandemoniumfromamerica", to Chomsky.
On January 22, 2010, a special honorary concert for Chomsky was given at Kresge Auditorium at MIT. The concert, attended by Chomsky and dozens of his family and friends, featured music composed by Edward Manukyan and speeches by Chomsky's colleagues, including David Pesetsky of MIT and Gennaro Chierchia, head of the linguistics department at Harvard University.
In June 2011, Chomsky was awarded the Sydney Peace Prize, which cited his "...unfailing courage, critical analysis of power and promotion of human rights."
In 2011, Chomsky was inducted into IEEE Intelligent Systems' AI's Hall of Fame for the "significant contributions to the field of AI and intelligent systems".
In 2013, a newly described species of bee was named after him: "Megachile chomskyi".

</doc>
<doc id="21571" url="http://en.wikipedia.org/wiki?curid=21571" title="Nial">
Nial

Nial (from "Nested Interactive Array Language") is a high-level array programming language developed from about 1981 by Mike Jenkins of Queen's University, Kingston, Ontario, Canada.
Nial combines a functional programming notation for arrays based on Array Theory developed by Trenchard More with structured programming concepts for numeric, character and symbolic data.
It is most often used for prototyping and artificial intelligence.
Q'Nial.
In 1982, Jenkins formed a company (Nial Systems Ltd) to market the language and the Q'Nial implementation of Nial. As of 2014, the company website supports an Open Source project for the Q'Nial software with the binary and source available for download. Its license is derived from Artistic License 1.0, the only differences being the preamble, the definition of "Copyright Holder" (which is changed from "whoever is named in the copyright or copyrights for the package" to "NIAL Systems Limited"), and an instance of "whoever" (which is changed to "whomever").
Nial Concepts.
Nial uses a generalized and expressive Array Theory in its Version 4, but sacrificed some of the generality of functional model, and modified the Array Theory in the Version 6. Only Version 6 is available now.
Nial defines all its datatypes as nested rectangular arrays. ints, booleans, chars etc. are considered as a solitary array or an array containing a single member. Arrays themselves can contain other arrays to form arbitrarily deep structures. Nial also provides Records. They are defined as non-homogenous array structure.
Functions in Nial are called Operations. From Nial manual: "An operation is a functional object that is given an argument array and returns a result array. The process of executing an operation by giving it an argument value is called an operation call or an operation application."
Application of Operations.
Nial like other APL derived languages allow the unification of binary operators and operations. Thus the below notations have the same meaning.
Note: codice_1 is same as codice_2
binary operation.
 2 + 3 
 2 sum 3
in array notation.
 + [2,3]
 sum [2,3]
strand notation.
 + 2 3
 sum 2 3
grouped notation.
 + (2 3)
 sum (2 3)
Nial also uses transformers which are higher order functions. They use the argument operation to construct a new modified operation.
 twice is transformer f (f f) 
 twice rest [4, 5, 6, 7, 8] 
 |6 7 8
Atlas.
An atlas in Nial is an operation made up of an array of component operations. When an atlas is applied to a value, each element of the atlas is applied in turn to the value to provide an end result. This is used to provide point free (without-variables) style of definitions. It is also used by the transformers. In the below examples 'inner [+,*]' the list '[+,*]' is an atlas.
Examples.
Creating Arrays.
codice_3
Arrays can also be literal
codice_4
Shape gives the array dimensions and reshape can be used to reshape the dimensions.
codice_5
Computing Average.
Definitions are of the form '<name> is <expression>'
 average is / [sum, tally] 
 average Arr
 |7.
Computing Factorial.
 fact is recur [ 0 =, 1 first, pass, product, -1 +]
 fact 4
 |24
Reversing an array.
 rev is reshape [ shape, across [pass, pass, converse append ] ]
 rev [1, 2, 3, 4]
 |4 3 2 1
Generating Primes.
Contrast with [[APL programming language|APL]]
 primes is sublist [ each (2 = sum eachright (0 = mod) [pass,count]), pass ] rest count
 primes 10
 |2 3 5 7
Explanation.
 Checking the divisibility of A by B
 is_divisible is 0 = mod [A,B]
Defining is_prime filter
 is_prime is 2 = sum eachright is_divisible [pass,count]
Count generates an array [1..N] and pass is N (identity operation).
eachright applies is_divisible(pass,element) in each element of count-generated array. 
Thus this transforms the count-generated array into an array where numbers that can divide N are replaced by '1' and others by '0'. Hence if the number N is prime, sum [transformed array] must be 2 (itself and 1).
Now all that remains is to generate another array using count N, and filter all that are not prime.
 primes is sublist [each is_prime, pass] rest count
QuickSort.
link joins together its argument arrays
<br>sublist [A,B] returns a list of items of B chosen according to the list of booleans given in A, selecting those items of B where the corresponding item of A is true.
In a Fork [A,B,C] X the first A is a predicate, and if A(X) is true, then B(X) is returned else C(X) is returned.
Pass is an identity operation for arrays.
 quicksort is fork [ >= [1 first,tally],
 pass,
 link [
 quicksort sublist [ < [pass, first], pass ],
 sublist [ match [pass,first],pass ],
 quicksort sublist [ > [pass,first], pass ]
 ]
Using it.
 quicksort [5, 8, 7, 4, 3]
 |3 4 5 7 8
External links.
[[Category:Array programming languages]]

</doc>
<doc id="21572" url="http://en.wikipedia.org/wiki?curid=21572" title="Nag Hammadi">
Nag Hammadi

Nag Hammadi (Arabic: نجع حمادى‎, ]), is a city in Upper Egypt. Nag Hammadi was known as Chenoboskion (Greek: Χηνοβόσκιον) in classical antiquity, meaning "geese grazing grounds". It is located on the west bank of the Nile in the Qena Governorate, about 80 kilometres north-west of Luxor. 
It has a population of about 30,000, who are mostly farmers. Sugar and aluminium are produced in Nag Hammadi. Egyptalum is the largest aluminium producer in the Middle East. Wood particleboard is manufactured from sugar cane bagasse. 
The town of Nag Hammadi was established by Mahmoud Pasha Hammadi, who was a member of the Hammadi family in Sohag, Egypt. Mahmoud Pasha Hammadi was a major landholder in Sohag, and known for his strong opposition to the British occupation.
Mahmoud Pasha Hammadi created Nag Hammadi for the indigenous people from Sohag who were forced to abandon their homeland by the British occupation. In recognition of this, the new town was given the name "Hammadi".
Nag Hammadi Library.
Nag Hammadi is best known for being the site where local farmers found a sealed earthenware jar containing thirteen leather-bound papyrus codices, together with pages torn from another book, in December 1945. The mother of the farmers burned one of the books and parts of a second (including its cover). Thus twelve of these books (one missing its cover) and the loose pages survive. The writings in these codices, dating back to the 2nd century AD, comprised 52 mostly Gnostic tractates, were found in a single grave site.
The contents of the Coptic-bound codices were written in Coptic, though the works were probably all translations from Greek. The Nag Hammadi codices contain the only complete copy of the "Gospel of Thomas".
All the texts have been public since 1975, and are available online.
Nag Hammadi massacre.
The city was the site of the Nag Hammadi massacre in January 2010, wherein eight Coptic Christians were shot dead by three men. Nineteen Coptic Christians were attacked altogether.

</doc>
<doc id="21573" url="http://en.wikipedia.org/wiki?curid=21573" title="Niels Henrik Abel">
Niels Henrik Abel

Niels Henrik Abel (5 August 1802 – 6 April 1829) was a Norwegian mathematician who made pioneering contributions in a variety of fields. His most famous single result is the first complete proof demonstrating the impossibility of solving the general quintic equation in radicals. This question was one of the outstanding open problems of his day, and had been unresolved for 250 years. He was also an innovator in the field of elliptic functions, discoverer of Abelian functions. Despite his achievements, Abel was largely unrecognized during his lifetime; he made his discoveries while living in poverty and died at the age of 26.
Most of his work was done in six or seven years of his working life. Regarding Abel, the French mathematician Charles Hermite said: "Abel has left mathematicians enough to keep them busy for five hundred years." Another French mathematician, Adrien-Marie Legendre, said: "quelle tête celle du jeune Norvégien!" ("what a head the young Norwegian has!").
Life.
Early life.
Niels Henrik Abel was born in Nedstrand, Norway, as the second child of Søren Georg Abel and Anne Marie Simonsen. When he was born, the family was living at a rectory on Finnøy. Much suggests that Niels Henrik was born in the neighboring parish, as his parents were guests of the bailiff in Nedstrand in July / August of his year of birth.
Niels Henrik Abel's father, Søren Georg Abel, had a degree in theology and philosophy and served as pastor at Finnøy. Søren's father, Niels's grandfather, Hans Mathias Abel, was also a pastor, at Gjerstad near Risør. Søren had spent his childhood at Gjerstad, and had also served as chaplain there; and after his father's death in 1804, Søren was appointed pastor at Gjerstad and the family moved there.
Anne Marie Simonsen was from Risør; her father, Niels Henrik Saxild Simonsen, was a tradesman and merchant ship-owner, and said to be the richest person in Risør. Anne Marie had grown up with two stepmothers, in relatively luxurious surroundings. At Gjerstad rectory, she enjoyed arranging balls and social gatherings. Much suggests she was early on an alcoholic and took little interest in the upbringing of the children.
Niels Henrik and his brothers were given their schooling by their father, with handwritten books to read. Interestingly, an addition table in a book of mathematics reads: 1+0=0.
Cathedral School and Royal Frederick University.
With Norwegian independence and the first election held in Norway, in 1814, Søren Abel was elected as a representative to the Storting. Meetings of the Storting were held until 1866 in the main hall of the Cathedral School in Christiania (now known as Oslo). Almost certainly, this is how he came into contact with the school, and he decided that his eldest son, Hans Mathias, should start there the following year. However, when the time for his departure approached, Hans was so saddened and depressed over having to leave home that his father did not dare send him away. He decided to send Niels instead.
In 1815, Niels Abel entered the Cathedral School at the age of 13. His elder brother Hans joined him there a year later. They shared rooms and had classes together. Hans got better grades than Niels; however, a new mathematics teacher, Bernt Michael Holmboe, was appointed in 1818. He gave the students mathematical tasks to do at home. He saw Niels Henrik's talent in mathematics, and encouraged him to study the subject to an advanced level. He even gave Niels private lessons after school.
In 1818, Søren Abel had a public theological argument with the theologian Stener Johannes Stenersen regarding his catechism from 1806. The argument was well covered in press. Søren was given the nickname "Abel Treating" "(Norwegian: "Abel Spandabel")". Niels' reaction to the quarrel was said to have been "excessive gaiety". At the same time, Søren also almost faced impeachment after insulting Carsten Anker, the host of the Norwegian Constituent Assembly; and in September 1818 he returned to Gjerstad with his political career in ruins. He began drinking heavily and died only two years later, in 1820, aged 48.
Bernt Michael Holmboe supported Niels Henrik Abel with a scholarship to remain at the school and raised money from his friends to enable him to study at the Royal Frederick University.
When Abel entered the university in 1821, he was already the most knowledgeable mathematician in Norway. Holmboe had nothing more he could teach him and Abel had studied all the latest mathematical literature in the university library. During this time Abel started working on the quintic equation in radicals. Abel initially thought he had found the solution to the quintic equation in radicals in 1821. Mathematicians had been looking for a solution on this problem for over 250 years. The two professors in Christiania, Søren Rasmussen and Christopher Hansteen, found no errors in Abel's formulas, and sent the work on to the leading mathematician in the Nordic countries, Professor Ferdinand Degen in Copenhagen. He also found no faults, but still doubted that the solution, which so many outstanding mathematicians had sought for so long, could now really have been found by an unknown student in far-off Christiania. Degen noted, however, Abel's unusually sharp mind, and believed that such a talented young man should not waste his abilities on such a "sterile object" as the fifth degree equation, but rather on elliptic functions and transcendence; for then, writes Degen, he will "discover Magellanian thoroughfares to large portions of a vast analytical ocean". Degen asked Abel to give a numerical example of his method and, while trying to provide an example, Abel discovered a mistake in his paper.
Abel graduated in 1822. His performance was average, except in mathematics which was exceptionally high.
Career.
After he graduated, professors from university supported Abel financially, and Professor Christopher Hansteen let him live in a room in the attic of his home. Abel would later view Ms. Hansteen as his second mother. While living here, Abel helped his younger brother, Peder Abel, through examen artium. He also helped his sister Elisabeth to find work in the town.
In early 1823, Niels Abel published his first article in "Magazin for Naturvidenskaberne", Norway's first scientific journal, which had been co-founded by Professor Hansteen. Abel published several articles, but the journal soon realized that this was not material for the common reader. In 1823, Abel also wrote a paper in French. It was "a general representation of the possibility to integrate all differential formulas" ("Norwegian: en alminnelig Fremstilling af Muligheten at integrere alle mulige Differential-Formler)". He applied for funds at the university to publish it. However the work was lost, while being reviewed, never to be found thereafter.
In mid-1823, Professor Rasmussen gave Abel a gift of 100 speciedaler so he could travel to Copenhagen and visit Ferdinand Degen and other mathematicians there. While in Copenhagen, Abel did some work on Fermat's Last Theorem. Abel's uncle, Peder Mandrup Tuxen, lived at the naval base in Christianshavn, Copenhagen, and at a ball there Niels Abel met Christine Kemp, his future fiancée. In 1824, Christine moved to Son, Norway to work as a governess and the couple got engaged over Christmas.
After returning from Copenhagen, Abel applied for a government scholarship in order to visit top mathematicians in Germany and France, but he was instead granted 200 speciedaler yearly for two years, to stay in Cristiania and study German and French. In the next two years, he was promised a scholarship of 600 speciedaler yearly and he would then be permitted to travel abroad. While studying these languages, Abel published his first notable work in 1824, "Mémoire sur les équations algébriques où on démontre l'impossibilité de la résolution de l'équation générale du cinquième degré" (Memoir on algebraic equations, in which the impossibility of solving the general equation of the fifth degree is proven). For, in 1823, Abel had at last proved the impossibility of solving the quintic equation in radicals (now referred to as the Abel–Ruffini theorem). However, this paper was in an abstruse and difficult form, in part because he had restricted himself to only six pages, in order to save money on printing. A more detailed proof was published in 1826 in the first volume of "Crelle's Journal".
In 1825, Abel wrote a personal letter to King Carl Johan of Norway/Sweden requesting permission to travel abroad. He was granted this permission, and in September 1825 he left Christiania together with four friends from university (Christian P.B Boeck, Balthazar M. Keilhau, Nicolay B. Møller and Otto Tank). These four friends of Abel were traveling to Berlin and to the Alps to study geology. Abel wanted to follow them to Copenhagen and from there make his way to Göttingen. The terms for his scholarship stipulated that he was to visit Gauss in Göttingen and then continue to Paris. However, when he got as far as Copenhagen he changed his plans. He wanted to follow his friends to Berlin instead, intending to visit Göttingen and Paris afterwards.
On the way, he visited the astronomer Heinrich Christian Schumacher in Altona, now a district of Hamburg. He then spent four months in Berlin, where he became well acquainted with August Leopold Crelle, who was then about to publish his mathematical journal, Journal für die reine und angewandte Mathematik. This project was warmly encouraged by Abel, who contributed much to the success of the venture. Abel contributed seven articles to it in its first year.
From Berlin Abel also followed his friends to the Alps. He went to Leipzig and Freiberg to visit Georg Amadeus Carl Friedrich Naumann and his brother the mathematician August Naumann. In Freiberg Abel did research in the theory of functions, particularly, elliptic, hyperelliptic, and a new class now known as abelian functions.
From Freiberg they went on to Dresden, Prague, Vienna, Trieste, Venice, Verona, Bolzano, Innsbruck, Luzern and Basel. From July 1826 Abel traveled on his own from Basel to Paris. Abel had sent most of his work to Berlin to be published in Crelle's Journal, but he had saved what he regarded as his most important work for the French Academy of Sciences, a theorem on addition of algebraic differentials. With the help of Johan Gørbitz he found an apartment in Paris and continued his work on the theorem. He finished in October 1826, and submitted it to the academy. It was to be reviewed by Augustin-Louis Cauchy. Abel's work was scarcely known in Paris, and his modesty restrained him from proclaiming his research. The theorem was put aside and forgotten until his death.
Abel's limited finances finally compelled him to abandon his tour in January 1827. He returned to Berlin, and was offered a position as editor of Crelle's Journal, but opted out. By May 1827 he was back in Norway. His tour abroad was viewed as a failure. He had not visited Gauss in Göttingen and he had not published anything in Paris. His scholarship was therefore not renewed and he had to take up a private loan in Norges Bank of 200 spesidaler. He never repaid this loan. He also started tutoring. He continued to send most of his work to Crelle's Journal. But in mid-1828 he published, in rivalry with Carl Jacobi, an important work on elliptic functions in Astronomische Nachrichten in Altona.
Death.
While in Paris, Abel contracted tuberculosis. During the Christmas of 1828, he traveled by sled to Froland to visit his fiancée. He became seriously ill on the journey and, although a temporary improvement allowed the couple to enjoy the holiday together, he died relatively soon after on 6 April 1829, just two days before a letter arrived from August Crelle. Crelle had been searching for a new job for Abel in Berlin, and had actually managed to have him appointed as a professor at the University of Berlin. Crelle wrote to Abel to tell him the good news, but it came too late.
Contributions to mathematics.
Abel showed that there is no general algebraic solution for the roots of a quintic equation, or any general polynomial equation of degree greater than four, in terms of explicit algebraic operations. To do this, he invented (independently of Galois) an extremely important branch of mathematics known as group theory, which is invaluable not only in many areas of mathematics, but for much of physics as well. Abel sent a paper on the unsolvability of the quintic equation to Carl Friedrich Gauss, who proceeded to discard without a glance what he believed to be the worthless work of a crank. Before Abel solved the problem, it had gone unsolved for over 250 years. He originally thought he had found a solution in 1821, which turned out to be wrong.
As a 16 year old Abel gave a proof of the binomial theorem valid for all numbers, extending Euler's result which had held only for rationals. Abel wrote a fundamental work on the theory of elliptic integrals, containing the foundations of the theory of elliptic functions.
While travelling to Paris he published a paper revealing the double periodicity of elliptic functions, which Adrien-Marie Legendre later described to Augustin-Louis Cauchy as "a monument more lasting than bronze" (borrowing a famous sentence by the Roman poet Horatius). The paper was however, misplaced by Cauchy.
While abroad Abel had sent most of his work to Berlin to be published in the Crelle's Journal, but he had saved what he regarded as his most important work for the French Academy of Sciences, a theorem on addition of algebraic differentials. The theorem was put aside and forgotten until his death.
While in Freiberg Abel did research in the theory of functions, particularly, elliptic, hyperelliptic, and a new class now known as abelian functions.
In 1823 Abel wrote a paper titled "a general representation of the possibility to integrate all differential formulas" ("Norwegian: en alminnelig Fremstilling af Muligheten at integrere alle mulige Differential-Formler)". He applied for funds at the university to publish it. However the work was lost, while being reviewed, never to be found thereafter.
Abel said famously of Carl Friedrich Gauss's writing style, "He is like the fox, who effaces his tracks in the sand with his tail."
Legacy.
Under Abel's guidance, the prevailing obscurities of analysis began to be cleared, new fields were entered upon and the study of functions so advanced as to provide mathematicians with numerous ramifications along which progress could be made. His works, the greater part of which originally appeared in "Crelle's Journal", were edited by Bernt Michael Holmboe and published in 1839 by the Norwegian government, and a more complete edition by Ludwig Sylow and Sophus Lie was published in 1881. The adjective "abelian", derived from his name, has become so commonplace in mathematical writing that it is conventionally spelled with a lower-case initial "a" (e.g., abelian group, abelian category, and abelian variety).
On 6 April 1929, four Norwegian stamps were issued for the centenary of Abel's death. His portrait appears on the 500-kroner banknote (version V) issued during 1978–1985. On 5 June 2002, four Norwegian stamps were issued in honour of Abel two months before the bicentenary of his birth. There is also a 20-kroner coin issued by Norway in his honour. A statue of Abel stands in Oslo, and crater Abel on the Moon was named after him. In 2002, the Abel Prize was established in his memory.
Mathematician Felix Klein wrote about Abel:
But I would not like to part from this ideal type of researcher, such as has seldom appeared in the history of mathematics, without evoking a figure from another sphere who, in spite of his totally different field, still seems related. Thus, although Abel shared with many mathematicians a complete lack of musical talent, I will not sound absurd if I compare his kind of productivity and his personality with Mozart's. Thus one might erect a monument to this divinely inspired mathematician like the one to Mozart in Vienna: simple and unassuming he stands there listening, while graceful angels float about, playfully bringing him inspiration from another world.
Instead, I must mention the very different type of memorial that was in fact erected to Abel in Christiania and which must greatly disappoint anyone familiar with his nature. On a towering, steep block of granite a youthful athlete of the Byronic type steps over two greyish sacrificial victims, his direction toward the heavens. If needed be, one might take the hero to be a symbol of the human spirit, but one ponders the deeper significance of the two monsters in vain. Are they the conquered quintic equations or elliptic functions? Or the sorrows and cares of his everyday life? The pedestal of the monument bears, in immense letters, the inscription ABEL.

</doc>
<doc id="21574" url="http://en.wikipedia.org/wiki?curid=21574" title="November 19">
November 19

November 19 is the day of the year in the Gregorian calendar.

</doc>
<doc id="21575" url="http://en.wikipedia.org/wiki?curid=21575" title="November 20">
November 20

November 20 is the day of the year in the Gregorian calendar.

</doc>
<doc id="21576" url="http://en.wikipedia.org/wiki?curid=21576" title="November 21">
November 21

November 21 is the day of the year in the Gregorian calendar.

</doc>
<doc id="21577" url="http://en.wikipedia.org/wiki?curid=21577" title="November 30">
November 30

November 30 is the day of the year in the Gregorian calendar.

</doc>
<doc id="21578" url="http://en.wikipedia.org/wiki?curid=21578" title="November 29">
November 29

November 29 is the day of the year in the Gregorian calendar.

</doc>
<doc id="21579" url="http://en.wikipedia.org/wiki?curid=21579" title="November 28">
November 28

November 28 is the day of the year in the Gregorian calendar.

</doc>
<doc id="21580" url="http://en.wikipedia.org/wiki?curid=21580" title="November 25">
November 25

November 25 is the day of the year in the Gregorian calendar.

</doc>
<doc id="21581" url="http://en.wikipedia.org/wiki?curid=21581" title="November 26">
November 26

November 26 is the day of the year in the Gregorian calendar.

</doc>
<doc id="21582" url="http://en.wikipedia.org/wiki?curid=21582" title="Nicolaus von Amsdorf">
Nicolaus von Amsdorf

Nicolaus von Amsdorf (3 December 1483 – 14 May 1565) was a German theologian and Protestant reformer.
Biography.
He was born in Torgau, on the Elbe.
He was educated at Leipzig, and then at Wittenberg, where he was one of the first who matriculated (1502) in the recently founded university. He soon obtained various academic honours, and became professor of theology in 1511.
Like Andreas Karlstadt, he was at first a leading exponent of the older type of scholastic theology, but under the influence of Luther abandoned his Aristotelian positions for a theology based on the Augustinian doctrine of grace. Throughout his life he remained one of Luther's most determined supporters; he was with him at the Leipzig conference (1519), and the Diet of Worms (1521); and was privy to the secret of his Wartburg seclusion. He assisted the first efforts of the Reformation at Magdeburg (1524), at Goslar (1531) and at Einbeck (1534); took an active part in the debates at Schmalkalden (1537), where he defended the use of the sacrament by the unbelieving; and (1539) spoke out strongly against the bigamy of the Landgrave of Hesse.
After the death of Philip of the Palatinate, bishop of Naumburg-Zeitz, he was installed there on 20 January 1542, though in opposition to the chapter, by the Prince-elector of Saxony and Luther. His position was a painful one, and he longed to get back to Magdeburg, but was persuaded by Luther to stay. After Luther's death (1546) and the Battle of Mühlberg (1547) he had to yield to his rival, Julius von Pflug, and retire to the protection of the young duke of Weimar. Here he took part in founding Jena University (1558); opposed the "Augsburg Interim" (1548); superintended the publication of the Jena edition of Luther's works; and debated on the freedom of the will, original sin, and, more noticeably, on the Christian value of good works, in regard to which he held that they were not only useless, but prejudicial. He urged the separation of the High Lutheran party from Melanchthon (1557), got the Saxon dukes to oppose the Frankfurt Recess (1558) and continued to fight for the purity of Lutheran doctrine.
He died at Eisenach in 1565, and was buried in the church of St. Georg there, where his effigy shows a well-knit frame and sharp-cut features.
Assessment.
He was a man of strong will, of great aptitude for controversy, and considerable learning, and thus exercised a decided influence on the Reformation. Many letters and other short productions of his pen are extant in manuscript, especially five thick volumes of Amsdorfiana, in the Weimar library. They are a valuable source for our knowledge of Luther. A small sect, which adopted his opinion on good works, was called after him; but it is now of mere historical interest.

</doc>
<doc id="21583" url="http://en.wikipedia.org/wiki?curid=21583" title="Nationality">
Nationality

Nationality is the legal relationship between a person and a state. Nationality affords the state jurisdiction over the person and affords the person the protection of the state. What these rights and duties are vary from state to state.
By custom and international conventions, it is the right of each state to determine who its nationals are. Such determinations are part of nationality law. In some cases, determinations of nationality are also governed by public international law—for example, by treaties on statelessness and the European Convention on Nationality.
Nationality differs technically and legally from citizenship, which is a different legal relationship between a person and a country. The noun "national" can include both citizens and non-citizens. The most common distinguishing feature of citizenship is that citizens have the right to participate in the political life of the state, such as by voting or standing for election. However, in most modern countries all nationals are citizens of the state, and full citizens are always nationals of the state.
In English and some other languages, the word "nationality" is sometimes used to refer to an ethnic group (a group of people who share a common ethnic identity, language, culture, descent, history, and so forth). This meaning of nationality is not defined by political borders or passport ownership and includes nations that lack an independent state (such as the Scots, Welsh, English, Basques, Kurds, Kabyles, Tamils, Hmong, Inuit and Māori).
Individuals may also be considered nationals of groups with autonomous status which have ceded some power to a larger government.
International law.
In international law, nationality is the status or relationship that gives a nation the right to protect a person from other nations. Diplomatic and consular protection are dependent upon this relationship between the person and the state. A person's status as being the national of a country is used to resolve the conflict of laws.
Nationality is also the status that allows a nation to grant rights to the subject and to impose obligations upon the subject. In most cases, no rights or obligations are automatically attached to this status, although the status is a necessary precondition for any rights and obligations created by the state.
Within the broad limits imposed by few treaties and international law, states may freely define who their nationals are and are not. However, since the "Nottebohm" case, other states are only required to respect their claim to protect an alleged national if the nationality is based on a true social bond. In the case of dual nationality, states may determine the most effective nationality for a person, to determine which state's laws are most relevant. There are also limits on removing a person's status as a national. Article 15 of the Universal Declaration of Human Rights states that "Everyone has the right to a nationality," and "No one shall be arbitrarily deprived of his nationality nor denied the right to change his nationality."
National law.
Nationals normally have the right to enter or return to the country they belong to. Passports are issued to nationals of a state, rather than only to citizens, because the passport is the travel document used to enter the country. However, nationals may not have the right of abode (the right to live permanently) in the countries that grant them passports.
Nationality versus citizenship.
Nationality is legally a distinct concept from citizenship. Conceptually, citizenship is focused on the internal political life of the state, and nationality is a matter of international dealings.
In the modern era, the concept of full citizenship encompasses not only active political rights, but full civil rights and social rights. Nationality is a necessary but not sufficient condition to exercise full political rights within a state or other polity. Nationality is required for full citizenship, and some people have nationality without having full citizenship. A person who is denied full rights is commonly called a second-class citizen.
Historically, the most significant difference between a national and a citizen is that the citizen has the right to vote for elected officials, and to be elected. This distinction between full citizenship and other, lesser relationships goes back to antiquity. Until the 19th and 20th centuries, it was typical for only a small percentage of people who belonged to a city or state to be full citizens. In the past, most people were excluded from citizenship on the basis of gender, socioeconomic class, ethnicity, religion, and other factors. However, they held a legal relationship with their government akin to the modern concept of nationality.
United States nationality law defines some persons born in U.S. outlying possessions as U.S. nationals but not citizens. British nationality law defines six classes of British national, among which "British citizen" is one class (and the only one having the right of abode in the United Kingdom). Similarly, in the Republic of China, commonly known as Taiwan, the status of national without household registration applies to people who have Republic of China nationality, but do not have an automatic entitlement to enter or reside in the Taiwan Area, and do not qualify for civic rights and duties there. Under the nationality laws of Mexico, Colombia, and some other Latin American countries, nationals do not become citizens until they turn 18.
Nationality versus ethnicity.
Nationality is sometimes used simply as an alternate word for ethnicity or national origin, just as some people assume that citizenship and nationality are identical. In some countries, the cognate word for "nationality" in local language may be understood as a synonym of ethnicity, or as an identifier of cultural and family-based self-determination, rather than on relations with a state or current government. For example, some Kurds say that they have Kurdish nationality, even though there is no Kurdish sovereign state at this time in history.
In the context of former Soviet Union and former Yugoslavia, "nationality" is often used as translation of the Russian "nacional'nost' " and Serbo-Croatian "narodnost", which were the terms used in the Soviet Union for ethnic groups and local affiliations within the member states. More than 100 such groups were formally recognized. Membership in these groups was identified on internal passports. In the early years of the Soviet Union's existence, ethnicity was usually determined by the person's native language, and sometimes through religion or cultural factors, such as clothing. Children born after the revolution were categorized according to their parents' recorded ethnicities. Many of these ethnic groups are still recognized by the modern Russian Federation.
Similarly, the term "nationalities of China" refers to ethnic and cultural groups in China. Spain is one nation, made out by nationalities, which are not politically recognized as nations (state), but can be considered smaller nations within the Spanish nation. Spanish law recognises the autonomous communities of Andalusia, Aragon, Balearic Islands, Canary Islands, Catalonia, Valencia, Galicia and the Basque Country as "nationalities" ("nacionalidades").
Nationality versus national identity.
National identity is a person's subjective sense of belonging to one state or to one nation. A person may be a national of a state, in the sense of having a formal legal relationship with it, without subjectively or emotionally feeling a part of that state. Conversely, a person may feel that he belongs to one state without having any legal relationship to it. For example, children who were brought to the U.S. illegally when quite young and grow up there in ignorance of their immigration status often have a national identity of feeling American, despite legally being nationals of a different country.
Dual nationality.
Dual nationality is when a single person has a formal relationship with two separate, sovereign states. This might occur, for example, if a person's parents are nationals of separate countries, and the mother's country claims all offspring of the mother's as their own nationals, but the father's country claims all offspring of the father's.
Nationality, with its historical origins in allegiance to a sovereign monarch, was seen originally as a permanent, inherent, unchangeable condition, and later, when a change of allegiance was permitted, as a strictly exclusive relationship, so that becoming a national of one state required rejecting the previous state.
Dual nationality was considered a problem that caused conflict between states and sometimes imposed mutually exclusive requirements on affected people, such as simultaneously serving in two countries' military forces. Through the middle of the 20th century, many international agreements were focused on reducing the possibility of dual nationality. Since then, many accords recognizing and regulating dual nationality have been formed.
Statelessness.
Statelessness is an international problem in which an individual has no formal or protective relationship with any state. This might occur, for example, if a person's parents are nationals of separate countries, and the mother's country rejects all offspring of mothers married to foreign fathers, but the father's country rejects all offspring born to foreign mothers. Although this person may have an emotional national identity, he or she may not legally be the national of any state.

</doc>
<doc id="21585" url="http://en.wikipedia.org/wiki?curid=21585" title="Nereus">
Nereus

In Greek mythology, Nereus (; Greek: Νηρεύς) was the eldest son of Pontus (the Sea) and Gaia (the Earth), who with Doris fathered the Nereids and Nerites, with whom Nereus lived in the Aegean Sea. 
Etymology.
R. S. P. Beekes suggests a Pre-Greek origin.
Ancient literature.
In the "Iliad" the Old Man of the Sea is the father of Nereids, though Nereus is not directly named. He was never more manifestly the Old Man of the Sea than when he was described, like Proteus, as a shapeshifter with the power of prophecy, who would aid heroes such as Heracles who managed to catch him even as he changed shapes. Nereus and Proteus (the "first") seem to be two manifestations of the god of the sea who was supplanted by Poseidon when Zeus overthrew Cronus. 
The earliest poet to link Nereus with the labours of Heracles was Pherekydes, according to a "scholion" on Apollonius of Rhodes.
During the course of the 5th century BC, Nereus was gradually replaced by Triton, who does not appear in Homer, in the imagery of the struggle between Heracles and the sea-god who had to be restrained in order to deliver his information that was employed by the vase-painters, independent of any literary testimony.
In a late appearance, according to a fragmentary papyrus, Alexander the Great paused at the Syrian seashore before the climacteric battle of Issus (333 BC), and resorted to prayers, "calling on Thetis, Nereus and the Nereids, nymphs of the sea, and invoking Poseidon the sea-god, for whom he ordered a four-horse chariot to be cast into the waves."
Nereus was known for his truthfulness and virtue:
But Pontos, the great sea, was father of truthful Nereus who tells no lies, eldest of his sons. They call him the Old Gentleman because he is trustworthy, and gentle, and never forgetful of what is right, but the thoughts of his mind are mild and righteous.
The Attic vase-painters showed the draped torso of Nereus issuing from a long coiling scaly fishlike tail. Bearded Nereus generally wields a staff of authority. He was also shown in scenes depicting the flight of the Nereides as Peleus wrestled their sister Thetis.
In Aelian's natural history, written in the early third century CE, Nereus was also the father of a watery consort of Aphrodite named Nerites who was transformed into "a shellfish with a spiral shell, small in size but of surpassing beauty."
Nereus was father to Thetis, one of the Nereids, who in turn was mother to the great Greek hero Achilles, and Amphitrite, who married Poseidon.
Modern usage.
The largest Mediterranean underwater sea cave yet found, lying northwest of Sardinia, was named by the discoverers, the Nereo Cave, in honor of this mythological figure.
Also, the deepest-diving underwater ROV, which recently set a record for exploring the Challenger Deep of the Mariana Trench, is named after this figure. It was reported lost May 9, 2014, during a six-mile dive to the Kermadec Trench. 
In "The Secrets of the Immortal Nicholas Flamel", Nereus appears as an Elder in Book 3 of the series, . In it he confronts and battles Perenelle Flamel in an effort to capture and subdue her, thereby making her his wife. He is described as being a man holding a trident from above the waist and below being an octopus. Perenelle ends up defeating him and his daughters, the Nereids, who appear as sharp toothed monsters.
In "Percy Jackson and the Titan's Curse", Nereus appears as a homeless old man in some port in San Francisco who is described by Percy as 'Santa's evil twin'. He has that smelly ocean stench that differs him from the other homeless. He changes his shape as Percy clings on him in order to get answers. Despite of being a sea-related Ancient Greek creature, he apparently doesn't know the differences between a demigod of Poseidon and other gods.
He later appears briefly in "The Son of Neptune", in which he recognizes Jackson in San Francisco, four years after "The Titan's Curse".
In Disney's "Hercules" cartoon series, Nereus makes occasional appearances. As in the myth, he is a grouchy old man who can transform into various monsters and creatures, and Hercules at one point has to fight him in some of his forms to gain information.
In the T.V. series "Stargate SG-1", a minor Goa'uld was named "Nerus". He was a scientist and inventor of technologies. He was the one who while working for Ba'al (Leader of the Goa'uld), made the stargates all dial up simultaneously during the battle with the Replicators. Nereus later tricked General Landry into aiding the Ori by claiming that they should throw all their firepower at an Ori beachhead in the Milky Way.
In computer science, Nereus is also the name of a formal language designed to define abstract data types.
In "EVE Online", Nereus is an industrial transport ship, known to be fast and reliable. Referring to the mythological shape-shifting ability of Nereus, the ship provides a high level of customization, allowing the pilot to adjust the ship to meet his or her needs.

</doc>
<doc id="21586" url="http://en.wikipedia.org/wiki?curid=21586" title="Nereid">
Nereid

In Greek mythology, the Nereids ( ; Greek: Νηρηΐδες, sg. Νηρηΐς) are sea nymphs (female spirits of sea waters), the fifty daughters of Nereus and Doris, sisters to Nerites. They were distinct from the Sirens. They often accompany Poseidon, the god of the sea, and can be friendly and helpful to sailors fighting perilous storms.
Mythology.
Nereids are particularly associated with the Aegean Sea, where they dwelt with their father in the depths within a silvery cave. The most notable of them are Thetis, wife of Peleus and mother of Achilles; Amphitrite, wife of Poseidon; and Galatea, lover of the Cyclops Polyphemus.
In Homer's "Iliad" XVIII, when Thetis cries out in sympathy for the grief of Achilles for the slain Patroclus, her sisters appear. The Nereid Opis is mentioned in Virgil's "Aeneid". She is called on by the goddess Diana to avenge the death of the Amazon-like female warrior Camilla. Diana gives Opis magical weapons with which to take revenge on Camilla's killer, the Etruscan . Opis sees and laments Camilla's death and shoots Arruns in revenge as directed by Diana.
Modern use.
In modern Greek folklore, the term "nereid" (νεράϊδα, "neráïda") has come to be used for all nymphs, or fairies, or mermaids, not merely nymphs of the sea.
The Nereids are the namesake of one of the moons of the planet Neptune.
Names.
"This list is correlated from four sources: Homer's "Iliad", Hesiod's "Theogony", the "Bibliotheca", and Hyginus. Because of this the total number of names goes beyond fifty."

</doc>
<doc id="21587" url="http://en.wikipedia.org/wiki?curid=21587" title="Nemesis">
Nemesis

Nemesis may refer to:

</doc>
<doc id="21588" url="http://en.wikipedia.org/wiki?curid=21588" title="Nereid (moon)">
Nereid (moon)

Nereid is the third-largest moon of Neptune. It has a highly eccentric orbit. It was the second moon of Neptune to be discovered, by Gerard Kuiper in 1949.
Discovery and naming.
Nereid was discovered on May 1, 1949, by Gerard P. Kuiper, on photographic plates taken with the 82-inch telescope at the McDonald Observatory. He proposed the name in the report of his discovery. It is named after the Nereids, sea-nymphs of Greek mythology and attendants of the god Neptune. It was the second and last moon of Neptune to be discovered before the arrival of Voyager 2 (not counting a single observation of an occultation by Larissa in 1981).
Orbit and rotation.
Nereid orbits Neptune in the prograde direction at an average distance of 5513400 km, but its high eccentricity of 0.7507 takes it as close as 1372000 km and as far as 9655000 km.
The unusual orbit suggests that it may be either a captured asteroid or Kuiper belt object, or that it was an inner moon in the past and was perturbed during the capture of Neptune's largest moon Triton.
In 1991, a rotation period of Nereid of about 13.6 hours was determined by an analysis of its light curve. In 2003, another rotation period of about 11.52 ± 0.14 hours was measured. However, this determination was later disputed. Other researchers have so far failed to detect any periodic modulation in Nereid's light curve.
Physical characteristics.
Nereid is Neptune's third-largest satellite and has an average radius of about 170 km. It is rather large for an irregular satellite. The shape of Nereid is not known.
Since 1987 some photometric observations of Nereid have detected large (by ~1 of magnitude) variations of it brightness, which can happen over years and months, but sometimes even over a few days. They persist even after a correction for distance and phase effects. On the other hand, not all astronomers who have observed Nereid have noticed such variations. This means that they may be quite chaotic. As of 2010 there is no credible explanation of the variations, but, if they exist, they are likely related to the rotation of Nereid. This moon due to its highly elliptical orbit can be either in the state of forced precession or even chaotic rotation (like Hyperion). In any case its rotation should be rather irregular.
Spectrally Nereid appears neutral in colour and water ice has been detected on its surface. Its spectrum appears to be intermediate between Uranus's moons Titania and Umbriel, which suggests that Nereid's surface is composed of a mixture of water ice and some spectrally neutral material. The spectrum is markedly different from the outer-Solar-System minor planets, centaurs Pholus, Chiron and Chariklo, suggesting that Nereid formed around Neptune rather than being a captured body.
Halimede, which has similar colours, may be a fragment of Nereid that was broken off during a collision.
Exploration.
The only spacecraft to visit Nereid is Voyager 2, which passed it at a distance of 4700000 km between April 20 and August 19, 1989. Voyager 2 obtained 83 images of the moon with observation accuracies of 70 km to 800 km. Prior to Voyager 2's arrival, observations of Nereid had been limited to ground-based observations that could only establish its intrinsic brightness and orbital elements. Although the images obtained by the space probe did not have enough resolution to allow surface features to be distinguished, Voyager 2 was able to measure the size of Nereid and did find that it was grey in colour and had a higher albedo than Neptune's other small satellites.
In fiction.
In the Larry Niven book "Ringworld", Nereid is described as having been leased by the outsiders "half a millennium ago". The protagonist, Louis Wu, speculates that the outsiders evolved on a gas giant moon similar to Nereid.
References.
 at WebCite.
</ref>

</doc>
<doc id="21592" url="http://en.wikipedia.org/wiki?curid=21592" title="Netball">
Netball

Netball is a ball sport played by two teams of seven players. Its development, derived from early versions of basketball, began in England in the 1890s. By 1960, international playing rules had been standardised for the game, and the International Federation of Netball and Women's Basketball (later renamed the International Netball Federation (INF)) was formed. As of 2011, the INF comprises more than 60 national teams organized into five global regions.
Games are played on a rectangular court with raised goal rings at each end. Each team attempts to score goals by passing a ball down the court and shooting it through its goal ring. Players are assigned specific positions, which define their roles within the team and restrict their movement to certain areas of the court. During general play, a player with the ball can hold on to it for only three seconds before shooting for a goal or passing to another player. The winning team is the one that scores the most goals. Netball games are 60 minutes long. Variations have been developed to increase the game's pace and appeal to a wider audience.
Netball is most popular in Commonwealth nations, specifically in schools, and is predominantly played by women. According to the INF, netball is played by more than 20 million people in more than 80 countries. Major transnational competitions take place, including the Netball Superleague in Great Britain and the ANZ Championship in Australia and New Zealand. Three major competitions take place internationally: the quadrennial World Netball Championships, the Commonwealth Games, and the yearly World Netball Series. In 1995, netball became an International Olympic Committee recognised sport, but it has not been played at the Olympics.
History.
Netball emerged from early versions of basketball and evolved into its own sport as the number of women participating in sports increased. Basketball was invented in 1891 by James Naismith in the United States. The game was initially played indoors between two teams of nine players, using an association football ball that was thrown into closed-end peach baskets. Naismith's game spread quickly across the United States and variations of the rules soon emerged. Physical Education instructor Senda Berenson developed modified rules for women in 1892; these eventually gave rise to women's basketball. Around this time separate intercollegiate rules were developed for men and women. The various basketball rules converged into a universal set in the United States.
Martina Bergman-Österberg introduced a version of basketball in 1893 to her female students at the Physical Training College in Hampstead, London. The rules of the game were modified at the college over several years: the game moved outdoors and was played on grass; the baskets were replaced by rings that had nets; and in 1897 and 1899, rules from women's basketball in the United States were incorporated. Madame Österberg's new sport acquired the name "net ball". The first codified rules of netball were published in 1901 by the Ling Association, later the Physical Education Association of the United Kingdom. From England, netball spread to other countries in the British Empire. Variations of the rules and even names for the sport arose in different areas: "women's (outdoor) basketball" arrived in Australia around 1900 and in New Zealand from 1906, while "netball" was being played in Jamaican schools by 1909.
From the start, it was considered socially appropriate for women to play netball; netball's restricted movement appealed to contemporary notions of women's participation in sports, and the sport was distinct from potential rival male sports. Netball became a popular women's sport in countries where it was introduced and spread rapidly through school systems. School leagues and domestic competitions emerged during the first half of the 20th century, and in 1924 the first national governing body was established in New Zealand. International competition was initially hampered by a lack of funds and varying rules in different countries. Australia hosted New Zealand in the first international game of netball in Melbourne on 20 August 1938; Australia won 40–11. Efforts began in 1957 to standardise netball rules globally: by 1960 international playing rules had been standardised, and the International Federation of Netball and Women's Basketball, later the International Netball Federation (INF), was formed to administer the sport worldwide.
Representatives from England, Australia, New Zealand, South Africa, and the West Indies were part of a 1960 meeting in Sri Lanka that standardised the rules for the game. The game spread to other African countries in the 1970s. South Africa was prohibited from competing internationally from 1969 to 1994 due to apartheid. In the United States, Netball's popularity also increased during the 1970s, particularly in the New York area, and the United States of America Netball Association was created in 1992. The game also became popular in the Pacific Island nations of the Cook Islands, Fiji and Samoa during the 1970s. Netball Singapore was created in 1962, and the Malaysian Netball Association was created in 1978.
In Australia, the term "women's basketball" was used to refer to both netball and basketball. During the 1950s and 1960s, a movement arose to change the Australian name of the game from "women's basketball" to "netball" in order to avoid confusion between the two sports. The Australian Basketball Union offered to pay the costs involved to alter the name, but the netball organisation rejected the change. In 1970, the Council of the All Australia Netball Association officially changed the name to "netball" in Australia.
In 1963, the first international tournament was held in Eastbourne, England. Originally called the World Tournament, it later became known as the World Netball Championships. Following the first tournament, one of the organisers, Miss R. Harris, declared,England could learn from the mistakes in the past from the empty stands at Eastbourne. To get the right publicity and the right status desired, the game must emerge from the school playground. Netball should be part of a sports centre where social events could also be held.
The World Netball Championships have been held every four years since, most recently in 2011. The World Youth Netball Championships started in Canberra in 1988, and have been held roughly every four years since. In 1995, the International Olympic Committee designated netball as an Olympic recognised sport. Three years later it debuted at the 1998 Commonwealth Games in Kuala Lumpur. Other international competitions also emerged in the late 20th century, including the Nations Cup and the Asian Netball Championship.
Gender.
As of 2006, the IFNA recognises only women's netball. Men's netball teams exist in some areas but attract less attention from sponsors and spectators. Men's netball started to become popular in Australia during the 1980s, and the first men's championship was held in 1985. In 2004, New Zealand and Fiji sent teams to compete in the Australian Mixed and Men's National Championships. By 2006, mixed netball teams in Australia had as many male participants as rugby union. Other countries with men's national teams include Canada, Fiji, Jamaica, Kenya, Pakistan and the United Arab Emirates. Unlike women's netball at elite and national levels, men's and mixed gendered teams are largely self-funded.
An all-transgender netball team from Indonesia competed at the 1994 Gay Games in New York City. The team had been the Indonesian national champions. At the 2000 Gay Games VI in Sydney, netball and volleyball were the two sports with the highest rates of transgender athletes participating. There were eight teams of indigenous players, with seven identifying as transgender. They came from places like Palm Island in northern Queensland, Samoa, Tonga and Papua New Guinea. Teams with transgender players were allowed to participate in several divisions including men's, mixed and transgender; they were not allowed to compete against the cisgender women's teams.
Description and rules.
The objective of a game is to score more goals than the opposition. Goals are scored when a team member positioned in the attacking shooting circle shoots the ball through the goal ring. The goal rings are 380 mm in diameter and sit atop 3.05 m-high goal posts that have no backboards. A 4.9 m-radius semi-circular "shooting circle" is an area at each end of the court. The goal posts are located within the shooting circle. Each team defends one shooting circle and attacks the other. The netball court is 30.5 m long, 15.25 m wide, and divided lengthwise into thirds. The ball is usually made of leather or rubber, measures 680 to in circumference, and weighs 397 to. A normal game consists of four 15-minute quarters and can be played outdoors or in a covered stadium.
Each team is allowed seven players on the court. Each player is assigned a specific position, which limits their movement to a certain area of the court. A "bib" worn by each player contains a two letter abbreviation of indicating this position. Only two positions are permitted in the attacking shooting circle, and can therefore shoot for a goal. Similarly, only two positions are permitted in the defensive shooting circle; they try to prevent the opposition from shooting goals. Other players are restricted to two thirds of the court, with the exception of the Centre, who may move anywhere on the court except for a shooting circle.
At the beginning of every quarter and after a goal has been scored, play starts with a player in the centre position passing the ball from the centre of the court. These "centre passes" alternate between the teams, regardless of which team scored the last goal. When the umpire blows the whistle to restart play, four players from each team can move into the centre third to receive the pass. The centre pass must be caught or touched in the centre third. The ball is then moved up and down the court through passing and must be touched by a player in each adjacent third of the court. Players can hold the ball for only three seconds at any time. It must be released before the foot they were standing on when they caught it touches the ground again. Contact between players is only permitted if it does not impede an opponent or the general play. When defending a pass or shot players must be at least 90 cm away from the player with the ball. If illegal contact is made, the player who contacted cannot participate in play until the player taking the penalty has passed or shot the ball. If the ball is held in two hands and either dropped or a shot at goal is missed, the same player cannot be the first to touch it unless it first rebounds off the goal.
Variants.
Indoor netball.
Indoor netball is a variation of netball, played exclusively indoors, in which the playing court is surrounded on each side and overhead by a net. The net prevents the ball from leaving the court, permitting faster play by reducing playing stoppages.
Different forms of indoor netball exist. In a seven-per-side version called "action netball", seven players per team play with rules similar to netball. However, a game is split into 15-minute halves with a three-minute break in between. This version is played in Australia, New Zealand, South Africa and England.
A six-per-side version of the sport is also played in New Zealand. Two Centres per team can play in the whole court except the shooting circles; the remaining attacking and defending players are each restricted to one half of the court, including the shooting circles. The attacking and Centre players may shoot from outside the shooting circle for a two-point goal.
A five-per-side game is also common in indoor netball. Players can move throughout the court, with the exception of the shooting circles, which are restricted to certain attacking or defending players.
Fast5.
Fast5 (originally called Fastnet) is a variation on the rules of netball designed to make games faster and more television-friendly. The World Netball Series promotes it to raise the sport's profile and attract more spectators and greater sponsorship. The game is much shorter, with each quarter lasting only six minutes and only a two-minute break between quarters. The coaches can give instructions from the sideline during play, and unlimited substitutions are allowed. Like six-per-side indoor netball, attacking players may shoot two-point goals from outside the shooting circle. Each team can separately nominate one "power play" quarter, in which each goal scored by that team is worth double points and the centre pass is taken by the team that conceded the goal.
For children.
Netball has been adapted in several ways to meet children's needs. The rules for children are similar to those for adults, but various aspects of the game (such as the length of each quarter, goal height, and ball size) are modified.
Fun Net is a version of netball developed by Netball Australia for five- to seven-year-olds. It aims to improve basic netball skills using games and activities. The Fun Net program runs for 8–16 weeks. There are no winners or losers. The goal posts are 2.4 m high, and a smaller ball is used.
Netball Australia also runs a modified game called Netta aimed at 8- to 11-year-olds. The goal height and ball size are the same as for adults, but players rotate positions during the game, permitting each player to play each position. Netta was created to develop passing and catching skills. Its rules permit six seconds between catching and passing the ball, instead of the three seconds permitted in the adult game. Most players under 11 play this version at netball clubs.
A version called High Five Netball is promoted by the All England Netball Association. It is aimed at 9- to 11-year-old girls and includes only five positions. The players swap positions during the game. When a player is not on the court, she is expected to help the game in some other way, such as being the timekeeper or scorekeeper. High Five Netball has four six-minute quarters.
Governance.
The recognised international governing body of netball is the International Federation of Netball Associations (IFNA), based in Manchester, England. Founded in 1960, the organisation was initially called the International Federation of Netball and Women's Basketball. The IFNA is responsible for compiling world rankings for national teams, maintaining the rules for netball and organising several major international competitions.
As of July 2012, the IFNA has 49 full and 24 associate national members in five regions. Each region has an IFNA Regional Federation.
The IFNA is affiliated with the General Association of International Sports Federations, the International World Games Association and the Association of IOC Recognised International Sports Federations. It is also a signatory to the World Anti-Doping Code.
International competition.
Netball is a popular participant sport in countries of the Commonwealth of Nations. Non-Commonwealth entities with full IFNA membership include Switzerland, Taiwan, Thailand, Argentina, Bermuda, the Cayman Islands and the United States, along with former Commonwealth members Zimbabwe, Ireland and Hong Kong. According to the IFNA, over 20 million people play netball in more than 80 countries. International tournaments are held among countries in each of the five IFNA regions, either annually or every four years. School leagues and national club competitions have been organised in England, Australia, New Zealand and Jamaica since the early 20th century. Franchise-based netball leagues did not emerge until the late 1990s. These competitions sought to increase the profile of the sport in their respective countries. Despite widespread local interest, participation was largely amateur.
Netball was one of three new sports included in the 1998 Commonwealth Games and has been a fixture ever since. Twelve teams competed there in 2010. Australia and New Zealand have won two golds and two silvers each, while England has three bronzes and Jamaica one bronze.
The major international tournament in Africa is organised by the Confederation of Southern African Netball Associations, which invites teams from Botswana, Namibia, Zambia, Malawi, South Africa, Lesotho, Swaziland, Zimbabwe and the Seychelles to take part. The tournament is hosted by a country within the region; senior and under 21 teams compete. The tournament has served as a qualifier for the World Championships. South Africa launched a new domestic competition in 2011 called Netball Grand Series. It features eight regional teams from South Africa and is aimed at increasing the amount of playing time for players. It runs for 17 weeks and replaces the National Netball League, which was played over only two weeks. According to Proteas captain Elsje Jordaan, it was hoped that the competition would create an opportunity for players to become professional.
The American Federation of Netball Associations (AFNA) hosts two tournaments each year: the Caribbean Netball Association (CNA) Under 16 Championship and the AFNA Senior Championship. The CNA championship involves two divisions of teams from the Caribbean islands. In 2010 five teams competed in two rounds of round robin matches in the Championship Division, while four teams competed in the Developmental Division. Jamaica, which has lost only once in the tournament, decided not to play the 2011 tournament. The AFNA Senior Championship includes Canada and the USA along with the Caribbean nations. The tournament serves as a qualifier for the World Championship. Jamaica, with its high ranking, does not have to qualify; this leaves two spots to the other teams in the tournament.
The Asian Netball Championship is held every four years. The seventh Asian games were held in 2009 and featured Singapore, Thailand, Maldives, Taiwan, Malaysia, Sri Lanka, Hong Kong, India and Pakistan. There is also an Asian Youth Netball Championship for girls under 21 years of age, the seventh of which was held in 2010.
The major netball competition in Europe is the Netball Superleague, which features nine teams from England, Wales and Scotland. The league was created in 2005. Matches are broadcast on Sky Sports.
Netball has been featured at the Pacific Games, a multi-sport event with participation from 22 countries from around the South Pacific. The event is held every four years and has 12 required sports; the host country chooses the other four. Netball is not a required sport and has missed selection, particularly when former French or American territories host the games.
The ANZ Championship is a Trans-Tasman competition that has been broadcast on television in both New Zealand and Australia since 2008. It is contested among ten teams from Australia and New Zealand. It began in April 2008, succeeding Australia's Commonwealth Bank Trophy and New Zealand's National Bank Cup as the pre-eminent netball league in those countries. The competition is held annually between April and July, consisting of 69 matches played over 17 weeks. The ANZ Championship saw netball become a semi-professional sport in both countries, with increased media coverage and player salaries.
Major championships.
There are three major international netball competitions.
Netball's important competition is the World Netball Championships, held every four years. It was first held in 1963 at the Chelsea College of Physical Education at Eastbourne, England, with 11 nations competing. Since its inception the competition has been dominated primarily by the Australian and New Zealand teams, which hold ten and four titles, respectively. Trinidad and Tobago is the only other team to win a championship title. That title, won in 1979, was shared with New Zealand and Australia; all three teams finished with equal points at the end of the round robin, and there were no finals.
The World Series is a competition among the top six national netball teams, as ranked by the INF World Rankings. It is organised by the INF in conjunction with the national governing bodies of the six competing nations, UK Sport, and the host city's local council. The All England Netball Association covers air travel, accommodation, food and local travel expenses for all teams, while the respective netball governing bodies cover player allowances. It is held over three days, with each team playing each other once during the first two days in a round-robin format. The four highest-scoring teams advance to the semi-finals; the winners face each other in the Grand Final. The competition features modified fastnet rules and has been likened to Twenty20 cricket and rugby sevens. A new format featuring shorter matches with modified rules was designed to make the game more appealing to spectators and television audiences. The World Netball Series was held annually in England from 2009 to 2011.
Netball gained Olympic recognition in 1995 after 20 years of lobbying. Although it has never been played at the Summer Olympics, politicians and administrators have been campaigning to have it included in the near future. Its absence from the Olympics has been seen by the netball community as a hindrance in the global growth of the game by limiting access to media attention and funding sources. Some funding sources became available with recognition in 1995, including the International Olympic Committee, national Olympic committees, national sport organisations, and state and federal governments.
Bibliography.
</dl>

</doc>
<doc id="21594" url="http://en.wikipedia.org/wiki?curid=21594" title="Njörðr">
Njörðr

In Norse Paganism, Njörðr is a god among the Vanir. Njörðr, father of the deities Freyr and Freyja by his unnamed Vanir sister, was in an ill-fated marriage with the goddess Skaði, lives in Nóatún and is associated with sea, seafaring, wind, fishing, wealth, and crop fertility.
Njörðr is attested in the "Poetic Edda", compiled in the 13th century from earlier traditional sources, the "Prose Edda", written in the 13th century by Snorri Sturluson, in euhemerized form as a beloved mythological early king of Sweden in "Heimskringla", also written by Snorri Sturluson in the 13th century, as one of three gods invoked in the 14th century "Hauksbók" ring oath, and in numerous Scandinavian place names. Veneration of Njörðr survived into 18th or 19th century Norwegian folk practice, where the god is recorded as Njor and thanked for a bountiful catch of fish.
Njörðr has been the subject of an amount of scholarly discourse and theory, often connecting him with the figure of the much earlier attested Germanic goddess Nerthus, the hero Hadingus, and theorizing on his formerly more prominent place in Norse paganism due to the appearance of his name in numerous place names. "Njörðr" is sometimes modernly anglicized as Njord, Njoerd, or Njorth.
Name and eponyms.
The name "Njörðr" corresponds to that of the older Germanic fertility goddess "Nerthus", and both derive from the Proto-Germanic "*Nerþuz". The original meaning of the name is contested, but it may be related to the Irish word "nert" which means "force" and "power". It has been suggested that the change of sex from the female "Nerthus" to the male "Njörðr" is due to the fact that feminine nouns with u-stems disappeared early in Germanic language while the masculine nouns with u-stems prevailed. However, other scholars hold the change to be based not on grammatical gender but on the evolution of religious beliefs; that *Nerþuz and Njörðr appear as different genders because they are to be considered separate beings. The name "Njörðr" may be related to the name of the Norse goddess Njörun.
Njörðr's name appears in various place names in Scandinavia, such as "Nærdhæwi" (now Nalavi), "Njærdhavi" (now Mjärdevi), "Nærdhælunda" (now Närlunda), "Nierdhatunum" (now Närtuna) in Sweden, Njarðvík in southwest Iceland, Njarðarlög and Njarðey (now Nærøy) in Norway. Njörðr's name appears in a word for sponge; "Njarðarvöttr" (Old Norse "Njörðr's glove"). Additionally, in Old Icelandic translations of Classical mythology the Roman god Saturn's name is glossed as "Njörðr."
Attestations.
Njörðr is attested in the following works:
"Poetic Edda".
Njörðr is described as a future survivor of Ragnarök in stanza 39 of the poem "Vafþrúðnismál". In the poem, the god Odin, disguised as "Gagnráðr" faces off with the wise jötunn Vafþrúðnir in a battle of wits. While Odin states that Vafþrúðnir knows all the fates of the gods, Odin asks Vafþrúðnir "from where Njörðr came to the sons of the Æsir," that Njörðr rules over quite a lot of temples and hörgrs (a type of Germanic altar), and further adds that Njörðr was not raised among the Æsir. In response, Vafþrúðnir says:
In stanza 16 of the poem "Grímnismál", Njörðr is described as having a hall in Nóatún made for himself. The stanza describes Njörðr as a "prince of men," that he is "lacking in malice," and that he "rules over the "high-timbered temple." In stanza 43, the creation of the god Freyr's ship Skíðblaðnir is recounted, and Freyr is cited as the son of Njörðr. In the prose introduction to the poem "Skírnismál", Freyr is mentioned as the son of Njörðr, and stanza 2 cites the goddess Skaði as the mother of Freyr. Further in the poem, Njörðr is again mentioned as the father of Freyr in stanzas 38, 39, and 41.
In the late flyting poem "Lokasenna", an exchange between Njörðr and Loki occurs in stanzas 33, 34, 35, and 36. After Loki has an exchange with the goddess Freyja, in stanza 33 Njörðr states:
Loki responds in the stanza 34, stating that "from here you were sent east as hostage to the gods" (a reference to the Æsir-Vanir War) and that "the daughters of Hymir used you as a pisspot, and pissed in your mouth." In stanza 35, Njörðr responds that:
Loki tells Njörðr to "stop" and "keep some moderation," and that he "won't keep it a secret any longer" that Njörðr's son Freyr was produced with his unnamed sister, "though you'd expect him to be worse than he is." The god Tyr then interjects and the flyting continues in turn.
Njörðr is referenced in stanza 22 of the poem "Þrymskviða", where he is referred to as the father of the goddess Freyja. In the poem, the jötunn Þrymr mistakenly thinks that he will be receiving the goddess Freyja as his bride, and while telling his fellow jötunn to spread straw on the benches in preparation for the arrival of Freyja, he refers to her as the daughter of Njörðr of Nóatún. Towards the end of the poem "Sólarljóð", Njörðr is cited as having nine daughters. Two of the names of these daughters are given; the eldest Ráðveig and the youngest Kreppvör.
"Prose Edda".
Njörðr is mentioned in the "Prose Edda" books "Gylfaginning" and "Skáldskaparmál".
"Gylfaginning".
In the "Prose Edda", Njörðr is introduced in chapter 23 of the book "Gylfaginning". In this chapter, Njörðr is described by the enthroned figure of High as living in the heavens at Nóatún, but also as ruling over the movement of the winds, having the ability to calm both sea and fire, and that he is to be invoked in seafaring and fishing. High continues that Njörðr is very wealthy and prosperous, and that he can also grant wealth in land and valuables to those who request his aid. Njörðr originates from Vanaheimr and is devoid of Æsir stock, and he is described as having been traded with Hœnir in hostage exchange with between the Æsir and Vanir.
High further states that Njörðr's wife is Skaði, that she is the daughter of the jötunn Þjazi, and recounts a tale involving the two. High recalls that Skaði wanted to live in the home once owned by her father called Þrymheimr ("Thunder Home"). However, Njörðr wanted to live nearer to the sea. Subsequently, the two made an agreement that they would spend nine nights in Þrymheimr and then next three nights in Nóatún (or nine winters in Þrymheimr and another nine in Nóatún according to the "Codex Regius" manuscript). However, when Njörðr returned from the mountains to Nóatún, he says:
Skaði then responds:
High states that afterward Skaði went back up to the mountains to Þrymheimr and recites a stanza where Skaði skis around, hunts animals with a bow, and lives in her fathers old house. Chapter 24 begins, which describes Njörðr as the father of two beautiful and powerful children: Freyr and Freyja. In chapter 37, after Freyr has spotted the beautiful jötunn Gerðr, he becomes overcome with sorrow, and refuses to sleep, drink, or talk. Njörðr then sends for Skírnir to find out who he seems to be so angry at, and, not looking forward to being treated roughly, Skírnir reluctantly goes to Freyr.
"Skáldskaparmál".
Njörðr is introduced in "Skáldskaparmál" within a list of 12 Æsir attending a banquet held for Ægir. Further in "Skáldskaparmál", the skaldic god Bragi recounds the death of Skaði's father Þjazi by the Æsir. As one of the three acts of reparation performed by the Æsir for Þjazi's death, Skaði was allowed by the Æsir to choose a husband from amongst them, but given the stipulation that she may not see any part of them but their feet when making the selection. Expecting to choose the god Baldr by the beauty of the feet she selects, Skaði instead finds that she has picked Njörðr.
In chapter 6, a list of kennings is provided for Njörðr: "God of chariots," "Descendant of Vanir," "a Van," father of Freyr and Freyja, and "the giving god." This is followed by an excerpt from a composition by the 11th century skald Þórðr Sjáreksson, explained as containing a reference to Skaði leaving Njörðr:
Chapter 7 follows and provides various kennings for Freyr, including referring to him as the son of Njörðr. This is followed by an excerpt from a work by the 10th century skald Egill Skallagrímsson that references Njörðr (here anglicized as "Niord"):
In chapter 20, "daughter of Njörðr" is given as a kenning for Freyja. In chapter 33, Njörðr is cited among the gods attending a banquet held by Ægir. In chapter 37, Freyja is again referred to as Njörðr's daughter in a verse by the 12th century skald Einarr Skúlason. In chapter 75, Njörðr is included in a list of the Æsir. Additionally, "Njörðr" is used in kennings for "warrior" or "warriors" various times in "Skáldskaparmál".
"Heimskringla".
Njörðr appears in or is mentioned in three Kings' sagas collected in "Heimskringla"; "Ynglinga saga", the "Saga of Hákon the Good" and the "Saga of Harald Graycloak". In chapter 4 of "Ynglinga saga", Njörðr is introduced in connection with the Æsir-Vanir War. When the two sides became tired of war, they came to a peace agreement and exchanged hostages. For their part, the Vanir send to the Æsir their most "outstanding men"; Njörðr, described as wealthy, and Freyr, described as his son, in exchange for the Æsir's Hœnir. Additionally, the Æsir send Mímir in exchange for the wise Kvasir.
Further into chapter 4, Odin appoints Njörðr and Freyr as priests of sacrificial offerings, and they became gods among the Æsir. Freyja is introduced as a daughter of Njörðr, and as the priestess at the sacrifices. In the saga, Njörðr is described as having once wed his unnamed sister while he was still among the Vanir, and the couple produced their children Freyr and Freyja from this union, though this custom was forbidden among the Æsir.
Chapter 5 relates that Odin gave all of his temple priests dwelling places and good estates, in Njörðr's case being Nóatún. Chapter 8 states that Njörðr married a woman named Skaði, though she would not have intercourse with him. Skaði then marries Odin, and the two had numerous sons.
In chapter 9, Odin dies and Njörðr takes over as ruler of the Swedes, and he continues the sacrifices. The Swedes recognize him as their king, and pay him tribute. Njörðr's rule is marked with peace and many great crops, so much so that the Swedes believed that Njörðr held power over the crops and over the prosperity of mankind. During his rule, most of the Æsir die, their bodies are burned, and sacrifices are made by men to them. Njörðr has himself "marked for" Odin and he dies in his bed. Njörðr's body is burnt by the Swedes, and they weep heavily at his tomb. After Njörðr's reign, his son Freyr replaces him, and he is greatly loved and "blessed by good seasons like his father."
In chapter 14 of "Saga of Hákon the Good" a description of the pagan Germanic custom of Yule is given. Part of the description includes a series of toasts. The toasts begin with Odin's toasts, described as for victory and power for the king, followed by Njörðr and Freyr's toast, intended for good harvests and peace. Following this, a beaker is drank for the king, and then a toast is given for departed kin. Chapter 28 quotes verse where the kenning "Njörðr-of-roller-horses" is used for "sailor". In the "Saga of Harald Graycloak", a stanza is given of a poem entitled "Vellekla" ("Lack of Gold") by the 10th century Icelandic skald Einarr skálaglamm that mentions Njörðr in a kenning for "warrior."
"Egils saga".
In chapter 80 of the 13th century Icelandic saga "Egils saga", Egill Skallagrímsson composes a poem in praise of Arinbjörn ("Arinbjarnarkviða"). In stanza 17, Egill writes that all others watch in marvel how Arinbjörn gives out wealth, as he has been so endowed by the gods Freyr and Njörðr.
Modern folk practice.
Veneration of Njörðr survived into 18th or 19th century Norwegian folk practice, as recorded in a tale collected by Halldar O. Opedal from an informant in Odda, Hordaland, Norway. The informant comments on a family tradition in which the god is thanked for a bountiful catch of fish: 
Scholar Georges Dumézil further cites various tales of "havmennesker" (Norwegian "sea people") who govern over sea weather, wealth, or, in some incidents, give magic boats are likely connected to Njörðr.
Theories.
Nerthus.
Njörðr is often identified with the goddess Nerthus, whose reverence by various Germanic tribes is described by Roman historian Tacitus in his 1st CE century work "Germania". The connection between the two is due to the linguistic relationship between "Njörðr" and the reconstructed "*Nerþuz", "Nerthus" being the feminine, Latinized form of what "Njörðr" would have looked like around 1 CE. This has led to theories about the relation of the two, including that Njörðr may have once been a hermaphroditic god or, generally considered more likely, that the name may indicate an otherwise unattested divine brother and sister pair such as Freyr and Freyja. Consequently, Nerthus has been identified with Njörðr's unnamed sister with whom he had Freyja and Freyr, which is mentioned in "Lokasenna".
Bieka-Galles.
In Saami mythology, Bieka-Galles (or Biega-, Biegga-Galles, depending on dialect; "The Old Man of the Winds") is a deity who rules over rain and wind, and is the subject of boat and wooden shovel (or, rather, oar) offerings. Due to similarities in between descriptions of Njörðr in "Gylfaginning" and descriptions of Bieka-Galles in 18th century missionary reports, Axel Olrik identified this deity as the result of influence from the seafaring North Germanic peoples on the landbound Saami.
Hadingus.
Parallels have been pointed out between Njörðr and the figure of Hadingus, attested in book I of Saxo Grammaticus' 13th century work "Gesta Danorum". Some of these similarities include that, in parallel to Skaði and Njörðr in "Skáldskaparmál", Hadingus is chosen by his wife Regnhild after selecting him from other men at a banquet by his lower legs, and, in parallel to Skaði and Njörðr in "Gylfaginning", Hadingus complains in verse of his displeasure at his life away from the sea and how he is disturbed by the howls of wolves, while his wife Regnhild complains of life at the shore and states her annoyance at the screeching sea birds. Georges Dumézil theorized that in the tale Hadingus passes through all three functions of his trifunctional hypothesis, before ending as an Odinic hero, paralleling Njörðr's passing from the Vanir to the Æsir in the Æsir-Vanir War.
Svafrþorinn.
In stanza 8 of the poem "Fjölsvinnsmál", Svafrþorinn is stated as the father of Menglöð by an unnamed mother, who the hero Svipdagr seeks. Menglöð has often been theorized as the goddess Freyja, and according to this theory, Svafrþorinn would therefore be Njörðr. The theory is complicated by the etymology of the name "Svafrþorinn" ("þorinn" meaning "brave" and "svafr" means "gossip") (or possibly connects to "sofa" "sleep"), which Rudolf Simek says makes little sense when attempting to connect it to Njörðr.
Modern influence.
Njörðr has been the subject of an amount of artistic depictions. Depictions include "Freyr und Gerda; Skade und Niurd" (drawing, 1883) by K. Ehrenberg, "Njörðr" (1893) by Carl Frederick von Saltza, "Skadi" (1901) by E. Doepler d. J., and "Njörd's desire of the Sea" (1908) by W. G. Collingwood.
Njörðr is one of the incarnated gods in the New Zealand comedy/drama "The Almighty Johnsons". The part of "Johan Johnson/Njörðr" is played by Stuart Devenie.
References.
</dl>

</doc>
<doc id="21597" url="http://en.wikipedia.org/wiki?curid=21597" title="Neutral">
Neutral

Neutral and neutrality may mean the following:

</doc>
<doc id="21601" url="http://en.wikipedia.org/wiki?curid=21601" title="Niger–Congo languages">
Niger–Congo languages

The Niger–Congo languages constitute one of the world's major language families, and Africa's largest in terms of geographical area, number of speakers, and number of distinct languages. They may constitute the world's largest language family in terms of distinct languages, although this question is complicated by ambiguity about what constitutes a distinct language. A characteristic common to most Niger–Congo languages is the use of a noun class system. The most widely spoken Niger–Congo languages by number of native speakers are Yoruba, Igbo, Fula, Shona and Zulu. The most widely spoken by total number of speakers is Swahili. Some scholars have doubted whether Niger–Congo is a valid genetic unit or rather a typological grouping, but most specialists today consider it to be a valid family, although there is no consensus on the subclassification.
Classification history.
Early classifications.
Niger–Congo as it is known today was only gradually recognized as a unity. In early classifications of the languages of Africa, one of the principal criteria used to distinguish different groupings was the languages' use of prefixes to classify nouns, or the lack thereof. A major advance came with the work of Sigismund Wilhelm Koelle, who in his 1854 "Polyglotta Africana" attempted a careful classification, the groupings of which in quite a number of cases correspond to modern groupings. An early sketch of the extent of Niger–Congo as one language family can be found in Koelle's observation, echoed in Bleek (1856), that the Atlantic languages used prefixes just like many Southern African languages. Subsequent work of Bleek, and some decades later the comparative work of Meinhof, solidly established Bantu as a linguistic unit.
In many cases, wider classifications employed a blend of typological and racial criteria. Thus, Friedrich Müller, in his ambitious classification (1876–88), separated the 'Negro' and Bantu languages. Likewise, the Africanist Karl Richard Lepsius considered Bantu to be of African origin, and many 'Mixed Negro languages' as products of an encounter between Bantu and intruding Asiatic languages.
In this period a relation between Bantu and languages with Bantu-like (but less complete) noun class systems began to emerge. Some authors saw the latter as languages which had not yet completely evolved to full Bantu status, whereas others regarded them as languages which had partly lost original features still found in Bantu. The Bantuist Meinhof made a major distinction between Bantu and a 'Semi-Bantu' group which according to him was originally of the unrelated Sudanic stock.
Westermann, Greenberg and beyond.
Westermann, a pupil of Meinhof, set out to establish the internal classification of the then Sudanic languages. In a 1911 work he established a basic division between 'East' and 'West'. A historical reconstruction of West Sudanic was published in 1927, and in his 1935 'Charakter und Einteilung der Sudansprachen' he conclusively established the relationship between Bantu and West Sudanic.
Joseph Greenberg took Westermann's work as a starting-point for his own classification. In a series of articles published between 1949 and 1954, he argued that Westermann's 'West Sudanic' and Bantu formed a single genetic family, which he named Niger–Congo; that Bantu constituted a subgroup of the Benue–Congo branch; that Adamawa–Eastern, previously not considered to be related, was another member of this family; and that Fula belonged to the West Atlantic languages. Just before these articles were collected in final book form ("The Languages of Africa") in 1963, he amended his classification by adding Kordofanian as a branch co-ordinate with Niger–Congo as a whole; consequently, he renamed the family "Congo–Kordofanian", later "Niger–Kordofanian". Greenberg's work on African languages, though initially greeted with scepticism, became the prevailing view among scholars.
Bennet and Sterk (1977) presented an internal reclassification based on lexicostatistics that laid the foundation for the regrouping in Bendor-Samuel (1989). Kordofanian was presented as one of several primary branches rather than being coordinate to the family as a whole, prompting re-introduction of the term "Niger–Congo", which is in current use among linguists. Many classifications continue to place Kordofanian as the most distant branch, but mainly due to negative evidence (fewer lexical correspondences), rather than positive evidence that the other languages form a valid genealogical group. Likewise, Mande is often assumed to be the second-most distant branch based on its lack of the noun-class system prototypical of the Niger–Congo family. Other branches lacking any trace of the noun-class system are Dogon and Ijaw, whereas the Talodi branch of Kordofanian does have cognate noun classes, suggesting that Kordofanian is also not a unitary group.
"Glottolog" (2013) accepts the core with noun-class systems, the Atlantic–Congo languages, apart from the recent inclusion of some of the Kordofanian groups, but not Niger–Congo as a whole. They list the following as separate families:
Niger–Congo and Nilo-Saharan.
Over the years, several linguists have suggested a link between Niger–Congo and Nilo-Saharan, probably starting with Westermann's comparative work on the 'Sudanic' family in which 'Eastern Sudanic' (now classified as Nilo-Saharan) and 'Western Sudanic' (now classified as Niger–Congo) were united. Gregersen (1972) proposed that Niger–Congo and Nilo-Saharan be united into a larger phylum which he termed "Kongo–Saharan". His evidence was mainly based on the uncertainty in the classification of Songhay, morphological resemblances, and lexical similarities. A more recent proponent was Roger Blench (1995), who puts forward phonological, morphological and lexical evidence for uniting Niger–Congo and Nilo-Saharan in a "Niger–Saharan" phylum, with special affinity between Niger–Congo and Central Sudanic. However, fifteen years later his views had changed, with Blench (2011) proposing instead that the noun-classifier system of Central Sudanic, commonly reflected in a tripartite general–singulative–plurative number system, triggered the development or elaboration of the noun-class system of the Atlantic–Congo languages, with tripartite number marking surviving in the Plateau and Gur languages of Niger–Congo, and the lexical similarities being due to loans.
Common features.
Phonology.
Niger–Congo languages have a clear preference for open syllables of the type CV (Consonant Vowel). The typical word structure of Proto-Niger–Congo is thought to have been CVCV, a structure still attested in, for example, Bantu, Mande and Ijoid – in many other branches this structure has been reduced through phonological change. Verbs are composed of a root followed by one or more extensional suffixes. Nouns consist of a root originally preceded by a noun class prefix of (C)V- shape which is often eroded by phonological change.
Consonants.
Reconstructions of the consonant set of several branches of Niger–Congo (Stewart for proto-Volta–Congo, Mukarovsky for his proto-West-Nigritic, roughly corresponding to Atlantic–Congo) have posited independently a regular phonological contrast between two classes of consonants. Pending more clarity as to the precise nature of this contrast it is commonly characterized as a contrast between 'fortis' and 'lenis' consonants. Five places of articulation are postulated for the consonant inventory of proto-Niger–Congo: labial, alveolar, palatal, velar, and labial-velar.
Vowels.
Many Niger–Congo languages' vowel harmony is based on the [ATR] (advanced tongue root) feature. In this type of vowel harmony, the position of the root of the tongue in regards to backness is the phonetic basis for the distinction between two harmonizing sets of vowels. In its fullest form, this type involves two classes, each of five vowels:
The roots are then divided into [+ATR] and [-ATR] categories. This feature is lexically assigned to the roots because there is no determiner within a normal root that causes the [ATR] value.
There are two types of [ATR] vowel harmony controllers in Niger–Congo. The first controller is the root. When a root contains a [+ATR] or [-ATR] vowel, then that value is applied to the rest of the word, which involves crossing morpheme boundaries. For example, suffixes in Wolof assimilate to the [ATR] value of the root to which they attach. Some examples of these suffixes that alternate depending on the root are:
Furthermore, the directionality of assimilation in [ATR] root-controlled vowel harmony need not be specified. The root features [+ATR] and [-ATR] spread left and/or right as needed, so that no vowel would lack a specification and be ill-formed.
Unlike in the root-controlled harmony system, where the two [ATR] values behave symmetrically, a large number of Niger–Congo languages exhibit a pattern where the [+ATR] value is more active or dominant than the [-ATR] value. This results in the second vowel harmony controller being the [+ATR] value. If there is even one vowel that is [+ATR] in the whole word, then the rest of the vowels harmonize with that feature. However, if there is no vowel that is [+ATR], the vowels appear in their underlying form. This form of vowel harmony control is best exhibited in West African languages. For example, in Nawuri, the diminutive suffix /-bi/ will cause the underlying [-ATR] vowels in a word to become phonetically [+ATR]
There are two types of vowels which affect the harmony process. These are known as neutral or opaque vowels. Neutral vowels do not harmonize to the [ATR] value of the word, and instead maintain their own [ATR] value. The vowels that follow them, however, will receive the [ATR] value of the root. Opaque vowels maintain their own [ATR] value as well, but they affect the harmony process behind them. All of the vowels following an opaque vowel will harmonize with the [ATR] value of the opaque vowel instead of the [ATR] vowel of the root.
The vowel inventory listed above is a ten-vowel language. This is a language in which all of the vowels of the language participate in the harmony system, producing five harmonic pairs. Vowel inventories of this type are still found in some branches of Niger-Congo, for example in the Ghana Togo Mountain languages. However, this is the rarer inventory as oftentimes there are one or more vowels that are not part of a harmonic pair. This has resulted in seven-and nine-vowel systems being the more popular systems. The majority of languages with [ATR] controlled vowel harmony have either seven- or nine-vowel phonemes, with the most common non-participatory vowel being /a/. It has been asserted that this is because vowel quality differences in the mid-central region where /ə/, the counterpart of /a/, is found, are difficult to perceive. Another possible reason for the non-participatory status of /a/ is that there is articulatory difficulty in advancing the tongue root when the tongue body is low in order to produce a low [+ATR] vowel. Therefore, the vowel inventory for nine-vowel languages is generally:
And seven-vowel languages have one of two inventories:
Note that in the nine-vowel language, the missing vowel is, in fact, [ə], [a]'s counterpart, as would be expected.
The fact that ten vowels have been reconstructed for proto-Atlantic, proto-Ijoid and possibly proto-Volta–Congo has led to the hypothesis that the original vowel inventory of Niger–Congo was a full ten-vowel system. On the other hand Stewart, in recent comparative work, reconstructs a seven vowel system for his proto-Potou-Akanic-Bantu.
Nasality.
Several scholars have documented a contrast between oral and nasal vowels in Niger–Congo. In his reconstruction of proto-Volta–Congo, Steward (1976) postulates that nasal consonants have originated under the influence of nasal vowels; this hypothesis is supported by the fact that there are several Niger–Congo languages that have been analysed as lacking nasal consonants altogether. Languages like this have nasal vowels accompanied with complementary distribution between oral and nasal consonants before oral and nasal vowels. Subsequent loss of the nasal/oral contrast in vowels may result in nasal consonants becoming part of the phoneme inventory. In all cases reported to date, the bilabial /m/ is the first nasal consonant to be phonologized. Niger–Congo thus invalidates two common assumptions about nasals: that all languages have at least one primary nasal consonant, and that if a language has only one primary nasal consonant it is /n/.
Niger–Congo languages commonly show fewer nasalized than oral vowels. Kasem, a language with a ten-vowel system employing ATR vowel harmony, has seven nasalized vowels. Similarly, Yoruba has seven oral vowels and only five nasal ones. However, the recently discovered language of Zialo has nasal equivalent for each of its seven vowels.
Tone.
The large majority of present-day Niger–Congo languages are tonal. A typical Niger–Congo tone system involves two or three contrastive level tones. Four level systems are less widespread, and five level systems are rare. Only a few Niger–Congo languages are non-tonal; Swahili is perhaps the best known, but within the Atlantic branch some others are found. Proto-Niger–Congo is thought to have been a tone language with two contrastive levels. Synchronic and comparative-historical studies of tone systems show that such a basic system can easily develop more tonal contrasts under the influence of depressor consonants or through the introduction of a downstep. Languages which have more tonal levels tend to use tone more for lexical and less for grammatical contrasts.
Morphosyntax.
Noun classification.
Niger–Congo languages are known for their system of noun classification, traces of which can be found in every branch of the family but Mande, Ijoid, Dogon, and the Katla and Rashad branches of Kordofanian. These noun-classification systems are somewhat analogous to grammatical gender in other languages, but there are often a fairly large number of classes (often 10 or more), and the classes may be male human/female human/animate/inanimate, or even completely gender-unrelated categories such as places, plants, abstracts, and groups of objects. For example, in Bantu, the Swahili language is called "Kiswahili," while the Swahili people are "Waswahili." Likewise, in Ubangian, the Zande language is called "Pazande," while the Zande people are called "Azande."
In the Bantu languages, where noun classification is particularly elaborate, it typically appears as prefixes, with verbs and adjectives marked according to the class of the noun they refer to. For example, in Swahili, "watu wazuri wataenda" is 'good "(zuri)" people "(tu)" will go "(ta-enda)"'.
Verbal extensions.
The same Atlantic–Congo languages which have noun classes also have a set of verb applicatives and other verbal extensions, such as the reciprocal suffix "-na" (Swahili "penda" 'to love', "pendana" 'to love each other'; also applicative "pendea" 'to love for' and causative "pendeza" 'to please').
Word order.
A subject–verb–object word order is quite widespread among today's Niger–Congo languages, but SOV is found in branches as divergent as Mande, Ijoid and Dogon. As a result, there has been quite some debate as to the basic word order of Niger–Congo.
Whereas Claudi (1993) argues for SVO on the basis of existing SVO > SOV grammaticalization paths (SOV > SVO is never found), Gensler (1997) points out that the notion of 'basic word order' is problematic as it excludes structures with, for example, auxiliaries.
However, the structure SC-OC-VbStem (Subject concord, Object concord, Verb stem) found in the "verbal complex" of the SVO Bantu languages suggests an earlier SOV pattern (where the subject and object were at least represented by pronouns).
Noun phrases in most Niger–Congo languages are characteristically "noun-initial", with adjectives, numerals, demonstratives and genitives all coming after the noun. The major exceptions are found in the western areas where verb-final word order predominates and genitives precede nouns, though other modifiers still come afterwards. Degree words almost always follow adjectives, and except in verb-final languages adpositions are prepositional.
The verb-final languages of the Mende region have two quite unusual word order characteristics. Although verbs follow their direct objects, oblique adpositional phrases (like "in the house", "with timber") typically come after the verb, creating a SOVX word order. Also noteworthy in these languages is the prevalence of internally headed and correlative relative clauses, in both of which the head occurs "inside" the relative clause rather than the main clause.
Major clades.
The traditional branches and major languages of the Niger–Congo family are:
Some linguists consider the twenty or so Kordofanian languages to form part of the Niger–Congo family, while others consider them and Niger–Congo to form two separate branches of a "Niger–Kordofanian" language family, and yet others do not accept Kordofanian as a single group. Senufo has been placed traditionally within Gur, but is now usually considered an early off-shoot from Atlantic–Congo.
However, Roger Blench believes that Adamawa, Ubangian, Kwa, Bantoid, and Bantu are not coherent groups.
The Laal, Mpre, and Jalaa languages are often linked with Niger–Congo, but have yet to be conclusively classified.

</doc>
<doc id="21606" url="http://en.wikipedia.org/wiki?curid=21606" title="Napo River">
Napo River

The Napo River (Spanish: "Río Napo") is a tributary to the Amazon River that rises in Ecuador on the flanks of the east Andean volcanoes of Antisana, Sinchulawa and Cotopaxi.
The total length is 1075 km. The river drains an area of 100518 km2. The mean annual discharge is 6976 m3 per second.
Before it reaches the plains it receives a great number of small streams from impenetrable, saturated and much broken mountainous districts, where the dense and varied vegetation seems to fight for every piece of ground. This river is one of Ecuador's Physical Features. From the north it is joined by the Coca River, having its sources in the gorges of Cayambe volcano on the equator, and also a powerful river, the Aguarico, having its headwaters between Cayambe and the Colombian frontier.
From the west it receives a secondary tributary, the Curaray, from the Andean slopes, between Cotopaxi and the Tungurahua volcano. From its Coca branch to the mouth of the Curaray the Napo is full of snags and shelving sandbanks, and throws out numerous canos among jungle-tangled islands, which in the wet season are flooded, giving the river an immense width. From the Coca to the Amazon it runs through a forested plain where not a hill is visible from the river - its uniformly level banks being only interrupted by swamps and lagoons.
From the Amazon the Napo is navigable for river craft up to its Curaray branch, a distance of about 216 mi, and perhaps a bit further; thence, by painful canoe navigation, its upper waters may be ascended as far as Santa Rosa, the usual point of embarkation for any venturesome traveller who descends from the Quito tableland. The Coca river may be penetrated as far up as its middle course, where it is jammed between two mountain walls, in a deep canyon, along which it dashes over high falls and numerous reefs. This is the stream made famous by the expedition of Gonzalo Pizarro.

</doc>
<doc id="21607" url="http://en.wikipedia.org/wiki?curid=21607" title="Nanay River">
Nanay River

The Nanay River is a river in northern Peru. It is a tributary of the Amazon River, merging into this river at the city of Iquitos. The lower part of the Nanay flows to the north and west of the city, while the Itaya River flows to the south and east. Other nearby settlements on the Nanay River include the villages of Santo Tomás, Padre Cocha, and Santa Clara. During periods when the river is low, the many beaches along the Nanay are popular destinations. The Nanay belongs entirely to the lowlands, and is very crooked, has a slow current and divides into many "canos" and strings of lagoons which flood the flat, low areas of country on either side. It is simply the drainage ditch of districts which are extensively overflowed in the rainy season. Captain Butt ascended it 195 mi, to near its source. A part of the Nanay River flows through the Allpahuayo-Mishana National Reserve.
The Nanay is blackwater river and it has a high fish species richness, including several that are well-known from the aquarium industry. Some of these, notably discus, are the result of accidental introductions that happened in the 1970s.

</doc>
<doc id="21609" url="http://en.wikipedia.org/wiki?curid=21609" title="Nine-ball">
Nine-ball

Nine-ball (sometimes written 9-ball) is a contemporary form of pool (pocket billiards), with historical beginnings rooted in the United States and traceable to the 1920s. The game may be played in social and recreational settings by any number of players (generally one-on-one) and subject to whatever rules are agreed upon beforehand, or in league and tournament settings in which the number of players and the rules are set by the sponsors. During much of its history, nine-ball has been known as a "money game" in both professional and recreational settings, but has since become established as a legitimate alternative to eight ball, straight pool and other major competition games. 
In recent decades, nine-ball has become the dominant tournament game in professional pool, in the World Pool-Billiard Association, Women's Professional Billiard Association and United States Professional Poolplayers Association. Matches proceed quickly, suitable for the time constraints of television coverage, and the fast-paced games tend to keep the audience engaged. 
Play.
The game is played on a pocket billiards table with six pockets and with ten balls. The <dfn id="">cue ball</dfn>, which is usually a solid shade of white (but may be spotted in some tournaments), is struck to hit the lowest numbered ball on the table (often referred to as the <dfn id=">object ball</dfn>), each of these balls are distinctly colored and numbered 1 through 9. The object of the game is to legally pocket the 9-ball.
In nine-ball, except when a push-out has been invoked, a legal shot consists of striking the cue ball into the lowest numbered object ball on the table and subsequently either pocketing an object ball, or driving any ball (including the cue ball) to any rail, otherwise the shot is a <dfn id=">foul</dfn>. Additional conditions apply for the break shot (see below). Object balls do not have to be pocketed in numerical order; Any ball may be pocketed at any time during the game, so long as the lowest-numbered ball is contacted first by the cue ball. Nine-ball is not a <dfn id=">call shot</dfn> game. The 9-ball itself can be legally pocketed for a win at any turn in the game, intentionally or by chance, including the break shot. Conversely, a player could potentially pocket all of the object balls numbered one through eight during the course of the game and lose after his opponent pockets only the nine-ball.
Players alternate <dfn id=">innings</dfn> at the table, meaning play continues by one player until he or she misses, commits a foul, or pockets the 9 ball for the win. The penalty for a foul is that the player's inning ends and the opponent comes to the table with <dfn id=">ball in hand</dfn>, able to place the cue ball anywhere on the table prior to shooting. 
Nine-ball is a relatively fast-paced game and is rarely played by the rack. Instead, players normally play a match (or <dfn id=">race</dfn>) to a set number of games, often five, seven or nine. The first player to win that set number of games wins the match.
The rack.
The object balls are placed in a diamond-shaped configuration, with the 1 ball positioned at the front (toward the position of the breaking player) on the foot spot, and the 9 ball placed in the center. The physical rack used to position the balls is typically triangle-shaped, usually wood or plastic, and capable of holding all fifteen object balls, although diamond-shaped racks that hold only nine balls are sometimes used. The placement of the remaining balls is generally considered to be random. However, in some <dfn id=">handicapped</dfn> tournaments, the ball being <dfn id=">spotted</dfn> to the lesser player must be one of the two balls placed behind the 1 ball at the apex of the rack. An imaginary line drawn through the one-ball and back apex of the diamond should be parallel to the long rails of the table (perpendicular to the short rails). The placement of balls is expected to be precise, especially in league and tournament play; if any ball in the rack does not touch each adjacent ball, or if the rack is not "straight", or if the 1 ball is not resting precisely on the <dfn id="">foot spot</dfn>, the player assigned the break may demand a re-rack. "(See also "European alterations", below, for a recently devised "template-trained" racking system.)"
The break.
One person is chosen to shoot first, by <dfn id="">breaking</dfn> the rack. Usually this is determined by flipping a coin, or by <dfn id=">lagging</dfn>, especially in professional tournaments in the case of the latter, or it may be ruled by the authority in charge, the sponsor or the players themselves that the winner or loser of the previous game will always shoot first in the next rack. As with most pocket billiard games, the base of the cue ball must be behind the <dfn id=">head string</dfn> for the break shot. If the player who breaks fails to make a legal break, the opponent can either demand a re-rack and become the breaker, or continue to play as if it had been an ordinary foul, depending upon the rules of the event. If the breaker pockets a ball and commits no foul, it remains the breaker's turn. If the breaker pockets the 9 ball on the break (without fouling), this is an instant win. "(See also "European alterations", below, for recent moves to change the breaking rules.)"
The push-out.
After the break (regardless of its result), before the second shot of the game, the player at the table may call a "<dfn id="">push-out</dfn>." A push-out can be called by the breaking player if he legally pocketed a ball on the break, or the non-breaking player if no ball was pocketed on the break. Calling a push-out for the shot after the break allows the player taking the shot to legally hit the cue ball in almost any fashion with no foul, with the exception that the cue ball must stay on the table and illegal shots such as double-hitting the cue ball or a "scoop jump shot" should still be called a foul. Playing a push-out shot ends the player's inning and play passes to the opponent. The main purpose of the push-out shot is to alleviate an unlucky lie after the break, where it is difficult to make a legal shot. Unlike any other shot of the game, for a push-out shot, the cue ball is not required to contact any object ball and if an object ball is contacted, it is not required to be the lowest numbered ball. If the nine-ball is pocketed on a push-out shot it is spotted, however any other pocketed object ball remains pocketed and is not spotted. A push-out should be called so that the opponent or referee hears the call, and it is customary for the opponent or referee to confirm that he heard the push-out call, so that there is no controversy surrounding the shot. After a push-out shot was called and played, the incoming player has the choice of accepting the table as it lies, or forcing the pushing-out player to take the next shot of the game (always the third shot of the game). Only one push-out is allowed per game, and it "must" be immediately after the break. "(See also "The rise of 'Texas express' rules", below, for the historical multi-push-out rule variation.)" If the pushing-out player has a particular type of shot he feels comfortable with, such as a jump shot, or two-rail bank shot, it may be strategical to leave that type of shot after the push-out. The ideal push-out shot leaves a lie that the opponent believes likely to be makeable, and will accept, but will fail to actually make, giving control of the table back to the pusher-out, and which the pusher-out is confident to make if the shot is passed back to him. Thus nine-ball players aim for a push-out that has about a 50/50 chance of being accepted or returned.
Winning.
Winning a game occurs any time a player hits the lowest numbered ball first and pockets the 9-ball without committing a foul. When only the 9-ball is on the table, this is straightforward and obvious; however, when other balls remain on the table, any number of events can result in victory so long as the above requirements are met. Loss of game can occur if three successive fouls are committed and the fouling player is warned audibly or visually after the 2nd foul during the third inning.
In most rule systems, including those of the World Pool-Billiard Association and its national affiliates like the Billiard Congress of America, if a player fouls and pockets the 9 ball, or knocks the 9 ball off the table, the 9 ball is placed on the foot spot, and the incoming player receives <dfn id="">ball-in-hand</dfn>.
Rule variations and governing bodies.
The general rules the game is played under are fairly consistent and usually do not stray too far from the format set forth in the Billiard Congress of America (BCA) , which have merged with those of the World Pool-Billiard Association (WPA), to form the World Standardised Rules, although amateur league play may be governed by similar but slightly different rules promulgated by the American Poolplayers Association (APA) and other organizations.
The rise of "Texas express" rules.
For much of its history nine-ball rules allowed participants to "<dfn id="">push out</dfn>" multiple times during a game "(see "The push-out", above, for the modern push-out rules)", meaning any player could call a "push-out", and then hit the cue ball to any area on the table without being penalized by normal <dfn id="">foul</dfn> rules, such as failure to contact the lowest-numbered ball on the table. However, once a push-out was called and executed, the incoming player had the right to shoot or give the inning back to the opponent. If the player shooting the resulting shot fouled, the other player would have ball-in-hand; hence this manner of play was called the "two-foul" version. "One-foul" became popular in the 1970s, as play turned more aggressive for the early televised matches. This newer version of nine-ball awarded ball-in-hand on any cue ball foul. A now-standard rule variant, which started to sweep the sport of nine-ball in the mid-1980s, restricted the push-out option to once per game and only to the inning immediately following the break. This change profoundly affected the way the game was played. By about 1990 this new push-out rule had become ubiquitous and it and any additional rules appended to it were collectively referred to as "<dfn id="">Texas express</dfn>" rules, so called because of the supposed US state of origin and the speeding up of the game. Today, Texas express push-out rules dominate the way nine-ball is played and is the variant incorporated into the official rules maintained by the WPA and its affiliates like the BCA.
European alterations.
As of the 2000s, the rules have been somewhat in flux in certain contexts, especially in Europe. The European Pocket Billiard Federation (EPBF), BCA's WPA-affiliate counterpart in Europe, has done away with standardized racking techniques, and instead relies upon <dfn id="">divots</dfn> in the cloth to position the balls, with no physical ball rack required; these indentations are carefully created using a "<dfn id="">training template</dfn>", such that the divots are slightly closer together than they would be expected to be, thus creating ball-on-ball pressure as the balls settle "partially" into the divot pattern, into which they cannot quite fit. This results in an especially tight rack, without any known possibility of cheating by carefully manipulating the ball positions while racking. This innovative racking technique was invented and patented as the Rack-M-Rite Racking Template by US professional player David Smith and his partner Dale Craig and first used in professional events on the Billiard Channel Tour in 2000 by tournament director David Vandenburgh. It is now the official rack of the EPBF Euro-Tour.
Another Euro-Tour innovation is a new requirement that the break shot be taken from a "<dfn id="">break box</dfn>", not unlike <dfn id="">the "D"</dfn> break shot zone used in snooker and blackball, consisting of the middle 50% of the <dfn id="">"kitchen"</dfn>. This change defeats the common break-from-the-side-rail technique for pocketing the 9 ball on the break and winning the game instantly. While 9 ball breaks are still possible, they are much more difficult under the new rule. This requirement was recently added to the Europe vs. US all-star team event, the Mosconi Cup, but has not otherwise been seen much by North Americans.
Yet a third EPBF change, used on the Euro-Tour for several years, is the "<dfn id="">three above the line</dfn>" rule, a stringent requirement that in order for a break shot to be legal, at least three object balls must either be pocketed or come up-table and "cross the <dfn id="">head string</dfn>". Failure to do so constitutes a loss-of-turn (but "not" <dfn id="">ball-in-hand</dfn>) foul – even if two object balls are pocketed, a potential major windfall for the non-breaking player under these rules. More stringently yet, the requirements are independent – if a ball crosses the head string and is then pocketed, it counts as a pocketed ball but "not" a head string-crossing ball. This alteration (from WPA's requirement that "one" object ball be pocketed or "four driven to cushions") requires a powerful break shot, and was instituted to thwart a different form of break manipulation, the recently developed "nine-ball soft break", in which a languid break performed correctly, and given a tight rack (such as that produced by EPBF template-trained racking), is almost guaranteed to pocket a <dfn id="">wing ball</dfn> in a <dfn id=">foot</dfn> <dfn id=">corner pocket</dfn>, perhaps even both wing balls, meanwhile the remaining balls stay mostly or entirely on the foot end of the table, giving the breaker an easy <dfn id=">run-out</dfn> of short shots. By effectively banning the soft break, wins "on a silver platter" are much less likely. One problem with this "three above the line" break requirement is that very careful attention must be paid to whether or not particular balls cross the head string, such that even professional referees have had to resort to video playback, as happened several times at the Mosconi Cup, when this rule, too, was introduced in 2007 by the MC's organizers, Matchroom Sport, in an effort to make the event more competitive and interesting to audiences, and more even (the US has mostly dominated the annual event since its inception, and they did in fact lose the 2007 match).
Another Mosconi Cup rule change in 2007 called for racking such that the 9 ball rather than the 1 ball is on the <dfn id="">foot spot</dfn> (i.e. the racker rolls the balls forward farther; the balls remain in the same position in the rack), which further thwarts pocketing a wing ball easily.
Derived games.
Three-ball (historical).
While the modern folk game of three-ball bears no resemblance to nine-ball, the earliest-known version of three-ball was essentially nine-ball played with only three balls, racked in a triangle, in which the 3 ball was the <dfn id="">money ball</dfn>. It is a quick game, and (due to the comparatively very high possibility of pocketing the 3 ball on the break) one with a more significant luck component than nine-ball and most other pool games.:254
Six-ball.
Six-ball is essentially identical to nine-ball but with three fewer balls, and racked in a three-row triangle, with the 6 ball (or more often the 15 ball; "see below") as the <dfn id="">money ball</dfn>, placed in the center of the back row.:224 According to Rudolph "Minnesota Fats" Wanderone, the game arose in early 20th century billiard halls that charged by the rack instead of by the hour, as nine-ball players had already paid for the 10–15 balls and did not want to waste them.:224 This explanation of the game's origin may be particularly plausible because six-ball remains popular today as a diversion or practice round among nine-ball-playing <dfn id="">bar pool</dfn> players, using coin-operated tables that deliver a full set of fifteen balls.
Seven-ball.
Seven-ball is a similar game, the primary differences being there are only seven object balls, racked in a hexagon, and the game is won by pocketing the 7 ball. Seven-ball is <dfn id="">racked</dfn> with the 1 ball at the apex on the <dfn id=">foot spot</dfn> and the 7 ball (the <dfn id=">money ball</dfn>) in the center of the hexagon. This game is not particularly common, and is primarily known because of ESPN's "Sudden Death Seven-ball" which aired in the early 2000s. Though hardly necessary, specialized equipment for the game can be purchased, including a unique black-striped seven ball and a hexagonal rack.
Ten-ball.
Ten-ball is a more stringent variant of the game, using ten balls (racked in a triangle with the 10 ball, the <dfn id="">money ball</dfn> in this case, in the center), in which all pocketed balls must be <dfn id=">called</dfn> and in which the money ball "cannot" be pocketed on the break for an instant win. Due to its more challenging nature, and the fact that there is no publicly known technique for reliably pocketing specific object balls on the break shot, there have been suggestions among the professional circuit that ten-ball should replace nine-ball as the pro game of choice, especially since the rise of the nine-ball soft break, which is still legal in most international and non-European competition. Regardless of the future of the nine-ball versus ten-ball debate, there are already hotly contested professional ten-ball tournaments.
9-Ball Kiss.
9-Ball Kiss (also carom nine) is played with the usual nine-ball rack, but breaking with the 1 ball, with the cue ball placed at the head of the rack (in the usual place of the 1 ball). As in regular 9-ball, play progresses from the lowest-numbered ball on the table; however a legal shot is made by shooting the object ball rather than the cue ball. The object ball must make first contact with the cue ball to count as a legal shot, the goal being to carom the object ball into a pocket (a kiss-shot) or into another ball. Once a legal shot has been performed, any ball then sunk counts for that player; the winner is the player to first pocket the 9-ball after a legal shot.
3-6-9 nine-ball.
A gambling version of nine-ball played with group of people. The game is played like regular 9 ball with a player order. Heckling the shooters is allowed but no touching may occur. Money balls are the three, six, and nine ball. Values of the money balls are 1-1-2 where each player pays out to the person who sunk a money ball. If the nine ball is sunk, the payout is the nine ball value and what ever money balls are left on the table. If a money ball is pocketed and the cue ball is scratched, that player must pay out that value to each of his opponents. Winner of the game has break on the next game, player before winner racks the next game.
References.
</dl>

</doc>
<doc id="21611" url="http://en.wikipedia.org/wiki?curid=21611" title="New World Order">
New World Order

New World Order, New world order or The New World Order may refer to:

</doc>
<doc id="21615" url="http://en.wikipedia.org/wiki?curid=21615" title="Nostradamus">
Nostradamus

Michel de Nostredame (depending on the source, 14 or 21 December 1503 – 2 July 1566), usually Latinised as Nostradamus, was a French apothecary and reputed seer who published collections of prophecies that have since become famous worldwide. He is best known for his book "Les Propheties", the first edition of which appeared in 1555. Since the publication of this book, which has rarely been out of print since his death, Nostradamus has attracted a following that, along with much of the popular press, credits him with predicting many major world events.
Most academic sources maintain that the associations made between world events and Nostradamus's quatrains are largely the result of misinterpretations or mistranslations (sometimes deliberate) or else are so tenuous as to render them useless as evidence of any genuine predictive power.
Biography.
Childhood.
Born on either 14 or 21 December 1503 in Saint-Rémy-de-Provence, Provence, France, where his claimed birthplace still exists, Michel de Nostredame was one of at least nine children of Reynière (or Renée) de Saint-Rémy and grain dealer and notary Jaume (or Jacques) de Nostredame. The latter's family had originally been Jewish, but Jaume's father, Guy Gassonet, had converted to Catholicism around 1455, taking the Christian name "Pierre" and the surname "Nostredame" (meaning "Our Lady", the saint's day on which his conversion was solemnised). Michel's known siblings included Delphine, Jean I (c. 1507–77), Pierre, Hector, Louis, Bertrand, Jean II (born 1522) and Antoine (born 1523).
Little else is known about his childhood, although there is a persistent tradition that he was educated by his maternal great-grandfather Jean de St. Rémy — a tradition which is somewhat undermined by the fact that the latter disappears from the historical record after 1504, when the child was only one year old.
Student years.
At the age of 15 Nostredame entered the University of Avignon to study for his baccalaureate. After little more than a year (when he would have studied the regular trivium of grammar, rhetoric and logic, rather than the later quadrivium of geometry, arithmetic, music and astronomy/astrology), he was forced to leave Avignon when the university closed its doors in the face of an outbreak of the plague. After leaving Avignon, Nostredame, by his own account, travelled the countryside for eight years from 1521 researching herbal remedies. In 1529, after some years as an apothecary, he entered the University of Montpellier to study for a doctorate in medicine. He was expelled shortly afterwards by the university's "procurator", Guillaume Rondelet, when it was discovered that he had been an apothecary, a "manual trade" expressly banned by the university statutes, and had been slandering doctors. The expulsion document, "BIU Montpellier, Register S 2 folio 87", still exists in the faculty library. However, some of his publishers and correspondents would later call him "Doctor". After his expulsion, Nostredame continued working, presumably still as an apothecary, and became famous for creating a "rose pill" that supposedly protected against the plague.
Marriage and healing work.
In 1531 Nostredame was invited by Jules-César Scaliger, a leading Renaissance scholar, to come to Agen. There he married a woman of uncertain name (possibly Henriette d'Encausse), who bore him two children.
 In 1534 his wife and children died, presumably from the plague. After their deaths, he continued to travel, passing through France and possibly Italy.
On his return in 1545, he assisted the prominent physician Louis Serre in his fight against a major plague outbreak in Marseille, and then tackled further outbreaks of disease on his own in Salon-de-Provence and in the regional capital, Aix-en-Provence. Finally, in 1547, he settled in Salon-de-Provence in the house which exists today, where he married a rich widow named Anne Ponsarde, with whom he had six children—three daughters and three sons. Between 1556 and 1567 he and his wife acquired a one-thirteenth share in a huge canal project organised by Adam de Craponne to irrigate largely waterless Salon-de-Provence and the nearby Désert de la Crau from the river Durance.
Seer.
After another visit to Italy, Nostredame began to move away from medicine and toward the occult. Following popular trends, he wrote an almanac for 1550, for the first time Latinising his name from Nostredame to Nostradam"us". He was so encouraged by the almanac's success that he decided to write one or more annually. Taken together, they are known to have contained at least 6,338 prophecies, as well as at least eleven annual calendars, all of them starting on 1 January and not, as is sometimes supposed, in March. It was mainly in response to the almanacs that the nobility and other prominent persons from far away soon started asking for horoscopes and "psychic" advice from him, though he generally expected "his clients" to supply the birth charts on which these would be based, rather than calculating them himself as a professional astrologer would have done. When obliged to attempt this himself on the basis of the published tables of the day, he frequently made errors and failed to adjust the figures for his clients' place or time of birth.
He then began his project of writing a book of one thousand mainly French quatrains, which constitute the largely undated prophecies for which he is most famous today. Feeling vulnerable to opposition on religious grounds, however, he devised a method of obscuring his meaning by using "Virgilianised" syntax, word games and a mixture of other languages such as Greek, Italian, Latin, and Provençal. For technical reasons connected with their publication in three installments (the publisher of the third and last installment seems to have been unwilling to start it in the middle of a "Century," or book of 100 verses), the last fifty-eight quatrains of the seventh "Century" have not survived in any extant edition.
The quatrains, published in a book titled "Les Propheties" (The Prophecies), received a mixed reaction when they were published. Some people thought Nostradamus was a servant of evil, a fake, or insane, while many of the elite evidently thought otherwise. Catherine de Médicis, wife of King Henry II of France, was one of Nostradamus' greatest admirers. After reading his almanacs for 1555, which hinted at unnamed threats to the royal family, she summoned him to Paris to explain them and to draw up horoscopes for her children. At the time, he feared that he would be beheaded, but by the time of his death in 1566, Queen Catherine had made him Counselor and Physician-in-Ordinary to her son, the young King Charles IX of France.
Some accounts of Nostradamus's life state that he was afraid of being persecuted for heresy by the Inquisition, but neither prophecy nor astrology fell in this bracket, and he would have been in danger only if he had practiced magic to support them. In fact, his relationship with the Church was always excellent. His brief imprisonment at Marignane in late 1561 was solely because he had violated a recent royal decree by publishing his 1562 almanac without the prior permission of a bishop.
Final years and death.
By 1566, Nostradamus's gout, which had plagued him painfully for many years and made movement very difficult, turned into edema, or dropsy. In late June he summoned his lawyer to draw up an extensive will bequeathing his property plus 3,444 crowns (around $300,000 US today), minus a few debts, to his wife pending her remarriage, in trust for her sons pending their twenty-fifth birthdays and her daughters pending their marriages. This was followed by a much shorter codicil. On the evening of 1 July, he is alleged to have told his secretary Jean de Chavigny, "You will not find me alive at sunrise." The next morning he was reportedly found dead, lying on the floor next to his bed and a bench (Presage 141 [originally 152] "for November 1567", as posthumously edited by Chavigny to fit what happened). He was buried in the local Franciscan chapel in Salon (part of it now incorporated into the restaurant "La Brocherie") but re-interred during the French Revolution in the Collégiale Saint-Laurent, where his tomb remains to this day.
Works.
In "The Prophecies" he compiled his collection of major, long-term predictions. The first installment was published in 1555 and contained 353 quatrains. The second, with 289 further prophetic verses, was printed in 1557. The third edition, with three hundred new quatrains, was reportedly printed in 1558, but now only survives as part of the omnibus edition that was published after his death in 1568. This version contains one unrhymed and 941 rhymed quatrains, grouped into nine sets of 100 and one of 42, called "Centuries".
Given printing practices at the time (which included type-setting "from dictation"), no two editions turned out to be identical, and it is relatively rare to find even two "copies" that are exactly the same. Certainly there is no warrant for assuming—as would-be "code-breakers" are prone to do—that either the spellings or the punctuation of any edition are Nostradamus' originals.
The "Almanacs", by far the most popular of his works, were published annually from 1550 until his death. He often published two or three in a year, entitled either "Almanachs" (detailed predictions), "Prognostications" or "Presages" (more generalised predictions).
Nostradamus was not only a diviner, but a professional healer. It is known that he wrote at least two books on medical science. One was an extremely free translation (or rather a paraphrase) of "The Protreptic" of Galen ("Paraphrase de C. GALIEN, sus l'Exhortation de Menodote aux estudes des bonnes Artz, mesmement Medicine"), and in his so-called "Traité des fardemens" (basically a medical cookbook containing, once again, materials borrowed mainly from others) he included a description of the methods he used to treat the plague, including bloodletting, none of which apparently worked. The same book also describes the preparation of cosmetics.
A manuscript normally known as the "Orus Apollo" also exists in the Lyon municipal library, where upwards of 2,000 original documents relating to Nostradamus are stored under the aegis of Michel Chomarat. It is a purported translation of an ancient Greek work on Egyptian hieroglyphs based on later Latin versions, all of them unfortunately ignorant of the true meanings of the ancient Egyptian script, which was not correctly deciphered until Champollion in the 19th century.
Since his death only the "Prophecies" have continued to be popular, but in this case they have been quite extraordinarily so. Over two hundred editions of them have appeared in that time, together with over 2,000 commentaries. Their persistence in popular culture seems to be partly due to the fact that their vagueness and lack of dating make it easy to quote them selectively after every major dramatic event and retrospectively claim them as "hits".
Origins of "The Prophecies".
Nostradamus claimed to base his published predictions on judicial astrology—the astrological 'judgement', or assessment, of the 'quality' (and thus potential) of events such as births, weddings, coronations etc.—but was heavily criticised by professional astrologers of the day such as Laurens Videl for incompetence and for assuming that "comparative horoscopy" (the comparison of future planetary configurations with those accompanying known past events) could actually predict what would happen in the future.
Research suggests that much of his prophetic work paraphrases collections of ancient end-of-the-world prophecies (mainly Bible-based), supplemented with references to historical events and anthologies of omen reports, and then projects those into the future in part with the aid of comparative horoscopy. Hence the many predictions involving ancient figures such as Sulla, Gaius Marius, Nero, and others, as well as his descriptions of "battles in the clouds" and "frogs falling from the sky." Astrology itself is mentioned only twice in Nostradamus's "Preface" and 41 times in the "Centuries" themselves, but more frequently in his dedicatory "Letter to King Henry II". In the last quatrain of his sixth "century" he specifically attacks astrologers.
His historical sources include easily identifiable passages from Livy, Suetonius, Plutarch and other classical historians, as well as from medieval chroniclers such as Geoffrey of Villehardouin and Jean Froissart. Many of his astrological references are taken almost word for word from Richard Roussat's "Livre de l'estat et mutations des temps" of 1549–50.
One of his major prophetic sources was evidently the "Mirabilis Liber" of 1522, which contained a range of prophecies by Pseudo-Methodius, the Tiburtine Sibyl, Joachim of Fiore, Savonarola and others (his "Preface" contains 24 biblical quotations, all but two in the order used by Savonarola). This book had enjoyed considerable success in the 1520s, when it went through half a dozen editions, but did not sustain its influence, perhaps owing to its mostly Latin text, Gothic script and many difficult abbreviations. Nostradamus was one of the first to re-paraphrase these prophecies in French, which may explain why they are credited to him. It should be noted that modern views of plagiarism did not apply in the 16th century; authors frequently copied and paraphrased passages without acknowledgement, especially from the classics. The latest research suggests that he may in fact have used bibliomancy for this—randomly selecting a book of history or prophecy and taking his cue from whatever page it happened to fall open at.
Further material was gleaned from the "De honesta disciplina" of 1504 by Petrus Crinitus, which included extracts from Michael Psellos's "De daemonibus", and the "De Mysteriis Aegyptiorum" (Concerning the mysteries of Egypt...), a book on Chaldean and Assyrian magic by Iamblichus, a 4th-century Neo-Platonist. Latin versions of both had recently been published in Lyon, and extracts from both are paraphrased (in the second case almost literally) in his first two verses, the first of which is appended to this article. While it is true that Nostradamus claimed in 1555 to have burned all of the occult works in his library, no one can say exactly what books were destroyed in this fire.
Only in the 17th century did people start to notice his reliance on earlier, mainly classical sources. This may help explain the fact that, during the same period, "The Prophecies" reportedly came into use in France as a classroom reader.
Nostradamus's reliance on historical precedent is reflected in the fact that he explicitly rejected the label "prophet" (i.e. a person having prophetic powers of his own) on several occasions:
Although, my son, I have used the word "prophet", I would not attribute to myself a title of such lofty sublimity—"Preface to César", 1555 (see caption to illustration above)
Not that I would attribute to myself either the name or the role of a prophet—"Preface to César", 1555
[S]ome of [the prophets] predicted great and marvelous things to come: [though] for me, I in no way attribute to myself such a title here.—"Letter to King Henry II", 1558
Not that I am foolish enough to claim to be a prophet.—Open letter to Privy Councillor (later Chancellor) Birague, 15 June 1566
His rejection of the title prophet is consistent with the fact that he entitled his book "Les Propheties de M. Michel Nostradamus" (a title that, in French, as easily means "The Prophecies, "by" M. Michel Nostradamus"—which is what they were—as "The Prophecies "of" M. Michel Nostradamus", which, except in a few cases, they were not, other than in the manner of their editing, expression and reapplication to the future).
Given this reliance on literary sources, it is doubtful whether Nostradamus used any particular methods for entering a trance state, other than contemplation, meditation and incubation. His sole description of this process is contained in "letter 41" of his collected Latin correspondence. The popular legend that he attempted the ancient methods of flame gazing, water gazing or both simultaneously is based on a naive reading of his first two verses, which merely liken his efforts to those of the Delphic and Branchidic oracles. The first of these is reproduced at the bottom of this article and the second can be seen by visiting the relevant facsimile site (see External Links). In his dedication to King Henri II, Nostradamus describes "emptying my soul, mind and heart of all care, worry and unease through mental calm and tranquility", but his frequent references to the "bronze tripod" of the Delphic rite are usually preceded by the words "as though" (compare, once again, External References to the original texts).
Interpretations.
Most of the quatrains deal with disasters, such as plagues, earthquakes, wars, floods, invasions, murders, droughts, and battles—all undated and based on foreshadowings by the "Mirabilis Liber". Some quatrains cover these disasters in overall terms; others concern a single person or small group of people. Some cover a single town, others several towns in several countries. A major, underlying theme is an impending invasion of Europe by Muslim forces from farther east and south headed by the expected Antichrist, directly reflecting the then-current Ottoman invasions and the earlier Saracen equivalents, as well as the prior expectations of the "Mirabilis Liber". All of this is presented in the context of the supposedly imminent end of the world—even though this is not in fact mentioned—a conviction that sparked numerous collections of end-time prophecies at the time, including an unpublished collection by Christopher Columbus.
Nostradamus has been credited, for the most part in hindsight, with predicting numerous events in world history, from the Great Fire of London, and the rise of Napoleon and Adolf Hitler, to the September 11 attacks on the World Trade Center. In 1992 one commentator who claimed to be able to contact Nostradamus under hypnosis even had him 'interpreting' his own verse X.6 (a prediction specifically about floods in southern France around the city of Nîmes and people taking refuge in its "collosse", or Colosseum, a Roman amphitheatre now known as the "Arènes") as a prediction of an undated "attack on the Pentagon", despite the historical seer's clear statement in his dedicatory letter to King Henri II that his prophecies were about Europe, North Africa and part of Asia Minor. Skeptics such as James Randi suggest that his reputation as a prophet is largely manufactured by modern-day supporters who fit his words to events that have either already occurred or are so imminent as to be inevitable, a process sometimes known as "retroactive clairvoyance" (postdiction). Thus, no Nostradamus quatrain is known to have been interpreted as predicting a specific event before it occurred, other than in vague, general terms that could equally apply to any number of other events. This even applies to quatrains that contain specific dates, such as III.77, which predicts "in 1727, in October, the king of Persia [shall be] captured by those of Egypt"—a prophecy that has, as ever, been interpreted retrospectively in the light of later events, in this case as though it presaged the known "peace treaty" between the Ottoman Empire and Persia of that year. Similarly, Nostradamus's notorious '1999' prophecy at X.72 (see Nostradamus in popular culture) describes no event that commentators have succeeded in identifying either before or since, other than by dint of twisting the words to fit whichever of the many contradictory happenings they are keen to claim as 'hits'. Moreover no quatrain suggests, as is often claimed by books and films on the alleged Mayan Prophecy, that the world would end in December 2012. In his preface to the "Prophecies", Nostradamus himself stated that his prophecies extend 'from now to the year 3797'—an extraordinary date which, given that the preface was written in 1555, may have more than a little to do with the fact that 2242 (3797 − 1555) had recently been proposed by his major astrological source Richard Roussat as a possible date for the end of the world.
Alternative views.
Views on Nostradamus have varied widely throughout history. At one end of the spectrum, there are extreme academic views such as those of Jacques Halbronn, who has suggested at great length and with great complexity that Nostradamus's "Prophecies" are antedated forgeries written by later hands with a political axe to grind. No other major source accepts this view [see reference-list].
At the other end of the spectrum, there are numerous fairly recent popular books, and thousands of private websites, suggesting not only that the "Prophecies" are genuine but that Nostradamus was a true prophet. Due to the subjective nature of these interpretations, however, no two of them agree on exactly what he predicted, whether for the past or for the future. Many of these do agree, though, that particular predictions refer, for example, to the French Revolution, Napoleon, Adolf Hitler, both world wars, and the nuclear destruction of Hiroshima and Nagasaki. There is also an evident consensus among popular authors that he predicted whatever major event had just happened at the time of each book's publication, from the Apollo moon landings, through the death of Diana, Princess of Wales in 1997, and the Space Shuttle "Challenger" disaster in 1986, to the events of 9/11: this 'movable feast' aspect appears to be characteristic of the genre.
Possibly the first of these books to become popular in English was Henry C. Roberts' "The Complete Prophecies of Nostradamus" of 1947, reprinted at least seven times during the next forty years, which contained both transcriptions and translations, with brief commentaries. This was followed in 1961 (reprinted in 1982) by Edgar Leoni's "Nostradamus and His Prophecies". After that came Erika Cheetham's "The Prophecies of Nostradamus", incorporating a reprint of the posthumous 1568 edition, which was reprinted, revised and republished several times from 1973 onwards, latterly as "The Final Prophecies of Nostradamus". This served as the basis for the documentary "The Man Who Saw Tomorrow" and both did indeed mention possible generalised future attacks on New York (via nuclear weapons), though not specifically on the World Trade Center or on any particular date. A two-part translation of Jean-Charles de Fontbrune's "Nostradamus: historien et prophète" was published in 1980, and John Hogue has published a number of books on Nostradamus from about 1987 including "Nostradamus and the Millenium: Predictions of the Future", "Nostradamus: The Complete Prophecies" (1999) and "Nostradamus: A Life and Myth" (2003).
With the exception of Roberts, these books and their many popular imitators were almost unanimous not merely about Nostradamus's powers of prophecy, but also about various aspects of his biography. He had been a descendant of the Israelite tribe of Issachar; he had been educated by his grandfathers, who had both been physicians to the court of Good King René of Provence; he had attended Montpellier University in 1525 to gain his first degree; after returning there in 1529, he had successfully taken his medical doctorate; he had gone on to lecture in the Medical Faculty there, until his views became too unpopular; he had supported the heliocentric view of the universe; he had travelled to the north-east of France, where he had composed prophecies at the abbey of Orval; in the course of his travels, he had performed a variety of prodigies, including identifying a future Pope; he had successfully cured the Plague at Aix-en-Provence and elsewhere; he had engaged in scrying, using either a magic mirror or a bowl of water; he had been joined by his secretary Chavigny at Easter 1554; having published the first installment of his "Propheties", he had been summoned by Queen Catherine de' Medici to Paris in 1556 to discuss with her his prophecy at quatrain I.35 that her husband King Henri II would be killed in a duel; he had examined the royal children at Blois; he had bequeathed to his son a "lost book" of his own prophetic paintings; he had been buried standing up; and he had been found, when dug up at the French Revolution, to be wearing a medallion bearing the exact date of his disinterment.
Curiously, this particular story seems to have been first recorded by Samuel Pepys "as early as 1667", long before the French Revolution. Pepys records in his celebrated diary a legend that, before his death, Nostradamus made the townsfolk swear that his grave would never be disturbed; but that 60 years later his body was exhumed, whereupon a brass plaque was found on his chest correctly stating the date and time when his grave would be opened and cursing the exhumers.
From the 1980s onwards, however, an academic reaction set in, especially in France. The publication in 1983 of Nostradamus's private correspondence and, during succeeding years, of the original editions of 1555 and 1557 discovered by Chomarat and Benazra, together with the unearthing of much original archival material revealed that much that was claimed about Nostradamus did not fit the documented facts. The academics revealed that "not one" of the claims just listed was backed up by any known contemporary documentary evidence. Most of them had evidently been based on unsourced rumours relayed as fact by much later commentators, such as Jaubert (1656), Guynaud (1693) and Bareste (1840), on modern misunderstandings of the 16th-century French texts, or on pure invention. Even the often-advanced suggestion that quatrain I.35 had successfully prophesied King Henri II's death did not actually appear in print for the first time until 1614, 55 years after the event.
Additionally, the academics, who themselves tend to eschew any attempt at interpretation, complained that the English translations were usually of poor quality, seemed to display little or no knowledge of 16th-century French, were tendentious and, at worst, were sometimes twisted to fit the events to which they were supposed to refer (or vice versa). None of them were based on the original editions: Roberts had based his writings on that of 1672, Cheetham and Hogue on the posthumous edition of 1568. Even Leoni accepted on page 115 that he had never seen an original edition, and on earlier pages he indicated that much of his biographical material was unsourced.
However, none of this research and criticism was originally known to most of the English-language commentators, by function of the dates when they were writing and, to some extent, of the language in which it was written. Hogue was in a position to take advantage of it, but it was only in 2003 that he accepted that some of his earlier biographical material had in fact been apocryphal. Meanwhile some of the more recent sources listed (Lemesurier, Gruber, Wilson) have been particularly scathing about later attempts by some lesser-known authors and Internet enthusiasts to extract alleged hidden meanings from the texts, whether with the aid of anagrams, numerical codes, graphs or otherwise.
In popular culture.
The prophecies retold and expanded by Nostradamus figured largely in popular culture in the 20th and 21st centuries. As well as being the subject of hundreds of books (both fiction and nonfiction), Nostradamus's life has been depicted in several films and videos, and his life and writings continue to be a subject of media interest.
There have also been several well-known Internet hoaxes, where quatrains in the style of Nostradamus have been circulated by e-mail as the real thing. The best-known examples concern the collapse of the World Trade Center in the 11 September attacks, which led both to hoaxes and to reinterpretations by enthusiasts of several quatrains as supposed prophecies.
With the arrival of the year 2012, Nostradamus's prophecies started to be co-opted (especially by the History Channel) as evidence suggesting that the end of the world was imminent, notwithstanding the fact that his book never mentions the end of the world, let alone the year 2012.
References.
Notes
References
Sources
</dl>
External links.
The following websites are or aim to be factual, and consistent with the article, rather than speculative or fictional in character.

</doc>
<doc id="21619" url="http://en.wikipedia.org/wiki?curid=21619" title="List of multi-level marketing companies">
List of multi-level marketing companies

This is a list of companies which use multi-level marketing (also known as network marketing, direct selling, referral marketing, and pyramid selling) for most of their sales.

</doc>
<doc id="21620" url="http://en.wikipedia.org/wiki?curid=21620" title="Noah Webster">
Noah Webster

Noah Webster, Jr. (October 16, 1758 – May 28, 1843), was an American lexicographer, textbook pioneer, English-language spelling reformer, political writer, editor, and prolific author. He has been called the "Father of American Scholarship and Education." His blue-backed speller books taught five generations of American children how to spell and read, secularizing their education. According to Ellis (1979) he gave Americans "a secular catechism to the nation-state."
Webster's name has become synonymous with "dictionary" in the United States, especially the modern Merriam-Webster dictionary that was first published in 1828 as "An American Dictionary of the English Language". He was one of the Founding Fathers of the nation.
Biography.
Webster was born in West Hartford, Connecticut, to an established family. His father, Noah Sr. (1722–1813), was a descendant of Connecticut Governor John Webster; his mother Mercy ("née" Steele; 1727–1794) was a descendant of Governor William Bradford of Plymouth Colony. His father was primarily a farmer though he was also deacon of the local Congregational church, captain of the town's militia, and a founder of a local book society—a precursor to the public library. After American independence, he was appointed a justice of the peace.
Though Webster's father never attended college, he was intellectually curious and prized education; his mother spent long hours teaching Noah and his siblings spelling, mathematics and music. At the age of six, Webster began attending a dilapidated one room primary school that had been built by West Hartford's Ecclesiastical Society. Many years later, he described the teachers as the "dregs of humanity" and complained that the instruction was mainly in religion. Webster's negative experiences in primary school motivated him to improve the educational experience of future generations.
At the age of fourteen, he began receiving tutoring in Latin and Greek from his church pastor to prepare for entrance to Yale College. He enrolled at Yale just shy of his 16th birthday, studying during his senior year with the learned Ezra Stiles, Yale's president. His four years at Yale overlapped with the American Revolutionary War, and because of food shortages and threatened invasions by the British, many of his college classes were held in other towns. He served in the Connecticut Militia. His father had mortgaged the farm to send Webster to Yale, but the son was now on his own and had no more to do with his family.
Webster lacked firm career plans after graduating from Yale in 1778, later writing that a liberal arts education "disqualifies a man for business." He briefly taught school in Glastonbury, found the working conditions to be harsh and the pay low, then left to study law to increase in earning power. While studying law under the mentorship of Oliver Ellsworth, the future U.S. Supreme Court Chief Justice, Webster held a full-time job teaching in Hartford—a schedule he found grueling, and ultimately impossible to sustain. After quitting his legal studies for a year and lapsing into a depression, he found another practicing attorney to mentor him, completing his studies and passing the bar examination in 1781. However, with the Revolutionary War still ongoing, he could not find employment as a lawyer. He picked up a master's degree from Yale for giving an oral dissertation to the Yale graduating class, and later that year opened a small, private school in western Connecticut that was an instant success, though he quickly closed it and left town—likely due to a failed romance. Turning to literary work as a way to overcome his losses and channel his ambitions, he began writing a series of well-received articles for a prominent New England newspaper justifying and praising the American Revolution and arguing that the separation from Britain was permanent. He then founded a private school catering to wealthy parents in Goshen, New York, and by 1785, he had written his speller, a grammar book and a reader for elementary schools. Proceeds from continuing sales of the popular blue-backed speller enabled Webster to spend many years working on his famous dictionary.
Political vision.
Webster was by nature a revolutionary, seeking American independence from the cultural thralldom to Britain. To replace it he sought to create a utopian America, cleansed of luxury and ostentation and the champion of freedom. By 1781, Webster had an expansive view of the new nation. American nationalism was superior to Europe because American values were superior, he claimed.
 America sees the absurdities—she sees the kingdoms of Europe, disturbed by wrangling sectaries, or their commerce, population and improvements of every kind cramped and retarded, because the human mind like the body is fettered 'and bound fast by the chords of policy and superstition': She laughs at their folly and shuns their errors: She founds her empire upon the idea of universal toleration: She admits all religions into her bosom; She secures the sacred rights of every individual; and (astonishing absurdity to Europeans!) she sees a thousand discordant opinions live in the strictest harmony ... it will finally raise her to a pitch of greatness and lustre, before which the glory of ancient Greece and Rome shall dwindle to a point, and the splendor of modern Empires fade into obscurity.
Webster dedicated his "Speller" and "Dictionary" to providing an intellectual foundation for American nationalism. From 1787 to 1789 Webster was an outspoken supporter of the new Constitution. In October 1787, he wrote a pamphlet titled "An Examination into the Leading Principles of the Federal Constitution Proposed by the Late Convention Held at Philadelphia," published under the pen name "A Citizen of America." The pamphlet was influential, particularly outside New York State.
In terms of political theory, he deemphasized virtue (a core value of republicanism) and emphasized widespread ownership of property (a key element of liberalism). He was one of the few Americans who paid much attention to the French theorist Jean Jacques Rousseau. It was not Rousseau's politics but his ideas on pedagogy in "Emile" (1762) that influenced Webster in adjusting his "Speller" to the stages of a child's development.
Federalist editor.
Webster married well and had joined the elite in Hartford but did not have much money. In 1793, Alexander Hamilton lent him $1,500 to move to New York City to edit the leading Federalist Party newspaper. In December, he founded New York's first daily newspaper, "American Minerva" (later known as the "Commercial Advertiser"), and edited it for four years, writing the equivalent of 20 volumes of articles and editorials. He also published the semi-weekly publication, "The Herald, A Gazette for the country" (later known as "The New York Spectator").
As a Federalist spokesman, he was repeatedly denounced by the Jeffersonian Republicans as "a pusillanimous, half-begotten, self-dubbed patriot," "an incurable lunatic," and "a deceitful newsmonger ... Pedagogue and Quack." Rival Federalist pamphleteer "Peter Porcupine" (William Cobbett) said Webster's pro-French views made him "a traitor to the cause of Federalism," calling him "a toad in the service of sans-cullottism," "a prostitute wretch," "a great fool, and a barefaced liar," "a spiteful viper," and "a maniacal pedant." Webster, the consummate master of words, was distressed. Even the use of words like "the people," "democracy," and "equality" in public debate bothered him, for such words were "metaphysical abstractions that either have no meaning, or at least none that mere mortals can comprehend."
Webster followed French radical thought and urged a neutral foreign policy when France and Britain went to war in 1793. But when French minister Citizen Genêt set up a network of pro-Jacobin "Democratic-Republican Societies" that entered American politics and attacked President Washington, Webster condemned them. He called on fellow Federalist editors to "all agree to let the clubs alone—publish nothing for or against them. They are a plant of exotic and forced birth: the sunshine of peace will destroy them." He was elected a Fellow of the American Academy of Arts and Sciences in 1799.
For decades, he was one of the most prolific authors in the new nation, publishing textbooks, political essays, a report on infectious diseases, and newspaper articles for his Federalist party. He wrote so much that a modern bibliography of his published works required 655 pages. He moved back to New Haven in 1798; he was elected as a Federalist to the Connecticut House of Representatives in 1800 and 1802–1807.
Copyright.
Politician Daniel Webster was Noah Webster's distant relative; he sponsored Noah's proposed copyright bill. The first major statutory revision of U.S. copyright law, the 1831 Act was a result of intensive lobbying by Noah Webster and his agents in Congress. Webster also played a critical role lobbying individual states throughout the country during the 1780s to pass the first American copyright laws, which were expected to have distinct nationalistic implications for the infant nation.
Blue-Backed Speller.
As a teacher, he had come to dislike American elementary schools. They could be overcrowded, with up to seventy children of all ages crammed into one-room schoolhouses. They had poor underpaid staff, no desks, and unsatisfactory textbooks that came from England. Webster thought that Americans should learn from American books, so he began writing a three volume compendium, "A Grammatical Institute of the English Language". The work consisted of a speller (published in 1783), a grammar (published in 1784), and a reader (published in 1785). His goal was to provide a uniquely American approach to training children. His most important improvement, he claimed, was to rescue "our native tongue" from "the clamour of pedantry" that surrounded English grammar and pronunciation. He complained that the English language had been corrupted by the British aristocracy, which set its own standard for proper spelling and pronunciation. Webster rejected the notion that the study of Greek and Latin must precede the study of English grammar. The appropriate standard for the American language, argued Webster, was "the same republican principles as American civil and ecclesiastical constitutions." This meant that the people-at-large must control the language; popular sovereignty in government must be accompanied by popular usage in language.
The "Speller" was arranged so that it could be easily taught to students, and it progressed by age. From his own experiences as a teacher, Webster thought the "Speller" should be simple and gave an orderly presentation of words and the rules of spelling and pronunciation. He believed students learned most readily when he broke a complex problem into its component parts and had each pupil master one part before moving to the next. Ellis argues that Webster anticipated some of the insights currently associated with Jean Piaget's theory of cognitive development. Webster said that children pass through distinctive learning phases in which they master increasingly complex or abstract tasks. Therefore, teachers must not try to teach a three-year-old how to read; they could not do it until age five. He organized his speller accordingly, beginning with the alphabet and moving systematically through the different sounds of vowels and consonants, then syllables, then simple words, then more complex words, then sentences.
The speller was originally titled "The First Part of the Grammatical Institute of the English Language". Over the course of 385 editions in his lifetime, the title was changed in 1786 to "The American Spelling Book", and again in 1829 to "The Elementary Spelling Book". Most people called it the "Blue-Backed Speller" because of its blue cover, and for the next one hundred years, Webster's book taught children how to read, spell, and pronounce words. It was the most popular American book of its time; by 1837 it had sold 15 million copies, and some 60 million by 1890—reaching the majority of young students in the nation's first century. Its royalty of a half-cent per copy was enough to sustain Webster in his other endeavors. It also helped create the popular contests known as spelling bees.
As time went on, Webster changed the spellings in the book to more phonetic ones. Most of them already existed as alternative spellings. He chose spellings like "defense", "color" and "traveler", and changed the "re" to "er" in words like "center". He also changed "tongue" to the older spelling "tung", but this did not catch on.
Part three of his "Grammatical Institute" (1785) was a reader designed to uplift the mind and "diffuse the principles of virtue and patriotism."
Students received the usual quota of Plutarch, Shakespeare, Swift, and Addison, as well as such Americans as Joel Barlow's "Vision of Columbus", Timothy Dwight's "Conquest of Canaan", and John Trumbull's poem "M'Fingal." He included excerpts from Tom Paine's "The Crisis" and an essay by Thomas Day calling for the abolition of slavery in accord with the Declaration of Independence.
Webster's "Speller" was entirely secular by design. It ended with two pages of important dates in American history, beginning with Columbus's in 1492 and ending with the battle of Yorktown in 1781. There was no mention of God, the Bible, or sacred events. "Let sacred things be appropriated for sacred purposes," wrote Webster. As Ellis explains, "Webster began to construct a secular catechism to the nation-state. Here was the first appearance of 'civics' in American schoolbooks. In this sense, Webster's speller becoming what was to be the secular successor to "The New England Primer" with its explicitly biblical injunctions." Later in life Webster became intensely religious and added religious themes. However after 1840 Webster's books lost market share to the "McGuffey Eclectic Readers" of William Holmes McGuffey, which sold over 120 million copies.
Vincent P. Bynack (1984) examines Webster in relation to his commitment to the idea of a unified American national culture that would stave off the decline of republican virtues and solidarity. Webster acquired his perspective on language from such theorists as Maupertuis, Michaelis, and Herder. There he found the belief that a nation's linguistic forms and the thoughts correlated with them shaped individuals' behavior. Thus the etymological clarification and reform of American English promised to improve citizens' manners and thereby preserve republican purity and social stability. This presupposition animated Webster's "Speller" and "Grammar".
Dictionary.
Publication.
In 1806, Webster published his first dictionary, . In 1807 Webster began compiling an expanded and fully comprehensive dictionary, "An American Dictionary of the English Language;" it took twenty-six years to complete. To evaluate the etymology of words, Webster learned twenty-eight languages, including Old English (Anglo-Saxon), Gothic, German, Greek, Latin, Italian, Spanish, French, Dutch, Welsh, Russian, Hebrew, Aramaic, Persian, Arabic, and Sanskrit. Webster hoped to standardize American speech, since Americans in different parts of the country used different languages. They also spelled, pronounced, and used English words differently.
Webster completed his dictionary during his year abroad in January 1825 in a boarding house in Cambridge, England. His book contained seventy thousand words, of which twelve thousand had never appeared in a published dictionary before. As a spelling reformer, Webster preferred spellings that matched pronunciation better. In "A Companion to the American Revolution" (2008), John Algeo notes: "It is often assumed that characteristically American spellings were invented by Noah Webster. He was very influential in popularizing certain spellings in America, but he did not originate them. Rather […] he chose already existing options such as "center, color" and "check" on such grounds as simplicity, analogy or etymology." He also added American words, like "skunk" and "squash," that did not appear in British dictionaries. At the age of seventy, Webster published his dictionary in 1828, registering the copyright on April 14.
Though it now has an honored place in the history of American English, Webster's first dictionary only sold 2,500 copies. He was forced to mortgage his home to develop a second edition, and his life from then on was plagued with debt.
In 1840, the second edition was published in two volumes. On May 28, 1843, a few days after he had completed revising an appendix to the second edition, and with much of his efforts with the dictionary still unrecognized, Noah Webster died.
Impact.
Lepore (2008) demonstrates Webster's paradoxical ideas about language and politics and shows why Webster's endeavors were at first so poorly received. Culturally conservative Federalists denounced the work as radical—too inclusive in its lexicon and even bordering on vulgar. Meanwhile Webster's old foes the Republicans attacked the man, labeling him mad for such an undertaking.
Scholars have long seen Webster's 1844 dictionary to be an important resource for reading poet Emily Dickinson's life and work; she once commented that the "Lexicon" was her "only companion" for years. One biographer said, "The dictionary was no mere reference book to her; she read it as a priest his breviary – over and over, page by page, with utter absorption."
Webster's dictionaries dominated the English speaking world. In 1850, for example, Blackie and Son in Glasgow published the first general dictionary of English that relied heavily upon pictorial illustrations integrated with the text. Its "The Imperial Dictionary, English, Technological, and Scientific, Adapted to the Present State of Literature, Science, and Art; On the Basis of Webster's English Dictionary" used Webster's for most of their text, adding some additional technical words that went with illustrations of machinery.
Religious views.
Webster in early life was something of a freethinker, but in 1808 he became a convert to Calvinistic orthodoxy, and thereafter became a devout Congregationalist who preached the need to Christianize the nation. Webster grew increasingly authoritarian and elitist, fighting against the prevailing grain of Jacksonian Democracy. Webster viewed language as a tool to control unruly thoughts. His "American Dictionary" emphasized the virtues of social control over human passions and individualism, submission to authority, and fear of God; they were necessary for the maintenance of the American social order. As he grew older, Webster's attitudes changed from those of an optimistic revolutionary in the 1780s to those of a pessimistic critic of man and society by the 1820s.
His 1828 "American Dictionary" contained the greatest number of Biblical definitions given in any reference volume. Webster considered education "useless without the Bible." Webster released his own edition of the Bible in 1833, called the Common Version. He used the King James Version (KJV) as a base and consulted the Hebrew and Greek along with various other versions and commentaries. Webster molded the KJV to correct grammar, replaced words that were no longer used, and did away with words and phrases that could be seen as offensive.
In 1834, he published an apologetic book in defense of The Bible and Christianity itself.
Opposition to slavery.
Webster helped found the Connecticut Society for the Abolition of Slavery in 1791, but by the 1830s rejected the new tone among abolitionists that emphasized Americans who tolerated slavery were themselves sinners. In 1837, Webster warned his daughter Eliza about her fervent support of the abolitionist cause. Webster wrote, "slavery is a great sin and a general calamity – but it is not "our" sin, though it may prove to be a terrible calamity to us in the north. But we cannot legally interfere with the South on this subject." He added, "To come north to preach and thus disturb "our" peace, when we can legally do nothing to effect this object, is, in my view, highly criminal and the preachers of abolitionism deserve the penitentiary."
Family.
Noah Webster married Rebecca Greenleaf (1766–1847) on October 26, 1789, New Haven, Connecticut. They had eight children:
He moved to Amherst, Massachusetts in 1812, where he helped to found Amherst College. In 1822 the family moved back to New Haven, where Webster was awarded an honorary degree from Yale the following year. He is buried in New Haven's Grove Street Cemetery.

</doc>
<doc id="21626" url="http://en.wikipedia.org/wiki?curid=21626" title="Near-Earth object">
Near-Earth object

A near-Earth object (NEO) is a Solar System object whose orbit brings it into proximity with Earth. All NEOs have a closest approach to the Sun (perihelion) of less than 1.3 AU. They include more than ten thousand near-Earth asteroids (NEAs), near-Earth comets, a number of solar-orbiting spacecraft, and meteoroids large enough to be tracked in space before striking the Earth. It is now widely accepted that collisions in the past have had a significant role in shaping the geological and biological history of the planet. NEOs have become of increased interest since the 1980s because of increased awareness of the potential danger some of the asteroids or comets pose to Earth, and active mitigations are being researched.
Those NEOs that are asteroids (NEA) have orbits that lie partly between 0.983 and 1.3 astronomical units away from the Sun. When an NEA is detected it is submitted to the IAU's Minor Planet Center (located at the Harvard–Smithsonian Center for Astrophysics) for cataloging. Some near-Earth asteroids' orbits intersect that of Earth's so they pose a collision danger. The United States, European Union, and other nations are currently scanning for NEOs in an effort called Spaceguard.
In the United States, NASA has a congressional mandate to catalogue all NEOs that are at least 1 kilometer wide, as the impact of such an object would be catastrophic. s of 2015[ [update]], there have been 867 near-Earth asteroids larger than 1 km discovered, of which 153 are potentially hazardous asteroids (PHAs). It was estimated in 2006 that 20% of the mandated objects have not yet been found. As a result of NEOWISE in 2011, it is estimated that 93% of the NEAs larger than 1 km have been found and that only about 70 remain to be discovered. Our inventory is much less complete for smaller objects, which still have potential for large scale damage.
Potentially hazardous objects (PHOs) are currently defined based on parameters that measure the object's potential to make threatening close approaches to the Earth. Mostly objects with an Earth minimum orbit intersection distance (MOID) of 0.05 AU or less and an absolute magnitude (H) of 22.0 or brighter (a rough indicator of large size) are considered PHOs. Objects that cannot approach closer to the Earth (i.e. MOID) than 0.05 AU, or are smaller than about 150 m (500 ft) in diameter (i.e. H = 22.0 with assumed albedo of 13%), are not considered PHOs. The NASA Near Earth Object Catalog also includes the approach distances of asteroids and comets measured in lunar distances, and this usage has become a common unit of measure used by the news media in discussing these objects.
Some NEOs are of high interest because they can be physically explored with lower mission velocity even than the Moon, due to their combination of low velocity with respect to Earth (ΔV) and small gravity, so they may present interesting scientific opportunities both for direct geochemical and astronomical investigation, and as potentially economical sources of extraterrestrial materials for human exploitation. This makes them an attractive target for exploration. As of 2012, three near-Earth objects have been visited by spacecraft: 433 Eros, by NASA's Near Earth Asteroid Rendezvous probe, 25143 Itokawa, by the JAXA Hayabusa mission, and 4179 Toutatis, by CNSA's Chang'e 2 spacecraft.
History of human awareness of NEOs.
Human perception of near-Earth objects as benign objects of fascination or killer objects with high risk to human society have ebbed and flowed in the short period of human history that NEOS have been scientifically observed.
Risk.
More recently, a typical frame of reference for looking at NEOs has been through the scientific concept of risk. In this frame, the risk that any near-Earth object poses is typically seen through a lens that is a function of both the culture and the technology of human society. "NEOs have been understood differently throughout history." Each time an NEO is observed, "a different risk was posed, and throughout time that risk perception has evolved. It is not just a matter of scientific knowledge."
Such perception of risk is thus "a product of religious belief, philosophic principles, scientific understanding, technological capabilities, and even economical resourcefulness."
Risk scales.
There are two schemes for the scientific classification of impact hazards from NEOs:
The annual background frequency used in the Palermo scale for impacts of energy greater than "E" megatonnes is estimated as:
For instance, this formula implies that the expected value of the time from now until the next impact greater than 1 megatonne is 33 years, and that when it occurs, there is a 50% chance that it will be above 2.4 megatonnes. This formula is only valid over a certain range of "E".
However, another paper published in 2002 – the same year as the paper on which the Palermo scale is based – found a power law with different constants:
This formula gives considerably lower rates for a given "E". For instance, it gives the rate for bolides of 10 megatonnes or more (like the Tunguska explosion) as 1 per thousand years, rather than 1 per 210 years as in the Palermo formula. However, the authors give a rather large uncertainty (once in 400 to 1800 years for 10 megatonnes), due in part to uncertainties in determining the energies of the atmospheric impacts that they used in their determination.
Highly rated risks.
On 24 December 2004, minor planet 99942 Apophis (at the time known by its provisional designation 2004 MN4) was assigned a 4 on the Torino scale, the highest rating ever achieved. There was a 2.7% chance of Earth impact on 13 April 2029. However, on 28 December 2004, the risk of impact dropped to zero for 2029, but future potential impact solutions were still rated 1 on the Torino scale. The 2036 risk was lowered to a Torino rating of 0 in August 2006. Apophis has no chance of impacting Earth before 2060.
The only known NEO with a Palermo scale value currently greater than zero is (29075) 1950 DA, which may pass very close to or collide with the Earth (probability ≤ 0.003) in the year 2880. Depending on the unknown orientation of its axis of rotation, it will either miss the Earth by tens of millions of kilometers, or have a 1 in 300 chance of hitting the Earth. However, humanity has over 800 years to refine the orbit of (29075) 1950 DA, and to deflect it, if necessary.
List of current threats.
NASA maintains a continuously updated Sentry Risk Table of the most significant NEO threats in the next 100 years. All or nearly all of the objects are highly likely to eventually drop off the list as more observations come in, reducing the uncertainties and enabling more accurate orbital predictions. (The list does not include (29075) 1950 DA, because that will not strike for at least 800 years.)
History of NEO science and exploratory mission proposals.
In a 2013 article in Wired Science, David Portree provides an overview of NEO science and proposed asteroidal missions, with an emphasis on the outcome of two conferences held in the 1970s. The International Astronomical Union minor planets workshop was held in Tucson, Arizona in March 1971 and a consensus "emerged that launching spacecraft to asteroids would be 'premature'."
"In January 1978, NASA’s Office of Space Science held a workshop at the University of Chicago to "assess the state of asteroid studies and consider options for the future."
Of all of the near-Earth asteroids (NEA) that had been discovered by mid-1977, it was estimated that spacecraft could rendezvous with and return from only about one in 10 using less propulsive energy than is necessary to reach Mars. "Because even the most massive NEA—35 km-wide 1036 Ganymed, discovered in 1924, has a very low surface gravity—landing and takeoff would need very little energy. This meant that a single spacecraft could sample multiple sites on any given NEA." 
Overall, it was estimated that about one percent of all NEAs might provide opportunities for human-crewed missions, or no more than about ten known NEAs. Therefore, unless the NEA discovery rate were "immediately increased five-fold, no opportunity to launch 'astronaut-scientists' to an NEA was likely to occur within a decade of the Chicago workshop."
Number and classification of near-Earth objects.
Near-Earth objects are classified as meteoroids, asteroids, or comets depending on size and composition. Asteroids can also be members of an asteroid family, and comets create meteoroid streams that can generate meteor showers.
s of 2014[ [update]], 10,713 NEOs have been discovered: 94 near-Earth comets and 10,619 near-Earth asteroids. Of those there are 815 Aten asteroids, 4,016 Amor asteroids, and 5,775 Apollo asteroids. There are 1,458 NEOs that are classified as potentially hazardous asteroids (PHAs). Currently, 154 PHAs and 867 NEAs have an absolute magnitude of 17.75 or brighter, which roughly corresponds to at least 1 km in size.
s of 2014[ [update]], there are 499 NEAs on the Sentry impact risk page at the NASA website. A significant number of these NEAs – 215 as of 2010[ [update]] – are equal to or smaller than 50 meters in diameter and none of the listed objects are placed even in the "green/yellow zone" (Torino Scale 1-2), meaning that none warrant the attention of general public. The JPL Small-Body Database lists 1,885 near Earth asteroids with an absolute magnitude (H) dimmer than 25 (roughly 50 meters in diameter).
Near-Earth asteroids smaller than ~1 meter are near-Earth meteoroids and are listed as asteroids on most asteroid tables. The smallest known near-Earth meteoroid is 2008 TS26 with an absolute magnitude of 33 and estimated size of only 1 meter.
Near-Earth asteroids.
These are objects in a near-Earth orbit without the tail or coma of a comet. s of 2015[ [update]], 12,113 near-Earth asteroids are known, ranging in size from 1 meter up to ~32 kilometers (1036 Ganymed). The number of near-Earth asteroids over one kilometer in diameter is estimated to be about 981, of which over 90% have been discovered. There are about 1 million near-Earth asteroids about 40 meters in diameter—of which about 1 percent have been discovered. The composition of near-Earth asteroids is comparable to that of asteroids from the asteroid belt, reflecting a variety of asteroid spectral types.
NEAs survive in their orbits for just a few million years. They are eventually eliminated by planetary perturbations, causing ejection from the Solar System or a collision with the Sun or a planet. With orbital lifetimes short compared to the age of the Solar System, new asteroids must be constantly moved into near-Earth orbits to explain the observed asteroids. The accepted origin of these asteroids is that asteroid-belt asteroids are moved into the inner Solar System through orbital resonances with Jupiter. The interaction with Jupiter through the resonance perturbs the asteroid's orbit and it comes into the inner Solar System. The asteroid belt has gaps, known as Kirkwood gaps, where these resonances occur as the asteroids in these resonances have been moved onto other orbits. New asteroids migrate into these resonances, due to the Yarkovsky effect that provides a continuing supply of near-Earth asteroids. The known asteroid with the greatest known chance of impacting Earth is 2010 RF12 with a 1 in 16 chance of impacting Earth on 5 September 2095. Its 7-meter estimated diameter ensures that an impact would cause little damage.
A small number of NEOs are extinct comets that have lost their volatile surface materials, although having a faint or intermittent comet-like tail does not necessarily result in a classification as a near-Earth comet, making the boundaries somewhat fuzzy. The rest of the near-Earth asteroids are driven out of the asteroid belt by gravitational interactions with Jupiter.
Near-Earth asteroids are divided into groups based on their semi-major axis (a), perihelion distance (q), and aphelion distance (Q):
Atiras and Amors do not cross the Earth's orbit and are not immediate impact threats, but their orbits may change to become Earth-crossing orbits in the future.
Near-Earth comets.
s of 2015[ [update]], 96 near-Earth comets have been discovered. Although no impact of a comet in Earth's history has been conclusively confirmed, the Tunguska event may have been caused by a fragment of Comet Encke. Cometary fragmenting may also be responsible for some impacts from near-Earth objects. It is rare for a comet to pass within 0.1 AU of Earth.
These near-Earth objects were probably derived from the Kuiper belt, beyond the orbit of Neptune.
Impact rate.
Stony asteroids with a diameter of 4 m impact Earth approximately once per year. Asteroids with a diameter of roughly 7 meters enter Earth's atmosphere with as much energy as Little Boy (the atomic bomb dropped on Hiroshima, approximately 15 kilotonnes of TNT) about every 5 years. These ordinarily explode in the upper atmosphere, and most or all of the solids are vaporized. Every 2,000–3,000 years, objects produce explosions of 10 megatons comparable to the one observed at Tunguska in 1908. Objects with a diameter of one kilometer hit the Earth an average of twice every million year interval. Large collisions with five kilometer objects happen approximately once every twenty million years.
Assuming that these rates will continue for the next billion years, there exist at least 2,000 objects of diameter greater than 1 km that will eventually hit Earth. However, most of these are not yet considered potentially hazardous objects because they are currently orbiting between Mars and Jupiter. Eventually they will change orbits and become NEOs. Objects spend on average a few million years as NEOs before hitting the Sun, being ejected from the Solar System, or (for a small proportion) hitting a planet.
Frequency of small asteroids roughly 1 to 20 meters in diameter impacting Earth's atmosphere.
Close approaches.
On August 10, 1972, a meteor that became known as 1972 Great Daylight Fireball was witnessed by many people moving north over the Rocky Mountains from the U.S. Southwest to Canada. It was an Earth-grazing meteoroid that passed within 57 kilometers (about 34 miles) of the Earth's surface. It was filmed by a tourist at the Grand Teton National Park in Wyoming with an 8-millimeter color movie camera.
On March 23, 1989, the 300-meter (1,000-foot) diameter Apollo asteroid 4581 Asclepius (1989 FC) missed the Earth by 700,000 km passing through the exact position where the Earth was only 6 hours before. If the asteroid had impacted it would have created the largest explosion in recorded history, 12 times as powerful as the Tsar Bomba, the most powerful nuclear bomb ever exploded. It attracted widespread attention as early calculations had its passage being as close as 64,000 km from the Earth, with large uncertainties that allowed for the possibility of it striking the Earth.
On 13 October 1990 an Earth-grazing meteoroid EN131090 was observed above Czechoslovakia and Poland. It was moving with a speed of 41.74 km/s along a 409 km trajectory from the south to the north. The closest approach to the Earth was 98.67 km. It was captured by two all-sky cameras of the European Fireball Network, which for the first time enabled geometric calculations of the orbit of such a body.
On March 18, 2004, LINEAR announced a 30-meter asteroid, 2004 FH, which would pass the Earth that day at only 42,600 km, about one-tenth the distance to the Moon, and the closest miss ever noticed. They estimated that similar-sized asteroids come as close about every two years.
On March 31, 2004, two weeks after 2004 FH, meteoroid 2004 FU162 set a new record for closest recorded approach, passing Earth only 6,500 km away (about one-sixtieth of the distance to the Moon). Because it was very small (6 meters/20 feet), FU162 was detected only hours before its closest approach. If it had collided with Earth, it probably would have harmlessly disintegrated in the atmosphere.
On March 2, 2009, near-Earth asteroid 2009 DD45 flew by Earth at about 13:40 UT. The estimated distance from Earth was 72,000 km, approximately twice the height of a geostationary communications satellite. The estimated size of the space rock was about 35 meters (115 feet) wide.
On January 13, 2010, at 12:46 UT, near-Earth asteroid 2010 AL30 passed at about 122,000 km. It was approximately 10 - wide. If 2010 AL30 had entered the Earth's atmosphere, it would have created an air burst equivalent to between 50 kt and 100 kt (kilotons of TNT). The Hiroshima "Little Boy" atom bomb had a yield between 13-18 kt.
On June 28, 2011, an asteroid designated 2011 MD, estimated at 5 - in diameter, passed within 20,000 km of the Earth, passing over the Atlantic Ocean.
On November 8, 2011, (308635) 2005 YU55 (at about 400m diameter) passed within 324600 km (0.85 lunar distances) of Earth. Ten weeks later, on January 27, 2012, the 10-metre wide asteroid 2012 BX34 passed a mere 60000 km from Earth.
On February 15, 2013, 367943 Duende (2012 DA14) passed approximately 27,700 km (17,200 mi) above the surface of Earth. This was closer than satellites in geosynchronous orbit. The asteroid was not visible to the unaided eye.
Future impacts.
Although there have been a few false alarms, a number of objects have been known to be threats to the Earth. (89959) 2002 NT7 was the first asteroid with a positive rating on the Palermo Technical Impact Hazard Scale, with approximately one in a million on a potential impact date of approximately February 1, 2019; it is now known that 2002 NT7 will actually safely pass 0.4078 AU from the Earth on January 13, 2019.
Asteroid (29075) 1950 DA was lost after its discovery in 1950, since its observations over just 17 days were insufficient to determine its orbit, and then rediscovered on December 31, 2000. It has a diameter of about a kilometer (0.6 miles). The chance that it could impact Earth during its March 16, 2880 close approach had been estimated as 1 in 300. This is roughly 50% greater than the combined chance of impact for all other similarly large objects until 2880. The next radar opportunity for 1950 DA is in 2032, and will pinpoint our knowledge of the orbit, but additional optical position measurements have already reduced the probability of a 2880 impact to 1 in 20 000.
Only the asteroids 99942 Apophis (provisionally known as 2004 MN4) and (144898) 2004 VD17 have briefly had above-normal rankings on the Torino Scale.
Projects to minimize the threat.
Several surveys have undertaken "Spaceguard" activities (an umbrella term), including Lincoln Near-Earth Asteroid Research (LINEAR), Spacewatch, Near-Earth Asteroid Tracking (NEAT), Lowell Observatory Near-Earth-Object Search (LONEOS), Catalina Sky Survey, Campo Imperatore Near-Earth Object Survey (CINEOS), Japanese Spaceguard Association, and Asiago-DLR Asteroid Survey. In 1998, the United States Congress mandated the Spaceguard Survey – detection of 90% of near-earth asteroids over 1 km diameter (which threaten global devastation) by 2008. In 2005, this was extended by the George E. Brown, Jr. Near-Earth Object Survey Act, which calls for NASA to detect 90% of NEOs with diameters of 140 meters or greater, by 2020.
As of 2011, 911 of the largest (>1 km diameter) near-Earth asteroids have been found, with an estimate of 70 yet to be found.
Notable objects.
Notable objects include near-Earth objects and flyby objects as minor planets, comets, asteroids, and meteors:, generally specifically mentioned in news articles.

</doc>
<doc id="21627" url="http://en.wikipedia.org/wiki?curid=21627" title="Nation state">
Nation state

A nation state is a geographical area that can be identified as deriving its political legitimacy from serving as a sovereign nation.
A state is a political and geopolitical entity, while a nation is a cultural and ethnic one. The term "nation state" implies that the two coincide, but "nation state" formation can take place at different times in different parts of the world.
The concept of a nation state can be compared and contrasted with that of the multinational state, city state, empire, confederation, and other state formations with which it may overlap. The key distinction is the identification of a people with a polity in the "nation state."
History and origins.
The origins and early history of nation states are disputed. A major theoretical question is: "Which came first, the nation or the nation state?" Professor Steven Weber of the University of California, Berkeley, has advanced the hypothesis that the nation state is an inadvertent byproduct of 15th-century advances in map-making technologies. For others, the nation existed first, then nationalist movements arose for sovereignty, and the nation state was created to meet that demand. Some "modernization theories" of nationalism see it as a product of government policies to unify and modernize an already existing state. Most theories see the nation state as a 19th-century European phenomenon, facilitated by developments such as state-mandated education, mass literacy and mass media. However, historians also note the early emergence of a relatively unified state and identity in Portugal and the Dutch Republic.
In France, Eric Hobsbawm argues, the French state preceded the formation of the French people. Hobsbawm considers that the state made the French nation, not French nationalism, which emerged at the end of the 19th century, the time of the Dreyfus Affair. At the time of the 1789 French Revolution, only half of the French people spoke some French, and 12-13% spoke it "fairly", according to Hobsbawm.
During the Italian unification, the number of people speaking the Italian language was even lower. The French state promoted the unification of various dialects and languages into the French language. The introduction of conscription and the Third Republic's 1880s laws on public instruction, facilitated the creation of a national identity, under this theory.
Some nation states, such as Germany or Italy, came into existence at least partly as a result of political campaigns by nationalists, during the 19th century. In both cases, the territory was previously divided among other states, some of them very small. The sense of common identity was at first a cultural movement, such as in the "Völkisch movement" in German-speaking states, which rapidly acquired a political significance. In these cases, the nationalist sentiment and the nationalist movement clearly precede the unification of the German and Italian nation states.
Historians Hans Kohn, Liah Greenfeld, Philip White and others have classified nations such as Germany or Italy, where cultural unification preceded state unification, as "ethnic nations" or "ethnic nationalities". Whereas 'state-driven' national unifications, such as in France, England or China, are more likely to flourish in multiethnic societies, producing a traditional national heritage of "civic nations", or "territory-based nationalities". Some authors deconstruct the distinction between ethnic nationalism and civic nationalism because of the ambiguity of the concepts. They argue that the paradigmatic case of Ernest Renan is an idealisation and it should be interpreted within the German tradition and not in opposition to it. For example, they argue that the arguments used by Renan at the conference "What is a nation?" are not consistent with his thinking. This alleged civic conception of the nation would be determined only by the case of the loss gives Alsace and Lorraine in the Franco-Prussian War.
The idea of a nation state was and is associated with the rise of the modern system of states, often called the "Westphalian system" in reference to the Treaty of Westphalia (1648). The balance of power, which characterized that system, depended on its effectiveness upon clearly defined, centrally controlled, independent entities, whether empires or nation states, which recognize each other's sovereignty and territory. The Westphalian system did not create the nation state, but the nation state meets the criteria for its component states (by assuming that there is no disputed territory).
The nation state received a philosophical underpinning in the era of Romanticism, at first as the 'natural' expression of the individual peoples (romantic nationalism: see Johann Gottlieb Fichte's conception of the "Volk", later opposed by Ernest Renan). The increasing emphasis during the 19th century on the ethnic and racial origins of the nation, led to a redefinition of the nation state in these terms. Racism, which in Boulainvilliers's theories was inherently antipatriotic and antinationalist, joined itself with colonialist imperialism and "continental imperialism", most notably in pan-Germanic and pan-Slavic movements.
The relation between racism and ethnic nationalism reached its height in the 20th century fascism and Nazism. The specific combination of 'nation' ('people') and 'state' expressed in such terms as the "Völkische Staat" and implemented in laws such as the 1935 Nuremberg laws made fascist states such as early Nazi Germany qualitatively different from non-fascist nation states. Minorities were not considered part of the people ("Volk"), and were consequently denied to have an authentic or legitimate role in such a state. In Germany, neither Jews nor the Roma were considered part of the people, and were specifically targeted for persecution. German nationality law defined 'German' on the basis of German ancestry, excluding "all" non-Germans from the people.
In recent years, a nation state's claim to absolute sovereignty within its borders has been much criticized. A global political system based on international agreements and supra-national blocs characterized the post-war era. Non-state actors, such as international corporations and non-governmental organizations, are widely seen as eroding the economic and political power of nation states, potentially leading to their eventual disappearance.
Before the nation state.
In Europe, during the 18th century, the classic non-national states were the "multiethnic" empires, the Austrian Empire, Kingdom of France, Kingdom of Hungary, the Russian Empire, the Ottoman Empire, the British Empire and smaller states at what would now be called sub-national level. The multi-ethnic empire was a monarchy ruled by a king, emperor or sultan. The population belonged to many ethnic groups, and they spoke many languages. The empire was dominated by one ethnic group, and their language was usually the language of public administration. The ruling dynasty was usually, but not always, from that group.
This type of state is not specifically European: such empires existed on all continents, except Australia and Antarctica. Some of the smaller European states were not so ethnically diverse, but were also dynastic states, ruled by a royal house. Their territory could expand by royal intermarriage or merge with another state when the dynasty merged. In some parts of Europe, notably Germany, very small territorial units existed. They were recognised by their neighbours as independent, and had their own government and laws. Some were ruled by princes or other hereditary rulers, some were governed by bishops or abbots. Because they were so small, however, they had no separate language or culture: the inhabitants shared the language of the surrounding region.
In some cases these states were simply overthrown by nationalist uprisings in the 19th century. Liberal ideas of free trade played a role in German unification, which was preceded by a customs union, the Zollverein. However, the Austro-Prussian War, and the German alliances in the Franco-Prussian War, were decisive in the unification. The Austro-Hungarian Empire and the Ottoman Empire broke up after the First World War and the Russian Empire became the Soviet Union, after the Russian Civil War.
A few of the smaller states survived: the independent principalities of Liechtenstein, Andorra, Monaco, and the republic of San Marino. (Vatican City is different. Although there was a larger Papal State, it was created in its present form by the 1929 Lateran treaties between Italy and the Roman Catholic Church.)
Characteristics of the nation state.
"Legitimate states that govern effectively and dynamic industrial economies are widely regarded today as the defining characteristics of a modern nation-state."
Nation states have their own characteristics, differing from those of the pre-national states. For a start, they have a different attitude to their territory when compared with dynastic monarchies: it is semisacred and nontransferable. No nation would swap territory with other states simply, for example, because the king's daughter married. They have a different type of border, in principle defined only by the area of settlement of the national group, although many nation states also sought natural borders (rivers, mountain ranges). They are constantly changing in size and power because of the limited restrictions of their borders.
The most noticeable characteristic is the degree to which nation states use the state as an instrument of national unity, in economic, social and cultural life.
The nation state promoted economic unity, by abolishing internal customs and tolls. In Germany, that process, the creation of the Zollverein, preceded formal national unity. Nation states typically have a policy to create and maintain a national transportation infrastructure, facilitating trade and travel. In 19th-century Europe, the expansion of the rail transport networks was at first largely a matter for private railway companies, but gradually came under control of the national governments. The French rail network, with its main lines radiating from Paris to all corners of France, is often seen as a reflection of the centralised French nation state, which directed its construction. Nation states continue to build, for instance, specifically national motorway networks. Specifically transnational infrastructure programmes, such as the Trans-European Networks, are a recent innovation.
The nation states typically had a more centralised and uniform public administration than its imperial predecessors: they were smaller, and the population less diverse. (The internal diversity of the Ottoman Empire, for instance, was very great.) After the 19th-century triumph of the nation state in Europe, regional identity was subordinate to national identity, in regions such as Alsace-Lorraine, Catalonia, Brittany and Corsica. In many cases, the regional administration was also subordinated to central (national) government. This process was partially reversed from the 1970s onward, with the introduction of various forms of regional autonomy, in formerly centralised states such as France.
The most obvious impact of the nation state, as compared to its non-national predecessors, is the creation of a uniform national culture, through state policy. The model of the nation state implies that its population constitutes a nation, united by a common descent, a common language and many forms of shared culture. When the implied unity was absent, the nation state often tried to create it. It promoted a uniform national language, through language policy. The creation of national systems of compulsory primary education and a relatively uniform curriculum in secondary schools, was the most effective instrument in the spread of the national languages. The schools also taught the national history, often in a propagandistic and mythologised version, and (especially during conflicts) some nation states still teach this kind of history.
Language and cultural policy was sometimes negative, aimed at the suppression of non-national elements. Language prohibitions were sometimes used to accelerate the adoption of national languages and the decline of minority languages (see examples: Anglicisation, Czechization, Francisation, Germanisation, Magyarisation, Polonisation, Russification, Serbization, Slovakisation).
In some cases, these policies triggered bitter conflicts and further ethnic separatism. But where it worked, the cultural uniformity and homogeneity of the population increased. Conversely, the cultural divergence at the border became sharper: in theory, a uniform French identity extends from the Atlantic coast to the Rhine, and on the other bank of the Rhine, a uniform German identity begins. To enforce that model, both sides have divergent language policy and educational systems, although the linguistic boundary is in fact well inside France, and the Alsace region changed hands four times between 1870 and 1945.
The nation state in practice.
In some cases, the geographic boundaries of an ethnic population and a political state largely coincide. In these cases, there is little immigration or emigration, few members of ethnic minorities, and few members of the "home" ethnicity living in other countries.
Examples of nation states where ethnic groups make up more than 95% of the population include the following:
The notion of a unifying "national identity" also extends to countries that host multiple ethnic or language groups, such as India and China. For example, Switzerland is constitutionally a confederation of cantons, and has four official languages, but it has also a 'Swiss' national identity, a national history and a classic national hero, Wilhelm Tell.
Innumerable conflicts have arisen where political boundaries did not correspond with ethnic or cultural boundaries. For one example, the Hatay Province was transferred to Turkey from Syria after the minority-Turkish population complained of mistreatment. The traditional homeland of the Kurdish people extends between northern Iraq, southeastern Turkey, and western Iran. Some of its inhabitants call for the creation of an independent Kurdistan, citing mistreatment by the Turkish and Iraqi governments. An armed conflict between the separatist Kurdistan Workers Party and the Turkish government over this issue has been ongoing since 1984.
After World War II in the Josip Broz Tito era, nationalism was appealed to for uniting South Slav peoples. Later in the 20th century, after the break-up of the Soviet Union, leaders appealed to ancient ethnic feuds or tensions that ignited conflict between the Serbs, Croats and Slovenes, as well Bosnians, Montenegrins and Macedonians, eventually breaking up the long collaboration of peoples and ethnic cleansing was carried out in the Balkans, resulting in the destruction of the formerly communist republic and produced the civil wars in Bosnia and Herzegovina in 1992–95, resulted in mass population displacements and segregation that radically altered what was once a highly diverse and intermixed ethnic makeup of the region. These conflicts were largely about creating a new political framework of states, each of which would be ethnically and politically homogeneous. Serbians, Croatians and Bosnians insisted they were ethnically distinct although many communities had a long history of intermarriage. All could speak the common Serbo-Croatian Language. Presently Slovenia (89% Slovene), Croatia (88% Croat) and Serbia (83% Serb) could be classified as nation states per se, whereas Macedonia (66% Macedonian), Montenegro (42% Montenegrin) and Bosnia and Herzegovina (47% Bosniak) are multinational states.
Belgium is a classic example of a state that is not a nation state. The state was formed by secession from the United Kingdom of the Netherlands in 1830, whose neutrality and integrity was protected by the Treaty of London 1839; thus it served as a buffer state after the Napoleonitic Wars between the European powers France, Prussia (after 1871 the German Empire) and the United Kingdom until World War I, when its neutrality was breached by the Germans. Currently, Belgium is divided between the Flemings in the north and the French-speaking or the German-speaking population in the south. The Flemish population in the north speaks Dutch, the Walloon population in the south speaks French and/or German. The Brussels population speaks French and/or Dutch.
The Flemish identity is also cultural, and there is a strong separatist movement espoused by the political parties, the right-wing Vlaams Belang and the Nieuw-Vlaamse Alliantie. The Francophone Walloon identity of Belgium is linguistically distinct and regionalist. There is also is unitary Belgian nationalism, several versions of a Greater Netherlands ideal, and a German-speaking community of Belgium annexed from Germany in 1920, and re-annexed by Germany in 1940–1944. However these ideologies are all very marginal and politically insignificant during elections.
China covers a large geographic area and uses the concept of "Zhonghua minzu" or Chinese nationality, in the sense of ethnic groups, but it also officially recognizes the majority Han ethnic group which accounts for over 90% of the population, and no fewer than 55 ethnic national minorities.
According to Philip G. Roeder, Moldova is an example of a Soviet era "segment-state" (Moldavian SSR), where the "nation-state project of the segment-state trumped the nation-state project of prior statehood. In Moldova, despite strong agitation from university faculty and students for reunification with Romania, the nation-state project forged within the Moldavian SSR trumped the project for a return to the interwar nation-state project of Greater Romania." See Controversy over linguistic and ethnic identity in Moldova for further details.
Exceptional cases.
United Kingdom.
The United Kingdom is an unusual example of a nation state, due to its "countries within a country" status. The United Kingdom which is formed by the union of England, Scotland, Wales and Northern Ireland, is a unitary state formed initially by the merger of two independent kingdoms, the Kingdom of England and the Kingdom of Scotland, but the Treaty of Union (1707) that set out the agreed terms has ensured the continuation of distinct features of each state, including separate legal systems and separate national churches.
In 2003, the British Government described the United Kingdom as "countries within a country". While the Office for National Statistics and others describe the United Kingdom as a "nation state", others, including a then Prime Minister, describe it as a "multinational state", and the term Home Nations is used to describe the four national teams that represent the four nations of the United Kingdom (England, Northern Ireland, Scotland, Wales).
Kingdom of the Netherlands.
A similar unusual example is the Kingdom of the Netherlands. As of 10 October 2010, the Kingdom of the Netherlands consists of four countries:
Each is expressly designated as a "land" in Dutch law by the Charter for the Kingdom of the Netherlands. Unlike the German "Länder" and the Austrian "Bundesländer", "landen" is consistently translated as "countries" by the Dutch government.
Israel.
Israel was founded as a Jewish state in 1948. Its "Basic Laws" describe it as both a Jewish and a democratic state. According to the Israel Central Bureau of Statistics, 75.7% of Israel's population is Jewish. Arabs, who make up 20.4% of the population, are the largest ethnic minority in Israel. Israel also has very small communities of Armenians, Circassians, Assyrians, Samaritans, and persons of some Jewish heritage. There are also some non-Jewish spouses of Israeli Jews. However, these communities are very small, and usually number only in the hundreds or thousands.
Pakistan.
Pakistan, even being an ethnically diverse country and officially a federation, is regarded as a nation state due to its ideological basis on which it was given independence from British India as a separate nation rather than as part of a unified India. Different ethnic groups in Pakistan are strongly bonded by their common Muslim identity, common cultural and social values, common historical heritage, a national Lingua franca (Urdu) and joint political, strategic and economic interests.
Minorities.
The most obvious deviation from the ideal of 'one nation, one state', is the presence of minorities, especially ethnic minorities, which are clearly not members of the majority nation. An ethnic nationalist definition of a nation is necessarily exclusive: ethnic nations typically do not have open membership. In most cases, there is a clear idea that surrounding nations are different, and that includes members of those nations who live on the 'wrong side' of the border. Historical examples of groups, who have been specifically singled out as "outsiders", are the Roma and Jews in Europe.
Negative responses to minorities within the nation state have ranged from cultural assimilation enforced by the state, to expulsion, persecution, violence, and extermination. The assimilation policies are usually enforced by the state, but violence against minorities is not always state initiated: it can occur in the form of mob violence such as lynching or pogroms. Nation states are responsible for some of the worst historical examples of violence against minorities: minorities not considered part of the nation.
However, many nation states accept specific minorities as being part of the nation, and the term "national minority" is often used in this sense. The Sorbs in Germany are an example: for centuries they have lived in German-speaking states, surrounded by a much larger ethnic German population, and they have no other historical territory. They are now generally considered to be part of the German nation and are accepted as such by the Federal Republic of Germany, which constitutionally guarantees their cultural rights. Of the thousands of ethnic and cultural minorities in nation states across the world, only a few have this level of acceptance and protection.
Multiculturalism is an official policy in many states, establishing the ideal of peaceful existence among multiple ethnic, cultural, and linguistic groups. Many nations have laws protecting minority rights.
When national boundaries that do not match ethnic boundaries are drawn, such as in the Balkans and Central Asia, ethnic tension, massacres and even genocide, sometimes has occurred historically (see Bosnian genocide and 2010 ethnic violence in southern Kyrgyzstan).
Irredentism.
Ideally, the border of a nation state extends far enough to include all the members of the nation, and all of the national homeland. Again, in practice some of them always live on the 'wrong side' of the border. Part of the national homeland may be there too, and it may be governed by the 'wrong' nation. The response to the non-inclusion of territory and population may take the form of irredentism: demands to annex "unredeemed" territory and incorporate it into the nation state.
Irredentist claims are usually based on the fact that an identifiable part of the national group lives across the border. However, they can include claims to territory where no members of that nation live at present, because they lived there in the past, the national language is spoken in that region, the national culture has influenced it, geographical unity with the existing territory, or a wide variety of other reasons. Past grievances are usually involved and can cause revanchism.
It is sometimes difficult to distinguish irredentism from pan-nationalism, since both claim that all members of an ethnic and cultural nation belong in one specific state. Pan-nationalism is less likely to specify the nation ethnically. For instance, variants of Pan-Germanism have different ideas about what constituted Greater Germany, including the confusing term "Grossdeutschland", which, in fact, implied the inclusion of huge Slavic minorities from the Austro-Hungarian Empire.
Typically, irredentist demands are at first made by members of non-state nationalist movements. When they are adopted by a state, they typically result in tensions, and actual attempts at annexation are always considered a "casus belli", a cause for war. In many cases, such claims result in long-term hostile relations between neighbouring states. Irredentist movements typically circulate maps of the claimed national territory, the "greater" nation state. That territory, which is often much larger than the existing state, plays a central role in their propaganda.
Irredentism should not be confused with claims to overseas colonies, which are not generally considered part of the national homeland. Some French overseas colonies would be an exception: French rule in Algeria unsuccessfully treated the colony as a "département" of France.
Future.
It has been speculated by both proponents of globalization and various science fiction writers that the concept of a nation state may disappear with the ever-increasingly interconnected nature of the world. Such ideas are sometimes expressed around concepts of a world government. Another possibility is a societal collapse and move into communal anarchy or zero world government, in which nation states no longer exist and government is done on the local level based on a global ethic of human rights.
This falls into line with the concept of internationalism, which states that sovereignty is an outdated concept and a barrier to achieving peace and harmony in the world, thus also stating that nation states are also a similar outdated concept.
Globalization especially has helped to bring about the discussion about the disappearance of nation states, as global trade and the rise of the concepts of a 'global citizen' and a common identity have helped to reduce differences and 'distances' between individual nation states, especially with regards to the internet.
Clash of civilizations.
The theory of the clash of civilizations lies in direct contrast to cosmopolitan theories about an ever more-connected world that no longer requires nation states. According to political scientist Samuel P. Huntington, people's cultural and religious identities will be the primary source of conflict in the post–Cold War world.
The theory was originally formulated in a 1992 lecture at the American Enterprise Institute, which was then developed in a 1993 "Foreign Affairs" article titled "The Clash of Civilizations?", in response to Francis Fukuyama's 1992 book, "The End of History and the Last Man". Huntington later expanded his thesis in a 1996 book "The Clash of Civilizations and the Remaking of World Order".
Huntington began his thinking by surveying the diverse theories about the nature of global politics in the post–Cold War period. Some theorists and writers argued that human rights, liberal democracy and capitalist free market economics had become the only remaining ideological alternative for nations in the post–Cold War world. Specifically, Francis Fukuyama, in "The End of History and the Last Man", argued that the world had reached a Hegelian "end of history".
Huntington believed that while the age of ideology had ended, the world had reverted only to a normal state of affairs characterized by cultural conflict. In his thesis, he argued that the primary axis of conflict in the future will be along cultural and religious lines.
As an extension, he posits that the concept of different civilizations, as the highest rank of cultural identity, will become increasingly useful in analyzing the potential for conflict.
In the 1993 "Foreign Affairs" article, Huntington writes:
Sandra Joireman suggests that Huntington may be characterised as a neo-primordialist, as, while he sees people as having strong ties to their ethnicity, he does not believe that these ties have always existed.
Historiography.
Historians of often look to the past to find the origins of a particular nation state. Indeed, they often put so much emphasis on the importance of the nation state in modern times, that they distort the history of earlier periods in order to emphasize the question of origins. Lansing and English argue that much of the medieval history of Europe was structured to follow the historical winners-- especially the nation states that emerged around Paris and London. Important developments that did not directly lead to a nation state get neglected, they argue:

</doc>
<doc id="21628" url="http://en.wikipedia.org/wiki?curid=21628" title="Nicolas Louis de Lacaille">
Nicolas Louis de Lacaille

Abbé Nicolas Louis de La Caille, sometimes spelled Lacaille, (]; 28 December 1713 – 21 March 1762) was a French astronomer. The birth date given here is that of his baptism; babies were normally baptised on the day that they were born. The traditional birth date of 15 March 1713 has been questioned due to many infants of the Roman Catholic Church being baptised on the day of their birth in the 17th and 18th centuries.
Biography.
Born at Rumigny (in present-day Ardennes), he attended school in Mantes-sur-Seine (now Mantes-la-Jolie). Afterwards he studied rhetoric and philosophy at the and then theology at the Collège de Navarre. He was left destitute in 1731 by the death of his father, who had held a post in the household of the duchess of Vendôme. However he was supported in his studies by the Duc de Bourbon, his father's former patron.
After he graduated he did not accept ordination as a priest but took deacon's orders, becoming an Abbé. He concentrated thereafter on science, and, through the patronage of Jacques Cassini, obtained employment, first in surveying the coast from Nantes to Bayonne, then, in 1739, in remeasuring the French arc of the meridian, for which he is honored with a pyramid at Juvisy-sur-Orge. The success of this difficult operation, which occupied two years, and achieved the correction of the anomalous result published by J. Cassini in 1718, was mainly due to Lacaille's industry and skill. He was rewarded by admission to the Royal Academy of Sciences and appointment as Professor of mathematics in the Mazarin college, where he constructed a small observatory fitted for his own use. He was the author of a number of influential textbooks and a firm advocate of Newtonian gravitational theory. Among his students were Antoine Lavoisier and Jean Sylvain Bailly, both of whom were guillotined during the Revolution.
Voyage to the Cape of Good Hope.
His desire to determine the distances of the planets trigonometrically, using the longest possible baseline, led him to propose, in 1750, an expedition to the Cape of Good Hope. This was officially sanctioned by Roland-Michel Barrin de La Galissonière. There he constructed an observatory on the shore of Table Bay with the support of the Dutch Governor Ryk Tulbagh. The primary result of his two-year stay was a catalogue of nearly 10,000 southern stars, the production of which required observing every night for over a year. In the course of his survey he took note of 42 nebulous objects. He also achieved his aim of determining the lunar and solar parallaxes (Mars serving as an intermediary). This work required near-simultaneous observations from Europe which were carried out by Jérôme Lalande.
His southern catalogue, called "Coelum Australe Stelliferum", was published posthumously in 1763. He found it necessary to introduce 14 new constellations which have since become standard. One of these was Mons Mensa, the only constellation named after a terrestrial feature (Table Mountain).
While at the Cape, La Caille determined the radius of the earth in the southern hemisphere. He set out a baseline in the Swartland plain north of present-day Darling. Using triangulation he then measured a 137 km arc of meridian between Cape Town and Aurora, determining the latitudes of the end points by means of astronomical observations. There is a memorial to his work at a location near Aurora, pictured here. His result suggested that the earth was more flattened towards the south pole than towards the north. George Everest, of the Indian Survey, while recuperating from an illness at the Cape nearly seventy years later, suggested that La Caille's latitude observations had been affected by the gravitational attraction of Table Mountain at the southern end and by the Piketberg Mountain at the northern. In 1838, Thomas Maclear, who was Astronomer Royal at the Cape, repeated the measurements over a longer baseline and ultimately confirmed Everest's conjecture.
Computing.
During his voyage to the southern hemisphere as a passenger on the vessel "Le Glorieux", captained by the noted hydrogapher Jean-Baptiste d'Après de Mannevillette, La Caille became conscious of the difficulties in determining positions at sea. On his return to Paris he prepared the first set of tables of the Moon's position that was accurate enough to use for determining time and longitude by the method of 'Lunars' (Lunar distances) using the orbital theory of Clairaut. La Caille was in fact an indefatigable calculator. Apart from constructing astronomical ephemerides and mathematical tables, he calculated a table of eclipses for 1800 years. Lalande said of him that, during a comparatively short life, he had made more observations and calculations than all the astronomers of his time put together. The quality of his work rivalled its quantity, while the disinterestedness and rectitude of his moral character earned him universal respect.
Later life.
On his return to Paris in 1754, following a diversion to Mauritius, La Caille was distressed to find himself an object of public attention. He resumed his work at the Mazarin College.
In 1757 he published his "Astronomiae Fundamenta Novissimus", containing a list of 400 bright stars with positions corrected for aberration and nutation. He carried out calculations on comet orbits and was responsible for giving Halley's Comet its name. His last public lecture, given on 14 September 1761 at the Royal Academy of Sciences, summarised the improvements to astronomy that had occurred during his lifetime, to which he had made no small contribution.
His death, probably caused in part by over-work, occurred in 1762. He was buried in the vaults of the Mazarin College, now the Institut de France in Paris.
Honours.
In 1754, he was elected a foreign member of the Royal Swedish Academy of Sciences. He was also an honorary member of the academies of Saint Petersburg and Berlin, the Royal Society of London and the Royal Society of Göttingen, and the Institute of Bologna. 
The crater La Caille on the Moon is named after him. Asteroid 9135 Lacaille (AKA 7609 P-L and 1994 EK6), discovered on 17 October 1960 by Cornelis Johannes van Houten, Ingrid van Houten-Groeneveld and Tom Gehrels at Palomar Observatory, was also named after him.
In honor of his contribution to the study of the southern hemisphere sky, a 60-cm telescope at Reunion Island will be named the La Caille Telescope.

</doc>
<doc id="21630" url="http://en.wikipedia.org/wiki?curid=21630" title="Nawaf al-Hazmi">
Nawaf al-Hazmi

Nawaf Muhammed Salim al-Hazmi (Arabic: نواف الحازمي‎, "Nawāf al-Ḥāzmī"; also known as "Rabia al-Makki") (August 9, 1976 – September 11, 2001) was a Saudi citizen and one of five hijackers of American Airlines Flight 77, which they crashed into the Pentagon as part of the September 11 attacks in the United States.
Hazmi and a longtime friend, Khalid al-Mihdhar, left their homes in Saudi Arabia in 1995 to fight for Muslims in the Bosnian War. Hazmi later traveled to Afghanistan to fight with the Taliban against the Afghan Northern Alliance. He returned to Saudi Arabia in early 1999.
Already long time affiliates of Al-Qaeda with extensive fighting experience, Hazmi and Mihdhar were chosen by Osama bin Laden for an ambitious terrorist plot to pilot commercial airlines into designated targets in the United States. Hazmi and Mihdhar both obtained US tourist visas in April 1999. Hazmi trained in an Al-Qaeda training camp in the fall of 1999. He traveled to Malaysia for the 2000 Al-Qaeda Summit.
Hazmi arrived in Los Angeles, California from Bangkok, Thailand, on January 15, 2000, with Khalid al-Mihdhar. The two settled in San Diego, staying at the Parkwood Apartments until May 2000. While in San Diego, they attended its mosque, led by Anwar Al-Awlaki. The two took flying lessons during that month in San Diego. Due to Hazmi and Mihdhar's poor English skills, they did not perform well during their flight lessons and their flight instructor regarded them as suspicious.
Mihdhar left Hazmi in California for Yemen in June 2000. Hazmi stayed in California until he met up with Hani Hanjour in December 2000, and they both traveled to Phoenix, Arizona. They later moved to Falls Church, Virginia in April 2001, where the rest of the hijackers began to join them. Hazmi met frequently with Mohamed Atta, the ringleader of the attacks, during the summer of 2001.
The CIA reportedly received Hazmi's name on a list of 19 persons suspected of planning an attack in the near future. Hazmi was one of the four names on the list who were known for certain. A search for Hazmi and other suspected terrorists commenced, but they were not located until after the attacks.
On September 10, 2001, Hazmi, along with Mihdhar and Hanjour checked into a hotel in Herndon, Virginia. The next morning, Hazmi and four other terrorists, boarded American Airlines Flight 77 at Dulles Airport and hijacked the plane so that Hani Hanjour could pilot and crash the plane into the Pentagon as part of the September 11 attacks. The crash killed all 64 passengers aboard the aircraft and 125 in the Pentagon. Hazmi was initially dismissed as a "muscle hijacker" following the attacks, but was later revealed to have played a larger role in the operational planning than previously believed. His younger brother, Salem al-Hazmi, was another of the hijackers aboard the same flight.
Background.
Nawaf was born in Mecca in Saudi Arabia to Muhammad Salim al-Hazmi, a grocer. He traveled to Afghanistan as a teenager in 1993. CNN's preliminary report following the attacks claimed that an unnamed acquaintance relayed "He told me once that his father had tried to kill him when he was a child. He never told me why, but he had a long knife scar on his forearm", and claimed that his older brother was a police chief in Jizan.
In 1995, he and his childhood friend, Khalid al-Mihdhar, joined a group that went to fight alongside Bosnian Muslims in the Bosnian War. Afterwards, Nawaf returned to Afghanistan along with his brother Salem, and Mihdhar. In Afghanistan, they fought alongside the Taliban against the Afghan Northern Alliance, and joined up with Al-Qaeda. Nawaf al-Hazmi returned to Saudi Arabia in early 1999.
Selected for the 9/11 plot.
Osama bin Laden held Hazmi and Mihdhar in high respect, with their experience fighting during the 1990s in Bosnia and elsewhere. Al-Qaeda later referred to Hazmi as Mihdhar's "Second-in-command". When Bin Laden committed to the "planes operation" plot in spring 1999, Bin Laden personally selected Hazmi and Mihdhar to be involved in the plot as pilot hijackers. In addition to Hazmi and Mihdhar, two Yemenis were selected for a southeast Asia component of the plot, which was later scrapped for being too difficult to coordinate with the operations in the United States. Known as "Rabi'ah al-Makki" during the preparations, Hazmi had been so eager to participate in operations within the United States, he already had a US visa when Bin Laden selected him. Hazmi obtained a B-1/B-2 tourist visa on April 3, 1999 from the US consulate in Jeddah, Saudi Arabia, using a new passport he acquired a few weeks earlier. Hazmi's passport did have indicators of Al-Qaeda association, but immigration inspectors were not trained to look for those.
In the autumn of 1999, these four attended the Mes Aynak training camp in Afghanistan, which provided advanced training. Hazmi went with the two Yemenis, Tawfiq bin Attash (Khallad) and Abu Bara al Yemeni, to Karachi, Pakistan where Khalid Sheikh Mohammed, the plot's coordinator, instructed him on western culture, travel, as well as taught some basic English phrases. Mihdhar did not go with him to Karachi, but instead left for Yemen. Khalid Sheikh Mohammed then sent Hazmi and the other men to Malaysia for a meeting. Before leaving for Malaysia, Khalid Sheikh Mohammed doctored Hazmi's Saudi passport in order to conceal his travel to Pakistan and Afghanistan, and make it appear that Hazmi had come to Malaysia from Saudi Arabia via Dubai.
After the attacks, the Associated Press would re-publish a "bizarre" story by the "Cody Enterprise" that quoted witnesses stating that Nawaf entered the United States during the autumn of 1999, crossing along the Canadian border as one of two men delivering skylights to the local high school in Cody, Wyoming. Leaving the city 45 minutes later with the remaining cardboard boxes, the men allegedly asked "how to get to Florida."
Malaysia summit.
Based on information uncovered by the FBI in the 1998 United States embassy bombings case, the National Security Agency (NSA) began tracking the communications of Mihdhar's father-in-law Ahmad Muhammad Ali al-Hada, who was facilitating al-Qaeda communications, in 1999. Authorities also became aware of Hazmi, as a friend and associate of Mihdhar. Saudi Intelligence was also aware that Hazmi was associated with Al-Qaeda, and associated with the 1998 African embassy bombings and attempts to smuggle arms into the kingdom in 1997. He also said that he revealed this to the CIA, saying "What we told them was these people were on our watch list from previous activities of al-Qaeda, in both the ." The CIA strongly denies having received any such warning.
In late 1999 the NSA informed the CIA of an upcoming meeting in Malaysia, which Hada mentioned would involve "Khalid", "Nawaf", and "Salem". On January 5, Hazmi arrived in Kuala Lumpur, where he met up with Mihdhar, Attash, and Abu Bara. The group was in Malaysia to meet with Hambali for the 2000 Al Qaeda Summit, during which key details of the attacks may have been arranged. At this time, there was an East Asia component to the September 11 attacks plot, but Bin Laden later canceled it for being too difficult to coordinate with operations in the United States. Ramzi bin al-Shibh was also at the summit, and Khalid Sheikh Mohammed possibly attended the summit. In Malaysia, the group stayed with Yazid Sufaat, a local member of Jemaah Islamiyah, who provided accommodations at request of Hambali. Both Mihdhar and Hazmi were secretly photographed at the meeting by Malaysian authorities, who provided surveillance at the request of the CIA. Malaysian authorities reported that Mihdhar spoke at length with Tawfiq bin Attash, one of the Yemenis, and others who were later involved in the USS Cole bombing. Hazmi and Mihdhar also met with Fahd al-Quso, who was later involved in the USS Cole bombing. After the meeting, Mihdhar and Hazmi traveled to Bangkok in Thailand on January 8, and left a week later on January 15 to travel to the United States.
In the United States.
Enters the United States with Mihdhar.
On January 15, 2000, Hazmi and Mihdhar arrived together at Los Angeles International Airport from Bangkok, and were admitted for a six-month period. Immediately after entering the country, Nawaf and Mihdhar met Omar al-Bayoumi in an airport restaurant. Bayoumi claims he was merely being charitable in helping the two seemingly out-of-place Muslims to move to San Diego where he helped them find an apartment near his own, co-signed their lease, and gave them $1500 to help pay their rent.
While in San Diego, witnesses told the FBI he and Mindhar had a close relationship with Anwar Al Awlaki, an imam who served as their spiritual advisor. Authorities say the two regularly attended the Masjid Ar-Ribat al-Islami mosque Awlaki led in San Diego, and Awlaki had many closed-door meetings with them, which led investigators to believe Awlaki knew about the 9/11 attacks in advance. Hazmi got a recommendation from the mosque for a job at a nearby Texaco station and car wash, a business whose former owner, a Muslim, was known to help young men in need of work. For a month, Hazmi worked there two days a week, vacuuming and drying cars.
In the beginning of February 2000, Mihdhar and Hazmi rented an apartment at the Parkwood Apartments, a 175-unit complex in the Clairemont Mesa section of San Diego, near the Balboa Drive Mosque. In February, Mihdhar purchased a used 1988 Toyota Corolla. While living at the Parkwood Apartments, neighbors thought that Mihdhar and Hazmi were odd. Months passed without them getting any furniture for the apartment. Instead, the men slept on mattresses on the floor, yet they carried briefcases, were frequently on their mobile phones, and were occasionally picked up by a limousine. After the attacks, their neighbors told the media that the pair constantly played flight simulator games. Residents said a total of four men spent time together at Parkwood, playing in the pool like children.
On April 4, 2000, Hazmi took a one-hour introductory flight lesson at the National Air College in San Diego. Both Mihdhar and Hazmi took flight lessons in May 2000 at the Sorbi Flying Club, located at Montgomery Field in San Diego. On May 5, Hazmi and Mihdhar took a lesson for one hour, and additional lessons on May 10 at the Sorbi Flying Club, with Hazmi flying an aircraft for 30 minutes. However, their English skills were very poor, and they did not do well with flight lessons. The first day that they showed up, they told instructors that they wanted to learn how to fly Boeings. Mihdhar and Hazmi raised some suspicion when they offered extra money to their flight instructor, Richard Garza, if he would train them to fly jets. Suspicious of the two men, Garza refused the offer but did not report them to authorities. Garza described the two men as "impatient students" who "wanted to learn to fly jets, specifically Boeings."
Adel Rafeea received a wire transfer of $5000, on April 18, from Ali Abdul Aziz Ali in the UAE, which he later claimed was money Nawaf had asked him to accept on his behalf.
At the end of May 2000, Hazmi and Mihdhar moved out of Parkwood Apartments, and moved to nearby Lemon Grove, California. At this time, Mihdhar transferred his vehicle's registration to Hazmi, and he left San Diego on June 10, 2000. Mihdhar returned to Yemen, which angered Khalid Sheikh Mohammed, who did not want Hazmi to be left alone in California.
On July 12, 2000, Hazmi filed for an extension of his visa, which was due to expire. His visa was extended until January 2001, though Hazmi never filed any further requests to extend it beyond that.
In September, Nawaf and Mihdhar both moved into the house of FBI informant Abdussattar Shaikh, although he did not report the pair as suspicious. Mihdhar is believed to have left the apartment in early October, less than two weeks before the USS Cole Bombing. Nawaf continued living with Shaikh until December.
Hani Hanjour arrived in San Diego in early December 2000, joining Hazmi, but on December 10, they were seen leaving their Mount Vernon address leaving for Phoenix, Arizona where Hanjour could take refresher flight training. On December 12, they arrived at Mesa AZ and stayed with Mourad Jdaaini and Mike Khalaf. On December 22, Hanjour and Hazmi signed a lease for an apartment in the Indian Springs Village complex in Mesa, Arizona, moving in on January 9.
2001.
In March al-Hazmi received a shipment of VHS videos including videos about Boeing 747 and 777 flight decks and “how an airline captain should look and act" and later a road atlas, map of NYC and a World aeronautical chart.
On March 30, Al-Hazmi notified his utility company that he might be moving to another state or Saudi Arabia. He and Hanjour moved out before the apartment rental expired at the end of the month on their way to Virginia. 2 days later on April 1, 2001, Oklahoma police officer C. L. Parkins pulled Hazmi over for speeding in their Corolla along with an additional citation for failing to use a seatbelt together totaling $138. A routine inspection of his California drivers license turned up no warrants or alerts, although his name was known to both the NSA and the CIA as a suspected terrorist.
Anwar al-Awlaki had already headed east and served as Imam at the Dar al-Hijrah mosque in the metropolitan Washington, DC area starting in January 2001. Shortly after this, his sermons were attended by three of the 9/11 hijackers (the new one being Hanjour).
By April 3, he was likely with companion Hani Hanjour when he was recorded at an ATM in Front Royal, Virginia, arriving in Falls Church, Virginia, by April 4. They met a man believed to be a Jordanian named Eyad Alrababah at a 7-11 that day. The 9-11 commission wrote that Hazmi and Hanjour met Alrababah at the Dar al Hijra mosque who was computer technician who had moved from West Paterson, New Jersey and was there to ask imam Anwar al-Awlaki about finding a job. He helped the pair rent an apartment in Alexandria where they moved in.
The September 11 Commission concluded that two of the hijackers "reportedly respected Awlaki as a religious figure". When police raided the Hamburg, Germany, apartment of Ramzi bin al-Shibh (the "20th hijacker") while investigating the 9/11 attacks, his telephone number was found among bin al-Shibh's personal contact information.
On May 1, 2001, Hazmi reported to police that men tried to take his wallet outside his Fairfax, Virginia residence, but before the county officer left, Hazmi signed a "statement of release" indicating he did not want the incident investigated.
In May 2001, Nidal Hasan's mother's funeral was held at the Falls Church mosque, although it is not known if al-Hazmi attended the service. May 2, two other hijackers, Ahmed al-Ghamdi and Majed Moqed, arrived in Virginia and moved in with them. On May 8, Alrababah suggested that al-Hazmi and al-Mihdhar move with him to Fairfield, Connecticut and helped all four hijackers move to a hotel there. They called area flight schools and after a few days Alrababah drove the four to Paterson, New Jersey to show them around. Some FBI agents suspected that Awlaki gave Alrababah the job of helping Hazmi and Hanjour. Alrababah was later arrested as a witness convicted after 9/11 in a fraudulent driver’s license scheme and deported to Jordan.
On May 21, Al-Hazmi moved in with Hanjour into an apartment in Paterson New Jersey. Mohammed Atta is living in the same city at another location.
On June 30, Al-Hazmi's car was involved in a minor traffic accident on the east-bound George Washington Bridge.
On June 25, 2001, Hazmi obtained a drivers' license in Florida, providing an address in Delray Beach, Florida, and he obtained a USA ID card on July 10. On August 2, Hazmi also obtained a Virginia drivers' license, and made a request for it to be reissued on September 7.
Hazmi, along with at least five other future hijackers, traveled to Las Vegas, Nevada at least six times in the summer of 2001. They reportedly drank alcohol, gambled, and paid strippers to perform lap dances for them.
Throughout the summer, Hazmi met with leader Mohammad Atta to discuss the status of the operation of a monthly basis.
On August 23, Israeli Mossad reportedly gives his name to the CIA as part of a list of 19 names they say are planning an attack in the near future. Only four of the names are known for certain – Nawaf, Atta, Marwan and Mihdhar, but again, the connection was not made with previous contacts with local law enforcement. On the same day, he is added to an INS watch list, together with Mihdhar to prevent entry into the US.
An internal review after 9/11 found that "everything was done [to find them] that could have been done." But the search does not appear to have been particularly aggressive. A national motor vehicle index was reportedly checked, but Hazmi's speeding ticket was not detected for some reason. The FBI did not search credit card databases, bank account databases, or car registration, all of which would have produced positive results. Hazmi was even listed in the 2000–2001 San Diego phone book, but this too was not searched until after the attacks.
He had not been placed on terrorist watch lists, nor did the CIA or NSA alert the FBI, Customs and Immigration, or local police and enforcement agencies.
On August 27, brothers Nawaf and Salem purchased flight tickets through Travelocity.com using Nawaf's Visa card.
On September 1, Nawaf registered Room #7 at the Pin-Del Motel in Laurel, Maryland. On the registration, he listed his driver's license number as 3402142-D, and gave a New York hotel as his permanent residence. Ziad Jarrah had checked into the hotel on August 27.
Nawaf and Mihdhar purchased their 9/11 plane tickets online using a credit card with their real names. This raised no red flags, since the FAA had not been informed that the two were on a terrorist watchlist.
Attacks.
On September 10, 2001, Hanjour, Mihdhar, and Nawaf checked into the Marriott Residence Inn in Herndon, Virginia where Saleh Ibn Abdul Rahman Hussayen, a prominent Saudi government official, was staying – although no evidence was ever uncovered that they had met, or knew of each other's presence.
On September 11, Hazmi board American Airlines Flight 77. The flight was scheduled to depart at 08:10, but ended up departing 10 minutes late from Gate D26 at Dulles. The last normal radio communications from the aircraft to air traffic control occurred at 08:50:51. At 08:54, the hijackers killed pilots Charles Burlingame and David Charlesbois Flight 77 began to deviate from its normal, assigned flight path and turned south, and then hijackers set the flight's autopilot heading for Washington, D.C. Passenger Barbara Olson called her husband, United States Solicitor General Theodore Olson, and reported that the plane had been hijacked and that the assailants had box cutters and knives. At 09:37, American Airlines Flight 77 crashed into the west facade of the Pentagon, killing all 64 aboard (including the hijackers), along with 125 on the ground in the Pentagon.
Aftermath.
Nawaf al-Hazmi's 1988 blue Toyota Corolla was found on the next day in Dulles International Airport's hourly parking lot. Inside the vehicle, authorities found a letter written by Mohamed Atta, maps of Washington, D.C. and New York City, a cashier's check made out to a Phoenix flight school, four drawings of a Boeing 757 cockpit, a box cutter, and a page with notes and phone numbers.
In the recovery process at the Pentagon, remains of all five Flight 77 hijackers were identified through a process of elimination, as not matching any DNA samples for the victims, and put into custody of the FBI. Forensics teams confirmed that it seemed two of the hijackers were brothers, based on their DNA similarities.
Several weeks after the attacks, a Las Vegas Days Inn employee went to the FBI and stated that she recognized Hazmi's photographs from the media as being a man she had met at the hotel, who had asked for details on hotels near Los Angeles. She admitted that he never gave his name.
Timeline in America.
Late in 2005, Army Lt. Col. Kevin Shaffer and Congressman Curt Weldon alleged that the Defense Department data mining project Able Danger had kept Nawaf, Khalid al-Mihdhar, Mohamed Atta and Marwan al-Shehhi all under surveillance as Al-Qaeda agents.

</doc>
<doc id="21631" url="http://en.wikipedia.org/wiki?curid=21631" title="November 12">
November 12

November 12 is the day of the year in the Gregorian calendar.

</doc>
<doc id="21632" url="http://en.wikipedia.org/wiki?curid=21632" title="Nero">
Nero

Nero (; Latin: "Nerō Claudius Caesar Augustus Germanicus"; 15 December 37 – 9 June 68) was Roman Emperor from 54 to 68, and the last in the Julio-Claudian dynasty. Nero was adopted by his grand-uncle Claudius to become his heir and successor, and succeeded to the throne in 54 following Claudius' death.
Nero focused much of his attention on diplomacy, trade and enhancing the cultural life of the Empire. He ordered theatres built and promoted athletic games. During his reign, the redoubtable general Corbulo conducted a successful war and negotiated peace with the Parthian Empire. His general Suetonius Paulinus crushed a revolt in Britain. Nero annexed the Bosporan Kingdom to the Empire and began the First Roman–Jewish War.
In 64 AD, most of Rome was destroyed in the Great Fire of Rome, which many Romans believed Nero himself had started in order to clear land for his planned palatial complex, the Domus Aurea. In 68, the rebellion of Vindex in Gaul and later the acclamation of Galba in Hispania drove Nero from the throne. Facing a false report of being denounced as a public enemy who was to be executed, he committed suicide on 9 June 68 (the first Roman emperor to do so). His death ended the Julio-Claudian Dynasty, sparking a brief period of civil wars known as the Year of the Four Emperors. Nero's rule is often associated with tyranny and extravagance. He is known for many executions, including that of his mother, and the probable murder by poison of his stepbrother Britannicus.
He is infamously known as the Emperor who "fiddled while Rome burned". He was rumored to have had captured Christians dipped in oil and set on fire in his garden at night as a source of light. This view is based on the writings of Tacitus, Suetonius and Cassius Dio, the main surviving sources for Nero's reign, but a few surviving sources paint Nero in a more favourable light. Some sources, including some mentioned above, portray him as an emperor who was popular with the common Roman people, especially in the East. Some modern historians question the reliability of ancient sources when reporting on Nero's tyrannical acts.
Early life.
Family.
Lucius Domitius Ahenobarbus, the future Nero, was born on 15 December 37 in Antium (modern Anzio and Nettuno), near Rome. He was the only son of Gnaeus Domitius Ahenobarbus and Agrippina the Younger, sister of Emperor Caligula.
Nero's father, Gnaeus, was the son of Lucius Domitius Ahenobarbus (consul 16 BC) and Antonia Major. Gnaeus was thus the grandson of Gnaeus Domitius Ahenobarbus (consul 32 BC) and probably Aemilia Lepida on his father's side, and the grandson of Mark Antony and Octavia Minor on his mother's side. Thus, Nero had as his paternal grandmother Antonia Major, and also claimed more remote descent from Antonia Minor as a great-grandson—later grandson after Claudius adopted him.
Through Octavia, Nero was the great-nephew of Caesar Augustus. Nero's father had been employed as a praetor and was a member of Caligula's staff when the latter travelled to the East (some apparently think Suetonius refers to Augustus' adopted son Gaius Caesar here, but this is not likely).
Nero's father was described by Suetonius as a murderer and a cheat who was charged by Emperor Tiberius with treason, adultery and incest. Tiberius died, allowing him to escape these charges. Nero's father died of edema ("dropsy") in 39 when Nero was two.
Nero's mother was Agrippina the Younger, a great-granddaughter of Caesar Augustus and his wife Scribonia through their daughter Julia the Elder and her husband Marcus Vipsanius Agrippa. Agrippina's father, Germanicus, was a grandson of Augustus's wife, Livia, on one side and to Mark Antony and Octavia on the other. Germanicus' mother Antonia Minor, was a daughter of Octavia Minor and Mark Antony. Octavia was Augustus' elder sister. Germanicus was also the adopted son of Tiberius. Agrippina poisoned her second husband Passienus Crispus, so many ancient historians also accuse her of murdering her third husband, the emperor Claudius.
Rise to power.
Nero was not expected to become Emperor because his maternal uncle, Caligula, had begun his reign at the age of 25 with enough time to produce his own heir. Nero's mother, Agrippina, lost favour with Caligula and was exiled in 39 after her husband's death. Caligula seized Nero's inheritance and sent him to be brought up by his less wealthy aunt, Domitia Lepida, who was the mother of Valeria Messalina, Claudius's third wife.
Caligula, his wife Caesonia and their infant daughter Julia Drusilla were murdered on 24 January 41. These events led Claudius, Caligula's uncle, to become emperor. Claudius allowed Agrippina to return from exile.
Claudius had married twice before marrying Valeria Messalina. His previous marriages produced three children including a son, Drusus, who died at a young age. He had two children with Messalina – Claudia Octavia (born 40) and Britannicus (born 41). Messalina was executed by Claudius in the year 48.
In 49 AD, Claudius married a fourth time, to Nero's mother Agrippina, despite her being his niece. To aid Claudius politically, young Nero was adopted in 50 and took the name Nero Claudius Caesar Drusus Germanicus (see adoption in Rome). Nero was older than his stepbrother Britannicus, and thus became heir to the throne.
Nero was proclaimed an adult in 51 at the age of 14. He was appointed proconsul, entered and first addressed the Senate, made joint public appearances with Claudius, and was featured in coinage. In 53, he married his stepsister Claudia Octavia.
Emperor (54–68 AD).
Early rule.
Claudius died in 54 and Nero, taking the name Nero Claudius Caesar Augustus Germanicus, was established as Emperor. Though accounts vary, many ancient historians state Agrippina poisoned Claudius. According to Pliny the Elder, she used poison mushrooms. It is not known how much Nero knew or if he was even involved in the death of Claudius.
Nero became Emperor at 17 when the news of Claudius' death was made known, the youngest emperor until that time. Ancient historians describe Nero's early reign as being strongly influenced by his mother, Agrippina, his tutor Lucius Annaeus Seneca, and the Praetorian Prefect Sextus Afranius Burrus, especially in the first year. Other tutors were less often mentioned, such as Alexander of Aegae.
Very early in Nero's rule, problems arose from competition for influence between Agrippina and Nero's two main advisers, Seneca and Burrus.
In 54, Agrippina tried to sit down next to Nero while he met with an Armenian envoy, but Seneca stopped her and prevented a scandalous scene (as it was unimaginable at that time for a woman to be in the same room as men doing official business). Nero's friends also mistrusted Agrippina and told Nero to beware of his mother.
Nero was reportedly unsatisfied with his marriage to Octavia and entered into an affair with Claudia Acte, a former slave. In 55, Agrippina attempted to intervene in favor of Octavia and demanded that her son dismiss Acte. Nero, with the support of Seneca, resisted the intervention of his mother in his personal affairs.
With Agrippina's influence over her son severed, she reportedly began pushing for Britannicus, Nero's stepbrother, to become emperor. Nearly fourteen-year-old Britannicus, heir-designate prior to Nero's adoption, was still legally a minor, but was approaching legal adulthood. According to Tacitus, Agrippina hoped that with her support, Britannicus, being the blood son of Claudius, would be seen as the true heir to the throne by the state over Nero. However, the youth died suddenly and suspiciously on 12 February 55, the very day before his proclamation as an adult had been set.
Nero claimed that Britannicus died from an epileptic seizure, but ancient historians all claim Britannicus' death came from Nero's poisoning him. Supposedly, he enlisted the services of Locusta, a woman who specialized in the manufacture of poisons. She devised a mixture to kill Britannicus, but after testing it unsuccessfully on a slave, Nero angrily threatened to have her put to death if she did not come up with something usable. Locusta then devised a new concoction that she promised would "kill swifter than a viper."
Her promise was fulfilled after Britannicus consumed it at a dinner party from water used to cool his wine, which had already been tasted, and succumbed within minutes. After the death of Britannicus, Agrippina was accused of slandering Octavia and Nero ordered her out of the imperial residence.
Matricide and consolidation of power.
Over time, Nero became progressively more powerful, freeing himself of his advisers and eliminating rivals to the throne. In 55, he removed Marcus Antonius Pallas, an ally of Agrippina, from his position in the treasury. Pallas, along with Burrus, was accused of conspiring against the Emperor to bring Faustus Sulla to the throne. Seneca was accused of having relations with Agrippina and embezzlement. Seneca succeeded in having himself, Pallas and Burrus acquitted. According to Cassius Dio, at this time, Seneca and Burrus reduced their role in governing from careful management to mere moderation of Nero.
In 58, Nero became romantically involved with Poppaea Sabina, the wife of his friend and future emperor Otho. Reportedly because a marriage to Poppaea and a divorce from Octavia did not seem politically feasible with Agrippina alive, Nero ordered the murder of his mother in 59. A number of modern historians find this an unlikely motive as Nero did not marry Poppaea until 62.
Additionally, according to Suetonius, Poppaea did not divorce her husband until after Agrippina's death, making it unlikely that the already married Poppaea would be pressing Nero for marriage. Some modern historians theorize that Nero's execution of Agrippina was prompted by her plotting to set Rubellius Plautus on the throne. According to Suetonius, Nero tried to kill his mother through a planned shipwreck, which took the life of her friend, Acerronia Polla, but when Agrippina survived, he had her executed and framed it as a suicide. The incident is also recorded by Tacitus.
In 62, Nero's adviser, Burrus, died. Additionally, Seneca was again faced with embezzlement charges. Seneca asked Nero for permission to retire from public affairs. Nero divorced and banished Octavia on grounds of infertility, leaving him free to marry the pregnant Poppaea. After public protests, Nero was forced to allow Octavia to return from exile, but she was executed shortly after her return.
Nero also was reported to have kicked Poppaea to death in 65 before she could have his second child. However, modern historians, noting Suetonius, Tacitus and Cassius Dio's possible bias against Nero and the likelihood that they did not have eyewitness accounts of private events, postulate that Poppaea may have died because of complications of miscarriage or childbirth.
Accusations of treason being plotted against Nero and the Senate first appeared in 62. The Senate ruled that Antistius, a praetor, should be put to death for speaking ill of Nero at a party. Later, Nero ordered the exile of Fabricius Veiento who slandered the Senate in a book. Tacitus writes that the roots of the conspiracy led by Gaius Calpurnius Piso began in this year. To consolidate power, Nero executed a number of people in 62 and 63 including his rivals Pallas, Rubellius Plautus and Faustus Sulla. According to Suetonius, Nero "showed neither discrimination nor moderation in putting to death whomsoever he pleased" during this period.
Nero's consolidation of power also included a slow usurping of authority from the Senate. In 54, Nero promised to give the Senate powers equivalent to those under Republican rule. By 65, senators complained that they had no power left and this led to the Pisonian conspiracy.
Other relationships.
When Nero's wife Poppaea Sabina died in 65, Nero went into deep mourning. Her body was not cremated, it was stuffed with spices, embalmed and put in the Mausoleum of Augustus. She was given a state funeral. Nero praised her during the funeral eulogy and gave her divine honors. It is said that Nero "burned ten years' worth of Arabia's incense production at her funeral.
In the beginning of 66, he married Statilia Messalina. She was already married when she became Nero's mistress in 65 AD, with Statilia's husband being driven to suicide in 66, so Nero could marry Statilia. She was one of the few of Nero's courtiers who survived the fall of his reign.
In 67, Nero ordered a young freedman, Sporus, to be castrated and then married him. According to Dion Cassius, Sporus bore an uncanny resemblance to Sabina, and Nero even called him by his dead wife's name.
Administrative policies.
Over the course of his reign, Nero often made rulings that pleased the lower class. Nero was criticized as being obsessed with personal popularity.
Nero began his reign in 54 by promising the Senate more autonomy. In this first year, he forbade others to refer to him with regard to enactments, for which he was praised by the Senate. Nero was known for spending his time visiting brothels and taverns during this period.
In 55, Nero began taking on a more active role as an administrator. He was consul four times between 55 and 60. During this period, some ancient historians speak fairly well of Nero and contrast it with his later rule.
Under Nero, restrictions were put on the amount of bail and fines. Also, fees for lawyers were limited. There was a discussion in the Senate on the misconduct of the freedmen class, and a strong demand was made that patrons should have the right of revoking freedom. Nero supported the freedmen and ruled that patrons had no such right.
The Senate tried to pass a law in which the crimes of one slave applied to all slaves within a household. Despite riots from the people, Nero supported the Senate on their measure, and deployed troops to organise the execution of 400 slaves affected by the law. However, he vetoed strong measures against the freedmen affected by the case.
After tax collectors were accused of being too harsh to the poor, Nero transferred collection authority to lower commissioners. Nero banned any magistrate or procurator from exhibiting public entertainment for fear that the venue was being used as a method to sway the populace. Additionally, there were many impeachments and removals of government officials along with arrests for extortion and corruption.
When further complaints arose that the poor were being overly taxed, Nero attempted to repeal all indirect taxes. The Senate convinced him this action would bankrupt the public treasury. As a compromise, taxes were cut from 4.5% to 2.5%. Additionally, secret government tax records were ordered to become public. To lower the cost of food imports, merchant ships were declared tax-exempt.
In imitation of the Greeks, Nero built a number of gymnasiums and theatres. Enormous gladiatorial shows were also held. Nero also established the quinquennial Neronia. The festival included games, poetry, and theater. Historians indicate that there was a belief that theatre led to immorality. Others considered that to have performers dressed in Greek clothing was old fashioned. Some questioned the large public expenditure on entertainment.
In 64, Rome burned. Nero enacted a public relief effort as well as significant reconstruction. A number of other major construction projects occurred in Nero's late reign. Nero had the marshes of Ostia filled with rubble from the fire. He erected the large Domus Aurea. In 67, Nero attempted to have a canal dug at the Isthmus of Corinth. Ancient historians state that these projects and others exacerbated the drain on the State's budget.
The cost to rebuild Rome was immense, requiring funds the state treasury did not have. Nero devalued the Roman currency for the first time in the Empire's history. He reduced the weight of the denarius from 84 per Roman pound to 96 (3.85 grams to 3.35 grams). He also reduced the silver purity from 99.5% to 93.5%—the silver weight dropping from 3.83 grams to 3.4 grams. Furthermore, Nero reduced the weight of the aureus from 40 per Roman pound to 45 (8 grams to 7.2 grams).
Between 62 and 67, according to Plinius the Elder and Seneca, Nero promoted an expedition to discover the sources of the Nile River. It was the first exploration of equatorial Africa from Europe in history. However, Nero's expedition up the Nile failed because water plants had clogged the river, denying Nero's vessels access to the Sudd of present-day South Sudan.
The economic policy of Nero is a point of debate among scholars. According to ancient historians, Nero's construction projects were overly extravagant and the large number of expenditures under Nero left Italy "thoroughly exhausted by contributions of money" with "the provinces ruined." Modern historians, though, note that the period was riddled with deflation and that it is likely that Nero's spending came in the form of public works projects and charity intended to ease economic troubles.
Great Fire of Rome (64 AD).
The Great Fire of Rome erupted on the night of 18 July to 19 July 64. The fire started at the southeastern end of the Circus Maximus in shops selling flammable goods.
The extent of the fire is uncertain. According to Tacitus, who was nine at the time of the fire, it spread quickly and burned for over five days. It destroyed three of fourteen Roman districts and severely damaged seven. The only other historian who lived through the period and mentioned the fire is Pliny the Elder, who wrote about it in passing. Other historians who lived through the period (including Josephus, Dio Chrysostom, Plutarch and Epictetus) make no mention of it in what remains of their work.
It is uncertain who or what actually caused the fire—whether accident or arson. Suetonius and Cassius Dio favor Nero as the arsonist, so he could build a palatial complex. Tacitus mentions that Christians confessed to the crime, but it is not known whether these confessions were induced by torture. However, accidental fires were common in ancient Rome. In fact, Rome suffered other large fires in 69 and in 80.
It was said by Suetonius and Cassius Dio that Nero sang the "Sack of Ilium" in stage costume while the city burned. Popular legend claims that Nero played the fiddle at the time of the fire, an anachronism based merely on the concept of the lyre, a stringed instrument associated with Nero and his performances. (There were no fiddles in 1st-century Rome.) Tacitus's account, however, has Nero in Antium at the time of the fire. Tacitus also said that Nero playing his lyre and singing while the city burned was only rumor.
According to Tacitus, upon hearing news of the fire, Nero returned to Rome to organize a relief effort, which he paid for from his own funds. Nero's contributions to the relief extended to personally taking part in the search for and rescue of victims of the blaze, spending days searching the debris without even his bodyguards. After the fire, Nero opened his palaces to provide shelter for the homeless, and arranged for food supplies to be delivered in order to prevent starvation among the survivors.
In the wake of the fire, he made a new urban development plan. Houses after the fire were spaced out, built in brick, and faced by porticos on wide roads. Nero also built a new palace complex known as the Domus Aurea in an area cleared by the fire. This included lush artificial landscapes and a 30-meter-tall statue of himself, the Colossus of Nero. The size of this complex is debated (from 100 to 300 acres). To find the necessary funds for the reconstruction, tributes were imposed on the provinces of the empire.
Tacitus, in one of the earliest non-Christian references to the origins of Christianity, notes that the population searched for a scapegoat and rumors held Nero responsible. To deflect blame, Nero targeted Christians. He ordered Christians to be thrown to dogs, while others were crucified and burned.
Public performances.
Nero enjoyed driving a one-horse chariot, singing to the lyre and poetry. He even composed songs that were performed by other entertainers throughout the empire. At first, Nero only performed for a private audience.
In 64 AD., Nero began singing in public in Neapolis in order to improve his popularity. He also sang at the second quinquennial Neronia in 65. It was said that Nero craved the attention, but historians also write that Nero was encouraged to sing and perform in public by the Senate, his inner circle and the people. Ancient historians strongly criticize his choice to perform, calling it shameful.
Nero was persuaded to participate in the Olympic Games of 67 in order to improve relations with Greece and display Roman dominance. As a competitor, Nero raced a ten-horse chariot and nearly died after being thrown from it. He also performed as an actor and a singer. Though Nero faltered in his racing (in one case, dropping out entirely before the end) and acting competitions, he won these crowns nevertheless and paraded them when he returned to Rome. The victories are attributed to Nero bribing the judges and his status as emperor.
War and peace with Parthia.
Shortly after Nero's accession to the throne in 54, the Roman vassal kingdom of Armenia overthrew their Iberian prince Rhadamistus and he was replaced with the Parthian prince Tiridates. This was seen as a Parthian invasion of Roman territory. There was concern in Rome over how the young Emperor would handle the situation. Nero reacted by immediately sending the military to the region under the command of Gnaeus Domitius Corbulo. The Parthians temporarily relinquished control of Armenia to Rome.
The peace did not last and full-scale war broke out in 58. The Parthian king Vologases I refused to remove his brother Tiridates from Armenia. The Parthians began a full-scale invasion of the Armenian kingdom. Commander Corbulo responded and repelled most of the Parthian army that same year. Tiridates retreated and Rome again controlled most of Armenia.
Nero was acclaimed in public for this initial victory. Tigranes, a Cappadocian noble raised in Rome, was installed by Nero as the new ruler of Armenia. Corbulo was appointed governor of Syria as a reward.
In 62, Tigranes invaded the Parthian province of Adiabene. Again, Rome and Parthia were at war and this continued until 63. Parthia began building up for a strike against the Roman province of Syria. Corbulo tried to convince Nero to continue the war, but Nero opted for a peace deal instead. There was anxiety in Rome about eastern grain supplies and a budget deficit.
The result was a deal where Tiridates again became the Armenian king, but was crowned in Rome by Emperor Nero. In the future, the king of Armenia was to be a Parthian prince, but his appointment required approval from the Romans. Tiridates was forced to come to Rome and partake in ceremonies meant to display Roman dominance.
This peace deal of 63 was a considerable victory for Nero politically. Nero became very popular in the eastern provinces of Rome and with the Parthians as well. The peace between Parthia and Rome lasted 50 years until Emperor Trajan of Rome invaded Armenia in 114.
Other major power struggles and rebellions.
The war with Parthia was not Nero's only major war but he was both criticized and praised for an aversion to battle. Like many emperors, Nero faced a number of rebellions and power struggles within the empire.
In 60, a major rebellion broke out in the province of Britannia. While the governor Gaius Suetonius Paulinus and his troops were busy capturing the island of Mona (Anglesey) from the druids, the tribes of the southeast staged a revolt led by queen Boudica of the Iceni. Boudica and her troops destroyed three cities before the army of Paulinus could return, receive reinforcements, and quell the rebellion in 61. Fearing Paulinus himself would provoke further rebellion, Nero replaced him with the more passive Publius Petronius Turpilianus.
In 65, Gaius Calpurnius Piso, a Roman statesman, organized a conspiracy against Nero with the help of Subrius Flavus and Sulpicius Asper, a tribune and a centurion of the Praetorian Guard. According to Tacitus, many conspirators wished to "rescue the state" from the emperor and restore the Republic. The freedman Milichus discovered the conspiracy and reported it to Nero's secretary, Epaphroditos. As a result, the conspiracy failed and its members were executed including Lucan, the poet. Nero's previous advisor, Seneca was ordered to commit suicide after admitting he discussed the plot with the conspirators.
In 66, there was a Jewish revolt in Judea stemming from Greek and Jewish religious tension. In 67, Nero dispatched Vespasian to restore order. This revolt was eventually put down in 70, after Nero's death. This revolt is famous for Romans breaching the walls of Jerusalem and destroying the Second Temple of Jerusalem.
The revolt of Vindex and Galba and the death of Nero.
In March 68, Gaius Julius Vindex, the governor of Gallia Lugdunensis, rebelled against Nero's tax policies. Lucius Verginius Rufus, the governor of Germania Superior, was ordered to put down Vindex's rebellion. In an attempt to gain support from outside his own province, Vindex called upon Servius Sulpicius Galba, the governor of Hispania Tarraconensis, to join the rebellion and further, to declare himself emperor in opposition to Nero.
At the Battle of Vesontio in May 68, Verginius' forces easily defeated those of Vindex and the latter committed suicide. However, after putting down this one rebel, Verginius' legions attempted to proclaim their own commander as Emperor. Verginius refused to act against Nero, but the discontent of the legions of Germany and the continued opposition of Galba in Spain did not bode well for him.
While Nero had retained some control of the situation, support for Galba increased despite his being officially declared a public enemy. The prefect of the Praetorian Guard, Gaius Nymphidius Sabinus, also abandoned his allegiance to the Emperor and came out in support for Galba.
In response, Nero fled Rome with the intention of going to the port of Ostia and, from there, to take a fleet to one of the still-loyal eastern provinces. According to Suetonius, Nero abandoned the idea when some army officers openly refused to obey his commands, responding with a line from Vergil's "Aeneid": "Is it so dreadful a thing then to die?" Nero then toyed with the idea of fleeing to Parthia, throwing himself upon the mercy of Galba, or to appeal to the people and beg them to pardon him for his past offences "and if he could not soften their hearts, to entreat them at least to allow him the prefecture of Egypt". Suetonius reports that the text of this speech was later found in Nero's writing desk, but that he dared not give it from fear of being torn to pieces before he could reach the Forum.
Nero returned to Rome and spent the evening in the palace. After sleeping, he awoke at about midnight to find the palace guard had left. Dispatching messages to his friends' palace chambers for them to come, he received no answers. Upon going to their chambers personally, he found them all abandoned. When he called for a gladiator or anyone else adept with a sword to kill him, no one appeared. He cried, "Have I neither friend nor foe?" and ran out as if to throw himself into the Tiber.
Returning, Nero sought for some place where he could hide and collect his thoughts. An imperial freedman, Phaon, offered his villa, located 4 miles outside the city. Travelling in disguise, Nero and four loyal freedman, Epaphroditos, Phaon, Neophytus, and Sporus, reached the villa, where Nero ordered them to dig a grave for him.
At this time, a courier arrived with a report that the Senate had declared Nero a public enemy and that it was their intention to execute him by beating him to death and that armed men had been sent to apprehend him for the act to take place in the Forum. The Senate actually was still reluctant and deliberating on the right course of action as Nero was the last member of the Julio-Claudian Family. Indeed, most of the senators had served the imperial family all their lives and felt a sense of loyalty to the deified bloodline, if not to Nero himself. The men actually had the goal of returning Nero back to the Senate, where the Senate hoped to work out a compromise with the rebelling governors that would preserve Nero's life, so that at least a future heir to the dynasty could be produced.
Nero, however, did not know this, and at the news brought by the courier, he prepared himself for suicide, pacing up and down muttering "Qualis artifex pereo" which translates to English as "What an artist dies in me." Losing his nerve, he first begged for one of his companions to set an example by first killing himself. At last, the sound of approaching horsemen drove Nero to face the end. However, he still could not bring himself to take his own life but instead he forced his private secretary, Epaphroditos, to perform the task.
When one of the horsemen entered, upon his seeing Nero all but dead he attempted to stop the bleeding in vain. Nero's final words were "Too late! This is fidelity!" He died on 9 June 68, the anniversary of the death of Octavia, and was buried in the Mausoleum of the Domitii Ahenobarbi, in what is now the Villa Borghese (Pincian Hill) area of Rome.
With his death, the Julio-Claudian dynasty ended. The Senate, when news of his death reached Rome, posthumously declared Nero a public enemy to appease the coming Galba (The Senate had initially declared Galba as a public enemy) and proclaimed him the new emperor. Chaos would ensue in the year of the Four Emperors.
Post mortem.
According to Suetonius and Cassius Dio, the people of Rome celebrated the death of Nero. Tacitus, though, describes a more complicated political environment. Tacitus mentions that Nero's death was welcomed by Senators, nobility and the upper class. The lower-class, slaves, frequenters of the arena and the theater, and "those who were supported by the famous excesses of Nero", on the other hand, were upset with the news. Members of the military were said to have mixed feelings, as they had allegiance to Nero, but were bribed to overthrow him.
Eastern sources, namely Philostratus II and Apollonius of Tyana, mention that Nero's death was mourned as he "restored the liberties of Hellas with a wisdom and moderation quite alien to his character" and that he "held our liberties in his hand and respected them."
Modern scholarship generally holds that, while the Senate and more well-off individuals welcomed Nero's death, the general populace was "loyal to the end and beyond, for Otho and Vitellius both thought it worthwhile to appeal to their nostalgia."
Nero's name was erased from some monuments, in what Edward Champlin regards as an "outburst of private zeal". Many portraits of Nero were reworked to represent other figures; according to Eric R. Varner, over fifty such images survive. This reworking of images is often explained as part of the way in which the memory of disgraced emperors was condemned posthumously (see damnatio memoriae). Champlin, however, doubts that the practice is necessarily negative and notes that some continued to create images of Nero long after his death.
The civil war during the year of the Four Emperors was described by ancient historians as a troubling period. According to Tacitus, this instability was rooted in the fact that emperors could no longer rely on the perceived legitimacy of the imperial bloodline, as Nero and those before him could. Galba began his short reign with the execution of many allies of Nero and possible future enemies. One such notable enemy included Nymphidius Sabinus, who claimed to be the son of Emperor Caligula.
Otho overthrew Galba. Otho was said to be liked by many soldiers because he had been a friend of Nero's and resembled him somewhat in temperament. It was said that the common Roman hailed Otho as Nero himself. Otho used "Nero" as a surname and reerected many statues to Nero. Vitellius overthrew Otho. Vitellius began his reign with a large funeral for Nero complete with songs written by Nero.
After Nero's suicide in 68, there was a widespread belief, especially in the eastern provinces, that he was not dead and somehow would return. This belief came to be known as the Nero Redivivus Legend.
The legend of Nero's return lasted for hundreds of years after Nero's death. Augustine of Hippo wrote of the legend as a popular belief in 422.
At least three Nero imposters emerged leading rebellions. The first, who sang and played the cithara or lyre and whose face was similar to that of the dead emperor, appeared in 69 during the reign of Vitellius. After persuading some to recognize him, he was captured and executed. Sometime during the reign of Titus (79–81), another impostor appeared in Asia and sang to the accompaniment of the lyre and looked like Nero but he, too, was killed. Twenty years after Nero's death, during the reign of Domitian, there was a third pretender. He was supported by the Parthians, who only reluctantly gave him up, and the matter almost came to war.
Physical appearance.
In his book "The Lives of the Twelve Caesars", Suetonius describes Nero as "about the average height, his body marked with spots and malodorous, his hair light blond, his features regular rather than attractive, his eyes blue and somewhat weak, his neck over thick, his belly prominent, and his legs very slender."
Historiography.
The history of Nero's reign is problematic in that no historical sources survived that were contemporary with Nero. These first histories at one time did exist and were described as biased and fantastical, either overly critical or praising of Nero. The original sources were also said to contradict on a number of events. Nonetheless, these lost primary sources were the basis of surviving secondary and tertiary histories on Nero written by the next generations of historians. A few of the contemporary historians are known by name. Fabius Rusticus, Cluvius Rufus and Pliny the Elder all wrote condemning histories on Nero that are now lost. There were also pro-Nero histories, but it is unknown who wrote them or for what deeds Nero was praised.
The bulk of what is known of Nero comes from Tacitus, Suetonius and Cassius Dio, who were all of the senatorial class. Tacitus and Suetonius wrote their histories on Nero over fifty years after his death, while Cassius Dio wrote his history over 150 years after Nero's death. These sources contradict on a number of events in Nero's life including the death of Claudius, the death of Agrippina, and the Roman fire of 64, but they are consistent in their condemnation of Nero.
A handful of other sources also add a limited and varying perspective on Nero. Few surviving sources paint Nero in a favourable light. Some sources, though, portray him as a competent emperor who was popular with the Roman people, especially in the east.
Cassius Dio (c. 155–229) was the son of Cassius Apronianus, a Roman senator. He passed the greater part of his life in public service. He was a senator under Commodus and governor of Smyrna after the death of Septimius Severus; and afterwards suffect consul around 205, and also proconsul in Africa and Pannonia.
Books 61–63 of Dio's "Roman History" describe the reign of Nero. Only fragments of these books remain and what does remain was abridged and altered by John Xiphilinus, an 11th-century monk.
Dio Chrysostom (c. 40–120), a Greek philosopher and historian, wrote the Roman people were very happy with Nero and would have allowed him to rule indefinitely. They longed for his rule once he was gone and embraced imposters when they appeared:
Indeed the truth about this has not come out even yet; for so far as the rest of his subjects were concerned, there was nothing to prevent his continuing to be Emperor for all time, seeing that even now everybody wishes he were still alive. And the great majority do believe that he still is, although in a certain sense he has died not once but often along with those who had been firmly convinced that he was still alive.
Epictetus (c. 55–135) was the slave to Nero's scribe Epaphroditos. He makes a few passing negative comments on Nero's character in his work, but makes no remarks on the nature of his rule. He describes Nero as a spoiled, angry and unhappy man.
The historian Josephus (c. 37–100), while calling Nero a tyrant, was also the first to mention bias against Nero. Of other historians, he said:
But I omit any further discourse about these affairs; for there have been a great many who have composed the history of Nero; some of which have departed from the truth of facts out of favour, as having received benefits from him; while others, out of hatred to him, and the great ill-will which they bore him, have so impudently raved against him with their lies, that they justly deserve to be condemned. Nor do I wonder at such as have told lies of Nero, since they have not in their writings preserved the truth of history as to those facts that were earlier than his time, even when the actors could have no way incurred their hatred, since those writers lived a long time after them.
Though more of a poet than historian, Lucanus (c. 39–65) has one of the kindest accounts of Nero's rule. He writes of peace and prosperity under Nero in contrast to previous war and strife. Ironically, he was later involved in a conspiracy to overthrow Nero and was executed.
Philostratus II "the Athenian" (c. 172–250) spoke of Nero in the Life of Apollonius Tyana (Books 4–5). Though he has a generally bad or dim view of Nero, he speaks of others' positive reception of Nero in the East.
The history of Nero by Pliny the Elder (c. 24–79) did not survive. Still, there are several references to Nero in Pliny's "Natural Histories". Pliny has one of the worst opinions of Nero and calls him an "enemy of mankind."
Plutarch (c. 46–127) mentions Nero indirectly in his account of the Life of Galba and the Life of Otho. Nero is portrayed as a tyrant, but those that replace him are not described as better.
It is not surprising that Seneca (c. 4 BEC–65), Nero's teacher and advisor, writes very well of Nero.
Suetonius (c. 69–130) was a member of the equestrian order, and he was the head of the department of the imperial correspondence. While in this position, Suetonius started writing biographies of the emperors, accentuating the anecdotal and sensational aspects.
The "Annals" by Tacitus (c. 56–117) is the most detailed and comprehensive history on the rule of Nero, despite being incomplete after the year 66. Tacitus described the rule of the Julio-Claudian emperors as generally unjust. He also thought that existing writing on them was unbalanced:
The histories of Tiberius, Caius, Claudius and Nero, while they were in power, were falsified through terror, and after their death were written under the irritation of a recent hatred.
Tacitus was the son of a procurator, who married into the elite family of Agricola. He entered his political life as a senator after Nero's death and, by Tacitus' own admission, owed much to Nero's rivals. Realising that this bias may be apparent to others, Tacitus protests that his writing is true.
In 1562 Girolamo Cardano published in Basel his "Encomium Neronis", which was one of the first historical references of the Modern era to portray Nero in a positive light.
Nero and religion.
Jewish tradition.
At the end of 66, conflict broke out between Greeks and Jews in Jerusalem and Caesarea. According to the Talmud, Nero went to Jerusalem and shot arrows in all four directions. All the arrows landed in the city. He then asked a passing child to repeat the verse he had learned that day. The child responded, "I will lay my vengeance upon Edom by the hand of my people Israel" (Ez. ). Nero became terrified, believing that God wanted the Temple in Jerusalem to be destroyed, but would punish the one to carry it out. Nero said, "He desires to lay waste His House and to lay the blame on me," whereupon he fled and converted to Judaism to avoid such retribution. Vespasian was then dispatched to put down the rebellion.
The Talmud adds that the sage Reb Meir Baal HaNess, a prominent supporter of the Bar Kokhba rebellion against Roman rule, was a descendant of Nero.
Roman and Greek sources nowhere report Nero's alleged trip to Jerusalem or his alleged conversion to Judaism. There is also no record of Nero having any offspring who survived infancy: his only recorded child, Claudia Augusta, died aged 4 months.
Christian tradition.
Non-Christian historian Tacitus describes Nero extensively torturing and executing Christians after the fire of 64. Suetonius also mentions Nero punishing Christians, though he does so because they are "given to a new and mischievous superstition" and does not connect it with the fire.
Christian writer Tertullian (c. 155–230) was the first to call Nero the first persecutor of Christians. He wrote, "Examine your records. There you will find that Nero was the first that persecuted this doctrine". Lactantius (c. 240–320) also said that Nero "first persecuted the servants of God". as does Sulpicius Severus. However, Suetonius writes that, "since the Jews constantly made disturbances at the instigation of Chrestus, he [emperor Claudius] expelled them from Rome" ("Iudaeos impulsore Chresto assidue tumultuantis Roma expulit"). These expelled "Jews" may have been early Christians, although Suetonius is not explicit. Nor is the Bible explicit, calling Aquila of Pontus and his wife, Priscilla, both expelled from Italy at the time, "Jews".
Reputed martyrdoms of Peter and Paul.
The first text to suggest that Nero ordered the execution of an apostle is the apocryphal "Ascension of Isaiah", a Christian writing from the 2nd century. It says, "the slayer of his mother, who himself (even) this king, will persecute the plant which the Twelve Apostles of the Beloved have planted. Of the Twelve one will be delivered into his hands."
Bishop Eusebius of Caesarea (c. 275–339) was the first to write explicitly that Paul was beheaded in Rome during the reign of Nero. He states that Nero's persecution led to Peter and Paul's deaths, but that Nero did not give any specific orders. However, several other accounts going back to the 1st century have Paul surviving his two years in Rome and travelling to Hispania, before facing trial in Rome again prior to his death.
Peter is first said to have been crucified upside-down in Rome during Nero's reign (but not by Nero) in the apocryphal Acts of Peter (c. 200). The account ends with Paul still alive and Nero abiding by God's command not to persecute any more Christians.
By the 4th century, a number of writers were stating that Nero killed Peter and Paul.
The Antichrist.
The Sibylline Oracles, Book 5 and 8, written in the 2nd century, speak of Nero returning and bringing destruction. Within Christian communities, these writings, along with others, fueled the belief that Nero would return as the Antichrist. In 310, Lactantius wrote that Nero "suddenly disappeared, and even the burial place of that noxious wild beast was nowhere to be seen. This has led some persons of extravagant imagination to suppose that, having been conveyed to a distant region, he is still reserved alive; and to him they apply the Sibylline verses".
In 422, Augustine of Hippo wrote about 2 Thessalonians 2:1–11, where he believed Paul mentioned the coming of the Antichrist. Though he rejects the theory, Augustine mentions that many Christians believed that Nero was the Antichrist or would return as the Antichrist. He wrote, "so that in saying, 'For the mystery of iniquity doth already work,' he alluded to Nero, whose deeds already seemed to be as the deeds of Antichrist."
Some modern biblical scholars such as Delbert Hillers (Johns Hopkins University) of the American Schools of Oriental Research and the editors of the Oxford & Harper Collins Study Bibles, contend that the number 666 in the Book of Revelation is a code for Nero, a view that is also supported in Roman Catholic Biblical commentaries.
The concept of Nero as the Antichrist is often a central belief of Preterist eschatology.
References.
Primary sources
Secondary sources

</doc>
<doc id="21634" url="http://en.wikipedia.org/wiki?curid=21634" title="Neoclassical economics">
Neoclassical economics

Neoclassical economics is a term variously used for approaches to economics focusing on the determination of prices, outputs, and income distributions in markets through supply and demand, often mediated through a hypothesized maximization of utility by income-constrained individuals and of profits by cost-constrained firms employing available information and factors of production, in accordance with rational choice theory.
Neoclassical economics dominates microeconomics, and together with Keynesian economics forms the neoclassical synthesis which dominates mainstream economics today. Although neoclassical economics has gained widespread acceptance by contemporary economists, there have been many critiques of neoclassical economics, often incorporated into newer versions of neoclassical theory.
Overview.
The term was originally introduced by Thorstein Veblen in his 1900 article 'Preconceptions of Economic Science', in which he related marginalists in the tradition of Alfred Marshall et al. to those in the Austrian School.
 "No attempt will here be made even to pass a verdict on the relative claims of the recognized two or three main "schools" of theory, beyond the somewhat obvious finding that, for the purpose in hand, the so-called Austrian school is scarcely distinguishable from the neo-classical, unless it be in the different distribution of emphasis. The divergence between the modernized classical views, on the one hand, and the historical and Marxist schools, on the other hand, is wider, so much so, indeed, as to bar out a consideration of the postulates of the latter under the same head of inquiry with the former." – Veblen
It was later used by John Hicks, George Stigler, and others to include the work of Carl Menger, William Stanley Jevons, Léon Walras, John Bates Clark, and many others. Today it is usually used to refer to mainstream economics, although it has also been used as an umbrella term encompassing a number of other schools of thought, notably excluding institutional economics, various historical schools of economics, and Marxian economics, in addition to various other heterodox approaches to economics.
Neoclassical economics is characterized by several assumptions common to many schools of economic thought. There is not a complete agreement on what is meant by neoclassical economics, and the result is a wide range of neoclassical approaches to various problem areas and domains—ranging from neoclassical theories of labor to neoclassical theories of demographic changes.
Three central assumptions.
It was expressed by E. Roy Weintraub that neoclassical economics rests on three assumptions, although certain branches of neoclassical theory may have different approaches:
From these three assumptions, neoclassical economists have built a structure to understand the allocation of scarce resources among alternative ends—in fact understanding such allocation is often considered the definition of economics to neoclassical theorists. Here's how William Stanley Jevons presented "the problem of Economics".
"Given, a certain population, with various needs and powers of production, in possession of certain lands and other sources of material: required, the mode of employing their labour which will maximize the utility of their produce."
From the basic assumptions of neoclassical economics comes a wide range of theories about various areas of economic activity. For example, profit maximization lies behind the neoclassical theory of the firm, while the derivation of demand curves leads to an understanding of consumer goods, and the supply curve allows an analysis of the factors of production. Utility maximization is the source for the neoclassical theory of consumption, the derivation of demand curves for consumer goods, and the derivation of labor supply curves and reservation demand.
Market supply and demand are aggregated across firms and individuals. Their interactions determine equilibrium output and price. The market supply and demand for each factor of production is derived analogously to those for market to determine equilibrium income and the income distribution. Factor demand incorporates the marginal-productivity relationship of that factor in the output market.
Neoclassical economics emphasizes equilibria, where equilibria are the solutions of agent maximization problems. Regularities in economies are explained by methodological individualism, the position that economic phenomena can be explained by aggregating over the behavior of agents. The emphasis is on microeconomics. Institutions, which might be considered as prior to and conditioning individual behavior, are de-emphasized. Economic subjectivism accompanies these emphases. See also general equilibrium.
Origins.
Classical economics, developed in the 18th and 19th centuries, included a value theory and distribution theory. The value of a product was thought to depend on the costs involved in producing that product. The explanation of costs in Classical economics was simultaneously an explanation of distribution. A landlord received rent, workers received wages, and a capitalist tenant farmer received profits on their investment. This classic approach included the work of Adam Smith and David Ricardo.
However, some economists gradually began emphasizing the perceived value of a good to the consumer. They proposed a theory that the value of a product was to be explained with differences in utility (usefulness) to the consumer. (In England, economists tended to conceptualize utility in keeping with the Utilitarianism of Jeremy Bentham and later of John Stuart Mill.)
The third step from political economy to economics was the introduction of marginalism and the proposition that economic actors made decisions based on margins. For example, a person decides to buy a second sandwich based on how full he or she is after the first one, a firm hires a new employee based on the expected increase in profits the employee will bring. This differs from the aggregate decision making of classical political economy in that it explains how vital goods such as water can be cheap, while luxuries can be expensive.
The marginal revolution.
The change in economic theory from classical to neoclassical economics has been called the 'marginal revolution', although it has been argued that the process was slower than the term suggests. It is frequently dated from William Stanley Jevons's "Theory of Political Economy" (1871), Carl Menger's "Principles of Economics" (1871), and Léon Walras's "Elements of Pure Economics" (1874–1877). Historians of economics and economists have debated:
In particular, Jevons saw his economics as an application and development of Jeremy Bentham's utilitarianism and never had a fully developed general equilibrium theory. Menger did not embrace this hedonic conception, explained diminishing marginal utility in terms of subjective prioritization of possible uses, and emphasized disequilibrium and the discrete; further Menger had an objection to the use of mathematics in economics, while the other two modeled their theories after 19th century mechanics. Jevons built on the hedonic conception of Bentham or of Mill, while Walras was more interested in the interaction of markets than in explaining the individual psyche.
Alfred Marshall's textbook, "Principles of Economics" (1890), was the dominant textbook in England a generation later. Marshall's influence extended elsewhere; Italians would compliment Maffeo Pantaleoni by calling him the "Marshall of Italy". Marshall thought classical economics attempted to explain prices by the cost of production. He asserted that earlier marginalists went too far in correcting this imbalance by overemphasizing utility and demand. Marshall thought that "We might as reasonably dispute whether it is the upper
or the under blade of a pair of scissors that cuts a piece of
paper, as whether value is governed by utility or cost of
production".
Marshall explained price by the intersection of supply and demand curves. The introduction of different market "periods" was an important innovation of Marshall’s:
Marshall took supply and demand as stable functions and extended supply and demand explanations of prices to all runs. He argued supply was easier to vary in longer runs, and thus became a more important determinant of price in the very long run.
Further developments.
An important change in neoclassical economics occurred around 1933. Joan Robinson and Edward H. Chamberlin, with the near simultaneous publication of their respective books, "The Economics of Imperfect Competition" (1933) and "The Theory of Monopolistic Competition" (1933), introduced models of imperfect competition. Theories of market forms and industrial organization grew out of this work. They also emphasized certain tools, such as the marginal revenue curve.
Joan Robinson's work on imperfect competition, at least, was a response to certain problems of Marshallian partial equilibrium theory highlighted by Piero Sraffa. Anglo-American economists also responded to these problems by turning towards general equilibrium theory, developed on the European continent by Walras and Vilfredo Pareto. J. R. Hicks's "Value and Capital" (1939) was influential in introducing his English-speaking colleagues to these traditions. He, in turn, was influenced by the Austrian School economist Friedrich Hayek's move to the London School of Economics, where Hicks then studied.
These developments were accompanied by the introduction of new tools, such as indifference curves and the theory of ordinal utility. The level of mathematical sophistication of neoclassical economics increased. Paul Samuelson's "Foundations of Economic Analysis" (1947) contributed to this increase in mathematical modelling.
The interwar period in American economics has been argued to have been pluralistic, with neoclassical economics and institutionalism competing for allegiance. Frank Knight, an early Chicago school economist attempted to combine both schools. But this increase in mathematics was accompanied by greater dominance of neoclassical economics in Anglo-American universities after World War II. Some argue that outside political interventions, such as McCarthyism, and internal ideological bullying played an important role in this rise to dominance.
Hicks' book, "Value and Capital" had two main parts. The second, which was arguably not immediately influential, presented a model of temporary equilibrium. Hicks was influenced directly by Hayek's notion of intertemporal coordination and paralleled by earlier work by Lindhal. This was part of an abandonment of disaggregated long run models. This trend probably reached its culmination with the Arrow-Debreu model of intertemporal equilibrium. The Arrow-Debreu model has canonical presentations in Gérard Debreu's "Theory of Value" (1959) and in Arrow and Hahn's "General Competitive Analysis" (1971).
Many of these developments were against the backdrop of improvements in both econometrics, that is the ability to measure prices and changes in goods and services, as well as their aggregate quantities, and in the creation of macroeconomics, or the study of whole economies. The attempt to combine neo-classical microeconomics and Keynesian macroeconomics would lead to the neoclassical synthesis which has been the dominant paradigm of economic reasoning in English-speaking countries since the 1950s. Hicks and Samuelson were for example instrumental in mainstreaming Keynesian economics.
Macroeconomics influenced the neoclassical synthesis from the other direction, undermining foundations of classical economic theory such as Say's Law, and assumptions about political economy such as the necessity for a hard-money standard. These developments are reflected in neoclassical theory by the search for the occurrence in markets of the equilibrium conditions of Pareto optimality and self-sustainability.
Criticisms.
Neoclassical economics is sometimes criticized for having a normative bias. In this view, it does not focus on explaining actual economies, but instead on describing a "utopia" in which Pareto optimality applies.
The assumption that individuals act rationally may be viewed as ignoring important aspects of human behavior. Many see the "economic man" as being quite different from real people. Many economists, even contemporaries, have criticized this model of economic man. Thorstein Veblen put it most sardonically. Neoclassical economics assumes a person to be,
"a lightning calculator of pleasures and pains, who oscillates like a homogeneous globule of desire of happiness under the impulse of stimuli that shift about the area, but leave him intact."
Large corporations might perhaps come closer to the neoclassical ideal of profit maximization, but this is not necessarily viewed as desirable if this comes at the expense of neglect of wider social issues.
Problems exist with making the neoclassical general equilibrium theory compatible with an economy that develops over time and includes capital goods. This was explored in a major debate in the 1960s—the "Cambridge capital controversy"—about the validity of neoclassical economics, with an emphasis on the economic growth, capital, aggregate theory, and the marginal productivity theory of distribution. There were also internal attempts by neoclassical economists to extend the Arrow-Debreu model to disequilibrium investigations of stability and uniqueness. However a result known as the Sonnenschein-Mantel-Debreu theorem suggests that the assumptions that must be made to ensure that the equilibrium is stable and unique are quite restrictive.
Neoclassical economics is also often seen as relying too heavily on complex mathematical models, such as those used in general equilibrium theory, without enough regard to whether these actually describe the real economy. Many see an attempt to model a system as complex as a modern economy by a mathematical model as unrealistic and doomed to failure. A famous answer to this criticism is Milton Friedman's claim that theories should be judged by their ability to predict events rather than by the realism of their assumptions. Mathematical models also include those in game theory, linear programming, and econometrics. Some see mathematical models used in contemporary research in mainstream economics as having transcended neoclassical economics, while others disagree. Critics of neoclassical economics are divided into those who think that highly mathematical method is inherently wrong and those who think that mathematical method is potentially good even if contemporary methods have problems.
In general, allegedly overly unrealistic assumptions are one of the most common criticisms towards neoclassical economics. It is fair to say that many (but not all) of these criticisms can only be directed towards a subset of the neoclassical models (for example, there are many neoclassical models where unregulated markets fail to achieve Pareto-optimality and there has recently been an increased interest in modeling non-rational decision making).

</doc>
<doc id="21636" url="http://en.wikipedia.org/wiki?curid=21636" title="Naomi Wolf">
Naomi Wolf

Naomi R. Wolf (born November 12, 1962) is an American author and former political consultant. With the publication of the 1991 bestselling book "The Beauty Myth", she became a leading spokeswoman of what was later described as the third wave of the feminist movement. In 2007, she published the bestselling book "The End of America".
Childhood, education and personal life.
Wolf was born in San Francisco, to a Jewish family. Her mother is Deborah Goleman, an anthropologist and the author of "The Lesbian Community". Her father is the Romanian-born gothic horror scholar Leonard Wolf. She attended Lowell High School and debated in regional speech tournaments as a member of the Lowell Forensic Society. Wolf then attended Yale University where in 1984, she received her Bachelor of Arts in English literature. From 1985 to 1987, she was a Rhodes Scholar at New College, Oxford.
In 2004, Wolf reported an alleged incident of "sexual encroachment" by professor Harold Bloom she had experienced when she was a Yale undergraduate working on poetry with Bloom. Frustrated in her efforts to gain satisfaction that the university would take such an incident seriously, Wolf made her complaint public.
Wolf was married to journalist David Shipley. They have two children, Rosa (b. 1995) and Joseph (b. 2000). Wolf and Shipley divorced in 2005.
Works.
"The Beauty Myth".
In the early 1990s, Wolf gained international fame as a spokeswoman of third-wave feminism as a result of the success of her first book "The Beauty Myth", which became an international bestseller. In the book, she argues that "beauty" as a normative value is entirely socially constructed, and that the patriarchy determines the content of that construction with the goal of reproducing its own hegemony.
Wolf posits the idea of an "iron-maiden," an intrinsically unattainable standard that is then used to punish women physically and psychologically for their failure to achieve and conform to it. Wolf criticized the fashion and beauty industries as exploitative of women, but added that the beauty myth extended into all areas of human functioning. Wolf writes that women should have "the choice to do whatever we want with our faces and bodies without being punished by an ideology that is using attitudes, economic pressure, and even legal judgments regarding women's appearance to undermine us psychologically and politically". Wolf argues that women were under assault by the "beauty myth" in five areas: work, religion, sex, violence, and hunger. Ultimately, Wolf argues for a relaxation of normative standards of beauty. In her introduction, Wolf positioned her argument against the concerns of second-wave feminists and offered the following analysis:
 The more legal and material hindrances women have broken through, the more strictly and heavily and cruelly images of female beauty have come to weigh upon us... [D]uring the past decade, women breached the power structure; meanwhile, eating disorders rose exponentially and cosmetic surgery became the fastest-growing specialty... [P]ornography became the main media category, ahead of legitimate films and records combined, and thirty-three thousand American women told researchers that they would rather lose ten to fifteen pounds than achieve any other goal...More women have more money and power and scope and legal recognition than we have ever had before; but in terms of how we feel about ourselves physically, we may actually be worse off than our unliberated grandmothers.
Wolf's book was a bestseller, receiving polarized responses from the public and mainstream media, but winning praise from most feminists. Second-wave feminist Germaine Greer wrote that "The Beauty Myth" was "the most important feminist publication since "The Female Eunuch", and Gloria Steinem wrote, ""The Beauty Myth" is a smart, angry, insightful book, and a clarion call to freedom. Every woman should read it." British novelist Fay Weldon called the book "essential reading for the New Woman". Betty Friedan wrote in "Allure" magazine that "'The Beauty Myth' and the controversy it is eliciting could be a hopeful sign of a new surge of feminist consciousness."
However, Camille Paglia, whose "Sexual Personae" was published the same year as "The Beauty Myth", derided Wolf as unable to perform "historical analysis", and called her education "completely removed from reality." Her comments touched off a series of contentious debates between Wolf and Paglia in the pages of "The New Republic".
Likewise, Christina Hoff Sommers criticized Wolf for publishing the estimate that 150,000 women were dying every year from anorexia. Sommers wrote that the actual number is closer to 100, a figure which others, such as Jennifer Baumgardner and Amy Richards, stated to be much too low. In the same interview, Sommers stated that Wolf had retracted the figure.
"The New York Times" published a harshly critical assessment of Wolf's work by Caryn James. She lambasted the book as a "sloppily researched polemic as dismissible as a hackneyed adventure film...Even by the standards of pop-cultural feminist studies, "The Beauty Myth" is a mess." In a comparatively positive review, "The Washington Post" called the book "persuasive" and praised its "accumulated evidence."
"Promiscuities".
"Promiscuities" reports on and analyzes the shifting patterns of contemporary adolescent sexuality. Wolf argues that literature is rife with examples of male coming-of-age stories, covered autobiographically by D. H. Lawrence, Tobias Wolff, J. D. Salinger, and Ernest Hemingway, and covered misogynistically by Henry Miller, Philip Roth, and Norman Mailer. Wolf insists, however, that female accounts of adolescent sexuality have been systematically suppressed. She adduces cross-cultural material to demonstrate that women have, across history, been celebrated as more carnal than men. Wolf also argues that women must reclaim the legitimacy of their own sexuality by shattering the polarization of women between virgin and whore.
"Promiscuities" received, in general, negative reviews. "The New York Times" published a review that characterized Wolf as a "frustratingly inept messenger: a sloppy thinker and incompetent writer. She tries in vain to pass off tired observations as radical aperçus, subjective musings as generational truths, sappy suggestions as useful ideas". Two days earlier, however, a different "Times" reviewer praised the book, writing, "Anyone—particularly anyone who, like Ms. Wolf, was born in the 1960s—will have a very hard time putting down "Promiscuities". Told through a series of confessions, her book is a searing and thoroughly fascinating exploration of the complex wildlife of female sexuality and desire." In contrast, "The Library Journal" excoriated the work, writing, "Overgeneralization abounds as she attempts to apply the microcosmic events of this mostly white, middle-class, liberal milieu to a whole generation...There is a desperate defensiveness in the tone of this book which diminishes the force of her argument."
"Misconceptions".
"Misconceptions" examines modern assumptions surrounding pregnancy and childbirth. Most of the book is told through the prism of Wolf's personal experience of her first pregnancy. She describes the "vacuous impassivity" of the ultrasound technician who gives her the first glimpse of her new baby. Wolf both laments her C-section and examines why the procedure is commonplace in the United States, and advocates a return to more personal approaches to childbirth such as midwifery. The second half of the book catalogs a series of anecdotes about life after giving birth, focusing in particular on inequalities that arise in men and women's approaches and adjustments to child care.
"The End of America".
In "," Wolf takes a historical look at the rise of fascism, outlining 10 steps necessary for a fascist group (or government) to destroy the democratic character of a nation-state and subvert the social/political liberty previously exercised by its citizens:
The book details how this pattern was implemented in Nazi Germany, Fascist Italy, and elsewhere, and analyzes its emergence and application of all the 10 steps in American political affairs since the September 11 attacks.
"The End of America" was adapted for the screen as a documentary by filmmakers Annie Sundberg and Ricki Stern, best known for "The Devil Came on Horseback" and "The Trials of Darryl Hunt". It had its worldwide premiere at the Hamptons International Film Festival on October 17, 2008. It has since been screened at Sheffield DocFest in the UK, as well as in limited release at New York City's IFC Center. The film became available online on October 21, 2008 at SnagFilms. "End of America" was favorably reviewed in "The New York Times" by Stephen Holden as well as in "Variety" magazine.
Mark Nuckols of the Russian Academy of National Economy argues in "The Atlantic" that Wolf draws false historical parallels based on highly selective and misleading citations.
"Give Me Liberty".
"Give Me Liberty: A Handbook for American Revolutionaries" was written as a sequel to "The End of America: Letter of Warning to a Young Patriot."
In the book, Wolf looks at times and places in history where citizens were faced with the closing of an open society and successfully fought back, and looks back at the ordinary people of the Founding Fathers of the United States' generation, the ones not named by history, all of whom had this "vision of liberty" and moved it forward by putting their lives on the line to make the vision real. She is an outspoken advocate for citizenship and wonders whether younger Americans have the skills and commitment to act as true citizens. She wrote in 2007:
 This lack of understanding about how democracy works is disturbing enough. But at a time when our system of government is under assault from an administration that ignores traditional checks and balances, engages in illegal wiretapping and writes secret laws on torture, it means that we're facing an unprecedented crisis. As the Founders knew, if citizens are ignorant of or complacent about the proper workings of a republic "of laws not of men," then any leader of any party – or any tyrannical Congress or even a tyrannical majority – can abuse the power they hold. But at this moment of threat to the system the Framers set in place, a third of young Americans don't really understand what they were up to.
"Vagina: A New Biography".
Published in 2012 on the topic of the vagina, "Vagina: A New Biography" was widely criticized, especially by feminist authors. Calling it "ludicrous" at "Slate.com", Katie Roiphe wrote, "I doubt the most brilliant novelist in the world could have created a more skewering satire of Naomi Wolf’s career than her latest book." In "The Nation", Katha Pollitt said the book was "silly" and contained "much dubious neuroscience and much foolishness"; she concluded, "It’s lucky vaginas can’t read, or mine would be cringing in embarrassment." Although writing that "Wolf’s ideas and suggestions in 'Vagina' are valuable ones," Toni Bentley said in "The New York Times Book Review" that the book contained "shoddy" research and "is undermined by the fact that she has rendered herself less than unreliable over the past couple of decades, with one rant more hysterical than another." In "The New York Review of Books" Zoë Heller called "Vagina" "a shoddy piece of work, full of childlike generalizations and dreary, feminist auto-think." "Los Angeles Times" columnist Meghan Daum decried the book’s "painful" writing and its "hoary ideas about how women think." In "The New York Observer", Nina Burleigh suggested that critics of the book were so vehement "because (a) their editors handed the book to them for review because they thought it was an Important Feminist Book when it's actually slight and (b) there’s a grain of truth in what she’s trying to say."
In response to the criticism, Wolf stated the following in a television interview:
...anything that shows documentation of the brain and vagina connection is going to alarm some feminists... ...also feminism has kind of retreated into the academy and sort of embraced the idea that all gender is socially constructed and so here is a book that is actually looking at science... ... though there has been some criticisms of the book from some feminists ... who say, well you can’t look at the science because that means we have to grapple with the science... ... to me the feminist task of creating a just world isn’t changed at all by this fascinating neuroscience that shows some differences between men and women.
Other writings.
Wolf's other books include "Fire with Fire" on politics, female empowerment and women's sexual liberation. "The New York Times" assailed the work for its "dubious oversimplifications and highly debatable assertions" and its "disconcerting penchant for inflationary prose," nonetheless noting Wolf's "efforts to articulate an accessible, pragmatic feminism, ...helping to replace strident dogma with common sense." The "Time" magazine reviewer dismissed the book as "flawed," noting however that Wolf was "an engaging raconteur" who was also "savvy about the role of TV – especially the Thomas-Hill hearings and daytime talk shows – in radicalizing women, including homemakers." The reviewer characterized the book as advocating an inclusive strain of feminism that welcomed abortion opponents.
In 2005, Wolf published "The Treehouse: Eccentric Wisdom from my Father on How to Live, Love, and See," which chronicled her midlife crisis attempt to reclaim her creative and poetic vision and revalue her father's love, and her father's force as an artist and a teacher.
Feminist positions.
In publishing an article in "The New Republic" that criticized contemporary pro-choice positions, Wolf argued that the movement had "developed a lexicon of dehumanization" and urged feminists to accept abortion as a form of homicide and defend the procedure within the ambiguity of this moral conundrum. She continues, "Abortion should be legal; it is sometimes even necessary. Sometimes the mother must be able to decide that the fetus, in its full humanity, must die."
Wolf concluded by speculating that in a world of "real gender equality," passionate feminists "might well hold candlelight vigils at abortion clinics, standing shoulder to shoulder with the doctors who work there, commemorating and saying goodbye to the dead." More recently, in an article on the subtle manipulation of George W. Bush's image among women, Wolf wrote "Abortion is an issue not of "Ms." Magazine-style fanaticism or suicidal Republican religious reaction, but a complex issue."
Pro-life commentators said Wolf "fails to carry through fully in her analysis...this simply is not, or should not be, the unqualified response of our society to the destruction of innocent life."
Wolf suggested in 2003 that the ubiquity of internet pornography tends to enervate the sexual attraction of men toward typical real women. She writes, "The onslaught of porn is responsible for deadening male libido in relation to real women, and leading men to see fewer and fewer women as 'porn-worthy.' Far from having to fend off porn-crazed young men, young women are worrying that as mere flesh and blood, they can scarcely get, let alone hold, their attention." Wolf advocates abstaining from porn not on moral grounds, but because "greater supply of the stimulant equals diminished capacity."
Wolf has examined how modern Western women, born in inclusive, egalitarian liberal democracies, are assuming positions of leadership in neofascist political movements:
 Second-wave feminist theory abounds in assertions that war, racism, love of hierarchy, and general repressiveness belong to “patriarchy”; women’s leadership, by contrast, would naturally create a more inclusive, collaborative world. The problem is that it has never worked out that way, as the rise of women to leadership positions in Western Europe’s far-right parties should remind us. Leaders such as Marine Le Pen of France’s National Front, Pia Kjaersgaard of Danish People's Party, and Siv Jensen of Norway’s Progress Party reflect the enduring appeal of neofascist movements to many modern women in egalitarian, inclusive liberal democracies.
Wolf has spoken about the dress required of women living in Muslim countries:
 The West interprets veiling as repression of women and suppression of their sexuality. But when I traveled in Muslim countries and was invited to join a discussion in women-only settings within Muslim homes, I learned that Muslim attitudes toward women's appearance and sexuality are not rooted in repression, but in a strong sense of public versus private, of what is due to God and what is due to one's husband. It is not that Islam suppresses sexuality, but that it embodies a strongly developed sense of its appropriate channeling – toward marriage, the bonds that sustain family life, and the attachment that secures a home.
The December 20, 2010 airing of "Democracy Now!" featured a segment titled "Naomi Wolf vs. Jaclyn Friedman: Feminists Debate the Sexual Allegations Against Julian Assange" in which Jaclyn Friedman argues the sexual assault allegations against WikiLeaks founder Julian Assange shouldn't be dismissed just because they may be politically motivated. Wolf argues that the alleged victims should have said no, that they consented to having sex with Assange, that the charges are politically motivated and demean the cause of legitimate rape victims. The discussion took place shortly after the leaking of the Swedish police report on the incident.
Alleged sexual encroachment incident at Yale.
In 2004, a year before her divorce, Wolf wrote an article for "New York" magazine accusing literary scholar Harold Bloom of a "sexual encroachment" more than two decades earlier by touching her thigh. She said that what she alleged Bloom did was not harassment, either legally or emotionally, and she did not think herself a "victim", but that she had harbored this secret for 21 years. Explaining why she had finally gone public with the charges, Wolf wrote, "I began, nearly a year ago, to try—privately—to start a conversation with my alma mater that would reassure me that steps had been taken in the ensuing years to ensure that unwanted sexual advances of this sort weren't still occurring. I expected Yale to be responsive. After nine months and many calls and e-mails, I was shocked to conclude that the atmosphere of collusion that had helped to keep me quiet twenty years ago was still intact—as secretive as a Masonic lodge."
Reflecting on Yale University's sexual harassment guidelines, Wolf wrote, "Sexual encroachment in an educational context or a workplace is, most seriously, a corruption of meritocracy; it is in this sense parallel to bribery. I was not traumatized personally, but my educational experience was corrupted. If we rephrase sexual transgression in school and work as a civil-rights and civil-society issue, everything becomes less emotional, less personal. If we see this as a systemic corruption issue, then when people bring allegations, the focus will be on whether the institution has been damaged in its larger mission."
In Slate.com, Meghan O'Rourke wrote that Wolf generalized about sexual assault at Yale on the basis of her personal experience. Moreover, O'Rourke noted that, despite Wolf's assertion that sexual assault existed at Yale, she did not interview any Yale students for her story. In addition, O'Rourke wrote, "She jumps through verbal hoops to make it clear she was not 'personally traumatized,' yet she spends paragraphs describing the incident in precisely those terms." Criticizing her "gaps and imprecision," O'Rourke concluded that Wolf's claim that no viable mechanism existed at Yale to prevent and prosecute sexual harassment was "deeply flawed."
Separately, a formal complaint was filed with the U.S. Department of Education Office for Civil Rights on March 15, 2011, by 16 current and former Yale students—12 female and 4 male—describing a sexually hostile environment at Yale. A federal investigation of Yale University began in March 2011 in response to the complaints. "Wolf said on CBS's "The Early Show": 'Yale has been systematically covering up much more serious crimes than the ones that can be easily identified. What they do is that they use the sexual harassment grievance procedure in a very cynical way, purporting to be supporting victims, but actually using a process to stonewall victims, to isolate them, and to protect the university'", as quoted in the "Daily Mail". Yale settled the Federal complaint in June 2012, acknowledging "inadequacies" but not "facing disciplinary action with the understanding that it keeps in place policy changes instituted after the complaint was filed. The school must report on its progress to the Office of Civil Rights until May 2014."
Political consultant.
Wolf was involved in Bill Clinton's 1996 re-election bid, brainstorming with the president's team about ways to reach female voters. During Al Gore's unsuccessful bid for the presidency in the 2000 election, Wolf was hired as a consultant to target female voters, reprising her role in the Clinton campaign. Wolf's ideas and participation in the Gore campaign generated considerable media coverage and criticism. According to a report by Michael Duffy in "Time", Wolf was paid a monthly salary of $15,000 "in exchange for advice on everything from how to win the women's vote to shirt-and-tie combinations." This article was the original source of the widely reported assertion that Wolf was responsible for Gore's "three-buttoned, earth-toned look."
In an interview with Melinda Henneberger in "The New York Times", Wolf denied ever advising Gore on his wardrobe. Wolf herself said she mentioned the term "alpha male" only once in passing and that "[it] was just a truism, something the pundits had been saying for months, that the vice president is in a supportive role and the President is in an initiatory role... I used those terms as shorthand in talking about the difference in their job descriptions".
Occupy Wall Street.
On October 18, 2011, Wolf was arrested in New York during the Occupy Wall Street protests, and spent about half an hour in a cell. Speaking about her arrest, Wolf said, "I was taken into custody for disobeying an unlawful order. The issue is that I actually know New York City permit law ... I didn’t choose to get myself arrested. I chose to obey the law and that didn’t protect me."
A month later, Wolf wrote an article which argued that attacks on the Occupy movement were a coordinated plot, orchestrated by federal law enforcement agencies and implemented by American mayors. She alleged that "congressional overseers, with the blessing of the White House, told the DHS to authorise mayors to order their police forces—pumped up with millions of dollars of hardware and training from the DHS—to make war on peaceful citizens." The response to this article ranged from praise to criticism of Wolf for being overly speculative and creating a "conspiracy theory". Wolf responded that there is ample evidence for her argument, and proceeded to review the information available to her at the time of the article, and what she alleged was new evidence since that time. In response, Joshua Holland, an editor at AlterNet, accused her of "many misstatements of fact, logical leaps and baseless assertions" and also a "reckless disregard of the available facts, a tendency toward inaccuracy...". Rejecting her criticism of his previous analysis in which he wrote: "The headline of the piece is 'The Shocking truth about the crackdown on Occupy,' but there is nothing truthful about what follows", he also claimed that Wolf "offers...a theory with no factual basis". Holland further stated that "my criticism of Wolf's piece was based on the many inaccuracies in her writing...". Another critic, Imani Gandy of Balloon Juice, wrote that "nothing substantiates Wolf's claims", that "Wolf's article has no factual basis whatsoever and is, therefore, a journalistic failure of the highest order" and that "it was incumbent upon (Wolf) to fully research her claims and to provide facts to back them up." Corey Robin, a political theorist, journalist, and associate professor of political science at Brooklyn College and the Graduate Center of the City University of New York, stated on his blog: "The reason Wolf gets her facts wrong is that she's got her theory wrong." 
In early 2012, WikiLeaks began publishing the Global Intelligence Files, a trove of e-mails obtained via a hack by Anonymous and Jeremy Hammond. Among them was an email with an official Department of Homeland Security It indicated that DHS was closely watching Occupy, and concluded, "While the peaceful nature of the protests has served so far to mitigate their impact, larger numbers and support from groups such as Anonymous substantially increase the risk for potential incidents and enhance the potential security risk to critical infrastructure." In late December 2012, FBI documents released following an FOIA request from the Partnership for Civil Justice revealed that the FBI used counterterrorism agents and other resources to extensively monitor the national Occupy movement. The documents contained no references to agency personnel covertly infiltrating Occupy branches, but did indicate that the FBI gathered information from police departments and other law enforcement agencies relating to planned protests. Additionally, the blog Techdirt reported that the documents disclosed a plot by unnamed parties "to murder OWS leadership in Texas" but that "the FBI never bothered to inform the targets of the threats against their lives."
In a December 2012 article for "The Guardian" Wolf wrote:
 "It was more sophisticated than we had imagined: new documents show that the violent crackdown on Occupy last fall [2011]—so mystifying at the time—was not just coordinated at the level of the FBI, the Department of Homeland Security, and local police. The crackdown, which involved, as you may recall, violent arrests, group disruption, canister missiles to the skulls of protesters, people held in handcuffs so tight they were injured, people held in bondage till they were forced to wet or soil themselves—was coordinated with the big banks themselves."
"How simple … just to label an entity a 'terrorist organization' and choke off, disrupt or indict its sources of financing."
"[The FBI crackdown on Occupy] was never really about 'the terrorists'. It was not even about civil unrest. It was always about this moment, when vast crimes might be uncovered by citizens—it was always, that is to say, meant to be about you."
According to "Mother Jones", none of the documents revealed efforts by federal law enforcement agencies to disband the Occupy camps or provided much evidence that federal officials attempted to suppress protesters' free speech rights. It was, said "Mother Jones", "a far cry from Wolf's contention"
Controversies over alleged conspiracy theories.
2013.
Writing in "The Atlantic" in January 2013, law and business professor Mark Nuckols declared, "In her various books, articles, and public speeches, Wolf has demonstrated recurring disregard for the historical record and consistently mutilated the truth with selective and ultimately deceptive use of her sources. All of this might have little real-world import when she writes about her orgasms or her weight problems. But when she distorts facts to advance her political agenda, she dishonors the victims of history and poisons present-day public discourse about issues of vital importance to a free society." In particular, Nuckols argued, "Naomi Wolf has for many years now been claiming that a fascist coup in America is imminent. Most recently in "The Guardian" she alleged, with no substantiation, that the U.S. government and big American banks are conspiring to impose a 'totally integrated corporate-state repression of dissent.'"
In June 2013, "New York" magazine reported that in a recent Facebook post, Wolf had expressed her "creeping concern" that NSA leaker Edward Snowden "is not who he purports to be, and that the motivations involved in the story may be more complex than they appear to be." Wolf was similarly skeptical of Snowden's "very pretty pole-dancing Facebooking girlfriend who appeared for, well, no reason in the media coverage … and who keeps leaking commentary, so her picture can be recycled in the press." Wolf responded at her website, "I do find a great deal of media/blog discussion about serious questions such as those I raised, questions that relate to querying some sources of news stories, and their potential relationship to intelligence agencies or to other agendas that may not coincide with the overt narrative, to be extraordinarily ill-informed and naive." Specifically regarding Snowden, she wrote, "Why should it be seen as bizarre to wonder, if there are some potential red flags—the key term is 'wonder'—if a former NSA spy turned apparent whistleblower might possibly still be—working for the same people he was working for before?"
2014.
In October 2014, Wolf again aroused controversy, with a series of Facebook posts questioning the authenticity of videos that purported to show beheadings of two Americans and two Britons by the Islamic State, implying that they had been staged by the U.S. government and that the victims and their parents were actors. Wolf also charged that the U.S. was dispatching troops not to assist in treating the Ebola virus epidemic in West Africa but to carry the disease back home to justify a military takeover of America. She further said that the Scottish independence referendum, in which Scots voted to remain in the United Kingdom, was faked. Speaking about this at a demonstration in Glasgow on October 12, Wolf said, "I truly believe it was rigged." "Vox" journalist Max Fisher urged Wolf's readers "to understand the distinction between her earlier work, which rose on its merits, and her newer conspiracy theories, which are unhinged, damaging, and dangerous." Charles C. W. Cooke observed at the "National Review Online", "Over the last eight years, Naomi Wolf has written hysterically about coups and about vaginas and about little else besides. She has repeatedly insisted that the country is on the verge of martial law, and transmogrified every threat—both pronounced and overhyped—into a government-led plot to establish a dictatorship. She has made prediction after prediction that has simply not come to pass. Hers are not sober and sensible forecasts of runaway human nature, institutional atrophy, and constitutional decline, but psychedelic fever-dreams that are more typically suited to the InfoWars crowd." Under the headline "Naomi Wolf Went Off the Deep End Long Ago," "The American Spectator" advised, "Her words must be taken not just with a grain of salt, but a full shaker's worth."
Responding to such criticism, Wolf said, "All the people who are attacking me right now for 'conspiracy theories' have no idea what they are talking about … people who assume the dominant narrative MUST BE TRUE and the dominant reasons MUST BE REAL are not experienced in how that world works." To her nearly 100,000 Facebook followers, Wolf maintained, "I stand by what I wrote." However, in a follow-up Facebook post two days later, Wolf back-pedaled. "I am not asserting that the ISIS videos have been staged," she wrote. "I certainly sincerely apologize if one of my posts was insensitively worded. I have taken that one down. … I am not saying the ISIS beheading videos are not authentic. I am not saying they are not records of terrible atrocities. I am saying that they are not yet independently confirmed by two sources as authentic, which any Journalism School teaches, and the single source for several of them, SITE, which received half a million dollars in government funding in 2004, and which is the only source cited for several, has conflicts of interest that should be disclosed to readers of news outlets." Wolf did not say how it was possible to independently verify the ISIS videos released by SITE.

</doc>
<doc id="21637" url="http://en.wikipedia.org/wiki?curid=21637" title="New Year">
New Year

New Year is the time at which a new calendar year begins and the calendar's year count increments by one. Many cultures celebrate the event in some manner. The New Year of the Gregorian calendar, today mostly in use, falls on from 1 January (New Year's Day) to 31 December (New Year's Eve), as was the case both in the old Roman calendar (at least after about 713 BCE) and in the Julian calendar that succeeded it. The order of months was January to December in the Old Roman calendar during the reign of King Numa Pompilius in about 700 BCE, according to Plutarch and Macrobius, and has been in continuous use since that time. Many countries, such as the Czech Republic, Italy, Spain, the UK, and the United States, mark 1 January is a national holiday.
During the Middle Ages in western Europe, while the Julian calendar was still in use,authorities moved New Year's Day variously, depending upon locale, to one of several other days, among them: 1 March, 25 March, Easter, 1 September, and 25 December. These New Year's Day changes generally reverted to using January 1 before or during the various local adoptions of the Gregorian calendar, beginning in 1582. The change from March 25 – Lady Day, one of the four quarter days – to January 1 took place in Scotland in 1600, before the ascension of James VI of Scotland to the throne of England in 1603 and well before the formation of the Kingdom of Great Britain in 1707. In England and Wales (and in all British dominions, including Britain's American colonies), 1751 began on March 25 and lasted 282 days, and 1752 began on January 1. For more information about the changeover from the Julian calendar to the Gregorian calendar and the effect on the dating of historical events etc., see Old Style and New Style dates.
A great many other calendars have seen use historically in different parts of the world; some such calendars count years numerically, while others do not. The expansion of Western culture during recent centuries has seen such widespread official adoption of the Gregorian calendar that its recognition and that of January 1 as the New Year has become virtually global. (Note for example the New Year celebrations held in Dubai to mark the start of 2014, which broke the world record for the most fireworks set off in a single display,
lasting for six minutes and including the use of over 500,000 fireworks.)
Nevertheless, regional or local use of other calendars persists, along with the cultural and religious practices that accompany them. Many places (such as Israel, China, and India) also celebrate New Year at the times determined by these other calendars. In Latin America the observation of traditions belonging to various native cultures continues according to their own calendars, despite the domination of recently arrived cultures. The most common dates of modern New Year's celebrations are listed below, ordered and grouped by their alignment relative to the Gregorian calendar.
By month or season.
Mid-April (Northern spring).
The new year of many South and Southeast Asian calendars falls between 13 and 15 April, marking the beginning of spring.
Christian liturgical year.
The early development of the Christian liturgical year coincided with the Roman Empire (east and west), and later the Byzantine Empire, both of which employed a taxation system labeled the Indiction, the years for which began on September 1. This timing may account for the ancient church's establishment of September 1 as the beginning of the liturgical year, despite the official Roman New Year's Day of January 1 in the Julian calendar, because the indiction was the principal means for counting years in the empires, apart from the reigns of the Emperors. The September 1 date prevailed throughout all of Christendom for many centuries, until subsequent divisions eventually produced revisions in some places.
After the sack of Rome in 410, communications and travel between east and west deteriorated. Liturgical developments in Rome and Constantinople did not always match, although a rigid adherence to form was never mandated in the church. Nevertheless, the principal points of development were maintained between east and west. The Roman and Constantinopolitan liturgical calendars remained compatible even after the East-West Schism in 1054. Separations between the Roman Catholic ecclesiastical year and Eastern Orthodox liturgical calendar grew only over several centuries' time.
During those intervening centuries, the Roman Catholic ecclesiastic year was moved to the first day of Advent, the Sunday nearest to St. Andrew's Day (30 November). According to the Latin Rite of the Catholic Church, the liturgical year begins at 4:00 pm on the Saturday preceding the fourth Sunday prior to 25 December (between November 26 and December 2). By the time of the Reformation (early 16th century), the Roman Catholic general calendar provided the initial basis for the calendars for the liturgically-oriented Protestants, including the Anglican and Lutheran Churches, who inherited this observation of the liturgical new year.
The present-day Eastern Orthodox liturgical calendar is the virtual culmination of the ancient eastern development cycle, though it includes later additions based on subsequent history and lives of saints. It still begins on 1 September, proceeding annually into the Nativity of the Theotokos (8 September) and Exaltation of the Cross (14 September) to the celebration of Nativity of Christ (Christmas), through his death and resurrection (Pascha / Easter), to his Ascension and the Dormition of the Theotokos ("falling asleep" of the Virgin Mary, 15 August). (This last feast is known in the Roman Catholic church as the Assumption.) The dating of "1 September" is according to the "new" (revised) Julian calendar or the "old" (standard) Julian calendar, depending on which is used by a particular Orthodox Church. Hence, it may fall on 1 September on the civil calendar, or on 14 September (between 1900 and 2099 inclusive).
The present-day Coptic Orthodox liturgical calendar reflects the same fundamental ancient structures, even though its early break from Eastern Orthodoxy in 452 shows evidence of a separate development. The Coptic calendar is based on the ancient Egyptian calendar, which Emperor Augustus reformed in 25 BC to keep it forever in synch with the Julian calendar, but it is not identical to the Julian calendar. The Coptic liturgical new year, at the feast of Neyrouz, synchronized with the Julian September 1 at a different point from the Gregorian calendar, has therefore a different degree of separation today. Between 1900 and 2099, Neyrouz occurs on 11 September (Gregorian), with the exception of the year before Gregorian leap years, when it occurs on 12 September. (The Coptic year 1731 began in September 2013.) The Ethiopian Orthodox new year, Enkutatash, falls on the same date as Neyrouz. The Ethiopian calendar year 2006 began on 11 September 2013.
Historical European new year dates.
During the Roman Republic and the Roman Empire years began on the date on which each consul first entered office. This was probably 1 May before 222 BC, 15 March from 222 BC to 154 BC, and 1 January from 153 BC. In 45 BC, when Julius Caesar's new Julian calendar took effect, the Senate fixed 1 January as the first day of the year. At that time, this was the date on which those who were to hold civil office assumed their official position, and it was also the traditional annual date for the convening of the Roman Senate. This civil new year remained in effect throughout the Roman Empire, east and west, during its lifetime and well after, wherever the Julian calendar continued in use.
In England, the Angle, Saxon, and Viking invasions of the fifth through tenth centuries plunged the region back into pre-history for a time. While the reintroduction of Christianity brought the Julian calendar with it, its use was primarily in the service of the church to begin with. After William the Conqueror became king in 1066, he ordered that 1 January be re-established as the civil New Year. Later, however, England and Scotland joined much of Europe to celebrate the New Year on 25 March.
In the Middle Ages in Europe a number of significant feast days in the ecclesiastical calendar of the Roman Catholic Church came to be used as the beginning of the Julian year:
In 1582, Pope Gregory XIII while reforming the Julian calendar established 1 January as the beginning of a New Year of the Gregorian calendar.
Southward equinox day (usually 22 September) was "New Year's Day" in the French Republican Calendar, which was in use from 1793 to 1805. This was "primidi Vendémiaire", the first day of the first month.
Current readoptions of January 1.
It took quite a long time before 1 January again became the universal or standard start of the civil year. The years of adoption of 1 January as the new year are as follows:
1 March was the first day of the numbered year in the Republic of Venice until its destruction in 1797, and in Russia from 988 until 1492 (Anno Mundi 7000 in the Byzantine calendar). 1 September was used in Russia from 1492 (A.M. 7000) until the adoption of the Christian era in 1700 via a December 1699 decree of Tsar Peter I.
Time zones.
Because of the division of the globe into time zones, the new year moves progressively around the globe as the start of the day ushers in the New Year. The first time zone to usher in the New Year, just west of the International Date Line, is located in the Line Islands, a part of the nation of Kiribati, and has a time zone 14 hours ahead of UTC. All other time zones are 1 to 25 hours behind, most in the previous day (31 December); on American Samoa and Midway, it is still 11 PM on 30 December. These are among the last inhabited places to observe New Year. However, uninhabited outlying U.S. territories Howland Island and Baker Island are designated as lying within the time zone 12 hours behind UTC, the last places on earth to see the arrival of 1 January. These small coral islands are found about midway between Hawaii and Australia, about 1,000 miles west of the Line Islands! This is because the International Date Line is a composite of local time zone arrangements, which winds through the Pacific Ocean, allowing each locale to remain most closely connected in time with the nearest or largest or most convenient political and economic locales with which each associates. By the time Howland island sees the new year, it is 2 AM on 2 January in the Line Islands of Kiribati.

</doc>
<doc id="21638" url="http://en.wikipedia.org/wiki?curid=21638" title="Northern Territory">
Northern Territory

Northern Territory (abbreviated as NT) is a federal Australian territory in the centre and central northern regions. It shares borders with Western Australia to the west (129th meridian east), South Australia to the south (26th parallel south), and Queensland to the east (138th meridian east).
To the north, the territory is bordered by the Timor Sea, the Arafura Sea and the Gulf of Carpentaria. Despite its large area—over 1349129 km2, making it the third largest Australian federal division—it is sparsely populated. With a population of 233,300 it is the least populous of Australia's eight major states and territories, having fewer than half as many people as Tasmania.
The archaeological history of the Northern Territory begins over 40,000 years ago when Indigenous Australians settled the region. Makassan traders began trading with the indigenous people of the Northern Territory for trepang from at least the 18th century onwards, and very likely for 300 years prior to that.
The coast of the territory was first seen by Europeans in the 17th century. The British were the first Europeans to attempt to settle the coastal regions. After three failed attempts to establish a settlement (1824-1828, 1838-1849 and 1864-66), success was achieved in 1869 with the establishment of a settlement at Port Darwin. Today the economy is based on tourism, especially Kakadu National Park in the Top End and the Uluru-Kata Tjuta National Park (Ayers Rock) in central Australia, and mining.
The capital city is Darwin. The population is not concentrated in coastal regions but rather along the Stuart Highway. The other major settlements are (in order of size) Palmerston, Alice Springs, Katherine, Nhulunbuy, and Tennant Creek.
Residents of the Northern Territory are often known simply as 'Territorians' and fully as 'Northern Territorians', or more informally as 'Top Enders' and 'Centralians'.
History.
Indigenous Australians have lived in the present area of the Northern Territory for an estimated 40,000 years, and extensive seasonal trade links existed between them and the peoples of what is now Indonesia for at least five centuries.
With the coming of the British, there were four early attempts to settle the harsh environment of the northern coast, of which three failed in starvation and despair. The Northern Territory was part of colonial New South Wales from 1825 to 1863, except for a brief time from February to December 1846, when it was part of the short lived colony of North Australia. It was part of South Australia from 1863 to 1911. Under the administration of colonial South Australia, the overland telegraph was constructed between 1870 and 1872.
A railway was also built between Palmerston and Pine Creek between 1883 and 1889. The economic pattern of cattle raising and mining was established so that by 1911 there were 513,000 cattle. Victoria River Downs was at one time the largest cattle station in the world. Gold was found at Grove Hill in 1872 and at Pine Creek, Brocks Creek, Burrundi, and copper was found at Daly River.
On 1 January 1911, a decade after federation, the Northern Territory was separated from South Australia and transferred to Commonwealth control. Alfred Deakin opined at this time "To me the question has been not so much commercial as national, first, second, third and last. Either we must accomplish the peopling of the northern territory or submit to its transfer to some other nation."
In late 1912 there was growing sentiment that the name "Northern Territory" was unsatisfactory. The names "Kingsland" (after King George V and to correspond with Queensland), "Centralia" and "Territoria" were proposed with Kingsland becoming the preferred choice in 1913. However, the name change never went ahead.
For a brief time between 1927 and 1931 the Northern Territory was divided into North Australia and Central Australia at the 20th parallel of South latitude. Soon after this time, parts of the Northern Territory were considered in the Kimberley Plan as a possible site for the establishment of a Jewish Homeland, understandably considered the "Unpromised Land".
During World War II, most of the Top End was placed under military government. This is the only time since Federation that part of an Australian state or territory has been under military control. After the war, control for the entire area was handed back to the Commonwealth.
Indigenous Australians had struggled for rights to fair wages and land. An important event in this struggle was the strike and walk off by the Gurindji people at Wave Hill Cattle Station in 1966. The Commonwealth Government of Gough Whitlam set up the Woodward Royal Commission in February 1973, which set to enquire into how land rights might be achieved in the Northern Territory. Justice Woodward's first report in July 1973 recommended that a Central Land Council and a Northern Land Council be established to present to him the views of Aboriginal people. In response to the report of the Royal Commission a Land Rights Bill was drafted, but the Whitlam Government was dismissed before it was passed.
The Aboriginal Land Rights (Northern Territory) Act 1976 was eventually passed by the Fraser Government on 16 December 1976 and began operation on the following Australia Day (26 January 1977).
In 1978 the Territory was granted responsible government, with a Legislative Assembly headed by a Chief Minister. The Administrator of the Northern Territory is an official acting as the Queen's "indirect" representative in the Territory.
During 1995–6 the Northern Territory was briefly one of the few places in the world with legal voluntary euthanasia, until the Federal Parliament overturned the legislation.
Before the over-riding legislation was enacted, three people committed suicide through voluntary euthanasia, a practice orchestrated by Dr. Philip Nitschke.
Geography.
There are many very small settlements scattered across the territory, but the larger population centres are located on the single paved road that links Darwin to southern Australia, the Stuart Highway, known to locals simply as "the track".
The Northern Territory is also home to two spectacular natural rock formations, Uluru (Ayers Rock) and Kata Tjuta (The Olgas), which are sacred to the local Aboriginal peoples and which have become major tourist attractions.
In the northern part of the territory lies Kakadu National Park, which features breathtaking wetlands and native wildlife. To the north of that lies the Arafura Sea, and to the east lies Arnhem Land, whose regional centre is Maningrida on the Liverpool River delta.
There is an extensive series of river systems in the Northern Territory. These rivers include: the Alligator Rivers, Daly River, Finke River, McArthur River, Roper River, Todd River and Victoria River.
Climate.
The Northern Territory has two distinctive climate zones.
The northern end, including Darwin, has a tropical climate with high humidity and two seasons, the wet (October to April) and dry season (May to September). During the dry season nearly every day is warm and sunny, and afternoon humidity averages around 30%. There is very little rainfall between May and September. In the coolest months of June and July, the daily minimum temperature may dip as low as 14 °C, but very rarely lower, and frost has never been recorded.
The wet season is associated with tropical cyclones and monsoon rains. The majority of rainfall occurs between December and March (the southern hemisphere summer), when thunderstorms are common and afternoon relative humidity averages over 70% during the wettest months. On average more than 1570 mm of rain falls in the north. Rainfall is highest in north-west coastal areas, where rainfall averages from 1,800–2,100mm (72–84 in).
The central region is the desert centre of the country, which includes Alice Springs and Ayers Rock, and is semi-arid with little rain usually falling during the hottest months from October to March. Central Australia receives less than 250 mm of rain per year.
The highest temperature recorded in the territory was 48.3 °C at Finke on 1 and 2 January 1960. The lowest temperature was -7.5 °C at Alice Springs on 12 July 1976.
Governance.
Parliament.
The Northern Territory Parliament is one of the three unicameral parliaments in the country. Based on the Westminster System, it consists of the Northern Territory Legislative Assembly which was created in 1974, replacing the Northern Territory Legislative Council.
The Northern Territory Legislative Council was the partly elected governing body from 1947 until its replacement by the fully elected Northern Territory Legislative Assembly in 1974. The total enrolment for the 1947 election was 4,443, all of whom were white. The Northern Territory was split into five electorates: Darwin, Alice Springs, Tennant Creek, Batchelor, and Stuart.
Whilst this assembly exercises similar powers as the governments of the states of Australia, it does so by legislated delegation of powers from the Commonwealth Government, rather than by any constitutional right. The Monarch is represented by the Administrator of the Northern Territory which is similar to that of state governors.
Twenty-five members of the Legislative Assembly are elected to four-year terms from single-member electorates.
For several years there has been agitation for full statehood. A referendum was held on the issue in 1998, which resulted in a 'no' vote. This was a shock to both the Northern Territory and Commonwealth governments, for opinion polls showed most Territorians supported statehood. However, under the Australian Constitution, the Federal Government may set the terms of entry to full statehood. The Northern Territory was offered three Senators, rather than the twelve guaranteed to original states. (Because of the difference in populations, equal numbers of Senate seats would mean a Territorian's vote for a Senator would have been worth more than 30 votes in New South Wales or Victoria.) Alongside what was cited as an arrogant approach adopted by then Chief Minister Shane Stone, it is believed that most Territorians, regardless of their general views on statehood, were reluctant to adopt the particular offer that was made.
Chief Minister and Cabinet.
The Chief Minister of the Northern Territory is the head of government of a self-governing territory, while the head of government of a state is a Premier. The Chief Minister is appointed by the Administrator of the Northern Territory, who in normal circumstances will appoint the leader of whichever party holds the majority of seats in the Northern Territory Legislative Assembly. The current Chief Minister of the Northern Territory is Adam Giles of the Country Liberal Party, who replaced Terry Mills on 14 March 2013. The Leader of the Opposition is Delia Lawrie of the Australian Labor Party.
Administrator.
The Northern Territory received self-government on 1 July 1978 under its own Administrator of the Northern Territory appointed by the Governor-General of Australia. The Commonwealth government, not the Government of the Northern Territory, advises the governor-general on appointment of the Administrator, but by convention, consults first with the Territory Government. The current Administrator is John Hardy.
Federal government.
The Northern Territory is represented in the Commonwealth parliament by two Members in the House of Representatives, currently Warren Snowdon from the Australian Labor Party (ALP) and Natasha Griggs from the Country Liberal Party (CLP), and two members in the Senate, currently Nova Peris for the ALP and Nigel Scullion for the CLP.
Local government.
The Northern Territory is divided into 17 local government areas, including 11 shires and five municipalities. Shire, city and town councils are responsible for functions delegated by the Northern Territory parliament, such as road infrastructure and waste management. Council revenue comes mostly from property taxes and government grants.
Aboriginal land councils.
Aboriginal land councils in the Northern Territory are groups of Aboriginal landowners, set up under the Aboriginal Land Rights Act.
Demographics.
The population of the Northern Territory at the 2011 Australian census was 211,945, a 10 per cent increase from the 2006 census. The Australian Bureau of Statistics estimated a resident population of 233,300 in March 2012, taking into account residents overseas or interstate. The Territory's population represents 1% of the total population of Australia.
The Northern Territory's population is the youngest in Australia and has the largest proportion (23.2%) under 15 years of age and the smallest proportion (5.7%) aged 65 and over. The median age of residents of the Northern Territory is 31 years, six years younger than the national median age.
More than 100 nationalities are represented in the Northern Territory's population, including more than 50 organisations representing different ethnic groups.
The 2006 Census revealed that of the Northern Territory's population, 68.4% is of European descent. 64,491 (30.6%) English with 44,662 (20.2%), Irish with 14,346 (6.8%), Scottish with 11,759 (5.6%), German with 7,729 (3.7%) and Italian with 3,308 (1.5%). Indigenous Australian people make up 32.5% of the Northern Territory's population, while Chinese people with 4,081 make up (1.9%).
Indigenous Australians own some 49% of the land. The life expectancy of Aboriginal Australians is well below that of non-Indigenous Australians in the Northern Territory, a fact that is mirrored elsewhere in Australia. ABS statistics suggest that Indigenous Australians die about 11 years earlier than the average Australian. There are Aboriginal communities in many parts of the territory, the largest ones being the Pitjantjatjara near Uluru, the Arrernte near Alice Springs, the Luritja between those two, the Warlpiri further north, and the Yolngu in eastern Arnhem Land.
In terms of birthplace, according to the 2011 census 25.4% of the population were born overseas. 2.5% of Territorians were born in England, 1.9% in New Zealand, 1.7% in Philippines, 0.9% in India and 0.5% in the United States.
More than 54% of Territorians live in Darwin, located in the territory's north (Top End). Less than half of the territory's population live in the rural Northern Territory.
Religion.
In the 2006 census, 54.6% of Territorians described themselves as Christian. Roman Catholics form the single largest religious group in the territory with 21.1% of the Northern Territory's population, followed by Anglican (12.3%), Uniting Church (7%) and Lutheran (3.6%). Buddhism is the territory's largest non-Christian religion (1.4%), followed by Islam (0.5%) and Hinduism (0.2%). Around 23% of Territorians do not profess any religion.
Education.
Primary and secondary.
A Northern Territory school education consists of six years of primary schooling, including one transition year, three years of middle schooling, and three years of secondary schooling. In the beginning of 2007, the Northern Territory introduced Middle School for Years 7–9 and High School for Years 10–12. Northern Territory children generally begin school at age five. On completing secondary school, students earn the Northern Territory Certificate of Education (NTCE). Students who successfully complete their secondary education also receive a tertiary entrance ranking, or ENTER score, to determine university admittance. An International Baccalaureate is offered at one school in the Territory – Kormilda College.
Northern Territory schools are either publicly or privately funded. Public schools, also known as state or government schools, are funded and run directly by the Department of Education. Private fee-paying schools include schools run by the Catholic Church and independent schools, some elite ones similar to English public schools. Some Northern Territory Independent schools are affiliated with Protestant, Lutheran, Anglican, Greek Orthodox or Seventh-day Adventist churches, but include non-church schools and an Indigenous school.
As of 2009, the Northern Territory had 151 public schools, 15 Catholic schools and 21 independent schools. 39,492 students were enrolled in schools around the Territory with 29,175 in public schools, and 9,882 in independent schools. The Northern Territory has about 4,000 full-time teachers.
Tertiary.
The Northern Territory has one university. Northern Territory University (now called Charles Darwin University) opened in 1989. Charles Darwin University had about 19,000 students enrolled: about 5500 higher education students and about 13500 students on vocational education and training (VET) courses. The first tertiary institution in the territory was the Batchelor Institute of Indigenous Tertiary Education (established in mid-1960s).
Libraries.
The Northern Territory Library is the Territory's research and reference library. It is responsible for collecting and preserving the Northern Territory documentary heritage and making it available through a range of programs and services. Material in the collection includes books, newspapers, magazines, journals, manuscripts, maps, pictures, objects, sound and video recordings and databases.
Economy.
The Northern Territory's economy is largely driven by mining, which is concentrated on energy producing minerals, petroleum and energy and contributes around $2.5 billion to the gross state product and employs over 4,600 people. Mining accounts for 26 per cent of the gross state product in 2006–2007 compared to just 7 per cent nationally.
The economy has continued to grow during the 2005–2006 financial year from the past two financial years. Between 2003 and 2006 the gross state product had risen from $8,670 million to $11,476 million and increase of 32.4 per cent. During the three years to 2006–2007 the Northern Territory gross state product grew by an average annual rate of 5.5 per cent. Gross state product per capita in the Northern Territory ($72,496) is higher than any Australian state or territory, and is also higher than the gross domestic product per capita for Australia ($54,606). This can be attributed to the recent mining and resources boom.
The Northern Territory's exports were up 19 per cent during 2005–2006. The largest contributor to the territory's exports was: petroleum and natural gas (33.4%), metal ores and concentrates (20.0%), other manufacturing (5.9 per cent) and agriculture (4.9%). Imports to the Northern Territory totalled $2,887.8 million which consisted of mainly machinery and equipment manufacturing (58.4%) and petroleum, coal, chemical and associated product manufacturing (17.0%).
The principal mining operations are bauxite at Gove Peninsula where the production is estimated to increase 52.1% to $254 million in 2007–08, manganese at Groote Eylandt, production is estimated to increase 10.5% to $1.1 billion which will be helped by the newly developed mines include Bootu Creek and Frances Creek, gold which is estimated to increase 21.7 per cent to $672 million at the Union Reefs plant and uranium at Ranger Uranium Mine.
Tourism is one of the major industries on the Northern Territory. Iconic destinations such as Uluru and Kakadu make the Northern Territory a popular destination for domestic and international travellers. Diverse landscapes, waterfalls, wide open spaces, aboriginal culture, wild and untamed wildlife, all create a unique opportunity for the visitor to immerse themselves in the natural wonder that the Northern Territory offers. In 2005–06, 1.38 million people visited the Northern Territory. They stayed for 9.2 million nights and spent over $1.5 billion.
The territory is promoted with the slogan "You'll Never Never Know if You Never Never Go". This was implemented as a result of the Kennedy Review in 1992.
Transport.
The Northern Territory is the most sparsely populated state or territory in Australia. From its establishment in 1869 the Port of Darwin was the major Territory supply for many decades. It was damaged in the 1942 Japanese air raids and subsequently restored. In the late 1960s improved roads in adjoining States linking with the Territory, port delays and rapid economic development led to uncertainty in port and regional infrastructure development. As a result of the Commission of Enquiry established by the Administrator, port working arrangements were changed, berth investment deferred and a port masterplan prepared. Extension of rail transport was then not considered because of low freight volumes.
Despite its sparse population there is a network of sealed roads, including two National Highways, linking with adjoining States and connecting the major Territory population centres, and some other centres such as Uluru (Ayers Rock), Kakadu and Litchfield National Parks. The Stuart Highway, known as "The Track", runs north to south, connecting Darwin and Alice Springs to Adelaide. Some of the sealed roads are single lane bitumen. Many unsealed (dirt) roads connect the more remote settlements.
The Adelaide–Darwin railway, a new standard gauge railway, connects Adelaide via Alice Springs with Darwin, replacing earlier narrow gauge railways which had a gap between Alice Springs and Birdum.
The Northern Territory is one of the few remaining places in the world with no speed restrictions on public roads. On 1 January 2007 a default speed limit of 110 km/h was introduced on roads outside of urban areas (Inside urban areas of 40, 50 or 60 km/h). Speeds of up to 130 km/h are permitted on some major highways, such as the Stuart Highway. On 1 February 2014, the speed limit was removed on a 204 km portion of the Stuart Highway for a one-year trial period.
Darwin International Airport is the major domestic and international airport for the territory. Several smaller airports are also scattered throughout the Territory and are served by smaller airlines; including Alice Springs Airport, Ayers Rock Airport, Katherine Airport and Tennant Creek Airport.
Media.
Print.
The Northern Territory has only one daily tabloid newspaper, News Corporation's "Northern Territory News"; the "Centralian Advocate" is circulated around the Alice Springs region twice a week. There is a Sunday tabloid newspaper, "The Sunday Territorian". There are also five weekly community newspapers. The Territory receives the national daily, "The Australian", while the "Sydney Morning Herald" and "The Age" are also available in Darwin. Katherine's paper is the "Katherine Times".
Television.
Metropolitan Darwin has had five broadcast television stations:
Darwin also has a single open-narrowcast station:
Regional Northern Territory has a similar availability of stations:
Remote areas are generally required to receive television via the Viewer Access Satellite Television service, which carries the same channels as the regional areas, as well as some extra open-narrowcast services, including Indigenous Community Television, Rural Health Channel and Westlink
Radio.
Darwin has radio stations on both AM and FM frequencies. ABC stations include ABC NewsRadio (102.5FM), 105.7 ABC Darwin (8DDD 105.7FM), ABC Radio National (657AM), ABC Classic FM (107.3FM) and Triple J (103.3FM). The 2 commercial stations are: Mix 104.9 (8MIX), Hot 100 (8HOT)
The leading community stations are 104.1 Territory FM and Radio Larrakia (8KNB).
The radio stations in Alice Springs are also broadcast on the AM and FM frequencies. ABC stations include Triple J (94.9FM), ABC Classic FM (97.9FM), 783 ABC Alice Springs (783AM) and ABC Radio National (99.7FM). There are two community stations in the town--CAAMA (100.5FM) and 8CCC (102.1FM). The commercial stations, which are both owned by the same company are Sun 96.9 (96.9FM) and 8HA (900AM). Two additional stations, Territory FM (98.7FM) and Radio TAB (95.9FM) are syndicated from Darwin and Brisbane respectively.

</doc>
<doc id="21640" url="http://en.wikipedia.org/wiki?curid=21640" title="Low-alcohol beer">
Low-alcohol beer

Low-alcohol beer (also called light beer, non-alcoholic beer, small beer, small ale, or near-beer) is beer with low alcohol content or no alcohol, which aim to reproduce the taste of beer without the inebriating effects of standard alcoholic brews. Most low-alcohol beers are lagers, but there are some low-alcohol ales.
In the United States, beverages containing less than 0.5% alcohol by volume (ABV) were legally called non-alcoholic, according to the now-defunct Volstead Act. Because of its very low alcohol content, non-alcoholic beer may be legally sold to minors in many American states.
In the United Kingdom, the following definitions apply by law (correct as of May 2007):
In some parts of the European Union, beer must contain no more than 0.5% ABV if it is labelled "alcohol-free".
In Australia, the term "light beer" refers to any beer with less than 3% alcohol.
Spain is the main consumer and producer of low-alcohol beer.
History.
Low-alcoholic brews such as small beer date back to at least Medieval Europe, where it served as a less risky alternative to water (which often was polluted by feces and parasites) and less expensive than the full strength brews used at festivities.
In the more modern forms, the temperance movements and general regard of certain tasks like driving being unsuitable when intoxicated led to the development of beers which could be drunk without intoxicating effects.
In the United States, the conceptualization of non-alcohol brews took place during Prohibition according to John Naleszkiewicz. President Wilson had proposed limiting the alcohol content in malt beverages to 2.75% in 1917 in an effort to appease avid prohibitionists. In 1919 Congress approved the Volstead Act, which limited the alcohol content of any beverage to less than 0.5%. These beverages became known as tonics and many breweries began brewing these extremely low alcohol content beverages in order to keep from going out of business during Prohibition. Due to the fact that removing the alcohol from the beer requires the addition of one simple step, many breweries saw this as an easy transition. In 1933, when Prohibition was repealed, removing this single step again was easily done by many breweries.
By the dawn of the 21st century, alcohol-free beer has seen a rise in popularity in the Middle East (which now makes up a third of the market). Part of the reason why it has grown in popularity is that Islamic scholars issued fatwas that permitted the consumption of beer so long as large quantities could be consumed without getting drunk.
Pros and cons.
There are both up sides and down falls to converting traditional brews to non-alcoholic brews. Positive aspects of converting standard brews to non-alcoholic brews include the ability to drive after consuming several drinks, the reduction of kidney/liver damage, and less intense hangover symptoms . Despite these benefits there are also aesthetic downfalls to the beverages. Some common complaints of non-alcoholic brews include a loss of flavor, addition of one step in the brewing process, very sugary taste, and a shorter shelf life. Along with aesthetic shortcomings of non-alcoholic brews, they also raise serious legal implications. Local governments in some states like Pennsylvania prohibit the sale of these non-alcoholic brews to persons under the age of 21. A study conducted by the department of psychology at Indiana University claimed “Because non-alcoholic beer provides sensory cues that simulate alcoholic beer, this beverage may be more effective than other placebos in contributing to a credible manipulation of expectancies to receive alcohol”, making people feel "drunk" when they physically are not.
Categories.
Light (reduced alcohol) beer.
Light beer is beer that is reduced in alcohol content or in calories, compared to regular beer. The spelling "lite beer" is also commonly used.
Light beers may be chosen by beer drinkers who wish to manage their alcohol consumption or their calorie intake. However, these beers are sometimes criticized for being less flavorful than full-strength beers, being "watered down" (whether in perception or in fact), and thus advertising campaigns for light beers generally advertise their retention of flavor.
In Australia, regular beers have approximately 5% ABV; reduced-alcohol beers have 2.2%–3.2%.
In Canada, a reduced-alcohol beer contains 2.6%–4.0% ABV, and an “extra-light” beer contains less than 2.5% ABV.
In the United States, most reduced-alcohol beers, including Bud Light, Coors Light, and Miller Lite have 4.2% ABV. This is a 16% reduction in alcohol compared to beer that has 5% ABV.
In Sweden, low alcohol beer is either 2.8% or 3.5% and can be purchased in a regular supermarket whereas regular strength beers of above 3.5% must be purchased at the Systembolaget
Low-point beer.
Low-point beer, which is often known in America as "three-two beer" or "3 point 2 brew", is beer that contains 3.2% alcohol by weight (equivalent to about 4% ABV).
The term "low-point beer" is unique to the United States, where some states limit the sale of beer, but beers of this type are also available in countries (such as Sweden and Finland) that tax or otherwise regulate beer according to its alcohol content. 
In Sweden, beer containing up to 3.5% ABV (called Folköl or "Peoples Beer") may be legally sold in any convenience store to people over 18 years of age, whereas stronger beer may only be sold in state-run liquor stores to people older than 20. In addition, businesses selling food for on-premises consumption do not need an alcohol license to serve 3.5% beer. Virtually all major Swedish brewers, and several international ones, in addition to their full-strength beer, make 3.5% folköl versions as well.
In the United States, 3.2 beer was the highest alcohol content beer allowed to be produced legally for nine months in 1933. As part of his New Deal, President Franklin D. Roosevelt signed a 3.2 beer law that repealed the Volsted Act on March 22, 1933. In December 1933, the Twenty-first Amendment to the United States Constitution was passed, negating the federal government's power to regulate the sale of alcoholic beverages, though states retained the power to regulate.
After the repeal of Prohibition, a number of state laws prohibiting the sale of intoxicating liquors remained in effect. As these were repealed, they were first replaced by laws limiting the maximum alcohol content allowed for sale as 3.2 ABW. To this day, the states of Colorado, Kansas, Minnesota, Oklahoma, and Utah permit general establishments such as supermarket chains and convenience stores to sell only low-point beer. In these states, all alcoholic beverages containing more than 3.2% alcohol by weight (ABW) must be sold from state-licensed liquor stores. Oklahoma additionally requires that any beverage containing more than 3.2% ABW must be sold at normal room temperature.
Missouri also has a legal classification for low-point beer, which it calls "nonintoxicating beer". Unlike Colorado, Kansas, Minnesota, Oklahoma, and Utah, however, Missouri does not limit supermarket chains and convenience stores to selling only low-point beer. Instead, Missouri's alcohol laws permit grocery stores, drug stores, gas stations, and even "general merchandise stores" (a term that Missouri law does not define) to sell "any" alcoholic beverage; consequently, 3.2% beer is rarely sold in Missouri.
Near beer.
Originally, "near beer" was a term for malt beverages containing little or no alcohol (less than 0.5% ABV), which were mass-marketed during Prohibition in the United States. Near beer could not legally be labeled as "beer" and was officially classified as a "cereal beverage". The public, however, almost universally called it "near beer".
The most popular "near beer" was Bevo, brewed by the Anheuser-Busch company. The Pabst company brewed "Pablo", Miller brewed "Vivo", and Schlitz brewed "Famo". Many local and regional breweries stayed in business by marketing their own near-beers. By 1921 production of near beer had reached over 300 million US gallons (1 billion L) a year (36 L/s).
A popular illegal practice was to add alcohol to near beer. The resulting beverage was known as "spiked beer" or "needle beer", so called because a needle was used to inject alcohol through the cork of the bottle or keg.
Food critic and writer Waverley Root described the common American near beer as "such a wishy-washy, thin, ill-tasting, discouraging sort of slop that it might have been dreamed up by a Puritan Machiavelli with the intent of disgusting drinkers with genuine beer forever."
Today, the term "near beer" has been revived to refer to modern non-alcoholic beer. 
A drink similar to "near beer", "bjórlíki" was quite popular in Iceland before alcoholic beer was made legal in 1989. The Icelandic variant normally consisted of a shot of vodka added to a half-a-litre glass of light beer.
Small beer.
Small beer (also, small ale) is a beer/ale that contains very little alcohol. Sometimes unfiltered and porridge-like, it was a favoured drink in Medieval Europe and colonial North America as opposed to the often polluted water and the expensive beer used for festivities. Small beer was also produced in households for consumption by children and servants at those occasions.
However, small beer/small ale can also refer to a beer made of the "second runnings" from a very strong beer (e.g., scotch ale) mash. These beers can be as strong as a mild ale, depending on the strength of the original mash. (Drake's 24th Anniversary Imperial Small Beer was expected to reach above 9.5% abv.) This was done as an economy measure in household brewing in England up to the 18th century and is still done by some homebrewers. One commercial brewery, San Francisco's Anchor Brewing Company, also produces their "Anchor Small Beer" using the second runnings from their Old Foghorn Barleywine. The term is also used for commercially produced beers which are thought to taste too weak.
Non-alcoholic beer.
Non-alcoholic beer or alcohol free beer contains 0.0% ABV. As such, it is permitted by Islam, and alcohol-free beers such as Holsten, Barbican and Moussy are often available in stores and restaurants that cater to an Islamic customer base. They are also popular in countries that enforce alcohol prohibition, such as Saudi Arabia, Kuwait and Iran. They are often available with added flavors such as apple, strawberry, and peach. The Middle East accounts for almost a third of worldwide sales of alcohol-free beer.
Legal drinking age in the US.
Beers that are labeled "non-alcoholic" still contain a very small amount of alcohol. Thus, some US states require the purchaser to be of a legal drinking age. Exceptions include:
In Sweden, beer below or equaling 2.25% ABV ("lättöl") is not legally subject to age restrictions; however, some stores voluntarily opt out from selling it to minors anyway.
Brewing process.
According to the Birmingham Beverage Company, the basic brewing process of traditional brews consists of eight basic steps, nine for brewing non-alcoholic brews.
How low-alcohol beer is made.
Low-alcohol beer starts out as regular alcoholic beer, which is then cooked in order to evaporate the alcohol. This is possible because alcohol is more volatile than water, so it is easier to boil off. The alcohol is allowed to escape and the remaining liquid is used, essentially the opposite of distillation. Most modern breweries also utilize vacuum evaporation to preserve flavor. In essence, the beer is placed under a light vacuum to facilitate the alcohol molecules going into the gaseous phase. If a sufficient vacuum is applied, it may not even be necessary to "cook" the beer, but heat must nevertheless be supplied.
An alternative process called reverse osmosis does not require heating. The beer is passed through a filter with pores small enough that only alcohol and water (and a few volatile acids) can pass through. The alcohol is distilled out of the alcohol-water mix using conventional distillation methods. After adding the water and remaining acids back into the syrupy mixture of sugars and flavor compounds left on the other side of the filter, the process is then complete.
Sometimes beer is simply diluted with water to give the desired alcohol level.
How non-alcoholic beer is made.
The conversion from a traditional alcoholic beer to a non-alcoholic beer takes place after the seventh step and preceding the finishing step. The un-carbonated beer is heated up to its boiling point. Another method of removing the alcohol is to decrease the pressure so the alcohol boils at room temperature. This is the preferred method because raising the temperature this late in the brewing process can greatly affect the flavor of the brew. If brewers decide to convert their brew to a non-alcoholic brew they must consider the volume of liquid they have lost during the removal of the alcohol. Typically the volume is reduced by roughly 4%, and to compensate water is added. Another tip would be avoiding using sugar from maize; this simply increases the alcohol content without adding to the flavor or body of the beer. Once the alcohol is removed, one proceeds with the normal finishing process in which the beer is carbonated and bottled.

</doc>
<doc id="21641" url="http://en.wikipedia.org/wiki?curid=21641" title="Norman Foster, Baron Foster of Thames Bank">
Norman Foster, Baron Foster of Thames Bank

Norman Robert Foster, Baron Foster of Thames Bank, OM, HonFREng (born 1 June 1935) is a British architect whose company, Foster + Partners, maintains an international design practice famous for high-tech architecture.
He is one of Britain's most prolific architects of his generation. In 1999 he was awarded the Pritzker Architecture Prize, often referred to as the Nobel Prize of architecture. In 2009 Foster was awarded the Prince of Asturias Award in the Arts category. In 1994 he received the AIA Gold Medal.
Biography.
Early life in Manchester.
Foster was born to Robert Foster and Lilian Smith in 1935 in Reddish, Stockport, Cheshire. They moved, soon after his birth, two miles to 4 Crescent Grove in Levenshulme, Manchester, which they rented for fourteen shillings (70p) a week: Foster has no recollection of Reddish.
He attended Burnage Grammar School for Boys in Burnage. In a "Guardian" interview in 1999, Foster said he always felt 'different' at school and was bullied. and he retired into the world of books. 
Manchester was 'one of the workshops of the world' and 'the embodiment of a great city'; his father, Robert, worked at Metropolitan-Vickers at Trafford Park which fuelled Foster's interest in engineering and design. He was fascinated with engineering and the process of designing. He says that caused him to pursue a career designing buildings. Specific interests included aircraft, a hobby he maintains today; and trains, generated by viewing passing trains on the railway outside his terraced home during his childhood. 
Foster's father convinced him to take the entrance exam for Manchester Town Hall's trainee scheme which he passed in 1951 and took a job as an office junior in the Treasurer's Department. A colleague, Mr Cobb's son, was studying architecture and his interest led to Foster considering a career in architecture. After working in the Manchester City Treasurer's office, Foster completed his National Service in 1953 serving in the Royal Air Force, a choice inspired by his passion for aircraft.
Foster returned to Manchester, not wanting to return to the town hall as his parents wished and unsure of which path to follow. Foster was searching for a world away from his working-class roots which led to the alienation of his parents.
Education.
Foster took a job as assistant to a contract manager with John Bearshaw and Partners, a local architectural practice. The staff advised him, that if he wished to become an architect, he should prepare a portfolio of drawings using the perspective and shop drawings from Bearshaw's practice as an example. Bearshaw was so impressed with the drawings that he promoted the young Foster to the drawing department of the practice.
In 1956 Foster won a place at the University of Manchester School of Architecture and City Planning. Foster was not eligible for a maintenance grant so took up a number of part-time jobs to fund his studies. becoming an ice-cream salesman, night-club bouncer and working night shifts at a bakery to make crumpets. He combined these with self-tuition via visits to the local library in Levenshulme. Foster took a keen interest in the works of Frank Lloyd Wright, Ludwig Mies van der Rohe, Le Corbusier and Oscar Niemeyer and graduated from Manchester in 1961.
Foster won the Henry Fellowship to the Yale School of Architecture, where he met future business partner Richard Rogers and earned his Master's degree. Vincent Scully encouraged Foster and Rogers to travel in America for a year. After returning to the UK in 1963 he set up an architectural practice as Team 4 with Rogers and the sisters Georgie and Wendy Cheesman. Georgie (later Wolton) was the only one of the team that had passed her RIBA exams allowing them to set up in practice on their own. Team 4 quickly earned a reputation for high-tech industrial design.
Foster + Partners.
After Team 4 went their separate ways, Foster and Wendy Cheesman founded Foster Associates, which later became Foster and Partners in 1967. A long period of collaboration with American architect Richard Buckminster Fuller began in 1968 and continued until Fuller's death in 1983. They collaborated on several projects that became catalysts in the development of an environmentally sensitive approach to design – including the Samuel Beckett Theatre project.
Originally they concentrated on industrial buildings. The turning point was the 1969 administrative and leisure center for Fred. Olsen Lines in London Docklands, where workers and managers are not separated any more. Foster and Partners' breakthrough building in the UK was the Willis Faber & Dumas headquarters in Ipswich, of 1974. The client was a family run insurance company which wanted to restore a sense of community to the workplace. Foster created open plan office floors long before open-plan became the norm. In a town not over-endowed with public facilities, the roof gardens, 25 metre swimming pool and gymnasium enhanced the quality of life for the company's 1200 employees. The building has a full-height glass facade moulded to the medieval street plan and contributes drama, subtly shifting from opaque, reflective black to a glowing backlit transparency as the sun sets. The design was inspired by the Daily Express Building in Manchester a work Foster admired in his youth. The building is now Grade II* listed.
Foster gained a reputation for designing office buildings. In the 1980s he designed the HSBC Main Building in Hong Kong for HSBC. The building is marked by its high level of light transparency, as all 3500 workers have a view to Victoria Peak or Victoria Harbour. Foster said that if the firm had not won the contract it would probably have been bankrupted. Foster believes that attracting young talent is essential, and is proud that the average age of people working for Foster and Partners is 32, just like it was in 1967.
Present day.
Foster was assigned the brief for a development on the site of the Baltic Exchange in the 1990s. The Exchange was damaged beyond repair by a bomb left by the IRA. Foster + Partners submitted a plan for a 385 metre tall skyscraper, the London Millennium Tower, but its height was seen as excessive for London's skyline. The proposal was scrapped and instead Foster proposed 30 St Mary Axe, popularly referred to as "the gherkin", after its shape. Foster worked with engineers to integrate complex computer systems with the most basic physical laws, such as convection. Green, sustainable energy ideas include the complex facade which lets in air for passive cooling and vents it as it warms and rises.
Foster's earlier designs reflected a sophisticated, machine-influenced high-tech vision. His style has evolved into a more sharp-edged modernity. In 2004, Foster designed the tallest bridge in the world, the Millau Viaduct in Southern France, with the Millau Mayor Jacques Godfrain stating; "The architect, Norman Foster, gave us a model of art."
In January 2007, the "Sunday Times" reported that Foster had called in Catalyst, a corporate finance house, to find buyers for Foster + Partners. Foster does not intend to retire, but sell his 80–90% holding in the company valued at £300M to £500M.
In 2007, he worked with Philippe Starck and Sir Richard Branson of the Virgin Group for the Virgin Galactic plans.
Foster currently sits on the Board of Trustees at architectural charity Article 25 who design, construct and manage innovative, safe, sustainable buildings in some of the most inhospitable and unstable regions of the world. He has also been on the Board of Trustees of the Architecture Foundation.
Recognition.
In 1986, he was awarded an honorary degree (Doctor of Science) from the University of Bath.
Foster was knighted in 1990 and appointed to the Order of Merit in 1997. On 19 July 1999, he was created a life peer, as Baron Foster of Thames Bank, of Reddish in the County of Greater Manchester. As a resident of Switzerland, in 2010 he stepped down from his seat in the House of Lords in order to maintain his non-domiciled status, and so be able to avoid paying UK residents' taxes on income earned abroad. Foster was criticised by some in the architecture world for not advocating the importance of high standards of architecture and planning whilst a member of the House of Lords. Foster last spoke in the Lords in 2003 before his resignation in 2010.
He was also appointed as a HonFREng of the Royal Academy of Engineering in 1995.
He is the second British architect to win the Stirling Prize twice: the first time for the American Air Museum at the Imperial War Museum Duxford in 1998, and the second for 30 St Mary Axe in 2004. In consideration of his whole portfolio, Foster was awarded the Pritzker Architecture Prize in 1999. He is a Fellow of the Chartered Society of Designers and winner of the Minerva Medal, its highest award. Foster is a Senior Fellow of the Design Futures Council.
Foster received The Lynn S. Beedle Lifetime Achievement Award from the Council on Tall Buildings and Urban Habitat in 2007 to honor his contributions to the advancement of tall buildings.
He was awarded the Aga Khan Award for Architecture, for the University of Technology Petronas in Malaysia, and in 2008 he was granted an honorary degree from the Dundee School of Architecture at the University of Dundee. In 2009 he received the Prince of Asturias Award in the category "Arts".

</doc>
<doc id="21642" url="http://en.wikipedia.org/wiki?curid=21642" title="Niklaus Wirth">
Niklaus Wirth

Niklaus Emil Wirth (born February 15, 1934) is a Swiss computer scientist, best known for designing several programming languages, including Pascal, and for pioneering several classic topics in software engineering. In 1984 he won the Turing Award for developing a sequence of innovative computer languages.
Biography.
Wirth was born in Winterthur, Switzerland, in 1934. In 1959 he earned a degree in Electronics Engineering from the Swiss Federal Institute of Technology Zürich (ETH Zürich). In 1960 he earned an M.Sc. from Université Laval, Canada. Then in 1963 he was awarded a Ph.D. in Electrical Engineering and Computer Science (EECS) from the University of California, Berkeley, supervised by the computer designer pioneer Harry Huskey.
From 1963 to 1967 he served as assistant professor of Computer Science at Stanford University and again at the University of Zurich. Then in 1968 he became Professor of Informatics at ETH Zürich, taking two one-year sabbaticals at Xerox PARC in California (1976–1977 and 1984–1985). Wirth retired in 1999.
In 2004, he was made a Fellow of the Computer History Museum "for seminal work in programming languages and algorithms, including Euler, Algol-W, Pascal, Modula, and Oberon."
Programming languages.
Wirth was the chief designer of the programming languages Euler, Algol W, Pascal, Modula, Modula-2, Oberon, Oberon-2, and Oberon-07. He was also a major part of the design and implementation team for the Lilith and Oberon operating systems, and for the Lola digital hardware design and simulation system. He received the "ACM Turing Award" for the development of these languages in 1984 and in 1994 he was inducted as a Fellow of the ACM.
He designed the simple programming language PL/0 to illustrate compiler design. It has formed the basis for many university compiler design classes.
Notable publications.
His book , served as the basis of many language implementation efforts in the 1970s and 1980s in the United States and across Europe.
His article , about the teaching of programming, is considered to be a classic text in software engineering.
In 1975 he wrote the book "Algorithms + Data Structures = Programs", which gained wide recognition. Major revisions of this book with the new title "Algorithms + Data Structures" were published in 1985 and 2004. The examples in the first edition were written in Pascal. These were replaced in the later editions with examples written in Modula-2 and Oberon respectively.
His textbook "" was considered a good source for students who wanted to do more than "just coding." Regarded as a challenging text to work through, it was sought as imperative reading for those interested in numerical mathematics.
Wirth's law.
In 1995, he popularized the adage now known as Wirth's law: "Software is getting slower more rapidly than hardware becomes faster." In his 1995 paper "A Plea for Lean Software" he attributes it to Martin Reiser.

</doc>
<doc id="21646" url="http://en.wikipedia.org/wiki?curid=21646" title="National Cartoonists Society">
National Cartoonists Society

The National Cartoonists Society (NCS) is an organization of professional cartoonists in the United States. It presents the National Cartoonists Society Awards. The Society was born in 1946 when groups of cartoonists got together to entertain the troops. They enjoyed each other's company and decided to meet on a regular basis.
NCS members work in many branches of the profession, including advertising, animation, newspaper comic strips and syndicated single-panel cartoons, comic books, editorial cartoons, gag cartoons, graphic novels, greeting cards, magazine and book illustration. Only recently has the National Cartoonists Society embraced web comics. Membership is limited to established professional cartoonists, with a few exceptions of outstanding persons in affiliated fields. The NCS is not a guild or labor union.
The organization's stated primary purposes are "to advance the ideals and standards of professional cartooning in its many forms", "to promote and foster a social, cultural and intellectual interchange among professional cartoonists of all types" and "to stimulate and encourage interest in and acceptance of the art of cartooning by aspiring cartoonists, students and the general public."
History.
The National Cartoonists Society had its origins during World War II when cartoonists Gus Edson, Otto Soglow, Clarence D. Russell, Bob Dunn and others did chalk talks at hospitals for the USO in 1943. Edson recalled, “We played two spots. Fort Hamilton and Governor’s Island. And then we quit the USO.” They were lured away by choreographer and former Rockette Toni Mendez. When she learned of these chalk talks, she recruited the cartoonists to do shows for the Hospital Committee of the American Theatre Wing. Beginning with a performance emceed by humor columnist Bugs Baer at Halloran Hospital on Staten Island, these shows were produced and directed by Mendez. The group expanded to junkets on military transport planes, flying to military bases along the southeastern seaboard. On one of those flights, Russell proposed a club to Rube Goldberg and others so the group could still get together after WWII ended. Mendez recalled:
The Society was organized on a Friday evening, March 1, 1946, when 26 cartoonists gathered at 7pm in the Barberry Room on East 52nd Street in Manhattan. After drinks and dinner, they voted to determine officers and a name for their new organization. It was initially known as The Cartoonists Society. Goldberg was elected president with Russell Patterson as vice president, C. D. Russell as secretary and Milton Caniff, treasurer. Soglow was later added as second vice president (“to follow the first vice president around”). Mendez functioned as the Society's trouble-shooter and later became an agent representing more than 50 cartoonists.
The 26 founding members came from the group of 32 members who had paid dues by March 13, including strip cartoonists Wally Bishop ("Muggs and Skeeter"), Martin Branner ("Winnie Winkle"), Ernie Bushmiller ("Nancy"), Milton Caniff, Gus Edson ("The Gumps"), Ham Fisher ("Joe Palooka"), Harry Haenigsen ("Penny"), Fred Harman ("Red Ryder"), Bill Holman ("Smokey Stover"), Jay Irving ("Willie Doodle"), Stan MacGovern ("Silly Milly"), Al Posen ("Sweeney and Son"), Clarence Russell ("Pete the Tramp"), Otto Soglow ("The Little King"), Jack Sparling ("Claire Voyant"), Raeburn Van Buren ("Abbie an' Slats"), Dow Walling ("Skeets") and Frank Willard ("Moon Mullins").
Also among the early 32 members were syndicated panel cartoonists Dave Breger ("Mister Breger"), George Clark ("The Neighbors"), Bob Dunn ("Just the Type") and Jimmy Hatlo ("They'll Do It Every Time"); freelance magazine cartoonists Abner Dean and Mischa Richter, editorial cartoonists Rube Goldberg ("New York Sun"), Burris Jenkins ("New York Journal American"), C. D. Batchelor ("Daily News") and Richard Q. Yardley ("The Baltimore Sun"); sports cartoonist Lou Hanlon; illustrator Russell Patterson and comic book artists Joe Shuster and Joe Musial.
More members joined by mid-May 1946, including Harold Gray ("Little Orphan Annie") and the Society’s first animator, Paul Terry, followed in the summer by letterer Frank Engli, Bela Zaboly ("Popeye"), Al Capp ("Li’l Abner") and Ray Bailey ("Bruce Gentry"). By March 1947, the NCS had 112 members, including Bud Fisher ("Mutt and Jeff"), Don Flowers (Glamor Girls), Bob Kane ("Batman"), Fred Lasswell ("Barney Google and Snuffy Smith"), George Lichty ("Grin and Bear It"), Zack Mosley ("The Adventures of Smilin' Jack"), Alex Raymond ("Rip Kirby"), Cliff Sterrett ("Polly and Her Pals") and Chic Young ("Blondie"), plus editorial cartoonists Reg Manning and Fred O. Seibel and sports cartoonist Willard Mullin.
Marge Devine Duffy, a secretary in King Features public relations department, had been helping Russell handle correspondence to the NCS, and in 1948, she was installed as the official NCS secretary and later given the title Scribe of the Society. Her name was on all the Society’s publications, and her address was the permanent mailing address of the NCS for more than 30 years. As the organizing secretary, she handled agendas, organization and publicity. “She practically ran the damn thing,” Caniff recalled. “A real autocrat, and everyone was delighted to have her be an autocrat because that’s what we needed.”
In the fall of 1949, the NCS cooperated with Treasury Department to sell savings bonds, engaging in a nationwide tour to 17 major cities with a team of 10 to 12 cartoonists and a traveling display, "20,000 Years of Comics", a 95-foot pictorial history of the comic strip.
Despite the contributions of Duffy and Mendez, there were no female members, as stipulated in the NCS' constitution which specified that “any cartoonist (male) who signs his name to his published work” could apply for membership. In 1949, Hilda Terry wrote a letter challenging that rule, and after more than six months of debates and votes, three women were finally admitted for membership in 1950—Terry, Edwina Dumm and gag cartoonist Barbara Shermund.
On November 6, 1951, 49 members of the NCS arrived at Washington's Carlton Hotel for breakfast with Harry S. Truman. Gathered in Washington to help the Treasury Department sell Defense Stamps, the group presented Truman with a bound volume of their comic strip characters, some interacting with caricatures of Truman.
USO Tour and charitable causes.
When Al Posen originated the idea of National Cartoonists Society tours to entertain American servicemen, he became the NCS Director of Overseas Shows. On October 4, 1952, nine cartoonists left on a USO-Camp Shows tour of U.S. Armed Forces installations in Europe, traveling via a Military Air Transport Service plane from Westover Air Force Base in Massachusetts and landing at Rhein-Main Air Base in Germany. On the tour, the cartoonists engaged models in each country to join in their "Laff Time" show of audience participation stunts and gags. The cartoonists were Posen, Charles Biro, Bob Dunn, Gus Edson, Bill Holman, Bob Montana, Russell Patterson, Clarence Russell and Dick Wingert ("Hubert"). The comic strip "Dondi" came about because of a friendship that developed between Edson and Irwin Hasen during a USO trip to Korea.
Hy Eisman described the atmosphere at the NCS when he joined in 1955:
During the 1960s, cartoonists of military comic strips went to the White House and met with Lyndon B. Johnson in the Oval Office. The group included Caniff, Bill Mauldin and Mort Walker.
In 1977-78, the National Cartoonists Society released "The National Cartoonists Society Portfolio of Fine Comic Art", published by Collector's Press. The portfolio featured a total of 34 art prints. Each 12" x 16" print was printed on archival fine art paper.
In 2011, to memorialize and commemorate the 10th anniversary of , many NCS cartoonists auctioned off art that gave commentary to the tragedy and raised money for families victimized by the event in a reflective homage called, . These cartoon tributes raised over $50,000 to benefit the 9/11 families.The art was featured and displayed in both nationally syndicated newspapers and museums across America, including the Newseum in Washington, DC, the Cartoon Art Museum in San Francisco and the Museum of Comic and Cartoon Art in New York City.
In 2005, the Society formed a Foundation to continue the charitable works of its fund for indigent cartoonists, the Milt Gross Fund.
The Society's offices are in Winter Park, Florida. In addition, the NCS has chartered 16 regional chapters throughout the United States and one in Canada. Chapter Chairpersons sit on the NCS Regional Council and are represented by a National Representative, who is a voting member of the Board of Directors. As NCS president for two consecutive terms, Jeff Keane, cartoonist for the Family Circus and son of comic creator, Bil Keane, returned to the charter and spirit of the NCS by extending the society's by visiting and cartooning for vets who served in the Iraq War and Afghanistan War, during the years 2007-2011.
In 2008, NCS joined over 60 other art licensing businesses (including the Artists Rights Society, Association of American Editorial Cartoonists, Society of Children's Book Writers and Illustrators, the Stock Artists Alliance, Illustrator's Partnership of America and the Advertising Photographers of America) in opposing both and . Known collectively as "", the diverse organizations joined forces to oppose the bills, which the groups believe "permits, and even encourages, wide-scale infringements while depriving creators of protections currently available under the Copyright Act."
Billy DeBeck Memorial Award.
The earliest NCS award was the Billy DeBeck Memorial Award, known as the Barney from the character in DeBeck's popular comic strip "Barney Google and Snuffy Smith". After DeBeck died on Veteran's Day, 1942, Mary DeBeck remarried (as Mary Bergman) and created the DeBeck Award in 1946. She also made the annual presentation of engraved silver cigarette cases (with DeBeck's characters etched on the cover) to the eight winners spanning the years 1946 to 1953.
Mary Bergman died February 14, 1953, aboard a National Airlines DC-6 which went down in the Gulf of Mexico during a thunderstorm on a flight from Tampa to New Orleans. In 1954, following her death, the DeBeck Award was renamed the Reuben Award. When the award name was changed in 1954, all of the prior eight winners were given Reuben statuettes designed by and named after the NCS' first president, Rube Goldberg. The Reuben Award was executed in bronze by sculptor and editorial cartoonist Bill Crawford.
Reuben Award.
The National Cartoonists Society's Reuben Awards weekend is an annual gala event which takes place at a site selected by the President. During the formal, black-tie banquet evening, the Reuben Award (determined by secret ballot) is presented to the Outstanding Cartoonist of the Year. Cartoonists in various professional divisions are also honored with special plaques for excellence. These awards are voted by a combination of the general membership (by secret ballot) and specially-formed juries overseen by various NCS Regional Chapters. A cartoonist does not need to be a member of the NCS to receive one of the Society's awards.
Prior to 1983, the Reuben Awards Dinner was held in New York City, usually at the Plaza Hotel. Since then, the event has expanded into a full weekend and is held in a different city each year. Recent Reuben locations have included New York City; Boca Raton; San Francisco; Cancún; Kansas City, Missouri; Las Vegas; and Pittsburgh, Pennsylvania in 2013.
Each year, during the NCS Annual Reuben Awards Weekend, the Society honors the year's outstanding achievements in all walks of the profession. Excellence in the fields of newspaper strips, newspaper panels, TV animation, feature animation, newspaper illustration, gag cartoons, book illustration, greeting cards, comic books, magazine feature/magazine illustration and editorial cartoons, is honored in the NCS Division Awards, which are chosen by specially-convened juries at the chapter level. An Online Comic Strip Award was added in 2011.
The recipient of the profession's highest honor, the Reuben Award for Outstanding Cartoonist of the Year, is chosen by a secret ballot of the members. As part of the presentations and general frivolity, the NCS has produced videos to initiate the festivities, some of which have been parodies of .
Award winners.
Billy DeBeck Memorial Award
Reuben Award
Other awards.
Award of Honor.
This award was for recognition of the American cartoon as an instrument in war, peace, education and in the artistic betterment of our cultural environment. On September 22, 1965, the following were honored:
Milton Caniff Lifetime Achievement Award.
The Milton Caniff Lifetime Achievement Award is awarded by unanimous vote of the NCS Board of Directors.
Gold T-Square Award.
The Gold T-Square is awarded for 50 years as professional cartoonist.
Silver T-Square Award.
The Silver T-Square is awarded, by unanimous vote of the NCS Board of Directors, to persons who have demonstrated outstanding dedication or service to the Society or the profession.
Elzie Segar Award.
This award is presented to a person who has made a unique and outstanding contribution to the profession of cartooning.
The winner was selected by the NCS Board and later by King Features Syndicate, in honor of "Popeye" creator, Elzie Segar.

</doc>
<doc id="21647" url="http://en.wikipedia.org/wiki?curid=21647" title="Nebraska">
Nebraska

Nebraska is a state that lies in both the Great Plains and the Midwestern United States. Its state capital is Lincoln. Its largest city is Omaha, which is on the Missouri River.
The state is crossed by many historic trails, and was explored by the Lewis and Clark Expedition. The California Gold Rush brought the first large numbers of non-indigenous settlers to the area. Nebraska was admitted as the 37th state of the United States in 1867.
The climate has wide variations between winter and summer temperatures, and violent thunderstorms and tornadoes are common. The state is characterized by treeless prairie, which is ideal for cattle-grazing. It is a major producer of beef, as well as pork, corn, and soybeans.
The largest ancestry group claimed by Nebraskans is German American. The state also has the largest per capita population of Czech Americans among U.S. states.
Etymology.
Nebraska's name is derived from transliteration of the archaic Otoe words "Ñí Brásge", pronounced ] (contemporary Otoe "Ñí Bráhge"), or the Omaha "Ní Btháska", pronounced ], meaning "flat water", after the Platte River that flows through the state.
History.
Indigenous peoples lived in the region of present-day Nebraska for thousands of years before European exploration. The historic tribes in the state included the Omaha, Missouria, Ponca, Pawnee, Otoe, and various branches of the Lakota (Sioux), some of which migrated from eastern areas into this region.
When European exploration, trade, and settlement began, both Spain and France sought to control the region. In the 1690s, Spain established trade connections with the Apaches, whose territory then included western Nebraska. By 1703, France had developed a regular trade with the native peoples along the Missouri River in Nebraska, and by 1719 had signed treaties with several of these peoples. After war broke out between the two countries, Spain dispatched an armed expedition to Nebraska under Lieutenant General Pedro de Villasur in 1720. The party was attacked and destroyed near present-day Columbus by a large force of Pawnees and Otoes, both allied to the French. The massacre of the Villasur expedition effectively put an end to Spanish exploration of Nebraska for the remainder of the 18th century.
In 1762, during the Seven Years' War, France ceded the Louisiana territory to Spain. France's withdrawal from the area left Britain and Spain competing for dominance along the Mississippi; by 1773, the British were trading with the native peoples of Nebraska. In response to this, Spain dispatched two trading expeditions up the Missouri in 1794 and 1795; the second of these, under James Mackay, established the first European settlement in Nebraska near the mouth of the Platte. Later that year, Mackay's party built a trading post, dubbed Fort Carlos IV (Fort Charles), near present-day Homer.
In 1819, the United States established Fort Atkinson as the first US Army post west of the Missouri River, just east of present-day Fort Calhoun. The army abandoned the fort in 1827 as migration moved further west.
European-American settlement did not begin in any numbers until after 1848 and the California Gold Rush. On May 30, 1854, the US Congress created the Kansas and the Nebraska territories, divided by the Parallel 40° North, under the Kansas-Nebraska Act. The Nebraska Territory included parts of the current states of Colorado, North Dakota, South Dakota, Wyoming, and Montana. The territorial capital of Nebraska was Omaha.
In the 1860s, after the US government forced many of the Native American tribes to cede their lands and settle on reservations, it opened large tracts of land to agricultural development by Europeans and Americans. Under the Homestead Act, thousands of new settlers migrated into Nebraska to claim free land granted by the federal government. Because so few trees grew on the prairies, many of the first farming settlers built their homes of sod, as had the Native Americans such as the Omaha. The first wave of settlement gave the territory a sufficient population to apply for statehood.
Nebraska became the 37th state on March 1, 1867, and the capital was moved from Omaha to the center at Lancaster, later renamed Lincoln after the recently assassinated President of the United States, Abraham Lincoln. The battle of Massacre Canyon on August 5, 1873, was the last major battle between the Pawnee and the Sioux.
During the 1870s to the 1880s, Nebraska experienced a large growth in population. Several factors contributed to attracting new residents. The first was that the vast prairie land was perfect for cattle grazing. This helped settlers to learn the unfamiliar geography of the area. The second factor was the invention of several farming technologies. Agricultural inventions such as barbed wire, wind mills, and the steel plow, combined with good weather, enabled settlers to make use of Nebraska as prime farming land. By the 1880s, Nebraska's population had soared to more than 450,000 people.
The Arbor Day holiday was founded in Nebraska City by territorial governor J. Sterling Morton. The National Arbor Day Foundation is still headquartered in Nebraska City, with some offices in Lincoln.
In the late nineteenth century, many African Americans migrated from the South to Nebraska as part of the Great Migration, primarily to Omaha which offered working class jobs in meatpacking, the railroads and other industries. Omaha has a long history of civil rights activism. Blacks encountered discrimination from other Americans in Omaha and especially from recent European immigrants, ethnic whites who were competing for the same jobs. In 1912 African Americans founded the Omaha chapter of the National Association for the Advancement of Colored People to work for improved conditions in the city and state. Activism has continued.
Since the 1960s, Native American activism in the state has increased, both through open protest, activities to build alliances with state and local governments, and in the slower, more extensive work of building tribal institutions and infrastructure. Native Americans in federally recognized tribes have pressed for self-determination, sovereignty and recognition. They have created community schools to preserve their cultures, as well as tribal colleges and universities. Tribal politicians have also collaborated with state and county officials on regional issues.
Geography.
The state is bordered by South Dakota to the north; Iowa to the east and Missouri to the southeast, across the Missouri River; Kansas to the south; Colorado to the southwest; and Wyoming to the west. The state has 93 counties; it occupies the central portion of the Frontier Strip. Nebraska is split into two time zones.
The Central Time zone comprises the eastern half of the state, while the western half observes Mountain Time. Three rivers cross the state from west to east. The Platte River, formed by the confluence of the North Platte and the South Platte, runs through the central portion of the state, the Niobrara River flows through the northern part, and the Republican River runs across the southern part.
Nebraska is composed of two major land regions: the Dissected Till Plains and the Great Plains. The easternmost portion of the state was scoured by Ice Age glaciers; the Dissected Till Plains were left behind after the glaciers retreated. The Dissected Till Plains is a region of gently rolling hills; Omaha and Lincoln are in this region.
The Great Plains occupy the majority of western Nebraska. The Great Plains region consists of several smaller, diverse land regions, including the Sandhills, the Pine Ridge, the Rainwater Basin, the High Plains and the Wildcat Hills. Panorama Point, at 5,424 feet (1,653 m), is the highest point in Nebraska; despite its name and elevation, it is a relatively low rise near the Colorado and Wyoming borders.
A past Nebraska tourism slogan was "Where the West Begins"; locations given for the beginning of the "West" include the Missouri River, the intersection of 13th and O Streets in Lincoln (where it is marked by a red brick star), the 100th meridian, and Chimney Rock.
Federal land management.
Areas under the management of the National Park Service include:
Areas under the management of the National Forest Service include:
Climate.
Two major climatic zones are represented in Nebraska: the eastern half of the state has a humid continental climate (Köppen climate classification "Dfa"), and the western half, a semi-arid climate (Koppen "BSk"). The entire state experiences wide seasonal variations in temperature and precipitation. Average temperatures are fairly uniform across Nebraska, with hot summers and generally cold winters.
Average annual precipitation decreases east to west from about 31.5 inches (800 mm) in the southeast corner of the state to about 13.8 inches (350 mm) in the Panhandle. Humidity also decreases significantly from east to west. Snowfall across the state is fairly even, with most of Nebraska receiving between 25 and 35 inches (65 to 90 cm) of snow annually. Nebraska's highest recorded temperature is 118 F at Minden on July 24, 1936 and the lowest recorded temperature is -47 F at Camp Clarke on February 12, 1899.
Nebraska is in Tornado Alley; thunderstorms are common in the spring and summer months, and violent thunderstorms and tornadoes happen primarily during the spring and summer, though they can also occur in the autumn. The chinook winds from the Rocky Mountains provide a temporary moderating effect on temperatures in western Nebraska during the winter months.
Demographics.
The United States Census Bureau estimates that the population of Nebraska was 1,881,503 on July 1, 2014, a 3.02% increase since the 2010 United States Census. The center of population of Nebraska is in Polk County, in the city of Shelby.
Race and ethnicity.
According to the 2010 Census, 86.1% of the population was White (82.1% non-Hispanic white), 4.5% was Black or African American, 1.0% American Indian and Alaska Native, 1.8% Asian, 0.1% Native Hawaiian and other Pacific Islander, 2.2% from two or more races. 9.2% of the total population was of Hispanic or Latino origin (they may be of any race).
As of 2004, the population of Nebraska included about 84,000 foreign-born residents (4.8% of the population).
The five largest ancestry groups in Nebraska are German (38.6%), Irish (12.4%), English (9.6%), Mexican (8.7%), and Czech (5.5%).
Nebraska has the largest Czech American and non-Mormon Danish American population (as a percentage of the total population) in the nation. German Americans are the largest ancestry group in most of the state, particularly in the eastern counties. Thurston County (made up entirely of the Omaha and Winnebago reservations) has an American Indian majority, and Butler County is one of only two counties in the nation with a Czech-American plurality.
As of 2011, 31.0% of Nebraska's population younger than age 1 were minorities.
Rural flight.
Eighty-nine percent of the cities in Nebraska have fewer than 3,000 people. Nebraska shares this characteristic with five other Midwestern states: Kansas, Oklahoma, North and South Dakota, and Iowa. Hundreds of towns have a population of fewer than 1,000. Regional population declines have forced many rural schools to consolidate.
Fifty-three of Nebraska's 93 counties reported declining populations between 1990 and 2000, ranging from a 0.06% loss (Frontier County) to a 17.04% loss (Hitchcock County).
More urbanized areas of the state have experienced substantial growth. In 2000, the city of Omaha had a population of 390,007; in 2005, the city's estimated population was 414,521 (427,872 including the recently annexed city of Elkhorn), a 6.3% increase over five years. The 2010 census showed that Omaha has a population of 408,958. The city of Lincoln had a 2000 population of 225,581 and a 2010 population of 258,379, a 14.5% increase.
Religion.
The religious affiliations of the people of Nebraska are:
The largest single denominations by number of adherents in 2010 were the Roman Catholic Church (372,838), the Lutheran Church–Missouri Synod (112,585), the Evangelical Lutheran Church in America (110,110) and the United Methodist Church (109,283).
Important cities and towns.
As of the 2010 Census, there are 530 cities and villages in the state of Nebraska. There are five classifications of cities and villages in Nebraska, which is based upon population. All population figures are 2013 Census Bureau estimates.
Largest cities.
Metropolitan Class City (300,000 or more)
Primary Class City (100,000 – 299,999)
First Class City (5,000 – 99,999)
Second Class Cities (800 – 4,999) and Villages (100–800) make up the rest of the communities in Nebraska. There are 116 second class cities and 382 villages in the state.
Urban areas.
Other areas
Taxation.
Nebraska has a progressive income tax. The portion of income from $0 to $2,400 is taxed at 2.56%; from $2,400 to $17,500, at 3.57%; from $17,500 to $27,000, at 5.12%; and income over $27,000, at 6.84%. The standard deduction for a single taxpayer is $5,700; the personal exemption is $118.
Nebraska has a state sales and use tax of 5.5%. In addition to the state tax, some Nebraska cities assess a city sales and use tax, in 0.5% increments, up to a maximum of 1.5%. One county in Nebraska, Dakota County, levies an additional 0.5% county sales tax. Food and ingredients that are generally for home preparation and consumption are not taxable. All real property within the state of Nebraska is taxable unless specifically exempted by statute. Since 1992, only depreciable personal property is subject to tax and all other personal property is exempt from tax. Inheritance tax is collected at the county level.
Economy.
The Bureau of Economic Analysis estimates of Nebraska's gross state product in 2010 was $89.8 billion. Per capita personal income in 2004 was $31,339, 25th in the nation. Nebraska has a large agriculture sector, and is a major producer of beef, pork, corn (maize), soybeans, and sorghum. Other important economic sectors include freight transport (by rail and truck), manufacturing, telecommunications, information technology, and insurance.
As of January 2010, the state's unemployment rate is 4.6%.
Industry.
Kool-Aid was created in 1927 by Edwin Perkins in the city of Hastings, which celebrates the event the second weekend of every August with . Kool-Aid is the official soft drink of Nebraska. "CliffsNotes" were developed by Clifton Hillegass of Rising City. He adapted his pamphlets from the Canadian publications, "Coles Notes".
Omaha is home to Berkshire Hathaway, whose CEO Warren Buffett was ranked in March 2009 by "Forbes" magazine as the second richest person in the world. The city is also home to ConAgra, Mutual of Omaha, InfoUSA, TD Ameritrade, West Corporation, Valmont Industries, Woodmen of the World, Kiewit Corporation, and the Union Pacific Railroad. UNIFI Companies, Nelnet, Sandhills Publishing Company, and Duncan Aviation are based in Lincoln; The Buckle is based in Kearney. Sidney is the national headquarters for Cabela's, a specialty retailer of outdoor goods.
The world's largest train yard, Union Pacific's Bailey Yard, is in North Platte. The Vise-Grip was invented by William Petersen in 1924, and was manufactured in De Witt until the plant was closed and moved to China in late 2008.
Lincoln's Kawasaki Motors Manufacturing is the only Kawasaki plant in the world to produce the Jet-Ski, ATV, and Mule lines of product. The facility employs more than 1200 people.
The Spade Ranch, in the Sand Hills, is one of Nebraska's oldest and largest beef cattle operations.
Energy.
Nebraska has the potential to generate 3,011,000 GWh/year from 918,000 MW of wind power, and 14,132,000 GWh/year from solar power using 4,881,000 MW of photovoltaics (PV), including 4,228 MW of rooftop photovoltaics, and 1,753,000 MW of concentrated solar power.
Transportation.
Railroads.
The Union Pacific Railroad, headquartered in Omaha, was incorporated on July 1, 1862, in the wake of the Pacific Railway Act of 1862. Bailey Yard, in North Platte, is the largest railroad classification yard in the world. The route of the original transcontinental railroad runs through the state.
Other major railroads with operations in the state are: Amtrak; BNSF Railway; Canadian Pacific Railway; and Iowa Interstate Railroad.
Roads and highways.
Interstate Highways through the State of Nebraska
The U.S. Routes in Nebraska
Law and government.
Nebraska's government operates under the framework of the Nebraska Constitution, adopted in 1875, and is divided into three branches: executive, legislative, and judicial.
Executive branch.
The head of the executive branch is Governor Pete Ricketts. Other elected officials in the executive branch are Lieutenant Governor Mike Foley, Attorney General Doug Peterson, Secretary of State John A. Gale, State Treasurer Don Stenberg, and State Auditor Charlie Janssen. All elected officials in the executive branch serve four-year terms.
Legislative branch.
Nebraska is the only state in the United States with a unicameral legislature. Although this house is officially known simply as the "Legislature", and more commonly called the "Unicameral", its members call themselves "senators". Nebraska's Legislature is also the only state legislature in the United States that is nonpartisan. The senators are elected with no party affiliation next to their names on the ballot, and the speaker and committee chairs are chosen at large, so that members of any party can be chosen for these positions. The Nebraska Legislature can also override a governor's veto with a three-fifths majority, in contrast to the two-thirds majority required in some other states.
The Nebraska Legislature meets in the third Nebraska State Capitol building, built between 1922 and 1932. It was designed by Bertram G. Goodhue. Built from Indiana limestone, the Capitol's base is a cross within a square. A 400-foot domed tower rises from this base. The Sower, a 19-foot bronze statue representing agriculture, crowns the Capitol. The state Capitol is considered an architectural achievement and has been recognized by the American Institute of Architects.
When Nebraska became a state in 1867, its legislature consisted of two houses: a House of Representatives and a Senate. For years, prior to 1934, US Senator George Norris and other Nebraskans encouraged the idea of a unicameral legislature, and demanded the issue be decided in a referendum. Norris argued:
The constitutions of our various states are built upon the idea that there is but one class. If this be true, there is no sense or reason in having the same thing done twice, especially if it is to be done by two bodies of men elected in the same way and having the same jurisdiction.
Unicameral supporters also argued that a bicameral legislature had a significant undemocratic feature in the committees that reconciled House and Senate legislation. Votes in these committees were secretive, and would sometimes add provisions to bills that neither house had approved. Nebraska's unicameral legislature today has rules that bills can contain only one subject, and must be given at least five days of consideration.
In 1934, due in part to the budgetary pressure of the Great Depression, Nebraska citizens ran a state initiative to vote on a constitutional amendment creating a unicameral legislature, which was approved. In effect, the House of Representatives (the lower house) was abolished; today's Nebraska state legislators are commonly referred to as "Senators".
Judicial branch.
The judicial system in Nebraska is unified, with the Nebraska Supreme Court having administrative authority over all Nebraska courts. Nebraska uses the Missouri Plan for the selection of judges at all levels. The lowest courts in Nebraska are the county courts, above that are twelve district courts (containing one or more counties). The Court of Appeals hears appeals from the district courts, juvenile courts, and workers' compensation courts. The Nebraska Supreme Court is the final court of appeal.
In 2008, the Nebraska Supreme Court ruled that the state's only method of execution, electrocution, was in conflict with the state's constitution. For the next year, Nebraska had no active death-penalty law. (Prior to that ruling, Nebraska was the only place in the world that used electrocution as the sole method of execution.) In May 2009, the legislature passed and the governor signed a bill that changed the method of execution in Nebraska to lethal injection, enabling capital punishment. Executions in Nebraska have been infrequent; none have been carried out in the 21st century. During the last few decades, residents have considered a moratorium on, or complete abolition of, capital punishment.
Federal government representation.
Nebraska's U.S. senators are Deb Fischer (R), the Senior senator, and Ben Sasse (R), the Junior senator.
Nebraska has three representatives in the House of Representatives: Jeff Fortenberry (R) of the 1st district; Brad Ashford (D) of the 2nd district; and Adrian Smith (R) of the 3rd district.
Nebraska is one of two states (with Maine) that allow for a split in the state's allocation of electoral votes in presidential elections. Under a 1991 law, two of Nebraska's five votes are awarded to the winner of the statewide popular vote, while the other three go to the highest vote-getter in each of the state's three congressional districts.
Politics.
For most of its history, Nebraska has been a solidly Republican state. Republicans have carried the state in all but one presidential election since 1940: the 1964 landslide election of Lyndon B. Johnson. In the 2004 presidential election, George W. Bush won the state's five electoral votes by a margin of 33 percentage points (making Nebraska's the fourth-strongest Republican vote among states) with 65.9% of the overall vote; only Thurston County, which is majority-Native American, voted for his Democratic challenger John Kerry. In 2008, the state split its electoral votes for the first time: Republican John McCain won the popular vote in Nebraska as a whole and two of its three congressional districts; the second district, which includes the city of Omaha, went for Democrat Barack Obama.
Despite the current Republican domination of Nebraska politics, the state has a long tradition of electing centrist members of both parties to state and federal office; examples include George Norris (who served few years in the Senate as an independent), J. James Exon, and Bob Kerrey. Voters have tilted to the right in recent years with the election of conservative Mike Johanns to the U.S. Senate and the 2006 re-election of Ben Nelson, who was considered the most conservative Democrat in the Senate until his retirement in 2013, when he was replaced by conservative Republican Deb Fischer.
Former President Gerald Ford was born in Nebraska, but moved away shortly after birth. Illinois native William Jennings Bryan represented Nebraska in Congress, served as U.S. Secretary of State under President Woodrow Wilson, and unsuccessfully ran for President three times.
Sports.
College sports.
NCAA Division I sports.
The following are National Collegiate Athletic Association Division I college sports played in Nebraska.
NCAA Division II sports.
Nebraska has several colleges playing in the NCAA Division II.
Bibliography.
Surveys.
</dl>
Scholarly special studies.
</dl>

</doc>
<doc id="21648" url="http://en.wikipedia.org/wiki?curid=21648" title="New Jersey">
New Jersey

New Jersey is a state in the Northeastern and Middle Atlantic regions of the United States. It is bordered on the north and east by New York State, on the southeast and south by the Atlantic Ocean, on the west by Pennsylvania, and on the southwest by Delaware. New Jersey is the fourth-smallest state, but the 11th-most populous and the most densely populated of the 50 United States. New Jersey lies entirely within the combined statistical areas of New York City and Philadelphia. It is also the second-wealthiest U.S. state by median household income, according to the 2008–2012 American Community Survey.
The area was inhabited by Native Americans for more than 2,800 years, with historical tribes such as the Lenape along the coast. In the early 17th century, the Dutch and the Swedes made the first European settlements. The English later seized control of the region, naming it the Province of New Jersey. It was granted as a colony to Sir George Carteret and John Berkeley, 1st Baron Berkeley of Stratton. At this time, it was named after the largest of the Channel Islands, Jersey, Carteret's birthplace.
New Jersey was the site of several decisive battles during the American Revolutionary War.
In the 19th century, factories in cities such as Camden, Paterson, Newark, Trenton, and Elizabeth helped to drive the Industrial Revolution. New Jersey's geographic location at the center of the Northeast megalopolis, between Boston and New York City to the northeast, and Philadelphia, Baltimore, and Washington, D.C., to the southwest, fueled its rapid growth through the process of suburbanization in the 1950s and beyond.
History.
Around 180 million years ago, during the Jurassic Period, New Jersey bordered North Africa. The pressure of the collision between North America and Africa gave rise to the Appalachian Mountains. Around 18,000 years ago, the Ice Age resulted in glaciers that reached New Jersey. As the glaciers retreated, they left behind Lake Passaic, as well as many rivers, swamps, and gorges.
New Jersey was originally settled by Native Americans, with the Lenni-Lenape being dominant at the time of contact. "Scheyichbi" is the Lenape name for the land that is now New Jersey. The Lenape were several autonomous groups that practiced maize agriculture in order to supplement their hunting and gathering in the region surrounding the Delaware River, the lower Hudson River, and western Long Island Sound. The Lenape society was divided into matrilinear clans that were based upon common female ancestors. These clans were organized into three distinct phratries identified by their animal sign: Turtle, Turkey, and Wolf. They first encountered the Dutch in the early 17th century, and their primary relationship with the Europeans was through fur trade.
Colonial era.
The Dutch became the first Europeans to lay claim to lands in New Jersey. The Dutch colony of New Netherland consisted of parts of modern Middle Atlantic states. Although the European principle of land ownership was not recognized by the Lenape, Dutch West India Company policy required their colonists to purchase land which they settled. The first to do so was Michiel Pauw who established a patronship named Pavonia along the North River which eventually became the Bergen. Peter Minuit's purchase of lands along the Delaware River established the colony of New Sweden. The entire region became a territory of England on June 24, 1664, after an English fleet under the command of Colonel Richard Nicolls sailed into what is today New York Harbor and took control of Fort Amsterdam, annexing the entire province.
During the English Civil War, the Channel Island of Jersey remained loyal to the British Crown and gave sanctuary to the King. It was from the Royal Square in St. Helier that Charles II of England was first proclaimed King in 1649, following the execution of his father, Charles I. The North American lands were divided by Charles II, who gave his brother, the Duke of York (later King James II), the region between New England and Maryland as a proprietary colony (as opposed to a royal colony). James then granted the land between the Hudson River and the Delaware River (the land that would become New Jersey) to two friends who had remained loyal through the English Civil War: Sir George Carteret and Lord Berkeley of Stratton. The area was named the Province of New Jersey.
Since the state's inception, New Jersey has been characterized by ethnic and religious diversity. New England Congregationalists settled alongside Scots Presbyterians and Dutch Reformed migrants. While the majority of residents lived in towns with individual landholdings of 100 acre, a few rich proprietors owned vast estates. English Quakers and Anglicans owned large landholdings. Unlike Plymouth Colony, Jamestown and other colonies, New Jersey was populated by a secondary wave of immigrants who came from other colonies instead of those who migrated directly from Europe. New Jersey remained agrarian and rural throughout the colonial era, and commercial farming developed sporadically. Some townships, such as Burlington on the Delaware River and Perth Amboy, emerged as important ports for shipping to New York City and Philadelphia. The colony's fertile lands and tolerant religious policy drew more settlers, and New Jersey's population had increased to 120,000 by 1775.
Settlement for the first 10 years of English rule took place along Hackensack River and Arthur Kill – settlers came primarily from New York and New England. On March 18, 1673, Berkeley sold his half of the colony to Quakers in England, who settled the Delaware Valley region as a Quaker colony. (William Penn acted as trustee for the lands for a time.) New Jersey was governed very briefly as two distinct provinces, East and West Jersey, for 28 years between 1674 and 1702, at times part of the Province of New York or Dominion of New England.
In 1702, the two provinces were reunited under a royal, rather than a proprietary, governor. Edward Hyde, Lord Cornbury, became the first governor of the colony as a royal colony. Britain believed that he was an ineffective and corrupt ruler, taking bribes and speculating on land. In 1708 he was recalled to England. New Jersey was then ruled by the governors of New York, but this infuriated the settlers of New Jersey, who accused those governors of favoritism to New York. Judge Lewis Morris led the case for a separate governor, and was appointed governor by King George II in 1738.
Revolutionary War era.
New Jersey was one of the Thirteen Colonies that revolted against British rule in the American Revolution. The was passed July 2, 1776, just two days before the Second Continental Congress declared American Independence from Great Britain. It was an act of the Provincial Congress, which made itself into the state Legislature. To reassure neutrals, it provided that it would become void if New Jersey reached reconciliation with Great Britain.
New Jersey representatives Richard Stockton, John Witherspoon, Francis Hopkinson, John Hart, and Abraham Clark were among those who signed the United States Declaration of Independence.
During the American Revolutionary War, British and American armies crossed New Jersey numerous times, and several pivotal battles took place in the state. Because of this, New Jersey today is often referred to as "The Crossroads of the Revolution." The winter quarters of the revolutionary army were established there twice by General George Washington in Morristown, which was called the military capital of the revolution.
On the night of December 25–26, 1776, the Continental Army under George Washington crossed the Delaware River. After the crossing, he surprised and defeated the Hessian troops in the Battle of Trenton. Slightly more than a week after victory at Trenton, American forces gained an important victory by stopping General Cornwallis's charges at the Second Battle of Trenton. By evading Cornwallis's army, Washington made a surprise attack on Princeton and successfully defeated the British forces there on January 3, 1777. Emanuel Leutze's painting of "Washington Crossing the Delaware" became an icon of the Revolution.
American forces under Washington met the forces under General Henry Clinton at the Battle of Monmouth in an indecisive engagement in June 1778. Washington attempted to take the British column by surprise; when the British army attempted to flank the Americans, the Americans retreated in disorder. The ranks were later reorganized and withstood the British charges.
In the summer of 1783, the Continental Congress met in Nassau Hall at Princeton University, making Princeton the nation's capital for four months. It was there that the Continental Congress learned of the signing of the Treaty of Paris (1783), which ended the war.
On December 18, 1787, New Jersey became the third state to ratify the United States Constitution, which was overwhelmingly popular in New Jersey, as it prevented New York and Pennsylvania from charging tariffs on goods imported from Europe. On November 20, 1789, the state became the first in the newly formed Union to ratify the Bill of Rights.
The 1776 New Jersey State Constitution gave the vote to "all inhabitants" who had a certain level of wealth. This included women and blacks, but not married women, because they could not own property separately from their husbands. Both sides, in several elections, claimed that the other side had had unqualified women vote and mocked them for use of "petticoat electors" (entitled to vote or not); on the other hand, both parties passed Voting Rights Acts. In 1807, the legislature passed a bill interpreting the constitution to mean universal "white male" suffrage, excluding paupers. (This was less revolutionary than it sounds: the constitution was itself an act of the legislature, and not enshrined as the modern constitution.)
19th century.
On February 15, 1804, New Jersey became the last northern state to abolish new slavery and enacted legislation that slowly phased out existing slavery. This led to a gradual decrease of the slave population. By the close of the Civil War, about a dozen African Americans in New Jersey were still held in bondage. New Jersey voters initially refused to ratify the constitutional amendments banning slavery and granting rights to the United States' black population.
Industrialization accelerated in the northern part of the state following completion of the Morris Canal in 1831. The canal allowed for coal to be brought from eastern Pennsylvania's Lehigh Valley to northern New Jersey's growing industries in Paterson, Newark and Jersey City.
In 1844, the second state constitution was ratified and brought into effect. Counties thereby became districts for the State Senate, and some realignment of boundaries (including the creation of Mercer County) immediately followed. This provision was retained in the 1947 Constitution, but was overturned by the Supreme Court of the United States in 1962 by the decision "Baker v. Carr". While the Governorship was stronger than under the 1776 constitution, the constitution of 1844 created many offices that were not responsible to him, or to the people, and it gave him a three-year term, but he could not succeed himself.
New Jersey was one of the few Union states (the others being Delaware and Kentucky) to select a candidate other than Abraham Lincoln twice in national elections, and sided with Stephen Douglas (1860) and George B. McClellan (1864) during their campaigns. McClellan, a native Philadelphian, had New Jersey ties and formally resided in New Jersey at the time; he later became Governor of New Jersey (1878–81). (In New Jersey, the factions of the Democratic party managed an effective coalition in 1860.) During the American Civil War, the state was led first by Republican Governor Charles Smith Olden, then by Democrat Joel Parker. During the course of the war, over 80,000 from the state enlisted in the Northern army; unlike many states, including some Northern ones, no battle was fought there. 
In the Industrial Revolution, cities like Paterson grew and prospered. Previously, the economy had been largely agrarian, which was problematically subject to crop failures and poor soil. This caused a shift to a more industrialized economy, one based on manufactured commodities such as textiles and silk. Inventor Thomas Edison also became an important figure of the Industrial Revolution, having been granted 1,093 patents, many of which for inventions he developed while working in New Jersey. Edison's facilities, first at Menlo Park and then in West Orange, are considered perhaps the first research centers in the U.S. Christie Street in Menlo Park was the first thoroughfare in the world to have electric lighting. Transportation was greatly improved as locomotion and steamboats were introduced to New Jersey.
Iron mining was also a leading industry during the middle to late 19th century. Bog iron pits in the southern New Jersey Pinelands were among the first sources of iron for the new nation. Mines such as Mt. Hope, Mine Hill and the Rockaway Valley Mines created a thriving industry. Mining generated the impetus for new towns and was one of the driving forces behind the need for the Morris Canal. Zinc mines were also a major industry, especially the Sterling Hill Mine.
20th century.
Through both World Wars, New Jersey was a center for war production, especially in naval construction. Battleships, cruisers, and destroyers were all made in this state. New Jersey manufactured 6.8 percent of total United States military armaments produced during World War II, ranking fifth among the 48 states. In addition, Fort Dix (1917) (originally called "Camp Dix"), Camp Merritt (1917) and Camp Kilmer (1941) were all constructed to house and train American soldiers through both World Wars. New Jersey also became a principal location for defense in the Cold War. Fourteen Nike Missile stations were constructed, especially for the defense of New York City and Philadelphia, Pennsylvania. "PT-109", a motor torpedo boat commanded by Lt. (j.g.) John F. Kennedy in World War II, was built at the Elco Boatworks in Bayonne. The aircraft carrier USS Enterprise (CV-6) was briefly docked at the Military Ocean Terminal in Bayonne in the 1950s before she was sent to Kearney to be scrapped. In 1962, the world's first nuclear-powered cargo ship, the NS Savannah, was launched at Camden.
New Jersey prospered through the Roaring Twenties. The first Miss America Pageant was held in 1921 in Atlantic City, the Holland Tunnel connecting Jersey City to Manhattan opened in 1927, and the first drive-in movie was shown in 1933 in Camden. During the Great Depression of the 1930s, the state offered begging licenses to unemployed residents, the zeppelin airship Hindenburg crashed in flames over Lakehurst, and the SS "Morro Castle" beached itself near Asbury Park after going up in flames while at sea.
In 1951, the New Jersey Turnpike opened, permitting fast travel by car and truck between North Jersey (and metropolitan New York) and South Jersey (and metropolitan Philadelphia).
In the 1960s, race riots erupted in many of the industrial cities of North Jersey. The first race riots in New Jersey occurred in Jersey City on August 2, 1964. Several others ensued in 1967, in Newark and Plainfield. Other riots followed the assassination of Dr. Martin Luther King, Jr. in April 1968, just as in the rest of the country. A riot occurred in Camden in 1971.
As a result of an order from the New Jersey Supreme Court to fund schools equitably, the New Jersey legislature passed an income tax bill in 1976. Prior to this bill, the state had no income tax.
21st century.
In the early part of the 2000s, two light rail systems were opened: the Hudson–Bergen Light Rail in Hudson County and the River Line between Camden and Trenton. The intent of these projects were to encourage transit-oriented development in North Jersey and South Jersey, respectively. The HBLR in particular was credited with a revitalization of Hudson County and Jersey City in particular. Urban revitalization has continued in North Jersey in the 21st century. Jersey City continued to grow. In 2010 Newark experienced its first population increase since the 1950s.
Geography.
New Jersey is bordered on the north and northeast by New York (parts of which are across the Hudson River, Upper New York Bay, the Kill Van Kull, Newark Bay, and the Arthur Kill); on the east by the Atlantic Ocean; on the southwest by Delaware across Delaware Bay; and on the west by Pennsylvania across the Delaware River.
New Jersey can be thought of as five regions, based on natural geography and population. Northeastern New Jersey, the Gateway Region, lies closest to Manhattan in New York City, and many residents commute into the city to work. Northwestern New Jersey, or the "Skylands", is, compared to the northeast, more wooded, rural, and mountainous. The "Shore", along the Atlantic Coast in the central-east and southeast, has its own natural, residential, and lifestyle characteristics owing to its location by the ocean. The Delaware Valley includes the southwestern counties of the state, which reside within the Philadelphia Metropolitan Area. The fifth region is the Pine Barrens in the interior of the southern part. Covered rather extensively by mixed pine and oak forest, it has a much lower population density than much of the rest of the state.
New Jersey also can be broadly divided into three geographic regions: North Jersey, Central Jersey, and South Jersey. Some New Jersey residents do not consider Central Jersey a region in its own right, but others believe it is a separate geographic and cultural area from the North and South.
The federal Office of Management and Budget divides New Jersey's counties into seven Metropolitan Statistical Areas, including sixteen counties in the New York City or Philadelphia metro areas. Four counties have independent metro areas, and Warren County is part of the Pennsylvania-based Lehigh Valley metro area. (See Metropolitan Statistical Areas of New Jersey for details.)
It is also at the center of the Northeast megalopolis.
Additionally, the New Jersey Commerce, Economic Growth, & Tourism Commission divides the state into six distinct regions to facilitate the state's tourism industry. The regions are:
High Point, in Montague Township, Sussex County, is the highest elevation, at 1803 ft. The Palisades are a line of steep cliffs on the lower west side of the Hudson River, in Bergen County and Hudson County.
Major rivers include the Hudson, Delaware, Raritan, Passaic, Hackensack, Rahway, Musconetcong, Mullica, Rancocas, Manasquan, Maurice, and Toms rivers.
Sandy Hook, along the eastern coast, is a popular recreational beach. It is a barrier spit and an extension of the Barnegat Peninsula along the state's Atlantic Ocean coast.
Long Beach Island ("LBI"), a barrier island along the eastern coast, has popular recreational beaches. The primary access point to the island is by a single bridge connection to the mainland. Barnegat Lighthouse is on the northern tip.
Areas managed by the National Park Service include:
Prominent geographic features include:
Climate.
There are two climatic conditions in the state. The south, central, and northeast parts of the state have a humid mesothermal climate, while the northwest has a humid continental climate (microthermal), with much cooler temperatures due to higher elevation. New Jersey receives between 2,400 and 2,800 hours of sunshine annually.
Summers are typically hot and humid, with statewide average high temperatures of 82 - and lows of 60 -; however, temperatures exceed 90 °F on average 25 days each summer, exceeding 100 °F in some years. Winters are usually cold, with average high temperatures of 34 - and lows of 16 to 28 °F (−9 to −2 °C) for most of the state, but temperatures could, for brief interludes, fall below 10 °F and occasionally rise above 50 °F. Northwestern parts of the state have significantly colder winters with sub-0 °F being an almost annual occurrence. Spring and autumn may feature wide temperature variations, with lower humidity than summer. The USDA Plant Hardiness Zone classification ranges from 6 in the northwest of the state, to between 7B and 8A near Cape May. All-time temperature extremes recorded in New Jersey include 110 °F on July 10, 1936 in Runyon and -34 °F on January 5, 1904 in River Vale.
Average annual precipitation ranges from 43 to, uniformly spread through the year. Average snowfall per winter season ranges from 10 - in the south and near the seacoast, 15 - in the northeast and central part of the state, to about 40 - in the northwestern highlands, but this often varies considerably from year to year. Precipitation falls on an average of 120 days a year, with 25 to 30 thunderstorms, most of which occur during the summer.
During winter and early spring, New Jersey can experience "nor'easters", which are capable of causing blizzards or flooding throughout the northeastern United States. Hurricanes and tropical storms (such as Tropical Storm Floyd in 1999), tornadoes, and earthquakes are rare, although New Jersey was severely impacted by Hurricane Sandy on October 29, 2012 with the storm making landfall in the state at 90 mph.
Demographics.
State population.
The United States Census Bureau estimates that the population of New Jersey was 8,938,175 on July 1, 2014, a 1.66% increase since the 2010 United States Census. Residents of New Jersey are most commonly referred to as "New Jerseyans" or, less commonly, as "New Jerseyites". As of the 2010 census, there were 8,791,894 people residing in the state. The racial makeup of the state was:
17.7% of the population were Hispanic or Latino (of any race).
Non-Hispanic Whites were 58.9% of the population in 2011, down from 85% in 1970.
In 2010, undocumented immigrants constituted an estimated 6.4% of the population. This was the fourth highest percentage of any state in the country. There were an estimated 550,000 illegal immigrants in the state in 2010.
The United States Census Bureau, as of 1, 2014[ [update]], estimated New Jersey's population at 8,938,175, which represents an increase of 146,281, or 1.66%, since the last census in 2010. This includes a natural increase since the last census of 343,965 people (that is, 933,185 births minus 589,220 deaths) and a decrease due to net migration of 53,930 people out of the state. Immigration from outside the United States resulted in a net increase of 384,687 people, and migration within the country produced a net loss of 438,617 people. s of 2005[ [update]], there were 1.6 million foreign-born living in the state (accounting for 19.2% of the population).
As of 2010, New Jersey is the eleventh-most populous state in the United States, and the most densely populated, at 1,185 residents per square mile (458 per km2), with most of the population residing in the counties surrounding New York City, Philadelphia, and along the eastern Jersey Shore, while the extreme southern and northwestern counties are relatively less dense overall. It is also the second wealthiest state according to the U.S. Census Bureau.
The center of population for New Jersey is located in Middlesex County, in the town of Milltown, just east of the New Jersey Turnpike.
New Jersey is home to more scientists and engineers "per square mile" than anywhere else in the world.
On October 21, 2013, same-sex marriages commenced in New Jersey.
New Jersey is one of the most ethnically and religiously diverse states in the country. As of 2011, 56.4% of New Jersey's children under the age of one belonged to racial or ethnic minority groups, meaning that they had at least one parent who was not non-Hispanic white. It has the second largest Jewish population by percentage (after New York); the second largest Muslim population by percentage (after Michigan); the largest population of Peruvian Americans in the United States; the largest population of Cubans outside of Florida; the third highest Asian population by percentage; and the third highest Italian population by percentage, according to the 2000 Census. African Americans, Hispanics, Arabs, and Brazilian and Portuguese Americans are also high in number. New Jersey has the third highest Asian Indian population of any state by absolute numbers. It has the third largest Korean population, fourth largest Filipino population, and fourth largest Chinese population, per the 2010 U.S. Census. The five largest ethnic groups in 2000 were: Italian (17.9%), Irish (15.9%), African (13.6%), German (12.6%), Polish (6.9%).
Newark was the fourth poorest of U.S. cities with over 250,000 residents in 2008, but New Jersey as a whole has the second highest median household income. This is largely because so much of New Jersey consists of suburbs, most of them affluent, of New York City and Philadelphia. New Jersey is also the most densely populated state, and the only state that has had every one of its counties deemed "urban" as defined by the Census Bureau's Combined Statistical Area.
In 2010, 6.2% of its population was reported as under age 5, 23.5% under 18, and 13.5% were 65 or older; and females made up approximately 51.3% of the population.
Languages.
As of 2010, 71.31% (5,830,812) of New Jersey residents age 5 and older spoke English at home as a primary language, while 14.59% (1,193,261) spoke Spanish, 1.23% (100,217) Chinese (which includes Cantonese and Mandarin), 1.06% (86,849) Italian, 1.06% (86,486) Portuguese, 0.96% (78,627) Tagalog, and Korean was spoken as a main language by 0.89% (73,057) of the population over the age of five. In total, 28.69% (2,345,644) of New Jersey's population age 5 and older spoke a mother language other than English.
A diverse collection of languages has since evolved amongst the state's population, given that New Jersey has become cosmopolitan and is home to ethnic enclaves of non-English-speaking communities:
Religion.
 *Less than 0.5%
By number of adherents, the largest denominations in New Jersey according to the Association of Religion Data Archives in 2010 were the Roman Catholic Church with 3,235,290; Islam with 160,666; and the United Methodist Church with 138,052.
Major cities.
For its overall population and nation-leading population density, New Jersey has a relative paucity of classic large cities. Many urban areas extend far beyond the limits of a single large city, as New Jersey cities (and indeed municipalities in general) tend to be geographically small; three of the four largest cities in New Jersey by population have under 20 square miles of land area, and eight of the top ten, including all of the top five have land area under 30 square miles. As of the United States 2010 Census[ [update]], only four municipalities had populations in excess of 100,000, although Edison and Woodbridge came very close.
Economy.
The Bureau of Economic Analysis estimates that New Jersey's gross state product in 2010 was $487 billion. s of 2012[ [update]], the state's unemployment rate is 9%, with the highest unemployment rate for military veterans in the country at 10.8 percent. New Jersey's estimated taxpayer burden in 2011 was $37,000 per taxpayer, 49th in the nation.
Affluence.
New Jersey's per capita gross state product in 2008 was $54,699, second in the U.S. and above the national per capita gross domestic product of $46,588. Its per capita income was the third highest in the nation with $51,358. In 2013, the state had the second-largest number of millionaires per capita in the United States (ratio of 7.49%), according to a study by Phoenix Marketing International. It is ranked 2nd in the nation by the number of places with per capita incomes above national average with 76.4%. Nine of New Jersey's counties are in the wealthiest 100 of the country.
Fiscal policy.
New Jersey has seven tax brackets that determine state income tax rates, which range from 1.4% to 8.97%. The standard sales tax rate is 7%, applicable to all retail sales unless specifically exempt by law. Tax exemptions include most food items for at-home preparation, medications, clothing (except fur items), footwear, and disposable paper products for use in the home. Approximately 30 New Jersey municipalities are designated as Urban Enterprise Zones, in which shoppers are charged a 3½% sales tax rate, half of the rate charged outside the UEZs. Sections of Paterson, Elizabeth, and Jersey City are examples of communities that are subject to the lower sales tax rate.
New Jersey has the highest cumulative tax rate of all 50 states with residents paying a total of $68 billion in state and local taxes annually with a per capita burden of $7,816 at a rate of 12.9% of income. All real property located in the state is subject to property tax unless specifically exempted by statute. New Jersey does not assess an intangible personal property tax, but it does impose an inheritance tax.
Federal taxation disparity.
New Jersey consistently ranks as having one of the highest proportional levels of disparity of any state in the United States based upon what it receives from the federal government relative to what it gives. In 2015, WalletHub ranked New Jersey the state least dependent upon federal government aid overall and having the fourth lowest return on taxpayer investment from the federal government, at 48 cents per dollar.
New Jersey has one of the highest tax burdens in the nation. Factors for this include the large federal tax liability which is not adjusted for New Jersey's higher cost of living and Medicaid funding formulas. As shown by the study, incomes tend to be higher in New Jersey, which puts those in higher tax brackets especially vulnerable to the alternative minimum tax.
Industries.
New Jersey's economy is multifaceted but is nevertheless centered upon the pharmaceutical industry, the financial industry, chemical development, telecommunications, food processing, electric equipment, printing, publishing, and tourism. New Jersey's agricultural outputs are nursery stock, horses, vegetables, fruits and nuts, seafood, and dairy products. New Jersey ranks second among states in blueberry production, third in cranberries and spinach, and fourth in bell peppers, peaches, and head lettuce. New Jersey harvests the fourth-largest number of acres planted with asparagus.
Although New Jersey is home to many energy-intensive industries, its energy consumption is only 2.7% of the U.S. total, and its carbon dioxide emissions are 0.8% of the U.S. total. Its comparatively low greenhouse gas emissions can be attributed to nuclear power. According to the Energy Information Administration, nuclear power dominates New Jersey's electricity market, typically supplying more than one-half of State generation. New Jersey has three nuclear power plants, including the Oyster Creek Nuclear Generating Station, which came online in 1969 and is the oldest operating nuclear plant in the country.
New Jersey has a strong scientific economy and is home to major pharmaceutical and telecommunications firms. There is also a strong service economy in New Jersey serving residents who work in New York City or Philadelphia in retail sales, education, and real estate. Furthermore, New Jersey draws upon its large and well-educated labor pool, which also supports the myriad of industries that exists today.
Shipping is a strong industry in New Jersey because of the state's strategic location, the Port of New York and New Jersey the busiest on the East Coast. The Port Newark-Elizabeth Marine Terminal was the world's first container port and is one of the world's largest container ports. New Jersey also has a strong presence in chemical development, refining, and food processing operations.
New Jersey hosts several business headquarters, including twenty-four Fortune 500 companies. Paramus in Bergen County has become the top retail zip code in the United States, with the municipality generating over $5 billion in annual retail sales. Several New Jersey counties such as Somerset (7), Morris (10), Hunterdon (13), Bergen (21), Monmouth (42) counties are ranked among the highest-income counties in the United States. Four others are also in the top 100.
Tourism.
New Jersey's location as a crossroads of commerce and its extensive transportation system have put over one third of all United States residents and many Canadian residents within overnight distance by land. This accessibility to consumer revenue has enabled seaside resorts such as Atlantic City and the remainder of the Jersey Shore, as well as the state's other natural and cultural attractions, to contribute significantly to New Jersey's record tourism revenue of $40.3 billion and 87.2 million tourist visitations in 2013.
Gambling.
In 1976, a referendum of New Jersey voters approved casino gambling in Atlantic City, where the first legalized casino opened in 1978. At that time, Las Vegas was the only mega-casino resort. Several casinos lie along the Atlantic City Boardwalk, the first and longest boardwalk in the world. On February 26, 2013, Governor Chris Christie signed online gambling into law. Atlantic City experienced a dramatic contraction in its stature as a gambling destination after 2010, including the closure of multiple casinos in 2014, spurred by competition from the advent of legalized gambling in other northeastern U.S. states.
Natural resources.
Forests cover 45%, or approximately 2.1 million acres, of New Jersey's land area. The chief tree of the northern forests is the oak. The Pine Barrens, consisting of pine forests, are in the southern part of the state.
Some mining activity of zinc, iron, and manganese still takes place in the area in and around the Franklin Furnace.
New Jersey is second in the nation in solar power installations, enabled by one of the country's most favorable net metering policies, and the renewable energy certificates program. The state has more than 10,000 solar installations.
Education.
In 2010, there were 605 school districts in the state.
Secretary of Education Rick Rosenberg, appointed by Governor Jon Corzine, created the Education Advancement Initiative (EAI) to increase college admission rates by 10% for New Jersey's high school students, decrease dropout rates by 15%, and increase the amount of money devoted to schools by 10%. Rosenberg retracted this plan when criticized for taking the money out of healthcare to fund this initiative.
In 2010 the state government paid all of the teachers' premiums for health insurance, but currently all NJ public teachers pay a portion of their own health insurance premiums.
Census data reveal that New Jersey spent more per each public school student than any other state except New York in 2009, amounting to $16,271 spent per pupil, with 41% of the revenue derived from state sources.
According to 2011 "Newsweek" statistics, students of High Technology High School in Lincroft, Monmouth County and Bergen County Academies in Hackensack, Bergen County registered average SAT scores of 2145 and 2100, respectively, representing the highest and second-highest scores, respectively, of all listed U.S. high schools.
Princeton University in Princeton, Mercer County, was ranked the top U.S. national university of 2015 per "U.S. News & World Report". In 2013, Rutgers University gained medical and dental schools intended to augment its profile as a national research university.
In 2014, New Jersey's school systems were ranked at the top of all fifty U.S. states by financial website Wallethub.com.
Media and communication.
Newspapers.
Major New Jersey newspapers including the following:
On-line news.
Since 2006 there have been a growing number of hyperlocal news sites. These sites provide relevant news for their respective communities.
Television and film.
Motion picture technology was developed by Thomas Edison, with much of his early work done at his West Orange laboratory. Edison's Black Maria was the first motion picture studio. America's first motion picture industry started in 1907 in Fort Lee and the first studio was constructed there in 1909. DuMont Laboratories in Passaic, developed early sets and made the first broadcast to the private home.
A number of television shows and films have been filmed in New Jersey. Since 1978, the state has maintained a Motion Picture and Television Commission to encourage filming in-state. New Jersey has long offered tax credits to television producers. Governor Chris Christie suspended the credits in 2010, but the New Jersey State Legislature in 2011 approved the restoration and expansion of the tax credit program. Under bills passed by both the state Senate and Assembly, the program offers 20 percent tax credits (22% in urban enterprise zones) to television and film productions that shoot in the state and meet set standards for hiring and local spending.
Transportation.
Roadways.
The New Jersey Turnpike is one of the most prominent and heavily traveled roadways in the United States. This toll road carries interstate traffic between Delaware and New York, and the East Coast in general. Commonly referred to as simply "the Turnpike," it is known for its numerous rest-areas named after prominent New Jerseyans as diverse as inventor Thomas Edison; United States Secretary of the Treasury Alexander Hamilton; United States Presidents Grover Cleveland and Woodrow Wilson; writers James Fenimore Cooper, Joyce Kilmer, and Walt Whitman; patriot Molly Pitcher; Red Cross founder Clara Barton; and football coach Vince Lombardi.
The Garden State Parkway, or simply "the Parkway," carries relatively more in-state traffic than interstate traffic and runs from the town of Montvale along New Jersey's northern border to its southernmost tip at Cape May for 172.4 mi. It is the trunk that connects the New York metropolitan area to Atlantic City and is consistently one of the safest roads in the nation. With a total of 15 travel and 6 shoulder lanes, the Driscoll Bridge on the Parkway, spanning the Raritan River in Middlesex County, is the widest motor vehicle bridge in the world by number of lanes as well as one of the busiest.
New Jersey is connected to New York City via various bridges and tunnels. The double-decked George Washington Bridge carries the heaviest load of motor vehicle traffic of any bridge in the world, at 102 million vehicles per year, over fourteen lanes, from Fort Lee, New Jersey in Bergen County across the Hudson River to the Trans-Manhattan Expressway in the Washington Heights neighborhood of Upper Manhattan in New York City; Interstate 95 and U.S. Route 1/9 cross the Hudson River via the "GWB", while U.S. Route 46, which lies entirely within New Jersey, ends halfway across the bridge at the state border with New York. The Lincoln Tunnel connects to Midtown Manhattan carrying New Jersey State Route 495 and the Holland Tunnel connects to Lower Manhattan carrying I-78. These are the three major Hudson River crossings that see heavy vehicular traffic. New Jersey is also connected to Staten Island by three bridges — from south to north: the Outerbridge Crossing, Goethals Bridge, and Bayonne Bridge.
Other expressways in New Jersey include the Atlantic City Expressway, the Palisades Interstate Parkway, Interstate 76, Interstate 78, Interstate 80, Interstate 95, Interstate 195, Interstate 278, Interstate 280, Interstate 287, Interstate 295, and Interstate 676. Other major roadways include U.S. 1, New Jersey Route 4, U.S. 9, New Jersey Route 10, and New Jersey Route 17.
New Jersey has interstate compacts with all three neighboring states. The Port Authority of New York and New Jersey, the Delaware River Port Authority (with Pennsylvania), and the Delaware River and Bay Authority (with Delaware) operate most of the major transportation routes into and out of New Jersey. Bridge tolls are collected in one direction only – it is free to cross into New Jersey, but motorists must pay when exiting the state. Exceptions to this are the Dingman's Ferry Bridge and the Delaware River – Turnpike Toll Bridge where tolls are charged both ways. The Washington Crossing and Scudders Falls (on I-95) bridges near Trenton, as well as Trenton's Calhoun Street and Bridge Street ("Trenton Makes") bridges, are toll-free. In addition, * Riverton-Belvidere Bridge, Northampton Street Bridge, Riegelsville Bridge, and Upper Black Eddy-Milford Bridge are free Delaware River bridges into and out of NJ.
New Jersey is one of only two states (along with Oregon) where all fuel dispensing stations are required to sell gasoline full-service to customers. It is unlawful for a customer to serve himself/herself.
Airports.
Newark Liberty International Airport is one of the busiest airports in the United States. Operated by the Port Authority of New York and New Jersey, which runs the other two major airports in the New York metropolitan area (John F. Kennedy International Airport and LaGuardia Airport), it is one of the main airports serving the New York City area. United Airlines is the facility's largest tenant, operating an entire terminal at Newark, which it uses as one of its primary hubs. FedEx Express operates a large cargo hub. The adjacent Newark Airport railroad station provides access to the trains of Amtrak and New Jersey Transit along the Northeast Corridor Line.
Two smaller commercial airports, Atlantic City International Airport and Trenton-Mercer Airport, also operate in other parts of New Jersey. Teterboro Airport, in Bergen County, is a general aviation airport popular with private and corporate aircraft, due to its proximity to New York City. Millville Municipal Airport, in Cumberland County, is a general aviation airport popular with private and corporate aircraft, due to its proximity to the shore.
Rail and bus.
The New Jersey Transit Corporation (NJ Transit) operates extensive rail and bus service throughout the state. NJ Transit is a state-run corporation that began with the consolidation of several private bus companies in North Jersey. In the early 1980s, it acquired the commuter train operations of Conrail that connect towns in northern and central New Jersey to New York City. NJ Transit has eleven lines that run throughout different parts of the state. Most of the trains start at various points in the state and most end at either Pennsylvania Station, in New York City, or Hoboken Terminal in Hoboken. NJ Transit began service between Atlantic City and Lindenwold in 1989 and extended it to Philadelphia, Pennsylvania, in the 1990s.
NJ Transit also operates three light rail systems in the state. The Hudson-Bergen Light Rail connects Bayonne to North Bergen, with planned expansion into Bergen County communities. The Newark Light Rail is partially underground, and connects downtown Newark with other parts of the city. The River Line connects Trenton and Camden.
The PATH is a subway and above-ground railway which links Hoboken, Jersey City, Harrison and Newark with New York City. The PATH operates four lines that connect various points in North Jersey and New York. The lines all terminate in Hudson County, Essex County or Manhattan in New York City.
The PATCO High Speedline links Camden County and Philadelphia. PATCO operates a single elevated and subway line that runs from Lindenwold to Center City Philadelphia. PATCO operates stations in Lindenwold, Voorhees, Cherry Hill, Haddonfield, Haddon Township, Collingswood, and Camden, along with four stations in Philadelphia.
Amtrak also operates numerous long-distance passenger trains in New Jersey to and from neighboring states and around the country. In addition to the Newark Airport connection, other major Amtrak railway stations include Trenton Rail Station, Metropark, and the grand historic Newark Penn Station.
SEPTA also has two lines that operate into New Jersey. The Trenton Line terminates at the Trenton Transit Center, and the West Trenton Line terminates at the West Trenton Rail Station in Ewing.
AirTrain Newark is a monorail connecting the Amtrak/NJ Transit station on the Northeast Corridor to the airport's terminals and parking lots.
Some private bus carriers still remain in New Jersey. Most of these carriers operate with state funding to offset losses and state owned buses are provided to these carriers of which Coach USA companies make up the bulk. Other carriers include private charter and tour bus operators that take gamblers from other parts of New Jersey, New York City, Philadelphia, and Delaware to the casino resorts of Atlantic City.
Ferries.
On the Delaware Bay, the Delaware River and Bay Authority operates the Cape May-Lewes Ferry. The agency also operates the Delaware City–Salem Ferry for passengers across the Delaware River. The Delaware River Port Authority operates the RiverLink Ferry between the Camden waterfront and Penn's Landing in Philadelphia, Pennsylvania.
In the Port of New York and New Jersey, New York Waterway has ferry terminals at Belford Harbor, Jersey City, Hoboken and Weehawken, and Edgewater Landing. There are slips at Port Liberte, Liberty Harbor, Exchange Place in Jersey City, Port Imperial and Lincoln Harbor in Weehawken, Hoboken Terminal and 14th Street in Hoboken. Manhattan terminals are located at Wall Street/Pier 11, Battery Park City (BPC) or West Midtown Ferry Terminal. Liberty Water Taxi in Jersey City has ferries from Paulus Hook and Liberty State Park to (BPC). Statue Cruises has service from Liberty State Park and Statue of Liberty National Monument, including Ellis Island. (Although there is a bridge from Ellis Island to the park built for renovations on the island it is not open for public use.) SeaStreak offers services from the Raritan Bayshore to Manhattan and during the Met's season to Shea Stadium. The ferries on leave from Atlantic Highlands and two terminals in Highlands. Ferry service from Keyport and Perth Amboy have been also been proposed. Service from Elizabeth at Newark Bay is proposed in conjunction with re-development plans on the shore near Jersey Gardens.
Private bus carriers.
Several private bus lines provide transportation service in the state of New Jersey. Below is a list of major carriers and their areas of operation:
Governance.
Executive.
The position of Governor of New Jersey has been considered one of the most powerful in the nation. Until 2010 the governor was the only statewide elected office in the state appointed numerous government officials. Formerly, an Acting Governor was even more powerful as he simultaneously served as President of the New Jersey State Senate, thus directing half of the legislative and all of the executive process. In 2002 and 2007, President of the State Senate Richard Codey held the position of Acting Governor for a short time, and from 2004 to 2006 Codey became a long-term Acting Governor due to Jim McGreevey's resignation. A 2005 amendment to the state Constitution prevents the Senate President from becoming Acting Governor in the event of a permanent gubernatorial vacancy without giving up her or his seat in the state Senate. Chris Christie (Republican) is the Governor.
The governor's mansion is Drumthwacket, located in Princeton.
Before 2010, New Jersey was one of the few states without a lieutenant governor. Republican Kim Guadagno was elected the first Lieutenant Governor of New Jersey and took office on January 19, 2010. She was elected on the Republican ticket with Governor-Elect Chris Christie in the November 2009 NJ gubernatorial election. The position was created as the result of a Constitutional amendment to the New Jersey State Constitution passed by the voters on November 8, 2005 and effective as of January 17, 2006.
Legislative.
The current version of the New Jersey State Constitution was adopted in 1947. It provides for a bicameral New Jersey Legislature, consisting of an upper house Senate of 40 members and a lower house General Assembly of 80 members. Each of the 40 legislative districts elects one State Senator and two Assembly members. Assembly members are elected for a two-year term in all odd-numbered years; State Senators are elected in the years ending in 1, 3, and 7 and thus serve either four- or two-year terms.
New Jersey is one of only five states that elects its state officials in odd-numbered years. (The others are Kentucky, Louisiana, Mississippi, and Virginia.) New Jersey holds elections for these offices every four years, in the year following each federal Presidential election year. Thus, the last year when New Jersey elected a Governor was 2013; the next gubernatorial election will occur in 2017, with future gubernatorial elections to take place in 2021, 2025, 2029, etc.
Judicial.
The New Jersey Supreme Court consists of a Chief Justice and six Associate Justices. All are appointed by the Governor with the advice and consent of a majority of the membership of the State Senate. Justices serve an initial seven-year term, after which they can be reappointed to serve until age 70.
Most of the day-to-day work in the New Jersey courts is carried out in the Municipal Courts, where simple traffic tickets, minor criminal offenses, and small civil matters are heard.
More serious criminal and civil cases are handled by the Superior Court for each county. All Superior Court judges are appointed by the Governor with the advice and consent of a majority of the membership of the State Senate. Each judge serves an initial seven-year term, after which he or she can be reappointed to serve until age 70.
New Jersey's judiciary is unusual in that it still has separate courts of law and equity, like its neighbor Delaware but unlike most other U.S. states. The New Jersey Superior Court is divided into Law and Chancery Divisions at the trial level.
The Superior Court also has an Appellate Division, which functions as the state's intermediate appellate court. Superior Court judges are assigned to the Appellate Division by the Chief Justice.
There is also a Tax Court, which is a court of limited jurisdiction. Tax Court judges hear appeals of tax decisions made by County Boards of Taxation. They also hear appeals on decisions made by the Director of the Division of Taxation on such matters as state income, sales and business taxes, and homestead rebates. Appeals from Tax Court decisions are heard in the Appellate Division of Superior Court. Tax Court judges are appointed by the Governor for initial terms of seven years, and upon reappointment are granted tenure until they reach the mandatory retirement age of 70. There are 12 Tax Court judgeships.
Counties.
New Jersey is divided into 21 counties; 13 date from the colonial era. New Jersey was completely divided into counties by 1692; the present counties were created by dividing the existing ones; most recently Union County in 1857. New Jersey is the only state in the nation where elected county officials are called "Freeholders," governing each county as part of its own Board of Chosen Freeholders. The number of freeholders in each county is determined by referendum, and must consist of three, five, seven or nine members.
Depending on the county, the executive and legislative functions may be performed by the Board of Chosen Freeholders or split into separate branches of government. In 16 counties, members of the Board of Chosen Freeholders perform both legislative and executive functions on a commission basis, with each Freeholder assigned responsibility for a department or group of departments. In the other 5 counties (Atlantic, Bergen, Essex, Hudson and Mercer), there is a directly elected County Executive who performs the executive functions while the Board of Chosen Freeholders retains a legislative and oversight role. In counties without an Executive, a County Administrator (or County Manager) may be hired to perform day-to-day administration of county functions.
Municipalities.
New Jersey has 565 municipalities; the number was 566 before Princeton Township and Princeton Borough merged to form the municipality of Princeton on January 1, 2013. Unlike states in the west and south, all New Jersey land is part of a municipality. In 2008, Governor Jon Corzine proposed cutting state aid to all towns under 10,000 people, to encourage mergers to reduce administrative costs. In May 2009, the Local Unit Alignment Reorganization and Consolidation Commission (LUARC) began a study of about 40 small communities in South Jersey to decide which ones might be good candidates for consolidation.
Types of government.
When the types of government were devised in the 19th century, the intention was that cities would be large built-up areas, with progressively smaller boroughs, towns, and villages; the rural areas in between would be relatively large townships. This is still often true, although Shrewsbury Township has been divided over the years; today it is less than a square mile, consisting only of a single housing development. Some townships – notably Brick, Hamilton, Middletown, and Toms River – have, without changing their boundaries, become large stretches of suburbia, as populous as cities, often focused around shopping centers and highways rather than traditional downtowns and main streets.
Short Hills, Murray Hill, and many other locations in New Jersey are not municipalities but rather neighborhoods, with no exact boundaries. Often the cluster of houses, the traditional neighborhood, the postal district, and the census-designated place will differ.
Forms of government.
The five types of municipality differ mostly in name. Originally, each type had its own form of government but more modern forms are available to any municipality, even though the original type is retained in its formal name. Only boroughs can (but are not required to) have the "borough form" of government.
Starting in the 20th century, largely driven by reform-minded goals, a series of six modern forms of government was implemented. This began with the Walsh Act, enacted in 1911 by the New Jersey Legislature, which provided for a 3- or 5-member commission elected on a non-partisan basis. This was followed by the 1923 Municipal Manager Law, which offered a non-partisan council, provided for a weak mayor elected by and from the members of the council, and introduced a Council-Manager government structure with an appointed manager responsible for day-to-day administration of municipal affairs.
The Faulkner Act, originally enacted in 1950 and substantially amended in 1981, offers four basic plans: Mayor-Council, Council-Manager, Small Municipality, and Mayor-Council-Administrator. The act provides many choices for communities with a preference for a strong executive and professional management of municipal affairs and offers great flexibility in allowing municipalities to select the characteristics of its government: the number of seats on the Council; seats selected at-large, by wards, or through a combination of both; staggered or concurrent terms of office; and a mayor chosen by the Council or elected directly by voters. Most large municipalities and a majority of New Jersey's residents are governed by municipalities with Faulkner Act charters. Municipalities can also formulate their own unique form of government and operate under a Special Charter with the approval of the New Jersey Legislature.
While municipalities retain their names derived from types of government, they may have changed to one of the modern forms of government, or further in the past to one of the other traditional forms, leading to municipalities with formal names quite baffling to the general public. For example, though there are four municipalities that are officially of the village type, Loch Arbour is the only one remaining with the village form of government. The other three villages – Ridgefield Park (now with a Walsh Act form), Ridgewood (now with a Faulkner Act Council-Manager charter) and South Orange (now operates under a Special Charter) – have all migrated to other non-village forms.
Politics.
Social attitudes and issues.
Socially, New Jersey is considered one of the more liberal states in the nation. Polls indicate that 60% of the population are self-described as pro-choice, although a majority are opposed to late trimester and Partial Birth Abortion and public funding of Abortion. In a 2009 Quinnipiac University Polling Institute poll, a plurality supported same-sex marriage 49% to 43% opposed, while the proportion supporting gay marriage continued to increase thereafter. On October 18, 2013, the New Jersey Supreme Court rendered a provisional, unanimous (7-0 vote) order authorizing same-sex marriage in the state, pending a legal appeal by Governor Chris Christie, who then withdrew this appeal hours after the inaugural same-sex marriages took place on October 21, 2013.
New Jersey also has some of the most stringent gun control laws in the U.S. These include bans on assault firearms, hollow-nose bullets and even slingshots. No gun offense in New Jersey is graded less than a felony. BB guns and black-powder guns are all treated as modern firearms. New Jersey does not recognize out-of-state gun licenses and aggressively enforces its own gun laws.
Elections.
In past elections, New Jersey was a Republican bastion, but recently has become a Democratic stronghold. Currently, New Jersey Democrats have majority control of both houses of the New Jersey Legislature (Senate, 24–16, and Assembly, 47–33), a 6-6 split of the state's twelve seats in the U.S. House of Representatives, and both U.S. Senate seats. Although the Democratic Party is very successful statewide, the state had a Republican governor from 1994 to 2002, as Christie Todd Whitman won twice with 47% and 49% of the votes, and in the 2009 gubernatorial election, Republican Chris Christie defeated incumbent Democrat Jon Corzine with 48%. In the 2013 gubernatorial election, Christie won reelection with over 60% of the votes. Because each candidate for lieutenant governor runs on the same ticket as the party's candidate for governor, the current Governor and Lieutenant Governor are members of the Republican Party. The governor's appointments to cabinet and non-cabinet positions may be from either party; for instance, the Attorney General is a Democrat.
In federal elections, the state leans heavily towards the Democratic Party. For many years in the past, however, it was a Republican stronghold, having given comfortable margins of victory to the Republican candidate in the close elections of 1948, 1968, and 1976. New Jersey was a crucial swing state in the elections of 1960, 1968, and 1992. The last elected Republican to hold a Senate seat from New Jersey was Clifford P. Case in 1979. Newark Mayor Cory Booker was elected in October 2013 to join Robert Menendez to make New Jersey the first state with concurrent serving black and Latino U.S. senators.
The state's Democratic strongholds include Camden County, Essex County (including Newark, the state's largest city), Hudson County (including Jersey City, the state's second-largest city); Mercer County (especially around Trenton and Princeton), Middlesex County, and Union County (including Elizabeth, the state's fourth-largest city).
The suburban northwestern and southeastern counties of the state are reliably Republican: Republicans have support along the coast in Ocean County and in the mountainous northwestern part of the state, especially Morris County, Sussex County, and Warren County. Other suburban counties, especially Bergen County and Burlington County had the majority of votes go to the Democratic Party. In the 2008 election, President Barack Obama won New Jersey with approximately fifty-seven percent of the vote, compared to McCain's forty-one percent. Independent candidate Ralph Nader garnered less than one percent of the vote.
About one-third of the state's counties are considered "swing" counties, but some go more one way than others. For example, Salem County, the same is true with Passaic County, with a highly populated Hispanic Democratic south (including Paterson, the state's third-largest city) and a rural, Republican north. Other "swing" counties like Monmouth County, Somerset County, and Cape May County tend to go Republican, as they also have population in conservative areas.
To be eligible to vote in a U.S. election, all New Jerseyans are required to start their residency in the state 30 days prior to an election and register 29 days prior.
Capital punishment.
On December 17, 2007, Governor Jon Corzine signed into law a bill that would eliminate the death penalty in New Jersey. New Jersey is the first state to pass such legislation since Iowa and West Virginia eliminated executions in 1965. Corzine also signed a bill that would downgrade the Death Row prisoners' sentences from "Death" to "Life in Prison with No Parole."
Points of interest.
Museums.
New Jersey has many museums of all kinds. A few major museums in the state are listed.
Entertainment and concert venues.
Visitors and residents take advantage of and contribute to performances at the numerous music, theater, and dance companies and venues located throughout the state, including:
Theme parks.
Skyline of Six Flags Great Adventure in Jackson Township, Ocean County, the world's largest theme park as of 2013. To the far left is Kingda Ka, the world's tallest roller coaster.
Jersey Shore.
Belmar, on the Jersey Shore.
Sports.
Professional sports.
New Jersey currently has four teams from major professional sports leagues playing in the state, although the Major League Soccer team and two National Football League teams identify themselves as being from New York.
The National Hockey League's New Jersey Devils, based in Newark at the Prudential Center, is the only major league franchise to bear the state's name. The Metropolitan Area's two National Football League teams, the New York Giants and the New York Jets, both play in East Rutherford, Bergen County, at MetLife Stadium. At completion, with a construction cost of approximately $1.6 billion, the venue is the most expensive stadium ever built. On February 2, 2014, MetLife Stadium hosted Super Bowl XLVIII, the first Super Bowl played outdoors in a cold-weather city.
The New York Red Bulls of Major League Soccer play in Red Bull Arena, a soccer-specific stadium located in Harrison outside of downtown Newark.
The sports complex is also home to the Meadowlands Racetrack, one of three major harness racing tracks in the state. The Meadowlands Racetrack along with Freehold Raceway in Freehold are two of the major harness racing tracks in North America. Monmouth Park Racetrack in Oceanport is also a popular spot for thoroughbred racing in New Jersey and the northeast. It hosted the Breeders' Cup in 2007, and its turf course was renovated in preparation.
Additionally, New Jersey is home to two MLB affiliated Minor League Baseball teams: the Trenton Thunder (New York Yankees affiliate) and the Lakewood BlueClaws (Philadelphia Phillies affiliate).
The following table shows the major league sports teams in the state:
College sports.
New Jerseyans' collegiate allegiances are predominately split among the three major NCAA Division I programs in the state – the Rutgers University Scarlet Knights, the Seton Hall University Pirates, and the Princeton University Tigers. Rutgers joined the Big Ten Conference in 2014.
Rutgers and Princeton have an intense rivalry – stemming from the first intercollegiate football game in 1869 – though the two schools have not met on the football field since 1980. They continue to play each other annually in other sports.
Rutgers, which fields 24 teams in various sports, is nationally known for its excellent football and women's basketball programs. The university is planning an expansion to Rutgers Stadium, and the teams play in Piscataway, which is adjacent to the New Brunswick campus. The university also fields rising basketball and baseball programs. Rutgers' fan base is mostly derived from the western parts of the state and Middlesex County, and its alumni base is the largest in the state.
Seton Hall's basketball team has been one of the most storied programs in the Big East, and it plays its home games at the Prudential Center in Newark. The Pirates have support in the predominately Roman Catholic areas of the northern part of the state and the Jersey Shore.
High-school sports.
New Jersey high schools are divided into divisions under the New Jersey State Interscholastic Athletic Association.(NJSIAA) ' Founded in 1918, the NJSIAA currently represents 22,000 schools, 330,000 coaches, and almost 4.5 million athletes. Sports are divided between 3 seasons (fall, winter, and spring).
Culture.
General.
Like every state, New Jersey has its own cuisine, religious communities, museums, and .
New Jersey is the birthplace of modern inventions such as: FM radio, the motion picture camera, the lithium battery, the light bulb, transistors, and the electric train. Other New Jersey creations include: the drive-in movie, the cultivated blueberry, cranberry sauce, the postcard, the boardwalk, the zipper, the phonograph, saltwater taffy, the dirigible, the seedless watermelon, the first use of a submarine in warfare, and the ice cream cone.
There are mineral museums in Franklin and Ogdensburg.
Diners are common in New Jersey. The state is home to many diner manufacturers and has more diners than any other state: over 600. There are more diners in the state of New Jersey than any other place in the world.
New Jersey is the only state without a state song. "I'm From New Jersey" is incorrectly listed on many websites as being the New Jersey State Song, but wasn't even a contender when in 1996 the New Jersey Arts Council submitted their suggestions to the New Jersey Legislature.
Cuisine.
New Jersey is known for several foods developed within the region, including pork roll (or Taylor ham), cheesesteaks, and scrapple.
Credit for the development of submarine sandwiches is claimed by several states with substantial Italian American populations, including New Jersey.
Music.
New Jersey has long been an important area for both rock and rap music. Some prominent musicians from or with significant connections to New Jersey are:

</doc>
<doc id="21649" url="http://en.wikipedia.org/wiki?curid=21649" title="New Mexico">
New Mexico

New Mexico (Spanish: "Nuevo México" ]; Navajo: Yootó Hahoodzo ]) is a state located in the southwestern and western regions of the United States, admitted to the union as the 47th state in 1912. It is usually considered one of the Mountain States. New Mexico is the 5th most extensive, the 36th most populous, and the 6th least densely populated of the 50 United States.
Inhabited by indigenous peoples of the Americas for many centuries before European exploration, New Mexico was subsequently part of the Imperial Spanish viceroyalty of New Spain. Later, it was part of Mexico before becoming a U.S. territory and eventually a U.S. state. Among U.S. states, New Mexico has the highest percentage of Hispanics, including descendants of Spanish colonists who have lived in the area for over 400 years. It also has the second-highest percentage of Native Americans after Alaska, and the fourth-highest total number of Native Americans after California, Oklahoma, and Arizona. The tribes in the state consist of mostly Navajo, Puebloan and the Apache peoples. As a result, the demographics and culture of the state are unique for their strong Hispanic and Native American influences, both of which are reflected in the state flag. The scarlet and gold colors of the New Mexico flag are taken from the royal standards of Spain, along with the ancient sun symbol of the Zia, a Pueblo-related tribe.
New Mexico, or "Nuevo México" in Spanish, is often incorrectly believed to have taken its name from the nation of Mexico. However, New Mexico was given its name in 1563, and again in 1581, by Spanish explorers who believed the area contained wealthy Indian cultures similar to those of the Mexica (Aztec) Empire. Mexico, formerly a part of New Spain, adopted its name centuries later in 1821, after winning independence from Spanish rule. Consequently, New Mexico was only a part of the independent federal republic of Mexico for 12 years, 1836 through 1848. The two developed as neighboring Spanish speaking communities, with relatively independent histories.
Geography.
The state's total area is 121412 sqmi. The eastern border of New Mexico lies along 103° W longitude with the state of Oklahoma, and three miles (5 km) west of 103° W longitude with Texas. On the southern border, Texas makes up the eastern two-thirds, while the Mexican states of Chihuahua and Sonora make up the western third, with Chihuahua making up about 90% of that. The western border with Arizona runs along the 109° 03' W longitude. The southwestern corner of the state is known as the Bootheel. The 37° N latitude parallel forms the northern boundary with Colorado. The states New Mexico, Colorado, Arizona, and Utah come together at the Four Corners in the northwestern corner of New Mexico. New Mexico, although a large state, has little water. Its surface water area is about 250 sqmi.
The New Mexican landscape ranges from wide, rose-colored deserts to broken mesas to high, snow-capped peaks. Despite New Mexico's arid image, heavily forested mountain wildernesses cover a significant portion of the state, especially towards the north. The Sangre de Cristo Mountains, the southernmost part of the Rocky Mountains, run roughly north-south along the east side of the Rio Grande in the rugged, pastoral north. The most important of New Mexico's rivers are the Rio Grande, Pecos, Canadian, San Juan, and Gila. The Rio Grande is tied for the fourth longest river in the U.S.
The U.S. government protects millions of acres of New Mexico as national forests including:
Areas managed by the National Park Service include:
Visitors also frequent the surviving native pueblos of New Mexico. Tourists visiting these sites bring significant money to the state. Other areas of geographical and scenic interest include Kasha-Katuwe Tent Rocks National Monument and the Valles Caldera National Preserve. The Gila Wilderness lies in the southwest of the state.
Climate.
The climate of New Mexico is generally semi-arid to arid, though there are areas of continental and alpine climates, and its territory is mostly covered by mountains, high plains, and desert. The Great Plains (High Plains) are located in the eastern portion of the state, similar to the Colorado high plains in eastern Colorado. The two states share similar terrain, with both having plains, mountains, basins, mesas, and desert lands. New Mexico's average precipitation rate is 13.9 in a year. The average annual temperatures can range from 64 °F in the southeast to below 40 °F in the northern mountains. During the summer months, daytime temperatures can often exceed 100 °F at elevations below 5000 ft, the average high temperature in July ranges from 97 °F at the lower elevations to the upper 70s (°F, up to 26 °C) at the higher elevations. Many cities in New Mexico can have temperature lows in the teens. The highest temperature recorded in New Mexico was 122 °F at the Waste Isolation Pilot Plant near Loving on June 27, 1994 and the lowest recorded temperature is -50 °F at Gavilan on February 1, 1951.
Flora and fauna.
New Mexico contains extensive habitat for many plants and animals, especially in desert areas and piñon-juniper woodlands. Creosote bush, mesquite, cacti, yucca, and desert grasses, including black grama, purple three-awn, tobosa, and burrograss, cover the broad, semiarid plains that cover the southern portion of the state. The northern portion of the state is home to many tree species such as ponderosa pine, aspen, cottonwood, spruce, fir, and Russian olive, which is an invasive species. Native birds include the greater roadrunner ("Geococcyx californianus") and wild turkey ("Meleagris gallopavo"). Other fauna present in New Mexico include black bears, cougars, jaguars, coyotes, porcupines, skunks, Mexican gray wolves, deer, elk, plains bison, collared peccary, bighorn sheep, squirrels, chipmunks, pronghorn, western diamondback, kangaroo rat, jackrabbit and a multitude of other birds, reptiles, and rodents. The black bear native to New Mexico, "Ursus americanus amblyceps", was formally adopted as the state's official animal in 1953.
History.
The first known inhabitants of New Mexico were members of the Clovis culture of Paleo-Indians.:19
Later inhabitants include American Indians of the Mogollon and Ancestral Pueblo peoples cultures.:52
By the time of European contact in the 16th century, the region was settled by the villages of the Pueblo peoples and groups of Navajo, Apache and Ute.:6,48
Francisco Vásquez de Coronado assembled an enormous expedition at Compostela in 1540–1542 to explore and find the mystical Seven Golden Cities of Cibola as described by Fray Marcos de Niza.:19–24 The name "Nuevo México" was first used by a seeker of gold mines named Francisco de Ibarra who explored far to the north of Mexico in 1563 and reported his findings as being in "a New Mexico". Juan de Oñate officially established the name when he was appointed the first governor of the new Province of New Mexico in 1598.:36–37 The same year he founded the San Juan de los Caballeros colony, the first permanent European settlement in the future state of New Mexico,
on the Rio Grande near Ohkay Owingeh Pueblo.:37 Oñate extended El Camino Real de Tierra Adentro, "Royal Road of the Interior," by 700 mi from Santa Bárbara, Chihuahua to his remote colony.:49
The settlement of Santa Fe was established at the foot of the Sangre de Cristo Mountains, the southernmost subrange of the Rocky Mountains, around 1608.:182 The city, along with most of the settled areas of the state, was abandoned by the Spanish for 12 years (1680–1692) as a result of the successful Pueblo Revolt. After the death of the Pueblo leader Popé, Diego de Vargas restored the area to Spanish rule.:68–75 While developing Santa Fe as a trade center, the returning settlers founded Albuquerque in 1706 from existing surrounding communities,:84 naming it for the viceroy of New Spain, Francisco Fernández de la Cueva, 10th Duke of Alburquerque.
As a part of New Spain, the claims for the province of New Mexico passed to independent Mexico in 1821 following the Mexican War of Independence.:109 The Republic of Texas claimed the portion east of the Rio Grande when it seceded from Mexico in 1836, when it incorrectly assumed the older Hispanic settlements of the upper Rio Grande were the same as the newly established Mexican settlements of Texas. Texas' only attempt to establish a presence or control in the claimed territory was the failed Texan Santa Fe Expedition, when their entire army was captured and jailed by Hispanic New Mexico militia.
The extreme northeastern part of New Mexico was owned by France, and sold to the United States as part of the Louisiana Purchase in 1803. By 1800 the Spanish population had reached 25,000, but Apache and Comanche raids on Hispanic settlers were common until well into the period of U.S. occupation.
Following the Mexican-American War, from 1846–1848 and the Treaty of Guadalupe Hidalgo in 1848, Mexico ceded its mostly unsettled northern holdings, today known as the American Southwest and California, to the United States of America.:132 In the Compromise of 1850 Texas ceded its claims to the area lying east of the Rio Grande in exchange for ten million dollars:135 and the US government established the New Mexico Territory on September 9, 1850, including most of the present-day states of Arizona and New Mexico, and part of Colorado. The United States acquired the southwestern boot heel of the state and southern Arizona below the Gila river in the mostly desert Gadsden Purchase of 1853, which was related to the construction by the US of a transcontinental railroad.:136
The compromise of 1850 created the current boundary between New Mexico and Texas. It is also considered during this time a surveyor's error awarded the Permian Basin to the State of Texas, which included the city of El Paso. Claims to the Permian were initially dropped by New Mexico in a bid to gain statehood in 1911.
New Mexico played a role in the Trans-Mississippi Theater of the American Civil War. Both Confederate and Union governments claimed ownership and territorial rights over New Mexico Territory. In 1861 the Confederacy claimed the southern tract as its own Arizona Territory and waged the ambitious New Mexico Campaign in an attempt to control the American Southwest and open up access to Union California. Confederate power in the New Mexico Territory was effectively broken after the Battle of Glorieta Pass in 1862. However, the Confederate territorial government continued to operate out of Texas, and Confederate troops marched under the Arizona flag until the end of the war. Additionally, over 8,000 troops from New Mexico Territory served the Union.
Congress admitted New Mexico as the 47th state in the Union on January 6, 1912.:166
A major oil discovery in 1928 brought prosperity to the state, especially Lea County and the town of Hobbs, named for James Hobbs, who was a homesteader there in 1907. The Midwest State No. 1 well, begun in late 1927 with a standard cable-tool drilling rig, revealed the first signs of oil from the Hobbs field on June 13, 1928. Drilled to 4,330 feet and completed a few months later, the well produced 700 barrels of oil per day on state land. The Midwest Refining Company's Hobbs well produced oil until 2002. The New Mexico Bureau of Mines and Mineral Resources called it "the most important single discovery of oil in New Mexico's history".
During World War II, the first atomic bombs were designed and manufactured at Los Alamos and the first was tested at Trinity site in the desert on the White Sands Proving Grounds between Socorro and Alamogordo.:179–180
New Mexico has benefited from federal government spending. It is home to three Air Force bases, White Sands Missile Range, and the federal research laboratories Los Alamos National Laboratory and Sandia National Laboratories. The state's population grew rapidly after World War II, going from 531,818 in 1940 to 1,819,046 in 2000. Employment growth areas in New Mexico include microelectronics, call centers, and Indian casinos.
Demographics.
Population.
The United States Census Bureau estimates that the population of New Mexico was 2,085,572 on July 1, 2014, a 1.28% increase since the 2010 United States Census.
Of the people residing in New Mexico, 51.4% were born in New Mexico, 37.9% were born in a different US state, 1.1% were born in Puerto Rico, U.S. Island areas, or born abroad to American parent(s), and 9.7% were foreign born.
7.5% of New Mexico's population was reported as under 5 years of age, 25% under 18, and 13% were 65 or older. Women make up approximately 51% of the population.
As of 2000, 8% of the residents of the state were foreign-born.
Among U.S. states, New Mexico has the highest percentage of Hispanic ancestry, at 47 percent (as of July 1, 2012), including descendants of Spanish colonists and recent immigrants from Latin America.
Race and ancestry.
The U.S. Census Bureau estimates the racial composition of the population in 2012 was:
Ethnically, 47.0% of the total population was of Hispanic or Latino.
According to the United States Census Bureau, 1.5% of the population is Multiracial/Mixed-Race, a population larger than both the Asian and NHPI population groups. In 2008 New Mexico had the highest percentage (47%) of Hispanics (of any race) of any state, with 83% of these native-born and 17% foreign-born. The majority of Hispanics in New Mexico claim a Spanish ancestry, especially in the northern part of the state. These people are the descendants of Spanish colonists who arrived during the 16th, 17th, and 18th centuries. See Nuevomexicanos. The state also has a large Native American population, second in percentage behind that of Alaska.
According to estimates from the United States Census Bureau's 2006–2008 American Community Survey 3-Year Estimate, New Mexico's population was 1,962,226. The number of New Mexicans of different single races were: White, 1,375,334 (70.1%); Black, 43,931 (2.2%); American Indian or Alaskan Native, 182,136 (9.3%); Asian, 26,767 (1.4%), Native Hawaiian or Pacific Islander, 854 (0.1%), and 273,778 (14.0%) of some other race. There were 59,415 (3.0%) of two or more races. There were 873,171 (44.5%) Hispanics or Latino (of any race).
According to the 2000 United States Census,:6
the most commonly claimed ancestry groups in New Mexico were:,
Languages.
According the 2000 U.S. Census, 28.76% of the population aged 5 and older speak Spanish at home, while 4.07% speak Navajo. Speakers of New Mexican Spanish dialect are mainly descendants of Spanish colonists who arrived in New Mexico in the 16th, 17th and 18th centuries. New Mexican Spanish is an archaic form of 17th century Castilian Spanish.
Official language.
The original state constitution of 1912 provided for a bilingual government with laws being published in both English and Spanish; this requirement was renewed twice, in 1931 and 1943. Nonetheless, the constitution does not declare any language as "official." While Spanish was permitted in the legislature until 1935, all state officials are required to have a good knowledge of English. Cobarrubias and Fishman therefore argue that New Mexico cannot be considered a bilingual state as not all laws are published in both languages. Others, such as Juan Perea, claim that the state was officially bilingual until 1953. In either case, Hawaii is the only state that remains officially bilingual in the 21st century.
With regard to the judiciary, witnesses have the right to testify in either of the two languages, and monolingual speakers of Spanish have the same right to be considered for jury-duty as do speakers of English. In public education, the state has the constitutional obligation to provide for bilingual education and Spanish-speaking instructors in school districts where the majority of students are hispanophone.
In 1995, the state adopted a State Bilingual Song, "New Mexico – Mi Lindo Nuevo México".:75,81 In 1989, New Mexico became the first state to officially adopt the English Plus resolution, and in 2008, the first to officially adopt a Navajo textbook for use in public schools.
Religion.
According to Association of Religion Data Archives(ARDA), the largest denominations in 2010 were the Catholic Church with 684,941; the Southern Baptist Convention with 113,452; The Church of Jesus Christ of Latter-day Saints with 67,637, and the United Methodist Church with 36,424 adherents. According to a 2008 survey by the Pew Research Center, the most common self-reported religious affiliation of New Mexico residents are mentioned in reference:100
Catholic Church hierarchy.
Within the hierarchy of the Catholic Church, New Mexico belongs to the Ecclesiastical Province of Santa Fe. New Mexico has three dioceses, one of which is an archdiocese:
Archdiocese of Santa Fe,
Diocese of Gallup,
Diocese of Las Cruces.
Economy.
Oil and gas production, tourism, and federal government spending are important drivers of the state economy. State government has an elaborate system of tax credits and technical assistance to promote job growth and business investment, especially in new technologies.
Economic indicators.
In 2010 New Mexico's Gross Domestic Product was $80 billion and an estimated $85 billion for 2013. In 2007 the per capita personal income was $31,474 (rank 43rd in the nation).
In 2005 the percentage of persons below the poverty level was 18.4%.
The New Mexico Tourism Department estimates that in Fiscal Year 2006 the travel industry in New Mexico generated expenditures of $6.5 billion. s of 2012[ [update]], the state's unemployment rate was 7.2%. During the Late 2000s Recession New Mexico's unemployment rate peaked at 8.0% for the period June–October 2010.
Oil and gas production.
New Mexico is the third leading crude oil and natural gas producer in the United States. The Permian Basin (part of the Mid-Continent Oil Field) and San Juan Basin lie partly in New Mexico. In 2006 New Mexico accounted for 3.4% of the crude oil, 8.5% of the dry natural gas, and 10.2% of the natural gas liquids produced in the United States.
In 2000 the value of oil and gas produced was $8.2 billion.
Federal government.
Federal government spending is a major driver of the New Mexico economy. In 2005 the federal government spent $2.03 on New Mexico for every dollar of tax revenue collected from the state. This rate of return is higher than any other state in the Union.
Many of the federal jobs relate to the military; the state hosts three air force bases (Kirtland Air Force Base, Holloman Air Force Base, and Cannon Air Force Base); a testing range (White Sands Missile Range); and an army proving ground and maneuver range (Fort Bliss – McGregor Range). A May 2005 estimate by New Mexico State University is that 11.65% of the state's total employment arises directly or indirectly from military spending.
Other federal installations include the technology labs of Los Alamos National Laboratory and Sandia National Laboratories.
Economic incentives.
New Mexico provides a number of economic incentives to businesses operating in the state, including various types of tax credits and tax exemptions. Most of the incentives are based on job creation.
New Mexico law allows governments to provide land, buildings, and infrastructure to businesses to promote job creation. Several municipalities have imposed an Economic Development Gross Receipts Tax (a form of Municipal Infrastructure GRT) that is used to pay for these infrastructure improvements and for marketing their areas.
The state provides financial incentives for film production. The New Mexico Film Office estimated at the end of 2007 that the incentive program had brought more than 85 film projects to the state since 2003 and had added $1.2 billion to the economy.
State taxes.
Since 2008, personal income tax rates for New Mexico have ranged from 1.7% to 4.9%, within four income brackets.
As of 2007, active-duty military salaries are exempt from state income tax.
New Mexico imposes a Gross Receipts Tax (GRT) on many transactions, which may even include some governmental receipts. This resembles a sales tax but, unlike the sales taxes in many states, it applies to services as well as tangible goods. Normally, the provider or seller passes the tax on to the purchaser, however legal incidence and burden apply to the business, as an excise tax. GRT is imposed by the state and there may an additional locality component to produce a total tax rate.
As of July 1, 2013 the combined tax rate ranged from 5.125% to 8.6875%.
Property tax is imposed on real property by the state, by counties, and by school districts. In general, personal-use personal property is not subject to property taxation. On the other hand, property tax is levied on most business-use personal property. The taxable value of property is 1/3 of the assessed value. A tax rate of about 30 mills is applied to the taxable value, resulting in an effective tax rate of about 1%. In the 2005 tax year the average millage was about 26.47 for residential property and 29.80 for non-residential property. Assessed values of residences cannot be increased by more than 3% per year unless the residence is remodeled or sold. Property tax deductions are available for military veterans and heads of household.
Transportation.
New Mexico has long been an important corridor for trade and migration. The builders of the ruins at Chaco Canyon also created a radiating network of roads from the mysterious settlement. Chaco Canyon's trade function shifted to Casas Grandes in the present-day Mexican state of Chihuahua, however, north-south trade continued. The pre-Columbian trade with Mesoamerican cultures included northbound exotic birds, seashells and copper. Turquoise, pottery, and salt were some of the goods transported south along the Rio Grande. Present-day New Mexico's pre-Columbian trade is especially remarkable for being undertaken on foot. The north-south trade route later became a path for colonists with horses arriving from New Spain as well as trade and communication. The route was called "El Camino Real de Tierra Adentro".
The Santa Fe Trail was the 19th century US territory's vital commercial and military highway link to the Eastern United States. All with termini in Northern New Mexico, the Camino Real, the Santa Fe Trail and the Old Spanish Trail are all recognized as National Historic Trails. New Mexico's latitude and low passes made it an attractive east-west transportation corridor. As a territory, the Gadsden Purchase increased New Mexico's land area for the purpose of the construction of a southern transcontinental railroad, that of the Southern Pacific Railroad. Another transcontinental railroad was completed by the Atchison, Topeka and Santa Fe Railway. The railroads essentially replaced the earlier trails but brought on a population boom. Early transcontinental auto trails later crossed the state bringing more migrants. Railroads were later supplemented or replaced by a system of highways and airports. Today, New Mexico's Interstate Highways approximate the earlier land routes of the Camino Real, the Santa Fe Trail and the transcontinental railroads.
Road.
New Mexico has had a problem with drunk driving, but that has lessened. According to the "Los Angeles Times", for years the state had the highest alcohol-related crash rates in the U.S., but ranked 25th in alcohol-related fatal crash rates, as of 2009[ [update]].
The automobile changed the character of New Mexico, marking the start of large scale immigration to the state from elsewhere in the United States. Settlers moving West during the Great Depression and post-World War II American culture immortalized the National Old Trails Highway, later U.S. Route 66. Today, the automobile is heavily relied upon in New Mexico for transportation.
New Mexico had 59,927 route miles of highway as of 2000[ [update]], of which 7,037 receive federal-aid. In that same year there were 1003 mi of freeways, of which 1000 were the route miles of Interstate Highways 10, 25 and 40. The former number has increased with the upgrading of roads near Pojoaque, Santa Fe and Las Cruces to freeways. The highway traffic fatality rate was 1.9 fatalities per million miles traveled in 2000, the 13th highest rate among U.S. states. Notable bridges include the Rio Grande Gorge Bridge near Taos. s of 2001[ [update]], 703 highway bridges, or one percent, were declared "structurally deficient" or "structurally obsolete".
Rural and intercity public transportation by road is provided by Americanos USA, LLC, Greyhound Lines and several government operators.
Urban mass transit.
The New Mexico Rail Runner Express is a commuter rail system serving the metropolitan area of Albuquerque, New Mexico. It began operation on July 14, 2006. The system runs from Belen to downtown Santa Fe. Larger cities in New Mexico typically have some form of public transportation by road; ABQ RIDE is the largest such system in the state.
Rail.
There were 2,354 route miles of railroads in the year 2000, this number increased with the opening of the Rail Runner's extension to Santa Fe. In addition to local railroads and other tourist lines, the state jointly owns and operates a heritage narrow-gauge steam railroad, the Cumbres and Toltec Scenic Railway, with the state of Colorado. Narrow gauge railroads once connected many communities in the northern part of the state, from Farmington to Santa Fe.:110 No fewer than 100 railroads of various names and lineage have operated in the jurisdiction at some point.:8 New Mexico's rail transportation system reached its height in terms of length following admission as a state; in 1914 eleven railroads operated 3124 route miles.:10
Railroad surveyors arrived in New Mexico in the 1850s. The first railroads incorporated in 1869.:9 The first operational railroad, the Atchison, Topeka & Santa Fe Railway (ATSF), entered the territory by way of the lucrative and contested Raton Pass in 1878. It eventually reached El Paso, Texas in 1881 and with the Southern Pacific Railroad created the nation's second transcontinental railroad with a junction at Deming. The Southern Pacific Railroad entered the territory from the Territory of Arizona in 1880.:9, 18, 58–59 The Denver & Rio Grande Railway, who would generally use narrow gauge equipment in New Mexico, entered the territory from Colorado and began service to Española on December 31, 1880.:95–96 These first railroads were built as long-distance corridors, later railroad construction also targeted resource extraction.:8–11
Freight.
New Mexico is served by two class I railroads, the BNSF Railway and the Union Pacific Railroad. Combined, they operate 2,200 route miles of railway in the state.
Passenger.
A commuter rail operation, the New Mexico Rail Runner Express, connects the state's capital, its largest city, and other communities. The privately operated state owned railroad began operations in July 2006. The BNSF Railway's entire line from Belen to Raton, New Mexico was sold to the state, partially for the construction of phase II of this operation, which opened in December 2008. Phase II of Rail Runner extended the line northward to Santa Fe from the Sandoval County station, the northernmost station under Phase I service. The service now connects Santa Fe, Sandoval, Bernalillo, and Valencia counties. The trains connect Albuquerque's population base and central business district to downtown Santa Fe with up to eight roundtrips in a day. The section of the line running south to Belen is served less frequently. Rail Runner operates scheduled service seven days per week.
With the rise of rail transportation many settlements grew or were founded and the territory became a tourist destination. As early as 1878, the ATSF promoted tourism in the region with emphasis on Native American imagery.:64 Named trains often reflected the territory they traveled: "Super Chief", the streamlined successor to the "Chief"; "Navajo", an early transcontinental tourist train; and "Cavern", a through car operation connecting Clovis and Carlsbad (by the early 1950s as train 23–24),:49–50:51 were some of the named passenger trains of the ATSF that connoted New Mexico.
Passenger train service once connected nine of New Mexico's present ten most populous cities (the exception is Rio Rancho), while today passenger train service connects two: Albuquerque and Santa Fe. With the decline of most intercity rail service in the United States in the late 1960s, New Mexico was left with minimal services. No less than six daily long-distance roundtrip trains supplemented by many branch line and local trains served New Mexico in the early 1960s. Declines in passenger revenue, but not necessarily ridership, prompted many railroads to turn over their passenger services in truncated form to Amtrak, a state owned enterprise. Amtrak, also known as the National Passenger Railroad Corporation, began operating the two extant long-distance routes in May 1971. Resurrection of passenger rail service from Denver to El Paso, a route once plied in part by the ATSF's "El Pasoan",:37 has been proposed over the years. As early as the 1980s former Governor Toney Anaya proposed building a high-speed rail line connecting the two cities with New Mexico's major cities. Front Range Commuter Rail is a project to connect Wyoming and New Mexico with high-speed rail.
Amtrak's "Southwest Chief" passes through daily at stations in Gallup, Albuquerque, Lamy, Las Vegas, and Raton, offering connections to Los Angeles, Chicago and intermediate points. The "Southwest Chief" is a fast Amtrak long distance train, being permitted a maximum speed of 90 mi/h in various places on the tracks of the BNSF Railway. It also operates on New Mexico Rail Runner Express trackage. The "Southwest Chief" is the successor to the "Super Chief" and "El Capitan".:115 The streamliner "Super Chief", a favorite of early Hollywood stars, was one of the most famous named trains in the United States and one of the most esteemed for its luxury and exoticness—train cars were named for regional Native American tribes and outfitted with the artwork of many local artists—but also for its speed: as few as 39 hours 45 minutes westbound.
The "Sunset Limited" makes stops three times a week in both directions at Lordsburg, and Deming, serving Los Angeles, New Orleans and intermediate points. The "Sunset Limited" is the successor to the Southern Pacific Railroad's train of the same name and operates exclusively on Union Pacific trackage in New Mexico.
Aerospace.
The Albuquerque International Sunport is the state's primary port of entry for air transportation.
Upham, near Truth or Consequences is the location of the world's first operational and purpose-built commercial spaceport, Spaceport America. Rocket launches began in April 2007. It is undeveloped and has one tenant, UP Aerospace, launching small payloads. Virgin Galactic, a space tourism company, plans to make this their primary operating base.
Government and politics.
Government.
The governmental structure of New Mexico is established by the Constitution of New Mexico. The executive is composed of the Governor, several other statewide elected officials including the Lieutenant Governor, Attorney General, Secretary of State, State Auditor, State Treasurer, and Commissioner of Public Lands, as well as the Governor's cabinet. The New Mexico Legislature consists of the House of Representatives and Senate. The judiciary is composed of the New Mexico Supreme Court and lower courts. There is also local government, consisting of counties, municipalities and special districts.
Politics.
Current Governor Susana Martinez (R) and Lieutenant Governor John Sanchez (R), were elected in 2010. Their terms expire in January 2019. Governors serve a term of four years and may seek re-election for one additional term (limit of two terms). Other constitutional officers, all of whose terms also expire in January 2019, include Secretary of State Dianna Duran (R), Attorney General Hector Balderas (D), State Auditor Timothy Keller (D), State Land Commissioner Aubrey Dunn (R), and State Treasurer Tim Eichenberg (D).
Currently, the New Mexico State Legislature has split majorities, with Democrats controlling the Senate and the House of Representatives being controlled by Republicans. There are 24 Democrats and 18 Republicans in the Senate, and 37 Republicans and 33 Democrats in the House of Representatives.
New Mexico's members of the United States Senate are Democrats Martin Heinrich and Tom Udall. Democrats Michelle Lujan Grisham, and Ben R. Luján represent the first and third congressional districts, respectively, and Republican Steve Pearce represents the second congressional district in the United States House of Representatives. See New Mexico congressional map.
New Mexico is considered a swing state, whose population has favored both Democratic and Republican presidential candidates in the past. The current governor is Susana Martinez (R), who succeeded Bill Richardson (D) on January 1, 2011 after he served two terms as governor from 2003 to 2011. Prior to Richardson, Gary Johnson served as governor from 1995 to 2003. Johnson served as a Republican, but in 2012 he ran for President from the Libertarian Party. Governors in New Mexico are limited to two terms. In previous presidential elections, Al Gore carried the state (by 366 votes) in 2000; George W. Bush won New Mexico's five electoral votes in 2004, and the state's electoral votes were won by Barack Obama in 2008 and 2012. Since achieving statehood in 1912, New Mexico has been carried by the victor in every presidential election except 1976 and 2000.
Democratic strongholds in the state include the Santa Fe Area, various areas of the Albuquerque Metro Area (such as the southeast and central areas, including the affluent Nob Hill neighborhood and the vicinity of the University of New Mexico), Northern and West Central New Mexico, and most of the Native American reservations, particularly the Navajo Nation. Republicans have traditionally had their strongholds in the eastern and southern parts of the state, the Farmington area, Rio Rancho, and Albuquerque's Northeast Heights and the newly developed areas in the Northwest mesa. While registered Democrats outnumber registered Republicans by nearly 200,000, New Mexico voters have historically favored moderate to conservative candidates of both parties at the state and federal levels.
On major political issues, New Mexico abolished its death penalty statute, though not retroactively, effective July 1, 2009. This means individuals currently on New Mexico's Death Row can still be executed, and those convicted of capital crimes prior to July 1, 2009 may still be sentenced to capital punishment under the pre-existing death penalty statute. On March 18, 2009, then Governor Bill Richardson signed the law abolishing the death penalty (although the repeal is not retroactive to capital crimes committed before it took effect) in New Mexico following the assembly and senate vote the week before, thus becoming the 15th U.S. state to abolish the penalty.
On gun control, New Mexico arguably has some of the least restrictive firearms laws in the country. State law pre-empts all local gun control ordinances. Unlike states with strong gun control laws, a New Mexico resident may purchase any firearm deemed legal under federal law. There are no waiting periods under state law for picking up a firearm after it has been purchased, and there are no restrictions on magazine capacity. Additionally, New Mexico allows open carry of a loaded firearm without a permit, and is "shall-issue" for concealed carry permits.
Prior to December 2013, New Mexico law did not explicitly allow nor prohibit same-sex marriage. Policy concerning the issuance of marriage licenses to same-sex couples was determined at the county level; that is, some county clerks issued marriage licenses to same-sex couples, while others did not. In December 2013, the New Mexico Supreme Court issued a unanimous ruling directing all county clerks to issue marriage licenses to same-sex couples, thereby making New Mexico the 17th state to recognize same-sex marriage at the statewide level.
Education.
Due to the state's various research facilities, such as Los Alamos National Laboratory, New Mexico had the highest concentration of PhD holders of any state in 2000.
Primary and secondary education.
The New Mexico Public Education Department oversees the operation of primary and secondary schools.
Culture.
With a Native American population of 134,000 in 1990, New Mexico still ranks as an important center of Native American culture. Both the Navajo and Apache share Athabaskan origin. The Apache and some Ute live on federal reservations within the state. With 16 million acres (6,500,000 ha), mostly in neighboring Arizona, the reservation of the Navajo Nation ranks as the largest in the United States. The prehistorically agricultural Pueblo Indians live in pueblos scattered throughout the state.
Almost half of New Mexicans claim Hispanic origin; many are descendants of colonial settlers. They settled in the northern portion of the state. Most of the Mexican immigrants reside in the southern part of the state. Also 10-15% of the population, mainly in the north, may contain Hispanic Jewish ancestry.
There are many New Mexicans who also speak a unique dialect of Spanish. New Mexican Spanish has vocabulary often unknown to other Spanish speakers. Because of the historical isolation of New Mexico from other speakers of the Spanish language adopts numerous Native American words for local features, and contains much Anglicized vocabulary for American concepts and modern inventions.
Albuquerque has the New Mexico Museum of Natural History and Science, the National Hispanic Cultural Center, and the National Museum of Nuclear Science & History, as well as hosts the famed annual Albuquerque International Balloon Fiesta every fall.
Art and literature.
The earliest New Mexico artists whose work survives today are the Mimbres Indians, whose black and white pottery could be mistaken for modern art, except for the fact that it was produced prior to the year 1130. See Mimbres culture. Many examples of this work can be seen at the Deming Luna Mimbres Museum and at the Western New Mexico University Museum.
A large artistic community thrives in Santa Fe, and has included such people as Bruce Nauman, Richard Tuttle, John Connell and Steina Vasulka. The capital city has several art museums, including the New Mexico Museum of Art, Museum of Spanish Colonial Art, Museum of International Folk Art, Museum of Indian Arts and Culture, Museum of Contemporary Native Arts, SITE Santa Fe and others. Colonies for artists and writers thrive, and the small city teems with art galleries. In August, the city hosts the annual Santa Fe Indian Market, which is the oldest and largest juried Native American art showcase in the world. Performing arts include the renowned Santa Fe Opera which presents five operas in repertory each July to August, the Santa Fe Chamber Music Festival held each summer, and the restored Lensic Theater a principal venue for many kinds of performances. Santa Fe is also home to Frogville Records, an indie record label. The weekend after Labor Day boasts the burning of Zozobra, a 50 ft (15 m) marionette, during Fiestas de Santa Fe.
Art is also a frequent theme in Albuquerque, New Mexico's largest city. The National Hispanic Cultural Center has held hundreds of performing arts events, art showcases, and other events related to Spanish culture in New Mexico and worldwide in the centerpiece Roy E Disney Center for the Performing Arts or in other venues at the 53 acre facility. New Mexico residents and visitors alike can enjoy performing art from around the world at Popejoy Hall on the campus of the University of New Mexico. Popejoy Hall hosts singers, dancers, Broadway shows, other types of acts, and Shakespeare. Albuquerque also has the unique and memorable KiMo Theater built in 1927 in the Pueblo Revival Style architecture. The KiMo presents live theater and concerts as well as movies and simulcast operas. In addition to other general interest theaters, Albuquerque also has the African American Performing Arts Center and Exhibit Hall which showcases achievements by people of African descent and the Indian Pueblo Cultural Center which highlights the cultural heritage of the First Nations people of New Mexico.
New Mexico still holds strong to its Spanish heritage. Old Spanish traditions such zarzuelas and flamenco are very popular in New Mexico. World renowned flamenco dancer and native New Mexican María Benítez founded the "to present programs of the highest quality of the rich artistic heritage of Spain as expressed through music, dance, visual arts and other art forms." There is also the held each year in which both native Spanish and New Mexican flamenco dancers perform at the University of New Mexico.
In the mid-20th century there was a thriving Hispano school of literature and scholarship being produced in both English and Spanish. Among the more notable authors were: Angélico Chávez, Nina Otero-Warren, Fabiola Cabeza de Baca, Aurelio Espinosa, Cleofas Jaramillo, Juan Bautista Rael, and Aurora Lucero-White Lea. As well, writer D. H. Lawrence lived near Taos in the 1920s at the D. H. Lawrence Ranch where there is a shrine said to contain his ashes.
New Mexico's strong Spanish, Native American, and Wild West frontier motifs have provided material for many authors in the state including internationally recognized Rudolfo Anaya and Tony Hillerman.
Silver City, in the southwestern mountains of the state, was originally a mining town, and at least one nearby mine still operates. It is perhaps better known now as the home of and/or exhibition center for large numbers of artists, visual and otherwise. Another former mining town turned art haven is Madrid, New Mexico. It was brought to national fame as the filming location for the movie "Wild Hogs" in 2007. The City of Las Cruces, in southern New Mexico, has a museum system that is affiliated with the Smithsonian Institution Affiliations Program. Las Cruces also has a variety of cultural and artistic opportunities for residents and visitors alike.
Aside from the aforementioned "Wild Hogs", other movies filmed in New Mexico include "Sunshine Cleaning" and "Vampires.
Sports.
Professional sports teams based in New Mexico include the Albuquerque Isotopes (Pacific Coast League Triple-A baseball affiliate of the MLB Colorado Rockies), the New Mexico Mustangs (North American Hockey League), and the New Mexico Renegades (Western States Hockey League). New Mexico is home to several baseball teams of the Pecos League: Santa Fe Fuego, Roswell Aliens, Taos Blizzard, White Sands Pupfish and Las Vegas Train Robbers.
Collegiate athletics in New Mexico involve various University of New Mexico Lobos and New Mexico State Aggies teams in many sports.
Olympic gold medalist Tom Jager, who is an advocate of controversial high-altitude training for swimming, has conducted training camps in Albuquerque (elevation 5,312 ft (1,619.1 m)) and Los Alamos (7,320 ft (2,231 m)).
Further reading.
Primary sources.
</dl>

</doc>
<doc id="21650" url="http://en.wikipedia.org/wiki?curid=21650" title="North Carolina">
North Carolina

North Carolina () is a state in the Southeastern United States. The state borders South Carolina and Georgia to the south, Tennessee to the west, Virginia to the north, and the Atlantic Ocean to the east. North Carolina is the 28th most extensive and the 9th most populous of the 50 United States. North Carolina is known as the "Tar Heel State" and the "Old North State".
North Carolina is composed of 100 counties. North Carolina's two largest metropolitan areas are among the top ten fastest-growing in the country: its capital, Raleigh, and its largest city, Charlotte. In the past five decades, North Carolina's economy has undergone a transition from reliance upon tobacco, textiles, and furniture-making to a more diversified economy with engineering, energy, biotechnology, and finance sectors.
North Carolina has a wide range of elevations, from sea level on the coast to 6699 ft at Mount Mitchell, the highest point in the Eastern US. The climate of the coastal plains is strongly influenced by the Atlantic Ocean. Most of the state falls in the humid subtropical climate zone. More than 300 mi from the coast, the western, mountainous part of the state has a subtropical highland climate.
Geography.
North Carolina is bordered by South Carolina on the south, Georgia on the southwest, Tennessee on the west, Virginia on the north, and the Atlantic Ocean on the east. The United States Census Bureau classifies North Carolina as a southern state, in the subcategory of being one of the South Atlantic States.
North Carolina consists of three main geographic sections: the Atlantic Coastal Plain, which occupies the eastern 45% of the state; the Piedmont region, which contains the middle 35%; and the Appalachian Mountains and foothills. The extreme eastern section of the state contains the Outer Banks, a string of sandy, narrow barrier islands between the Atlantic Ocean and two inland waterways or "sounds": Albemarle Sound in the north and Pamlico Sound in the south. They are the two largest landlocked sounds in the United States.
So many ships have been lost off Cape Hatteras that the area is known as the "Graveyard of the Atlantic"; more than 1,000 ships have sunk in these waters since records began in 1526. The most famous of these is the "Queen Anne's Revenge" (flagship of the pirate Blackbeard), which went aground in Beaufort Inlet in 1718.
Immediately inland, the coastal plain is relatively flat, with rich soil ideal for growing tobacco, soybeans, melons, and cotton. The coastal plain is North Carolina's most rural section, with few large towns or cities. Agriculture remains an important industry.
The coastal plain transitions to the Piedmont region along the Atlantic Seaboard fall line, a line which marks the elevation at which waterfalls first appear on streams and rivers. The Piedmont region of central North Carolina is the state's most urbanized and densely populated section. It consists of gently rolling countryside frequently broken by hills or low mountain ridges. Small, isolated, and deeply eroded mountain ranges and peaks are located in the Piedmont, including the Sauratown Mountains, Pilot Mountain, the Uwharrie Mountains, Crowder's Mountain, King's Pinnacle, the Brushy Mountains, and the South Mountains. The Piedmont ranges from about 300 to in elevation in the east to over 1000 ft in the west. Because of the rapid population growth in the Piedmont, a significant part of the rural area in this region is being transformed into suburbs with shopping centers, housing, and corporate offices. Agriculture is steadily declining in importance. The major rivers of the Piedmont, such as the Yadkin and Catawba, tend to be fast-flowing, shallow, and narrow.
The western section of the state is part of the Appalachian Mountain range. Among the subranges of the Appalachians located in the state are the Great Smoky Mountains, Blue Ridge Mountains, Great Balsam Mountains, and Black Mountains. The Black Mountains are the highest in the eastern United States, and culminate in Mount Mitchell at 6684 ft the highest point east of the Mississippi River. Although agriculture still remains important, tourism has become a dominant industry in the mountains. Growing Christmas trees has recently become an important industry as well. Because of the higher altitude, the climate in the mountains often differs markedly from that of the rest of the state. Winter in western North Carolina typically features high snowfall and subfreezing temperatures more akin to those of a midwestern state than of a southern state.
North Carolina has 17 major river basins. The basins west of the Blue Ridge Mountains flow to the Gulf of Mexico (via the Ohio and then the Mississippi River). All the others flow to the Atlantic Ocean. Of the 17 basins, 11 originate within the state of North Carolina, but only four are contained entirely within the state's border – the Cape Fear, the Neuse, the White Oak, and the Tar-Pamlico basin.
Climate.
The geographical divisions of North Carolina are useful when discussing the climate of the state.
The climate of the coastal plain is influenced by the Atlantic Ocean, which keeps conditions mild in winter and moderate, although humid, in summer. The highest coastal, daytime temperature averages less than 89 °F during summer months. The coast has mild temperatures in winter, with daytime highs rarely below 40 °F. The average daytime temperature in the coastal plain is usually in the mid-50s °F (11–14 °C) in winter. Temperatures in the coastal plain only occasionally drop below the freezing point at night. The coastal plain averages only around 1 in of snow or ice annually, and in many years, there may be no snow or ice at all.
The Atlantic Ocean has less influence on the climate of the Piedmont region, which has hotter summers and colder winters than in the coast. Daytime highs in the Piedmont often reach over 90 °F in the summer. While it is not common for the temperature to reach over 100 °F in the state, such temperatures, when they occur, typically are found only in the lower-elevation areas of the Piedmont and far-inland areas of the coastal plain. The weaker influence of the Atlantic Ocean also means that temperatures in the Piedmont often fluctuate more widely than in the coast.
In winter, the Piedmont is colder than the coast, with temperatures usually averaging in the upper 40s–lower 50s °F (8–12 °C) during the day and often dropping below the freezing point at night. The region averages around 3 – of snowfall annually in the Charlotte area. The Piedmont is especially notorious for sleet and freezing rain. Freezing rain can be heavy enough to snarl traffic and break down trees and power lines. Annual precipitation and humidity are lower in the Piedmont than in the mountains or the coast, but even at its lowest, the average is 40 in per year.
The Appalachian Mountains are the coolest area of the state, with temperatures averaging in the low 40s and upper 30s °F (6–3 °C) for highs in the winter and falling into the low 20s °F (−5 °C) or lower on winter nights. Relatively cool summers have temperatures rarely rising above 80 °F. Average snowfall in many areas exceeds 30 in per year, and can be heavy at the higher elevations; for example, during the Blizzard of 1993 more than 60 in of snow fell on Mount Mitchell over a period of three days. Mount Mitchell has received snow in every month of the year.
Severe weather occurs regularly in North Carolina. On the average, a hurricane hits the state once a decade. Destructive hurricanes that have struck the state include Hurricane Fran, Hurricane Floyd, and Hurricane Hazel, the strongest storm to make landfall in the state, as a Category 4 in 1954. Hurricane Isabel stands out as the most damaging of the 21st century. Tropical storms arrive every 3 or 4 years. In addition, many hurricanes and tropical storms graze the state. In some years, several hurricanes or tropical storms can directly strike the state or brush across the coastal areas. Only Florida and Louisiana are hit by hurricanes more often. Although many people believe that hurricanes menace only coastal areas, the rare hurricane which moves inland quickly enough can cause severe damage; for example, in 1989, Hurricane Hugo caused heavy damage in Charlotte and even as far inland as the Blue Ridge Mountains in the northwestern part of the state. On the average, North Carolina has 50 days of thunderstorm activity per year, with some storms becoming severe enough to produce hail, flash floods, and damaging winds.
North Carolina averages fewer than 20 tornadoes per year, many of them produced by hurricanes or tropical storms along the coastal plain. Tornadoes from thunderstorms are a risk, especially in the eastern part of the state. The western Piedmont is often protected by the mountains, which tend to break up storms as they try to cross over; the storms will often re-form farther east. Also a weather phenomenon known as "cold air damming" often occurs in the northwestern part of the state, which can also weaken storms but can also lead to major ice events in winter.
In April 2011, the worst tornado outbreak in North Carolina's history occurred. Thirty confirmed tornadoes touched down, mainly in the Eastern Piedmont and Sandhills, killing at least 24 people. Damages in the capital of Raleigh alone were over $115 million. Sanford and Fayetteville received a similar degree of devastation.
History.
Before A.D. 200, residents were building earthwork mounds, which were used for ceremonial and religious purposes. Succeeding peoples, including those of the ancient Mississippian culture established by A.D. 1000 in the Piedmont, continued to build or add onto such mounds. In the 500–700 years preceding European contact, the Mississippian culture built large, complex cities and maintained far-flung regional trading networks. Historically documented tribes in the North Carolina region included the Carolina Algonquian-speaking tribes of the coastal areas, such as the Chowanoke, Roanoke, Pamlico, Machapunga, Coree, Cape Fear Indians, and others, who were the first to encounter the English; Iroquoian-speaking Meherrin, Cherokee and Tuscarora of the interior; and Southeastern Siouan tribes, such as the Cheraw, Waxhaw, Saponi, Waccamaw, and Catawba.
Spanish colonial forces were the first Europeans to make a permanent settlement in the area, when the Juan Pardo-led expedition built Fort San Juan in 1567 at the site of the Native American community of Joara, a Mississippian culture regional chiefdom in the western interior, near the present-day city of Morganton. The fort lasted only 18 months; the local inhabitants killed all but one of the 120 men Pardo had stationed at a total of six forts in the area.
In 1718, after losing his ship and appealing to the governor of North Carolina who promised safe-haven and a pardon, the notorious pirate, Black Beard (Daniel Teach) was killed in an ambush by British soldiers. 
North Carolina became one of the English Thirteen Colonies and with the territory of South Carolina was originally known as the Province of Carolina. The northern and southern parts of the original province separated in 1729. Originally settled by small farmers, sometimes having a few slaves, who were oriented toward subsistence agriculture, the colony lacked cities or towns. Pirates menaced the coastal settlements, but by 1718 the pirates had been captured and killed. Growth was strong in the middle of the 18th century, as the economy attracted Scots-Irish, Quaker, English and German immigrants. The colonists generally supported the American Revolution, as the number of Loyalists was smaller than in some other colonies.
During colonial times, Edenton served as the state capital beginning in 1722, and New Bern was selected as the capital in 1766. Construction of Tryon Palace, which served as the residence and offices of the provincial governor William Tryon, began in 1767 and was completed in 1771. In 1788 Raleigh was chosen as the site of the new capital, as its central location protected it from attacks from the coast. Officially established in 1792 as both county seat and state capital, the city was named after Sir Walter Raleigh, sponsor of Roanoke, the "lost colony" on Roanoke Island.
North Carolina made the smallest per-capita contribution to the war of any state, as only 7,800 men joined the Continental Army under General George Washington; an additional 10,000 served in local militia units under such leaders as General Nathanael Greene. There was some military action, especially in 1780–81. Many Carolinian frontiersmen had moved west over the mountains, into the Washington District (later known as Tennessee), but in 1789, following the Revolution, the state was persuaded to relinquish its claim to the western lands. It ceded them to the national government so that the Northwest Territory could be organized and managed nationally.
After 1800, cotton and tobacco became important export crops. The eastern half of the state, especially the Tidewater region, developed a slave society based on a plantation system and slave labor. Many free people of color migrated to the frontier along with their European-American neighbors, where the social system was looser. By 1810, nearly 3 percent of the free population consisted of free people of color, who numbered slightly more than 10,000. The western areas were dominated by white families, especially Scots-Irish, who operated small subsistence farms. In the early national period, the state became a center of Jeffersonian and Jacksonian democracy, with a strong Whig presence, especially in the West. After Nat Turner's slave uprising in 1831, North Carolina and other southern states reduced the rights of free blacks. In 1835 the legislature withdrew their right to vote.
On May 20, 1861, North Carolina was the last of the Confederate states to declare secession from the Union, 13 days after the Tennessee legislature voted for secession. Some 125,000 North Carolinians served in the military; 20,000 were killed in battle, the most of any state in the Confederacy, and 21,000 died of disease. The state government was reluctant to support the demands of the national government in Richmond, and the state was the scene of only small battles.
With the defeat of the Confederacy in 1865, the Reconstruction Era began. The United States abolished slavery without compensation to slaveholders or reparations to freedmen. A Republican Party coalition of black freedmen, northern carpetbaggers and local scalawags controlled state government for three years. The white conservative Democrats regained control of the state legislature in 1870, in part by Ku Klux Klan violence and terrorism at the polls, to suppress black voting. Republicans were elected to the governorship until 1876, when the Red Shirts, a paramilitary organization that arose in 1874 and was allied with the Democratic Party, helped suppress black voting. More than 150 black Americans were murdered in electoral violence in 1876.
Democrats were elected to the legislature and governor's office, but the Populists attracted voters displeased with them. In 1896 a biracial, Populist-Republican Fusionist coalition gained the governor's office. The Democrats regained control of the legislature in 1896 and passed laws to impose Jim Crow and racial segregation of public facilities. Voters of North Carolina's 2nd congressional district elected a total of four African-American congressmen through these years of the late 19th century.
Political tensions ran so high that a small group of white Democrats in 1898 planned to take over the Wilmington government if their candidates were not elected. In the Wilmington Insurrection of 1898, more than 1,500 white men attacked the black newspaper and neighborhood, killed numerous men, and ran off the white Republican mayor and aldermen. They installed their own people and elected Alfred M. Waddell as mayor, in the only coup d'état in United States history.
In 1899 the state legislature passed a new constitution, with requirements for poll taxes and literacy tests for voter registration which disfranchised most black Americans in the state. Exclusion from voting had wide effects: it meant that black Americans could not serve on juries or in any local office. After a decade of white supremacy, many people forgot that North Carolina had ever had thriving middle-class black Americans. Black citizens had no political voice in the state until after the federal Civil Rights Act of 1964 and Voting Rights Act of 1965 were passed to enforce their constitutional rights. It was not until 1992 that another African American was elected as a US Representative from North Carolina.
As in the rest of the former Confederacy, North Carolina had become a one-party state, dominated by the Democratic Party. Impoverished by the Civil War, the state continued with an economy based on tobacco, cotton and agriculture. Towns and cities remained few in the east. A major industrial base emerged in the late 19th century in the western counties of the Piedmont, based on cotton mills established at the fall line. Railroads were built to connect the new industrializing cities. The state was the site of the first successful controlled, powered and sustained heavier-than-air flight, by the Wright brothers, near Kitty Hawk on December 17, 1903. In the first half of the 20th century, many African Americans left the state to go North for better opportunities, in the Great Migration. Their departure changed the demographic characteristics of many areas.
North Carolina was hard hit by the Great Depression, but the New Deal programs of Franklin D. Roosevelt for cotton and tobacco significantly helped the farmers. After World War II, the state's economy grew rapidly, highlighted by the growth of such cities as Charlotte, Raleigh, and Durham in the Piedmont. Raleigh, Durham, and Chapel Hill form the Research Triangle, a major area of universities and advanced scientific and technical research. In the 1990s, Charlotte became a major regional and national banking center. Tourism has also been a boon for the North Carolina economy as people flock to the Outer Banks coastal area and the Appalachian Mountains anchored by Asheville.
By the 1970s, spurred in part by the increasingly leftward tilt of national Democrats and rightward tilt of national Republicans, conservative whites began to vote for Republican national candidates and gradually for more Republicans locally although Democrats have held the governors office in all but three elections since 1901. The Greensboro Sit-ins played a crucial role in the Civil Rights Movement to bring full and equal equality to American blacks. Since the 1965 Civil Rights Act and Voting Rights Act under President Lyndon Johnson in which no Senators or Congressmen from North Carolina voted in favor for, black Americans have affiliated with and consistently elected officials of the Democratic Party.
Native Americans, lost colonies, and permanent settlement.
North Carolina was inhabited for thousands of years by succeeding cultures of prehistoric indigenous cultures. Before 200 AD, they were building earthwork mounds, which were used for ceremonial and religious purposes. Succeeding peoples, including those of the ancient Mississippian culture established by 1000 AD in the Piedmont, continued to build or add on to such mounds. In the 500–700 years preceding European contact, the Mississippian culture built large, complex cities and maintained far-flung regional trading networks. Its largest city was Cahokia, located in present-day Illinois near the Mississippi River.
Historically documented tribes in the North Carolina region include the Carolina Algonquian-speaking tribes of the coastal areas, such as the Chowanoke, Roanoke, Pamlico, Machapunga, Coree, and Cape Fear Indians, who were the first encountered by the English; the Iroquoian-speaking Meherrin, Cherokee, and Tuscarora of the interior; and Southeastern Siouan tribes, such as the Cheraw, Waxhaw, Saponi, Waccamaw, and Catawba.
Spanish explorers traveling inland in the 16th century met Mississippian culture people at Joara, a regional chiefdom near present-day Morganton. Records of Hernando de Soto attested to his meeting with them in 1540. In 1567 Captain Juan Pardo led an expedition to claim the area for the Spanish colony and to establish another route to protect silver mines in Mexico. Pardo made a winter base at Joara, which he renamed "Cuenca". His expedition built Fort San Juan and left a contingent of 30 men there, while Pardo traveled further, and built and garrisoned five other forts. He returned by a different route to Santa Elena on Parris Island, South Carolina, then a center of Spanish Florida. In the spring of 1568, natives killed all but one of the soldiers and burned the six forts in the interior, including the one at Fort San Juan. Although the Spanish never returned to the interior, this effort marked the first European attempt at colonization of the interior of what became the United States. A 16th-century journal by Pardo's scribe Bandera and archaeological findings since 1986 at Joara have confirmed the settlement.
In 1584, Elizabeth I granted a charter to Sir Walter Raleigh, for whom the state capital is named, for land in present-day North Carolina (then part of the territory of Virginia). It was the second American territory which the English attempted to colonize. Raleigh established two colonies on the coast in the late 1580s, but both failed. The fate of the "Lost Colony" of Roanoke Island remains one of the most widely debated mysteries of American history. Virginia Dare, the first English child to be born in North America, was born on Roanoke Island on August 18, 1587; Dare County is named for her.
As early as 1650, settlers from the Virginia colony moved into the area of Albemarle Sound. By 1663, King Charles II of England granted a charter to start a new colony on the North American continent; it generally established North Carolina's borders. He named it "Carolina" in honor of his father Charles I. By 1665, a second charter was issued to attempt to resolve territorial questions. In 1710, owing to disputes over governance, the Carolina colony began to split into North Carolina and South Carolina. The latter became a crown colony in 1729.
In the 1700s, a series of smallpox epidemics swept the South, causing high fatalities among the Native Americans, who had no immunity to the new disease (it had become endemic in Europe). According to the historian Russell Thornton, "The 1738 epidemic was said to have killed one-half of the Cherokee, with other tribes of the area suffering equally."
Colonial period and Revolutionary War.
After the Spanish in the 16th century, the first permanent European settlers of North Carolina were English colonists who migrated south from Virginia. The latter had grown rapidly and land was less available. Nathaniel Batts was documented as one of the first of these Virginian migrants. He settled south of the Chowan River and east of the Great Dismal Swamp in 1655. By 1663, this northeastern area of the Province of Carolina, known as the Albemarle Settlements, was undergoing full-scale English settlement. During the same period, the English monarch Charles II gave the province to the Lords Proprietors, a group of noblemen who had helped restore Charles to the throne in 1660. The new province of "Carolina" was named in honor and memory of King Charles I (Latin: "Carolus"). In 1712, North Carolina became a separate colony. Except for the Earl Granville holdings, it became a royal colony seventeen years later.
Differences in the settlement patterns of eastern and western North Carolina, or the Low Country and uplands, affected the political, economic, and social life of the state from the 18th until the 20th century. The Tidewater in eastern North Carolina was settled chiefly by immigrants from rural England and the Scottish Highlands. The upcountry of western North Carolina was settled chiefly by Scots-Irish, English, and German Protestants, the so-called "cohee". Arriving during the mid- to late 18th century, the Scots-Irish from what is today Northern Ireland were the largest non-English immigrant group before the Revolution; English indentured servants were overwhelmingly the largest immigrant group prior to the Revolution. During the American Revolutionary War, the English and Highland Scots of eastern North Carolina tended to remain loyal to the British Crown, because of longstanding business and personal connections with Great Britain. The English, Welsh, Scots-Irish, and German settlers of western North Carolina tended to favor American independence from Britain.
Most of the English colonists had arrived as indentured servants, hiring themselves out as laborers for a fixed period to pay for their passage. In the early years the line between indentured servants and African slaves or laborers was fluid. Some Africans were allowed to earn their freedom before slavery became a lifelong status. Most of the free colored families formed in North Carolina before the Revolution were descended from unions or marriages between free white women and enslaved or free African or African-American men. Because the mothers were free, their children were born free. Many had migrated or were descendants of migrants from colonial Virginia. As the flow of indentured laborers to the colony decreased with improving economic conditions in Great Britain, planters imported more slaves, and the state's legal delineations between free and slave status tightened, effectively hardening the latter into a racial caste. The economy's growth and prosperity was based on slave labor, devoted first to the production of tobacco.
On April 12, 1776, the colony became the first to instruct its delegates to the Continental Congress to vote for independence from the British Crown, through the Halifax Resolves passed by the North Carolina Provincial Congress. The dates of both of these events are memorialized on the state flag and state seal. Throughout the Revolutionary War, fierce guerrilla warfare erupted between bands of pro-independence and pro-British colonists. In some cases the war was also an excuse to settle private grudges and rivalries. A major American victory in the war took place at King's Mountain along the North Carolina–South Carolina border; on October 7, 1780, a force of 1000 mountain men from western North Carolina (including what is today the state of Tennessee) overwhelmed a force of some 1000 British troops led by Major Patrick Ferguson. Most of the soldiers fighting for the British side in this battle were Carolinians who had remained loyal to the Crown (they were called "Tories" or Loyalists). The American victory at Kings Mountain gave the advantage to colonists who favored American independence, and it prevented the British Army from recruiting new soldiers from the Tories.
The road to Yorktown and America's independence from Great Britain led through North Carolina. As the British Army moved north from victories in Charleston and Camden, South Carolina, the Southern Division of the Continental Army and local militia prepared to meet them. Following General Daniel Morgan's victory over the British Cavalry Commander Banastre Tarleton at the Battle of Cowpens on January 17, 1781, southern commander Nathanael Greene led British Lord Charles Cornwallis across the heartland of North Carolina, and away from the latter's base of supply in Charleston, South Carolina. This campaign is known as "The Race to the Dan" or "The Race for the River."
In the Battle of Cowan's Ford, Cornwallis met resistance along the banks of the Catawba River at Cowan's Ford on February 1, 1781, in an attempt to engage General Morgan's forces during a tactical withdrawal. Morgan had moved to the northern part of the state to combine with General Greene's newly recruited forces. Generals Greene and Cornwallis finally met at the Battle of Guilford Courthouse in present-day Greensboro on March 15, 1781. Although the British troops held the field at the end of the battle, their casualties at the hands of the numerically superior Continental Army were crippling. Following this "Pyrrhic victory", Cornwallis chose to move to the Virginia coastline to get reinforcements, and to allow the Royal Navy to protect his battered army. This decision would result in Cornwallis' eventual defeat at Yorktown, Virginia, later in 1781. The Patriots' victory there guaranteed American independence.
Antebellum period.
On November 21, 1789, North Carolina became the twelfth state to ratify the Constitution. In 1840, it completed the state capitol building in Raleigh, still standing today. Most of North Carolina's slave owners and large plantations were located in the eastern portion of the state. Although North Carolina's plantation system was smaller and less cohesive than that of Virginia, Georgia, or South Carolina, significant numbers of planters were concentrated in the counties around the port cities of Wilmington and Edenton, as well as suburban planters around the cities of Raleigh, Charlotte, and Durham in the Piedmont. Planters owning large estates wielded significant political and socio-economic power in antebellum North Carolina, which was a slave society. They placed their interests above those of the generally non-slave-holding "yeoman" farmers of western North Carolina. In mid-century, the state's rural and commercial areas were connected by the construction of a 129-mile (208 km) wooden plank road, known as a "farmer's railroad", from Fayetteville in the east to Bethania (northwest of Winston-Salem).
Besides slaves, there were a number of free people of color in the state. Most were descended from free African Americans who had migrated along with neighbors from Virginia during the 18th century. The majority were the descendants of unions in the working classes between white women, indentured servants or free, and African men, indentured, slave or free. After the Revolution, Quakers and Mennonites worked to persuade slaveholders to free their slaves. Some were inspired by their efforts and the language of the Revolution to arrange for manumission of their slaves. The number of free people of color rose markedly in the first couple of decades after the Revolution.
On October 25, 1836, construction began on the Wilmington and Raleigh Railroad to connect the port city of Wilmington with the state capital of Raleigh. In 1849 the North Carolina Railroad was created by act of the legislature to extend that railroad west to Greensboro, High Point, and Charlotte. During the Civil War, the Wilmington-to-Raleigh stretch of the railroad would be vital to the Confederate war effort; supplies shipped into Wilmington would be moved by rail through Raleigh to the Confederate capital of Richmond, Virginia.
During the antebellum period, North Carolina was an overwhelmingly rural state, even by Southern standards. In 1860 only one North Carolina town, the port city of Wilmington, had a population of more than 10,000. Raleigh, the state capital, had barely more than 5,000 residents.
While slaveholding was slightly less concentrated than in some Southern states, according to the 1860 census, more than 330,000 people, or 33% of the population of 992,622, were enslaved African Americans. They lived and worked chiefly on plantations in the eastern Tidewater. In addition, 30,463 free people of color lived in the state. They were also concentrated in the eastern coastal plain, especially at port cities such as Wilmington and New Bern, where a variety of jobs were available. Free African Americans were allowed to vote until 1835, when the state revoked their suffrage in restrictions following the slave rebellion of 1831 led by Nat Turner. Southern slave codes criminalized willful killing of a slave in most cases.
American Civil War.
In 1860, North Carolina was a slave state, in which about one-third of the population was enslaved. This was a smaller proportion than in many Southern states. The state did not vote to join the Confederacy until President Abraham Lincoln called on it to invade its sister state, South Carolina, becoming the last or second-to-last state to officially join the Confederacy. The title of "last to join the Confederacy" has been disputed; although Tennessee's informal secession on May 7, 1861, preceded North Carolina's official secession on May 20, the Tennessee legislature did not formally vote to secede until June 8, 1861.
North Carolina was the site of few battles, but it provided the Confederacy with at least 125,000 troops, which is far more than any other state did. Approximately 40,000 of those troops died: more than half of disease, the remainder from battlefield wounds and from starvation. North Carolina also supplied about 15,000 Union troops. Elected in 1862, Governor Zebulon Baird Vance tried to maintain state autonomy against Confederate President Jefferson Davis in Richmond.
After secession, some North Carolinians refused to support the Confederacy. Some of the yeoman farmers in the state's mountains and western Piedmont region remained neutral during the Civil War, while some covertly supported the Union cause during the conflict. Approximately 2,000 North Carolinians from western North Carolina enlisted in the Union Army and fought for the North in the war. Two additional Union Army regiments were raised in the coastal areas of the state, which were occupied by Union forces in 1862 and 1863. Numerous slaves escaped to Union lines, where they became essentially free.
Confederate troops from all parts of North Carolina served in virtually all the major battles of the Army of Northern Virginia, the Confederacy's most famous army. The largest battle fought in North Carolina was at Bentonville, which was a futile attempt by Confederate General Joseph Johnston to slow Union General William Tecumseh Sherman's advance through the Carolinas in the spring of 1865. In April 1865, after losing the Battle of Morrisville, Johnston surrendered to Sherman at Bennett Place, in what is today Durham. North Carolina's port city of Wilmington was the last Confederate port to fall to the Union, in February 1865, after the Union won the nearby Second Battle of Fort Fisher, its major defense downriver.
The first Confederate soldier to be killed in the Civil War was Private Henry Wyatt from North Carolina, in the Battle of Big Bethel in June 1861. At the Battle of Gettysburg in July 1863, the 26th North Carolina Regiment participated in Pickett/Pettigrew's Charge and advanced the farthest into the Northern lines of any Confederate regiment. During the Battle of Chickamauga, the 58th North Carolina Regiment advanced farther than any other regiment on Snodgrass Hill to push back the remaining Union forces from the battlefield. At Appomattox Court House in Virginia in April 1865, the 75th North Carolina Regiment, a cavalry unit, fired the last shots of the Confederate Army of Northern Virginia in the Civil War. For many years, North Carolinians proudly boasted that they had been "First at Bethel, Farthest at Gettysburg and Chickamauga, and Last at Appomattox."
Demographics.
The United States Census Bureau estimates that the population of North Carolina was 9,943,964 on July 1, 2014, a 4.28% increase since the 2010 United States Census. Of the people residing in North Carolina, 58.5% were born in North Carolina, 33.1% were born in another US state, 1.0% were born in Puerto Rico, U.S. Island areas, or born abroad to American parent(s), and 7.4% were born in another country.
As of 2011, 49.8% of North Carolina's population younger than age 1 were minorities.
Race and ethnicity.
Demographics of North Carolina covers the varieties of ethnic groups that reside in North Carolina, along with the relevant trends.
The state's racial composition in the 2010 Census:
Languages.
As of 2010, 89.66% (7,750,904) of North Carolina residents age 5 and older spoke English at home as a primary language, while 6.93% (598,756) spoke Spanish, 0.32% (27,310) French, 0.27% (23,204) German, and Chinese (which includes Mandarin) was spoken as a main language by 0.27% (23,072) of the population over the age of five. In total, 10.34% (893,735) of North Carolina's population age 5 and older spoke a mother language other than English.
Religion.
North Carolina residents, like those of other Southern states, since the colonial era have historically been overwhelmingly Protestant, first Anglican, then Baptist and Methodist. By the late 19th century, the largest Protestant denomination was the Baptist. After the Civil War, black Baptists left white churches to set up their own independent congregations, and developed their own state and national associations, to be free of white supervision.
While the Baptists in total (counting both blacks and whites) have maintained the majority in this part of the country (known as the Bible Belt), the population in North Carolina practices a wide variety of faiths, including Judaism, Islam, Baha'i, Buddhism, and Hinduism. As of 2010 the Southern Baptist Church was the biggest denomination, with 4,241 churches and 1,513,000 members; the second largest was the United Methodist Church, with 660,000 members and 1,923 churches. The third was the Roman Catholic Church, with 428,000 members in 190 congregations. The fourth greatest was the Presbyterian Church (USA), with 186,000 members and 710 congregations; this denomination was brought by Scots-Irish immigrants who settled the backcountry in the colonial era.
The state also has a special history with the Moravian Church, as settlers of this faith (largely of German origin) found a home in the Winston-Salem area in the 18th and 19th centuries. Presbyterians, historically Scots-Irish, have had a strong presence in Charlotte and in Scotland County.
Currently, the rapid influx of northerners and immigrants from Latin America is steadily increasing ethnic and religious diversity: the number of Roman Catholics and Jews in the state has increased, as well as general religious diversity. The second-largest Protestant denomination in North Carolina after Baptist traditions is Methodism, which is strong in the northern Piedmont, especially in populous Guilford County. There are also a substantial number of Quakers in Guilford County and northeastern North Carolina. Many universities and colleges in the state have been founded on religious traditions, and some currently maintain that affiliation, including: 
The state also has several major seminaries, including Duke University Divinity School in Durham, the Southeastern Baptist Theological Seminary in Wake Forest, and the Hood Theological Seminary (AME Zion) in Salisbury.
Major cities.
In 2014, the US Census Bureau released 2013 population estimate counts for North Carolina's cities with populations above 70,000. Charlotte has the largest population, while Raleigh has the highest population density of North Carolina's largest cities.
Largest combined statistical areas.
North Carolina has three major Combined Statistical Areas with populations of more than 1.6 million (U.S. Census Bureau 2012 estimates):
Economy.
According to a Forbes article written in 2013 Employment in the "Old North State" has gained many different industry sectors. See the following article summary: science, technology, energy and math, or STEM, industries in the area surrounding North Carolina's capital have grown 17.9 percent since 2001, placing Raleigh-Cary at No. 5 among the 51 largest metro areas in the country where technology is booming. In 2010 North Carolina's total gross state product was $424.9 billion, while the state debt in November 2012, according to one source, totalled US$2.4bn, while according to another, was in 2012 US$57.8bn. In 2011 the civilian labor force was at around 4.5 million with employment near 4.1 million. The working population is employed across the major employment sectors. The economy of North Carolina covers 15 metropolitan areas. In 2010, North Carolina was chosen as the third-best state for business by Forbes Magazine, and the second-best state by Chief Executive Officer Magazine.
Transportation.
Transportation systems in North Carolina consist of air, water, road, rail, and public transportation including intercity rail via Amtrak and light rail in Charlotte. North Carolina has the second-largest state highway system in the country as well as the largest ferry system on the east coast.
North Carolina's airports serve destinations throughout the United States and international destinations in Canada, Europe, Central America, and the Caribbean. In 2013 Charlotte Douglass International Airport ranked as the 23rd busiest airport in the world.
North Carolina has a growing passenger rail system with Amtrak serving most major cities. Charlotte is also home to North Carolina's only light rail system known as the Lynx.
Government and politics.
The government of North Carolina is divided into three branches: executive, legislative, and judicial. These consist of the Council of State (led by the Governor), the bicameral legislature (called the General Assembly), and the state court system (headed by the North Carolina Supreme Court). The state constitution delineates the structure and function of the state government. North Carolina has 13 seats in the U.S. House of Representatives and two seats in the U.S. Senate.
North Carolina's party loyalties have undergone a series of important shifts in the last few years: While the 2010 midterms saw Tar Heel voters elect a bicameral Republican majority legislature for the first time in over a century, North Carolina has also become a Southern swing state in presidential races. Since Southern Democrat Jimmy Carter's comfortable victory in the state in 1976, the state had consistently leaned Republican in presidential elections until Democrat Barack Obama narrowly won the state in 2008. In the 1990s, Democrat Bill Clinton came within a point of winning the state in 1992 and also only narrowly lost the state in 1996. In the early 2000s, Republican George W. Bush easily won the state by over 12 points, but by 2008, demographic shifts, population growth, and increased liberalization in heavily populated areas such as the Research Triangle, Charlotte, Greensboro, Winston-Salem, Fayetteville, and Asheville, propelled Barack Obama to victory in North Carolina, the first Democratic win in the state since 1976. In 2012, North Carolina was again considered a competitive swing state, with the Democrats even holding their 2012 Democratic National Convention in Charlotte. However, Republican Mitt Romney ultimately eked out a 2-point win in North Carolina, the only 2012 swing state that Obama lost, and one of only two states (along with Indiana) to flip from Obama in 2008 to the GOP in 2012.
In 2012, the state also elected a Republican Governor (Pat McCrory) and Lieutenant Governor (Dan Forest) for the first time in more than two decades, while also giving the Republicans veto-proof majorities in both the State House of Representatives and the State Senate. Several U.S. House of Representatives seats also flipped control, with the Republicans holding nine seats to the Democrats' four.
Education.
Primary and secondary education.
Elementary and secondary public schools are overseen by the North Carolina Department of Public Instruction. The North Carolina Superintendent of Public Instruction is the secretary of the North Carolina State Board of Education, but the board, rather than the superintendent, holds most of the legal authority for making public education policy. In 2009, the board's chairman also became the "chief executive officer" for the state's school system. North Carolina has 115 public school systems, each of which is overseen by a local school board. A county may have one or more systems within it. The largest school systems in North Carolina are the Wake County Public School System, Charlotte-Mecklenburg Schools, Guilford County Schools, Winston-Salem/Forsyth County Schools, and Cumberland County Schools. In total there are 2,425 public schools in the state, including 99 charter schools. North Carolina Schools were segregated until the Brown v. Board of Education trial and the release of the Pearsall Plan.
Colleges and universities.
In 1795, North Carolina opened the first public university in the United States—the University of North Carolina (now named the University of North Carolina at Chapel Hill). More than 200 years later, the University of North Carolina system encompasses 17 public universities including North Carolina State University, North Carolina A&T State University, North Carolina Central University, the University of North Carolina at Chapel Hill, the University of North Carolina at Greensboro, East Carolina University, Western Carolina University, Winston-Salem State University, the University of North Carolina at Asheville, the University of North Carolina at Charlotte, the University of North Carolina at Pembroke, UNC Wilmington, Elizabeth City State University, and Fayetteville State University, UNC School of the Arts, and Appalachian State University. Along with its public universities, North Carolina has 58 public community colleges in its community college system.The largest university in North Carolina is currently North Carolina State University, with more than 34,000 students. North Carolina is home to many excellent universities as well as dozens of community colleges and private universities.
North Carolina is also home to many well-known private colleges and universities, including Duke University, Wake Forest University, Pfeiffer University, Lees-McRae College, Davidson College, Barton College, North Carolina Wesleyan College, Elon University, Guilford College, Salem College, Shaw University (the first historically black college or university in the South), Laurel University, Meredith College, Methodist University, Belmont Abbey College (the only Catholic college in the Carolinas), Campbell University, Mount Olive College, Montreat College, High Point University, Lenoir-Rhyne University (the only Lutheran university in North Carolina) and Wingate University.
Sports.
North Carolina is home to three major league sports franchises: the Carolina Panthers of the National Football League and the Charlotte Hornets of the National Basketball Association are based in Charlotte, while the Raleigh-based Carolina Hurricanes play in the National Hockey League. The Hurricanes are the only major professional team from North Carolina to have won a league championship, having captured the Stanley Cup in 2006.
While North Carolina has no Major League Baseball team, it does have numerous minor league baseball teams, with the highest level of play coming from the AAA-affiliated Charlotte Knights and Durham Bulls. Additionally, North Carolina has minor league teams in other team sports including soccer and ice hockey, most notably the Carolina RailHawks and Charlotte Checkers, both of which play in the second tier of their respective sport.
In addition to professional team sports, North Carolina has a strong affiliation with NASCAR and stock-car racing, with Charlotte Motor Speedway in Concord hosting two Sprint Cup Series races every year. Charlotte also hosts the NASCAR Hall of Fame, while Concord is the home of several top-flight racing teams, including Hendrick Motorsports, Roush Fenway Racing, Richard Petty Motorsports, Stewart-Haas Racing, and Chip Ganassi Racing. Numerous other tracks around North Carolina host races from low-tier NASCAR circuits as well.
Golf is a popular summertime leisure activity, and North Carolina has hosted several important professional golf tournaments. Pinehurst Resort in Pinehurst has hosted a PGA Championship, Ryder Cup, and two U.S. Open tournaments. The Wells Fargo Championship is a regular stop on the PGA Tour and is held at Quail Hollow Club in Charlotte, while the Wyndham Championship is played annually in Greensboro.
College sports are also popular in North Carolina, with 18 schools competing at the Division I level. The Atlantic Coast Conference (ACC) is headquartered in Greensboro, and both the ACC Football Championship Game (Charlotte) and the ACC Men's Basketball Tournament (Greensboro) were most recently held in North Carolina. College basketball in particular is very popular, buoyed by the Tobacco Road rivalries between Duke, North Carolina, North Carolina State, and Wake Forest. The Belk Bowl is a post-season college football game held annually in Charlotte's Bank of America Stadium, featuring teams from the ACC and the Southeastern Conference. Additionally, the state has hosted the NCAA Men's Basketball Final Four on two occasions, in Greensboro in 1974 and in Charlotte in 1994.
Tourism.
 Every year the Appalachian Mountains attract several million tourists to the Western part of the state, including the historic Biltmore Estate. The scenic Blue Ridge Parkway and Great Smoky Mountains National Park are the two most visited national park and unit in the United States with over 25 million visitors in 2013. The City of is consistently voted as one of the top places to visit and live in the United States, known for its rich art deco architecture, mountain scenery and outdoor activities, and liberal and happy residents.
In Raleigh many tourists visit the Capital, African American Cultural Complex, Contemporary Art Museum of Raleigh, Gregg Museum of Art & Design at NCSU, Haywood Hall House & Gardens, Marbles Kids Museum, North Carolina Museum of Art, North Carolina Museum of History, North Carolina Museum of Natural Sciences, North Carolina Sports Hall of Fame, Raleigh City Museum, J. C. Raulston Arboretum, Joel Lane House, Mordecai House, Montfort Hall, and the Pope House Museum. The Carolina Hurricanes NHL hockey team is also located in the city.
In the Charlotte area, amenities include the Carolina Panthers NFL football team and Charlotte Hornets basketball team, Carowinds amusement park, Charlotte Motor Speedway, U.S. National Whitewater Center, and the Discovery Place. Nearby Concord has the Great Wolf Lodge and Sea Life Aquarium.
In the Conover – Hickory area, Hickory Motor Speedway, RockBarn Golf and Spa, home of the Greater Hickory Classic at Rock Barn; Catawba County Firefighters Museum, and SALT Block attract many tourists to Conover. Hickory which has Valley Hills Mall.
The Piedmont Triad, or center of the state, is home to Krispy Kreme, Mayberry, Texas Pete, the Lexington Barbecue Festival, and Moravian cookies. The internationally acclaimed North Carolina Zoo in Asheboro attracts visitors to its animals, plants, and a 57-piece art collection along five miles of shaded pathways in the world's largest-land-area natural-habitat park. Seagrove, in the central portion of the state, attracts many tourists along Pottery Highway (NC Hwy 705). MerleFest in Wilkesboro attracts more than 80,000 people to its four-day music festival; and Wet 'n Wild Emerald Pointe water park in Greensboro is another attraction.
The Outer Banks and surrounding beaches attract millions of people to the Atlantic beaches every year.
Recreation.
North Carolina provides a large range of recreational activities, from swimming at the beach to skiing in the mountains. North Carolina offers fall colors, freshwater and saltwater fishing, hunting, birdwatching, agritourism, ATV trails, ballooning, rock climbing, biking, hiking, skiing, boating and sailing, camping, canoeing, caving (spelunking), gardens, and arboretums. North Carolina has theme parks, aquariums, museums, historic sites, lighthouses, elegant theaters, concert halls, and fine dining.
North Carolinians enjoy outdoor recreation utilizing numerous local bike paths, 34 state parks, and 14 national parks. National Park Service units include the Appalachian National Scenic Trail, the Blue Ridge Parkway, Cape Hatteras National Seashore, Cape Lookout National Seashore, Carl Sandburg Home National Historic Site at Flat Rock, Fort Raleigh National Historic Site at Manteo, Great Smoky Mountains National Park, Guilford Courthouse National Military Park in Greensboro, Moores Creek National Battlefield near Currie in Pender County, the Overmountain Victory National Historic Trail, Old Salem National Historic Site in Winston-Salem, the Trail of Tears National Historic Trail, and Wright Brothers National Memorial in Kill Devil Hills. National Forests include Uwharrie National Forest in central North Carolina, Croatan National Forest in Eastern North Carolina, Pisgah National Forest in the northern mountains, and Nantahala National Forest in the southwestern part of the state.
Arts and culture.
North Carolina has rich traditions in art, music, and cuisine. The nonprofit arts and culture industry generates $1.2 billion in direct economic activity in North Carolina, supporting more than 43,600 full-time equivalent jobs and generating $119 million in revenue for local governments and the state of North Carolina. North Carolina established the North Carolina Museum of Art as the first major museum collection in the country to be formed by state legislation and funding and continues to bring millions into the NC economy. Also see this list of museums in North Carolina.
One of the more famous arts communities in the state is Seagrove, the handmade-pottery capital of the U.S., where artisans create handcrafted pottery inspired by the same traditions that began in this community more than 200 years ago. With nearly 100 shops and galleries scattered throughout the area, visitors can find everything from traditional tableware to folk and collectible art pieces and historical reproductions.
Music.
North Carolina boasts a large number of noteworthy jazz musicians, some among the most important in the history of the genre. These include: John Coltrane, (Hamlet, High Point); Thelonious Monk (Rocky Mount); Billy Taylor (Greenville); Woody Shaw (Laurinburg); Lou Donaldson (Durham); Max Roach (Newland); Tal Farlow (Greensboro); Albert, Jimmy and Percy Heath (Wilmington); Nina Simone (Tryon); and Billy Strayhorn (Hillsborough).
North Carolina is also famous for its tradition of old-time music, and many recordings were made in the early 20th century by folk-song collector Bascom Lamar Lunsford. Musicians such as the North Carolina Ramblers helped solidify the sound of country music in the late 1920s, while the influential bluegrass musician Doc Watson also hailed from North Carolina. Both North and South Carolina are hotbeds for traditional rural blues, especially the style known as the Piedmont blues.
Ben Folds Five originated in Winston-Salem, and Ben Folds still records and resides in Chapel Hill.
The British band Pink Floyd is named, in part, after Chapel Hill bluesman Floyd Council.
The Research Triangle area has long been a well-known center for folk, rock, metal, jazz and punk. James Taylor grew up around Chapel Hill, and his 1968 song "Carolina in My Mind" has been called an unofficial anthem for the state. Other famous musicians from North Carolina include J. Cole, Shirley Caesar, Roberta Flack, Clyde McPhatter, Nnenna Freelon, Jimmy Herring, Michael Houser, Eric Church, Future Islands, Randy Travis, Ryan Adams, Ronnie Milsap, Anthony Hamilton, and The Avett Brothers.
Metal and punk acts such as Corrosion of Conformity, Between the Buried and Me, and Nightmare Sonata are native to North Carolina.
EDM producer Porter Robinson hails from Chapel Hill.
North Carolina is the home of more "American Idol" finalists than any other state: Clay Aiken (season two), Fantasia Barrino (season three), Kellie Pickler (season five), Bucky Covington (season five), Chris Daughtry (season five), Anoop Desai (season eight), and Scotty McCreery (season ten).
In the mountains, the Brevard Music Center hosts choral, orchestral, and solo performances during its annual summer schedule.
Also, see the North Carolina Music Hall of Fame.
Shopping.
North Carolina has a variety of shopping choices. SouthPark Mall in Charlotte is currently the largest in the Carolinas, with almost 2.0 million square feet. Other major malls in Charlotte include Northlake Mall and Carolina Place Mall in nearby suburb Pineville. Other major malls throughout the state include Hanes Mall in Winston-Salem; Crabtree Valley Mall, North Hills Mall, and Triangle Town Center in Raleigh; Friendly Center and Four Seasons Town Centre in Greensboro; Oak Hollow Mall in High Point; Concord Mills in Concord; Valley Hills Mall in Hickory; and The Streets at Southpoint and Northgate Mall in Durham and Independence Mall in Wilmington, NC.
Cuisine and agriculture.
A culinary staple of North Carolina is pork barbecue. There are strong regional differences and rivalries over the sauces and methods used in making the barbecue. The common trend across Western North Carolina is the use of premium grade Boston butt. Western North Carolina pork barbecue uses a tomato-based sauce, and only the pork shoulder (dark meat) is used. Western North Carolina barbecue is commonly referred to as Lexington barbecue after the Piedmont Triad town of Lexington, home of the Lexington Barbecue Festival, which attracts over 100,000 visitors each October. Eastern North Carolina pork barbecue uses a vinegar-and-red-pepper-based sauce and the "whole hog" is cooked, thus integrating both white and dark meat.
Krispy Kreme, an international chain of doughnut stores, was started in North Carolina; the company's headquarters are in Winston-Salem. Pepsi-Cola was first produced in 1898 in New Bern. A regional soft drink, Cheerwine, was created and is still based in the city of Salisbury. Despite its name, the hot sauce Texas Pete was created in North Carolina; its headquarters are also in Winston-Salem. The Hardee's fast-food chain was started in Rocky Mount. Another fast-food chain, Bojangles', was started in Charlotte, and has its corporate headquarters there. A popular North Carolina restaurant chain is Golden Corral. Started in 1973, the chain was founded in Fayetteville, with headquarters located in Raleigh. Popular pickle brand Mount Olive Pickle Company was founded in Mount Olive in 1926. Fast casual burger chain Hwy 55 Burgers, Shakes & Fries also makes its home in Mount Olive. Cook Out, a popular fast-food chain featuring burgers, hot dogs, and milkshakes in a wide variety of flavors, was founded in Greensboro in 1989 and has begun expanding outside of North Carolina.
Over the last decade, North Carolina has become a cultural epicenter and haven for internationally prize-winning wine (Noni Bacca Winery), internationally prized cheeses (Ashe County), "L'institut International aux Arts Gastronomiques: Conquerront Les Yanks les Truffes, January 15, 2010" international hub for truffles (Garland Truffles), and beer making, as tobacco land has been converted to grape orchards while state laws regulating alcohol content in beer allowed a jump in ABV from 6% to 15%. The Yadkin Valley in particular has become a strengthening market for grape production, while Asheville recently won the recognition of being named 'Beer City USA.' Asheville boasts the largest breweries per capita of any city in the United States. Recognized and marketed brands of beer in North Carolina include Highland Brewing, Duck Rabbit Brewery, Mother Earth Brewery, Weeping Radish Brewery, Big Boss Brewing, Foothills Brewing, Carolina Brewing Company, Lonerider Brewing, and White Rabbit Brewing Company.
Tobacco was one of the first major industries to develop after the Civil War. Many farmers grew some tobacco, and the invention of the cigarette made the product especially popular. Winston-Salem is the birthplace of R. J. Reynolds Tobacco Company (RJR), founded by R. J. Reynolds in 1874 as one of 16 tobacco companies in the town. By 1914 it was selling 425 million packs of Camels a year. Today it is the second-largest tobacco company in the U.S. (behind Altria Group). RJR is an indirect wholly owned subsidiary of Reynolds American Inc., which in turn is 42% owned by British American Tobacco.
Ships named for the state.
Several ships have been named after the state. Most famous is the USS "North Carolina", a World War II battleship. The ship served in several battles against the forces of Imperial Japan in the Pacific theater during the war. Now decommissioned, it is part of the USS "North Carolina" Battleship Memorial in Wilmington. Another USS "North Carolina", a nuclear attack submarine, was commissioned in Wilmington, NC, on May 3, 2008.
State parks.
The state maintains a group of protected areas known as the North Carolina State Park System, which is managed by the North Carolina Division of Parks & Recreation (NCDPR), an agency of the North Carolina Department of Environment and Natural Resources (NCDENR).
Armed forces installations.
Fort Bragg, near Fayetteville and Southern Pines, is a large and comprehensive military base and is the headquarters of the XVIII Airborne Corps, 82nd Airborne Division, and the U.S. Army Special Operations Command. Serving as the air wing for Fort Bragg is Pope Field, also located near Fayetteville.
Located in Jacksonville, Marine Corps Base Camp Lejeune, combined with nearby bases Marine Corps Air Station (MCAS) Cherry Point, MCAS New River, Camp Geiger, Camp Johnson, Stone Bay and Courthouse Bay, makes up the largest concentration of Marines and sailors in the world. MCAS Cherry Point is home of the 2nd Marine Aircraft Wing. Located in Goldsboro, Seymour Johnson Air Force Base is home of the 4th Fighter Wing and 916th Air Refueling Wing. One of the busiest air stations in the United States Coast Guard is located at the Coast Guard Air Station in Elizabeth City. Also stationed in North Carolina is the Military Ocean Terminal Sunny Point in Southport.

</doc>
