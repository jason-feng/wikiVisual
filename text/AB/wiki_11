<doc id="14739" url="http://en.wikipedia.org/wiki?curid=14739" title="IEEE 802.11">
IEEE 802.11

IEEE 802.11 is a set of media access control (MAC) and physical layer (PHY) specifications for implementing wireless local area network (WLAN) computer communication in the 2.4, 3.6, 5, and 60 GHz frequency bands. They are created and maintained by the IEEE LAN/MAN Standards Committee (IEEE 802). The base version of the standard was released in 1997, and has had subsequent amendments. The standard and amendments provide the basis for wireless network products using the Wi-Fi brand. While each amendment is officially revoked when it is incorporated in the latest version of the standard, the corporate world tends to market to the revisions because they concisely denote capabilities of their products. As a result, in the market place, each revision tends to become its own standard.
General description.
The 802.11 family consists of a series of half-duplex over-the-air modulation techniques that use the same basic protocol. 802.11-1997 was the first wireless networking standard in the family, but 802.11b was the first widely accepted one, followed by 802.11a, 802.11g, 802.11n, and 802.11ac. Other standards in the family (c–f, h, j) are service amendments and extensions or corrections to the previous specifications.
802.11b and 802.11g use the 2.4 GHz ISM band, operating in the United States under Part 15 of the U.S. Federal Communications Commission Rules and Regulations. Because of this choice of frequency band, 802.11b and g equipment may occasionally suffer interference from microwave ovens, cordless telephones, and Bluetooth devices. 802.11b and 802.11g control their interference and susceptibility to interference by using direct-sequence spread spectrum (DSSS) and orthogonal frequency-division multiplexing (OFDM) signaling methods, respectively. 802.11a uses the 5 GHz U-NII band, which, for much of the world, offers at least 23 non-overlapping channels rather than the 2.4 GHz ISM frequency band, where adjacent channels overlap — see list of WLAN channels. Better or worse performance with higher or lower frequencies (channels) may be realized, depending on the environment.
The segment of the radio frequency spectrum used by 802.11 varies between countries. In the US, 802.11a and 802.11g devices may be operated without a license, as allowed in Part 15 of the FCC Rules and Regulations. Frequencies used by channels one through six of 802.11b and 802.11g fall within the 2.4 GHz amateur radio band. Licensed amateur radio operators may operate 802.11b/g devices under Part 97 of the FCC Rules and Regulations, allowing increased power output but not commercial content or encryption.
History.
802.11 technology has its origins in a 1985 ruling by the U.S. Federal Communications Commission that released the ISM band for unlicensed use.
In 1991 NCR Corporation/AT&T (now Alcatel-Lucent and LSI Corporation) invented a precursor to 802.11 in Nieuwegein, The Netherlands. The inventors initially intended to use the technology for cashier systems. The first wireless products were brought to the market under the name WaveLAN with raw data rates of 1 Mbit/s and 2 Mbit/s.
Vic Hayes, who held the chair of IEEE 802.11 for 10 years, and has been called the "father of Wi-Fi", was involved in designing the initial 802.11b and 802.11a standards within the IEEE.
In 1999, the Wi-Fi Alliance was formed as a trade association to hold the Wi-Fi trademark under which most products are sold.
Protocol.
802.11-1997 (802.11 legacy).
The original version of the standard IEEE 802.11 was released in 1997 and clarified in 1999, but is today obsolete. It specified two net bit rates of 1 or 2 megabits per second (Mbit/s), plus forward error correction code. It specified three alternative physical layer technologies: diffuse infrared operating at 1 Mbit/s; frequency-hopping spread spectrum operating at 1 Mbit/s or 2 Mbit/s; and direct-sequence spread spectrum operating at 1 Mbit/s or 2 Mbit/s. The latter two radio technologies used microwave transmission over the Industrial Scientific Medical frequency band at 2.4 GHz. Some earlier WLAN technologies used lower frequencies, such as the U.S. 900 MHz ISM band.
Legacy 802.11 with direct-sequence spread spectrum was rapidly supplanted and popularized by 802.11b.
802.11a (OFDM Waveform).
Originally described as clause 17 of the 1999 specification, the OFDM waveform at 5.8 GHz is now defined in clause 18 of the 2012 specification, and provides protocols that allow transmission and reception of data at rates of 1.5 to 54 Mbit/s. It has seen widespread worldwide implementation, particularly within the corporate workspace. While the original amendment is no longer valid, the term "802.11a" is still used by wireless access point (cards and routers) manufacturers to describe interoperability of their systems at 5.8 GHz, 54 Mbit/s.
The 802.11a standard uses the same data link layer protocol and frame format as the original standard, but an OFDM based air interface (physical layer). It operates in the 5 GHz band with a maximum net data rate of 54 Mbit/s, plus error correction code, which yields realistic net achievable throughput in the mid-20 Mbit/s.
Since the 2.4 GHz band is heavily used to the point of being crowded, using the relatively unused 5 GHz band gives 802.11a a significant advantage. However, this high carrier frequency also brings a disadvantage: the effective overall range of 802.11a is less than that of 802.11b/g. In theory, 802.11a signals are absorbed more readily by walls and other solid objects in their path due to their smaller wavelength, and, as a result, cannot penetrate as far as those of 802.11b. In practice, 802.11b typically has a higher range at low speeds (802.11b will reduce speed to 5.5 Mbit/s or even 1 Mbit/s at low signal strengths). 802.11a also suffers from interference, but locally there may be fewer signals to interfere with, resulting in less interference and better throughput.
802.11b.
The 802.11b standard has a maximum raw data rate of 11 Mbit/s, and uses the same media access method defined in the original standard. 802.11b products appeared on the market in early 2000, since 802.11b is a direct extension of the modulation technique defined in the original standard. The dramatic increase in throughput of 802.11b (compared to the original standard) along with simultaneous substantial price reductions led to the rapid acceptance of 802.11b as the definitive wireless LAN technology.
Devices using 802.11b experience interference from other products operating in the 2.4 GHz band. Devices operating in the 2.4 GHz range include microwave ovens, Bluetooth devices, baby monitors, cordless telephones, and some amateur radio equipment.
802.11g.
In June 2003, a third modulation standard was ratified: 802.11g. This works in the 2.4 GHz band (like 802.11b), but uses the same OFDM based transmission scheme as 802.11a. It operates at a maximum physical layer bit rate of 54 Mbit/s exclusive of forward error correction codes, or about 22 Mbit/s average throughput. 802.11g hardware is fully backward compatible with 802.11b hardware, and therefore is encumbered with legacy issues that reduce throughput when compared to 802.11a by ~21%.
The then-proposed 802.11g standard was rapidly adopted in the market starting in January 2003, well before ratification, due to the desire for higher data rates as well as to reductions in manufacturing costs. By summer 2003, most dual-band 802.11a/b products became dual-band/tri-mode, supporting a and b/g in a single mobile adapter card or access point. Details of making b and g work well together occupied much of the lingering technical process; in an 802.11g network, however, activity of an 802.11b participant will reduce the data rate of the overall 802.11g network.
Like 802.11b, 802.11g devices suffer interference from other products operating in the 2.4 GHz band, for example wireless keyboards.
802.11-2007.
In 2003, task group TGma was authorized to "roll up" many of the amendments to the 1999 version of the 802.11 standard. REVma or 802.11ma, as it was called, created a single document that merged 8 amendments (802.11a, b, d, e, g, h, i, j) with the base standard. Upon approval on March 8, 2007, 802.11REVma was renamed to the then-current base standard IEEE 802.11-2007.
802.11n.
802.11n is an amendment that improves upon the previous 802.11 standards by adding multiple-input multiple-output antennas (MIMO). 802.11n operates on both the 2.4 GHz and the lesser-used 5 GHz bands. Support for 5 GHz bands is optional. It operates at a maximum net data rate from 54 Mbit/s to 600 Mbit/s. The IEEE has approved the amendment, and it was published in October 2009. Prior to the final ratification, enterprises were already migrating to 802.11n networks based on the Wi-Fi Alliance's certification of products conforming to a 2007 draft of the 802.11n proposal.
802.11-2012.
In 2007, task group TGmb was authorized to "roll up" many of the amendments to the 2007 version of the 802.11 standard. REVmb or 802.11mb, as it was called, created a single document that merged ten amendments (802.11k, r, y, n, w, p, z, v, u, s) with the 2007 base standard. In addition much cleanup was done, including a reordering of many of the clauses. Upon publication on March 29, 2012, the new standard was referred to as IEEE 802.11-2012.
802.11ac.
IEEE 802.11ac-2013 is an amendment to IEEE 802.11, published in December 2013, that builds on 802.11n. Changes compared to 802.11n include wider channels (80 or 160 MHz versus 40 MHz) in the 5 GHz band, more spatial streams (up to eight versus four), higher-order modulation (up to 256-QAM vs. 64-QAM), and the addition of Multi-user MIMO (MU-MIMO). As of October 2013, high-end implementations support 80 MHz channels, three spatial streams, and 256-QAM, yielding a data rate of up to 433.3 Mbit/s per spatial stream, 1300 Mbit/s total, in 80 MHz channels in the 5 GHz band. Vendors have announced plans to release so-called "Wave 2" devices with support for 160 MHz channels, four spatial streams, and MU-MIMO in 2014 and 2015.
802.11ad.
IEEE 802.11ad is an amendment that defines a new physical layer for 802.11 networks to operate in the 60 GHz millimeter wave spectrum. This frequency band has significantly different propagation characteristics than the 2.4 GHz and 5 GHz bands where Wi-Fi networks operate. Products implementing the 802.11ad standard are being brought to market under the WiGig brand name. The certification program is now being developed by the Wi-Fi Alliance instead of the now defunct WiGig Alliance. The peak transmission rate of 802.11ad is 7 Gbit/s.
802.11af.
IEEE 802.11af, also referred to as "White-Fi" and "Super Wi-Fi", is an amendment, approved in February 2014, that allows WLAN operation in TV white space spectrum in the VHF and UHF bands between 54 and 790 MHz. It uses cognitive radio technology to transmit on unused TV channels, with the standard taking measures to limit interference for primary users, such as analog TV, digital TV, and wireless microphones. Access points and stations determine their position using a satellite positioning system such as GPS, and use the Internet to query a geolocation database (GDB) provided by a regional regulatory agency to discover what frequency channels are available for use at a given time and position. The physical layer uses OFDM and is based on 802.11ac. The propagation path loss as well as the attenuation by materials such as brick and concrete is lower in the UHF and VHF bands than in the 2.4 and 5 GHz bands, which increases the possible range. The frequency channels are 6 to 8 MHz wide, depending on the regulatory domain. Up to four channels may be bonded in either one or two contiguous blocks. MIMO operation is possible with up to four streams used for either space–time block code (STBC) or multi-user (MU) operation. The achievable data rate per spatial stream is 26.7 Mbit/s for 6 and 7 MHz channels, and 35.6 Mbit/s for 8 MHz channels. With four spatial streams and four bonded channels, the maximum data rate is 426.7 Mbit/s for 6 and 7 MHz channels and 568.9 Mbit/s for 8 MHz channels.
802.11ah.
IEEE 802.11ah defines a WLAN system operating at sub 1 GHz license-exempt bands, with final approval slated for March 2016. Due to the favorable propagation characteristics of the low frequency spectra, 802.11ah can provide improved transmission range compared with the conventional 802.11 WLANs operating in the 2.4 GHz and 5 GHz bands. 802.11ah can be used for various purposes including large scale sensor networks, extended range hotspot, and outdoor Wi-Fi for cellular traffic offloading, whereas the available bandwidth is relatively narrow.
802.11ai.
IEEE 802.11ai is an amendment to the 802.11 standard that will add new mechanisms for a faster initial link setup time.
802.11aj.
IEEE 802.11aj is a rebanding of 802.11ad for use in the 45 GHz unlicensed spectrum available in some regions of the world (specifically China).
802.11aq.
IEEE 802.11aq is an amendment to the 802.11 standard that will enable pre-association discovery of services. This extends some of the mechanisms in 802.11u that enabled device discovery to further discover the services running on a device, or provided by a network.
802.11ax.
IEEE 802.11ax is the successor to 802.11ac, and will increase the efficiency of WLAN networks. Currently at a very early stage of development this project has the goal of providing 4x the throughput of 802.11ac
802.11ay.
IEEE 802.11ay is a standard that is being developed. It is an amendment that defines a new physical layer for 802.11 networks to operate in the 60 GHz millimeter wave spectrum. It will be an extension of the existing 11ad, aimed to extend the throughput, range and use-cases. The main use-cases include: indoor operation, out-door back-haul and short range communications. The peak transmission rate of 802.11ay is 100 Gbit/s. The main extensions include: channel bonding (2, 3 and 4), MIMO and higher modulation schemes.
Common misunderstandings about achievable throughput.
Across all flavours of 802.11, maximum achievable throughputs are given either based on measurements under ideal conditions or in the layer-2 data rates. This, however, does not apply to typical deployments in which data is being transferred between two endpoints, of which at least one is typically connected to a wired infrastructure and the other endpoint is connected to an infrastructure via a wireless link.
This means that, typically, data frames pass an 802.11 (WLAN) medium, and are being converted to 802.3 (Ethernet) or vice versa. Due to the difference in the frame (header) lengths of these two media, the application's packet size determines the speed of the data transfer. This means applications that use small packets (e.g., VoIP) create dataflows with high-overhead traffic (i.e., a low goodput). Other factors that contribute to the overall application data rate are the speed with which the application transmits the packets (i.e., the data rate) and, of course, the energy with which the wireless signal is received. The latter is determined by distance and by the configured output power of the communicating devices.
The same references apply to the attached graphs that show measurements of UDP throughput. Each represents an average (UDP) throughput (please note that the error bars are there, but barely visible due to the small variation) of 25 measurements. Each is with a specific packet size (small or large) and with a specific data rate (10 kbit/s – 100 Mbit/s). Markers for traffic profiles of common applications are included as well. Please note, this text and measurements do not cover packet errors, but information about this can be found at the references above.
Channels and frequencies.
802.11b, 802.11g, and 802.11n-2.4 utilize the 2.400–2.500 GHz spectrum, one of the ISM bands. 802.11a and 802.11n use the more heavily regulated 4.915–5.825 GHz band. These are commonly referred to as the "2.4 GHz and 5 GHz bands" in most sales literature. Each spectrum is sub-divided into "channels" with a center frequency and bandwidth, analogous to the way radio and TV broadcast bands are sub-divided.
The 2.4 GHz band is divided into 14 channels spaced 5 MHz apart, beginning with channel 1, which is centered on 2.412 GHz. The latter channels have additional restrictions or are unavailable for use in some regulatory domains.
The channel numbering of the 5.725–5.875 GHz spectrum is less intuitive due to the differences in regulations between countries. These are discussed in greater detail on the list of WLAN channels.
Channel spacing within the 2.4 GHz band.
In addition to specifying the channel centre frequency, 802.11 also specifies (in Clause 17) a spectral mask defining the permitted power distribution across each channel. The mask requires the signal be attenuated a minimum of 20 dB from its peak amplitude at ±11 MHz from the centre frequency, the point at which a channel is effectively 22 MHz wide. One consequence is that stations can use only every fourth or fifth channel without overlap.
Availability of channels is regulated by country, constrained in part by how each country allocates radio spectrum to various services. At one extreme, Japan permits the use of all 14 channels for 802.11b, and 1–13 for 802.11g/n-2.4. Other countries such as Spain initially allowed only channels 10 and 11, and France allowed only 10, 11, 12, and 13; however, they now allow channels 1 through 13. North America and some Central and South American countries allow only 1 through 11.
Since the spectral mask defines only power output restrictions up to ±11 MHz from the center frequency to be attenuated by −50 dBr, it is often assumed that the energy of the channel extends no further than these limits. It is more correct to say that, given the separation between channels, the overlapping signal on any channel should be sufficiently attenuated to minimally interfere with a transmitter on any other channel. Due to the near-far problem a transmitter can impact (desense) a receiver on a "non-overlapping" channel, but only if it is close to the victim receiver (within a meter) or operating above allowed power levels.
Confusion often arises over the amount of channel separation required between transmitting devices. 802.11b was based on DSSS modulation and utilized a channel bandwidth of 22 MHz, resulting in "three" "non-overlapping" channels (1, 6, and 11). 802.11g was based on OFDM modulation and utilized a channel bandwidth of 20 MHz. This occasionally leads to the belief that "four" "non-overlapping" channels (1, 5, 9, and 13) exist under 802.11g, although this is not the case as per 17.4.6.3 Channel Numbering of operating channels of the IEEE Std 802.11 (2012), which states "In a multiple cell network topology, overlapping and/or adjacent cells using different channels can operate simultaneously without interference if the distance between the center frequencies is at least 25 MHz."
and section 18.3.9.3 and Figure 18-13.
This does not mean that the technical overlap of the channels recommends the non-use of overlapping channels. The amount of interference seen on a configuration using channels 1, 5, 9, and 13 can have very small difference from a three-channel configuration, and in the paper entitled "Effect of adjacent-channel interference in IEEE 802.11 WLANs" by Villegas this is also demonstrated.
Although the statement that channels 1, 5, 9, and 13 are "non-overlapping" is limited to spacing or product density, the concept has some merit in limited circumstances. Special care must be taken to adequately space AP cells, since overlap between the channels may cause unacceptable degradation of signal quality and throughput. If more advanced equipment such as spectral analyzers are available, overlapping channels may be used under certain circumstances. This way, more channels are available.
Regulatory domains and legal compliance.
IEEE uses the phrase "regdomain" to refer to a legal regulatory region. Different countries define different levels of allowable transmitter power, time that a channel can be occupied, and different available channels. Domain codes are specified for the United States, Canada, ETSI (Europe), Spain, France, Japan, and China.
Most Wi-Fi certified devices default to "regdomain" 0, which means least common denominator settings, i.e., the device will not transmit at a power above the allowable power in any nation, nor will it use frequencies that are not permitted in any nation.
The "regdomain" setting is often made difficult or impossible to change so that the end users do not conflict with local regulatory agencies such as the United States' Federal Communications Commission.
Layer 2 – Datagrams.
The datagrams are called "frames". Current 802.11 standards define "frame" types for use in transmission of data as well as management and control of wireless links.
Frames are divided into very specific and standardized sections. Each frame consists of a MAC header, payload, and frame check sequence (FCS). Some frames may not have a payload.
The first two bytes of the MAC header form a frame control field specifying the form and function of the frame. This frame control field is subdivided into the following sub-fields:
The next two bytes are reserved for the Duration ID field. This field can take one of three forms: Duration, Contention-Free Period (CFP), and Association ID (AID).
An 802.11 frame can have up to four address fields. Each field can carry a MAC address. Address 1 is the receiver, Address 2 is the transmitter, Address 3 is used for filtering purposes by the receiver.
The remaining fields of the header are:
The payload or frame body field is variable in size, from 0 to 2304 bytes plus any overhead from security encapsulation, and contains information from higher layers.
The Frame Check Sequence (FCS) is the last four bytes in the standard 802.11 frame. Often referred to as the Cyclic Redundancy Check (CRC), it allows for integrity check of retrieved frames. As frames are about to be sent, the FCS is calculated and appended. When a station receives a frame, it can calculate the FCS of the frame and compare it to the one received. If they match, it is assumed that the frame was not distorted during transmission.
Management Frames.
Management Frames allow for the maintenance of communication. Some common 802.11 subtypes include:
Information Elements.
2. In terms of ICT, an Information Element (IE) is a part of management frames in the IEEE 802.11 wireless LAN protocol. IEs are a device's way to transfer descriptive information about itself inside management frames. There are usually several IEs inside each such frame, and each is built of TLVs mostly defined outside the basic IEEE 802.11 specification.
The common structure of an IE is as follows:
 ← 1 → ← 1 → ← 3 → ← 1-252 →
Whereas the OUI (organizationally unique identifier) is used only when necessary to the protocol being used, and the data field holds the TLVs relevant to that IE.
Control Frames.
Control frames facilitate in the exchange of data frames between stations. Some common 802.11 control frames include:
Data Frames.
Data frames carry packets from web pages, files, etc. within the body. The body begins with an IEEE 802.2 header, with the Destination Service Access Point (DSAP) specifying the protocol; however, if the DSAP is hex AA, the 802.2 header is followed by a Subnetwork Access Protocol (SNAP) header, with the Organizationally Unique Identifier (OUI) and protocol ID (PID) fields specifying the protocol. If the OUI is all zeroes, the protocol ID field is an EtherType value. Almost all 802.11 data frames use 802.2 and SNAP headers, and most use an OUI of 00:00:00 and an EtherType value.
Standards and amendments.
Within the IEEE 802.11 Working Group, the following IEEE Standards Association Standard and Amendments exist:
In process.
802.11F and 802.11T are recommended practices rather than standards, and are capitalized as such.
802.11m is used for standard maintenance. 802.11ma was completed for 802.11-2007, 802.11mb was completed for 802.11-2012, and 802.11mc is working towards publishing 802.11-2016.
Standard vs. amendment.
Both the terms "standard" and "amendment" are used when referring to the different variants of IEEE standards.
As far as the IEEE Standards Association is concerned, there is only one current standard; it is denoted by IEEE 802.11 followed by the date that it was published. IEEE 802.11-2012 is the only version currently in publication. The standard is updated by means of amendments. Amendments are created by task groups (TG). Both the task group and their finished document are denoted by 802.11 followed by a non-capitalized letter, for example, IEEE 802.11a and IEEE 802.11b. Updating 802.11 is the responsibility of task group m. In order to create a new version, TGm combines the previous version of the standard and all published amendments. TGm also provides clarification and interpretation to industry on published documents. New versions of the IEEE 802.11 were published in 1999, 2007, and 2012. The next is expected in 2016.
Nomenclature.
Various terms in 802.11 are used to specify aspects of wireless local-area networking operation, and may be unfamiliar to some readers.
For example, Time Unit (usually abbreviated TU) is used to indicate a unit of time equal to 1024 microseconds. Numerous time constants are defined in terms of TU (rather than the nearly equal millisecond).
Also the term "Portal" is used to describe an entity that is similar to an 802.1H bridge. A Portal provides access to the WLAN by non-802.11 LAN STAs.
Community networks.
With the proliferation of cable modems and DSL, there is an ever-increasing market of people who wish to establish small networks in their homes to share their broadband Internet connection.
Many hotspot or free networks frequently allow anyone within range, including passersby outside, to connect to the Internet. There are also efforts by volunteer groups to establish wireless community networks to provide free wireless connectivity to the public.
Security.
In 2001, a group from the University of California, Berkeley presented a paper describing weaknesses in the 802.11 Wired Equivalent Privacy (WEP) security mechanism defined in the original standard; they were followed by Fluhrer, Mantin, and Shamir's paper titled "Weaknesses in the Key Scheduling Algorithm of RC4". Not long after, Adam Stubblefield and AT&T publicly announced the first verification of the attack. In the attack, they were able to intercept transmissions and gain unauthorized access to wireless networks.
The IEEE set up a dedicated task group to create a replacement security solution, 802.11i (previously this work was handled as part of a broader 802.11e effort to enhance the MAC layer). The Wi-Fi Alliance announced an interim specification called Wi-Fi Protected Access (WPA) based on a subset of the then current IEEE 802.11i draft. These started to appear in products in mid-2003. IEEE 802.11i (also known as WPA2) itself was ratified in June 2004, and uses the Advanced Encryption Standard AES, instead of RC4, which was used in WEP. The modern recommended encryption for the home/consumer space is WPA2 (AES Pre-Shared Key), and for the Enterprise space is WPA2 along with a RADIUS authentication server (or another type of authentication server) and a strong authentication method such as EAP-TLS.
In January 2005, the IEEE set up yet another task group "w" to protect management and broadcast frames, which previously were sent unsecured. Its standard was published in 2009.
In December 2011, a security flaw was revealed that affects some wireless routers with a specific implementation of the optional Wi-Fi Protected Setup (WPS) feature. While WPS is not a part of 802.11, the flaw allows a remote attacker to recover the WPS PIN and, with it, the router's 802.11i password in a few hours.
In late 2014 Apple announced that its IOS 8 mobile operating system would scramble MAC addresses during the pre-association stage to thwart retail footfall tracking made possible by the regular transmission of uniquely identifiable probe requests.
Non-standard 802.11 extensions and equipment.
Many companies implement wireless networking equipment with non-IEEE standard 802.11 extensions either by implementing proprietary or draft features. These changes may lead to incompatibilities between these extensions.
References.
</dl>

</doc>
<doc id="14741" url="http://en.wikipedia.org/wiki?curid=14741" title="Irn-Bru">
Irn-Bru

Irn-Bru is a Scottish carbonated soft drink, often described as "Scotland's other national drink" (after Scotch whisky). It is produced in Westfield, Cumbernauld, North Lanarkshire, by A.G. Barr of Glasgow, since moving out of their Parkhead factory in the mid-1990s, and at a second manufacturing site in Mansfield. In addition to being sold throughout the United Kingdom, Barr's Irn-Bru is available throughout the world and can usually be purchased where there is a significant community of people from Scotland. Innovative and sometimes controversial marketing campaigns have kept it as the number one selling soft drink in Scotland, where it competes directly with global brands such as Coca-Cola and Pepsi.
Overview.
Irn-Bru is known for its bright orange colour. As of 1999 it contained 0.002% of ammonium ferric citrate, sugar, 32 flavouring agents including caffeine and quinine (but not in Australia), and two controversial colourings (Sunset Yellow FCF and Ponceau 4R). On 27 January 2010, A.G. Barr agreed to a Food Standards Agency voluntary ban on these two colourings although no date has been set for their replacement.
Irn-Bru was first produced in 1901, in the town of Falkirk, under the name "Iron Brew". In 1946, a change in laws required that the word "brew" be removed from the name, as the drink is not brewed. The chairman of the company came up with the idea of changing the spelling of both halves of the name, giving the Irn-Bru brand. 1980 saw the introduction of Low Calorie Irn-Bru: this was re-launched in 1991 as Diet Irn-Bru and again in 2011 as Irn-Bru Sugar Free. The Irn-Bru 32 energy drink variant was launched in 2006.
It has long been the most popular soft drink in Scotland, with Coca-Cola second, but recent competition between the two brands has brought their sales to roughly equal levels. It is also the third best selling soft drink in the UK, after Coca-Cola and Pepsi, outselling high-profile brands such as Fanta, Dr Pepper, Sprite and 7-Up. This success in defending its home market (a feat claimed only by Irn-Bru, Thums Up and Inca Kola) led to ongoing speculation that Coca-Cola, PepsiCo, Inc. or its UK brand franchisee Britvic would attempt to buy A.G. Barr. In November 2012 AG Barr and Britvic announced a merger proposal, in July 2013 the merger collapsed when terms could not be agreed.
Irn-Bru's advertising slogans used to be 'Scotland's other National Drink', referring to whisky, and 'Made in Scotland from girders', a reference to the rusty colour of the drink; though the closest one can come to substantiating this claim is the 0.002% ammonium ferric citrate listed in the ingredients.
A limited edition Irn-Bru was released in Autumn 2011. Packaged with a black and orange design, and with the signature man icon with an added image of a fire, Fiery Irn-Bru, had a warm, tingly feeling in the mouth once drunk. The after taste to it is similar to ginger but still has the Irn-Bru flavour.
Irn-Bru is also sold in reusable 750 ml glass bottles which, like other Barr's drinks, may be returned to the manufacturer in exchange for the 30 pence deposit paid. This scheme is widely available in shops across Scotland.
Packaging.
Irn-Bru and other Barr brands including Pineappleade, Cream Soda, Tizer, Red Kola, Barr Cola, and Limeade are still available in 750 ml reusable glass bottles. The empty bottles can be returned to the manufacturer via any retailer which sells them, and can usually be exchanged for the deposit (30 pence deposit).
Irn-Bru and Diet Irn-Bru are available in the following sizes:
In May 2007, Irn-Bru re-designed its bottles and cans.
Marketing.
Advertising campaigns.
An early (and long running) advertising campaign was "The Adventures of Ba-Bru and Sandy" comic which ran from the 1930s to the early 70s. A neon sign featuring Ba-Bru stood outside Glasgow Central Station for many years, and was only removed in the late 1970s.
Barr has a long-established gimmick associating Irn-Bru with Scottishness, stemming from the claim of it being Scotland's most popular soft drink. A tagline, "Made in Scotland from girders", was used for several years from the 1980s, usually featuring Irn-Bru drinkers becoming unusually strong, durable, or magnetic.
An advertising campaign launched in 2000 featured eccentric characters and situations. One involved a grandfather (played by actor Robert Wilson) who removed his false teeth to spoil his grandson's interest in his can of Irn-Bru. A further TV advertisement featured a senior citizen in a motorised wheelchair robbing a local shopping market of a supply of Irn-Bru. Further advertising campaigns for Irn-Bru appeared in conjunction with the release of Irn-Bru 32 in 2006. This campaign consisted of a parody commercial of a popular Christmas Cartoon, The Snowman, and was effective in interesting American audiences in the Irn-Bru brand.
A 2009 advertisement for the product features a group of high school students performing a musical number, with the refrain "It's fizzy, it's ginger, it's phenomenal!" It is a parody of "High School Musical", and stars Jack Lowden.
In response to the Coca Cola 'Share a Coke' campaign, Barr decided to produce thousands of limited edition 750 ml bottles of "Irn-Bru" with the names 'Fanny', 'Senga', 'Rab' and 'Tam' on the label, mimicking that by "Coca Cola". The use of the name 'Fanny' ties in with one of "Irn-Bru"'s controversial marketing advertisements.
Controversy.
One of the most controversial Irn-Bru television adverts evoked 1950s entertainment. A mother plays the piano, while the father and two children deliver a song which ends with the mother singing: "...even though I used to be a man". This advertisement was broadcast in 2000, but when it was repeated in 2003, it led to seventeen complaints about it being offensive to transgender people. Issue A14 of the Ofcom Advertising Complaints bulletin reports that the children's response to their mother's claim was not offensive. The advertisement was meant to be a joke about changing points of view over time. However, the scene involving the mother shaving at the end of the advertisement was deemed to be potentially offensive to transgender people, and so it was taken off the air.
In 2003, an Irn-Bru commercial which showed a midwife trying to entice a baby from its mother's womb during a difficult delivery sparked a complaint from one viewer. Some saw it as upsetting to women who had suffered miscarriages.
One billboard featured a young woman in a bikini along with the slogan "I never knew four-and-a-half inches could give so much pleasure". Another featured a picture of a cow with the slogan "When I'm a burger, I want to be washed down with Irn-Bru". This billboard resulted in over 700 complaints but was cleared by advertisement watchdogs. A billboard which featured a depressed goth and the slogan 'Cheer up Goth. Have an Irn Bru.' was also criticised for inciting bullying.
Brand portfolio.
Irn-Bru and others.
It can be used as a mixer with alcoholic beverages—mainly vodka and whisky. Indeed, the alcopop WKD (produced by Beverage Brands) was launched as an alcoholic equivalent of Irn-Bru. Barr retaliated by launching a drink combining Irn-Bru and Bell's whisky, though this proved to be unpopular and was discontinued. A later attempt came in the form of an official Irn-Bru flavour in the Red Square line-up of vodka-based drinks; this too has been discontinued. There is an official Irn-Bru WKD flavour.
Exports and foreign markets.
Irn-Bru is manufactured in five factories in Russia, and manufactured under licence in Canada, the United States, and since May 2008 in Norway. Bru and other Barr products are exported to Spain, Netherlands, Germany, Gibraltar, Greece, and Cyprus, as well as parts of Africa and Asia. It is available in Ireland, increasingly being stocked in BWG and ADM Londis supplied stores, as well as in supermarkets owned by Dunnes Stores and Tesco Ireland. It is also available in Malta, Belgium and, as of 2005, in Poland. It is now sold in Iceland, as of 2011. A similarly named product, using the "Iron Brew" spelling but bearing little resemblance to Irn-Bru in flavour, colour or packaging, is produced by Coca-Cola in South Africa.
Australia.
In Australia, Irn-Bru was manufactured and distributed under licence by Occasio Australia Pty Ltd until 2009. It was available in 500 ml and 1.25 l varieties in both regular and diet. The drink enjoyed growing success in the country, with its first advertising campaign launched in Queensland in September 2007. It was initially available in major chains such as Coles and Woolworths, Caltex service stations and in many independent grocers and convenience stores, however, it was then delisted at Coles supermarkets. Because of manufacturing and bottling issues, Occasio ceased local production in late 2009. British Provender Pty Ltd are now importing Irn-Bru directly from the UK, with stocks now seen on IGA and Coles shelves throughout Australia as of October 2010. Although it is imported from the UK it does not contain caffeine or quinine, so the taste is different from that sold in the UK. Imported cans of the original Scottish-made formula can be found in some import shops for around $3.00 each.
Canada.
Irn-Bru sold in Canada contained no caffeine until recently. In March 2010, Health Canada repealed the ban on caffeine on clear coloured soft drinks and now bottles of Irn-Bru have the label 'Now Contains caffeine' on the packaging. Irn-Bru in Canada is distributed by TFB & Associates Ltd from Markham, Ontario but is packaged by A.G. Barr in Glasgow, Scotland. Irn-Bru can be found at Sobeys supermarkets.
The now-defunct McKinley/McInlay soft-drink company in Cape Breton, Nova Scotia, Canada, for many years offered its own non-licensed beverage called "Iron Brew". It was a brown carbonated soft-drink with a fruity cola taste. After the company stopped operations around 1990, PepsiCo continued to sell the drink locally as 'Cape Breton's Irn Bru'. The packaging consisted of plainly labelled plastic bottles (black text on a featureless white label) and a disclaimer "Not a source of Iron".
The standard Irn-Bru distributed in Canada also contains the "Not a source of iron" disclaimer on the label.
The UK version of the drink (with caffeine) is commonly imported by speciality retailers, particularly in areas with large British populations.
Denmark.
Irn-Bru started being sold at 7-Eleven. It has often appeared in the Danish supermarket 'Netto', 'Rema 1000' and 'Normal'. Today only a few 7-Elevens in Denmark continue distributing Irn-Bru, while most Føtex and Bilka stores now stock Irn Bru.
Finland.
Imported Irn Bru cans are found throughout Finland in selected K-supermarket and K-citymarket supermarkets, in Punnitse ja Säästä stores, the Behnford's store in Helsinki and from Verkkokauppa.com.
Hong Kong.
Irn-Bru can be found in selected Wellcome supermarkets, in and around areas where the expatriate population is significant such as the Sheung Wan and Central districts.
Middle East.
A.G. Barr has launched its Irn-Bru product throughout the Middle East
Norway.
Irn-Bru entered the Norwegian market in May 2008. They had to withdraw from the market again in 2009 as a result of problems with production agreements and lack of funding for proper marketing efforts, and Irn-Bru can not be bought in Norway as of February 2010.
They were believed to be sponsoring the Adeccoligaclub Mjøndalen IF in 2009. This later turned out to be fraud carried out by a third party company, and Mjøndalen IF never received any sponsorship from Irn-Bru, even though the team played the 2009 season with Irn-Bru marketing on their shirts.
United States.
Irn-Bru and Diet Irn-Bru have been formulated since 2002 by A.G. Barr plc to meet the regulations for food colouring of the U.S. Food and Drug Administration (FDA). Ponceau 4R, used in the UK formulation, is prohibited by the FDA. Barr uses alternative food and drink colourants manufactured by a U.S. company approved by the FDA. The product labelling also meets U.S. labelling standards on nutritional information and bar code. Compliant Irn-Bru is solely imported by Great Scot International in Charlotte, North Carolina, who supply distributors and retailers throughout the U.S. It is only supplied in 500 ml.
References in media.
Ebola.
Irn Bru was mentioned by British Aid Worker Pauline Cafferkey as helping her through her treatment for Ebola virus disease, contracted whilst volunteering in Sierra Leone. 
Museums.
In the Museum of Scotland, on Chambers Street in Edinburgh, there is a range of exhibits selected by celebrities—Sir Sean Connery chose a crate of Irn-Bru.
In the Hunterian Museum in Glasgow, a small refrigerator contains a 6-pack of Irn Bru in the section dedicated to Scientific Instruments and Lord Kelvin.
Music.
Scottish rock band the Fratellis featured a play on Irn-Bru's logo as one of their T-shirt designs in their 2008 tour. The band also brought Irn-Bru with them to drink during their performances.
Elvis Costello references Irn-Bru in "The St. Stephen's Day Murders," referring to a mixture of Tia Maria and "that drink made from girders".
Scottish indiepop band The Orchids reference Irn-Bru in their first single, "I've Got A Habit."
Scottish Folk-n-Roll band Scocha has a song dedicated to Irn-Bru on their album "ScattyBoo". The song is called "Irn Bru".

</doc>
<doc id="14742" url="http://en.wikipedia.org/wiki?curid=14742" title="Internet Standard">
Internet Standard

In computer network engineering, an Internet Standard (abbreviated as "STD") is a normative specification of a technology or methodology applicable to the Internet. Internet Standards are created and published by the Internet Engineering Task Force (IETF).
Overview.
An Internet Standard is a special Request for Comments (RFC) or set of RFCs. An RFC that is to become a Standard or part of a Standard begins as an Internet Draft, and is later (usually after several revisions) accepted and published by the RFC Editor as an RFC and labeled a "Proposed Standard". Later, an RFC can be labeled "Internet Standard". Collectively, these stages are known as the "Standards Track", and are defined in RFC 2026 and RFC 6410. The label "Historic" is applied to deprecated Standards Track documents or obsolete RFCs that were published before the Standards Track was established.
Only the IETF, represented by the Internet Engineering Steering Group (IESG), can approve Standards Track RFCs. The definitive list of Internet Standards is maintained in Internet Standards document STD 1: "Internet Official Protocol Standards".
Standardization process.
Becoming a standard is a two-step process within the IETF called Proposed Standards and Internet Standards. If an RFC is part of a proposal that is on the Standard Track, then at the first stage, the standard is proposed and subsequently organizations decide whether to implement this Proposed Standard. After the criteria in RFC 6410 is met (two separate implementations, widespread use, no errata etc.), the RFC can advance to Internet Standard.
The Internet Standards Process is defined in several "Best Current Practice" documents, notably (currently[ [update]] RFC 2026 and RFC 6410). There were previously three standard maturity levels "Proposed Standard", "Draft Standard" and "Internet Standard". RFC 6410 reduced this to two maturity levels.
Proposed Standard.
A "Proposed Standard" (PS) is generally stable, has resolved known design choices, is believed to be well-understood, has received significant community review, and appears to enjoy enough community interest to be considered valuable. However, further experience might result in a change or even retraction of the specification before it advances. Usually, neither implementation nor operational experience is required.
Draft Standard.
In October 2011 RFC 6410 in essence merged this second and the third Internet Standard maturity level for future Internet Standards. Existing older "Draft Standards" retain that classification. The IESG can reclassify an old "Draft Standard" as "Proposed Standard" after two years (October 2013).
Internet Standard.
An Internet Standard is characterized by a high degree of technical maturity and by a generally held belief that the specified protocol or service provides significant benefit to the Internet community. Generally Internet Standards cover interoperability of systems on the Internet through defining protocols, message formats, schemas, and languages. The most fundamental of the Internet Standards are the ones defining the Internet Protocol.
An Internet Standard ensures that hardware and software produced by different vendors can work together. Having a standard makes it much easier to develop software and hardware that link different networks because software and hardware can be developed one layer at a time. Normally, the standards used in data communication are called protocols.
All Internet Standards are given a number in the STD series - The first document in this series, STD 1, describes the remaining documents in the series, and has a list of Proposed Standards.
Each RFC is static; if the document is changed, it is submitted again and assigned a new RFC number. If an RFC becomes an Internet Standard (STD), it is assigned an STD number but retains its RFC number. When an Internet Standard is updated, its number stays the same and it simply refers to a different RFC or set of RFCs. A given Internet Standard, STD "n", may be RFCs "x" and "y" at a given time, but later the same standard may be updated to be RFC "z" instead. For example, in 2007 RFC 3700 was an Internet Standard—STD 1—and in May 2008 it was replaced with RFC 5000, so RFC 3700 changed to "Historic" status, and now[ [update]] STD 1 is RFC 5000. When STD 1 is updated again, it will simply refer to a newer RFC, but it will still be STD 1. Note that not all RFCs are standards-track documents, but all Internet Standards and other standards-track documents are RFCs.
The list of Internet standards in RFC 5000 ends with STD 68 (RFC 5234, ABNF) published in 2008. It does not cover STD 69 (a set of five EPP RFCs), 
STD 70 (RFC 5652, CMS) published in 2009, 
STD 71 (RFC 6152, 8BITMIME), and STD 72 (RFC 6409, Mail Submission) published in 2011.

</doc>
<doc id="14743" url="http://en.wikipedia.org/wiki?curid=14743" title="ISOC">
ISOC

ISOC is an abbreviation which may refer to:

</doc>
<doc id="14744" url="http://en.wikipedia.org/wiki?curid=14744" title="ITU-T">
ITU-T

The ITU Telecommunication Standardization Sector (ITU-T) is one of the three sectors (divisions or units) of the International Telecommunication Union (ITU); it coordinates standards for telecommunications. 
The standardization efforts of ITU commenced in 1865 with the formation of the International Telegraph Union (ITU). ITU became a United Nations specialized agency in 1947. The International Telegraph and Telephone Consultative Committee (CCITT, from French: "Comité Consultatif International Téléphonique et Télégraphique") was created in 1956, and was renamed ITU-T in 1993.
ITU-T has a permanent secretariat, the Telecommunication Standardization Bureau (TSB), based at the ITU headquarters in Geneva, Switzerland. The current Director of the Bureau is Chaesub Lee, whose 4-year term commenced on 1 January 2015, who replaced Malcolm Johnson of the United Kingdom, who was director from 1 January 2007 to 2014.
Primary function.
The ITU-T mission is to ensure the efficient and timely production of standards covering all fields of telecommunications on a worldwide basis, as well as defining tariff and accounting principles for international telecommunication services.
The international standards that are produced by the ITU-T are referred to as "Recommendations" (with the word ordinarily capitalized to distinguish its meaning from the ordinary sense of the word "recommendation"), as they become mandatory only when adopted as part of a national law.
Since the ITU-T is part of the ITU, which is a United Nations specialized agency, its standards carry more formal international weight than those of most other standards development organizations that publish technical specifications of a similar form.
History.
Although the ITU itself dates back to 1865, the formal standardization processes are more recent.
Two consultative committees were created by the ITU’s 1925 Paris conference to deal with the complexities of the international telephone services (known as CCIF, as the French acronym) and long-distance telegraphy (CCIT).
In view of the basic similarity of many of the technical problems faced by the CCIF and CCIT, a decision was taken in 1956 to merge them to become the single International Telegraph and Telephone Consultative Committee (CCITT, in the French acronym).
In 1992, the Plenipotentiary Conference (the top policy-making conference of ITU) saw a reform of ITU, giving the Union greater flexibility to adapt to an increasingly complex, interactive and competitive environment. It was at this time that CCITT was renamed the Telecommunication Standardization Sector (ITU-T), as one of three Sectors of the Union alongside the Radiocommunication Sector (ITU-R) and the Telecommunication Development Sector (ITU-D).
Historically, the Recommendations of the CCITT were presented to four-yearly plenary assemblies for endorsement, and the full set of Recommendations were published after each plenary assembly. However, the delays in producing texts, and translating them into other working languages, did not suit the fast pace of change in the telecommunications industry.
"Real time" standardization.
The rise of the personal computer industry in the early 1980s created a new common practice among both consumers and businesses of adopting "bleeding edge" communications technology even if it was not yet standardized. Thus, standards organizations had to put forth standards much faster, or find themselves ratifying de facto standards after the fact.
The ITU-T now operates under much more streamlined processes. The time between an initial proposal of a draft document by a member company and the final approval of a full-status ITU-T Recommendation can now be as short as a few months (or less in some cases). This makes the standardization approval process in the ITU-T much more responsive to the needs of rapid technology development than in the ITU's historical past. New and updated Recommendations are published on an almost daily basis, and much of the library of over 3,270 Recommendations is now free of charge online. (Specifications jointly maintained by the ITU-T and ISO/IEC are not free.)
ITU-T has moreover tried to facilitate cooperation between the various forums and standard-developing organizations (SDOs). This collaboration is necessary to avoid duplication of work and the consequent risk of conflicting standards in the market place.
In the work of standardization, ITU-T cooperates with other SDOs, e.g., the International Organization for Standardization (ISO) and the Internet Engineering Task Force (IETF).
Development of Recommendations.
Most of the work of ITU-T is carried out by its Sector Members and Associates, while the Telecommunication Standardization Bureau (TSB) is the executive arm of ITU-T and coordinator for a number of workshops and seminars to progress existing work areas and explore new ones. The events cover a wide array of topics in the field of information and communication technologies (ICT) and attract high-ranking experts as speakers, and attendees from engineers to high-level management from all industry sectors.
The technical work, the development of Recommendations, of ITU-T is managed by Study Groups (SGs). The people involved in these SGs are experts in telecommunications from all over the world. There are currently 13 SGs. Study groups meet face to face according to a calendar issued by the TSB. SGs are augmented by Focus Groups (FGs), an instrument created by ITU-T, providing a way to quickly react to ICT standardization needs and allowing great flexibility in terms of participation and working methods. The key difference between SGs and FGs is that the latter have greater freedom to organize and finance themselves, and to involve non-members in their work. Focus Groups can be created very quickly, are usually short-lived and can choose their own working methods, leadership, financing, and types of deliverables. Recent examples include work on Next Generation Networking, Internet Protocol Television (IPTV) and digital identity management.
Approval of Recommendations.
The “Alternative Approval Process” (AAP) is a fast-track approval procedure that was developed to allow standards to be brought to market in the timeframe that industry now demands.
This dramatic overhaul of standards-making by streamlining approval procedures was implemented in 2001 and is estimated to have cut the time involved in this critical aspect of the standardization process by 80 to 90 per cent. This means that an average standard which took around four years to approve and publish until the mid nineties, and two years until 1997, can now be approved in an average of two months, or as little as five weeks.
Besides streamlining the underlying procedures involved in the approval process, an important contributory factor to the use of AAP is electronic document handling. Once the approval process has begun the rest of the process can be completed electronically, in the vast majority of cases, with no further physical meetings.
The introduction of AAP also formalizes public/private partnership in the approval process by providing equal opportunities for both Sector Members and Member States in the approval of technical standards.
Once the text of a draft Recommendation prepared by SG experts is considered mature, it is submitted for review to an SG meeting. If agreed by the meeting it is given Consent. This means that the SG has given its consent that the text is sufficiently mature to initiate a final review process leading to approval of the draft Recommendation.
After this Consent has been achieved, TSB announces the start of the AAP procedure by posting the draft text to the ITU-T web site and calling for comments. This gives the opportunity for all members to review the text. This phase, called Last Call, is a four-week period in which comments can be submitted by Member States and Sector Members.
If no comments other than editorial corrections are received, the Recommendation is considered approved since no issues were identified that might need any further work. However, if there are any comments, the SG chairman, in consultation with TSB, sets up a comment resolution process by the concerned experts. The revised text is then posted on the web for an Additional Review period of three weeks.
Similar to the Last Call phase, in Additional Review the Recommendation is considered as approved if no comments are received. If comments are received, it is apparent that there are some issues that still need more work, and the draft text and all comments are sent to the next Study Group meeting for further discussion and possible approval.
Those Recommendations considered as having policy or regulatory implications are approved through what is known as the “Traditional Approval Process” (TAP), which allows a longer period for reflection and commenting by Member States. TAP Recommendations are also translated into the six working languages of ITU (Arabic, Chinese, English, French, Russian and Spanish).
Series and Recommendations.
ITU-T Recommendations are the names given to telecommunications and computer protocol specification documents published by ITU-T.
Many of the Recommendations that define OSI are also ISO standards.
Standards for Internet protocols are typically developed in the IETF, and standards for mobile telephone systems are developed in ETSI and other forums.
Series of ITU Recommendations.
ITU-T issues Recommendations that have names like X.500, where X is the series and 500 is an identifying number. When a Recommendation is updated, it will (mostly) keep the same number, so the year of issue may be necessary to identify a specific version of a Recommendation. The term "X.500" is used both to refer to the specific X.500 Recommendation, and to the entire family of Recommendations named X.5xx, where the specific X.500 Recommendation forms the introduction and overview to the set.
International Telecommunication Regulations (ITRs).
In addition to the ITU-T Recommendations, which have non-mandatory status until they are adopted in national laws, ITU-T is also the custodian of a binding international treaty, the International Telecommunication Regulations. The ITRs go back to the earliest days of the ITU when there were two separate treaties, dealing with telegraph and telephone. The ITRs were adopted, as a single treaty, at the World Administrative Telegraphy and Telephone Conference held in Melbourne, 1988 (WATTC-88).
The ITRs comprise ten articles which deal, inter alia, with the definition of international telecommunication services, cooperation between countries and national administrations, safety of life and priority of telecommunications and charging and accounting principles. The adoption of the ITRs in 1988 is often taken as the start of the wider liberalization process in international telecommunications, though a few countries, including United States and United Kingdom, had made steps to liberalize their markets before 1988.
The Constitution and Convention of ITU provides for the amendment of ITRs through a World Conference on International Telecommunications (WCIT). Accordingly, in 1998 there began a process of review of the ITRs; and in 2009 extensive preparations began for such a conference, WCIT-12. In addition to "regional preparatory meetings," the ITU Secretariat developed 13 "Background Briefs on key issues" that were expected to be discussed at the conference. Convened by former ITU secretary-general Hamadoun Touré, the Conference, WCIT-12, was then held in Dubai, United Arab Emirates, during the period 3-14 December 2014. 

</doc>
<doc id="14745" url="http://en.wikipedia.org/wiki?curid=14745" title="Indian">
Indian

Indian or Indians may refer to:

</doc>
<doc id="14746" url="http://en.wikipedia.org/wiki?curid=14746" title="Internalization">
Internalization

Internalization (or internalisation) has different definitions depending on the field that the term is used in. Internalization is the opposite of externalization. Generally, internalization is the process of consolidating and embedding one's own beliefs, attitudes, and values when it comes to moral behavior. The accomplishment of this may involve the deliberate use of psychoanalytical or behavioral methods.
Internalization of norms might take place following religious conversion, or in the process of the more general moral conversion of the person. Internalization is also often associated with learning (for example, learning ideas or skills) and making use of what has been learned from then on. The notion of internalization therefore also finds currency in applications in education, learning, and training, and in business and management thinking.
Psychology and sociology.
In sciences such as psychology and sociology, internalization involves the integration of attitudes, values, standards and the opinions of others into one's own identity or sense of self. In psychoanalytic theory, internalization is a process involving the formation of the super ego. Many theorists believe that the internalized values of behavior implemented during early socialization are key factors in predicting a child's future moral character. The self-determination theory proposes a motivational continuum from the extrinsic to intrinsic motivation and autonomous self-regulation. Some research suggests a child's moral self starts to develop around age three. These early years of socialization may be the underpinnings of moral development in later childhood. Proponents of this theory suggest that children whose view of self is "good and moral" tend to have a developmental trajectory toward pro-social behavior and few signs of anti-social behavior.
In one child developmental study, researchers examined two key dimensions of early conscience – internalization of rules of conduct and empathic affects to others – as factors that may predict future social, adaptive and competent behavior. Data was collected from a longitudinal study of children, from two parent families, at age 25, 38, 52, 67 and 80 months. Children's internalization of each parent's rules and empathy toward each parent's simulated distress were observed at 25, 38 and 52 months. Parents and teachers rated their adaptive, competent, pro-social behavior and anti-social behavior at 80 months. The researchers found that first, both the history of the child's early internalization of parental rules and the history of his or her empathy predicted the children's competent and adaptive functioning at 80 months, as rated by parents and teachers. Second, children with stronger histories of internalization of parental rules from 25 to 52 months perceived themselves as more moral at 67 months. Third, the children that showed stronger internalization from 25 to 52 months came to see themselves as more moral and "good." These self-perceptions, in turn, predicted the way parents and teachers would rate their competent and adaptive functioning at 80 months.
Internalization as symptom.
In behavioral psychology, the concept of internalization may also refer to disorders and behaviors in which a patient deals with stressors in manners not externally evident. Such disorders and behaviors include depression, anxiety, bulimia and anorexia.
Biology.
In sciences such as biology, internalization is another term for endocytosis, in which molecules such as proteins are engulfed by the cell membrane and drawn into the cell.
Economics and management.
In economics, internalization theory explains the practice of multinational enterprises (MNEs) to execute transactions within their organization rather than relying on an outside market. It must be cheaper for an MNE to internalize the transfer of its unique ownership advantages between countries than to do so through markets. In other words, the alternative to internalization through direct investment is some form of licensing of the firm's know-how to a firm in the target economy.
Finance.
In finance, internalization can refer to several concepts. "When you place an order to buy or sell a stock, your broker has choices on where to execute your order. Instead of routing your order to a market or market-makers for execution, your broker may fill the order from the firm's own inventory – this is called 'internalization.' In this way, your broker's firm may make money on the "spread" – which is the difference between the purchase price and the sale price." For a related issue regarding trade execution, see payment for order flow.

</doc>
<doc id="14747" url="http://en.wikipedia.org/wiki?curid=14747" title="Ionic">
Ionic

Ionic or Ionian may refer to:

</doc>
<doc id="14749" url="http://en.wikipedia.org/wiki?curid=14749" title="Indium">
Indium

Indium is a chemical element with symbol In and atomic number 49. It is a post-transition metallic element that is rare in Earth's crust. It has no obvious role in biological processes, but is of considerable industrial importance. The metal is very soft, malleable and easily fusible, with a melting point higher than sodium, but lower than lithium or tin. Given its physical nature and position in the periodic table, it counts as a heavy metal, but in common circumstances is not a toxic hazard. Chemically, indium is similar to gallium and thallium, and it is largely intermediate between the two in terms of its properties.
Characteristics.
Physical.
Indium is a very soft, silvery-white, highly ductile, relatively rare post-transition metal with a bright luster. It is so soft (Mohs hardness 1.2) that the metal can be cut with a knife, as can sodium. It also leaves a visible line on paper. Like tin, when it is bent indium emits a high-pitched "cry". Like gallium, indium is able to wet glass. Like both, indium has a low melting point, 156.60 °C (313.88 °F); higher than its lighter homologue, gallium, but lower than its heavier homologue, thallium, and lower than tin. Only mercury, gallium, and most of the alkali metals have lower melting points. Its boiling point is, however, moderate, being 2072 °C (3762 °F), which is higher than that of thallium, but lower than that of gallium, showing opposition to the melting points trend. Indium thus has a very large liquid range of around 2000 °C. The density of indium, 7.31 g·cm−3, is also higher than that of gallium, but lower than that of thallium. Below its critical temperature of 3.41 K, indium becomes a superconductor. At standard temperature and pressure, indium crystallizes in the tetragonal crystal system in the space group "I"4/"mmm" (lattice parameters: "a" = 325 pm, "c" = 495 pm).
Chemical.
See also: .
Indium is an post-transition metal and chemically, is the intermediate element between its group 13 neighbors gallium and thallium. An indium atom has 49 electrons, having an electronic configuration of [Kr]4d105s25p1. In its compounds, indium most commonly loses its three outermost electrons, becoming indium(III) ions, In3+, but in some cases the pair of 5s-electrons can stay within the atom, indium thus being oxidized only to indium(I), In+. This happens due to the inert pair effect, which occurs because of the stabilization of 5s-orbital due to relativistic effects, which are stronger closer to the bottom of the periodic table. In(III) is the more stable oxidation state. Thallium (indium's heavier homolog) shows an even stronger effect, making oxidation to thallium(I) more likely than to thallium(III), making +1 the more likely oxidation state, whereas gallium (indium's lighter homolog) commonly shows only the +3 oxidation state. Thus, although thallium(III) is a moderately strong oxidizing agent, indium(III) is stable and indium(I) is a powerful reducing agent.
A number of standard electrode potentials, depending on the reaction under study, are reported for indium:
Indium does not react with water, but it is oxidized by stronger oxidizing agents, such as halogens or oxalic acid, to give indium(III) compounds. It does not react with boron, silicon or carbon, and the corresponding boride, silicide or carbide are not known. Similarly, reaction between indium and hydrogen has not been observed, but both indium(I) and indium(III) hydrides are known.
Indium(III) oxide is formed at high temperatures during reaction between indium and oxygen, with blue flame. It is amphoteric, i. e. it can react with both acids and bases. Its reaction with water results in insoluble indium(III) hydroxide, which is also amphoteric, reacting with alkalies to give indates(III) and with acids to give indium(III) salts:
The hydrolysis of sodium indate(III) gives weak indic acid, HInO2. Out of common indium(III) salts, chloride, sulfate and nitrate are soluble. In water solutions, In3+ and [InO2]− ions are hydrolyzed to give InOH2+ and HInO2 due to generally amphoteric character of indium(III) ions. Indium(III) compounds are not well-soluble, similarly to thallium(III) compounds; however, indium(III) salts of strong acids, such as chloride, sulfate and nitrate are soluble, hydrolyzing in water solutions. The In3+ ion is colorless in solution because of the absence of unpaired electrons in the d- and f-electron shells.
Indium(I) compounds are not as common as indium(III) ones; only chloride, bromide, iodide, sulfide and cyclopentadienyl are well-characterized. Indium(I) sulfide is the product of reaction between indium and sulfur or indium and hydrogen sulfide, and can be received at 700—1000 °C. Indium(I) oxide black powder is received at 850 °C during reaction between indium and carbon dioxide or during decomposition of indium(III) oxide at 1200 °C. Cyclopentadienylindium(I), which was the first organoindium(I) compound reported, is polymer consisting of zigzag chains of alternating indium atoms and cyclopentadienyl complexes.
Less frequently, indium shows an intermediate oxidation state +2, in compounds with an In–In bond, most notably in halides, In2X4 and [In2X6]2−. Several other compounds are known to combine indium(I) and indium(III), such as InI6(InIIICl6)Cl3, InI5(InIIIBr4)2(InIIIBr6), InIInIIIBr4.
In organic synthesis it is used for indium-mediated allylation.
Biological and medical.
Indium is not known to have any metabolic role in any organism. In a similar way to aluminium salts, indium(III) ions can be toxic to the kidney when given by injection, but oral indium compounds do not have the chronic toxicity of salts of heavy metals, probably due to poor absorption in basic conditions. Radioactive indium-111 (in very small amounts on a chemical basis) is used in nuclear medicine tests, as a radiotracer to follow the movement of labeled proteins and white blood cells in the body.
Isotopes.
Indium has 39 known isotopes, ranging in mass from 97 to 135. Only two isotopes occur naturally in primordial nuclides: indium-113, the only stable isotope, and indium-115, which has a half-life of 4.41×1014 years, four orders of magnitude longer than the age of the universe and nearly 50,000 times longer than that of natural thorium. Indium-115 makes up 95.7% of all indium. This situation is uncommon among stable chemical elements; only indium, tellurium, and rhenium have been shown to have most-abundant isotopes that are radioactive. 
The most stable artificial indium isotope is indium-111, which has half-life of approximately 2.8 days. All other isotopes have half-lives shorter than 5 hours. Indium also has 47 meta states; indium-114m1 is the most stable, being more stable than the ground state of any indium isotope other than the primordial ones.
Creation.
Indium is created via the long-lasting, (up to thousands of years), s-process in low-to-medium mass stars (which range in mass between 0.6 and 10 solar masses). When a silver-109 atom (the isotope of which approximately half of all silver in existence is composed), catches a neutron, it undergoes a beta decay to become cadmium-110. Capturing further neutrons, it becomes cadmium-115, which decays to indium-115 via another beta decay. This explains why the radioactive isotope predominates in abundance compared to the stable one.
Occurrence.
In Earth's crust, indium occurs only in the form of its compounds, except occasionally as rare grains of free metal of no commercial importance. Indium is 68th most abundant element in Earth's crust at approximately 160 ppb, making indium approximately as abundant as cadmium.
Fewer than 10 indium minerals are known, such as dzhalindite (In(OH)3) and indite (FeIn2S4), but none of these occurs in significant deposits.
Based on content of indium in zinc ore stocks, there is a worldwide reserve of approximately 6,000 tonnes of economically viable indium. However, the Indium Corporation, the largest processor of indium, claims that, on the basis of increasing recovery yields during extraction, recovery from a wider range of base metals (including tin, copper and other polymetallic deposits) and new mining investments, the long-term supply of indium is sustainable, reliable, and sufficient to meet increasing future demands. This conclusion may be reasonable considering that silver, which is one-third as abundant as indium in Earth's crust, is currently mined at approximately 18,300 tonnes per year, which is 40 times greater than current indium mining rates.
History.
In 1863, the German chemists Ferdinand Reich and Hieronymous Theodor Richter were testing ores from the mines around Freiberg, Saxony. They dissolved the minerals pyrite, arsenopyrite, galena and sphalerite in hydrochloric acid and distilled raw zinc chloride. As it was known that ores from that region sometimes contain thallium they searched for the green emission lines with spectroscopy. The green lines were absent but a blue line was present in the spectrum. As no element was known with a bright blue emission they concluded that a new element was present in the minerals. They named the element with the blue spectral line indium, from the indigo color seen in its spectrum. That line was the first indication of an unknown element in zinc ores, and when the free metal was isolated in the following year it was named indium after the colour of the light that had provided a clue to its presence. Zinc ores still are the primary source of indium.
Richter went on to isolate the metal in 1864. At the World Fair 1867 an ingot of 0.5 kg was presented. 
In 1924, indium was found to have a valued ability to stabilize non-ferrous metals, which was the first significant use for the element. It took until 1936 for the U.S. Bureau of Mines to list indium as a commodity, and even in the early 1950s only very limited applications for indium were known, the most important of which was making light-emitting diodes and coating bearings for aircraft engines during World War II. The start of production of indium-containing semiconductors started in 1952. The development and widespread use of indium-containing nuclear control rods increased demand during the 1970s, and the use of indium tin oxide in liquid crystal displays increased and became the major application by 1992.
Currently the demand for indium is driven by the manufacture of transparent electrodes from indium tin oxide (ITO). The electrodes are used in liquid crystal displays and touchscreens. The metal also is used in a wide range of alloys; one of its first large-volume applications was in high-performance bearing alloys for aircraft) in WWII. It is also used for making particularly low melting point alloys, and is a component in some solders. One of its unusual attributes is that, like gallium molten indium wets glass, so that it can be used as a solder in glass seals. It also is used in a wide range of electric and electronic roles, and has been used in superconducting alloys.
Production.
The lack of indium mineral deposits and the fact that indium is enriched in sulfidic lead, tin, copper, iron and predominately in zinc deposits, makes zinc production the main source for indium. The indium is leached from slag and dust of zinc production. Further purification is done by electrolysis. The exact process varies with the exact composition of the slag and dust.
Indium is produced mainly from residues generated during zinc ore processing but is also found in iron, lead, and copper ores. China is a leading producer of indium (390 tonnes in 2012), followed by Canada, Japan and South Korea with 70 tonnes each. The Teck Cominco refinery in Trail, British Columbia, is a large single-source indium producer, with an output of 32.5 tonnes in 2005, 41.8 tonnes in 2004 and 36.1 tonnes in 2003. South American Silver Corporation's Malku Khota property in Bolivia is a large resource of indium with an indicated resource of 1,481 tonnes and inferred resource of 935 tonnes. Adex Mining Inc.’s Mount Pleasant Mine in New Brunswick, Canada, holds some of the world’s total known indium resources.
The amount of indium consumed is largely a function of worldwide LCD production. Worldwide production in 2007 was 475 tonnes per year from mining and a further 650 tonnes per year from recycling. Demand has risen rapidly in recent years with the popularity of LCD computer monitors and television sets, which now account for 50% of indium consumption. Increased manufacturing efficiency and recycling (especially in Japan) maintain a balance between demand and supply. According to the UNEP, indium's end-of-life recycling rate is less than 1%. Demand increased as the metal is used in LCDs and televisions, and supply decreased when a number of Chinese mining concerns stopped extracting indium from their zinc tailings. In 2002, the price was US$94 per kilogram. The recent changes in demand and supply have resulted in high and fluctuating prices of indium, which from 2006 to 2009 ranged from US$382/kg to US$918/kg.
It has been estimated that there are fewer than 14 years left of indium supplies, based on current rates of extraction, demonstrating the need for additional recycling.
Applications.
The first large-scale application for indium was as a coating for bearings in high-performance aircraft engines during World War II. Afterward, production gradually increased as new uses were found in fusible alloys, solders, and electronics. In the 1950s, tiny beads of it were used for the emitters and collectors of PNP alloy junction transistors. In the middle and late 1980s, the development of indium phosphide semiconductors and indium tin oxide thin films for liquid crystal displays (LCD) aroused much interest. By 1992, the thin-film application had become the largest end use.
Health issues.
The health effects of exposure to Indium have been little studied. The EU does not consider it a chemical of "High Concern". Indium tin oxide and indium phosphide have been shown to cause harm to the pulmonary and immune systems, predominantly through ionic indium. Mild eye irritation may result from exposure to its dust or vapor. Lab studies in animals have shown injection may cause liver and kidney damage. Because of its rarity, little is known about its ecological fate, bioaccumulation has not been ruled out.

</doc>
<doc id="14750" url="http://en.wikipedia.org/wiki?curid=14750" title="Iodine">
Iodine

Iodine is a chemical element with symbol I and atomic number 53. The name is from Greek ἰοειδής "ioeidēs", meaning violet or purple, due to the color of elemental iodine vapor.
Iodine and its compounds are primarily used in nutrition, and industrially in the production of acetic acid and certain polymers. Iodine's relatively high atomic number, low toxicity, and ease of attachment to organic compounds have made it a part of many X-ray contrast materials in modern medicine. Iodine has only one stable isotope. A number of iodine radioisotopes, such as 131I, are also used in medical applications.
Iodine is found on Earth mainly as the highly water-soluble iodide ion I−, which concentrates it in oceans and brine pools. Like the other halogens, free iodine occurs mainly as a diatomic molecule I2, and then only momentarily after being oxidized from iodide by an oxidant like free oxygen. In the universe and on Earth, iodine's high atomic number makes it a relatively rare element. However, its presence in ocean water has given it a role in biology. It is the heaviest essential element utilized widely by life in biological functions (only tungsten, employed in enzymes by a few species of bacteria, is heavier). Iodine's rarity in many soils, due to initial low abundance as a crust-element, and also leaching of soluble iodide by rainwater, has led to many deficiency problems in land animals and inland human populations. Iodine deficiency affects about two billion people and is the leading preventable cause of intellectual disabilities.
Iodine is required by higher animals for synthesizing thyroid hormones, which contain the element. Because of this function, radioisotopes of iodine are concentrated in the thyroid gland along with nonradioactive iodine. If inhaled, the radioisotope iodine-131, which has a high fission product yield, concentrates in the thyroid, but is easily remedied with non-radioactive potassium iodide treatment.
Characteristics.
Under standard conditions, iodine is a bluish-black solid appearing to sublimate into a noxious violet-pink gas, the colour due to absorption of visible light by electronic transitions between the highest occupied and lowest unoccupied molecular orbitals. Melting at 113.7 C, it forms compounds with many elements but is less reactive than the other members of its group, the halogens, and has some metallic light reflectance.
Elemental iodine is slightly soluble in water, with one gram dissolving in 3450 ml at 20 °C and 1280 ml at 50 °C; potassium iodide may be added to increase solubility via formation of triiodide ions. Nonpolar solvents such as hexane and carbon tetrachloride provide a higher solubility. Polar solutions are brown, reflecting the role of these solvents as Lewis bases, while nonpolar solutions are violet, the color of iodine vapor. Charge-transfer complexes form when iodine is dissolved in polar solvents, modifying the energy distribution of iodine's molecular orbitals, hence changing the colour. A metal ion may replace the solvent, in which case the two species exchange electrons, the ion undergoing π backbonding.
Structure and bonding.
Iodine normally exists as a diatomic molecule with an I-I bond length of 270 pm, one of the longest single bonds known. The I2 molecules tend to interact via the weak van der Waals forces called the London dispersion forces, and this interaction is responsible for the higher melting point compared to more compact halogens, which are also diatomic. Since the atomic size of iodine is larger, its melting point is higher. The solid crystallizes as orthorhombic crystals. The crystal motif in the Hermann–Mauguin notation is Cmca (No 64), Pearson symbol oS8. The I-I bond is relatively weak, with a bond dissociation energy of 36 kcal/mol, and most bonds to iodine are weaker than for the lighter halides. One consequence of this weak bonding is the relatively high tendency of I2 molecules to dissociate into atomic iodine.
Isotopes.
Of the 37 known (characterized) isotopes of iodine, only one, 127I, is stable.
The longest-lived radioisotope, 129I, has a half-life of 15.7 million years. This is long enough to make it a permanent fixture of the environment on human time scales, but far too short for it to exist as a primordial isotope today. Instead, iodine-129 is an extinct radionuclide, and its presence in the early Solar System is inferred from the observation of an excess of its daughter xenon-129. This nuclide is also newly made by cosmic rays and as a byproduct of artificial nuclear fission, which it is used to monitor as a very long-lived environmental contaminant.
The next-longest-lived radioisotope, iodine-125, has a half-life of 59 days. It is used as a convenient gamma-emitting tag for proteins in biological assays, and a few nuclear medicine imaging tests where a longer half-life is required. It is also commonly used in brachytherapy implanted capsules, which kill tumors by local short-range gamma radiation (but where the isotope is never released into the body).
Iodine-123 (half-life 13 hours) is the isotope of choice for nuclear medicine imaging of the thyroid gland, which naturally accumulates all iodine isotopes.
Iodine-131 (half-life 8 days) is a beta-emitting isotope, which is a common nuclear fission product. It is preferably administered to humans only in very high doses that destroy all tissues that accumulate it (usually the thyroid), which in turn prevents these tissues from developing cancer from a lower dose (paradoxically, a high dose of this isotope appears safer for the thyroid than a low dose). Like other radioiodines, I-131 accumulates in the thyroid gland, but unlike the others, in small amounts it is highly carcinogenic there, it seems, owing to the high local cell mutation due to damage from beta decay. Because of this tendency of 131I to cause high damage to cells that accumulate it and other cells near them (0.6 to 2 mm away, the range of the beta rays), it is the only iodine radioisotope used as direct therapy, to kill tissues such as cancers that take up artificially iodinated molecules (example, the compound iobenguane, also known as MIBG). For the same reason, only the iodine isotope I-131 is used to treat Grave's disease and those types of thyroid cancers (sometimes in metastatic form) where the tissue that requires destruction, still functions to naturally accumulate iodide.
Nonradioactive ordinary potassium iodide (iodine-127), in a number of convenient forms (tablets or solution) may be used to saturate the thyroid gland's ability to take up further iodine, and thus protect against accidental contamination from iodine-131 generated by nuclear fission accidents, such as the Chernobyl disaster and more recently the Fukushima I nuclear accidents, as well as from contamination from this isotope in nuclear fallout from nuclear weapons.
Occurrence.
Iodine is rare in the Solar System and Earth's crust (47–60th in abundance); however, iodide salts are often very soluble in water. Iodine occurs in slightly greater concentrations in seawater than in rocks, 0.05 vs. 0.04 ppm. Minerals containing iodine include caliche, found in Chile. The brown algae "Laminaria" and "Fucus" found in temperate zones of the Northern Hemisphere contain 0.028–0.454 dry weight percent of iodine. Aside from tungsten, iodine is the heaviest element to be essential in living organisms. About 19,000 tonnes are produced annually from natural sources.
Organoiodine compounds are produced by marine life forms, the most notable being iodomethane (commonly called methyl iodide). About 214 kilotonnes/year of iodomethane is produced by the marine environment, by microbial activity in rice paddies and by the burning of biological material. The volatile iodomethane is broken up in the atmosphere as part of a global iodine cycle.
Chemistry.
Iodine adopts a variety of oxidation states, commonly ranging from (formally) I(VII) to I(-I), and including the intermediate states of I(V), I(III) and I(I). Practically, only the −1 oxidation state is of significance, being the form found in iodide salts and organoiodine compounds. Iodine is a Lewis acid. With electron donors such as triphenylphosphine and pyridine it forms a charge-transfer complex. With the iodide anion it forms the triiodide ion.
Iodine and the iodide ion form a redox couple. I2 is easily reduced and I− is easily oxidized.
Redox reactions.
In everyday life, iodides are slowly oxidized by atmospheric oxygen to give free iodine. Evidence for this conversion is the yellow tint of certain aged samples of iodide salts and some organoiodine compounds. The oxidation of iodide to iodine in air is also responsible for the slow loss of iodide content in iodized salt if exposed to air. Some salts use iodate (IO3-) to prevent the loss of iodine.
Iodine is easily reduced. Most common is the interconversion of I− and I2. Molecular iodine can be prepared by oxidizing iodides with chlorine:
or with manganese dioxide in acid solution:
Iodine is reduced to hydrogen iodide by hydrogen sulfide and hydrazine:
When dissolved in fuming sulfuric acid (65% oleum), iodine forms an intense blue solution. The blue color is due to I2+ cation, the result of iodine being oxidized by SO3:
The I2+ cation is also formed in the oxidation of iodine by SbF5 or TaF5. The resulting I2+SbF11- or I2+TaF11- can be isolated as deep blue crystals. The solutions of these salts turn red when cooled below −60 °C, owing to the formation of the I42+ cation:
Under slightly more alkaline conditions, I42+ disproportionates into I3+ and an iodine(III) compound. Excess iodine can then react with I3+ to form I5+ (green) and I153+ (black).
Oxides.
The best-known oxides are the anions, IO3- and IO4-, but several other oxides are known, such as the strong oxidant iodine pentoxide.
By contrast with chlorine, the formation of the hypohalite ion (IO−) in neutral aqueous solutions of iodine is negligible.
Organic derivatives of hypoiodate (2-Iodoxybenzoic acid, and Dess-Martin periodinane) are used in organic chemistry.
Iodic acid (HIO3), periodic acid (HIO4) and their salts are strong oxidizers and are of some use in organic synthesis. Iodine is oxidized to iodate by nitric acid as well as by chlorates:
Other inorganic compounds.
Iodine forms compounds with all the elements except for the noble gases. From the perspective of commercial applications, an important compound is hydroiodic acid, used as a co-catalyst in the Cativa process for the production of acetic acid. Titanium and aluminium iodides are used in the production of butadiene, a precursor to rubber tires.
Alkali metal salts are common colourless solids that are highly soluble in water. Potassium iodide is a convenient source of the iodide anion; it is easier to handle than sodium iodide because it is not hygroscopic. Both salts are mainly used in the production of iodized salt. Sodium iodide is especially useful in the Finkelstein reaction, because it is soluble in acetone, whereas potassium iodide is less so. In this reaction, an alkyl chloride is converted to an alkyl iodide. This relies on the insolubility of sodium chloride in acetone to drive the reaction:
Despite having the lowest electronegativity of the common halogens, iodine reacts violently with some metals, such as aluminium:
This reaction produces 314 kJ per mole of aluminium, comparable to thermite's 425 kJ. Yet the reaction initiates spontaneously, and if unconfined, causes a cloud of gaseous iodine due to the high temperature.
Interhalogen compounds are well known; examples include iodine monochloride and trichloride; iodine pentafluoride and heptafluoride.
Organic compounds.
Organoiodine compounds can be made in many ways. For example, methyl iodide can be prepared from methanol, red phosphorus, and iodine. The iodinating reagent is phosphorus triiodide that is formed "in situ":
The simplest organoiodine compound is iodomethane, approved as a soil fumigant. The iodoform test uses an alkaline solution of iodine to react with methyl ketones to give the labile triiodomethide leaving group, forming iodoform, which precipitates. Aryl and alkyl iodides both form Grignard reagents. Iodine is sometimes used to activate magnesium when preparing Grignard reagents. Alkyl iodides such as iodomethane are good alkylating agents.
Some drawbacks to the use of organoiodine compounds in chemical synthesis are:
Production.
Of the several places in which iodine occurs in nature, only two sources are useful commercially: the caliche, found in Chile, and the iodine-containing brines of gas and oil fields, especially in Japan and the United States. The caliche contains sodium nitrate, which is the main product of the mining activities, and small amounts of sodium iodate and sodium iodide. In the extraction of sodium nitrate, the sodium iodate and sodium iodide are also extracted. The high concentration of iodine in the caliche and the extensive mining made Chile the largest producer of iodine in 2007.
Most other producers use naturally occurring brine for the production of iodine. The Japanese Minami Kanto gas field east of Tokyo and the American Anadarko Basin gas field in northwest Oklahoma are the two largest sources for iodine from brine. The brine has a temperature of over 60 °C owing to the depth of the source. The brine is first purified and acidified using sulfuric acid, then the iodide present is oxidized to iodine with chlorine. An iodine solution is produced, but is dilute and must be concentrated. Air is blown into the solution, causing the iodine to evaporate, then it is passed into an absorbing tower containing acid where sulfur dioxide is added to reduce the iodine. The hydrogen iodide (HI) is reacted with chlorine to precipitate the iodine. After filtering and purification the iodine is packed.
The production of iodine from seawater via electrolysis is not used owing to the sufficient abundance of iodine-rich brine. Another source of iodine is kelp, used in the 18th and 19th centuries, but it is no longer economically viable.
Commercial samples often contain high concentrations of impurities, which can be removed by sublimation. The element may also be prepared in an ultra-pure form through the reaction of potassium iodide with copper(II) sulfate, which gives copper(II) iodide initially, which then decomposes spontaneously to copper(I) iodide and iodine:
There are also other methods of isolating this element in the laboratory, for example, the method used to isolate other halogens: oxidation of the iodide in hydrogen iodide (often made "in situ" with an iodide and sulfuric acid) by manganese dioxide.
History.
Iodine was discovered by French chemist Bernard Courtois in 1811. He was born to a manufacturer of saltpeter (a vital part of gunpowder). At the time of the Napoleonic Wars, France was at war and saltpeter was in great demand. Saltpeter produced from French niter beds required sodium carbonate, which could be isolated from seaweed collected on the coasts of Normandy and Brittany. To isolate the sodium carbonate, seaweed was burned and the ash washed with water. The remaining waste was destroyed by adding sulfuric acid. Courtois once added excessive sulfuric acid and a cloud of purple vapor rose. He noted that the vapor crystallized on cold surfaces, making dark crystals. Courtois suspected that this was a new element but lacked funding to pursue it further.
Courtois gave samples to his friends, Charles Bernard Desormes (1777–1862) and Nicolas Clément (1779–1841), to continue research. He also gave some of the substance to chemist Joseph Louis Gay-Lussac (1778–1850), and to physicist André-Marie Ampère (1775–1836). On 29 November 1813, Desormes and Clément made public Courtois's discovery. They described the substance to a meeting of the Imperial Institute of France. On 6 December, Gay-Lussac announced that the new substance was either an element or a compound of oxygen. It was Gay-Lussac who suggested the name "iode", from the Greek word ιώδες (iodes) for violet (because of the color of iodine vapor). Ampère had given some of his sample to English chemist Humphry Davy (1778–1829). Davy did some experiments on the substance and noted its similarity to chlorine. Davy sent a letter dated 10 December to the Royal Society of London stating that he had identified a new element. Arguments erupted between Davy and Gay-Lussac over who identified iodine first, but both scientists acknowledged Courtois as the first to isolate the element.
Applications.
The production of ethylenediamine dihydroiodide, provided as a nutritional supplement for livestock, consumes a large fraction of available iodine. Another significant use is as a co-catalyst for the production of acetic acid by the Monsanto and Cativa processes. In these technologies, which support the world's demand for acetic acid, hydroiodic acid converts the methanol feedstock into methyl iodide, which undergoes carbonylation. Hydrolysis of the resulting acetyl iodide regenerates hydroiodic acid and gives acetic acid.
Disinfectants.
Elemental iodine is used as a disinfectant in various forms. The iodine exists as the element, or as the water-soluble triiodide anion I3− generated "in situ" by adding iodide to poorly water-soluble elemental iodine (the reverse chemical reaction makes some free elemental iodine available for antisepsis). In alternative fashion, iodine may come from iodophors, which contain iodine complexed with a solubilizing agent (iodide ion may be thought of loosely as the iodophor in triiodide water solutions). Examples of such preparations include:
Analysis.
Iodine is useful in analytical chemistry because of its reactions with alkenes, starch and oxidizing and reducing agents. The highly colored species involved in these reactions make it easy to detect the endpoints in many analytical determinations.
Iodine is a common general stain used in thin-layer chromatography.
Iodine forms an intense blue complex with the glucose polymers starch and glycogen. Several analytical methods rely on this property:
Iodine value or iodine number is used to indicate the number of carbon-carbon double bonds in vegetable oils and fatty acids.
Medical applications.
Potassium iodide has been used as an expectorant, although this use is increasingly uncommon. In medicine, potassium iodide is usually used to treat acute thyrotoxicosis, usually as a saturated solution of potassium iodide called SSKI. It is also used to block uptake of iodine-131 in the thyroid gland (see isotopes section above), when this isotope is used as part of radiopharmaceuticals (such as iobenguane) that are not targeted to the thyroid or thyroid-type tissues.
Iodine-131 (usually in the chemical form of iodide) is a component of nuclear fallout, and is particularly dangerous owing to the thyroid gland's propensity to concentrate ingested iodine, where it is kept for periods longer than this isotope's radiological half-life of eight days. For this reason, if people are expected to be exposed to a significant amount of environmental radioactive iodine (iodine-131 in fallout), they may be instructed to take non-radioactive potassium iodide tablets. The typical adult dose is one 130 mg tablet per 24 hours, supplying 100 mg (100,000 micrograms) iodine, as iodide ion. (Typical daily dose of iodine to maintain normal health is of order 100 micrograms; see "Dietary Intake" below.) By ingesting this large amount of non-radioactive iodine, radioactive iodine uptake by the thyroid gland is minimized. See the article on potassium iodide for more on this topic.
Iodine, as an element with high electron density and atomic number, absorbs X-rays well. Therefore, it may be used as a radiocontrast agent by filtering out imaging X-rays weaker than 33.3 keV, where iodine's innermost electrons begin absorbing X-rays strongly due to the photoelectric effect. Organic compounds of a certain type (typically iodine-substituted benzene derivatives) are thus used in medicine as X-ray radiocontrast agents for intravenous injection. This is often in conjunction with advanced X-ray techniques such as angiography and CT scanning. At present, all water-soluble radiocontrast agents rely on iodine. It is on the World Health Organization's List of Essential Medicines, a list of the most important medication needed in a basic health system.
Historical medical applications.
In the early 1900s, the Encyclopædia Britannica described iodine as being "of definite value" for treatment of multiple conditions including "metallic poisonings, as by lead and mercury, asthma, aneurism, arteriosclerosis, angina pectoris, gout, goitre, syphilis, haemophilia, Bright's disease (nephritis) and bronchitis" with "usual doses" of iodide salts ranging from "five to thirty grains or more" (324,000mcg to 1,944,000mcg, though this is hundred of times higher than what is considered generally safe per today's tolerable UL). For treatment of syphilis, it states "in its tertiary stages and also earlier this disease yields in the most rapid and unmistakable fashion to iodides; so much so that the administration of these salts is at present the best means of determining whether, for instance, a cranial tumour be syphilitic or not" (modern treatment for syphilis involves the use of antibiotics to kill syphilis bacteria - see Syphilis). For the treatment of chronic lead poisoning, it states "the essential part of the medicinal treatment of this condition is the administration of iodides, which are able to decompose the insoluble albuminates of lead which have become locked up in the tissues, rapidly causing their degeneration, and to cause the excretion of the poisonous metal by means of the intestine and the kidneys" (modern treatment for lead poisoning involves the use of a variety of substances - see Lead poisoning).
Other uses.
Inorganic iodides find specialized uses. Hafnium, zirconium, titanium are purified by the van Arkel Process, which involves the reversible formation of the tetraiodides of these elements. Silver iodide is a major ingredient to traditional photographic film. Thousands of kilograms of silver iodide are consumed annually for cloud seeding.
The organoiodine compound erythrosine is an important food coloring agent. Perfluoroalkyl iodides are precursors to important surfactants, such as perfluorooctanesulfonic acid.
Iodine was also used by the police, especially forensics, Iodine fuming was an effective way of revealing latent fingerprints on paper and other similar surfaces. It is still used mildly today.
In the United States, the Drug Enforcement Administration (DEA) regards iodine and compounds containing iodine (ionic iodides, iodoform, ethyl iodide, and so on) as reagents useful for the clandestine manufacture of methamphetamine.
Iodine can be used to stabilize the wavelength of a helium–neon laser.
Biological role.
Iodine is an essential trace element for life, the heaviest element commonly needed by living organisms. Only tungsten, a component of a few bacterial enzymes, has a higher atomic number and atomic weight.
Iodine's main role in animal biology is as a constituent of the thyroid hormones "thyroxine" (T4) and "triiodothyronine" (T3). These are made from addition condensation products of the amino acid tyrosine, and are stored prior to release in an iodine-containing protein called thyroglobulin. T4 and T3 contain four and three atoms of iodine per molecule, respectively. The thyroid gland actively absorbs iodide from the blood to make and release these hormones into the blood, actions that are regulated by a second hormone TSH from the pituitary. Thyroid hormones are phylogenetically very old molecules that are synthesized by most multicellular organisms, and that even have some effect on unicellular organisms.
Thyroid hormones play a basic role in biology, acting on gene transcription to regulate the basal metabolic rate. Total deficiency of thyroid hormones can reduce basal metabolic rate up to 50%. Excessive production of thyroid hormones can increase the basal metabolic rate by 100%. T4 acts largely as a precursor to T3, which is (with minor exceptions) the biologically active hormone. In amphibian metamorphosis iodine and thyroid hormones exert a well-studied experimental model of apoptosis on the cells of gills, tail, and fins of tadpoles.
Iodine has a nutritional relationship with selenium. A family of selenium-dependent enzymes called deiodinases converts T4 to T3 (the active hormone) by removing an iodine atom from the outer tyrosine ring. These enzymes also convert T4 to reverse T3 (rT3) by removing an inner ring iodine atom, and convert T3 to 3,3'-diiodothyronine (T2) also by removing an inner ring atom. Both of the latter are inactivated hormones that are ready for disposal and have, in essence, no biological effects. A family of non-selenium-dependent enzymes then further deiodinates the products of these reactions.
Iodine accounts for 65% of the molecular weight of T4 and 59% of the T3. Fifteen to 20 mg of iodine is concentrated in thyroid tissue and hormones, but 70% of the body's iodine is distributed in other tissues, including mammary glands, eyes, gastric mucosa, fetal thymus, cerebro-spinal fluid and coroid plexus, arterial walls, the cervix, and salivary glands. In the cells of these tissues, iodide enters directly by sodium-iodide symporter (NIS). Its role in mammary tissue is related to fetal and neonatal development, but its role in the other tissues is partially unknown.
Dietary intake.
The daily Dietary Reference Intake recommended by the United States Institute of Medicine is between 110 and 130 µg for infants up to 12 months, 90 µg for children up to eight years, 130 µg for children up to 13 years, 150 µg for adults, 220 µg for pregnant women and 290 µg for lactating mothers. The Tolerable Upper Intake Level (UL) for adults is 1,100 μg/day (1.1 mg/day). The tolerable upper limit was assessed by analyzing the effect of supplementation on thyroid-stimulating hormone.
The thyroid gland needs no more than 70 μg/day to synthesize the requisite daily amounts of T4 and T3. The higher recommended daily allowance levels of iodine seem necessary for optimal function of a number of body systems, including lactating breast, gastric mucosa, salivary glands, oral mucosa, and arterial walls.
Natural sources of dietary iodine include seafood, such as fish, kelp and shellfish, dairy products such as milk, cheese and eggs and plants grown on iodine-rich soil. Iodized salt is fortified with iodine.
As of 2000, the median intake of iodine from food in the United States was 240 to 300 μg/day for men and 190 to 210 μg/day for women. In Japan, consumption was considered much higher, ranging between 5,280 μg/day to 13,800 μg/day, this owing to the frequent consumption of seaweed or kombu kelp. However, new studies suggest that Japan's consumption is closer to 1,000–3,000 μg/day.
After iodine fortification programs (e.g., iodized salt) have been implemented, some cases of iodine-induced hyperthyroidism have been observed (so-called Jod-Basedow phenomenon). The condition seems to occur mainly in people over forty, and the risk appears higher when iodine deficiency is severe and the initial rise in iodine intake is high.
Information processing, fine motor skills, and visual problem solving are improved by iodine repletion in moderately iodine-deficient children.
Deficiency.
In an estimated two-thirds of households on Earth, table salt is iodized. However, this still leaves an estimated two billion people iodine-deficient. Iodine is required for the essential thyroxin hormones produced by and concentrated in the thyroid gland.
In areas where there is little iodine in the diet, typically remote inland areas and semi-arid equatorial climates where no marine foods are eaten, iodine deficiency gives rise to hypothyroidism, symptoms of which are extreme fatigue, goitre, mental slowing, depression, weight gain, and low basal body temperatures. Iodine deficiency is the leading cause of preventable intellectual disability, a result that occurs primarily when babies or small children are rendered hypothyroidic by a lack of the element. The addition of iodine to table salt has largely eliminated this problem in the wealthier nations, but, as of March 2006, iodine deficiency remained a serious public health problem in the developing world. Iodine deficiency is also a problem in certain areas of Europe.
Other possible health effects being investigated as being related to deficiency include:
Toxicity.
Elemental iodine (I2) is toxic if taken orally. The lethal dose for an adult human is 30 mg/kg, which is about 2.1–2.4 grams (even if experiments on rats demonstrated that these animals could survive after eating a 14000 mg/kg dose). Excess iodine can be more cytotoxic in the presence of selenium deficiency. Iodine supplementation in selenium-deficient populations is, in theory, problematic, partly for this reason. Its toxicity derives from its oxidizing properties, which make it able to denaturate proteins (including enzymes).
Elemental iodine is also a skin irritant, and direct contact with skin can cause damage, so solid iodine crystals should be handled with care. Solutions with high elemental iodine concentration such as tincture of iodine and Lugol's solution are capable of causing tissue damage if their use for cleaning and antisepsis is prolonged; similarly, cases have been reported where liquid Povidone-iodine (Betadine) trapped against the skin resulted in chemical burns.
Allergic reactions.
Some people develop a hypersensitivity to iodine-containing products and foods. Applications of tincture of iodine or Betadine can cause rashes, sometimes severe. Parenteral use of iodine-based contrast agents (see above) can cause reactions ranging from a mild rash to fatal anaphylaxis. Such reactions have led to the misconception (widely held, even among physicians) that some people are allergic to iodine itself; even allergies to iodine-rich seafood have been so construed. In fact, there has never been a confirmed report of a true iodine allergy, and an allergy to elemental iodine or simple iodide salts is theoretically impossible. Hypersensitivity reactions to iodine-containing products and foods are apparently related to their other molecular components; thus, a person who has demonstrated an allergy to one iodine-containing food or product should not be assumed to have an allergy to another one. Still, as with all medications, the potential severity of reactions to medical iodine-containing products should prompt questions about a patient's allergy history before they are administered.

</doc>
<doc id="14751" url="http://en.wikipedia.org/wiki?curid=14751" title="IKEA">
IKEA

IKEA (; ]) is a multinational group of companies that designs and sells ready-to-assemble furniture (such as beds, chairs and desks), appliances, small motor vehicles and home accessories. As of January 2008, it is the world's largest furniture retailer. Founded in Sweden in 1943 by then-17-year-old Ingvar Kamprad, who was listed as one of the world's richest people in 2013, the company's name is an acronym that consists of the initials of Ingvar Kamprad, Elmtaryd (the farm where he grew up), and Agunnaryd (his hometown in Småland, south Sweden). The company is known for its modern architectural designs for various types of appliances and furniture, and its interior design work is often associated with an eco-friendly simplicity. In addition, the firm is known for its attention to cost control, operational details, and continuous product development, corporate attributes that allowed IKEA to lower its prices by an average of two to three percent over the decade to 2010 during a period of global expansion. The IKEA group has a complex corporate structure and is controlled by several foundations based in the Netherlands, Luxembourg and Liechtenstein.
As of December 2014, IKEA owns and operates 351 stores in 46 countries. In fiscal year 2010, US$23.1 billion worth of goods were sold, a total that represented a 7.7 percent increase over 2009. The IKEA website contains about 12,000 products and is the closest representation of the entire IKEA range. There were over 470 million visitors to IKEA's websites in the year from September 2007 to September 2008. The company is responsible for approximately 1% of world commercial-product wood consumption, making it one of the largest users of wood in the retail sector.
History.
Ingvar Kamprad founded IKEA in 1943 as a mostly mail-order sales business. It began to sell furniture five years later. The first Möbel-IKÉA store was opened in Älmhult, Småland, in 1958, while the first stores outside Sweden were opened in Norway (1963) and Denmark (1969). The stores spread to other parts of Europe in the 1970s, with the first store outside Scandinavia opening in Switzerland (1973), followed by West Germany (1974).
Amid a high level of success, the company's West German executives accidentally opened a store in Konstanz in 1973 instead of Koblenz. Later that decade, stores opened in other parts of the world, such as Japan (1974), Australia and Hong Kong (1975), Canada (1976), and Singapore (1978). IKEA further expanded in the 1980s, opening stores in countries such as France and Spain (1981), Canada (1982), Belgium (1984), the United States (1985), the United Kingdom (1987), Italy (1989) and Poland (1991). The company then expanded into more countries in the 1990s and 2000s. Germany, with 44 stores, is IKEA's biggest market, followed by the United States, with 40 stores. At the end of the 2009 financial year, the IKEA group operated 267 stores in 25 countries. The first IKEA store in Latin America opened on 17 February 2010 in Santo Domingo, Dominican Republic. As of July 2013, the company's presence in developing countries remains minimal.
The world's five largest IKEA stores are:
The largest store in the Southern Hemisphere is located in Tempe, Sydney, Australia with a total area of 39,000 m2. The biggest store in North America is located in Montreal, in the province of Quebec, Canada. The store was opened in 1986 in the Ville-St-Laurent area, and was completely renovated and expanded in 2012-2013. Built in 1986, the store's initial area was 22,062 m2, while the renovated store now measures 43,636 m2.
In 2014, IKEA opened its first warehouse in Croatia, near Zagreb. Due to problems with building permissions, the construction was postponed to 28 August 2013. Eventually, the warehouse opened its doors on 21 August 2014. The shopping centre in Zagreb with a total area of 38,000 m2 is one of the 5 biggest in Europe and among the 10 biggest IKEA stores in the world. In 2013, IKEA opened its first shopping centre in Vilnius, Lithuania that is the biggest furniture-selling mall in the Baltic states.
In March 2013, IKEA opened its first outlet in Qatar, after a delay of several months. Like others in the Gulf Cooperation Council, the Doha outlet is operated by the Al-Futtaim Group. In August 2013, the first store in the Baltic States was opened in the Vilnius region of Lithuania. Construction of the 26500 sqft store commenced in 2011 and the store employs over 200 people.
In July 2014 IKEA announced it would open its first store in India in the city of Hyderabad, where the local government has committed to fast track all the required paperwork and permits, as it is seeking to attract foreign investment. The new IKEA is expected to open in 2015.
In December 2014, the world's largest IKEA store at 59,000 square meters (640,000 square feet), bigger than the previously largest store in Sweden, opened near the KTX Gwangmyeong Station, located at the heart of South Korea's Seoul Capital Area. A second store will open in Goyang, with a third one planned in Gangdong District, Seoul. IKEA plans to have 5 stores in the country by 2020.
Store design.
Layout.
Older IKEA stores are usually blue buildings with yellow accents (also Sweden's national colours) and few windows. They are often designed in a one-way layout, leading customers counter clockwise along what IKEA calls "the long natural way" designed to encourage the customer to see the store in its entirety (as opposed to a traditional retail store, which allows a customer to go directly to the section where the desired goods and services are displayed). There are often shortcuts to other parts of the showroom. Newer IKEA stores, like the one in Mönchengladbach, Germany, make more use of glass, both for aesthetics and functionality. Skylights are also now common in the self-serve warehouses; natural lighting reduces energy costs, improves worker morale and gives a better impression of the products.
The sequence first involves going through furniture showrooms making note of selected items. The customer then collects a shopping cart and proceeds to an open-shelf "Market Hall" warehouse for smaller items, then visits the "Self Serve" furniture warehouse to collect previously noted showroom products in flat pack form. Sometimes, they are directed to collect products from an external warehouse on the same site or at a site nearby after purchase. Finally, customers pay for their products at a cash register.
Today, most stores follow the same layout of having the showroom upstairs with the marketplace and self-service warehouse downstairs. Some stores are single level, while others have separate warehouses to allow more stock to be kept on-site. Single-level stores are found predominantly in areas where the cost of land would be less than the cost of building a 2-level store, such as the Saarlouis, Germany and Haparanda, Sweden locations. Some stores have dual-level warehouses with machine-controlled silos to allow large quantities of stock to be accessed throughout the selling day.
Most IKEA stores offer an "as-is" area at the end of the warehouse, just before the cash registers. Returned, damaged and formerly showcased products are displayed here and sold with a significant discount, but also with a no-returns policy. Most IKEA stores communicate the IKEA policy on environmental issues in this part of the store. The area, which is painted red, is named according to local customs, in the United Kingdom this is referred to as "Bargain Corner", in Sweden "FYND" (Bargains) and in Denmark, "Rodebutikken" (Rummage boutique).
In Hong Kong, where shop space is limited and costly, IKEA has opened three outlets across the city, most of which have the one-way layout. They are part of shopping malls, and while being tiny compared to common store design, are huge by Hong Kong standards.
The vast majority of IKEA stores are located outside of city centres, primarily because of land cost and traffic access. Several smaller store formats have been unsuccessfully tested in the past (the "midi" concept in the early '90s, which was tested in Ottawa and Heerlen with 9,300 m2, or a "boutique" shop in Manhattan). A new format for a full-size, city centre store was introduced with the opening of the Manchester (United Kingdom) store, situated in Ashton-Under-Lyne in 2006. Another store, in Coventry opened in December 2007. The store has seven floors and a different flow from other Ikea stores. IKEA's Southampton store which opened in February 2009 is also in the city centre and built in an urban style similar to the Coventry store. IKEA built these stores in response to UK government restrictions blocking retail establishment outside city centres.
Another feature of IKEA stores is their long opening hours. Many stores are in operation 24 hours a day with restocking and maintenance being carried out throughout the night. Public opening hours tend to be much longer than most other retailers, with stores open well into the evening in many countries. In the UK, almost all stores are open past 8pm and open around 9am to 10am. IKEA Saudi Arabia stores have some of the longest opening hours worldwide being open from 10am to midnight, 7 days a week. Some IKEA stores are not open on Sundays due to local laws.
The IKEA stores are also known for the free IKEA pencils, whereby some people consider it as a sport to collect as many of these IKEA pencils as they can during their visit.
Food markets.
Every store includes a restaurant serving traditional Swedish food, including potatoes with Swedish meatballs, cream sauce and lingonberry jam, although there are variations. In Kuala Lumpur, Malaysia, the usual boiled potatoes have been replaced with French fries. Besides these Swedish foods, hot dogs and drinks are also sold, along with a few varieties of the local cuisine, and beverages such as lingonberry juice. Also items such as "prinsesstårta" (princess cake) are sold as desserts. Stores in Israel sell kosher food with a high degree of rabbinical supervision. The kosher restaurants are separated into dairy and meat areas; falafel and non-dairy ice cream are available at the exit. IKEA stores in Saudi Arabia, Kuwait, Qatar and the United Arab Emirates serve chicken shawarma at the exit café as well as beef hot dogs, while in United Kingdom, a Quorn hot dog is available in the exit café.
In many locations, the IKEA restaurants open daily before the rest of the store and serve an inexpensive breakfast. In Canada, this breakfast includes eggs, sausage and hash browns and various add-ons like bacon and pancakes at additional cost. In the United States, the local variation serves scrambled eggs, bacon, country potatoes and a choice of Swedish pancakes or French toast sticks. In the Netherlands, it consists of a croissant, a small bread roll, butter or margarine, jam, a slice of cheese, a boiled egg and coffee or tea. In Australia, it consists of a hash brown, bacon, scrambled eggs, a sausage and a tomato, with a vegetarian option with baked beans which omits the sausage and bacon. In Germany, this breakfast consists of two bread rolls, one slice of smoked salmon, one slice of cheese, one slice of salami, two portions of butter, one portion of jam, and coffee. Alcoholic drinks, like their Öl Ljus beer, are available in some locations. Refills of coffee, tea, and soft drinks are, as is traditional in Sweden, free of charge within store premises, even in countries where this is uncommon. In Austria, IKEA restaurants offer a free refill policy for soft drinks, a practice that is otherwise unknown in the country.
Every store also has a Swedish Food Market that, until 2011, sold branded Swedish prepared specialist foods, such as meatballs, packages of gravy, lingonberry jam, various biscuits and crackers, and salmon and fish roe spread. Later IKEA replaced most of the branded foods and extended its product range with the introduction of the IKEA food label. The new label has a variety of items including chocolates, meatballs, jams, pancakes, salmon, along with various drinks. All IKEA food products are based on Swedish recipes and traditions. The majority of the food production still takes place in Sweden by small, medium and large manufacturers, like Gunnar Dafgård AB, which make its meatballs.
Småland.
Every store has a play area, named Småland (Swedish for "small lands"; it is also the Swedish province where Kamprad was born). Parents drop off their children at a gate to the playground, and pick them up after they arrive at another entrance. In some stores, parents are given free pagers by the on-site staff, which the staff can use to summon parents whose children need them earlier than expected; in others, staff summon parents through announcements over the in-store public address system.
Products and services.
Furniture.
Rather than being sold pre-assembled, much of IKEA's furniture is designed to be self-assembled. The company claims that this helps reduce costs and use of packaging by not shipping air; the volume of a bookcase, for example, is considerably less if it is shipped unassembled rather than assembled. This is also practical for many of the chain's European customers, where public transport is commonly used, because the flat-pack methods allow for easier transport via public transportation.
IKEA contends that it has been a pioneering force in sustainable approaches to mass consumer culture.. Kamprad calls this "democratic design," meaning that the company applies an integrated approach to manufacturing and design (see also environmental design). In response to the explosion of human population and material expectations in the 20th and 21st centuries, the company implements economies of scale, capturing material streams and creating manufacturing processes that hold costs and resource use down, such as the extensive use of Medium-Density Fiberboard ("MDF"), also called "particle board." It is an engineered wood fibre glued under heat and pressure to create a building material of superior strength which is resistant to warp. IKEA uses cabinet-grade and furniture-grade MDF in all of its MDF products, such as PAX wardrobes and kitchen cupboards. IKEA also uses wood, plastic, and other materials for furniture and other products. The intended result is flexible, adaptable home furnishings, scalable both to smaller homes and dwellings as well as large houses.
Not all furniture is stocked at the store level, such as particular sofa colours needing to be shipped from a warehouse to the customer's home (for a delivery charge). The item can also be shipped from the warehouse to the store. Some stores charge an extra fee for this service, but not all.
Houses and flats.
IKEA has also expanded its product base to include flat-pack houses, in an effort to cut prices involved in a first-time buyer's home. (This practice is not new; the American retailer Sears Roebuck and Company sold houses under the Craftsman brand in a similar fashion (shipped flat pack with instructions to allow the homeowner to assemble it themselves) by mail order as far back as the 1920s; the products were so well constructed that as of 2014 there are original 1920s Craftsman houses still in use), The IKEA product, named BoKlok was launched in Sweden in 1996 in a joint venture with Skanska. Now working in the Nordic countries and in the UK, sites confirmed in England include London, Ashton-under-Lyne, Leeds, Gateshead, Warrington and Liverpool.
At the end of September 2013, the company announced that solar panel packages for houses will be sold at 17 UK stores by the end of July 2014. The decision followed a successful pilot project at the Lakeside IKEA store, whereby one photovoltaic (PV) system was sold almost every day. The panels are manufactured by the Chinese company Hanergy.
Retail.
IKEA owns and operates a network of shopping centers MEGA.
Family Mobile.
On 8 August 2008, IKEA UK launched Family Mobile, a virtual mobile phone network, running on T-Mobile.
Manufacturing.
Although IKEA household products and furniture are designed in Sweden, they are largely manufactured in developing countries to keep costs down. China accounts for about 2½ times as much supply as Sweden. For most of its products, the final assembly is performed by the end-user (consumer).
Swedwood, an IKEA subsidiary, handles production of all of the company's wood-based products, with the largest Swedwood factory located in Southern Poland. According to the subsidiary, over 16,000 employees across 50 sites in 10 countries manufacture the 100 million pieces of furniture that IKEA sells annually. IKEA furniture uses the hardwood alternative particle board and Hultsfred, a factory in southern Sweden, is the company's sole supplier.
Product names.
IKEA products are identified by one-word (rarely two-word) names. Most of the names are Scandinavian in origin. Although there are some exceptions, most product names are based on a special naming system developed by IKEA.
For example, "DUKTIG" (meaning: clever, well-behaved) is a line of children's toys, "OSLO" is a name of a bed, "BILLY" (a Swedish masculine name) is a popular bookcase, "DINERA" (meaning: (to) dine) for tableware, "KASSETT" (meaning: cassette) for media storage. One range of office furniture is named "EFFEKTIV" (meaning: efficient, effective), "SKÄRPT" (meaning: sharp or clever) is a line of kitchen knives.
A notable exception is the "IVAR" shelving system, which dates back to the early 1970s. This item is named after the item's designer.
Some of IKEA's Swedish product names have amusing or unfortunate connotations in other languages, sometimes resulting in the names being withdrawn in certain countries. Notable examples for English include the "Jerker" computer desk (discontinued several years ago as of 2013), "Fukta" plant spray, "Fartfull" workbench, and "Lyckhem" (meaning bliss). Kitchen legs are called FAKTUM (called AKURUM in the United States). The latest addition is the new "Askholmen" outdoor suite. Similar blunders happen with other multinational companies.
Company founder Kamprad, who is dyslexic, found that naming the furniture with proper names and words, rather than a product code, made the names easier to remember.
IKEA uses a sales technique called "bulla bulla" in which a bunch of items are purposefully jumbled in bins, to create the impression of volume, and therefore, inexpensiveness.
Catalogue.
IKEA publishes an annual catalogue, first published in Swedish in 1951. IKEA published 197 million catalogues in 2010, in twenty languages and sixty-one editions. It is considered to be the main marketing tool of the retail giant, consuming 70% of the company's annual marketing budget.
The catalogue is distributed both in stores and by mail, with most of it being produced by IKEA Communications AB in IKEA's hometown of Älmhult, Sweden where IKEA operates the largest photo studio in northern Europe at 8000 sqm. The catalogue itself is printed on chlorine-free paper of 10–15% post-consumer waste, and prints approximately 175 million copies worldwide annually, more than 3 times as much as the Bible.
According to Canadian broadcaster, CTV, "IKEA's publications have developed an almost cult-like following online. Readers have found all kinds of strange tidbits, including mysterious cat pictures, apparent Mickey Mouse references and weird books wedged into the many shelves that clutter the catalogues."
The 2013 catalogue is smartphone compatible, containing videos and photo galleries that can be accessed via an app by scanning the catalogue's pages, while the 2014 catalog incorporates an augmented reality app that projects an item into a real-time photograph image of the user's room. The augmented reality app also provides an indication of the scale of IKEA objects in relation to the user's living environment.
IKEA Family loyalty card.
In common with some other retailers, IKEA has launched a loyalty card called "IKEA family". The card is free of charge and can be used to obtain discounts on a special range of products found in each IKEA store. In conjunction with the card, IKEA also publishes and sells a printed quarterly magazine titled "IKEA Family Live" which supplements the card and catalogue. The magazine is already printed in thirteen languages and an English edition for the United Kingdom was launched in February 2007. It is expected to have a subscription of over 500,000.
IKEA Family, as other loyalty cards, allows for lower prices. The main, generally unusual difference is that it allows for free tea or coffee (from Monday to Friday at most locations) at Ikea restaurant.
Corporate structure.
IKEA is owned and operated by a complicated array of not-for-profit and for-profit corporations. The corporate structure is divided into two main parts: operations and franchising. Most of IKEA's operations, including the management of the majority of its stores, the design and manufacture of its furniture, and purchasing and supply functions are overseen by INGKA Holding, a private, for-profit Dutch company. Of the IKEA stores in 43 countries, 303 are run by the INGKA Holding. The remaining 47 stores are run by franchisees outside of the INGKA Holding, with the exception of IKEA Delft which is not franchised.
INGKA Holding is not an independent company, but is wholly owned by the Stichting Ingka Foundation, which Kamprad established in 1982 in the Netherlands as a tax-exempt, not-for-profit foundation. The Ingka Foundation is controlled by a five-member executive committee that is chaired by Kamprad and includes his wife and attorney.
While most IKEA stores operate under the direct purview of Ingka Holding and the Ingka Foundation, the IKEA trademark and concept is owned by an entirely separate Dutch company Inter IKEA Systems. Every IKEA store, including those run by Ingka Holding, pays a franchise fee of 3% of revenue to Inter IKEA Systems. The ownership of Inter IKEA Systems is exceedingly complicated and not publicly known. Inter IKEA Systems is owned by Inter IKEA Holding, a company registered in Luxembourg. Inter IKEA Holding, in turn, belongs to an identically named company in the former Netherlands Antilles that is run by a trust company based in Curaçao. In 2009 the company in Curaçao was liquidated and the company responsible for this liquidation traces back to the Interogo Foundation in Liechtenstein. Ingvar Kamprad has confirmed that this foundation owns Inter IKEA Holding S.A. in Luxembourg and is controlled by the Kamprad family. The IKEA food concessions that operate in IKEA stores are still directly owned by the Kamprad family and represent a major part of the family's income.
In Australia, IKEA is operated by two companies. Stores located on the East Coast including Queensland, New South Wales and Victoria are owned by INGKA Holding. Stores elsewhere in the country including South Australia and Western Australia are owned by Cebas Pty Ltd. Like elsewhere, all stores are operated under a franchise agreement with Inter IKEA Systems.
In June 2013, Ingvar Kamprad resigned from the board of Inter IKEA Holding SA and his youngest son Mathias Kamprad replaced Per Ludvigsson as the chairman of the holding company. Following his decision to step down, the 87-year-old founder explained, "I see this as a good time for me to leave the board of Inter IKEA Group. By that we are also taking another step in the generation shift that has been ongoing for some years." Mathias and his two older brothers, who also have leadership roles at IKEA, work on the corporation's overall vision and long-term strategy.
Profits.
The net profit of IKEA Group (which does not include Inter IKEA systems) in fiscal year 2009 (after paying franchise fees to Inter IKEA systems) was €2.538 billion on sales of €21.846 billion. Because INGKA Holding is owned by the nonprofit INGKA Foundation, none of this profit is taxed. The foundation's nonprofit status also means that the Kamprad family cannot reap these profits directly, but the Kamprads do collect a portion of IKEA sales profits through the franchising relationship between INGKA Holding and Inter IKEA Systems.
Inter IKEA Systems collected €631 million of franchise fees in 2004, but reported pre-tax profits of only €225 million in 2004. One of the major pre-tax expenses that Inter IKEA systems reported was €590 million of "other operating charges". IKEA has refused to explain these charges, but Inter IKEA Systems appears to make large payments to I.I. Holding, another Luxembourg-registered group that, according to "The Economist," "is almost certain to be controlled by the Kamprad family." I.I. Holding made a profit of €328 million in 2004.
In 2004, the Inter IKEA group of companies and I.I. Holding reported combined profits of €553m and paid €19m in taxes, or approximately 3.5 percent. In 2013 the "Daily Mail" media publication reported that the IKEA subsidiary Swedwood had grown between 20-25% per year since its inception in 1991.
The Berne Declaration, a non-profit organisation in Switzerland that promotes corporate responsibility, has formally criticised IKEA for its tax avoidance strategies. In 2007, the Berne Declaration nominated IKEA for one of its Public Eye "awards", which highlight corporate irresponsibility and are announced during the World Economic Forum in Davos, Switzerland.
In a company statement emailed on 14 October 2013, Ikea's full-year sales rose 3.1 percent due in part to growth in Russia and China. Ikea's revenue total rose to US$37.9 billion (27.9 billion euros), with significant growth also recorded in North America.
Control by Kamprad.
Along with helping IKEA make non-taxable profit, IKEA's complicated corporate structure allows Kamprad to maintain tight control over the operations of Ingka Holding, and thus the operation of most IKEA stores. The Ingka Foundation's five-person executive committee is chaired by Kamprad. It appoints the board of Ingka Holding, approves any changes to Ingka Holding's bylaws, and has the right to preempt new share issues. If a member of the executive committee quits or dies, the other four members appoint his or her replacement.
In Kamprad's absence the foundation's bylaws include specific provisions requiring it to continue operating the Ingka Holding group and specifying that shares can be sold only to another foundation with the same objectives as the Ingka Foundation.
Charitable giving.
The INGKA Foundation is officially dedicated to promoting "innovations in architecture and interior design." With an estimated net worth of $36 billion, the foundation is unofficially the world's largest charitable organization, ahead of the much better known Bill and Melinda Gates Foundation, which has a net worth of approximately $33 billion. However, most of the Group's profit is spent on investment; the foundation expects to spend €45 million on charitable giving in 2010 (compare the Gates Foundation, which made gifts of more than $1.5 billion in 2005.)
IKEA is involved in several international charitable causes, particularly in partnership with UNICEF, including:
IKEA also supports American Forests to restore forests and reduce pollution.
Minimum Wage.
In June 2014, IKEA announced that it would be raising its minimum wage in the United States. The company raised the US minimum wage average to $10.76, but the actual minimum wage in each city will fluctuate depending on that city's living costs. Employees at the IKEA in Woodbridge, VA will receive the highest wage of $13.22 per hour and workers in Pittsburgh and West Chester, OH will receive the lowest wage at $8.69 per hour.
IKEA Social Initiative.
In September 2005, IKEA Social Initiative was formed to manage the company's social involvements on a global level. IKEA Social Initiative is headed by Marianne Barner.
The main partners of IKEA Social Initiative are UNICEF and Save the Children.
On 23 February 2009, at the ECOSOC event in New York, UNICEF announced that IKEA Social Initiative has become the agency's largest corporate partner, with total commitments of more than US$180 million.
Examples of involvements:
In 2009, Sweden's largest television station, SVT, revealed that IKEA's money—the three per cent collection from each store—does not actually go to a charitable foundation in the Netherlands, as IKEA has said. Inter IKEA is owned by a foundation in Liechtenstein, called Interogo, which has amassed twelve billion dollars, and is controlled by the Kamprad family.
Environmental performance.
After initial environmental issues like the highly publicized formaldehyde scandals in the early 1980s and 1992, IKEA took a proactive stance on environmental issues and tried to prevent future incidents through a variety of measures. In 1990, IKEA invited Karl-Henrik Robèrt, founder of the Natural Step, to address its board of directors. Robert's system conditions for sustainability provided a strategic approach to improving the company's environmental performance. In 1990, IKEA adopted the Natural Step framework as the basis for its environmental plan. This led to the development of an Environmental Action Plan, which was adopted in 1992. The plan focused on structural change, allowing IKEA to "maximize the impact of resources invested and reduce the energy necessary to address isolated issues." The environmental measures taken include the following:
In 2000 IKEA introduced its code of conduct for suppliers, called the IKEA way of purchasing... shortened to IWAY. Today IWAY is a totally integrated part of IKEA's purchasing model. IWAY covers social, safety and environmental questions. Today IKEA has around 60 IWAY auditors that performs hundreds of supplier audits every year. The main purpose with IWAY is to make sure that the IKEA suppliers follows the law in each country where they are based. Most IKEA suppliers fulfill the law today with exceptions for some special issues, one being excessive working hours in Asia, in countries such as China and India.
More recently, IKEA has stopped providing plastic bags to customers, but offers reusable bags for sale. The IKEA restaurants also only offer reusable plates, knives, forks, spoons, etc. Toilets in some IKEA WC-rooms have been outfitted with dual-function flushers. IKEA has recycling bins for compact fluorescent lamps (CFLs), energy saving bulbs and batteries.
In 2001 IKEA was one of the first companies to operate its own cross-border goods trains through several countries in Europe.
In August 2008, IKEA also announced that it had created IKEA GreenTech, a €50 million venture capital fund. Located in Lund (a university town in Sweden), it will invest in 8–10 companies in the coming five years with focus on solar panels, alternative light sources, product materials, energy efficiency and water saving and purification. The aim is to commercialise green technologies for sale in IKEA stores within 3–4 years.
To make IKEA a more sustainable company, a product life cycle was created. For the idea stage, products should be flat-packed so that more items can be shipped at once; products should also be easier to dismantle and recycle. Raw materials are used, and since wood and cotton are two of IKEA's most important manufacturing products, the company works with environmentally friendly forests and cotton, whereby the excessive use of chemicals and water is avoided.
Manufacturing is third in the life cycle and includes IWAY, IKEA's code of conduct for manufactures and suppliers that formulates and enforces requirements for working conditions, social and environmental standards, and what suppliers can expect from IKEA in return. Marketing is another part of IKEA's life cycle and a portion of the paper used for its catalogues is sourced from responsibly managed forests. The catalogue is also smaller, so that less paper is required, less waste is produced and more catalogues can be shipped per load.
IKEA stores recycle waste and many run on renewable energy with the use of energy-saving bulbs and sensors. All employees are trained in environmental and social responsibility, while public transit is one of the priorities when the location of stores is considered. Also, the coffee served at IKEA stores is certified organic.
The last stage of the life cycle is the end of life. Most IKEA stores recycle light bulbs and drained batteries, and the company is also exploring the recycling of sofas and other home furnishing products. According to IKEA's 2012 "Sustainability Report", 23% of all wood that the company uses meets the standards of the Forest Stewardship Council, and the report states that IKEA aims to double this percentage by 2017. The report also states that IKEA does not accept illegally logged wood and supports 13 World Wide Fund For Nature (WWF) projects.
On 17 February 2011, IKEA announced its plans to develop a wind farm in Dalarna County, Sweden, furthering its goal of using only renewable energy to fuel its operations. As of June 2012, 17 United States (US) IKEA stores are powered by solar panels, with 22 additional installations in progress.
In 2011, the company examined its wood consumption and noticed that almost half of its global pine and spruce consumption was for the fabrication of pallets. The company consequently started a transition to the use of paper pallets and the "Optiledge system". The OptiLedge product is totally recyclable, made from 100% virgin high-impact copolymer polypropylene (PP). The system is a "unit load alternative to the use of a pallet. The system consists of the OptiLedge (usually used in pairs), aligned and strapped to the bottom carton to form a base layer upon which to stack more product. Corner boards are used when strapping to minimize the potential for package compression." The conversion began in Germany and Japan, before its introduction into the rest of Europe and North America. The system has been marketed to other companies, and IKEA has formed the OptiLedge company to manage and sell the product.
IKEA has expanded its sustainability plan in the UK to include electric car charge points for customers at all locations by the end of 2013. The effort will include Nissan and Ecotricity and promise to deliver an 80% charge in 30 minutes.
In February 2014, IKEA in the UK announced that from 2016 they will only sell energy-efficient LED lightbulbs, lamps and light fixtures. LED lightbulbs uses as much as only 15% of the power of a regular incandescent light bulb.
Negative community impact.
IKEA's goals of sustainability and environmental design in its merchandise have sometimes been at odds with the impact a new IKEA store can have on a community.
Criticisms.
Accusations of price gouging.
Ikea has been criticised by Citytv in Canada for charging up to twice as much in their Canadian stores as for the same items sold in their American stores, despite the Canadian dollar reaching parity with the U.S. dollar.
Operation Scandinavica.
In 2014, documents were found at the Securitate archives in Bucharest which indicated that Ikea's open purchase of Romanian lumber throughout the 1980s was part of a complex scheme (codenamed "Scandinavica") to fund the Securitate and allow the accumulation of foreign currency: the Romanian lumber company Tehnoforestexport would regularly overcharge Ikea, transfer the overpayments into private Securitate bank accounts, wait for interest to accrue, and then reimburse Ikea the principal. Ikea has denied complicity in Scandinavica, but has begun an internal investigation to learn more.
Use of forced labor, 1980s.
During the 1980s, IKEA kept its costs down by using production facilities in East Germany. A portion of the workforce at those factories consisted of political prisoners. This fact, revealed in a report by Ernst & Young commissioned by the company, resulted from intermingling of criminals and political dissidents in the state-owned production facilities IKEA contracted with, a practice which was generally known in West Germany. IKEA was one of a number of companies, including West German firms, which benefited from this practice. The investigation resulted from attempts by former political prisoners to obtain compensation. In November 2012, IKEA admitted being aware at the time of the possibility of use of forced labor and failing to exercise sufficient control to identify and avoid it. A summary of the Ernst & Young report was released on 16 November 2012.
Verdana typeface.
In 2009 IKEA caused a flap in the graphic design world when it changed the typeface used in its catalogue from Futura to Verdana, expressing a desire to unify its branding between print and web media. The controversy has been attributed to the perception of Verdana as a symbol of homogeneity in popular typography.
"Time" magazine and The Associated Press ran articles on the controversy including a brief interview with an IKEA representative, focusing on the opinions of typographers and designers. Design and advertising industry-focused publications such as "Business Week" joined the fray of online posts. The branding critic blog, Brand New, was one of those using the "Verdanagate" name. The Australian online daily news site "Crikey" also published an article on the controversy. "The Guardian" ran an article asking "IKEA is changing its font to Verdana – causing outrage among typomaniacs. Should the rest of us care? Absolutely." "The New York Times" said the change to Verdana "is so offensive to many because it seems like a slap at the principles of design by a company that has been hailed for its adherence to them."
Advertising.
In 1994, IKEA ran a commercial in the United States widely thought to be the first to feature a homosexual couple; it aired for several weeks before being pulled out due to terrorist threats directed at IKEA stores. Other IKEA commercials appeal to the wider GLBTQ community, one featuring a transgender woman.
In 2002, the inaugural television component of the "Unböring" campaign, titled "Lamp", went on to win several awards, including a Grand Clio, Golds at the London International Awards and the ANDY Awards, and the Grand Prix at the Cannes Lions International Advertising Festival, the most prestigious awards ceremony in the advertising community.
IKEA launched a UK-wide "Home is the Most Important Place in the World" advertising campaign in September 2007 using estate agent signs with the term "Not For Sale" written on them as part of the wider campaign. After the campaign appeared in the Metro newspaper London the business news website www.mad.co.uk remarked that the IKEA campaign had amazing similarities with the marketing activity of UK home refurbishment company Onis living who had launched its own Not For Sale advertising campaign two years prior and was awarded the Interbuild 2006 Construction Marketing Award for best campaign under £25,000.
A debate ensued between Fraser Patterson, Chief Executive of Onis and Andrew McGuinness, partner at Beattie McGuinness Bungay (BMB), the advertising and PR agency awarded the £12m IKEA account. The essence of the debate was that BMB claimed to be unaware of Onis's campaign as Onis was not an advertising agency. Onis's argument was that its advertising could be seen in prominent landmarks throughout London, having been already accredited, showing concern about the impact IKEA's campaign would have on the originality of its own.
After some negotiations BMB and IKEA agreed to provide Onis with a feature page on linking through to , for a period of 1 year. Onis is possibly the only company to have ever been advertised by IKEA in such a fashion. In 2008, Onis Homes limited was placed into voluntary liquidation and the website www.onishome.com closed.
The Intellectual Property and trading rights of Onis Homes Limited were later purchased by new shareholders with the strategy to grow the Onis brand throughout the UK as a one stop shop home refurbishment franchise using the trading name Onis living.
In 2008, IKEA paired up with the makers of popular video game "The Sims 2" to make a stuff pack called "The Sims 2 IKEA Home Stuff", featuring many IKEA products. It was released on 24 June 2008 in North America and 26 June 2008 in Europe. It is the second stuff pack with a major brand, the first being "The Sims 2 H&M Fashion Stuff", which are both coincidentally companies of Swedish origin.
IKEA took over the title sponsorship of Philadelphia's annual Thanksgiving Day parade in 2008, replacing Boscov's, which filed for bankruptcy in August 2008.
In November 2008, a subway train decorated in IKEA style was introduced in Novosibirsk, Russia. Four cars were turned into a mobile showroom of the Swedish design. The redesigned train, which features colourful seats and fancy curtains, carried passengers until 6 June 2009.
Oyster cards (the ticket-free system for the London Underground) were for given with wallets sponsored by IKEA in 2008-09. IKEA also sponsored the tube map.
In January 2009, just before the new store opened in Southampton, of Red Funnel was re-painted in an entirely yellow and blue livery to celebrate the opening of the new IKEA store in Southampton. This is the first time a Red Funnel ferry has been re-painted out of its own red and white colour scheme. It stayed in these colours for 12 months as part of a deal between Red Funnel and IKEA to provide home delivery services to the Isle of Wight. It was repainted with Red Funnel's red and white livery when the deal ended in January 2010.
In March 2010, IKEA developed an event in four important Metro stations in Paris, in which furniture collections are displayed in high-traffic spots, giving potential customers a chance to check out the brand's products. The Metro walls were also filled with prints that showcase IKEA interiors.
In September 2010, IKEA launched an advertisement for UK & Ireland called "Happy Inside" which had 100 cats lying on IKEA furniture in the flagship IKEA store in Wembley, London.
In April 2011, an advertising campaign was launched aiming at discovering whether men or women are messier in the home. Created by Mother, the campaign will begin with a TV advert shot in front of a live audience, featuring four stand-up comedians, two men and two women, debating which gender is messier. The idea behind the campaign is that domestic clutter leads to arguments, and thus to an unhappy home, a conflict that IKEA wants to show can be avoided with better storage. Viewers will be directed to a new Facebook page for the brand, where they are able to vote on who they believe is messier, and submit evidence using videos and photos through an app created especially for the campaign. Meanwhile, online display banners will allow other users the opportunity to vote, with online adverts promoting Ikea products demonstrating the problems confronting people, and offering solutions.
Anna Crona, marketing director at IKEA United Kingdom and Ireland, explained: "We are committed to understanding how our customers live life at home so we can provide solutions to make life happier. Everybody has storage needs in the home and by encouraging debate and providing solutions we will show that IKEA is relevant to everybody, no matter what your home is like or how much money you have." Press adverts will also support the campaign, as will a handbook entitled "Peace, Love and Storage", which will be available through the Facebook site.
Other ventures.
In mid-August 2012, the company announced that it will establish a chain of 100 economy hotels in Europe but, unlike its few existing hotels in Scandinavia, they will not carry the IKEA name, nor will they use IKEA furniture and furnishings – they will be operated by an unnamed international group of hoteliers.
Awards.
IKEA was named one of the 100 Best Companies for Working Mothers in 2004 and 2005 by "Working Mothers" magazine. It ranked 80 in Fortune's 200 Best Companies to Work For in 2006 and in October 2008, IKEA Canada LP was named one of "Canada's Top 100 Employers" by Mediacorp Canada Inc., and was featured in "Maclean's" newsmagazine. Additionally, IKEA is the most popular store for college furnishings.

</doc>
<doc id="14752" url="http://en.wikipedia.org/wiki?curid=14752" title="Iridium">
Iridium

Iridium is a chemical element with symbol Ir and atomic number 77. A very hard, brittle, silvery-white transition metal of the platinum group, iridium is generally credited with being the second densest element (after osmium) based on measured density, although calculations involving the space lattices of the elements show that iridium is denser, and is the most corrosion-resistant metal, even at temperatures as high as 2000 °C. Although only certain molten salts and halogens are corrosive to solid iridium, finely divided iridium dust is much more reactive and can be flammable.
Iridium was discovered in 1803 among insoluble impurities in natural platinum. Smithson Tennant, the primary discoverer, named iridium for the Greek goddess Iris, personification of the rainbow, because of the striking and diverse colors of its salts. Iridium is one of the rarest elements in Earth's crust, with annual production and consumption of only three tonnes. 191Ir and 193Ir are the only two naturally occurring isotopes of iridium, as well as the only stable isotopes; the latter is the more abundant of the two.
The most important iridium compounds in use are the salts and acids it forms with chlorine, though iridium also forms a number of organometallic compounds used in industrial catalysis, and in research. Iridium metal is employed when high corrosion resistance at high temperatures is needed, as in high-performance spark plugs, crucibles for recrystallization of semiconductors at high temperatures, and electrodes for the production of chlorine in the chloralkali process. Iridium radioisotopes are used in some radioisotope thermoelectric generators.
Iridium is found in meteorites with an abundance much higher than its average abundance in Earth's crust. For this reason, the unusually high abundance of iridium in the clay layer at the Cretaceous–Paleogene boundary gave rise to the Alvarez hypothesis that the impact of a massive extraterrestrial object caused the extinction of dinosaurs and many other species 66 million years ago. It is thought that the total amount of iridium in the planet Earth is much higher than that observed in crustal rocks, but as with other platinum-group metals, the high density and tendency of iridium to bond with iron caused most iridium to descend below the crust when the planet was young and still molten.
Characteristics.
Physical properties.
A member of the platinum group metals, iridium is white, resembling platinum, but with a slight yellowish cast. Because of its hardness, brittleness, and very high melting point, solid iridium is difficult to machine, form, or work, thus powder metallurgy is commonly employed, instead. It is the only metal to maintain good mechanical properties in air at temperatures above 1600 C. It has the 10th highest boiling point among all elements and becomes a superconductor at temperatures below 0.14 K.
Iridium's modulus of elasticity is the second-highest among the metals, only being surpassed by osmium. This, together with a high shear modulus and a very low figure for Poisson's ratio (the relationship of longitudinal to lateral strain), indicate the high degree of stiffness and resistance to deformation that have rendered its fabrication into useful components a matter of great difficulty. Despite these limitations and iridium's high cost, a number of applications have developed where mechanical strength is an essential factor in some of the extremely severe conditions encountered in modern technology.
The measured density of iridium is only slightly lower (by about 0.12%) than that of osmium, the densest element known. Some ambiguity occurred regarding which of the two elements was denser, due to the small size of the difference in density and difficulties in measuring it accurately, but, with increased accuracy in factors used for calculating density X-ray crystallographic data yielded densities of 22.56 g/cm3 for iridium and 22.59 g/cm3 for osmium.
Chemical properties.
Iridium is the most corrosion-resistant metal known: it is not attacked by almost any acid, aqua regia, molten metals, or silicates at high temperatures. It can, however, be attacked by some molten salts, such as sodium cyanide and potassium cyanide, as well as oxygen and the halogens (particularly fluorine) at higher temperatures.
Compounds.
Iridium forms compounds in oxidation states between −3 and +9; the most common oxidation states are +3 and +4. Well-characterized examples of the high +6 oxidation state are rare, but include IrF6 and two mixed oxides Sr2MgIrO6 and Sr2CaIrO6. In addition, it was reported in 2009 that iridium(VIII) oxide (IrO4) was prepared under matrix isolation conditions (6 K in Ar) by UV irradiation of an iridium-peroxo complex. This species, however, is not expected to be stable as a bulk solid at higher temperatures. The highest oxidation state (+9), which is also the highest recorded for "any" element, is only known in one cation, IrO4+; it is only known as gas-phase species and is not known to form any salts.
Iridium dioxide, IrO2, a brown powder, is the only well-characterized oxide of iridium. A sesquioxide, Ir2O3, has been described as a blue-black powder which is oxidized to IrO2 by HNO3. The corresponding disulfides, diselenides, sesquisulfides, and sesquiselenides are known, and IrS3 has also been reported. Iridium also forms iridates with oxidation states +4 and +5, such as K2IrO3 and KIrO3, which can be prepared from the reaction of potassium oxide or potassium superoxide with iridium at high temperatures.
Although no binary hydrides of iridium, Ir"x"H"y" are known, complexes are known that contain IrH54- and IrH63-, where iridium has the +1 and +3 oxidation states, respectively. The ternary hydride Mg6Ir2H11 is believed to contain both the IrH54- and the 18-electron IrH45- anion.
No monohalides or dihalides are known, whereas trihalides, IrX3, are known for all of the halogens. For oxidation states +4 and above, only the tetrafluoride, pentafluoride and hexafluoride are known. Iridium hexafluoride, IrF6, is a volatile and highly reactive yellow solid, composed of octahedral molecules. It decomposes in water and is reduced to IrF4, a crystalline solid, by iridium black. Iridium pentafluoride has similar properties but it is actually a tetramer, Ir4F20, formed by four corner-sharing octahedra.
Hexachloroiridic(IV) acid, H2IrCl6, and its ammonium salt are the most important iridium compounds from an industrial perspective. They are involved in the purification of iridium and used as precursors for most other iridium compounds, as well as in the preparation of anode coatings. The IrCl62- ion has an intense dark brown color, and can be readily reduced to the lighter-colored IrCl63- and vice versa. Iridium trichloride, IrCl3, which can be obtained in anhydrous form from direct oxidation of iridium powder by chlorine at 650 °C, or in hydrated form by dissolving Ir2O3 in hydrochloric acid, is often used as a starting material for the synthesis of other Ir(III) compounds. Another compound used as a starting material is ammonium hexachloroiridate(III), (NH4)3IrCl6. Iridium(III) complexes are diamagnetic (low-spin) and generally have an octahedral molecular geometry.
Organoiridium compounds contain iridium–carbon bonds where the metal is usually in lower oxidation states. For example, oxidation state zero is found in tetrairidium dodecacarbonyl, Ir4(CO)12, which is the most common and stable binary carbonyl of iridium. In this compound, each of the iridium atoms is bonded to the other three, forming a tetrahedral cluster. Some organometallic Ir(I) compounds are notable enough to be named after their discoverers. One is Vaska's complex, IrCl(CO)[P(C6H5)3]2, which has the unusual property of binding to the dioxygen molecule, O2. Another one is Crabtree's catalyst, a homogeneous catalyst for hydrogenation reactions. These compounds are both square planar, d8 complexes, with a total of 16 valence electrons, which accounts for their reactivity.
An iridium-based organic LED material has been documented, and found to be much brighter than DPA or PPV, so could be the basis for flexible OLED lighting in the future.
Isotopes.
Iridium has two naturally occurring, stable isotopes, 191Ir and 193Ir, with natural abundances of 37.3% and 62.7%, respectively. At least 34 radioisotopes have also been synthesized, ranging in mass number from 164 to 199. 192Ir, which falls between the two stable isotopes, is the most stable radioisotope, with a half-life of 73.827 days, and finds application in brachytherapy and in industrial radiography, particularly for nondestructive testing of welds in steel in the oil and gas industries; iridium-192 sources have been involved in a number of radiological accidents. Three other isotopes have half-lives of at least a day—188Ir, 189Ir, and 190Ir. Isotopes with masses below 191 decay by some combination of β+ decay, α decay, and (rare) proton emission, with the exceptions of 189Ir, which decays by electron capture. Synthetic isotopes heavier than 191 decay by β− decay, although 192Ir also has a minor electron capture decay path. All known isotopes of iridium were discovered between 1934 and 2001; the most recent is 171Ir.
At least 32 metastable isomers have been characterized, ranging in mass number from 164 to 197. The most stable of these is 192m2Ir, which decays by isomeric transition with a half-life of 241 years, making it more stable than any of iridium's synthetic isotopes in their ground states. The least stable isomer is 190m3Ir with a half-life of only 2 µs. The isotope 191Ir was the first one of any element to be shown to present a Mössbauer effect. This renders it useful for Mössbauer spectroscopy for research in physics, chemistry, biochemistry, metallurgy, and mineralogy.
History.
The discovery of iridium is intertwined with that of platinum and the other metals of the platinum group. Native platinum used by ancient Ethiopians and by South American cultures always contained a small amount of the other platinum group metals, including iridium. Platinum reached Europe as "platina" ("small silver"), found in the 17th century by the Spanish conquerors in a region today known as the department of Chocó in Colombia. The discovery that this metal was not an alloy of known elements, but instead a distinct new element, did not occur until 1748.
Chemists who studied platinum dissolved it in aqua regia (a mixture of hydrochloric and nitric acids) to create soluble salts. They always observed a small amount of a dark, insoluble residue. Joseph Louis Proust thought that the residue was graphite. The French chemists Victor Collet-Descotils, Antoine François, comte de Fourcroy, and Louis Nicolas Vauquelin also observed the black residue in 1803, but did not obtain enough for further experiments.
In 1803, British scientist Smithson Tennant (1761–1815) analyzed the insoluble residue and concluded it must contain a new metal. Vauquelin treated the powder alternately with alkali and acids and obtained a volatile new oxide, which he believed to be of this new metal—which he named "ptene", from the Greek word πτηνός "ptēnós", "winged". Tennant, who had the advantage of a much greater amount of residue, continued his research and identified the two previously undiscovered elements in the black residue, iridium and osmium. He obtained dark red crystals (probably of Na2[IrCl6]·"n"H2O) by a sequence of reactions with sodium hydroxide and hydrochloric acid. He named iridium after Iris (Ἶρις), the Greek winged goddess of the rainbow and the messenger of the Olympian gods, because many of the salts he obtained were strongly colored. Discovery of the new elements was documented in a letter to the Royal Society on June 21, 1804.
British scientist John George Children was the first to melt a sample of iridium in 1813 with the aid of "the greatest galvanic battery that has ever been constructed" (at that time). The first to obtain high-purity iridium was Robert Hare in 1842. He found it had a density of around 21.8 g/cm3 and noted the metal is nearly immalleable and very hard. The first melting in appreciable quantity was done by Henri Sainte-Claire Deville and Jules Henri Debray in 1860. They required burning more than 300 l of pure O2 and H2 for each kg of iridium.
These extreme difficulties in melting the metal limited the possibilities for handling iridium. John Isaac Hawkins was looking to obtain a fine and hard point for fountain pen nibs, and in 1834 managed to create an iridium-pointed gold pen. In 1880, John Holland and William Lofland Dudley were able to melt iridium by adding phosphorus and patented the process in the United States; British company Johnson Matthey later stated they had been using a similar process since 1837 and had already presented fused iridium at a number of World Fairs. The first use of an alloy of iridium with ruthenium in thermocouples was made by Otto Feussner in 1933. These allowed for the measurement of high temperatures in air up to 2000 °C.
In Munich, Germany in 1957 Rudolf Mössbauer, in what has been called one of the "landmark experiments in twentieth-century physics", discovered the resonant and recoil-free emission and absorption of gamma rays by atoms in a solid metal sample containing only 191Ir. This phenomenon, known as the Mössbauer effect (which has since been observed for other nuclei, such as 57Fe), and developed as Mössbauer spectroscopy, has made important contributions to research in physics, chemistry, biochemistry, metallurgy, and mineralogy. Mössbauer received the Nobel Prize in Physics in 1961, at the age 32, just three years after he published his discovery. In 1986 Rudolf Mössbauer was honored for his achievements with the Albert Einstein Medal and the Elliot Cresson Medal.
Occurrence.
Iridium is one of the nine least abundant stable elements in Earth's crust, having an average mass fraction of 0.001 ppm in crustal rock; gold is 40 times more abundant, platinum is 10 times more abundant, and silver and mercury are 80 times more abundant. Tellurium is about as abundant as iridium. In contrast to its low abundance in crustal rock, iridium is relatively common in meteorites, with concentrations of 0.5 ppm or more. The overall concentration of iridium on Earth is thought to be much higher than what is observed in crustal rocks, but because of the density and siderophilic ("iron-loving") character of iridium, it descended below the crust and into Earth's core when the planet was still molten.
Iridium is found in nature as an uncombined element or in natural alloys; especially the iridium–osmium alloys, osmiridium (osmium-rich), and Iridosmium (iridium-rich). In the nickel and copper deposits, the platinum group metals occur as sulfides (i.e. (Pt,Pd)S), tellurides (i.e. PtBiTe), antimonides (PdSb), and arsenides (i.e. PtAs2). In all of these compounds, platinum is exchanged by a small amount of iridium and osmium. As with all of the platinum group metals, iridium can be found naturally in alloys with raw nickel or raw copper.
Within Earth's crust, iridium is found at highest concentrations in three types of geologic structure: igneous deposits (crustal intrusions from below), impact craters, and deposits reworked from one of the former structures. The largest known primary reserves are in the Bushveld igneous complex in South Africa, though the large copper–nickel deposits near Norilsk in Russia, and the Sudbury Basin in Canada are also significant sources of iridium. Smaller reserves are found in the United States. Iridium is also found in secondary deposits, combined with platinum and other platinum group metals in alluvial deposits. The alluvial deposits used by pre-Columbian people in the Chocó Department of Colombia are still a source for platinum-group metals. As of 2003, the world reserves had not been estimated.
Cretaceous–Paleogene boundary presence.
The Cretaceous–Paleogene boundary of 66 million years ago, marking the temporal border between the Cretaceous and Paleogene periods of geological time, was identified by a thin stratum of iridium-rich clay. A team led by Luis Alvarez proposed in 1980 an extraterrestrial origin for this iridium, attributing it to an asteroid or comet impact. Their theory, known as the Alvarez hypothesis, is now widely accepted to explain the demise of the dinosaurs. A large buried impact crater structure with an estimated age of about 66 million years was later identified under what is now the Yucatán Peninsula (the Chicxulub crater). Dewey M. McLean and others argue that the iridium may have been of volcanic origin instead, because Earth's core is rich in iridium, and active volcanoes such as Piton de la Fournaise, in the island of Réunion, are still releasing iridium.
Production.
Iridium is also obtained commercially as a by-product from nickel and copper mining and processing. During electrorefining of copper and nickel, noble metals such as silver, gold and the platinum group metals as well as selenium and tellurium settle to the bottom of the cell as "anode mud", which forms the starting point for their extraction. To separate the metals, they must first be brought into solution. Several separation methods are available depending on the nature of the mixture; two representative methods are fusion with sodium peroxide followed by dissolution in aqua regia, and dissolution in a mixture of chlorine with hydrochloric acid.
After the mixture is dissolved, iridium is separated from the other platinum group metals by precipitating ammonium hexachloroiridate ((NH4)2IrCl6) or by extracting IrCl62- with organic amines. The first method is similar to the procedure Tennant and Wollaston used for their separation. The second method can be planned as continuous liquid–liquid extraction and is therefore more suitable for industrial scale production. In either case, the product is reduced using hydrogen, yielding the metal as a powder or "sponge" that can be treated using powder metallurgy techniques.
Iridium prices have fluctuated over a considerable range. With a relatively small volume in the world market (compared to other industrial metals like aluminium or copper), the iridium price reacts strongly to instabilities in production, demand, speculation, hoarding, and politics in the producing countries.
As a substance with rare properties, its price has been particularly influenced by changes in modern technology:
The gradual decrease between 2001 and 2003 has been related to an oversupply of Ir crucibles used for industrial growth of large single crystals.
Likewise the prices above 1000 USD/oz between 2010 and 2014 have been explained with the installation of production facilities for single crystal sapphire used in LED backlights for TVs.
Applications.
The demand for iridium surged from 2.5 tonnes in 2009 to 10.4 tonnes in 2010, mostly because of electronics-related applications that saw a rise from 0.2 to 6 tonnes – iridium crucibles are commonly used for growing large high-quality single crystals, demand for which has increased sharply. This increase in iridium consumption is predicted to saturate due to accumulating stocks of crucibles, as happened earlier in the 2000s. Other major applications include spark plugs that consumed 0.78 tonnes of Ir in 2007, electrodes for the chloralkali process (1.1 t in 2007) and chemical catalysts (0.75 t in 2007).
Industrial and medical.
The high melting point, hardness and corrosion resistance of iridium and its alloys determine most of its applications. Iridium and especially iridium–platinum alloys or osmium–iridium alloys have a low wear and are used, for example, for multi-pored spinnerets, through which a plastic polymer melt is extruded to form fibers, such as rayon. Osmium–iridium is used for compass bearings and for balances.
Corrosion and heat resistance makes iridium an important alloying agent. Certain long-life aircraft engine parts are made of an iridium alloy, and an iridium–titanium alloy is used for deep-water pipes because of its corrosion resistance. Iridium is also used as a hardening agent in platinum alloys. The Vickers hardness of pure platinum is 56 HV, whereas platinum with 50% of iridium can reach over 500 HV.
Devices that must withstand extremely high temperatures are often made from iridium. For example, high-temperature crucibles made of iridium are used in the Czochralski process to produce oxide single-crystals (such as sapphires) for use in computer memory devices and in solid state lasers. The crystals, such as gadolinium gallium garnet and yttrium gallium garnet, are grown by melting pre-sintered charges of mixed oxides under oxidizing conditions at temperatures up to 2100 °C. Its resistance to arc erosion makes iridium alloys ideal for electrical contacts for spark plugs.
Iridium compounds are used as catalysts in the Cativa process for carbonylation of methanol to produce acetic acid.
The radioisotope iridium-192 is one of the two most important sources of energy for use in industrial γ-radiography for non-destructive testing of metals. Additionally, 192Ir is used as a source of gamma radiation for the treatment of cancer using brachytherapy, a form of radiotherapy where a sealed radioactive source is placed inside or next to the area requiring treatment. Specific treatments include high dose rate prostate brachytherapy, bilary duct brachytherapy, and intracavitary cervix brachytherapy.
Scientific.
An alloy of 90% platinum and 10% iridium was used in 1889 to construct the International Prototype Metre and kilogram mass, kept by the International Bureau of Weights and Measures near Paris. The meter bar was replaced as the definition of the fundamental unit of length in 1960 by a line in the atomic spectrum of krypton, but the kilogram prototype is still the international standard of mass.
Iridium has been used in the radioisotope thermoelectric generators of unmanned spacecraft such as the "Voyager", "Viking", "Pioneer", "Cassini", "Galileo", and "New Horizons". Iridium was chosen to encapsulate the plutonium-238 fuel in the generator because it can withstand the operating temperatures of up to 2000 °C and for its great strength.
Another use concerns X-ray optics, especially X-ray telescopes. The mirrors of the Chandra X-ray Observatory are coated with a layer of iridium 60 nm thick. Iridium proved to be the best choice for reflecting X-rays after nickel, gold, and platinum were also tested. The iridium layer, which had to be smooth to within a few atoms, was applied by depositing iridium vapor under high vacuum on a base layer of chromium.
Iridium is used in particle physics for the production of antiprotons, a form of antimatter. Antiprotons are made by shooting a high-intensity proton beam at a "conversion target", which needs to be made from a very high density material. Although tungsten may be used instead, iridium has the advantage of better stability under the shock waves induced by the temperature rise due to the incident beam.
Carbon–hydrogen bond activation (C–H activation) is an area of research on reactions that cleave carbon–hydrogen bonds, which were traditionally regarded as unreactive. The first reported successes at activating C–H bonds in saturated hydrocarbons, published in 1982, used organometallic iridium complexes that undergo an oxidative addition with the hydrocarbon.
Iridium complexes are being investigated as catalysts for asymmetric hydrogenation. These catalysts have been used in the synthesis of natural products and able to hydrogenate certain difficult substrates, such as unfunctionalized alkenes, enantioselectively (generating only one of the two possible enantiomers).
Iridium forms a variety of complexes of fundamental interest in triplet harvesting.
Historical.
Iridium–osmium alloys were used to tip fountain pen nibs. The first major use of iridium was in 1834 in nibs mounted on gold. Since 1944, the famous Parker 51 fountain pen was fitted with a nib tipped by a ruthenium and iridium alloy (with 3.8% iridium). The tip material in modern fountain pens is still conventionally called "iridium", although there is seldom any iridium in it; other metals such as tungsten have taken its place.
An iridium–platinum alloy was used for the touch holes or vent pieces of cannon. According to a report of the Paris Exhibition of 1867, one of the pieces being exhibited by Johnson and Matthey "has been used in a Withworth gun for more than 3000 rounds, and scarcely shows signs of wear yet. Those who know the constant trouble and expense which are occasioned by the wearing of the vent-pieces of cannon when in active service, will appreciate this important adaptation".
The pigment "iridium black", which consists of very finely divided iridium, is used for painting porcelain an intense black; it was said that "all other porcelain black colors appear grey by the side of it".
Precautions.
Iridium in bulk metallic form is not biologically important or hazardous to health due to its lack of reactivity with tissues; there are only about 20 parts per trillion of iridium in human tissue. Like most metals, finely divided iridium powder can be hazardous to handle, as it is an irritant and may ignite in air.
Very little is known about the toxicity of iridium compounds because they are used in very small amounts, but soluble salts, such as the iridium halides, could be hazardous due to elements other than iridium or due to iridium itself. However, most iridium compounds are insoluble, which makes absorption into the body difficult.
A radioisotope of iridium, 192Ir, is dangerous like other radioactive isotopes. The only reported injuries related to iridium concern accidental exposure to radiation from 192Ir used in brachytherapy. High-energy gamma radiation from 192Ir can increase the risk of cancer. External exposure can cause burns, radiation poisoning, and death. Ingestion of 192Ir can burn the linings of the stomach and the intestines. 192Ir, 192mIr, and 194mIr tend to deposit in the liver, and can pose health hazards from both gamma and beta radiation.

</doc>
<doc id="14753" url="http://en.wikipedia.org/wiki?curid=14753" title="IOC (disambiguation)">
IOC (disambiguation)

IOC commonly refers to the International Olympic Committee.
IOC may also refer to:

</doc>
<doc id="14761" url="http://en.wikipedia.org/wiki?curid=14761" title="International Phonetic Alphabet">
International Phonetic Alphabet

The International Phonetic Alphabet (unofficially—though commonly—abbreviated IPA) is an alphabetic system of phonetic notation based primarily on the Latin alphabet. It was devised by the International Phonetic Association as a standardized representation of the sounds of oral language. The IPA is used by lexicographers, foreign language students and teachers, linguists, speech-language pathologists, singers, actors, constructed language creators, and translators.
The IPA is designed to represent only those qualities of speech that are part of oral language: phones, phonemes, intonation, and the separation of words and syllables. To represent additional qualities of speech, such as tooth gnashing, lisping, and sounds made with a cleft palate, an extended set of symbols called the Extensions to the IPA may be used.
IPA symbols are composed of one or more elements of two basic types, letters and diacritics. For example, the sound of the English letter ⟨t⟩ may be transcribed in IPA with a single letter, [t], or with a letter plus diacritics, [t̺ʰ], depending on how precise one wishes to be. Often, slashes are used to signal broad or phonemic transcription; thus, /t/ is less specific than, and could refer to, either [t̺ʰ] or [t], depending on the context and language.
Occasionally letters or diacritics are added, removed, or modified by the International Phonetic Association. As of the most recent change in 2005, there are 107 letters, 52 diacritics, and four prosodic marks in the IPA. These are shown in the current IPA chart, posted below in this article and at the website of the IPA.
History.
In 1886, a group of French and British language teachers, led by the French linguist Paul Passy, formed what would come to be known from 1897 onwards as the International Phonetic Association (in French, "l’Association phonétique internationale"). Their original alphabet was based on a spelling reform for English known as the Romic alphabet, but in order to make it usable for other languages, the values of the symbols were allowed to vary from language to language. For example, the sound [ʃ] (the "sh" in "shoe") was originally represented with the letter ⟨c⟩ in English, but with the digraph ⟨ch⟩ in French. However, in 1888, the alphabet was revised so as to be uniform across languages, thus providing the base for all future revisions. The idea of making the IPA was first suggested by Otto Jespersen in a letter to Paul Passy. It was developed by A.J. Ellis, Henry Sweet, Daniel Jones, and Passy.
Since its creation, the IPA has undergone a number of revisions. After major revisions and expansions in 1900 and 1932, the IPA remained unchanged until the IPA Kiel Convention in 1989. A minor revision took place in 1993 with the addition of four letters for mid-central vowels and the removal of letters for voiceless implosives. The alphabet was last revised in May 2005 with the addition of a letter for a labiodental flap. Apart from the addition and removal of symbols, changes to the IPA have consisted largely in renaming symbols and categories and in modifying typefaces.
Extensions to the IPA for speech pathology were created in 1990 and officially adopted by the International Clinical Phonetics and Linguistics Association in 1994.
Description.
The general principle of the IPA is to provide one letter for each distinctive sound (speech segment), although this practice is not followed if the sound itself is complex. This means that:
Among the symbols of the IPA, 107 letters represent consonants and vowels, 31 diacritics are used to modify these, and 19 additional signs indicate suprasegmental qualities such as length, tone, stress, and intonation. These are organized into a chart; the chart displayed here is the
 as posted at the website of the IPA.
Letterforms.
The letters chosen for the IPA are meant to harmonize with the Latin alphabet. For this reason, most letters are either Latin or Greek, or modifications thereof. Some letters are neither: for example, the letter denoting the glottal stop, ⟨ʔ⟩, has the form of a dotless question mark, and derives originally from an apostrophe. A few letters, such as that of the voiced pharyngeal fricative, ⟨ʕ⟩, were inspired by other writing systems (in this case, the Arabic letter ﻉ‎ "‘ain").
Despite its preference for harmonizing with the Latin script, the International Phonetic Association has occasionally admitted other letters. For example, before 1989, the IPA letters for click consonants were ⟨ʘ⟩, ⟨ʇ⟩, ⟨ʗ⟩, and ⟨ʖ⟩, all of which were derived either from existing IPA letters, or from Latin and Greek letters. However, except for ⟨ʘ⟩, none of these letters were widely used among Khoisanists or Bantuists, and as a result they were replaced by the more widespread symbols ⟨ʘ⟩, ⟨ǀ⟩, ⟨ǃ⟩, ⟨ǂ⟩, and ⟨ǁ⟩ at the IPA Kiel Convention in 1989.
Although the IPA diacritics are fully featural, there is little systemicity in the letter forms. A retroflex articulation is consistently indicated with a right-swinging tail, as in ⟨ɖ ʂ ɳ⟩, and implosion by a top hook, ⟨ɓ ɗ ɠ⟩, but other pseudo-featural elements are due to haphazard derivation and coincidence. For example, all nasal consonants but uvular ⟨ɴ⟩ are based on the form ⟨n⟩: ⟨m ɱ n ɲ ɳ ŋ⟩. However, the similarity between ⟨m⟩ and ⟨n⟩ is a historical accident, ⟨ɲ⟩ and ⟨ŋ⟩ are derived from ligatures of "gn" and "ng," and ⟨ɱ⟩ is an "ad hoc" imitation of ⟨ŋ⟩. In none of these is the form consistent with other letters that share these places of articulation.
Some of the new letters were ordinary Latin letters turned 180 degrees, such as ɐ ɔ ə ɟ ɥ ɯ ɹ ʇ ʌ ʍ ʎ (turned "a c e f h m r t v w y"). This was easily done in the era of mechanical typesetting, and had the advantage of not requiring the casting of special type for IPA symbols.
Symbols and sounds.
The International Phonetic Alphabet is based on the Latin alphabet, using as few non-Latin forms as possible. The Association created the IPA so that the sound values of most consonant letters taken from the Latin alphabet would correspond to "international usage". Hence, the letters ⟨b⟩, ⟨d⟩, ⟨f⟩, (hard) ⟨ɡ⟩, (non-silent) ⟨h⟩, (unaspirated) ⟨k⟩, ⟨l⟩, ⟨m⟩, ⟨n⟩, (unaspirated) ⟨p⟩, (voiceless) ⟨s⟩, (unaspirated) ⟨t⟩, ⟨v⟩, ⟨w⟩, and ⟨z⟩ have the values used in English; and the vowel letters from the Latin alphabet (⟨a⟩, ⟨e⟩, ⟨i⟩, ⟨o⟩, ⟨u⟩) correspond to the (long) sound values of Latin: [i] is like the vowel in "machine", [u] is as in "rule", etc. Other letters may differ from English, but are used with these values in other European languages, such as ⟨j⟩, ⟨r⟩, and ⟨y⟩.
This inventory was extended by using capital or cursive forms, diacritics, and rotation. There are also several symbols derived or taken from the Greek alphabet, though the sound values may differ. For example, ⟨ʋ⟩ is a vowel in Greek, but an only indirectly related consonant in the IPA. Though most of these subtly different glyph shapes have been devised for the IPA, in particular ⟨ɑ⟩, ⟨ɣ⟩, ⟨ɛ⟩, ⟨ɸ⟩, and ⟨ʋ⟩ which are encoded in Unicode separately from their Greek "parent" letters, three of these – ⟨β⟩, ⟨θ⟩ and ⟨χ⟩ – are often used unmodified in form, as they have not been encoded separately. However, ⟨β⟩ has been accepted for encoding as a separate character.
The sound values of modified Latin letters can often be derived from those of the original letters. For example, letters with a rightward-facing hook at the bottom represent retroflex consonants; and small capital letters usually represent uvular consonants. Apart from the fact that certain kinds of modification to the shape of a letter generally correspond to certain kinds of modification to the sound represented, there is no way to deduce the sound represented by a symbol from its shape (as for example in Visible Speech) nor even any systematic relation between signs and the sounds they represent (as in Hangul).
Beyond the letters themselves, there are a variety of secondary symbols which aid in transcription. Diacritic marks can be combined with IPA letters to transcribe modified phonetic values or secondary articulations. There are also special symbols for suprasegmental features such as stress and tone that are often employed.
Types of transcription.
There are two principal types of brackets used to set off IPA transcriptions:
For example, while the /p/ sounds of "pin" and "spin" are pronounced slightly differently in English (and this difference would be meaningful in some languages), the difference is not meaningful in English. Thus "phonemically" the words are /pɪn/ and /spɪn/, with the same /p/ phoneme. However, to capture the difference between them (the allophones of /p/), they can be transcribed phonetically as [pʰɪn] and [spɪn].
Other conventions are less commonly seen:
Handwritten forms.
IPA letters have handwritten forms designed for use in manuscripts and when taking field notes; they are occasionally seen in publications when the printer did not have fonts that supported IPA, and the IPA was therefore filled in by hand.
Modifying the IPA chart.
The International Phonetic Alphabet is occasionally modified by the Association. After each modification, the Association provides an updated simplified presentation of the alphabet in the form of a chart. (See History of the IPA.) The most recent official chart, from 2005, is presented above. Not all aspects of the alphabet can be accommodated in a chart. The indefinitely large number of tone letters, for example, make a full accounting impractical, and only a few examples are shown.
The procedure for modifying the alphabet or the chart is to propose the change in the "Journal of the IPA." (See, for example, August 2008 on a low central vowel and August 2011 on central approximants.) Reactions to the proposal may be published in the same or subsequent issues of the Journal (as in August 2009 on the low central vowel). A formal proposal is then put to the Council of the IPA – which is elected by the membership – for further discussion and a formal vote.
Only changes to the alphabet or chart that have been approved by the Council can be considered part of the official IPA. Nonetheless, many users of the alphabet, including the leadership of the Association itself, make personal changes or additions in their own practice, either for convenience in working on a particular language (see "Illustrations of the IPA" for individual languages in the "Handbook", which for example may use ⟨c⟩ for [tʃ]), or because they object to some aspect of the official version. For example, the chart displayed here is reorganized in response to perceived shortcomings of the official version, and in places reflects the organization of the 1979 chart.
Usage.
Although the IPA offers over 160 symbols for transcribing speech, only a relatively small subset of these will be used to transcribe any one language. It is possible to transcribe speech with various levels of precision. A precise phonetic transcription, in which sounds are described in a great deal of detail, is known as a "narrow transcription". A coarser transcription which ignores some of this detail is called a "broad transcription." Both are relative terms, and both are generally enclosed in square brackets. Broad phonetic transcriptions may restrict themselves to easily heard details, or only to details that are relevant to the discussion at hand, and may differ little if at all from phonemic transcriptions, but they make no theoretical claim that all the distinctions transcribed are necessarily meaningful in the language.
For example, the English word "little" may be transcribed broadly using the IPA as [ˈlɪtəl], and this broad (imprecise) transcription is a more or less accurate description of many pronunciations. A narrower transcription may focus on individual or dialectical details: [ˈɫɪɾɫ] in General American, [ˈlɪʔo] in Cockney, or [ˈɫɪːɫ] in Southern US English.
It is customary to use simpler letters, without many diacritics, in phonemic transcriptions. The choice of IPA letters may reflect the theoretical claims of the author, or merely be a convenience for typesetting. For instance, in English, either the vowel of "pick" or the vowel of "peak" may be transcribed as /i/ (for the pairs /pik, piːk/ or /pɪk, pik/), and neither is identical to the vowel of the French word "pique" which is also generally transcribed /i/. That is, letters between slashes do not have absolute values, something true of broader phonetic approximations as well. A narrow transcription may, however, be used to distinguish them: [pʰɪk], [pʰiːk], [pikʲ].
Linguists.
Although IPA is popular for transcription by linguists, American linguists often alternate use of the IPA with Americanist phonetic notation or use the IPA together with some nonstandard symbols, for reasons including reducing the error rate on reading handwritten transcriptions or avoiding perceived awkwardness of IPA in some situations. The exact practice may vary somewhat between languages and even individual researchers, so authors are generally encouraged to include a chart or other explanation of their choices.
Language study.
Some language study programs use the IPA to teach pronunciation. For example, in Russia (and earlier in the Soviet Union) and mainland China, textbooks for children and adults for studying English and French consistently use the IPA. English teachers and textbooks in Taiwan tend to use the Kenyon and Knott system, an IPA with slight typographical variations.
Dictionaries.
English.
Many British dictionaries, including the Oxford English Dictionary and some learner's dictionaries such as the "Oxford Advanced Learner's Dictionary" and the "Cambridge Advanced Learner's Dictionary", now use the International Phonetic Alphabet to represent the pronunciation of words. However, most American (and some British) volumes use one of a variety of pronunciation respelling systems, intended to be more comfortable for readers of English. For example, the respelling systems in many American dictionaries (such as "Merriam-Webster") use ⟨y⟩ for IPA [j] and ⟨sh⟩ for IPA [ʃ], reflecting common representations of those sounds in written English, using only letters of the English Roman alphabet and variations of them. (In IPA, [y] represents the sound of the French ⟨u⟩ (as in "tu"), and [sh] represents the pair of sounds in "grasshopper".)
Other languages.
The IPA is also not universal among dictionaries in languages other than English. Monolingual dictionaries of languages with generally phonemic orthographies generally do not bother with indicating the pronunciation of most words, and tend to use respelling systems for words with unexpected pronunciations. Dictionaries produced in Israel use the IPA rarely and sometimes use the Hebrew script for transcription of foreign words. Monolingual Hebrew dictionaries use pronunciation respelling for words with unusual spelling; for example, the "Even-Shoshan Dictionary" respells תָּכְנִית as תּוֹכְנִית because this word uses kamatz katan. Bilingual dictionaries that translate from foreign languages into Russian usually employ the IPA, but monolingual Russian dictionaries occasionally use pronunciation respelling for foreign words; for example, Ozhegov's dictionary adds нэ́ in brackets for the French word пенсне ("pince-nez") to indicate that the е does not iotate the н.
The IPA is more common in bilingual dictionaries, but there are exceptions here too. Mass-market bilingual Czech dictionaries, for instance, tend to use the IPA only for sounds not found in the Czech language.
Standard orthographies and capital variants.
IPA letters have been incorporated into the alphabets of various languages, notably via the Africa Alphabet in sub-Saharan Africa: Hausa, Fula, Akan, Gbe languages, Manding languages, Lingala, etc. This has created the need for capital variants. For example, Kabiyé of northern Togo has Ɔ ɔ, Ɛ ɛ, Ɖ ɖ, Ŋ ŋ, Ɣ ɣ, Ʃ ʃ, Ʊ ʊ (or Ʋ ʋ):
These, and others, are supported by Unicode, but appear in Latin ranges other than the IPA extensions.
In the IPA itself, only lower-case letters are used. The 1949 edition of the IPA handbook indicated that an asterisk ⟨*⟩ may be prefixed to indicate that a word is a proper name, but this convention has not been included in recent editions.
Classical singing.
IPA has widespread use among classical singers for preparation, especially among English-speaking singers who are expected to sing in a variety of foreign languages. Opera librettos are authoritatively transcribed in IPA, such as Nico Castel's volumes and Timothy Cheek's book "Singing in Czech". Opera singers' ability to read IPA was used by the site "Visual Thesaurus", which employed several opera singers "to make recordings for the 150,000 words and phrases in VT's lexical database. ...for their vocal stamina, attention to the details of enunciation, and most of all, knowledge of IPA."
Letters.
The International Phonetic Association organizes the letters of the IPA into three categories: pulmonic consonants, non-pulmonic consonants, and vowels.
Pulmonic consonant letters are arranged singly or in pairs of voiceless (tenuis) and voiced sounds, with these then grouped in columns from front (labial) sounds on the left to back (glottal) sounds on the right. In official publications by the IPA, two columns are omitted to save space, with the letters listed among 'other symbols', and with the remaining consonants arranged in rows from full closure (occlusives: stops and nasals), to brief closure (vibrants: trills and taps), to partial closure (fricatives) and minimal closure (approximants), again with a row left out to save space. In the table below, a slightly different arrangement is made: All pulmonic consonants are included in the pulmonic-consonant table, and the vibrants and laterals are separated out so that the rows reflect the common lenition pathway of "stop → fricative → approximant," as well as the fact that several letters pull double duty as both fricative and approximant; affricates may be created by joining stops and fricatives from adjacent cells. Shaded cells are judged to be implausible.
Vowel letters are also grouped in pairs—of unrounded and rounded vowel sounds—with these pairs also arranged from front on the left to back on the right, and from maximal closure at top to minimal closure at bottom. No vowel letters are omitted from the chart, though in the past some of the mid central vowels were listed among the 'other symbols'.
Each character is assigned a number, to prevent confusion between similar letters (such as ɵ and θ, ɤ and ɣ, or ʃ and ʄ) in such situations as the printing of manuscripts. The categories of sounds are assigned different ranges of numbers.
Consonants.
Pulmonic consonants.
A pulmonic consonant is a consonant made by obstructing the glottis (the space between the vocal cords) or oral cavity (the mouth) and either simultaneously or subsequently letting out air from the lungs. Pulmonic consonants make up the majority of consonants in the IPA, as well as in human language. All consonants in the English language fall into this category.
The pulmonic consonant table, which includes most consonants, is arranged in rows that designate manner of articulation, meaning how the consonant is produced, and columns that designate place of articulation, meaning where in the vocal tract the consonant is produced. The main chart includes only consonants with a single place of articulation.
Co-articulated consonants.
Co-articulated consonants are sounds that involve two simultaneous places of articulation (are pronounced using two parts of the vocal tract). In English, the [w] in "went" is a coarticulated consonant, because it is pronounced by rounding the lips and raising the back of the tongue. Other languages, such as French and Swedish, have different coarticulated consonants.
Affricates and double articulated consonants.
Affricates and doubly articulated stops are represented by two letters joined by a tie bar, either above or below the letters. The six most common affricates are optionally represented by ligatures, though this is no longer official IPA usage, because a great number of ligatures would be required to represent all affricates this way. Alternatively, a superscript notation for a consonant release is sometimes used to transcribe affricates, for example tˢ for t͡s, paralleling kˣ ~ k͡x. The letters for the palatal plosives c and ɟ, are often used as a convenience for t͡ʃ and d͡ʒ or similar affricates, even in official IPA publications, so they must be interpreted with care.
Non-pulmonic consonants.
Non-pulmonic consonants are sounds whose airflow is not dependent on the lungs. These include clicks (found in the Khoisan languages of Africa), implosives (found in languages such as Sindhi, Saraiki, Swahili and Vietnamese), and ejectives (found in many Amerindian and Caucasian languages).
Vowels.
The IPA defines a vowel as a sound which occurs at a syllable center. Below is a chart depicting the vowels of the IPA. The IPA maps the vowels according to the position of the tongue.
The vertical axis of the chart is mapped by vowel height. Vowels pronounced with the tongue lowered are at the bottom, and vowels pronounced with the tongue raised are at the top. For example, [ɑ] (the first vowel in "father") is at the bottom because the tongue is lowered in this position. However, [i] (the vowel in "meet") is at the top because the sound is said with the tongue raised to the roof of the mouth.
In a similar fashion, the horizontal axis of the chart is determined by vowel backness. Vowels with the tongue moved towards the front of the mouth (such as [ɛ], the vowel in "met") are to the left in the chart, while those in which it is moved to the back (such as [ʌ], the vowel in "but") are placed to the right in the chart.
In places where vowels are paired, the right represents a rounded vowel (in which the lips are rounded) while the left is its unrounded counterpart.
Diphthongs.
Diphthongs are typically specified with a non-syllabic diacritic, as in ⟨aɪ̯⟩. However, sometimes a tie bar is used, especially if it is difficult to tell if the vowel is characterized by an on-glide or an off-glide: ⟨a͡ɪ⟩ or ⟨o͜e⟩.
Diacritics.
Diacritics are small markings which are placed around the IPA letter in order to show a certain alteration or more specific description in the letter's pronunciation. Subdiacritics (markings normally placed below a letter) may be placed above a letter having a descender (informally called a tail), e.g. ŋ̊, ȷ̈.
The dotless "i," ⟨ı⟩, is used when the dot would interfere with the diacritic. Other IPA letters may appear as diacritic variants to represent phonetic detail: tˢ (fricative release), bʱ (breathy voice), ˀa (glottal onset), ᵊ (epenthetic schwa), oᶷ (diphthongization). Additional diacritics were introduced in the Extensions to the IPA, which were designed principally for speech pathology.
The state of the glottis can be finely transcribed with diacritics. A series of alveolar plosives ranging from an open to a closed glottis phonation are:
Suprasegmentals.
These symbols describe the features of a language above the level of individual consonants and vowels, such as prosody, tone, length, and stress, which often operate on syllables, words, or phrases: that is, elements such as the intensity, pitch, and gemination of the sounds of a language, as well as the rhythm and intonation of speech. Although most of these symbols indicate distinctions that are phonemic at the word level, symbols also exist for intonation on a level greater than that of the word.
Finer distinctions of tone may be indicated by combining the tone diacritics and letters shown here, though not many fonts support this. The primary examples are high (mid) rising ɔ᷄, ɔ˧˥; low rising ɔ᷅, ɔ˩˧; high falling ɔ᷇, ɔ˥˧; low (mid) falling ɔ᷆, ɔ˧˩; peaking ɔ᷈, ɔ˧˥˧ (etc.); and dipping ɔ᷉, ɔ˧˩˧ (etc.). The correspondence between the diacritics and tone letters is only approximate; for example, diacritics only indicate generic peaking or dipping tones, while the tone letters can convey fine phonetic detail, with over a hundred peaking and hundred dipping tone contours that correspond to these two diacritics, or even approximately to the six rising and falling diacritics. Various combinations are used in the IPA "Handbook" despite not being found on the simplified official IPA chart. However, although it is theoretically possible to combine the three diacritics in any permutation, in practice only the six combinations given here are actually used.
A work-around for diacritics sometimes seen when a language has more than one rising or falling tone, and the author does not wish to completely abandon the IPA, is to restrict generic rising ɔ̌ and falling ɔ̂ for the higher-pitched of the rising and falling tones, ɔ˥˧ and ɔ˧˥, and to use the non-standard subscript diacritics ɔ̗ and ɔ̖ for the lower-pitched rising and falling tones, ɔ˩˧ and ɔ˧˩. When a language has four or six level tones, the two mid tones are sometimes transcribed as high-mid ɔ̍ (non-standard) and low-mid ɔ̄.
As with other IPA diacritics, such as length, aspiration, and rhoticity, the stress mark may be doubled to indicate an extra degree of stress.
Obsolete and nonstandard symbols.
The IPA inherited alternate symbols from various traditions, but eventually settled on one for each sound. The other symbols are now considered obsolete. An example is ⟨ɷ⟩ which has been standardized to ⟨ʊ⟩. Several letters indicating secondary articulation have been dropped altogether, with the idea that such things should be indicated with diacritics: ⟨ƍ⟩ for ⟨zʷ⟩ is one. In addition, the rare voiceless implosive series ⟨ƥ ƭ ƈ ƙ ʠ⟩ has been dropped; they are now written ⟨ɓ̥ ɗ̥ ʄ̊ ɠ̊ ʛ̥⟩ or ⟨pʼ↓ tʼ↓ cʼ↓ kʼ↓ qʼ↓⟩. A rejected competing proposal for transcribing clicks, ⟨ʇ, ʗ, ʖ⟩, is still sometimes seen, as the official letters ⟨ǀ, ǃ, ǁ⟩ may cause problems with legibility, especially when used with brackets ([ ] or / /), the letter ⟨l⟩, or the prosodic marks ⟨⟩ (for this reason, some publications which use standard IPA click letters disallow IPA brackets).
There are also unsupported or "ad hoc" letters from local traditions that find their way into publications that otherwise use the standard IPA. This is especially common with affricates such as the "barred lambda" ⟨ƛ⟩ for [t͜ɬ].
IPA extensions.
The "Extensions to the IPA", often abbreviated as "extIPA" and sometimes called "Extended IPA", are symbols whose original purpose was to accurately transcribe disordered speech. At the IPA Kiel Convention in 1989, a group of linguists drew up the initial extensions, which were based on the previous work of the PRDS (Phonetic Representation of Disordered Speech) Group in the early 1980s. The extensions were first published in 1990, then modified, and published again in 1994 in the "Journal of the International Phonetic Association", when they were officially adopted by the ICPLA. While the original purpose was to transcribe disordered speech, linguists have used the extensions to designate a number of unique sounds within standard communication, such as hushing, gnashing teeth, and smacking lips. The extensions have also been used to record certain peculiarities in an individual's voice, such as nasalized voicing.
The Extensions to the IPA do not include symbols used for voice quality (VoQS), such as whispering.
Segments without letters.
The remaining blank cells on the IPA chart can be filled without too much difficulty if the need arises. Some "ad hoc" letters have appeared in the literature for the retroflex lateral flap, the voiceless lateral fricatives, the epiglottal trill, and the labiodental plosives. (See the grey letters in the PDF chart.) Diacritics can supply much of the remainder. If a sound cannot be transcribed, an asterisk ⟨*⟩ may be used, either as a letter or as a diacritic (as in ⟨k*⟩ sometimes seen for the Korean 'fortis' velar).
Consonants.
Representations of consonant sounds outside of the core set are created by adding diacritics to letters with similar sound values. The Spanish bilabial and dental approximants are commonly written as lowered fricatives, [β̞] and [ð̞] respectively. Similarly, voiced lateral fricatives would be written as raised lateral approximants, [ɭ˔ ʎ̝ ʟ̝]. A few languages such as Banda have a bilabial flap as the preferred allophone of what is elsewhere a labiodental flap. It has been suggested that this be written with the labiodental flap letter and the advanced diacritic, [ⱱ̟].
Similarly, a labiodental trill would be written [ʙ̪] (bilabial trill and the dental sign), and labiodental stops [p̪ b̪] rather than with the "ad hoc" letters sometimes found in the literature. Other taps can be written as extra-short plosives or laterals, e.g. [ɟ̆ ɢ̆/ʀ̆ ʟ̆], though in some cases the diacritic would need to be written below the letter. A retroflex trill can be written as a retracted [r̠], just as retroflex fricatives sometimes are. The remaining consonants, the uvular laterals (ʟ̠ "etc.") and the palatal trill, while not strictly impossible, are very difficult to pronounce and are unlikely to occur even as allophones in the world's languages.
Vowels.
The vowels are similarly manageable by using diacritics for raising, lowering, fronting, backing, centering, and mid-centering. For example, the unrounded equivalent of [ʊ] can be transcribed as mid-centered [ɯ̽], and the rounded equivalent of [æ] as raised [ɶ̝]. True mid vowels are lowered [e̞ ø̞ ɘ̞ ɵ̞ ɤ̞ o̞], while centered [ɪ̈ ʊ̈] and [ä] are near-close and open central vowels, respectively. The only known vowels that cannot be represented in this scheme are vowels with unexpected roundedness, which would require a dedicated diacritic, such as ⟨ʏʷ⟩ and ⟨uᵝ⟩ (or ⟨ɪʷ⟩ and ⟨ɯᵝ⟩).
Symbol names.
An IPA symbol is often distinguished from the sound it is intended to represent, since there is not necessarily a one-to-one correspondence between letter and sound in broad transcription, making articulatory descriptions such as 'mid front rounded vowel' or 'voiced velar stop' unreliable. While the "Handbook of the International Phonetic Association" states that no official names exist for its symbols, it admits the presence of one or two common names for each. The symbols also have nonce names in the Unicode standard. In some cases, the Unicode names and the IPA names do not agree. For example, IPA calls ɛ "epsilon", but Unicode calls it "small letter open E".
The traditional names of the Latin and Greek letters are usually used for unmodified letters. Letters which are not directly derived from these alphabets, such as [ʕ], may have a variety of names, sometimes based on the appearance of the symbol or on the sound that it represents. In Unicode, some of the letters of Greek origin have Latin forms for use in IPA; the others use the letters from the Greek section.
For diacritics, there are two methods of naming. For traditional diacritics, the IPA notes the name in a well known language; for example, é is "acute", based on the name of the diacritic in English and French. Non-traditional diacritics are often named after objects they resemble, so d̪ is called "bridge".
Pullum and Ladusaw list a variety of names in use for IPA symbols, both current and retired, in addition to names of many other non-IPA phonetic symbols. Their collection is extensive enough that the Unicode Consortium used it in the development of Unicode.
ASCII and keyboard transliterations.
Several systems have been developed that map the IPA symbols to ASCII characters. Notable systems include Kirshenbaum, Arpabet, SAMPA, and X-SAMPA. The usage of mapping systems in on-line text has to some extent been adopted in the context input methods, allowing convenient keying of IPA characters that would be otherwise unavailable on standard keyboard layouts.
Further reading.
</dl>

</doc>
<doc id="14762" url="http://en.wikipedia.org/wiki?curid=14762" title="Inspector Morse">
Inspector Morse

Inspector Endeavour Morse is a fictional character in the eponymous series of detective novels by British author Colin Dexter. On television, he appears in the 33-episode 1987–2000 drama series "Inspector Morse", in which John Thaw played the character; as well as the 2012 series "Endeavour", portrayed by Shaun Evans. Morse originally is described as a senior CID (Criminal Investigation Department) officer with the Thames Valley Police force in Oxford, England. With a Jaguar car (a Lancia in the early novels), a thirst for English real ale and a penchant for music (especially opera and Wagner), poetry, art, classics, classic cars, and cryptic crossword puzzles, Morse presents a likeable persona, despite his sullen temperament.
Name and family.
Morse prefers to use only his last name, and is generally evasive when asked about his first name, sometimes joking that it is "Inspector". At the end of "Death Is Now My Neighbour", it is revealed to be "Endeavour". Two-thirds of the way through the television episode based on the book, he gives the cryptic clue "My whole life's effort has revolved around Eve". In the series, it is noted that Morse's reluctance to use his Christian name led to his receiving the nickname "Pagan" while attending Stamford School (Stamford is an alma mater of Colin Dexter, the author of the Morse novels, and of Dexter's brother). In the novels, Morse's first name came from the vessel HMS "Endeavour": his mother was a member of the Religious Society of Friends (Quakers), who have a tradition of "virtue names", and his father admired Captain James Cook. Dexter, a fan of cryptic crosswords, named Morse after champion setter Jeremy Morse, one of Dexter's arch-rivals in writing crossword clues. Dexter used to walk along the bank of the River Thames at Oxford, opposite the boathouse belonging to 22nd Oxford Sea Scout Group; the building is named "T.S. Endeavour".
Morse's father was, by trade, a taxi driver, and Morse likes to explain the origin of his additional private income by saying that he "used to drive the Aga Khan". During the episode "Cherubim and Seraphim", it is revealed that Morse's parents divorced when he was 12. He remained with his mother until her death three years later, upon which he had to return to his father. Morse had a dreadful relationship with his stepmother, Gwen. He claims that he only read poetry to annoy her, and that her petty bullying almost drove him to suicide. He has a half-sister, Joyce, with whom he is on better terms. Morse was devastated when Joyce's daughter Marilyn took her own life.
Habits and personality.
Morse is ostensibly the embodiment of white, male, middle-class Englishness, with a set of prejudices and assumptions to match. He may thus be considered a late example of the gentleman detective, a staple of British detective fiction. This background is in sharp juxtaposition to the working class origins of his assistant, Lewis (named after another rival clue-writer, Mrs. B. Lewis); in the novels, Lewis is Welsh, but this was altered to a northern English (Geordie) background in the TV series. He is also middle-aged in the books.
Morse's relationships with authority—the establishment, bastions of power, and the status quo—are markedly ambiguous, as sometimes are his relations with women. Morse is frequently portrayed in the act of patronising female characters.
Morse's appearance of being patronising might have been misleading. He habitually showed empathy towards women, once opining that the female sex is not naturally prone to crime, being caring and non-violent. He was also never shy of showing his liking for attractive women and often had dates with those involved in cases.
Morse is extremely intelligent. He dislikes spelling and grammatical errors, demonstrated by the fact that, in every personal or private document he receives, he manages to point out at least one mistake. He claims his approach to crime-solving is deductive, and one of his key tenets is that "there is a 50 per cent chance that the last person to see the victim alive was the murderer". In reality, it is the pathologists who deduce. Morse uses immense intuition and his fantastic memory to get to the killer.
Career.
Although details of Morse's career are deliberately kept vague, it is hinted that he won a scholarship to study at St John's College, Oxford. He lost the scholarship as the result of poor academic performance resulting from a failed love affair, which is mentioned in the series in Season 3, Episode 2, "The Last Enemy", and recounted in detail in the novel "The Riddle of the Third Mile", chapter 7. Forced to leave the University, he entered the Army and, on leaving it, joined the police. He often reflects on such renowned scholars as A. E. Housman who, like himself, failed to get an academic degree from Oxford.
Novels.
The novels in the series are:
Inspector Morse also appears in several stories in Dexter's short story collection, "Morse's Greatest Mystery and Other Stories" (1993, expanded edition 1994).
In Dexter's last book, "The Remorseful Day", Morse dies in hospital from a heart attack.
Television.
The Inspector Morse novels were made into a TV series (also called "Inspector Morse") for the British TV channel ITV. The series was made by Zenith Productions for Central (a company later acquired by Carlton) and comprises 33 two-hour episodes (100 minutes excluding commercials)—20 more episodes than there are novels—produced between 1987 and 2000. The last episode was adapted from the final novel, "The Remorseful Day", in which, as previously stated, Morse dies.
A spin-off series, based on the television incarnation of Lewis, was titled "Lewis" and began airing in 2006 and appeared regularly until 2013. Kevin Whateley left open the possibility of creating more shows occasionally: "I think we might, as we did with 'Morse,' do the odd one or two [specials], but I don't want to go on spending six months each year filming it, and I don't think Laurence [actor Laurence Fox] does either," Whately tells the site. "... I think it's probably healthy if we do some, as ITV wants them, but not keep hammering them out." 
In August 2011, "ITV" announced plans to film a prequel drama, "Endeavour", with author Colin Dexter's participation. English actor Shaun Evans was cast as a young Morse in his university days and early career. The drama was broadcast on 2 January 2012 on ITV 1. Four new episodes were televised from 14 April 2013, showing Morse's early cases working for DI Fred Thursday and with Jim Strange, his later boss and Max De Bryn the pathologist. A second series of four episodes followed, screening in March and April 2014.
Radio.
An occasional BBC Radio 4 series (for the Saturday Play) was made starring the voices of John Shrapnel as Morse and Robert Glenister as Lewis. The series was written by Guy Meredith and directed by Ned Chaillet. Episodes included: "The Wench is Dead" (23 March 1992); "Last Seen Wearing" (28 May 1994); and "The Silent World of Nicholas Quinn" (10 February 1996).
Theatre.
A new Inspector Morse stage play appeared in 2010, written by Alma Cullen (author of four Morse screenplays for ITV). The part of Morse was played by Colin Baker. The play, entitled "Morse—House of Ghosts", saw the inscrutable Detective Chief Inspector Morse looking to his past, when an old acquaintance becomes the lead suspect in a murder case that involves the on-stage death of a young actress. The play toured the UK from August to December 2010.

</doc>
<doc id="14763" url="http://en.wikipedia.org/wiki?curid=14763" title="History of the Isle of Man">
History of the Isle of Man

The Isle of Man became separated from Britain and Ireland by about 8000 BC. It appears that colonisation took place by sea sometime before 6500 BC. The island has been visited by various raiders and trading peoples over the years. After being settled by people from Ireland in the first millennium, the Isle of Man was converted to Christianity and then suffered raids by Vikings from Norway. After becoming subject to suzerainty to Norway as part of the Kingdom of Mann and the Isles, the Isle of Man later became a possession of the Scottish and then English crowns.
Since 1866, the Isle of Man has been a Crown Dependency and has democratic self-government.
Prehistory.
Mesolithic.
The Isle of Man effectively became an island around 8,500 years ago when rising sea levels caused by the melting glaciers cut Mesolithic Britain off from continental Europe for the last time. A land bridge had existed between the Isle of Man and Cumbria prior to this date, although the location and opening of the land-bridge remains poorly understood.
The earliest traces of people on the Isle of Man date back to the Mesolithic Period, also known as the Middle Stone Age. The first residents lived in small natural shelters, hunting, gathering and fishing for their food. They used small tools made of flint or bone, examples of which have been found near the coast. Representatives of these artifacts are kept at the Manx National Heritage museum.
Neolithic to Bronze Age.
The Neolithic Period marked the coming of knowledge of farming, improved stone tools and pottery. It was during this period that megalithic monuments began to appear around the island. Examples are found at Cashtal yn Ard near Maughold, King Orry's Grave in Laxey, Meayll Circle near Cregneash, and Ballaharra Stones in St John's. The Megaliths were not the only culture during this time; there were also the local Ronaldsway and Bann cultures.
During the Bronze Age, the large communal tombs of the Megaliths were replaced with smaller burial mounds. Bodies were put in stone lined graves along with ornamental containers. The Bronze Age burial mounds created long lasting markers about the countryside.
Iron Age.
The Iron Age marked the beginning of Celtic cultural influence. Large hill forts appeared on hill summits and smaller promontory forts along the coastal cliffs, whilst large timber-framed roundhouses were built.
It is likely that the first Celts to inhabit the Island were Brythonic tribes from mainland Britain. The secular history of the Isle of Man during the Brythonic period remains mysterious. It is not known if the Romans ever made a landing on the island; if they did they certainly never conquered it. It has been speculated that the island may have become a haven for Druids and other refugees from Anglesey after the Sacking of Mona in 60AD. The best record of any event before the incursions of the Northmen is attributed to Báetán mac Cairill, king of Ulster, at the end of the 6th century (though some have thought this event may refer to Manau Gododdin between the Firths of Clyde and Forth). Even if the supposed conquest of the Menavian islands – Mann and Anglesey – by Edwin of Northumbria, in 616, did take place, it could not have led to any permanent results, for when the English were driven from the coasts of Cumberland and Lancashire, soon afterwards, they could not well have retained their hold on the island to the west of these coasts. One can speculate, however, that when Ecfrid's Northumbrians laid Ireland waste from Dublin to Drogheda in 684, they temporarily occupied Mann.
It is generally assumed that Irish invasion or immigration formed the basis of the modern Manx language; Irish migration to the island probably began in the 5th century AD. This is evident in the change in language used in Ogham inscriptions. The transition between "Manx Brythonic" (like Welsh) and "Manx Gaelic" (a Goidelic language which remains closely related to Irish Gaelic and Scottish Gaelic) may have been gradual. One question is whether present-day Manx language survives from pre-Norse days or reflects a linguistic reintroduction after the Norse invasion.
Tradition attributes the island's conversion to Christianity to St Maughold (Maccul), an Irish missionary who gives his name to a parish. There are the remains of around 200 tiny early chapels called keeils scattered across the Island. Evidence such as radiocarbon dating and magnetic drift points to many of these being built around 550-600AD. The island lends its name to "Manannán", the Brythonic and Gaelic sea god who is said in myth to have once ruled the island.
Middle Ages.
Viking Age and Norse kingdom.
During the period of Scandinavian domination there are two main epochs – one before the conquest of Mann by Godred Crovan in 1079, and the other after it. Warfare and unsettled rule characterize the earlier epoch; the later saw comparatively more peace.
Between about AD 800 and 815 the Vikings came to Mann chiefly for plunder; between about 850 and 990, when they settled in it, the island fell under the rule of the Scandinavian Kings of Dublin; and between 990 and 1079, it became subject to the powerful Earls of Orkney.
There was a mint producing coins on Mann between c.1025 and c.1065. These Manx coins were minted from an imported type 2 Hiberno-Norse penny die from Dublin. Hiberno-Norse coins were first minted under Sihtric, King of Dublin. This illustrates that Mann may have in fact been under the thumb of Dublin at this time.
The conqueror Godred Crovan was evidently a remarkable man, though little information about him is attainable. According to the "Chronicon Manniae" he subdued Dublin, and a great part of Leinster, and held the Scots in such subjection that no one who built a vessel dared to insert more than three bolts. The memory of such a ruler would be likely to survive in tradition, and it seems probable therefore that he is the person commemorated in Manx legend under the name of King Gorse or Orry. He created the Kingdom of Mann and the Isles in around 1079; it included the south-western islands of Scotland (Sodor) until 1164, when two separate kingdoms were formed from it. In 1154, the Diocese of Sodor and Man was formed under the Church of England.
The islands which were under his rule were called the "Suðr-eyjar" (Sudreys or the south isles, in contradistinction to the "Norðr-eyjar", or the "north isles," i.e. Orkney and Shetland), and they consisted of the Hebrides, and of all the smaller western islands of Scotland, with Mann. At a later date his successors took the title of "Rex Manniae et Insularum" (King of Mann and the Isles). The kingdom's capital was on St Patrick's Isle, where Peel Castle was built on the site of a Celtic monastery.
Olaf, Godred's son, exercised considerable power, and according to the Chronicle, maintained such close alliance with the kings of Ireland and Scotland that no one ventured to disturb the Isles during his time (1113–1152). In 1156, his son, Godred (reigned 1153–1158), who for a short period ruled over Dublin also, lost the smaller islands off the coast of Argyll as a result of a quarrel with Somerled (the ruler of Argyll). An independent sovereignty thus appeared between the two divisions of his kingdom.
In the 1130s the sent a small mission to establish the first bishopric on the Isle of Man, and appointed Wimund as the first bishop. He soon after embarked with a band of followers on a career of murder and looting throughout Scotland and the surrounding islands.
During the whole of the Scandinavian period, the Isles remained nominally under the suzerainty of the Kings of Norway, but the Norwegians only occasionally asserted it with any vigour. The first such king to assert control over the region was likely Magnus Barelegs, at the turn of the 12th century. It wasn't until Hakon Hakonarson's 1263 expedition that another king returned to the Isles.
Decline of Norse rule.
From the middle of the 12th century till 1217 the suzerainty, because Norway had become a prey to civil dissensions, had remained of a very shadowy character. But after that date it became a reality and Norway consequently came into collision with the growing power of the kingdom of Scotland.
Early in the 13th century, when Ragnald (reigned 1187–1229) paid homage to King John of England (reigned 1199–1216), we hear for the first time of English intervention in the affairs of Mann. But a period of Scots domination would precede the establishment of full English control.
Finally, in 1261, Alexander III of Scotland sent envoys to Norway to negotiate for the cession of the isles, but their efforts led to no result. He therefore initiated hostilities which terminated in the indecisive Battle of Largs against the Norwegian fleet in 1263. However, the Norwegian king Haakon Haakonsson died the following winter, and this allowed King Alexander to bring the war to a successful conclusion. Magnus Olafsson, King of Mann and the Isles (reigned 1252–1265), who had campaigned on the Norwegian side, had to surrender all the islands over which he had ruled, except Mann, for which he did homage. Two years later Magnus died and in 1266 King Magnus VI of Norway ceded the islands, including Mann, to Scotland in the Treaty of Perth in consideration of the sum of 4,000 marks (known as "merks" in Scotland) and an annuity of 100 marks. But Scotland's rule over Mann did not become firmly established till 1275, when the Manx suffered defeat in the decisive Battle of Ronaldsway, near Castletown.
English dominance.
In 1290 King Edward I of England sent Walter de Huntercombe to take possession of Mann, and it remained in English hands until 1313, when Robert Bruce took it after besieging Castle Rushen for five weeks. Then, until 1346, when the Battle of Neville's Cross decided the long struggle between England and Scotland in England's favour, there followed a confused period when Mann sometimes experienced English rule and sometimes Scottish.
About 1333 King Edward III of England granted Mann to William de Montacute, 3rd Baron Montacute, (later the 1st Earl of Salisbury), as his absolute possession, without reserving any service to be rendered to him. In 1388 the Island was "ravaged" by Sir William Douglas of Nithsdale on his way home from the destruction of the town of Carlingford. In 1392 his son sold the island including sovereignty to Sir William le Scrope. In 1399 King Henry IV brought about the beheading of Le Scrope, who had taken the side of Richard II. The island then came into the possession of the Crown, which granted it to Henry Percy, 1st Earl of Northumberland, but following his attainder, Henry IV, in 1405, made a lifetime grant of it, with the patronage of the bishopric, to Sir John Stanley. In 1406 this grant was extended – on a feudatory basis under the English Crown – to Sir John's heirs and assigns, the feudal fee being the service of rendering homage and two falcons to all future Kings of England on their coronations.
Early Modern period.
With the accession of the Stanleys to the throne there begins a more settled epoch in Manx history. Though the island's new rulers rarely visited its shores, they placed it under governors, who, in the main, seem to have treated it with the justice of the time. Of the thirteen members of the family who ruled in Mann, the second Sir John Stanley (1414–1432), James, the 7th Earl (1627–1651), and the 10th Earl of the same name (1702–1736) had the most important influence on it. The first curbed the power of the spiritual barons, introduced trial by jury, instead of trial by battle, and ordered the laws to be written. The second, known as the Great Stanley, and his wife, Charlotte de la Tremoille (or Tremouille), are probably the most striking figures in Manx history.
English Civil War and Interregnum.
In 1643 Charles I ordered James Stanley, 7th Earl of Derby to go to Mann, where the people, who were no doubt influenced by what was taking place in England, threatened to revolt.
Stanley's arrival, with English soldiers, soon put a stop to anything of this kind. He conciliated the people by his affability, brought in Englishmen to teach various handicrafts and tried to help the farmers by improving the breed of Manx horses, and, at the same time, he restricted the exactions of the Church. But the Manx also lost much of their liberty under his rule: they were heavily taxed; troops were quartered upon them; and they also had the more lasting grievance of being compelled to accept leases for three lives instead of holding their land by the straw tenure which they considered to be equivalent to a customary inheritance.
Six months after the death of Charles I (30 January 1649), Stanley received a summons from General Ireton to surrender the island, which he declined. In August 1651 Stanley went to England with some of his troops, among whom were 300 Manxmen, to join King Charles II. Charles was decisively defeated at the Battle of Worcester and Stanley was captured, imprisoned in Chester Castle and then tried by court-martial and executed at Bolton.
Rebellion.
Soon after Stanley's death, the Manx Militia, under the command of William Christian (known by his Manx name of Illiam Dhone), rose against the Countess and captured all the insular forts except Rushen and Peel. They were then joined by a Parliamentary force under Colonel Duckenfield, to whom the Countess surrendered after a brief resistance.
Oliver Cromwell had appointed Thomas Fairfax "Lord of Mann and the Isles" in September 1651, so that Mann continued under a monarchical government and remained in the same relation to England as before.
Restoration of the Stanleys.
The restoration of Stanley government in 1660 therefore caused as little friction and alteration as its temporary cessation had. One of the first acts of the new Lord, Charles Stanley, 8th Earl of Derby, was to order Christian to be tried. He was found guilty and executed. Of the other persons implicated in the rebellion only three were excepted from the general amnesty. But by Order in Council, Charles II pardoned them, and the judges responsible for the sentence on Christian were punished.
Charles Stanley's next act was to dispute the permanency of the tenants' holdings, which they had not at first regarded as being affected by the acceptance of leases, a proceeding which led to an almost open rebellion against his authority and to the neglect of agriculture, in lieu of which the people devoted themselves to the fisheries and to contraband trade.
Charles Stanley, who died in 1672, was succeeded firstly by his son William Richard George Stanley, 9th Earl of Derby until his death in 1702.
The agrarian question subsided only in 1704, when James, William's brother and successor, largely through the influence of Bishop Wilson, entered into a compact with his tenants, which became embodied in an act, called the Act of Settlement. Their compact secured the tenants in the possession of their estates in perpetuity on condition of a fixed rent, and a small fine on succession or alienation. From the great importance of this act to the Manx people it has been called their "Magna Carta". As time went on, and the value of the estates increased, the rent payable to the Lord became so small in proportion as to be almost nominal, being extinguished by purchase in 1916.
Revestment.
James died in 1736, and the suzerainty of the isle passed to James Murray, 2nd Duke of Atholl, his first cousin and heir-male. In 1764 he was succeeded by his only surviving child Charlotte, Baroness Strange, and her husband, John Murray, who (in right of his wife) became Lord of Mann. About 1720 the contraband trade greatly increased. In 1726 Parliament checked it somewhat for a time, but during the last ten years of the Atholl regime (1756–1765) it assumed such proportions that, in the interests of the Imperial revenue, it became necessary to suppress it. With a view to so doing, Parliament passed the Isle of Man Purchase Act 1765 (commonly called the "Revestment Act" by the Manx), under which it purchased the rights of the Atholls as Lords of Mann including the customs revenues of the Island for the sum of £70,000 sterling, and granted an annuity to the Duke and Duchess. The Atholls still retained their manorial rights, the patronage of the bishopric, and certain other perquisites, until they sold them for the sum of £417,144 in 1828.
Up to the time of the revestment, Tynwald had passed laws concerning the government of the island in all respects and had control over its finances, subject to the approval of the Lord of Mann. After the revestment, or rather after the passage of the Smuggling Act 1765 (commonly called the "Mischief Act" by the Manx), the Parliament at Westminster legislated with respect to customs, harbours and merchant shipping, and, in measures of a general character, it occasionally inserted clauses permitting the enforcement in the island of penalties in contravention of the acts of which they formed part. It also assumed the control of the insular customs duties. Such changes, rather than the transference of the full suzerainty to the King of Great Britain and Ireland, modified the (unwritten) constitution of the Isle of Man. Its ancient laws and tenures remained untouched, but in many ways the revestment affected it adversely. The hereditary Lords of Mann seldom, if ever, functioned as model rulers, but most of them had taken some personal share in its government, and had interested themselves in the well-being of its inhabitants. But now the whole direction of its affairs became the work of officials who regarded the island as a pestilent nest of smugglers, from which it seemed their duty to extract as much revenue as possible.
Some alleviation of this state of things happened between 1793 and 1826 when John Murray, 4th Duke of Atholl served as Governor, since, though he quarrelled with the House of Keys and unduly cared for his own pecuniary interests, he did occasionally exert himself to promote the welfare of the island. After his departure the English officials resumed their sway, but they showed more consideration than before. Moreover, since smuggling, which the Isle of Man Purchase Act had only checked – not suppressed – had by that time almost disappeared, and since the Manx revenue had started to produce a large and increasing surplus, the authorities looked more favourably on the Isle of Man, and, thanks to this fact and to the representations of the Manx people to British ministers in 1837, 1844 and 1853, it obtained a somewhat less stringent customs tariff and an occasional dole towards erecting its much neglected public works.
Modern period.
After 1866, when the Isle of Man obtained a nominal measure of Home Rule, the Manx people have made remarkable progress, and currently form a prosperous community, with a thriving offshore financial centre, a tourist industry (albeit smaller than in the past) and a variety of other industries.
The Isle of Man was a base for alien civilian internment camps in both the First World War (1914–18) and the Second World War (1939–45). During the First World War there were two camps, one a requisitioned holiday camp in Douglas and the other a purpose built camp at Knockaloe near Peel in the parish of Patrick. During the Second World War there were a number of smaller camps in Douglas, Peel, Port Erin and Ramsey. The (now disbanded) Manx Regiment was raised in 1938 and saw action during the Second World War.
On 2 August 1973, a flash fire killed 51 people at the Summerland amusement centre in Douglas.
Greater autonomy.
The early 20th century saw a revival of music, dance, and a limited revival of the Manx language, although the last "native" speaker of Manx Gaelic died in the 1970s. In the middle of the 20th century, the Taoiseach, Éamon de Valera, visited, and was so dissatisfied with the lack of support for Manx that he immediately had two recording vans sent over. During the 20th century the Manx tourist economy declined, as the English and Irish started flying to Spain for package holidays. The Manx Government responded to this by successfully promoting the island, with its low tax rates, as an offshore financial centre, although it has avoided being placed on a recent UK black list of tax havens. The financial centre has had its detractors who have pointed to the potential for money laundering.
In 1949 an Executive Council, chaired by the Lieutenant-Governor and including members of Tynwald, was created. This was the start of a transfer of executive power from the unelected Lieutenant Governor to democratically elected Manx politicians. Finance and the police passed to Manx control between 1958 and 1976. In 1980 the Lieutenant Governor was replaced as Chairman of the Executive Council by a chairman elected by Tynwald. Following legislation in 1984, the Executive Council was reconstituted in 1985 to include the chairmen of the eight principal Boards; in 1986 they were given the title of Minister and the chairman was retitled Chief Minister. In 1986 Sir Miles Walker CBE became the first Chief Minister of the Isle of Man. In 1990 the Executive Council was renamed the Council of Ministers.
The 1960s also saw a rise in Manx nationalism, spawning the parties Mec Vannin and the Manx National Party, as well as the now defunct "Fo Halloo" (literally "Underground"), which mounted a direct-action campaign of spray-painting and attempted house-burning.
On 5 July 1973, control of the postal service passed from the UK General Post Office to the new Isle of Man Post, which began to issue its own postage stamps.
The 1990s and early 21st century have seen a greater recognition of indigenous Manx culture, including the opening of the first Manx language primary school, as well as a general re-evaluation of the island's economy.

</doc>
<doc id="14764" url="http://en.wikipedia.org/wiki?curid=14764" title="Geography of the Isle of Man">
Geography of the Isle of Man

The Isle of Man is an island in the Irish Sea, between Great Britain and Ireland in Western Europe, with a population of over 75,000. It is a British Crown dependency. It has a small islet, the Calf of Man, to its south. It is located at .
Dimensions.
Area:
<br>"total:"
572 km²
<br>"land:"
572 km²
<br>"water:"
0 km²
This makes it:
Coast.
The Isle of Man has a coastline of 160 km, and claims 12 nm of territorial waters, but only holds exclusive fishing rights in the first 3 miles.
Raad ny Foillan long distance footpath runs 95 miles around the Manx coast.
Climate.
The Isle of Man enjoys a temperate climate, with cool summers and mild winters. Average rainfall is high compared to the majority of the British Isles, due to its location to the western side of Great Britain and sufficient distance from Ireland for moisture to be accumulated by the prevailing south-westerly winds. Average rainfall is highest at Snaefell, where it is around 1900 mm a year. At lower levels it can fall to around 800 mm a year.
Temperatures remain fairly cool, with the recorded maximum being 28.9 °C at Ronaldsway.
Terrain.
The island's terrain is varied. There are two mountainous areas divided by a central valley which runs between Douglas and Peel. The highest point in the Isle of Man, Snaefell, is in the northern area and reaches 620 m above sea level. The northern end of the island is a flat plain, consisting of glacial tills and marine sediments. To the south the island is more hilly, with distinct valleys. There is no land below sea level.
Natural hazards and environmental issues.
There are few severe natural hazards, the most common being high winds, rough seas and dense fog. In recent years there has been a marked increase in the frequency of high winds, heavy rains, summer droughts and flooding both from heavy rain and from high seas. Snow fall has decreased significantly over the past century while temperatures are increasing year round with rainfall decreasing.
Air pollution, marine pollution and waste disposal are issues in the Isle of Man.
Global warming and a sea level rise potentially pose a great threat to the Isle of Man. All of the Island's towns are at threat from rising sea levels while the Northern Plain, a large, flat and low-lying plain composed of soft marine sediments and glacial material, which makes up about a quarter of the Island's landmass, is in danger of being lost to the sea over the next two centuries. The same is true for the considerably smaller Southern Plain surrounding the settlements of Castletown and Ballasalla and including Ronaldsway Airport.
Protected sites for nature conservation.
In order of importance, international first, non-statutory last.
Ramsar sites.
Shares an identical boundary to the Ballaugh Curraghs ASSI.
Areas of Special Scientific Importance.
There are 14 ASSIs on the Isle of Man as of 01/01/09.
Marine nature reserves.
A marine nature reserve was designated in Ramsey Bay in Oct 2011.
Nature reserves and wildlife sites.
The Isle of Man now has forty-five non-statutory wildlife sites as of 30 January 2009, covering approximately 195ha of land and an additional 10.5 km of inter-tidal coast. The Manx Wildlife Trust also manage twenty nature reserves.
Geology.
The larger part of the island is formed from highly faulted and folded sedimentary rocks of Ordovician age. There is a belt of younger Silurian rocks along the west coast between Niarbyl and St Patrick's Isle and a small area of Devonian sandstones around Peel. 
A band of Carboniferous age rocks underlies part of the northern plain but is nowhere seen at the surface however similar age rocks do outcrop in the south between Castletown, Silverdale and Port St Mary. Permo-Triassic age rocks are known to lie beneath Point of Ayre but, as with the rest of the northern plain, these rocks are concealed by substantial thicknesses of superficial deposits.
The island has significant deposits of copper, lead and silver, zinc, iron, and plumbago (a mix of graphite and clay). There are also quarries of black marble, limestone flags, clay schist, and granite. These are all modern, and there was no noticeable exploitation of metals or minerals prior to the modern era.
Demographics.
The island has a census-estimated population of 84,497 according to the most recent 2011 census: up from 79,805 in 2006 and 76,315 in 2001.
The island's largest town and administrative centre is Douglas, whose population is 23,000 — nearly a third of the population of the island. Neighbouring Onchan, Ramsey in the north, Peel in the west and the three southern ports of Castletown, Port Erin and Port St Mary are the island's other main settlements. Almost all its population lives on or very near the coast.
References.
</dl>

</doc>
<doc id="14765" url="http://en.wikipedia.org/wiki?curid=14765" title="Demographics of the Isle of Man">
Demographics of the Isle of Man

This article is about the demographic features of the population of the Isle of Man, including population density, ethnicity, education level, health of the populace, economic status, religious affiliations and other aspects of the population.
Demographic statistics from the CIA World Factbook.
The following demographic statistics are from the CIA World Factbook, unless otherwise indicated.
Ethnic groups.
English
Scotish
Irish
Significant numbers of South Africans
Religions.
Pentecostals
Anglican, Roman Catholic, Methodist, Baptist, Presbyterian, Religious Society of Friends, Jehovah's Witnesses, Atheism, Agnosticism.
The Church of England is the established church.

</doc>
<doc id="14766" url="http://en.wikipedia.org/wiki?curid=14766" title="Politics of the Isle of Man">
Politics of the Isle of Man

The government of the Isle of Man is a parliamentary representative democracy. As a Crown Dependency, it is not subordinate to the government of the United Kingdom. That government, however, is responsible for defence and external affairs and could intervene in the domestic affairs of the isle under its residual responsibilities to guarantee "good government" in all Crown dependencies. The Monarch of the United Kingdom is also the head of state of the Isle of Man, and generally referred to as "The Queen, Lord of Mann". Legislation of the Isle of Man defines "the Crown in right of the Isle of Man" as being separate from the "Crown in right of the United Kingdom". Her representative on the isle is the Lieutenant Governor of the Isle of Man, but his role is mostly ceremonial, though he does have the power to grant Royal Assent (the withholding of which is the same as a veto).
Although the Isle of Man is not an integral part of the United Kingdom, its people are British citizens under UK law - there is no separate Manx citizenship. The United Kingdom has responsibility for all the island's external affairs, including citizenship, the isle's defence, good governance, and foreign relations. The isle has no representation at either the UK or EU parliaments.
The legislative power of the government is vested in a bicameral parliament called Tynwald (said to be the world's oldest "continuously existing" parliament), which consists of the directly elected House of Keys and the indirectly chosen Legislative Council. Following every House of Keys general election, the members of Tynwald elect from amongst themselves the Chief Minister of the Isle of Man, who serves as the head of government for five years (until the next general election). Executive power is vested in the Lieutenant Governor (as Governor-in-Council), the Chief Minister, and the Isle of Man's Council of Ministers. The judiciary is independent of the executive and the legislature.
Douglas, the largest town on the Isle of Man is its capital and seat of government, where the Government offices and the parliament chambers (Tynwald) are located.
Executive branch.
The Head of State is the Lord of Mann, which is a hereditary position held by the British monarch (currently Queen Elizabeth II). The Lieutenant Governor is appointed by the Queen, on the advice of the UK's Secretary of State for Justice, for a five-year term and nominally exercises executive power on behalf of the Queen. The Chief Minister is elected by Tynwald following every House of Keys general election and serves for five years until the next general election.
When acting as Lord of Mann, the Queen acts on the advice of the Secretary of State for Justice and Lord Chancellor of the United Kingdom having prime responsibility as Privy Counsellor for Manx affairs.
The executive branch under the Chief Minister is referred to as "the Government" or the "Civil Service", and consists of the Council of Ministers, nine Departments, ten Statutory Boards and three Offices. Each Department is run by a Minister who reports directly to the Council of Ministers. The Civil Service has more than 2000 employees and the total number of public sector employees including the Civil Service, teachers, nurses, police, etc. is about 9000 people. This is somewhat more than 10% of the population of the Island, and a full 23% of the working population. This does not include any military forces, as defence is the responsibility of the United Kingdom.
Legislative branch.
The Manx legislature is Tynwald, which consists of two chambers. The House of Keys has 24 members, elected for a five-year term in multi- and single-seat constituencies by the whole island. The Legislative Council has eleven members, the President of Tynwald, Bishop of Sodor and Man, the Attorney General and eight other members who are elected from the general population (often they are already Members of the House of Keys, but must leave the Keys if selected) by the House of Keys for a five-year term. The voting age is 16.
Political parties and elections.
In the 2011 Manx general election, of 29 September, the Liberal Vannin Party won three seats, up one since the last election, the remaining seats were won by independents. Three ministers lost their seats Anne Craine, Martyn Quayle, and Adrian Earnshaw as well as the former vice chairman of the Liberal Vannin Party Bill Malarkey. Voter turnout dropped from 64% to 54%.
Most Manx politicians stand for election as independents rather than as representatives of political parties. Though political parties do exist, their influence is not nearly as strong as is the case in mainland Britain. Consequently, much Manx legislation develops through consensus among the members of Tynwald, which contrasts with the much more adversarial nature of the British Parliament.
The largest political party is the recently established Liberal Vannin Party, which promotes greater Manx independence and more accountability in Government. In the 2011 Manx general election it won three seats in Tynwald including Leader Peter Karran MHK.
A Manx Labour Party also exists, unaffiliated to the British Labour Party.
A political pressure group Mec Vannin advocates the establishment of a sovereign republic.
The island also formerly had a Manx National Party. There are Manx members in the Celtic League, a political pressure group that advocates greater co-operation between and political autonomy for the Celtic nations.
The main political issues include the Island's relationship with the finance sector, housing prices and shortages, and the Manx language.
The vast majority of the members of the House of Keys are non-partisan (19), with two representatives from the Manx Labour Party and three from the Alliance for Progressive Government.
Intervention of the United Kingdom.
The UK Parliament has paramount power to legislate for the Isle of Man on all matters but it is a long-standing convention that it does not do so on domestic ('insular') matters without Tynwald's consent.
Occasionally, the UK Parliament acts against the wishes of Tynwald – the most recent example being the "Marine etc. Broadcasting (Offences) Act 1967", which banned pirate radio stations from operating in Manx waters. Legislation to accomplish this was defeated on its second reading in Tynwald, prompting Westminster to legislate directly.
The UK's secondary legislation (regulations and Statutory Instruments) cannot be extended to apply to the Isle of Man.
The Isle of Man is subject to certain European Union laws, by virtue of a being a territory for which the UK has responsibility in international law. These laws are those for areas not covered by the Protocol 3 opt-out that the UK included for the Isle of Man in its accession treaty – the areas excluded being free movement of persons, services and capital, and taxation and social policy harmonisation.
The Isle of Man has had several disputes with the European Court of Human Rights because it was late to change its laws concerning birching (corporal punishment) and sodomy.
Judicial branch.
The lowest courts in the Isle of Man are presided over by the High Bailiff and the Deputy High Bailiff, along with lay Justices of the Peace. The High Court of Justice consists of three civil divisions and is presided over by a Deemster. Appeals are dealt with by the Staff of Government Division with final appeal to the Judicial Committee of the Privy Council in the United Kingdom. The head of the Judiciary is the First Deemster and Clerk of the Rolls. The other High and Appeal Court Judges are the Second Deemster, Deputy Deemster and Judge of Appeal, all of whom are appointed by the Lieutenant Governor.
The Court of General Gaol Delivery is the criminal court for serious offences (effectively the equivalent of a Crown Court in England). It is theoretically not part of the High Court, but is effectively the criminal division of the court. The Second Deemster normally sits as the judge in this court. In 1992, His Honour Deemster Callow passed the last-ever sentence of death in a court in the British Islands (which was commuted to life imprisonment). Capital punishment in the Isle of Man was formally abolished by Tynwald in 1993 (although the last execution on the island took place in 1872).

</doc>
<doc id="14767" url="http://en.wikipedia.org/wiki?curid=14767" title="Economy of the Isle of Man">
Economy of the Isle of Man

Offshore banking, manufacturing, and tourism form key sectors of the economy of the Isle of Man, a British Crown dependency in the Irish Sea.
The government's policy of offering incentives to high-technology companies and financial institutions to locate on the island has expanded employment opportunities in high-income industries. As a result, agriculture and fishing, once the mainstays of the economy, now make declining contributions to the Island's Gross Domestic Product (GDP). Banking and other services now contribute the great bulk of GDP. The stability of the Government and openness for business make the Isle of Man an attractive alternative jurisdiction (DAW Index ranked 3).
Trade is mostly with the United Kingdom. The Isle of Man has free access to European Union markets for goods, but only has restricted access for services, people, or financial products.
The Isle of Man is a low tax economy with no capital gains tax, wealth tax, stamp duty, death duty or inheritance tax and income tax rates of 10% and 20%; corporation tax is at 0%.
Gambling.
The Isle of Man has also recently entered the online gambling industry. In 2005 PokerStars, one of the world's largest online poker sites, relocated its headquarters to the Isle of Man from Costa Rica. In 2006, RNG Gaming a large gaming software developer of P2P tournaments and Get21, a multiplayer online blackjack site, based their corporate offices on the island. 
The Isle of Man Government Lottery operated from 1986 to 1997. Since 2 December 1999 the island has participated in the United Kingdom National Lottery. The island is the only jurisdiction outside the United Kingdom where it is possible to play the UK National Lottery. Since 2010 it has also been possible for projects in the Isle of Man to receive national lottery Good Causes Funding. The good causes funding is distributed by the Manx Lottery Trust. Tynwald receives the 12p lottery duty for tickets sold in the Island.
Filmmaking.
The Manx government also promotes island locations for making films by contributing to the production costs. Among the most successful productions funded in part by the Isle of Man film industry were "Waking Ned", where the Manx countryside stood in for rural Ireland, and films like "Stormbreaker", "Shergar", "Tom Brown's Schooldays", "I Capture the Castle", "The Libertine", "Island at War" (TV series), "Five Children and It", "Colour Me Kubrick", "Sparkle", and others. Other films that have been filmed on the Isle of Man include "Thomas and the Magic Railroad", "Harry Potter and the Chamber of Secrets", and "Keeping Mum".
Radio and television.
The British television show "Top Gear" frequently tests high-powered cars on the island because many of the rural roads do not have speed limits.
Electricity.
Since 1999, the Isle of Man has received electricity through the world's longest submarine AC cable, the 90 kV Isle of Man to England Interconnector, as well as from a natural gas power station in Douglas, an oil power station in Peel and a small hydro-electric power station in Sulby Glen.
Tourism.
Tourism in the Isle of Man developed from the advancement of transportation to the Isle. In 1819 the first steamship "Robert Bruce" came to the Isle, only seven years after the first steam-vessel in the UK. In the 1820s the tourist scene was growing due to betterment of transportation capabilities.
Statistics.
GDP:
purchasing power parity: $2.113 billion (2003 est.) 
GDP—real growth rate:
NA%
GDP—per capita:
purchasing power parity: $28,500 (2003 est.) 
GDP—composition by sector:
<br>"agriculture:"
1%
<br>"industry:"
13%
<br>"services:"
86% (2000 est.)
Population below poverty line:
NA%
Household income or consumption by percentage share:
<br>"lowest 10%:"
NA%
<br>"highest 10%:"
NA%
Inflation rate (consumer prices):
3.6% (2003 est.)
Labor force:
39,690(2001)
Labour force—by occupation:
agriculture, forestry and fishing 3%, manufacturing 11%, construction 10%, transport and communication 8%, wholesale and retail distribution 11%, professional and scientific services 18%, public administration 6%, banking and finance 18%, tourism 2%, entertainment and catering 3%, miscellaneous services 10%
Unemployment rate:
0.6% (2004 est.)
Budget:
<br>"revenues:"
$485 million
<br>"expenditures:"
$463 million, including capital expenditures of $NA (FY00/01 est.)
Industries:
financial services, light manufacturing, tourism
Industrial production growth rate:
3.2% (1996/97)
Electricity—production:
329 GWh (1999)
Electricity—production by source:
<br>"fossil fuel:"
100%
<br>"hydro:"
0%
<br>"nuclear:"
0%
<br>"other:"
0% (1999)
Electricity—consumption:
287 GWh (1999)
Electricity—exports:
NA kWh
Electricity—imports:
NA kWh
Agriculture—products:
cereals, vegetables, cattle, sheep, pigs, poultry
Exports:
$NA
Exports—commodities:
tweeds, herring, processed shellfish, beef, lamb
Exports—partners:
UK
Imports:
$NA
Imports—commodities:
timber, fertilizers, fish
Imports—partners:
UK
Debt—external:
$NA
Economic aid—recipient:
$NA
Currency:
1 Isle of Man pound = 100 pence
Exchange rates:
Manx pounds per US$1: 0.6092 (January 2000), 0.6180 (1999), 0.6037 (1998), 0.6106 (1997), 0.6403 (1996), 0.6335 (1995); the Manx pound is at par with the British pound
Fiscal year:
1 April – 31 March

</doc>
<doc id="14768" url="http://en.wikipedia.org/wiki?curid=14768" title="Communications in the Isle of Man">
Communications in the Isle of Man

The Isle of Man has an extensive communications infrastructure. Consisting of telephone wires, submarine cables, and an array of television and mobile phone transmitters and towers.
Telecommunications.
Telegraph.
The history of Manx telecommunications starts in 1859, when the Isle of Man Electric Telegraph Company was formed on the island with the intention of connecting across the island by telegraph, and allowing messages to be sent onwards to the UK. In August 1859, a 36 nmi long cable was commissioned from Glass, Elliot and Company of Greenwich and laid from Cranstal (north of Ramsey) to St Bees in Cumbria using the chartered cable ship "Resolute". The cable was single-core, with gutta-percha insulation.
Twenty miles of overhead cable were also erected from Cranstal south to Ramsey, and on to Douglas. In England, the telegraph was connected to Whitehaven and the circuits of the Electric Telegraph Company.
The telegraph offices were located at 64 Athol Street, Douglas (also the company's head office) and at East Quay, Ramsey (now Marina House).
On 10 August 1860 the company was statutorily incorporated by an Act of Tynwald with a capital of £5,500.
The currents at Cranstal proved too strong, and in 1864 the cable was taken up and relaid further south, at Port-e-Vullen in Ramsey Bay. It was later relaid to land even further south at Port Cornaa.
Following the 1869 finalisation of UK telegraph nationalisation into a General Post Office monopoly, the Isle of Man Telegraph Company was nationalised in 1870 under the Telegraph Act 1870 (an Act of Parliament) at a cost to the British Government of £16,106 (paid in 1872 following arbitration proceedings over the value). Prior to nationalisation, the island's telegraph operations had been performing poorly and the company's share price valued it at around £100.
Subsequent to nationalisation, operations were taken over by the GPO. The internal telegraph system was extended within a year to Castletown and Peel, however by then the previous lack of modern communications in Castletown had already started the Isle of Man Government on its move to Douglas.
Due to increasing usage in the years following nationalisation, further cables between Port Cornaa and St Bees were laid in 1875 and 1885.
By 1883 Smith's Directory listed several telegraph offices operated by the Post Office, in addition to those at Douglas, Ramsey, Castletown and Peel the telegraph was also available at Laxey, Ballaugh, and Port St. Mary.
Throughout the First World War, the cable landing station at Port Cornaa was guarded by the Isle of Man Volunteer Corps.
The undersea telegraph cables have been disused since the 1950s, but remain in place.
Telephones.
The main telephone provider on the Isle of Man today is Manx Telecom.
In 1889 George Gillmore, formerly an electrician for the GPO's Manx telegraph operations, was granted a licence by the Postmaster General to operate the Isle of Man's first telephone service. Based in an exchange in Athol Street, early customers of Gilbert's telephone service included the Isle of Man Steam Packet Company and the Isle of Man Railway. Not having the resources to fund expansion or a link to England, Gillmore sold his licence to the National Telephone Company and stayed on as their manager on the island.
By 1901 there were 600 subscribers, and the telephone system had been extended to Ramsey, Castletown, Peel, Port Erin, Port St. Mary and Onchan.
On 1 January 1912 the National Telephone Company was nationalised and merged into the General Post Office by the Telephone Transfer Act 1911. Only Guernsey, Portsmouth and Hull remained outside of the GPO.
In 1922, the General Post Office offered to sell the island's telephone service to the Manx government, but the offer was not taken up. A similar arrangement in Jersey for that island's telephone service was concluded in 1923.
The first off-island telephone link was established in 1929, with the laying of a cable by the "CS Faraday" between Port Erin and Ballyhornan in Northern Ireland, a distance of 57 km, and then between Port Grenaugh and Blackpool, primarily to provide a link to Northern Ireland. The cable was completed on 6 June 1929 and the first call between the Isle of Man and the outside world was made on 28 June 1929 by Lieutenant Governor Sir Claude Hill in Douglas to the Postmaster General in Liverpool. The cable initially carried only two trunk circuits.
In 1942, a pioneering VHF frequency-modulated radio-link was established between Creg-na-Baa and the UK to provide an alternative to the sub-sea cable. This has since been discontinued.
This was augmented on 24 June 1943 by a 74 km long cable between Cemaes Bay in Anglesea and Port Erin, which had the world's first submerged repeater, laid by "HMCS Iris". The repeater doubled the possible number of circuits on the cable, and although it failed after only five months, its replacement worked for seven years.
In 1962 a further undersea cable was laid by "HMTS Ariel" between Colwyn Bay and the Island.
Historically, the telephone system on the Isle of Man had been run as a monopoly by the British General Post Office, and later British Telecommunications, and operated as part of the Liverpool telephone district.
By 1985 the privatised British Telecom had inherited the telephone operations of the GPO, including those on the Isle of Man. At this time the Manx Government announced that it would award a 20-year licence to operate the telephone system in a tender process. As part of this process, in 1986 British Telecom created a Manx-registered subsidiary company, Manx Telecom, to bid for the tender. It was believed that a local identity and management would be more politically acceptable in the tendering process as they competed with Cable & Wireless to win the licence. Manx Telecom won the tender, and commenced operations under the new identity from 1 January 1987.
On 28 March 1988 an 8,000 telephone circuit fibre optic cable, the longest unregenerated system in Europe, was inaugurated. In links Port Grenaugh to Silecroft in Cumbria, and was laid in September 1987. The cable was buried in the seabed along its entire length.
A further fibre optic cable, known as BT-MT1 was laid in October 1990 between Millom in Cumbria and Douglas, a distance of 43 nmi. Jointly operated by BT and Manx Telecom, it provides six channels each with a bandwidth of 140 Mbit/s. This cable remains in use today.
In July 1992, Mercury Communications laid the LANIS fibre-optic cables. LANIS-1 runs for 61 nmi between Port Grenaugh and Blackpool, and LANIS-2 runs for 36 nmi between the Isle of Man and Northern Ireland. They have six channels each with a bandwidth of 565 Mbit/s. The LANIS cables are now operated by Cable & Wireless. The LANIS-1 cable was damaged 600 m off Port Grenaugh on 27 November 2006, causing loss of the link and resulting in temporary Internet access issues for some Manx customers whilst it was awaiting repair.
On 17 November 2001 Manx Telecom became part of mmO2 following the demerger of BT Wireless's operations from BT Group, and the company was owned by Telefónica. On 4 June 2010 Manx Telecom was sold by Telefónica to UK private equity investor HgCapital (who were buying the majority stake), alongside telecoms management company CPS Partners
In December 2007, the Manx Electricity Authority and its telecoms subsidiary, e-llan Communications, commissioned the lighting of a new undersea fibre-optic link. It was laid in 1999 between Blackpool and Douglas as part of the Isle of Man to England Interconnector which connects the Manx electricity system to the UK's National Grid.
In March 2009, BlueWave Communications installed microwave links to Ireland and the UK. These were the first off-island microwave links.
According to the CIA World Factbook, in 1999 there were 51,000 fixed telephone lines in use in the Isle of Man.
The Isle of Man is included within the UK telephone numbering system, and is accessed externally via UK area codes, rather than by its own country calling code. The area codes currently in use are: +44 1624 (landlines) and +44 7425 / +44 7624 / +44 7924 (mobiles).
Submarine communications cables in service.
Submarine cables in Manx waters are governed by the Submarine Cables Act 2003 (an Act of Tynwald).
Telecoms service providers.
It is also rumoured that various online gaming companies operate their own networks outside of these providers, although they do not resell that service.
Mobile telephones.
The mobile phone network operated by Manx Telecom has been used by O2 as an environment for developing and testing new products and services prior to wider rollout. In December 2001, the company became the first telecommunications operator in Europe to launch a live 3G network. In November 2005, the company became the first in Europe to offer its customers an HSDPA (3.5G) service.
Internet.
In 1996 the Isle of Man Government obtained permission to use the .im National Top Level Domain (TLD) and has ultimate responsibility for its use. The domain is managed on a daily basis by Domicilium (IOM) Limited, an island based internet service provider. Broadband internet services are available through five local providers which are Manx Telecom, Sure, Wi-Manx, Domicilium, and BlueWave Communications.
Broadcasting.
Radio.
The public-service commercial radio station for the island is Manx Radio. Manx Radio is part funded by government grant, and partly by advertising.
There are two other Manx-based FM radio stations, Energy FM and 3 FM.
BBC national radio stations are also relayed locally via a transmitter located to the south of Douglas, relayed from Sandale transmitting station in Cumbria, as well as a signal feed from the Holme Moss transmitting station in West Yorkshire. The Douglas transmitter also broadcasts the BBC's DAB digital radio services and Classic FM.
Manx Radio is the only local service to broadcast on AM medium wave. No UK services are relayed via local AM transmitters. No longwave stations operate from the Island, although one (Musicmann279) was proposed.
A Channel 4 operated DAB multiplex is proposed, but there are currently no proposals to broadcast any of the three insular FM stations on DAB.
Television.
There is no Island-specific television service. Local transmitters retransmit UK Freeview broadcasts. The BBC region is BBC North West and the ITV region is Granada.
Many TV services are available by satellite, such as Sky, and Freesat from the Astra 2/Eurobird 1 group, as well as services from a range of other satellites around Europe such as Astra 1 and Hot Bird.
Manx ViaSat-IOM, ManSat, Telesat-IOM companies uses the first communications satellite ViaSat-1 that launched in 2011 and positioned at the Isle of Man registered 115.1 degrees West longitude geostationary orbit point.
In some areas, terrestrial television directly from the United Kingdom or Republic of Ireland can also be received.
Analogue television transmission ceased between 2008 and 2009, when limited local transmission of digital terrestrial television commenced. The UK's television licence regime extends to the Island.
There is no Island-specific opt-out of the BBC regional news programme "North West Tonight", in the way that the Channel Islands get their own version of "Spotlight".
ITV television has been available on parts of the east of the Isle of Man on 3 May 1956 when Granada Television transmissions started from the Winter Hill transmitting station, and to parts of the west of the island on 1 October 1959 from the Black Mountain transmitting station in Northern Ireland which broadcast Ulster Television. Parts of the north of the island received Border Television since 1 September 1961, initially directly from the Caldbeck transmitting station in Cumberland. On 26 March 1965 Border Television commenced relay of their signal through a local transmitter on Richmond Hill, 542 ft above sea level and three miles (5 km) from the centre of Douglas. The site allowed reliable reception of the Caldbeck signal, which is rebroadcast on a different frequency. The 200 ft high transmission tower was re-sited from London, where it had been used for early ITV transmissions. Richmond Hill was decommissioned after the close of 405 line broadcasts, although the 200 ft tower remained in use for radio with Manx Radio transmitting on 96.9 MHz and then 97.3 MHz until 1989. Manx Radio moved their FM service to the Carnane site and the frequecny changed to the current 97.2 MHz.
The television broadcasts are now transmitted from a 195 ft high transmitter on a hill to the south of Douglas. The transmitter is operated by Arqiva and is directly fed using a Fibre Optic cable. There are further sub-relay transmitters across the island. Following a realignment of ITV regional services and the digital switchover, the Douglas relay switched ITV broadcasts to Granada Television on Thursday 17 July 2009.
The Broadcasting Act 1993 (An Act of Tynwald) allows for the establishment of local television services. Only one application for a licence to run such a service was received by the Communications Commission. That application was rejected.
According to the CIA World Factbook, in 1999 there were 27,490 televisions in use in the Isle of Man.
Post.
Isle of Man Post issues its own stamps for use within the island and for sending post off-island. Only Manx stamps are valid for sending mail using the postal system. The Isle of Man adopted postcodes in 1993 using the prefix IM to fit in with the already established UK postcode system.

</doc>
<doc id="14769" url="http://en.wikipedia.org/wiki?curid=14769" title="Transport in the Isle of Man">
Transport in the Isle of Man

There are a number of transport services around the Isle of Man, Mostly consisting of paved roads, public transport, rail services, ports and an airport.
Roads.
The island has a total of 688 mi of public roads, all of which are paved. Roads are named using a numbering scheme similar to those used in the numbering of roads in Great Britain and Northern Ireland; each road is assigned a letter, which represents the road's category, and a subsequent 1–2 digit number. "A" roads constitute the main roads of the island whilst roads labelled B to D will decrease in size and or quality. U roads are yet smaller. There is no national speed limit - that is to say, the majority of roads one may drive at any speed which is safe and appropriate. Careless and dangerous driving laws still apply of course, so one may not travel at absolutely any speed. Nevertheless, sight lines are such that there are parts of the network where someone in an appropriate vehicle could approach 200mph - but local speed limits are prevalent in a similar manner to the UK. Nevertheless, measured travel speeds are often relatively low. One potential reason for this is that locals are permitted to start driving at the age of sixteen, when they are limited to 50mph for two years (indeed all drivers are limited to 50mph in the first two years after passing their driving test) and some are not used to having to make progress in the same way that drivers using a larger road network like in the UK are (even an awful driver can get from anywhere in the island to anywhere else in ninety minutes). Set against that is a strong culture of motor sport enthusiasm (pinaccled in the TT, but there are a huge number of events throughout the year) and the better locals are well used to traversing country roads at speeds illegal in roads of such low quality anywhere else on earth. This leads to a very diverse level of both driving competence and speed. It is probably safe to say the typical driver is both highly competent and relatively slow, rarely exceeding 75mph (121 km/h). Nevertheless it should be noted that in a referendum in the 2000s the introduction of blanket speed limits was refused by the population, suggesting that a large number appreciate the freedom.
There is a comprehensive bus network, operated by Bus Vannin, a department of the Isle of Man Government, with most routes originating or terminating in Douglas.
Railways.
The island has a total of 68.5 km of railway, of which 43.5 km is electrified. There are six separate rail systems on the island:
Beginning at Peel, on the west coast of the island, one can make a 'circular tour' of the Isle of Man railways - with a little bit of help from the buses. Taking Bus Route 8 from Peel to Port Erin, you pick up the Isle of Man Steam Railway for a journey to Douglas. A short walk from Douglas Railway Station to the promenade brings you to the Douglas Horse Tram line, which takes you to Derby Castle at the opposite end of the prom. At Derby Castle, the Manx Electric Railway begins its route northwards to Laxey and Ramsey. At Laxey, the MER interchanges with the Snaefell Mountain Railway - and a change of carriage will allow you to ride to the top of Snaefell. Upon returning to Laxey, the MER offers a route northwards to Ramsey. The final leg, from Ramsey back to Peel, is achieved by taking Bus Route 5. Leaving Peel at 8:10 am, and allowing time for a light lunch at the top of Snaefell, the total journey time is a little over 6 hours.
Airports.
The only commercial airport on the island is the Isle of Man Airport at Ronaldsway. Scheduled services operate to and from various cities in the United Kingdom and Ireland, operated by several different airlines.
The island's other paved runways are at Jurby and Andreas. Jurby remains in Isle of Man Government ownership and is used for motorsport events and, previously, airshows, while Andreas is privately owned and used by a local glider club. The old Hall Caine Airport, a grass field near Ramsey, is no longer used.
Aircraft Register.
The Isle of Man Aircraft Register became operational on 1 May 2007. The register is open to all non-commercial aircraft and is intended to be of particular interest to professionally flown corporate operators.
As of November 2012 a total of 537 corporate and private aircraft had been registered.
Ports and harbours.
Ports are located at Castletown, Douglas, Peel and Ramsey. Douglas is served by frequent ferries to and from United Kingdom and Ireland; the sole operator is the Isle of Man Steam Packet Company with exclusive use of the Isle of Man Sea Terminal, and the Douglas port linkspans under the conditions of the "user agreement" negotiated with the Isle of Man Government.
Merchant marine.
The Isle of Man register comprises 226 ships of 1,000 GRT or over, totalling 6,055,436 GRT or  tonnes deadweight (DWT). This figure includes some foreign-owned ships registered on the Island as a flag of convenience: Australia, 3; Cyprus, 4; Denmark, 30; Estonia, 3; France, 1; Germany, 57; Greece, 8; Hong Kong, 11; Iceland, 1; Italy, 6; Monaco, 4; Netherlands, 2; New Zealand, 1; Norway, 10; Singapore, 2; Sweden, 3; United Kingdom, 80; United States, 1.
A breakdown of ships by type: bulk, 25; cargo, 40; chemical tanker, 25; combination bulk, 2; container, 19; liquefied gas, 31; multi-functional large load carrier, 1; petroleum tanker, 59; refrigerated cargo, 1; roll on/roll off, 17; specialised tanker, 1; vehicle carrier, 5.

</doc>
<doc id="14773" url="http://en.wikipedia.org/wiki?curid=14773" title="Information theory">
Information theory

Information theory is a branch of applied mathematics, electrical engineering, and computer science involving the quantification of information. Information theory was developed by Claude E. Shannon to find fundamental limits on signal processing operations such as compressing data and on reliably storing and communicating data. Since its inception it has broadened to find applications in many other areas, including statistical inference, natural language processing, cryptography, neurobiology, the evolution and function of molecular codes, model selection in ecology, thermal physics, quantum computing, linguistics, plagiarism detection, pattern recognition, anomaly detection and other forms of data analysis.
A key measure of information is entropy, which is usually expressed by the average number of bits needed to store or communicate one symbol in a message. Entropy quantifies the uncertainty involved in predicting the value of a random variable. For example, specifying the outcome of a fair coin flip (two equally likely outcomes) provides less information (lower entropy) than specifying the outcome from a roll of a die (six equally likely outcomes).
Applications of fundamental topics of information theory include lossless data compression (e.g. ZIP files), lossy data compression (e.g. MP3s and JPEGs), and channel coding (e.g. for Digital Subscriber Line (DSL)). The field is at the intersection of mathematics, statistics, computer science, physics, neurobiology, and electrical engineering. Its impact has been crucial to the success of the Voyager missions to deep space, the invention of the compact disc, the feasibility of mobile phones, the development of the Internet, the study of linguistics and of human perception, the understanding of black holes, and numerous other fields. Important sub-fields of information theory are source coding, channel coding, algorithmic complexity theory, algorithmic information theory, information-theoretic security, and measures of information.
Overview.
The main concepts of information theory are, first, that a "message" conveys a quantifiable amount of information to the recipient, and, second, that a "channel" (over which messages are transmitted) has a quantifiable information "capacity" defining the limiting rate at which it can convey information. An underlying concept is that information must be news to the recipient; in particular, telling the recipient something the recipient already knows conveys no information. The object of coding theory is to encode messages so as to send them over a channel at as high a rate as possible (within the limits of the channel capacity).
These concepts can be grasped by considering the most widespread means of human communication: language. Two important aspects of a concise language are as follows: First, the most common words (e.g., "a", "the", "I") should be shorter than less common words (e.g., "roundabout", "generation", "mediocre"), so that sentences will not be too long. Such a tradeoff in word length is analogous to data compression and is the essential aspect of source coding. Second, if part of a sentence is unheard or misheard due to noise — e.g., a passing car — the listener should still be able to glean the meaning of the underlying message. Such robustness is as essential for an electronic communication system as it is for a language; properly building such robustness into communications is done by channel coding. Source coding and channel coding are the fundamental concerns of information theory.
Note that these concerns have nothing to do with the "importance" of messages. For example, a platitude such as "Thank you; come again" takes about as long to say or write as the urgent plea, "Call an ambulance!" while the latter may be more important and more meaningful in many contexts. Information theory, however, does not consider message importance or meaning, as these are matters of the quality of data rather than the quantity and readability of data, the latter of which is determined solely by probabilities. "Thank you, come again" conveys less information than "Call an ambulance!" not because it is less important or less urgent, but because it is said more often.
Information theory is generally considered to have been founded in 1948 by Claude Shannon in his seminal work, "A Mathematical Theory of Communication". The central paradigm of classical information theory is the engineering problem of the transmission of information over a noisy channel. The most fundamental results of this theory are Shannon's source coding theorem, which establishes that, on average, the number of "bits" needed to represent the result of an uncertain event is given by its entropy; and Shannon's noisy-channel coding theorem, which states that "reliable" communication is possible over "noisy" channels provided that the rate of communication is below a certain threshold, called the channel capacity. The channel capacity can be approached in practice by using appropriate encoding and decoding systems.
Information theory is closely associated with a collection of pure and applied disciplines that have been investigated and reduced to engineering practice under a variety of rubrics throughout the world over the past half century or more: adaptive systems, anticipatory systems, artificial intelligence, complex systems, complexity science, cybernetics, informatics, machine learning, along with systems sciences of many descriptions. Information theory is a broad and deep mathematical theory, with equally broad and deep applications, amongst which is the vital field of coding theory.
Coding theory is concerned with finding explicit methods, called "codes", for increasing the efficiency and reducing the net error rate of data communication over a noisy channel to near the limit that Shannon proved is the maximum possible for that channel. These codes can be roughly subdivided into data compression (source coding) and error-correction (channel coding) techniques. In the latter case, it took many years to find the methods Shannon's work proved were possible. A third class of information theory codes are cryptographic algorithms (both codes and ciphers). Concepts, methods and results from coding theory and information theory are widely used in cryptography and cryptanalysis. "See the article ban (unit) for a historical application."
Information theory is also used in information retrieval, intelligence gathering, gambling, statistics, and even in musical composition.
Historical background.
The landmark event that established the discipline of information theory, and brought it to immediate worldwide attention, was the publication of Claude E. Shannon's classic paper "A Mathematical Theory of Communication" in the "Bell System Technical Journal" in July and October 1948.
Prior to this paper, limited information-theoretic ideas had been developed at Bell Labs, all implicitly assuming events of equal probability. Harry Nyquist's 1924 paper, "Certain Factors Affecting Telegraph Speed", contains a theoretical section quantifying "intelligence" and the "line speed" at which it can be transmitted by a communication system, giving the relation formula_1 (recalling Boltzmann's constant), where "W" is the speed of transmission of intelligence, "m" is the number of different voltage levels to choose from at each time step, and "K" is a constant. Ralph Hartley's 1928 paper, "Transmission of Information", uses the word "information" as a measurable quantity, reflecting the receiver's ability to distinguish one sequence of symbols from any other, thus quantifying information as formula_2, where "S" was the number of possible symbols, and "n" the number of symbols in a transmission. The unit of information was therefore the decimal digit, much later renamed the hartley in his honour as a unit or scale or measure of information. Alan Turing in 1940 used similar ideas as part of the statistical analysis of the breaking of the German second world war Enigma ciphers.
Much of the mathematics behind information theory with events of different probabilities were developed for the field of thermodynamics by Ludwig Boltzmann and J. Willard Gibbs. Connections between information-theoretic entropy and thermodynamic entropy, including the important contributions by Rolf Landauer in the 1960s, are explored in "Entropy in thermodynamics and information theory".
In Shannon's revolutionary and groundbreaking paper, the work for which had been substantially completed at Bell Labs by the end of 1944, Shannon for the first time introduced the qualitative and quantitative model of communication as a statistical process underlying information theory, opening with the assertion that
With it came the ideas of
Quantities of information.
Information theory is based on probability theory and statistics. The most important quantities of information are entropy, the information in a random variable, and mutual information, the amount of information in common between two random variables. The former quantity gives the limit on how far message data can be compressed, while the latter can be used to find the communication rate across a channel.
The choice of logarithmic base in the following formulae determines the unit of information entropy that is used. The most common unit of information is the bit, based on the binary logarithm. Other units include the nat, which is based on the natural logarithm, and the hartley, which is based on the common logarithm.
In what follows, an expression of the form formula_3 is considered by convention to be equal to zero whenever formula_4 This is justified because formula_5 for any logarithmic base.
Entropy.
The entropy, formula_6, of a discrete random variable formula_7 is a measure of the amount of "uncertainty" associated with the value of formula_7.
Suppose one transmits 1000 bits (0s and 1s). If the value of each these bits is known to the receiver (has a specific value with certainty) ahead of transmission, it is clear that no information is transmitted. If, however, each bit is independently equally likely to be 0 or 1, 1000 shannons of information (also often called bits, in the information theoretic sense) have been transmitted. Between these two extremes, information can be quantified as follows. If formula_9 is the set of all messages formula_10 that formula_7 could be, and formula_12 is the probability of some formula_13, then the entropy, formula_6, of formula_7 is defined:
(Here, formula_17 is the self-information, which is the entropy contribution of an individual message, and formula_18 is the expected value.) A property of entropy is that it is maximized when all the messages in the message space are equiprobable formula_19,—i.e., most unpredictable—in which case formula_20.
The special case of information entropy for a random variable with two outcomes is the binary entropy function, usually taken to the logarithmic base 2, thus having the shannon (Sh) as unit:
Joint entropy.
The joint entropy of two discrete random variables formula_7 and formula_23 is merely the entropy of their pairing: formula_24. This implies that if formula_7 and formula_23 are independent, then their joint entropy is the sum of their individual entropies.
For example, if formula_27 represents the position of a chess piece — formula_7 the row and formula_23 the column, then the joint entropy of the row of the piece and the column of the piece will be the entropy of the position of the piece.
Despite similar notation, joint entropy should not be confused with cross entropy.
Conditional entropy (equivocation).
The conditional entropy or conditional uncertainty of formula_7 given random variable formula_23 (also called the equivocation of formula_7 about formula_23) is the average conditional entropy over formula_23:
Because entropy can be conditioned on a random variable or on that random variable being a certain value, care should be taken not to confuse these two definitions of conditional entropy, the former of which is in more common use. A basic property of this form of conditional entropy is that:
Mutual information (transinformation).
Mutual information measures the amount of information that can be obtained about one random variable by observing another. It is important in communication where it can be used to maximize the amount of information shared between sent and received signals. The mutual information of formula_7 relative to formula_23 is given by:
where formula_41 ("S"pecific mutual "I"nformation) is the pointwise mutual information.
A basic property of the mutual information is that
That is, knowing "Y", we can save an average of formula_43 bits in encoding "X" compared to not knowing "Y".
Mutual information is symmetric:
Mutual information can be expressed as the average Kullback–Leibler divergence (information gain) between the posterior probability distribution of "X" given the value of "Y" and the prior distribution on "X":
In other words, this is a measure of how much, on the average, the probability distribution on "X" will change if we are given the value of "Y". This is often recalculated as the divergence from the product of the marginal distributions to the actual joint distribution:
Mutual information is closely related to the log-likelihood ratio test in the context of contingency tables and the multinomial distribution and to Pearson's χ2 test: mutual information can be considered a statistic for assessing independence between a pair of variables, and has a well-specified asymptotic distribution.
Kullback–Leibler divergence (information gain).
The Kullback–Leibler divergence (or information divergence, information gain, or relative entropy) is a way of comparing two distributions: a "true" probability distribution "p(X)", and an arbitrary probability distribution "q(X)". If we compress data in a manner that assumes "q(X)" is the distribution underlying some data, when, in reality, "p(X)" is the correct distribution, the Kullback–Leibler divergence is the number of average additional bits per datum necessary for compression. It is thus defined
Although it is sometimes used as a 'distance metric', KL divergence is not a true metric since it is not symmetric and does not satisfy the triangle inequality (making it a semi-quasimetric).
Kullback–Leibler divergence of a prior from the truth.
Another interpretation of KL divergence is this: suppose a number "X" is about to be drawn randomly from a discrete set with probability distribution "p(x)". If Alice knows the true distribution "p(x)", while Bob believes (has a prior) that the distribution is "q(x)", then Bob will be more surprised than Alice, on average, upon seeing the value of "X". The KL divergence is the (objective) expected value of Bob's (subjective) surprisal minus Alice's surprisal, measured in bits if the "log" is in base 2. In this way, the extent to which Bob's prior is "wrong" can be quantified in terms of how "unnecessarily surprised" it's expected to make him.
Other quantities.
Other important information theoretic quantities include Rényi entropy (a generalization of entropy), differential entropy (a generalization of quantities of information to continuous distributions), and the conditional mutual information.
Coding theory.
Coding theory is one of the most important and direct applications of information theory. It can be subdivided into source coding theory and channel coding theory. Using a statistical description for data, information theory quantifies the number of bits needed to describe the data, which is the information entropy of the source.
This division of coding theory into compression and transmission is justified by the information transmission theorems, or source–channel separation theorems that justify the use of bits as the universal currency for information in many contexts. However, these theorems only hold in the situation where one transmitting user wishes to communicate to one receiving user. In scenarios with more than one transmitter (the multiple-access channel), more than one receiver (the broadcast channel) or intermediary "helpers" (the relay channel), or more general networks, compression followed by transmission may no longer be optimal. Network information theory refers to these multi-agent communication models.
Source theory.
Any process that generates successive messages can be considered a source of information. A memoryless source is one in which each message is an independent identically distributed random variable, whereas the properties of ergodicity and stationarity impose less restrictive constraints. All such sources are stochastic. These terms are well studied in their own right outside information theory.
Rate.
Information rate is the average entropy per symbol. For memoryless sources, this is merely the entropy of each symbol, while, in the case of a stationary stochastic process, it is
that is, the conditional entropy of a symbol given all the previous symbols generated. For the more general case of a process that is not necessarily stationary, the "average rate" is
that is, the limit of the joint entropy per symbol. For stationary sources, these two expressions give the same result.
It is common in information theory to speak of the "rate" or "entropy" of a language. This is appropriate, for example, when the source of information is English prose. The rate of a source of information is related to its redundancy and how well it can be compressed, the subject of source coding.
Channel capacity.
Communications over a channel—such as an ethernet cable—is the primary motivation of information theory. As anyone who's ever used a telephone (mobile or landline) knows, however, such channels often fail to produce exact reconstruction of a signal; noise, periods of silence, and other forms of signal corruption often degrade quality. How much information can one hope to communicate over a noisy (or otherwise imperfect) channel?
Consider the communications process over a discrete channel. A simple model of the process is shown below:
Here "X" represents the space of messages transmitted, and "Y" the space of messages received during a unit time over our channel. Let formula_50 be the conditional probability distribution function of "Y" given "X". We will consider formula_50 to be an inherent fixed property of our communications channel (representing the nature of the noise of our channel). Then the joint distribution of "X" and "Y" is completely determined by our channel and by our choice of formula_52, the marginal distribution of messages we choose to send over the channel. Under these constraints, we would like to maximize the rate of information, or the signal, we can communicate over the channel. The appropriate measure for this is the mutual information, and this maximum mutual information is called the channel capacity and is given by:
This capacity has the following property related to communicating at information rate "R" (where "R" is usually bits per symbol). For any information rate "R < C" and coding error ε > 0, for large enough "N", there exists a code of length "N" and rate ≥ R and a decoding algorithm, such that the maximal probability of block error is ≤ ε; that is, it is always possible to transmit with arbitrarily small block error. In addition, for any rate "R > C", it is impossible to transmit with arbitrarily small block error.
Channel coding is concerned with finding such nearly optimal codes that can be used to transmit data over a noisy channel with a small coding error at a rate near the channel capacity.
Applications to other fields.
Intelligence uses and secrecy applications.
Information theoretic concepts apply to cryptography and cryptanalysis. Turing's information unit, the ban, was used in the Ultra project, breaking the German Enigma machine code and hastening the end of World War II in Europe. Shannon himself defined an important concept now called the unicity distance. Based on the redundancy of the plaintext, it attempts to give a minimum amount of ciphertext necessary to ensure unique decipherability.
Information theory leads us to believe it is much more difficult to keep secrets than it might first appear. A brute force attack can break systems based on asymmetric key algorithms or on most commonly used methods of symmetric key algorithms (sometimes called secret key algorithms), such as block ciphers. The security of all such methods currently comes from the assumption that no known attack can break them in a practical amount of time.
Information theoretic security refers to methods such as the one-time pad that are not vulnerable to such brute force attacks. In such cases, the positive conditional mutual information between the plaintext and ciphertext (conditioned on the key) can ensure proper transmission, while the unconditional mutual information between the plaintext and ciphertext remains zero, resulting in absolutely secure communications. In other words, an eavesdropper would not be able to improve his or her guess of the plaintext by gaining knowledge of the ciphertext but not of the key. However, as in any other cryptographic system, care must be used to correctly apply even information-theoretically secure methods; the Venona project was able to crack the one-time pads of the Soviet Union due to their improper reuse of key material.
Pseudorandom number generation.
Pseudorandom number generators are widely available in computer language libraries and application programs. They are, almost universally, unsuited to cryptographic use as they do not evade the deterministic nature of modern computer equipment and software. A class of improved random number generators is termed cryptographically secure pseudorandom number generators, but even they require random seeds external to the software to work as intended. These can be obtained via extractors, if done carefully. The measure of sufficient randomness in extractors is min-entropy, a value related to Shannon entropy through Rényi entropy; Rényi entropy is also used in evaluating randomness in cryptographic systems. Although related, the distinctions among these measures mean that a random variable with high Shannon entropy is not necessarily satisfactory for use in an extractor and so for cryptography uses.
Seismic exploration.
One early commercial application of information theory was in the field of seismic oil exploration. Work in this field made it possible to strip off and separate the unwanted noise from the desired seismic signal. Information theory and digital signal processing offer a major improvement of resolution and image clarity over previous analog methods.
Semiotics.
Concepts from information theory such as redundancy and code control have been used by semioticians such as Umberto Eco and Rossi-Landi to explain ideology as a form of message transmission whereby a dominant social class emits its message by using signs that exhibit a high degree of redundancy such that only one message is decoded among a selection of competing ones.
Miscellaneous applications.
Information theory also has applications in gambling and investing, black holes, bioinformatics, and music.
References.
The classic work.
</dl>
Other journal articles.
</dl>
Textbooks on information theory.
</dl>
Other books.
</dl>

</doc>
<doc id="14774" url="http://en.wikipedia.org/wiki?curid=14774" title="Information explosion">
Information explosion

The information explosion is the rapid increase in the amount of published information or data and the effects of this abundance. As the amount of available data grows, the problem of managing the information becomes more difficult, which can lead to information overload. The Online Oxford English Dictionary indicates use of the phrase in a March 1964 "New Statesman" article. "The New York Times" first used the phrase in its editorial content in an article by Walter Sullivan on June 7, 1964, in which he described the phrase as "much discussed". (pE11.) The earliest use of the phrase seems to have been in an IBM advertising supplement to the New York Times published on April 30, 1961, and by Frank Fremont-Smith, Director of the American Institute of Biological Sciences Interdisciplinary Conference Program, in an April 1961 article in the AIBS Bulletin (p. 18.)
Techniques to gather knowledge from an overabundance of electronic information (e.g., data fusion may help in data mining) have existed since the 1970s.
Related terms.
Since "information" in electronic media is often used synonymously with "data", the term "information explosion" is closely related to the concept of "data flood" (also dubbed "data deluge"). Sometimes the term "information flood" is used as well. All of those basically boil down to the ever-increasing amount of electronic data exchanged per time unit. The awareness about non-manageable amounts of data grew along with the advent of ever more powerful data processing since the mid-1960s.
Web servers.
As of August 2005, there were over 70 million web servers. s of 2007[ [update]] there were over 135 million web servers.
Blogs.
According to Technorati, the number of blogs doubles about every 6 months with a total of 35.3 million blogs as of 2006. This is an example of the early stages of logistic growth, where growth is approximately exponential, since blogs are a recent innovation. As the number of blogs approaches the number of possible producers (humans), saturation occurs, growth declines, and the number of blogs eventually stabilizes.

</doc>
<doc id="14775" url="http://en.wikipedia.org/wiki?curid=14775" title="Inch">
Inch

An inch (plural: inches; abbreviation or symbol: in or ″ – a double prime) is a unit of length in the imperial and United States customary systems of measurement. Historically an inch was also used in a number of other systems of units. Traditional standards for the exact length of an inch have varied in the past, but since July 1959 when the international yard was defined as 0.9144 metres, the international inch has been exactly 25.4 mm. There are 12 inches in a foot and 36 inches in a yard.
Usage.
The inch is a commonly used customary unit of length in the United States, Canada, and the United Kingdom. For the United Kingdom, guidance on public sector use states that since 1 October 1995, without time limit, that the inch (along with the foot) is to be used as a primary unit for road signs and related measurements of distance (with the possible exception of clearance heights and widths) and may continue to be used as a secondary or supplementary indication following a metric measurement for other purposes.
The international standard symbol for inch is in (see ISO 31-1, Annex A) but traditionally the inch is denoted by a double prime, which is often approximated by double quotes, and the foot by a prime, which is often approximated by an apostrophe. For example three feet two inches can be written as 3′ 2″. Subdivisions of an inch are typically written using dyadic fractions with odd number numerators; for example, two and three eighths of an inch would be written as 2 3/8″ and not as 2.375″ nor as 2 6/16″.
Equivalence to other units of length.
1 international inch is equal to:
Etymology.
The English word "inch" comes from Latin "uncia" meaning "one-twelfth part" (in this case, one twelfth of a foot); the word "ounce" (one twelfth of a troy pound) has the same origin. The vowel change from "u" to "i" is umlaut; the consonant change from "c" (pronounced as "k") to "ch" is palatalisation (see Old English phonology).
In some other languages, the word for "inch" is similar to or the same as the word for "thumb"; for example, Catalan: "polzada" inch, "polze" thumb; French: "pouce" inch/thumb; Italian: "pollice" inch/thumb; Spanish: "pulgada" inch, "pulgar" thumb; Portuguese: "polegada" inch, "polegar" thumb; Dutch: "duim" inch/thumb; Afrikaans: "duim" inch/thumb; Swedish: "tum" inch, Danish and Norwegian: "tomme" / "tommer" inch/inches and "tommel" thumb, "tumme" thumb; Czech: "palec" inch/thumb; Slovak: "palec" inch/thumb; Hungarian: "hüvelyk" inch/thumb.
Given the etymology of the word "inch", it would seem that the inch is a unit derived from the foot unit in Latin in Roman times.
History.
The earliest known reference to the inch in England is from the "Laws of Æthelberht" dating to the early 7th century, surviving in a single manuscript from 1120. Paragraph LXVII sets out the fine for wounds of various depths: one inch, one shilling, two inches, two shillings, etc. "Gif man þeoh þurhstingð, stice ghwilve vi scillingas. Gife ofer ynce, scilling. æt twam yncum, twegen. ofer þry, iii scill."
An Anglo-Saxon unit of length was the barleycorn. After 1066, 1 inch was equal to 3 barleycorn, which continued to be its legal definition for several centuries, with the barleycorn being the base unit. One of the earliest such definitions is that of 1324, where the legal definition of the inch was set out in a statute of Edward II of England, defining it as "three grains of barley, dry and round, placed end to end, lengthwise".
Similar definitions are recorded in both English and Welsh medieval law tracts. One, dating from the first half of the 10th century, is contained in the Laws of Hywel Dda which superseded those of Dyvnwal, an even earlier definition of the inch in Wales. Both definitions, as recorded in "Ancient Laws and Institutes of Wales" (vol i., pp. 184,187,189), are that "three lengths of a barleycorn is the inch".
King David I of Scotland in his Assize of Weights and Measures (c. 1150) is said to have defined the Scottish inch as the width of an average man's thumb at the base of the nail, even including the requirement to calculate the average of a small, a medium, and a large man's measures. However, the oldest surviving manuscripts date from the early 14th century and appear to have been altered with the inclusion of newer material.
Charles Butler, a mathematics teacher at Cheam School, in 1814 recorded the old legal definition of the inch to be "three grains of sound ripe barley being taken out the middle of the ear, well dried, and laid end to end in a row", and placed the barleycorn, not the inch, as the base unit of the English Long Measure system, from which all other units were derived. John Bouvier similarly recorded in his 1843 law dictionary that the barleycorn was the fundamental measure. Butler observed, however, that "[a]s the length of the barley-corn cannot be fixed, so the inch according to this method will be uncertain", noting that a standard inch measure was now (by his time) kept in the Exchequer chamber, Guildhall, and "that" was the legal definition of the inch. This was a point also made by George Long in his 1842 Penny Cyclopædia, observing that standard measures had since surpassed the barleycorn definition of the inch, and that to recover the inch measure from its original definition, in the event that the standard measure were destroyed, would involve the measurement of large numbers of barleycorns and taking their average lengths. He noted that this process would not perfectly recover the standard, since it might introduce errors of anywhere between one hundredth and one tenth of an inch in the definition of a yard.
Scottish inch.
The now obsolete Scottish inch (Scottish Gaelic: "òirleach"), 1/12 of a Scottish foot, was about 1.0016 imperial inches (about 1.0016 in). It was used in the popular expression "Gie 'im an inch, an he'll tak an ell", in English "Give him an inch and he'll take an ell", first published as "For when I gave you an inch, you tooke an ell" by John Heywood in 1546. (The ell, equal to 37 inches (about 94 cm), was in use in England until 1685.)
Continental inches.
Before the adoption of the metric system, several European countries had customary units whose name translates into "inch". The French "pouce" measured 2.70 cm, at least when applied to describe the calibre of artillery pieces (see also: Units of measurement in France). The Amsterdam foot ("voet") consisted of 11 Amsterdam inches ("duim") (see Dutch units of measurement). The Amsterdam foot is about 8% shorter than an English foot.
Modern standardisation.
In 1959 the International yard and pound agreement defined the international yard as 0.9144 metres, and the imperial and US yards were redefined accordingly. 
This resulted in the internationally accepted length of the imperial and US customary inch being exactly 25.4 millimetres. The international inch is 1.7 millionths of an inch longer than the old imperial inch, and 2 millionths of an inch shorter than the US inch. 
Before the adoption of the international inch various definitions were in use. In the United Kingdom and most countries of the British Commonwealth the inch was defined in terms of the Imperial Standard Yard. The United States adopted the conversion factor 1 metre = 39.37 inches by an act in 1866, and in 1893 Mendenhall ordered the physical realization of the inch be based on the international prototype metres numbers 21 and 27, which had been received from the CGPM together with the previously adopted conversion factor. 
In 1930 the British Standards Institution adopted an inch of exactly 25.4 mm. The American Standards Association followed suit in 1933. By 1935 industry in 16 countries had adopted the "industrial inch" as it came to be known.
In 1946 the Commonwealth Science Congress recommended a yard of exactly 0.9144 metres for adoption throughout the British Commonwealth. This was adopted by Canada in 1951. The United States, the United Kingdom, Canada, Australia, New Zealand and South Africa signed a treaty agreeing to the same standards on 1 July 1959. This gives an inch of exactly 25.4 mm. However, the United States retains the 1/39.37-metre definition for survey purposes creating a slight difference between the international and US survey inches; the difference is 2 millionths of the US survey inch. This is approximately 1/8-inch in a mile.

</doc>
<doc id="14776" url="http://en.wikipedia.org/wiki?curid=14776" title="Inn">
Inn

 
Inns are generally establishments or buildings where travelers can seek lodging and, usually, food and drink. They are typically located in the country or along a highway.
History and origins.
Inns in Europe were possibly first established when the Romans built their system of Roman roads two millennia ago. The Gospel of Luke records there being "no room at the inn" at the time of the nativity of Jesus. Some inns in Europe are several centuries old. In addition to providing for the needs of travelers, inns traditionally acted as community gathering places.
Historically, inns in Europe provided not only food and lodging, but also stabling and fodder for the travelers' horses. Famous London examples of inns include the George and the Tabard. There is however no longer a formal distinction between an inn and other kinds of establishment. Many pubs use the name "inn", either because they are long established and may have been formerly coaching inns, or to summon up a particular kind of image.
During the 1800s the inn played a major role in the growing transportation system of England. Industry was on the rise and people were traveling more in order to keep and maintain business. The English Inn was considered an important part of English infrastructure as it helped maintain a smooth flow of travel throughout the country.
As modes of transport have evolved, tourist' lodging has adapted to serve each generation of traveller. A stagecoach made frequent stops at roadside coaching inns for water, food and horses. A passenger train stops only at designated stations in the city centre, around which were built grand railway hotels. Motorcar traffic on old-style two-lane highways may pause at any camp, cabin court or motel along the way, while freeway traffic is restricted to access from designated off-ramps to side roads which quickly become crowded with hotel chain operators.
The original functions of an inn are now usually split among separate establishments, such as hotels, lodges, and motels, all of which might provide the traditional functions of an inn but which focus more on lodging customers than on other services; public houses, which are primarily alcohol-serving establishments; and restaurants and taverns, which serve food and drink. (Hotels often contain restaurants serving full breakfasts and meals, thus providing all of the functions of traditional inns. Economy, limited service properties, however, claim at most an included continental breakfast as there is no kitchen and no bar.)
The lodging aspect of the word "inn" lives on in hotel brand names like Holiday Inn, and in some laws that refer to lodging operators as "innkeepers".
Seljuq and Ottoman inns.
In Asia Minor during the periods of rule by the Seljuq and Ottoman Turks impressive structures functioning as inns (Turkish: "") were built because it was thought that inns were socially significant. These inns provided accommodation for people and their vehicles or animals and served as a resting place for people, whether travelling on foot or by other means.
These inns were built between towns if the distance between them was too far for one day's travel. These structures were called caravansarais which were inns with large courtyards with ample supplies of water for both drinking and other uses. They would also routinely contain a café in addition to supplies of food and fodder. After the caravans travelled a while they would take a break at these caravansarais, and spend the night there to rest both themselves and their animals.
Inns of Court.
The Inns of Court in London were originally ordinary inns where barristers met to do business, but have become institutions of the legal profession in England and Wales, and no longer function as inns.
Modern usage.
Most properly, "inn" in modern usage signifies a hotel which provides both lodging and a restaurant (possibly with a bar or tavern) to travellers. There is a growing trend for roadside motor hotel operators to distance themselves from the low-end category of "motel" in their branding by styling themselves instead as "inns" or "lodges".
The term has been readily adopted by chains such as Premier Inn, Holiday Inn, Comfort Inn, Days Inn and Knights Inn, even though not all of these serve food and drink. Less often, it has been applied to tavern-only facilities (such as the Stonewall Inn at the centre of the New York City drag queen riots of 1969) or restaurants (such as the former U-Drop Inn café on U.S. Route 66 in Texas) which do not provide all functions of a traditional roadside inn.
Laws governing motels and hotels are often named "Innkeeper's Act" or refer to hôteliers and motel operators as "innkeepers" in the body of the legislation and legal precedent cases. These laws typically define the innkeepers' liability for valuables entrusted to them by clients and determine whether an innkeeper holds any lien against such goods. In some jurisdictions, an offence named as "defrauding an innkeeper" prohibits fraudulently obtaining "food, lodging, or other accommodation at any hotel, inn, boarding house, or eating house"; in this context, the term is often an anachronism as the majority of modern restaurants are free-standing and not attached to coaching inns or tourist lodging.

</doc>
<doc id="14777" url="http://en.wikipedia.org/wiki?curid=14777" title="International Olympiad in Informatics">
International Olympiad in Informatics

The International Olympiad in Informatics (IOI) is the most prestigious annual competitive programming competition for secondary school students. It is the second largest olympiad, after International Mathematical Olympiad, in terms of number of participating countries (IOI 2014 saw participation of 84 countries). The first IOI was held in 1989 in Pravetz, Bulgaria.
The contest consists of two days of computer programming and problem-solving of algorithmic nature. To deal with problems involving very large amounts of data, it is necessary to have not only programmers, "but also creative coders, who can dream up what it is that the programmers need to tell the computer to do ... the hard part isn't the programming, but the mathematics underneath it." Students at the IOI compete on an individual basis, with up to four students competing from each participating country (with 81 countries in 2012). Students in the national teams are selected through national computing contests, such as the Australian Informatics Olympiad, British Informatics Olympiad, Indian Computing Olympiad and Bundeswettbewerb Informatik (Germany).
The International Olympiad in Informatics is one of the most prestigious computer science competitions in the world. UNESCO and IFIP are patrons. 
Competition structure and participation.
On each of the two competition days, the students are typically given three problems which they have to solve in five hours. Each student works on his/her own, with only a computer and no other help allowed, specifically no communication with other contestants, books etc. Usually to solve a task the contestant has to write a computer program (in C, C++ or Pascal, and occasionally FORTRAN and PHP, C++11 is supported starting from IOI 2014, while Java is planned to be added in IOI 2015) and submit it before the five hour competition time ends. The program is graded by being run with secret test data. From IOI 2010, tasks are divided into subtasks with graduated difficulty, and points are awarded only when all tests for a particular subtask yield correct results, within specific time and memory limits. In some cases, the contestant's program has to interact with a secret computer library, which allows problems where the input is not fixed, but depends on the program's actions – for example in game problems. Another type of problem has known inputs which are publicly available already during the five hours of the contest. For these, the contestants have to submit an output file instead of a program, and it is up to them whether they obtain the output files by writing a program (possibly exploiting special characteristics of the input), or by hand, or by a combination of these means.
IOI 2010 for the first time had a live web scoreboard with real-time provisional results. Submissions will be scored as soon as possible during the contest, and the results posted. Contestants will be aware of their scores, but not others', and may resubmit to improve their scores.
The scores from the two competition days and all problems are summed up separately for each contestant. At the awarding ceremony, contestants are awarded medals depending on their relative total score. The top 50% of the contestants are awarded medals, such that the relative number of gold : silver : bronze : no medal is approximately 1:2:3:6 (thus 1/12 of the contestants get a gold medal).
Unlike other science olympiads, the IOI regulations specifically prohibit ranking by countries. Although unofficial rankings are circulated within some participating nations, there is therefore no standard. Prior to IOI 2010, students who did not receive medals did not have their scores published, making it impossible for a country to be ranked by adding together scores of its competitors unless each wins a medal. From IOI 2010, although the scores of students who did not receive medals are still not available in the official results, they are known from the live web scoreboard. In IOI 2012 the top 3 nations ranked by aggregate score (Russia, China and USA) were subsequently awarded during the closing ceremony.
President of the IOI, Richard Forster, says the competition has difficulty attracting women and that in spite of trying to solve it, "none of us have hit on quite what the problem is, let alone the solution."
Multiple IOI winners.
The following is a list of the top performers in the history of the IOI. The * sign indicates a perfect score, a rare achievement in IOI history. Also, first (I), second (II) and third (III) places among gold medalists are indicated where appropriate. This list includes only those countries where the national selection contest allows the same participant to go multiple times to the IOI.
External links.
Open-source project for running contests:

</doc>
<doc id="14779" url="http://en.wikipedia.org/wiki?curid=14779" title="Iota">
Iota

Iota (uppercase Ι, lowercase ι; Greek: Ιώτα) is the ninth letter of the Greek alphabet. It was derived from the Phoenician letter Yodh. Letters that arose from this letter include the Roman I and J and the Cyrillic І (І, і), Yi (Ї, ї), Je (Ј, ј), and iotified letters (e.g. Yu (Ю, ю)).
In the system of Greek numerals iota has a value of 10. 
Iota represents the sound ]. In ancient Greek it occurred in both long [iː] and short [i] versions, but this distinction was lost in Koine Greek.
Iota participated as the second element in falling diphthongs, with both long and short vowels as the first element. Where the first element was long, the iota was lost in pronunciation at an early date, and was written in polytonic orthography as iota subscript, in other words as a very small ι under the main vowel, for instance ᾼ ᾳ ῌ ῃ ῼ ῳ. The former diphthongs became digraphs for simple vowels in Koine Greek.
The word is used in a common English phrase, 'not one iota', meaning 'not the slightest amount', in reference to a phrase in the New Testament: "until heaven and earth pass away, not an iota, not a dot, (King James Version: '[not] one jot or one tittle') will pass from the Law until all is accomplished." ()
The word 'jot' (or "iot") derives from iota.
The German, Portuguese and Spanish name for the letter J (Jot / jota) is derived from iota.
Character encodings.
These characters are used only as mathematical symbols. Stylized Greek text should be encoded using the normal Greek letters, with markup and formatting to indicate text style.

</doc>
<doc id="14780" url="http://en.wikipedia.org/wiki?curid=14780" title="ISP (disambiguation)">
ISP (disambiguation)

ISP may refer to:

</doc>
<doc id="14783" url="http://en.wikipedia.org/wiki?curid=14783" title="Erectile dysfunction">
Erectile dysfunction

Erectile dysfunction (ED) or impotence is sexual dysfunction characterized by the inability to develop or maintain an erection of the penis during sexual activity. A penile erection is the hydraulic effect of blood entering and being retained in sponge-like bodies within the penis. The process is most often initiated as a result of sexual arousal, when signals are transmitted from the brain to nerves in the penis. The most important organic causes are cardiovascular disease and diabetes, neurological problems (for example, trauma from prostatectomy surgery), hormonal insufficiencies (hypogonadism) and drug side effects.
Psychological impotence is where erection or penetration fails due to thoughts or feelings (psychological reasons) rather than physical impossibility; this is somewhat less frequent but can often be helped. Notably in psychological impotence, there is a strong response to placebo treatment. Erectile dysfunction can have severe psychological consequences as it can be tied to relationship difficulties and masculine self-image generally.
Besides treating the underlying causes such as potassium deficiency or arsenic contamination of drinking water, the first line treatment of erectile dysfunction consists of a trial of PDE5 inhibitor drugs (the first of which was sildenafil or Viagra). In some cases, treatment can involve prostaglandin tablets in the urethra, injections into the penis, a penile prosthesis, a penis pump or vascular reconstructive surgery.
The Latin term "impotentia coeundi" describes simple inability to insert the penis into the vagina; it is now mostly replaced by more precise terms, such as "erectile dysfunction" (ED). The study of erectile dysfunction within medicine is covered by andrology, a sub-field within urology. Research indicates that erectile dysfunction is common, and it is suggested that approximately 40% of males suffer from erectile dysfunction or impotence, at least occasionally.
Signs and symptoms.
Erectile dysfunction is characterized by the regular or repeated inability to obtain or maintain an erection. It is analyzed in several ways:
Causes.
Surgical intervention for a number of conditions may remove anatomical structures necessary to erection, damage nerves, or impair blood supply. Erectile dysfunction is a common complication of treatments for prostate cancer, including prostatectomy and destruction of the prostate by external beam radiation, although the prostate gland itself is not necessary to achieve erection.
ED can also be associated with bicycling due to both neurological and vascular problems due to compression. The increase risk appears to be about 1.7-fold.
Pathophysiology.
Penile erection is managed by two mechanisms: the reflex erection, which is achieved by directly touching the penile shaft, and the psychogenic erection, which is achieved by erotic or emotional stimuli. The former uses the peripheral nerves and the lower parts of the spinal cord, whereas the latter uses the limbic system of the brain. In both conditions, an intact neural system is required for a successful and complete erection. Stimulation of the penile shaft by the nervous system leads to the secretion of nitric oxide (NO), which causes the relaxation of smooth muscles of corpora cavernosa (the main erectile tissue of penis), and subsequently penile erection. Additionally, adequate levels of testosterone (produced by the testes) and an intact pituitary gland are required for the development of a healthy erectile system. As can be understood from the mechanisms of a normal erection, impotence may develop due to hormonal deficiency, disorders of the neural system, lack of adequate penile blood supply or psychological problems. Restriction of blood flow can arise from impaired endothelial function due to the usual causes associated with coronary artery disease, but can also be caused by prolonged exposure to bright light.
Diagnosis.
There are no formal tests to diagnose erectile dysfunction. Some blood tests are generally done to exclude underlying disease, such as hypogonadism and prolactinoma. Impotence is also related to generally poor physical health, poor dietary habits, obesity, and most specifically cardiovascular disease such as coronary artery disease and peripheral vascular disease.
A useful and simple way to distinguish between physiological and psychological impotence is to determine whether the patient "ever" has an erection. If "never", the problem is likely to be physiological; if "sometimes" (however rarely), it could be physiological or psychological. The current diagnostic and statistical manual of mental diseases (DSM-IV) has included a listing for impotence.
Treatment.
Treatment depends on the cause.
Exercise, particularly aerobic exercise during midlife is effective for preventing ED; exercise as a treatment is under investigation.:6, 18–19 For tobacco smokers, cessation results in a significant improvement.
Oral pharmacotherapy and vacuum erection devices are first-line treatments,:20,24 followed by injections of drugs into the penis, and penile implants.:25–26
Oral medication.
The cyclic nucleotide phosphodiesterases constitute a group of enzymes that destroy the cyclic nucleotides cyclic adenosine monophosphate (cAMP) and cyclic guanosine monophosphate (cGMP). Phosphodiesterases exist in different molecular forms and are unevenly distributed throughout the body. One of the forms of phosphodiesterase is termed PDE5, and inhibiting PDE5 increases the amount of cGMP available in the blood supply to the penis, thus increasing blood flow. The PDE5 inhibitors sildenafil (Viagra), vardenafil (Levitra) and tadalafil (Cialis) are prescription drugs which are taken orally.:20–21
Topical medication.
A topical cream combining alprostadil with the permeation enhancer DDAIP has been approved in Canada under the brand name Vitaros as a first line treatment for erectile dysfunction.
Injected medication.
Another treatment regimen is injection therapy. One of the following drugs is injected into the penis: papaverine, phentolamine, and prostaglandin E1.:25
Pumps.
A vacuum erection device helps draw blood into the penis by applying negative pressure. This type of device is sometimes referred to as penis pump and may be used just prior to sexual intercourse. Several types of FDA approved vacuum therapy devices are available with a doctor's prescription. When pharmacological methods fail, a purpose-designed external vacuum pump can be used to attain erection, with a separate compression ring fitted to the penis to maintain it. These pumps should be distinguished from other penis pumps (supplied without compression rings) which, rather than being used for temporary treatment of impotence, are claimed to increase penis length if used frequently, or vibrate as an aid to masturbation. More drastically, inflatable or rigid penile implants may be fitted surgically.
Surgery.
Often, as a last resort if other treatments have failed, the most common procedure is prosthetic implants which involves the insertion of artificial rods into the penis.:26
Alternative medicine.
The FDA does not recommend alternative therapies (i.e. those that have not received FDA approval) to treat sexual dysfunction. Many products are advertised as "herbal viagra" or "natural" sexual enhancement products, but no clinical trials or scientific studies support the effectiveness of these products for the treatment of erectile dysfunction, and synthetic chemical compounds similar to sildenafil have been found as adulterants in many of these products. The United States Food and Drug Administration has warned consumers that any sexual enhancement product that claims to work as well as prescription products is likely to contain such a contaminant.
History.
During the late 16th and 17th centuries in France, male impotence was considered a crime, as well as legal grounds for a divorce. The practice, which involved inspection of the complainants by court experts, was declared obscene in 1677.
John R. Brinkley initiated a boom in male impotence cures in the U.S. in the 1920s and 1930s. His radio programs recommended expensive goat gland implants and "mercurochrome" injections as the path to restored male virility, including operations by surgeon Serge Voronoff.
Modern drug therapy for ED made a significant advance in 1983, when British physiologist Giles Brindley dropped his trousers and demonstrated to a shocked Urodynamics Society audience his papaverine-induced erection. The drug Brindley injected into his penis was a non-specific vasodilator, an alpha-blocking agent, and the mechanism of action was clearly corporal smooth muscle relaxation. The effect that Brindley discovered established the fundamentals for the later development of specific, safe, orally effective drug therapies.
Research.
Gene therapy is being developed that would allow for weeks or months long effect, supporting erections. This gene therapy involves injection of a transfer gene, calcium-sensitive potassium channel (hMaxi-K), into the penis.
A study done at the Medical College of Georgia has found that venom from the Brazilian wandering spider contains a toxin, called Tx2-6, causes erections. Scientists believe that combining this toxin with existing medication such as Viagra may lead to an effective treatment for erectile dysfunction.

</doc>
<doc id="14784" url="http://en.wikipedia.org/wiki?curid=14784" title="Identity and change">
Identity and change

The relationship between identity and change in the philosophical field of metaphysics seems, at first glance, deceptively simple, and belies the complexity of the issues involved. This article explores "the problem of identity and change".
Change.
When an object changes, it always changes "in some particular way". A baby grows up, and so changes in respect of size and maturity; a snake sheds its skin, and so changes in respect of its skin. "Change" may therefore be defined as follows:
That seems to be, in one way, what it means for a thing to change: it has a property at one time, and later it does not have that property. If a banana becomes brown, it can then be said: at one time, the banana is yellow; several days later, the banana is not yellow, but is instead brown. This appears fairly straightforward at this point, and there are no apparent problems as yet.
Another way for an object to change is to change its parts.
Some philosophers believe that an object can't persist through a change of parts. They defend mereological essentialism.
Problem of change.
The question then arises as to what sort of change happens after a thing is "destroyed"? When a person dies, one does not say that the person's life has "changed". Neither does one go around saying, "Harry just isn't the same sort of guy since he died." Instead, one says that Harry's life has "ended". Similarly, when a building is demolished, one does not say that the building "changes"; one says that it is "destroyed". So what sort of events, on the one hand, result in a mere change, and what sort of events, on the other hand, result in a thing's destruction — in the state of its existence? This is one aspect of the problem that will be considered here. It is called "the problem of change and identity".
The Ship of Theseus.
The "problem of change and identity" is generally explained with the story of the Ship of Theseus (q.v.):
There is one answer which is a little too easy and quick. One might say: "No, of course not. The Theseus has changed a lot, so it's not the same ship. At the end of your life, you're not going to be the same person as you were, when you were a teenager. You're going to change a lot in the meantime." However, this is not quite answering the intended question. What is intended by the question is the sense of the word, "same", in which an old woman is the "same" person at the end of her life as she is, at the beginning of her life. Certainly, the word, "same", has such a sense. After all, one implicitly depends on it when one says, for example, "She has changed a lot". In order for someone to change a lot, there has to be "one person" who underwent the change. (One could perhaps reject that sense, saying that objects "do not" change over time.)
Going back to the definition of "change", an object changes with respect to a property if the object has that property at one time, and at a later time, the object does not have the property. What changes is the fact that "the object has a particular property". The only way that that fact "can" change is if the object remains in existence. One can therefore think of a continuing object as the "ground" of change, or the arena where change occurs, as it were. To get back to the Theseus, the question is: Has the Theseus merely changed "a lot", or is the Theseus gone, being replaced by a new ship?
One may say, "Sure, it's just a refurbished Theseus, greatly changed to be sure, but still the Theseus". If one thinks in this manner, then consider what happens when the story is extended further. Suppose someone buys all the planks, masts and whatever that is stored in the warehouse, and out of all of those materials, and absolutely no others, he builds a ship according to the same plans that were used to build the ship, christened "the Theseus". And this ship, called "S3", is launched and sits in the harbor right next to where "S2" is. Is "S3" the same as "S1"? In other words, is this recently constructed ship, the same ship as the ship originally called the "Theseus", considering that "S3" was built out of the "same materials", and according to the "same plans" as "S1".
Other questions: Should we stop calling S1 the Ship of Theseus and instead call S3 the Ship of Theseus? S1 has a historic path through the oceans, a path which could be traced regardless of the repairs which were made to it over time. The path identifies the ship; no other ship has this path. Or does S3 also have this path?
One could take this concept even further by not only the properties but also its subject matter of the "ship". What if instead the warehoused planks, masts, and other materials were used to build something completely different from a ship, like a house. (A concept explored by the artist Simon Starling, who turned a shed into a working boat and then back into a shed, winning him the 2005 Turner Prize.) The same materials and supplies are being used; yet they have taken on a new form. This relates to the concept of recreation vs. destruction.
Inevitably, the problem arises: How can one ever say that both "S2" "and" "S3" are the same ship as "S1", the original Theseus? This is because if they were both the same as "S1", then they would have to be the same as each other. This follows from transitivity, which states that if "x" = "y" and "x" = "z", then "y" = "z". With "S2" and "S3" being clearly different ships, sitting in different places in the harbor, several choices present themselves: 
How does one then decide which is the correct answer in this case? Whenever one makes an identity claim (i.e. a claim which states that two things are the same), one almost always uses "two different descriptions". Sometimes, one may say, ""x" = "x"", like "I am I", but such claims are not particularly interesting or informative. The interesting identity claims are claims where two different descriptions are used for one and the same thing. As an example, take these two descriptions: "the Morning Star", and "the Evening Star". Sometimes, one can look in the sky just before dawn, and see a very bright point of light — that has been called "the Morning Star". And then also, one can look in the sky just after sunset, and see a very similar point — that has been called "the Evening Star". The Morning Star is, in fact, identical to the Evening Star — both are the planet Venus. As such, they are "two" things, only in description, but in actuality, are one and the same thing under two different descriptions.
It is a similar case with "S1", "S2", and "S3", those being three different abbreviations, standing for the following descriptions:
When one, therefore, asks a question like, "Is "S2" the same as "S1"?", one can be understood to mean this: "Is the ship which sits in the harbor now, with the new planks, "the same ship" as the ship which sat in the harbor fifty years ago, newly christened 'the Theseus'?" Do those two descriptions refer to the same thing, or do they not?
Philosophers are perhaps not interested in the "Ship of Theseus" problem "per se", but in a more general problem: How does one decide that "X" is the same as "Y", where "X" describes something at one time, and "Y" describes that "same" thing at a later time? This is called the "problem of identity over time", or alternatively, the "problem of change".
Leibniz's solution.
The German philosopher Gottfried Leibniz came up with what is now called Leibniz's law (see identity of indiscernibles) that may have some bearing on the question. Leibniz's law states:
Applying Leibniz's Law to the Ship of Theseus problem, "S2" is the same as "S1" if, and only if, "S2" and "S1" have all the same properties and relations. "Does" the ship now in the harbor have all the same properties and relations as the ship that was in the harbor fifty years ago? One might be tempted to say, "Clearly not! They have "lots" of different properties. So they can't be the same ship." Does that sound convincing? To answer this question, let us consider the property, "contains mast #1". Mast #1 is one of the masts that the original Ship of Theseus had. "S1" definitely had this property, but "S2" is not so equipped, but has mast #2, instead. It follows that "S2" must therefore be different from "S1".
Many philosophers strongly oppose this view. For if this argument works, then "any" property that has changed from the last time we looked at a thing would mean that the thing does not exist anymore, and there is a new thing in its place. Every little change in every little property would mean the whole thing is destroyed. Suppose we look at "S1" just a couple of years after it was built. If just one plank has been replaced, will we say that the ship is a different ship? Many philosophers would say surely not, as would common sense. But the ship that is floating on the ocean for a couple of years "does" have different properties from the original. Leibniz's Law would have us say that it is a different ship. One might see all this and conclude, "Well, Leibniz's Law must not be a law at all, but a false claim! "X" and "Y" do not need to have all the same properties to be the same thing."
Leibniz's Law "can" be saved, by saying: Properties are to be described as occurring at particular times, i.e. they are "indexed to times". A property that is described as at a particular time is said to be "temporally-indexed". For example, we can say that "S1" has mast #1 "in 600 BC". If we say what time the ship has the mast, then we have indexed the property of having the mast to that time. We say the ship "has" the mast then, using the word, "has", tenselessly. That means we do not say that it, "at present", has the mast, but rather, we say it "has" the mast in 600 BC. We are not claiming that the ship has the mast at any "other" time; just at "that" time. But if it were a later time, say 550 BC, "that very same ship" could "have" mast #1 "in 600 BC", considering that we are talking about a tenseless "have". That is, it always has the same properties, but the properties are of the form "P"-at-"T". This gives us a way to save Leibniz's Law from the objection we gave, but at the same time, brings up the issue of whether "change" really occurs. After all, we defined "change" as something having one property at one time, and not at some later time. By this solution though, any given object always has all the properties throughout time, and the properties are merely temporally-specific.
Putting this in plain English, "S1" "now" has the property that it "will" have mast #2; and S2 "now" has the property that it "did" have mast #1. We can then say that "S1" and "S2" have all the same "temporally-indexed properties". According to Leibniz's Law, therefore, they would be the same ship.
One might also say, through the same sorts of contortions that "S1" and "S3" "might" have the same temporally-indexed properties. It then follows from Leibniz's Law that "they instead" would be the same ship.
Can Leibniz's Law help us decide whether it is "S2" or "S3" that is the same as the original Theseus? Perhaps not by itself. Leibniz's Law says that some ships are the same, if, and only if they have all the same properties and relations — or, rather, the same "temporally-indexed" properties and relations. How then is one to decide that they have all the same temporally-indexed properties and relations? Leibniz's Law seems to offer little or no help when it comes to that decision.
Pragmatic solution.
One especially meaningful "solution" to the problem of the Ship of Theseus is to say that whether the ship is the same or not depends on what purpose the word "same" here is being used for. There are multiple, perhaps infinite, purposes which could underlie the question. Here are just a few examples.
If, supposing it turns out that the original Ship of Theseus, "S1", was actually stolen property, and the rightful owner demands its return, should the police give him "S2" or "S3"? Instead of figuring out which ship, if either, is the "same", and then declaring that it should be returned, the pragmatic solution is to figure out which ship should be returned, and then declare that it is the "same". The current owner of "S2" could argue that the original owner did not pay for any of the labor or materials of "S2", but did provide at least the materials for "S3". Thus, the original owner should not be entitled to "S2", but rather, some or all of "S3". For the purpose of legal entitlement, therefore, part or all of "S3" is the same as "S1".
Now, let us say that the purpose is not legal entitlement, but rather, the following situation: The admiral of the fleet believes that captains and crews who have fought alongside each other are more effective than captains and crews who are strangers to each other. The admiral then declares that captains must serve at least one year on the same ship. One day, Captain Hercules takes command of the Theseus, and then transfers 18 months later. During this time, the ship's materials are completely replaced as in the previous example, but the crew stays the same. Is "S2" = "S1", "S3" = "S1", both, or neither? For the admiral's purpose, "S2" = "S1" because "S2" has the same crew as "S1", and Captain Hercules has thus fulfilled the admiral's objective.
Still another example supposes that you are writing a history of this great ship, when it was conceived, how it was constructed, even what repairs were made to it, what battles it saw, who served in it, and so on. For this purpose the fact that pieces of the ship have been replaced over time, even if all pieces have been replaced, is irrelevant. The history of the Ship of Theseus is the history of the Ship of Theseus.
Thus, whether "S2", "S3", both, or neither is the same ship as "S1" is a matter of convention and what purposes we have for considering things to be the same or different. Two objects may be considered the same for one purpose, and yet different for another. See pragmatism.
The ship of Theseus problem: a non-receivable question.
One way of thinking about the Ship of Theseus problem is as follows: It is a question that is not receivable because of the mismatch between the domain of the question and the domain of the subject matter to which it is applied. Let us review the three main knowledge domains of concern here:
The distinction between "B" and "C" is demonstrated in the following example: In the evening, one can go out and see at the same moment the sun setting, the moon and a few stars; this is our reality or "B". In the scientific domain "C", however, the analysis of "B" reveals that the stars are thousands of light years away, the sun is eight light minutes away, and the moon is about a light second away. Since one cannot logically consider these subjects to be both "at the same moment" and "away in time", an exclusive choice has to be made that defines these two separate domains, "B" and "C". Our reality or domain "B" is created by the complex, but consistent transformation of "A" by our biological and mental makeup. Therefore, domain "B", or our reality, is internally logical. The scientific knowledge, or domain "C", is created by the application of a consistent methodology of analysis of our reality, "B". Therefore, the scientific domain is internally logical. Domains "B" and "C" each have their own internal logic, derived from a consistent approach respecting both processes and subject matter. Using the questions or processes of one domain on the subject matter of another domain will logically produce puzzles, paradoxes, and inconsistencies. The Ship of Theseus problem is an example of such an inconsistency created by the use of the question of identity proper to the ontology of domain "A", applied to the subject matter of domain "B", our reality. The question about the identity of the Ship of Theseus is simply not receivable and comes from the poor practice of not respecting the proper correspondence of the question domain to the subject matter domain. The problem of identity is an ontological problem, and should therefore be applied to the (metaphysical) subject matter of domain "A", the real universe.
Persistence over time.
Common-sense tells us that objects persist across time, that there is some sense in which you are the same person you were yesterday, in which the oak is the same as the acorn, in which you perhaps even can step into the same river twice. Philosophers have developed two rival theories for how this happens, called "endurantism" and "perdurantism". Broadly speaking, endurantists hold that a whole object exists at each moment of its history, and the same object exists at each moment, while perdurantists believe that objects are 4-dimensional entities made up of a series of temporal parts like the frames of a movie.
Identity and change in conscious beings.
The problem of personal identity relates to change as applied to people. The molecules that make up each individual change almost completely over a period of years. Usually, there is no trouble in saying that a little girl in 1920, for example, is the same as an old woman in 1998, even though they share a relatively small number of molecules in common. The same person is just described in two different ways, first as a little girl, and second, as an old woman. In fact, we are confident enough of our ability to reidentify people over time that we are given names that are supposed to last us from when we get them until we die many years later. The question is exactly why we call the old woman in 1998 "the same person" as that little girl in 1920.
However, according to quantum physics, individual molecules (and atoms, electrons, protons etc.) have no identity. For example, every electron is the same and in quantum mechanics, one can not keep track of an individual electron precisely. Therefore any electron can interchange with another one with no observable physical change of the system at all. Thus, any real object cannot remain the same, also because of movement of its physical parts (even much bigger than molecules). Similarly to Leibniz solution, in a real life, we cannot say the person (or any macroscopic object) is the same, because all signs refer to the person (or object) in the past, which evolved in time.

</doc>
<doc id="14787" url="http://en.wikipedia.org/wiki?curid=14787" title="Iran–Contra affair">
Iran–Contra affair

The Iran–Contra affair (Persian: ایران-کنترا‎, Spanish: "caso Irán-Contra"), also referred to as Irangate, Contragate or the Iran–Contra scandal, was a political scandal in the United States that occurred during the second term of the Reagan Administration. Senior administration officials secretly facilitated the sale of arms to Iran, which was the subject of an arms embargo. They hoped that the arms sales would secure the release of several US hostages and use the money to fund the Contras in Nicaragua. Under the Boland Amendment, further funding of the Contras by the government had been prohibited by Congress.
The scandal began as an operation to free the seven American hostages being held in Lebanon by a group with Iranian ties connected to the Army of the Guardians of the Islamic Revolution. It was planned that Israel would ship weapons to Iran, and then the United States would resupply Israel and receive the Israeli payment. The Iranian recipients promised to do everything in their power to achieve the release of the U.S. hostages. The plan deteriorated into an arms-for-hostages scheme, in which members of the executive branch sold weapons to Iran in exchange for the release of the American hostages. Large modifications to the plan were devised by Lieutenant Colonel Oliver North of the National Security Council in late 1985, in which a portion of the proceeds from the weapon sales was diverted to fund anti-Sandinista and anti-communist rebels, or Contras, in Nicaragua.
While President Ronald Reagan was a supporter of the Contra cause, the evidence is disputed as to whether he authorized the diversion of the money raised by the Iranian arms sales to the Contras. Handwritten notes taken by Defense Secretary Caspar Weinberger on December 7, 1985, indicate that Reagan was aware of potential hostage transfers with Iran, as well as the sale of Hawk and TOW missiles to "moderate elements" within that country. Weinberger wrote that Reagan said "he could answer to charges of illegality but couldn't answer to the charge that 'big strong President Reagan passed up a chance to free the hostages'". After the weapon sales were revealed in November 1986, Reagan appeared on national television and stated that the weapons transfers had indeed occurred, but that the United States did not trade arms for hostages. The investigation was impeded when large volumes of documents relating to the scandal were destroyed or withheld from investigators by Reagan administration officials. On March 4, 1987, Reagan returned to the airwaves in a nationally televised address, taking full responsibility for any actions that he was unaware of, and admitting that "what began as a strategic opening to Iran deteriorated, in its implementation, into trading arms for hostages".
Several investigations ensued, including those by the U.S. Congress and the three-person, Reagan-appointed Tower Commission. Neither found any evidence that President Reagan himself knew of the extent of the multiple programs. Ultimately the sale of weapons to Iran was not deemed a criminal offense but charges were brought against five individuals for their support of the Contras. Those charges, however, were later dropped because the administration refused to declassify certain documents. The indicted conspirators faced various lesser charges instead. In the end, fourteen administration officials were indicted, including then-Secretary of Defense Caspar Weinberger. Eleven convictions resulted, some of which were vacated on appeal. The rest of those indicted or convicted were all pardoned in the final days of the presidency of George H. W. Bush, who had been vice-president at the time of the affair.
Background.
Contra militants based in Honduras waged a guerrilla war to topple the Sandinista National Liberation Front (FSLN) revolutionary government of Nicaragua. Direct U.S. funding of the Contras insurgency was made illegal through the Boland Amendment, the name given to three U.S. legislative amendments between 1982 and 1984 aimed at limiting U.S. government assistance to the Contra's militants. Funding ran out for the Contras by July 1984 and in October a total ban was placed in effect. In violation of the Boland Amendment, senior officials of the Reagan administration continued to secretly arm and train the Contras and provide arms to Iran, an operation they called "the Enterprise".
Ironically, military aid to the Contras was reinstated with Congressional consent in October 1986, a month before the scandal broke.
Arms sales to Iran.
Michael Ledeen, a consultant of National Security Adviser Robert McFarlane, requested assistance from Israeli Prime Minister Shimon Peres for help in the sale of arms to Iran. Having been designated a State Sponsor of Terrorism since January 1984, Iran was in the midst of the Iran–Iraq War and could find few Western nations willing to supply it with weapons. The idea behind the plan was for Israel to ship weapons through an intermediary (identified as Manucher Ghorbanifar) to the Islamic republic as a way of aiding a supposedly moderate, politically influential faction within the regime of Ayatollah Khomeini who was believed to be seeking a rapprochement with the United States; after the transaction, the United States would reimburse Israel with the same weapons, while receiving monetary benefits. The Israeli government required that the sale of arms meet high level approval from the United States government, and when McFarlane convinced them that the U.S. government approved the sale, Israel obliged by agreeing to sell the arms.
In 1985 President Reagan entered Bethesda Naval Hospital for colon cancer surgery. While the President was recovering in the hospital, McFarlane met with him and told him that representatives from Israel had contacted the National Security Agency to pass on confidential information from what Reagan later described as the "moderate" Iranian faction opposed to the Ayatollah's hardline anti-American policies. According to Reagan, these Iranians sought to establish a quiet relationship with the United States, before establishing formal relationships upon the death of the aging Ayatollah. In Reagan's account, McFarlane told Reagan that the Iranians, to demonstrate their seriousness, offered to persuade the Hezbollah militants to release the seven U.S. hostages. McFarlane met with the Israeli intermediaries; Reagan claims that he allowed this because he believed that establishing relations with a strategically located country, and preventing the Soviet Union from doing the same, was a beneficial move. Although Reagan claims that the arms sales were to a "moderate" faction of Iranians, the Walsh Iran/Contra Report states that the arms sales were "to Iran" itself, which was under the control of the Ayatollah.
Following the Israeli–U.S. meeting, Israel requested permission from the United States to sell a small number of TOW antitank missiles (tube-launched, optically tracked, and wire-guided) to Iran, claiming that this would aid the "moderate" Iranian faction, by demonstrating that the group actually had high-level connections to the U.S. government. Reagan initially rejected the plan, until Israel sent information to the United States showing that the "moderate" Iranians were opposed to terrorism and had fought against it. Now having a reason to trust the "moderates", Reagan approved the transaction, which was meant to be between Israel and the "moderates" in Iran, with the United States reimbursing Israel. In his 1990 autobiography "An American Life", Reagan claimed that he was deeply committed to securing the release of the hostages; it was this compassion that supposedly motivated his support for the arms initiatives. The president requested that the "moderate" Iranians do everything in their capability to free the hostages held by Hezbollah.
The following arms were supplied to Iran:
First arms sale.
On August 20, 1985, Israel sent 100 American-made BGM-71 TOW antitank missiles to Iran through an arms dealer named Manucher Ghorbanifar. Subsequently, on September 14, 1985, 408 more TOW missiles were delivered. On September 15, 1985, following the second delivery, Reverend Benjamin Weir was released by his captors, the Islamic Jihad Organization.
Modifications in plans.
Robert McFarlane resigned on December 4, 1985, citing that he wanted to spend more time with his family. He was replaced by Admiral John Poindexter.
Two days later, Reagan met with his advisors at the White House, where a new plan was introduced. This one called for a slight change in the arms transactions: instead of the weapons going to the "moderate" Iranian group, they would go to "moderate" Iranian army leaders. As the weapons were delivered from Israel by air, the hostages held by Hezbollah would be released. Israel would continue to be reimbursed by the United States for the weapons. Though staunchly opposed by Secretary of State George Shultz and Secretary of Defense Caspar Weinberger, the plan was authorized by Reagan, who stated that, "We were "not" trading arms for hostages, nor were we negotiating with terrorists". Now retired National Security Advisor McFarlane flew to London to meet with Israelis and Ghorbanifar in an attempt to persuade the Iranian to use his influence to release the hostages before any arms transactions occurred; this plan was rejected by Ghorbanifar.
On the day of McFarlane's resignation, Oliver North, a military aide to the United States National Security Council (NSC), proposed a new plan for selling arms to Iran, which included two major adjustments: instead of selling arms through Israel, the sale was to be direct, and a portion of the proceeds would go to Contras, or Nicaraguan paramilitary fighters waging guerrilla warfare against the democratically-elected Sandinista government, at a markup. North proposed a $15 million markup, while contracted arms broker Ghorbanifar added a 41% markup of his own. Other members of the NSC were in favor of North's plan; with large support, Poindexter authorized it without notifying President Reagan, and it went into effect. At first, the Iranians refused to buy the arms at the inflated price because of the excessive markup imposed by North and Ghorbanifar. They eventually relented, and in February 1986, 1,000 TOW missiles were shipped to the country. From May to November 1986, there were additional shipments of miscellaneous weapons and parts.
Both the sale of weapons to Iran, and the funding of the Contras, attempted to circumvent not only stated administration policy, but also the Boland Amendment. Administration officials argued that regardless of the Congress restricting the funds for the Contras, or any affair, the President (or in this case the administration) could carry on by seeking alternative means of funding such as private entities and foreign governments. Funding from one foreign country, Brunei, was botched when North's secretary, Fawn Hall, transposed the numbers of North's Swiss bank account number. A Swiss businessman, suddenly $10 million richer, alerted the authorities of the mistake. The money was eventually returned to the Sultan of Brunei, with interest.
On January 7, 1986, John Poindexter proposed to the president a modification of the approved plan: instead of negotiating with the "moderate" Iranian political group, the United States would negotiate with "moderate" members of the Iranian government. Poindexter told Reagan that Ghorbanifar had important connections within the Iranian government, so with the hope of the release of the hostages, Reagan approved this plan as well. Throughout February 1986, weapons were shipped directly to Iran by the United States (as part of Oliver North's plan, without the knowledge of President Reagan) and none of the hostages were released. Retired National Security Advisor McFarlane conducted another international voyage, this one to Tehran; bringing with him a gift of a bible having a handwritten inscription by Ronald Reagan; and, according to George Cave a cake baked in the shape of a key. He met directly with the "moderate" Iranian political group that sought to establish U.S.-Iranian relations in an attempt to free the four remaining hostages. This meeting also failed. The members requested concessions such as Israel's withdrawal from the Golan Heights, which the United States rejected.
Subsequent dealings.
In late July 1986, Hezbollah released another hostage, Father Lawrence Jenco, former head of Catholic Relief Services in Lebanon. Following this, William Casey, head of the CIA, requested that the United States authorize sending a shipment of small missile parts to Iranian military forces as a way of expressing gratitude. Casey also justified this request by stating that the contact in the Iranian government might otherwise lose face, or be executed, and hostages killed. Reagan authorized the shipment to ensure that those potential events would not occur.
In September and October 1986 three more Americans—Frank Reed, Joseph Cicippio, and Edward Tracy—were abducted in Lebanon by a separate terrorist group. The reasons for their abduction are unknown, although it is speculated that they were kidnapped to replace the freed Americans. One more original hostage, David Jacobsen, was later released. The captors promised to release the remaining two, but the release never happened.
Discovery and scandal.
After a leak by Mehdi Hashemi, a senior official in the Army of the Guardians of the Islamic Revolution, the Lebanese magazine "Ash-Shiraa" exposed the arrangement on November 3, 1986. This was the first public reporting of the weapons-for-hostages deal. The operation was discovered only after an airlift of guns (Corporate Air Services HPF821) was downed over Nicaragua. Eugene Hasenfus, who was captured by Nicaraguan authorities after surviving the plane crash, initially alleged in a press conference on Nicaraguan soil that two of his coworkers, Max Gomez and Ramon Medina, worked for the Central Intelligence Agency. He later said he did not know whether they did or not. The Iranian government confirmed the "Ash-Shiraa" story, and ten days after the story was first published, President Reagan appeared on national television from the Oval Office on November 13, stating:
"My purpose was... to send a signal that the United States was prepared to replace the animosity between [the U.S. and Iran] with a new relationship... At the same time we undertook this initiative, we made clear that Iran must oppose all forms of international terrorism as a condition of progress in our relationship. The most significant step which Iran could take, we indicated, would be to use its influence in Lebanon to secure the release of all hostages held there."
The scandal was compounded when Oliver North destroyed or hid pertinent documents between November 21 and November 25, 1986. During North's trial in 1989, his secretary, Fawn Hall, testified extensively about helping North alter, shred, and remove official United States National Security Council (NSC) documents from the White House. According to the "New York Times", enough documents were put into a government shredder to jam it. North's explanation for destroying some documents was to protect the lives of individuals involved in Iran and Contra operations. It was not until 1993, years after the trial, that North's notebooks were made public, and only after the National Security Archive and Public Citizen sued the Office of the Independent Counsel under the Freedom of Information Act.
During the trial North testified that on November 21, 22, or 24, he witnessed Poindexter destroy what may have been the only signed copy of a presidential covert-action finding that sought to authorize CIA participation in the November 1985 Hawk missile shipment to Iran. U.S. Attorney General Edwin Meese admitted on November 25 that profits from weapons sales to Iran were made available to assist the Contra rebels in Nicaragua. On the same day, John Poindexter resigned, and Oliver North was fired by President Reagan. Poindexter was replaced by Frank Carlucci on December 2, 1986.
In his expose "Veil: The Secret Wars of the CIA 1981–1987", journalist Bob Woodward chronicles the role of the CIA in facilitating the transfer of funds from the Iran arms sales to the Nicaraguan Contras spearheaded by Oliver North. Then Director of the CIA, William J. Casey, admitted to Woodward in February 1987 that he was aware of the diversion of funds to the contras confirming a number of encounters documented by Woodward. The controversial admission occurred while Casey was hospitalized for a stroke, and, according to his wife, was unable to communicate. On May 6, 1987, William Casey died the day after Congress began its public hearings on Iran–Contra.
Tower Commission.
On November 25, 1986, President Reagan announced the creation of a Special Review Board to look into the matter; the following day, he appointed former Senator John Tower, former Secretary of State Edmund Muskie, and former National Security Adviser Brent Scowcroft to serve as members. This Presidential Commission took effect on December 1 and became known as the Tower Commission. The main objectives of the commission were to inquire into "the circumstances surrounding the Iran-Contra matter, other case studies that might reveal strengths and weaknesses in the operation of the National Security Council system under stress, and the manner in which that system has served eight different presidents since its inception in 1947". The Tower Commission was the first presidential commission to review and evaluate the National Security Council.
President Reagan appeared before the Tower Commission on December 2, 1986, to answer questions regarding his involvement in the affair. When asked about his role in authorizing the arms deals, he first stated that he had; later, he appeared to contradict himself by stating that he had no recollection of doing so. In his 1990 autobiography, "An American Life", Reagan acknowledges authorizing the shipments to Israel.
The report published by the Tower Commission was delivered to the president on February 26, 1987. The Commission had interviewed 80 witnesses to the scheme, including Reagan, and two of the arms trade middlemen: Manucher Ghorbanifar and Adnan Khashoggi. The 200-page report was the most comprehensive of any released, criticizing the actions of Oliver North, John Poindexter, Caspar Weinberger, and others. It determined that President Reagan did not have knowledge of the extent of the program, especially about the diversion of funds to the Contras, although it argued that the president ought to have had better control of the National Security Council staff. The report heavily criticized Reagan for not properly supervising his subordinates or being aware of their actions. A major result of the Tower Commission was the consensus that Reagan should have listened to his National Security Advisor more, thereby placing more power in the hands of that chair.
Congressional committees investigating the Iran–Contra affair.
The Democratic-controlled United States Congress issued its own report on November 18, 1987, stating that "If the president did not know what his national security advisers were doing, he should have". The congressional report wrote that the president bore "ultimate responsibility" for wrongdoing by his aides, and his administration exhibited "secrecy, deception and disdain for the law". It also read that "the central remaining question is the role of the President in the Iran–Contra affair. On this critical point, the shredding of documents by Poindexter, North and others, and the death of Casey, leave the record incomplete".
Aftermath.
Reagan expressed regret regarding the situation during a nationally televised address from the Oval Office on March 4, 1987, and two other speeches; Reagan had not spoken to the American people directly for three months amidst the scandal. President Reagan told the American people the reason why he did not update them on the scandal:
"The reason I haven't spoken to you before now is this: You deserve the truth. And as frustrating as the waiting has been, I felt it was improper to come to you with sketchy reports, or possibly even erroneous statements, which would then have to be corrected, creating even more doubt and confusion. There's been enough of that."
He then took full responsibility for the acts committed:
"First, let me say I take full responsibility for my own actions and for those of my administration. As angry as I may be about activities undertaken without my knowledge, I am still accountable for those activities. As disappointed as I may be in some who served me, I'm still the one who must answer to the American people for this behavior."
Finally, the president stated that his previous assertions that the U.S. did not trade arms for hostages were incorrect:
"A few months ago I told the American people I did not trade arms for hostages. My heart and my best intentions still tell me that's true, but the facts and the evidence tell me it is not. As the Tower board reported, what began as a strategic opening to Iran deteriorated, in its implementation, into trading arms for hostages. This runs counter to my own beliefs, to administration policy, and to the original strategy we had in mind."
To this day Reagan's role in the transactions is not definitively known; it is unclear exactly what Reagan knew and when, and whether the arms sales were motivated by his desire to save the U.S. hostages. Oliver North wrote that "Ronald Reagan knew of and approved a great deal of what went on with both the Iranian initiative and private efforts on behalf of the contras and he received regular, detailed briefings on both...I have no doubt that he was told about the use of residuals for the Contras, and that he approved it. Enthusiastically." Handwritten notes by Defense Secretary Weinberger indicate that the President was aware of potential hostages transfers with Iran, as well as the sale of Hawk and TOW missiles to what he was told were "moderate elements" within Iran. Notes taken on December 7, 1985, by Weinberger record that Reagan said that "he could answer charges of illegality but he couldn't answer charge ["sic"] that 'big strong President Reagan passed up a chance to free hostages'". The Republican-written "Report of the Congressional Committees Investigating the Iran-Contra Affair" concluded, that There is some question and dispute about precisely the level at which he chose to follow the operation details. There is no doubt, however, ... [that] the President set the US policy towards Nicaragua, with few if any ambiguities, and then left subordinates more or less free to implement it.
Domestically, the scandal precipitated a drop in President Reagan's popularity as his approval ratings saw "the largest single drop for any U.S. president in history", from 67% to 46% in November 1986, according to a "New York Times"/CBS News poll. The "Teflon President", as Reagan was nicknamed by critics, survived the scandal, however, and by January 1989 a Gallup poll was "recording a 64% approval rating", the highest ever recorded for a departing President at that time.
Internationally the damage was more severe. Magnus Ranstorp wrote, "U.S. willingness to engage in concessions with Iran and the Hezbollah not only signaled to its adversaries that hostage-taking was an extremely useful instrument in extracting political and financial concessions for the West but also undermined any credibility of U.S. criticism of other states' deviation from the principles of no-negotiation and no concession to terrorists and their demands".
In Iran Mehdi Hashemi, the leaker of the scandal, was executed in 1987, allegedly for activities unrelated to the scandal. Though Hashemi made a full video confession to numerous serious charges, some observers find the coincidence of his leak and the subsequent prosecution highly suspicious.
Indictments.
Oliver North and John Poindexter were indicted on multiple charges on March 16, 1988. North, indicted on 16 counts, was found guilty by a jury of three felony counts. The convictions were vacated on appeal on the grounds that North's Fifth Amendment rights may have been violated by the indirect use of his testimony to Congress which had been given under a grant of immunity. In 1990 Poindexter was convicted on several felony counts of conspiracy, lying to Congress, obstruction of justice, and altering and destroying documents pertinent to the investigation. His convictions were also overturned on appeal on similar grounds. Arthur L. Liman served as chief counsel for the Senate during the Iran–Contra Scandal.
The Independent Counsel, Lawrence E. Walsh, chose not to re-try North or Poindexter. In total, several dozen people were investigated by Walsh's office.
During his election campaign in 1988, Vice President Bush denied any knowledge of the Iran–Contra affair by saying he was "out of the loop". Though his diaries included that he was "one of the few people that know fully the details", he repeatedly refused to discuss the incident and won the election. However, a book published in 2008 by Israeli journalist and terrorism expert Ronen Bergman asserts that Bush was personally and secretly briefed on the affair by Amiram Nir, counter-terrorism adviser to the then Israeli Prime Minister, when Bush was on a visit to Israel. "Nir could have incriminated the incoming President. The fact that Nir was killed in a mysterious chartered airplane crash in Mexico in December 1988 has given rise to numerous conspiracy theories", writes Bergman. On December 24, 1992, nearing the end of his term in office after being defeated by Bill Clinton the previous month, Bush pardoned six administration officials, namely Elliott Abrams, Duane Clarridge, Alan Fiers, Clair George, Robert McFarlane, and Caspar Weinberger.
In Poindexter's hometown of Odon, Indiana, a street was renamed to John Poindexter Street. Bill Breeden, a former minister, stole the street's sign in protest of the Iran–Contra affair. He claimed that he was holding it for a ransom of $30 million, in reference to the amount of money given to Iran to transfer to the Contras. He was later arrested and confined to prison, making him, as satirically noted by Howard Zinn, "the only person to be imprisoned as a result of the Iran–Contra Scandal".
Reports and documents.
The 100th Congress formed a joint committee (Congressional Committees Investigating The Iran-Contra Affair) and held hearings in mid-1987. Transcripts were published as: "Iran-Contra Investigation: Joint Hearings Before the Senate Select Committee on Secret Military Assistance to Iran and the Nicaraguan Opposition and the House Select Committee to Invesitgate Covert Arms Transactions with Iran" (U.S. GPO 1987-88). A closed Executive Session heard classified testimony from North and Poindexter; this transcript was published in a redacted format. The joint committee's final report was "Report of the Congressional Committees Investigating the Iran-Contra Affair With Supplemental, Minority, and Additional Views" (U.S. GPO November 17, 1987). The records of the committee are at the National Archives, but many are still non-public.
Testimony was also heard before the House Foreign Affairs Committee, House Permanent Select Committee on Intelligence, and Senate Select Committee on Intelligence and can be found in the Congressional Record for those bodies. The Senate Intelligence Committee produced two reports: "Preliminary Inquiry into the Sale of Arms to Iran and Possible Diversion of Funds to the Nicaraguan Resistance" (February 2, 1987) and "Were Relevant Documents Withheld from the Congressional Committees Investigating the Iran-Contra Affair?" (June 1989).
The Tower Commission Report was published as the "Report of the President's Special Review Board". U.S. GPO February 26, 1987. It was also published as "The Tower Commission Report", Bantam Books, 1987, ISBN 0-553-26968-2 
The Office of Independent Counsel/Walsh investigation produced four interim reports to Congress. Its final report was published as the "Final Report of the Independent Counsel for Iran/Contra Matters". Walsh's records are available at the National Archives.

</doc>
<doc id="14788" url="http://en.wikipedia.org/wiki?curid=14788" title="Infocom">
Infocom

Infocom was a software company, based in Cambridge, Massachusetts, that produced numerous works of interactive fiction. They also produced one notable business application, a relational database called "Cornerstone".
Infocom was founded on June 22, 1979 by MIT staff and students led by Dave Lebling, Marc Blank, Albert Vezza, and Joel Berez and lasted as an independent company until 1986 when it was bought by Activision. Activision finally shut down the Infocom division in 1989, although they released some titles in the 1990s under the Infocom "Zork" brand. Activision abandoned the Infocom trademark in 2002.
The name was later registered by Oliver Klaeffling of Germany in 2007, which itself was abandoned the following year. The Infocom trademark is currently held by Pete Hottelet's Omni Consumer Products, who registered the name around the same time as Klaeffling in 2007.
Overview.
Infocom games are text adventures where users direct the action by entering short strings of words to give commands when prompted. Generally the program will respond by describing the results of the action, often the contents of a room if the player has moved within the virtual world. The user reads this information, decides what to do, and enters another short series of words. Examples include "go west" or "take flashlight".
Infocom games were written using a roughly LISP-like programming language called "ZIL" (Zork Implementation Language or Zork Interactive Language—it was referred to as both) that compiled into a byte code able to run on a standardized virtual machine called the Z-machine. As the games were text based and used variants of the same Z-machine interpreter, the interpreter had to be ported to new computer architectures only once per architecture, rather than once per game. Each game file included a sophisticated parser which allowed the user to type complex instructions to the game. Unlike earlier works of interactive fiction which only understood commands of the form 'verb noun', Infocom's parser could understand a wider variety of sentences. For instance one might type "open the large door, then go west", or "go to festeron".
With the Z-machine, Infocom was able to release most of their games for most popular home computers of the day simultaneously—the Apple II family, Atari 800, IBM PC compatibles, Amstrad CPC/PCW (one disc worked on both machines), Commodore 64, Commodore Plus/4, Commodore 128, Kaypro CP/M, Texas Instruments TI-99/4A, the Mac, Atari ST, the Commodore Amiga and the Radio Shack TRS-80. The company was also known for shipping creative props, or "feelies" (and even "smellies"), with its games.
History.
The beginning.
Inspired by "Colossal Cave", Marc Blank and Dave Lebling created what was to become the first Infocom game, "Zork", in 1977 at MIT's Laboratory for Computer Science. Despite the development of a revolutionary virtual memory system that allowed games to be much larger than the average personal computer's normal capacity, the enormous mainframe-developed game had to be split into three roughly equal parts. "Zork I" was released originally for the TRS-80 in 1980 and eventually sold more than a million copies across several platforms. Even though Microsoft released a cheap version of Adventure with its initial version of MS-DOS 1.0 for IBM PCs, "Zork I" was still a popular seller for the PC, thanks to the superior quality of its writing and packaging.
Lebling and Blank each authored several more games and additional game writers (or "Implementors") were hired, notably including Steve Meretzky. Other popular and inventive titles included a number of sequels and spinoff games in the "Zork" series, "The Hitchhiker's Guide to the Galaxy" by Douglas Adams, and "A Mind Forever Voyaging".
In its first few years of operation, text adventures proved to be a huge revenue stream for the company. Whereas most computer games of the era would achieve initial success and then suffer a significant drop-off in sales, Infocom titles continued to sell for years and years. Employee Tim Anderson said of their situation, "It was phenomenal — we had a basement that just printed money." By 1983 Infocom was perhaps the most dominant computer-game company; for example, all ten of its games were on the "Softsel" top 40 list of best-selling computer games for the week of 12 December 1983, with "Zork" in first place and two others in the top ten. In late 1984, management declined an offer by publisher Simon & Schuster to acquire Infocom for $28 million, far more than the board of directors's valuation of $10–12 million. In 1993 "Computer Gaming World" described this era as the "Cambridge Camelot, where the Great Underground Empire was formed".
Reception.
In a 1987 interview Infocom president Joel Berez stated, "[Infocom's] audience tends to be composed of heavy readers. We sell to the minority that does read". Three components proved key to Infocom's success: marketing strategy, rich storytelling and feelies. Whereas most game developers sold their games mainly in software stores, Infocom also distributed their games via bookstores. Infocom's products appealed more to those with expensive computers, such as the Apple Macintosh, IBM PC, and Commodore Amiga. Berez stated that "there is no noticeable correlation between graphics machines and our penetration. There is a high correlation between the price of the machine and our sales ... people who are putting more money into their machines tend to buy more of our software". Since their games were text-based, patrons of bookstores were drawn to the Infocom games as they were already interested in reading. Unlike most computer software, Infocom titles were distributed under a no-returns policy, which allowed them to make money from a single game for a longer period of time.
Next, Infocom titles featured strong storytelling and rich descriptions, eschewing the day's primitive graphic capabilities, allowing users to use their own imaginations for the lavish and exotic locations the games described. Infocom's puzzles were unique in that they were usually tightly integrated into the storyline, and rarely did gamers feel like they were being made to jump through one arbitrary hoop after another, as was the case in many of the competitors' games. The puzzles were logical but also required close attention to the clues and hints given in the story, causing most gamers to keep copious notes as they went along.
Sometimes, though, Infocom threw in puzzles just for the humor of it—if the user never ran into these, they could still finish the game just fine. But discovering these early Easter Eggs was satisfying for some fans of the games. For example, one popular Easter egg was in the "Enchanter" game, which involved collecting magic spells to use in accomplishing the quest. One of these was a summoning spell, which the player needed to use to summon certain characters at different parts of the game. At one point the game mentions the "Implementers" who were responsible for creating the land of Zork. If the player tried to summon the Implementers, the game would suddenly produce a vision of Dave Lebling and Marc Blank at their computers, surprised at this "bug" in the game and working feverishly to fix it.
Third, the inclusion of "feelies"—imaginative props and extras tied to the game's theme—provided some copy protection against pirating. Some games were unsolvable without the extra content provided with the boxed game. And because of the cleverness and uniqueness of the feelies, users rarely felt like they were an intrusion or inconvenience, as was the case with most of the other copy-protection schemes of the time.
Although Infocom started out with "Zork", and although the "Zork" world was the centerpiece of their product line throughout the "Zork" and "Enchanter" series, the company quickly branched out into a wide variety of story lines: fantasy, science-fiction, mystery, horror, historical adventure, children's stories, and others that defied categories. In an attempt to reach out to females, Infocom also produced "Plundered Hearts", which required the gamer to take the part of a heroine in a swashbuckling adventure on the high seas, and which required the heroine to use more feminine tactics to win the game, since hacking-and-slashing was not a very ladylike way to behave. And to compete with the "Leisure Suit Larry" style games that were also appearing, Infocom also came out with "Leather Goddesses of Phobos" in 1986, which featured "tame", "suggestive", and "lewd" playing modes. It was notable for including among its "feelies" a "scratch-and-sniff" card with six odors that corresponded to cues given to the player during the game.
Invisiclues.
Originally, hints for the game were provided as a "pay-per-hint" service created by Mike Dornbrook, called the Zork Users Group (ZUG). Dornbrook also started Infocom's customer newsletter, called "The New Zork Times", to discuss game hints and preview and showcase new products.
The pay-per-hint service eventually led to the development of InvisiClues: books with hints, maps, clues and solutions for puzzles in the games. The answers to the puzzles were printed in invisible ink that only became visible when rubbed with a special marker that was provided with each book. Usually, two or more answers were given for each question that a gamer might have. The first answer would provide a subtle hint, the second a less subtle hint, and so forth until the last one gave an explicit walkthrough. Gamers could thus reveal only the hints that they needed to have to play the game. To prevent the mere questions (printed in normal ink) from giving away too much information about the game, a certain number of misleading fake questions were included in every InvisiClues book. Answers to these questions would start by giving misleading or impossible to carry out answers, before the final answer revealed that the question was a fake (and usually admonishing the player that revealing random clues from the book would spoil their enjoyment of the game). The InvisiClues books were regularly ranked in near the top of best seller lists for computer books.
In the Solid Gold line of re-releases, InvisiClues were integrated into the game. By typing "HINT" twice the player would open up a screen of possible topics where they could then reveal one hint at a time for each puzzle, just like the books.
Interactive fiction.
Infocom also released a small number of "interactive fiction paperbacks" (gamebooks), which were based on the games and featured the ability to choose a different path through the story. Similar to the "Choose Your Own Adventure" series, every couple of pages the book would give the reader the chance to make a choice, such as which direction they wanted to go or how they wanted to respond to another character. The reader would then choose one of the given answers and turn to the appropriate page. These books, however, never did sell particularly well, and quickly disappeared from the bookshelves.
Cornerstone.
Despite their success with computer games, Vezza and other company founders hoped to produce successful business programs like Lotus Development, also founded by people from MIT and located in the same building as Infocom. Lotus released its first product, 1-2-3, in January 1983; within a year it had earned $53 million, compared to Infocom's $6 million. In 1982 Infocom started putting resources into a new division to produce business products. In 1985 they released a database product, "Cornerstone", aimed at capturing the then booming database market for small business. Though this application was hailed upon its release for ease of use, it sold only 10,000 copies; not enough to cover the development expenses.
The program failed for a number of reasons. Although it was packaged in a slick hard plastic carrying case and was a very good database for personal and home use, it was originally priced at USD$495 per copy and used copy-protected disks. Another serious miscalculation was that the program did not include any kind of scripting language, so it was not promoted by any of the database consultants that small businesses typically hired to create and maintain their DB applications. Reviewers were also consistently disappointed that Infocom—noted for the natural language syntax of their games—did not include a natural language query ability, which was the most expected feature for this database. And a final disappointment was that "Cornerstone" was available only for IBM PCs and not any of the other platforms that Infocom supported for their games; while "Cornerstone" had been programmed with its own virtual machine for maximum portability, that feature had become essentially irrelevant. Cornerstone used the virtual machine for its processing, resulting in lackluster performance.
Changing marketplace.
Infocom's games benefited significantly from the portability offered by running on top of a virtual machine. "InfoWorld" wrote in 1984 that "the company always sells games for computers you don't normally think of as game machines, such as the DEC Rainbow or the Texas Instruments Professional Computer. This is one of the key reasons for the continued success of old titles such as Zork." Its products were the only third-party games available for the Macintosh at launch, and Berlyn promised that all 13 of its games would be available for the Atari ST within one month of its release. The virtual machine significantly slowed "Cornerstone"‍ '​s execution speed, however. Businesses were moving "en masse" to the IBM PC platform by that time, so portability was no longer a significant differentiator. Infocom had sunk much of the money from games sales into "Cornerstone"; this, in addition to a slump in computer game sales, left the company in a very precarious financial position. By the time Infocom removed the copy-protection and reduced the price to less than $100, it was too late, and the market had moved on to other database solutions.
By 1982 the market was moving to graphic adventures. Infocom was interested in producing them, that year proposing to Penguin Software that Antonio Antiochia, author of its "Transylvania", provide artwork. Within Infocom the game designers tended to oppose graphics, while marketing and business employees supported using them for the company to remain competitive. The partnership negotiations failed, in part because of the difficulty of adding graphics to the Z-machine, and Infocom instead began a series of advertisements mocking graphical games. The marketing campaign was very successful, and Infocom's success led to other companies like Broderbund and Electronic Arts also releasing their own text games.
The 1990s, though, were a turbulent time for graphics development, as the computer industry was collapsing, with long-time computer makers such as Tandy/Radio Shack, Atari, and Commodore/Amiga disappearing, and the PC and Macintosh markets were fighting for dominance. Development of graphics technology was very aggressive during this time with VGA and the first MPC standards appearing and low-cost color Macintosh models available for the first time. The rapid progress in consumer-level graphics technology made it very expensive and risky to create cutting-edge, high-performance graphics, and many companies came and went in this period. Many people were buying new, more powerful computers expressly for games, and the days were long-gone when people would be satisfied with simple vectored line drawings, such as those that made the "Wizardry" games famous, or with the blocky graphics that were used in Sierra Entertainment's "King's Quest" games. Instead, consumers increasingly demanded photorealistic 3d rendered images, and full motion video became a buzzword. In this climate, Infocom's history of text-based adventures and story-centered gaming did not help much in making the transition to graphics.
Activision takeover.
After Cornerstone's failure, Infocom laid off half of its 100 employees, and Activision acquired the company on 13 June 1986 for $7.5 million. Berez stated that although the two companies' headquarters and product lines would remain separate, "One of the effects of the merger will be for both of us to broaden our horizons". He said that "We're looking at graphics a lot", while Activision was reportedly interested in using Infocom's parser. While relations were cordial between the two companies at first, the departure of Jim Levy from Activision left Bruce Davis in charge. Davis believed that his company had paid too much for Infocom and initiated a lawsuit against them to recoup some of the cost, along with changing the way Infocom was run. For example:
Closure and afterward.
By 1988 rumors spread of disputes between Activision and Infocom. Infocom employees reportedly believed that Activision gave poorer-quality games to Infocom, such as Tom Snyder Productions' unsuccessful "Infocomics". Activision moved Infocom development to California in 1989, and the company was now just a publishing label. Rising costs and falling profits, exacerbated by the lack of new products in 1988 and technical issues with its DOS products, caused Activision to close Infocom in 1989, after which some of the remaining Infocom designers such as Steve Meretzky moved to the company Legend Entertainment, founded by Bob Bates and Mike Verdu, to continue creating games in the Infocom tradition.
For a few years, Activision continued to market Infocom's classic games in collections (usually by genre, such as the Science Fiction collection); in 1991, they published "The Lost Treasures of Infocom", followed in 1992 by "The Lost Treasures of Infocom II". These compilations featured nearly every game produced by Infocom before 1988. ("Leather Goddesses of Phobos" was not included in either bundle, but could be ordered via a coupon included with "Lost Treasures II".) The compilations lacked the "feelies" that came with each game, but in some cases included photographs of them. In 1996, the first bundles were followed by "Classic Text Adventure Masterpieces of Infocom", a single CD-ROM which contained the works of both collections. This release, however, was missing "The Hitchhiker's Guide to the Galaxy" and "Shogun" because the licenses from Douglas Adams' and James Clavell's estates had expired.
In 2012, Activision released "Lost Treasures of Infocom" for iOS devices. In-app purchases provide access for 27 of the titles. It also lacks "Shogun" and "The Hitchhiker's Guide to the Galaxy" as well as "Beyond Zork", "Zork Zero" and "Nord and Bert".
Legacy.
With the exception of "The Hitchhiker's Guide to the Galaxy" and "Shogun", the copyrights to the Infocom games are believed to be still held by Activision. "Dungeon", the mainframe precursor to the commercial Zork trilogy, is generally assumed to be in the public domain and is available from The Interactive Fiction Archive as original FORTRAN source code, a Z-machine story file and as various native source ports. Many Infocom titles can be downloaded via the Internet, but only in violation of the copyright. There are currently at least four Infocom sampler and demos available from the IF Archive as Z-machine story files which require a Z-machine interpreter to play. Interpreters are available for most computer platforms, the most widely used being the Frotz, Zip, and Nitfol interpreters.
Five games ("Zork I", "Planetfall", "The Hitchhiker's Guide to the Galaxy", "Wishbringer" and "Leather Goddesses of Phobos") were re-released in Solid Gold format. The Solid Gold versions of those games include a built-in InvisiClues hint system.
"Zork" made a cameo appearance as an easter egg in Activision and Treyarch's "". It can be accessed during the main menu and runs much like a DOS program.

</doc>
<doc id="14789" url="http://en.wikipedia.org/wiki?curid=14789" title="Interactive fiction">
Interactive fiction

Interactive fiction, often abbreviated IF, is software simulating environments in which players use text commands to control characters and influence the environment. Works in this form can be understood as literary narratives and as video games. In common usage, the term refers to text adventures"', a type of adventure game where the entire interface can be "text-only". Graphical text adventure games, where the text is accompanied by graphics (still images, animations or video) still fall under the text adventure category if the main way to interact with the game is text. Some users of the term distinguish between "interactive fiction" that focuses on narrative and "text adventures" that focus on puzzles. Meanwhile, more expansive definitions of "interactive fiction" may include all adventure games, including wholly graphical adventures such as "Myst".
As a commercial product, interactive fiction reached its peak in popularity from 1979 to 1986, as a dominant software product marketed for home computers. Due to their text-only nature, they sidestepped the problem of writing for widely divergent graphics architectures. This meant that interactive fiction games were easily ported across all the popular platforms, including CP/M (not known for gaming or strong graphics capabilities). Today, a steady stream of new works is produced by an online interactive fiction community, using freely available development systems.
The term can also be used to refer to literary works that are not read in a linear fashion, known as gamebooks, where the reader is instead given choices at different points in the text; these decisions determine the flow and outcome of the story. The most famous example of this form of interactive fiction is the "Choose Your Own Adventure" book series, and the collaborative "addventure" format has also been described as a form of interactive fiction.
Interactive fiction is sometimes used as a synonym for visual novel, a popular style of entertainment software in Japan.
Medium.
Text adventures are one of the oldest types of computer games and form a subset of the adventure genre. The player uses text input to control the game, and the game state is relayed to the player via text output.
Input is usually provided by the player in the form of simple sentences such as "get key" or "go east", which are interpreted by a text parser. Parsers may vary in sophistication; the first text adventure parsers could only handle two-word sentences in the form of verb-noun pairs. Later parsers, such as those built on Infocom's ZIL (Zork Implementation Language), could understand complete sentences. Later parsers could handle increasing levels of complexity parsing sentences such as "open the red box with the green key then go north". This level of complexity is the standard for works of interactive fiction today.
Despite their lack of graphics, text adventures include a physical dimension where players move between rooms. Many text adventure games boasted their total number of rooms to indicate how much gameplay they offered. These games are unique in that they may create an illogical space, where going north from area A takes you to area B, but going south from area B did not take you back to area A. This can create mazes that do not behave as players expect, and thus players must maintain their own map. These illogical spaces are much more rare in today's era of 3D gaming, and the Interactive Fiction community in general decries the use of mazes entirely, claiming that mazes have become arbitrary 'puzzles for the sake of puzzles' and that they can, in the hands of inexperienced designers, become immensely frustrating for players to navigate.
Interactive fiction shares much in common with Multi-User Dungeons ('MUDs'). MUDs, which became popular in the mid-1980s, rely on a textual exchange and accept similar commands from players as do works of IF; however, since interactive fiction is single player, and MUDs, by definition, have multiple players, they differ enormously in gameplay styles. MUDs often focus gameplay on activities that involve communities of players, simulated political systems, in-game trading, and other gameplay mechanics that aren't possible in a single player environment.
Interactive fiction usually relies on reading from a screen and on typing input, although text-to-speech synthesizers allow blind and visually impaired users to play interactive fiction titles as audio games.
Writing style.
Interactive fiction features two distinct modes of writing: the player input and the game output.
As described above, player input is expected to be in simple command form (imperative sentences). A typical command may be:
pull lever
The responses from the game are usually written from a second-person point of view, in present tense. This is because, unlike in most works of fiction, the main character is closely associated with the player, and the events are seen to be happening as the player plays. While older text adventures often identified the protagonist with the player directly, newer games tend to have specific, well-defined protagonists with separate identities from the player. The classic essay "Crimes Against Mimesis" discusses, among other IF issues, the nature of "You" in interactive fiction.
A typical response might look something like this, the response to "look in tea chest" at the start of Curses:
That was the first place you tried, hours and hours ago now, and there's nothing there but that boring old book. You pick it up anyway, bored as you are. 
Many text adventures, particularly those designed for humour (such as "Zork", "The Hitchhiker's Guide to the Galaxy", and "Leather Goddesses of Phobos"), address the player with an informal tone, sometimes including sarcastic remarks (see the transcript from "Curses", above, for an example). The late Douglas Adams, in designing the IF version of his 'Hitchhiker's Guide to the Galaxy', created a unique solution to the final puzzle of the game: the game requires the one solitary item that the player "didn't" choose at the outset of play.
Some IF works dispense with second-person narrative entirely, opting for a first-person perspective ('I') or even placing the player in the position of an observer, rather than a direct participant. In some 'experimental' IF, the concept of self-identification is eliminated entirely, and the player instead takes the role of an inanimate object, a force of nature, or an abstract concept; experimental IF usually pushes the limits of the concept and challenges many assumptions about the medium.
History.
"Adventure".
Around 1975, Will Crowther, a programmer and an amateur caver, wrote the first text adventure game, "Adventure" (originally called "ADVENT" because a filename could only be six characters long in the operating system he was using, and later named "Colossal Cave"). Having just gone through a divorce, he was looking for a way to connect with his two young children. Over the course of a few weekends, he wrote a text based cave exploration game that featured a sort of guide/narrator who talked in full sentences and who understood simple two word commands that came close to natural English. Adventure was programmed in Fortran for the PDP-10. Stanford University graduate student Don Woods discovered "Adventure" while working at the Stanford Artificial Intelligence Laboratory, and in 1977 obtained and expanded Crowther's source code (with Crowther's permission). Crowther's original version was an accurate simulation of part of the real Colossal Cave, but also included fantasy elements (such as axe-wielding dwarves and a magic bridge); Woods's changes were reminiscent of the writings of J.R.R. Tolkien, and included a troll, elves, and a volcano some claim is based on Mount Doom, but Woods says was not.
In early 1977, Adventure spread across ARPAnet, and has survived on the Internet to this day. The game has since been ported to many other operating systems, and was included with the floppy-disk distribution of Microsoft's MS-DOS 5.0 OS. "Adventure" is a cornerstone of the online IF community; there currently exist dozens of different independently-programmed versions, with additional elements, such as new rooms or puzzles, and various scoring systems.
The popularity of "Adventure" led to the wide success of interactive fiction during the late 1970s and the 1980s, when home computers had little, if any, graphics capability. Many elements of the original game have survived into the present, such as the command 'xyzzy', which is now included as an Easter Egg in games such as Minesweeper.
"Adventure" was also directly responsible for the founding of Sierra Online (later Sierra Entertainment); Ken and Roberta Williams played the game and decided to design one of their own, but with graphics. By 1982 "Softline" wrote that "the demands of the market are weighted heavily toward hi-res graphics" in games like Sierra's "The Wizard and the Princess" and its imitators. Such graphic adventures became the dominant form of the genre on computers with graphics like the Apple II.
Commercial era.
Adventure International.
Adventure International was founded by Scott Adams (not to be confused with the creator of Dilbert).
In 1978, Adams wrote "Adventureland", which was loosely patterned after the original Advent. He took out a small ad in a computer magazine in order to promote and sell "Adventureland", thus creating the first commercial adventure game. In 1979 he founded Adventure International, the first commercial publisher of interactive fiction.
By 1982 Adventure International began releasing versions of its games with graphics. The company went bankrupt in 1985.
Infocom.
The largest company producing works of interactive fiction was Infocom, which created the "Zork" series and many other titles, among them "Trinity", "The Hitchhiker's Guide to the Galaxy" and "A Mind Forever Voyaging".
In June 1977, Marc Blank, Bruce K. Daniels, Tim Anderson, and Dave Lebling began writing the mainframe version of "Zork" (also known as "Dungeon"), at the MIT Laboratory for Computer Science. The game was programmed in a computer language called MDL, a variant of LISP. In early 1979, the game was completed. Ten members of the MIT Dynamics Modelling Group went on to join Infocom when it was incorporated later that year.
In order to make its games as portable as possible, Infocom developed the Z-machine, a custom virtual machine which could be implemented on a large number of platforms, and which took standardized "story files" as input.
In a non-technical sense, Infocom was responsible for developing the interactive style that would be emulated by many later interpreters. The Infocom parser was widely regarded as the best of its era. It accepted complex, complete sentence commands like "put the blue book on the writing desk" at a time when most of its competitors parsers were restricted to simple two word verb-noun combinations such as "put book". The parser was actively upgraded with new features like undo and error correction, and later games would 'understand' multiple sentence input: 'pick up the gem and put it in my bag. take the newspaper clipping out of my bag then burn it with the book of matches'.
By 1982 Infocom was the only company producing text-only adventure games on the Apple II with sophisticated parsers and writing, and by 1983 advertised its lack of graphics as a virtue. The company was bought by Activision in 1986 after the failure of "Cornerstone", Infocom's database software program, and stopped producing text adventures a few years later.
In 1991 and 1992, Activision released volumes one and two of "The Lost Treasures of Infocom", a collection containing most of Infocom's games, followed in 1996 by "Classic Text Adventure Masterpieces of Infocom".
Legend Entertainment.
Legend Entertainment was founded by Bob Bates and Mike Verdu in 1989. It started out from the ashes of Infocom.
The text adventures produced by Legend used (high-resolution) graphics as well as sound. Some of their titles include "Eric the Unready", the "Spellcasting" series and "Gateway" (based on Frederik Pohl's novels).
The last text adventure created by Legend was "Gateway II", while the last game ever created by Legend was "" (the well-known first-person shooter action game). Legend was acquired in 2004 by Atari.
Other companies.
Probably the first commercial work of interactive fiction produced outside the U.S. was the dungeon crawl game of "Acheton", produced in Cambridge, England, and first commercially released by Acornsoft (later expanded and reissued by Topologika). Other leading companies in the U.K. were Magnetic Scrolls and Level 9 Computing. Also worthy of mention are Delta 4, Melbourne House, and the homebrew company Zenobi.
In the early 1980s Edu-Ware also produced interactive fiction for the Apple II as designated by the "if" graphic that was displayed on startup. Their titles included the "Prisoner" and "Empire" series ("Empire I: World Builders", "Empire II: Interstellar Sharks", "Empire III: Armageddon").
In 1981, CE Software published SwordThrust as a commercial successor to the Eamon gaming system for the Apple II. SwordThrust and Eamon were simple two-word parser games with many role-playing elements not available in other interactive fiction.
While SwordThrust published seven different titles, it was vastly overshadowed by the non-commercial Eamon system which allowed private authors to publish their own titles in the series. By March 1984, there were 48 titles published for the Eamon system, and over 270 titles in total as of March 2013.
In Italy, interactive fiction games were mainly published and distributed through various magazines in included tapes. The largest number of games were published in the two magazines Viking and Explorer, with versions for the main 8-bit home computers (Sinclair ZX Spectrum, Commodore 64 and MSX). The software house producing those games was Brainstorm Enterprise, and the most prolific IF author was Bonaventura Di Bello, who produced 70 games in the Italian language. The wave of interactive fiction in Italy lasted for a couple of years thanks to the various magazines promoting the genre, then faded and remains still today a topic of interest for a small group of fans and less known developers, celebrated on Web sites and in related newsgroups.
In Spain, interactive fiction was considered a minority genre, and was not very much successful. The first Spanish interactive fiction commercially released was Yenght in 1983, by Dinamic Software, for the ZX Spectrum. Later on, it was in 1987, when the same company produced an interactive fiction about "Don Quijote". After several other attempts, a company emerged from Dinamic, called Aventuras AD which was the main interactive fiction publisher in Spain, including titles like a Spanish adaptation of Colossal Cave Adventure, an adaptation of the Spanish comic "El Jabato", and mainly the "Ci-U-Than" trilogy, composed by "La diosa de Cozumel" (1990), "Los templos sagrados" (1991) and "Chichen Itzá" (1992). During this period, the Club de Aventuras AD (CAAD), the main Spanish speaking community around interactive fiction in the world, was founded, and after the end of Aventuras AD in 1992, the CAAD continued on its own, first with their own magazine, and then with the advent of Internet, with the launch of an active internet community that still produces interactive non commercial fiction nowadays.
Modern era.
After the decline of the commercial interactive fiction market in the 1990s, an online community eventually formed around the medium. In 1987, the Usenet newsgroup rec.arts.int-fiction was created, and was soon followed by rec.games.int-fiction. By custom, the topic of rec.arts.int-fiction is interactive fiction authorship and programming, while rec.games.int-fiction encompasses topics related to playing interactive fiction games, such as hint requests and game reviews. As of late 2011, discussions between writers have mostly moved from rec.arts.int-fiction to the Interactive Fiction Community Forum.
One of the most important early developments was the reverse-engineering of Infocom's Z-Code format and Z-Machine virtual machine in 1987 by a group of enthusiasts called the InfoTaskForce and the subsequent development of an interpreter for Z-Code story files. As a result, it became possible to play Infocom's work on modern computers.
For years amateurs formed a small community producing interactive fiction works of relatively limited scope using the Adventure Game Toolkit and similar tools. The breakthrough that allowed the interactive fiction community to truly prosper, however, was the creation and distribution of two sophisticated development systems. In 1987, Michael J. Roberts released TADS, a programming language designed to produce works of interactive fiction. In 1993, Graham Nelson released Inform, a programming language and set of libraries which compiled to a Z-Code story file. Each of these systems allowed anyone with sufficient time and dedication to create a game, and caused a growth boom in the online interactive fiction community.
Despite the lack of commercial support, the availability of high quality tools allowed enthusiasts of the genre to develop new high quality games. Competitions such as the annual Interactive Fiction Competition for short works, the newer Spring Thing for longer works, and the XYZZY Awards, further helped to improve the quality and complexity of the games. Modern games go much further than the original "Adventure" style, improving upon Infocom games, which relied extensively on puzzle solving, and to a lesser extent on communication with non player characters, to include experimentation with writing and story-telling techniques.
While the majority of modern interactive fiction developed is distributed for free, there are some commercial endeavors, including Peter Nepstad's "", several games by Howard Sherman published as Malinche Entertainment, The General Coffee Company's "Future Boy!," "Cypher", a graphically enhanced cyberpunk game and various titles by Textfyre. Emily Short was commissioned to develop the game "City of Secrets" but the project fell through and she ended up releasing it herself.
Some authors offer optional commercial feelies (physical props associated with a game); the tradition of 'Feelies' (and the term itself) is believed to have originated with "Deadline" (1982), the third Infocom title after "Zork I" and "II". Seeing the dual potential benefits of both aiding game-play immersion and providing a measure of creative copy-protection, Infocom and later other companies began creating feelies for numerous titles. In 1987, Infocom released a special version of the first three "Zork" titles together with plot-specific coins and other trinkets. This concept would see expansion as time went on, such that later game feelies would contain passwords, coded instructions, page numbers, or other information that would be required to successfully complete the game.
Other uses.
The term "Interactive Fiction" is sometimes used to describe other forms of storytelling and games, including visual novels, interactive novels, and interactive storytelling.
Visual novel.
Visual novels are interactive fiction featuring mostly static graphics, usually with anime-style art. As the name might suggest, they resemble mixed-media novels or tableau vivant stage plays. Visual novels are especially prevalent in Japan, where they make up nearly 70% of PC games released. They are rarely produced for video game consoles, but the more popular games are sometimes ported to video game systems such as the PlayStation 2. The market for visual novels outside of East Asia, however, is limited.
Visual novels have been a staple of PC software sales in Japan and other East Asian countries for over a decade, so much so that popular titles are open ported to consoles, and some even have famous manga and anime series based upon them; such titles include "Kanon" (1999), "Air" (2000) and "Clannad" (2004) by Key; "Rumbling Hearts" (2001) by Age; "School Days" (2005) by 0verflow; "Higurashi no Naku Koro ni" (2002) by 07th Expansion; and "Fate/stay night" (2004) by Type-Moon.
Interactive novel.
The interactive novel is a form of web fiction and interactive fiction. While authors of traditional paper-and-ink novels have sometimes tried to give readers the random directionality offered by true hypertexting, this approach was not completely feasible until the development of HTML. Paper novels (indeed, some digital novels) are linear, that is, read from page to page in a straight line. Interactive novels, however, offer readers a unique way to read fiction by choosing a page, a character, or a direction. By following hyperlinked phrases within the novel, readers can find new ways to understand characters. There is no wrong way to read a hypertext interactive novel. Links embedded within the pages are meant to be taken at a reader's discretion – to allow the reader a choice in the novel's world.
As interactive fiction becomes more accessible via reading apps like Kindle Fire, digital publishing houses like "Coliloquy" have emerged.
Interactive storytelling.
Interactive storytelling is a developing kind of computer entertainment. The term was coined by Chris Crawford, a main proponent and developer. He defines interactive storytelling as, "a form of interactive entertainment in which the player plays the role of the protagonist in a dramatically rich environment."
Interactive storytelling and interactive fiction are distinct in that interactive storytelling focuses on drama and dynamic circumstances, where interactive fiction games, traditionally (but not necessarily) focus on puzzle-solving and navigating through pre-conceived circumstances. They are similar, however, in that well-written forms of both are nonlinear.
Software.
Development systems.
A number of systems for writing interactive fiction exist. Most IF development is now implemented in Inform, TADS, or ADRIFT. In the 2006 IFComp, most games were written for Inform, with a strong minority of games for TADS and ADRIFT, followed by a smattering of games for other systems.
While familiarity with a programming language leads many new authors to attempt to produce their own complete IF application, most established IF authors recommend use of a specialised IF language, arguing that such systems allow authors to avoid the technicalities of producing a full featured parser, while allowing broad community support. The choice of authoring system usually depends on the author's desired balance of ease of use versus power, and the portability of the final product.
Other development systems include:
Interpreters.
Interpreters are the software used to play the works of interactive fiction created with a development system. They may be part of the development system, or can be compiled together with the work of fiction as a standalone executable file. Interpreters distributed separately include:
Distribution.
In addition to commercial distribution venues and individual websites, many works of free interactive fiction are distributed through community websites. These include the Interactive Fiction Database (IFDB), The Interactive Fiction Reviews Organization (IFRO), a game catalog and recommendation engine, and the Interactive Fiction Archive.
Works may be distributed for playing in a web browser or in a separate interpreter. In the latter case they are often made available in the Blorb package format that many interpreters support.

</doc>
<doc id="14790" url="http://en.wikipedia.org/wiki?curid=14790" title="Ice hockey">
Ice hockey

Ice hockey is a contact team sport played on ice, usually a rink, in which two teams of skaters use their sticks to shoot a vulcanized rubber puck into their opponent's net to score points. In Canada, the United States, and some European countries such as Latvia and Sweden, it is known as "hockey"; the name "ice hockey" is used in places where "hockey" more often refers to field hockey, such as South America, Asia, Africa, Australasia, and some European countries like Germany, the Netherlands, Spain and the United Kingdom. Ice hockey teams usually consist of four lines of three forwards, three pairs of defencemen, and two goaltenders. Normally, each team has five players who skate up and down the ice trying to take the puck and score a goal against the opposing team. Teams normally have a goaltender as their sixth on-ice player, whose job is to prevent the puck from entering the goal.
A fast-paced physical sport (leading to the nickname "The Fastest Game on Earth"), hockey is most popular in areas of North America (particularly Canada and the northern United States) and Europe. In North America, the National Hockey League (NHL) is the highest level for men's hockey and the most popular. The Kontinental Hockey League (KHL) is the highest league in Russia and much of eastern Europe. Ice hockey is the official national winter sport of Canada, where the game enjoys immense popularity. The International Ice Hockey Federation (IIHF) is the formal governing body for international ice hockey. The IIHF manages international tournaments and maintains the IIHF World Ranking. Worldwide, there are ice hockey federations in 73 countries.
Ice hockey is believed to have evolved from simple stick and ball games played in the 18th and 19th century United Kingdom and elsewhere. These games were brought to Canada and the United States and several similar winter games using informal rules were developed, such as "shinney" and "ice polo". The contemporary sport of ice hockey was developed in Canada, most notably in Montreal, where the first indoor hockey game was played on March 3, 1875. Some characteristics of that game, such as the length of the ice rink and the use of a puck, have been retained to this day. Amateur ice hockey leagues began in the 1880s, and professional ice hockey originated around 1900. The Stanley Cup, emblematic of ice hockey club supremacy, was first awarded in 1893 to recognize the Canadian amateur champion and later became the championship trophy of the NHL. In the early 1900s, the Canadian rules were adopted by the Ligue International de Hockey sur Glace, the precursor of the IIHF and the sport was played for the first time in the Olympics in the Olympic Games of 1920.
In international competitions, the national teams of six countries (The "Big Six") predominate: Canada, the Czech Republic, Finland, Russia, Sweden and the United States. Of the 69 medals awarded all-time in men's competition at the Olympics, only six medals were not awarded to one of those countries. In the annual Ice Hockey World Championships, 177 of 201 medals have been awarded to the six nations. Teams outside the "Big Six" have won only 5 medals in either competition since 1953: All 12 Women's Olympic and 36 IIHF World Women's Championships medals have been awarded to one of these six countries, and every gold medal in both competitions has been won by either Canada or the United States.
History.
Stick-and-ball games date back to pre-Christian times. In Europe, these games included the Irish game of hurling, the closely related Scottish game of shinty and versions of field hockey (including "bandie ball," played in England). IJscolf, a game resembling colf on an ice-covered surface, was popular in the Low Countries between the Middle Ages and the Dutch Golden Age. It was played with a wooden curved bat (called a "colf" or "kolf"), a wooden or leather ball and two poles (or nearby landmarks), with the objective to hit the chosen point using the least number of strokes. A similar game ("knattleikr") had been played for a thousand years or more by the Norse, as documented in the Icelandic sagas. In England, evidence of games of 'hockey on ice' (the name replaced "bandie ball"), played with a "bung" (a plug of cork or oak used as a stopper on a barrel) date back to the 1700s. William Pierre Le Cocq stated, in a 1799 letter written in Chesham, England:
I must now describe to you the game of Hockey; we have each a stick turning up at the end. We get a bung. There are two sides one of them knocks one way and the other side the other way. If any one of the sides makes the bung reach that end of the churchyard it is victorious.
A 1797 engraving unearthed by Swedish sport historians Carl Gidén and Patrick Houda shows a person on skates with a stick and bung on the River Thames, probably in December 1796.
British soldiers and immigrants to Canada and the United States brought their stick-and-ball games with them and played them on the ice and snow of winter. In 1825, John Franklin wrote "The game of hockey played on the ice was the morning sport" on Great Bear Lake during one of his Arctic expeditions. A mid-1830s watercolour portrays New Brunswick lieutenant governor Archibald Campbell and his family with British soldiers on skates playing a stick-on-ice sport. Captain R.G.A. Levinge, a British Army officer in New Brunswick during Campbell’s time, wrote about "hockey on ice" on Chippewa Creek (a tributary of the Niagara River) in 1839. In 1843 another British Army officer in Kingston, Ontario wrote, "Began to skate this year, improved quickly and had great fun at hockey on the ice." An 1859 "Boston Evening Gazette" article referred to an early game of hockey on ice in Halifax that year. An 1835 painting by John O'Toole depicts skaters with sticks and bung on a frozen stream in the American state of West Virginia.
In the same era, the Mi'kmaq, a First Nations people of Nova Scotia, also had a stick-and-ball game. Canadian oral histories describe a traditional stick-and-ball game played by the Mi'kmaq in eastern Canada, and Silas Tertius Rand (in his 1894 "Legends of the Micmacs") describes a Mi'kmaq ball game known as "tooadijik". Rand also describes a game played (probably after European contact) with hurleys, known as "wolchamaadijik". Sticks made by the Mi'kmaq were used by the British for their games.
Early 19th-century paintings depict shinney (or "shinny"), an early form of hockey with no standard rules which was played in Nova Scotia. Many of these early games absorbed the physical aggression of what the Mi'kmaq in Nova Scotia called "dehuntshigwa'es" (lacrosse). Shinney was played on the St. Lawrence River at Montreal and Quebec City, and in Kingston, Ontario and Ottawa, Ontario. The number of players was often large. To this day, shinney (derived from "shinty") is a popular Canadian term for an informal type of hockey, either ice or street hockey.
Thomas Chandler Haliburton, in "The Attache: Second Series" (published in 1844), reminisced about boys from King's College School in Windsor, Nova Scotia playing "hurly on the long pond on the ice" when he was a student there in 1810 and earlier. Based on Haliburton's account, the most eligible claims state, that modern hockey was invented in Windsor, Nova Scotia, by King's College students and named after an individual (“Colonel Hockey's game”). Others claim that the origins of hockey come from games played in the area of Dartmouth and Halifax in Nova Scotia.
Name.
The name "hockey" has no clear origin. Its first known mention is from the 1773 book "Juvenile Sports and Pastimes, to Which Are Prefixed, Memoirs of the Author: Including a New Mode of Infant Education", by Richard Johnson (Pseud. Master Michel Angelo), whose chapter XI was titled "New Improvements on the Game of Hockey". The belief that hockey was mentioned in a 1363 proclamation by King Edward III of England is based on modern translations of the proclamation, which was originally in Latin and explicitly forbade the games "Pilam Manualem, Pedivam, & Bacularem: & ad Canibucam & Gallorum Pugnam". The English historian and biographer John Strype did not use the word "hockey" when he translated the proclamation in 1720.
According to the Austin Hockey Association, the word "puck" derives from the Scots Gaelic "puc" or the Irish "poc" (to poke, punch or deliver a blow). "...The blow given by a hurler to the ball with his caman or hurley is always called a puck."
Development of ice hockey.
While the game's origins lie elsewhere, Montreal is at the centre of the development of the sport of contemporary ice hockey. On March 3, 1875, the first organized indoor game was played at Montreal's Victoria Skating Rink between two nine-player teams, including James Creighton and several McGill University students. Instead of a ball or bung, the game featured a "flat circular piece of wood" (to keep it in the rink and to protect spectators). The goal posts were 8 ft apart (today's goals are six feet wide).
In 1876, the first game played in Montreal was reportedly “conducted under the ‘Hockey Association’ rules”; the Hockey Association was England’s field hockey organization. In 1877, "The Gazette" (Montreal) published a list of seven rules, six of which were largely based on six of the Hockey Association’s twelve rules, with only minor differences (even the word “ball” was kept); the one added rule explained how disputes should be settled. The McGill University Hockey Club, the first hockey club, was founded in 1877 (followed by the Montreal Victorias, organized in 1881). In the meantime, in 1880, the number of players had gone from nine to seven.
The game became so popular that the first "world championship" of ice hockey was featured in Montreal's annual Winter Carnival in 1883; the McGill team captured the "Carnival Cup." The game was divided into thirty-minute halves. The positions were now named: left and right wing, centre, rover, point, cover point and goalkeeper. In 1885, the Montreal City Hockey League was established. In 1886 the teams competing at the Winter Carnival organized the Amateur Hockey Association of Canada (AHAC), and played a season comprising "challenges" to the existing champion.
In Europe, it is believed that in 1885 the Oxford University Ice Hockey Club was formed to play the first Ice Hockey Varsity Match against traditional rival Cambridge in St. Moritz, Switzerland; however, this is undocumented. The match was won by the Oxford Dark Blues, 6–0; the first photographs and team lists date from 1895. This rivalry continues, claiming to be the oldest hockey rivalry in history; a similar claim is made about the rivalry between Queen's University and Royal Military College of Kingston, Ontario. Since 1986, considered the 100th anniversary of the rivalry, teams of the two colleges play for the Carr-Harris Cup.
In 1888 the Governor General of Canada, Lord Stanley of Preston (whose sons and daughter were hockey enthusiasts), attended the Montreal Winter Carnival tournament and was impressed with the game. In 1892, realizing that there was no recognition for the best team in Canada (although a number of leagues had championship trophies), he purchased a decorative bowl for use as a trophy. The Dominion Hockey Challenge Cup (which later became known as the Stanley Cup) was first awarded in 1893 to the Montreal Hockey Club, champions of the AHAC; it continues to be awarded annually to the National Hockey League's championship team. Stanley's son Arthur helped organize the Ontario Hockey Association, and Stanley's daughter Isobel was one of the first women to play ice hockey.
By 1893, there were almost a hundred teams in Montreal alone; in addition, there were leagues throughout Canada. Winnipeg hockey players used cricket pads to better protect the goaltender's legs; they also introduced the "scoop" shot, or what is now known as the wrist shot. Goal nets became a standard feature of the Canadian Amateur Hockey League (CAHL) in 1900. Left and right defence began to replace the point and cover-point positions in the OHA in 1906.
Ice hockey was not the only game on ice derived from stick-and-ball games played in Europe; during this period bandie ball was adapted to the ice, evolving into bandy (which remains popular in Sweden, Russia, Finland and Norway). "Ice polo", played with a ball rather than a puck, was popular in the United States during this period; however, by 1893 Yale University and Johns Hopkins University held their first ice hockey matches. Ice polo (played in New England) would die out as Americans adopted ice hockey. In 1896, the first ice hockey league in the U.S. was formed. The U.S. Amateur Hockey League was founded in New York City, shortly after the opening of the artificial-ice St. Nicholas Rink.
Lord Stanley's five sons were instrumental in bringing ice hockey to Europe, defeating a court team (which included the future Edward VII and George V) at Buckingham Palace in 1895. By 1903, a five-team league had been founded. The "Ligue Internationale de Hockey sur Glace" was founded in 1908 to govern international competition, and the first European championship was won by Great Britain in 1910. During the mid-20th century, the "Ligue" became the International Ice Hockey Federation.
As the popularity of ice hockey as a spectator sport grew, earlier rinks were replaced by larger rinks. Most of the early indoor ice rinks have been demolished; Montreal's Victoria Rink, built in 1862, was demolished in 1925. Many older rinks succumbed to fire, such as Denman Arena, Dey's Arena, Quebec Skating Rink and Montreal Arena, a hazard of the buildings' wood construction. The Stannus Street Rink in Windsor, Nova Scotia (built in 1897) may be the oldest still in existence; however, it is no longer used for ice hockey. The Aberdeen Pavilion (built in 1898) in Ottawa was used for ice hockey in 1904 and is the oldest existing facility that has hosted Stanley Cup games.
The oldest indoor ice hockey arena still in use today for ice hockey is Boston's Matthews Arena, which was built in 1910. It has been modified extensively several times in its history and is used today by Northeastern University for ice hockey and other sports. It was the original home rink of the Boston Bruins professional team, itself the oldest United States-based team in the NHL, starting play in the league in today's Matthews Arena on December 1, 1924. Madison Square Garden in New York City, built in 1968, is the oldest continuously-operating arena in the NHL.
Professional era.
Professional hockey has existed since the early 20th century. By 1902, the Western Pennsylvania Hockey League was the first to employ professionals. The league joined with teams in Michigan and Ontario to form the first fully professional league—the International Professional Hockey League (IPHL)—in 1904. The WPHL and IPHL hired players from Canada; in response, Canadian leagues began to pay players (who played with amateurs). The IPHL, cut off from its largest source of players, disbanded in 1907. By then, several professional hockey leagues were operating in Canada (with leagues in Manitoba, Ontario and Quebec).
In 1910, the National Hockey Association (NHA) was formed in Montreal. The NHA would further refine the rules: dropping the rover position, dividing the game into three 20-minute periods and introducing minor and major penalties. After re-organizing as the National Hockey League (NHL) in 1917, the league expanded into the United States, starting with the Boston Bruins in 1924.
Professional hockey leagues developed later in Europe, since bandy was still popular, but amateur leagues leading to national championships were in place. One of the first was the Swiss National League A, founded in 1916. Today, professional leagues have been introduced in most countries of Europe. Top European leagues include the Kontinental Hockey League, the Czech Extraliga, the Finnish Liiga and the Swedish Hockey League.
Game.
While the general characteristics of the game are the same wherever it is played, the exact rules depend on the particular code of play being used. The two most important codes are those of the IIHF and the NHL. Both of the codes, and others, originated from Canadian rules of ice hockey of the early 20th Century.
Ice hockey is played on a "hockey rink". During normal play, there are six players per side on the ice at any time, one of them being the goaltender, each of whom is on ice skates. The objective of the game is to score "goals" by shooting a hard vulcanized rubber disc, the "puck", into the opponent's goal net, which is placed at the opposite end of the rink. The players use their sticks to pass or shoot the puck.
Within certain restrictions, players may redirect the puck with any part of their body. Players may not hold the puck in their hand and are prohibited from using their hands to pass the puck to their teammates, unless they are in the defensive zone. Players are also prohibited from kicking the puck into the opponent's goal, though intentional redirections off the skate are permitted. Players may not intentionally bat the puck into the net with their hands.
Hockey is an "off-side" game, meaning that forward passes are allowed, unlike in rugby. Before the 1930s hockey was an on-side game, meaning that only backward passes were allowed. Those rules favoured individual stick-handling as a key means of driving the puck forward. With the arrival of offside rules, the forward pass transformed hockey into a truly team sport, where individual performance diminished in importance relative to team play, which could now be coordinated over the entire surface of the ice as opposed to merely rearward players.
Between the five players on the ice, they are typically divided into three forwards and two defensemen. The "forward" positions consist of a "centre" and two "wingers": a "left wing" and a "right wing". Forwards often play together as units or "lines", with the same three forwards always playing together. The "defencemen" usually stay together as a pair generally divided between left and right. Left and right side wingers or defencemen are generally positioned as such, based on the side on which they carry their stick. A substitution of an entire unit at once is called a "line change". Teams typically employ alternate sets of forward lines and defensive pairings when "shorthanded" or on a "power play". Substitutions are permitted at any time during the course of the game, although during a stoppage of play the home team is permitted the final change. When players are substituted during play, it is called changing "on the fly". A new NHL rule added in the 2005–2006 season prevents a team from changing their line after they "ice" the puck.
The boards surrounding the ice help keep the puck in play and they can also be used as tools to play the puck. Players are permitted to "bodycheck" opponents into the boards as a means of stopping progress. The referees, linesmen and the outsides of the goal are "in play" and do not cause a stoppage of the game when the puck or players are influenced (by either bouncing or colliding) into them. Play can be stopped if the goal is knocked out of position. Play often proceeds for minutes without interruption. When play is stopped, it is restarted with a "faceoff". Two players "face" each other and an official drops the puck to the ice, where the two players attempt to gain control of the puck. Markings on the ice indicate the locations for the faceoff and guide the positioning of players.
The three major rules of play in ice hockey that limit the movement of the puck: "offside", "icing", and the puck going out of play. A player is "offside" if he enters his opponent's zone before the puck itself. Under many situations, a player may not "ice the puck", shoot the puck all the way across both the centre line and the opponent's goal line. The puck goes "out of play" whenever it goes past the perimeter of the ice rink (onto the player benches, over the "glass," or onto the protective netting above the glass) and a stoppage of play is called by the officials using whistles. It also does not matter if the puck comes back onto the ice surface from those areas as the puck is considered dead once it leaves the perimeter of the rink.
Under IIHF rules, each team may carry a maximum of 20 players and two goaltenders on their roster. NHL rules restrict the total number of players per game to 18, plus two goaltenders. In the NHL, the players are usually divided into four lines of three forwards, and into three pairs of defenceman. On occasion, teams may elect to substitute an extra defenceman for a forward; this seventh defenceman might sometimes play on the fourth line as a forward.
Periods and overtime.
A professional game consists of three "periods" of twenty minutes, the clock running only when the puck is in play. The teams change ends for the second period, again for the third period, and again at the start of each overtime played (playoffs only; same ends as the odd periods otherwise). Recreational leagues and children's leagues often play shorter games, generally with three shorter periods of play.
Various procedures are used if a game is tied. In tournament play, as well as in the NHL playoffs, North Americans favour "sudden death overtime", in which the teams continue to play twenty-minute periods until a goal is scored. Up until the 1999–2000 season regular season NHL games were settled with a single five-minute sudden death period with five players (plus a goalie) per side, with both teams awarded one point in the standings in the event of a tie. With a goal, the winning team would be awarded two points and the losing team none (just as if they had lost in regulation).
From 1999–2000 until 2003–04, the National Hockey League decided ties by playing a single five-minute sudden death overtime period with each team having four players (plus a goalie) per side to "open-up" the game. In the event of a tie, each team would still receive one point in the standings but in the event of a victory the winning team would be awarded two points in the standings and the losing team one point. The idea was to discourage teams from playing for a tie, since previously some teams might have preferred a tie and 1 point to risking a loss and zero points. The only exception to this rule is if a team opts to pull their goalie in exchange for an extra skater during overtime and is subsequently scored upon (an 'empty net' goal), in which case the losing team receives no points for the overtime loss.
International play and several North American professional leagues, including the NHL (in the regular season), now use an overtime period identical to that from 99–00 – 03–04 followed by a penalty shootout. If the score remains tied after an extra overtime period, the subsequent shootout consists of three players from each team taking penalty shots. After these six total shots, the team with the most goals is awarded the victory. If the score is still tied, the shootout then proceeds to a "sudden death" format. Regardless of the number of goals scored during the shootout by either team, the final score recorded will award the winning team one more goal than the score at the end of regulation time. In the NHL if a game is decided in overtime or by a shootout the winning team is awarded two points in the standings and the losing team is awarded one point. Ties no longer occur in the NHL.
The overtime mode for the NHL playoffs differ from the regular season. In the playoffs there are no shootouts nor ties. If a game is tied after regulation an additional 20 minutes of 5 on 5 sudden death overtime will be added. In case of a tied game after the overtime, multiple 20-minute overtimes will be played until a team scores, which wins them the match.
Penalties.
In ice hockey, infractions of the rules lead to play stoppages whereby the play is restarted at a face off. Some infractions result in the imposition of a "penalty" to a player or team. In the simplest case, the offending player is sent to the "penalty box" and their team has to play with one fewer player on the ice for a designated period of time. "Minor" penalties last for two minutes, "major" penalties last for five minutes, and a "double minor" penalty is two "consecutive" penalties of two minutes duration. A single minor penalty may be extended by a further two minutes for causing visible injury to the victimized player. This is usually when blood is drawn during high sticking. Players may be also assessed personal extended penalties or game expulsions for misconduct in addition to the penalty or penalties their team must serve. The team that has been given a penalty is said to be playing "short-handed" while the opposing team is on a "power play."
A two-minute minor penalty is often charged for lesser infractions such as "tripping", "elbowing", "roughing", "high-sticking", "delay of the game", "too many players on the ice", "boarding", illegal equipment, "charging" (leaping into an opponent or body-checking him after taking more than two strides), "holding", holding the stick (grabbing an opponent's stick), "interference", "hooking", "slashing", "kneeing", "unsportsmanlike conduct" (arguing a penalty call with referee, extremely vulgar or inappropriate verbal comments), "butt-ending" (striking an opponent with the knob of the stick—a very rare penalty), "spearing", or "cross-checking". As of the 2005–2006 season, a minor penalty is also assessed for "diving", where a player embellishes or simulates an offence. More egregious fouls may be penalized by a four-minute double-minor penalty, particularly those that injure the victimized player. These penalties end either when the time runs out or when the other team scores during the power play. In the case of a goal scored during the first two minutes of a double-minor, the penalty clock is set down to two minutes upon a score, effectively expiring the first minor penalty. Five-minute major penalties are called for especially violent instances of most minor infractions that result in intentional injury to an opponent, or when a "minor" penalty results in visible injury (such as bleeding), as well as for fighting. Major penalties are always served in full; they do not terminate on a goal scored by the other team. Major penalties assessed for fighting are typically offsetting, meaning neither team is short-handed and the players exit the penalty box upon a stoppage of play following the expiration of their respective penalties. The foul of "boarding" (defined as "check[ing] an opponent in such a manner that causes the opponent to be thrown violently in the boards") is penalized either by a minor or major penalty at the discretion of the referee, based on the violent state of the hit. A minor or major penalty for boarding is often assessed when a player checks an opponent from behind and into the boards.
Some varieties of penalties do not always require the offending team to play a man short. Concurrent five-minute major penalties in the NHL usually result from fighting. In the case of two players being assessed five-minute fighting majors, both the players serve five minutes without their team incurring a loss of player (both teams still have a full complement of players on the ice). This differs with two players from opposing sides getting minor penalties, at the same time or at any intersecting moment, resulting from more common infractions. In this case, both teams will have only four skating players (not counting the goaltender) until one or both penalties expire (if one penalty expires before the other, the opposing team gets a power play for the remainder of the time); this applies regardless of current pending penalties. However, in the NHL, a team always has at least three skaters on the ice. Thus, ten-minute "misconduct" penalties are served in full by the penalized player, but his team may immediately substitute another player on the ice "unless" a minor or major penalty is assessed in conjunction with the misconduct (a "two-and-ten" or "five-and-ten"). In this case, the team designates another player to serve the minor or major; both players go to the penalty box, but only the designee may not be replaced, and he is released upon the expiration of the two or five minutes, at which point the ten-minute misconduct begins. In addition, "game misconducts" are assessed for deliberate intent to inflict severe injury on an opponent (at the officials' discretion), or for a major penalty for a stick infraction or repeated major penalties. The offending player is ejected from the game and must immediately leave the playing surface (he does not sit in the penalty box); meanwhile, if an additional minor or major penalty is assessed, a designated player must serve out of that segment of the penalty in the box (similar to the above-mentioned "two-and-ten"). In some rare cases, a player may receive up to nineteen minutes in penalties for one string of plays. This could involve receiving a four-minute double minor penalty, getting in a fight with an opposing player who retaliates, and then receiving a game misconduct after the fight. In this case, the player is ejected and two teammates must serve the double-minor and major penalties.
A "penalty shot" is awarded to a player when the illegal actions of another player stop a clear scoring opportunity, most commonly when the player is on a "breakaway". A penalty shot allows the obstructed player to pick up the puck on the centre red-line and attempt to score on the goalie with no other players on the ice, to compensate for the earlier missed scoring opportunity. A penalty shot is also awarded for a defender other than the goaltender covering the puck in the goal crease, a goaltender intentionally displacing his own goal posts during a breakaway to avoid a goal, a defender intentionally displacing his own goal posts when there is less than two minutes to play in regulation time or at any point during overtime, or a player or coach intentionally throwing a stick or other object at the puck or the puck carrier and the throwing action disrupts a shot or pass play.
Officials also stop play for puck movement violations, such as using one's hands to pass the puck in the offensive end, but no players are penalized for these offences. The sole exceptions are deliberately falling on or gathering the puck to the body, carrying the puck in the hand, and shooting the puck out of play in one's defensive zone (all penalized two minutes for delay of game).
In the NHL, a unique penalty applies to the goalies. The goalies now are forbidden to play the puck in the "corners" of the rink near their own net. This will result in a two-minute penalty against the goalie's team. The area immediately behind the net (marked by two red lines on either side of the net) is the only area behind the net where the goalie can play the puck.
An additional rule that has never been a penalty, but was an infraction in the NHL before recent rules changes, is the "two-line offside pass." Prior to the 2005–06 NHL season, play was stopped when a pass from inside a team's defending zone crossed the centre line, with a face-off held in the defending zone of the offending team. Now, the centre line is no longer used in the NHL to determine a two-line pass infraction, a change that the IIHF had adopted in 1998. Players are now able to pass to teammates who are more than the blue and centre ice red line away.
The NHL has taken steps to speed up the game of hockey and create a game of finesse, by retreating from the past where illegal hits, fights, and "clutching and grabbing" among players were commonplace. Rules are now more strictly enforced, resulting in more penalties, which in turn provides more protection to the players and facilitates more goals being scored. The governing body for United States amateur hockey has implemented many new rules to reduce the number of stick-on-body occurrences, as well as other detrimental and illegal facets of the game ("zero tolerance").
In men's hockey, but not in women's, a player may use his hip or shoulder to hit another player if the player has the puck or is the last to have touched it. This use of the hip and shoulder is called "body checking." Not all physical contact is legal — in particular, hits from behind, hits to the head and most types of forceful stick-on-body contact are illegal.
A "delayed penalty call" occurs when a penalty offense is committed by the team that does not have possession of the puck. In this circumstance the team with possession of the puck is allowed to complete the play; that is, play continues until a goal is scored, a player on the opposing team gains control of the puck, or the team in possession commits an infraction or penalty of their own. Because the team on which the penalty was called cannot control the puck without stopping play, it is impossible for them to score a goal. In these cases the team in possession of the puck can pull the goalie for an extra attacker without fear of being scored on. However, it is possible for the controlling team to mishandle the puck into their own net. If a delayed penalty is signaled and the team in possession scores, the penalty is still assessed to the offending player, but not served. In 2012, this rule was changed by the NCAA for college level hockey in the United States. In college games, the penalty is still enforced even if the team in possession scores.
Officials.
A typical game of hockey is governed by two to four "officials" on the ice, charged with enforcing the rules of the game. There are typically two "linesmen" who are mainly responsible for calling "offside" and "icing" violations, breaking up fights, and conducting faceoffs, and one or two "referees", who call goals and all other penalties. Linesmen can, however, report to the referee(s) that a penalty should be assessed against an offending player in some situations. The restrictions on this practice vary depending on the governing rules. On-ice officials are assisted by off-ice officials who act as goal judges, time keepers, and official scorers.
The most widespread system in use today is the "three-man system," that uses one referee and two linesmen. Another less commonly used system is the two referee and one linesman system. This system is very close to the regular three-man system except for a few procedure changes. With the first being the National Hockey League, a number of leagues have started to implement the "four-official system," where an additional referee is added to aid in the calling of penalties normally difficult to assess by one single referee. The system is now used in every NHL game, at IIHF World Championships, the Olympics and in many professional and high-level amateur leagues in North America and Europe.
Officials are selected by the league they work for. Amateur hockey leagues use guidelines established by national organizing bodies as a basis for choosing their officiating staffs. In North America, the national organizing bodies Hockey Canada and USA Hockey approve officials according to their experience level as well as their ability to pass rules knowledge and skating ability tests. Hockey Canada has officiating levels I through VI. USA Hockey has officiating levels 1 through 4.
Equipment.
Since ice hockey is a full contact sport in men’s hockey, body checks are allowed so injuries are a common occurrence. Protective equipment is mandatory and is enforced in all competitive situations. This includes a helmet (cage worn if certain age), shoulder pads, elbow pads, mouth guard, protective gloves, heavily padded shorts (also known as hockey pants) or a girdle, athletic cup (also known as a jock, for males; and jill, for females), shin pads, skates, and (optionally) a neck protector. In addition, goaltenders use different gear, a neck guard, chest/arm protector, blocker, catch glove, and leg pads.
Ice hockey skates are optimized for physical acceleration, speed and maneuverability. This includes rapid starts, stops, turns, and changes in skating direction. In addition, they must be rigid and tough to protect the skater's feet from contact with other skaters, sticks, pucks, the boards, and the ice itself. Rigidity also improves the overall maneuverability of the skate. Blade length, thickness (width), and curvature (rocker/radius (front to back) and radius of hollow (across the blade width) are quite different from speed or figure skates. Hockey players usually adjust these parameters based on their skill level, position, and body type.
The ice hockey stick consists of a long, relatively wide, and slightly curved flat blade, attached to a shaft. The curve itself has a big impact on its performance. A deep curve allows for lifting the puck easier while a shallow curve allows for easier backhands. The flex of the stick also impacts the performance. Typically a less flexible stick is meant for a stronger player since the player is looking for the right balanced flex that allows the stick to flex easily while still having a strong "whip-back" which sends the puck flying at high speeds. It is quite distinct from sticks in other sports games and most suited to hitting and controlling the flat puck. Its unique shape contributed to the early development of the game.
Injury.
Ice hockey is a full contact sport and carries a high risk of injury. Players are moving at speeds around approximately 20 - 30 mph and quite a bit of the game revolves around the physical contact between the players. Skate blades, hockey sticks, shoulders, hips, and hockey pucks all contribute. The type of injuries associated with hockey includes: lacerations, concussions, contusions, ligament tears, broken bones, hyperextensions, and muscle strains. Women’s ice hockey can have contact but is not allowed to body check. There are many injuries in women’s ice hockey too. Some common injuries are concussions, broken bones, hyperextensions, and muscle strains.
Head injuries.
According to the Hughston Health Alert, "Lacerations to the head, scalp, and face are the most frequent types of injury [in hockey]." (Schmidt 6) Even a shallow cut to the head results in a loss of a large amount of blood. Not only are lacerations common, “it is estimated that direct trauma accounts for 80% of all [hockey] injuries. Most of these injuries are caused by player contact, falls and contact with a puck, high stick and occasionally, a skate blade.” (Schmidt 3) One of the causes of head injury is checking from behind. Due to the danger of delivering a check from behind, many leagues, including the NHL have made this a major and game misconduct penalty (called "boarding"). Another type of check that accounts for many of the player-to-player contact concussions is a check to the head resulting in a misconduct penalty (called “head contact”). A check to the head can be defined as delivering a hit while the receiving player’s head is down and their waist is bent and the aggressor is targeting the opponent player's head. The most dangerous result of a head injury in hockey can be classified as a concussion. Most concussions occur during player-to-player contact rather than when a player is checked into the boards. Checks to the head have accounted for nearly 50% of concussions that players in the National Hockey League have suffered. Concussions that players suffer may go unreported because there is no obvious physical signs if a player is not knocked unconscious. This can prove to be dangerous if a player decides to return to play without receiving proper medical attention. Studies show that, ice hockey causes 44.3% of all traumatic brain injuries among Canadian kids. In severe cases, the traumatic brain injuries are capable of resulting in death. Occurrences of death from these injuries are rare, but occur all too much in a variety of sports.
Tactics.
Checking.
An important defensive tactic is checking—attempting to take the puck from an opponent or to remove the opponent from play. "Stick checking", "sweep checking", and "poke checking" are legal uses of the stick to obtain possession of the puck. The "neutral zone trap" is designed to isolate the puck carrier in the neutral zone preventing him from entering the offensive zone. "Body checking" is using one's shoulder or hip to strike an opponent who has the puck or who is the last to have touched it (the last person to have touched the puck is still legally "in possession" of it, although a penalty is generally called if he is checked more than two seconds after his last touch). Often the term checking is used to refer to body checking, with its true definition generally only propagated among fans of the game.
Offensive tactics.
Offensive tactics include improving a team's position on the ice by advancing the puck out of one's zone towards the opponent's zone, progressively by gaining lines, first your own blue line, then the red line and finally the opponent's blue line. NHL rules instated for the 2006 season redefined the offside rule to make the two-line pass legal; a player may pass the puck from behind his own blue line, past both that blue line and the centre red line, to a player on the near side of the opponents' blue line. Offensive tactics are designed ultimately to score a goal by taking a shot. When a player purposely directs the puck towards the opponent's goal, he or she is said to "shoot" the puck.
A "deflection" is a shot that redirects a shot or a pass towards the goal from another player, by allowing the puck to strike the stick and carom towards the goal. A "one-timer" is a shot struck directly off a pass, without receiving the pass and shooting in two separate actions. "Headmanning the puck", also known as "breaking out", is the tactic of rapidly passing to the player farthest down the ice. "Loafing", also known as "cherry-picking", is when a player, usually a forward, skates behind an attacking team, instead of playing defense, in an attempt to create an easy scoring chance.
A team that is losing by one or two goals in the last few minutes of play will often elect to "pull the goalie"; that is, remove the goaltender and replace him or her with an "extra attacker" on the ice in the hope of gaining enough advantage to score a goal. However, it is an act of desperation, as it sometimes leads to the opposing team extending their lead by scoring a goal in the empty net.
One of the most important strategies for a team is their "forecheck". Forechecking is the act of attacking the opposition in their defensive zone. Forechecking is an important part of the "dump and chase" strategy (i.e. shooting the puck into the offensive zone and then chasing after it). Each team will use their own unique system but the main ones are: 2–1–2, 1–2–2, and 1–4. The 2–1–2 is the most basic forecheck system where two forwards will go in deep and pressure the opposition's defencemen, the third forward stays high and the two defencemen stay at the blueline. The 1–2–2 is a bit more conservative system where one forward pressures the puck carrier and the other two forwards cover the oppositions' wingers, with the two defencemen staying at the blueline. The 1–4 is the most defensive forecheck system, referred to as the neutral zone trap, where one forward will apply pressure to the puck carrier around the oppositions' blueline and the other 4 players stand basically in a line by their blueline in hopes the opposition will skate into one of them. Another strategy is the left wing lock, which has two forwards pressure the puck and the left wing and the two defencemen stay at the blueline.
There are many other little tactics used in the game of hockey. "Cycling" moves the puck along the boards in the offensive zone to create a scoring chance by making defenders tired or moving them out of position. "Pinching" is when a defencemen pressures the opposition's winger in the offensive zone when they are breaking out, attempting to stop their attack and keep the puck in the offensive zone. A "saucer pass" is a pass used when an opposition's stick or body is in the passing lane. It is the act of raising the puck over the obstruction and having it land on a teammate's stick.
A deke, short for "decoy," is a feint with the body or stick to fool a defender or the goalie. Many modern players, such as Pavel Datsyuk, Sidney Crosby and Patrick Kane, have picked up the skill of "dangling," which is fancier deking and requires more stick handling skills.
Fights.
Although fighting is officially prohibited in the rules, it is both a target of criticism and a considerable draw for the sport. At the professional level in North America fights are unofficially condoned. Enforcers and other players fight to demoralize the opposing players while exciting their own, as well as settling personal scores. A fight will also break out if one of the team's skilled players gets hit hard or someone gets hit by what the team perceives as a dirty hit. The amateur game penalizes fisticuffs more harshly, as a player who receives a fighting major is also assessed at least a 10-minute misconduct penalty (NCAA and some Junior leagues) or a game misconduct penalty and suspension (high school and younger, as well as some casual adult leagues). Crowds seem to like fighting in ice hockey and cheer when fighting erupts.
Women's ice hockey.
Ice hockey is one of the fastest growing women's sports in the world, with the number of participants increasing 350 percent in the last 10 years. In 2011, Canada had 85,827 women players, United States had 65,609, Finland 4,760, Sweden 3,075 and Switzerland 1,172. While there are not as many organized leagues for women as there are for men, there exist leagues of all levels, including the Canadian Women's Hockey League, Western Women's Hockey League, Mid-Atlantic Women's Hockey League, and various European leagues; as well as university teams, national and Olympic teams, and recreational teams. The IIHF holds a IIHF World Women's Championship tournament annually except in Olympic years.
The chief difference between women's and men's hockey is that body checking is not allowed in women's hockey. After the 1990 Women's World Championship, body checking was eliminated in women's hockey. In current IIHF women's competition, body checking is either a minor or major penalty, decided at the referee's discretion. In addition, players in women's competition are required to wear protective full-face masks.
In Canada, to some extent ringette serves as the female counterpart to ice hockey, in the sense that in many families, the boys play hockey while the girls play ringette.
History.
Women are known to have played the game in the 19th century. Several games were recorded in the 1890s in Ottawa, Canada. The women of Lord Stanley's family were known to participate in the game of ice hockey on the outdoor ice rink at Rideau Hall, the residence of Canada's Governor-General.
The game developed at first without an organizing body. A tournament in 1902 between Montreal and Trois-Rivieres was billed as the first championship tournament. Several tournaments, such as at the Banff Winter Carnival, were held in the early 20th Century and numerous women's teams such as the Seattle Vamps and Vancouver Amazons existed. Organizations started to develop in the 1920s, such as the Ladies Ontario Hockey Association, and later, the Dominion Women's Amateur Hockey Association. Starting in the 1960s, the game spread to universities. Today, the game is played from youth through adult leagues, and in the universities of North America and internationally. One league, the Canadian Women's Hockey League with teams in Canada and the United States, is semi-professional and is developing toward becoming a fully professional league.
The first women's world championship tournament, albeit unofficial, was held in 1987 in Toronto, Canada. This was followed by the first IIHF World Championship in 1990 in Ottawa. Women's ice hockey was added as a medal sport at the 1998 Winter Olympics in Nagano, Japan. The United States won the gold, Canada won the silver and Finland won the bronze medal.
The United States Hockey League (USHL) welcomed the first female professional hockey player in 1969–70, when the Marquette Iron Rangers signed Karen Koch. One woman, Manon Rhéaume, has played in the NHL, as a goaltender for the Tampa Bay Lightning in pre-season games against the St. Louis Blues and the Boston Bruins. In 2003, Hayley Wickenheiser played with the Kirkkonummi Salamat in the Finnish men's Suomi-sarja league. Several women have competed in North American minor leagues, including Rhéaume, goaltenders Kelly Dyer and Erin Whitten and defenceman Angela Ruggiero.
Leagues and championships.
National teams.
Ice hockey has been played at the Winter Olympics since 1924 (and was played at the summer games in 1920). Canada won six of the first seven gold medals to 1952, the exception occurring in 1936 when Great Britain won. The USSR won all but two gold medals from 1956 to 1988 as well as a final time as the Unified Team at the 1992 Albertville Olympics. The United States won their first gold medal in 1960. On the way to winning the gold medal at the 1980 Lake Placid Olympics amateur US college players defeated the heavily favoured Soviet squad – an event known as the "Miracle on Ice" in the United States. Restrictions on professional players were fully dropped at the 1998 games in Nagano. The Games saw the full participation of players from the NHL, which suspended operations during the Games and has done so in subsequent Games. The 2010 games in Vancouver were the first played in an NHL city since the inclusion of NHL players. The 2010 games were the first played on NHL-sized ice rinks, which are narrower than the IIHF standard.
National teams representing the member federations of the IIHF compete annually in the IIHF Ice Hockey World Championships. Teams are selected from the available players by the individual federations, without restriction on amateur or professional status. Since it is held in the spring, the tournament coincides with the annual NHL Stanley Cup playoffs and many of the top players are hence not available to participate in the tournament. Many of the NHL players who do play in the IIHF tournament come from teams eliminated before the playoffs or in the first round, and federations often hold open spots until the tournament to allow for players to join the tournament after their club team is eliminated. For many years, the tournament was an amateur-only tournament, but this restriction was removed, beginning in the 1970s. Players are not paid to play in the tournament, but insurance and expenses are covered from the tournament revenues.
The 1972 Summit Series and 1974 Summit Series, two series pitting the best Canadian and Soviet players without IIHF restrictions were major successes, and established a rivalry between Canada and the USSR. In the spirit of best-versus-best without restrictions on amateur or professional status, the series were followed by five Canada Cup tournaments, played in North America. Two NHL versus USSR series were also held: the 1979 Challenge Cup and Rendez-vous '87. The Canada Cup tournament later became the World Cup of Hockey, played in 1996 and 2004. The United States won in 1996 and Canada won in 2004.
Since the initial women's world championships in 1990, there have been fifteen tournaments. Women's hockey has been played at the Olympics since 1998. The 2006 Winter Olympic final between Canada and Sweden marked the only time the women's world championship or Olympic final did not involve both Canada and the United States.
Other ice hockey tournaments featuring national teams include the World U20 Championship, the World U18 Championships, the World U-17 Hockey Challenge, the World Junior A Challenge, the Ivan Hlinka Memorial Tournament, the World Women's U18 Championships and the 4 Nations Cup. The annual Euro Hockey Tour, an unofficial European championships between the national men's teams of the Czech Republic, Finland, Russia and Sweden have been played since 1996–97.
International leagues.
The National Hockey League and specifically the Stanley Cup trophy, is the oldest still operating international competition, featuring clubs from the United States and Canada. The league has 30 teams, seven in Canada and twenty-three in the United States.
The Kontinental Hockey League (KHL) is an ice hockey league in Eurasia. The league is the successor to the Russian Super League and the Soviet League, the history of which dates back to the 1940s. The KHL was launched in 2008 with clubs from the post-Soviet states. The league expanded beyond the former Soviet countries, beginning in the 2011–12 season, with clubs in Croatia, the Czech Republic and Slovakia. The number of teams has since increased to 28 from eight different countries.
The Asia League Ice Hockey, an international ice hockey league featuring clubs from China, Japan and South Korea, is the successor to the Japan Ice Hockey League.
The Austrian Hockey League, called the Erste Bank Eishockey Liga (English: Erste Bank Hockey League) for sponsorship reasons, is the highest-level ice hockey league in Austria. The roots of the EBEL league go back to 1923 and changed to its current form in 1965. Starting in the 2005/06 season, non-Austrian teams were invited to compete for the "EBEL Champion" title. The league has subsequently added clubs from Slovenia, Hungary and the Czech Republic, reaching twelve teams in 2012.
Beginning in the 2014-15 season, the Champions Hockey League was launched, a league consisting of first-tier teams from several European countries, running parallelly with the teams domestic leagues.
There are also several annual tournaments for clubs, held outside of league play. Pre-season tournaments include the European Trophy, Tampere Cup and the Pajulahti Cup. One of the oldest international ice hockey competition for clubs is the Spengler Cup, held every year in Davos, Switzerland, between Christmas and New Year's Day. It was first awarded in 1923 to the Oxford University Ice Hockey Club. The Memorial Cup, a competition for junior-level (age 20 and under) clubs is held annually from a pool of junior championship teams in Canada and the United States.
International club competitions organized by the IIHF include the Continental Cup, the Victoria Cup and the European Women's Champions Cup. The World Junior Club Cup is an annual tournament of junior ice hockey clubs representing each of the top junior leagues.
Leagues.
Several countries in Europe have their own top professional senior leagues. Many future KHL and NHL players start their professional careers in these leagues.
In North America, the American Hockey League (AHL), sometimes referred to as "The A," is the primary developmental professional league for players aspiring to enter the NHL. It comprises 30 teams from the United States and Canada. It is run as a "farm league" to the NHL, with the vast majority of AHL players under contract to an NHL team. The East Coast Hockey League (ECHL) is a mid-level minor league in the United States. Some ECHL players are under contract to NHL teams. The Southern Professional Hockey League (SPHL) is a developmental minor league in the United States. Most undrafted players get their start in this league.
The Australian Ice Hockey League and New Zealand Ice Hockey League are represented by nine and five teams respectively. As of 2012, the two top teams of the previous season from each league compete in the Trans-Tasman Champions League.
Several countries have leagues for players of junior-age, under the age of 20. The Canadian Hockey League is an umbrella organization comprising three major junior leagues: the Ontario Hockey League, the Western Hockey League, and the Quebec Major Junior Hockey League. It attracts players from Canada, the United States and Europe. There are also junior leagues in the United States and Russia, and several of the national professional leagues in Europe also have developmental leagues.
Pond hockey.
Pond hockey is a form of ice hockey played generally as pick-up hockey on lakes, ponds and artificial outdoor rinks during the winter. Pond hockey is commonly referred to in hockey circles as shinny. Its rules differ from traditional hockey because there is no hitting and very little shooting, placing a greater emphasis on skating, puckhandling and passing abilities. Since 2002, the World Pond Hockey Championship has been played on Roulston Lake in Plaster Rock, New Brunswick, Canada. Since 2006, the U.S. Pond Hockey Championships have been played in Minneapolis, Minnesota, and the Canadian National Pond Hockey Championships have been played in Huntsville, Ontario.
Ice hockey in popular culture.
Ice hockey is the official winter sport of Canada. Ice hockey, partially because of its popularity as a major professional sport, has been a source of inspiration for numerous films, television episodes and songs in North American popular culture.
Attendance records.
The record for a Stanley Cup playoff game is 28,183, set on April 23, 1996, at the Thunderdome during a Tampa Bay Lightning – Philadelphia Flyers game.
A new record was set on December 11, 2010, when the University of Michigan's men's ice hockey team faced cross-state rival Michigan State in an event billed as "The Big Chill at the Big House." The game was played at Michigan's (American) football venue, Michigan Stadium in Ann Arbor, with a capacity of 109,901 as of the 2010 football season. When UM stopped sales to the general public on May 6, 2010, with plans to reserve remaining tickets for students, over 100,000 tickets had been sold for the event. Ultimately, a crowd announced by UM as 113,411, the largest in the stadium's history (including football), saw the homestanding Wolverines win 5–0. "Guinness World Records", using a count of ticketed fans who actually entered the stadium instead of UM's figure of tickets sold, announced a final figure of 104,173.
The record was approached but not broken at the 2014 NHL Winter Classic, which also held at Michigan Stadium, with the Detroit Red Wings as the home team and the Toronto Maple Leafs as the opposing team with an announced crowd of 105,491.
Number of registered players by country.
Number of registered hockey players, including male, female and junior, provided by the respective countries' federations. Note that this list only includes the 32 of 72 IIHF member countries with more than 1,000 registered players as of December 2012.
Further reading.
</dl>

</doc>
<doc id="14791" url="http://en.wikipedia.org/wiki?curid=14791" title="IEEE 802.3">
IEEE 802.3

IEEE 802.3 is a working group and a collection of IEEE standards produced by the working group defining the physical layer and data link layer's media access control (MAC) of wired Ethernet. This is generally a local area network technology with some wide area network applications. Physical connections are made between nodes and/or infrastructure devices (hubs, switches, routers) by various types of copper or fiber cable.
802.3 is a technology that supports the IEEE 802.1network architecture.
802.3 also defines LAN access method using CSMA/CD.

</doc>
<doc id="14794" url="http://en.wikipedia.org/wiki?curid=14794" title="Integer (computer science)">
Integer (computer science)

In computer science, an integer is a datum of integral data type, a data type which represents some finite subset of the mathematical integers. Integral data types may be of different sizes and may or may not be allowed to contain negative values. Integers are commonly represented in a computer as a group of binary digits. The size of the grouping varies so the set of integer sizes available varies between different types of computers. Computer hardware, including virtual machines, nearly always provide a way to represent a processor register or memory address as an integer.
Value and representation.
The "value" of an item with an integral type is the mathematical integer that it corresponds to. Integral types may be "unsigned" (capable of representing only non-negative integers) or "signed" (capable of representing negative integers as well).
An integer value is typically specified in the source code of a program as a sequence of digits optionally prefixed with + or −. Some programming languages allow other notations, such as hexadecimal (base 16) or octal (base 8). Some programming languages also permit digit group separators.
The "internal representation" of this datum is the way the value is stored in the computer's memory. Unlike mathematical integers, a typical datum in a computer has some minimal and maximum possible value. 
The most common representation of a positive integer is a string of bits, using the binary numeral system. The order of the memory bytes storing the bits varies; see endianness. The "width" or "precision" of an integral type is the number of bits in its representation. An integral type with "n" bits can encode 2"n" numbers; for example an unsigned type typically represents the non-negative values 0 through 2"n"−1. Other encodings of integer values to bit patterns are sometimes used, for example Binary-coded decimal or Gray code, or as printed character codes such as ASCII.
There are four well-known ways to represent signed numbers in a binary computing system. The most common is two's complement, which allows a signed integral type with "n" bits to represent numbers from −2("n"−1) through 2("n"−1)−1. Two's complement arithmetic is convenient because there is a perfect one-to-one correspondence between representations and values (in particular, no separate +0 and −0), and because addition, subtraction and multiplication do not need to distinguish between signed and unsigned types. Other possibilities include offset binary, sign-magnitude, and ones' complement.
Some computer languages define integer sizes in a machine-independent way; others have varying definitions depending on the underlying processor word size. Not all language implementations define variables of all integer sizes, and defined sizes may not even be distinct in a particular implementation. An integer in one programming language may be a different size in a different language or on a different processor.
Common integral data types.
Different CPUs support different integral data types. Typically, hardware will support both signed and unsigned types but only a small, fixed set of widths.
The table above lists integral type widths that are supported in hardware by common processors. High level programming languages provide more possibilities. It is common to have a 'double width' integral type that has twice as many bits as the biggest hardware-supported type. Many languages also have "bit-field" types (a specified number of bits, usually constrained to be less than the maximum hardware-supported width) and "range" types (which can represent only the integers in a specified range).
Some languages, such as Lisp, Smalltalk, REXX and Haskell, support "arbitrary precision" integers (also known as "infinite precision integers" or "bignums"). Other languages which do not support this concept as a top-level construct may have libraries available to represent very large numbers using arrays of smaller variables, such as Java's codice_1 class or Perl's "codice_2" package. These use as much of the computer's memory as is necessary to store the numbers; however, a computer has only a finite amount of storage, so they too can only represent a finite subset of the mathematical integers. These schemes support very large numbers, for example one kilobyte of memory could be used to store numbers up to 2466 decimal digits long.
A Boolean or Flag type is a type which can represent only two values: 0 and 1, usually identified with "false" and "true" respectively. This type can be stored in memory using a single bit, but is often given a full byte for convenience of addressing and speed of access.
A four-bit quantity is known as a "nibble" (when eating, being smaller than a "bite") or "nybble" (being a pun on the form of the word "byte"). One nibble corresponds to one digit in hexadecimal and holds one digit or a sign code in binary-coded decimal.
Bytes and octets.
The term "byte" initially meant 'the smallest addressable unit of memory'. In the past, 5-, 6-, 7-, 8-, and 9-bit bytes have all been used. There have also been computers that could address individual bits ('bit-addressed machine'), or that could only address 16- or 32-bit quantities ('word-addressed machine'). The term "byte" was usually not used at all in connection with bit- and word-addressed machines.
The term "octet" always refers to an 8-bit quantity. It is mostly used in the field of computer networking, where computers with different byte widths might have to communicate. 
In modern usage "byte" almost invariably means eight bits, since all other sizes have fallen into disuse; thus "byte" has come to be synonymous with "octet".
Words.
The term 'word' is used for a small group of bits which are handled simultaneously by processors of a particular architecture. The size of a word is thus CPU-specific. Many different word sizes have been used, including 6-, 8-, 12-, 16-, 18-, 24-, 32-, 36-, 39-, 48-, 60-, and 64-bit. Since it is architectural, the size of a "word" is usually set by the first CPU in a family, rather than the characteristics of a later compatible CPU. The meanings of terms derived from "word", such as "longword", "doubleword", "quadword", and "halfword", also vary with the CPU and OS.
Practically all new desktop processors are capable of using 64-bit words, though embedded processors with 8- and 16-bit word size are still common. The 36-bit word length was common in the early days of computers.
One important cause of non-portability of software is the incorrect assumption that all computers have the same word size as the computer used by the programmer. For example, if a programmer using the C language incorrectly declares as codice_3 a variable that will be used to store values greater than 215−1, the program will fail on computers with 16-bit integers. That variable should have been declared as codice_4, which has at least 32 bits on any computer. Programmers may also incorrectly assume that a pointer can be converted to an integer without loss of information, which may work on (some) 32-bit computers, but fail on 64-bit computers with 64-bit pointers and 32-bit integers.
Short integer.
A "short integer" can represent a whole number which may take less storage, while having a smaller range, compared with a standard integer on the same machine.
In C, it is denoted by codice_5. It is required to be at least 16 bits, and is often smaller than a standard integer, but this is not required. A conforming program can assume that it can safely store values between −(215−1) and 215−1, but it may not assume that the range isn't larger. In Java, a codice_5 is "always" a 16-bit integer. In the Windows API, the datatype codice_7 is defined as a 16-bit signed integer on all machines.
Long integer.
A "long integer" can represent a whole integer whose range is greater than or equal to that of a standard integer on the same machine.
In C, it is denoted by codice_4. It is required to be at least 32 bits, and may or may not be larger than a standard integer. A conforming program can assume that it can safely store values between −(231−1) and 231−1, but it may not assume that the range isn't larger.
Common long integer sizes.
† the term codice_9 is equivalent
Long long.
In the C99 version of the C programming language and the C++11 version of C++, a codice_10 type is supported that has double the minimum capacity of the standard codice_11, 64 bits. This type is not supported by compilers that require C code to be compliant with the previous C++ standard, C++03, because the codice_12 type did not exist in C++03. For an ANSI/ISO compliant compiler the minimum requirements for the specified ranges, that is −(231) to 231−1 for signed and 0 to 232−1 for unsigned, must be fulfilled; however, extending this range is permitted. This can be an issue when exchanging code and data between platforms, or doing direct hardware access. Thus, there are several sets of headers providing platform independent exact width types. The C standard library provides "stdint.h"; this was introduced in C99 and C++11.

</doc>
<doc id="14800" url="http://en.wikipedia.org/wiki?curid=14800" title="Icon">
Icon

An icon (from Greek εἰκών "eikōn" "image") is generally a flat panel painting depicting Jesus Christ, Mary, saints and/or angels, which is venerated among Eastern Orthodox, Oriental Orthodox, and in certain Eastern Catholic Churches.
Icons may also be cast in metal, carved in stone, embroidered on cloth, painted on wood, done in mosaic or fresco work, printed on paper or metal, etc. Icons are often illuminated with a candle or jar of oil with a wick. (Beeswax for candles and olive oil for oil lamps are preferred because they burn very cleanly, although other materials are sometimes used.) The illumination of religious images with lamps or candles is an ancient practice pre-dating Christianity.
Although common in translated works from Greek or Russian, in English iconography does not mean icon painting, and "iconographer" does not mean an artist of icons, which are painted or carved, not "written", as they are in those languages.
Comparable images from Western Christianity are generally not described as "icons", although "iconic" may be used to describe a static style of devotional image.
History.
Emergence of the Icon.
Aside from the legend that Pilate had made an image of Christ, the 4th-century Eusebius of Caesarea, in his "Church History", provides a more substantial reference to a "first" icon of Jesus. He relates that King Abgar of Edessa sent a letter to Jesus at Jerusalem, asking Jesus to come and heal him of an illness. In this version there is no image. In the later account found in the Syriac "Doctrine of Addai", a painted image of Jesus is mentioned in the story; and even later, in the account given by Evagrius, the painted image is transformed into an image that miraculously appeared on a towel when Christ pressed the cloth to his wet face. Further legends relate that the cloth remained in Edessa until the 10th century, when it was taken to Constantinople. In 1204 it was lost when Constantinople was sacked by Crusaders, but its iconic type had been well fixed in numerous copies.
The earliest written records of Christian images treated like icons in a pagan or Gnostic context are offered by the 4th-century Christian Aelius Lampridius in the "Life of Alexander Severus" (xxix) that was part of the Augustan History. According to Lampridius, the emperor Alexander Severus (222–235), who was not a Christian, had kept a domestic chapel for the veneration of images of deified emperors, of portraits of his ancestors, and of Christ, Apollonius, Orpheus and Abraham. Irenaeus, (c. 130–202) in his "Against Heresies" (1:25;6) says scornfully of the Gnostic Carpocratians, "They also possess images, some of them painted, and others formed from different kinds of material; while they maintain that a likeness of Christ was made by Pilate at that time when Jesus lived among them. They crown these images, and set them up along with the images of the philosophers of the world that is to say, with the images of Pythagoras, and Plato, and Aristotle, and the rest. They have also other modes of honouring these images, after the same manner of the Gentiles [pagans]". St. Irenaeus on the other hand does not speak critically of icons or portraits in a general sense, only of certain gnostic sectarians use of icons.
Another criticism of image veneration is found in the non-canonical 2nd-century "Acts of John" (generally considered a gnostic work), in which the Apostle John discovers that one of his followers has had a portrait made of him, and is venerating it: (27) "...he [John] went into the bedchamber, and saw the portrait of an old man crowned with garlands, and lamps and altars set before it. And he called him and said: Lycomedes, what do you mean by this matter of the portrait? Can it be one of thy gods that is painted here? For I see that you are still living in heathen fashion." Later in the passage John says, "But this that you have now done is childish and imperfect: you have drawn a dead likeness of the dead."
At least some of the hierarchy of the church was still strictly opposed to icons in the early 4th century. At the Spanish Synod of Elvira (c. 305) bishops concluded, "Pictures are not to be placed in churches, so that they do not become objects of worship and adoration". Bishop Epiphanius of Salamis, wrote his letter 51 to John, Bishop of Jerusalem (c. 394) in which he recounted how he tore down an image in a church and admonished the other bishop that such images are "opposed . . . to our religion".
Elsewhere in his "Church History", Eusebius reports seeing what he took to be portraits of Jesus, Peter and Paul, and also mentions a bronze statue at Banias / Paneas, of which he wrote, "They say that this statue is an image of Jesus" ("H.E." 7:18); further, he relates that locals thought the image to be a memorial of the healing of the woman with an issue of blood by Jesus (Luke 8:43-48), because it depicted a standing man wearing a double cloak and with arm outstretched, and a woman kneeling before him with arms reaching out as if in supplication. John Francis Wilson thinks it possible to have been a pagan bronze statue whose true identity had been forgotten; some have thought it to be Aesculapius, the god of healing, but the description of the standing figure and the woman kneeling in supplication is precisely that found on coins depicting the bearded emperor Hadrian reaching out to a female figure symbolizing a province kneeling before him.
When asked by Constantia (Emperor Constantine's sister) for an image of Jesus, Eusebius denied the request, replying that "To depict purely the human form of Christ before its transformation, on the other hand, is to break the commandment of God and to fall into pagan error".
After Christianity was legalized by the emperor Constantine I within the Roman Empire in 313, huge numbers of pagans became converts. This created the necessity for the transfer of allegiance and practice from the old gods and heroes to the new religion, and for the gradual adaptation of the old system of image making and veneration to a Christian context, in the process of Christianization. Robin Lane Fox states "By the early fifth century, we know of the ownership of private icons of saints; by c. 480-500, we can be sure that the inside of a saint's shrine would be adorned with images and votive portraits, a practice which had probably begun earlier".
When Constantine converted to Christianity the majority of his subjects were still pagans and the Roman Imperial cult of the divinity of the emperor, expressed through the traditional burning of candles and the offering of incense to the emperor’s image, was tolerated for a period because it would have been politically dangerous to attempt to suppress it. Indeed, in the 5th century the portrait of the reigning emperor was still honoured this way in the courts of justice and municipal buildings of the empire and in 425 Philostorgius, an Arian Christian, charged the Orthodox Christians in Constantinople with idolatry because they still honored the image of the emperor Constantine the Great, the founder of the city, in this way. Dix notes that this was more than a century before we find the first reference to a similar honouring of the image of Christ or His apostles or saints, but that it would seem a natural progression for the image of Christ, the King of Heaven and Earth, to be paid similar veneration as that given to the earthly Roman emperor. However, the Orthodox, Eastern Catholics, and other groups insist that veneration to icons is explicitly distinct from worship to idols as pagans did. This is explained further in later sections on this page.
Theodosius to Justinian.
After adoption of Christianity as the only permissible Roman state religion under Theodosius I, Christian art began to change not only in quality and sophistication, but also in nature. This was in no small part due to Christians being free for the first time to express their faith openly without persecution from the state, in addition to the faith spreading to the non-poor segments of society. Paintings of martyrs and their feats began to appear, and early writers commented on their lifelike effect, one of the elements a few Christian writers criticized in pagan art — the ability to imitate life. The writers mostly criticized pagan works of art for pointing to false gods, thus encouraging idolatry. Statues in the round were avoided as being too close to the principal artistic focus of pagan cult practices, as they have continued to be (with some small-scale exceptions) throughout the history of Eastern Christianity.
Nilus of Sinai (d. c.430), in his "Letter to Heliodorus Silentiarius", records a miracle in which St. Plato of Ankyra appeared to a Christian in a dream. The Saint was recognized because the young man had often seen his portrait. This recognition of a religious apparition from likeness to an image was also a characteristic of pagan pious accounts of appearances of gods to humans, and was a regular "topos" in hagiography. One critical recipient of a vision from Saint Demetrius of Thessaloniki apparently specified that the saint resembled the "more ancient" images of him - presumably the 7th century mosaics still in Hagios Demetrios. Another, an African bishop, had been rescued from Arab slavery by a young soldier called Demetrios, who told him to go to his house in Thessaloniki. Having discovered that most young soldiers in the city seemed to be called Demetrios, he gave up and went to the largest church in the city, to find his rescuer on the wall.
During this period the church began to discourage all non-religious human images - the Emperor and donor figures counting as religious. This became largely effective, so that most of the population would only ever see religious images and those of the ruling class. The word icon referred to any and all images, not just religious ones, but there was barely a need for a separate word for these.
Luke's portrait of Mary.
It is in a context attributed to the 5th century that the first mention of an image of Mary painted from life appears, though earlier paintings on catacomb walls bear resemblance to modern icons of Mary. Theodorus Lector, in his 6th-century "History of the Church" 1:1 stated that Eudokia (wife of Theodosius II, died 460) sent an image of "the Mother of God" named Icon of the Hodegetria from Jerusalem to Pulcheria, daughter of the Emperor Arcadius: the image was specified to have been "painted by the Apostle Luke."
Margherita Guarducci relates a tradition that the original icon of Mary attributed to Luke, sent by Eudokia to Pulcheria from Palestine, was a large circular icon only of her head. When the icon arrived in Constantinople it was fitted in as the head into a very large rectangular icon of her holding the Christ child and it is this composite icon that became the one historically known as the Hodegetria. She further states another tradition that when the last Latin Emperor of Constantinople, Baldwin II, fled Constantinople in 1261 he took this original circular portion of the icon with him. This remained in the possession of the Angevin dynasty who had it likewise inserted into a much larger image of Mary and the Christ child, which is presently enshrined above the high altar of the Benedictine Abbey church of Montevergine. Unfortunately this icon has been over the subsequent centuries subjected to repeated repainting, so that it is difficult to determine what the original image of Mary’s face would have looked like. However, Guarducci also states that in 1950 an ancient image of Mary at the Church of Santa Francesca Romana was determined to be a very exact, but reverse mirror image of the original circular icon that was made in the 5th century and brought to Rome, where it has remained until the present.
In later tradition the number of icons of Mary attributed to Luke would greatly multiply; the Salus Populi Romani, the Theotokos of Vladimir, the Theotokos Iverskaya of Mount Athos, the Theotokos of Tikhvin, the Theotokos of Smolensk and the Black Madonna of Częstochowa are examples, and another is in the cathedral on St Thomas Mount, which is believed to be one of the seven painted by St.Luke the Evangelist and brought to India by St. Thomas. Ethiopia has at least seven more.
In the period before and during the Iconoclastic Controversy, stories attributing the creation of icons to the New Testament period greatly increased, with several apostles and even the Virgin herself believed to have acted as the artist or commissioner of images (embroidered in the case of the Virgin).
Iconoclast period.
There was a continuing opposition to images and their misuse within Christianity from very early times. "Whenever images threatened to gain undue influence within the church, theologians have sought to strip them of their power". Further,"there is no century between the fourth and the eighth in which there is not some evidence of opposition to images even within the Church". Nonetheless, popular favor for icons guaranteed their continued existence, while no systematic apologia for or against icons, or doctrinal authorization or condemnation of icons yet existed.
The use of icons was seriously challenged by Byzantine Imperial authority in the 8th century. Though by this time opposition to images was strongly entrenched in Judaism and Islam, attribution of the impetus toward an iconoclastic movement in Eastern Orthodoxy to Muslims or Jews "seems to have been highly exaggerated, both by contemporaries and by modern scholars".
Though significant in the history of religious doctrine, the Byzantine controversy over images is not seen as of primary importance in Byzantine history. "Few historians still hold it to have been the greatest issue of the period..."
The Iconoclastic Period began when images were banned by Emperor Leo III the Isaurian sometime between 726 and 730. Under his son Constantine V, a council forbidding image veneration was held at Hieria near Constantinople in 754. Image veneration was later reinstated by the Empress Regent Irene, under whom another council was held reversing the decisions of the previous iconoclast council and taking its title as Seventh Ecumenical Council. The council anathemized all who hold to iconoclasm, i.e. those who held that veneration of images constitutes idolatry. Then the ban was enforced again by Leo V in 815. And finally icon veneration was decisively restored by Empress Regent Theodora.
From then on all Byzantine coins had a religious image or symbol on the reverse, usually an image of Christ for larger denominations, with the head of the Emperor on the obverse, reinforcing the bond of the state and the divine order.
Acheiropoieta.
The tradition of "acheiropoieta" (ἀχειροποίητα, literally "not-made-by-hand") accrued to icons that are alleged to have come into existence miraculously, not by a human painter. Such images functioned as powerful relics as well as icons, and their images were naturally seen as especially authoritative as to the true appearance of the subject: naturally and especially because of the reluctance to accept mere human productions as embodying anything of the divine, a commonplace of Christian deprecation of man-made "idols". Like icons believed to be painted directly from the live subject, they therefore acted as important references for other images in the tradition. Beside the developed legend of the "mandylion" or Image of Edessa, was the tale of the Veil of Veronica, whose very name signifies "true icon" or "true image", the fear of a "false image" remaining strong.
Stylistic developments.
Although there are earlier records of their use, no panel icons earlier than the few from the 6th century preserved at the Greek Orthodox Saint Catherine's Monastery in Egypt survive, as the other examples in Rome have all been drastically over-painted. The surviving evidence for the earliest depictions of Christ, Mary and saints therefore comes from wall-paintings, mosaics and some carvings. They are realistic in appearance, in contrast to the later stylization. They are broadly similar in style, though often much superior in quality, to the mummy portraits done in wax (encaustic) and found at Fayyum in Egypt. As we may judge from such items, the first depictions of Jesus were generic rather than portrait images, generally representing him as a beardless young man. It was some time before the earliest examples of the long-haired, bearded face that was later to become standardized as the image of Jesus appeared. When they did begin to appear there was still variation. Augustine of Hippo (354-430) said that no one knew the appearance of Jesus or that of Mary. However, Augustine was not a resident of the Holy Land and therefore was not familiar with the local populations and their oral traditions. Gradually, paintings of Jesus took on characteristics of portrait images.
At this time the manner of depicting Jesus was not yet uniform, and there was some controversy over which of the two most common icons was to be favored. The first or "Semitic" form showed Jesus with short and "frizzy" hair; the second showed a bearded Jesus with hair parted in the middle, the manner in which the god Zeus was depicted. Theodorus Lector remarked that of the two, the one with short and frizzy hair was "more authentic". To support his assertion, he relates a story (excerpted by John of Damascus) that a pagan commissioned to paint an image of Jesus used the "Zeus" form instead of the "Semitic" form, and that as punishment his hands withered.
Though their development was gradual, we can date the full-blown appearance and general ecclesiastical (as opposed to simply popular or local) acceptance of Christian images as venerated and miracle-working objects to the 6th century, when, as Hans Belting writes, "we first hear of the church's use of religious images." "As we reach the second half of the sixth century, we find that images are attracting direct veneration and some of them are credited with the performance of miracles" Cyril Mango writes, "In the post-Justinianic period the icon assumes an ever increasing role in popular devotion, and there is a proliferation of miracle stories connected with icons, some of them rather shocking to our eyes". However, the earlier references by Eusebius and Irenaeus indicate veneration of images and reported miracles associated with them as early as the 2nd century. What might be shocking to our contemporary eyes may not have been viewed as such by the early Christians. Acts 5:15 reports that "people brought the sick into the streets and laid them on beds and mats so that at least Peter's shadow might fall on some of them as he passed by."
Symbolism.
In the icons of Eastern Orthodoxy, and of the Early Medieval West, very little room is made for artistic license. Almost everything within the image has a symbolic aspect. Christ, the saints, and the angels all have halos. Angels (and often John the Baptist) have wings because they are messengers. Figures have consistent facial appearances, hold attributes personal to them, and use a few conventional poses.
Colour plays an important role as well. Gold represents the radiance of Heaven; red, divine life. Blue is the color of human life, white is the Uncreated Light of God, only used for resurrection and transfiguration of Christ. If you look at icons of Jesus and Mary: Jesus wears red undergarment with a blue outer garment (God become Human) and Mary wears a blue undergarment with a red overgarment (human was granted gifts by God), thus the doctrine of deification is conveyed by icons. Letters are symbols too. Most icons incorporate some calligraphic text naming the person or event depicted. Even this is often presented in a stylized manner.
Miracles.
In the Eastern Orthodox Christian tradition there are reports of particular, Wonderworking icons that exude myrrh (fragrant, healing oil), or perform miracles upon petition by believers. When such reports are verified by the Orthodox hierarchy, they are understood as miracles performed by God through the prayers of the saint, rather than being magical properties of the painted wood itself. Theologically, all icons are considered to be sacred, and are miraculous by nature, being a means of spiritual communion between the heavenly and earthly realms. However, it is not uncommon for specific icons to be characterised as "miracle-working", meaning that God has chosen to glorify them by working miracles through them. Such icons are often given particular names (especially those of the Virgin Mary), and even taken from city to city where believers gather to venerate them and pray before them. Islands like that of Tinos are renowned for possessing such "miraculous" icons, and are visited every year by thousands of pilgrims.
Eastern Orthodox teaching.
The Eastern Orthodox view of the origin of icons is generally quite different from that of most secular scholars and from some in contemporary Roman Catholic circles: "The Orthodox Church maintains and teaches that the sacred image has existed from the beginning of Christianity", Léonid Ouspensky has written. Accounts that some non-Orthodox writers consider legendary are accepted as history within Eastern Orthodoxy, because they are a part of church tradition. Thus accounts such as that of the miraculous "Image Not Made by Hands", and the weeping and moving "Mother of God of the Sign" of Novgorod are accepted as fact: ""Church Tradition tells us, for example, of the existence of an Icon of the Savior during His lifetime (the "Icon-Made-Without-Hands") and of Icons of the Most-Holy Theotokos [Mary] immediately after Him."" Eastern Orthodoxy further teaches that "a clear understanding of the importance of Icons" was part of the church from its very beginning, and has never changed, although explanations of their importance may have developed over time. This is because icon painting is rooted in the theology of the Incarnation (Christ being the "eikon" of God) which didn't change, though its subsequent clarification within the Church occurred over the period of the first seven Ecumenical Councils. Also, icons served as tools of edification for the illiterate faithful during most of the history of Christendom.
Eastern Orthodox find the first instance of an image or icon in the Bible when God made man in His own image (Septuagint Greek "eikona"), in Genesis 1:26-27. In Exodus, God commanded that the Israelites not make any graven image; but soon afterwards, he commanded that they make graven images of cherubim and other like things, both as statues and woven on tapestries. Later, Solomon included still more such imagery when he built the first temple. Eastern Orthodox believe these qualify as icons, in that they were visible images depicting heavenly beings and, in the case of the cherubim, used to indirectly indicate God's presence above the Ark.
In the Book of Numbers it is written that God told Moses to make a bronze serpent, "Nehushtan", and hold it up, so that anyone looking at the snake would be healed of their snakebites. In John 3, Jesus refers to the same serpent, saying that he must be lifted up in the same way that the serpent was. John of Damascus also regarded the brazen serpent as an icon. Further, Jesus Christ himself is called the "image of the invisible God" in Colossians 1:15, and is therefore in one sense an icon. As people are also made in God's images, people are also considered to be living icons, and are therefore "censed" along with painted icons during Orthodox prayer services.
According to John of Damascus, anyone who tries to destroy icons "is the enemy of Christ, the Holy Mother of God and the saints, and is the defender of the Devil and his demons." This is because the theology behind icons is closely tied to the Incarnational theology of the humanity and divinity of Jesus, so that attacks on icons typically have the effect of undermining or attacking the Incarnation of Jesus himself as elucidated in the Ecumenical Councils.
Basil of Caesarea, in his writing "On the Holy Spirit", says: "The honor paid to the image passes to the prototype". He also illustrates the concept by saying, "If I point to a statue of Caesar and ask you 'Who is that?', your answer would properly be, 'It is Caesar.' When you say such you do not mean that the stone itself is Caesar, but rather, the name and honor you ascribe to the statue passes over to the original, the archetype, Caesar himself." So it is with an Icon.
Thus to kiss an icon of Christ, in the Eastern Orthodox view, is to show love towards Christ Jesus himself, not mere wood and paint making up the physical substance of the icon. Worship of the icon as somehow entirely separate from its prototype is expressly forbidden by the Seventh Ecumenical Council.
The word eikōn in the Bible.
The Greek word "eikōn" means an image or likeness that represents something else. An "eikon" does not necessarily imply sanctity or veneration.
Septuagint.
The Septuagint is the Greek translation of the Hebrew Scriptures used by the early Christians, and Eastern Orthodox consider it the only authoritative text of those Scriptures. In it the word "eikōn" is used for everything from man being made in the divine image to the "molten idol" placed by Manasses in the Temple.
Be aware that Septuagint numberings and names and the English Bible numberings and names are not uniformly identical.
New Testament.
Though the word "eikōn" is found in the New Testament, it is never in the context of painted icons though it is used to mean. In the New Testament the term is used for everything from Jesus as the image of the invisible God (Colossians 1:15) to the image of Caesar on a Roman coin () to the image of the Beast in the Apocalypse (Revelation 14:9). Here is a complete listing:
Icon painting tradition by region.
Eastern Roman Empire.
Of the icon painting tradition that developed in Byzantium, with Constantinople as the chief city, we have only a few icons from the 11th century and none preceding them, in part because of the Iconoclastic reforms during which many were destroyed or lost, and also because of plundering by Venetians in 1204 during the Fourth Crusade, and finally the taking of the city by the Islamic Turks in 1453.
It was only in the Comnenian period (1081–1185) that the cult of the icon became widespread in the Byzantine world, partly on account of the dearth of richer materials (such as mosaics, ivory, and enamels), but also because an "iconostasis" a special screen for icons was introduced then in ecclesiastical practice. The style of the time was severe, hieratic and distant.
In the late Comnenian period this severity softened, and emotion, formerly avoided, entered icon painting. Major monuments for this change include the murals at Daphni (ca. 1100) and Nerezi near Skopje (1164). The Theotokos of Vladimir (ca. 1115, "illustration, right") is probably the most representative example of the new trend towards spirituality and emotion.
The tendency toward emotionalism in icons continued in the Paleologan period, which began in 1261. Paleologan art reached its pinnacle in mosaics such as those of the "Kariye Camii" (the former Chora Monastery). In the last half of the 14th century, Paleologan saints were painted in an exaggerated manner, very slim and in contorted positions, that is, in a style known as the Paleologan Mannerism, of which is a superb example.
After 1453, the Byzantine tradition was carried on in regions previously influenced by its religion and culture — in the Balkans and Russia, Georgia in the Caucasus, and, in the Greek-speaking realm, on Crete.
Crete.
Crete was under Venetian control from 1204 and became a thriving center of art with eventually a "Scuola di San Luca", or organized painter's guild on Western lines. Cretan painting was heavily patronized both by Catholics of Venetian territories and by Eastern Orthodox. For ease of transport, Cretan painters specialized in panel paintings, and developed the ability to work in many styles to fit the taste of various patrons. El Greco, who moved to Venice after establishing his reputation in Crete, is the most famous artist of the school, who continued to use many Byzantine conventions in his works. In 1669 the city of Heraklion, on Crete, which at one time boasted at least 120 painters, finally fell to the Turks, and from that time Greek icon painting went into a decline, with a revival attempted in the 20th century by art reformers such as Photios Kontoglou, who emphasized a return to earlier styles.
Russia.
Russian icons are typically paintings on wood, often small, though some in churches and monasteries may be as large as a table top. Many religious homes in Russia have icons hanging on the wall in the "krasny ugol", the "red" or "beautiful" corner (see Icon Corner). There is a rich history and elaborate religious symbolism associated with icons. In Russian churches, the nave is typically separated from the sanctuary by an "iconostasis" (Russian "ikonostás") a wall of icons.
The use and making of icons entered Kievan Rus' following its conversion to Orthodox Christianity from the Eastern Roman (Byzantine) Empire in 988 AD. As a general rule, these icons strictly followed models and formulas hallowed by usage, some of which had originated in Constantinople. As time passed, the Russians—notably Andrei Rublev and Dionisius—widened the vocabulary of iconic types and styles far beyond anything found elsewhere. The personal, improvisatory and creative traditions of Western European religious art are largely lacking in Russia before the 17th century, when Simon Ushakov's painting became strongly influenced by religious paintings and engravings from Protestant as well as Catholic Europe.
In the mid-17th century, changes in liturgy and practice instituted by Patriarch Nikon resulted in a split in the Russian Orthodox Church. The traditionalists, the persecuted "Old Ritualists" or "Old Believers", continued the traditional stylization of icons, while the State Church modified its practice. From that time icons began to be painted not only in the traditional stylized and nonrealistic mode, but also in a mixture of Russian stylization and Western European realism, and in a Western European manner very much like that of Catholic religious art of the time. The Stroganov movement and the icons from Nevyansk rank among the last important schools of Russian icon-painting.
Romania.
In Romania, icons painted as reversed images behind glass and set in frames were common in the 19th century and are still made. The process is known as Reverse painting on glass. "In the Transylvanian countryside, the expensive icons on panels imported from Moldavia, Wallachia, and Mt. Athos were gradually replaced by small, locally produced icons on glass, which were much less expensive and thus accessible to the Transylvanian peasants..."
Egypt and Ethiopia.
The Egyptian Coptic Church and the Ethiopian Church also have distinctive, living icon painting traditions. Coptic icons have their origin in the Hellenistic art of Egyptian Late Antiquity, as exemplified by the Fayum mummy portraits. Beginning in the 4th century, churches painted their walls and made icons to reflect an authentic expression of their faith.
Western Christianity.
Although the word "icon" is not used in Western Christianity, there are religious works of art which were largely patterned on Byzantine works, and equally conventional in composition and depiction. Until the 13th century, "icon"-like portraits followed East pattern - although very few survive from this early period. From the 13th century, the western tradition came slowly to allow the artist far more flexibility, and a more realist approach to the figures. If only because there was a much smaller number of skilled artists, the quantity of works of art, in the sense of panel paintings, was much smaller in the West, and in most Western settings a single diptych as an altarpiece, or in a domestic room, probably stood in place of the larger collections typical of Orthodox "icon corners".
Only in the 15th century did production of painted works of art begin to approach Eastern levels, supplemented by mass-produced imports from the Cretan school. In this century, the use of "icon"-like portraits in the West was enormously increased by the introduction of prints on paper, mostly woodcuts which were produced in vast numbers (although hardly any survive). They were mostly sold, hand-coloured, by churches, and the smallest sizes (often only an inch high) were affordable even by peasants, who glued or pinned them straight onto a wall.
With the Reformation, after an initial uncertainty among early Lutherans, who painted a few "icon"-like depictions of leading Reformers, and continued to paint scenes from Scripture, Protestants came down firmly against icon-like portraits, especially larger ones, even of Christ. Many Protestants found these "idolatrous".
Catholic Church view.
The Roman Catholic Church, accepted the decrees of the iconodule Seventh Ecumenical Council regarding images. There is some minor difference, however, in the Catholic attitude to images from that of the Orthodox. Following Gregory the Great, Catholics emphasize the role of images as the "Biblia Pauperum", the "Bible of the Poor," from which those who could not read could nonetheless learn.
Catholics also, however, accept in principle the Eastern Orthodox veneration of images, believing that whenever approached, sacred images are to be reverenced. Though using both flat wooden panel and stretched canvas paintings, Catholics traditionally have also favored images in the form of three-dimensional statuary, whereas in the East statuary is much less widely employed.
Lutheran Church view.
A recent joint Lutheran-Orthodox statement made in the 7th Plenary of the Lutheran-Orthodox Joint Commission, on July 1993 in Helsinki, reaffirmed the Ecumenical council decisions on the nature of Christ and the veneration of images:
7. As Lutherans and Orthodox we affirm that the teachings of the ecumenical councils are authoritative for our churches. The ecumenical councils maintain the integrity of the teaching of the undivided Church concerning the saving, illuminating/justifying and glorifying acts of God and reject heresies which subvert the saving work of God in Christ. Orthodox and Lutherans, however, have different histories. Lutherans have received the Nicaeno-Constantinopolitan Creed with the addition of the filioque. The Seventh Ecumenical Council, the Second Council of Nicaea in 787, which rejected iconoclasm and restored the veneration of icons in the churches, was not part of the tradition received by the Reformation. Lutherans, however, rejected the iconoclasm of the 16th century, and affirmed the distinction between adoration due to the Triune God alone and all other forms of veneration (CA 21). Through historical research this council has become better known. Nevertheless it does not have the same significance for Lutherans as it does for the Orthodox. Yet, Lutherans and Orthodox are in agreement that the Second Council of Nicaea confirms the christological teaching of the earlier councils and in setting forth the role of images (icons) in the lives of the faithful reaffirms the reality of the incarnation of the eternal Word of God, when it states: "The more frequently, Christ, Mary, the mother of God, and the saints are seen, the more are those who see them drawn to remember and long for those who serve as models, and to pay these icons the tribute of salutation and respectful veneration. Certainly this is not the full adoration in accordance with our faith, which is properly paid only to the divine nature, but it resembles that given to the figure of the honored and life-giving cross, and also to the holy books of the gospels and to other sacred objects" (Definition of the Second Council of Nicaea).

</doc>
<doc id="14801" url="http://en.wikipedia.org/wiki?curid=14801" title="Icon (programming language)">
Icon (programming language)

Icon is a very high-level programming language featuring goal directed execution and many facilities for managing strings and textual patterns. It is related to SNOBOL and SL5, string processing languages. Icon is not object-oriented, but an object-oriented extension called Idol was developed in 1996 which eventually became Unicon.
Basic syntax.
The Icon language is derived from the ALGOL-class of structured programming languages, and thus has syntax similar to C or Pascal. Icon is most similar to Pascal, using syntax for assignments, the keyword and similar syntax. On the other hand, Icon uses C-style brackets for structuring execution groups, and programs start by running a procedure called "main".
In many ways Icon also shares features with most scripting programming languages (as well as SNOBOL and SL5, from which they were taken): variables do not have to be declared, types are cast automatically, and numbers can be converted to strings and back automatically. Another feature common to many scripting languages, but not all, is the lack of a line-ending character; in Icon, lines not ended by a semicolon get ended by an implied semicolon if it makes sense.
Procedures are the basic building blocks of Icon programs, and although they use Pascal naming they work more like C functions and can return values; there is no keyword in Icon.
Goal-directed execution.
One of Icon's key concepts is that control structures are based on the "success" or "failure" of expressions, rather than on boolean logic, as in most other programming languages. Under this model, simple comparisons like codice_1 do not mean "if the operations to the right evaluate to true" as they would under most languages; instead it means something more like "if the operations to the right "succeed"". In this case the < operator succeeds if the comparison is true, so the end result is the same. In addition, the < operator returns its second argument if it succeeds, allowing things like codice_2, a common type of comparison that in most languages must be written as a conjunction of two inequalities like codice_3.
The utility of this concept becomes much clearer when you consider real-world examples. Since Icon uses success or failure for all flow control, this simple code:
will copy one line of the standard input to standard output. What's interesting about this example is that the code will work even if the read() causes an error, for instance, if the file does not exist. In that case the statement will fail, and write will simply not be called.
Success and failure are passed "up" through functions, meaning that a failure inside a nested function will cause the functions calling it to fail as well. For instance, we can write a program to copy an entire input file to output in a single line:
When the read() command fails, at the end of file for instance, the failure will be passed up the chain and write() will fail as well. The while, being a control structure, stops on failure, meaning it stops when the file is empty. For comparison, consider a similar example written in Java-based pseudocode:
In this case there are two comparisons needed, one for end of file (EOF) and another for all other errors. Since Java does not allow errors to be compared as logic elements, as under Icon, the lengthy syntax must be used instead. Try blocks also impose a performance penalty for simply using them, even if no error occurs, a distributed cost that Icon avoids.
Icon refers to this concept as "goal-directed execution", referring to the way that execution continues until some goal is reached. In the example above the goal is to read the entire file; the read command continues to succeed while there is more information to be read, and fails when there isn't. The goal is thus coded directly in the language, instead of using statements checking return codes or similar constructs.
Generators.
Expressions in Icon often return a single value, for instance, x < 5 will evaluate and succeed if the value of x is less than 5 or fail. However several of the examples below rely on the fact that many expressions do not "immediately" return success or failure, returning values in the meantime. This drives the examples with every and to; every causes to to continue to return values until it fails. 
This is a key concept in Icon, known as "generators". Generators drive much of the loop functionality in the language, but do so more directly; the programmer does not write a loop and then pull out and compare values, Icon will do all of this for you.
Within the parlance of Icon, the evaluation of an expression or function results in a result sequence. A result sequence contains all the possible values that can be generated by the expression or function. When the result sequence is exhausted (e.g. there are no more values within the result sequence), the expression or function fails. Iteration over the result sequence is achieved either implicitly via Icon's goal directed evaluation or explicitly via the every clause. 
Icon includes several generator-builders. The "alternator" syntax allows a series of items to be generated in sequence until one fails: 
can generate "1", "hello", and "5" if x is less than 5. Alternators can be read as "or" in many cases, for instance:
will write out the value of y if it is smaller than x "or" 5. Internally Icon checks every value from left to right until one succeeds or the list empties and it returns a failure. Remember that functions will not be called unless the calls within do not fail, so this example can be shortened to:
Another simple generator is the , which generates lists of integers; will do exactly what it seems to. The "bang syntax" generates every item of a list; will output each character of aString on a new line.
To demonstrate the power of this concept, consider string operations. Most languages include a function known as or that returns the location of a string within another. Consider:
This code will return 4, the position of the first occurrence of the word "the". To get the next instance of "the" an alternate form must be used, 
the 5 at the end saying it should look from position 5 on. In order to extract all the occurrences of "the", a loop must be used...
Under Icon the find function is a generator, and will return the next instance of the string each time it is resumed before finally failing after it passes the end of the string. The same code under Icon can be written:
find will return the index of the next instance of "the" each time it is resumed by every, eventually passing the end of the string and failing. As in the prior example, this will cause write to fail, and the (one-line) every loop to exit. 
Of course there are times where you deliberately want to find a string after some point in input, for instance, you might be scanning a text file containing data in multiple columns. Goal-directed execution works here as well, and can be used this way:
The position will only be returned if "the" appears after position 5, the comparison will fail otherwise, passing that failure to write() as before. There is one small "trick" to this code that needs to be considered: comparisons return the right hand result, so it is important to put the find on the right hand side of the comparison. If the 5 were placed on the right, 5 would be written.
Icon adds several control structures for looping through 
generators. The every operator is similar to while, looping through every item returned by a generator and exiting on failure:
Why use every instead of a while loop in this case? 
Because while re-evaluates the first result,
but every produces all results.
The every syntax actually injects values into the function in a fashion similar to blocks under Smalltalk. For instance, the above loop can be re-written this way:
Users can build new generators easily using the suspend keyword:
This example loops over "theString" using find to look for "pattern". When one is found, and the position is odd, the location is returned from the function with suspend. Unlike return, suspend writes down where it is in the internal generators as well, allowing it to pick up where it left off on the next iteration.
Strings.
In keeping with its script-like functionality, Icon adds a number of features to make working with strings easier. Most notable among these is the "scanning" system, which repeatedly calls functions on a string:
is a short form of the examples shown earlier. In this case the "subject" of the function is placed outside the parameters in front of the question-mark. Icon functions are deliberately (as opposed to automatically) written to identify the subject in parameter lists and allow them to be pulled out in this fashion.
Substrings can be extracted from a string by using a range specification within brackets. A range specification can return a point to a single character, or a slice of the string. Strings can be indexed from either the right or the left. It is important to note that positions within a string are between the characters 1A2B3C4 and can be specified from the right -3A-2B-1C0
For example
Where the last example shows using a length instead of an ending position
The subscripting specification can be used as a Lvalue within an expression. This can be used to insert strings into another string or delete parts of a string. For example,
Other structures.
Icon also allows the user to easily construct their own lists (or "arrays"):
The items within a list can be of any sort, including other structures. To quickly build larger lists, Icon includes the generator; generates a list containing 10 copies of "word".
Like arrays in other languages, Icon allows items to be looked up by position, e.g., .
The "bang-syntax", e.g., , will print out four lines, each with one element.
Icon includes stack-like functions, and to allow them to form the basis of stacks and queues.
Icon also includes functionality for sets and tables (known as "hashes", "associative arrays", "dictionaries", etc.):
This code creates a table that will use zero as the default value of any unknown key. It then adds two items into it, with the keys "there" and "here", and values 1 and 2.
String scanning.
One of the powerful features of Icon is string scanning. The scan string operator, saves the current string scanning environment and creates a new string scanning environment. The string scanning environment consists of two keyword variables, and . Where &subject is the string being scanned, and &pos is the "cursor" or current position within the subject string. 
For example
would produce
Built-in and user defined functions can be used to move around within the string being scanned. Many of the built in functions will default to &subject and &pos (for example the "find" function). The following, for example, will write all blank delimited "words" in a string.
A more complicated example demonstrates the integration of generators and string scanning within the language.
The idiom of codice_4 returns the value of the last expression
References.
The definitive work is "The Icon Programming Language" (third edition) by Griswold and Griswold, ISBN 1-57398-001-3.
It is out of print but can be in PDF form.
Icon also has co-expressions, providing non-local exits for program execution. Please see "The Icon Programming language" and also Shamim Mohamed's "Co-expressions in Icon". (This topic should probably be expanded).

</doc>
<doc id="14802" url="http://en.wikipedia.org/wiki?curid=14802" title="Iconology">
Iconology

Iconology is a method of interpretation in cultural history and the history of art used by Aby Warburg, Erwin Panofsky and their followers that uncovers the cultural, social, and historical background of themes and subjects in the visual arts. It is derived from synthesis rather than scattered analysis and examines symbolic meaning on more than its face value by reconciling it with its historical context and with the artist's body of work - in contrast to the widely descriptive iconography, i.e. an approach to studying the content and meaning of works of art that is primarily focused on classifying, establishing dates, provenance and other necessary fundamental knowledge concerning the subject matter of an artwork that is needed for further interpretation.
Though Panofsky strongly differentiated between iconology and iconography, both approaches are still frequently confused, "and they have never been given definitions accepted by all iconographers and iconologists". It should also be noted that Panofsky's "use of iconology as the principle tool of art analysis brought him critics." For instance, in 1946, Jan Gerrit Van Gelder "criticized Panofsky's iconology as putting too much emphasis on the symbolic content of the work of art, neglecting its formal aspects and the work as a unity of form and content." Furthermore, iconology is mostly avoided by social historians who do not accept the theoretical dogmaticism in the work of Panofsky.
Iconology in contrast to iconography.
Erwin Panofsky defines iconography as "a description and classification of images", 
while iconology is "an iconography turned interpretive". According to his view, iconology tries to reveal the underlying principles that form the basic attitude of a nation, a period, a class, a religious or philosophical perspective, which is modulated by one personality and condensed into one work. According to Roelof van Straten, iconology "can explain why an artist or patron chose a particular subject at a specific location and time and represented it in a certain way. An iconological investigation should concentrate on the social-historical, not art-historical, influences and values that the artist might not have consciously brought into play but are nevertheless present. The artwork is primarily seen as a document of its time."
Warburg used the term "iconography" in his early research, replacing it in 1908 with "iconology" in his particular method of visual interpretation called "critical iconology", which focused on the tracing of motifs through different cultures and visual forms. In 1932, Panofsky published a seminal article, introducing a three-step method of visual interpretation dealing with (1) primary or natural subject matter; (2) secondary or conventional subject matter, i.e. iconography; (3) tertiary or intrinsic meaning or content, i.e. iconology. Whereas iconography analyses the world of images, stories and allegories and requires knowledge of literary sources, an understanding of the history of types and how themes and concepts were expressed by objects and events under different historical conditions, iconology interprets intrinsic meaning or content and the world of symbolical values by using "synthetic intuition". The interpreter is aware of the essential tendencies of the human mind as conditioned by psychology and world view; he analyses the history of cultural symptoms or symbols, or how tendencies of the human mind were expressed by specific themes due to different historical conditions. Moreover, when understanding the work of art as a document of a specific civilization, or of a certain religious attitude therein, the work of art becomes a symptom of something else, which expresses itself in a variety of other symptoms. Interpreting these symbolical values, which can be unknown to, or different from, the artist's intention, is the object of iconology. Panofsky emphasized that "iconology can be done when there are no originals to look at and nothing but artificial light to work in."
According to Ernst Gombrich, "the emerging discipline of iconology [...] must ultimately do for the image what linguistics has done for the word." However, Michael Camille is of the opinion that "though Panofsky's concept of iconology has been very influential in the humanities and is quite effective when applied to Renaissance art, it is still problematic when applied to art from periods before and after."
Nuances of iconology.
In 1952, Creighton Gilbert added another opinion about the meaning of the word "iconology". According to his view, iconology was not the actual investigation of the work of art but rather the result of this investigation. The Austrian art historian Hans Sedlmayr differentiated between "sachliche" and "methodische" iconology. "Sachliche" iconology refers to the "general meaning of an individual painting or of an artistic complex (church, palace, monument) as seen and explained with reference to the ideas which take shape in them." In contrast, "methodische" iconology is the "integral iconography which accounts for the changes and development in the representations". In "Iconology: Images, Text, Ideology" (1986), W.J.T. Mitchell writes that iconology is a study of "what to say about images", concerned with the description and interpretation of visual art, and also a study of "what images say" – the ways in which they seem to speak for themselves by persuading, telling stories, or describing. He pleads for a postlinguistic, postsemiotic "iconic turn", emphasizing the role of "non-linguistic symbol systems". Instead of just pointing out the difference between the material (pictorial or artistic) images, "he pays attention to the dialectic relationship between material images and mental images". According to Dennise Bartelo and Robert Morton, the term "iconology" can also be used for characterizing "a movement toward seeing connections across all the language processes" and the idea about "multiple levels and forms used to communicate meaning" in order to get "the total picture” of learning. "Being both literate in the traditional sense and visually literate are the true mark of a well-educated human."
Studies in iconology.
Studies in Iconology is the title of a book by Erwin Panofsky on humanistic themes in the art of the Renaissance, which was first published in 1939. It is also the name of a peer-reviewed series of books started in 2014 and published by Peeters international academic publishers, Leuven, Belgium, which addresses an audience that seeks to understand any aspect and any deeper meaning of the visual medium along the history of mankind in the fields of philosophy, art history, theology and cultural anthropology.

</doc>
<doc id="14804" url="http://en.wikipedia.org/wiki?curid=14804" title="Indian massacre">
Indian massacre

In the history of the European colonization of North America, the term "Indian massacre" was often used to describe either mass killings of people of European descent by indigenous people of the North American continent (Indians) or mass killings of indigenous people by people of European descent and/or other indigenous people.
List of massacres.
This is a listing of some of the events reported then or referred to now as "Indian massacre".

</doc>
<doc id="14810" url="http://en.wikipedia.org/wiki?curid=14810" title="Islamic calendar">
Islamic calendar

The Islamic calendar, Muslim calendar or Hijri calendar (AH) is a lunar calendar consisting of 12 months in a year of 354 days.
It is used to date events in many Muslim countries (concurrently with the Gregorian calendar), and used by Muslims everywhere to determine the proper days on which to observe the annual fasting, to attend "Hajj", and to celebrate other Islamic holidays and festivals.
The first year was the Islamic year beginning in AD 622 during which the emigration of Muhammad from Mecca to Medina, known as the Hijra, occurred. Each numbered year is designated either "H" for "Hijra" or "AH" for the Latin "anno Hegirae" ("in the year of the Hijra"); hence, Muslims typically call their calendar the Hijri calendar.
The current Islamic year is 1436 AH. In the Gregorian calendar, 1436 AH runs from approximately 24 October 2014 (evening) to 13 October 2015 (evening).
Months.
 of the twelve Hijri months are considered sacred: Rajab (7), and the three consecutive months of Dhu al-Qa‘dah (11), Dhu al-Hijjah (12) and Muharram (1).
Length of months.
Each month of the Islamic calendar commences on the birth of the new lunar cycle. Traditionally this is based on actual witnessing of the crescent marking the end of the previous lunar cycle and hence the previous month thereby beginning the new month. Consequently each month can have 29 or 30 days depending on the visibility of the moon, astronomical positioning of the earth and weather conditions. However, certain sects and groups, most notably Dawoodi Bohra Muslims and Shia Ismaili Muslims use a tabular Islamic calendar (see section below) in which odd months have thirty days (and also the twelfth month in a leap year) and even months have 29.
Days of the week.
In Arabic, the "first day" of the week corresponds with Sunday of the planetary week. The Islamic weekdays, like those in the Hebrew and Baha'i calendars, begin at sunset. The Christian liturgical day, kept in monasteries, begins with vespers (see vesper), which is evening, in line with the other Abrahamic traditions. Christian and planetary weekdays begin at the following midnight. Muslims gather for worship at a mosque at noon on "gathering day" (Yawm al-Jumu‘ah, yawm يوم meaning "day") which corresponds with Friday. Thus "gathering day" is often regarded as the weekly day of rest. This is frequently made official, with many Muslim countries adopting Friday and Saturday (e.g. Egypt, Saudi Arabia) or Thursday and Friday as official weekends, during which offices are closed; other countries (e.g. Iran) choose to make Friday alone a day of rest. A few others (e.g. Turkey, Pakistan) have adopted the Western Saturday-Sunday weekend while making Friday a working day with a long midday break to allow time off for worship.
History.
Pre-Islamic calendar.
Inscriptions of the ancient South Arabian calendars reveal the use of a number of local calendars. At least some of these calendars followed the lunisolar system. For Central Arabia, especially Mecca, there is a lack of epigraphical evidence but details are found in the writings of Muslim authors of the Abbasid era. Both al-Biruni and al-Mas'udi suggest that the Ancient Arabs used the same month names as the Muslims, though they also record other month names used by the pagan Arabs.
It is well known that Hajj was originally an equinoctial festival and research on the pre-Islamic calendar has been summarized in recent Islamic and secular scholarship which equates the pre-Islamic months from Muharram to Dhu al-Hijjah with the Hebrew religious months of Iyyar to Nisan respectively (Ramadan corresponding to the Fast of Adam in Tevet) rather than Nisan to Adar as might otherwise be presumed. In stark opposition to this opinion however, subsequent Christian then Jewish scholars have both tried to equate the pre-Islamic months from Muharram to Jumādā ath-Thāniya at least with the Hebrew months of Tishrei to Adar I respectively. Nevertheless, the Islamic position equating Nisan with Dhū al-Ḥijja has prevailed. 
The Islamic tradition is unanimous in stating that Arabs of Tihamah, Hejaz, and Najd distinguished between two types of months, permitted ("ḥalāl") and forbidden ("ḥarām") months. The forbidden months were four months during which fighting is forbidden, listed as Rajab and the three months around the pilgrimage season, Dhu al-Qa‘dah, Dhu al-Hijjah, and Muharram. Information about the forbidden months is also found in the writings of Procopius, where he describes an armistice with the Eastern Arabs of the Lakhmid al-Mundhir which happened in the summer of 541 AD. However, Muslim historians do not link these months to a particular season. The Qur'an links the four forbidden months with "Nasī’", a word that literally means "postponement". According to Muslim tradition, the decision of postponement was administered by the tribe of Kinanah, by a man known as the "al-Qalammas" of Kinanah and his descendants (pl. "qalāmisa").
Different interpretations of the concept of "Nasī’" have been proposed. Some scholars, both Muslim and Western, maintain that the pre-Islamic calendar used in Central Arabia was a purely lunar calendar similar to the modern Islamic calendar. According to this view, "Nasī’" is related to the Pagan practices of the Meccan Arabs, where they would alter the distribution of the forbidden months within a given year without implying a calendar manipulation. This interpretation is supported by Arab historians and lexicographers, like Ibn Hisham, Ibn Manzur, and the corpus of Qur'anic exegesis. It is also corroborated by an early Sabaic inscription, where a religious ritual was "postponed" ("ns'ʾw") due to war. According to the context of this inscription, the verb "ns'ʾ" has nothing to do with intercalation, but only with moving religious events within the calendar itself. The similarity between the religious concept of this ancient inscription and the Qur'an suggests that non-calendaring postponement is also the Qur'anic meaning of "Nasī’". Thus the Encyclopaedia of Islam concludes that the "The Arabic system of [Nasī’] can only have been intended to move the Hajj and the fairs associated with it in the vicinity of Mecca to a suitable season of the year. It was not intended to establish a fixed calendar to be generally observed."
However, as mentioned above there is strong evidence that although originally a lunar calendar about 200 years before the Hijra it was remodelled on the Jewish lunisolar calendar containing an intercalary month added from time to time to keep the pilgrimage within the season of the year when merchandise was most abundant. This interpretation was first proposed by the medieval Muslim astrologer and astronomer Abu Ma'shar al-Balkhi, and later by al-Biruni, al-Mas'udi, and some Western scholars. This interpretation considers "Nasī’" to be a synonym to the Arabic word for "intercalation" ("kabīsa"). The Jewish "Nasi" was the official who decided when to intercalate the Jewish calendar. The Arabs, according to one explanation mentioned by Abu Ma'shar, learned of this type of intercalation from the Jews. For a comparison between the Islamic and pre-Islamic calendars, see Islamic and Jahili months. Scholars have suggested that the Arabic system was to intercalate three months in eight years (nine in 24), seven in nineteen or eleven in thirty. All these values are in agreement with the cycle of the seasons which requires on average an addition of one month every 33 or 34 months.
Some writers have suggested that the first intercalation doubled the first month Muharram, then on the next adjustment the second month Safar was doubled, continuing until the intercalation had passed through all twelve months of the year and returned to Muharram, when it was repeated. This is explained by one scholar as the writer simply explaining the intercalated calendar in terms of the fixed calendar, which his readers were familiar with. The Qu'ran makes it clear that in intercalary years the number of months was expanded from its usual twelve (see next section). It is affirmed that the divinely ordained number of the months is twelve.
What dates we can fix confirm this picture. Traditionally Muhammad was born in the spring of the year of the elephant (AD 570) on Monday, 12 Rabi'I. This would equate to 2 June, making Muharram equal to Nisan. In the year of the Hejira (AD 622) Muhammad traditionally left Mecca on Sunday night, the start of 24 Safar. This equates to Sunday, 9 May and points to Muharram starting on 18 March, again equivalent to Nisan. He entered Medina traditionally on Monday, 8 Rabi'I (24 May). There he found the Jews observing an important holy day. From the reference to Moses and the Exodus this holy day can be identified with the Feast of Weeks, which is observed on the sixth and seventh days of the third Jewish month. Muhammad's son Ibrahim was traditionally born in Dhu al - Hijjah, the twelfth month, which was the month of the pilgrimage, in AD 630. He is believed to have died in AD 632, possibly at the age of one year ten months and six days or one year ten months and eight days. The date of his death coincided with a solar eclipse. This fixes the date, 29 Shawwal AH 10, as 27 January. With no intercalation the following Muharram corresponds to Nisan, and also Muharram in the present calendar, that being the end of intercalation in the Islamic calendar.
Prohibiting Nasī’.
In the tenth year of the Hijra, as documented in the Qur'an (sura 9:36–37), God revealed the "prohibition of the Nasī’".
In the sight of God the number of months is twelve, and so it was decreed on the day He created the heavens and the earth. Of them four are sacred: that is the correct religious practice, so do not wrong yourselves in them and fight the pagans altogether, as they fight you altogether. And know that God is with those who restrain themselves.
Know that intercalation (nasi) is an addition to disbelief. Those who disbelieve are led to error thereby, making it lawful in one year and forbidden in another in order to adjust the number of (the months) made sacred by God and make the sacred ones permissible. The evil of their course appears pleasing to them. But God gives no guidance to those who disbelieve.—"Sura" 9 ("At-Tawba"), "ayat" 36–37
It is suggested that the prohibition of "Nasi" would have been announced when the intercalated month had returned to its position just before the month of "Nasi"' began. This is demonstrably false. It would only take 33 years for the month to rotate through the calendar, and the system was in use for 200 years. Either way, Western calendar dates commonly cited for key events in early Islam such as the Hijra, the Battle of Badr, the Battle of Uhud and the Battle of the Trench, should be viewed with caution since date calculators do not allow for intercalation.
This prohibition was mentioned by Muhammad during the farewell sermon which was delivered on 9 Dhu al-Hijjah 10 AH (Julian date Friday 6 March, AD 632) on Mount Arafat during the farewell pilgrimage to Mecca.
Certainly the Nasi’ is an impious addition, which has led the infidels into error. One year they authorise the Nasi’, another year they forbid it. They observe the divine precept with respect to the number of the sacred months, but in fact they profane that which God has declared to be inviolable, and sanctify that which God has declared to be profane. Assuredly time, in its revolution, has returned to such as it was at the creation of the heavens and the earth. In the eyes of God the number of the months is twelve. Among these twelve months four are sacred, namely, Rajab, which stands alone, and three others which are consecutive.—translated by Sherrard Beaumont Burnaby
The three successive forbidden months mentioned by Muhammad (months in which battles are forbidden) are Dhu al-Qa‘dah, Dhu al-Hijjah, and Muharram, months 11, 12, and 1. The single forbidden month is Rajab, month 7.
Year numbering.
In pre-Islamic Arabia, it was customary to identify a year after a major event which took place in it. Thus, according to Islamic tradition, Abraha, governor of Yemen, then a province of the Christian Kingdom of Aksum (Ethiopia), attempted to destroy the Kaaba with an army which included several elephants. The raid was unsuccessful, but that year became known as the "Year of the Elephant", during which Muhammad was born (sura al-Fil). Most equate this to the year AD 570, but a minority use AD 571.
The first ten years of the Hijra were not numbered, but were named after events in the life of Muhammad according to Abū Rayḥān al-Bīrūnī:
In AD 638 (17 AH), Abu Musa Ashaari, one of the officials of the Caliph Umar in Basrah, complained about the absence of any years on the correspondence he received from Umar, making it difficult for him to determine which instructions were most recent. This report convinced Umar of the need to introduce an era for Muslims. After debating the issue with his counsellors, he decided that the first year should include the date of Muhammad's arrival at Medina (known as Yathrib, before Muhammad's arrival). Uthman ibn Affan then suggested that the months begin with Muharram, in line with the established custom of the Arabs at that time. The years of the Islamic calendar thus began with the month of Muharram in the year of Muhammad's arrival at the city of Medina, even though the actual emigration took place in Safar and Rabi' I. Because of the Hijra, the calendar was named the Hijra calendar.
The first day of the first month of the Islamic calendar (1 Muharram 1 AH) was set to the first new moon after the day the Prophet moved from Quba' to Medina (originally 26 Rabi' I on the pagan calendar) i.e. Friday, 19 July 622 in the Gregorian calendar or 16 July AD 622, the equivalent civil tabular date (same daylight period) in the Julian calendar. The Islamic day began at the preceding sunset on the evening of 15 July. This Julian date (16 July) was determined by medieval Muslim astronomers by projecting back in time their own tabular Islamic calendar, which had alternating 30- and 29-day months in each lunar year plus eleven leap days every 30 years. For example, al-Biruni mentioned this Julian date in the year AD 1000. Although not used by either medieval Muslim astronomers or modern scholars to determine the Islamic epoch, the thin crescent moon would have also first become visible (assuming clouds did not obscure it) shortly after the preceding sunset on the evening of 15 July, 1.5 days after the associated dark moon (astronomical new moon) on the morning of 14 July.
Though Cook and Crone in "" cite a coin from 17 AH, the first surviving attested use of a Hijri calendar date alongside a date in another calendar (Coptic) is on a papyrus from Egypt in 22 AH, PERF 558.
Astronomical considerations.
The Islamic calendar is not to be confused with a lunar calendar that is based on astronomical calculations. The latter is based on a year of 12 months adding up to 354.37 days. Each lunar month begins at the time of the monthly "conjunction", when the Moon is located on a straight line between the Earth and the Sun. The month is defined as the average duration of a revolution of the Moon around the Earth (29.53 days). By convention, months of 30 days and 29 days succeed each other, adding up over two successive months to 59 full days. This leaves only a small monthly variation of 44 minutes to account for, which adds up to a total of 24 hours (i.e. the equivalent of one full day) in 2.73 years. To settle accounts, it is sufficient to add one day every three years to the lunar calendar, in the same way that one adds one day to the Gregorian calendar every four years. The technical details of the adjustment are described in Tabular Islamic calendar.
The Islamic calendar, however, is based on a different set of conventions. Each month has either 29 or 30 days, but usually in no discernible order. Traditionally, the first day of each month is the day (beginning at sunset) of the first sighting of the hilal (crescent moon) shortly after sunset. If the hilal is not observed immediately after the 29th day of a month (either because clouds block its view or because the western sky is still too bright when the moon sets), then the day that begins at that sunset is the 30th. Such a sighting has to be made by one or more trustworthy men testifying before a committee of Muslim leaders. Determining the most likely day that the hilal could be observed was a motivation for Muslim interest in astronomy, which put Islam in the forefront of that science for many centuries.
This traditional practice is still followed in the overwhelming majority of Muslim countries. Each Islamic state proceeds with its own monthly observation of the new moon (or, failing that, awaits the completion of 30 days) before declaring the beginning of a new month on its territory. But, the lunar crescent becomes visible only some 17 hours after the conjunction, and only subject to the existence of a number of favourable conditions relative to weather, time, geographic location, as well as various astronomical parameters. Given the fact that the moon sets progressively later than the sun as one goes west, with a corresponding increase in its "age" since conjunction, Western Muslim countries may, under favorable conditions, observe the new moon one day earlier than eastern Muslim countries. Due to the interplay of all these factors, the beginning of each month differs from one Muslim country to another, during the 48 h period following the conjunction. The information provided by the calendar in any country does not extend beyond the current month.
A number of Muslim countries try to overcome some of these difficulties by applying different astronomy-related rules to determine the beginning of months. Thus, Malaysia, Indonesia, and a few others begin each month at sunset on the first day that the moon sets after the sun (moonset after sunset). In Egypt, the month begins at sunset on the first day that the moon sets at least five minutes after the sun. A detailed analysis of the available data shows, however, that there are major discrepancies between what countries say they do on this subject, and what they actually do. In some instances, what a country says it does is impossible.
Theological considerations.
If the Islamic calendar were prepared using astronomical calculations, Muslims throughout the Muslim world could use it to meet all their needs, the way they use the Gregorian calendar today. But, there are divergent views on whether it is licit to do so.
A majority of theologians oppose the use of calculations (beyond the constraint that each month must be not less than 29 nor more than 30 days) on the grounds that the latter would not conform with Muhammad's recommendation to observe the new moon of Ramadan and Shawal in order to determine the beginning of these months.
However, some jurists see no contradiction between Muhammad's teachings and the use of calculations to determine the beginnings of lunar months. They consider that Muhammad's recommendation was adapted to the culture of the times, and should not be confused with the acts of worship.
Thus the jurists Ahmad Muhammad Shakir and Yusuf al-Qaradawi both endorsed the use of calculations to determine the beginning of all months of the Islamic calendar, in 1939 and 2004 respectively. So did the "Fiqh Council of North America" (FCNA) in 2006 and the "European Council for Fatwa and Research" (ECFR) in 2007.
The major Muslim associations of France also announced in 2012 that they would henceforth use a calendar based on astronomical calculations, taking into account the criteria of the possibility of crescent sighting in any place on Earth. But, shortly after the official adoption of this rule by the French Council of the Muslim Faith (CFCM) in 2013, the new leadership of the association decided, on the eve of ramadan 2013, to follow the Saudi announcement rather than to apply the rule just adopted. This resulted in a division of the Muslim community of France in two camps, with some members following the new rule, and others following the Saudi announcement.
Turkish Muslims also use an Islamic calendar which is calculated several years in advance (currently up to 1444 AH/2022 CE) by the Turkish Presidency of Religious Affairs (Diyanet İşleri Başkanlığı). From 1 Muharrem 1400 AH (21 November 1979) until 29 Zilhicce 1435 (24 October 2014) the computed Turkish lunar calendar was based on the following rule: “The lunar month is assumed to begin on the evening when, within some region of the terrestrial globe, the computed centre of the lunar crescent at local sunset is more than 5° above the local horizon and (geocentrically) more than 8° from the Sun.” In the current rule the (computed) lunar crescent has to be above the local horizon of Ankara at sunset.
Fatimid Dawoodi Bohra and Qutbi Bohra a sub sect of Dawoodi Bohra follow the tabular Islamic calendar (see section below) prepared on the basis of astronomical calculations from the days of Fatimid imams.
Saudi Arabia's "Umm al-Qura" calendar.
Saudi Arabia uses the sighting method to determine the beginning of each month of the Hijri calendar. Since AH 1419 (1998/99) several official hilal sighting committees have been set up by the government to determine the first visual sighting of the lunar crescent at the beginning of each lunar month. Nevertheless, the religious authorities also allow the testimony of less experienced observers and thus often announce the sighting of the lunar crescent on a date when none of the official committees could see it.
The country also uses the Umm al-Qura calendar, based on astronomical calculations, but this is restricted to administrative purposes. The parameters used in the establishment of this calendar underwent significant changes over the past decade.
Before AH 1420 (before 18 April 1999), if the moon's age at sunset in Riyadh was at least 12 hours, then the day "ending" at that sunset was the first day of the month. This often caused the Saudis to celebrate holy days one or even two days before other predominantly Muslim countries, including the dates for the Hajj, which can only be dated using Saudi dates because it is performed in Mecca.
For AH 1420–22, if moonset occurred after sunset at Mecca, then the day beginning at that sunset was the first day of a Saudi month, essentially the same rule used by Malaysia, Indonesia, and others (except for the location from which the hilal was observed).
Since the beginning of AH 1423 (16 March 2002), the rule has been clarified a little by requiring the geocentric conjunction of the sun and moon to occur before sunset, in addition to requiring moonset to occur after sunset at Mecca. This ensures that the moon has moved past the sun by sunset, even though the sky may still be too bright immediately before moonset to actually see the crescent.
In 2007, the Islamic Society of North America, the "Fiqh" Council of North America and the European Council for "Fatwa" and Research announced that they will henceforth use a calendar based on calculations using the same parameters as the "Umm al-Qura" calendar to determine (well in advance) the beginning of all lunar months (and therefore the days associated with all religious observances). This was intended as a first step on the way to unify, at some future time, Muslims' calendars throughout the world.
Other calendars using the Islamic era.
The Solar Hejri is a solar calendar used in Iran and Afghanistan which counts its years from the Hijra or migration of Muhammad from Mecca to Medina in AD 622.
Tabular Islamic calendar.
The Tabular Islamic calendar is a rule-based variation of the Islamic calendar, in which months are worked out by arithmetic rules rather than by observation or astronomical calculation. It has a 30-year cycle with 11 leap years of 355 days and 19 years of 354 days. In the long term, it is accurate to one day in about 2,500 years. It also deviates up to about one or two days in the short term.
Kuwaiti algorithm.
Microsoft uses the "Kuwaiti algorithm", a variant of the tabular Islamic calendar, to convert Gregorian dates to the Islamic ones. Microsoft claims that the variant is based on a statistical analysis of historical data from Kuwait.
Notable dates.
Important dates in the Islamic (Hijri) year are:
Days considered important predominantly for Shia Muslims:
Days considered important predominantly for Sunni Muslims(especially in India & parts of Asia):
Converting Hijri to Gregorian date or vice versa.
Conversions may be made online (see list below), by using the Tabular Islamic calendar (see Tabular Islamic calendar), or, for greatest accuracy (one day in 15,186 years), via the Jewish calendar. Theoretically, the days of the months correspond in both calendars if the displacements which are a feature of the Jewish system are ignored. The table below gives, for nineteen years, the Muslim month which corresponds to the first Jewish month.
This table may be extended since every nineteen years the Muslim month number increases by seven. When it goes above twelve, subtract twelve and add one to the year AH. From AD412 to AD632 inclusive the month number is 1 and the calculation gives the month correct to a month or so. AD622 corresponds to BH1 and AH1. For earlier years, year BH = (623 or 622) – year AD).
An example calculation: What is the civil date and year AH of the first day of the first month in the year AD 20875?
We first find the Muslim month number corresponding to the first month of the Jewish year which begins in AD20874. Dividing 20874 by 19 gives quotient 1098 and remainder 12. Dividing 2026 by 19 gives quotient 106 and remainder 12. The two years are therefore (1098–106)=992x19 years apart. The Muslim month number corresponding to the first Jewish month is therefore (992x7)=6944 higher than in 2026. To convert into years and months divide by twelve – 6944/12=578 years and 8 months. Adding, we get 1447y 10m + 20874y – 2026y + 578y 8m = 20874y 6m. Therefore, the first month of the Jewish year beginning in AD20874 corresponds to the sixth month of the Muslim year AH20874. The worked example in Conversion between Jewish and civil dates, shows that the civil date of the first day of this month (ignoring the displacements) is Friday, 14 June. The year AH20875 will therefore begin seven months later, on the first day of the eighth Jewish month, which the worked example shows to be 7 January, AD20875 (again ignoring the displacements). The date given by this method, being calculated, may differ by a day from the actual date, which is determined by observation.
A reading of the section which follows will show that the year AH20875 is wholly contained within the year AD20875, also that in the Gregorian calendar this correspondence will occur one year earlier. The reason for the discrepancy is that the Gregorian year (like the Julian) is slightly too long, so the Gregorian date for a given AH date will be earlier and the Muslim calendar catches up sooner.
Current correlations.
An Islamic year will be entirely within a Gregorian year of the same number in the year 20874, after which year the number of the Islamic year will always be greater than the number of the concurrent civil year. The Islamic calendar year of 1429 occurred entirely within the civil calendar year of 2008. Such years occur once every 33 or 34 Islamic years (32 or 33 civil years). More are listed here:
Because a hijri or Islamic lunar year is between 10 and 12 days shorter than a civil year, it begins 10–12 days earlier in the civil year following the civil year in which the previous hijri year began. Once every 33 or 34 hijri years, or once every 32 or 33 civil years, the beginning of a hijri year (1 Muharram) coincides with one of the first ten days of January. Subsequent hijri New Years move backward through the civil year back to the beginning of January again, passing through each civil month from December to January.
Uses.
The Islamic calendar is now used primarily for religious purposes, and for official dating of public events and documents in Muslim countries. Because of its nature as a purely lunar calendar, it cannot be used for agricultural purposes and historically Islamic communities have used other calendars for this purpose: the Egyptian calendar was formerly widespread in Islamic countries, and the Iranian calendar and the 1789 Ottoman calendar (a modified Julian calendar) were also used for agriculture in their countries. In the Levant and Iraq the Aramaic names of the Babylonian calendar are still used for all secular matters. In Morocco, the Berber calendar (another Julian calendar) is still used by farmers in the countryside. These local solar calendars have receded in importance with the near-universal adoption of the Gregorian calendar for civil purposes. As noted above, Saudi Arabia uses the Islamic calendar to date religious occasions such as Ramadan, Hajj, etc. and the Umm-al-Qura calendar, based on calculations, for administrative purposes and daily government business. In Indonesia, the Javanese calendar, created by Sultan Agung in 1633, combines elements of the Islamic and pre-Islamic Saka calendars.
British author Nicholas Hagger writes that after seizing control of Libya, Muammar Gaddafi "declared" on 1 December 1978 "that the Muslim calendar should start with the death of the prophet Mohammed in 632 rather than the hijra (Mohammed's 'emigration' from Mecca to Medina) in 622". This put the country ten solar years behind the standard Muslim calendar. However, according to the 2006 "Encyclopedia of the Developing World", "More confusing still is Qaddafi's unique Libyan calendar, which counts the years from the Prophet's birth, or sometimes from his death. The months July and August, named after Julius and Augustus Caesar, are now Nasser and Hannibal respectively." Reflecting on a 2001 visit to the country, American reporter Neil MacFarquhar observed, "Life in Libya was so unpredictable that people weren't even sure what year it was. The year of my visit was officially 1369. But just two years earlier Libyans had been living through 1429. No one could quite name for me the day the count changed, especially since both remained in play. ... Event organizers threw up their hands and put the Western year in parentheses somewhere in their announcements."

</doc>
<doc id="14812" url="http://en.wikipedia.org/wiki?curid=14812" title="Interquartile range">
Interquartile range

In descriptive statistics, the interquartile range (IQR), also called the midspread or middle fifty, is a measure of statistical dispersion, being equal to the difference between the upper and lower quartiles, IQR = "Q"3 −  "Q"1. In other words, the IQR is the 1st quartile subtracted from the 3rd quartile; these quartiles can be clearly seen on a box plot on the data. It is a trimmed estimator, defined as the 25% trimmed range, and is the most significant basic robust measure of scale.
Use.
Unlike (total) range, the interquartile range has a breakdown point of 50%, and is thus often preferred to the total range.
The IQR is used to build box plots, simple graphical representations of a probability distribution.
For a symmetric distribution (where the median equals the midhinge, the average of the first and third quartiles), half the IQR equals the median absolute deviation (MAD).
The median is the corresponding measure of central tendency.
Identification of outliers (see below).
Examples.
Data set in a table.
For the data in this table the interquartile range is IQR = 115 − 105 = 10.
Data set in a plain-text box plot.
For the data set in this box plot:
Interquartile range of distributions.
The interquartile range of a continuous distribution can be calculated by integrating the probability density function (which yields the cumulative distribution function — any other means of calculating the CDF will also work). The lower quartile, "Q"1, is a number such that integral of the PDF from -∞ to "Q"1 equals 0.25, while the upper quartile, "Q"3, is such a number that the integral from -∞ to "Q"3 equals 0.75; in terms of the CDF, the quartiles can be defined as follows:
where CDF−1 is the quantile function.
The interquartile range and median of some common distributions are shown below
Interquartile range test for normality of distribution.
The IQR, mean, and standard deviation of a population "P" can be used in a simple test of whether or not "P" is normally distributed, or Gaussian. If "P" is normally distributed, then the standard score of the first quartile, "z"1, is -0.67, and the standard score of the third quartile, "z"3, is +0.67. Given "mean" = "X" and "standard deviation" = σ for "P", if "P" is normally distributed, the first quartile 
and the third quartile
If the actual values of the first or third quartiles differ substantially from the calculated values, "P" is not normally distributed.
Interquartile range and outliers.
The interquartile range is often used to find outliers in data. Outliers are observations that fall below Q1 - 1.5(IQR) or above Q3 + 1.5(IQR). In a boxplot, the highest and lowest occurring value within this limit are drawn as bar of the "whiskers", and the outliers as individual points.

</doc>
<doc id="14814" url="http://en.wikipedia.org/wiki?curid=14814" title="Indiana Jones">
Indiana Jones

Dr. Henry Walton "Indiana" Jones, Jr., often shortened to "Indy", is the title character of the "Indiana Jones" franchise. George Lucas created the character in homage to the action heroes of 1930s film serials. The character first appeared in the 1981 film "Raiders of the Lost Ark", to be followed by "Indiana Jones and the Temple of Doom" in 1984, "Indiana Jones and the Last Crusade" in 1989, "The Young Indiana Jones Chronicles" from 1992 to 1996, and "Indiana Jones and the Kingdom of the Crystal Skull" in 2008. Alongside the more widely known films and television programs, the character is also featured in novels, comics, video games, and other media. Jones is also featured in the Disney theme park attraction; Indiana Jones Adventure at Disneyland and Tokyo DisneySea, as well as the Disneyland Paris attraction Indiana Jones et le Temple du Péril.
Jones is most famously played by Harrison Ford and has also been portrayed by River Phoenix (as the young Jones in "The Last Crusade") and in the television series "The Young Indiana Jones Chronicles" by Corey Carrier, Sean Patrick Flanery, and George Hall. Doug Lee has supplied Jones's voice to two LucasArts video games, "Indiana Jones and the Fate of Atlantis" and "Indiana Jones and the Infernal Machine", while David Esch supplied his voice to "Indiana Jones and the Emperor's Tomb" and John Armstrong in "Indiana Jones and the Staff of Kings".
Particularly notable facets of the character include his iconic look (bullwhip, fedora, satchel and leather jacket), sense of humor, deep knowledge of many ancient civilizations and languages, and fear of snakes.
Since his first appearance in "Raiders of the Lost Ark", Indiana Jones has become a worldwide star and remains one of cinema's most revered film characters. In 2003, the American Film Institute ranked him as the second greatest film hero of all time. He was also named the 6th Greatest Movie Character by "Empire" magazine. "Entertainment Weekly" ranked Indy 2nd on their list of The All-Time Coolest Heroes in Pop Culture. "Premiere" magazine also placed Indy at number 7 on their list of The 100 Greatest Movie Characters of All Time. On their list of the 100 Greatest Fictional Characters, Fandomania.com ranked Indy at number 10.
Appearances.
A native of Princeton, New Jersey, Indiana Jones was introduced in the 1981 film "Raiders of the Lost Ark", set in 1936. The character is an adventurer reminiscent of the 1930s film serial treasure hunters and pulp action heroes, whose research is funded by Marshall College (named after producer Frank Marshall), a fictional college in Connecticut, where he is a professor of archaeology.
In this first adventure, he is pitted against the Nazis, who are commissioned by Hitler to recover evidence related to Aryan roots of Nazism. (see Nazi archaeology). In consequence, Dr Jones travels the world to prevent them from recovering the Ark of the Covenant (see also Biblical archaeology). He is aided by Marion Ravenwood and Sallah. The Nazis are led by Jones's archrival, a Nazi-sympathizing French archaeologist named René Belloq, and Arnold Toht, a sinister Gestapo agent.
In the 1984 prequel, "Indiana Jones and the Temple of Doom", set in 1935, Jones travels to India and attempts to free enslaved children and the three Sankara stones from the bloodthirsty Thuggee cult. He is aided by Short Round, a young boy, and is accompanied by singer Willie Scott (Kate Capshaw).
The third film, 1989's "Indiana Jones and the Last Crusade", set in 1938, returned to the formula of the original, reintroducing characters such as Sallah and Marcus Brody, a scene from Professor Jones's classroom (he now teaches at Barnett College), the globe trotting element of multiple locations, and the return of the infamous Nazi mystics, this time trying to find the Holy Grail. The film's introduction, set in 1912, provided some back story to the character, specifically the origin of his fear of snakes, his use of a bullwhip, the scar on his chin, and his hat; the film's epilogue also reveals that "Indiana" is not Jones's first name, but a nickname he took from the family dog. The film was a buddy movie of sorts, teaming Jones with his father, often to comical effect. Although Lucas intended to make five Indiana Jones films, "Indiana Jones and the Last Crusade" was the last for over eighteen years, as he could not think of a good plot element to drive the next installment.
The 2008 film, "Indiana Jones and the Kingdom of the Crystal Skull", is the latest film in the series. Set in 1957, 19 years after the third film, it pits an older, wiser Indiana Jones against Soviet agents bent on harnessing the power of a crystal skull associated with extraterrestrials discovered in South America by his former colleague Harold Oxley (John Hurt). Jones is aided in his adventure by his former lover, Marion Ravenwood (Karen Allen), and her son—a young greaser named Henry "Mutt" Williams (Shia LaBeouf), later revealed to be Jones's biological child, Henry Jones III. There were rumors that Harrison Ford will not return for any future installments and LaBeouf will take over the Indy franchise. This film also reveals that Jones was recruited by the Office of Strategic Services (a predecessor department to the Central Intelligence Agency) during World War II, attaining the rank of Colonel in the United States Army and running covert operations with MI6 agent George McHale on the Soviet Union.
Television.
From 1992 to 1996, George Lucas executive-produced a television series named "The Young Indiana Jones Chronicles", aimed mainly at teenagers and older children, which showed many of the important events and historical figures of the early 20th century through the prism of Indiana Jones' life.
The show initially featured the formula of an elderly (93 to 94 years of age) lndiana Jones played by George Hall introducing a story from his youth by way of an anecdote: the main part of the episode then featured an adventure with either a young adult Indy (16 to 21 years of age) played by Sean Patrick Flanery or a child Indy (8 to 11 years) played by Corey Carrier. One episode, "Young Indiana Jones and the Mystery of the Blues", is bookended by Harrison Ford as Indiana Jones, rather than Hall. Later episodes and telemovies did not have this bookend format.
The bulk of the series centers around the young adult Indiana Jones and his activities during World War I as a 16–17 year old soldier in the Belgian Army and then as an intelligence officer and spy seconded to French intelligence. The child Indy episodes follow the boy's travels around the globe as he accompanies his parents on his father's worldwide lecture tour from 1908 to 1910.
The show provided some backstory for the films, as well as new information regarding the character. Indiana Jones was born July 1, 1899, and his middle name is Walton (Lucas's middle name). It is also mentioned that he had a sister called Suzie who died as an infant of fever, and that he eventually has a daughter and grandchildren who appear in some episode introductions and epilogues. His relationship with his father, first introduced in "Indiana Jones and the Last Crusade", was further fleshed out with stories about his travels with his father as a young boy. Indy damages or loses his right eye sometime between the events in 1957 and the early 1990s, when the "Old Indy" segments take place, as the elderly Indiana Jones wears an eyepatch.
In 1999, Lucas removed the episode introductions and epilogues by George Hall for the VHS and DVD releases, and re-edited the episodes into chronologically ordered feature-length stories. The series title was also changed to "The Adventures of Young Indiana Jones".
Video games.
The character has appeared in several officially licensed games, including LEGO Indiana Jones video games, beginning with adaptations of "Indiana Jones and the Temple of Doom", "Raiders of the Lost Ark", two adaptations of "The Last Crusade" (one with purely action mechanics, one with an adventure and puzzle based structure) and Indiana Jones' Greatest Adventures which included the storylines from all three of the original films.
Following this, the games branched off into original storylines with Indiana Jones in the Lost Kingdom, "Indiana Jones and the Fate of Atlantis", "Indiana Jones and the Infernal Machine", "Indiana Jones and the Emperor's Tomb" and "Indiana Jones and the Staff of Kings". "Emperor's Tomb" sets up Jones's companion Wu Han and the search for Nurhaci's ashes seen at the beginning of "Temple of Doom". The first two games were developed by Hal Barwood and starred Doug Lee as the voice of Indiana Jones; "Emperor's Tomb" had David Esch fill the role and "Staff of Kings" starred John Armstrong.
"Indiana Jones and the Infernal Machine" was the first Indy-based game presented in three dimensions, as opposed to 8-bit graphics and side-scrolling games before.
There is also a small game from Lucas Arts "Indiana Jones and His Desktop Adventures". A video game was made for young Indy called "Young Indiana Jones and the Instruments of Chaos", as well as a video game version of "The Young Indiana Jones Chronicles".
Two Lego Indiana Jones games have also been released. ' was released in 2008 and follows the plots of the first three films. It was followed by ' in late 2009. The sequel includes an abbreviated reprise of the first three films, but focuses on the plot of "Indiana Jones and the Kingdom of the Crystal Skull".
Indiana Jones has also made cameo appearances as an unlockable character in the games ' and '.
Social gaming company Zynga introduced Indiana Jones to their "Adventure World" game in late 2011.
Books.
In 2008, Random House commissioned James Rollins to write the novelization of the film "Indiana Jones and the Kingdom of the Crystal Skull" (2008), which was published in 2010.
Theme parks.
Indiana Jones is featured at several Walt Disney theme park attractions. The Indiana Jones Adventure attractions at Disneyland and Tokyo DisneySea ("Temple of the Forbidden Eye" and "Temple of the Crystal Skull," respectively) place Indy at the forefront of two similar archaeological discoveries. These two temples each contain a wrathful deity who threatens the guests who ride through in World War II troop transports. The attractions, some of the most expensive of their kind at the time, opened in 1995 and 2001, respectively, with sole design credit attributed to Walt Disney Imagineering. Disney did not originally license Harrison Ford's likeness for the American version; nonetheless, a differentiated Indiana Jones audio-animatronic character appears at three points in both attractions. However, the Indiana Jones featured in the DisneySea version does use Harrison Ford's likeness but uses Japanese audio for all of his speaking parts. In 2010, some of the Indy audio-animatronics at the Disneyland version were replaced with ones resembling Ford.
Disneyland Paris also features an Indiana Jones-titled ride where people speed off through ancient ruins in a runaway mine wagon similar to that found in "Indiana Jones and the Temple of Doom". "Indiana Jones and the Temple of Peril" is a looping roller coaster engineered by Intamin, designed by Walt Disney Imagineering, and opened in 1993.
The "Indiana Jones Epic Stunt Spectacular!" is a live show that has been presented in the Disney's Hollywood Studios theme park of the Walt Disney World Resort with few changes since the park's 1989 opening, as Disney-MGM Studios. The 25-minute show presents various stunts framed in the context of a feature film production, and recruits members of the audience to participate in the show. Stunt artists in the show re-create and ultimately reveal some of the secrets of the stunts of the "Raiders of the Lost Ark" films, including the well-known "running-from-the-boulder" scene. Stunt performer Anislav Varbanov was fatally injured in August 2009, while rehearsing the popular show. Also at Disney's Hollywood Studios, an audio-animatronic Indiana Jones appears in another attraction; during the The Great Movie Ride's "Raiders of the Lost Ark" segment.
Character description and formation.
In his role as a college professor of archaeology, Henry Jones Jr. is scholarly and learned in a tweed suit, lecturing on ancient civilizations. In "Indiana Jones and the Kingdom of the Crystal Skull", it is revealed that Jones is influenced by the Marxist Archaeologist, Vere Gordon Childe, whose qualified acceptance of cultural diffusionism theory he propounds. Ironically, though Childe loathes fieldwork, Indy goes on to say, "If you want to be a good archaeologist, you gotta get out of the library." This is in tongue-in-cheek contrast to the previous film's comment, "Seventy percent of all archaeology is done in the library."
However, at the opportunity to recover important artifacts, Dr. Jones transforms into "Indiana," a "non-superhero superhero" image he has concocted for himself. Producer Frank Marshall said, "Indy [is] a fallible character. He makes mistakes and gets hurt. [...] That's the other thing people like: He's a real character, not a character with superpowers." Spielberg said there "was the willingness to allow our leading man to get hurt and to express his pain and to get his mad out and to take pratfalls and sometimes be the butt of his own jokes. I mean, Indiana Jones is not a perfect hero, and his imperfections, I think, make the audience feel that, with a little more exercise and a little more courage, they could be just like him." According to Spielberg biographer Douglas Brode, Indiana created his heroic figure so as to escape the dullness of teaching at a school. Both of Indiana's personas reject one another in philosophy, creating a duality. Harrison Ford said the fun of playing the character was because Indiana is both a romantic and a cynic, while scholars have analyzed Indiana as having traits of a lone wolf; a man on a quest; a noble treasure hunter; a hardboiled detective; a human superhero; and an American patriot.
Like many characters in his films, Jones has some autobiographical elements of Spielberg. Indiana lacks a proper father figure because of his strained relationship with his father, Henry Senior. His own contained anger is misdirected towards Professor Abner Ravenwood, his mentor at the University of Chicago, leading to a strained relationship with Marion Ravenwood. The teenage Indiana bases his own look on a figure from the prologue of "Indiana Jones and the Last Crusade", after being given his hat. Marcus Brody acts as Indiana's positive role model at the college. Indiana's own insecurities are made worse by the absence of his mother. In "Indiana Jones and the Temple of Doom", he becomes the father figure to Willie Scott and Short Round, to survive; he is rescued from Kali's evil by Short Round's dedication. Indiana also saves many enslaved children.
Because of Indiana's strained relationship with his father, who was absent much of Indiana's youth searching for the Holy Grail, the character does not pursue the more spiritual aspects of the cultures he studies. Indiana uses his knowledge of Shiva to defeat Mola Ram. In "Raiders", however, he is wise enough to close his eyes in the presence of God in the Ark of the Covenant. By contrast, his rival Rene Belloq is killed for having the audacity to try to communicate directly with God.
In the prologue of "Indiana Jones and the Last Crusade", Jones is seen as a teenager, establishing his look when given a hat. Indiana's intentions are revealed as prosocial, as he believes artifacts "belong in a museum." In the film's climax, Indiana undergoes "literal" tests of faith to retrieve the Grail and save his father's life. He also remembers Jesus as a historical figure – a humble carpenter – rather than an exalted figure when he recognizes the simple nature and tarnished appearance of the real Grail amongst a large assortment of much more ornately decorated ones. Henry Senior rescues his son from falling to his death when reaching for the fallen Grail, telling him to "let it go," overcoming his mercenary nature. "The Young Indiana Jones Chronicles" explains how Indiana becomes solitary and less idealistic following his service in World War I. In "Indiana Jones and the Kingdom of the Crystal Skull", Jones is older and wiser, whereas his sidekicks Mutt and Mac are youthfully arrogant and greedy, respectively.
Origins and inspirations.
Indiana Jones is modeled after the strong-jawed heroes of the matinée serials and pulp magazines that George Lucas and Steven Spielberg enjoyed in their childhoods (such as the Republic Pictures serials, and the Doc Savage series). Sir H. Rider Haggard's safari guide/big game hunter Allan Quatermain of "King Solomon's Mines", who dates back to 1885, is a notable template for Jones. The two friends first discussed the project in Hawaii around the time of the release of the first "" film. Spielberg told Lucas how he wanted his next project to be something fun, like a James Bond film (this would later be referenced when they cast Sean Connery as Henry Jones, Sr.). According to sources, Lucas responded to the effect that he had something "even better," or that he'd "got that beat."
One of the possible bases for Indiana Jones are Professor Challenger, created by Sir Arthur Conan Doyle in 1912 for his novel, "The Lost World". Challenger was based on Doyle's physiology professor, Sir William Rutherford, an adventuring academic, albeit a zoologist/anthropologist.
The character was originally named Indiana Smith, after an Alaskan Malamute called Indiana that Lucas owned in the 1970s. The name was perhaps in a nod to the 1966 Western film "Nevada Smith". Spielberg disliked the name Smith, and Lucas casually suggested Jones as an alternative. The "Last Crusade" script references the name's origin, with Jones's father revealing his son's birth name to be Henry and explaining that "we named the "dog" Indiana", to his son's chagrin.
Lucas has said on various occasions that Sean Connery's portrayal of British secret agent James Bond was one of the primary inspirations for Jones, a reason Connery was chosen for the role of Indiana's father in "Indiana Jones and the Last Crusade". Given that both Spielberg and Ford were Eagle and Life Scouts, respectively, in their youth, gave them the inspiration to portray Indiana Jones as a Life Scout at age 13 in "The Last Crusade", mirroring Ford's Scouting past.
Costume designer Deborah Nadoolman Landis noted that the inspiration for the series as well as Indiana Jones' outfit was Charlton Heston's Harry Steele in "Secret of the Incas" (1954) and called "Raiders of the Lost Ark" "almost a shot for shot" remake of the Heston film, citing that Indiana Jones was "a kinder, gentler Harry Steele": "We did watch this film together as a crew several times, and I always thought it strange that the filmmakers did not credit it later as the inspiration for the series."
Historical models.
Many people are said to be the real-life inspiration of the Indiana Jones character—although none of the following have been confirmed as inspirations by Lucas or Spielberg. There are some suggestions, listed here in alphabetical order by last name:
Costume.
Upon requests by Spielberg and Lucas, the costume designer gave the character a distinctive silhouette through the styling of the hat; after examining many hats, the designers chose a tall-crowned, wide-brimmed fedora. As a documentary of "Raiders" pointed out, the hat served a practical purpose. Following the lead of the old "B"-movies that inspired the "Indiana Jones" series, the fedora hid the actor's face sufficiently to allow doubles to perform the more dangerous stunts seamlessly. Examples in "Raiders" include the wider-angle shot of Indy and Marion crashing a statue through a wall, and Indy sliding under a fast-moving vehicle from front to back. Thus it was necessary for the hat to stay in place much of the time.
The hat became so iconic that the filmmakers could only come up with very good reasons or jokes to remove it. If it ever fell off during a take, filming would have to stop to put it back on. In jest, Ford put a stapler against his head to stop his hat from falling off when a documentary crew visited during shooting of "Indiana Jones and the Last Crusade". This created the urban legend that Ford stapled the hat to his head. Although other hats were also used throughout the films, the general style and profile remained the same. Elements of the outfit include:
The fedora and leather jacket from "Indiana Jones and the Last Crusade" are on display at the Smithsonian Institution's American History Museum in Washington, D.C. The collection of props and clothing from the films has become a thriving hobby for some aficionados of the franchise. Jones' whip was the third most popular film weapon, as shown by a 2008 poll held by 20th Century Fox, which surveyed approximately two thousand film fans.
Casting.
Originally, Spielberg suggested Harrison Ford; Lucas resisted the idea, since he had already cast the actor in "American Graffiti", "Star Wars" and "", and did not want Ford to become known as his "Bobby De Niro" (in reference to the fact that fellow director Martin Scorsese regularly casts Robert De Niro in his films). During an intensive casting process, Lucas and Spielberg auditioned many actors, and finally cast actor Tom Selleck as Indiana Jones. Shortly afterward pre-production began in earnest on "Raiders of the Lost Ark". However, CBS refused to release Selleck from his contractual commitment to "Magnum, P.I." (which was gradually gaining momentum in the ratings), forcing him to turn down the role. One of CBS's concerns was that shooting for "Magnum P.I." conflicted with shooting for "Raiders", both of which were to begin about the same time. However, Selleck was to say later in an interview that shooting for "Magnum P.I." was delayed and did not actually begin until shooting for "Raiders" had concluded.
After Spielberg suggested Ford again, Lucas gave in, and Ford was cast in the role less than three weeks before filming began.
Archaeological influence.
For many within the public spectrum, Indiana Jones is the image that comes to mind when archaeology is mentioned. The industry magazine Archaeology, named eight past and present archaeologists who they felt "embodied [Jones'] spirit" as recipients of the "Indy Spirit Awards" in 2008. That same year Ford himself was elected to the Board of Directors for the Archaeological Institute of America; commenting that "understanding the past can only help us in dealing with the present and the future," Ford was praised by the association's president for his character's "significant role in stimulating the public's interest in archaeological exploration."
He is perhaps the most influential character in films that explore archaeology, since the release of ‘Indiana Jones and the Raiders of the Lost Ark’ in 1981, the very idea of archaeology and archaeologists has fundamentally shifted. Prior to the films release, the stereotypical image of an archaeologist was that of an older, lacklustre professor type. In the early years of films involving archaeologists, they were portrayed as victims who would need to be rescued by a more masculine or heroic figure. Following 1981, the stereotypical archaeologist is thought of as a male bull whip wielding adventurer and Ivy League professor. The stereotypical image of an archaeologist is also portrayed as an individual usually out doing fieldwork, which is not always the case.
Indiana Jones is essentially the archetype for the field of archaeology, individuals who are actively involved in this field are influenced by the ideas put forward in the films and any other associated media. Indiana Jones is still a highly debated topic among archaeologists, whether the influence of these films is positive or negative has yet to be determined. The argument for these films having a negative influence states that it reflects poorly on the field, one prominent individual with this opinion is Anne Pyburn. Pyburn described the influence of Indiana Jones as being one that is elitist and sexist, she went on to say that the Indiana Jones films have caused new discoveries in the field of archaeology to become oversimplified and overhyped in an attempt to gain public interest which negatively influences archaeology as a whole. Eric Powell, an editor with the magazine Archaeology, was quoted saying “O.K., fine, the movie romanticizes what we do,” continuing on to say that “Indy may be a horrible archeologist, but he’s a great diplomat for archeology. I think we’ll see a spike in kids who want to become archeologists.” In an article written by Kevin McGeoughs, an associate professor of archaeology, he describes the original archaeological criticism of the film as missing the point of the film. Going on to say that the various critiques of poor excavation techniques used were a plot feature to make the film more enjoyable and that in doing so it is not trying to push an agenda. He finished by saying, "dramatic interest is what is at issue, and it is unlikely that film will change in order to promote and foster better archaeological techniques".
A 2007 survey conducted at Lycoming College set out to examine the public perception of archaeology and what an archaeologist looks like. The results from this survey indicated that the majority of participants all formed a similar image of an archaeologist, the picture painted is one of a male dressed in light weight khaki clothing, wearing a “Indiana Jones hat” and would typically be found in a desert or exotic location. In addition individuals described that the archaeologist would potentially have to become destructive or involved in dangerous situations to obtain the wanted artifacts, demonstrating an adventurer personality.
Popular culture influence.
While himself a homage to various prior adventurers, aspects of Indiana Jones also directly influenced some subsequent characterizations:

</doc>
<doc id="14822" url="http://en.wikipedia.org/wiki?curid=14822" title="Irreducible fraction">
Irreducible fraction

An irreducible fraction (or fraction in lowest terms or reduced fraction) is a fraction in which the numerator and denominator are integers that have no other common divisors than 1 (and -1, when negative numbers are considered). In other words, a fraction a⁄b is irreducible if and only if "a" and "b" are coprime, that is, if "a" and "b" have a greatest common divisor of 1. In higher mathematics, "irreducible fraction" may also refer to rational fractions such that the numerator and the denominator are coprime polynomials. Every positive rational number can be represented as an irreducible fraction in exactly one way.
An equivalent definition is sometimes useful: if "a", "b" are integers, then the fraction "a"⁄"b" is irreducible if and only if there is no other equal fraction "c"⁄"d" such that |"c"| < |"a"| or |"d"| < |"b"|, where |"a"| means the absolute value of "a". (Two fractions "a"⁄"b" and "c"⁄"d" are "equal" or "equivalent" if and only if "ad" = "bc".)
For example, 1⁄4, 5⁄6, and −101⁄100 are all irreducible fractions. On the other hand, 2⁄4 is reducible since it is equal in value to 1⁄2, and the numerator of 1⁄2 is less than the numerator of 2⁄4.
A fraction that is reducible can be reduced by dividing both the numerator and denominator by a common factor. It can be fully reduced to lowest terms if both are divided by their greatest common divisor. In order to find the greatest common divisor, the Euclidean algorithm or prime factorization may be used. The Euclidean algorithm is commonly preferred because it allows one to reduce fractions with numerators and denominators too large to be easily factored.
Examples.
In the first step both numbers were divided by 10, which is a factor common to both 120 and 90. In the second step, they were divided by 3. The final result, 4/3, is an irreducible fraction because 4 and 3 have no common factors other than 1.
The original fraction could have also been reduced in a single step by using the greatest common divisor of 90 and 120, which is 30 (i.e., gcd(90,120)=30).
Which method is faster "by hand" depends on the fraction and the ease with which common factors are spotted. In case a denominator and numerator remain that are too large to ensure they are coprime by inspection, a greatest common divisor computation is needed anyway to ensure the fraction is actually irreducible.
Uniqueness.
Every rational number has a "unique" representation as an irreducible fraction with a positive denominator (however formula_3 although both are irreducible). Uniqueness is a consequence of the unique prime factorization of integers, since formula_4 implies "ad" = "bc" and so both sides of the latter must share the same prime factorization, yet formula_5 and formula_6 share no prime factors so the set of prime factors of formula_5 (with multiplicity) is a subset of those of formula_8 and vice versa meaning formula_9 and formula_10.
Applications.
The fact that any rational number has a unique representation as an irreducible fraction is utilized in various proofs of the irrationality of the square root of 2 and of other irrational numbers. For example, one proof notes that if the square root of 2 could be represented as a ratio of integers, then it would have in particular the fully reduced representation formula_11 where "a" and "b" are the smallest possible; but given that formula_11 equals the square root of 2, so does formula_13 (since cross-multiplying this with formula_11 shows that they are equal). Since the latter is a ratio of smaller integers, this is a contradiction, so the premise that the square root of two has a representation as the ratio of two integers is false.
Generalization.
The notion of irreducible fraction generalizes to the field of fractions of any unique factorization domain: any element of such a field can be written as a fraction in which denominator and numerator are coprime, by dividing both by their greatest common divisor. This applies notably to rational expressions over a field. The irreducible fraction for a given element is unique up to multiplication of denominator and numerator by the same invertible element. In the case of the rational numbers this means that any number has two irreducible fractions, related by a change of sign of both numerator and denominator; this ambiguity can be removed by requiring the denominator to be positive. In the case of rational functions the denominator could similarly be required to be a monic polynomial.

</doc>
<doc id="14826" url="http://en.wikipedia.org/wiki?curid=14826" title="Isomorphism class">
Isomorphism class

An isomorphism class is a collection of mathematical objects isomorphic to each other. 
Isomorphism classes are often defined if the exact identity of the elements of the set is considered irrelevant, and the properties of the structure of the mathematical object are studied. Examples of this are ordinals and graphs. However, there are circumstances in which the isomorphism class of an object conceals vital internal information about it; consider these examples:

</doc>
<doc id="14828" url="http://en.wikipedia.org/wiki?curid=14828" title="Isomorphism">
Isomorphism

In mathematics, an isomorphism (from the Ancient Greek: ἴσος "isos" "equal", and μορφή "morphe" "shape") is a homomorphism (or more generally a morphism) that admits an inverse. Two mathematical objects are isomorphic if an isomorphism exists between them. An "automorphism" is an isomorphism whose source and target coincide. The interest of isomorphisms lies in the fact that two isomorphic objects cannot be distinguished by using only the properties used to define morphisms; thus isomorphic objects may be considered the same as long as one considers only these properties and their consequences.
For most algebraic structures, including groups and rings, a homomorphism is an isomorphism if and only if it is bijective.
In topology, where the morphisms are continuous functions, isomorphisms are also called "homeomorphisms" or "bicontinuous functions". In mathematical analysis, where the morphisms are differentiable functions, isomorphisms are also called "diffeomorphisms".
A canonical isomorphism is a canonical map that is an isomorphism. Two objects are said to be canonically isomorphic if there is a canonical isomorphism between them. For example, the canonical map from a finite-dimensional vector space "V" to its second dual space is a canonical isomorphism; on the other hand, "V" is isomorphic to its dual space but not canonically in general.
Isomorphisms are formalized using category theory. A morphism "f" : "X" → "Y" in a category is an isomorphism if it admits a two-sided inverse, meaning that there is another morphism "g" : "Y" → "X" in that category such that and , where 1"X" and 1"Y" are the identity morphisms of "X" and "Y", respectively.
Examples.
Logarithm and exponential.
Let formula_1 be the multiplicative group of positive real numbers, and let formula_2 be the additive group of real numbers.
The logarithm function formula_3 satisfies formula_4 for all formula_5, so it is a group homomorphism. The exponential function formula_6 satisfies formula_7 for all formula_8, so it too is a homomorphism. The identities formula_9 and formula_10 show that formula_11 and formula_12 are inverses of each other. Since formula_11 is a homomorphism that has an inverse that is also a homomorphism, formula_11 is an isomorphism of groups.
Because formula_11 is an isomorphism, it translates multiplication of positive real numbers into addition of real numbers. This is what makes it possible to multiply real numbers using a ruler and a table of logarithms, or using a slide rule with a logarithmic scale.
Integers modulo 6.
Consider the group formula_16, the integers from 0 to 5 with addition modulo 6. Also consider the group formula_17, the ordered pairs where the "x" coordinates can be 0 or 1, and the y coordinates can be 0, 1, or 2, where addition in the "x"-coordinate is modulo 2 and addition in the "y"-coordinate is modulo 3.
These structures are isomorphic under addition, if you identify them using the following scheme:
or in general ("a","b") → (3"a" + 4"b") mod 6.
For example note that (1,1) + (1,0) = (0,1), which translates in the other system as 1 + 3 = 4.
Even though these two groups "look" different in that the sets contain different elements, they are indeed isomorphic: their structures are exactly the same. More generally, the direct product of two cyclic groups formula_18 and formula_19 is isomorphic to formula_20 if and only if "m" and "n" are coprime.
Relation-preserving isomorphism.
If one object consists of a set "X" with a binary relation R and the other object consists of a set "Y" with a binary relation S then an isomorphism from "X" to "Y" is a bijective function ƒ: "X" → "Y" such that:
S is reflexive, irreflexive, symmetric, antisymmetric, asymmetric, transitive, total, trichotomous, a partial order, total order, strict weak order, total preorder (weak order), an equivalence relation, or a relation with any other special properties, if and only if R is.
For example, R is an ordering ≤ and S an ordering formula_22, then an isomorphism from "X" to "Y" is a bijective function ƒ: "X" → "Y" such that
Such an isomorphism is called an "order isomorphism" or (less commonly) an "isotone isomorphism".
If "X" = "Y", then this is a relation-preserving automorphism.
Isomorphism vs. bijective morphism.
In a concrete category (that is, roughly speaking, a category whose objects are sets and morphisms are mappings between sets), such as the category of topological spaces or categories of algebraic objects like groups, rings, and modules, an isomorphism must be bijective on the underlying sets. In algebraic categories (specifically, categories of varieties in the sense of universal algebra), an isomorphism is the same as a homomorphism which is bijective on underlying sets. However, there are concrete categories in which bijective morphisms are not necessarily isomorphisms (such as the category of topological spaces), and there are categories in which each object admits an underlying set but in which isomorphisms need not be bijective (such as the homotopy category of CW-complexes).
Applications.
In abstract algebra, two basic isomorphisms are defined:
Just as the automorphisms of an algebraic structure form a group, the isomorphisms between two algebras sharing a common structure form a heap. Letting a particular isomorphism identify the two structures turns this heap into a group.
In mathematical analysis, the Laplace transform is an isomorphism mapping hard differential equations into easier algebraic equations.
In category theory, Iet the category "C" consist of two classes, one of "objects" and the other of morphisms. Then a general definition of isomorphism that covers the previous and many other cases is: an isomorphism is a morphism ƒ: "a" → "b" that has an inverse, i.e. there exists a morphism "g": "b" → "a" with "ƒg" = 1"b" and "gƒ" = 1"a". For example, a bijective linear map is an isomorphism between vector spaces, and a bijective continuous function whose inverse is also continuous is an isomorphism between topological spaces, called a homeomorphism.
In graph theory, an isomorphism between two graphs "G" and "H" is a bijective map "f" from the vertices of "G" to the vertices of "H" that preserves the "edge structure" in the sense that there is an edge from vertex "u" to vertex "v" in "G" if and only if there is an edge from ƒ("u") to ƒ("v") in "H". See graph isomorphism.
In mathematical analysis, an isomorphism between two Hilbert spaces is a bijection preserving addition, scalar multiplication, and inner product.
In early theories of logical atomism, the formal relationship between facts and true propositions was theorized by Bertrand Russell and Ludwig Wittgenstein to be isomorphic. An example of this line of thinking can be found in Russell's Introduction to Mathematical Philosophy.
In cybernetics, the Good Regulator or Conant-Ashby theorem is stated "Every Good Regulator of a system must be a model of that system". Whether regulated or self-regulating an isomorphism is required between regulator part and the processing part of the system.
Relation with equality.
In certain areas of mathematics, notably category theory, it is valuable to distinguish between "equality" on the one hand and "isomorphism" on the other. Equality is when two objects are exactly the same, and everything that's true about one object is true about the other, while an isomorphism implies everything that's true about a designated part of one object's structure is true about the other's. For example, the sets
are "equal"; they are merely different presentations—the first an intensional one (in set builder notation), and the second extensional (by explicit enumeration)—of the same subset of the integers. By contrast, the sets {"A","B","C"} and {1,2,3} are not "equal"—the first has elements that are letters, while the second has elements that are numbers. These are isomorphic as sets, since finite sets are determined up to isomorphism by their cardinality (number of elements) and these both have three elements, but there are many choices of isomorphism—one isomorphism is
and no one isomorphism is intrinsically better than any other. On this view and in this sense, these two sets are not equal because one cannot consider them "identical": one can choose an isomorphism between them, but that is a weaker claim than identity—and valid only in the context of the chosen isomorphism.
Sometimes the isomorphisms can seem obvious and compelling, but are still not equalities. As a simple example, the genealogical relationships among Joe, John, and Bobby Kennedy are, in a real sense, the same as those among the American football quarterbacks in the Manning family: Archie, Peyton, and Eli. The father-son pairings and the elder-brother-younger-brother pairings correspond perfectly. That similarity between the two family structures illustrates the origin of the word "isomorphism" (Greek "iso"-, "same," and -"morph", "form" or "shape"). But because the Kennedys are not the same people as the Mannings, the two genealogical structures are merely isomorphic and not equal.
Another example is more formal and more directly illustrates the motivation for distinguishing equality from isomorphism: the distinction between a finite-dimensional vector space "V" and its dual space "V"* = { φ: V → K} of linear maps from "V" to its field of scalars K.
These spaces have the same dimension, and thus are isomorphic as abstract vector spaces (since algebraically, vector spaces are classified by dimension, just as sets are classified by cardinality), but there is no "natural" choice of isomorphism formula_28.
If one chooses a basis for "V", then this yields an isomorphism: For all "u". "v" ∈ "V",
This corresponds to transforming a column vector (element of "V") to a row vector (element of "V"*) by transpose, but a different choice of basis gives a different isomorphism: the isomorphism "depends on the choice of basis".
More subtly, there "is" a map from a vector space "V" to its double dual "V"** = { "x": "V"* → K} that does not depend on the choice of basis: For all "v" ∈ "V" and φ ∈ "V"*,
This leads to a third notion, that of a natural isomorphism: while "V" and "V"** are different sets, there is a "natural" choice of isomorphism between them.
This intuitive notion of "an isomorphism that does not depend on an arbitrary choice" is formalized in the notion of a natural transformation; briefly, that one may "consistently" identify, or more generally map from, a vector space to its double dual, formula_31, for "any" vector space in a consistent way.
Formalizing this intuition is a motivation for the development of category theory.
However, there is a case where the distinction between natural isomorphism and equality is usually not made. That is for the objects that may be characterized by a universal property. In fact, there is a unique isomorphism, necessarily natural, between two objects sharing the same universal property. A typical example is the set of real numbers, which may be defined through infinite decimal expansion, infinite binary expansion, Cauchy sequences, Dedekind cuts and many other ways. Formally these constructions define different objects, which all are solutions of the same universal property. As these objects have exactly the same properties, one may forget the method of construction and considering them as equal. This is what everybody does when talking of ""the" set of the real numbers". The same occurs with quotient spaces: they are commonly constructed as sets of equivalence classes. However, talking of set of sets may be counterintuitive, and quotient spaces are commonly considered as a pair of a set of undetermined objects, often called "points", and a surjective map onto this set.
If one wishes to draw a distinction between an arbitrary isomorphism (one that depends on a choice) and a natural isomorphism (one that can be done consistently), one may write ≈ for an unnatural isomorphism and ≅ for a natural isomorphism, as in "V" ≈ "V"* and "V" ≅ "V"**.
This convention is not universally followed, and authors who wish to distinguish between unnatural isomorphisms and natural isomorphisms will generally explicitly state the distinction.
Generally, saying that two objects are "equal" is reserved for when there is a notion of a larger (ambient) space that these objects live in. Most often, one speaks of equality of two subsets of a given set (as in the integer set example above), but not of two objects abstractly presented. For example, the 2-dimensional unit sphere in 3-dimensional space
which can be presented as the one-point compactification of the complex plane C ∪ {∞} "or" as the complex projective line (a quotient space)
are three different descriptions for a mathematical object, all of which are isomorphic, but not "equal" because they are not all subsets of a single space: the first is a subset of R3, the second is C ≅ R2 plus an additional point, and the third is a subquotient of C2
In the context of category theory, objects are usually at most isomorphic—indeed, a motivation for the development of category theory was showing that different constructions in homology theory yielded equivalent (isomorphic) groups. Given maps between two objects "X" and "Y", however, one asks if they are equal or not (they are both elements of the set Hom("X", "Y"), hence equality is the proper relationship), particularly in commutative diagrams.

</doc>
<doc id="14829" url="http://en.wikipedia.org/wiki?curid=14829" title="Infinite descending chain">
Infinite descending chain

Given a set "S" with a partial order ≤, an infinite descending chain is an infinite, strictly decreasing sequence of elements "x1 > x2 > ... > xn > ..."
As an example, in the set of integers, the chain −1, −2, −3, ... is an infinite descending chain, but there exists no infinite descending chain on the natural numbers, as every chain of natural numbers has a minimal element.
If a partially ordered set does not possess any infinite descending chains, it is said then, that it satisfies the descending chain condition. Assuming the axiom of choice, the descending chain condition on a partially ordered set is equivalent to requiring that the corresponding strict order is well-founded. A stronger condition, that there be no infinite descending chains and no infinite antichains, defines the well-quasi-orderings. A totally ordered set without infinite descending chains is called well-ordered.

</doc>
<doc id="14831" url="http://en.wikipedia.org/wiki?curid=14831" title="Public international law">
Public international law

Public international law concerns the structure and conduct of sovereign states; analogous entities, such as the Holy See; and intergovernmental organizations. To a lesser degree, international law also may affect multinational corporations and individuals, an impact increasingly evolving beyond domestic legal interpretation and enforcement. Public international law has increased in use and importance vastly over the twentieth century, due to the increase in global trade, environmental deterioration on a worldwide scale, awareness of human rights violations, rapid and vast increases in international transportation and a boom in global communications.
The field of study combines two main branches: the law of nations ("jus gentium") and international agreements and conventions ("jus inter gentes").
Public international law is usually distinguished from "private international law", which concerns the resolution of conflict of laws. In its most general sense, international law "consists of rules and principles of general application dealing with the conduct of states and of intergovernmental organizations and with their relations "inter se", as well as with some of their relations with persons, whether natural or juridical."
History.
Beginning with the Peace of Westphalia in 1648, the 17th, 18th and 19th centuries saw the growth of the concept of the sovereign "nation-state", which consisted of a nation controlled by a centralized system of government. The concept of nationalism became increasingly important as people began to see themselves as citizens of a particular nation with a distinct national identity. Until the mid-19th century, relations between nation-states were dictated by treaty, agreements to behave in a certain way towards another state, unenforceable except by force, and not binding except as matters of honor and faithfulness. But treaties alone became increasingly toothless and wars became increasingly destructive, most markedly towards civilians, and civilized peoples decried their horrors, leading to calls for regulation of the acts of states, especially in times of war.
Perhaps the first instrument of modern public international law was the Lieber Code, passed in 1863 by the Congress of the United States, to govern the conduct of US forces during the United States Civil War and considered to be the first written recitation of the rules and articles of war, adhered to by all civilized nations, the precursor of public international law. Part of the Code follows:
"Military necessity, as understood by modern civilized nations, consists in the necessity of those measures which are indispensable for securing the ends of the war, and which are lawful according to the modern law and usages of war. Military necessity admits of all direct destruction of life or limb of armed enemies, and of other persons whose destruction is incidentally unavoidable in the armed contests of the war; it allows of the capturing of every armed enemy, and every enemy of importance to the hostile government, or of peculiar danger to the captor; it allows of all destruction of property, and obstruction of the ways and channels of traffic, travel, or communication, and of all withholding of sustenance or means of life from the enemy; of the appropriation of whatever an enemy's country affords necessary for the subsistence and safety of the Army, and of such deception as does not involve the breaking of good faith either positively pledged, regarding agreements entered into during the war, or supposed by the modern law of war to exist. (...But...) Men who take up arms against one another in public war do not cease on this account to be moral beings, responsible to one another and to God. Military necessity does not admit of cruelty—that is, the infliction of suffering for the sake of suffering or for revenge, nor of maiming or wounding except in fight, nor of torture to extort confessions. It does not admit of the use of poison in any way, nor of the wanton devastation of a district. It admits of deception, but disclaims acts of perfidy; and, in general, military necessity does not include any act of hostility which makes the return to peace unnecessarily difficult."
This first statement of the previously uncodified rules and articles of war led to the first prosecution for war crimes—in the case of United States prisoners of war held in cruel and depraved conditions at Andersonville, Georgia, in which the Confederate commandant of that camp was tried and hanged, the only Confederate soldier to be punished by death in the aftermath of the entire Civil War.
In the years that followed, other states subscribed to limitations of their conduct, and numerous other treaties and bodies were created to regulate the conduct of states towards one another in terms of these treaties, including, but not limited to, the Permanent Court of Arbitration in 1899; the Hague and Geneva Conventions, the first of which was passed in 1864; the International Court of Justice in 1921; the Genocide Convention; and the International Criminal Court, in the late 1990s. Because international law is a relatively new area of law its development and propriety in applicable areas are often subject to dispute.
International relations.
Under article 38 of the Statute of the International Court of Justice, public international law has three principal sources: international treaties, custom, and general principles of law. In addition, judicial decisions and teachings may be applied as "subsidiary means for the determination of rules of law".
International treaty law comprises obligations states expressly and voluntarily accept between themselves in treaties. Customary international law is derived from the consistent practice of States accompanied by "opinio juris", i.e. the conviction of States that the consistent practice is required by a legal obligation. Judgments of international tribunals as well as scholarly works have traditionally been looked to as persuasive sources for custom in addition to direct evidence of state behavior. Attempts to codify customary international law picked up momentum after the Second World War with the formation of the International Law Commission (ILC), under the aegis of the United Nations. Codified customary law is made the binding interpretation of the underlying custom by agreement through treaty. For states not party to such treaties, the work of the ILC may still be accepted as custom applying to those states. General principles of law are those commonly recognized by the major legal systems of the world. Certain norms of international law achieve the binding force of peremptory norms ("jus cogens") as to include all states with no permissible derogations.
Treaties.
Where there are disputes about the exact meaning and application of national laws, it is the responsibility of the courts to decide what the law means. In international law interpretation is within the domain of the protagonists, but may also be conferred on judicial bodies such as the International Court of Justice, by the terms of the treaties or by consent of the parties. It is generally the responsibility of states to interpret the law for themselves, but the processes of diplomacy and availability of supra-national judicial organs operate routinely to provide assistance to that end.
Insofar as treaties are concerned, the Vienna Convention on the Law of Treaties writes on the topic of interpretation that:
This is actually a compromise between three different theories of interpretation:
These are general rules of interpretation; specific rules might exist in specific areas of international law.
Statehood and responsibility.
Public international law establishes the framework and the criteria for identifying states as the principal actors in the international legal system. As the existence of a state presupposes control and jurisdiction over territory, international law deals with the acquisition of territory, state immunity and the legal responsibility of states in their conduct with each other. International law is similarly concerned with the treatment of individuals within state boundaries. There is thus a comprehensive regime dealing with group rights, the treatment of aliens, the rights of refugees, international crimes, nationality problems, and human rights generally. It further includes the important functions of the maintenance of international peace and security, arms control, the pacific settlement of disputes and the regulation of the use of force in international relations. Even when the law is not able to stop the outbreak of war, it has developed principles to govern the conduct of hostilities and the treatment of prisoners. International law is also used to govern issues relating to the global environment, the global commons such as international waters and outer space, global communications, and world trade.
In theory all states are sovereign and equal. As a result of the notion of sovereignty, the value and authority of international law is dependent upon the voluntary participation of states in its formulation, observance, and enforcement. Although there may be exceptions, it is thought by many international academics that most states enter into legal commitments with other states out of enlightened self-interest rather than adherence to a body of law that is higher than their own. As D. W. Greig notes, "international law cannot exist in isolation from the political factors operating in the sphere of international relations".
Traditionally, sovereign states and the Holy See were the sole subjects of international law. With the proliferation of international organizations over the last century, they have in some cases been recognized as relevant parties as well. Recent interpretations of international human rights law, international humanitarian law, and international trade law (e.g., North American Free Trade Agreement (NAFTA) Chapter 11 actions) have been inclusive of corporations, and even of certain individuals.
The conflict between international law and national sovereignty is subject to vigorous debate and dispute in academia, diplomacy, and politics. Certainly, there is a growing trend toward judging a state's domestic actions in the light of international law and standards. Numerous people now view the nation-state as the primary unit of international affairs, and believe that only states may choose to voluntarily enter into commitments under international law, and that they have the right to follow their own counsel when it comes to interpretation of their commitments. Certain scholars and political leaders feel that these modern developments endanger nation states by taking power away from state governments and ceding it to international bodies such as the U.N. and the World Bank, argue that international law has evolved to a point where it exists separately from the mere consent of states, and discern a legislative and judicial process to international law that parallels such processes within domestic law. This especially occurs when states violate or deviate from the expected standards of conduct adhered to by all civilized nations.
A number of states place emphasis on the principle of territorial sovereignty, thus seeing states as having free rein over their internal affairs. Other states oppose this view. One group of opponents of this point of view, including many European nations, maintain that all civilized nations have certain norms of conduct expected of them, including the prohibition of genocide, slavery and the slave trade, wars of aggression, torture, and piracy, and that violation of these universal norms represents a crime, not only against the individual victims, but against humanity as a whole. States and individuals who subscribe to this view opine that, in the case of the individual responsible for violation of international law, he "is become, like the pirate and the slave trader before him, hostis humani generis, an enemy of all mankind", and thus subject to prosecution in a fair trial before any fundamentally just tribunal, through the exercise of universal jurisdiction.
Though the European democracies tend to support broad, universalistic interpretations of international law, many other democracies have differing views on international law. Several democracies, including India, Israel and the United States, take a flexible, eclectic approach, recognizing aspects of public international law such as territorial rights as universal, regarding other aspects as arising from treaty or custom, and viewing certain aspects as not being subjects of public international law at all. Democracies in the developing world, due to their past colonial histories, often insist on non-interference in their internal affairs, particularly regarding human rights standards or their peculiar institutions, but often strongly support international law at the bilateral and multilateral levels, such as in the United Nations, and especially regarding the use of force, disarmament obligations, and the terms of the UN Charter.
Courts and enforcement.
It is probably the case that almost all nations observe almost all principles of international law and almost all of their obligations almost all the time.—Louis Henkin
Since international law has no established compulsory judicial system for the settlement of disputes or a coercive penal system, it is not as straightforward as managing breaches within a domestic legal system. However, there are means by which breaches are brought to the attention of the international community and some means for resolution. For example, there are judicial or quasi-judicial tribunals in international law in certain areas such as trade and human rights. The formation of the United Nations, for example, created a means for the world community to enforce international law upon members that violate its charter through the Security Council.
Since international law exists in a legal environment without an overarching "sovereign" (i.e., an external power able and willing to compel compliance with international norms), "enforcement" of international law is very different from in the domestic context. In many cases, enforcement takes on Coasian characteristics, where the norm is self-enforcing. In other cases, defection from the norm can pose a real risk, particularly if the international environment is changing. When this happens, and if enough states (or enough powerful states) continually ignore a particular aspect of international law, the norm may actually change according to concepts of customary international law. For example, prior to World War I, unrestricted submarine warfare was considered a violation of international law and ostensibly the casus belli for the United States' declaration of war against Germany. By World War II, however, the practice was so widespread that during the Nuremberg trials, the charges against German Admiral Karl Dönitz for ordering unrestricted submarine warfare were dropped, notwithstanding that the activity constituted a clear violation of the Second London Naval Treaty of 1936.
Domestic enforcement.
Apart from a state's natural inclination to uphold certain norms, the force of international law comes from the pressure that states put upon one another to behave consistently and to honor their obligations. As with any system of law, many violations of international law obligations are overlooked. If addressed, it may be through diplomacy and the consequences upon an offending state's reputation, submission to international judicial determination, arbitration, sanctions or force including war. Though violations may be common in fact, states try to avoid the appearance of having disregarded international obligations. States may also unilaterally adopt sanctions against one another such as the severance of economic or diplomatic ties, or through reciprocal action. In some cases, domestic courts may render judgment against a foreign state (the realm of private international law) for an injury, though this is a complicated area of law where international law intersects with domestic law.
It is implicit in the Westphalian system of nation-states, and explicitly recognized under Article 51 of the Charter of the United Nations, that all states have the inherent right to individual and collective self-defense if an armed attack occurs against them. Article 51 of the UN Charter guarantees the right of states to defend themselves until (and unless) the Security Council takes measures to keep the peace.
International bodies.
Violations of the UN Charter by members of the United Nations may be raised by the aggrieved state in the General Assembly for debate. The General Assembly cannot make binding resolutions, only 'recommendations', but through its adoption of the "Uniting for Peace" resolution (A/RES/377 A), of 3 November 1950, the Assembly declared that it has the power to authorize the use of force, under the terms of the UN Charter, in cases of breaches of the peace or acts of aggression, provided that the Security Council, owing to the negative vote of a permanent member, fails to act to address the situation. The Assembly also declared, by its adoption of resolution 377 A, that it could call for other collective measures—such as economic and diplomatic sanctions—in situations constituting the milder "threat to the Peace".
The Uniting for Peace resolution was initiated by the United States in 1950, shortly after the outbreak of the Korean War, as a means of circumventing possible future Soviet vetoes in the Security Council. The legal significance of the resolution is unclear, given that the General Assembly cannot issue binding resolutions. However, it was never argued by the "Joint Seven-Powers" that put forward the draft resolution, during the corresponding discussions, that it in any way afforded the Assembly new powers. Instead, they argued that the resolution simply declared what the Assembly's powers already were, according to the UN Charter, in the case of a dead-locked Security Council. The Soviet Union was the only permanent member of the Security Council to vote against the Charter interpretations that were made law by the Assembly's adoption of resolution 377 A.
Alleged violations of the Charter can also be raised by states in the Security Council. The Security Council could subsequently pass resolutions under Chapter VI of the UN Charter to recommend the "Pacific Resolution of Disputes." Such resolutions are not binding under international law, though they usually are expressive of the Council's convictions. In rare cases, the Security Council can adopt resolutions under Chapter VII of the UN Charter, related to "threats to Peace, Breaches of the Peace and Acts of Aggression," which are legally binding under international law, and can be followed up with economic sanctions, military action, and similar uses of force through the auspices of the United Nations.
It has been argued that resolutions passed outside of Chapter VII can also be binding; the legal basis for that is the Council's broad powers under Article 24(2), which states that "in discharging these duties (exercise of primary responsibility in international peace and security), it shall act in accordance with the Purposes and Principles of the United Nations". The mandatory nature of such resolutions was upheld by the International Court of Justice (ICJ) in its advisory opinion on Namibia. The binding nature of such resolutions can be deduced from an interpretation of their language and intent.
States can also, upon mutual consent, submit disputes for arbitration by the International Court of Justice, located in The Hague, Netherlands. The judgments given by the Court in these cases are binding, although it possesses no means to enforce its rulings.
The Court may give an advisory opinion on any legal question at the request of whatever body may be authorized by or in accordance with the Charter of the United Nations to make such a request. Some of the advisory cases brought before the court have been controversial with respect to the court's competence and jurisdiction.
Often enormously complicated matters, ICJ cases (of which there have been less than 150 since the court was created from the Permanent Court of International Justice in 1945) can stretch on for years and generally involve thousands of pages of pleadings, evidence, and the world's leading specialist public international lawyers. As of June 2009, there are 15 cases pending at the ICJ. Decisions made through other means of arbitration may be binding or non-binding depending on the nature of the arbitration agreement, whereas decisions resulting from contentious cases argued before the ICJ are always binding on the involved states.
Though states (or increasingly, international organizations) are usually the only ones with standing to address a violation of international law, some treaties, such as the International Covenant on Civil and Political Rights have an optional protocol that allows individuals who have had their rights violated by member states to petition the international Human Rights Committee. Investment treaties commonly and routinely provide for enforcement by individuals or investing entities. and commercial agreements of foreigners with sovereign governments may be enforced on the international plane.
International legal theory.
International legal theory comprises a variety of theoretical and methodological approaches used to explain and analyse the content, formation and effectiveness of public international law and institutions and to suggest improvements. Some approaches center on the question of compliance: why states follow international norms in the absence of a coercitive power that ensures compliance. Other approaches focus on the problem of the formation of international rules: why states voluntarily adopt international law norms, that limit their freedom of action, in the absence of a world legislature; while other perspectives are policy oriented: they elaborate theoretical frameworks and instruments to criticize the existing norms and to make suggestions on how to improve them. Some of these approaches are based on domestic legal theory, some are interdisciplinary, and others have been developed expressly to analyse international law. Classical approaches to International legal theory are the Natural law, the Eclectic and the Legal positivism schools of thought.
The natural law approach argues that international norms should be based on axiomatic truths. 16th century natural law writer, Francisco de Vitoria, a professor of theology at the University of Salamanca, examined the questions of the just war, the Spanish authority in the Americas, and the rights of the Native American peoples.
In 1625 Hugo Grotius argued that nations as well as persons ought to be governed by universal principle based on morality and divine justice while the relations among polities ought to be governed by the law of peoples, the "jus gentium", established by the consent of the community of nations on the basis of the principle of "pacta sunt servanda", that is, on the basis of the observance of commitments. On his part, Emmerich de Vattel argued instead for the equality of states as articulated by 18th century natural law and suggested that the law of nations was composed of custom and law on the one hand, and natural law on the other. During the 17th century, the basic tenets of the Grotian or eclectic school, especially the doctrines of legal equality, territorial sovereignty, and independence of states, became the fundamental principles of the European political and legal system and were enshrined in the 1648 Peace of Westphalia.
The early positivist school emphasized the importance of custom and treaties as sources of international law. 16th century Alberico Gentili used historical examples to posit that positive law ("jus voluntarium") was determined by general consent. Cornelius van Bynkershoek asserted that the bases of international law were customs and treaties commonly consented to by various states, while John Jacob Moser emphasized the importance of state practice in international law. The positivism school narrowed the range of international practice that might qualify as law, favouring rationality over morality and ethics. The 1815 Congress of Vienna marked the formal recognition of the political and international legal system based on the conditions of Europe.
Modern legal positivists consider international law as a unified system of rules that emanates from the states' will. International law, as it is, is an "objective" reality that needs to be distinguished from law "as it should be." Classic positivism demands rigorous tests for legal validity and it deems irrelevant all extralegal arguments.
References.
</dl>

</doc>
<doc id="14832" url="http://en.wikipedia.org/wiki?curid=14832" title="Intergovernmental organization">
Intergovernmental organization

An intergovernmental organization (or international governmental organization; IGO) is an organization composed primarily of sovereign states (referred to as "member states"), or of other intergovernmental organizations. Intergovernmental organizations are often called international organizations, although that term may also include international nongovernmental organization such as international nonprofit organizations or multinational corporations.
Intergovernmental organizations are an important aspect of public international law. IGOs are established by treaty that acts as a charter creating the group. Treaties are formed when lawful representatives (governments) of several states go through a ratification process, providing the IGO with an international legal personality.
Intergovernmental organizations in a legal sense should be distinguished from simple groupings or coalitions of states, such as the G8 or the Quartet. Such groups or associations have not been founded by a constituent document and exist only as task groups.
Intergovernmental organizations must also be distinguished from treaties. Many treaties (such as the North American Free Trade Agreement, or the General Agreement on Tariffs and Trade before the establishment of the World Trade Organization) do not establish an organization and instead rely purely on the parties for their administration becoming legally recognized as an "ad hoc" commission. Other treaties have established an administrative apparatus which was not deemed to have been granted international legal personality.
Types and purpose.
Intergovernmental organizations differ in function, membership and membership criteria. They have various goals and scopes, often outlined in the treaty or charter. Some IGOs developed to fulfill a need for a neutral forum for debate or negotiation to resolve disputes. Others developed to carry out mutual interests with unified aims to preserve peace through conflict resolution and better international relations, promote international cooperation on matters such as environmental protection, to promote human rights, to promote social development (education, health care), to render humanitarian aid, and to economic development. Some are more general in scope (the United Nations) while others may have subject-specific missions (such as Interpol or the International Organization for Standardization and other standards organizations). Common types include:
Some organizations, such as NATO, have collective security or mutual defense provisions.
The Union of International Associations publishes an annual directory of organizations and provides ancillary information on most international organizations, both intergovernmental and non-governmental.
Examples.
United Nations.
Mission
Membership
193 Member States. Membership is "...open to all other peace-loving states which accept the obligations contained in the present Charter and, in the judgment of the Organization, are able and willing to carry out these obligations."
North Atlantic Treaty Organization.
Mission
"The Parties to this Treaty reaffirm their faith in the purposes and principles of the Charter of the United Nations and their desire to live in peace with all peoples and all governments. They are determined to safeguard the freedom, common heritage and civilisation of their peoples, founded on the principles of democracy, individual liberty and the rule of law. They seek to promote stability and well-being in the North Atlantic area.
They are resolved to unite their efforts for collective defence and for the preservation of peace and security. They therefore agree to this North Atlantic Treaty."
Membership
"NATO is an Alliance that consists of 28 independent member countries."
World Bank.
Mission
Membership
188 member countries made up of government-owned organizations.
History.
While treaties, alliances, and multilateral conferences had existed for centuries, IGOs only began to be established in the 19th century. Among the first were the Central Commission for Navigation on the Rhine, initiated in the aftermath of the Napoleonic Wars, and the future International Telegraph Union, which was founded by the signing of the International Telegraph Convention by 20 countries in May 1865. Of notable significance was the emergence of the League of Nations following World War One, designed as an institution to foster collective security in order to sustain peace.
Expansion and growth.
Held and McGrew (2002) counted thousands of IGOs worldwide, and this number continues to rise. This increase may be attributed to globalization, which increases and encourages the cooperation among and within states. Globalization has also provided easier means for IGO growth, as a result of increased international relations. This is seen economically, politically, militarily, as well as on the domestic level. Economically, IGOs gain material and non-material resources for economic prosperity. IGOs also provide more political stability within the state and among differing states. Military alliances are also formed by establishing common standards in order to ensure security of the members to ward off outside threats. Lastly, the formation has encouraged autocratic states to develop into democracies in order to form an effective and internal government.
Participation and involvement.
There are several different reasons a state may choose membership in an intergovernmental organization. But there are also reasons membership may be rejected. These reasons are explored in the sections below.
Reasons for participation:
Reasons for rejecting membership:
Privileges and immunities.
Intergovernmental organizations are provided with privileges and immunities that are intended to ensure their independent and effective functioning. They are specified in the treaties that give rise to the organization (such as the Convention on the Privileges and Immunities of the United Nations and the Agreement on the Privileges and Immunities of the International Criminal Court), which are normally supplemented by further multinational agreements and national regulations (for example the International Organizations Immunities Act in the United States). The organizations are thereby immune from the jurisdiction of national courts.
Rather than by national jurisdiction, legal accountability is intended to be ensured by legal mechanisms that are internal to the intergovernental organization itself and access to administrative tribunals. In the course of many court cases where private parties tried to pursue claims against international organizations, there has been a gradual realization that alternate means of dispute settlement are required, as states have fundamental human rights obligations to provide plaintiffs with access to court in view of their right to a fair trial. Otherwise, the organizations' immunities may be put in question in national and international courts. Some organizations hold proceedings before tribunals relating to their organization to be confidential, and in some instances have threatened disciplinary action should an employee disclose any of the relevant information. Such confidentiality has been criticized as a lack of transparency.
The immunities also extend to employment law. In this regard, immunity from national jurisdiction necessitates that reasonable alternative means are available to effectively protect employees' rights; in this context, a first instance Dutch court considered an estimated duration of proceedings before the Administrative Tribunal of the International Labour Organisation of 15 years to be too long.
Strengths and weaknesses.
These are some of the strengths and weaknesses of IGOs:
Strengths:
Weaknesses:
They can be deemed unfair as countries with a higher percentage voting power have the right to veto any decision that is not in their favor, leaving the smaller countries powerless.

</doc>
<doc id="14836" url="http://en.wikipedia.org/wiki?curid=14836" title="International Telecommunication Union">
International Telecommunication Union

The International Telecommunication Union (ITU), originally the International Telegraph Union (French: "Union Internationale des Télécommunications"), is a specialized agency of the United Nations (UN) that is responsible for issues that concern information and communication technologies.
The ITU coordinates the shared global use of the radio spectrum, promotes international cooperation in assigning satellite orbits, works to improve telecommunication infrastructure in the developing world, and assists in the development and coordination of worldwide technical standards. The ITU is active in areas including broadband Internet, latest-generation wireless technologies, aeronautical and maritime navigation, radio astronomy, satellite-based meteorology, convergence in fixed-mobile phone, Internet access, data, voice, TV broadcasting, and next-generation networks.
ITU also organizes worldwide and regional exhibitions and forums, such as ITU TELECOM WORLD, bringing together representatives of government and the telecommunications and ICT industry to exchange ideas, knowledge and technology.
ITU, based in Geneva, Switzerland, is a member of the United Nations Development Group. ITU has been an intergovernmental public-private partnership organization since its inception. Its membership includes 193 Member States and around 700 public and private sector companies as well as international and regional telecommunication entities, known as Sector Members and Associates, which undertake most of the work of each Sector.
History.
ITU was formed in 1865 at the International Telegraph Convention. ITU became a United Nations specialized agency in 1947.
ITU sectors.
The ITU comprises three sectors, each managing a different aspect of the matters handled by the Union, as well as ITU Telecom. The sectors were created during the restructuring of ITU at its 1992 Plenipotentiary Conference.
A permanent General Secretariat, headed by the Secretary General, manages the day-to-day work of the Union and its sectors.
Legal framework of ITU.
The basic texts of the ITU are adopted by the ITU Plenipotentiary Conference. The founding document of the ITU was the 1865 International Telegraph Convention, which has since been amended several times and is now entitled the "Constitution and Convention of the International Telecommunication Union". In addition to the Constitution and Convention, the consolidated basic texts include the Optional Protocol on the settlement of disputes, the Decisions, Resolutions and Recommendations in force, as well as the General Rules of Conferences, Assemblies and Meetings of the Union.
Leadership.
The ITU is headed by a Secretary-General, who is elected to a four-year term by the member states at the ITU Plenipotentiary Conference.
On 23 October 2014 Houlin Zhao was elected 19th Secretary-General of the ITU at the Plenipotentiary Conference in Busan, Republic of Korea. His four-year mandate started on 1 January 2015, and he was formally inaugurated on 15 January 2015.
Membership.
Membership of ITU is open to governments, which may join the Union as Member States, as well as to private organizations like carriers, equipment manufacturers, funding bodies, research and development organizations and international and regional telecommunication organizations, which can join ITU as non-voting Sector Members.
There are 193 member states of the ITU, which includes 192 UN member states (all except Palau) and Vatican City. The most recent member state to join the ITU is South Sudan, which became a member on 14 July 2011.
The Republic of China (Taiwan) was blocked from membership by the People's Republic of China, but nevertheless received a country code, being listed as "Taiwan, China". Palestine was admitted as an observer in 2010.
Regional groupings.
Member states of the ITU are organized into six regional groups:
World Summit on the Information Society.
The ITU was one of the UN agencies responsible for convening the World Summit on the Information Society (WSIS), along with UNESCO, UNCTAD and UNDP. The Summit was held as two conferences in 2003 and 2005 in Geneva and Tunis, respectively, with the aim of bridging the digital divide.
World Conference on International Telecommunications 2012 (WCIT-12).
In December 2012, the ITU facilitated The World Conference on International Telecommunications 2012 (WCIT-12) in Dubai. WCIT-12 was a treaty-level conference to address International Telecommunications Regulations, the international rules for telecommunications, including international tariffs. The previous conference to update the Regulations (ITRs) was held in Melbourne in 1988.
In August 2012, ITU called for a public consultation on a draft document ahead of the conference. It is claimed the proposal would allow government restriction or blocking of information disseminated via the internet and create a global regime of monitoring internet communications, including the demand that those who send and receive information identify themselves. It would also allow governments to shut down the internet if there is the belief that it may interfere in the internal affairs of other states or that information of a sensitive nature might be shared.
Telecommunications ministers from 193 countries attended the conference in Dubai.
Changes to International Telecommunication Regulations.
The current regulatory structure was based on voice telecommunications, when the Internet was still in its infancy. In 1988, telecommunications operated under regulated monopolies in most countries. As the Internet has grown, organizations such as ICANN have come into existence to manage key resources such as Internet addresses and Domain Names. Some outside the United States believe that the United States exerts too much influence over the governance of the Internet.
Proposed Changes to the Treaty And Concerns.
Current proposals look to take into account the prevalence of data communications. Proposals under consideration would establish regulatory oversight by the UN over security, fraud, traffic accounting as well as traffic flow, management of Internet Domain Names and IP addresses, and other aspects of the Internet that are currently governed either by community-based approaches such as Regional Internet Registries, , or largely national regulatory frameworks. The move by the ITU and some countries has alarmed many within the United States and within the Internet community. Indeed some European telecommunication services have proposed a so-called "sender pays" model that would require sources of Internet traffic to pay destinations, similar to the way funds are transferred between countries using the telephone.
The WCIT-12 activity has been attacked by Google, which has characterized it as a threat to the "...free and open internet."
On 22 November 2012, the European Parliament passed a resolution urging member states to prevent ITU WCIT-12 activity that would "negatively impact the internet, its architecture, operations, content and security, business relations, internet governance and the free flow of information online". The resolution asserted that "the ITU [...] is not the appropriate body to assert regulatory authority over the internet".
On 5 December 2012, the lower chamber of the United States Congress passed a resolution opposing U.N. governance of the Internet by a rare unanimous 397–0 vote. The resolution warned that "... proposals have been put forward for consideration at the [WCIT-12] that would fundamentally alter the governance and operation of the Internet ... [and] would attempt to justify increased government control over the Internet ...", and stated that the policy of the United States is "... to promote a global Internet free from government control and preserve and advance the successful Multistakeholder Model that governs the Internet today." The same resolution had previously been passed unanimously by the upper chamber of the Congress in September.
On 14 December 2012, an amended version of the was signed by 89 of the 152 countries. Countries that did not sign included the United States, Japan, Canada, Germany, New Zealand, India and the United Kingdom. The Head of the U.S. Delegation, Terry Kramer, said "We cannot support a treaty that is not supportive of the multistakeholder model of Internet governance".
 The disagreement appeared to be over some language in the revised ITRs referring to ITU roles in addressing unsolicited bulk communications, network security, and a resolution on Internet governance that called for government participation in Internet topics at various ITU forums. Despite the significant number countries not signing, the ITU organisation came out with a press release: """. "
WCIT-12 Conference Participation.
The conference itself was managed by the International Telecommunication Union (ITU). While certain parts of civil society and industry were able to advise and observe, active participation was restricted to member states. The Electronic Frontier Foundation expressed concern at this, calling for a more transparent multi-stakeholder process. Some leaked contributions can be found on the web site. Google-affiliated researchers have suggested that the ITU should completely reform its processes to align itself with the openness and participation of other multistakeholder organizations concerned with the Internet.

</doc>
<doc id="14837" url="http://en.wikipedia.org/wiki?curid=14837" title="Internet Message Access Protocol">
Internet Message Access Protocol

Internet Message Access Protocol (IMAP) is a protocol for e-mail retrieval and storage developed by Mark Crispin in 1986 at Stanford University as an alternative to POP. IMAP uses port 143, and IMAP over SSL (IMAPS) uses port 993. IMAP, unlike POP, specifically allows multiple clients simultaneously connected to the same mailbox, and through flags stored on the server, different clients accessing the same mailbox at the same or different times can detect state changes made by other clients.
E-mail protocols.
The Internet Message Access Protocol (commonly known as IMAP) is an Application Layer Internet protocol that allows an e-mail client to access e-mail on a remote mail server. The current version, IMAP version 4 revision 1 (IMAP4rev1), is defined by . An IMAP server typically listens on well-known port 143. IMAP over SSL (IMAPS) is assigned well-known port number 993.
IMAP supports both on-line and off-line modes of operation. E-mail clients using IMAP generally leave messages on the server until the user explicitly deletes them. This and other characteristics of IMAP operation allow multiple clients to manage the same mailbox. Most e-mail "clients" support IMAP in addition to Post Office Protocol (POP) to retrieve messages; however, fewer e-mail "services" support IMAP. IMAP offers access to the mail storage. Clients may store local copies of the messages, but these are considered to be a temporary cache.
Incoming e-mail messages are sent to an e-mail server that stores messages in the recipient's e-mail box. The user retrieves the messages with an e-mail client that uses one of a number of e-mail retrieval protocols. Some clients and servers preferentially use vendor-specific, proprietary protocols, but most support SMTP for sending e-mail and POP and IMAP for retrieving e-mail, allowing interoperability with other servers and clients. For example, Microsoft's Outlook client uses MAPI, a Microsoft proprietary protocol to communicate with a Microsoft Exchange Server. IBM's Notes client works in a similar fashion when communicating with a Domino server. All of these products also support POP, IMAP, and outgoing SMTP. Support for the Internet standard protocols allows many e-mail clients such as Pegasus Mail or Mozilla Thunderbird to access these servers, and allows the clients to be used with other servers.
History.
IMAP was designed by Mark Crispin in 1986 as a remote mailbox protocol, in contrast to the widely used POP, a protocol for retrieving the contents of a mailbox.
IMAP was previously known as Internet Mail Access Protocol, Interactive Mail Access Protocol (RFC 1064), and Interim Mail Access Protocol.
Original IMAP.
The original "Interim Mail Access Protocol" was implemented as a Xerox Lisp machine client and a TOPS-20 server.
No copies of the original interim protocol specification or its software exist. Although some of its commands and responses were similar to IMAP2, the interim protocol lacked command/response tagging and thus its syntax was incompatible with all other versions of IMAP.
IMAP2.
The interim protocol was quickly replaced by the "Interactive Mail Access Protocol" (IMAP2), defined in RFC 1064 (in 1988) and later updated by RFC 1176 (in 1990). IMAP2 introduced the command/response tagging and was the first publicly distributed version.
IMAP3.
IMAP3 is an extremely rare variant of IMAP. It was published as RFC 1203 in 1991. It was written specifically as a counter proposal to RFC 1176, which itself proposed modifications to IMAP2. IMAP3 was never accepted by the marketplace. The IESG reclassified RFC1203 "Interactive Mail Access Protocol - Version 3" as a Historic protocol in 1993. The IMAP Working Group used RFC1176 (IMAP2) rather than RFC1203 (IMAP3) as its starting point.
IMAP2bis.
With the advent of MIME, IMAP2 was extended to support MIME body structures and add mailbox management functionality (create, delete, rename, message upload) that was absent from IMAP2. This experimental revision was called IMAP2bis; its specification was never published in non-draft form. An internet draft of IMAP2bis was published by the IETF IMAP Working Group in October 1993. This draft was based upon the following earlier specifications: unpublished "IMAP2bis.TXT" document, RFC1176, and RFC1064 (IMAP2). The "IMAP2bis.TXT" draft documented the state of extensions to IMAP2 as of December 1992. Early versions of Pine were widely distributed with IMAP2bis support (Pine 4.00 and later supports IMAP4rev1).
IMAP4.
An IMAP Working Group formed in the IETF in the early 1990s took over responsibility for the IMAP2bis design. The IMAP WG decided to rename IMAP2bis to IMAP4 to avoid confusion
Advantages over POP.
Connected and disconnected modes of operation.
When using POP, clients typically connect to the e-mail server briefly, only as long as it takes to download new messages. When using IMAP4, clients often stay connected as long as the user interface is active and download message content on demand. For users with many or large messages, this IMAP4 usage pattern can result in faster response times.
Multiple clients simultaneously connected to the same mailbox.
The POP protocol requires the currently connected client to be the only client connected to the mailbox. In contrast, the IMAP protocol specifically allows simultaneous access by multiple clients and provides mechanisms for clients to detect changes made to the mailbox by other, concurrently connected, clients. See for example RFC3501 section 5.2 which specifically cites "simultaneous access to the same mailbox by multiple agents" as an example.
Access to MIME message parts and partial fetch.
Usually all Internet e-mail is transmitted in MIME format, allowing messages to have a tree structure where the leaf nodes are any of a variety of single part content types and the non-leaf nodes are any of a variety of multipart types. The IMAP4 protocol allows clients to retrieve any of the individual MIME parts separately and also to retrieve portions of either individual parts or the entire message. These mechanisms allow clients to retrieve the text portion of a message without retrieving attached files or to stream content as it is being fetched.
Message state information.
Through the use of flags defined in the IMAP4 protocol, clients can keep track of message state: for example, whether or not the message has been read, replied to, or deleted. These flags are stored on the server, so different clients accessing the same mailbox at different times can detect state changes made by other clients. POP provides no mechanism for clients to store such state information on the server so if a single user accesses a mailbox with two different POP clients (at different times), state information—such as whether a message has been accessed—cannot be synchronized between the clients. The IMAP4 protocol supports both predefined system flags and client-defined keywords. System flags indicate state information such as whether a message has been read. Keywords, which are not supported by all IMAP servers, allow messages to be given one or more tags whose meaning is up to the client. IMAP keywords should not be confused with proprietary labels of web-based e-mail services which are sometimes translated into IMAP folders by the corresponding proprietary servers.
Multiple mailboxes on the server.
IMAP4 clients can create, rename, and/or delete mailboxes (usually presented to the user as folders) on the server, and copy messages between mailboxes. Multiple mailbox support also allows servers to provide access to shared and public folders. The "IMAP4 Access Control List (ACL) Extension" (RFC 4314) may be used to regulate access rights.
Server-side searches.
IMAP4 provides a mechanism for a client to ask the server to search for messages meeting a variety of criteria. This mechanism avoids requiring clients to download every message in the mailbox in order to perform these searches.
Built-in extension mechanism.
Reflecting the experience of earlier Internet protocols, IMAP4 defines an explicit mechanism by which it may be extended. Many IMAP4 extensions to the base protocol have been proposed and are in common use. IMAP2bis did not have an extension mechanism, and POP now has one defined by RFC 2449.
Disadvantages.
While IMAP remedies many of the shortcomings of POP, this inherently introduces additional complexity. Much of this complexity (e.g., multiple clients accessing the same mailbox at the same time) is compensated for by server-side workarounds such as Maildir or database backends.
The IMAP specification has been criticised for being insufficiently strict and allowing behaviours that effectively negate its usefulness. For instance, the specification states that each message stored on the server has a "unique id" to allow the clients to identify the messages they have already seen between sessions. However, the specification also allows these UIDs to be invalidated with no restrictions, practically defeating their purpose.
Unless the mail storage and searching algorithms on the server are carefully implemented, a client can potentially consume large amounts of server resources when searching massive mailboxes.
IMAP4 clients need to maintain a TCP/IP connection to the IMAP server in order to be notified of the arrival of new mail. Notification of mail arrival is done through in-band signaling, which contributes to the complexity of client-side IMAP protocol handling somewhat. A private proposal, push IMAP, would extend IMAP to implement push e-mail by sending the entire message instead of just a notification. However, push IMAP has not been generally accepted and current IETF work has addressed the problem in other ways (see the Lemonade Profile for more information).
Unlike some proprietary protocols which combine sending and retrieval operations, sending a message and saving a copy in a server-side folder with a base-level IMAP client requires transmitting the message content twice, once to SMTP for delivery and a second time to IMAP to store in a sent mail folder. This is remedied by a set of extensions defined by the IETF LEMONADE Working Group for mobile devices: URLAUTH (RFC 4467) and CATENATE (RFC 4469) in IMAP and BURL (RFC 4468) in SMTP-SUBMISSION. POP servers don't support server-side folders so clients have no choice but to store sent items on the client. Many IMAP clients can be configured to store sent mail in a client-side folder, or to BCC oneself and then filter the incoming mail instead of saving a copy in a folder directly. In addition to the LEMONADE "trio", Courier Mail Server offers a non-standard method of sending using IMAP by copying an outgoing message to a dedicated outbox folder.
Lastly, support for message states can also cause problems for shared mailboxes; if a user on an IMAP client downloads and reads new mail from the server, the next user to download the same mail via an IMAP client as well will see the client automatically setting the status of said mail to 'Read' even though he or she has yet to do so. This can be a major issue since most IMAP clients do not provide notifications when read messages are downloaded; POP3 users do not experience such problems as the server does not store message states and as such will always have their messages delivered as new and unread mail.
Security.
STARTTLS can be used to provide secure communications between the MUA communicating with the MSA or MTA implementing the smtp protocol.
Dialog example.
This is an example IMAP connection as taken from :
 C: <open connection>
 S: * OK IMAP4rev1 Service Ready
 C: a001 login mrc secret
 S: a001 OK LOGIN completed
 C: a002 select inbox
 S: * 18 EXISTS
 S: * FLAGS (\Answered \Flagged \Deleted \Seen \Draft)
 S: * 2 RECENT
 S: * OK [UNSEEN 17] Message 17 is the first unseen message
 S: * OK [UIDVALIDITY 3857529045] UIDs valid
 S: a002 OK [READ-WRITE] SELECT completed
 C: a003 fetch 12 full
 S: * 12 FETCH (FLAGS (\Seen) INTERNALDATE "17-Jul-1996 02:44:25 -0700"
 RFC822.SIZE 4286 ENVELOPE ("Wed, 17 Jul 1996 02:23:25 -0700 (PDT)"
 "IMAP4rev1 WG mtg summary and minutes"
 (("Terry Gray" NIL "gray" "cac.washington.edu"))
 (("Terry Gray" NIL "gray" "cac.washington.edu"))
 (("Terry Gray" NIL "gray" "cac.washington.edu"))
 ((NIL NIL "imap" "cac.washington.edu"))
 ((NIL NIL "minutes" "CNRI.Reston.VA.US")
 ("John Klensin" NIL "KLENSIN" "MIT.EDU")) NIL NIL
 "<B27397-0100000@cac.washington.edu>")
 BODY ("TEXT" "PLAIN" ("CHARSET" "US-ASCII") NIL NIL "7BIT" 3028
 92))
 S: a003 OK FETCH completed
 C: a004 fetch 12 body[header]
 S: Date: Wed, 17 Jul 1996 02:23:25 -0700 (PDT)
 S: From: Terry Gray <gray@cac.washington.edu>
 S: Subject: IMAP4rev1 WG mtg summary and minutes
 S: To: imap@cac.washington.edu
 S: cc: minutes@CNRI.Reston.VA.US, John Klensin <KLENSIN@MIT.EDU>
 S: Message-Id: <B27397-0100000@cac.washington.edu>
 S: MIME-Version: 1.0
 S: Content-Type: TEXT/PLAIN; CHARSET=US-ASCII
 S:
 S: )
 S: a004 OK FETCH completed
 C a005 store 12 +flags \deleted
 S: * 12 FETCH (FLAGS (\Seen \Deleted))
 S: a005 OK +FLAGS completed
 C: a006 logout
 S: * BYE IMAP4rev1 server terminating connection
 S: a006 OK LOGOUT completed

</doc>
<doc id="14838" url="http://en.wikipedia.org/wiki?curid=14838" title="Inertial frame of reference">
Inertial frame of reference

In physics, an inertial frame of reference (also inertial reference frame or inertial frame or Galilean reference frame or inertial space) is a frame of reference that describes time and space homogeneously, isotropically, and in a time-independent manner.
All inertial frames are in a state of constant, rectilinear motion with respect to one another; an accelerometer moving with any of them would detect zero acceleration. Measurements in one inertial frame can be converted to measurements in another by a simple transformation (the Galilean transformation in Newtonian physics and the Lorentz transformation in special relativity). In general relativity, in any region small enough for the curvature of spacetime to be negligible, one can find a set of inertial frames that approximately describe that region.
Physical laws take the same form in all inertial frames. By contrast, in a non-inertial reference frame the laws of physics vary depending on the acceleration of that frame with respect to an inertial frame, and the usual physical forces must be supplemented by fictitious forces. For example, a ball dropped towards the ground does not go exactly straight down because the Earth is rotating. Someone rotating with the Earth must account for the Coriolis effect—in this case thought of as a force—to predict the horizontal motion. Another example of such a fictitious force associated with rotating reference frames is the centrifugal effect, or centrifugal force.
Introduction.
The motion of a body can only be described relative to something else - other bodies, observers, or a set of space-time coordinates. These are called frames of reference. If the coordinates are chosen badly, the laws of motion may be more complex than necessary. For example, suppose a free body (one having no external forces on it) is at rest at some instant. In many coordinate systems, it would begin to move at the next instant, even though there are no forces on it. However, a frame of reference can always be chosen in which it remains stationary. Similarly, if space is not described uniformly or time independently, a coordinate system could describe the simple flight of a free body in space as a complicated zig-zag in its coordinate system. Indeed, an intuitive summary of inertial frames can be given as: In an inertial reference frame, the laws of mechanics take their simplest form.
In an inertial frame, Newton's first law (the "law of inertia") is satisfied: Any free motion has a constant magnitude and direction. Newton's second law for a particle takes the form:
with F the net force (a vector), "m" the mass of a particle and a the acceleration of the particle (also a vector) which would be measured by an observer at rest in the frame. The force F is the vector sum of all "real" forces on the particle, such as electromagnetic, gravitational, nuclear and so forth. In contrast, Newton's second law in a rotating frame of reference, rotating at angular rate "Ω" about an axis, takes the form:
which looks the same as in an inertial frame, but now the force F′ is the resultant of not only F, but also additional terms (the paragraph following this equation presents the main points without detailed mathematics):
where the angular rotation of the frame is expressed by the vector Ω pointing in the direction of the axis of rotation, and with magnitude equal to the angular rate of rotation "Ω", symbol × denotes the vector cross product, vector x"B" locates the body and vector v"B" is the velocity of the body according to a rotating observer (different from the velocity seen by the inertial observer).
The extra terms in the force F′ are the "fictitious" forces for this frame. (The first extra term is the Coriolis force, the second the centrifugal force, and the third the Euler force.) These terms all have these properties: they vanish when "Ω" = 0; that is, they are zero for an inertial frame (which, of course, does not rotate); they take on a different magnitude and direction in every rotating frame, depending upon its particular value of Ω; they are ubiquitous in the rotating frame (affect every particle, regardless of circumstance); and they have no apparent source in identifiable physical sources, in particular, matter. Also, fictitious forces do not drop off with distance (unlike, for example, nuclear forces or electrical forces). For example, the centrifugal force that appears to emanate from the axis of rotation in a rotating frame increases with distance from the axis.
All observers agree on the real forces, F; only non-inertial observers need fictitious forces. The laws of physics in the inertial frame are simpler because unnecessary forces are not present.
In Newton's time the fixed stars were invoked as a reference frame, supposedly at rest relative to absolute space. In reference frames that were either at rest with respect to the fixed stars or in uniform translation relative to these stars, Newton's laws of motion were supposed to hold. In contrast, in frames accelerating with respect to the fixed stars, an important case being frames rotating relative to the fixed stars, the laws of motion did not hold in their simplest form, but had to be supplemented by the addition of fictitious forces, for example, the Coriolis force and the centrifugal force. Two interesting experiments were devised by Newton to demonstrate how these forces could be discovered, thereby revealing to an observer that they were not in an inertial frame: the example of the tension in the cord linking two spheres rotating about their center of gravity, and the example of the curvature of the surface of water in a rotating bucket. In both cases, application of Newton's second law would not work for the rotating observer without invoking centrifugal and Coriolis forces to account for their observations (tension in the case of the spheres; parabolic water surface in the case of the rotating bucket).
As we now know, the fixed stars are not fixed. Those that reside in the Milky Way turn with the galaxy, exhibiting proper motions. Those that are outside our galaxy (such as nebulae once mistaken to be stars) participate in their own motion as well, partly due to expansion of the universe, and partly due to peculiar velocities. (The Andromeda galaxy is on collision course with the Milky Way at a speed of 117 km/s.) The concept of inertial frames of reference is no longer tied to either the fixed stars or to absolute space. Rather, the identification of an inertial frame is based upon the simplicity of the laws of physics in the frame. In particular, the absence of fictitious forces is their identifying property.
In practice, although not a requirement, using a frame of reference based upon the fixed stars as though it were an inertial frame of reference introduces very little discrepancy. For example, the centrifugal acceleration of the Earth because of its rotation about the Sun is about thirty million times greater than that of the Sun about the galactic center.
To illustrate further, consider the question: "Does our Universe rotate?" To answer, we might attempt to explain the shape of the Milky Way galaxy using the laws of physics. (Other observations might be more definitive (that is, provide larger discrepancies or less measurement uncertainty), like the anisotropy of the microwave background radiation or Big Bang nucleosynthesis.) Just how flat the disc of the Milky Way is depends on its rate of rotation in an inertial frame of reference. If we attribute its apparent rate of rotation entirely to rotation in an inertial frame, a different "flatness" is predicted than if we suppose part of this rotation actually is due to rotation of the Universe and should not be included in the rotation of the galaxy itself. Based upon the laws of physics, a model is set up in which one parameter is the rate of rotation of the Universe. If the laws of physics agree more accurately with observations in a model with rotation than without it, we are inclined to select the best-fit value for rotation, subject to all other pertinent experimental observations. If no value of the rotation parameter is successful and theory is not within observational error, a modification of physical law is considered. (For example, dark matter is invoked to explain the galactic rotation curve.) So far, observations show any rotation of the Universe is very slow (no faster than once every 60·1012 years (10−13 rad/yr)), and debate persists over whether there is "any" rotation. However, if rotation were found, interpretation of observations in a frame tied to the Universe would have to be corrected for the fictitious forces inherent in such rotation. Evidently, such an approach adopts the view that "an inertial frame of reference is one where our laws of physics apply" (or need the least modification).
When quantum effects are important, there are additional conceptual complications that arise in quantum reference frames.
Background.
A brief comparison of inertial frames in special relativity and in Newtonian mechanics, and the role of absolute space is next.
A set of frames where the laws of physics are simple.
According to the first postulate of special relativity, all physical laws take their simplest form in an inertial frame, and there exist multiple inertial frames interrelated by uniform translation: Special principle of relativity: If a system of coordinates K is chosen so that, in relation to it, physical laws hold good in their simplest form, the same laws hold good in relation to any other system of coordinates K' moving in uniform translation relatively to K.—Albert Einstein: "The foundation of the general theory of relativity", Section A, §1
The principle of simplicity can be used within Newtonian physics as well as in special relativity; see Nagel and also Blagojević.
The laws of Newtonian mechanics do not always hold in their simplest form...If, for instance, an observer is placed on a disc rotating relative to the earth, he/she will sense a 'force' pushing him/her toward the periphery of the disc, which is not caused by any interaction with other bodies. Here, the acceleration is not the consequence of the usual force, but of the so-called inertial force. Newton's laws hold in their simplest form only in a family of reference frames, called inertial frames. This fact represents the essence of the Galilean principle of relativity:   The laws of mechanics have the same form in all inertial frames.—Milutin Blagojević: "Gravitation and Gauge Symmetries", p. 4
In practical terms, the equivalence of inertial reference frames means that scientists within a box moving uniformly cannot determine their absolute velocity by any experiment (otherwise the differences would set up an absolute standard reference frame). According to this definition, supplemented with the constancy of the speed of light, inertial frames of reference transform among themselves according to the Poincaré group of symmetry transformations, of which the Lorentz transformations are a subgroup. In Newtonian mechanics, which can be viewed as a limiting case of special relativity in which the speed of light is infinite, inertial frames of reference are related by the Galilean group of symmetries.
Absolute space.
Newton posited an absolute space considered well approximated by a frame of reference stationary relative to the fixed stars. An inertial frame was then one in uniform translation relative to absolute space. However, some scientists (called "relativists" by Mach), even at the time of Newton, felt that absolute space was a defect of the formulation, and should be replaced.
Indeed, the expression "inertial frame of reference" (German: "Inertialsystem") was coined by Ludwig Lange in 1885, to replace Newton's definitions of "absolute space and time" by a more operational definition. As referenced by Iro, :
A reference frame in which a mass point thrown from the same point in three different (non co-planar) directions follows rectilinear paths each time it is thrown, is called an inertial frame.
A discussion of Lange's proposal can be found in Mach.
The inadequacy of the notion of "absolute space" in Newtonian mechanics is spelled out by Blagojević: —Milutin Blagojević: "Gravitation and Gauge Symmetries", p. 5
The utility of operational definitions was carried much further in the special theory of relativity. Some historical background including Lange's definition is provided by DiSalle, who says in summary:
The original question, "relative to what frame of reference do the laws of motion hold?" is revealed to be wrongly posed. For the laws of motion essentially determine a class of reference frames, and (in principle) a procedure for constructing them.—
Newton's inertial frame of reference.
Within the realm of Newtonian mechanics, an inertial frame of reference, or inertial reference frame, is one in which Newton's first law of motion is valid. However, the principle of special relativity generalizes the notion of inertial frame to include all physical laws, not simply Newton's first law.
Newton viewed the first law as valid in any reference frame that is in uniform motion relative to the fixed stars; that is, neither rotating nor accelerating relative to the stars. Today the notion of "absolute space" is abandoned, and an inertial frame in the field of classical mechanics is defined as:
An inertial frame of reference is one in which the motion of a particle not subject to forces is in a straight line at constant speed.
Hence, with respect to an inertial frame, an object or body accelerates only when a physical force is applied, and (following Newton's first law of motion), in the absence of a net force, a body at rest will remain at rest and a body in motion will continue to move uniformly—that is, in a straight line and at constant speed. Newtonian inertial frames transform among each other according to the Galilean group of symmetries.
If this rule is interpreted as saying that straight-line motion is an indication of zero net force, the rule does not identify inertial reference frames, because straight-line motion can be observed in a variety of frames. If the rule is interpreted as defining an inertial frame, then we have to be able to determine when zero net force is applied. The problem was summarized by Einstein:
The weakness of the principle of inertia lies in this, that it involves an argument in a circle: a mass moves without acceleration if it is sufficiently far from other bodies; we know that it is sufficiently far from other bodies only by the fact that it moves without acceleration.—Albert Einstein: "The Meaning of Relativity", p. 58
There are several approaches to this issue. One approach is to argue that all real forces drop off with distance from their sources in a known manner, so we have only to be sure that we are far enough away from all sources to ensure that no force is present. A possible issue with this approach is the historically long-lived view that the distant universe might affect matters (Mach's principle). Another approach is to identify all real sources for real forces and account for them. A possible issue with this approach is that we might miss something, or account inappropriately for their influence (Mach's principle again?). A third approach is to look at the way the forces transform when we shift reference frames. Fictitious forces, those that arise due to the acceleration of a frame, disappear in inertial frames, and have complicated rules of transformation in general cases. On the basis of universality of physical law and the request for frames where the laws are most simply expressed, inertial frames are distinguished by the absence of such fictitious forces.
Newton enunciated a principle of relativity himself in one of his corollaries to the laws of motion: The motions of bodies included in a given space are the same among themselves, whether that space is at rest or moves uniformly forward in a straight line.—Isaac Newton: "Principia", Corollary V, p. 88 in Andrew Motte translation
This principle differs from the special principle in two ways: first, it is restricted to mechanics, and second, it makes no mention of simplicity. It shares with the special principle the invariance of the form of the description among mutually translating reference frames. The role of fictitious forces in classifying reference frames is pursued further below.
Separating non-inertial from inertial reference frames.
Theory.
Inertial and non-inertial reference frames can be distinguished by the absence or presence of fictitious forces, as explained shortly. The effect of this being in the noninertial frame is to require the observer to introduce a fictitious force into his calculations….—Sidney Borowitz and Lawrence A Bornstein in "A Contemporary View of Elementary Physics", p. 138
The presence of fictitious forces indicates the physical laws are not the simplest laws available so, in terms of the special principle of relativity, a frame where fictitious forces are present is not an inertial frame:
The equations of motion in a non-inertial system differ from the equations in an inertial system by additional terms called inertial forces. This allows us to detect experimentally the non-inertial nature of a system.—V. I. Arnol'd: "Mathematical Methods of Classical Mechanics" Second Edition, p. 129
Bodies in non-inertial reference frames are subject to so-called "fictitious" forces (pseudo-forces); that is, forces that result from the acceleration of the reference frame itself and not from any physical force acting on the body. Examples of fictitious forces are the centrifugal force and the Coriolis force in rotating reference frames.
How then, are "fictitious" forces to be separated from "real" forces? It is hard to apply the Newtonian definition of an inertial frame without this separation. For example, consider a stationary object in an inertial frame. Being at rest, no net force is applied. But in a frame rotating about a fixed axis, the object appears to move in a circle, and is subject to centripetal force (which is made up of the Coriolis force and the centrifugal force). How can we decide that the rotating frame is a non-inertial frame? There are two approaches to this resolution: one approach is to look for the origin of the fictitious forces (the Coriolis force and the centrifugal force). We will find there are no sources for these forces, no associated force carriers, no originating bodies. A second approach is to look at a variety of frames of reference. For any inertial frame, the Coriolis force and the centrifugal force disappear, so application of the principle of special relativity would identify these frames where the forces disappear as sharing the same and the simplest physical laws, and hence rule that the rotating frame is not an inertial frame.
Newton examined this problem himself using rotating spheres, as shown in Figure 2 and Figure 3. He pointed out that if the spheres are not rotating, the tension in the tying string is measured as zero in every frame of reference. If the spheres only appear to rotate (that is, we are watching stationary spheres from a rotating frame), the zero tension in the string is accounted for by observing that the centripetal force is supplied by the centrifugal and Coriolis forces in combination, so no tension is needed. If the spheres really are rotating, the tension observed is exactly the centripetal force required by the circular motion. Thus, measurement of the tension in the string identifies the inertial frame: it is the one where the tension in the string provides exactly the centripetal force demanded by the motion as it is observed in that frame, and not a different value. That is, the inertial frame is the one where the fictitious forces vanish.
So much for fictitious forces due to rotation. However, for linear acceleration, Newton expressed the idea of undetectability of straight-line accelerations held in common:
If bodies, any how moved among themselves, are urged in the direction of parallel lines by equal accelerative forces, they will continue to move among themselves, after the same manner as if they had been urged by no such forces.—Isaac Newton: "Principia" Corollary VI, p. 89, in Andrew Motte translation
This principle generalizes the notion of an inertial frame. For example, an observer confined in a free-falling lift will assert that he himself is a valid inertial frame, even if he is accelerating under gravity, so long as he has no knowledge about anything outside the lift. So, strictly speaking, inertial frame is a relative concept. With this in mind, we can define inertial frames collectively as a set of frames which are stationary or moving at constant velocity with respect to each other, so that a single inertial frame is defined as an element of this set.
For these ideas to apply, everything observed in the frame has to be subject to a base-line, common acceleration shared by the frame itself. That situation would apply, for example, to the elevator example, where all objects are subject to the same gravitational acceleration, and the elevator itself accelerates at the same rate.
In 1899 the astronomer Karl Schwarzschild pointed out an observation about double stars. The motion of two stars orbiting each other is planar, the two orbits of the stars of the system lie in a plane. In the case of sufficiently near double star systems, it can be seen from Earth whether the perihelion of the orbits of the two stars remains pointing in the same direction with respect to the solar system. Schwarzschild pointed out that that was invariably seen: the direction of the angular momentum of all observed double star systems remains fixed with respect to the direction of the angular momentum of the Solar system. The logical inference is that just like gyroscopes, the angular momentum of all celestial bodies is angular momentum with respect to a universal inertial space.
Applications.
Inertial navigation systems used a cluster of gyroscopes and accelerometers to determine accelerations relative to inertial space. After a gyroscope is spun up in a particular orientation in inertial space, the law of conservation of angular momentum requires that it retain that orientation as long as no external forces are applied to it.:59 Three orthogonal gyroscopes establish an inertial reference frame, and the accelerators measure acceleration relative to that frame. The accelerations, along with a clock, can then be used to calculate the change in position. Thus, inertial navigation is a form of dead reckoning that requires no external input, and therefore cannot be jammed by any external or internal signal source. 
A gyrocompass, employed for navigation of seagoing vessels, finds the geometric north. It does so, not by sensing the Earth's magnetic field, but by using inertial space as its reference. The outer casing of the gyrocompass device is held in such a way that it remains aligned with the local plumb line. When the gyroscope wheel inside the gyrocompass device is spun up, the way the gyroscope wheel is suspended causes the gyroscope wheel to gradually align its spinning axis with the Earth's axis. Alignment with the Earth's axis is the only direction for which the gyroscope's spinning axis can be stationary with respect to the Earth and not be required to change direction with respect to inertial space. After being spun up, a gyrocompass can reach the direction of alignment with the Earth's axis in as little as a quarter of an hour.
Newtonian mechanics.
Classical mechanics, which includes relativity, assumes the equivalence of all inertial reference frames. Newtonian mechanics makes the additional assumptions of absolute space and absolute time. Given these two assumptions, the coordinates of the same event (a point in space and time) described in two inertial reference frames are related by a Galilean transformation.
where r0 and "t"0 represent shifts in the origin of space and time, and v is the relative velocity of the two inertial reference frames. Under Galilean transformations, the time "t"2 − "t"1 between two events is the same for all inertial reference frames and the distance between two simultaneous events (or, equivalently, the length of any object, |r2 − r1|) is also the same.
Special relativity.
Einstein's theory of special relativity, like Newtonian mechanics, assumes the equivalence of all inertial reference frames, but makes an additional assumption, foreign to Newtonian mechanics, namely, that in free space light always is propagated with the speed of light "c"0, a defined independent of its direction of propagation and its frequency, and also independent of the state of motion of the emitting body. This second assumption has been verified experimentally and leads to counter-intuitive deductions including:
These deductions are logical consequences of the stated assumptions, and are general properties of space-time, typically without regard to a consideration of properties pertaining to the structure of individual objects like atoms or stars, nor to the mechanisms of clocks.
These effects are expressed mathematically by the Lorentz transformation
where shifts in origin have been ignored, the relative velocity is assumed to be in the formula_10-direction and the Lorentz factor γ is defined by:
The Lorentz transformation is equivalent to the Galilean transformation in the limit "c"0 → ∞ (a hypothetical case) or "v" → 0 (low speeds).
Under Lorentz transformations, the time and distance between events may differ among inertial reference frames; however, the Lorentz scalar distance "s" between two events is the same in all inertial reference frames
From this perspective, the speed of light is only accidentally a property of light, and is rather a property of spacetime, a conversion factor between conventional time units (such as seconds) and length units (such as meters).
Incidentally, because of the limitations on speeds faster than the speed of light, notice that in a rotating frame of reference (which is a non-inertial frame, of course) stationarity is not possible at arbitrary distances because at large radius the object would move faster than the speed of light.
General relativity.
General relativity is based upon the principle of equivalence:There is no experiment observers can perform to distinguish whether an acceleration arises because of a gravitational force or because their reference frame is accelerating.—Douglas C. Giancoli, "Physics for Scientists and Engineers with Modern Physics", p. 155.
This idea was introduced in Einstein's 1907 article "Principle of Relativity and Gravitation" and later developed in 1911. Support for this principle is found in the Eötvös experiment, which determines whether the ratio of inertial to gravitational mass is the same for all bodies, regardless of size or composition. To date no difference has been found to a few parts in 1011. For some discussion of the subtleties of the Eötvös experiment, such as the local mass distribution around the experimental site (including a quip about the mass of Eötvös himself), see Franklin.
Einstein’s general theory modifies the distinction between nominally "inertial" and "noninertial" effects by replacing special relativity's "flat" Minkowski Space with a metric that produces non-zero curvature. In general relativity, the principle of inertia is replaced with the principle of geodesic motion, whereby objects move in a way dictated by the curvature of spacetime. As a consequence of this curvature, it is not a given in general relativity that inertial objects moving at a particular rate with respect to each other will continue to do so. This phenomenon of geodesic deviation means that inertial frames of reference do not exist globally as they do in Newtonian mechanics and special relativity.
However, the general theory reduces to the special theory over sufficiently small regions of spacetime, where curvature effects become less important and the earlier inertial frame arguments can come back into play. Consequently, modern special relativity is now sometimes described as only a "local theory".

</doc>
<doc id="14841" url="http://en.wikipedia.org/wiki?curid=14841" title="Integration">
Integration

Integration may refer to:

</doc>
<doc id="14843" url="http://en.wikipedia.org/wiki?curid=14843" title="Interstellar travel">
Interstellar travel

Interstellar space travel is manned or unmanned travel between stars. Interstellar travel is much more difficult than interplanetary travel: the distances between the planets in the Solar System are typically measured in standard astronomical units (AU)—whereas the distances between stars are typically hundreds of thousands of AU, and usually expressed in light-years. Because of the vastness of those distances, interstellar travel would require either great speed (some percentage of the speed of light) or huge travel time (lasting from decades to millennia).
The required speeds for interstellar travel in a human lifespan are far beyond what current methods of spacecraft propulsion can provide. The energy required to propel a spacecraft to these speeds, regardless of the propulsion system used, is enormous by today's standards of energy production. At these speeds, collisions by the spacecraft with cosmic dust and gas can produce very dangerous effects both to any passengers and the spacecraft itself.
A number of widely differing strategies have been proposed to deal with these problems, ranging from giant arks that would carry entire societies and ecosystems very slowly, to microscopic space probes. Many different spacecraft propulsion systems have been proposed to give spacecraft the required speeds: these range from different forms of nuclear propulsion, to beam-powered propulsion methods that would require megascale engineering projects, to methods based on speculative physics.
For both unmanned and manned interstellar travel, considerable technological and economic challenges would need to be met. Even the most optimistic views about interstellar travel are that it might happen decades in the future due to the exponential growth in technology; the more common view is that it is a century or more away.
Challenges.
Interstellar distances.
The basic challenge facing interstellar travel is the immense distances between the stars.
Astronomical distances are measured using different units of length, depending on the scale of the distances involved. Between the planets in the Solar System they are often measured in astronomical units (AU), defined as the average distance between the Sun and Earth, some 150 million kilometers (93 million miles). Venus, the closest other planet to Earth is (at closest approach) 0.28 AU away. Neptune, the farthest planet from the Sun, is 29.8 AU away. Voyager 1, the farthest man-made object from Earth, is 130.83 AU away.
The closest known star Proxima Centauri, however, is some 268,332 AU away, or over 9000 times farther away than even the farthest planet in the Solar System.
Because of this, distances between stars are usually expressed in light-years, defined as the distance that a ray of light travels in a year. Light in a vacuum travels around 300,000 kilometers (186,000 miles) per second, so this is some 9.46 trillion kilometers (5.87 trillion miles) or 63,241 AU. Proxima Centauri is 4.243 light-years away.
Another way of understanding the vastness of interstellar distances is by scaling: one of the closest stars to the Sun, Alpha Centauri A (a Sun-like star), can be pictured by scaling down the Earth–Sun distance to one meter (~3.3 ft). On this scale, the distance to Alpha Centauri A would be 271 kilometers (169 miles).
The fastest outward-bound spacecraft yet sent, Voyager 1, has covered 1/600th of a light-year in 30 years and is currently moving at 1/18,000th the speed of light. At this rate, a journey to Proxima Centauri would take 80,000 years.
Some combination of great speed and long travel time are required. The time required by propulsion methods based on currently known physical principles would require years to millennia.
Required energy.
A significant factor contributing to the difficulty is the energy that must be supplied to obtain a reasonable travel time. A lower bound for the required energy is the kinetic energy K =  1⁄2 mv2 where m is the final mass. If deceleration on arrival is desired and cannot be achieved by any means other than the engines of the ship, then the lower bound for the required energy is doubled to mv2.
The velocity for a manned round trip of a few decades to even the nearest star is several thousand times greater than those of present space vehicles. This means that due to the v2 term in the kinetic energy formula, millions of times as much energy is required. Accelerating one ton to one-tenth of the speed of light requires at least 450 PJ or 4.5 ×1017 J or 125 terawatt-hours (world energy consumption 2008 was 143,851 terawatt-hours), without factoring in efficiency of the propulsion mechanism. This energy has to be generated on-board from stored fuel, harvested from the interstellar medium, or projected over immense distances.
Manned missions.
The mass of any craft capable of carrying humans would inevitably be substantially larger than that necessary for an unmanned interstellar probe. For instance, the first space probe, Sputnik 1, had a payload of 83.6 kg, whereas the first spacecraft carrying a living passenger (the dog Laika), Sputnik 2, had a payload six times that at 508.3 kg. This underestimates the difference in the case of interstellar missions, given the vastly greater travel times involved and the resulting necessity of a closed-cycle life support system. As technology continues to advance, combined with the aggregate risks and support requirements of manned interstellar travel, the first interstellar missions are unlikely to carry life forms.
A manned craft will require more time to reach its top speed as humans have limited tolerance to acceleration.
Interstellar medium.
A major issue with traveling at extremely high speeds is that interstellar dust and gas may cause considerable damage to the craft, due to the high relative speeds and large kinetic energies involved. Various shielding methods to mitigate this problem have been proposed. Larger objects (such as macroscopic dust grains) are far less common, but would be much more destructive. The risks of impacting such objects, and methods of mitigating these risks, have been discussed in the literature, but many unknowns remain.
Travel time.
An interstellar ship would face manifold hazards found in interplanetary travel, including vacuum, radiation, weightlessness, and micrometeoroids. Even the minimum multi-year travel times to the nearest stars are beyond current manned space mission design experience.
The habitual illumination energy requirement for each person is estimated to be 12 kilowatts. Other long-term energy requirements are still being investigated.
More speculative approaches to interstellar travel offer the possibility of circumventing these difficulties. Special relativity offers the possibility of shortening the travel time through relativistic time dilation: if a starship could reach velocities approaching the speed of light, the journey time as experienced by the traveler would be greatly reduced (see time dilation section). General relativity offers the theoretical possibility that faster-than-light travel could greatly shorten travel times, both for the traveler and those on Earth (see Faster-than-light travel section).
Wait calculation.
It has been argued that an interstellar mission that cannot be completed within 50 years should not be started at all. Instead, assuming that a civilization is still on an increasing curve of propulsion system velocity, not yet having reached the limit, the resources should be invested in designing a better propulsion system. This is because a slow spacecraft would probably be passed by another mission sent later with more-advanced propulsion (the incessant obsolescence postulate). On the other hand, Andrew Kennedy has shown that if one calculates the journey time to a given destination as the rate of travel speed derived from growth (even exponential growth) increases, there is a clear minimum in the total time to that destination from now (see wait calculation). Voyages undertaken before the minimum will be overtaken by those who leave at the minimum, whereas those who leave after the minimum will never overtake those who left at the minimum.
One argument against the stance of delaying a start until reaching fast propulsion system velocity is that the various other non-technical problems that are specific to long-distance travel at considerably higher speed (such as interstellar particle impact, possible dramatic shortening of average human life span during extended space residence, etc.) may remain obstacles that take much longer time to resolve than the propulsion issue alone, assuming that they can even be solved eventually at all. A case can therefore be made for starting a mission without delay, based on the concept of an achievable and dedicated but relatively slow interstellar mission using the current technological state-of-the-art and at relatively low cost, rather than banking on being able to solve all problems associated with a faster mission without having a reliable time frame for achievability of such.
Communications.
The round-trip delay time is the minimum time between an observation by the probe and the moment the probe can receive instructions from Earth reacting to the observation. Given that information can travel no faster than the speed of light, this is for the Voyager 1 about 36 hours, and near Proxima Centauri it would be 8 years. Faster reaction would have to be programmed to be carried out automatically. Of course, in the case of a manned flight the crew can respond immediately to their observations. However, the round-trip delay time makes them not only extremely distant from, but, in terms of communication, also extremely isolated from Earth (analogous to how past long distance explorers were similarly isolated before the invention of the electrical telegraph).
Interstellar communication is still problematic – even if a probe could reach the nearest star, its ability to communicate back to Earth would be difficult given the extreme distance. See Interstellar communication.
Prime targets for interstellar travel.
There are 59 known stellar systems within 20 light years of the Sun, containing 81 visible stars. The following could be considered prime targets for interstellar missions:
Existing and near-term astronomical technology is capable of finding planetary systems around these objects, increasing their potential for exploration.
Proposed methods.
Slow, uncrewed probes.
Slow interstellar missions based on current and near-future propulsion technologies are associated with trip times starting from about one hundred years to thousands of years. These missions consist of sending a robotic probe to a nearby star for exploration, similar to interplanetary probes such as used in the Voyager program. By taking along no crew, the cost and complexity of the mission is significantly reduced although technology lifetime is still a significant issue next to obtaining a reasonable speed of travel. Proposed concepts include Project Daedalus, Project Icarus, Project Dragonfly, and Project Longshot.
Fast, uncrewed probes.
Nanoprobes.
Near-lightspeed nanospacecraft might be possible within the near future built on existing microchip technology with a newly developed nanoscale thruster. Researchers at the University of Michigan are developing thrusters that use nanoparticles as propellant. Their technology is called “nanoparticle field extraction thruster”, or nanoFET. These devices act like small particle accelerators shooting conductive nanoparticles out into space.
Michio Kaku, a theoretical physicist, has suggested that clouds of "smart dust" be sent to the stars, which may become possible with advances in nanotechnology. Kaku also notes that a large amount of nanoprobes would need to be sent due to the vulnerability of very small probes to be easily deflected by magnetic fields, micrometeorites and other dangers to ensure the chances that at least one nanoprobe will survive the journey and reach the destination.
Given the light weight of these probes, it would take much less energy to accelerate them. With on board solar cells they could continually accelerate using solar power. One can envision a day when a fleet of millions or even billions of these particles swarm to distant stars at nearly the speed of light and relay signals back to Earth through a vast interstellar communication network.
As a near-term solution, small, laser-propelled interstellar probes, based on current CubeSat technology were proposed in the context of Project Dragonfly.
Slow, manned missions.
In crewed missions, the duration of a slow interstellar journey presents a major obstacle and existing concepts deal with this problem in different ways. They can be distinguished by the "state" in which humans are transported on-board of the spacecraft.
Generation ships.
A generation ship (or world ship) is a type of interstellar ark in which the crew that arrives at the destination is descended from those who started the journey. Generation ships are not currently feasible because of the difficulty of constructing a ship of the enormous required scale and the great biological and sociological problems that life aboard such a ship raises.
Suspended animation.
Scientists and writers have postulated various techniques for suspended animation. These include human hibernation and cryonic preservation. Although neither is currently practical, they offer the possibility of sleeper ships in which the passengers lie inert for the long duration of the voyage.
Extended human lifespan.
A variant on this possibility is based on the development of substantial human life extension, such as the "Strategies for Engineered Negligible Senescence" proposed by Dr. Aubrey de Grey. If a ship crew had lifespans of some thousands of years, or had artificial bodies, they could traverse interstellar distances without the need to replace the crew in generations. The psychological effects of such an extended period of travel would potentially still pose a problem.
Frozen embryos.
A robotic space mission carrying some number of frozen early stage human embryos is another theoretical possibility. This method of space colonization requires, among other things, the development of an artificial uterus, the prior detection of a habitable terrestrial planet, and advances in the field of fully autonomous mobile robots and educational robots that would replace human parents.
Mind uploading.
A more speculative method of transporting humans to the stars is by using mind uploading or also called brain emulation. Frank J. Tipler speculates about the colonization of the universe by starships transporting uploaded astronauts. Hein presents a range of concepts how such missions could be conducted, using more or less speculative technologies, for example self-replicating machines, wormholes, and teleportation. One of the major challenges besides mind uploading itself are the means for downloading the uploads into physical entities, which can be biological or artificial or both.
Island hopping through interstellar space.
Interstellar space is not completely empty; it contains trillions of icy bodies ranging from small asteroids (Oort cloud) to possible rogue planets. There may be ways to take advantage of these resources for a good part of an interstellar trip, slowly hopping from body to body or setting up waystations along the way.
Fast missions.
If a spaceship could average 10 percent of light speed (and decelerate at the destination, for manned missions), this would be enough to reach Proxima Centauri in forty years. Several propulsion concepts are proposed that might be eventually developed to accomplish this (see section below on propulsion methods), but none of them are ready for near-term (few decades) development at acceptable cost. 
Time dilation.
Assuming one cannot travel faster than light one might conclude that a human can never make a round-trip farther from Earth than 20 light years if the traveler is active between the ages of 20 and 60. A traveler would never be able to reach more than the very few star systems that exist within the limit of 20 light years from Earth. This, however, fails to take into account time dilation. Clocks aboard an interstellar ship would run slower than Earth clocks, so if a ship's engines were powerful enough the ship could reach mostly anywhere in the galaxy and return to Earth within 40 years ship-time. Upon return, there would be a difference between the time elapsed on the astronaut's ship and the time elapsed on Earth. A spaceship could travel to a star 32 light-years away, initially accelerating at a constant 1.03g (i.e. 10.1 m/s2) for 1.32 years (ship time), then stopping its engines and coasting for the next 17.3 years (ship time) at a constant speed, then decelerating again for 1.32 ship-years, and coming to a stop at the destination. After a short visit the astronaut could return to Earth the same way.
After the full round-trip, the clocks on board the ship show that 40 years have passed, but according to those on Earth, the ship comes back 76 years after launch.
From the viewpoint of the astronaut, on-board clocks seem to be running normally. The star ahead seems to be approaching at a speed of 0.87 lightyears per ship-year. The universe would appear contracted along the direction of travel to half the size it had when the ship was at rest; the distance between that star and the Sun would seem to be 16 light years as measured by the astronaut.
At higher speeds, the time onboard will run even slower, so the astronaut could travel to the center of the Milky Way (30 kly from Earth) and back in 40 years ship-time. But the speed according to Earth clocks will always be less than 1 lightyear per Earth year, so, when back home, the astronaut will find that 60 thousand years will have passed on Earth.
Constant acceleration.
Regardless of how it is achieved, if a propulsion system can produce acceleration continuously from departure to destination, then this will be the fastest method of travel. If the propulsion system drives the ship faster and faster for the first half of the journey, then turns around and brakes the craft so that it arrives at the destination at a standstill, this is a constant acceleration journey. If this were performed at nearly 1g, this would have the added advantage of producing artificial "gravity". This is, however, prohibitively expensive with current technology.
From the planetary observer perspective the ship will appear to steadily accelerate but more slowly as it approaches the speed of light. The ship will be close to the speed of light after about a year of accelerating and remain at that speed until it brakes for the end of the journey.
From the ship perspective there will be no top limit on speed – the ship keeps going faster and faster the whole first half. This happens because the ship's time sense slows down – relative to the planetary observer – the more it approaches the speed of light.
The result is an impressively fast journey if you are in the ship.
By transmission.
If physical entities could be transmitted as information and reconstructed at a destination, travel at nearly the speed of light would be possible, which for the "travelers" would be instantaneous. However, sending an atom-by-atom description of (say) a human body would be a daunting task. Extracting and sending only a computer brain simulation is a significant part of that problem. "Journey" time would be the light-travel time plus the time needed to encode, send and reconstruct the whole transmission. In addition, the receiver system would have to be sent ahead and be in place, this would presumably require a lead time of much more than the light-travel time.
Propulsion.
Rocket concepts.
All rocket concepts are limited by the rocket equation, which sets the characteristic velocity available as a function of exhaust velocity and mass ratio, the ratio of initial ("M"0, including fuel) to final ("M"1, fuel depleted) mass.
Very high specific power, the ratio of thrust to total vehicle mass, is required to reach interstellar targets within sub-century time-frames. Some heat transfer is inevitable and a tremendous heating load must be adequately handled.
Thus, for interstellar rocket concepts of all technologies, a key engineering problem (seldom explicitly discussed) is limiting the heat transfer from the exhaust stream back into the vehicle.
Ion engine.
A type of electric propulsion, spacecraft such as Dawn use an ion engine. In an ion engine, electric power is used to create charged particles of the fuel, usually the gas xenon, and accelerate them to extremely high velocities. The exhaust velocity of conventional rockets is limited by the chemical energy stored in the fuel’s molecular bonds, which limits the thrust to about 5 km/s. This gives them power (for lift-off from Earth, for example) but limits the top speed. By contrast, ion engines have low force, but the top speed in principle is limited only by the electrical power available on the spacecraft and on the gas ions being accelerated. The exhaust speed of the charged particles range from 15 km/s to 35 km/s.<ref name="http://www.iflscience.com"></ref>
Fission-electric.
Nuclear-electric or plasma engines, operating for long periods at low thrust and powered by fission reactors, have the potential to reach speeds much greater than chemically powered vehicles or nuclear-thermal rockets. Such vehicles probably have the potential to power Solar System exploration with reasonable trip times within the current century. Because of their low-thrust propulsion, they would be limited to off-planet, deep-space operation. Electrically powered spacecraft propulsion powered by a portable power-source, say a nuclear reactor, producing only small accelerations, would take centuries to reach for example 15% of the velocity of light, thus unsuitable for interstellar flight during a single human lifetime.
Fission-fragment.
Fission-fragment rockets use nuclear fission to create high-speed jets of fission fragments, which are ejected at speeds of up to 12,000 km/s. With fission, the energy output is approximately 0.1% of the total mass-energy of the reactor fuel and limits the effective exhaust velocity to about 5% of the velocity of light. For maximum velocity, the reaction mass should optimally consist of fission products, the "ash" of the primary energy source, in order that no extra reaction mass need be book-kept in the mass ratio. This is known as a fission-fragment rocket. thermal-propulsion engines such as NERVA produce sufficient thrust, but can only achieve relatively low-velocity exhaust jets, so to accelerate to the desired speed would require an enormous amount of fuel.
Nuclear pulse.
Based on work in the late 1950s to the early 1960s, it has been technically possible to build spaceships with nuclear pulse propulsion engines, i.e. driven by a series of nuclear explosions. This propulsion system contains the prospect of very high specific impulse (space travel's equivalent of fuel economy) and high specific power.
Project Orion team member, Freeman Dyson, proposed in 1968 an interstellar spacecraft using nuclear pulse propulsion that used pure deuterium fusion detonations with a very high fuel-burnup fraction. He computed an exhaust velocity of 15,000 km/s and a 100,000-tonne space vehicle able to achieve a 20,000 km/s delta-v allowing a flight-time to Alpha Centauri of 130 years. Later studies indicate that the top cruise velocity that can theoretically be achieved by a Teller-Ulam thermonuclear unit powered Orion starship, assuming no fuel is saved for slowing back down, is about 8% to 10% of the speed of light (0.08-0.1c). An atomic (fission) Orion can achieve perhaps 3%-5% of the speed of light. A nuclear pulse drive starship powered by Fusion-antimatter catalyzed nuclear pulse propulsion units would be similarly in the 10% range and pure Matter-antimatter annihilation rockets would be theoretically capable of obtaining a velocity between 50% to 80% of the speed of light. In each case saving fuel for slowing down halves the maximum speed. The concept of using a magnetic sail to decelerate the spacecraft as it approaches its destination has been discussed as an alternative to using propellant, this would allow the ship to travel near the maximum theoretical velocity. Alternative designs utilizing similar principles include Project Longshot, Project Daedalus, and Mini-Mag Orion. The principle of external nuclear pulse propulsion to maximize survivable power has remained common among serious concepts for interstellar flight without external power beaming and for very high-performance interplanetary flight.
In the 1970s the Nuclear Pulse Propulsion concept further was refined by Project Daedalus by use of externally triggered inertial confinement fusion, in this case producing fusion explosions via compressing fusion fuel pellets with high-powered electron beams. Since then, lasers, ion beams, neutral particle beams and hyper-kinetic projectiles have been suggested to produce nuclear pulses for propulsion purposes.
A current impediment to the development of "any" nuclear-explosion-powered spacecraft is the 1963 Partial Test Ban Treaty, which includes a prohibition on the detonation of any nuclear devices (even non-weapon based) in outer space. This treaty would therefore need to be renegotiated, although a project on the scale of an interstellar mission using currently foreseeable technology would probably require international cooperation on at least the scale of the International Space Station.
Nuclear fusion rockets.
Fusion rocket starships, powered by nuclear fusion reactions, should conceivably be able to reach speeds of the order of 10% of that of light, based on energy considerations alone. In theory, a large number of stages could push a vehicle arbitrarily close to the speed of light. These would "burn" such light element fuels as deuterium, tritium, 3He, 11B, and 7Li. Because fusion yields about 0.3–0.9% of the mass of the nuclear fuel as released energy, it is energetically more favorable than fission, which releases <0.1% of the fuel's mass-energy. The maximum exhaust velocities potentially energetically available are correspondingly higher than for fission, typically 4–10% of c. However, the most easily achievable fusion reactions release a large fraction of their energy as high-energy neutrons, which are a significant source of energy loss. Thus, although these concepts seem to offer the best (nearest-term) prospects for travel to the nearest stars within a (long) human lifetime, they still involve massive technological and engineering difficulties, which may turn out to be intractable for decades or centuries.
Early studies include Project Daedalus, performed by the British Interplanetary Society in 1973–1978, and Project Longshot, a student project sponsored by NASA and the US Naval Academy, completed in 1988. Another fairly detailed vehicle system, "Discovery II", designed and optimized for crewed Solar System exploration, based on the D3He reaction but using hydrogen as reaction mass, has been described by a team from NASA's Glenn Research Center. It achieves characteristic velocities of >300 km/s with an acceleration of ~1.7•10−3 "g", with a ship initial mass of ~1700 metric tons, and payload fraction above 10%. Although these are still far short of the requirements for interstellar travel on human timescales, the study seems to represent a reasonable benchmark towards what may be approachable within several decades, which is not impossibly beyond the current state-of-the-art. Based on the concept's 2.2% burnup fraction it could achieve a pure fusion product exhaust velocity of ~3,000 km/s.
Antimatter rockets.
An antimatter rocket would have a far higher energy density and specific impulse than any other proposed class of rocket. If energy resources and efficient production methods are found to make antimatter in the quantities required and store it safely, it would be theoretically possible to reach speeds approaching that of light. Then relativistic time dilation would become more noticeable, thus making time pass at a slower rate for the travelers as perceived by an outside observer, reducing the trip time experienced by human travelers.
Supposing the production and storage of antimatter should become practical, two further problems would present and need to be solved. First, in the annihilation of antimatter, much of the energy is lost in very penetrating high-energy gamma radiation, and especially also in neutrinos, so that substantially less than "mc"2 would actually be available if the antimatter were simply allowed to annihilate into radiations thermally. Even so, the energy available for propulsion would probably be substantially higher than the ~1% of "mc"2 yield of nuclear fusion, the next-best rival candidate.
Second, once again heat transfer from exhaust to vehicle seems likely to deposit enormous wasted energy into the ship, considering the large fraction of the energy that goes into penetrating gamma rays. Even assuming biological shielding were provided to protect the passengers, some of the energy would inevitably heat the vehicle, and may thereby prove limiting. This requires consideration for serious proposals if useful accelerations are to be achieved, because the energies involved (e.g. for 0.1"g" ship acceleration, approaching 0.3 trillion watts per ton of ship mass) are very large.
More recently, Winterberg proposed that a matter-antimatter GeV gamma ray laser photon rocket is possible by a relativistic proton-antiproton pinch discharge, where the recoil from the laser beam is transmitted by the Moessbauer effect to the spacecraft.
Rockets with an external energy source.
Rockets deriving their power from external sources, such as a laser, could replace their internal energy source with an energy collector, potentially reducing the mass of the ship greatly and allowing much higher travel speeds. Geoffrey A. Landis has proposed for an interstellar probe, with energy supplied by an external laser from a base station powering an Ion thruster.
Non-rocket concepts.
A problem with all traditional rocket propulsion methods is that the spacecraft would need to carry its fuel with it, thus making it very massive, in accordance with the rocket equation. Some concepts attempt to escape from this problem ():
Interstellar ramjets.
In 1960, Robert W. Bussard proposed the Bussard ramjet, a fusion rocket in which a huge scoop would collect the diffuse hydrogen in interstellar space, "burn" it on the fly using a proton–proton fusion reaction, and expel it out of the back. Later calculations with more accurate estimates suggest that the thrust generated would be less than the drag caused by any conceivable scoop design. Yet the idea is attractive because the fuel would be collected "en route" (commensurate with the concept of "energy harvesting"), so the craft could theoretically accelerate to near the speed of light.
Beamed propulsion.
A light sail or magnetic sail powered by a massive laser or particle accelerator in the home star system could potentially reach even greater speeds than rocket- or pulse propulsion methods, because it would not need to carry its own reaction mass and therefore would only need to accelerate the craft's payload. Robert L. Forward proposed a means for decelerating an interstellar light sail in the destination star system without requiring a laser array to be present in that system. In this scheme, a smaller secondary sail is deployed to the rear of the spacecraft, whereas the large primary sail is detached from the craft to keep moving forward on its own. Light is reflected from the large primary sail to the secondary sail, which is used to decelerate the secondary sail and the spacecraft payload.
A magnetic sail could also decelerate at its destination without depending on carried fuel or a driving beam in the destination system, by interacting with the plasma found in the solar wind of the destination star and the interstellar medium.
The following table lists some example concepts using beamed laser propulsion as proposed by the physicist Robert L. Forward:
Pre-accelerated fuel.
Achieving start-stop interstellar trip times of less than a human lifetime require mass-ratios of between 1,000 and 1,000,000, even for the nearer stars. This could be achieved by multi-staged vehicles on a vast scale. Alternatively large linear accelerators could propel fuel to fission propelled space-vehicles, avoiding the limitations of the Rocket equation.
Speculative methods.
Quark matter.
Scientist T. Marshall Eubanks thinks that nuggets of condensed quark matter may exist at the centers of some asteroids, created during the Big Bang and each nugget with a mass of 1010 to 1011 kg. If so these could be an enormous source of energy, as the nuggets could be used to generate huge quantities of antimatter—about a million tonnes of antimatter per nugget. This would be enough to propel a spacecraft close to the speed of light.
Hawking radiation rockets.
In a black hole starship, a parabolic reflector would reflect Hawking radiation from an artificial black hole. In 2009, Louis Crane and Shawn Westmoreland of Kansas State University published a paper investigating the feasibility of this idea. Their conclusion was that it was on the edge of possibility, but that quantum gravity effects that are presently unknown may make it easier or make it impossible.
Magnetic monopole rockets.
If some of the Grand unification models are correct, e.g. 't Hooft–Polyakov, it would be possible to construct a photonic engine that uses no antimatter thanks to the magnetic monopole that hypothetically can catalyze the decay of a proton to a positron and π0-meson:
π0 decays rapidly to two photons, and the positron annihilates with an electron to give two more photons. As a result, a hydrogen atom turns into four photons and only the problem of a mirror remains unresolved.
A magnetic monopole engine could also work on a once-through scheme such as the Bussard ramjet (see below).
At the same time, most of the modern Grand unification theories such as M-theory predict no magnetic monopoles, which casts doubt on this attractive idea.
Faster-than-light travel.
Scientists and authors have postulated a number of ways by which it might be possible to surpass the speed of light. Even the most serious-minded of these are speculative.
It is also debated whether this is possible, in part, because of causality concerns, because in essence travel faster than light is equivalent to going back in time. Proposed mechanisms for faster-than-light travel within the theory of general relativity require the existence of exotic matter.
Alcubierre drive.
According to Einstein's equation of general relativity, spacetime is curved:
General relativity may permit the travel of an object faster than light in curved spacetime.
One could imagine exploiting the curvature to take a "shortcut" from one point to another. This is one form of the warp drive concept.
In physics, the Alcubierre drive is based on an argument that the curvature could take the form of a wave in which a spaceship might be carried in a "bubble". Space would be collapsing at one end of the bubble and expanding at the other end. The motion of the wave would carry a spaceship from one space point to another in less time than light would take through unwarped space. Nevertheless, the spaceship would not be moving faster than light within the bubble. This concept would require the spaceship to incorporate a region of exotic matter, or "negative mass".
Artificial gravity control.
Scientist Lance Williams thinks that gravity can be controlled artificially through electromagnetic control.
Wormholes.
Wormholes are conjectural distortions in spacetime that theorists postulate could connect two arbitrary points in the universe, across an Einstein–Rosen Bridge. It is not known whether wormholes are possible in practice. Although there are solutions to the Einstein equation of general relativity that allow for wormholes, all of the currently known solutions involve some assumption, for example the existence of negative mass, which may be unphysical. However, Cramer "et al." argue that such wormholes might have been created in the early universe, stabilized by cosmic string. The general theory of wormholes is discussed by Visser in the book "Lorentzian Wormholes".
Designs and studies.
Enzmann starship.
The Enzmann starship, as detailed by G. Harry Stine in the October 1973 issue of "Analog", was a design for a future starship, based on the ideas of Dr. Robert Duncan-Enzmann. The spacecraft itself as proposed used a 12,000,000 ton ball of frozen deuterium to power 12–24 thermonuclear pulse propulsion units. Twice as long as the Empire State Building and assembled in-orbit, the spacecraft was part of a larger project preceded by interstellar probes and telescopic observation of target star systems.
Project Hyperion.
Project Hyperion, one of the projects of Icarus Interstellar.
NASA research.
NASA has been researching interstellar travel since its formation, translating important foreign language papers and conducting early studies on applying fusion propulsion, in the 1960s, and laser propulsion, in the 1970s, to interstellar travel.
The NASA Breakthrough Propulsion Physics Program (terminated in FY 2003 after a 6-year, $1.2-million study, because "No breakthroughs appear imminent.") identified some breakthroughs that are needed for interstellar travel to be possible.
Geoffrey A. Landis of NASA's Glenn Research Center states that a laser-powered interstellar sail ship could possibly be launched within 50 years, using new methods of space travel. "I think that ultimately we're going to do it, it's just a question of when and who," Landis said in an interview. Rockets are too slow to send humans on interstellar missions. Instead, he envisions interstellar craft with extensive sails, propelled by laser light to about one-tenth the speed of light. It would take such a ship about 43 years to reach Alpha Centauri, if it passed through the system. Slowing down to stop at Alpha Centauri could increase the trip to 100 years, whereas a journey without slowing down raises the issue of making sufficiently accurate and useful observations and measurements during a fly-by.
100 Year Starship study.
The 100 Year Starship (100YSS) is the name of the overall effort that will, over the next century, work toward achieving interstellar travel. The effort will also go by the moniker 100YSS. The 100 Year Starship study is the name of a one-year project to assess the attributes of and lay the groundwork for an organization that can carry forward the 100 Year Starship vision.
Dr. Harold ("Sonny") White from NASA's Johnson Space Center is a member of Icarus Interstellar, the nonprofit foundation whose mission is to realize interstellar flight before the year 2100. At the 2012 meeting of 100YSS, he reported using a laser to try to warp spacetime by 1 part in 10 million with the aim of helping to make interstellar travel possible.
Non-profit organizations.
A few organisations dedicated to interstellar propulsion research and advocacy for the case exist worldwide. These are still in their infancy, but are already backed up by a membership of a wide variety of scientists, students and professionals.
Skepticism.
The energy requirements make interstellar travel very difficult. It has been reported that at the 2008 Joint Propulsion Conference, multiple experts opined that it was improbable that humans would ever explore beyond the Solar System. Brice N. Cassenti, an associate professor with the Department of Engineering and Science at Rensselaer Polytechnic Institute, stated at least the total energy output of the entire world [in a given year] would be required to send a probe to the nearest star.

</doc>
<doc id="14844" url="http://en.wikipedia.org/wiki?curid=14844" title="Interior Gateway Routing Protocol">
Interior Gateway Routing Protocol

Interior Gateway Routing Protocol (IGRP) is a distance vector interior routing protocol (IGP) developed by Cisco. It is used by routers to exchange routing data within an autonomous system.
IGRP is a proprietary protocol. IGRP was created in part to overcome the limitations of RIP (maximum hop count of only 15, and a single routing metric) when used within large networks. IGRP supports multiple metrics for each route, including bandwidth, delay, load, MTU, and reliability; to compare two routes these metrics are combined together into a single metric, using a formula which can be adjusted through the use of pre-set constants. By default, the IGRP composite metric is a sum of the segment delays and the lowest segment bandwidth. The maximum configurable hop count of IGRP-routed packets is 255 (default 100), and routing updates are broadcast every 90 seconds (by default). IGRP uses protocol number 9 for communication.
IGRP is considered a classful routing protocol. Because the protocol has no field for a subnet mask, the router assumes that all subnetwork addresses within the same Class A, Class B, or Class C network have the same subnet mask as the subnet mask configured for the interfaces in question. This contrasts with classless routing protocols that can use variable length subnet masks. Classful protocols have become less popular as they are wasteful of IP address space.
Advancement.
In order to address the issues of address space and other factors, Cisco created EIGRP (Enhanced Interior Gateway Routing Protocol). EIGRP adds support for VLSM (variable length subnet mask) and adds the Diffusing Update Algorithm (DUAL) in order to improve routing and provide a loopless environment. EIGRP has completely replaced IGRP, making IGRP an obsolete routing protocol. In Cisco IOS versions 12.3 and greater, IGRP is completely unsupported. In the new Cisco CCNA curriculum (version 4), IGRP is mentioned only briefly, as an "obsolete protocol".

</doc>
<doc id="14845" url="http://en.wikipedia.org/wiki?curid=14845" title="IRS (disambiguation)">
IRS (disambiguation)

IRS is the United States Internal Revenue Service.
IRS may also refer to:

</doc>
<doc id="14848" url="http://en.wikipedia.org/wiki?curid=14848" title="Indo-European languages">
Indo-European languages

The Indo-European languages are a family of several hundred related languages and dialects. There are about 445 Indo-European languages and dialects, according to the estimate by "Ethnologue", with over two-thirds (313) of them belonging to the Indo-Iranian branch alone. The Indo-European family includes most major current languages of South Asia, Europe, and parts of Western and Central Asia. It was also predominant in ancient Anatolia (present-day Turkey), and the ancient Tarim Basin (present-day Northwest China). With written attestations appearing since the Bronze Age in the form of the Anatolian languages and Mycenaean Greek, the Indo-European family is significant to the field of historical linguistics as possessing the second-longest recorded history, after the Afroasiatic family.
Indo-European languages are spoken by almost 3 billion native speakers, the largest number by far for any recognised language family. Of the 20 languages with the largest numbers of native speakers according to "Ethnologue", 11 are Indo-European: Spanish, English, Hindi, Portuguese, Bengali, Russian, Punjabi, German, French, Marathi, and Urdu, accounting for over 1.7 billion native speakers. Several disputed proposals link Indo-European to other major language families.
Etymology.
Thomas Young coined the term "Indo-European" in 1813, from Indo- + European, after the geographical extremes of the language family: from Western Europe to Northeast India.
History of Indo-European linguistics.
In the 16th century, European visitors to the Indian subcontinent began to suggest similarities between Indo-Aryan, Iranian, and European languages. In 1583, Thomas Stephens, an English Jesuit missionary in Goa, in a letter to his brother that was not published until the 20th century, noted similarities between Indian languages, specifically Sanskrit, and Greek and Latin.
Another account to mention the ancient language Sanskrit came from Filippo Sassetti (born in Florence in 1540), a merchant who travelled to the Indian subcontinent. Writing in 1585, he noted some word similarities between Sanskrit and Italian (these included devaḥ/dio "God", sarpaḥ/serpe "serpent", sapta/sette "seven", aṣṭa/otto "eight", nava/nove "nine"). However, neither Stephens's nor Sassetti's observations led to further scholarly inquiry.
In 1647, Dutch linguist and scholar Marcus Zuerius van Boxhorn noted the similarity among Indo-European languages, and supposed that they derived from a primitive common language he called "Scythian". He included in his hypothesis Dutch, Albanian, Greek, Latin, Persian, and German, later adding Slavic, Celtic, and Baltic languages. However, Van Boxhorn's suggestions did not become widely known and did not stimulate further research.
The Ottoman Turkish traveller Evliya Çelebi, who visited Vienna in 1665–1666 as part of a diplomatic mission, noted a few similarities between words in German and Persian.
Gaston Coeurdoux and others made observations of the same type. Coeurdoux made a thorough comparison of Sanskrit, Latin and Greek conjugations in the late 1760s to suggest a relationship between them. Similarly, Mikhail Lomonosov compared different language groups of the world including Slavic, Baltic ("Kurlandic"), Iranian ("Medic"), Finnish, Chinese, "Hottentot", and others. He emphatically expressed the antiquity of the linguistic stages accessible to comparative method in the drafts for his "Russian Grammar" (published 1755).
The hypothesis reappeared in 1786 when Sir William Jones first lectured on the striking similarities between three of the oldest languages known in his time: Latin, Greek, and Sanskrit, to which he tentatively added Gothic, Celtic, and Persian, though his classification contained some inaccuracies and omissions.
It was Thomas Young who in 1813 first used the term "Indo-European", which became the standard scientific term through the work of Franz Bopp, whose systematic comparison of these and other old languages supported the hypothesis. A synonym for "Indo-European" is "Indo-Germanic" ("Idg." or "IdG."), which defines the family by indicating its southeasternmost and northwesternmost branches. In most languages this term is dated or less common, whereas in German it is still the standard scientific term. Advocates of "Indo-Germanic" often claim that "Indo-European" is misleading because many historic and several living European languages (the unrelated Uralic languages, as well as several others, are also spoken in Europe) do not belong to this family. Advocates of "Indo-European" counter that "Indo-Germanic" is misleading because many of the European languages included are not in fact Germanic.
Franz Bopp's "Comparative Grammar", which appeared between 1833 and 1852, is the beginning of Indo-European studies as an academic discipline. The classical phase of Indo-European comparative linguistics leads from this work to August Schleicher's 1861 "Compendium" and up to Karl Brugmann's "Grundriss", published in the 1880s. Brugmann's "junggrammatische" reevaluation of the field and Ferdinand de Saussure's development of the laryngeal theory may be considered the beginning of "modern" Indo-European studies. The generation of Indo-Europeanists active in the last third of the 20th century (such as Calvert Watkins, Jochem Schindler and Helmut Rix) developed a better understanding of morphology and, in the wake of Kuryłowicz's 1956 "Apophonie", understanding of the ablaut.
Classification.
The various subgroups of the Indo-European language family include ten major branches, given in the chronological order of their emergence according to David Anthony:
In addition to the classical ten branches listed above, several extinct and little-known languages have existed:
Grouping.
Membership of these languages in the Indo-European language family is determined by genetic relationships, meaning that all members are presumed descendants of a common ancestor, Proto-Indo-European. (The word "genetic" here has nothing to do with human genetics; it refers to relationships between languages.) Membership in the various branches, groups and subgroups of Indo-European is also genetic, but here the defining factors are "shared innovations" among various languages, suggesting a common ancestor that split off from other Indo-European groups. For example, what makes the Germanic languages a branch of Indo-European is that much of their structure and phonology can be stated in rules that apply to all of them. Many of their common features are presumed innovations that took place in Proto-Germanic, the source of all the Germanic languages.
Tree versus wave model.
The "tree model" is considered an appropriate representation of the genetic history of a language family if communities do not remain in contact after their languages have started to diverge. In this case, subgroups defined by shared innovations form a nested pattern. The tree model is not appropriate in cases where languages remain in contact as they diversify; in such cases subgroups may overlap, and the "wave model" is a more accurate representation. Most approaches to Indo-European subgrouping to date have assumed that the tree model is by and large valid for Indo-European; however, there is also a long tradition of wave-model approaches.
In addition to genetic changes, many of the early changes in Indo-European languages can be attributed to language contact. It has been asserted, for example, that many of the more striking features shared by Italic languages (Latin, Oscan, Umbrian, etc.) might well be areal features. More certainly, very similar-looking alterations in the systems of long vowels in the West Germanic languages greatly postdate any possible notion of a proto-language innovation (and cannot readily be regarded as "areal", either, because English and continental West Germanic were not a linguistic area). In a similar vein, there are many similar innovations in Germanic and Balto-Slavic that are far more likely areal features than traceable to a common proto-language, such as the uniform development of a high vowel (*"u" in the case of Germanic, *"i/u" in the case of Baltic and Slavic) before the PIE syllabic resonants *"ṛ,* ḷ, *ṃ, *ṇ", unique to these two groups among IE languages, which is in agreement with the wave model. The Balkan sprachbund even features areal convergence among members of very different branches.
Using an extension to the "Ringe-Warnow model of language evolution", early IE was confirmed to have featured limited contact between distinct lineages, whereas only the Germanic subfamily exhibited a less treelike behaviour as it acquired some characteristics from neighbours early in its evolution rather than from its direct ancestors. The internal diversification of especially West Germanic is cited to have been radically non-treelike.
Proposed subgroupings.
Specialists have postulated the existence of higher-order subgroups such as Italo-Celtic, Graeco-Armenian, Graeco-Aryan, and Balto-Slavo-Germanic. However, unlike the ten traditional branches, these are all controversial to a greater or lesser degree.
The Italo-Celtic subgroup was at one point uncontroversial, considered by Antoine Meillet to be even better established than Balto-Slavic. The main lines of evidence included the genitive suffix "-ī"; the superlative suffix "-m̥mo"; the change of /p/ to /kʷ/ before another /kʷ/ in the same word (as in "penkʷe" > "*kʷenkʷe" > Latin "quīnque", Old Irish "cóic"); and the subjunctive morpheme "-ā-". This evidence was prominently challenged by Calvert Watkins; but other, stronger evidence has since emerged.
Evidence for a relationship between Greek and Armenian includes the regular change of the second laryngeal to "a" at the beginnings of words, as well as terms for "woman" and "sheep". Greek and Indo-Iranian share innovations mainly in verbal morphology and patterns of nominal derivation. Relations have also been proposed between Phrygian and Greek, and between Thracian and Armenian. Some fundamental shared features, like the aorist (a verb form denoting action without reference to duration or completion) having the perfect active particle -s fixed to the stem, link this group closer to Anatolian languages and Tocharian. Shared features with Balto-Slavic languages, on the other hand (especially present and preterit formations), might be due to later contacts.
The Indo-Hittite hypothesis proposes the Indo-European language family to consist of two main branches: one represented by the Anatolian languages and another branch encompassing all other Indo-European languages. Features that separate Anatolian from all other branches of Indo-European (such as the gender or the verb system) have been interpreted alternately as archaic debris or as innovations due to prolonged isolation. Points proffered in favour of the Indo-Hittite hypothesis are the (non-universal) Indo-European agricultural terminology in Anatolia and the preservation of laryngeals. However, in general this hypothesis is considered to attribute too much weight to the Anatolian evidence. According to another view, the Anatolian subgroup left the Indo-European parent language comparatively late, approximately at the same time as Indo-Iranian and later than the Greek or Armenian divisions. A third view, especially prevalent in the so-called French school of Indo-European studies, holds that extant similarities in non-satem languages in general — including Anatolian — might be due to their peripheral location in the Indo-European language area and early separation, rather than indicating a special ancestral relationship. Hans J. Holm, based on lexical calculations, arrives at a picture roughly replicating the general scholarly opinion and refuting the Indo-Hittite hypothesis.
Satem and centum languages.
The division of the Indo-European languages into a Satem vs. a Centum group was devised by Peter von Bradke in his 1890 work, "Concerning Method and Conclusions of Aryan (Indo-Germanic) Studies". In it, von Bradke described a division similar to that of Karl Brugmann's (1886), saying that the original "Aryans" knew two kinds of guttural sounds, the guttural or velar and palatal rows, each of which were aspirated and unaspirated. The velars were to be viewed as gutturals in a "narrow sense," and considered "pure K-sounds." Palatals were "often followed by labialization." This latter distinction led von Bradke to divide the "palatal series" into a "group as a spirant" and a "pure K-sound", typified by the words "satem" and "centum" respectively.
 the grouping of satem languages is commonly inferred as an innovative change that occurred just once, and subsequently spread over a large cohesive territory or PIE continuum that affected all but the peripheral areas. Kortlandt proposes the ancestors of Balts and Slavs took part in satemization and were then drawn into the western Indo-European sphere.
Suggested macrofamilies.
Some linguists propose that Indo-European languages form part of one of several hypothetical macrofamilies. However, these theories remain highly controversial, not being accepted by most linguists in the field. Some of smaller proposed macrofamilies are:
Other, greater proposed families including Indo-European languages, are:
Objections to such groupings are not based on any theoretical claim about the likely historical existence or non-existence of such macrofamilies; it is entirely reasonable to suppose that they might have existed. The serious difficulty lies in identifying the details of actual relationships between language families, because it is very hard to find concrete evidence that transcends chance resemblance, or is not equally likely explained as being due to borrowing (including Wanderwörter, which can travel very long distances). Because the signal-to-noise ratio in historical linguistics declines steadily over time, at great enough time-depths it becomes open to reasonable doubt that it can even be possible to distinguish between signal and noise.
Evolution.
Proto-Indo-European.
The proposed Proto-Indo-European language (PIE) is the hypothetical common ancestor of the Indo-European languages, spoken by the Proto-Indo-Europeans. From the 1960s, knowledge of Anatolian became certain enough to establish its relationship to PIE. Using the method of internal reconstruction an earlier stage, called Pre-Proto-Indo-European, has been proposed.
PIE was an inflected language, in which the grammatical relationships between words were signaled through inflectional morphemes (usually endings). The roots of PIE are basic morphemes carrying a lexical meaning. By addition of suffixes, they form stems, and by addition of desinences (usually endings), these form grammatically inflected words (nouns or verbs). The hypothetical Indo-European verb system is complex and, like the noun, exhibits a system of ablaut.
Diversification.
The diversification of the parent language into the attested branches of daughter languages is historically unattested. The timeline of the evolution of the various daughter languages, on the other hand, is mostly undisputed, quite regardless of the question of Indo-European origins.
Using a mathematical analysis borrowed from evolutionary biology, Don Ringe and Tandy Warnow propose the following evolutionary tree of Indo-European branches:
David Anthony proposes the following sequence:
From 1500 BC the following sequence may be given:
Important languages for reconstruction.
In reconstructing the history of the Indo-European languages and the form of the Proto-Indo-European language, some languages have been of particular importance. These generally include the ancient Indo-European languages that are both well-attested and documented at an early date, although some languages from later periods are important if they are particularly linguistically conservative (most notably, Lithuanian). Early poetry is of special significance because of the rigid poetic meter normally employed, which makes it possible to reconstruct a number of features (e.g. vowel length) that were either unwritten or corrupted in the process of transmission down to the earliest extant written manuscripts.
Most important of all:
Other primary sources:
Other secondary sources, of lesser value due to poor attestation:
Other secondary sources, of lesser value due to extensive phonological changes and relatively limited attestation:
Sound changes.
As the Proto-Indo-European (PIE) language broke up, its sound system diverged as well, changing according to various sound laws evidenced in the daughter languages.
PIE is normally reconstructed with a complex system of 15 stop consonants, including an unusual three-way phonation (voicing) distinction between voiceless, voiced and "voiced aspirated" (i.e. breathy voiced) stops, and a three-way distinction among velar consonants ("k"-type sounds) between "palatal" "ḱ ǵ ǵh", "plain velar" "k g gh" and labiovelar "kʷ gʷ gʷh". (The correctness of the terms "palatal" and "plain velar" is disputed; see Proto-Indo-European phonology.) All daughter languages have reduced the number of distinctions among these sounds, often in divergent ways.
As an example, in English, one of the Germanic languages, the following are some of the major changes that happened:
None of the daughter-language families (except possibly Anatolian, particularly Luvian) reflect the plain velar stops differently from the other two series, and there is even a certain amount of dispute whether this series existed at all in PIE. The major distinction between "centum" and "satem" languages corresponds to the outcome of the PIE plain velars:
The three-way PIE distinction between voiceless, voiced and voiced aspirated stops is considered extremely unusual from the perspective of linguistic typology—particularly in the existence of voiced aspirated stops without a corresponding series of voiceless aspirated stops. None of the various daughter-language families continue it unchanged, with numerous "solutions" to the apparently unstable PIE situation:
Among the other notable changes affecting consonants are:
The following table shows the basic outcomes of PIE consonants in some of the most important daughter languages for the purposes of reconstruction. For a fuller table, see Indo-European sound laws.
Comparison of conjugations.
The following table presents a comparison of conjugations of the thematic present indicative of the verbal root *bʰer- of the English verb "to bear" and its reflexes in various early attested IE languages and their modern descendants or relatives, showing that all languages had in the early stage an inflectional verb system.
While similarities are still visible between the modern descendants and relatives of these ancient languages, the differences have increased over time. Some IE languages have moved from synthetic verb systems to largely periphrastic systems. The pronouns of periphrastic forms are in brackets when they appear. Some of these verbs have undergone a change in meaning as well.
Sources.
</dl>

</doc>
<doc id="14849" url="http://en.wikipedia.org/wiki?curid=14849" title="Illinois">
Illinois

Illinois ( ) is a state in the Midwestern United States. It is the 5th most populous state and 25th largest state in terms of land area, and is often noted as a microcosm of the entire country. With Chicago in the northeast, small industrial cities and great agricultural productivity in central and northern Illinois, and natural resources like coal, timber, and petroleum in the south, Illinois has a diverse economic base and is a major transportation hub. The Port of Chicago connects the state to other global ports from the Great Lakes, via the Saint Lawrence Seaway, to the Atlantic Ocean; as well as the Great Lakes to the Mississippi River, via the Illinois River. For decades, O'Hare International Airport has been ranked as one of the world's busiest airports. Illinois has long had a reputation as a bellwether both in social and cultural terms and politics.
Although today the state's largest population center is around Chicago in the northern part of the state, the state's European population grew first in the west, with French Canadians who settled along the Mississippi River, and gave the area the name, "Illinois". After the American Revolutionary War established the United States, American settlers began arriving from Kentucky in the 1810s via the Ohio River, and the population grew from south to north. In 1818, Illinois achieved statehood. After construction of the Erie Canal increased traffic and trade through the Great Lakes, Chicago was founded in the 1830s on the banks of the Chicago River, at one of the few natural harbors on southern Lake Michigan. John Deere's invention of the self-scouring steel plow turned Illinois' rich prairie into some of the world's most productive and valuable farmlands, attracting immigrant farmers from Germany and Sweden. Railroads carried immigrants to new homes, as well as being used to ship their commodity crops out to markets.
By 1900, the growth of industrial jobs in the northern cities and coal mining in the central and southern areas attracted immigrants from Eastern and Southern Europe. Illinois was an important manufacturing center during both world wars. The Great Migration from the South established a large community of African Americans in Chicago, who created the city's famous jazz and blues cultures.
Three U.S. presidents have been elected while living in Illinois: Abraham Lincoln, Ulysses S. Grant, and Barack Obama. Additionally, Ronald Reagan, whose political career was based in California, was the only US President born and raised in Illinois. Today, Illinois honors Lincoln with its official state slogan, "Land of Lincoln", which has been displayed on its license plates since 1954. The Abraham Lincoln Presidential Library and Museum is located in the state capital of Springfield.
Etymology.
"Illinois" is the modern spelling for the early French Catholic missionaries and explorers' name for the Illinois Native Americans, a name that was spelled in many different ways in the early records.
American scholars previously thought the name "Illinois" meant "man" or "men" in the Miami-Illinois language, with the original "iliniwek" transformed via French into Illinois. This etymology is not supported by the Illinois language, as the word for 'man' is "ireniwa" and plural 'men' is "ireniwaki". The name "Illiniwek" has also been said to mean "tribe of superior men", which is a false etymology. The name "Illinois" derives from the Miami-Illinois verb "irenwe·wa" "he speaks the regular way". This was taken into the Ojibwe language, perhaps in the Ottawa dialect, and modified into "ilinwe·" (pluralized as "ilinwe·k"). The French borrowed these forms, changing the /we/ ending to spell it as "-ois," a transliteration for its pronunciation in French of that time. The current spelling form, "Illinois", began to appear in the early 1670s, when French colonists had settled in the western area. The Illinois' name for themselves, as attested in all three of the French missionary-period dictionaries of Illinois, was "Inoka", of unknown meaning and unrelated to the other terms.
History.
Pre-European.
American Indians of successive cultures lived along the waterways of the Illinois area for thousands of years before the arrival of Europeans. The Koster Site has been excavated and demonstrates 7,000 years of continuous habitation. Cahokia, the largest regional chiefdom and urban center of the Pre-Columbian Mississippian culture, was located near present-day Collinsville, Illinois. They built an urban complex of more than 100 platform and burial mounds, a 50 acre plaza larger than 35 football fields, and a woodhenge of sacred cedar, all in a planned design expressing the culture's cosmology. Monks Mound, the center of the site, is the largest precolumbian structure north of the Valley of Mexico. It is 100 ft high, 951 ft long, 836 ft wide and covers 13.8 acre. It contains about 814000 cuyd of earth. It was topped by a structure thought to have measured about 105 ft in length and 48 ft in width, covered an area 5000 sqft, and been as much as 50 ft high, making its peak 150 ft above the level of the plaza. The civilization vanished in the 15th century for unknown reasons, but historians and archeologists have speculated that the people depleted the area of resources. Many indigenous tribes engaged in constant warfare. According to Suzanne Austin Alchon, "At one site in the central Illinois River valley, one-third of all adults died as a result of violent injuries."
The next major power in the region was the Illinois Confederation or Illini, a political alliance. As the Illini declined during the Beaver Wars era, members of the Algonquian-speaking Potawatomi, Miami, Sauk, and other tribes including the Fox (Mesquakie), Ioway, Kickapoo , Mascouten, Piankashaw, Shawnee, Wea, and Winnebago (Ho-Chunk) came into the area from the east and north around the Great Lakes.
European exploration.
French explorers Jacques Marquette and Louis Jolliet explored the Illinois River in 1673. In 1680, other French explorers constructed a fort at the site of present day Peoria, and in 1682, a fort atop Starved Rock in today's Starved Rock State Park. French Canadians came south to settle particularly along the Mississippi River, and Illinois was part of the French empire of La Louisiane until 1763, when it passed to the British with their defeat of France in the Seven Years' War. The small French settlements continued, although many French migrated west to Ste. Genevieve and St. Louis, Missouri to evade British rule.
A few British soldiers were posted in Illinois, but few British or American settlers moved there, as the Crown made it part of the territory reserved for Indians west of the Appalachians. In 1778, George Rogers Clark claimed Illinois County for Virginia. In a compromise, Virginia ceded the area to the new United States in 1783 and it became part of the Northwest Territory, to be administered by the federal government and later organized as states.
19th century.
The Illinois-Wabash Company was an early claimant to much of Illinois. The Illinois Territory was created on February 3, 1809, with its capital at Kaskaskia, an early French settlement.
During the discussions leading up to Illinois' admission to the Union, the proposed northern boundary of the state was moved twice. The original provisions of the Northwest Ordinance had specified a boundary that would have been tangent to the southern tip of Lake Michigan. Such a boundary would have left Illinois with no shoreline on Lake Michigan at all. However, as Indiana had successfully been granted a 10-mile northern extension of its boundary to provide it with a usable lakefront, the original bill for Illinois statehood, submitted to Congress on January 23, 1818, stipulated a northern border at the same latitude as Indiana's, which is defined as 10 mi north of the southernmost extremity of Lake Michigan. But the Illinois delegate, Nathaniel Pope, wanted more. Pope lobbied to have the boundary moved further north, and the final bill passed by Congress did just that; it included an amendment to shift the border to 42° 30' north, which is approximately 51 mi north of the Indiana northern border. This shift added 8500 sqmi to the state, including the lead mining region near Galena. More importantly, it added nearly 50 miles of Lake Michigan shoreline and the Chicago River. Pope and others envisioned a canal that would connect the Chicago and Illinois rivers, and thus, connect the Great Lakes to the Mississippi.
In 1818, Illinois became the 21st U.S. state. The capital remained at Kaskaskia, headquartered in a small building rented by the state. In 1819, Vandalia became the capital, and over the next 18 years, three separate buildings were built to serve successively as the capitol building. In 1837, the state legislators representing Sangamon County, under the leadership of state representative Abraham Lincoln, succeeded in having the capital moved to Springfield, where a fifth capitol building was constructed. A sixth capitol building was erected in 1867, which continues to serve as the Illinois capitol today.
Though it was ostensibly a "free state", there was slavery in Illinois. The ethnic French had owned black slaves as late as the 1820s, and American settlers had already brought slaves into the area from Kentucky. Slavery was nominally banned by the Northwest Ordinance, but that was not enforced for those already holding slaves. When Illinois became a sovereign state in 1818, the Ordinance no longer applied, and about 900 slaves were held in the state. As the southern part of the state, later known as "Egypt"or "Little Egypt", was largely settled by migrants from the South, the section was hostile to free blacks. Settlers were allowed to bring slaves with them for labor but, in 1822, state residents voted against making slavery legal. Still, most residents opposed allowing free blacks as permanent residents. Some settlers brought in slaves seasonally or as house servants. The Illinois Constitution of 1848 was written with a provision for exclusionary laws to be passed. In 1853, John A. Logan helped pass a law to prohibit all African Americans, including freedmen, from settling in the state.
In 1832, the Black Hawk War was fought in Illinois and current-day Wisconsin between the United States and the Sauk, Fox (Meskwaki) and Kickapoo Indian tribes. It represents the end of Indian resistance to white settlement in the Chicago region. The Indians had been forced to leave their homes and move to Iowa in 1831; when they attempted to return, they were attacked and eventually defeated by U.S. militia. The survivors were forced back to Iowa.
The winter of 1830–1831 is called the "Winter of the Deep Snow"; a sudden, deep snowfall blanketed the state, making travel impossible for the rest of the winter, and many travelers perished. Several severe winters followed, including the "Winter of the Sudden Freeze". On December 20, 1836, a fast-moving cold front passed through, freezing puddles in minutes and killing many travelers who could not reach shelter. The adverse weather resulted in crop failures in the northern part of the state. The southern part of the state shipped food north and this may have contributed to its name: "Little Egypt", after the Biblical story of Joseph in Egypt supplying grain to his brothers.
By 1839, the Mormons had founded a utopian city called Nauvoo. Located in Hancock County along the Mississippi River, Nauvoo flourished and soon rivaled Chicago for the position of the state's largest city. But in 1844, the Mormon leader Joseph Smith was murdered in the Carthage Jail, about 30 miles away from Nauvoo. Soon afterward, the Mormons' new leadership led the group out of Illinois in a mass exodus to present-day Utah; after close to six years of rapid development, Nauvoo rapidly declined afterward. 
Chicago gained prominence as a Great Lakes port and then as an Illinois and Michigan Canal port after 1848, and as a rail hub soon afterward. By 1857, Chicago was Illinois' largest city. With the tremendous growth of mines and factories in the state in the 19th century, Illinois was the ground for the formation of labor unions in the United States. The Pullman Strike and Haymarket Riot, in particular, greatly influenced the development of the American labor movement. From Sunday, October 8, 1871, until Tuesday, October 10, 1871, the Great Chicago Fire burned in downtown Chicago, destroying 4 sqmi.
In 1847, after lobbying by Dorothea L. Dix, Illinois became one of the first states to establish a system of state-supported treatment of mental illness and disabilities, replacing local almshouses.
Civil War.
During the American Civil War, Illinois ranked fourth in men who served (more than 250,000) in the Union Army, a figure surpassed by only New York, Pennsylvania, and Ohio. Beginning with President Abraham Lincoln's first call for troops and continuing throughout the war, Illinois mustered 150 infantry regiments, which were numbered from the 7th to the 156th regiments. Seventeen cavalry regiments were also gathered, as well as two light artillery regiments. The town of Cairo, at the southern tip of the state at the confluence of the Mississippi and Ohio Rivers, served as a strategically important supply base and training center for the Union army. For several months, both General Grant and Admiral Foote had headquarters in Cairo.
20th century.
At the turn of the 20th century, Illinois had a population of nearly 5 million. Many people from other parts of the country were attracted to the state by employment caused by the then-expanding industrial base. Whites were 98% of the state's population. Bolstered by continued immigration from southern and eastern Europe, and by the African-American Great Migration from the South, Illinois grew and emerged as one of the most important states in the union. By the end of the century, the population had reached 12.4 million.
The Century of Progress World's Fair was held at Chicago in 1933. Oil strikes in Marion County and Crawford County lead to a boom in 1937, and, by 1939, Illinois ranked fourth in U.S. oil production. Illinois manufactured 6.1 percent of total United States military armaments produced during World War II, ranking seventh among the 48 states. Chicago became an ocean port with the opening of the Saint Lawrence Seaway in 1959. The seaway and the Illinois Waterway connected Chicago to both the Mississippi River and the Atlantic Ocean. In 1960, Ray Kroc opened the first McDonald's franchise in Des Plaines (which still exists as a museum, with a working McDonald's across the street).
Illinois had a prominent role in the emergence of the nuclear age. In 1942, as part of the Manhattan Project, the University of Chicago conducted the first sustained nuclear chain reaction. In 1957, Argonne National Laboratory, near Chicago, activated the first experimental nuclear power generating system in the United States. By 1960, the first privately financed nuclear plant in the United States, Dresden 1, was dedicated near Morris. In 1967, Fermilab, a national nuclear research facility near Batavia, opened a particle accelerator, which was the world's largest for over 40 years. With eleven plants currently operating, Illinois leads all states in the amount of electricity generated from nuclear power.
In 1961, Illinois became the first state in the nation to adopt the recommendation of the American Law Institute and pass a comprehensive criminal code revision that repealed the law against sodomy. The code also abrogated common law crimes and established an age of consent of 18. The state's fourth constitution was adopted in 1970, replacing the 1870 document.
The first Farm Aid concert was held in Champaign to benefit American farmers, in 1985. The worst upper Mississippi River flood of the century, the Great Flood of 1993, inundated many towns and thousands of acres of farmland.
Geography.
Illinois is located in the Midwest Region of the United States and is one of the nine states and Canadian Province of Ontario in the bi-national Great Lakes region of North America.
Boundaries.
Illinois' eastern border with Indiana consists of a north-south line at 87° 31′ 30″ west longitude in Lake Michigan at the north, to the Wabash River in the south above Post Vincennes. The Wabash River continues as the eastern/southeastern border with Indiana until the Wabash enters the Ohio River. This marks the beginning of Illinois' southern border with Kentucky, which runs along the northern shoreline of the Ohio River. Most of the western border with Missouri and Iowa is the Mississippi River; Kaskaskia is an exclave of Illinois, lying west of the Mississippi and reachable only from Missouri. The state's northern border with Wisconsin is fixed at 42° 30' north latitude. The northeastern border of Illinois lies in Lake Michigan, within which Illinois shares a water boundary with the state of Michigan, as well as Wisconsin and Indiana.
Topography.
Though Illinois lies entirely in the Interior Plains, it does have some minor variation in its elevation. In extreme northwestern Illinois, the Driftless Area, a region of unglaciated and therefore higher and more rugged topography, occupies a small part of the state. Charles Mound, located in this region, has the state's highest elevation above sea level at 1235 ft. Other highlands include the Shawnee Hills in the south, and there is varying topography along its rivers; the Illinois River bisects the state northeast to southwest. The floodplain on the Mississippi River from Alton to the Kaskaskia River is known as the American Bottom.
Divisions.
Illinois has three major geographical divisions. Northern Illinois is dominated by Chicagoland, which is the city of Chicago and its suburbs, and the adjoining exurban area into which the metropolis is expanding. As defined by the federal government, the Chicago metro area includes several counties in Illinois, Indiana, and Wisconsin, and has a population of over 9.8 million people. Chicago itself is a cosmopolitan city, densely populated, industrialized, and the transportation hub of the nation, and settled by a wide variety of ethnic groups. The city of Rockford, Illinois' third largest city and center of the state's fourth largest metropolitan area, sits along Interstates 39 and 90 some 75 mi northwest of Chicago. The Quad Cities region, located along the Mississippi River in northern Illinois, had a population of 381,342 in 2011.
The midsection of Illinois is a second major division, called Central Illinois. It is an area of mostly prairie and known as the Heart of Illinois. It is characterized by small towns and medium-small cities. The western section (west of the Illinois River) was originally part of the Military Tract of 1812 and forms the conspicuous western bulge of the state. Agriculture, particularly corn and soybeans, as well as educational institutions and manufacturing centers, figure prominently in Central Illinois. Cities include Peoria, Springfield, the state capital; Quincy; Decatur; Bloomington-Normal; and Champaign-Urbana.
The third division is Southern Illinois, comprising the area south of U.S. Route 50, including Little Egypt, near the juncture of the Mississippi River and Ohio River. Southern Illinois is the site of the ancient city of Cahokia, as well as the site of the first state capital at Kaskaskia, which today is separated from the rest of the state by the Mississippi River. This region has a somewhat warmer winter climate, different variety of crops (including some cotton farming in the past), more rugged topography (due to the area remaining unglaciated during the Illinoian Stage, unlike most of the rest of the state), as well as small-scale oil deposits and coal mining. The Illinois suburbs of St. Louis, such as East St. Louis are located in this region and collectively they are known as the Metro-East. The other somewhat significant concentration of population in Southern Illinois is the Carbondale-Marion-Herrin, Illinois Combined Statistical Area centered on Carbondale and Marion, a two-county area that is home to 123,272 residents. A portion of southeastern Illinois is part of the extended Evansville, Indiana Metro Area, locally referred to as the Tri-State with Indiana and Kentucky. Seven Illinois counties are in the area.
In addition to these three, largely latitudinally defined divisions, all of the region outside of the Chicago Metropolitan area is often called "downstate" Illinois. This term is flexible, but is generally meant to mean everything outside the Chicago-area. Thus, some cities in "Northern" Illinois, such as DeKalb, which is west of Chicago, and Rockford—which is actually "north" of Chicago—are considered to be "downstate".
Climate.
Illinois has a climate that varies widely throughout the year. Because of its nearly 400-mile distance between its northernmost and southernmost extremes, as well as its mid-continental situation, most of Illinois has a humid continental climate (Köppen climate classification "Dfa"), with hot, humid summers and cold winters. The southernmost part of the state, from about Carbondale southward, borders on a humid subtropical climate (Koppen "Cfa"), with more moderate winters. Average yearly precipitation for Illinois varies from just over 48 in at the southern tip to around 35 in in the northern portion of the state. Normal annual snowfall exceeds 38 in in the Chicago area, while the southern portion of the state normally receives less than 14 in. The all-time high temperature was 117 F, recorded on July 14, 1954, at East St. Louis, while the all-time low temperature was -36 F, recorded on January 5, 1999, at Congerville. A temperature of -37 °F (-39 °C), was recorded on January 15, 2009, at Rochelle.
Illinois averages around 51 days of thunderstorm activity a year, which ranks somewhat above average in the number of thunderstorm days for the United States. Illinois is vulnerable to tornadoes with an average of 35 occurring annually, which puts much of the state at around five tornadoes per 10000 sqmi annually. While tornadoes are no more powerful in Illinois than other states, the nation's deadliest tornadoes on record have occurred largely in Illinois because it is the most populous state in Tornado Alley. The Tri-State Tornado of 1925 killed 695 people in three states; 613 of the victims died in Illinois. Other significant high-casualty tornadoes include the 1896 St. Louis – East St. Louis tornado, which killed 111 people in East St. Louis and a May 1917 tornado that killed 101 people in Charleston and Mattoon. Modern developments in storm forecasting and tracking have caused death tolls from tornadoes to decline dramatically, with the 1967 Belvidere – Oak Lawn tornado outbreak (58 fatalities) and 1990 Plainfield tornado (29 fatalities) standing out as exceptions. On November 18, 2013, tornadoes touched down and ripped through Washington, Illinois. There were 7 fatalities.
Demographics.
The United States Census Bureau estimates that the population of Illinois was 12,880,580 on July 1, 2014, a 0.39% increase since the 2010 United States Census. Illinois is the most populous state in the Midwest region. Chicago, the third most populous city in the United States, is the center of the Chicago metropolitan area. "Chicagoland", as this area is known locally, comprises only 8% of the land area of the state, but contains 65% of the state's residents.
According to the 2010 Census, the racial composition of the state was:
In the same year 15.8% of the total population was of Hispanic or Latino origin (they may be of any race).
The state's most populous ethnic group, non-Hispanic white, has declined from 83.5% in 1970 to 63.3% in 2011. As of 2011, 49.4% of Illinois's population younger than age 1 were minorities (note: children born to white Hispanics are counted as minority group).
At the 2007 estimates from the U.S. Census Bureau, there were 1,768,518 foreign-born inhabitants of the state or 13.8% of the population, with 48.4% from Latin America, 24.6% from Asia, 22.8% from Europe, 2.9% from Africa, 1.2% from Northern America and 0.2% from Oceania. Of the foreign-born population, 43.7% were naturalized U.S. citizens and 56.3% were not U.S. citizens. In 2007, 6.9% of Illinois' population was reported as being under age 5, 24.9% under age 18 and 12.1% were age 65 and over. Females made up approximately 50.7% of the population.
According to the 2007 estimates, 21.1% of the population had German ancestry, 13.3% had Irish ancestry, 8% had British ancestry, 7.9% had Polish ancestry, 6.4% had Italian ancestry, 4.6% listed themselves as American, 2.4% had Swedish ancestry, 2.2% had French ancestry, other than Basque, 1.6% had Dutch ancestry, and 1.4% had Norwegian ancestry.
Chicago, along the shores of Lake Michigan, is the nation's third largest city. In 2000, 23.3% of Illinois' population lived in the city of Chicago, 43.3% in Cook County, and 65.6% in the counties of the Chicago metropolitan area: Will, DuPage, Kane, Lake, and McHenry counties, as well as Cook County. The remaining population lives in the smaller cities and rural areas that dot the state's plains. As of 2000, the state's center of population was at , located in Grundy County, northeast of the village of Mazon.
Urban areas.
Chicago is the largest city in the state and the third most populous city in the United States, with its 2010 population of 2,695,598. The U.S. Census Bureau currently lists seven other cities with populations of over 100,000 within Illinois. Based upon the Census Bureau's official 2010 population: Aurora, a Chicago satellite town that eclipsed Rockford for the title of second most populous city in Illinois; its 2010 population was 197,899. Rockford, at 152,871, is the third largest city in the state, and is the largest city in the state not located within the Chicago suburbs. Joliet, located in metropolitan Chicago, is the fourth largest city in the state, with a population of 147,433. Naperville, a suburb of Chicago, is fifth with 141,853. Naperville and Aurora share a boundary along Illinois Route 59. Springfield, the state's capital, comes in as sixth most populous with 117,352 residents. Peoria, which decades ago was the second-most populous city in the state, is seventh with 115,007. The eighth largest and final city in the 100,000 club is Elgin, a northwest suburb of Chicago, with a 2010 population of 108,188.
The most populated city in the state south of Springfield is Belleville, with 44,478 people at the 2010 census. It is located in the Illinois portion of Greater St. Louis (often called the Metro-East area), which has a rapidly growing population of over 700,000 people.
Other major urban areas include the Champaign-Urbana Metropolitan Area, which has a combined population of almost 230,000 people, the Illinois portion of the Quad Cities area with about 215,000 people, and the Bloomington-Normal area with a combined population of over 165,000.
Languages.
The official language of Illinois is English, although between 1923 and 1969 state law gave official status to "the American language." Nearly 80% of people in Illinois speak English natively, and most of the rest speak it fluently as a second language. A number of dialects of American English are spoken, ranging from Inland Northern American English and African American Vernacular English around Chicago, to Midland American English in Central Illinois to Southern American English in the far south.
Over 20% of Illinoians speak a language other than English at home, of which Spanish is by far the most widespread at more than 12% of the total population.
Religion.
Roman Catholics constitute the single largest religious denomination in Illinois; they are heavily concentrated in and around Chicago, and account for nearly 30% of the state's population. However, taken together "as a group", the various Protestant denominations comprise a greater percentage of the state's population than do Catholics. In 2010 Catholics in Illinois numbered 3,648,907. The largest Protestant denominations were the United Methodist Church with 314,461, and the Southern Baptist Convention, with 283,519 members. Illinois has one of the largest concentrations of Missouri Synod Lutherans in the United States. Muslims constituted the largest non-Christian group with 359,264 adherents. Chicago and its suburbs are also home to a large and growing population of Hindus, Muslims, Baha'is and Buddists. Illinois has the largest concentration of Muslims by state in the country with 2800 Muslims per 100,000 citizens.
Illinois played an important role in the early Latter Day Saint movement, with Nauvoo, Illinois, becoming a gathering place for Mormons in the early 1840s. Nauvoo was the location of the succession crisis, which led to the separation of the Mormon movement into several Latter Day Saint sects. The Church of Jesus Christ of Latter-day Saints, the largest of the sects to emerge from the Mormon schism, has over 55,000 adherents in Illinois today. The largest and oldest surviving Bahá'í House of Worship in the world is located in Wilmette, Illinois and the oldest standing mosque in the U.S. is the Al-Sadiq Mosque of the Ahmadiyya Muslim Community, located in the Bronzeville neighbourhood of Chicago.
Economy.
The dollar gross state product for Illinois was estimated to be US$ billion in 2010. The state's 2010 per capita gross state product was estimated to be US$, the state's per capita personal income was estimated to be US$ in 2009, while the state's taxpayer burden in 2011 was estimated at US$ per taxpayer.
s of 2010[ [update]], the state's unemployment rate was 11.5%, which fell to 9.9% by August 2011 and 6.6% by September, 2014.
Taxes.
Illinois' state income tax is calculated by multiplying net income by a flat rate. In 1990, that rate was set at 3%, but in 2010, the General Assembly voted in a temporary increase in the rate to 5%; the new rate went into effect on January 1, 2011; the personal income rate partially sunset on January 1, 2015 to 3.75%, while the corporate income tax fell to 5.25% There are two rates for state sales tax: 6.25% for general merchandise and 1% for qualifying food, drugs, and medical appliances. The property tax is a major source of tax revenue for local government taxing districts. The property tax is a local — not state — tax, imposed by local government taxing districts, which include counties, townships, municipalities, school districts, and special taxation districts. The property tax in Illinois is imposed only on real property.
Agriculture.
Illinois' major agricultural outputs are corn, soybeans, hogs, cattle, dairy products, and wheat. In most years, Illinois is either the first or second state for the highest production of soybeans, with a harvest of 427.7 million bushels (11.64 million metric tons) in 2008, after Iowa's production of 444.82 million bushels (12.11 million metric tons). Illinois ranks second in U.S. corn production with more than 1.5 billion bushels produced annually. With a production capacity of 1.5 billion gallons per year, Illinois is a top producer of ethanol; ranking third in the United States in 2011. Illinois is a leader in food manufacturing and meat processing. Although Chicago may no longer be "Hog Butcher for the World," the Chicago area remains a global center for food manufacture and meat processing, with many plants, processing houses, and distribution facilities concentrated in the area of the former Union Stock Yards. Illinois also produces wine, and the state is home to two American viticultural areas. In the area of The Meeting of the Great Rivers Scenic Byway, peach and apple are grown. The German immigrants from agricultural backgrounds who settled in Illinois in mid- to late 19th century are the in part responsible for the profusion of fruit orchards in that area of Illinois. Illinois' universities are actively researching alternative agricultural products as alternative crops.
Manufacturing.
Illinois is one of the nation's manufacturing leaders, boasting annual value added productivity by manufacturing of over $107 billion in 2006. As of 2011, Illinois is ranked as the 4th most productive manufacturing state in the country, behind California, Texas, and Ohio. About three-quarters of the state's manufacturers are located in the Northeastern Opportunity Return Region, with 38 percent of Illinois' approximately 18,900 manufacturing plants located in Cook County. As of 2006, the leading manufacturing industries in Illinois, based upon value-added, were chemical manufacturing ($18.3 billion), machinery manufacturing ($13.4 billion), food manufacturing ($12.9 billion), fabricated metal products ($11.5 billion), transportation equipment ($7.4 billion), plastics and rubber products ($7.0 billion), and computer and electronic products ($6.1 billion).
Services.
By the early 2000s, Illinois' economy had moved toward a dependence on high-value-added services, such as financial trading, higher education, law, logistics, and medicine. In some cases, these services clustered around institutions that hearkened back to Illinois' earlier economies. For example, the Chicago Mercantile Exchange, a trading exchange for global derivatives, had begun its life as an agricultural futures market. Other important non-manufacturing industries include publishing, tourism, and energy production and distribution.
Energy.
Illinois is a net importer of fuels for energy, despite large coal resources and some minor oil production. Illinois exports electricity, ranking fifth among states in electricity production and seventh in electricity consumption.
Coal.
The coal industry of Illinois has its origins in the middle 19th century, when entrepreneurs such as Jacob Loose discovered coal in locations such as Sangamon County. Jacob Bunn contributed to the development of the Illinois coal industry, and was a founder and owner of the Western Coal & Mining Company of Illinois. About 68% of Illinois has coal-bearing strata of the Pennsylvanian geologic period. According to the Illinois State Geological Survey, 211 billion tons of bituminous coal are estimated to lie under the surface, having a total heating value greater than the estimated oil deposits in the Arabian Peninsula. However, this coal has a high sulfur content, which causes acid rain unless special equipment is used to reduce sulfur dioxide emissions. Many Illinois power plants are not equipped to burn high-sulfur coal. In 1999, Illinois produced 40.4 million tons of coal, but only 17 million tons (42%) of Illinois coal was consumed in Illinois. Most of the coal produced in Illinois is exported to other states and countries. In 2008, Illinois exported 3 million tons of coal and was projected to export 9 million tons in 2011, as demand for energy grows in places such as China, India, elsewise in Asia and Europe. As of 2010, Illinois was ranked third in recoverable coal reserves at producing mines in the Nation. Most of the coal produced in Illinois is exported to other states, while much of the coal burned for power in Illinois (21 million tons in 1998) is mined in the Powder River Basin of Wyoming.
Mattoon was recently chosen as the site for the Department of Energy's FutureGen project, a 275 megawatt experimental zero emission coal-burning power plant that the DOE just gave a second round of funding. In 2010, after a number of setbacks, the city of Mattoon backed out of the project.
Petroleum.
Illinois is a leading refiner of petroleum in the American Midwest, with a combined crude oil distillation capacity of nearly 900000 oilbbl/d. However, Illinois has very limited crude oil proved reserves that account for less than 1% of U.S. crude oil proved reserves. Residential heating is 81% natural gas compared to less than 1% heating oil. Illinois is ranked 14th in oil production among states, with a daily output of approximately 28000 oilbbl in 2005.
Nuclear power.
Nuclear power arguably began in Illinois with the Chicago Pile-1, the world's first artificial self-sustaining nuclear chain reaction in the world's first nuclear reactor, built on the University of Chicago campus. There are six operating nuclear power plants in Illinois: Braidwood; Byron; Clinton; Dresden; LaSalle; and Quad Cities. With the exception of the single-unit Clinton plant, each of these facilities has two reactors. Three reactors have been permanently shut down and are in various stages of decommissioning: Dresden-1 and Zion-1 and 2. Illinois ranked first in the nation in 2010 in both nuclear capacity and nuclear generation. Generation from its nuclear power plants accounted for 12 percent of the Nation's total. In 2007, 48% of Illinois' electricity was generated using nuclear power. The Morris Operation is the only de facto high-level radioactive waste storage site in the United States.
Wind power.
Illinois has seen growing interest in the use of wind power for electrical generation. Most of Illinois was rated in 2009 as "marginal or fair" for wind energy production by the U.S. Department of Energy, with some western sections rated "good" and parts of the south rated "poor". These ratings are for wind turbines with 50 m hub heights; newer wind turbines are taller, enabling them to reach stronger winds farther from the ground. As a result, more areas of Illinois have become prospective wind farm sites. As of September 2009, Illinois had 1116.06 MW of installed wind power nameplate capacity with another 741.9 MW under construction. Illinois ranked ninth among U.S. states in installed wind power capacity, and sixteenth by potential capacity. Large wind farms in Illinois include Twin Groves, Rail Splitter, EcoGrove, and Mendota Hills.
As of 2007, wind energy represented only 1.7% of Illinois' energy production, and it was estimated that wind power could provide 5–10% of the state's energy needs. Also, the Illinois General Assembly mandated in 2007 that by 2025, 25% of all electricity generated in Illinois is to come from renewable resources.
Biofuels.
Illinois is ranked second in corn production among U.S. states, and Illinois corn is used to produce 40% of the ethanol consumed in the United States. The Archer Daniels Midland corporation in Decatur, Illinois is the world's leading producer of ethanol from corn.
The National Corn-to-Ethanol Research Center (NCERC), the world's only facility dedicated to researching the ways and means of converting corn (maize) to ethanol is located on the campus of Southern Illinois University Edwardsville.
University of Illinois at Urbana-Champaign is one of the partners in the Energy Biosciences Institute (EBI), a $500 million biofuels research project funded by petroleum giant BP.
Arts and culture.
Museums.
Illinois has numerous museums; the greatest concentration of these is in Chicago. Several museums in the city of Chicago are considered some of the best in the world. These include the John G. Shedd Aquarium, the Field Museum of Natural History, the Art Institute of Chicago, the Adler Planetarium, and the Museum of Science and Industry.
The modern Abraham Lincoln Presidential Library and Museum in Springfield is the largest and most attended presidential library in the country. Other historical museums in the state include the Polish Museum of America in Chicago; Magnolia Manor in Cairo; the Elihu Benjamin Washburne; Ulysses S. Grant Homes, both in Galena; and the Chanute Air Museum, located on the former Chanute Air Force Base in Rantoul.
The Chicago metropolitan area also has two zoos: The very large Brookfield Zoo, located approximately 13 miles west of the city center in suburban Brookfield, contains over 2300 animals and covers 216 acre. The Lincoln Park Zoo is located in huge Lincoln Park on Chicago's North Side, approximately 3 mi north of the Loop. The zoo covers over 35 acre within the park.
Music.
Illinois is a leader in music education having hosted the Midwest Clinic: An International Band and Orchestra Conference since 1946, as well being home to the Illinois Music Educators Association (IMEA), one of the largest professional music educator's organizations in the country. Each summer since 2004, Southern Illinois University Carbondale has played host to the Southern Illinois Music Festival, which presents dozens of performances throughout the region. Past featured artists include the Eroica Trio and violinist David Kim.
Sports.
Major league teams.
As one of the United States' major metropolises, all major sports leagues have teams headquartered in Chicago.
Minor league teams.
Many minor league teams also call Illinois their home. They include:
Former Chicago sports franchises.
Folded teams.
The city was formerly home to several other teams that either failed to survive, or that belonged to leagues that folded.
Relocated teams.
The NFL's Arizona Cardinals, who currently play in Phoenix, Arizona, played in Chicago as the Chicago Cardinals, until moving to St. Louis, Missouri after the 1959 season. An NBA expansion team known as the Chicago Packers in 1961–62 and the Chicago Zephyrs the following year moved to Baltimore after the 1962–63 season. The franchise is now known as the Washington Wizards.
Professional sports teams outside of Chicago.
The Rockford Lightning is one of the oldest CBA teams in the league. The Peoria Chiefs and Kane County Cougars are minor league baseball teams affiliated with MLB. The Schaumburg Boomers and Lake County Fielders are members of the North American League, and the Southern Illinois Miners, Gateway Grizzlies, Joliet Slammers, Windy City ThunderBolts and Normal CornBelters belong to the Frontier League.
In addition to the Chicago Wolves, the AHL also has the Rockford IceHogs serving as the AHL affiliate of the Chicago Blackhawks. The second incarnation of the Peoria Rivermen plays in the SPHL.
Motor racing.
Motor racing oval tracks at the Chicagoland Speedway in Joliet, the Chicago Motor Speedway in Cicero and the Gateway International Raceway in Madison, near St. Louis, have hosted NASCAR, CART, and IRL races, whereas the Sports Car Club of America, among other national and regional road racing clubs, have visited the Autobahn Country Club in Joliet, the Blackhawk Farms Raceway in South Beloit and the former Meadowdale International Raceway in Carpentersville. Illinois also has several short tracks and dragstrips. The dragstrip at Gateway International Raceway and the Route 66 Raceway, which sits on the same property as the Chicagoland Speedway, both host NHRA drag races.
Parks and recreation.
The Illinois state parks system began in 1908 with what is now Fort Massac State Park, becoming the first park in a system encompassing over 60 parks and about the same number of recreational and wildlife areas.
Areas under the protection and control of the National Park Service include: the Illinois and Michigan Canal National Heritage Corridor near Lockport; the Lewis and Clark National Historic Trail; the Lincoln Home National Historic Site in Springfield; the Mormon Pioneer National Historic Trail; the Trail of Tears National Historic Trail; and the American Discovery Trail.
Law and government.
The government of Illinois, under the Constitution of Illinois, has three branches of government: Executive, legislative and judicial. The executive branch is split into several statewide elected offices, with the Governor as chief executive. Legislative functions are granted to the Illinois General Assembly. The judiciary is composed of the Supreme Court and lower courts.
The Illinois General Assembly is the state legislature, composed of the 118-member Illinois House of Representatives and the 59-member Illinois Senate. The members of the General Assembly are elected at the beginning of each even-numbered year. The "Illinois Compiled Statutes" (ILCS) are the codified statutes of a general and permanent nature.
The executive branch is composed of six elected officers and their offices as well as numerous other departments. The six elected officers are the: Governor, Lieutenant Governor, Attorney General, Secretary of State, Comptroller, and Treasurer. The government of Illinois has numerous departments, agencies, boards and commissions, but the so-called code departments provide most of the state's services.
The Judiciary of Illinois is the unified court system of Illinois. It consists of the Supreme Court, Appellate Court, and Circuit Courts. The Supreme Court oversees the administration of the court system.
The administrative divisions of Illinois are counties, townships, precincts, cities, towns, villages, and special-purpose districts. The basic subdivision of Illinois are the 102 counties. 85 Of the 102 counties are in turn divided into townships and precincts. Municipal governments are the cities, villages, and incorporated towns. Some localities possess "home rule", which allows them to govern themselves to a certain extent.
Politics.
Party balance.
Historically, Illinois was long a major swing state, with near-parity existing between the Republican and the Democratic parties. However, in recent elections, the Democratic Party has gained ground and Illinois has come to be seen as a "blue" state in presidential contests. Chicago and most of Cook County votes have long been strongly Democratic. However, the "collar counties" (the suburbs surrounding Chicago's Cook County, Illinois), can be seen as a Republican stronghold, though the party's strength has weakened in recent decades.
Republicans continue to prevail in the Chicago suburban "collar counties" surrounding Cook County, as well as rural northern and central Illinois; Republican support is also strong in southern Illinois, outside of the East St. Louis metropolitan area. From 1920 until 1972, the state was carried by the victor of each of these presidential elections - 14 elections. In fact, Illinois was long seen as a national bellwether, supporting the winner in every election in the 20th Century except for 1916 and 1976. By contrast, Illinois has trended more toward the Democratic party and such, has voted for their presidential candidates in the last six elections; in 2000, George W. Bush became the first Republican to win the presidency without carrying Illinois or Vermont. Native son and current president Barack Obama easily won the state's 21 electoral votes in 2008, with 61.9% of the vote. In 2010, incumbent Governor Pat Quinn was re-elected with 47% of the vote, while Republican Mark Kirk was elected to the Senate with 48% of the vote. In 2012, President Obama easily carried Illinois again with 58% to Republican Mitt Romney's 41%. In 2014, Republican Bruce Rauner defeated Governor Quinn 50% - 46% to become Illinois' first Republican governor in 12 years when he was sworn in on January 12, 2015, while Democratic Senator Dick Durbin was re-elected with 53% of the vote.
History of corruption.
Politics in the state have been infamous for highly visible corruption cases, as well as for crusading reformers, such as governors Adlai Stevenson and James R. Thompson. In 2006, former Governor George Ryan was convicted of racketeering and bribery, leading to a 6 1⁄2-year prison sentence. In 2008, then-Governor Rod Blagojevich was served with a criminal complaint on corruption charges, stemming from allegations that he conspired to sell the vacated Senate seat left by President Barack Obama to the highest bidder. Subsequently, on December 7, 2011, Rod Blagojevich was sentenced to 14 years in prison for those charges, as well as perjury while testifying during the case, totaling 18 convictions. In the late 20th century, Congressman Dan Rostenkowski was imprisoned for mail fraud; former governor and federal judge Otto Kerner, Jr. was imprisoned for bribery; and State Auditor of Public Accounts (Comptroller) Orville Hodge was imprisoned for embezzlement. In 1912, William Lorimer, the GOP boss of Chicago, was expelled from the U.S. Senate for bribery and in 1921, Governor Len Small was found to have defrauded the state of a million dollars.
US Presidents from Illinois.
Three presidents have claimed Illinois as their political base: Lincoln, Grant, and Obama. Lincoln was born in Kentucky, but moved to Illinois at the age of 21; he served in the General Assembly and represented the 7th congressional district in the US House of Representatives before his election as President. Ulysses S. Grant was born in Ohio and had a military career that precluded settling down, but on the eve of the Civil War, and approaching middle age, Grant moved to Illinois and thus claimed it as his home when running for President. Barack Obama was born and raised in Hawaii (other than a four-year period of his childhood spent in Indonesia) and made Illinois his home and base after completing law school.
Only one person elected President of the United States was actually born in Illinois. Ronald Reagan was born in Tampico, raised in Dixon and educated at Eureka College. Reagan moved to Los Angeles as a young adult and later became Governor of California before being elected President.
African-American US senators.
Nine African-Americans have served as members of the United States Senate. Three of them have represented Illinois, the most of any single state: Carol Moseley-Braun, Barack Obama, and Roland Burris, who was appointed to replace Obama after his election to the presidency. Moseley-Braun was the first and to date only African-American woman to become a U.S. Senator.
Political families.
Two families from Illinois have played particularly prominent roles in the Democratic Party, gaining both statewide and national fame.
Stevensons.
The Stevenson family, rooted in central Illinois, has provided four generations of Illinois elected leadership.
Daleys.
The Daley family's powerbase was in Chicago.
Education.
Illinois State Board of education.
The Illinois State Board of Education (ISBE) is autonomous of the governor and the state legislature, and administers public education in the state. Local municipalities and their respective school districts operate individual public schools but the ISBE audits performance of public schools with the Illinois School Report Card. The ISBE also makes recommendations to state leaders concerning education spending and policies.
Primary and secondary schools.
Education is compulsory from ages 7 to 17 in Illinois. Schools are commonly but not exclusively divided into three tiers of primary and secondary education: elementary school, middle school or junior high school, and high school. District territories are often complex in structure. Many areas in the state are actually located in "two" school districts—one for high school, the other for elementary and middle schools. And such districts do not necessarily share boundaries. A given high school may have several elementary districts that feed into it, yet some of those feeder districts may themselves feed into multiple high school districts.
Colleges and universities.
Using the criterion established by the Carnegie Foundation for the Advancement of Teaching, there are eleven "National Universities" in the state. s of 19 2010[ [update]], five of these rank in the "first tier" (that is, the top quartile) among the top 500 National Universities in the United States, as determined by the "U.S. News & World Report" rankings: the University of Chicago (4), Northwestern University (12), the University of Illinois at Urbana-Champaign (41), Loyola University Chicago (106), the Illinois Institute of Technology (113), and DePaul University (121).
The University of Chicago is continuously ranked as one of the world's top ten universities on various independent university rankings and the University of Illinois at Urbana-Champaign consistently ranks among the best engineering schools in the world and in United States.
Illinois also has more than 20 additional accredited four-year universities, both public and private, and dozens of small liberal arts colleges across the state. Additionally, Illinois supports 49 public community colleges in the Illinois Community College System.
Infrastructure.
Transportation.
Because of its central location and its proximity to the Rust Belt and Grain Belt, Illinois is a national crossroads for air, auto, rail, and truck traffic.
Airports.
From 1962 until 1998, Chicago's O'Hare International Airport (ORD) was the busiest airport in the world, measured both in terms of total flights and passengers. While it was surpassed by Atlanta's Hartsfield in 1998, with 59.3 million domestic passengers annually, along with 11.4 million international passengers in 2008, O'Hare remains one of the two or three busiest airports in the world, and some years still ranks number one in total flights. It is a major hub for United Airlines and American Airlines, and a major airport expansion project is currently underway. Chicago Midway International Airport (MDW), which had been the busiest airport in the world until supplanted by O'Hare in 1962, is now the secondary airport in the Chicago metropolitan area. For a time in the late 1960s and 1970s, Midway was nearly vacant except for general aviation, but growth in the area, combined with political deadlock over the building of a new major airport in the region, has caused a resurgence for Midway. It is now a major hub for Southwest Airlines, and services many other airlines as well. Midway served 17.3 million domestic and international passengers in 2008.
Rail.
Illinois has an extensive passenger and freight rail transportation network. Chicago is a national Amtrak hub and in-state passengers are served by Amtrak's Illinois Service, featuring the Chicago to Carbondale "Illini" and "Saluki", the Chicago to Quincy "Carl Sandburg" and "Illinois Zephyr", and the Chicago to St. Louis "Lincoln Service". Currently there is trackwork on the Chicago–St. Louis line to bring the maximum speed up to 110 mi/h, which would reduce the trip time by an hour and a half. Nearly every North American railway meets at Chicago, making it the largest and most active rail hub in the country. Extensive commuter rail is provided in the city proper and some immediate suburbs by the Chicago Transit Authority's 'L' system. The largest suburban commuter rail system in the United States, operated by Metra, uses existing rail lines to provide direct commuter rail access for hundreds of suburbs to the city and beyond.
In addition to the state's rail lines, the Mississippi River and Illinois River provide major transportation routes for the state's agricultural interests. Lake Michigan gives Illinois access to the Atlantic Ocean by way of the Saint Lawrence Seaway.
Interstate highway system.
Illinois is among many US states with a well developed interstate highway system. Illinois has the distinction of having the most primary (two-digit) interstates pass through it among all the 50 states, tied with Pennsylvania with 12, as well as the 3rd most interstate mileage behind California and Texas.
Major U.S. Interstate highways crossing the state include: Interstate 24 (I-24), I-39, I-55, I-57, I-64, I-70, I-72, I-74, I-80, I-88, I-90, and I-94.
U.S. highway system.
Among the U.S. highways that pass through the state, the primary ones are: US 6, US 12, US 14, US 20, US 24, US 30, US 34, US 36, US 40, US 41, US 45, US 50, US 51, US 52, US 54, US 60, US 62, and US 67.
Further reading.
</dl>

</doc>
<doc id="14851" url="http://en.wikipedia.org/wiki?curid=14851" title="Ian Murdock">
Ian Murdock

Ian Murdock (born 28 April 1973) is an American software engineer, known for being the founder of the Debian project and Progeny Linux Systems, a commercial Linux company.
Life and career.
Ian Ashley Murdock was born in Konstanz, West Germany on 28 April 1973. He wrote the Debian Manifesto while a student at Purdue University, where he earned his bachelor's degree in computer science in 1996. He named Debian after his then-girlfriend Debra Lynn, and himself (Deb and Ian). They subsequently married (between 1993 and 1996), filed for divorce on the week of 10 August 2007, and were granted the divorce in January 2008.
On joining Sun, he led Project Indiana, which he described as "taking the lesson that Linux has brought to the operating system and providing that for Solaris", making a full OpenSolaris distribution with GNOME and userland tools from GNU plus a network-based package management system. From March 2007 to February 2010, he was Vice President of Emerging Platforms at Sun, until the company merged with Oracle and he resigned his position with the company.
Murdock is currently Vice President of Platform and Developer Community at Salesforce Marketing Cloud, based in Indianapolis.

</doc>
<doc id="14856" url="http://en.wikipedia.org/wiki?curid=14856" title="Inner product space">
Inner product space

In linear algebra, an inner product space is a vector space with an additional structure called an inner product. This additional structure associates each pair of vectors in the space with a scalar quantity known as the inner product of the vectors. Inner products allow the rigorous introduction of intuitive geometrical notions such as the length of a vector or the angle between two vectors. They also provide the means of defining orthogonality between vectors (zero inner product). Inner product spaces generalize Euclidean spaces (in which the inner product is the dot product, also known as the scalar product) to vector spaces of any (possibly infinite) dimension, and are studied in functional analysis.
An inner product naturally induces an associated norm, thus an inner product space is also a normed vector space. A complete space with an inner product is called a Hilbert space. An incomplete space with an inner product is called a pre-Hilbert space, since its completion with respect to the norm induced by the inner product is a Hilbert space. Inner product spaces over the field of complex numbers are sometimes referred to as unitary spaces.
Definition.
In this article, the field of scalars denoted "F" is either the field of real numbers R or the field of complex numbers C.
Formally, an inner product space is a vector space "V" over the field "F" together with an "inner product", i.e., with a map
that satisfies the following three axioms for all vectors formula_2 and all scalars formula_3:
Alternative definitions, notations and remarks.
Some authors, especially in physics and matrix algebra, prefer to define the inner product and the sesquilinear form with linearity in the second argument rather than the first. Then the first argument becomes conjugate linear, rather than the second. In those disciplines we would write the product formula_9 as formula_10 (the bra–ket notation of quantum mechanics), respectively formula_11 (dot product as a case of the convention of forming the matrix product "AB" as the dot products of rows of "A" with columns of "B"). Here the kets and columns are identified with the vectors of "V" and the bras and rows with the dual vectors or linear functionals of the dual space "V"∗, with conjugacy associated with duality. This reverse order is now occasionally followed in the more abstract literature, taking formula_9 to be conjugate linear in "x" rather than "y". A few instead find a middle ground by recognizing both formula_13 and formula_14 as distinct notations differing only in which argument is conjugate linear.
There are various technical reasons why it is necessary to restrict the basefield to R and C in the definition. Briefly, the basefield has to contain an ordered subfield in order for non-negativity to make sense, and therefore has to have characteristic equal to 0 (since any ordered field has to have such characteristic). This immediately excludes finite fields. The basefield has to have additional structure, such as a distinguished automorphism. More generally any quadratically closed subfield of R or C will suffice for this purpose, e.g., the algebraic numbers, but when it is a proper subfield (i.e., neither R nor C) even finite-dimensional inner product spaces will fail to be metrically complete. In contrast all finite-dimensional inner product spaces over R or C, such as those used in quantum computation, are automatically metrically complete and hence Hilbert spaces.
In some cases we need to consider non-negative "semi-definite" sesquilinear forms. This means that formula_15 is only required to be non-negative. We show how to treat these below.
Elementary properties.
When , conjugate symmetry reduces to symmetry. That is, formula_16 for ; while for , formula_17 is equal to the complex conjugate.
Notice that conjugate symmetry implies that formula_18 is real for all "x", since we have:
Moreover, sesquilinearity (see below) implies that
Conjugate symmetry and linearity in the first variable gives
so an inner product is a sesquilinear form. Conjugate symmetry is also called Hermitian symmetry, and a conjugate symmetric sesquilinear form is called a "Hermitian form". While the above axioms are more mathematically economical, a compact verbal definition of an inner product is a "positive-definite Hermitian form".
In the case of , conjugate-symmetry reduces to symmetry, and sesquilinear reduces to bilinear. So, an inner product on a real vector space is a "positive-definite symmetric bilinear form".
From the linearity property it is derived that implies formula_23 while from the positive-definiteness axiom we obtain the converse, formula_24 implies . Combining these two, we have the property that formula_24 if and only if .
Combining the linearity of the inner product in its first argument and the conjugate symmetry gives the following important generalization of the familiar square expansion:
Assuming the underlying field to be R, the inner product becomes symmetric, and we obtain
The property of an inner product space "V" that
is also known as "additivity".
Norms on inner product spaces.
A linear space with a norm such as:
is a normed space but not an inner product space, because this norm does not satisfy the parallelogram equality required of a norm to have an inner product associated with it.
However, inner product spaces have a naturally defined norm based upon the inner product of the space itself that does satisfy the parallelogram equality:
This is well defined by the nonnegativity axiom of the definition of inner product space. The norm is thought of as the length of the vector "x". Directly from the axioms, we can prove the following:
Orthonormal sequences.
Let "V" be a finite dimensional inner product space of dimension "n". Recall that every basis of "V" consists of exactly "n" linearly independent vectors. Using the Gram–Schmidt process we may start with an arbitrary basis and transform it into an orthonormal basis. That is, into a basis in which all the elements are orthogonal and have unit norm. In symbols, a basis formula_53 is orthonormal if formula_54 if formula_55 and formula_56 for each "i".
This definition of orthonormal basis generalizes to the case of infinite-dimensional inner product spaces in the following way. Let "V" be any inner product space. Then a collection
is a "basis" for "V" if the subspace of "V" generated by finite linear combinations of elements of "E" is dense in "V" (in the norm induced by the inner product). We say that "E" is an "orthonormal basis" for "V" if it is a basis and
if formula_59 and formula_60 for all formula_61.
Using an infinite-dimensional analog of the Gram-Schmidt process one may show:
Theorem. Any separable inner product space "V" has an orthonormal basis.
Using the Hausdorff maximal principle and the fact that in a complete inner product space orthogonal projection onto linear subspaces is well-defined, one may also show that
Theorem. Any complete inner product space "V" has an orthonormal basis.
The two previous theorems raise the question of whether all inner product spaces have an orthonormal basis. The answer, it turns out is negative. This is a non-trivial result, and is proved below. The following proof is taken from Halmos's A Hilbert Space Problem Book (see the references).
Parseval's identity leads immediately to the following theorem:
Theorem. Let "V" be a separable inner product space and {"e""k"}"k" an orthonormal basis of "V". Then the map
is an isometric linear map "V" → "ℓ" 2 with a dense image.
This theorem can be regarded as an abstract form of Fourier series, in which an arbitrary orthonormal basis plays the role of the sequence of trigonometric polynomials. Note that the underlying index set can be taken to be any countable set (and in fact any set whatsoever, provided "ℓ" 2 is defined appropriately, as is explained in the article Hilbert space). In particular, we obtain the following result in the theory of Fourier series:
Theorem. Let "V" be the inner product space formula_63. Then the sequence (indexed on set of all integers) of continuous functions
is an orthonormal basis of the space formula_63 with the "L"2 inner product. The mapping
is an isometric linear map with dense image.
Orthogonality of the sequence {"ek"}"k" follows immediately from the fact that if "k" ≠ "j", then
Normality of the sequence is by design, that is, the coefficients are so chosen so that the norm comes out to 1. Finally the fact that the sequence has a dense algebraic span, in the "inner product norm", follows from the fact that the sequence has a dense algebraic span, this time in the space of continuous periodic functions on formula_68 with the uniform norm. This is the content of the Weierstrass theorem on the uniform density of trigonometric polynomials.
Operators on inner product spaces.
Several types of linear maps "A" from an inner product space "V" to an inner product space "W" are of relevance:
From the point of view of inner product space theory, there is no need to distinguish between two spaces which are isometrically isomorphic. The spectral theorem provides a canonical form for symmetric, unitary and more generally normal operators on finite dimensional inner product spaces. A generalization of the spectral theorem holds for continuous normal operators in Hilbert spaces.
Generalizations.
Any of the axioms of an inner product may be weakened, yielding generalized notions. The generalizations that are closest to inner products occur where bilinearity and conjugate symmetry are retained, but positive-definiteness is weakened.
Degenerate inner products.
If "V" is a vector space and formula_13 a semi-definite sesquilinear form, then the function:
makes sense and satisfies all the properties of norm except that ‖"x"‖ = 0 does not imply (such a functional is then called a semi-norm). We can produce an inner product space by considering the quotient "W" = "V"/{ "x" : ‖"x"‖ = 0}. The sesquilinear form formula_73 factors through "W".
This construction is used in numerous contexts. The Gelfand–Naimark–Segal construction is a particularly important example of the use of this technique. Another example is the representation of semi-definite kernels on arbitrary sets.
Nondegenerate conjugate symmetric forms.
Alternatively, one may require that the pairing be a nondegenerate form, meaning that for all non-zero "x" there exists some "y" such that formula_74 though "y" need not equal "x"; in other words, the induced map to the dual space "V" → "V"* is injective. This generalization is important in differential geometry: a manifold whose tangent spaces have an inner product is a Riemannian manifold, while if this is related to nondegenerate conjugate symmetric form the manifold is a pseudo-Riemannian manifold. By Sylvester's law of inertia, just as every inner product is similar to the dot product with positive weights on a set of vectors, every nondegenerate conjugate symmetric form is similar to the dot product with "nonzero" weights on a set of vectors, and the number of positive and negative weights are called respectively the positive index and negative index. Product of vectors in Minkowski space is an example of indefinite inner product, although, technically speaking, it is not an inner product according to the standard definition above. Minkowski space has four dimensions and indices 3 and 1 (assignment of "+" and "−" to them differs depending on conventions).
Purely algebraic statements (ones that do not use positivity) usually only rely on the nondegeneracy (the injective homomorphism "V" → "V"*) and thus hold more generally.
Related products.
The term "inner product" is opposed to outer product, which is a slightly more general opposite. Simply, in coordinates, the inner product is the product of a 1×"n" "co"vector with an "n"×1 vector, yielding a 1×1 matrix (a scalar), while the outer product is the product of an "m"×1 vector with a 1×"n" covector, yielding an "m"×"n" matrix. Note that the outer product is defined for different dimensions, while the inner product requires the same dimension. If the dimensions are the same, then the inner product is the "trace" of the outer product (trace only being properly defined for square matrices).
On an inner product space, or more generally a vector space with a nondegenerate form (so an isomorphism "V" → "V"*) vectors can be sent to covectors (in coordinates, via transpose), so one can take the inner product and outer product of two vectors, not simply of a vector and a covector.
In a quip: "inner is horizontal times vertical and shrinks down, outer is vertical times horizontal and expands out".
More abstractly, the outer product is the bilinear map formula_75 sending a vector and a covector to a rank 1 linear transformation (simple tensor of type (1,1)), while the inner product is the bilinear evaluation map formula_76 given by evaluating a covector on a vector; the order of the domain vector spaces here reflects the covector/vector distinction.
The inner product and outer product should not be confused with the interior product and exterior product, which are instead operations on vector fields and differential forms, or more generally on the exterior algebra.
As a further complication, in geometric algebra the inner product and the "exterior" (Grassmann) product are combined in the geometric product (the Clifford product in a Clifford algebra) – the inner product sends two vectors (1-vectors) to a scalar (a 0-vector), while the exterior product sends two vectors to a bivector (2-vector) – and in this context the exterior product is usually called the ""outer" (alternatively, wedge) product". The inner product is more correctly called a "scalar" product in this context, as the nondegenerate quadratic form in question need not be positive definite (need not be an inner product).

</doc>
<doc id="14858" url="http://en.wikipedia.org/wiki?curid=14858" title="Iain Banks">
Iain Banks

Iain Banks (16 February 1954 – 9 June 2013) was a Scottish author. He wrote mainstream fiction under the name Iain Banks, and science fiction as Iain M. Banks, including the initial of his adopted middle name Menzies ().
Following the publication and success of "The Wasp Factory" (1984), Banks began to write on a full-time basis. His first science fiction book, "Consider Phlebas", was released in 1987, marking the start of the popular "The Culture" series. His books have been adapted for theatre, radio and television. In 2008, "The Times" named Banks in their list of "The 50 greatest British writers since 1945". In September 2012 Banks was revealed as one of the Guests of Honour at the 2014 World Science Fiction Convention, Loncon 3. In April 2013, Banks announced that he had inoperable cancer and was unlikely to live beyond a year. He died on 9 June 2013.
Early life.
Banks was born in Dunfermline, Fife, to a mother who was a professional ice skater and a father who was an officer in the Admiralty. An only child, Banks lived in North Queensferry until the age of nine, near the naval dockyards in Rosyth where his father was based. Banks's family then moved to Gourock due to the requirements of his father's work. When someone introduced him to science fiction by giving him "Kemlo and the Zones of Silence", a book in the Kemlo series, he continued reading it which made him want to write science fiction himself. After attending Gourock and Greenock High Schools, Banks studied English, philosophy and psychology at the University of Stirling (1972–1975). He wrote his second novel " TTR" during his first year at university.
Following graduation Banks chose a succession of jobs that left him free to write in the evenings. These posts supported his writing throughout his twenties and allowed him to take long breaks between contracts, during which time he travelled through Europe, Scandinavia and North America. He was an expediter analyser for IBM, a technician (for British Steel) and a costing clerk for a Chancery Lane, London, law firm during this period of his life.
Career.
Writing career.
Banks decided to become a writer at the age of 11 and completed his first novel "The Hungarian Lift-Jet" at 16. Though he considered himself primarily a science fiction author, his lack of success at being published as such led him to pursue mainstream fiction, resulting in his first published novel "The Wasp Factory", which was published in 1984 when he was thirty. Following the publication and success of "The Wasp Factory", Banks began to write full-time. His editor at Macmillan, James Hale, advised him to write one book a year and Banks agreed to this schedule.
His second novel "Walking on Glass" was published in 1985. "The Bridge" followed in 1986, and "Espedair Street", published in 1987, was later broadcast as a series on BBC Radio 4. His first published science fiction book "Consider Phlebas" was released in 1987 and would be the first of several novels of the acclaimed Culture series. Banks cited Robert A. Heinlein, Isaac Asimov, Arthur C. Clarke, Brian Aldiss, M. John Harrison and Dan Simmons as literary influences. "The Crow Road", published in 1992, was adapted as a BBC television series. Banks continued to write both science fiction and mainstream novels, with his final novel "The Quarry" published in June 2013, the month of his death.
Banks published work under two names. His parents had intended to name him "Iain Menzies Banks", but his father made a mistake when registering the birth and "Iain Banks" became the officially registered name. Despite this error, Banks continued to use his middle name and submitted "The Wasp Factory" for publication as "Iain M. Banks". Banks' editor inquired about the possibility of omitting the 'M' as it appeared "too fussy" and the potential existed for confusion with Rosie M. Banks, a romantic novelist in the Jeeves novels by P.G. Wodehouse; Banks agreed to the omission. Following three mainstream novels, Banks's publishers agreed to publish his first science fiction (SF) novel "Consider Phlebas". To create a distinction between the mainstream and SF novels, Banks suggested the return of the 'M' to his name. All of his science fiction writing has ended up been being published under "Iain M. Banks", in contrast to publishing his mainstream fiction under "Iain Banks".
By his death in June 2013 Banks had published 26 novels. His twenty-seventh novel "The Quarry" was published posthumously. The author's final work, a collection of poetry, will be released in 2015 and will be published following comments that Banks made about his own poetry in a May 2013 interview: "The poems are a part of the desperate urge to get things that were supposed to be long-term projects out the way. I'm going to see if I can get a book of poetry published before I kick the bucket. I've got about 50 I'm proud of."
While he wrote in different categories, he did not try to hide that science fiction was what he enjoyed the most to work on:
Until the last few years or so, when the SF novels started to achieve something approaching parity in sales, the mainstream always out-sold the SF – on average, if my memory isn’t letting me down, by a ratio of about three or four to one. I think a lot of people have assumed that the SF was the trashy but high-selling stuff I had to churn out in order to keep a roof over my head while I wrote the important, serious, non-genre literary novels. Never been the case, and I can’t imagine that I’d have lied about this sort of thing, least of all as some sort of joke. The SF novels have always mattered deeply to me – the Culture series in particular – and while it might not be what people want to hear (academics especially), the mainstream subsidised the SF, not the other way round.
Radio and television.
Banks was the subject of "The Strange Worlds of Iain Banks" "South Bank Show" (1997), a television documentary that examined his mainstream writing, and was also an in-studio guest for the final episode of Marc Riley's "Rocket Science" radio show, broadcast on BBC Radio 6 Music. A radio adaptation of Banks's "The State of the Art" was broadcast on BBC Radio 4 in 2009; the adaptation was written by Paul Cornell and the production was directed/produced by Nadia Molinari. In 1998 "Espedair Street" was dramatised as a serial for Radio 4, presented by Paul Gambaccini in the style of a Radio 1 documentary.
In 2011 Banks was featured on the BBC Radio 4 programme "Saturday Live". Banks reaffirmed his atheism during his "Saturday Live" appearance, whereby he explained that death is an important "part of the totality of life" and should be treated realistically, instead of feared.
Banks appeared on the BBC television programme "Question Time", a show that features political discussion. In 2006 Banks captained a team of writers to victory in a special series of BBC Two's "". Banks also won a 2006 edition of BBC One's "Celebrity Mastermind"; the author selected "Malt whisky and the distilleries of Scotland" as his specialist subject.
His final interview with Kirsty Wark was broadcast as "Iain Banks: Raw Spirit" on BBC2 Scotland on Wednesday 12 June 2013.
Theatre.
Banks was involved in the theatre production "The Curse of Iain Banks" that was written by Maxton Walker and was performed at the Edinburgh Fringe festival in 1999. Banks wrote the music for some of the songs that were featured in the production and collaborated with the play's soundtrack composer Gary Lloyd, who also composed the score for a musical production of the Banks novel "The Bridge". Lloyd explained his collaboration with Banks in a "Guardian" article prior to the opening of the "The Curse of Iain Banks":
When he [Banks] first played them to me, I think he was worried that they might not be up to scratch (some of them dated back to 1973 and had never been heard). He needn't have worried. They're fantastic. We're slaving away to get the songs to the stage where we can go into the studio and make a demo. Iain bashes out melodies on his state-of-the-art Apple Mac in Edinburgh and sends them down to me in Chester where I put them onto my Atari.
Politics.
Banks' political position has been described as "left of centre", and he was an Honorary Associate of the National Secular Society and a Distinguished Supporter of the Humanist Society of Scotland. As a signatory to the Declaration of Calton Hill, he was an open supporter of Scottish independence. In November 2012, Banks supported the campaign group that emerged from the Radical Independence Conference that was held during that month. Banks explained that the Scottish independence movement was motivated by co-operation and "just seem to be more communitarian than the consensus expressed by the UK population as a whole".
In late 2004, Banks was a member of a group of British politicians and media figures who campaigned to have Prime Minister Tony Blair impeached following the 2003 invasion of Iraq. In protest he cut up his passport and posted it to 10 Downing Street, the address of the British prime minister—in a "Socialist Review" interview, Banks explained that his passport protest occurred after he "abandoned the idea of crashing my Land Rover through the gates of Fife dockyard, after spotting the guys armed with machine guns." Banks relayed his concerns about the invasion of Iraq in his book "Raw Spirit", and the principal protagonist (Alban McGill) in the novel "The Steep Approach to Garbadale" confronts another character with arguments of a similar nature.
In 2010 Banks called for a cultural and educational boycott of Israel following the Gaza flotilla raid incident. In a letter to "The Guardian" newspaper, Banks stated that he had instructed his agent to turn down any further book translation deals with Israeli publishers:
Appeals to reason, international law, U.N. resolutions and simple human decency mean—it is now obvious—nothing to Israel ... I would urge all writers, artists and others in the creative arts, as well as those academics engaging in joint educational projects with Israeli institutions, to consider doing everything they can to convince Israel of its moral degradation and ethical isolation, preferably by simply having nothing more to do with this outlaw state.
An extract from Banks' contribution to the written collection "Generation Palestine: Voices from the Boycott, Divestment and Sanctions Movement", entitled "Our People", was published in "The Guardian" in the wake of the author's cancer revelation. The extract relays the author's support for the Boycott, Divestment and Sanctions (BDS) campaign that was issued by a Palestinian civil society against Israel until the country complies with international law and Palestinian rights, that commenced in 2005 and applies the lessons from Banks' experience with South Africa's apartheid era. The continuation of Banks' boycott of Israeli publishers for the sale of the rights to his novels was also confirmed in the extract and Banks further explained, "I don't buy Israeli-sourced products or food, and my partner and I try to support Palestinian-sourced products wherever possible."
Personal life.
Banks met his first wife, Annie, in London before the 1984 release of his first book. The couple lived in Faversham in the south of England, then split up in 1988. Banks returned to Edinburgh. The couple later resumed their relationship and moved to Fife. They got married in Hawaii in 1992. In 2007, after 15 years of marriage, they announced their separation.
In 1998 Banks had been in a near-fatal accident when his car rolled off the road. In February 2007, Banks sold his extensive car collection, including a 3.2 litre Porsche Boxster, a Porsche 911 Turbo, a 3.8 litre Jaguar Mark II, a 5 litre BMW M5 and a daily use diesel Land Rover Defender whose power he had boosted by about 50%. Banks exchanged all of the vehicles for a Lexus RX 400h hybrid – later replaced by a diesel Toyota Yaris – and said in the future he would fly only in emergencies. Banks bought another M5 after he was diagnosed with his illness, which he enjoyed until his death.
In April 2012 Banks became the "Acting Honorary Non-Executive Figurehead President Elect pro tem (trainee)" of the Science Fiction Book Club based in London England. The title was his own creation and on 3 October 2012 Banks accepted a T-shirt decorated with this title.
Banks lived in North Queensferry, on the north side of the Firth of Forth, with the author and founder of the Dead by Dawn film festival Adele Hartley. Banks and Hartley commenced their relationship in 2006, and married on 29 March 2013 after he asked her to "do me the honour of becoming my widow".
Illness and death.
On 3 April 2013, Banks announced on his website that he had been diagnosed with terminal cancer of the gallbladder and was unlikely to live beyond a year. In his announcement, Banks stated that he would be withdrawing from all public engagements and that "The Quarry" would be his last novel. The dates of publication of "The Quarry" were brought forward at Banks's request, to 20 June 2013 in the UK and 25 June 2013 in the US. Banks died on 9 June 2013.
Remembrance.
Banks's publisher stated that the author was "an irreplaceable part of the literary world", a sentiment that was reaffirmed by fellow Scottish author and friend since secondary school Ken MacLeod, who observed that Banks's death "left a large gap in the Scottish literary scene as well as the wider English-speaking world." British author Charles Stross wrote that "One of the giants of 20th and 21st century Scottish literature has left the building." Authors, including Neil Gaiman, Ian Rankin, Alastair Reynolds, and David Brin also paid tribute to Banks, in their blogs and elsewhere.
The asteroid (5099) Iainbanks was named after him shortly after his death.
On January 23rd, 2015, SpaceX's CEO and Chief Designer Elon Musk named two of the company's spaceport drone ships "Just Read The Instructions" and "Of Course I Still Love You", after ships from Banks' novel The Player Of Games.
Awards and nominations.
Iain Banks received the following literary awards and nominations:
Bibliography.
Introductions.
Banks wrote introductions for works by other writers including:

</doc>
<doc id="14863" url="http://en.wikipedia.org/wiki?curid=14863" title="Incunable">
Incunable

An incunable, or sometimes incunabulum (plural incunables or incunabula, respectively), is a book, pamphlet, or broadside (such as the Almanach cracoviense ad annum 1474) that was printed—not handwritten—before the year 1501 in Europe. "Incunable" is the anglicised singular form of "incunabula", Latin for "swaddling clothes" or "cradle", which can refer to "the earliest stages or first traces in the development of anything." A former term for "incunable" is "fifteener", referring to the 15th century.
The first recorded use of "incunabula" as a printing term is in a Latin pamphlet by Bernhard von Mallinckrodt, "De ortu et progressu artis typographicae" ("Of the rise and progress of the typographic art", Cologne, 1639), which includes the phrase "prima typographicae incunabula", "the first infancy of printing", a term to which he arbitrarily set an end, 1500, which still stands as a convention. The term came to denote the printed books themselves in the late 17th century. John Evelyn, in moving the Arundel Manuscripts to the Royal Society in August 1678, remarked of the printed books among the manuscripts "The printed books, being of the oldest impressions, are not the less valuable; I esteem them almost equal to MSS."
The convenient but arbitrarily chosen end date for identifying a printed book as an incunable does not reflect any notable developments in the printing process, and many books printed for a number of years after 1500 continued to be visually indistinguishable from incunables. "Post-incunable" typically refers to books printed after 1500 up to another arbitrary end date such as 1520 or 1540.
As of 2008, there are between 28,000 and 30,000 distinct incunable editions known to be extant, while the number of surviving copies in Germany alone is estimated at around 125,000.
Types.
There are two types of "incunabula" in printing: the "Block book" printed from a single carved or sculpted wooden block for each page, by the same process as the woodcut in art (these may be called "xylographic"), and the "typographic book", made with individual pieces of cast metal movable type on a printing press. Many authors reserve the term "incunabula" for the typographic ones only.
The spread of printing to cities both in the north and in Italy ensured that there was great variety in the texts chosen for printing and the styles in which they appeared. Many early typefaces were modelled on local forms of writing or derived from the various European forms of Gothic script, but there were also some derived from documentary scripts (such as most of Caxton's types), and, particularly in Italy, types modelled on handwritten scripts and calligraphy employed by humanists.
Printers congregated in urban centres where there were scholars, ecclesiastics, lawyers, nobles and professionals who formed their major customer base. Standard works in Latin inherited from the medieval tradition formed the bulk of the earliest printing, but as books became cheaper, works in the various vernaculars (or translations of standard works) began to appear.
Examples and collections.
"Incunabula" include the Gutenberg Bible of 1455, the "Peregrinatio in terram sanctam" of 1486—printed and illustrated by Erhard Reuwich—both from Mainz, the "Nuremberg Chronicle" written by Hartmann Schedel and printed by Anton Koberger in 1493, and the "Hypnerotomachia Poliphili" printed by Aldus Manutius with important illustrations by an unknown artist. Other printers of incunabula were Günther Zainer of Augsburg, Johannes Mentelin and Heinrich Eggestein of Strasbourg, Heinrich Gran of Haguenau and William Caxton of Bruges and London. The first incunable to have woodcut illustrations was Ulrich Boner's "Der Edelstein," printed by Albrecht Pfister in Bamberg in 1461.
The British Library's Incunabula Short Title Catalogue now records over 29,000 titles, of which around 27,400 are incunabula editions (not all unique works). Studies of incunabula began in the 17th century. Michel Maittaire (1667–1747) and Georg Wolfgang Panzer (1729–1805) arranged printed material chronologically in annals format, and in the first half of the 19th century, Ludwig Hain published, "Repertorium bibliographicum"— a checklist of incunabula arranged alphabetically by author: "Hain numbers" are still a reference point. Hain was expanded in subsequent editions, by Walter A. Copinger and Dietrich Reichling, but it is being superseded by the authoritative modern listing, a German catalogue, the "Gesamtkatalog der Wiegendrucke", which has been under way since 1925 and is still being compiled at the Staatsbibliothek zu Berlin. North American holdings were listed by Frederick R. Goff and a worldwide union catalogue is provided by the Incunabula Short Title Catalogue.
Notable collections, with the approximate numbers of incunabula held, include:
Statistical data.
The data in this section were derived from the Incunabula Short-Title Catalogue.
Post-incunable.
The "end date" for identifying a printed book as an incunable is convenient but was chosen arbitrarily. It does not reflect any notable developments in the printing process around the year 1500. Books printed for a number of years after 1500 continued to look much like incunables, with the notable exception of the small format books printed in italic type introduced by Aldus Manutius in 1501. The term post-incunable is sometimes used to refer to books printed "after 1500—how long after, the experts have not yet agreed." For books printed on the Continent, the term generally covers 1501–1540, and for books printed in England, 1501–1520.

</doc>
<doc id="14865" url="http://en.wikipedia.org/wiki?curid=14865" title="Isotropy">
Isotropy

Isotropy is uniformity in all orientations; it is derived from the Greek "isos" (ἴσος, "equal") and "tropos" (τρόπος, "way"). Precise definitions depend on the subject area. Exceptions, or inequalities, are frequently indicated by the prefix "an", hence "anisotropy". "Anisotropy" is also used to describe situations where properties vary systematically, dependent on direction. Isotropic radiation has the same intensity regardless of the direction of measurement, and an isotropic field exerts the same action regardless of how the test particle is oriented.
Mathematics.
Within mathematics, "isotropy" has a few different meanings:
Physics.
Materials science.
In the study of mechanical properties of materials, "isotropic" means having identical values of a property in all directions. This definition is also used in geology and mineralogy. Glass and metals are examples of isotropic materials. Common anisotropic materials include wood, because its material properties are different parallel and perpendicular to the grain, and layered minerals such as slate.
Isotropic materials are useful since they are easier to shape, and their behavior is easier to predict. Anisotropic materials can be tailored to the forces an object is expected to experience. For example, the fibers in carbon fiber materials and rebars in reinforced concrete are oriented to withstand tension.
Microfabrication.
In industrial processes, such as etching steps, isotropic means that the process proceeds at the same rate, regardless of direction. Simple chemical reaction and removal of a substrate by an acid, a solvent or a reactive gas is often very close to isotropic. Conversely, anisotropic means that the attack rate of the substrate is higher in a certain direction. Anisotropic etch processes, where vertical etch-rate is high, but lateral etch-rate is very small are essential processes in microfabrication of integrated circuits and MEMS devices.
Antenna (radio).
An isotropic antenna is an idealized "radiating element" used as a reference; an antenna that broadcasts power equally (calculated by the Poynting vector) in all directions. The gain of an arbitrary antenna is usually reported in decibels relative to an isotropic antenna, and is expressed as dBi or dB(i).

</doc>
<doc id="14868" url="http://en.wikipedia.org/wiki?curid=14868" title="International Mathematical Union">
International Mathematical Union

The International Mathematical Union (IMU) is an international non-governmental organisation devoted to international cooperation in the field of mathematics across the world. It is a member of the International Council for Science (ICSU) and supports the International Congress of Mathematicians. Its members are national mathematics organizations from more than 80 countries.
The objectives of the International Mathematical Union (IMU) are to promote international cooperation in mathematics. By supporting and assisting the International Congress of Mathematicians (ICM) and other international scientific meetings/conferences. To acknowledge outstanding research contributions to mathematics, through the awarding of scientific prizes and to encourage and support other international mathematical activities, considered likely to contribute to the development of mathematical science in any of its aspects, whether pure, applied, or educational.
The IMU was established in 1920, but dissolved in September 1932 and then re-established 1950 de facto at the Constitutive Convention in New York, de jure on September 10, 1951, when ten countries had become members. The last milestone was the General Assembly in March 1952, in Rome, Italy where the activities of the new IMU were inaugurated and the first Executive Committee, President and various commissions where elected. In 1952 the IMU was also readmitted to the ICSU. The past president of the Union is Ingrid Daubechies (2011–2014). The current president is Shigefumi Mori who is the first head of the group from Asia.
At the 16th meeting of the IMU General Assembly in Bangalore, India, in August 2010, Berlin was chosen as the location of the permanent office of the IMU, which was opened on January 1, 2011, and is hosted by the Weierstrass Institute for Applied Analysis and Stochastics (WIAS), an institute of the Gottfried Wilhelm Leibniz Scientific Community, with about 120 scientists engaging in mathematical research applied to complex problems in industry and commerce.
Commissions and committees.
IMU has a close relationship to mathematics education through its International Commission on Mathematical Instruction (ICMI). This commission is organized similarly to IMU with its own Executive Committee and General Assembly.
Developing countries are a high priority for the IMU and a significant percentage of their budget, including grants received from individuals, mathematical societies, foundations, and funding agencies, is spent on activities for developing countries. Since 2011 this has been coordinated by the .
The International Commission for the History of Mathematics (ICHM) is operated jointly by the IMU and the Division of the History of Science (DHS) of the International Union for the History and Philosophy of Science (IUHPS).
The Committee on Electronic Information and Communication (CEIC) advises IMU on matters concerning mathematical information, communication, and publishing.
Prizes.
The scientific prizes awarded by the IMU are deemed to be the highest distinctions in the mathematical world. The opening ceremony of the International Congress of Mathematicians (ICM) is where the awards are presented: Fields Medals (two to four medals are given since 1936), the Rolf Nevanlinna Prize (since 1986), the Carl Friedrich Gauss Prize (since 2006), and the Chern Medal Award (since 2010).
Membership and General Assembly.
The IMU's members are Member Countries and each Member country is represented through an Adhering Organization, which may be its principal academy, a mathematical society, its research council or some other institution or association of institutions, or an appropriate agency of its government. A country starting to develop its mathematical culture and interested in building links to mathematicians all over the world is invited to join IMU as an Associate Member. For the purpose of facilitating jointly sponsored activities and jointly pursuing the objectives of the IMU, multinational mathematical societies and professional societies can join IMU as an Affiliate Member. Every four years the IMU membership gathers in a General Assembly (GA) which consists of delegates appointed by the Adhering Organizations, together with the members of the Executive Committee. All important decisions are made at the GA, including the election of the officers, establishment of commissions, the approval of the budget, and any changes to the statutes and by-laws.
Organization and Executive Committee.
The International Mathematical Union is administered by an Executive Committee (EC) which conducts the business of the Union. The EC consists of the President, two Vice-Presidents, the Secretary, six Members-at-Large, all elected for a term of four years, and the Past President. The EC is responsible for all policy matters and for tasks, such as choosing the members of the ICM Program Committee and various prize committees.
Publications.
Every two months IMU publishes an electronic newsletter, "IMU-Net", that aims to improve communication between IMU and the worldwide mathematical community by reporting on decisions and recommendations of the Union, major international mathematical events and developments, and on other topics of general mathematical interest. IMU Bulletins are published annually with the aim to inform IMU’s members about the Union’s current activities. In 2009 IMU published the document "Best Current Practices for Journals".
IMU’s Involvement in Developing Countries.
The IMU took its first organized steps towards the promotion of mathematics in developing countries in the early 1970s and has, since then supported various activities. In 2010 IMU formed the Commission for Developing Countries (CDC) which brings together all of the past and current initiatives in support of mathematics and mathematicians in the developing world.
Some IMU Supported Initiatives:
IMU also supports the "International Commission on Mathematical Instruction" (ICMI) with its programmes, exhibits and workshops in emerging countries, especially in Asia and Africa.
IMU released a report in 2008, "Mathematics in Africa: Challenges and Opportunities", on the current state of mathematics in Africa and on opportunities for new initiatives to support mathematical development. In 2014, the IMU's Commission for Developing Countries CDC released an update of the report.
Additionally, reports about "Mathematics in Latin America and the Caribbean and South East Asia". were published.
In July 2014 IMU released the report: The International Mathematical Union in the Developing World: Past, Present and Future (July 2014).
MENAO Symposium at the ICM.
In 2014, the IMU held a day-long symposium prior to the opening of the International Congress of Mathematicians (ICM), entitled "Mathematics in Emerging Nations: Achievements and Opportunities" (MENAO). Approximately 260 participants from around the world, including representatives of embassies, scientific institutions, private business and foundations attended this session. Attendees heard inspiring stories of individual mathematicians and specific developing nations.
Presidents.
List of presidents of the International Mathematical Union from 1952 to the present:
1952–1954: Marshall Harvey Stone (vice: Émile Borel, Erich Kamke)
1955–1958: Heinz Hopf (vice: Arnaud Denjoy, W. V. D. Hodge)
1959–1962: Rolf Nevanlinna (vice: Pavel Alexandrov, Marston Morse)
1963–1966: Georges de Rham (vice: Henri Cartan, Kazimierz Kuratowski)
1967–1970: Henri Cartan (vice: Mikhail Lavrentyev, Deane Montgomery)
1971–1974: K. S. Chandrasekharan (vice: Abraham Adrian Albert, Lev Pontryagin)
1975–1978: Deane Montgomery (vice: J. W. S. Cassels, Miron Nicolescu, Gheorghe Vrânceanu)
1979–1982: Lennart Carleson (vice: Masayoshi Nagata, Yuri Vasilyevich Prokhorov)
1983–1986: Jürgen Moser (vice: Ludvig Faddeev, Jean-Pierre Serre)
1987–1990: Ludvig Faddeev (vice: Walter Feit, Lars Hörmander)
1991–1994: Jacques-Louis Lions (vice: John H. Coates, David Mumford)
1995–1998: David Mumford (vice: Vladimir Arnold, Albrecht Dold)
1999–2002: Jacob Palis (vice: Simon Donaldson, Shigefumi Mori)
2003–2006: John M. Ball (vice: Jean-Michel Bismut, Masaki Kashiwara)
2007–2010: László Lovász (vice: Zhi-Ming Ma, Claudio Procesi)
2011–2014: Ingrid Daubechies (vice: Christiane Rousseau, Marcelo Viana)
2015–2018: Shigefumi Mori (vice: Alicia Dickenstein, Vaughan Jones)

</doc>
<doc id="14869" url="http://en.wikipedia.org/wiki?curid=14869" title="International Council for Science">
International Council for Science

The International Council for Science (abbreviated ICSU, after its former name, International Council of Scientific Unions) is an international organization devoted to international cooperation in the advancement of science. Its members are national scientific bodies and international scientific unions. As of 2012, it comprises 120 multi-disciplinary National Scientific Members, Associates and Observers representing 140 countries and 31 international, disciplinary Scientific Unions. ICSU also has 22 Scientific Associates.
Mission and principles.
"ICSU’s mission is to strengthen international science for the benefit of society. To do this, ICSU mobilizes the knowledge and resources of the international science community to:
Activities focus on three areas: International Research Collaboration, Science for Policy, and Universality of Science.
History.
ICSU is one of the oldest non-governmental organizations in the world and represents the evolution and expansion of two earlier bodies known as the International Association of Academies (IAA; 1899-1914) and the International Research Council (IRC; 1919-1931). In 1998, Members agreed that the Council’s current composition and activities would be better reflected by modifying the name from the International Council of Scientific Unions to the International Council for Science, while its rich history and strong identity would be well served by retaining the existing acronym, ICSU.
Universality of Science.
"The universality of science in its broadest sense is about developing a truly global scientific community on the basis of equity and non-discrimination. It is also about ensuring that science is trusted and valued by societies across the world. As such, it incorporates issues related to the conduct of science; capacity building; science education and literacy; access to data and information and the relationship between science and society. [...] Underpinning this broader concept of universality is the Principle of the Universality of Science (ICSU Statute 5) which is more narrowly focused on the freedoms and responsibilities of science. Adherence to this Principle is a condition of ICSU membership. The policy Committee on Freedom and Responsibility in the conduct of Science (CFRS) serves as the guardian of the Principle and undertakes a variety of actions to defend scientific freedoms and promote integrity and responsibility."
 The "Freedom and Responsibility Portal" on the ICSU's website documents its activities in these areas.
Structure.
The ICSU Secretariat (20 staff in 2012) in Paris ensures the day-to-day planning and operations under the guidance of an elected Executive Board. Three Policy Committees − Committee on Scientific Planning and Review (CSPR), Committee on Freedom and Responsibility in the conduct of Science (CFRS) and Committee on Finance − assist the Executive Board in its work and a General Assembly of all Members is convened every three years. ICSU has three Regional Offices − Africa, Asia and the Pacific as well as Latin America and the Caribbean.
Finances.
The principal source of ICSU's finances is the contributions it receives from its members. Other sources of income are the framework contracts from UNESCO (United Nations Educational, Scientific and Cultural Organization) and grants and contracts from United Nations bodies, foundations and agencies, which are used to support the scientific activities of the ICSU Unions and interdisciplinary bodies.

</doc>
<doc id="14870" url="http://en.wikipedia.org/wiki?curid=14870" title="International Union of Pure and Applied Chemistry">
International Union of Pure and Applied Chemistry

The International Union of Pure and Applied Chemistry (IUPAC, on lowercase letters: iupac, or ) is an international federation of National Adhering Organizations that represents chemists in individual countries. It is a member of the International Council for Science (ICSU). The international headquarters of IUPAC is in Zürich, Switzerland. The administrative office, known as the "IUPAC Secretariat", is in Research Triangle Park, North Carolina, United States. This administrative office is headed by the IUPAC executive director. As of 1 August 2012, the Executive Director is Dr. John D. Petersen.
IUPAC was established in 1919 as the successor of the International Congress of Applied Chemistry for the advancement of chemistry. Its members, the National Adhering Organizations, can be national chemistry societies, national academies of sciences, or other bodies representing chemists. There are fifty-four National Adhering Organizations and three Associate National Adhering Organizations. IUPAC's Inter-divisional Committee on Nomenclature and Symbols (IUPAC nomenclature) is the recognized world authority in developing standards for the naming of the chemical elements and compounds. Since its creation, IUPAC has been run by many different committees with different responsibilities. These committees run different projects which include standardizing nomenclature, finding ways to bring chemistry to the world, and publishing works.
IUPAC is best known for its works standardizing nomenclature in chemistry and other fields of science, but IUPAC has publications in many fields including chemistry, biology and physics. Some important work IUPAC has done in these fields includes standardizing nucleotide base sequence code names; publishing books for environmental scientists, chemists, and physicists; and leading the way in improving education in science. IUPAC is also known for standardizing the atomic weights of the elements through one of its oldest standing committees, the Commission on Isotopic Abundances and Atomic Weights.
Creation and history.
The need for an international standard for chemistry was first addressed in 1860 by a committee headed by German scientist Friedrich August Kekulé von Stradonitz. This committee was the first international conference to create an international naming system for organic compounds. The ideas that were formulated in that conference evolved into the official IUPAC nomenclature of organic chemistry. The IUPAC stands as a legacy of this meeting, making it one of the most important historical international collaborations of chemistry societies. Since this time, IUPAC has been the official organization held with the responsibility of updating and maintaining official organic nomenclature. IUPAC as such was established in 1919. One notable country excluded from this early IUPAC was Germany. Germany's exclusion was a result of prejudice towards Germans by the allied powers after World War I. Germany was finally admitted into IUPAC during 1929. However, Nazi Germany was removed from IUPAC during World War II.
During World War II, IUPAC was affiliated with the Allied powers, but had little involvement during the war effort itself. After the war, West Germany was allowed back into IUPAC. Since World War II, IUPAC has been focused on standardizing nomenclature and methods in science without interruption.
Committees and governance.
IUPAC is governed by several committees that all have different responsibilities. The committees are as follows: Bureau, CHEMRAWN (Chem Research Applied to World Needs) Committee, Committee on Chemistry Education, Committee on Chemistry and Industry, Committee on Printed and Electronic Publications, Evaluation Committee, Executive Committee, Finance Committee, Interdivisional Committee on Terminology, Nomenclature and Symbols, Project Committee, Pure and Applied Chemistry Editorial Advisory Board. Each committee is made from members of different National Adhering Organizations from different countries.
The steering committee hierarchy for IUPAC is as follows:
Nomenclature.
The IUPAC committee has a long history of officially naming organic and inorganic compounds as mentioned in the Creation and History section. IUPAC nomenclature is developed so that any compound can be named under one set of standard rules to avoid repeat names. The first publication, which is information from the International Congress of Applied Chemistry, is on IUPAC nomenclature of organic compounds can be found from the early 20th century in "A Guide to IUPAC Nomenclature of Organic Compounds" (1900).
Organic nomenclature.
IUPAC organic nomenclature has three basic parts: the substituents, carbon chain length and chemical ending. The substituents are any functional groups attached to the main carbon chain. The main carbon chain is the longest possible continuous chain. The chemical ending denotes what type of molecule it is. For example, the ending "ane" denotes a single bonded carbon chain, as in "hexane" (C6H14).
Another example of IUPAC organic nomenclature is cyclohexanol:
Inorganic nomenclature.
Basic IUPAC inorganic nomenclature has two main parts: the cation and the anion. The cation is the name for the positively charged ion and the anion is the name for the negatively charged ion.
An example of IUPAC nomenclature of inorganic chemistry is potassium chlorate (KClO3):
Amino acid and nucleotide base codes.
IUPAC also has a system for giving codes to identify amino acids and nucleotide bases. IUPAC needed a coding system that represented long sequences of amino acids. This would allow for these sequences to be compared to try to find homologies. These codes can consist of either a one letter code or a three letter code.
These codes make it easier and shorter to write down the amino acid sequences that make up proteins. The nucleotide bases are made up of purines (adenine and guanine) and pyrimidines (cytosine and thymine or uracil). These nucleotide bases make up DNA and RNA. These nucleotide base codes make the genome of an organism much smaller and easier to read.
The codes for amino acids (24 amino acids and 3 special codes) are:
Publications.
Experimental Thermodynamics book series.
The Experimental Thermodynamics books series covers many topics in the fields of thermodynamics.
Colored cover book and website series (nomenclature).
IUPAC color codes their books in order to make each publication distinguishable.
International Year of Chemistry.
IUPAC and UNESCO are the lead organizations coordinating events for the International Year of Chemistry, which took place in 2011. The International Year of Chemistry was originally proposed by IUPAC at the General Assembly in Turin, Italy. This motion was adopted by UNESCO at a meeting in 2008. The main objectives of the International Year of Chemistry is to increase public appreciation of chemistry and gain more interest in the world of chemistry. This event is also being held to encourage young people to get involved and contribute to chemistry. A further reason for this event being held is to honour how chemistry has made improvements to everyone's way of life.

</doc>
<doc id="14871" url="http://en.wikipedia.org/wiki?curid=14871" title="International Hydrographic Organization">
International Hydrographic Organization

The International Hydrographic Organization (IHO) is an inter-governmental organisation representing the hydrographic community. 
The principal role of the IHO is to ensure that the world’s seas, oceans and national waters are properly surveyed and charted. It does this through the setting of international standards, the co-ordination of the endeavours of national hydrographic offices, and through its capacity building programme.
The IHO enjoys observer status at the United Nations where it is the recognised competent authority on hydrographic surveying and nautical charting. When referring to hydrography and nautical charting in Conventions and similar Instruments, it is the IHO standards and specifications that are normally used.
History.
The IHO was established in 1921 as the International Hydrographic Bureau (IHB). The present name was adopted in 1970 as part of a new international Convention on the IHO adopted by the then member nations. The former name International Hydrographic Bureau was retained to describe the IHO secretariat comprising three elected Directors and a small staff at the Organization's headquarters in Monaco. 
During the 19th century, many maritime nations established hydrographic offices to provide means for improving the navigation of naval and merchant vessels by providing nautical publications, nautical charts, and other navigational services. There were substantial differences in hydrographic procedures charts, and publications. In 1889, an International Marine Conference was held at Washington, D.C., and it was proposed to establish a "permanent international commission." Similar proposals were made at the sessions of the International Congress of Navigation held at St. Petersburg in 1908 and again in 1912.
In 1919 the hydrographers of Great Britain and France cooperated in taking the necessary steps to convene an international conference of hydrographers. London was selected as the most suitable place for this conference, and on 24 July 1919, the First International Conference opened, attended by the hydrographers of 24 nations. The object of the conference was "To consider the advisability of all maritime nations adopting similar methods in preparation, construction, and production of their charts and all hydrographic publications; of rendering the results in the most convenient form to enable them to be readily used; of instituting a prompt system of mutual exchange of hydrographic information between all countries; and of providing an opportunity to consultations and discussions to be carried out on hydrographic subjects generally by the hydrographic experts of the world." This is still the major purpose of IHO.
As a result of the conference, a permanent organization was formed and statutes for its operations were prepared. The IHB, now the IHO, began its activities in 1921 with 18 nations as members. The Principality of Monaco was selected as the seat of the organization as a result of the offer of Albert I, Prince of Monaco to provide suitable accommodations for the bureau in the principality.
Functions.
The IHO develops hydrographic and nautical charting standards. These are subsequently adopted and used by its member countries in their surveys, nautical charts, and publications. The almost universal use of the IHO standards means that the products and services provided by the world's national hydrographic and oceanographic offices are consistent and recognisable by all seafarers and for other users. Much has been done in the field of standardisation since the Bureau (now the IHO) was founded.
The IHO has encouraged the formation of Regional Hydrographic Commissions (RHCs). Each RHC coordinates the national surveying and charting activities of countries within each region and acts as a forum to address other matters of common hydrographic interest. The 15 RHCs plus the IHO Hydrographic Commission on Antarctica (HCA) effectively cover the world.
The IHO, in partnership with the Intergovernmental Oceanographic Commission (IOC), directs the General Bathymetric Chart of the Oceans programme. 
Publications.
Most IHO publications, including the standards, guidelines and associated documents such as the "International Hydrographic Review", "International Hydrographic Bulletin", the "Hydrographic Dictionary" and the "Year Book" are available to the general public free from the IHO website.
The IHO publishes the international standards related to charting and hydrography, including S-57, "IHO Transfer Standard for Digital Hydrographic Data", the encoding standard that is used primarily for electronic navigational charts. In 2010 the IHO introduced a new, contemporary hydrographic geospatial standard for modelling marine data and information, known as S-100. S-100 and any dependent product specifications are underpinned by an on-line registry accessible via the IHO website. S-100 is aligned with the ISO 19100 series of geographic standards, thereby making it fully compatible with contemporary geospatial data standards. Because S-100 is based on ISO 19100, it can be used by other data providers for their maritime related (non-hydrographic) data and information. This is already occurring in 2014, with various would-be data providers preparing themselves for the advent of the e-Navigation concept currently under active discussion in the UN International Maritime Organisation.
Meetings.
The IHO maintains a programme of meetings of its committees and working groups around the world. The meetings and the meetings of other related International Organisations are promulgated in the calendar on the IHO website.
Member countries.
The following countries are members of the IHO:

</doc>
<doc id="14872" url="http://en.wikipedia.org/wiki?curid=14872" title="IBM mainframe">
IBM mainframe

IBM mainframes are large computer systems produced by IBM from 1952 to the present. During the 1960s and 1970s, the term mainframe computer was almost synonymous with IBM products due to their marketshare. Current mainframes in IBM's line of business computers are developments of the basic design of the IBM System/360.
First and second generation.
From 1952 into the late 1960s, IBM manufactured and marketed several large computer models, known as the IBM 700/7000 series. The first-generation 700s were based on vacuum tubes, while the later, second-generation 7000s used transistors. These machines established IBM's dominance in electronic data processing ("EDP"). IBM had two model categories: one (701, 704, 709, 7090, 7040) for engineering and scientific use, and one (702, 705, 705-II, 705-III, 7080, 7070, 7010) for commercial or data processing use. The two categories, scientific and commercial, generally used common peripherals but had completely different instruction sets, and there were incompatibilities even within each category.
IBM initially sold its computers without any software, expecting customers to write their own; programs were manually initiated, one at a time. Later, IBM provided compilers for the newly developed higher-level programming languages Fortran and COBOL. The first operating systems for IBM computers were written by IBM customers who did not wish to have their very expensive machines ($2M USD in the mid-1950s) sitting idle while operators set up jobs manually. These first operating systems were essentially scheduled work queues. It is generally thought that the first operating system used for real work was GM-NAA I/O, produced by General Motors' Research division in 1956. IBM enhanced one of GM-NAA I/O's successors, the SHARE Operating System, and provided it to customers under the name IBSYS. As software became more complex and important, the cost of supporting it on so many different designs became burdensome, and this was one of the factors which led IBM to develop System/360 and its operating systems.
The second generation (transistor-based) products were a mainstay of IBM's business and IBM continued to make them for several years after the introduction of the System/360. (Some IBM 7094s remained in service into the 1980s.)
Smaller machines.
Prior to System/360, IBM also sold computers smaller in scale that were not considered mainframes, though they were still bulky and expensive by modern standards. These included:
IBM had difficulty getting customers to upgrade from the smaller machines to the mainframes because so much software had to be rewritten. The 7010 was introduced in 1962 as a mainframe-sized 1410. The later Systems 360 and 370 could emulate the 1400 machines. A desk size machine with a different instruction set, the IBM 1130, was released concurrently with the System/360 to address the niche occupied by the 1620. It used the same EBCDIC character encoding as the 360 and was mostly programmed in Fortran, which was relatively easy to adapt to larger machines when necessary.
"Midrange computer" is a designation used by IBM for a class of computer systems which fall in between mainframes and microcomputers.
IBM System/360.
All that changed with the announcement of the System/360 (S/360) in April, 1964. The System/360 was a single series of compatible models for both commercial and scientific use. The number "360" suggested a "360 degree," or "all-around" computer system. System/360 incorporated features which had previously been present on only either the commercial line (such as decimal arithmetic and byte addressing) or the technical line (such as floating point arithmetic). Some of the arithmetic units and addressing features were optional on some models of the System/360. However, models were upward compatible and most were also downward compatible. The System/360 was also the first computer in wide use to include dedicated hardware provisions for the use of operating systems. Among these were supervisor and application mode programs and instructions, as well as built-in memory protection facilities. Hardware memory protection was provided to protect the operating system from the user programs (tasks) and the user tasks from each other. The new machine also had a larger address space than the older mainframes, 24 bits addressing 8-bit bytes vs. a typical 18 bits addressing 36-bit words. 
The smaller models in the System/360 line (e.g. the 360/30) were intended to replace the 1400 series while providing an easier upgrade path to the larger 360s. To smooth the transition from second generation to the new line, IBM used the 360's microprogramming capability to emulate the more popular older models. Thus 360/30s with this added cost feature could run 1401 programs and the larger 360/65s could run 7094 programs. To run old programs, the 360 had to be halted and restarted in emulation mode. Many customers kept using their old software and one of the features of the later System/370 was the ability to switch to emulation mode and back under operating system control.
Operating systems for the System/360 family included OS/360 (with PCP, MFT, and MVT), BOS/360, TOS/360, and DOS/360.
The System/360 later evolved into the System/370, the System/390, and the 64-bit zSeries, System z, and zEnterprise machines. System/370 introduced virtual memory capabilities in all models other than the very first System/370 models; the OS/VS1 variant of OS/360 MFT, the OS/VS2 (SVS) variant of OS/360 MVT, and the DOS/VS variant of DOS/360 were introduced to use the virtual memory capabilities, followed by MVS, which, unlike the earlier virtual-memory operating systems, ran separate programs in separate address spaces, rather than running all programs in a single virtual address space. The virtual memory capabilities also allowed the system to support virtual machines; the VM/370 hypervisor would run one or more virtual machines running either standard System/360 or System/370 operating systems or the single-user Conversational Monitor System (CMS). A time-sharing VM system could run multiple virtual machines, one per user, with each virtual machine running an instance of CMS.
Today's systems.
The zSeries family, introduced in 2000 with the z900, included IBM's newly designed 64-bit z/Architecture. The new servers provided more than four times the performance of previous models.
Processor units.
The different processors on current IBM mainframes are:
Note that the ICF and zAAP are essentially identical to CP, but distinguished for software cost control: they are slightly restricted such they cannot be used to run arbitrary operating systems, and thus do not count in software licensing costs (which are typically based on the number of CPs).
There are other supporting processors typically installed inside mainframes such as cryptographic accelerators (CryptoExpress), the OSA-Express networking processor, and FICON Express disk I/O processors.
Software to allow users to run "traditional" workloads on zIIPs and zAAPs was briefly marketed by Neon Enterprise Software as "zPrime" but was withdrawn from the market in 2011 after a lawsuit by IBM.
Operating systems.
The primary operating systems in use on current IBM mainframes include z/OS (which followed MVS and OS/390), z/VM (previously VM/CMS), z/VSE (which is in the DOS/360 lineage), z/TPF (a successor of Airlines Control Program), and Linux on System z such as SUSE Linux Enterprise Server and others. A few systems run MUSIC/SP and UTS (Mainframe UNIX). In October 2008, Sine Nomine Associates introduced OpenSolaris on System z.
Middleware.
Current IBM mainframes run all the major enterprise transaction processing environments and databases, including CICS, IMS, WebSphere Application Server, DB2, and Oracle. In many cases these software subsystems can run on more than one mainframe operating system.
Emulators.
There are software-based emulators for the System/370, System/390, and System z hardware, including FLEX-ES, which runs under UnixWare or Linux, and the freely available Hercules, which runs under Linux, FreeBSD, Solaris, Mac OS X and Microsoft Windows.

</doc>
<doc id="14875" url="http://en.wikipedia.org/wiki?curid=14875" title="Iowa State University">
Iowa State University

Iowa State University of Science and Technology, more commonly known as Iowa State University, Iowa State, or ISU, is a public land-grant and space-grant research university located in Ames, Iowa, United States. Until 1959 it was known as the Iowa State College of Agriculture and Mechanic Arts.
Founded in 1858 and coeducational from its start, Iowa State became the nation’s first designated land-grant institution when the Iowa Legislature accepted the provisions of the 1862 Morrill Act on September 11, 1862, making Iowa the first state in the nation to do so. Iowa State's academic offerings are administered today through eight colleges, including the graduate college, that offer over 100 bachelor's degree programs, 112 master's degree programs, and 83 at the Ph.D. level, plus a professional degree program in Veterinary Medicine.
ISU is classified as a Research University with very high research activity (RU/VH) by the Carnegie Foundation for the Advancement of Teaching. The university is a group member of the Association of American Universities and the Universities Research Association, and a charter member of the Big 12 Conference.
History.
Beginnings.
In 1856, the Iowa General Assembly enacted legislation to establish the Iowa Agricultural College and Model Farm. This institution (now Iowa State University) was officially established on March 22, 1858, by the General Assembly. Story County was chosen as the location on June 21, 1859, beating proposals from Johnson, Kossuth, Marshall and Polk counties. The original farm of 648 acre was purchased for a cost of $5,379.
Iowa was the first state in the nation to accept the provisions of the Morrill Act of 1862. Iowa subsequently designated Iowa State as the land-grant college on March 29, 1864. From the start, Iowa Agricultural College focused on the ideals that higher education should be accessible to all and that the university should teach liberal and practical subjects. These ideals are integral to the land-grant university.
The institution was coeducational from the first preparatory class admitted in 1868. The formal admitting of students began the following year, and the first graduating class of 1872 consisted of 24 men and two women.
The Farm House, the first building on the Iowa State campus, was completed in 1861 before the campus was occupied by students or classrooms. It became the home of the superintendent of the Model Farm and in later years, the deans of Agriculture, including Seaman Knapp and "Tama Jim" Wilson. Iowa State's first president, Adonijah Welch, briefly stayed at the Farm House and penned his inaugural speech in a second floor bedroom.
The college's first farm tenants primed the land for agricultural experimentation. The Iowa Experiment Station was one of the university's prominent features. Practical courses of instruction were taught, including one designed to give a general training for the career of a farmer. Courses in mechanical, civil, electrical, and mining engineering were also part of the curriculum.
In 1870, President Welch and I. P. Robert, professor of agriculture, held three-day farmers' institutes at Cedar Falls, Council Bluffs, Washington, and Muscatine. These became the earliest institutes held off-campus by a land grant institution and were the forerunners of 20th century extension.
In 1872, the first courses were given in domestic economy (home economics, family and consumer sciences) and were taught by Mary B. Welch, the president's wife. Iowa State became the first land grant university in the nation to offer training in domestic economy for college credit.
In 1879, the "School" of Veterinary Science was organized, the first state veterinary college in the United States (although veterinary courses has been taught since the beginning of the College). This was originally a two-year course leading to a diploma. The veterinary course of study contained classes in zoology, botany, anatomy of domestic animals, veterinary obstetrics, and sanitary science.
William M. Beardshear was appointed President of Iowa State in 1891. During his tenure, Iowa Agricultural College truly came of age. Beardshear developed new agricultural programs and was instrumental in hiring premier faculty members such Anson Marston, Louis B. Spinney, J.B. Weems, Perry G. Holden, and Maria Roberts. He also expanded the university administration, and the following buildings were added to the campus: Morrill Hall (1891); the Campanile (1899); Old Botany (now Carrie Chapman Catt Hall) (1892); and Margaret Hall (1895) which continue to stand today. In his honor, Iowa State named its central administrative building (Central Building) after Beardshear in 1925. In 1898, reflecting the school's growth during his tenure, it was renamed Iowa State College of Agricultural and Mechanic Arts, or Iowa State for short.
Today, Beardshear Hall holds the following offices: President, Vice-President, Treasurer, Secretary, Registrar, Provost, and student financial aid. Catt Hall is named after famed alumna Carrie Chapman Catt and is the home of the College of Liberal Arts and Sciences.
In 1912 Iowa State had its first Homecoming celebration. The idea was first proposed by Professor Samuel Beyer, the college’s “patron saint of athletics,” who suggested that Iowa State inaugurate a celebration for alumni during the annual football game against rival University of Iowa. Iowa State’s new president, Raymond A. Pearson, liked the idea and issued a special invitation to alumni two weeks prior to the event: “We need you, we must have you. Come and see what a school you have made in Iowa State College. Find a way.” In October 2012 Iowa State marked its 100th Homecoming with a "CYtennial" Celebration.
Iowa State celebrated its first VEISHEA on May 11–13, 1922. Wallace McKee (class of 1922) served as the first chairman of the Central Committee and Frank D. Paine (professor of electrical engineering) chose the name, based on the first letters of Iowa State's colleges: Veterinary Medicine, Engineering, Industrial Science, Home Economics, and Agriculture. VEISHEA has grown to become the largest student-run festival in the nation.
The Statistical Laboratory was established in 1933, with George W. Snedecor, professor of mathematics, as the first director. It was and is the first research and consulting institute of its kind in the country.
While attempting to develop a faster method of computation, mathematics and physics professor John Vincent Atanasoff conceptualized the basic tenets of what would become the world’s first electronic digital computer, the Atanasoff-Berry Computer (ABC), during a drive to Illinois in 1937. These included the use of a binary system of arithmetic, the separation of computer and memory functions, and regenerative drum memory, among others. The 1939 prototype was constructed with graduate student Clifford Berry in the basement of the Physics Building.
During World War II, Iowa State was one of 131 colleges and universities nationally that took part in the V-12 Navy College Training Program which offered students a path to a Navy commission.
Maturity as a university.
On July 4, 1959, the college was officially renamed Iowa State University of Science and Technology. However, the short-form name "Iowa State University" is used even in official documents such as diplomas. 
Official names given the university’s divisions were the College of Agriculture, College of Engineering, College of Home Economics, College of Sciences and Humanities, and College of Veterinary Medicine.
Iowa State's eight colleges today offer more than 100 undergraduate majors and 200 fields of study leading to graduate and professional degrees. The academic program at ISU includes a vigorous liberal arts education and some of the world's leading research in the biological and physical sciences.
Breakthroughs at Iowa State changing the world are in the areas of human, social, economic, and environmental sustainability; new materials and processes for biomedical as well as industrial applications; nutrition, health, and wellness for humans and animals; transportation and infrastructure; food safety and security; plant and animal sciences; information and decision sciences; and renewable energies. The focus on technology has led directly to many research patents and inventions including the first binary computer (the ABC), Maytag blue cheese, the round hay baler, and many more.
Located on a lush, 2,000 acre campus, the university has grown considerably from its roots as an agricultural college and model farm and is recognized internationally today for its comprehensive research programs that are especially interdisciplinary. It continues to grow and set a new record for enrollment in the fall of 2013 with 33,241 students.
They are drug free since 1993
Timeline chronology.
Events occurring in the same year did not necessarily happen in the order presented here.
Academics.
Colleges and schools.
Iowa State University is organized into eight colleges and two schools that offer 100 Bachelor's degree programs, 112 Masters programs, and 83 Ph.D programs, including one professional degree program in Veterinary Medicine.
ISU is home to the following schools:
Rankings.
ISU is ranked among the top 50 public universities in the U.S. and is known for its degree programs in agriculture, engineering, and science. Classified as a Carnegie RU/VH doctoral/research institution, Iowa State receives nearly $300 million in research grants each year.
The university is one of 62 elected members of the Association of American Universities, an organization composed of the most highly ranked public and private research universities in the U.S. and Canada.
Overall, ISU ranks #101 in the "U.S. News & World Report" ranking of national universities and #21 in the "Washington Monthly" rankings. In engineering specialties, at schools whose highest degree is a doctorate, Iowa State's agricultural engineering program is ranked third among top programs in the U.S. Aerospace engineering ranks 13th among public universities (18th overall). Chemical engineering and civil engineering both are ranked 13th among public universities (20th overall). Materials engineering is ranked 11th among public universities (17th overall). ISU's Greenlee School of Journalism and Communication is notable for being among the first group of accredited journalism and mass communication programs and is cited as one of the leading JMC research programs in the nation, ranked 23rd in a publication by the AEJMC.
The National Science Foundation ranks ISU #94 in the nation in research and development expenditures for science and engineering and #78 in total research and development expenditures. Currently, ISU ranks #2 in license and options executed on its intellectual property and #5 in license and options that yield income.
Parks Library.
The W. Robert and Ellen Sorge Parks Library contains over 2.6 million books and subscribes to more than 98,600 journal titles. Named for W. Robert Parks (1915–2003), the 11th president of Iowa State University, and his wife, Ellen Sorge Parks, the original library was built in 1925 with three subsequent additions made in 1961, 1969, and 1983. The library was dedicated and named after W. Robert and Ellen Sorge Parks in 1984.
Parks Library provides extensive research collections, services and information literacy instruction/information for all students. Facilities consist of the main Parks Library, the e-Library, the Veterinary Medical Library, two subject-oriented reading rooms (design and mathematics), and a remote library storage building.
The Library’s extensive collections include electronic and print resources that support research and study for all undergraduate and graduate programs. Nationally recognized collections support the basic and applied fields of biological and physical sciences. The Parks Library includes four public service desks: the Learning Connections Center, the Circulation Desk, the Media Center (including Maps, Media,
Microforms, and Course Reserve collections), and Special Collections. The Library’s instruction program includes a required undergraduate information literacy course as well as a wide variety of subject-based seminars on effective use of Library resources for undergraduate and graduate students.
The e-Library, accessed through the Internet, provides access to local and Web-based resources including electronic journals and books, local collections, online indexes, electronic course reserves and guides, and a broad range of subject research guides.
Surrounding the first floor lobby staircase in Parks Library are eight mural panels
designed by Iowa artist Grant Wood. As with "Breaking the Prairie Sod", Wood's other
Iowa State University mural painted two years later, Wood borrowed his theme for "When Tillage Begins Other Arts Follow" from a speech on agriculture delivered by Daniel
Webster in 1840 at the State House in Boston. Webster said, “When tillage begins, other
arts follow. The farmers therefore are the founders of human civilization.” Wood had
planned to create seventeen mural panels for the library, but only the eleven devoted to
agriculture and the practical arts were completed. The final six, which would have hung
in the main reading room (now the Periodical Room) and were to have depicted the fine
arts, were never begun.
Intensive English and Orientation Program.
The university has an IEOP for foreign students. Students whose native language is not English can take IEOP courses to improve their English proficiency to help them succeed at University-level study. IEOP course content also helps students prepare for English proficiency exams, like the TOEFL and IELTS. Classes included in the IEOP include Grammar, Reading, Writing, Oral Communication and Business and various bridge classes.
Distinctions.
Birthplace of first electronic digital computer.
Iowa State is the birthplace of the first electronic digital computer, starting the world’s computer technology revolution. Invented by mathematics and physics professor John Atanasoff and engineering graduate student Clifford Berry during 1937-42, the Atanasoff-Berry Computer, or ABC, pioneered important elements of modern computing, including binary arithmetic, regenerative memory, parallel processing, electronic switching elements, and separation of memory and computer functions.
On October 19, 1973, U.S. Federal Judge Earl R. Larson signed his decision following a lengthy court trial which declared the ENIAC patent of Mauchly and Eckert invalid and named Atanasoff the inventor of the electronic digital computer—the Atanasoff-Berry Computer or the ABC.
An ABC Team consisting of Ames Laboratory and Iowa State engineers, technicians, researchers and students unveiled a working replica of the Atanasoff-Berry Computer in 1997 which can be seen on display on campus in the Durham Computation Center.
Birth of cooperative extension.
The Extension Service traces its roots to farmers’ institutes developed at Iowa State in the late 19th century. Committed to community, Iowa State pioneered the outreach mission of being a land-grant college through creation of the first Extension Service in 1902. In 1906, the Iowa Legislature enacted the Agricultural Extension Act making funds available for demonstration projects. It is believed this was the first specific legislation establishing state extension work, for which Iowa State assumed responsibility. The national extension program was created in 1914 based heavily on the Iowa State model.
Manhattan Project.
ISU is the only university nationwide that has a U.S. Department of Energy research laboratory physically located on its campus. Iowa State played a critical role in the development of the atomic bomb during World War II as part of the Manhattan Project, a research and development program begun in 1942 under the U.S. Army Corps of Engineers to develop the atomic bomb.
The process to produce large quantities of high-purity uranium metal became known as the Ames process. One-third of the uranium metal used in the world’s first controlled nuclear chain reaction was produced at Iowa State under the direction of Frank Spedding. The Ames project received the Army-Navy ‘E’ Award for Excellence in Production on October 12, 1945, signifying two-and-one-half years of excellence in industrial production of metallic uranium as a vital war material. Iowa State is unique among educational institutions to have received this award for outstanding service, an honor normally given to industry.
Today, the Ames Laboratory focuses on more peaceful applications of materials research, usually related to increasing energy efficiency. It has broadened the scope of its research into various areas of national concern, including energy resources, high-speed computer design, environmental cleanup and restoration, and the synthesis and study of new materials.
VEISHEA celebration.
Iowa State is widely known for VEISHEA, an annual education and entertainment festival held on campus each spring. The name VEISHEA is derived from the initials of ISU's five original colleges, forming an acronym as the university existed when the festival was founded in 1922:
VEISHEA was the largest student run festival in the nation, bringing in tens of thousands of visitors to the campus each year.
The celebration featured an annual parade and many open-house demonstrations of the university facilities and departments. Campus organizations exhibit products, technologies, and hold fund raisers for various charity groups. In addition, VEISHEA brought speakers, lecturers, and entertainers to Iowa State, and throughout its over eight decade history, it has hosted such distinguished guests as Bob Hope, John Wayne, Presidents Harry Truman, Ronald Reagan, and Lyndon Johnson, and performers Diana Ross, Billy Joel, Sonny and Cher, The Who, The Goo Goo Dolls, Bobby V, and The Black Eyed Peas.
The 2007 VEISHEA festivities marked the start of Iowa State's year-long sesquicentennial celebration.
On August 8, 2014, President Steven Leath announced that VEISHEA would no longer be an annual event at Iowa State and the name VEISHEA would be retired.
Research.
Ames Laboratory.
Iowa State is the only university nationwide that has a U.S. Department of Energy research laboratory physically located on its campus. Operated by ISU, the Ames Laboratory is one of ten national DOE Office of Science research laboratories.
ISU research for the government provided Ames Laboratory its start in the 1940s with the development of a highly efficient process for producing high-purity uranium for atomic energy. Today, Ames Laboratory continues its leading status in current materials research and focuses diverse fundamental and applied research strengths upon issues of national concern, cultivates research talent, and develops and transfers technologies to improve industrial competitiveness and enhance U.S. economic security. Ames Laboratory employs more than 430 full- and part-time employees, including more than 250 scientists and engineers. Students make up more than 20 percent of the paid workforce.
The Ames Laboratory is the U.S. home to 2011 Nobel Prize in Chemistry winner Dan Shechtman and is intensely engaged with the international scientific community, including hosting a large number of international visitors each year.
ISU Research Park.
The ISU Research Park is a 230-acre development with over 270,000 square feet of building space located just south of the Iowa State campus in Ames. Though closely connected with the university, the research park operates independently to help tenants reach their proprietary goals, linking technology creation, business formation, and development assistance with established technology firms and the marketplace.
The ISU Research Park Corporation was established in 1987 as a not-for-profit, independent, corporation operating under a board of directors appointed by Iowa State University and the ISU Foundation. The corporation manages both the Research Park and incubator programs.
Other research institutes.
Iowa State is involved in a number of other significant research and creative endeavors, multidisciplinary collaboration, technology transfer, and strategies addressing real-world problems.
In 2010, the Biorenewables Research Laboratory opened in a LEED-Gold certified building that complements and helps replace labs and offices across Iowa State and promotes interdisciplinary, systems-level research and collaboration. The Lab houses the Bioeconomy Institute, the Biobased Industry Center, and the National Science Foundation Engineering Research Center for Biorenewable Chemicals, a partnership of six universities as well as the Max Planck Society in Germany and the Technical University of Denmark.
The Engineering Teaching and Research Complex is home to one of the world’s only six-sided virtual reality labs (C6) which supports the research of more than 50 faculty and 200 graduate, undergraduate, and postdoctoral students.
Campus.
Recognition.
Iowa State's campus contains over 160 buildings. Several buildings, as well as the Marston Water Tower, are listed on the National Register of Historic Places. The central campus includes 490 acre of trees, plants, and classically designed buildings. The landscape's most dominant feature is the 20 acre central lawn, which was listed as a "medallion site" by the American Society of Landscape Architects in 1999, one of only three central campuses designated as such. The other two were Harvard University and the University of Virginia.
Thomas Gaines, in "The Campus As a Work of Art", proclaimed the Iowa State campus to be one of the twenty-five most beautiful campuses in the country. Gaines noted Iowa State's park-like expanse of central campus, and the use of trees and shrubbery to draw together ISU's varied building architecture. Over decades, campus buildings, including the Campanile, Beardshear Hall, and Curtiss Hall, circled and preserved the central lawn, creating a space where students study, relax, and socialize.
Campanile.
The campanile was constructed during 1897-1898 as a memorial to Margaret MacDonald Stanton, Iowa State's first dean of women, who died on July 25, 1895. The tower is located on ISU's central campus, just north of the Memorial Union. The site was selected by Margaret's husband, Edgar W. Stanton, with the help of then-university president William M. Beardshear. The campanile stands 110 ft tall on a 16 by 16 foot (5 by 5 m) base, and cost $6,510.20 to construct.
The campanile is widely seen as one of the major symbols of Iowa State University. It is featured prominently on the university's official ring and the university's mace, and is also the subject of the university's alma mater, "The Bells of Iowa State".
Lake LaVerne.
Named for Dr. LaVerne W. Noyes, who also donated the funds to see that Alumni Hall could be completed after sitting unfinished and unused from 1905 to 1907. Dr. Noyes is an 1872 alumnus. Lake LaVerne is located west of the Memorial Union and south of Alumni Hall, Carver Hall, and Music Hall. The lake was a gift from Dr. Noyes in 1916.
Lake LaVerne is the home of two mute swans named Sir Lancelot and Elaine, donated to Iowa State by VEISHEA 1935. In 1944, 1970, and 1971 cygnets (baby swans) made their home on Lake LaVerne. Previously Sir Lancelot and Elaine were trumpeter swans but were too aggressive and in 1999 were replaced with two mute swans.
In early spring 2003, Lake LaVerne welcomed its newest and most current mute swan duo. In support of Iowa Department of Natural Resources efforts to re-establish the trumpeter swans in Iowa, university officials avoided bringing breeding pairs of male and female mute swans to Iowa State which means the current Sir Lancelot and Elaine are both female.
Reiman Gardens.
Iowa State has maintained a horticulture garden since 1914. Reiman Gardens is the third location for these gardens. Today's gardens began in 1993 with a gift from Bobbi and Roy Reiman. Construction began in 1994 and the Gardens' initial 5 acre were officially dedicated on September 16, 1995.
Reiman Gardens has since grown to become a 14 acre site consisting of a dozen distinct garden areas, an indoor conservatory and an indoor butterfly "wing", butterfly emergence cases, a gift shop, and several supporting greenhouses. Located immediately south of Jack Trice Stadium on the ISU campus, Reiman Gardens is a year-round facility that has become one of the most visited attractions in central Iowa.
The Gardens has received a number of national, state, and local awards since its opening, and its rose gardens are particularly noteworthy. It was honored with the President's Award in 2000 by All American Rose Selections, Inc., which is presented to one public garden in the United States each year for superior rose maintenance and display: “For contributing to the public interest in rose growing through its efforts in maintaining an outstanding public rose garden.”
University Museums.
The University Museums consist of the Brunnier Art Museum, Farm House Museum, the Art on Campus Program, the Christian Petersen Art Museum, and the Elizabeth and Byron Anderson Sculpture Garden. The Museums include a multitude of unique exhibits, each promoting the understanding and delight of the visual arts as well as attempt to incorporate a vast interaction between the arts, sciences, and technology.
Brunnier Art Museum.
The Brunnier Art Museum, Iowa’s only accredited museum emphasizing a decorative arts collection, is one of the nation's few museums located within a performing arts and conference complex, the Iowa State Center. Founded in 1975, the museum is named after its benefactors, Iowa State alumnus Henry J. Brunnier and his wife Ann. The decorative arts collection they donated, called the Brunnier Collection, is extensive, consisting of ceramics, glass, dolls, ivory, jade, and enameled metals.
Other fine and decorative art objects from the University Art Collection include prints, paintings, sculptures, textiles, carpets, wood objects, lacquered pieces, silver, and furniture. About eight to 12 annual changing exhibitions and permanent collection exhibitions provide educational opportunities for all ages, from learning the history of a quilt hand-stitched over 100 years ago to discovering how scientists analyze the physical properties of artists' materials, such as glass or stone. Lectures, receptions, conferences, university classes, panel discussions, gallery walks, and gallery talks are presented to assist with further interpretation of objects.
Farm House Museum.
Located near the center of the Iowa State campus, the Farm House Museum sits as a monument to early Iowa State history and culture as well as a National Historic Landmark. As the first building on campus, the Farm House was built in 1860 before campus was occupied by students or even classrooms. The college’s first farm tenants primed the land for agricultural experimentation. This early practice lead to Iowa State Agricultural College and Model Farm opening its doors to Iowa students for free in 1869 under the Morrill Act (or Land-grant Act) of 1862.
Many prominent figures have made the Farm House their home throughout its 150 years of use. The first president of the College, Adonijah Welch, briefly stayed at the Farm House and even wrote his inaugural speech in a bedroom on the second floor. James “Tama Jim” Wilson resided for much of the 1890s with his family at the Farm House until he joined President William McKinley’s cabinet as U.S. Secretary of Agriculture. Agriculture Dean Charles Curtiss and his young family replaced Wilson and became the longest resident of Farm House.
In 1976, over 110 years after the initial construction, the Farm House became a museum after much time and effort was put into restoring the early beauty of the modest farm home. Today, faculty, students, and community members can enjoy the museum while honoring its significance in shaping a nationally recognized land-grant university. Its collection boasts a large collection of 19th and early 20th century decorative arts, furnishings and material culture reflecting Iowa State and Iowa heritage. Objects include furnishings from Carrie Chapman Catt and Charles Curtiss, a wide variety of quilts, a modest collection of textiles and apparel, and various china and glassware items.
As with many sites on the Iowa State University Campus, The Farm House Museum has a few old myths and legends associated with it. There are rumors of a ghost changing silverware and dinnerware, unexplained rattling furniture, and curtains that have opened seemingly by themselves.
The Farm House Museum is a unique on-campus educational resource providing a changing environment of exhibitions among the historical permanent collection objects that are on display. A walk through the Farm House Museum immerses visitors in the Victorian era (1860-1910) as well as exhibits colorful Iowa and local Ames history.
Art on Campus Collection.
Iowa State is home to one of the largest campus public art programs in the United States. Over 2,000 works of public art, including 600 by significant national and international artists, are located across campus in buildings, courtyards, open spaces and offices.
The traditional public art program began during the Depression in the 1930s when Iowa State College’s President Raymond Hughes envisioned that "the arts would enrich and provide substantial intellectual exploration into our college curricula." Hughes invited Grant Wood to create the Library’s agricultural murals that speak to the founding of Iowa and Iowa State College and Model Farm. He also offered Christian Petersen a one-semester sculptor residency to design and build the fountain and bas relief at the Dairy Industry Building. In 1955, 21 years later, Petersen retired having created 12 major sculptures for the campus and hundreds of small studio sculptures.
The Art on Campus Collection is a campus-wide resource of over 2000 public works of art. Programs, receptions, dedications, university classes, Wednesday Walks, and educational tours are presented on a regular basis to enhance visual literacy and aesthetic appreciation of this diverse collection.
Christian Petersen Art Museum.
The Christian Petersen Art Museum in Morrill Hall is named for the nation’s first permanent campus artist-in-residence, Christian Petersen, who sculpted and taught at Iowa State from 1934 through 1955, and is considered the founding artist of the Art on Campus Collection.
Named for Justin Smith Morrill who created the Morrill Land-Grant Colleges Act, Morrill Hall was completed in 1891. Originally constructed to fill the capacity of a library, museum, and chapel, its original uses are engraved in the exterior stonework on the east side. The building was vacated in 1996 when it was determined unsafe and was also listed in the National Register of Historic Places the same year. In 2005, $9 million was raised to renovate the building and convert it into a museum. Completed and reopened in March 2007, Morrill Hall is home to the Christian Petersen Art Museum.
As part of University Museums, the Christian Petersen Art Museum at Morrill Hall is the home of the Christian Petersen Art Collection, the Art on Campus Program, the University Museums’s Visual Literacy and Learning Program, and Contemporary Changing Art Exhibitions Program.
Located within the Christian Petersen Art Museum are the Lyle and Nancy Campbell Art Gallery, the Roy and Bobbi Reiman Public Art Studio Gallery, the Margaret Davidson Center for the Study of the Art on Campus Collection, the Edith D. and Torsten E. Lagerstrom Loaned Collections Center, and the Neva M. Petersen Visual Learning Gallery. University Museums shares the James R. and Barbara R. Palmer Small Objects Classroom in Morrill Hall.
Anderson Sculpture Garden.
The Elizabeth and Byron Anderson Sculpture Garden is located by the Christian Petersen Art Museum at historic Morrill Hall. The sculpture garden design incorporates sculptures, a gathering arena, and sidewalks and pathways. Planted with perennials, ground cover, shrubs, and flowering trees, the landscape design provides a distinctive setting for important works of 20th and 21st century sculpture, primarily American. Ranging from forty-four inches to nearly nine feet high and from bronze to other metals, these works of art represent the richly diverse character of modern and contemporary sculpture.
The sculpture garden is adjacent to Iowa State’s 22 acre central campus. Adonijah Welch, ISU’s first president, envisioned a picturesque campus with a winding road encircling the college’s majestic buildings, vast lawns of green grass, many varieties of trees sprinkled throughout to provide shade, and shrubbery and flowers for fragrance. Today, the central lawn continues to be an iconic place for all Iowa Staters, and enjoys national acclaim as one of the most beautiful campuses in the country. The new Elizabeth and Byron Anderson Sculpture Garden further enhances the beauty of Iowa State.
Sustainability.
Iowa State's composting facility "can handle more than 10,000 tons of organic wastes annually." The school's new $3 million revolving loan fund loans money for energy efficiency and conservation projects on campus. In the 2011 College Sustainability Report Card issued by the Sustainable Endowments Institute, the university received a B grade.
Student life.
Residence halls.
Iowa State operates 19 on-campus residence halls. The residence halls are divided into geographical areas.
The Union Drive Association
(UDA) consists of four residence halls located on the west side of campus, including Friley Hall, which has been declared one of the largest residence halls in the country.
The Richardson Court Association (RCA) consists of 12 residence halls on the east side of campus.
The Towers Residence Association (TRA) are located south of the main campus. Two of the four towers, Knapp and Storms Halls, were imploded in 2005; however, Wallace and Wilson Halls still stand.
Buchanan Hall is an upper-division hall housing graduate students that is nominally considered part of the RCA, despite its distance from the other buildings.
ISU operates four apartment complexes for upperclassmen, Frederiksen Court, SUV Apartments, Legacy Tower, and Maricopa, the latter two being leased by the university.
Student government.
The governing body for ISU students is the Government of Student Body or GSB. The GSB is composed of a president, vice president, finance director, cabinet appointed by the president, a clerk appointed by the vice president, senators representing each college and residence area at the university, a nine-member judicial branch and an election commission.
Student organizations.
ISU has over 800 student organizations on campus that represent a variety of interests. Organizations are supported by Iowa State's Student Activities Center. Many student organization offices are housed in the Memorial Union.
The Memorial Union at Iowa State University opened in September 1928 and is currently home to a number of University departments and student organizations, a bowling alley, the University Book Store, and the Hotel Memorial Union.
The original building was designed by architect, William T. Proudfoot. The building employs a classical style of architecture reflecting Greek and Roman influences. The building's design specifically complements the designs of the major buildings surrounding the University's Central Campus area, Beardshear Hall to the west, Curtiss Hall to the east, and MacKay Hall to the north. The style utilizes columns with Corinthian capitals, Paladian windows, triangular pediments, and formally balanced facades.
Designed to be a living memorial for ISU students lost in World War I, the building includes a solemn memorial hall, named the Gold Star Room, which honors the names of the dead World War I, World War II, Korean, Vietnam, and War on Terrorism veterans engraved in marble. Symbolically, the hall was built directly over a library (the Browsing Library) and a small chapel, the symbol being that no country would ever send its young men to die in a war for a noble cause without a solid foundation on both education (the library) and religion (the chapel).
Renovations and additions have continued through the years to include: elevators, bowling lanes, a parking ramp, a book store, food court, and additional wings.
Greek community.
ISU is home to an active Greek community. There are 50 chapters that involve 14.6 percent of undergraduate students. Collectively, fraternity and sorority members have raised over $82,000 for philanthropies and committed 31,416 hours to community service. In 2006, the ISU Greek community was named the best large Greek community in the Midwest.
The ISU Greek Community has received multiple Jellison and Sutherland Awards from Association for Fraternal Leadership and Values, formerly the Mid-American Greek Council Association. These awards recognize the top Greek Communities in the Midwest.
The first fraternity, Delta Tau Delta, was established at Iowa State in 1875, six years after the first graduating class entered Iowa State. The first sorority, I.C. Sorocis, was established only two years later, in 1877. I.C. Sorocis later became a chapter of the first national sorority at Iowa State, Pi Beta Phi. Anti-Greek rioting occurred in 1888. As reported in "The Des Moines Register", "The anti-secret society men of the college met in a mob last night about 11 o'clock in front of the society rooms in chemical and physical hall, determined to break up a joint meeting of three secret societies." In 1891, President William Beardshear banned students from joining secret college fraternities, resulting in the eventually closing of all formerly established fraternities. President Storms lifted the ban in 1904.
Following the lifting of the fraternity ban, the first thirteen national fraternities (IFC) installed on the Iowa State campus between 1904 and 1913 were, in order, Sigma Nu, Sigma Alpha Epsilon, Beta Theta Pi, Phi Gamma Delta, Alpha Tau Omega, Kappa Sigma, Theta Xi, Acacia, Phi Sigma Kappa, Delta Tau Delta, Pi Kappa Alpha, and Phi Delta Theta. Though some have suspended their chapters at various times, eleven of the original thirteen fraternities were active in 2008. Many of these chapters existed on campus as local fraternities before being reorganized as national fraternities, prior to 1904.
In the Spring of 2014, it was announced that Alpha Phi Sorority would be coming to Iowa state in the Fall of 2014, with Delta Gamma Sorority Following in the near future.
School newspaper.
The "Iowa State Daily" is the university's student newspaper. The "Daily" has its roots from a news sheet titled the "Clipper", which was started in the spring of 1890 by a group of students at Iowa Agricultural College led by F.E. Davidson. The "Clipper" soon led to the creation of the "Iowa Agricultural College Student", and the beginnings of what would one day become the "Iowa State Daily".
Campus radio.
88.5 KURE is the university's student-run radio station. Programming for KURE includes ISU sports coverage, talk shows, the annual quiz contest Kaleidoquiz, and various music genres.
Student television.
ISUtv is the university's student-run television station. It is housed in the former WOI-TV station that was established in 1950. The student organization of ISUtv has many programs including Newswatch, a twice weekly news spot, Cyclone InCyders, the campus sports show, Fortnightly News, a satirical/comedy program, and Cy's Eyes on the Skies, a twice weekly weather show.
Athletics.
The "Cyclones" name dates back to 1895. That year, Iowa suffered an unusually high number of devastating cyclones (as tornadoes were called at the time). In September, the Iowa State football team traveled to Northwestern University and defeated that team by a score of 36-0. The next day, the "Chicago Tribune"'s headline read "Struck by a Cyclone: It Comes from Iowa and Devastates Evanston Town." The article reported that "Northwestern might as well have tried to play football with an Iowa cyclone as with the Iowa team it met yesterday." The nickname stuck and the Iowa State team had made a name for itself.
The school colors are cardinal and gold. The mascot is Cy the Cardinal, introduced in 1954. Since a cyclone was determined to be difficult to depict in costume, the cardinal was chosen in reference to the school colors. A contest was held to select a name for the mascot, with the name Cy being chosen as the winner.
The Iowa State Cyclones are a member of the Big 12 Conference and compete in NCAA Division I Football Bowl Subdivision (FBS), fielding 16 varsity teams in 12 sports. The Cyclones also compete in and are a founding member of the Central States Collegiate Hockey League of the American Collegiate Hockey Association.
Iowa State's intrastate archrival is the University of Iowa with whom it competes annually for the Iowa Corn Cy-Hawk Series trophy, an annual athletic competition between the two schools. Sponsored by the Iowa Corn Growers Association, the competition includes all head-to-head regular season competitions between the two rival universities in all sports.
Football.
Football first made its way onto the Iowa State campus in 1878 as a recreational sport, but it was not until 1892 that Iowa State organized its first team to represent the school in football. In 1894, college president William M. Beardshear spearheaded the foundation of an athletic association to officially sanction Iowa State football teams. The 1894 team finished with a 6-1 mark. The Cyclones compete each year for traveling trophies. Since 1977, Iowa State and Iowa compete annually for the Cy-Hawk Trophy. Iowa State competes in an annual rivalry game against Kansas State known as Farmageddon and against former conference foe Missouri for the Telephone Trophy.
The Cyclones play its home games at Jack Trice Stadium, named after Jack Trice, ISU's first African-American athlete and also the first and only Iowa State athlete to die from injuries sustained during athletic competition. Trice died three days after his first game playing for Iowa State against Minnesota in Minneapolis on October 6, 1923. Suffering from a broken collarbone early in the game, he continued to play until he was trampled by a group of Minnesota players. It is disputed whether he was trampled purposely or if it was by accident. The stadium was named in his honor in 1997 and is the only NCAA Division I-A stadium named after an African-American. Jack Trice Stadium, formerly known as Cyclone Stadium, opened on September 20, 1975, with a win against the Air Force Academy.
Men's Basketball.
Hopes of "Hilton Magic" returning took a boost with the hiring of ISU alum, Ames native, and fan favorite Fred Hoiberg as coach of the men's basketball team in April 2010. Hoiberg ("The Mayor") played three seasons under legendary coach Johnny Orr and one season under future Chicago Bulls coach Tim Floyd during his standout collegiate career as a Cyclone (1991–95). Orr laid the foundation of success in men's basketball upon his arrival from Michigan in 1980 and is credited with building Hilton Magic. Besides Hoiberg, other Cyclone greats played for Orr and brought winning seasons, including Jeff Grayer, Barry Stevens, and walk-on Jeff Hornacek. The 1985-86 Cyclones were one of the most memorable. Orr coached the team to second place in the Big Eight and produced one of his greatest career wins, a victory over his former team and No. 2 seed Michigan in the second round of the NCAA tournament.
Under coaches Floyd (1995–98) and Larry Eustachy (1998–2003), Iowa State achieved even greater success. Floyd took the Cyclones to the Sweet Sixteen in 1997 and Eustachy led ISU to two consecutive Big 12 regular season conference titles in 1999-2000 and 2000–01, plus the conference tournament title in 2000. Seeded No. 2 in the 2000 NCAA tournament, Eustachy and the Cyclones defeated UCLA in the Sweet Sixteen before falling to Michigan State, the eventual NCAA Champion, in the regional finals by a score of 75-64 (the differential representing the Spartans' narrowest margin of victory in the tournament). Standout Marcus Fizer and Jamaal Tinsley were scoring leaders for the Cyclones who finished the season 32-5. Tinsley returned to lead the Cyclones the following year with another conference title and No. 2 seed, but ISU finished the season with a 25-6 overall record after a stunning loss to No. 15 seed Hampton in the first round.
In 2011-12, Hoiberg's Cyclones finished third in the Big 12 and returned to the NCAA Tournament, dethroning defending national champion Connecticut, 77-64, in the second round before losing in the Round of 32 to top-seeded Kentucky. All-Big 12 First Team selection Royce White led the Cyclones with 38 points and 22 rebounds in the two contests, ending the season at 23-11.
The 2013-14 campaign turned out to be another highly successful season. Iowa State went 28-8, won the Big 12 Tournament, and advanced to the Sweet Sixteen by beating North Carolina in the second round of the NCAA Tournament. The Cyclones finished 11-7 in Big 12 play, finishing in a tie for third in the league standings, and beat a school-record nine teams (9-3) that were ranked in the Associated Press top 25. The Cyclones opened the season 14-0, breaking the school record for consecutive wins. Melvin Ejim was named the Big 12 Player of the Year and an All-American by five organizations. Deandre Kane was named the Big 12 Tournament’s most valuable player.
Of Iowa State's 16 NCAA Tournament appearances, the Cyclones have reached the Sweet Sixteen five times (1944, 1986, 1997, 2000, 2014), made two appearances in the Elite Eight (1944, 2000), and reached the Final Four once in 1944.
Women's Basketball.
Iowa State is known for having one of the most successful women's basketball programs in the nation. Since the founding of the Big 12, Coach Bill Fennelly and the Cyclones have won three conference titles (one regular season, two tournament), and have advanced to the Sweet Sixteen five times (1999–2001, 2009, 2010) and the Elite Eight twice (1999, 2009) in the NCAA Tournament. The team has one of the largest fan bases in the nation with attendance figures ranked third in the nation in 2009, 2010, and 2012.
Volleyball.
Coach Christy Johnson-Lynch led the 2012 Cyclones team to a fifth straight 20-win season and fifth NCAA regional semifinal appearance in six seasons, and leading Iowa State to a 22-8 (13-3 Big 12) overall record and second-place finish in the conference. The Cyclones finished the season with seven wins over top-25 teams, including a victory over No. 1 Nebraska Cornhuskers in Iowa State’s first-ever win over a top-ranked opponent in addition to providing the only Big 12 Conference loss to the 2012 conference and NCAA champion Texas Longhorns.
In 2011, Iowa State finished the season 25-6 (13-3 Big 12), placing second in the league, as well as a final national ranking of eighth. 2011 is only the second season in which an Iowa State volleyball team has ever recorded 25 wins. The Cyclones beat No. 9 Florida during the season in Gainesville, its sixth win over a top-10 team in Cyclone history. In 2009, Iowa State finished the season second in the Big 12 behind Texas with a 27-5 record and ranked No. 6, its highest ever national finish.
Johnson-Lynch is the fastest Iowa State coach to clinch 100 victories. In 2011, she became the school’s winningest volleyball coach when her team defeated the Texas Tech Red Raiders, her 136th coaching victory, in straight sets.
Wrestling.
The ISU wrestling program has captured the NCAA wrestling tournament title eight times between 1928 and 1987, and won the Big 12 Conference Tournament three consecutive years, 2007-2009. On February 7, 2010, the Cyclones became the first collegiate wrestling program to record its 1,000th dual win in program history by defeating the Arizona State Sun Devils, 30-10, in Tempe, Arizona.
In 2002, under former NCAA champion & Olympian Coach Bobby Douglas, Iowa State became the first school to produce a four-time, undefeated NCAA Division I champion, Cael Sanderson (considered by the majority of the wrestling community to be the best college wrestler ever), who also took the gold medal at the 2004 Olympic Games in Athens, Greece. Dan Gable, another legendary ISU wrestler, is famous for having lost only one match in his entire Iowa State collegiate career - his last, and winning gold at the 1972 Olympics in Munich, Germany, while not giving up a single point.
In 2013, Iowa State hosted its eighth NCAA Wrestling Championships. The Cyclones hosted the first NCAA championships in 1928.
The current head coach is former Olympic gold medalist and two-time World Champion Kevin Jackson, in his fifth season as Iowa State’s head wrestling coach.
Notable people.
As with any major public university, many Iowa State University alumni have achieved fame or notoriety after graduating. These people include astronauts, scientists, Pulitzer Prize winners, statesmen, academicians, CEOs, entrepreneurs, athletes, film and television actors, and a host of other notable individuals in their respective fields.

</doc>
<doc id="14877" url="http://en.wikipedia.org/wiki?curid=14877" title="Induction">
Induction

Induction may refer to:
Technical uses.
In biology and chemistry:
In mathematics:
In philosophy, logic, and computer science:
In physics:

</doc>
<doc id="14878" url="http://en.wikipedia.org/wiki?curid=14878" title="International Astronomical Union">
International Astronomical Union

The International Astronomical Union (IAU; French: "Union astronomique internationale", UAI) is a collection of professional astronomers, at the PhD level and beyond, active in professional research and education in astronomy. It acts as the internationally recognized authority for assigning designations to celestial bodies (stars, planets, asteroids, etc.) and any surface features on them.
The IAU is a member of the International Council for Science (ICSU). Its main objective is to promote and safeguard the science of astronomy in all its aspects through international cooperation. The IAU maintains friendly relations with organizations that include amateur astronomers in their membership. The IAU has its head office on the second floor of the "Institut d'Astrophysique de Paris" in the 14th arrondissement of Paris. Working groups include the Working Group for Planetary System Nomenclature (WGPSN), which maintains the astronomical naming conventions and planetary nomenclature for planetary bodies. The IAU is also responsible for the system of astronomical telegrams which are produced and distributed on its behalf by the Central Bureau for Astronomical Telegrams. The Minor Planet Center also operates under the IAU, and is a clearinghouse for all non-planetary or non-moon bodies in the solar system. The Working Group for Meteor Shower Nomenclature and the Meteor Data Center coordinate the nomenclature of meteor showers. 
History.
The IAU was founded in 1919, as a merger of various international projects including the "Carte du Ciel", the Solar Union and the International Time Bureau ("Bureau International de l'Heure"). The first appointed President was Benjamin Baillaud. Pieter Johannes van Rhijn served as president from 1932 to 1958. In the IAU Information Bulletin No. 100, twelve of the fourteen past General Secretaries since 1964, each one in office for the three years between General Assemblies, recall the IAU history with its difficulties, e.g. with Soviet bloc officials, with the Greek military junta, and the reasons behind the unpopular decision to hold an additional Extraordinary General Assembly in Poland on the occasion of Nicolaus Copernicus' 500th birthday in February 1973, shortly after the regular GA in Australia.
Composition.
The IAU counts a total of 11,438 members, most of them being "active individual members", professional astronomers from 96 countries worldwide. 86% of all individual members are male, while 14% are female, among them the union's former president, astronomer Catherine J. Cesarsky.
Membership also includes 73 "national members", professional astronomical communities representing their country's affiliation with the IAU. National members include the Australian Academy of Science, the Chinese Astronomical Society, the French Academy of Sciences, the Indian National Science Academy, the National Academies (United States), the National Research Foundation of South Africa, the National Scientific and Technical Research Council (Argentina), KACST (Saudi Arabia), the Council of German Observatories, the Royal Astronomical Society (United Kingdom), the Royal Astronomical Society of New Zealand, the Royal Swedish Academy of Sciences, the Russian Academy of Sciences, and the Science Council of Japan, among many others.
The sovereign body of the IAU is its "General Assembly", which comprises all members. The Assembly determines IAU policy, approves the Statutes and By-Laws of the Union (and amendments proposed thereto) and elects various committees.
The right to vote on matters brought before the Assembly varies according to the type of business under discussion. The Statutes consider such business to be divided into two categories:
On budget matters (which fall into the second category), votes are weighted according to the relative subscription levels of the national members. A second category vote requires a turnout of at least two-thirds of national members in order to be valid. An absolute majority is sufficient for approval in any vote, except for Statute revision which requires a two-thirds majority. An equality of votes is resolved by the vote of the President of the Union.
General Assemblies.
Since 1922, the IAU General Assembly meets every three years, with the exception of the period between 1938 to 1948, due to World War II.
After a Polish request in 1967, and by a controversial decision of the then President of the IAU, an Extraordinary IAU General Assembly was held in February 1973 in Warsaw, Poland, to commemorate the 500th anniversary of the birth of Nicolaus Copernicus, soon after the regular 1973 GA had been held in Australia.
The XXVIth General Assembly and the definition of a planet.
The XXVIth General Assembly of the International Astronomical Union was held from 14 to 25 August 2006 in Prague, Czech Republic. On 15 August the Assembly decided to restore to individual members the right to vote on scientific matters, which had been removed from them at the XXVth Assembly in 2003. Among the business before the Assembly was a proposal to adopt a formal definition of "planet". During the General Assembly the text of the definition evolved from the initial proposal that would have created 12 known planets in the Solar System (retaining Pluto and adding Ceres, Pluto's largest moon Charon, and Eris) to the final definition of a planet resolution that was passed on 24 August by the Assembly, which classified Ceres, Eris and Pluto as dwarf planets, and reduced the number of planets in the Solar System to 8. The voting procedure followed IAU's Statutes and Working Rules. The General Assembly lasted 12 days and had 2412 participants, most of them for only part of the duration of the Assembly. 424 of the 9785 individual IAU members attended the Closing Ceremony on 24 August 2006. Following the Closing Ceremony, parts of the scientific community did not agree with this ruling, especially the specific wording of the resolution, and criticized IAU's authority to name celestial bodies. In the ensuing public debate, a number of laypersons expressed (at times strong) disagreement with the vote. Another, less vocal, fraction of the scientific community backs the resolution, including the discoverer of the dwarf planet Eris, Mike Brown.
A final decision was made, announced 11 June 2008, for acceptance of the term "plutoid" and its official IAU definition:
"Plutoids are celestial bodies in orbit around the Sun at a semimajor axis greater than that of Neptune that have sufficient mass for their self-gravity to overcome rigid body forces so that they assume a hydrostatic equilibrium (near-spherical) shape, and that have not cleared the neighbourhood around their orbit. Satellites of plutoids are not plutoids themselves."
The Commission 46: Education in astronomy.
Commission 46 is a Committee of the Executive Committee of the IAU.
As a prestigious international scientific union, the IAU plays a special
role in the discussion of astronomy development with governments and scientific academies and in interceding about such matters at the highest levels. The IAU is affiliated with the International
Council of Scientific Unions (ICSU), a non-governmental organization representing a global membership
that includes both national scientific bodies and international scientific unions. When
appropriate, the President and officers of the IAU are proactive in persuading the authorities of
the importance of astronomy for development and education and in encouraging countries to
become members of the IAU. A strategic plan for the period 2010-2020 has been published.
The Commission seeks to further the development and improvement of astronomical education at all levels throughout the world, through various projects initiated, maintained, and to be developed by the Commission and by disseminating information concerning astronomy education at all levels.
Part of Commission 46, the Teaching Astronomy for Development (TAD) program is intended to help enhance astronomy education significantly in countries where there is currently very little on offer. TAD operates on the basis of a proposal from a professional astronomy organization or a contract between the IAU and an academic institution, usually a university.
The IAU has launched in 2009 the Galileo Teacher Training Program (GTTP), a Cornerstone project of the International Year of Astronomy 2009, among which Hands-On Universe is a major partner. Hands-On Universe is now officially included in the Astronomy for the Developing World Strategic Plan 2010-20 of IAU, under Section 3.4.2 Astronomy for Children and Schools. During the next decade the IAU will concentrate more resources on education activities for children and schools designed to advance sustainable global development.
The GTTP is concerned with the effective use and transfer of astronomy education tools and resources into classroom science curricula. By training a worldwide network of "Galileo Ambassadors" who will train new "Galileo Teachers" the effect of the program will be multiplied. The GTTP is closely affiliated with the Global Hands-on Universe Program.
Outreach to teachers will involve the provision of training courses, development and translation of materials and harnessing global technological resources in the service of primary and secondary education. A specific goal will be to provide expertise for at least one teacher training course in each region every year, to be organized together with the regional coordinators.
Related programs (leader name): Hands-On Universe (Dr Roger Ferlet), and Universe Awareness (Dr Carolina Ödman).

</doc>
<doc id="14879" url="http://en.wikipedia.org/wiki?curid=14879" title="Interval">
Interval

Interval may refer to:

</doc>
<doc id="14880" url="http://en.wikipedia.org/wiki?curid=14880" title="International Criminal Court">
International Criminal Court

The International Criminal Court (ICC or ICCt) is an intergovernmental organization and international tribunal that sits in The Hague in the Netherlands. The ICC has the jurisdiction to prosecute individuals for the international crimes of genocide, crimes against humanity, and war crimes. The ICC is intended to complement existing national judicial systems and it may therefore only exercise its jurisdiction when certain conditions are met, such as when national courts are unwilling or unable to prosecute criminals or when the United Nations Security Council or individual states refer investigations to the Court. The ICC began functioning on 1 July 2002, the date that the Rome Statute entered into force. The Rome Statute is a multilateral treaty which serves as the ICC's foundational and governing document. States which become party to the Rome Statute, for example by ratifying it, become member states of the ICC. Currently, there are 123 states which are party to the Rome Statute and therefore members of the ICC.
The ICC has four principal organs: the Presidency, the Judicial Divisions, the Office of the Prosecutor, and the Registry. The President is the most senior judge chosen by his or her peers in the Judicial Division, which hears cases before the Court. The Office of the Prosecutor is headed by the Prosecutor who investigates crimes and initiates proceedings before the Judicial Division. The Registry is headed by the Registrar and is charged with managing all the administrative functions of the ICC, including the headquarters, detention union, and public defense office.
The Office of the Prosecutor has opened nine official investigations and is also conducting an additional nine preliminary examinations. Thus far, 36 individuals have been indicted in the ICC, including Ugandan rebel leader Joseph Kony, Sudanese president Omar al-Bashir, Kenyan president Uhuru Kenyatta, Libyan leader Muammar Gaddafi, and Ivorian president Laurent Gbagbo. Since all of the official investigations have been in Africa, the Office of the Prosecutor has been accused of selective enforcement and Western imperialism towards African countries.
History.
The establishment of an international tribunal to judge political leaders accused of international crimes was first proposed during the Paris Peace Conference in 1919 following the First World War by the Commission of Responsibilities. The issue was addressed again at a conference held in Geneva under the auspices of the League of Nations in 1937, which resulted in the conclusion of the first convention stipulating the establishment of a permanent international court to try acts of international terrorism. The convention was signed by 13 states, but none ratified it and the convention never entered into force.
Following the Second World War, the allied powers established two "ad hoc" tribunals to prosecute axis power leaders accused of war crimes. The International Military Tribunal, which sat in Nuremberg, prosecuted German leaders while the International Military Tribunal for the Far East in Tokyo prosecuted Japanese leaders. In 1948 the United Nations General Assembly first recognised the need for a permanent international court to deal with atrocities of the kind prosecuted after the Second World War. At the request of the General Assembly, the International Law Commission (ILC) drafted two statutes by the early 1950s but these were shelved during the Cold War, which made the establishment of an international criminal court politically unrealistic.
Benjamin B. Ferencz, an investigator of Nazi war crimes after the Second World War, and the Chief Prosecutor for the United States Army at the Einsatzgruppen Trial, became a vocal advocate of the establishment of international rule of law and of an international criminal court. In his first book published in 1975, entitled "Defining International Aggression: The Search for World Peace", he advocated for the establishment of such a court.
In June 1989 Prime Minister of Trinidad and Tobago A. N. R. Robinson revived the idea of a permanent international criminal court by proposing the creation of such a court to deal with the illegal drug trade. Following Trinidad and Tobago's proposal, the General Assembly tasked the ILC with once again drafting a statute for a permanent court. While work began on the draft, the United Nations Security Council established two "ad hoc" tribunals in early 1990s. The International Criminal Tribunal for the former Yugoslavia was created in 1993 in response to large-scale atrocities committed by armed forces during Yugoslav Wars and the International Criminal Tribunal for Rwanda was created in 1994 following the Rwandan Genocide. The creation of these tribunals further highlighted the need for a permanent international criminal court.
In 1994, the ILC presented its final draft statute for the International Criminal Court to the General Assembly and recommended that a conference be convened to negotiate a treaty that would serve as the Court's statute. To consider major substantive issues in the draft statute, the General Assembly established the Ad Hoc Committee on the Establishment of an International Criminal Court, which met twice in 1995. After considering the Committee's report, the General Assembly created the Preparatory Committee on the Establishment of the ICC to prepare a consolidated draft text. From 1996 to 1998, six sessions of the Preparatory Committee were held at the United Nations headquarters in New York City, during which NGOs provided input and attended meetings under the umbrella organisation of the Coalition for an ICC (CICC). In January 1998, the Bureau and coordinators of the Preparatory Committee convened for an Inter-Sessional meeting in Zutphen in the Netherlands to technically consolidate and restructure the draft articles into a draft.
Finally the General Assembly convened a conference in Rome in June 1998, with the aim of finalizing the treaty to serve as the Court's statute. On 17 July 1998, the Rome Statute of the International Criminal Court was adopted by a vote of 120 to 7, with 21 countries abstaining. The seven countries that voted against the treaty were China, Iraq, Israel, Libya, Qatar, the United States, and Yemen. Following 60 ratifications, the Rome Statute entered into force on 1 July 2002 and the International Criminal Court was formally established. The first bench of 18 judges was elected by the Assembly of States Parties in February 2003. They were sworn in at the inaugural session of the Court on 11 March 2003.
The Court issued its first arrest warrants on 8 July 2005, and the first pre-trial hearings were held in 2006. The Court issued its first judgment in 2012 when it found Congolese rebel leader Thomas Lubanga Dyilo guilty of war crimes related to using child soldiers.
In 2010 the states parties of the Rome Statute held the first Review Conference of the Rome Statute of the International Criminal Court in Kampala, Uganda. There they adopted, two amendments to the Statute. The second amendment defined the crime of aggression and outlined the procedure by which the ICC could prosecute individuals. However, the conditions outlined in the amendment have not yet been met and the ICC can not yet exercise jurisdiction over crimes of aggression.
Structure.
The ICC is governed by an Assembly of States Parties, which is made up of the states which are party to the Rome Statute The Assembly elects officials of the Court, approves its budget, and adopts amendments to the Rome Statute. The Court itself, however, is composed of four organs: the Presidency, the Judicial Divisions, the Office of the Prosecutor, and the Registry.
State parties.
s of 2015[ [update]], 123 states are parties to the Statute of the Court, including all the countries of South America, nearly all of Europe, most of Oceania and roughly half of Africa. A further 31 countries have signed but not ratified the Rome Statute. The law of treaties obliges these states to refrain from "acts which would defeat the object and purpose" of the treaty until they declare they do not intend to become a party to the treaty. Three signatory states—Israel, Sudan and the United States—have informed the UN Secretary General that they no longer intend to become states parties and, as such, have no legal obligations arising from their former representatives' signature of the Statute. 41 United Nations member states have neither signed nor acceded to the Rome Statute; some of them, including China and India, are critical of the Court. Ukraine, a non-ratifying signatory, has accepted the Court's jurisdiction for a limited period in 2013-2014. 
Assembly of States Parties.
The Court's management oversight and legislative body, the Assembly of States Parties, consists of one representative from each state party. Each state party has one vote and "every effort" has to be made to reach decisions by consensus. If consensus cannot be reached, decisions are made by vote. The Assembly is presided over by a president and two vice-presidents, who are elected by the members to three-year terms.
The Assembly meets in full session once a year in New York or The Hague, and may also hold special sessions where circumstances require. Sessions are open to observer states and non-governmental organizations.
The Assembly elects the judges and prosecutors, decides the Court's budget, adopts important texts (such as the ), and provides management oversight to the other organs of the Court. Article 46 of the Rome Statute allows the Assembly to remove from office a judge or prosecutor who "is found to have committed serious misconduct or a serious breach of his or her duties" or "is unable to exercise the functions required by this Statute".
The states parties cannot interfere with the judicial functions of the Court. Disputes concerning individual cases are settled by the Judicial Divisions.
In 2010, Kampala, Uganda hosted the Assembly's Rome Statute Review Conference.
The Assembly meets every year rotating between New York and The Hague, The Netherlands.
Organs of the Court.
The Court has four organs: the Presidency, the Judicial Division, the Office of the Prosecutor, and the Registry.
Presidency.
The Presidency is responsible for the proper administration of the Court (apart from the Office of the Prosecutor). It comprises the President and the First and Second Vice-Presidents—three judges of the Court who are elected to the Presidency by their fellow judges for a maximum of two three-year terms. The current (and first female) president is Silvia Fernández de Gurmendi, who was elected on 11 March 2015.
Judicial Divisions.
The Judicial Divisions consist of the 18 judges of the Court, organized into three chambers—the Pre-Trial Chamber, Trial Chamber and Appeals Chamber—which carry out the judicial functions of the Court. Judges are elected to the Court by the Assembly of States Parties. They serve nine-year terms and are not generally eligible for re-election. All judges must be nationals of states parties to the Rome Statute, and no two judges may be nationals of the same state. They must be "persons of high moral character, impartiality and integrity who possess the qualifications required in their respective States for appointment to the highest judicial offices".
The Prosecutor or any person being investigated or prosecuted may request the disqualification of a judge from "any case in which his or her impartiality might reasonably be doubted on any ground". Any request for the disqualification of a judge from a particular case is decided by an absolute majority of the other judges. A judge may be removed from office if he or she "is found to have committed serious misconduct or a serious breach of his or her duties" or is unable to exercise his or her functions. The removal of a judge requires both a two-thirds majority of the other judges and a two-thirds majority of the states parties.
Office of the Prosecutor.
The Office of the Prosecutor is responsible for conducting investigations and prosecutions. It is headed by the Chief Prosecutor, who is assisted by one or more Deputy Prosecutors. The Rome Statute provides that the Office of the Prosecutor shall act independently; as such, no member of the Office may seek or act on instructions from any external source, such as states, international organisations, non-governmental organisations or individuals.
The Prosecutor may open an investigation under three circumstances:
Any person being investigated or prosecuted may request the disqualification of a prosecutor from any case "in which their impartiality might reasonably be doubted on any ground". Requests for the disqualification of prosecutors are decided by the Appeals Chamber. A prosecutor may be removed from office by an absolute majority of the states parties if he or she "is found to have committed serious misconduct or a serious breach of his or her duties" or is unable to exercise his or her functions. However, critics of the Court argue that there are "insufficient checks and balances on the authority of the ICC prosecutor and judges" and "insufficient protection against politicized prosecutions or other abuses". Henry Kissinger says the checks and balances are so weak that the prosecutor "has virtually unlimited discretion in practice". Some efforts have been made to hold Kissinger himself responsible for perceived injustices of American foreign policy during his tenure in government.
As of 16 June 2012, the Prosecutor has been Fatou Bensouda of Gambia who had been elected as the new Prosecutor on 12 December 2011. She has been elected for nine years. Her predecessor, Luis Moreno Ocampo of Argentina, had been in office from 2003 to 2012.
Registry.
The Registry is responsible for the non-judicial aspects of the administration and servicing of the Court. This includes, among other things, "the administration of legal aid matters, court management, victims and witnesses matters, defence counsel, detention unit, and the traditional services provided by administrations in international organisations, such as finance, translation, building management, procurement and personnel". The Registry is headed by the Registrar, who is elected by the judges to a five-year term. The current Registrar is Herman von Hebel, who was elected on 8 March 2013.
Headquarters, offices and detention unit.
The official seat of the Court is in The Hague, Netherlands, but its proceedings may take place anywhere.
The Court is currently housed in interim premises on the eastern edge of The Hague. It intends to construct the ICC Permanent Premises in the Alexanderkazerne, to the north of The Hague. The land and financing for the new construction have been provided by the Netherlands, and architects Schmidt Hammer Lassen have been retained to design the project.
The ICC also maintains a liaison office in New York and field offices in places where it conducts its activities. As of 18 October 2007, the Court had field offices in Kampala, Kinshasa, Bunia, Abéché and Bangui.
The ICC's detention centre comprises twelve cells on the premises of the Scheveningen branch of the Haaglanden Penal Institution, The Hague. Suspects held by the International Criminal Tribunal for the former Yugoslavia are held in the same prison and share some facilities, like the fitness room, but have no contact with suspects held by the ICC. The detention unit is close to the ICC's future headquarters in the Alexanderkazerne.
As of July 2012, the detention centre houses one person convicted by the court, Thomas Lubanga, and four suspects: Germain Katanga, Mathieu Ngudjolo Chui, Jean-Pierre Bemba and Laurent Gbagbo. Additionally, former Liberian President Charles Taylor is held there. Taylor was tried under the mandate and auspices of the Special Court for Sierra Leone, but his trial was held at the ICC's facilities in The Hague because of political and security concerns about holding the trial in Freetown. On 26 April 2012, Taylor was convicted on eleven charges.
The ICC does not have its own witness protection program, but rather must rely on national programs to keep witnesses safe.
Jurisdiction and admissibility.
The Rome Statute requires that several criteria exist in a particular case before an individual can be prosecuted by the Court. The Statute contains three jurisdictional requirements and three admissibility requirements. All criteria must be met for a case to proceed.
Jurisdiction.
There are three jurisdictional requirements in the Rome Statute that must be met before a case may begin against an individual. The requirements are (1) subject-matter jurisdiction (what acts constitute crimes), (2) territorial or personal jurisdiction (where the crimes were committed or who committed them), and (3) temporal jurisdiction (when the crimes were committed).
Subject-matter jurisdiction.
The Court's subject-matter jurisdiction is the crimes for which individuals can be prosecuted. Individuals can only be prosecuted for crimes that are listed in the Statute. The primary crimes are listed in article 5 of the Statute and defined in later articles: genocide (defined in article 6), crimes against humanity (defined in article 7), war crimes (defined in article 8), and crimes of aggression (defined in article 8 "bis"). In addition, article 70 defines offences against the administration of justice, which are also crimes for which individuals can be prosecuted.
Genocide.
Article 6 defines the crime of genocide as "acts committed with intent to destroy, in whole or in part, a national, ethnical, racial or religious group". There are five such acts which constitute crimes of genocide under article 6:
The definition of these crimes is identical to those contained within the Convention on the Prevention and Punishment of the Crime of Genocide of 1948.
Crimes against humanity.
Article 7 defines crimes against humanity as acts "committed as part of a widespread or systematic attack directed against any civilian population, with knowledge of the attack". The article lists 16 such as individual crimes:
War crimes.
Article 8 defines war crimes depending on whether an armed conflict is either international (which generally means it is fought between states) or non-international (which generally means that it is fought between non-state actors, such as rebel groups, or between a state and such non-state actors). In total there are 74 war crimes listed in article 8. The most serious crimes, however, are those that constitute either grave breaches of the Geneva Conventions of 1949, which only apply to international conflicts, and serious violations of article 3 common to the Geneva Conventions of 1949, which apply to non-international conflicts.
There are 11 crimes which constitute grave breaches of the Geneva Conventions and which are applicable only to international armed conflicts:
There are seven crimes which constitute serious violations of article 3 common to the Geneva Conventions and which are applicable only to non-international armed conflicts:
Additionally, there are 56 other crimes which defined by article 8: 35 that are apply to international armed conflicts and 21 that apply to non-international armed conflicts. Such crimes include attacking civilians or civilian objects, attacking peacekeepers, causing excessive incidental death or damage, transferring populations into occupied territories, treacherously killing or wounding, denying quarter, pillaging, employing poison, using expanding bullets, rape and other forms of sexual violence, and conscripting or using child soldiers.
Crimes of aggression.
Article 8 "bis" defines crimes of aggression, however the Court is not yet able to prosecute individuals for these crimes. The Statute originally provided that the Court could not exercise its jurisdiction over the crime of aggression until such time as the states parties agreed on a definition of the crime and set out the conditions under which it could be prosecuted. Such an amendment was adopted at the first review conference of the ICC in Kampala, Uganda, in June 2010. However, this amendment specified that the ICC would not be allowed to exercise jurisdiction of the crime of aggression until two further conditions had been satisfied: (1) the amendment has entered into force for 30 states parties and (2) on or after 1 January 2017, the Assembly of States Parties has voted in favor of allowing the Court to exercise jurisdiction.
The Statute, as amended, defines the crime of aggression as "the planning, preparation, initiation or execution, by a person in a position effectively to exercise control over or to direct the political or military action of a State, of an act of aggression which, by its character, gravity and scale, constitutes a manifest violation of the Charter of the United Nations." The Statute defines an "act of aggression" as "the use of armed force by a State against the sovereignty, territorial integrity or political independence of another State, or in any other manner inconsistent with the Charter of the United Nations." The article also contains a list of seven acts of aggression, which are identical to those in United Nations General Assembly Resolution 3314 of 1974 and include the following acts when committed by one state against another state:
Offences against the administration of justice.
Article 70 criminalizes certain intentional acts which interfere with investigations and proceedings before the Court, including giving false testimony, presenting false evidence, corruptly influencing a witness or official of the Court, retaliating against an official of the Court, and soliciting or accepting bribes as an official of the Court.
Territorial or personal jurisdiction.
For an individual to be prosecuted by the Court either territorial jurisdiction or personal jurisdiction must exist. Therefore an individual can only be prosecuted if he or she has either (1) committed a crime within the territorial jurisdiction of the Court or (2) committed a crime while a national of a state that is within the territorial jurisdiction of the Court.
Territorial jurisdiction.
The territorial jurisdiction of the Court includes the territory, registered vessels, and registered aircraft of states which have either (1) become party to the Rome Statute or (2) accepted the Court's jurisdiction by filing a declaration with the Court.
In situations that are referred to the Court by the United Nations Security Council, the territorial jurisdiction is defined by the Security Council, which may be more expansive that the Court's normal territorial jurisdiction. For example, if the Security Council refers a situation that took place in the territory of a state that has both not become party to the Rome Statute and not lodged a declaration with the Court, the Court will still be able to prosecute crimes that occurred within that state.
Personal jurisdiction.
The personal jurisdiction of the Court extends to all natural persons who commit crimes, regardless of where they are located or where the crimes were committed, as long as those individuals are nationals of either (1) states that are party to the Rome Statute or (2) states that have accepted the Court's jurisdiction by filing a declaration with the Court. As with territorial jurisdiction, the personal jurisdiction can be expanded by the Security Council if it refers a situation to the Court.
Temporal jurisdiction.
Temporal jurisdiction is the time period over which the Court can exercise its powers. No statute of limitations applies to any of the crimes defined in the Statute. However, the Court's jurisdiction is not completely retroactive. Individuals can only be prosecuted for crimes that took place on or after 1 July 2002, which is the date that the Rome Statute entered into force. However, if a state became party to the Statute, and therefore a member of the Court, after 1 July 2002, then the Court cannot exercise jurisdiction prior to that date for certain cases. For example, if the Statute entered into force for a state on 1 January 2003, the Court could only exercise temporal jurisdiction over crimes that took place in that state or were committed by a national of that state on or after 1 January 2003.
Admissibility.
To initiate an investigation, the Prosecutor must (1) have a "reasonable basis to believe that a crime within the jurisdiction of the Court has been or is being committed", (2) the investigation would be consistent with the principle of complementarity, and (3) the investigation serves the interests of justice.
Complementarity.
The principle of complementarity means that the Court will only prosecute an individual if states are unwilling or unable to prosecute. Therefore, if legitimate national investigations or proceedings into crimes have taken place or are ongoing, the Court will not initiate proceedings. This principle applies regardless of the outcome of national proceedings. Even if an investigation is closed without any criminal charges being filed or if an accused person is acquitted by a national court, the Court will not prosecute an individual for the crime in question so long as it is satisfied that the national proceedings were legitimate.
Gravity.
The Court will only initiate proceedings if a crime is of "sufficient gravity to justify further action by the Court".
Interests of justice.
The Prosecutor will initiate an investigation unless there are "substantial reasons to believe that an investigation would not serve the interests of justice" when "[t]aking into account the gravity of the crime and the interests of victims". Furthermore, even if an investigation has been initiated and there are substantial facts to warrant a prosecution and no other admissibility issues, the Prosecutor must determine whether a prosecution would serve the interests of justice "taking into account all the circumstances, including the gravity of the crime, the interests of victims and the age or infirmity of the alleged perpetrator, and his or her role in the alleged crime".
Procedure.
Trial.
Trials are conducted under a hybrid common law and civil law judicial system, but it has been argued the procedural orientation and character of the court is still evolving. A majority of the three judges present, as triers of fact, may reach a decision, which must include a full and reasoned statement. Trials are supposed to be public, but proceedings are often closed, and such exceptions to a public trial have not been enumerated in detail. "In camera" proceedings are allowed for protection of witnesses or defendants as well as for confidential or sensitive evidence. Hearsay and other indirect evidence is not generally prohibited, but it has been argued the court is guided by hearsay exceptions which are prominent in common law systems. There is no subpoena or other means to compel witnesses to come before the court, although the court has some power to compel testimony of those who chose to come before it, such as fines.
Rights of the accused.
The Rome Statute provides that all persons are presumed innocent until proven guilty beyond reasonable doubt, and establishes certain rights of the accused and persons during investigations. These include the right to be fully informed of the charges against him or her; the right to have a lawyer appointed, free of charge; the right to a speedy trial; and the right to examine the witnesses against him or her.
To ensure "equality of arms" between defence and prosecution teams, the ICC has established an independent Office of Public Counsel for the Defence (OPCD) to provide logistical support, advice and information to defendants and their counsel. The OPCD also helps to safeguard the rights of the accused during the initial stages of an investigation. However, Thomas Lubanga's defence team say they were given a smaller budget than the Prosecutor and that evidence and witness statements were slow to arrive.
Victim participation and reparations.
One of the great innovations of the Statute of the International Criminal Court and its Rules of Procedure and Evidence is the series of rights granted to victims. For the first time in the history of international criminal justice, victims have the possibility under the Statute to present their views and observations before the Court.
Participation before the Court may occur at various stages of proceedings and may take different forms, although it will be up to the judges to give directions as to the timing and manner of participation.
Participation in the Court's proceedings will in most cases take place through a legal representative and will be conducted "in a manner which is not prejudicial or inconsistent with the rights of the accused and a fair and impartial trial".
The victim-based provisions within the Rome Statute provide victims with the opportunity to have their voices heard and to obtain, where appropriate, some form of reparation for their suffering. It is this balance between retributive and restorative justice that will enable the ICC, not only to bring criminals to justice but also to help the victims themselves obtain justice.
Article 43(6) establishes a Victims and Witnesses Unit to provide "protective measures and security arrangements, counseling and other appropriate assistance for witnesses, victims who appear before the Court, and others who are at risk on account of testimony given by such witnesses." Article 68 sets out procedures for the "Protection of the victims and witnesses and their participation in the proceedings." The Court has also established an Office of Public Counsel for Victims, to provide support and assistance to victims and their legal representatives. Article 79 of the Rome Statute establishes a Trust Fund to make financial reparations to victims and their families.
Co-operation by states not party to Rome Statute.
One of the principles of international law is that a treaty does not create either obligations or rights for third states ("pacta tertiis nec nocent nec prosunt") without their consent, and this is also enshrined in the 1969 Vienna Convention on the Law of Treaties. The co-operation of the non-party states with the ICC is envisioned by the Rome Statute of the International Criminal Court to be of voluntary nature. However, even states that have not acceded to the Rome Statute might still be subjects to an obligation to co-operate with ICC in certain cases. When a case is referred to the ICC by the UN Security Council all UN member states are obliged to co-operate, since its decisions are binding for all of them. Also, there is an obligation to respect and ensure respect for international humanitarian law, which stems from the Geneva Conventions and Additional Protocol I, which reflects the absolute nature of IHL. Although the wording of the Conventions might not be precise as to what steps have to be taken, it has been argued that it at least requires non-party states to make an effort not to block actions of ICC in response to serious violations of those Conventions. In relation to co-operation in investigation and evidence gathering, it is implied from the Rome Statute that the consent of a non-party state is a prerequisite for ICC Prosecutor to conduct an investigation within its territory, and it seems that it is even more necessary for him to observe any reasonable conditions raised by that state, since such restrictions exist for states party to the Statute. Taking into account the experience of the ICTY (which worked with the principle of the primacy, instead of complementarity) in relation to co-operation, some scholars have expressed their pessimism as to the possibility of ICC to obtain co-operation of non-party states. As for the actions that ICC can take towards non-party states that do not co-operate, the Rome Statute stipulates that the Court may inform the Assembly of States Parties or Security Council, when the matter was referred by it, when non-party state refuses to co-operate after it has entered into an "ad hoc" arrangement or an agreement with the Court.
Amnesties and national reconciliation processes.
It is unclear to what extent the ICC is compatible with reconciliation processes that grant amnesty to human rights abusers as part of agreements to end conflict. Article 16 of the Rome Statute allows the Security Council to prevent the Court from investigating or prosecuting a case, and Article 53 allows the Prosecutor the discretion not to initiate an investigation if he or she believes that "an investigation would not serve the interests of justice". Former ICC president Philippe Kirsch has said that "some limited amnesties may be compatible" with a country's obligations genuinely to investigate or prosecute under the Statute.
It is sometimes argued that amnesties are necessary to allow the peaceful transfer of power from abusive regimes. By denying states the right to offer amnesty to human rights abusers, the International Criminal Court may make it more difficult to negotiate an end to conflict and a transition to democracy. For example, the outstanding arrest warrants for four leaders of the Lord's Resistance Army are regarded by some as an obstacle to ending the insurgency in Uganda. Czech politician Marek Benda argues that "the ICC as a deterrent will in our view only mean the worst dictators will try to retain power at all costs". However, the United Nations and the International Committee of the Red Cross maintain that granting amnesty to those accused of war crimes and other serious crimes is a violation of international law.
Finance.
The ICC is financed by contributions from the states parties. The amount payable by each state party is determined using the same method as the United Nations: each state's contribution is based on the country's capacity to pay, which reflects factors such as a national income and population. The maximum amount a single country can pay in any year is limited to 22% of the Court's budget; Japan paid this amount in 2008.
The Court spent €80.5 million in 2007, and the Assembly of States Parties has approved a budget of €90,382,100 for 2008 and €101,229,900 for 2009. As of September 2008, the ICC’s staff consisted of 571 persons from 83 states.
Trial history to date.
To date, the Prosecutor has opened investigations into nine situations: the Democratic Republic of the Congo; Uganda; Central African Republic I and II; Darfur, Sudan; Kenya; Libya; Côte d'Ivoire; and Mali. The Office of the Prosecutor is also conducting preliminary examinations in nine matters in Afghanistan, Colombia, Georgia, Guinea, Honduras, Iraq, Nigeria, Palestine and Ukraine.
The Court's Pre-Trial Chambers have publicly indicted 36 people. The ICC has issued arrest warrants for 28 individuals and summonses to eight others. Eight persons are in detention. Proceedings against 24 are ongoing: ten are at large as fugitives, two are under arrest but not in the Court's custody, nine are in the pre-trial phase, and another three are at trial. Proceedings against 12 have been completed: two have been convicted, one has been acquitted, four have had the charges against them dismissed, two have had the charges against them withdrawn, one has had his case declared inadmissible, and three have died before trial.
As of March 2015, the "Lubanga" and "Katanga-Chui" trials in the situation of the DR Congo were concluded with Mr Lubanga and Mr Katanga convicted and sentenced to 14 and 12 years imprisonment, respectively. Mr Chui was acquitted. The "Bemba" trial regarding the Central African Republic has been closed with the decision pending. A fourth trial, in the "Ruto-Sang" case regarding the situation in Kenya, began in September 2013. The "Banda" trial in the situation of Darfur, Sudan, was scheduled to begin in 2014 but the start date was vacated. In the "Ntaganda" case in the DR Congo situation and in the "Laurent Gbagbo" case in the Côte d'Ivoire situation, trials are to begin in June and July 2015, respectively. The charges in the "Blé Goudé" case were confirmed in December 2014 with the trial to be held before the same Trial Chamber as the "Gbagbo" case. The charges against all five suspects in the "Bemba et al." case were confirmed in November 2014; a Trial Chamber was established. One suspect, Dominic Ongwen, in the "Kony et al." case in the Uganda situation had his initial appearance in January 2015 with the confirmation of charges hearing scheduled for August 2015.
Situations examined.
<br>Key:
      "Official investigation"
      "Authorization to open investigation requested"
      "Preliminary examination ongoing"
      "Preliminary examination closed"
Notes
Notes
Relationships.
United Nations.
Unlike the International Court of Justice, the ICC is legally independent from the United Nations. However, the Rome Statute grants certain powers to the United Nations Security Council, which limits its functional independence. Article 13 allows the Security Council to refer to the Court situations that would not otherwise fall under the Court's jurisdiction (as it did in relation to the situations in Darfur and Libya, which the Court could not otherwise have prosecuted as neither Sudan nor Libya are state parties). Article 16 allows the Security Council to require the Court to defer from investigating a case for a period of 12 months. Such a deferral may be renewed indefinitely by the Security Council. This sort of an arrangement gives the ICC some of the advantages inhering in the organs of the United Nations such as using the enforcement powers of the Security Council but it also creates a risk of being tainted with the political controversies of the Security Council.
The Court cooperates with the UN in many different areas, including the exchange of information and logistical support. The Court reports to the UN each year on its activities, and some meetings of the Assembly of States Parties are held at UN facilities. The relationship between the Court and the UN is governed by a "Relationship Agreement between the International Criminal Court and the United Nations".
Nongovernmental organizations.
During the 1970s and 1980s, international human rights and humanitarian Nongovernmental Organizations (or NGOs) began to proliferate at exponential rates. Concurrently, the quest to find a way to punish international crimes shifted from being the exclusive responsibility of legal experts to being shared with international human rights activism.
NGOs helped birth the ICC through advocacy and championing for the prosecution of perpetrators of crimes against humanity. NGOs closely monitor the organization's declarations and actions, ensuring that the work that is being executed on behalf of the ICC is fulfilling its objectives and responsibilities to civil society. According to Benjamin Schiff, "From the Statute Conference onward, the relationship between the ICC and the NGOs has probably been closer, more consistent, and more vital to the Court than have analogous relations between NGOs and any other international organization."
There are a number of NGOs working on a variety of issues related to the ICC. The NGO Coalition for the International Criminal Court has served as a sort of umbrella for NGOs to coordinate with each other on similar objectives related to the ICC. The CICC has 2,500 member organizations in 150 different countries. The original steering committee included representatives from the World Federalist Movement, the International Commission of Jurists, Amnesty International, the Lawyers Committee for Human Rights, Human Rights Watch, Parliamentarians for Global Action, and No Peace Without Justice. Today, many of the NGOs with which the ICC cooperates are members of the CICC. These organizations come from a range of backgrounds, spanning from major international NGOs such as Human Rights Watch and Amnesty International, to smaller, more local organizations focused on peace and justice missions. Many work closely with states, such as the International Criminal Law Network, founded and predominantly funded by the Hague municipality and the Dutch Ministries of Defense and Foreign Affairs. The CICC also claims organizations that are themselves federations, such as the International Federation of Human Rights Leagues (FIDH).
CICC members ascribe to three principles that permit them to work under the umbrella of the CICC, so long as their objectives match them:
The NGOs that work under the CICC do not normally pursue agendas exclusive to the work of the Court, rather they may work for broader causes, such as general human rights issues, victims' rights, gender rights, rule of law, conflict mediation, and peace. The CICC coordinates their efforts to improve the efficiency of NGOs' contributions to the Court and to pool their influence on major common issues. From the ICC side, it has been useful to have the CICC channel NGO contacts with the Court so that its officials do not have to interact individually with thousands of separate organizations.
NGOs have been crucial to the evolution of the ICC, as they assisted in the creation of the normative climate that urged states to seriously consider the Court's formation. Their legal experts helped shape the Statute, while their lobbying efforts built support for it. They advocate Statute ratification globally and work at expert and political levels within member states for passage of necessary domestic legislation. NGOs are greatly represented at meetings for the Assembly of States Parties and they use the ASP meetings to press for decisions promoting their priorities. Many of these NGOs have reasonable access to important officials at the ICC because of their involvement during the Statute process. They are engaged in monitoring, commenting upon, and assisting in the ICC's activities.
The ICC many time depends on NGOs to interact with local populations. The Registry Public Information Office personnel and Victims Participation and Reparations Section officials hold seminars for local leaders, professionals and the media to spread the word about the Court. These are the kinds of events that are often hosted or organized by local NGOs. Because there can be challenges with determining which of these NGOs are legitimate, CICC regional representatives often have the ability to help screen and identify trustworthy organizations.
However, NGOs are also "sources of criticism, exhortation and pressure upon" the ICC. The ICC heavily depends on NGOs for its operations. Although NGOs and states cannot directly impact the judicial nucleus of the organization, they can impart information on crimes, can help locate victims and witnesses, and can promote and organize victim participation. NGOs outwardly comment on the Court's operations, "push for expansion of its activities especially in the new justice areas of outreach in conflict areas, in victims' participation and reparations, and in upholding due-process standards and defense 'equality of arms' and so implicitly set an agenda for the future evolution of the ICC." The relatively uninterrupted progression of NGO involvement with the ICC may mean that NGOs have become repositories of more institutional historical knowledge about the ICC than have national representatives to it and have greater expertise than some of the organization's employees themselves. While NGOs look to mold the ICC to satisfy the interests and priorities that they have worked for since the early 1990s, they unavoidably press against the limits imposed upon the ICC by the states that are members of the organization. NGOs can pursue their own mandates, irrespective of whether they are compatible with those of other NGOs, while the ICC must respond to the complexities of its own mandate as well as those of the states and NGOs.
Another issue has been that NGOs possess "exaggerated senses of their ownership over the organization and, having been vital to and successful in promoting the Court, were not managing to redefine their roles to permit the Court its necessary independence." Additionally, because there does exist such a gap between the large human rights organizations and the smaller peace-oriented organizations, it is difficult for ICC officials to manage and gratify all of their NGOs. "ICC officials recognize that the NGOs pursue their own agendas, and that they will seek to pressure the ICC in the direction of their own priorities rather than necessarily understanding or being fully sympathetic to the myriad constraints and pressures under which the Court operates." Both the ICC and the NGO community avoid criticizing each other publicly or vehemently, although NGOs have released advisory and cautionary messages regarding the ICC. They avoid taking stances that could potentially give the Court's adversaries, particularly the US, more motive to berate the organization.
Criticisms.
Western Imperialism accusations.
The ICC has been accused of bias and as being a tool of Western imperialism, only punishing leaders from small, weak states while ignoring crimes committed by richer and more powerful states. This sentiment has been expressed particularly by African leaders due to an alleged disproportionate focus of the Court on Africa, while it claims to have a global mandate; to date, all eight situations which the ICC has investigated are in African countries.
The prosecution of Kenyan Deputy President William Ruto and President Uhuru Kenyatta (charged before becoming president) led to the Kenyan parliament passing a motion calling for Kenya's withdrawal from the ICC, and the country has called on the other 34 African states party to the ICC to withdraw their support, an issue which was discussed at a special African Union summit in October 2013.
Though the ICC has denied the charge of disproportionately targeting African leaders, and claims to stand up for victims wherever they may be, Kenya was not alone in criticising the ICC. Sudanese President Omar al-Bashir visited Kenya despite an outstanding ICC warrant for his arrest but was not arrested; he said that the charges against him are "exaggerated" and that the ICC was a part of a "western plot" against him. Ivory Coast’s government opted not to transfer former first lady Simone Gbagbo to the court but to instead try her at home. Rwanda’s ambassador to the African Union, Joseph Nsengimana, argued that "It is not only the case of Kenya. We have seen international justice become more and more a political matter." Ugandan President Yoweri Museveni accused the ICC of "mishandling complex African issues." Ethiopian Prime Minister Hailemariam Desalegn, the AU chairman, told the UN General Assembly at the General debate of the sixty-eighth session of the United Nations General Assembly: "The manner in which the ICC has been operating has left a very bad impression in Africa. It is totally unacceptable."
AU withdrawal proposal.
South African President Jacob Zuma said the perceptions of the ICC as "unreasonable" led to the calling of the special AU summit on 13 October. Botswana is a notable supporter of the ICC in Africa. At the summit, the AU did not endorse the proposal for a mass withdrawal from the ICC due to lack of support for the idea. However, the summit did conclude that serving heads of state should not be put on trial and that the Kenyan cases should be deferred. Ethiopian Foreign Minister Tedros Adhanom said: "We have rejected the double standard that the ICC is applying in dispensing international justice." Despite these calls, the ICC went ahead with requiring William Ruto to attend his trial. The UNSC was then asked to consider deferring the trials of Kenyatta and Ruto for a year, but this was rejected. In November, the ICC's Assembly of State Parties responded to Kenya's calls for an exemption for sitting heads of state by agreeing to consider amendments to the Rome Statute to address the concerns.
Checks and balances.
Critics of the Court argue that there are "insufficient checks and balances on the authority of the ICC prosecutor and judges" and "insufficient protection against politicized prosecutions or other abuses".
Concerning the independent Office of Public Counsel for the Defence (OPCD), Thomas Lubanga's defence team say they were given a smaller budget than the Prosecutor and that evidence and witness statements were slow to arrive.
Rights of the accused.
Among those who argue that the protections offered by the ICC are insufficient is the Heritage Foundation, an American conservative think tank based in Washington DC which stated in 2001 that "Americans who appear before the court would be denied such basic U.S. constitutional rights as trial by a jury of one's peers, protection from double jeopardy, and the right to confront one's accusers." It should be noted, however, that US citizens do not always have a right to a jury trial. In common with the practice of most nation states, American service personnel, for example, tried by courts martial do not have a right to a jury trial in the usual sense nor are the panel members necessarily their peers. By contrast Human Rights Watch writes "the ICC has one of the most extensive lists of due process guarantees ever written", including "presumption of innocence; right to counsel; right to present evidence and to confront witnesses; right to remain silent; right to be present at trial; right to have charges proved beyond a reasonable doubt; and protection against double jeopardy". Although the United States actually voted against adoption of the Rome treaty, David Scheffer, who led the US delegation to the Rome Conference maintained "when we were negotiating the Rome treaty, we always kept very close tabs on, 'Does this meet U.S. constitutional tests, the formation of this court and the due process rights that are accorded defendants?' And we were very confident at the end of Rome that those due process rights, in fact, are protected, and that this treaty does meet a constitutional test."
In some common law systems, such as the United States, the right to confront one's accusers is traditionally seen as negatively affected by the lack of an ability to compel witnesses and the admission of hearsay evidence, which along with other indirect evidence is not generally prohibited.
Limitations.
Limitations exist for the ICC. The Human Rights Watch (HRW) reported that the ICC's prosecutor team takes no account of the roles played by the government in the conflict of Uganda, Rwanda or Congo. This led to a flawed investigation, because the ICC did not reach the conclusion of its verdict after considering the governments’ position and actions in the conflict.

</doc>
<doc id="14881" url="http://en.wikipedia.org/wiki?curid=14881" title="ICC">
ICC

ICC may refer to:

</doc>
<doc id="14882" url="http://en.wikipedia.org/wiki?curid=14882" title="Incubus (disambiguation)">
Incubus (disambiguation)

An incubus is a male demon that has sexual intercourse with sleeping women.
Incubus may also refer to:

</doc>
<doc id="14883" url="http://en.wikipedia.org/wiki?curid=14883" title="Iberian Peninsula">
Iberian Peninsula

The Iberian Peninsula (Asturian, Galician, Leonese, Mirandese, Portuguese, Spanish: "Península ibérica"; Catalan: "Península Ibèrica"; Aragonese, Occitan: "Peninsula Iberica"; French: "Péninsule Ibérique"; Basque: "Iberiar Penintsula"), commonly called Iberia , is the third-largest European peninsula (after the Scandinavian and Balkan peninsulas); it is located in the extreme southwest of the continent. The area is approximately 582000 km2. There are three countries in it: Spain, Portugal, and Andorra, as well as a part of France and the British Overseas Territory of Gibraltar.
Geography.
The Iberian Peninsula is the westernmost of the three major southern European peninsulas—the Iberian, Italian, and Balkan. It is bordered on the southeast and east by the Mediterranean Sea, and on the north, west, and southwest by the Atlantic Ocean. The Pyrenees mountains form the northeast edge of the peninsula, separating it from the rest of Europe. Its southern tip is very close to the northwest coast of Africa, separated from it by the Strait of Gibraltar.
Name.
Greek name.
The English word "Iberia" was adapted from the use of the Ancient Greek word Ιβηρία (Ibēría) by Greek geographers under the rule of the Roman Empire to refer to what is known today in English as the Iberian Peninsula. At that time, the name did not describe a single political entity or a distinct population of people. Strabo's "Iberia" was delineated from Keltikē (Gaul) by the Pyrenees and included the entire land mass southwest (he says "west") of there.
The ancient Greeks discovered the Iberian Peninsula by voyaging westward. Hecataeus of Miletus was the first known to use the term around 500 BC. Herodotus of Halicarnassus says of the Phocaeans that "it was they who made the Greeks acquainted with ... Iberia." According to Strabo, prior historians used "Iberia" to mean the country "this side of the Ἶβηρος (Ibēros)" as far north as the river Rhône in France, but currently they set the Pyrenees as the limit. Polybius respects that limit, but identifies Iberia as the Mediterranean side as far south as Gibraltar, with the Atlantic side having no name. Elsewhere he says that Saguntum is "on the seaward foot of the range of hills connecting Iberia and Celtiberia."
Strabo refers to the Carretanians as people "of the Iberian stock" living in the Pyrenees, who are to be distinguished from either Celts or Celtiberians.
Roman names.
According to Charles Ebel, the ancient sources in both Latin and Greek use Hispania and Hiberia (Greek: Iberia) as synonyms. The confusion of the words was because of an overlapping in political and geographic perspectives. The Latin word "Hiberia", similar to the Greek "Iberia", literally translates to "land of the Hiberians". This word was derived from the river Ebron, which the Romans called "Hiberus". "Hiber" (Iberian) was thus used as a term for peoples living near the river Ebron. The first mention in Roman literature was by the annalist poet Quintus Ennius in 200 BC. The Romans had broad experience with the peoples on the peninsula acquired during the long conflict with Carthage. Virgil refers to the "Ipacatos Hiberos" ("restless Iberi") in his Georgics. The Roman geographers and other prose writers from the time of the late Roman Republic called the entire peninsula "Hispania".
As they became politically interested in the former Carthaginian territories, the Romans began to use the names "Hispania Citerior" and "Hispania Ulterior" for 'near' and 'far' Hispania. At the time Hispania was made up of three Roman provinces: Hispania Baetica (Southern Spain), Hispania Tarraconensis (Northern Spain), and Hispania Lusitania (Southern, most of modern Portugal). Strabo says that the Romans use "Hispania" and "Iberia" synonymously, distinguishing between the "near" northern and the "far" southern provinces. Whatever language may generally have been spoken on the peninsula soon gave way to Latin, except for that of the Vascones, which was preserved as a language isolate by the barrier of the Pyrenees.
Etymology.
The Iberian Peninsula has always been associated with the Ebro River, Ibēros in ancient Greek and Ibērus or Hibērus in Latin. The association was so well known it was hardly necessary to state; for example, Ibēria was the country "this side of the Ibērus" in Strabo. Pliny goes so far as to assert that the Greeks had called "the whole of Spain" Hiberia because of the Hiberus River. The river appears in the Ebro Treaty of 226 BC between Rome and Carthage, setting the limit of Carthaginian interest at the Ebro. The fullest description of the treaty, stated in Appian, uses Ibērus. With reference to this border, Polybius states that the "native name" is "Ibēr", apparently the original word, stripped of its Greek or Latin "-os" or "-us" termination.
The early range of these natives, stated by the geographers and historians to be from southern Spain to southern France along the Mediterranean coast, is marked by instances of a readable script expressing a yet unknown language, dubbed "Iberian." Whether this was the native name or was given to them by the Greeks for their residence on the Ebro remains unknown. Credence in Polybius imposes certain limitations on etymologizing: if the language remains unknown, the meanings of the words, including Iber, must also remain unknown. In modern Basque, the word "ibar" means "valley" or "watered meadow", while "ibai" means "river", but there is no proof relating the etymology of the Ebro River with these Basque names.
Prehistory.
Palaeolithic.
The Iberian Peninsula has been inhabited for at least 1,000,000 years as remains found in the sites at Atapuerca demonstrate. Among these sites is the cave of Gran Dolina, where six hominin skeletons, dated between 780,000 and one million years ago, were found in 1994. Experts have debated whether these skeletons belong to the species "Homo erectus", "Homo heidelbergensis", or a new species called "Homo antecessor".
Around 200,000 BC, during the Lower Paleolithic period, Neanderthals first entered the Iberian Peninsula. Around 70,000 BC, during the Middle Paleolithic period, the last glacial event began and the Neanderthal Mousterian culture was established. Around 35,000 BC, during the Upper Paleolithic, the Neanderthal Châtelperronian cultural period began. Emanating from Southern France, this culture extended into the north of the peninsula. It continued to exist until around 28,000 BC, when Neanderthal man faced extinction.
At about the 40th millennium BC, modern humans entered the Iberian Peninsula from Southern France. Here, this genetically homogeneous population (characterized by the M173 mutation in the Y-chromosome), developed the M343 mutation, giving rise to the R1b Haplogroup, still the most common in modern Portuguese and Spanish males. On the Iberian Peninsula, modern humans developed a series of different cultures, such as the Aurignacian, Gravettian, Solutrean and Magdalenian cultures, some of them characterized by complex forms of Paleolithic art.
Neolithic.
During the Neolithic expansion, various megalithic cultures developed in the Iberian Peninsula. An open seas navigation culture from the east Mediterranean, called the Cardium culture, also extended its influence to the eastern coasts of the peninsula, possibly as early as the 5th millennium BC. These people may have had some relation to the subsequent development of the Iberian civilization.
Chalcolithic.
In the Chalcolithic or Copper Age (c. 3000 BC), a series of complex cultures developed that would give rise to the peninsula's first civilizations and to extensive exchange networks reaching to the Baltic, Middle East and North Africa. Around 2800 – 2700 BC, the Bell Beaker culture, which produced the "Maritime Bell Beaker", probably originated in the vibrant copper-using communities of the Tagus estuary in Portugal and spread from there to many parts of western Europe.
Bronze Age.
Bronze Age cultures developed beginning c.1800 BC, when the civilization of Los Millares was followed by that of El Argar. From this centre, bronze technology spread to other areas, such as those of the Bronze of Levante, South-Western Iberian Bronze and Cogotas I.
In the Late Bronze Age, the urban civilisation of Tartessos developed in the area of modern western Andalusia, characterized by Phoenician influence and using the Tartessian script for its Tartessian language, not related to the Iberian language.
Some scholars believe that early in the first millennium BC, several waves of Pre-Celts and Celts migrated from Central Europe, thus partially changing the peninsula's ethnic landscape to Indo-European in its northern and western regions. In Northwestern Iberia (Northern Portugal, Asturias and Galicia), a Celtic culture developed, the Castro culture, with a large number of hill forts and some fortified cities.
Proto-history.
By the Iron Age, starting in the 7th century BC, the Iberian Peninsula consisted of complex agrarian and urban civilizations, either Pre-Celtic or Celtic (such as the Lusitanians, Celtiberians, Gallaeci, Astur, Celtici and others), the cultures of the Iberians in the eastern and southern zones and the cultures of the Aquitanian in the western portion of the Pyrenees.
The seafaring Phoenicians, Greeks and Carthaginians successively settled along the Mediterranean coast and founded trading colonies there over a period of several centuries. Around 1100 BC, Phoenician merchants founded the trading colony of Gadir or Gades (modern day Cádiz) near Tartessos. In the 8th century BC, the first Greek colonies, such as Emporion (modern Empúries), were founded along the Mediterranean coast on the east, leaving the south coast to the Phoenicians. The Greeks coined the name Iberia, after the river Iber (Ebro). In the 6th century BC, the Carthaginians arrived in the peninsula while struggling with the Greeks for control of the Western Mediterranean. Their most important colony was Carthago Nova (Latin name of modern day Cartagena).
History.
Roman rule.
In 218 B.C., during the Second Punic war against the Carthaginians, the first Roman troops invaded the Iberian Peninsula and annexed it under Augustus after two centuries of war with the Celtic and Iberian tribes and the Phoenician, Greek and Carthaginian colonies, resulting in the creation of the province of Hispania. It was divided into Hispania Ulterior and Hispania Citerior during the late Roman Republic, and during the Roman Empire, it was divided into Hispania Taraconensis in the northeast, Hispania Baetica in the south and Lusitania in the southwest.
Hispania supplied the Roman Empire with food, olive oil, wine, and metal. The emperors Trajan, Hadrian, and Theodosius I, the philosopher Seneca, and the poets Martial and Lucan were born from families living on the peninsula.
Germanic kingdoms.
In the early 5th century, Germanic tribes invaded the peninsula, namely the Suebi, the Vandals (Silingi and Hasdingi) and their allies, the Sarmatian Alans. Only the kingdom of the Suebi (Quadi and Marcomanni) would endure after the arrival of another wave of Germanic invaders, the Visigoths, who conquered all of the Iberian Peninsula and expelled or partially integrated the Vandals and the Alans. The Visigoths eventually conquered the Suebi kingdom and its capital city Bracara (modern day Braga) in 584–585. They would also conquer the province of the Byzantine Empire (552–624) of Spania in the south of the peninsula and the Balearic Islands.
Islamic rule.
In AD 711, a Muslim army invaded the Visigothic Kingdom in Hispania. Under Tariq ibn-Ziyad, the Islamic army landed at Gibraltar and brought most of the Iberian Peninsula under Islamic control in an eight-year campaign. Al-ʾAndalūs (Arabic الإندلس : possibly "Land of the Vandals"), is the Arabic name given the Iberian Peninsula by its Muslim Berber and Arab conquerors.
From the 8th–15th centuries, the Iberian Peninsula was incorporated into the Islamic world and became a center of culture and learning, especially during the Caliphate of Cordoba, which reached its height under the rule of Abd ar-Rahman III. The Muslims, which were initially Arabs and Berbers, included local Iberian converts, the so-called Muladi, who formed the majority of the Iberian population by the year 1100. The Muslims were referred to by the generic name, "Moors". Thus, before the so-called Reconquista gained momentum, the Iberian Peninsula had been transformed from a mainly Romance-speaking Christian land into a mainly Arabic-speaking Muslim land. However, pockets of Arabic and Romance-speaking Christians called Mozarabs survived throughout al-Andalus, in addition to a large minority of Arabic-speaking Jews.
Reconquest.
Many of the ousted Gothic nobles took refuge in the unconquered north Asturian highlands. From there, they aimed to reconquer their lands from the Moors; this war of reconquest is known as the Reconquista. Christian and Muslim kingdoms fought and allied among themselves. The Muslim taifa kings competed in patronage of the arts, the Way of Saint James attracted pilgrims from all Western Europe, and the Jewish population set the basis of Sephardic culture.
During the Middle Ages, the peninsula housed many small states including Castile, Aragon, Navarre, León and Portugal. The peninsula was part of the Islamic Almohad empire until they were finally uprooted. The last major Muslim stronghold was Granada, which was conquered by a combined Castilian and Aragonese force in 1492. Muslims and Jews throughout the period were variously tolerated or shown intolerance in different Christian kingdoms. However, after the conquest of Granada, all Muslims and Jews were ordered to convert to Christianity or face expulsion. Many Jews and Muslims fled to North Africa and the Ottoman Empire, while others publicly converted to Christianity and became known respectively as Marranos and Moriscos. However, many of these continued to practice their religion in secret. The Moriscos revolted several times and were ultimately forcibly expelled from Spain in the early 17th century.
Post-reconquest.
The small states gradually amalgamated over time, with the exception of Portugal, even if for a brief period (1580–1640) the whole peninsula was united politically under the Iberian Union. After that point, the modern position was reached and the peninsula now consists of the countries of Spain and Portugal (excluding their islands—the Portuguese Azores and Madeira Islands and the Spanish Canary Islands and Balearic Islands; and the Spanish exclaves of Ceuta and Melilla), Andorra, French Cerdagne and Gibraltar.
Geography and geology.
Overall characteristics.
The Iberian Peninsula extends from the southernmost extremity at Punta de Tarifa () to the northernmost extremity at Estaca de Bares Point () over a distance between lines of latitude of about 865 km based on a degree length of 111 km per degree, and from the westernmost extremity at Cabo da Roca () to the easternmost extremity at Cap de Creus () over a distance between lines of longitude at 40° N latitude of about 1155 km based on an estimated degree length of about 90 km for that latitude. The irregular, roughly octagonal shape of the peninsula contained within this spherical quadrangle was compared to an ox-hide by the geographer Strabo.
About three quarters of that rough octagon is the Meseta Central, a vast plateau ranging from 610 to 760 m in altitude. It is located approximately in the centre, staggered slightly to the east and tilted slightly toward the west (the conventional centre of the Iberian Peninsula has long been considered to be Getafe just south of Madrid). It is ringed by mountains and contains the sources of most of the rivers, which find their way through gaps in the mountain barriers on all sides.
Coastline.
The coastline of the Iberian Peninsula is 3313 km, 1660 km on the Mediterranean side and 1653 km on the Atlantic side. The coast has been inundated over time, with sea levels having risen from a minimum of 115 - lower than today at the Last Glacial Maximum (LGM) to its current level at 4,000 years BP. The coastal shelf created by sedimentation during that time remains below the surface; however, it was never very extensive on the Atlantic side, as the continental shelf drops rather steeply into the depths. An estimated 700 km length of Atlantic shelf is only 10 - wide. At the 500 m isobath, on the edge, the shelf drops off to 1000 m.
The submarine topography of the coastal waters of the Iberian Peninsula has been studied extensively in the process of drilling for oil. Ultimately, the shelf drops into the Bay of Biscay on the north (an abyss), the Iberian abyssal plain at 4800 m on the west and Tagus abyssal plain to the south. In the north, between the continental shelf and the abyss, is an extension, the Galicia Bank, a plateau also containing the Porto, Vigo and Vasco da Gama seamounts, creating the Galicia interior basin. The southern border of these features is marked by Nazaré Canyon, splitting the continental shelf and leading directly into the abyss.
Rivers.
The major rivers flow through the wide valleys between the mountain systems. These are the Ebro, Douro, Tagus, Guadiana and Guadalquivir. All rivers in the Iberian Peninsula are subject to seasonal variations in flow.
The Tagus is the longest river in the peninsula and, like the Douro, flows westwards with its lower course in Portugal.
The Guadiana bends southwards and forms the border between Spain and Portugal in the last stretch of its course.
Mountains.
The terrain of the Iberian Peninsula is largely mountainous. The major mountain systems are:
Geology.
The Iberian Peninsula contains rocks of every geological period from the Ediacaran to the Recent, and almost every kind of rock is represented. World-class mineral deposits can also be found there. The core of the Iberian Peninsula consists of a Hercynian cratonic block known as the Iberian Massif. On the northeast, this is bounded by the Pyrenean fold belt, and on the southeast it is bounded by the Betic Foldchain. These twofold chains are part of the Alpine belt. To the west, the peninsula is delimited by the continental boundary formed by the magma-poor opening of the Atlantic Ocean. The Hercynian Foldbelt is mostly buried by Mesozoic and Tertiary cover rocks to the east, but nevertheless outcrops through the Iberian Chain and the Catalan Coastal Ranges.
Climate.
The Iberian peninsula has two dominant climate types. One of these is the oceanic climate seen in the Atlantic coastal region resulting in evenly temperatures with relatively cool summers. However, pretty much all of Portugal and most of Spain have mediterranean climates with various precipitation and temperatures depending on latitude and position versus the sea. There are also more localized semi-arid climates in central Spain, with temperatures resembling a more continental mediterranean climate. In other extreme cases highland alpine climates such as in Sierra Nevada and areas with extremely low precitipation such as the Almería area can be found. In the Spanish interior the hottest temperatures in Europe are found, with Córdoba averaging around 37 C in July. The Spanish mediterranean coast usually averages around 30 C in summer. In sharp contrast A Coruña at the northern tip of Galicia has a summer daytime high average at just below 23 C. This cool and wet summer climate is replicated throughout most of the northern coastline. Winter temperatures are more consistent throughout the peninsula, although frosts are common in the Spanish interior, even though daytime highs are usually some way above the freezing point.
Modern countries and territories.
Political divisions of the Iberian Peninsula sorted by area:
Urbanization.
Major cities.
Various other notable cities are also present on the peninsula, like Elche (230,354), Oviedo (225,973), Badalona (220,977) and Terrassa (215 678) in Spain; and Braga (181,874), Amadora (175,558), Coimbra (102,455) and Setúbal (90,640) in Portugal.
Major metropolitan areas.
The main metropolitan areas of the Iberian Peninsula are Madrid, Barcelona, Lisbon, Valencia, Porto, Seville, Bilbao, Málaga, Central Asturias (Gijón-Oviedo-Avilés), Alicante-Elche, Murcia, Braga and Coimbra
Ecology.
Forests.
The woodlands of the Iberian Peninsula are distinct ecosystems. Although the various regions are each characterized by distinct vegetation, there are some similarities across the peninsula.
While the borders between these regions are not clearly defined, there is a mutual influence that makes it very hard to establish boundaries and some species find their optimal habitat in the intermediate areas.
East Atlantic flyway.
The Iberian Peninsula in an important stopover on the East Atlantic flyway for birds migrating from northern Europe to Africa. For example, curlew sandpipers rest in the region of the Bay of Cádiz.
In addition to the birds migrating through, some seven million wading birds from the north spend the winter in the estuaries and wetlands of the Iberian Peninsula, mainly at locations on the Atlantic coast. In Galicia are Ria de Arousa (a home of grey plover), Ria de Ortigueira, Ria de Corme and Ria de Laxe. In Portugal, the Aveiro Lagoon hosts "Recurvirostra avosetta", ringed plover, grey plover and little stint. Ribatejo Province on the Tagus River supports "Recurvirostra arosetta", grey plover, dunlin, bar-tailed godwit and common redshank. In the Sado Estuary are dunlin, Eurasian curlew, grey plover and common redshank. The Algarve hosts red knot, greenshank and turnstone. The Marismas de Guadalquivir region of Andalusia and the Salinas de Cádiz are especially rich in wintering wading birds: Kentish plover, ringed plover, sanderling, and black-tailed godwit in addition to the others. And finally, the Ebro delta is home to all the species mentioned above.
Languages.
Except for Basque, which is of unknown origin, most modern Iberian languages descend from Vulgar Latin. Throughout history (and pre-history), many different languages have been spoken in the Iberian Peninsula, contributing to the formation and differentiation of the contemporaneous languages of Iberia; however, most of them have become extinct or fallen into disuse. Basque is the only non-Indo-European surviving language in Iberia and Western Europe.
In modern times, Spanish (cf. 30 to 40 million speakers), Portuguese (cf. around 10 million speakers), Catalan (cf. around 9 million speakers), Galician (cf. around 3 million speakers) and Basque (cf. around 720,000 speakers) are the most widely spoken languages in the Iberian Peninsula. Spanish and Portuguese have expanded beyond Iberia to the rest of world, becoming global languages.

</doc>
