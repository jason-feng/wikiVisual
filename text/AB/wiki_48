<doc id="19457" url="http://en.wikipedia.org/wiki?curid=19457" title="Burma">
Burma

Burma ( ), officially the Republic of the Union of Myanmar and commonly shortened to Myanmar ( , or , ]), is a sovereign state in Southeast Asia bordered by Bangladesh, India, China, Laos and Thailand. One-third of Burma's total perimeter of 1,930 km (1,200 miles) forms an uninterrupted coastline along the Bay of Bengal and the Andaman Sea. Burma has a population of 51 million people. Burma is 676,578 square kilometres (261,227 sq mi) in size. Burma's capital city is Naypyidaw and its largest city is Yangon.
Early civilizations in Burma included the Tibeto-Burman-speaking Pyu in Upper Burma and the Mon in Lower Burma. In the 9th century, the Burmans of the Kingdom of Nanzhao entered the upper Irrawaddy valley and, following the establishment of the Pagan Empire in the 1050s, the Burmese language, culture and Theravada Buddhism slowly became dominant in the country. The Pagan Empire fell due to the Mongol invasions and several warring states emerged. In the 16th century, reunified by the Taungoo Dynasty, the country was for a brief period the largest empire in the history of Southeast Asia. The early 19th century Konbaung Dynasty ruled over an area that included modern Burma and briefly controlled Manipur and Assam as well. While Burma is regarded as a Buddhist nation, many religions have peacefully co-existed throughout the centuries. The British conquered Burma after three Anglo-Burmese Wars in the 19th century and the country became a British colony. Burma became an independent nation in 1948, initially as a democratic nation and then, following a coup in 1962, a military dictatorship. While the military dictatorship formally ended in 2011, most of the party leaders are former military officers. 
For most of its independent years, the country has been engrossed in rampant ethnic strife and a myriad of Burma's ethnic groups have been involved in one of the world's longest-running ongoing civil wars. During this time, the United Nations and several other organisations have reported consistent and systematic human rights violations in the country. In 2011, the military junta was officially dissolved following a 2010 general election, and a nominally civilian government was installed. While former military leaders still yield enormous power in the country, Burmese Military have taken steps toward relinquishing control of the government. This, along with the release of Aung San Suu Kyi and political prisoners, has improved the country's human rights record and foreign relations, and has led to the easing of trade and other economic sanctions. There is, however, continuing criticism of the government's treatment of the Muslim Rohingya minority and its poor response to the religious clashes.
Burma is a country rich in jade and gems, oil, natural gas and other mineral resources. In 2013, its GDP (nominal) stood at US$56.7 billion and its GDP (PPP) at US$221.5 billion. The income gap in Myanmar is among the widest in the world, as a large proportion of the economy is controlled by supporters of the former military government. As of 2013, according to the Human Development Index (HDI), Burma had a low level of human development, ranking 150 out of 187 countries.
Etymology.
In 1989, the military government officially changed the English translations of many names dating back to Burma's colonial period or earlier, including that of the country itself: "Burma" became "Myanmar". The renaming remains a contested issue. Many political and ethnic opposition groups and countries continue to use "Burma" because they do not recognise the legitimacy of the ruling military government or its authority to rename the country.
The country's official full name is the "Republic of the Union of Myanmar" (ပြည်ထောင်စု သမ္မတ မြန်မာနိုင်ငံတော်, "Pyidaunzu Thanmăda Myăma Nainngandaw", ]). Some countries, however, have not recognised this name and use the short form "Union of Burma" instead.
In English, the country is popularly known as either "Burma" or "Myanmar" . Both these names are derived from the name of the majority Burmese Bamar ethnic group. "Myanmar" is considered to be the literary form of the name of the group, while "Burma" is derived from "Bamar", the colloquial form of the group's name. Depending on the register used, the pronunciation would be "Bama" (]) or "Myamah" (]). The name "Burma" has been in use in English since the 18th century.
"Burma" continues to be used in English by the governments of many countries, including the United Kingdom and Canada. Official United States policy retains Burma as the country's name, although the State Department's website lists the country as "Burma (Myanmar)" and Barack Obama has referred to the country as "Myanmar". The United Nations uses "Myanmar", as do the Association of Southeast Asian Nations, Russia, Germany, China, India, Norway, and Japan.
Most English-speaking international news media officially refer to the country by the name "Myanmar", including the BBC, CNN, Al Jazeera, Reuters, and Russia Today.
Burma is known as "Birmania" in Spanish, Italian and Romanian, as "Birmânia" in Portuguese, and as "Birmanie" in French. The Government of Brazil uses "Mianmar".
History.
Prehistory.
Archaeological evidence shows that "Homo erectus" lived in the region now known as Burma as early as 400,000 years ago. The first evidence of "Homo sapiens" is dated to about 11,000 BC, in a Stone Age culture called the "Anyathian" with discoveries of stone tools in central Burma. Evidence of neolithic age domestication of plants and animals and the use of polished stone tools dating to sometime between 10,000 and 6,000 BC has been discovered in the form of cave paintings near the city of Taunggyi.
The Bronze Age arrived circa 1500 BC when people in the region were turning copper into bronze, growing rice and domesticating poultry and pigs; they were among the first people in the world to do so. The Iron Age began around 500 BC with the emergence of iron-working settlements in an area south of present-day Mandalay. Evidence also shows the presence of rice-growing settlements of large villages and small towns that traded with their surroundings as far as China between 500 BC and 200 AD. Iron Age Burmese cultures also had influences from outside sources such as India and Thailand, as seen in their funerary practices concerning child burials. This indicates some form of communication between groups in Burma and other places, possibly through trade.
Around the 2nd century BC the first-known city-states emerged in central Burma. The city-states were founded as part of the southward migration by the Tibeto-Burman-speaking Pyu, the earliest inhabitants of Burma of whom records are extant, from present-day Yunnan. The Pyu culture was heavily influenced by trade with India, importing Buddhism as well as other cultural, architectural and political concepts which would have an enduring influence on later Burmese culture and political organisation.
By the 9th century AD several city-states had sprouted across the land: the Pyu states in the central dry zone, Mon states along the southern coastline and Arakanese states along the western littoral. The balance was upset when the Pyu states came under repeated attacks from the Kingdom of Nanzhao between the 750s and the 830s. In the mid-to-late 9th century the Mranma (Burmans/Bamar) of Nanzhao founded a small settlement at Pagan (Bagan). It was one of several competing city-states until the late 10th century when it grew in authority and grandeur.
Imperial Burma.
Pagan gradually grew to absorb its surrounding states until the 1050s–1060s when Anawrahta founded the Pagan Empire, the first ever unification of the Irrawaddy valley and its periphery. In the 12th and 13th centuries, the Pagan Empire and the Khmer Empire were two main powers in mainland Southeast Asia. The Burmese language and culture gradually became dominant in the upper Irrawaddy valley, eclipsing the Pyu, Mon and Pali norms by the late 12th century.
Theravada Buddhism slowly began to spread to the village level although Tantric, Mahayana, Brahmanic, and animist practices remained heavily entrenched. Pagan's rulers and wealthy built over 10,000 Buddhist temples in the Pagan capital zone alone. Repeated Mongol invasions (1277–1301) toppled the four-century-old kingdom in 1287.
Pagan's collapse was followed by 250 years of political fragmentation that lasted well into the 16th century. Like the Burmans four centuries earlier, Shan migrants who arrived with the Mongol invasions stayed behind. Several competing Shan states came to dominate the entire northwestern to eastern arc surrounding the Irrawaddy valley. The valley too was beset with petty states until the late 14th century when two sizable powers, Ava Kingdom and Hanthawaddy Kingdom, emerged. In the west, a politically fragmented Arakan was under competing influences of its stronger neighbours until the Kingdom of Mrauk U unified the Arakan coastline for the first time in 1437.
Early on, Ava fought wars of unification (1385–1424) but could never quite reassemble the lost empire. Having held off Ava, Hanthawaddy entered its golden age, and Arakan went on to become a power in its own right for the next 350 years. In contrast, constant warfare left Ava greatly weakened, and it slowly disintegrated from 1481 onward. In 1527, the Confederation of Shan States conquered Ava itself, and ruled Upper Burma until 1555.
Like the Pagan Empire, Ava, Hanthawaddy and the Shan states were all multi-ethnic polities. Despite the wars, cultural synchronisation continued. This period is considered a golden age for Burmese culture. Burmese literature "grew more confident, popular, and stylistically diverse", and the second generation of Burmese law codes as well as the earliest pan-Burma chronicles emerged. Hanthawaddy monarchs introduced religious reforms that later spread to the rest of the country. Many splendid temples of Mrauk U were built during this period.
Political unification returned in the mid-16th century, due to the efforts of one tiny Toungoo (Taungoo), a former vassal state of Ava. Toungoo's young, ambitious king Tabinshwehti defeated the more powerful Hanthawaddy in 1541. His successor Bayinnaung went on to conquer a vast swath of mainland Southeast Asia including the Shan states, Lan Na, Manipur, the Chinese Shan states, Siam, Lan Xang and southern Arakan. However, the largest empire in the history of Southeast Asia unravelled soon after Bayinnaung's death in 1581, completely collapsing by 1599. Siam seized Tenasserim and Lan Na, and Portuguese mercenaries established Portuguese rule at Syriam (Thanlyin).
The dynasty regrouped and defeated the Portuguese in 1613 and Siam in 1614. It restored a smaller, more manageable kingdom, encompassing Lower Burma, Upper Burma, Shan states, Lan Na and upper Tenasserim. The Restored Toungoo kings created a legal and political framework whose basic features would continue well into the 19th century. The crown completely replaced the hereditary chieftainships with appointed governorships in the entire Irrawaddy valley, and greatly reduced the hereditary rights of Shan chiefs. Its trade and secular administrative reforms built a prosperous economy for more than 80 years. From the 1720s onward, the kingdom was beset with repeated Manipuri raids into Upper Burma, and a nagging rebellion in Lan Na. In 1740, the Mon of Lower Burma founded the Restored Hanthawaddy Kingdom. Hanthawaddy forces sacked Ava in 1752, ending the 266-year-old Toungoo Dynasty.
After the fall of Ava, one resistance group, Alaungpaya's Konbaung Dynasty defeated Restored Hanthawaddy, and by 1759, had reunited all of Burma (and Manipur), and driven out the French and the British who had provided arms to Hanthawaddy. By 1770, Alaungpaya's heirs had subdued much of Laos (1765), defeated Siam (1767), and defeated four invasions by China (1765–1769).
With Burma preoccupied by the Chinese threat, Siam recovered its territories by 1770, and went on to capture Lan Na by 1776. Burma and Siam went to war until 1855, but all resulted in a stalemate, exchanging Tenasserim (to Burma) and Lan Na (to Siam). Faced with a powerful China and a resurgent Siam in the east, King Bodawpaya turned west, acquiring Arakan (1785), Manipur (1814) and Assam (1817). It was the second largest empire in Burmese history but also one with a long ill-defined border with British India.
The breadth of this empire was short lived. Burma lost Arakan, Manipur, Assam and Tenasserim to the British in the First Anglo-Burmese War (1824–1826). In 1852, the British easily seized Lower Burma in the Second Anglo-Burmese War. King Mindon tried to modernise the kingdom, and in 1875 narrowly avoided annexation by ceding the Karenni States. The British, alarmed by the consolidation of French Indo-China, annexed the remainder of the country in the Third Anglo-Burmese War in 1885.
Konbaung kings extended Restored Toungoo's administrative reforms, and achieved unprecedented levels of internal control and external expansion. For the first time in history, the Burmese language and culture came to predominate the entire Irrawaddy valley. The evolution and growth of Burmese literature and theatre continued, aided by an extremely high adult male literacy rate for the era (half of all males and 5% of females). Nonetheless, the extent and pace of reforms were uneven and ultimately proved insufficient to stem the advance of British colonialism.
British Burma (1824-1948).
The country was colonised by Britain following three Anglo-Burmese Wars (1824–1885). British rule brought social, economic, cultural and administrative changes.
With the fall of Mandalay, all of Burma came under British rule, being annexed on 1 January 1886. Throughout the colonial era, many Indians arrived as soldiers, civil servants, construction workers and traders and, along with the Anglo-Burmese community, dominated commercial and civil life in Burma. Rangoon became the capital of British Burma and an important port between Calcutta and Singapore.
Burmese resentment was strong and was vented in violent riots that paralysed Yangon (Rangoon) on occasion all the way until the 1930s. Some of the discontent was caused by a disrespect for Burmese culture and traditions such as the British refusal to remove shoes when they entered pagodas. Buddhist monks became the vanguards of the independence movement. U Wisara, an activist monk, died in prison after a 166-day hunger strike to protest against a rule that forbade him from wearing his Buddhist robes while imprisoned.
On 1 April 1937, Burma became a separately administered colony of Great Britain and Ba Maw the first Prime Minister and Premier of Burma. Ba Maw was an outspoken advocate for Burmese self-rule and he opposed the participation of Great Britain, and by extension Burma, in World War II. He resigned from the Legislative Assembly and was arrested for sedition. In 1940, before Japan formally entered the Second World War, Aung San formed the Burma Independence Army in Japan.
A major battleground, Burma was devastated during World War II. By March 1942, within months after they entered the war, Japanese troops had advanced on Rangoon and the British administration had collapsed. A Burmese Executive Administration headed by Ba Maw was established by the Japanese in August 1942. Wingate's British Chindits were formed into long-range penetration groups trained to operate deep behind Japanese lines. A similar American unit, Merrill's Marauders, followed the Chindits into the Burmese jungle in 1943. Beginning in late 1944, allied troops launched a series of offensives that led to the end of Japanese rule in July 1945. The battles were intense with much of Burma laid waste by the fighting. Overall, the Japanese lost some 150,000 men in Burma. Only 1,700 prisoners were taken.
Although many Burmese fought initially for the Japanese as part of the Burma Independence Army, many Burmese, mostly from the ethnic minorities, served in the British Burma Army. The Burma National Army and the Arakan National Army fought with the Japanese from 1942 to 1944 but switched allegiance to the Allied side in 1945. Under Japanese occupation, 170,000 to 250,000 civilians died.
Following World War II, Aung San negotiated the Panglong Agreement with ethnic leaders that guaranteed the independence of Burma as a unified state. Aung Zan Wai, Pe Khin, Bo Hmu Aung, Sir Maung Gyi, Dr. Sein Mya Maung, Myoma U Than Kywe were among the negotiators of the historical Panglong Conference negotiated with Bamar leader General Aung San and other ethnic leaders in 1947. In 1947, Aung San became Deputy Chairman of the Executive Council of Burma, a transitional government. But in July 1947, political rivals assassinated Aung San and several cabinet members.
Independence (1948-1962).
On 4 January 1948, the nation became an independent republic, named the "Union of Burma", with Sao Shwe Thaik as its first President and U Nu as its first Prime Minister. Unlike most other former British colonies and overseas territories, Burma did not become a member of the Commonwealth. A bicameral parliament was formed, consisting of a Chamber of Deputies and a Chamber of Nationalities, and multi-party elections were held in 1951–1952, 1956 and 1960.
The geographical area Burma encompasses today can be traced to the Panglong Agreement, which combined Burma Proper, which consisted of Lower Burma and Upper Burma, and the Frontier Areas, which had been administered separately by the British.
In 1961, U Thant, then the Union of Burma's Permanent Representative to the United Nations and former Secretary to the Prime Minister, was elected Secretary-General of the United Nations, a position he held for ten years. Among the Burmese to work at the UN when he was Secretary-General was a young Aung San Suu Kyi, who went on to become winner of the 1991 Nobel Peace Prize.
Military rule (1962-2011).
On 2 March 1962, the military led by General Ne Win took control of Burma through a coup d'état and the government has been under direct or indirect control by the military since then. Between 1962 and 1974, Burma was ruled by a revolutionary council headed by the general. Almost all aspects of society (business, media, production) were nationalised or brought under government control under the Burmese Way to Socialism, which combined Soviet-style nationalisation and central planning.
A new constitution of the Socialist Republic of the Union of Burma was adopted in 1974. Until 1988, the country was ruled as a one-party system, with the General and other military officers resigning and ruling through the Burma Socialist Programme Party (BSPP). During this period, Burma became one of the world's most impoverished countries.
There were sporadic protests against military rule during the Ne Win years and these were almost always violently suppressed. On 7 July 1962, the government broke up demonstrations at Rangoon University, killing 15 students. In 1974, the military violently suppressed anti-government protests at the funeral of U Thant. Student protests in 1975, 1976 and 1977 were quickly suppressed by overwhelming force.
In 1988, unrest over economic mismanagement and political oppression by the government led to widespread pro-democracy demonstrations throughout the country known as the 8888 Uprising. Security forces killed thousands of demonstrators, and General Saw Maung staged a coup d'état and formed the State Law and Order Restoration Council (SLORC). In 1989, SLORC declared martial law after widespread protests. The military government finalised plans for People's Assembly elections on 31 May 1989. SLORC changed the country's official English name from the "Socialist Republic of the Union of Burma" to the "Union of Myanmar" in 1989.
In May 1990, the government held free elections for the first time in almost 30 years and the National League for Democracy (NLD), the party of Aung San Suu Kyi, won 392 out of a total 489 seats (i.e., 80% of the seats). However, the military junta refused to cede power and continued to rule the nation as SLORC until 1997, and then as the State Peace and Development Council (SPDC) until its dissolution in March 2011.
On 23 June 1997, Burma was admitted into the Association of Southeast Asian Nations (ASEAN). On 27 March 2006, the military junta, which had moved the national capital from Yangon to a site near Pyinmana in November 2005, officially named the new capital Naypyidaw, meaning "city of the kings".
In August 2007, an increase in the price of diesel and petrol led to a series of anti-government protests that were dealt with harshly by the government. The protests then became a campaign of civil resistance (also called the Saffron Revolution.) led by Buddhist monks, hundreds of whom defied the house arrest of democracy advocate Aung San Suu Kyi to pay their respects at the gate of her house.
The government cracked down on them on 26 September 2007. The crackdown was harsh, with reports of barricades at the Shwedagon Pagoda and monks killed. There were also rumours of disagreement within the Burmese armed forces, but none was confirmed. The military crackdown against unarmed Saffron Revolution protesters was widely condemned as part of the International reaction to the 2007 Burmese anti-government protests and led to an increase in economic sanctions against the Burmese Government.
In May 2008, Cyclone Nargis caused extensive damage in the densely populated, rice-farming delta of the Irrawaddy Division. It was the worst natural disaster in Burmese history with reports of an estimated 200,000 people dead or missing, and damage totalled to 10 billion US Dollars, and as many as 1 million left homeless. In the critical days following this disaster, Burma's isolationist government was accused of hindering United Nations recovery efforts. Humanitarian aid was requested but concerns about foreign military or intelligence presence in the country delayed the entry of United States military planes delivering medicine, food, and other supplies.
In early August 2009, a conflict known as the Kokang incident broke out in Shan State in northern Burma. For several weeks, junta troops fought against ethnic minorities including the Han Chinese, Wa, and Kachin. During 8–12 August, the first days of the conflict, as many as 10,000 Burmese civilians fled to Yunnan province in neighbouring China.
Democratic reforms.
The goal of the Burmese constitutional referendum of 2008, held on 10 May 2008, is the creation of a "discipline-flourishing democracy". As part of the referendum process, the name of the country was changed from the "Union of Myanmar" to the "Republic of the Union of Myanmar", and general elections were held under the new constitution in 2010. Observer accounts of the 2010 election describe the event as mostly peaceful; however, allegations of polling station irregularities were raised, and the United Nations (UN) and a number of Western countries condemned the elections as fraudulent.
The military-backed Union Solidarity and Development Party declared victory in the 2010 elections, stating that it had been favoured by 80 percent of the votes; however, the claim was disputed by numerous pro-democracy opposition groups who asserted that the military regime had engaged in rampant fraud. One report documented 77 percent as the official turnout rate of the election. The military junta was dissolved on 30 March 2011.
Opinions differ whether the transition to liberal democracy is underway. According to some reports, the military's presence continues as the label 'disciplined democracy' suggests. This label asserts that the Burmese military is allowing certain civil liberties while clandestinely institutionalising itself further into Burmese politics. Such an assertion assumes that reforms only occurred when the military was able to safeguard its own interests through the transition—here, "transition" does not refer to a transition to a liberal democracy, but transition to a quasi-military rule.
Since the 2010 election, the government has embarked on a series of reforms to direct the country towards liberal democracy, a mixed economy, and reconciliation, although doubts persist about the motives that underpin such reforms. The series of reforms includes the release of pro-democracy leader Aung San Suu Kyi from house arrest, the establishment of the National Human Rights Commission, the granting of general amnesties for more than 200 political prisoners, new labour laws that permit labour unions and strikes, a relaxation of press censorship, and the regulation of currency practices.
The impact of the post-election reforms has been observed in numerous areas, including ASEAN's approval of Burma's bid for the position of ASEAN chair in 2014; the visit by United States Secretary of State Hillary Clinton in December 2011 for the encouragement of further progress—it was the first visit by a Secretary of State in more than fifty years (Clinton met with the Burmese president and former military commander Thein Sein, as well as opposition leader Daw Aung San Suu Kyi); and the participation of Aung San Suu Kyi's National League for Democracy (NLD) party in the 2012 by-elections, facilitated by the government's abolition of the laws that previously barred the NLD. As of July 2013, about 100 political prisoners remain imprisoned, while conflict between the Burmese Army and local insurgent groups continues.
In 1 April 2012 by-elections the NLD won 43 of the 45 available seats; previously an illegal organisation, the NLD had never won a Burmese election until this time. The 2012 by-elections were also the first time that international representatives were allowed to monitor the voting process in Burma. Following announcement of the by-elections, the Freedom House organisation raised concerns about "reports of fraud and harassment in the lead up to elections, including the March 23 deportation of Somsri Hananuntasuk, executive director of the Asian Network for Free Elections (ANFREL), a regional network of civil society organizations promoting democratization."
Civil wars.
Civil wars have been a constant feature of Burma's socio-political landscape since the attainment of independence in 1948. These wars are predominantly struggles for ethnic and sub-national autonomy, with the areas surrounding the ethnically Burman central districts of the country serving as the primary geographical setting of conflict. Foreign journalists and visitors require a special travel permit to visit the areas in which Burma's civil wars continue.
In October 2012 the number of ongoing conflicts in Burma included the Kachin conflict, between the Pro-Christian Kachin Independence Army and the government; a civil war between the Rohingya Muslims, and the government and non-government groups in Arakan State; and a conflict between the Shan, Lahu and Karen minority groups, and the government in the eastern half of the country. In addition al-Qaeda signalled an intention to become involved in Burma. In a video released 3 September 2014 mainly addressed to India, the militant group's leader Ayman al-Zawahiri said al-Qaeda had not forgotten the Muslims of Burma and that the group was doing "what they can to rescue you". In response, the military raised its level of alertness while the Burmese Muslim Association issued a statement saying Muslims would not tolerate any threat to their motherland.
Armed conflict between ethnic Chinese rebels and the Myanmar Armed Forces have resulted in the Kokang offensive in February 2015. The conflict had forced 40,000 to 50,000 civilians to flee their homes and seek shelter on the Chinese side of the border. During the incident the government of China was accused of giving military assistance to the ethnic Chinese rebels.
Geography.
Burma has a total area of 678500 km2. It lies between latitudes 9° and 29°N, and longitudes 92° and 102°E. As of February 2011, Burma consisted of 14 states and regions, 67 districts, 330 townships, 64 sub-townships, 377 towns, 2,914 Wards, 14,220 village tracts and 68,290 villages.
Burma is bordered in the northwest by the Chittagong Division of Bangladesh and the Mizoram, Manipur, Nagaland and Arunachal Pradesh states of India. Its north and northeast border straddles the Tibet Autonomous Region and Yunnan province for a Sino-Burman border total of 2185 km. It is bounded by Laos and Thailand to the southeast. Burma has 1930 km of contiguous coastline along the Bay of Bengal and Andaman Sea to the southwest and the south, which forms one quarter of its total perimeter.
In the north, the Hengduan Mountains form the border with China. Hkakabo Razi, located in Kachin State, at an elevation of 5881 m, is the highest point in Burma. Many mountain ranges, such as the Rakhine Yoma, the Bago Yoma, the Shan Hills and the Tenasserim Hills exist within Burma, all of which run north-to-south from the Himalayas.
The mountain chains divide Burma's three river systems, which are the Irrawaddy, Salween (Thanlwin), and the Sittaung rivers. The Irrawaddy River, Burma's longest river, nearly 2170 km long, flows into the Gulf of Martaban. Fertile plains exist in the valleys between the mountain chains. The majority of Burma's population lives in the Irrawaddy valley, which is situated between the Rakhine Yoma and the Shan Plateau.
Administrative divisions.
Burma is divided into seven states (ပြည်နယ်) and seven regions (တိုင်းဒေသကြီး), formerly called divisions. Regions are predominantly Bamar (that is, mainly inhabited by the dominant ethnic group). States, in essence, are regions that are home to particular ethnic minorities. The administrative divisions are further subdivided into districts, which are further subdivided into townships, wards, and villages.
Below are the number of districts, townships, cities/towns, wards, village groups and villages in each divisions and states of Burma as of 31 December 2001:
Climate.
Much of the country lies between the Tropic of Cancer and the Equator. It lies in the monsoon region of Asia, with its coastal regions receiving over 5000 mm of rain annually. Annual rainfall in the delta region is approximately 2500 mm, while average annual rainfall in the Dry Zone in central Burma is less than 1000 mm. The Northern regions of Burma are the coolest, with average temperatures of 21 C. Coastal and delta regions have an average maximum temperature of 32 C.
Wildlife.
Burma's slow economic growth has contributed to the preservation of much of its environment and ecosystems. Forests, including dense tropical growth and valuable teak in lower Burma, cover over 49% of the country, including areas of acacia, bamboo, ironwood and "Magnolia champaca". Coconut and betel palm and rubber have been introduced. In the highlands of the north, oak, pine and various rhododendrons cover much of the land.
Heavy logging since the new 1995 forestry law went into effect has seriously reduced forest acreage and wildlife habitat. The lands along the coast support all varieties of tropical fruits and once had large areas of mangroves although much of the protective mangroves have disappeared. In much of central Burma (the Dry Zone), vegetation is sparse and stunted.
Typical jungle animals, particularly tigers and leopards, occur sparsely in Burma. In upper Burma, there are rhinoceros, wild buffalo, wild boars, deer, antelope, and elephants, which are also tamed or bred in captivity for use as work animals, particularly in the lumber industry. Smaller mammals are also numerous, ranging from gibbons and monkeys to flying foxes and tapirs. The abundance of birds is notable with over 800 species, including parrots, peafowl, pheasants, crows, herons, and paddybirds. Among reptile species there are crocodiles, geckos, cobras, Burmese pythons, and turtles. Hundreds of species of freshwater fish are wide-ranging, plentiful and are very important food sources. For a list of protected areas, see List of protected areas of Burma.
Government and politics.
The constitution of Burma, its third since independence, was drafted by its military rulers and published in September 2008. The country is governed as a presidential republic with a bicameral legislature, with a portion of legislators appointed by the military and others elected in general elections. The current head of state, inaugurated as President on 30 March 2011, is Thein Sein.
The legislature, called the Pyidaungsu Hluttaw, is bicameral and made up of two houses: the 224-seat upper house Amyotha Hluttaw (House of Nationalities) and the 440-seat lower house Pyithu Hluttaw (House of Representatives). The upper house consists of 224 members, of whom 168 are directly elected and 56 are appointed by the Burmese Armed Forces. The lower house consists of 440 members, of whom 330 are directly elected and 110 are appointed by the armed forces.
Political culture.
The major political parties are the National League for Democracy, National Democratic Force and the two backed by the military: the National Unity Party, and the Union Solidarity and Development Party.
Burma's army-drafted constitution was approved in a referendum in May 2008. The results, 92.4% of the 22 million voters with an official turnout of 99%, are considered suspect by many international observers and by the National League of Democracy with reports of widespread fraud, ballot stuffing, and voter intimidation.
The elections of 2010 resulted in a victory for the military-backed Union Solidarity and Development Party. Various foreign observers questioned the fairness of the elections. One criticism of the election was that only government sanctioned political parties were allowed to contest in it and the popular National League for Democracy was declared illegal. However, immediately following the elections, the government ended the house arrest of the democracy advocate and leader of the National League for Democracy, Aung San Suu Kyi, and her ability to move freely around the country is considered an important test of the military's movement toward more openness. After unexpected reforms in 2011, NLD senior leaders have decided to register as a political party and to field candidates in future by-elections.
Burma rates as a corrupt nation on the Corruption Perceptions Index with a rank of 157th out of 177 countries worldwide and a rating of 2.1 out of 10 (10 being least corrupt and 0 being highly corrupt) as of 2012.
Foreign relations.
Though the country's foreign relations, particularly with Western nations, have been strained, relations have thawed since the reforms following the 2010 elections. After years of diplomatic isolation and economic and military sanctions, the United States relaxed curbs on foreign aid to Burma in November 2011 and announced the resumption of diplomatic relations on 13 January 2012 The European Union has placed sanctions on Burma, including an arms embargo, cessation of trade preferences, and suspension of all aid with the exception of humanitarian aid.
Sanctions imposed by the United States and European countries against the former military government, coupled with boycotts and other direct pressure on corporations by supporters of the democracy movement, have resulted in the withdrawal from the country of most U.S. and many European companies.
On 13 April 2012 British Prime Minister David Cameron called for the economic sanctions on Burma to be suspended in the wake of the pro-democracy party gaining 43 seats out of a possible 45 in the 2012 by-elections with the party leader, Aung San Suu Kyi becoming a member of the Burmese parliament.
Despite Western isolation, Asian corporations have generally remained willing to continue investing in the country and to initiate new investments, particularly in natural resource extraction. The country has close relations with neighbouring India and China with several Indian and Chinese companies operating in the country. Under India's Look East policy, fields of co-operation between India and Burma include remote sensing, oil and gas exploration, information technology, hydro power and construction of ports and buildings.
In 2008, India suspended military aid to Burma over the issue of human rights abuses by the ruling junta, although it has preserved extensive commercial ties, which provide the regime with much-needed revenue. The thaw in relations began on 28 November 2011, when Belarusian Prime Minister Mikhail Myasnikovich and his wife Ludmila arrived in the capital, Naypyidaw, the same day as the country received a visit by U.S. Secretary of State Hillary Rodham Clinton, who also met with pro-democracy opposition leader Aung San Suu Kyi. International relations progress indicators continued in September 2012 when Aung San Suu Kyi visited to the US followed by Burma's reformist president visit to the United Nations.
In May 2013, Thein Sein became the first Myanmar president to visit the White House in 47 years; the last Burmese leader to visit the White House was Ne Win in September 1966. President Barack Obama praised the former general for political and economic reforms, and the cessation of tensions between Myanmar and the United States. Political activists objected to the visit due to concerns over human rights abuses in Myanmar but Obama assured Thein Sein that Myanmar will receive U.S. support. The two leaders discussed to release more political prisoners, the institutionalisation of political reform and rule of law, and ending ethnic conflict in Myanmar—the two governments agreed to sign a bilateral trade and investment framework agreement on 21 May 2013.
In June 2013, Myanmar held its first ever summit, the World Economic Forum on East Asia 2013. A regional spinoff of the annual World Economic Forum in Davos, Switzerland, the summit was held on 5–7 June and attended by 1,200 participants, including 10 heads of state, 12 ministers and 40 senior directors from around the world.
Military.
Burma has received extensive military aid from China in the past
Burma has been a member of ASEAN since 1997. Though it gave up its turn to hold the ASEAN chair and host the ASEAN Summit in 2006, it is scheduled to chair the forum and host the summit in 2014. In November 2008, Burma's political situation with neighbouring Bangladesh became tense as they began searching for natural gas in a disputed block of the Bay of Bengal. Controversy surrounding the Rohingya population also remains an issue between Bangladesh and Burma.
Burma's armed forces are known as the Tatmadaw, which numbers 488,000. The Tatmadaw comprises the Army, the Navy, and the Air Force. The country ranked twelfth in the world for its number of active troops in service. The military is very influential in Burma, with all top cabinet and ministry posts usually held by military officials. Official figures for military spending are not available. Estimates vary widely because of uncertain exchange rates, but Burma's military forces' expenses are high. Burma imports most of its weapons from Russia, Ukraine, China and India.
Burma is building a research nuclear reactor near Pyin Oo Lwin with help from Russia. It is one of the signatories of the nuclear non-proliferation pact since 1992 and a member of the International Atomic Energy Agency (IAEA) since 1957. The military junta had informed the IAEA in September 2000 of its intention to construct the reactor. The research reactor outbuilding frame was built by ELE steel industries limited of Yangon/Rangoon and water from Anisakhan/BE water fall will be used for the reactor cavity cooling system.
In 2010 as part of the Wikileaks leaked cables, Burma was suspected of using North Korean construction teams to build a fortified Surface-to-Air Missile facility.
Until 2005, the United Nations General Assembly annually adopted a detailed resolution about the situation in Burma by consensus. But in 2006 a divided United Nations General Assembly voted through a resolution that strongly called upon the government of Burma to end its systematic violations of human rights. In January 2007, Russia and China vetoed a draft resolution before the United Nations Security Council calling on the government of Burma to respect human rights and begin a democratic transition. South Africa also voted against the resolution.
Human rights and internal conflicts.
There is consensus that the military regime in Burma is one of the world's most repressive and abusive regimes. In November 2012, Samantha Power, Barack Obama's Special Assistant to the President on Human Rights, wrote on the White House blog in advance of the president's visit that "Serious human rights abuses against civilians in several regions continue, including against women and children." Members of the United Nations and major international human rights organisations have issued repeated and consistent reports of widespread and systematic human rights violations in Burma. The United Nations General Assembly has repeatedly called on the Burmese Military Junta to respect human rights and in November 2009 the General Assembly adopted a resolution "strongly condemning the ongoing systematic violations of human rights and fundamental freedoms" and calling on the Burmese Military Regime "to take urgent measures to put an end to violations of international human rights and humanitarian law."
International human rights organisations including Human Rights Watch, Amnesty International and the American Association for the Advancement of Science have repeatedly documented and condemned widespread human rights violations in Burma. The "Freedom in the World 2011" report by Freedom House notes, "The military junta has ... suppressed nearly all basic rights; and committed human rights abuses with impunity." In July 2013, the Assistance Association for Political Prisoners indicated that there were approximately 100 political prisoners being held in Burmese prisons.
Evidence gathered by a British researcher was published in 2005 regarding the extermination or 'Burmisation' of certain ethnic minorities, such as the Karen, Karenni and Shan.
Child soldiers.
Child soldiers have and continue to play a major part in the Burmese Army as well as Burmese rebel movements. "The Independent" reported in June 2012 that "Children are being sold as conscripts into the Burmese military for as little as $40 and a bag of rice or a can of petrol." The UN's Special Representative of the Secretary-General for Children and Armed Conflict, Radhika Coomaraswamy, who stepped down from her position a week later, met representatives of the Government of Myanmar on 5 July 2012 and stated that she hoped the government's signing of an action plan would "signal a transformation." In September 2012, the Myanmar Armed Forces released 42 child soldiers and the International Labour Organization met with representatives of the government as well as the Kachin Independence Army to secure the release of more child soldiers. According to Samantha Power, a US delegation raised the issue of child soldiers with the government in October 2012. However, she did not comment on the government's progress towards reform in this area.
A "Bangkok Post" article on 23 December 2012 reported that the Myanmar Armed Forces continued to use child soldiers including during the army's large offensive against the KIA in December 2012. The newspaper reported that "Many of them were pulled off Yangon streets and elsewhere and given a minimum of training before being sent to the front line."
Child/forced/slave labour, systematic sexual violence and human trafficking.
Forced labour, human trafficking, and child labour are common. The military is also notorious for rampant use of sexual violence, a practice continuing as of 2012. In 2007 the international movement to defend women's human rights issues in Burma was said to be gaining speed.
Genocide allegations and crimes against Rohingya people.
The Rohingya people have consistently faced human rights abuses by the Burmese regime that has refused to acknowledge them as Burmese citizens (despite some of them having lived in Burma for over three generations)—the Rohingya have been denied Burmese citizenship since the enactment of a 1982 citizenship law. The law created three categories of citizenship: citizenship, associate citizenship, and naturalized citizenship. Citizenship is given to those who belong to one of the national races such as Kachin, Kayah (Karenni), Karen, Chin, Burman, Mon, Rakhine, Shan, Kaman, or Zerbadee. Associate citizenship is given to those who cannot prove their ancestors settled in Myanmar before 1823, but can prove they have one grandparent, or pre-1823 ancestor, was a citizen of another country. As well as people who applied for citizenship in 1948 and qualified for the laws then. Naturalized citizenship is only given to those who have at least one parent with one of these types of Burmese citizenship or can provide "conclusive evidence" that their parents entered and resided in Burma prior to independence in 1948. The Burmese regime has attempted to forcibly expel Rohingya and bring in non-Rohingyas to replace them—this policy has resulted in the expulsion of approximately half of the 800,000 Rohingya from Burma, while the Rohingya people have been described as "among the world's least wanted" and "one of the world's most persecuted minorities."
Rohingya are also not allowed to travel without official permission, are banned from owning land and are required to sign a commitment to have no more than two children. As of July 2012, the Myanmar Government does not include the Rohingya minority group—classified as stateless Bengali Muslims from Bangladesh since 1982—on the government's list of more than 130 ethnic races and, therefore, the government states that they have no claim to Myanmar citizenship.
In 2007 the German professor Bassam Tibi suggested that the Rohingya conflict may be driven by an Islamist political agenda to impose religious laws, while non-religious causes have also been raised, such as a lingering resentment over the violence that occurred during the Japanese occupation of Burma in World War II—during this time period the British allied themselves with the Rohingya and fought against the puppet government of Burma (composed mostly of Bamar Japanese) that helped to establish the Tatmadaw military organisation that remains in power as of March 2013.
Since the democratic transition began in 2011, there has been continuous violence as 280 people have been killed and 140,000 forced to flee from their homes in the Rakhine state. A UN envoy reported in March 2013 that unrest had re-emerged between Burma's Buddhist and Muslim communities, with violence spreading to towns that are located closer to Yangon. The BBC News media outlet obtained video footage of a man with severe burns who received no assistance from passers-by or police officers even though he was lying on the ground in a public area. The footage was filmed by members of the Burmese police force in the town of Meiktila and was used as evidence that Buddhists continued to kill Muslims after the European Union sanctions were lifted on 23 April 2013.
Rohingya Fleeing by boat.
Rohingya have been fleeing Rakhine State by boat in recent years. Often, the boats are very small and dangerous on the open seas. An estimated 100,000 Rohingya have fled Myanmar in the last two years in fear of persecution and violence. They have been fleeing to Thailand, Malaysia, or even Australia for refuge. Over 200 have died in recent years and over 7,000 have been held in detention centres even after surviving the boat trip.
2012 Rakhine State riots.
A widely publicised Burmese conflict was the 2012 Rakhine State riots, a series of conflicts that primarily involved the ethnic Rakhine Buddhist people and the Rohingya Muslim people in the northern Rakhine State—an estimated 90,000 people were displaced as a result of the riots.
The immediate cause of the riots is unclear, with many commentators citing the killing of ten Burmese Muslims by ethnic Rakhine after the rape and murder of a Rakhine woman as the main cause. Whole villages have been "decimated". Over 300 houses and a number of public buildings have been razed. According to Tun Khin, the president of the Burmese Rohingya Organisation UK (BROUK), as of 28 June 2012, 650 Rohingyas have been killed, 1,200 are missing, and more than 80,000 have been displaced. According to the Myanmar authorities, the violence, between ethnic Rakhine Buddhists and Rohingya Muslims, left 78 people dead, 87 injured, and thousands of homes destroyed. It displaced more than 52,000 people.
The government has responded by imposing curfews and by deploying troops in the regions. On 10 June 2012, a state of emergency was declared in Rakhine, allowing the military to participate in administration of the region. The Burmese army and police have been accused of targeting Rohingya Muslims through mass arrests and arbitrary violence. A number of monks' organisations that played a vital role in Burma's struggle for democracy have taken measures to block any humanitarian assistance to the Rohingya community.
Freedom of speech.
Restrictions on media censorship were significantly eased in August 2012 following demonstrations by hundreds of protesters who wore shirts demanding that the government "Stop Killing the Press." The most significant change has come in the form that media organisations will no longer have to submit their content to a censorship board before publication. However, as explained by one editorial in the exiled press "The Irrawaddy", this new "freedom" has caused some Burmese journalists to simply see the new law as an attempt to create an environment of self-censorship as journalists "are required to follow 16 guidelines towards protecting the three national causes — non-disintegration of the Union, non-disintegration of national solidarity, perpetuation of sovereignty — and "journalistic ethics" to ensure their stories are accurate and do not jeopardise national security." In July 2014 five journalists were sentenced to 10 years in jail after publishing a report saying the country was planning to build a new chemical weapons plant. Journalists described the jailings as a blow to the recently-won news media freedoms that had followed five decades of censorship and persecution.
Praise for the 2011 government reforms.
According to the Crisis Group, since Burma transitioned to a new government in August 2011, the country's human rights record has been improving. Previously giving Burma its lowest rating of 7, the 2012 "Freedom in the World" report also notes improvement, giving Burma a 6 for improvements in civil liberties and political rights, the release of political prisoners, and a loosening of restrictions. In 2013, Burma improved yet again, receiving a score of five in civil liberties and a six in political freedoms
The government has assembled a National Human Rights Commission that consists of 15 members from various backgrounds. Several activists in exile, including Thee Lay Thee Anyeint members, have returned to Burma after President Thein Sein's invitation to expatriates to return home to work for national development. In an address to the United Nations Security Council on 22 September 2011, Burma's Foreign Minister Wunna Maung Lwin confirmed the government's intention to release prisoners in the near future.
The government has also relaxed reporting laws, but these remain highly restrictive. In September 2011, several banned websites, including YouTube, Democratic Voice of Burma and Voice of America, were unblocked. A 2011 report by the Hauser Center for Nonprofit Organizations found that, while contact with the Myanmar government was constrained by donor restrictions, international humanitarian non-governmental organisations (NGOs) see opportunities for effective advocacy with government officials, especially at the local level. At the same time, international NGOs are mindful of the ethical quandary of how to work with the government without bolstering or appeasing it.
2013 onwards.
Following Thein Sein's first ever visit to the UK and a meeting with Prime Minister David Cameron, the Myanmar president declared that all of his nation's political prisoners will be released by the end of 2013, in addition to a statement of support for the well-being of the Rohingya Muslim community. In a speech at Chatham House, he revealed that "We [Myanmar government] are reviewing all cases. I guarantee to you that by the end of this year, there will be no prisoners of conscience in Myanmar.", in addition to expressing a desire to strengthen links between the UK and Myanmar's military forces.
Nuclear weapons programme.
There have been reports that Burma is interested in or may be developing nuclear weapons. These reports are based on evidence gathered from anti-government Burmese and on reports that North Korea may be exporting nuclear technology to Burma. However, there has been no independent corroboration of these reports.
Economy.
Burma is one of the poorest nations in Southeast Asia, suffering from decades of stagnation, mismanagement and isolation. The lack of an educated workforce skilled in modern technology hinders Burma's economy.
Burma lacks adequate infrastructure. Goods travel primarily across the Thai border (where most illegal drugs are exported) and along the Irrawaddy River. Railways are old and rudimentary, with few repairs since their construction in the late 19th century. Highways are normally unpaved, except in the major cities. Energy shortages are common throughout the country including in Yangon and only 25% of the country's population has electricity.
The military government has the majority stakeholder position in all of the major industrial corporations of the country (from oil production and consumer goods to transportation and tourism).
The national currency is Kyat. Inflation averaged 30.1% between 2005 and 2007. Inflation is a serious problem for the economy.
In 2010–2011, Bangladesh exported products worth $9.65 million to Myanmar against its import of $179 million. The annual import of medicine and medical equipment to Burma during the 2000s was 160 million USD.
In recent years, both China and India have attempted to strengthen ties with the government for economic benefit. Many nations, including the United States and Canada, and the European Union, have imposed investment and trade sanctions on Burma. The United States and European Union eased most of their sanctions in 2012. Foreign investment comes primarily from China, Singapore, the Philippines, South Korea, India, and Thailand.
Economic history.
Under British administration, Burma was the second-wealthiest country in South-East Asia. It had been the world's largest exporter of rice. Burma also had a wealth of natural and labour resources. British Burma began exporting crude oil in 1853, making it one of the earliest petroleum producers in the world. It produced 75% of the world's teak and had a highly literate population. The wealth was however, mainly concentrated in the hands of Europeans. In 1930s, agricultural production fell dramatically as international rice prices declined, and did not recover for several decades.
During World War II, the British destroyed the major government buildings, oil wells and mines for tungsten, tin, lead and silver to keep them from the Japanese. Burma was bombed extensively by both sides. After independence, the country was in ruins with its major infrastructure completely destroyed. After a parliamentary government was formed in 1948, Prime Minister U Nu embarked upon a policy of nationalisation and the state was declared the owner of all land. The government also tried to implement a poorly considered Eight-Year plan. By the 1950s, rice exports had fallen by two thirds and mineral exports by over 96% (as compared to the pre-World War II period). Plans were partly financed by printing money, which led to inflation.
The 1962 coup d'état was followed by an economic scheme called the Burmese Way to Socialism, a plan to nationalise all industries, with the exception of agriculture. The catastrophic programme turned Burma into one of the world's most impoverished countries. Burma's admittance to least developed country status by the UN in 1987 highlighted its economic bankruptcy.
Agriculture.
The major agricultural product is rice, which covers about 60% of the country's total cultivated land area. Rice accounts for 97% of total food grain production by weight. Through collaboration with the International Rice Research Institute 52 modern rice varieties were released in the country between 1966 and 1997, helping increase national rice production to 14 million tons in 1987 and to 19 million tons in 1996. By 1988, modern varieties were planted on half of the country's ricelands, including 98 percent of the irrigated areas. In 2008 rice production was estimated at 50 million tons.
Drug production.
Burma is also the world's second largest producer of opium, accounting for 8% of entire world production and is a major source of illegal drugs, including amphetamines.
Opium bans implemented since 2002 after international pressure have left ex-poppy farmers without sustainable sources of income in the Kokang and Wa regions. They depend on casual labour for income.
Natural resources.
Burma produces precious stones such as rubies, sapphires, pearls, and jade. Rubies are the biggest earner; 90% of the world's rubies come from the country, whose red stones are prized for their purity and hue. Thailand buys the majority of the country's gems. Burma's "Valley of Rubies", the mountainous Mogok area, 200 km north of Mandalay, is noted for its rare pigeon's blood rubies and blue sapphires.
Many US and European jewellery companies, including Bulgari, Tiffany, and Cartier, refuse to import these stones based on reports of deplorable working conditions in the mines. Human Rights Watch has encouraged a complete ban on the purchase of Burmese gems based on these reports and because nearly all profits go to the ruling junta, as the majority of mining activity in the country is government-run. The government of Burma controls the gem trade by direct ownership or by joint ventures with private owners of mines.
Other industries include agricultural goods, textiles, wood products, construction materials, gems, metals, oil and natural gas.
Tourism.
Since 1992, the government has encouraged tourism in the country; however, fewer than 270,000 tourists entered the country in 2006 according to the Myanmar Tourism Promotion Board. Burma's Minister of Hotels and Tourism Saw Lwin has stated that the government receives a significant percentage of the income of private sector tourism services.
The most popular available tourist destinations in Burma include big cities such as Yangon and Mandalay; religious sites in Mon State, Pindaya, Bago and Hpa-An; nature trails in Inle Lake, Kengtung, Putao, Pyin Oo Lwin; ancient cities such as Bagan and Mrauk-U; as well as beaches in Ngapali, Ngwe-Saung, Mergui. Nevertheless much of the country is off-limits to tourists, and interactions between foreigners and the people of Burma, particularly in the border regions, are subject to police scrutiny. They are not to discuss politics with foreigners, under penalty of imprisonment and, in 2001, the Myanmar Tourism Promotion Board issued an order for local officials to protect tourists and limit "unnecessary contact" between foreigners and ordinary Burmese people.
The most common way for travellers to enter the country seems to be by air. According to the website "Lonely Planet", getting into Burma (Myanmar) is problematic: "No bus or train service connects Myanmar with another country, nor can you travel by car or motorcycle across the border – you must walk across.", and states that, "It is not possible for foreigners to go to/from Myanmar by sea or river." There are a small number of border crossings that allow the passage of private vehicles, such as the border between Ruili (China) to Mu-se, the border between Htee Kee (Burma) and Ban Nam Pu (Thailand) (the most direct border between Dawei and Kanchanaburi), and the border between Myawaddy (Burma) and Mae Sot (Thailand). At least one tourist company has successfully run commercial overland routes through these borders since 2013. "From Mae Sai (Thailand) you can cross to Tachileik, but can only go as far as Kengtung. Those in Thailand on a visa run can cross to Kawthaung but cannot venture farther into Myanmar."
Flights are available from most countries, though direct flights are limited to mainly Thai and other ASEAN airlines. According to "Eleven" magazine, "In the past, there were only 15 international airlines and increasing numbers of airlines have began launching direct flights from Japan, Qatar, Taiwan, South Korea, Germany and Singapore." Expansions were expected in September 2013, but yet again are mainly Thai and other Asian-based airlines according to Eleven Media Group's "Eleven", "Thailand-based Nok Air and Business Airlines and Singapore-based Tiger Airline".
Economic sanctions.
The Government of Burma is under economic sanctions by the US Treasury Department (31 CFR Part 537, 16 August 2005) and by Executive orders 13047 (1997), 13310 (2003), 13448 (2007), 13464 (2008), and the most recent, 13619 (2012). There exists debate as to the extent to which the American-led sanctions have had more adverse effects on the civilian population rather than on the military rulers.
From May 2012 to February 2013, the United States began to lift its economic sanctions on Burma "in response to the historic reforms that have been taking place in that country." Sanctions remain in place for blocked banks and for any business entities that are more than 50% owned by persons on "OFAC's Specially Designated Nationals and Blocked Persons list (SDN list)".
Government stakeholders in business.
The military has the majority stakeholder position in all of the major industrial corporations of the country (from oil production and consumer goods to transportation and tourism).
Economic liberalization, post–2011.
In March 2012, a draft foreign investment law emerged, the first in more than 2 decades. Foreigners will no longer require a local partner to start a business in the country, and will be able to legally lease but not own property. The draft law also stipulates that Burmese citizens must constitute at least 25% of the firm's skilled workforce, and with subsequent training, up to 50–75%.
In 2012, the Asian Development Bank formally began re-engaging with the country, to finance infrastructure and development projects in the country. The United States, Japan, and the European Union countries have also begun to reduce or eliminate economic sanctions to allow foreign direct investment which will provide the Burmese government with additional tax revenue.
In December 2014, Myanmar signed an agreement to set up its first stock exchange. = The Yangon Stock Exchange Joint Venture Co. Ltd will be set up with Myanmar Economic Bank sharing 51 percent, Japan's Daiwa Institute of Research Ltd 30.25 percent and Japan Exchange Group 18.75 percent, reported Xinhua.
Units of measurement.
According to The World Factbook, Burma is one of three countries along with Liberia and the United States of America that has not adopted the International System of Units (SI) metric system as their official system of weights and measures. The common units of measure are unique to Burma, but the government web pages use both imperial units and metric units.
In June 2011, the Burmese government's Ministry of Commerce began discussing proposals to reform the measurement system and adopt the International System of Units used by most of its trading partners. In October 2013 it was reported that Dr. Pwint San, Deputy Minister for Commerce, had announced that the country was preparing to adopt the International System of Units.
Society.
Demographics.
The provisional results of the 2014 Burma Census show that the total population is 51,419,420. This figure includes an estimated 1,206,353 persons in parts of northern Rakhine State, Kachin State and Kayin State who were not counted. People who were out of the country at the time of the census are not included in these figures. There are over 600,000 registered migrant workers from Burma in Thailand, and millions more work illegally. Burmese migrant workers account for 80% of Thailand's migrant workers. Population density is 76 /km2, among the lowest in Southeast Asia.
Burma's fertility rate as of 2011 is 2.23, which is slightly above replacement level and is low compared to Southeast Asian countries of similar economic standing, such Cambodia (3.18) and Laos (4.41). There has been a significant decline in fertility, from a rate of 4.7 children per woman in 1983, down to 2.4 in 2001, despite the absence of any national population policy. The fertility rate is much lower in urban areas.
The relatively rapid decline in fertility is attributed to several factors, including extreme delays in marriage (almost unparalleled among developing countries in the region), the prevalence of illegal abortions, and the high proportion of single, unmarried women of reproductive age, with 25.9% of women aged 30–34 and 33.1% of men and women aged 25–34 single.
These patterns stem from several cultural and economic dynamics. The first is economic hardship, which results in the delay of marriage and family-building; the average age of marriage in Burma is 27.5 for men, 26.4 for women. The second is the social acceptability of celibacy among the Burmese, who are predominantly Buddhist and value celibacy as a means of spiritual development.
Ethnic groups.
Burma is ethnically diverse. The government recognises 135 distinct ethnic groups. While it is extremely difficult to verify this statement, there are at least 108 different ethnolinguistic groups in Burma, consisting mainly of distinct Tibeto-Burman peoples, but with sizeable populations of Tai–Kadai, Hmong–Mien, and Austroasiatic (Mon–Khmer) peoples.
The Bamar form an estimated 68% of the population. 10% of the population are Shan. The Kayin make up 7% of the population. The Rakhine people constitute 4% of the population. Overseas Chinese form approximately 3% of the population. Burma's ethnic minority groups prefer the term "ethnic nationality" over "ethnic minority" as the term "minority" furthers their sense of insecurity in the face of what is often described as "Burmanisation"—the proliferation and domination of the dominant Bamar culture over minority cultures.
Mon, who form 2% of the population, are ethno-linguistically related to the Khmer. Overseas Indians are 2%. The remainder are Kachin, Chin, Anglo-Indians, Gurkha, Nepali and other ethnic minorities. Included in this group are the Anglo-Burmese. Once forming a large and influential community, the Anglo-Burmese left the country in steady streams from 1958 onwards, principally to Australia and the UK. It is estimated that 52,000 Anglo-Burmese remain in Burma. s of 2009[ [update]], 110,000 Burmese refugees were living in refugee camps in Thailand.
Refugee camps exist along Indian, Bangladeshi and Thai borders while several thousand are in Malaysia. Conservative estimates state that there are over 295,800 refugees from Burma, with the majority being Karenni, and Kayin and are principally located along the Thai-Burma border. There are nine permanent refugee camps along the Thai-Burma border, most of which were established in the mid-1980s. The refugee camps are under the care of the . Since 2006, over 55,000 Burmese refugees have been resettled in the United States.
The persecution of Burmese Indians and other ethnic groups after the military coup headed by General Ne Win in 1962 led to the expulsion or emigration of 300,000 people. They migrated to escape racial discrimination and the wholesale nationalisation of private enterprise that took place in 1964. The Anglo-Burmese at this time either fled the country or changed their names and blended in with the broader Burmese society.
Many Rohingya Muslims fled Burma. Many refugees headed to neighbouring Bangladesh, including 200,000 in 1978 as a result of the King Dragon operation in Arakan. 250,000 more left in 1991.
Languages.
Burma is home to four major language families: Sino-Tibetan, Tai–Kadai, Austro-Asiatic, and Indo-European. Sino-Tibetan languages are most widely spoken. They include Burmese, Karen, Kachin, Chin, and Chinese. The primary Tai–Kadai language is Shan. Mon, Palaung, and Wa are the major Austroasiatic languages spoken in Burma. The two major Indo-European languages are Pali, the liturgical language of Theravada Buddhism, and English.
Burmese, the mother tongue of the Bamar and official language of Burma, is related to Tibetan and to the Chinese languages. It is written in a script consisting of circular and semi-circular letters, which were adapted from the Mon script, which in turn was developed from a southern Indian script in the 5th century. The earliest known inscriptions in the Burmese script date from the 11th century. It is also used to write Pali, the sacred language of Theravada Buddhism, as well as several ethnic minority languages, including Shan, several Karen dialects, and Kayah (Karenni), with the addition of specialised characters and diacritics for each language.
The Burmese language incorporates widespread usage of honorifics and is age-oriented. Burmese society has traditionally stressed the importance of education. In villages, secular schooling often takes place in monasteries. Secondary and tertiary education take place at government schools.
Religion.
Many religions are practised in Burma. Religious edifices and orders have been in existence for many years. Festivals can be held on a grand scale. The Christian and Muslim populations do, however, face religious persecution and it is hard, if not impossible, for non-Buddhists to join the army or get government jobs, the main route to success in the country. Such persecution and targeting of civilians is particularly notable in Eastern Burma, where over 3000 villages have been destroyed in the past ten years. More than 200,000 Rohingya Muslims have fled to Bangladesh over the last 20 years to escape persecution.
A large majority of the population practices Buddhism; estimates range from 80% to 89%. Theravāda Buddhism is the most widespread. Other religions are practised largely without obstruction, with the notable exception of some ethnic minorities such as the Muslim Rohingya people, who have continued to have their citizenship status denied and treated as illegal immigrants instead, and Christians in Chin State.
Four percent of the population practices Islam; 4% Christianity; 1% traditional animistic beliefs; and 2% follow other religions, including Mahayana Buddhism, Hinduism, and East Asian religions. However, according to a US State Department's 2010 international religious freedom report, official statistics are alleged to underestimate the non-Buddhist population. Independent researchers put the Muslim population at 6 to 10% of the population. A tiny Jewish community in Rangoon had a synagogue but no resident rabbi to conduct services.
Although Hinduism is practised by 1% of the population, it was a major religion in Burma's past. Several strains of Hinduism existed alongside both Theravada Buddhism and Mahayana Buddhism in the Mon and Pyu period in the first millennium CE, and down to the Pagan period (9th to 13th centuries) when "Saivite and Vaishana elements enjoyed greater elite influence than they would later do."
Health.
The general state of health care in Myanmar (Burma) is poor. The government spends anywhere from 0.5% to 3% of the country's GDP on health care, consistently ranking among the lowest in the world. Although health care is nominally free, in reality, patients have to pay for medicine and treatment, even in public clinics and hospitals. Public hospitals lack many of the basic facilities and equipment.
HIV/AIDS, recognised as a disease of concern by the Burmese Ministry of Health, is most prevalent among sex workers and intravenous drug users. In 2005, the estimated adult HIV prevalence rate in Burma was 1.3% (200,000–570,000 people), according to UNAIDS, and early indicators of any progress against the HIV epidemic are inconsistent. However, the National AIDS Programme Burma found that 32% of sex workers and 43% of intravenous drug users in Burma have HIV.
Burma's government spends the least percentage of its GDP on health care of any country in the world, and international donor organisations give less to Burma, per capita, than any other country except India. According to the report named "Preventable Fate", published by Doctors without Borders, 25,000 Burmese AIDS patients died in 2007, deaths that could largely have been prevented by antiretroviral therapy drugs and proper treatment.
The 2010 maternal mortality rate per 100,000 births for Myanmar is 240. This is compared with 219.3 in 2008 and 662 in 1990. The under 5 mortality rate, per 1,000 births is 73 and the neonatal mortality as a percentage of under 5's mortality is 47.
Education.
According to the UNESCO Institute of Statistics, Burma's official literacy rate as of 2000 was 90%. Historically, Burma has had high literacy rates. To qualify for least developed country status by the UN to receive debt relief, Burma lowered its official literacy rate from 79% to 19% in 1987. 
The educational system of Burma is operated by the government agency, the Ministry of Education. The education system is based on the United Kingdom's system due to nearly a century of British and Christian presences in Burma. Nearly all schools are government-operated, but there has been a recent increase in privately funded English language schools. Schooling is compulsory until the end of elementary school, approximately about 9 years old, while the compulsory schooling age is 15 or 16 at international level.
There are 101 universities, 12 institutes, 9 degree colleges and 24 colleges in Burma, a total of 146 higher education institutions. There are 10 Technical Training Schools, 23 nursing training schools, 1 sport academy and 20 midwifery schools. There are 2047 Basic Education High Schools, 2605 Basic Education Middle Schools, 29944 Basic Education Primary Schools and 5952 Post Primary Schools. 1692 multimedia classrooms exist within this system.
There are four international schools acknowledged by WASC and College Board—The International School Yangon (ISY), Crane International School Yangon (CISM), Yangon International School (YIS) and International School of Myanmar (ISM) in Yangon.
Crime.
In 2012, Burma had a murder rate of 15.2 per 100,000 population. There were a total of 8,044 murders in Burma in 2012. Factors influencing Burma's high murder rate include communal violence and armed conflict. Burma is one of the world's most corrupt nations. The 2012 Transparency International Corruption Perceptions Index ranked the country at number 171, out of 176 countries in total.
Burma is the world's second largest producer of opium after Afghanistan, producing some 25% of the world's opium, and forms part of the Golden Triangle. The opium industry was a monopoly during colonial times and has since been illegally operated by corrupt officials in the Burmese military and rebel fighters, primarily as the basis for heroin manufacture.
Burma is the largest producer of methamphetamines in the world, with the majority of "Ya ba" found in Thailand produced in Burma, particularly in the Golden Triangle and Northeastern Shan State, which borders Thailand, Laos and China. Burmese-produced "ya ba" is typically trafficked to Thailand via Laos, before being transported through the northeastern Thai region of Isan.
Culture.
A diverse range of indigenous cultures exist in Burma, the majority culture is primarily Buddhist and Bamar. Bamar culture has been influenced by the cultures of neighbouring countries. This is manifested in its language, cuisine, music, dance and theatre. The arts, particularly literature, have historically been influenced by the local form of Theravada Buddhism. Considered the national epic of Burma, the "Yama Zatdaw", an adaptation of India's "Ramayana", has been influenced greatly by Thai, Mon, and Indian versions of the play. Buddhism is practised along with nat worship, which involves elaborate rituals to propitiate one from a pantheon of 37 nats.
In a traditional village, the monastery is the centre of cultural life. Monks are venerated and supported by the lay people. A novitiation ceremony called shinbyu is the most important coming of age events for a boy, during which he enters the monastery for a short time. All male children in Buddhist families are encouraged to be a novice (beginner for Buddhism) before the age of twenty and to be a monk after the age of twenty. Girls have ear-piercing ceremonies (နားသ) at the same time. Burmese culture is most evident in villages where local festivals are held throughout the year, the most important being the pagoda festival. Many villages have a guardian nat, and superstition and taboos are commonplace.
British colonial rule introduced Western elements of culture to Burma. Burma's education system is modelled after that of the United Kingdom. Colonial architectural influences are most evident in major cities such as Yangon. Many ethnic minorities, particularly the Karen in the southeast and the Kachin and Chin who populate the north and northeast, practice Christianity. According to the The World Factbook, the Burman population is 68% and the ethnic groups constitute 32%. However, the exiled leaders and organisations claims that ethnic population is 40%, which is implicitly contrasted with CIA report (official US report).
Cuisine.
Burmese cuisine is characterized by extensive use of fish products like fish sauce and ngapi (fermented seafood).
Mohinga is the traditional breakfast dish and is considered by many to be Burma's national dish. Seafood is a common ingredient in coastal cities such as Sittwe, Kyaukpyu, Mawlamyaing (formerly Moulmein), Mergui (Myeik) and Dawei, while meat and poultry are more commonly used in landlocked cities like Mandalay. Freshwater fish and shrimp have been incorporated into inland cooking as a primary source of protein and are used in a variety of ways, fresh, salted whole or filleted, salted and dried, made into a salty paste, or fermented sour and pressed.
Burmese cuisine also includes a variety of salads ("a thoke"), centered on one major ingredient, ranging from starches like rice, wheat and rice noodles, glass noodles and vermicelli, to potato, ginger, tomato, kaffir lime, long bean, lahpet (pickled tea leaves), and ngapi (fish paste).
Art.
Burmese contemporary art has developed rather on its own terms and quite rapidly.
One of the first to study western art was Ba Nyan. Together with Ngwe Gaing and a handful of other artists, they were pioneers of western painting style in Burma. Later, most of the students learnt from masters through apprenticeship. Some well known contemporary artists are Lun Gywe, Aung Kyaw Htet, MPP Yei Myint, Myint Swe, Min Wai Aung, Aung Myint, Khin Maung Yin, Po Po and Zaw Zaw Aung.
Most of the young artists who were born in the 1980s have greater chances of art practises inside and outside the country. Performance art is a popular genre among Burmese young artists.
Media and communications.
Due to Burma's political climate, there are not many media companies in relation to the country's population, although a certain number exists. Some are privately owned. All programming must meet with the approval of the censorship board.
The Burmese government announced on 20 August 2012 that it will stop censoring media before publication. Following the announcement, newspapers and other outlets no longer required approved by state censors; however, journalists in the country can still face consequences for what they write and say.
In April 2013, international media reports were published to relay the enactment of the media liberalisation reforms that we announced in August 2012. For the first time in numerous decades, the publication of privately owned newspapers commenced in the country.
Internet.
Internet use is estimated to be relatively low compared to other countries. Activity at internet cafes is regulated. There had been censorship, and authorities view e-mail and posts on Internet blogs until 2012 when government removed censorship in media. During the strict censorship days, one blogger named Zarganar, was sentenced to a few years in prison for publishing a video of destruction caused by the Cyclone Nargis in 2008; Zarganar was released in October 2011.
In regards to communications infrastructure, Myanmar is the last ranked Asian country in the World Economic Forum's Network Readiness Index (NRI) – an indicator for determining the development level of a country's information and communication technologies. With 148 countries reported on, Myanmar ranked number 146 overall in the 2014 NRI ranking. No data is currently available for previous years.
Film.
Burma's first film was a documentary of the funeral of Tun Shein — a leading politician of the 1910s, who campaigned for Burmese independence in London. The first Burmese silent film Myitta Ne Thuya (Love and Liquor) in 1920 which proved a major success, despite its poor quality due to a fixed camera position and inadequate film accessories. During the 1920s and 1930s, many Burmese-owned film companies made and produced several films. The first Burmese sound film was produced in 1932 in Bombay, India with the title Ngwe Pay Lo Ma Ya (Money Can't Buy It). After World War II, Burmese cinema continued to address political themes. Many of the films produced in the early Cold War era had a strong propaganda element to them.
In the era that followed the political events of 1988, the film industry has been increasingly controlled by the government. Film stars who had been involved in the political activities were banned from appearing in films. The government issues strict rules on censorship and largely determines who produces films, as well as who gets academy awards.
Over the years, the movie industry has also shifted to producing many lower budget direct-to-video films.
Most of the movies produced nowadays are comedies. In 2008, only 12 films worthy of being considered for an Academy Award were made, although at least 800 VCDs were produced.
Burma is the primary subject of a 2007 graphic novel titled "Chroniques Birmanes" by Québécois author and animator, Guy Delisle. The graphic novel was translated into English under the title "Burma Chronicles" in 2008. In 2009, a documentary about Burmese videojournalists called "Burma VJ" was released. This film was nominated for Best Documentary Feature at the 2010 Academy Awards. The Lady (2011 film) had its world premiere on 12 September 2011 at the 36th Toronto International Film Festival.
Sport.
The Lethwei, Bando, Banshay, Pongyi thaing martial arts and chinlone are the national sports in Burma.
The 2013 Southeast Asian Games took place in Naypyidaw, Yangon, Mandalay and Ngwesaung Beach in December representing the third occasion that the event has been staged in Burma. Burma previously hosted the Games in 1961 and 1969.

</doc>
<doc id="19458" url="http://en.wikipedia.org/wiki?curid=19458" title="Mediterranean (disambiguation)">
Mediterranean (disambiguation)

The Mediterranean Sea is a major body of water south of Europe, west of Asia and north of Africa.
Mediterranean or Mediterranean sea may also refer to:

</doc>
<doc id="19459" url="http://en.wikipedia.org/wiki?curid=19459" title="May 24">
May 24

May 24 is the day of the year in the Gregorian calendar.

</doc>
<doc id="19495" url="http://en.wikipedia.org/wiki?curid=19495" title="Poland Is Not Yet Lost">
Poland Is Not Yet Lost

"Mazurek Dąbrowskiego" (], "Dąbrowski's Mazurka") is the national anthem of Poland. It is also known by its original title, "Pieśń Legionów Polskich we Włoszech" (], "Song of the Polish Legions in Italy"). English translations of its Polish incipit ("Jeszcze Polska nie zginęła" ]) include: "Poland has not yet perished", "Poland has not perished yet", "Poland is not lost", "Poland is not lost yet", and "Poland is not yet lost". 
The lyrics were written by Józef Wybicki in Reggio Emilia, Cisalpine Republic in Northern Italy, between 16 and 19 of July, 1797, two years after the Third Partition of Poland erased the Polish–Lithuanian Commonwealth from the map. It was originally meant to boost the morale of Polish soldiers serving under General Jan Henryk Dąbrowski's Polish Legions that served with Napoleon's French Revolutionary Army in the Italian campaigns of the French Revolutionary Wars. "Dabrowski's Mazurka", expressing the idea that the nation of Poland, despite lack of independence, had not disappeared as long as the Polish people were still alive and fighting in its name, soon became one of the most popular patriotic songs in Poland.
The music is an unattributed mazurka and considered a "folk tune" that Polish composer Edward Pałłasz categorizes as "functional art" which was "fashionable among the gentry and rich bourgeoisie". Pałłasz opined that, "Wybicki probably made use of melodic motifs he had heard and combined them in one formal structure to suit the text".
It is "one of the most important songs of the Slavic nations." The "text of the hymn was modified to suit new occasions and socio-political contexts" throughout the songs history. When Poland re-emerged as an independent state in 1918, "Dabrowski's Mazurka" became its "de facto" anthem. It was officially adopted as the national anthem of the Republic of Poland in 1926. It also inspired similar songs by other peoples struggling for independence during the 19th century. One such anthem is "Hey Slavs".
Lyrics.
The original lyrics, authored by Wybicki, were a poem consisting of six stanzas and a chorus repeated after all but last stanzas, all following an ABAB rhyme scheme. The official lyrics, based on a variant from 1806,
show a certain departure from the original text. It misses two of the original stanzas and reverses the order of other two. Notably, the initial verse, "Poland has not yet died" was replaced with "Poland has not yet perished", suggesting a more violent cause of the nation's possible death. Wybicki's original manuscript was in the hands of his descendants until February 1944, when it was lost in Wybicki's great-great-grandson, Johann von Roznowski's home in Charlottenburg during the Allied bombing of Berlin. The manuscript is known today only from facsimile copies, twenty four of which were made in 1886 by Edward Rożnowski, Wybicki's grandson, who donated them to Polish libraries.
The main theme of the poem is the idea that was novel in the times of early nationalisms based on centralized nation-states – that the lack of political sovereignty does not preclude the existence of a nation. As Adam Mickiewicz explained in 1842 to students of Slavic Literature in Paris, the song "The famous song of the Polish legions begins with lines that express the new history: Poland has not perished yet as long as we live. These words mean that people who have in them what constitutes the essence of a nation can prolong the existence of their country regardless of its political circumstances and may even strive to make it real again..." The song also includes a call to arms and expresses the hope that, under General Dąbrowski's command, the legionaries would rejoin their nation and retrieve "what the alien force has seized" through armed struggle.
The chorus and subsequent stanzas include heart-lifting examples of military heroes, set as role models for Polish soldiers: Jan Henryk Dąbrowski, Napoleon, Stefan Czarniecki and Tadeusz Kościuszko. Dąbrowski, for whom the anthem is named, was a commander in the failed 1794 Kościuszko Uprising against Russia. After the Third Partition in 1795, he came to Paris to seek French aid in re-establishing Polish independence and, in 1796, he started the formation of the Polish Legions, a Polish unit of the French Revolutionary Army. Bonaparte was, at the time when the song was written, a commander of the Italian campaign of French Revolutionary Wars and Dąbrowski's superior. Having already proven his skills as a military leader, he is described in the lyrics as the one "who has shown us ways to victory." Bonaparte is the only non-Polish person mentioned by name in the Polish anthem.
Stefan Czarniecki was a 17th-century hetman (military commander), famous for his role in driving the Swedish army out of Poland after an occupation that had left the country in ruins and is remembered by Poles as the Deluge. With the outbreak of a Dano-Swedish War, he continued his fight against Sweden in Denmark, from where he "returned across the sea" to fight the invaders alongside the king who was then at the Royal Castle in Poznań. In the same castle, Józef Wybicki, started his career as a lawyer (in 1765). Kościuszko, mentioned in a stanza now missing from the anthem, became a hero of the American Revolutionary War before coming back to Poland to defend his native country from Russia in the war of 1792 and a national uprising he led in 1794. One of his major victories during the uprising was the Battle of Racławice where the result was partly due to Polish peasants armed with scythes. Alongside the scythes, the song mentioned other types of weaponry, traditionally used by the Polish "szlachta", or nobility: the sabre, known in Polish as "szabla", and the backsword.
Basia (a female name, diminutive of Barbara) and her father are fictional characters. They are used to represent the women and elderly men who waited for the Polish soldiers to return home and liberate their fatherland. The route that Dąbrowski and his legions hoped to follow upon leaving Italy is hinted at by the words "we'll cross the Vistula, we'll cross the Warta", two major rivers flowing through the parts of Poland that were in Austrian and Prussian hands at the time.
Music.
The melody of the Polish anthem is a lively and rhythmical mazurka. Mazurka as a musical form derives from the stylization of traditional melodies for the folk dances of Masovia, a region in central Poland. It is characterized by a triple meter and strong accents placed irregularly on the second or third beat. Considered one of Poland's national dances in pre-partition times, it owes its popularity in 19th-century West European ballrooms to the mazurkas of Frédéric Chopin.
The composer of "Mazurek Dąbrowskiego" is unknown. The melody is most probably Wybicki's adaptation of a folk tune that had already been popular during the second half of the 18th century. The composition used to be erroneously attributed to Michał Kleofas Ogiński who was known to have written a march for Dąbrowski's legions. Several historians confused Ogiński's "Marche pour les Légions polonaises" ("March for the Polish Legions") with Wybicki's mazurka, possibly due to the mazurka's chorus "March, march, Dąbrowski", until Ogiński's sheet music for the march was discovered in 1938 and proven to be a different piece of music than Poland's national anthem.
The first composer, who used the anthem for an artistical music piece, was Karol Kurpiński. In 1821 he composed his piano/organ Fugue on "Jeszcze Polska nie zginęła" (it was published in 1821 in Warsaw; the first modern edition by Rostislaw Wygranienko was printed only in 2009).
Wojciech Sowiński was the next who arranged "Mazurek Dąbrowskiego" for the piano. The arrangement, accompanied by the lyrics in Polish and French, was published 1829 in Paris. The current official musical score of the national anthem was arranged by Kazimierz Sikorski and published by the Polish Ministry of Culture and National Heritage. Sikorski's harmonization allows for each vocal version to be performed either "a cappella" or together with any of the instrumental versions. Some orchestra parts, marked in the score as "ad libitum", may be left out or replaced by other instruments of equivalent musical scale.
In 1908, Ignacy Jan Paderewski, later to become the first Prime Minister of independent Poland, quoted the anthem in a disguised way in his Symphony in B minor "Polonia". He scored it in duple meter rather than its standard triple meter.
Regulations.
The national anthem is, along with the national coat of arms and the national colors, one of three national symbols defined by the Polish constitution.
As such, it is protected by law which declares that treating the national symbols "with reverence and respect" is the "right and obligation" of every Polish citizen and all state organs, institutions and organizations. The anthem should be performed or reproduced especially at celebrations of national holidays and anniversaries. Civilians should pay respect to the anthem by standing in a dignified manner; additionally, men should uncover their heads. Members of uniformed services should stand at attention; if their uniform includes headgear and they are not standing in an organized group, they should also perform the two-finger salute. Color guards pay respect to the anthem by dipping their banners.
History.
Origin.
In 1795, after a prolonged decline and despite last-minute attempts at constitutional reforms and armed resistance, the Polish-Lithuanian Commonwealth was ultimately partitioned by its three neighbors: Russia, Prussia and Austria. A once vast and powerful empire was effectively erased from the map while monarchs of the partitioning powers pledged never to use the name "Poland" in their official titles. For many, including even leading representatives of the Polish Enlightenment, this new political situation meant an end of the Polish nation. In the words of Hugo Kołłątaj, a notable Polish political thinker of the time, "Poland no longer belonged to currently extant nations," while historian Tadeusz Czacki declared that Poland "was now effaced from the number of nations."
Meanwhile, Polish patriots and revolutionaries turned for help to France, Poland's traditional ally, which was at war with Austria (member of the First Coalition) at the time. Józef Wybicki was among the leading moderate émigré politicians seeking French aid in re-establishing Polish independence. In 1796, he came up with the idea of creating Polish Legions within the French Revolutionary Army. To this end, he convinced General Jan Henryk Dąbrowski, a hero of the Greater Poland campaign of the 1794 Kościuszko Uprising, to come to Paris and present the plan to the French Directory. Dąbrowski was sent by the Directory to Napoleon who was then spreading the French Revolution in northern Italy. In January 1797, the newly created French-controlled Cisalpine Republic accepted Dąbrowski's offer and a Polish legion was formed. Dąbrowski and his soldiers hoped to fight against Austria under Napoleon and, subsequently, march across the Austrian territory, "from Italy to Poland," where they would ignite a national uprising.
In early July 1797, Wybicki arrived in Reggio Emilia where the Polish Legions were then quartered and where he wrote the "Song of the Polish Legions" soon afterwards. He first sung it at a private meeting of Polish officers in the Legions' headquarters at the episcopal palace in Reggio. The first public performance most probably took place on 16 July 1797 during a military parade in Reggio's Piazza del Duomo (Cathedral Square). On 20 July, it was played again as the Legions were marching off from Reggio to Milan, the Cisalpine capital.
With its heart-lifting lyrics and folk melody, the song soon became a popular tune among Polish legionaries. On 29 August 1797, Dąbrowski already wrote to Wybicki from Bologna: "soldiers gain more and more taste for your song." It appealed to both officers, usually émigré noblemen, and simple soldiers, most of whom were Galician peasants who had been drafted into the Austrian army and captured as POWs by the French. The last stanza, referring to Kościuszko, who famously fought for freedom of the entire nation rather than the nobility alone, and the "scythes of Racławice", seems to be directed particularly at the latter. Wybicki may have even hoped for Kościuszko to arrive in Italy and personally lead the Legions which might explain why the chorus "March, march, Dąbrowski" is not repeated after the last stanza. At that time Wybicki was not yet aware that Kościuszko had already returned to Philadelphia.
Rising popularity.
The song became popular in Poland as soon as late 1797 and quickly became an object of variations and modifications. A variant from 1798 introduced some stylistic changes, which have since become standard, such as replacing "nie umarła" ("not dead") with "zginęła" ("not perished") or "do Polski z ziemi włoski" ("to Poland from the Italian land") with "z ziemi włoskiej do Polski" ("from the Italian land to Poland"). It also added four new stanzas, now forgotten, written from the viewpoint of Polish patriots waiting for General Dąbrowski to bring freedom and human rights to Poland.
The ultimate fate of the Polish Legions in Italy was different from that promised by Wybicki's song. Rather than coming back to Poland, they were exploited by the French government to quell uprisings in Italy, Germany and, later, in Haiti where they were decimated by war and disease. Polish national hopes were revived with the outbreak of a Franco-Prussian war (part of the War of the Fourth Coalition) in 1806. Napoleon called Dąbrowski and Wybicki to come back from Italy and help gather support for the French army in Polish-populated parts of Prussia. On 6 November 1806, both generals arrived in Poznań, enthusiastically greeted by locals singing "Poland Is Not Yet Lost". The ensuing Greater Poland Uprising and Napoleon's victory over Russian forces at Friedland led to the creation of a French-controlled Polish puppet state known as the Duchy of Warsaw.
"Poland Is Not Yet Lost" was one of the most popular patriotic songs in the duchy, stopping short of becoming that entity's national anthem. Among other occasions, it was sung in Warsaw on 16 June 1807 to celebrate the battle of Friedland, in Kraków as it was liberated by Prince Józef Poniatowski on 19 July 1809, and at a ball in Warsaw on 23 December 1809, the birthday of Frederick Augustus, King of Saxony and Duke of Warsaw. On the occasion of Dąbrowski's name day on 25 December 1810 in Poznań, Dąbrowski and Wybicki led the mazurka to the tune of "Poland Is Not Yet Lost". Although the melody of Wybicki's song remained unchanged and widely known, the lyrics kept changing. With the signing of a Franco-Russian alliance at Tilsit in 1807, the fourth stanza, specifically mentioning Russians as Poland's enemies, was removed. The last stanza, referring to Kościuszko, who had grown suspicious of Napoleon and refused to lend his support to the emperor's war in Poland, met the same fate.
The anthem is mentioned twice in "Pan Tadeusz", the Polish national epic written by Adam Mickiewicz in 1834, but set in the years 1811–1812. The author makes the first reference to the song when Tadeusz, the main protagonist, returns home and, recalling childhood memories, pulls the string of a chiming clock to hear the "old Dąbrowski's Mazurka" once again. Musical boxes and musical clocks playing the melody of "Poland Is Not Yet Lost" belonged to popular patriotic paraphernalia of that time. The song appears in the epic poem again when Jankiel, a Jewish dulcimerist and ardent Polish patriot, plays the mazurka in the presence of General Dąbrowski himself.
With Napoleon's defeat and the Congress of Vienna in 1815 came a century of foreign domination over Poland interspersed with occasional bursts of armed rebellion. "Poland Is Not Yet Lost" continued to be sung throughout that period, especially during national uprisings. During the November Uprising against Russia in 1830−1831, the song was chanted in the battlefields of Stoczek, Olszynka Grochowska and Iganie. In peacetime, Polish patriots performed it at homes, official functions and political demonstrations. New variants of the song, of various artistic value and length of life, abounded. At least 16 alternative versions were penned during the November Uprising alone. At times, Dąbrowski's name was replaced by other national heroes: from Józef Chłopicki during the November Uprising to Józef Piłsudski during the First World War to Władysław Sikorski during the Second World War. New lyrics were also written in regional dialects of Polish, from Silesia to Ermland and Masuria. A variant known as "Marsz Polonii" ("March Polonia") spread among Polish immigrants in the Americas.
Mass political emigration following the defeat of the November Uprising, known as the Great Emigration, brought "Poland Is Not Yet Lost" to Western Europe. It soon found favor from Britain to France to Germany where it was performed as a token of sympathy with the Polish cause. It was also highly esteemed in Central Europe where various, mostly Slavic, peoples struggling for their own independence, looked to the Polish anthem for inspiration. Back in Poland, however, especially in the parts under Russian and Prussian rule, it was becoming increasingly risky to sing the anthem in public. Polish patriotic songs were banned in Prussia in 1850; between 1873 and 1911, German courts passed 44 sentences for singing such songs, 20 of which were specifically for singing "Poland Is Not Yet Lost". In Russian Poland, public performance of the song often ended with a police intervention.
Choice of national anthem.
When Poland re-emerged as an independent nation after the First World War in 1918, it had to make a decision about its national symbols. While the coat of arms and the flag were officially adopted as soon as 1919, the question of a national anthem had to wait. Apart from "Poland Is Not Yet Lost", there were other popular patriotic songs which could compete for the status of an official national anthem.
In the Middle Ages, the role of a national anthem was played by hymns. Among them were "Bogurodzica" ("Mother of God"), one of the oldest (11th-12th century) known literary texts in Polish, and the Latin "Gaude Mater Polonia" ("Rejoice, Mother Poland"), written in the 13th century to celebrate the canonization of Bishop Stanislaus of Szczepanów, the patron saint of Poland. Both were chanted on special occasions and on battlefields. The latter is sung nowadays at university ceremonies. During the Renaissance and the Enlightenment, several songs, both religious and secular, were written with the specific purpose of creating a new national anthem. Examples include the 16th-century Latin prayer "Oratio pro Republica et Rege" ("Prayer for the Commonwealth and the King") by a Calvinist poet, Andrzej Trzeciński, and "Hymn do miłości Ojczyzny" ("Hymn to the Love of the Fatherland") written in 1744 by Prince-Bishop Ignacy Krasicki. They failed, however, to win substantial favor with the populace. Another candidate was "Bóg się rodzi" ("God is Born"), whose melody was originally a 16th-century coronation polonaise for Polish kings.
The official anthem of the Russian-controlled Congress Kingdom of Poland was "Pieśń narodowa na pomyślność Króla" ("National Song to the King's Well-being") written in 1816 by Alojzy Feliński and Jan Kaszewski. Initially unpopular, it evolved in the early 1860s into an important religious and patriotic hymn. The final verse, which originally begged "Save, Oh Lord, our King", was substituted with "Return us, Oh Lord, our free Fatherland" while the melody was replaced with that of a Marian hymn. The result, known today as "Boże, coś Polskę" ("God Save Poland"), has been sung in Polish churches ever since, with the final verse alternating between "Return..." and "Bless, Oh Lord, our free Fatherland", depending on Poland's political situation.
A national song that was particularly popular during the November Uprising was "Warszawianka", originally written in French as "La Varsovienne" by Casimir Delavigne, with melody by Karol Kurpiński. The song praised Polish insurgents taking their ideals from the French July Revolution of 1830. A peasant rebellion against Polish nobles, which took place in western Galicia in 1846 and was encouraged by Austrian authorities who wished to thwart a new uprising attempt, moved Kornel Ujejski to write a mournful chorale entitled "Z dymem pożarów" ("With the Smoke of Fires"). With the music composed by Józef Nikorowicz, it became one of the most popular national songs of the time, although it declined into obscurity during the 20th century. In 1908, Maria Konopnicka and Feliks Nowowiejski created "Rota" ("The Oath"), a song protesting against the oppression of the Polish population of the German Empire, who were subject to eviction from their land and forced assimilation. First publicly performed in 1910, during a quincentennial celebration of the Polish-Lithuanian victory over the Teutonic Knights at Grunwald, it too became one of the most treasured national Polish songs.
At the inauguration of the UN in 1945, no delegation from Poland had been invited.(p12), both the United States and United Kingdom withdrew their recognition of the Polish government-in-exile as the legitimate government of Poland.(p33) Poland was the 51st nation to sign the "United Nations Charter" on none.|name=CoUN|group=lower-alpha
 |, both the United States and United Kingdom withdrew their recognition of the Polish government-in-exile as the legitimate government of Poland.(p33) Poland was the 51st nation to sign the "United Nations Charter" on none }}.|group=lower-alpha
}} The Polish pianist Artur Rubinstein, who was to perform the opening concert at the inauguration, began the concert by stating his deep disappointment that the conference did not have a delegation from Poland. Rubinstein later described becoming overwhelmed by a blind fury and angrily pointing out to the public the absence of the Polish flag. He then sat down to the piano and played "Poland Is Not Yet Lost" loudly and slowly, repeating the final part in a great thunderous "forte". When he had finished, the public rose to their feet and gave him a great ovation.
Over 60 years later, on none }}, Aleksander Kwaśniewski, President of Poland, said: For the UN is rightly criticised for being anachronistic, for reflecting the old world that is drifting away into the past. Particularly we, the Polish people, and all the nations of Central and Eastern Europe find it difficult to forget about that. The UN idea dates back to 1943; to the meeting of the "Big Three" in Tehran; to the illusions that Roosevelt harboured about Stalin, benevolently nicknamed "Uncle Joe". As a result, the road to San Francisco led via Yalta. And even though Poland had made a major contribution to the victory which put an end to the Second World War, in June 1945 a representative of our country was not allowed to put his signature to the United Nations Charter. We remember that event when Artur Rubinstein, seeing that there was no Polish delegation at the concert to mark the signing of the Charter, decided to play the Dąbrowski Mazurka, Poland's national anthem, to demonstrate that "Poland was not lost yet", that Poland lived on. I am recalling this because I had a very touching moment a few days ago in the same San Francisco opera house, to which I was invited for the opening of the season. This time it was the orchestra that played the Dąbrowski Mazurka, and at that moment the memories of the great Artur Rubinstein and his performance came back with full force and it was very touching indeed for me. The UN is rooted in the Second World War and in the post-war situation; it reflects the balance of power of that era.
Influence.
During the European Revolutions of 1848, "Poland Is Not Yet Lost" won favor throughout Europe as a revolutionary anthem. This led the Slovak poet Samo Tomášik to write the anthem, "Hey Slavs", based on the melody of the Polish anthem. This was later adopted by the First Congress of the Pan-Slavic Movement in Prague as the Pan-Slavic Anthem. During the Second World War, a translation of this anthem became the national anthem of Yugoslavia, and later, Serbia and Montenegro. The similarity of the anthems sometimes caused confusion during these countries' football or volleyball matches. However, after the 2006 split between the two, neither Serbia nor Montenegro kept the song as its national anthem, instead choosing "Bože pravde" and "Oj, svijetla majska zoro" respectively. The Polish anthem is also notable for influencing the lyrics of the Ukrainian anthem, "Shche ne vmerla Ukraina" ("Ukraine's glory has not yet perished").

</doc>
<doc id="19496" url="http://en.wikipedia.org/wiki?curid=19496" title="Mahjong">
Mahjong

Mahjong, also spelled majiang, mah jongg, and numerous other variants, is a game that originated in China. It is commonly played by four players (with some three-player variations found in South Korea and Japan). The game and its regional variants are widely played throughout Eastern and South Eastern Asia and have a small following in Western countries. Similar to the Western card game rummy, mahjong is a game of skill, strategy, and calculation and involves a degree of chance.
The game is played with a set of 144 tiles based on Chinese characters and symbols, although some regional variations use a different number of tiles. In most variations, each player begins by receiving 13 tiles. In turn players draw and discard tiles until they complete a legal hand using the 14th drawn tile to form four groups (melds) and a pair (head). There are fairly standard rules about how a piece is drawn, how a piece is stolen from another player and thus melded, the use of simples (numbered tiles) and honors (winds and dragons), the kinds of melds, and the order of dealing and play. However there are many regional variations in the rules; in addition, the scoring system and the minimum hand necessary to win varies significantly based on the local rules being used.
Name.
In Chinese, the game was originally called 麻雀 ()—meaning sparrow—which is still the name most commonly used in some southern Chinese languages such as Cantonese and Min Nan, as well as in Japanese. However, most Mandarin-speaking Chinese now call the game "májiàng" (麻將). In Northern Wu Chinese (Shanghainese and its relatives), it is pronounced as 麻將 ], but in actuality, 麻將 is the diminutive form of 麻雀, written as 麻雀兒 ], due to an erhua event. It is through the Wu Chinese pronunciation of 麻雀兒 that the diminutive form of 麻雀 in Northern Wu became known as 麻將 in both Mandarin and Wu.
History.
China.
One of the myths of the origin of mahjong suggests that Confucius, the Chinese philosopher, developed the game in about 500 BC. The three dragon (cardinal) tiles also agree with the three cardinal virtues bequeathed by Confucius. "Hóng Zhōng" (紅中 , red middle), "Fā Cái" (發財 , prosperity), and "Bái Bǎn"" (白板 , white board) represent benevolence, sincerity, and filial piety, respectively.
The myth also claims that Confucius was fond of birds, which would explain the name "mahjong" (maque 麻雀 = hemp sparrow).
Many historians believe it was based on a Chinese card game called "Mǎ diào" (馬吊) (also known as "Ma Tiae", hanging horse; or "Yèzí" [葉子], leaf) in the early Ming dynasty. This game was played with 40 paper cards similar in appearance to the cards used in the game Ya Pei. These 40 cards are numbered 1 to 9 in four different suits, along with four extra flower cards. This is quite similar to the numbering of mahjong tiles today, although mahjong only has three suits and, in effect, uses four packs of Ya Pei cards.
During the early 19th century and perhaps as early as 18th century, there was a Chinese card game with principle of drawing and discarding with a view to melding and is in fact essence of mahjong.
There is still some debate about who created the game. One theory is that Chinese army officers serving during the Taiping Rebellion created the game to pass the time. Another theory is that a nobleman living in the Shanghai area created the game between 1870 and 1875. Others believe that two brothers from Níngpō created mahjong around 1850, from the earlier game of Mǎ diào.
This game was banned by the government of People's Republic of China when it took power in 1949. The new Communist government forbade any gambling activities, which were regarded as symbols of capitalist corruption. After the Cultural Revolution, the game was revived, without gambling elements, and the prohibition was revoked in 1985. Today, it is a favorite pastime in China and other Chinese-speaking communities.
Mahjong in the West.
The game was mentioned in Portuguese Jesuit accounts from the beginning of the 17th century. In 1895, British Sinologist William Henry Wilkinson wrote a paper which mentioned a set of cards known in central China by the name of "ma chioh", literally, hemp sparrow, which he maintained was the origin of the term mahjong. He did not state the specific Chinese language or dialect of his informant. By 1910, there were written accounts in many languages, including French and Japanese.
The game was imported to the United States in the 1920s. The first mahjong sets sold in the U.S. were sold by Abercrombie & Fitch starting in 1920. It became a success in Washington, D.C., and the co-owner of the company, Ezra Fitch, sent emissaries to Chinese villages to buy every mahjong set they could find. Abercrombie & Fitch sold a total of 12,000 mahjong sets.
Also in 1920, Joseph Park Babcock published his book "Rules of Mah-Jongg", also known as the "red book". This was the earliest version of mahjong known in America. Babcock had learned mahjong while living in China. His rules simplified the game to make it easier for Americans to take up, and his version was common through the mahjong fad of the 1920s. Later, when the 1920s fad died out, many of Babcock's simplifications were abandoned.
The game has taken on a number of trademarked names, such as "Pung Chow" and the "Game of Thousand Intelligences". Mahjong nights in America often involved dressing and decorating rooms in Chinese style. Several hit songs were recorded during the mahjong fad, most notably "Since Ma Is Playing Mah Jong" by Eddie Cantor.
Many variants of mahjong developed during this period. By the 1930s, many revisions of the rules developed that were substantially different from Babcock's classical version (including some that were considered fundamentals in other variants, such as the notion of a standard hand). The most common form, which eventually became "American mahjong", was most popular among Jewish women. Standardization came with the formation of the National Mah Jongg League (NMJL) in 1937, along with the first American mahjong rulebook, "Maajh: The American Version of the Ancient Chinese Game."
Many consider the modern American version a remake of a Jewish game, as many American mahjong players are of Jewish descent. The NMJL was founded by Jewish players and is considered a Jewish organization. In 1986, the National Mah Jongg League conducted their first Mah Jongg Cruise Tournament, in conjunction with Mah Jongg Madness. In 2010, this large scale seagoing event hosted its 25th Silver Anniversary Cruise, with players from all over the States and Canada participating.
In recent years, a second organization has formed, the American Mah Jongg Association. The AMJA currently hosts tournaments all across North America, with their signature event being at the Trump Taj Mahal Casino Resort in Atlantic City, New Jersey.
British author Alan D. Millington revived the Chinese classical game of the 1920s with his book "The Complete Book of Mah-jongg" (1977). This handbook includes a formal rules set for the game.
A playing card form was published by an official of Britain's Consular Service named William Henry Wilkinson, author of "Chinese origin of playing cards", under the name Khanhoo.
Games scholar David Parlett has written that the Western card games Conquian and Rummy were derived from Mahjong. All these games involve players drawing and discarding tiles or cards to make melds.
Current development.
There are many governing bodies which often host exhibition games and tournaments for modern and traditional mahjong gaming.
Mahjong, as of 2010, is the most popular table game in Japan. As of 2008, there were approximately 7.6 million Mahjong players in Japan and an estimated 8,900 Mahjong parlors did ¥300 billion in sales. Many devotees there believe the game is losing popularity and have taken efforts to revive it. There are several manga and anime (e.g. Saki and Akagi) devoted to dramatic and comic situations involving mahjong. Since the 1980s, hundreds of different mahjong arcade machines in Japanese video arcades have been created, including strip versions. Newer units can connect with other arcade machines across the Internet.
Mahjong culture is still deeply ingrained in the Chinese community. Sam Hui wrote Cantopop songs using mahjong as their themes, and Hong Kong movies have often included scenes of mahjong games. Many gambling movies have been filmed in Hong Kong, and a recent subgenre is the mahjong movie.
Prolonged playing of mahjong may trigger epileptic seizures according to a 2007 study. To date there are 23 reported cases of mahjong-induced seizures in the English medical literature.
Studies by doctors have also shown in Hong Kong that the game is beneficial for individuals suffering from dementia or cognitive memory difficulties, leading to the development of mahjong therapy.
Type of game.
Because of the solid form of the tiles, mahjong is sometimes classified as a domino game but plays similar to card games such as rummy.
Old Hong Kong mahjong.
Old Hong Kong mahjong uses most of the standardised tiles, utilizes the basic features in common with most variations of the game and has a relatively simple scoring system.
Equipment.
Hong Kong Mahjong is played with a set of mahjong tiles (though cards may be used). Sets often include counters (to keep score), dice (to decide how to deal) and a marker to show who is dealer and which round is being played. Some sets include racks to hold tiles (if they are shaped small or differently).
A set of mahjong tiles usually has at least 136 tiles (most commonly 144), although sets originating from America or Japan will have more. Mahjong tiles are split into these categories: suits, honor, and flowers.
Simples.
There are three different suits numbered 1 to 9, which are called simple tiles. They are bamboo (bams), characters (or myriads or cracks), and circles (or dots).
There are four identical copies of each number of each suit giving 108 simple tiles (3x9x4).
Honors and bonus tiles.
There are two different honor suits: the winds and the dragons. The winds are east, south, west and north, and the dragons are Red, Green and White. They have no numerical sequence and there are four identical tiles of each wind and dragon (e.g. four Red dragon tiles, four Green dragon tiles etc.)
There are eight bonus tiles: four flowers and four seasons. Each flower and season tile is unique without three matching pieces as per simple tiles and honour tiles. These tiles are not part of a player's hand but are set to the side when drawn and an extra tile is drawn in lieu of the bonus tile.
Choosing table positions and first dealer.
The dealer is chosen by various means, either by throwing dice (the highest total takes the east wind), by placing one of each wind face down and having each player randomly select one of these tiles or other house rule variations. Each player sits down at their respective position (called the wind position) at the table in positions of an inverted compass: East is dealer, the right of the dealer is South, across is West and the left is North. The order essentially is counter-clockwise.
Hands, rounds, and matches.
A match consists of four rounds of which each round represents a "prevailing wind" starting with East. In each round at least four hands are played with each player taking the position of dealer. In the first hand of each round player 1 (winner of the dice toss) is east and therefore dealer. In the second hand, player 2 takes the east position shifting the seat winds amongst the players counter clockwise (though players don't physically move their chairs). A marker is used to mark which player is east and often the round number. This continues until all four players have been east (dealer).
Once the first round is completed, a second round begins with the prevailing wind of "south". Player 1 deals the first hand and player two deals the second hand etc. There are four rounds which represent all four prevailing winds.
Whenever a player in the east position (dealer) wins a hand or if there is no winner (a draw or "goulash hand") an extra hand is played with the players repeating the same position as the previous hand.
Example of Games (assuming the player who is dealer in each hand does not win the hand)
If the dealer wins a hand or if there is a draw (no winner), then an extra hand is played and the seating and prevailing wind remains the same. This may mean that a match would have no limit to the number of hands played (though some players will set a limit to three consecutive hands allowed with the same seat positions and prevailing winds).
A mahjong set with Winds in play will usually include a separate Prevailing Wind marker (typically a die marked with the Wind characters in a holder) and a pointer that can be oriented towards the dealer to show Player Game Wind. In sets with racks, a rack may be marked differently to denote the dealer.
Wind position is significant in that it affects the scoring of the game.
Dealing tiles.
All tiles are placed face down on the table and are shuffled. By convention all players should participate in shuffling using both hands moving the pieces around the table, loudly, for a lengthy period. There is no fixed rule on how to deal or how to treat tiles which flip over during shuffle, though possible solutions include turning back over the pieces at the moment they are seen, turning over all revealed pieces at intervals or doing so at the end of the shuffling and forming of the wall.
Each player then stacks a row of 18 tiles two tiles high in front of them (for a total of 36 tiles). Players then push each side of their tiles together to form a square wall.
The dealer throws three dice and sums up the total. Counting counterclockwise so that the dealer is 1 (or 5, 9, 13, 17), so that south is 2 (or 6, 10, 14, 18), etc., a player's quarter of the wall is chosen. Using the same total on the dice, the player then counts the stacks of tiles from right to left. Starting from the left of the stacks counted, the dealer takes four tiles to himself, and players in counterclockwise order take blocks of four tiles until all players have 12 tiles, so that the stacks decrease clockwise. Each player then takes one last tile to make a 13-tile hand. Dealing does not have to be this formal and may be done quite differently based on house rules.
Each player now sets aside any flowers or seasons they may have drawn and takes replacement piece(s) from the wall.
The dealer takes the next piece from the wall, adds it to his hand. If this does not complete a legal hand, he then discards a piece (throwing it into the middle of the wall with no particular order in mind).
Rules.
Each player takes a turn picking up a tile from the wall and then discarding a tile by throwing it into the center and, if desired, announcing out loud what the piece is. Play continues this way until one player has a legal winning hand and calls out mahjong while revealing their hand. There are four different ways that this order of play can be interrupted.
During play, the number of tiles maintained by each player should always be thirteen tiles (meaning in each turn a tile must be picked up and another discarded). Not included in the count of thirteen tiles are flowers and seasons set to the side and the fourth added piece of a kong. If a player is seen to have more or less than thirteen tiles in their hand outside of their turn they are penalised.
Legal hand.
A winning hand consists of fourteen tiles (the thirteen tiles in the hand plus the additional tile picked up from the wall or stolen when a player discards a tile needed to complete a hand). The first is called winning from the wall, the second is called winning by a discard.
The winning hand is made of four melds (a specific pattern of three pieces) and the eyes (a pair of two identical pieces). The exception to this rule are the special hands listed below.
Most players play with a table minimum, meaning a winning hand must score a minimum number of points (which can be seen in the scoring section). In Hong Kong Mahjong the most common point set is three.
Melds.
You can form a pong with any tile (except flowers as they are bonus tiles set to the side when drawn from the wall). The tiles must be identical (you cannot mix suits).
Consider a Kong the same as a Pong/ Pung with an additional tile to make a set of four. There are three ways to form a Kong.
In any case, whenever a Kong is formed, the player must draw an extra tile from the end of the wall and then discard a tile. The fourth piece of the kong (not flowers/seasons) is not considered as one of the 13 tiles a player must always have in their hand. Kongs are worth collecting to score more points and/or deprive opponents of obtaining a specific tile.
The meld must be in absolute numerical sequence. There is no skipping of numbers, nor does 9 loop around to 1. The sequence must be in the same suit. Honours, flowers and seasons cannot be used to make chows. A player can steal a discard to form a chow from the player prior to them in order if no one else needs the tile to make pongs/ pungs or kongs or win (go mahjong).
For example:
Interruption of play.
Flower or season.
Whenever a player draws a flower or season, it is announced and then placed to the side (it is not considered as a part of the hand but can earn a bonus points if part of the winning hand) and the last tile of the wall is drawn as a replacement tile so that the player has the fourteen pieces needed before their discard. This may happen successively in a player's turn.
Melding another player's discard.
When a player discards a tile, any other player may steal the tile to complete a meld. Stealing tiles has both advantages (quickly forming a winning hand and scoring extra points) and disadvantages such as revealing part of ones hand to other players and not being able to change the meld once declared.
When a meld (Pong, Kong or Chow) is declared through a discard, the player must state the type of meld to be declared and place the meld face up. The player must then discard a tile, and play continues to the right. If the player who melds a discard is not directly after the discarder (in order of play), one or two players essentially miss their turn as play continues to the player after the one who declared the meld.
When two or more players call for a discarded tile, a player taking the tile to win the hand has precedence over all others. Otherwise a player who can form a "Pong" or "Kong" takes precedence over a player who claims a "Chow".
Going mahjong.
If at any point in the game a player can use another player's discard to complete a legal hand (and with the agreed minimum points), they yell out Mahjong, take the piece and reveal their hand, with the way of calling it out depending on variations. This ends the hand, and scoring commences. If two or three players need the piece to win, there are two ways to resolve the issue depending on agreed table rules: Either the players compete to see who would have a better hand in terms of scoring, or simply the player closest to the discarder in order of turn wins the game.
Robbing a kong.
A rarely occurring and high scoring feature of Hong Kong Mahjong is a move called robbing the kong. If a player declares a kong (by melding it or adding a fourth piece to a pong to form a kong or declaring a concealed kong) and another player(s) can use that piece to complete a hand (which by logic could not be used to form a pong or kong as two players cannot make a pong out of the same tile) a player may steal that piece from that player when declaring the kong and go mahjong (win the hand).
Example winning hands.
Below are examples of winning hands. A winning hand must consist of four melds (pongs, kongs and/or chows) and a pair (eyes) and must also score the agreed table minimum.
"Hand formed with four pongs and the eyes (pair) of East wind. Only bamboo is used (no other simples), scoring extra points (clean hand). No chows are used (an all pong/kong hand scores extra points)."
"A high scoring hand formed using only circles, known as a pure hand. Hand is made of chows, pongs and the eyes of circles."
Most players include table variations in their games, of which some non-standard are included. The hands of "seven different pairs", "thirteen orphans" and "heavenly gates" are examples which do not have four melds and the eyes. They are described in more detail below.
Calling out mahjong.
In Western Classical variants, this is known as creating a "mahjong", and the process of winning is called "going mahjong". Calling a mahjong without having a legal hand or with the minimum points is usually penalized via points or with the player having to play the rest of the hand with his tiles shown to the other players face up.
Turns and rounds.
If the dealer wins the hand, s/he will remain the dealer and an extra hand is played in addition to the minimum 16 hands in a match. The same occurs if there is no winner.
The dealer position is significant in that s/he owes or is owed double their score.
Extra points are also scored if their hand is composed of pieces that match their seat wind and or the prevailing wind.
Flowers and seasons are also scored as bonus points to the winner depending on their seat position.
Rhythm of play.
Amongst players, there is an agreed amount of time allowed to make a call for a discarded tile, before the next player takes their turn, known as "window of opportunity" is explicitly stated in the rules; whereas in other variants, it is generally considered that when the next player's turn starts, i.e., the tile leaves the wall, the opportunity has been lost.
Scoring.
Old Hong Kong scoring involves adding up the fan value (the value of a hand) of the winner's hand and paying the winner the appropriate sum/points:
Fan value.
Basic fan value.
A winning hand must include an agreed minimum amount of fan value (often 3)
Bonus fan.
A player only scores a bonus fan for flowers or seasons if it is their own flower or season (East=1, South=2, West=3 and North=4) or if the player has all four flowers or all four seasons (scoring five fan in total).
Payment.
The fan value of a hand is converted into base points which are then used to calculate the money (or "points") the losers pay the winner.
If a player has three fan then his hand is worth one base point. A winning hand with nine fan is worth four base points. The base points are doubled for the following (if two criteria apply, the base payment is doubled and then redoubled):
Examples.
Hong Kong mahjong is essentially a payment system of doubling and redoubling where winning from the wall adds great value to the final payment and where the dealer is highly rewarded or penalised if he or she wins or loses.
Limit hands.
There are a series of "limit hands". Table rules dictate if these rare and special hands are allowed, which ones, and the limit for scoring. A common scoring limit is 64 points, which is the highest base points doubled twice. A winner receives the scoring limit from each player without any doubling.
In some cases it is expected that the hand is achieved without calling any sets, except when winning, and or that it must be won from the wall.
Some groups also play with the "great flowers" rule. If a player picks up all 4 flowers and all 4 seasons during his/her hand, s/he instantly wins the hand and receives the maximum points from all of the players. This is exceptionally rare.
Examples of high-scoring hands.
All-pong hand
Clean hand
Pure hand
Pure honor hand
Thirteen orphans hand
Variations.
Variations may have far more complicated scoring systems, add or remove tiles, and include far more scoring elements and limit hands.
In many places, players often observe one version and are either unaware of other variations or claim that different versions are incorrect. Many variations today differ only by scoring:
Equipment.
There are variations that feature specific use of tiles. Some three player versions remove the North Wind and one Chinese provincial version has no honors. Korean mahjong removes the bamboo suit or at least its numbers 2–8 so that terminals can be used. Japanese mahjong rarely uses flowers or seasons. The seasons are removed in Korean mahjong, while Singapore/Malaysian mahjong has a third set of bonus tiles called animals and even a fourth called vehicles. Joker tiles are used in some versions. Some variations use counting sticks while others use chips, and some use pencils and paper for score keeping.
Rules.
Japanese and Korean mahjong have some special rules. A player cannot win by a discard if that player had already discarded that piece, where players' discards are kept in neat rows in front of them. Players may declare ready, meaning that they need one tile to win, cannot change their hand and win extra points if they win. Some rules may replace some of the number 5 tiles with red tiles, as they can earn more points. Korean mahjong does not allow melded (stolen) chows.
Taiwanese mahjong adds three tiles to a hand requiring a 5th set to be formed, making a clean hand or all pong hand very difficult to procure.
American mahjong has distinctive game mechanics and the article on American mahjong details these. Some differences include many special patterns, a different scoring system and the use of jokers and 5 of a kind.
Scoring.
Scoring in mahjong involves points, with a monetary value for points agreed upon by players. Although in many variations scoreless hands are possible, many require that hands be of some point value in order to win the hand.
While the basic rules are more or less the same throughout mahjong, the greatest divergence between variations lies in the scoring systems. Like the rules, there is a generalized system of scoring, based on the method of winning and the winning hand, from which Chinese and Japanese base their roots. American mahjong generally has greatly divergent scoring rules, as well as greatly divergent general rules.
Because of the large differences between the various systems of scoring (especially for Chinese variants), groups of players will often agree on particular scoring rules before a game.
Points (terminology of which differs from variation to variation) are obtained by matching the winning hand with different criteria scoring different values. The points obtained may be modified into scores for each player using some (typically exponential) functions. Some criteria may be also in terms of both points and score.
In many variations the dealer receives no scoring bonus and does not maintain his/her turn by winning or a dead hand.
In classical mahjong all players score points. Points are given for sets and hand composition and winning bonuses, doubled and redoubled for basic patterns. Sometimes a loser may score more points than a winner. Japanese mahjong has a complex scoring system with several stages of scoring, rules and exceptions, evening out scores and bonus points at the end of a match. Korean mahjong has a simple scoring system where only winner scores without any form of doubling.
Some variations give points for concealed hands, in which case no melds are made except by winning on a discard.
In Old Hong Kong Mahjong:
Wildcards.
Some players accept wildcards (Chinese: 混儿，hunr) when playing Mahjong. The wildcards are decided at the beginning of the game. The wildcard can be the next tile after spreading tiles to all players or separately decided by a dice toss. Wildcards are not allowed to be discarded and can replace any tiles in Chows. Wildcards can't replace any tiles in Pongs and Kongs.
For example, if a character 4 taken out, then character 4 and the next number 5 can be used as wildcards in this round (When the tile showed, the tiles of the same pattern left only 3, so the next tile in the suit will be used as wildcards as well, adding to 7 wildcards for 4 players). Also, if a tile numbered 9 is chosen, then the number 9 and 1 are wildcards.
Also, if the chosen tile is not in the simples, the wildcards are decided in rules:
The bonus tiles are not available for wildcards.
Hands.
Many variations have specific hands, some of which are common while some are optional depending on regions and players. One example is the Pure Green hand made of chows or pongs using 2, 3, 4, 6, 8 of bamboo and green dragon.
Flowers.
Japanese rule sets discourage the use of flowers and seasons. Korean rules and three-player mahjong in the Korean/Japanese tradition use only flowers. In Singapore and Malaysia an extra set of bonus tiles of four animals are used. The rule set includes a unique function in that players who get two specific animals get a one-time immediate payout from all players. In Taiwanese mahjong, getting all eight flowers and seasons constitutes an automatic win of the hand and specific payout from all players.
Four of the flower tiles represent the four noble plants of Confucian reckoning:
The other four flower tiles (or season tiles) represent seasons:
The animal tiles used in Malaysia, Singapore and local variations are the animals. They represent the cat, mouse, cockerel and centipede.
Number of tiles.
All tiles are placed face down and shuffled. Each player then stacks a row of tiles two tiles high in front of him, the length of the row depending on the number of tiles in use:
Charleston.
In the American variations it is required that, before each hand begins, a Charleston be enacted. In the first exchange, three tiles are passed to the player on one's right; in the next exchange, the tiles are passed to the player opposite, followed by three tiles passed to the left. If all players are in agreement, a second Charleston is performed; however, any player may decide to stop passing after the first Charleston is complete. The Charleston is followed by an optional pass to the player across of one, two, or three tiles. The Charleston, a distinctive feature of American mahjong, may have been borrowed from card games such as Hearts.
Jokers.
A feature of several variations of mahjong, most notably American variations, is the notion of some number of Joker tiles. They may be used as a wild card: a substitute for any tile in a hand, or, in some variations, only tiles in melds. Another variation is that the Joker tile may "not" be used for melding. Depending on the variation, a player may replace a Joker tile that is part of an exposed meld belonging to any player with the tile it represents.
Rules governing discarding Joker tiles also exist; some variations permit the Joker tile to take on the identity of any tile, and others only permit the Joker tile to take on the identity of the previously discarded tile (or the absence of a tile, if it is the first discard).
Joker tiles may or may not have an impact on scoring, depending on the variation. Some special hands may require the use of Joker tiles (for example, to represent a "fifth tile" of a certain suited or honor tile).
In American mahjong, it is illegal to pass Jokers during the Charleston.
Ready hands.
When a hand is one tile short of winning (for example: , waiting for: , , or , as can be the eyes), the hand is said to be a ready hand (Traditional Chinese: 聽牌; Simplified Chinese: 听牌; Japanese: "tenpai" 聴牌), or more figuratively, "on the pot". The player holding a ready hand is said to be "waiting" for certain tiles. It is common to be waiting for two or three tiles, and some variations award points for a hand that is waiting for one tile. In 13-tile mahjong, the largest number of tiles for which a player can wait is 13 (the "thirteen wonders", or "thirteen orphans", a nonstandard special hand). Ready hands must be declared in some variations of mahjong, while other variations prohibit the same.
Some variations of mahjong, most notably Japanese and Korean ones, allow a player to declare "rīchi" (立直, sometimes known as "reach", as it is phonetically similar). A declaration of "rīchi" is a promise that any tile drawn by the player is immediately discarded unless it constitutes a win. Standard requirements for "rīchi" are that the hand be "closed" or have no melds declared (other than a concealed kong) and that players already have points for declaration of "rīchi". A player who declares "rīchi" and wins usually receives a point bonus for their hand directly, and a player who won with "rīchi" also has the advantage to open the inner "dora" (ドラ, from "dra"gon) which leads to higher possibilities to match such a card, thus has more chance to grant additional bonus. However, a player who declares "rīchi" and loses is usually penalized in some fashion. Declaring a nonexistent "rīchi" is also penalized in some way.
In some variations, a situation in which all four players declare a "rīchi" is an automatic drawn game, as it reduces the game down to pure luck, i.e., who gets their needed tile first.
Draws.
If only the dead wall remains (or if no dead wall exists and the wall is depleted) and no one has won, the hand is drawn (流局 "liú jú", 黃莊 "huáng zhuāng", Japanese "ryūkyoku"), or "goulashed". A new hand begins, and depending on the variant, the Game Wind may change. For example, in most playing circles in Singapore, if there is at least one Kong when the hand is a draw, the following player of the dealer becomes the next dealer; otherwise, the dealer remains dealer.
Japanese mahjong has a special rule called "sanchahō" (三家和), which is, if three players claim the same discard in order to win, the hand is drawn. One reason for this is that there are cases in which bars of 1,000 points for declaring "rīchi" cannot be divided by three. The rule is treated the same as "abortive draws".
Abortive draws.
In Japanese mahjong, rules allow abortive draws to be declared while tiles are still available. They can be declared under the following conditions:
Competition.
In 1998, in the interest of dissociating illegal gambling from mahjong, the China State Sports Commission published a new set of rules, now generally referred to as Chinese Official rules or International Tournament rules (see Guobiao Majiang). The principles of the new, wholesome mahjong are no gambling, no drinking, and no smoking. In international tournaments, players are often grouped in teams to emphasize that mahjong from now on is considered a sport.
The new rules are highly pattern-based. The rulebook contains 81 combinations, based on patterns and scoring elements popular in classic and modern regional Chinese variants; some table practices of Japan have also been adopted. Points for flower tiles (each flower is worth one point) may not be added until the player has scored 8 points. The winner of a game receives the score from the player who discards the winning tile, plus 8 basic points from each player; in the case of "zimo" (self-drawn win), he receives the value of this round plus 8 points from all players.
The new rules were first used in an international tournament in Tokyo, where, in 2002, the first World Championship in Mahjong was organized by the Mahjong Museum, the Japan Mahjong Organizing Committee, and the city council of Ningbo, China. One hundred players participated, mainly from Japan and China, but also from Europe and the United States. Mai Hatsune, from Japan, became the first world champion. The following year saw the first annual China Mahjong Championship, held in Hainan; the next two annual tournaments were held in Hong Kong and Beijing. Most players were Chinese; players from other nations attended as well.
In 2005, the first Open European Mahjong Championship was held in the Netherlands, with 108 players. The competition was won by Masato Chiba from Japan. The second European championship in Copenhagen(2007) was attended by 136 players and won by Danish player Martin Wedel Jacobsen. The first Online European Mahjong Championship was held on the Mahjong Time server in 2007, with 64 players, and the winner was Juliani Leo, from the U.S., and the Best European Player was Gerda van Oorschot, from the Netherlands. The Third Open European Mahjong Championship 2009 at Baden/Vienna, Austria, was won by Japanese player Koji Idota, while runner-up Bo Lang from Switzerland became European Champion. There were 152 participants.
In 2006, the World Mahjong Organization (WMO) was founded in Beijing, China, with the cooperation of, amongst others, the Japan Mahjong Organizing Committee (JMOC) and the European Mahjong Association (EMA). This organization held its first World Championship in November 2007 in the Chinese town of Chengdu, attended by 144 participants from all over the world. It was won by Li Li, a Chinese student at Tsinghua University. The next World Championship took place in Utrecht, the Netherlands, 27 to 29 August 2010.
Western or American-style mah jongg tournaments are held in virtually every state—the largest is in Las Vegas, Nevada twice a year, and in Atlantic City, New Jersey, by Mah Jongg Madness; and the annual cruise hosted by the National Mah Jongg League and Mah Jongg Madness (MJM). MJM tournaments host between 150 and 500 participants at these larger events; and there are several smaller scale, but equally successful tournaments held annually by other hosts. Prize pools are based on the number participating. Rules are based on the National Mah Jongg League standard rules.
Special meaning and history of tiles.
The suits of the tiles are money-based. In ancient China, the copper coins had a square hole in the center; people passed a rope through the holes to tie coins into strings. These strings are usually in groups of 100 coins, called "diào" (弔, or variant 吊), or 1000 coins, called "guàn" (貫). Mahjong's connection to the ancient Chinese currency system is consistent with its alleged derivation from the game named "mǎ diào" (馬弔).
In the mahjong suits, the coppers represent the coins, the ropes are actually strings of 100 coins, and the character myriad represents 10,000 coins or 100 strings. When a hand receives the maximum allowed winning of a round, it is called "mǎn guàn" (滿貫, literally, "full string of coins").
The red tile ("中"榜, "zhōngbǎng") means passing the examination to clear the way to officialdom.
The green tile ("發"財, "fācái", literally "get rich") means wealth.
The white tile (白板, "báibǎn", literally "clean slate") means freedom from corruption. It usually has a blue border to distinguish from replacement tiles and prevent alterations.
In the original Chinese mahjong, these pieces are called "jiàn" (箭), which represents archery, and the red "中" represents a hit on the target. In ancient Chinese archery, one would put a red "中" to signify that the target was hit. White "白" represents failure, and green "發" means that one will release the draw.
Superstitions.
There are many superstitions associated with the game of Mahjong. For example, players will try to find seats with the best Feng Shui or wear their lucky clothing or trinkets.
Some superstitious rituals in Mahjong can involve things from not counting one's wins and losses, to changing one's underwear after a loss.
Unicode.
Mahjong tiles were added to the Unicode Standard in April, 2008 with the release of version 5.1.
The Unicode block for mahjong tiles is U+1F000–U+1F02F:
border="1" cellspacing="0" cellpadding="5" class="wikitable nounderlines Unicode" style="border-collapse:collapse;background:#FFFFFF;font-size:large;text-align:center"
References.
Further reading.
</dl>
Historical research.
</dl>
Chinese classic.
</dl>
Chinese official.
</dl>

</doc>
<doc id="19497" url="http://en.wikipedia.org/wiki?curid=19497" title="May 12">
May 12

May 12 is the day of the year in the Gregorian calendar.

</doc>
<doc id="19499" url="http://en.wikipedia.org/wiki?curid=19499" title="Mariah Carey">
Mariah Carey

Mariah Carey (born March 27, 1969 or 1970) is an American singer, songwriter, record producer, and occasional actress. She rose to prominence after releasing her self-titled debut studio album "Mariah Carey" in 1990; it went multiplatinum and spawned four consecutive number one singles on the U.S. "Billboard" Hot 100 chart. Under the guidance of Columbia Records executive and later husband Tommy Mottola, Carey continued booking success with followup albums "Emotions" (1991), "Music Box" (1993), and "Merry Christmas" (1994), and was established as Columbia's highest-selling act. "Daydream" (1995) made music history when its second single "One Sweet Day", a duet with Boyz II Men, spent a record sixteen weeks on top of the "Billboard" Hot 100, and it remains the longest-running number-one song in U.S. chart history. During the recording of the album, Carey began to deviate from her R&B and pop beginnings and slowly traversed into hip hop. This musical change became evident with the release of "Butterfly" (1997), at which time Carey had separated from Mottola.
Carey left Columbia in 2000, and signed a $100 million recording contract with Virgin Records America. Before the release of her film "Glitter" (2001), she suffered a physical and emotional breakdown and was hospitalized for severe exhaustion. Following the film and album's poor reception, she was bought out of her recording contract for $50 million, which led to a decline in her career. She signed a multimillion dollar contract deal with Island Records in 2002, and after an unsuccessful period, returned to the top of music charts with "The Emancipation of Mimi" (2005). Its second single "We Belong Together" became her most successful single of the 2000s, and was later named "Song of the Decade" by "Billboard". Carey once again ventured into film with a well-received supporting role in "Precious" (2009); she was awarded the "Breakthrough Performance Award" at the Palm Springs International Film Festival, and received Black Reel and NAACP Image Award nominations.
Throughout her career, Carey has sold more than 200 million records worldwide, making her one of the best-selling music artists of all time. In 1998, she was honored as the world's best-selling recording artist of the 1990s at the World Music Awards. Carey was also named the best-selling female artist of the millennium in 2000. According to the Recording Industry Association of America, she is the third-best-selling female artist in the United States, with 63.5 million certified albums. With the release of "Touch My Body" (2008), Carey gained her 18th number-one single in the United States, more than any other solo artist. In 2012, Carey was ranked second on VH1's list of the "100 Greatest Women in Music". Aside from her commercial accomplishments, Carey has won five Grammy Awards, 19 World Music Awards, 11 American Music Awards, and 14 Billboard Music Awards. Referred to as the "songbird supreme" by the "Guinness World Records", she is famed for her five-octave vocal range, power, melismatic style and signature use of the whistle register.
Early life.
Mariah Carey was born on March 27, 1969 or 1970 in Huntington, New York. Her father, Alfred Roy, was of African American and Venezuelan (including Afro-Venezuelan) descent, while her mother, Patricia (Hickey), is of White Irish descent. The last name Carey was adopted by her Venezuelan grandfather, Francisco Núñez, after emigrating to New York. Patricia was an occasional opera singer and vocal coach before she met Alfred in 1960. As he began earning a living as an aeronautical engineer, the couple wed later that year, and moved into a small suburb in New York. After their elopement, Patricia's family disowned her due to her marrying a black man. Carey later explained that growing up, she felt a notion of neglect from her maternal family, a mark that affected her greatly. During the years between the births of Carey's older sister Alison and herself, the Carey family struggled within the community due to their ethnicity. Carey's name was derived from the song "They Call the Wind Maria", originally from the 1951 Broadway musical "Paint Your Wagon." When Carey was three, her parents divorced.
"It's been difficult for me, moving around so much, having to grow up by myself... my parents divorced. And I always felt kind of different from everybody else in my neighborhoods. I was a different person ethnically. And sometimes, that can be a problem. If you look a certain way, everybody goes 'White girl', and I'd go, 'No, that's not what I am'."
—Carey, on her childhood
After their separation, Alison moved in with her father, while the other two children, Mariah and brother Morgan, remained with their mother. Carey would grow apart from her father, and would later stop seeing him altogether. By the age of four, Carey recalled that she had begun to sneak the radio under her covers at night, and just sing and try and find peace within the music. During elementary school, she excelled in subjects that she enjoyed, such as music, art, and literature, but did not find interest in others. After several years of financial struggles, Patricia earned enough money to move her family into a stable and more affluent sector in New York. Carey had begun writing poems and adding melodies to them, thus starting as a singer-songwriter while attending Harborfields High School in Greenlawn, New York. Carey excelled in her music, and demonstrated usage of the whistle register, though only beginning to master and control it through her training with her mother. Though introducing her daughter to classical opera, Patricia never pressured her to pursue a career in it, as she never seemed interested. Carey recalled that she kept her singer-songwriter works a secret and noted that Patricia had "never been a pushy mom. She never said, 'Give it more of an operatic feel'. I respect opera like crazy, but it didn't influence me."
While in high school, Carey began writing songs with Gavin Christopher. They needed an assistant who could play the keyboard: "We called someone and he couldn't come, so by accident we stumbled upon Ben [Margulies]. Ben came to the studio, and he really couldn't play the keyboards very well — he was really more of a drummer — but after that day, we kept in touch, and we sort of clicked as writers." Carey and Christopher began writing and composing songs in the basement of his father's store during Carey's senior year. After composing their first song together, "Here We Go Round Again", which Carey described as having a Motown vibe, they continued writing material for a full-length demo. She began living in a one-bedroom apartment in Manhattan, which she shared with four other female students. Carey worked as a waitress for various restaurants, usually getting fired after two weeks. While requiring work to pay for her rent, Carey still had musical ambitions, as she continued working late into the night with Margulies in hopes of completing a demo. After completing her four song demo tape, Carey attempted to pass it to music labels, but failed each time. Shortly thereafter, she was introduced to rising pop singer Brenda K. Starr.
Career.
1988–92: "Mariah Carey" and "Emotions".
As Starr's friendship with Carey grew, so did her interest in helping Carey succeed in the industry. In December 1988, Carey accompanied Starr to a record executives' gala, where she handed her demo tape to the head of Columbia Records, Tommy Mottola, who listened to it on his way back home. After the first two songs, he was so enamored of Carey's voice that he returned to the event, only to find that she had left. In what has been widely described by critics as a modern day Cinderella tale, after searching for Carey for two weeks, he immediately signed her and began mapping out her commercial debut. While she maintained that she wanted to continue working with Margulies, Mottola enlisted top producers of the time, including Ric Wake, Narada Michael Walden and Rhett Lawrence. Mottola and the staff at Columbia had planned to market Carey as their main female pop artist, competing with Whitney Houston and Madonna (signed to Arista and Sire Records respectively). After the completion of her debut album, "Mariah Carey", Columbia spent more than $1 million promoting it. Despite a weak start, the album eventually reached the top of the "Billboard" 200, after Carey's exposure at the 33rd Annual Grammy Awards. "Mariah Carey" stayed atop the charts for eleven consecutive weeks, and she won the Best New Artist, and Best Female Pop Vocal Performance awards for her single "Vision of Love". The album yielded three more number one singles on the "Billboard" Hot 100, following the four-week number-one run of "Vision of Love". Carey became the first artist since The Jackson 5 to have their first four singles reach number one. "Mariah Carey" finished as the best-selling album in the United States in 1991, while totaling sales of over 15 million copies.
Carey began recording her second studio album, "Emotions", in 1991. She described it as a homage to Motown soul music, as she felt the need to pay tribute to the type of music that had influenced her as a child. For the project, Carey worked with Walter Afanasieff, who only had a small role on her debut, as well as Robert Clivillés and David Cole, from the dance group C+C Music Factory. Carey's relationship with Margulies deteriorated over a personal contract Carey had signed with him before signing the record deal with Columbia, agreeing to split not only the songwriting royalties from the songs, but half of her earnings as well. However, when the time came to write music for "Emotions," Sony officials made it clear he would only be paid the fair amount given to co-writers on an album. Margulies later filed a lawsuit against Sony which ultimately led to their parting of ways. "Emotions" was released on September 17, 1991, and was accepted by critics as a more mature album than its predecessor. While praised for Carey's improved songwriting, production, and new sound, the album was criticized for its material, thought weaker than that of her debut. Though the album managed sales of over eight million copies globally, "Emotions" failed to reach the commercial and critical heights of its predecessor.
As after the release of her debut, critics again questioned whether Carey would embark on a world tour to promote her material. Although Carey explained that stage fright and the style of her songs made a tour very daunting, speculation grew that Carey was a "studio worm", and that she was incapable of producing the perfect pitch and 5-octave vocal range for which she was known. In hopes of putting to rest any claims of her being a manufactured artist, Carey and Walter Afanasieff decided to book an appearance on MTV Unplugged, a television program aired by MTV. The show presented name artists "unplugged" or stripped of studio equipment. While Carey felt strongly of her more soulful and powerful songs, it was decided that her most popular content would be included. Days before the show's taping, Carey and Afanasieff thought of adding a cover version of an older song, in order to provide something different and unexpected. They chose "I'll Be There", a song made popular by The Jackson 5 in 1970. On March 16, 1992, Carey recorded a seven-piece set-list at Kaufman Astoria Studios in Queens, New York. The revue was met with critical acclaim, leading to it being aired more than three times as often as an average episode would. The success tempted Sony officials to market it. Sony decided to release it as an EP, priced low because it was short. The EP proved to be a success, contrary to critics and speculations that Carey was just a studio artist, and was given a triple-Platinum certification by the Recording Industry Association of America (RIAA), and managed Gold and Platinum certifications in several European markets.
1993–96: "Music Box", international breakthrough, and "Daydream".
"The writing partnership that her and I had and I can't speak for her other songwriting partners, but if you could see us in the room I would hit a chord and play a little melody on the piano and she would say, 'Oh, that's nice,' and she would sing that melody and then she adds a little bit to it. I would then play it back and then she would say, 'Yea, that's good' so it instantly becomes this partnership where eventually she'll have a melody and then the melody would prompt her to start thinking about this feeling she wants to put into words. This would eventually become the theme of the song."
—Afanasieff, on his songwriting partnership with Carey.
During early 1993, Carey began working on her third studio album, "Music Box". After "Emotions" failed to achieve the commercial heights of her debut album, Carey and Columbia came to the agreement that the next album would contain a more pop influenced sound, in order to appeal to a wider audience. During Carey's writing sessions, she began working mostly with Afanasieff, with whom she co-wrote and produced most of "Music Box". On August 31, "Music Box" was released around the world, debuting at number-one on the "Billboard" 200. The album was met with mixed reception from music critics; while many praised the album's pop influence and strong content, others felt that Carey made less usage of her acclaimed vocal range. Ron Wynn from AllMusic described Carey's different form of singing on the album: "It was wise for Carey to display other elements of her approach, but sometimes excessive spirit is preferable to an absence of passion." The album's second single, "Hero", would eventually come to be one of Carey's most popular and inspirational songs of her career. The song became Carey's eighth chart topper in the United States, and began expanding Carey's popularity throughout Europe. With the release of the album's third single, Carey achieved several career milestones. Her cover of Badfinger's "Without You" became her first number one single in Germany, Sweden, and the United Kingdom.
"Music Box" spent prolonged periods at number one on the album charts of several countries, and eventually became one of the best-selling albums of all time, with worldwide sales of over 32 million copies. After declining to tour for her past two albums, Carey agreed to embark on a short stateside string of concerts, titled the Music Box Tour. Spanning only six dates across North America, the short but successful tour was a large step for Carey, who dreaded the hassle of touring. Following "Music Box", Carey took a relatively large period of time away from the public eye, and began working on an unknown project throughout 1994. In October 1994, "Billboard" announced that Carey would release a holiday album later that year. That 1994, Carey recorded a duet with Luther Vandross; a cover of Lionel Richie and Diana Ross's "Endless Love". Carey's album "Merry Christmas" was released on November 1, 1994, on the same day that the album's first single, "All I Want for Christmas Is You", was released. The album eventually became the best-selling Christmas album of all time, with global sales reaching over 15 million copies. Additionally, "All I Want for Christmas Is You" was critically lauded, and is considered "one of the few worthy modern additions to the holiday canon." "Rolling Stone" described it as a "holiday standard", and ranked it fourth on its Greatest Rock and Roll Christmas Songs list. Commercially, it became the best-selling holiday ringtone of all time, and the best-selling single by a non-Asian artist in Japan, selling over 2.1 million units (both ringtone and digital download). By the end of the holiday season of 1994, Carey and Afanasieff had already begun writing material for her next studio album, which would be released late the following year.
Released on October 3, 1995, "Daydream" combined the pop sensibilities of "Music Box" with downbeat R&B and hip hop influences. The album's second single, "One Sweet Day" was inspired by the death of David Cole, as well as her sister Alison, who had contracted AIDS. The song remained atop the Hot 100 for a record-holding 16 weeks, and became the longest-running number-one song in history. "Daydream" became her biggest-selling album in the United States, and became her second album to be certified Diamond by the RIAA, following "Music Box". The album again was the best-seller by an international artist in Japan, shipping over 2.2 million copies, and eventually reaching global sales of over 25 million units. Critically, the album was heralded as Carey's best to date; "The New York Times" named it one of 1995's best albums, and wrote, "best cuts bring R&B candy-making to a new peak of textural refinement [...] Carey's songwriting has taken a leap forward and become more relaxed, sexier and less reliant on thudding clichés." Carey once again opted to embark on a short world tour titled Daydream World Tour. It had seven dates, three in Japan and four throughout Europe. When tickets went on sale, Carey set records when all 150,000 tickets for her three shows at Japan's largest stadium, Tokyo Dome, sold out in under three hours, breaking the previous record held by The Rolling Stones. Due to the album's success, Carey won two awards at the American Music Awards for her solo efforts: Favorite Pop/Rock Female Artist and Favorite Soul/R&B Female Artist. "Daydream" and its singles were respectively nominated in six categories at the 38th Grammy Awards. Carey, along with Boyz II Men, opened the event with a performance of "One Sweet Day". However, Carey did not receive any award, prompting her to comment "What can you do? I will never be disappointed again. After I sat through the whole show and didn't win once, I can handle anything." In 1995, due to "Daydream"‍ '​s enormous Japanese sales, "Billboard" declared Carey the "Overseas Artist of the Year" in Japan.
1997–2000: New image and independence, "Butterfly", and "Rainbow".
With her following albums, Carey began to take more initiative and control with her music, and started infusing more genres into her work. During mid-1997, Carey was well underway, writing and recording material for her next album, "Butterfly" (1997). She sought to work with other producers and writers other than Afanasieff, such as Sean Combs, Kamaal Fareed, Missy Elliott and Jean Claude Oliver and Samuel Barnes from Trackmasters. During the album's recording, Carey and Mottola separated, with Carey citing it as her way of achieving freedom, and a new lease on life. Aside from the album's different approach, critics took notice of Carey's altered style of singing, which she described as breathy vocals. Her new-found style of singing was met with mixed reception; some critics felt this was a sign of maturity, that she did not feel the need to always show off her upper range, while others felt it was a sign of her weakening and waning voice. The album's lead single, "Honey", and its accompanying music video, introduced a more overtly sexual image than Carey had ever demonstrated, and furthered reports of her freedom from Mottola. Carey stated that "Butterfly" marked the point when she attained full creative control over her music. However, she added, "I don't think that it's that much of a departure from what I've done in the past [...] It's not like I went psycho and thought I would be a rapper. Personally, this album is about doing whatever the hell I wanted to do." Growing creative differences with producer Afanasieff continued, and eventually ended their working relationship, after collaborating on most of Carey's material. Reviews for "Butterfly" were generally positive: "Rolling Stone" wrote, "It's not as if Carey has totally dispensed with her old saccharine, Houston-style balladry [...] but the predominant mood of 'Butterfly' is one of coolly erotic reverie. [... Except "Outside" the album sounds] very 1997. [...] Carey has spread her wings and she's ready to fly." AllMusic editor Stephen Thomas Erlewine described Carey's vocals as "sultrier and more controlled than ever", and heralded "Butterfly" as one of her "best records and illustrates that Carey continues to improve and refine her music, which makes her a rarity among her '90s peers.'" The album was a commercial success, although not to the degree of her previous three albums.
Toward the turn of the millennium, Carey began developing other projects. On April 14, 1998, Carey partook in the VH1 Divas benefit concert, where she sang alongside Aretha Franklin, Celine Dion, Shania Twain, Gloria Estefan, and Carole King. Carey had begun developing a film project "All That Glitters", later re-titled to simply "Glitter", and intended her songwriting to other projects, such as "Men in Black" (1997) and "How the Grinch Stole Christmas" (2000). After "Glitter" fell into developmental hell, Carey postponed the project, and began writing material for a new album. The executives at Sony Music, the parent company of Carey's label Columbia, wanted her to prepare a greatest hits collection in time for the commercially favorable holiday season. However, they disagreed as to what content and singles should constitute the album. Sony wanted to release an album that featured her number one singles in the United States, and her international chart toppers on the European versions, void of any new material, while Carey felt that a compilation album should reflect on her most personal songs, not just her most commercial. She felt that not including any new material would result in cheating her fans, therefore including four new songs that she had recorded. While compromised, Carey often expressed distaste towards the album's song selection, expressing her disappointment in the omission of her "favorite songs". The album, titled "#1's" (1998), featured a duet with Whitney Houston, "When You Believe", which was included on the soundtrack for "The Prince of Egypt" (1998). During the development of "All That Glitters", Carey had been introduced to DreamWorks producer Jeffrey Katzenberg, who asked her if she would record the song "When You Believe" for the soundtrack to the animated film "The Prince of Egypt". In an interview with "Ebony", Houston described working with Carey, as well as their growing friendship: "Mariah and I got along very great. We had never talked and never sang together before. We just had a chance for camaraderie, singer-to-singer, artist-to-artist, that kind of thing. We just laughed and talked and laughed and talked and sang in between that ... It's good to know that two ladies of soul and music can still be friends." "#1's" became a phenomenon in Japan, selling over one million copies in its opening week, and placing as the only international artist to accomplish this feat. When describing Carey's popularity in Japan throughout the 1990s, author Chris Nickson compared it to Beatlemania in the 1960s. The album sold over 3.25 million copies in Japan after only the first three months, and holds the record as the best-selling album by a non-Asian artist, while amassing global sales of over 17 million copies.
During the spring of 1999, Carey began working on the final album of her record contract with Sony, her ex-husband's label. During this time, Carey's strained relationship with Sony affected her work with writing partner Afanasieff, who had worked extensively with Carey throughout the first half of her career. She felt Mottola was trying to separate her from Afanasieff, in hopes of keeping their relationship permanently strained. Due to the pressure and the awkward relationship Carey had now developed with Sony, she completed the album in a period of three months in the summer of 1999, quicker than any of her other albums. The album, titled "Rainbow" (1999), found Carey once again working with a new array of music producers and songwriters, such as Jay-Z and DJ Clue?. Carey also wrote two ballads with David Foster and Diane Warren, whom she seemingly used to replace Afanasieff. "Rainbow" was released on November 2, 1999, to the highest first week sales of her career at the time, however debuting at number two on the "Billboard" 200. Throughout early-2000, Carey's troubled relationship with Columbia grew, as they halted promotion after the album's first two singles. They felt "Rainbow" didn't have any strong single to be released, whereas Carey wanted a ballad regarding personal and inner strength released. The difference in opinion led to a very public feud, as Carey began posting messages on her webpage in early and mid-2000, telling fans inside information on the dispute, as well as instructing them to request "Can't Take That Away (Mariah's Theme)" on radio stations. One of the messages Carey left on her page read: "Basically, a lot of you know the political situation in my professional career is not positive. It's been really, really hard. I don't even know if this message is going to get to you because I don't know if they want you to hear this. I'm getting a lot of negative feedback from certain corporate people. But I am not willing to give up." Fearing to lose their label's highest seller, Sony chose to release the song. Carey, initially content with the agreement, soon found out that the song had only been given a very limited and low-promotion release, which made charting extremely difficult and unlikely. Critical reception of "Rainbow" was generally enthusiastic, with the "Sunday Herald" saying that the album "sees her impressively tottering between soul ballads and collaborations with R&B heavyweights like Snoop Doggy Dogg and Usher [...] It's a polished collection of pop-soul." "Vibe" magazine expressed similar sentiments, writing, "She pulls out all stops [...] "Rainbow" will garner even more adoration". Though a commercial success, "Rainbow" became Carey's lowest selling album to that point in her career.
2001–04: "Glitter", "Charmbracelet", personal and professional struggles.
After she received "Billboard"'s Artist of the Decade Award and the World Music Award for Best-Selling Female Artist of the Millennium, Carey parted from Columbia and signed a $100 million five-album recording contract with Virgin Records (EMI Records). Carey was given full conceptual and creative control over the project. She opted to record an album partly mixed with 1980s influenced disco and other similar genres, in order to go hand-in-hand with the film's setting. She often stated that Columbia had regarded her as a commodity, with her separation from Mottola exacerbating her relations with label executives. Just a few months later, in July 2001, it was widely reported that Carey had suffered a physical and emotional breakdown. She had left messages on her website that complained of being overworked, and her relationship with the Latin icon Luis Miguel ended. In an interview the following year, she said, "I was with people who didn't really know me and I had no personal assistant. I'd do interviews all day long and get two hours of sleep a night, if that." Due to the pressure from the media, her heavy work schedule and the split from Miguel, Carey began posting a series of disturbing messages on her official website, and displayed erratic behavior on several live promotional outings. On July 19, 2001, Carey made a surprise appearance on the MTV program "Total Request Live" (TRL). As the show's host Carson Daly began taping following a commercial break, Carey came out pushing an ice cream cart while wearing a large men's shirt, and began a striptease, in which she shed her shirt to reveal a tight yellow and green ensemble. While she later revealed that Daly was aware of her presence in the building prior to her appearance, Carey's appearance on TRL garnered strong media attention. Only days later, Carey began posting irregular voice notes and messages on her official website: "I'm trying to understand things in life right now and so I really don't feel that I should be doing music right now. What I'd like to do is just a take a little break or at least get one night of sleep without someone popping up about a video. All I really want is [to] just be me and that's what I should have done in the first place ... I don't say this much but guess what, I don't take care of myself." Following the quick removal of the messages, Berger commented that Carey had been "obviously exhausted and not thinking clearly" when she posted the letters.
On July 26, she was suddenly hospitalized, citing "extreme exhaustion" and a "physical and emotional breakdown". Carey was inducted at an un-disclosed hospital in Connecticut, and remained hospitalized and under doctor's care for two weeks, followed by an extended absence from the public. Following the heavy media coverage surrounding Carey's publicized breakdown and hospitalization, Virgin Records and 20th Century Fox delayed the release of both "Glitter", as well as its soundtrack of the same name. Consequently, critics suggested that in delaying "Glitter", hype for the project would have largely subsided, and would possibly hurt both ticket and album sales. When discussing the project's weak commercial reaction, Carey blamed both her frame of mind during the time of its release, its postponement, as well as the soundtrack having been released on September 11. Critics panned "Glitter", as well as its accompanying soundtrack; both were unsuccessful commercially. The accompanying soundtrack album, "Glitter", became Carey's lowest-selling album to that point. The "St. Louis Post-Dispatch" dismissed it as "an absolute mess that'll go down as an annoying blemish on a career that, while not always critically heralded, was at least nearly consistently successful." Following the negative cloud that was ensuing Carey's personal life at the time, as well as the project's poor reception, her $100 million five-album record deal with Virgin Records (EMI Records) was bought out for $50 million. Soon after, Carey flew to Capri, Italy for a period of five months, in which she began writing material for her new album, stemming from all the personal experiences she had endured throughout the past year. Carey later said that her time at Virgin was "a complete and total stress-fest [...] I made a total snap decision which was based on money and I never make decisions based on money. I learned a big lesson from that." Later that year, she signed a contract with Island Records, valued at more than $24 million, and launched the record label MonarC. To add further to Carey's emotional burdens, her father, with whom she had little contact since childhood, died of cancer that year.
In 2002, Carey was cast in the independent film, "WiseGirls", alongside Mira Sorvino and Melora Walters, who co-starred as waitresses at a mobster-operated restaurant. It premiered at the Sundance Film Festival, and received generally negative critical response, though Carey's portrayal of the character was praised; Roger Friedman of Fox News referred to her as "a Thelma Ritter for the new millennium", and wrote, "Her line delivery is sharp and she manages to get the right laughs". Later that year, Carey performed the American national anthem to rave reviews at the Super Bowl XXXVI at the Louisiana Superdome in New Orleans, Louisiana. Towards the end of 2002, Carey released her next studio album "Charmbracelet", which she said marked "a new lease on life" for her. Though released in the wake of "Glitter" and Carey's return to the music scene, sales of "Charmbracelet" were moderate and the quality of Carey's vocals came under criticism. Joan Anderson from "The Boston Globe" declared the album "the worst of her career, and revealed a voice [that is] no longer capable of either gravity-defying gymnastics or soft coos", while AllMusic editor Stephen Thomas Erlewine expressed similar sentiments and wrote, "What is a greater problem is that Mariah's voice is shot, sounding in tatters throughout the record. She can no longer coo or softly croon nor can she perform her trademark gravity-defying vocal runs." In an attempt to "relaunch" her career following the poor reception to "Glitter", as well as her breakdown, Carey announced a world tour in April 2003. Lasting over eight months, the , became her most extensive tour to date, spanning sixty-nine shows around the world. Throughout the United States, the shows were done in smaller theaters, and something more Broadway-influenced, "It's much more intimate so you'll feel like you had an experience. You experience a night with me." However, while smaller productions were booked throughout the tour's stateside leg, Carey performed at stadiums in Asia and Europe, performing for a crowd of over 35,000 in Manila, 50,000 in Malaysia, and to over 70,000 people in China. In the United Kingdom, it became Carey's first tour to feature shows outside of London, booking arena stops in Glasgow, Birmingham and Manchester. Charmbracelet World Tour: An Intimate Evening with Mariah Carey garnered generally positive reviews from music critics and concert goers, with many complimenting the quality of Carey's live vocals, as well as the production as a whole.
2005–07: Commercial success with "The Emancipation of Mimi".
Throughout 2004, Carey focused on composing material for her tenth studio album, "The Emancipation of Mimi" (2005). The album found Carey working predominantly with Jermaine Dupri, as well as Bryan-Michael Cox, Manuel Seal, The Neptunes and Kanye West. The album debuted atop the charts in several countries, and was warmly accepted by critics. Caroline Sullivan of "The Guardian" defined it as "cool, focused and urban [... some of] the first Mariah Carey tunes in years which I wouldn't have to be paid to listen to again", while "USA Today"‍ '​s Elysa Gardner wrote, "The ballads and midtempo numbers that truly reflect the renewed confidence of a songbird who has taken her shots and kept on flying." The album's second single, "We Belong Together", became a "career re-defining" song for Carey, at a point when many critics had considered her career over. Music critics heralded the song as her "return to form", as well as the "return of The Voice", while many felt it would revive "faith" in Carey's potential as a balladeer. "We Belong Together" broke several records in the United States and became Carey's sixteenth chart topper on the "Billboard" Hot 100. After staying at number one for fourteen non-consecutive weeks, the song became the second longest running number one song in US chart history, behind Carey's 1996 collaboration with Boyz II Men, "One Sweet Day". "Billboard" listed it as the "song of the decade" and the ninth most popular song of all time. Besides its chart success, the song broke several airplay records, and according to Nielsen BDS, gathered both the largest one-day and one-week audiences in history.
During the week of September 25, 2005, Carey set another record, becoming the first female to occupy the first two spots atop the Hot 100, as "We Belong Together" remained at number one, and her next single, "Shake It Off" moved into the number two spot (Ashanti had topped the chart in 2002 while being a "featured" singer on the number two single). On the Billboard Hot 100 Year-end Chart of 2005, the song was declared the number one song, a career first for Carey. "Billboard" listed "We Belong Together" ninth on The "Billboard" Hot 100 All-Time Top Songs and was declared the most popular song of the 2000s decade by "Billboard". The album earned ten Grammy Award nominations in 2006–07: eight in 2006 for the original release (the most received by Carey in a single year), and two in 2007 for the "Ultra Platinum Edition" (from which "Don't Forget About Us" became her seventeenth number-one hit). In 2006 Carey won Best Contemporary R&B Album for "The Emancipation of Mimi", as well as Best Female R&B Vocal Performance and Best R&B Song for "We Belong Together". "The Emancipation of Mimi" was the best-selling album in the United States in 2005, with nearly five million units sold. It was the first album by a solo female artist to become the year's best-selling album since Alanis Morissette's "Jagged Little Pill" in 1996. At the end of 2005, the IFPI reported that "The Emancipation of Mimi" had sold more than 7.7 million copies globally, and was the second-best-selling album of the year after Coldplay's "X&Y". It was the best-selling album worldwide by a solo and female artist. To date, "The Emancipation of Mimi" has sold over 12 million copies worldwide. At the 48th Grammy Awards, Carey performed a medley of "We Belong Together" and "Fly Like a Bird".
In support of the album, Carey embarked on her first headlining tour in three years, named The Adventures of Mimi: The Voice, The Hits, The Tour after a "Carey-centric fan's" music diary. The tour spanned forty stops, with thirty-two in the United States and Canada, two in Africa, and six in Japan. It received warm reaction from music critics and concert goers, many of which celebrated the quality of Carey's live vocals, as well as the show as a whole. The tour proved successful, with Carey playing to over 60,000 fans in the two stops in Tunis alone. "The Adventures of Mimi" DVD was released in November 2007 internationally and December 2007 in the US.
2008–09: "E=MC²" and "Memoirs of an Imperfect Angel".
By spring 2007, Carey had begun to work on her eleventh studio album, "E=MC²", in a private villa in Anguilla. Although "E=MC²" was well received by most critics, some of them criticized it for being very similar to the formula used on "The Emancipation of Mimi". Two weeks before the album's release, "Touch My Body", the record's lead single, reached the top position on the "Billboard" Hot 100, becoming Carey's eighteenth number one and making her the solo artist with the most number one singles in United States history, pushing her past Elvis Presley into second place according to the magazine's revised methodology. Carey is second only to The Beatles, who have twenty number-one singles. Additionally, it gave Carey her 79th week atop the Hot 100, tying her with Presley as the artist with the most weeks at number one in the "Billboard" chart history."
"E=MC²" debuted at number one on the "Billboard" 200 with 463,000 copies sold, the biggest opening week sales of her career. With six number one albums, Carey was tied with Britney Spears and Janet Jackson in the United States for the third most number one albums for a female artist, behind Madonna with eight and Barbra Streisand's ten chart toppers. In 2008, "Billboard" magazine ranked her at number six on the "Billboard" Hot 100 All-Time Top Artists, making Carey the second most successful female artist in the history of the "Billboard" Hot 100 chart. That year, Carey also played an aspiring singer named Krystal in "Tennessee" and had a cameo appearance in Adam Sandler's film "You Don't Mess with the Zohan", playing herself. Since the album's release, Carey had planned to embark on an extensive tour in support of "E=MC²". However the tour was suddenly cancelled in early December 2008. Carey later stated that she had been pregnant during that time period, and suffered a miscarriage, hence she cancelled the tour. On January 20, 2009, Carey performed "Hero" at the Neighborhood Inaugural Ball after Barack Obama was sworn as the first African-American president of the United States. On July 7, 2009, Carey – alongside Trey Lorenz – performed her version of The Jackson 5 song "I'll Be There" at the memorial service for Michael Jackson.
In 2009, she appeared as a social worker in "Precious", the movie adaptation of the 1996 novel "Push" by Sapphire. The film garnered mostly positive reviews from critics, also for Carey's performance. "Variety" described her acting as "pitch-perfect". In January 2010, Carey won the Breakthrough Actress Performance Award for her role in "Precious" at the Palm Springs International Film Festival. On September 25, 2009, Carey's twelfth studio album, "Memoirs of an Imperfect Angel", was released. Reception for the album was mostly mixed; Stephen Thomas Erlewine of AllMusic called it "her most interesting album in a decade", while Jon Caramanica from "The New York Times" criticized Carey's vocal performances, decrying her overuse of her softer vocal registers at the expense of her more powerful lower and upper registers. Commercially, the album debuted at number three on the "Billboard" 200, and became the lowest-selling studio album of her career. The album's lead single, "Obsessed", debuted at number eleven and peaked at number seven on the chart, and became Carey's 27th US top-ten hit, tying her with Elton John and Janet Jackson as the fifth most top-ten hits. The album's follow-up single, a cover of Foreigner's "I Want to Know What Love Is", managed to break airplay records in Brazil. The song spent 27 weeks atop the Brasil Hot 100 Airplay, making it the longest running song in the chart's history.
On December 31, 2009, Carey embarked her seventh concert tour, Angels Advocate Tour, which visited the United States and Canada and ended on September 26, 2010. A planned remix album of "Memoirs of an Imperfect Angel"; titled "Angels Advocate" was slated for a March 30, 2010 release, but was eventually cancelled.
2010–14: "Merry Christmas II You", "American Idol", and "Me. I Am Mariah... The Elusive Chanteuse".
Following the cancellation of "Angels Advocate", it was announced that Carey would return to the studio to start work on her thirteenth studio album. It was later revealed that it would be her second Christmas album, and follow-up to "Merry Christmas". Longtime collaborators for the project included Jermaine Dupri, Johntá Austin, Bryan-Michael Cox, and Randy Jackson, as well as new collaborators such as Marc Shaiman. The release date for the album, titled "Merry Christmas II You", was November 2, 2010; the track list included six new songs as well as a remix of "All I Want for Christmas Is You". "Merry Christmas II You" debuted at number four on the "Billboard" 200 with sales of 56,000 copies, becoming Carey's 16th top ten album in the United States. The album debuted at number one on the R&B/Hip-Hop Albums chart, making it only the second Christmas album to top this chart.
In May 2010, Carey dropped out of her planned appearance in "For Colored Girls", the film adaptation of the play "For Colored Girls Who Have Considered Suicide When the Rainbow Is Enuf", citing medical reasons. In February 2011, Carey announced that she had officially began writing new material for her upcoming fourteenth studio album. Carey recorded a duet with Tony Bennett for his "Duets II" album, titled "When Do The Bells Ring For Me". In October 2011, Carey announced that she re-recorded "All I Want for Christmas Is You" with Justin Bieber as a duet for his Christmas album, "Under the Mistletoe". In November 2011, Carey was included in the remix to the mixtape single "Warning" by Uncle Murda; the remix also features 50 Cent and Young Jeezy. That same month, Carey released a duet with John Legend titled "When Christmas Comes", originally part of "Merry Christmas II You".
On March 1, 2012, Carey performed at New York City's Gotham Hall; her first time performing since pregnancy. She also performed a three song set at a special fundraiser for US President Barack Obama held in New York's Plaza Hotel. A new song titled "Bring It On Home", which Carey wrote specifically for the event to show her support behind Obama's re-election campaign, was also performed. In August 2012, she released a stand alone single, "Triumphant (Get 'Em)", featuring American rappers Rick Ross and Meek Mill and co-written and co-produced by Carey, Jermaine Dupri, and Bryan-Michael Cox. Carey joined the judging panel of "American Idol" season twelve as Jennifer Lopez's replacement, joining Randy Jackson, Nicki Minaj and Keith Urban. In November 2013, she explained about hating to work at "American Idol" adding, "It was like going to work every day in hell with Satan", referring to her on-set squabbles with Minaj. Carey appeared in Lee Daniels' 2013 film "The Butler", about a White House butler who served eight American Presidents over the course of three decades. Carey made guest voice-star as a redneck character on the adult animated series "American Dad!" on November 24, 2013.
In February 2013 Carey recorded and released a song called "Almost Home", for the soundtrack of the Walt Disney Studios film "Oz the Great and Powerful". The video was directed by photographer David LaChapelle. News started coming around about the singer's fourteenth studio album. Some of the people that Carey worked with on the album included: DJ Clue?, Randy Jackson, Q-Tip, R. Kelly, David Morales, Loris Holland, Stevie J, James Fauntleroy II, Ray Angry, Afanasieff, Dupri, Bryan-Michael Cox, James "Big Jim" Wright, Hit-Boy, The-Dream, Da Brat, and Rodney Jerkins. Carey told "Billboard": "It's about making sure I have tons of good music, because at the end of the day that's the most important thing... There are a lot more raw ballads than people might expect...there are also uptempo and signature-type songs that represent [my] different facets as an artist".
The lead single, "Beautiful" featuring singer Miguel, was released on May 6, 2013, and peaked at number 15 on the Hot 100. Carey taped a performance of "Beautiful" along with a medley of her greatest hits on May 15, 2013; the taping aired on the "American Idol" finale the following day. On October 14, 2013, Carey announced that the album's former title track has been chosen as the second single; it premiered via Facebook on November 11, 2013. During a Q&A session following the song's release, Carey gave an update about the album, stating: "Now I've been inspired to add two more songs, so we're almost there. I can't even express this properly but I feel like this is gonna be my favorite album". Following another song release, "You're Mine (Eternal)", it was announced that "The Art of Letting Go" would no longer be the title of the album. After the final name was announced, "Me. I Am Mariah... The Elusive Chanteuse" was released on May 27, 2014. A fourth single, "You Don't Know What to Do" featuring rapper Wale, was released on June 30, 2014 with limited success, not charting in her home country of the US but peaking at number 2 on the South Korea GAON International chart and 14 on the Belgium Ultratip Wallonia chart.
2015: Residency show in Las Vegas and "#1 to Infinity".
On January 15, 2015, Carey announced on "The Ellen DeGeneres Show" that she will be taking up residency at The Colosseum at the Caesars Palace hotel in Las Vegas, stating "I have to hope that the fans will enjoy this cause I'm gonna be performing, which was kind of inspired by my album "#1's", and this is now the updated version with 18 of them". On January 30, it was announced that Carey has left Universal Music Group's Def Jam Recordings to re-unite with L.A. Reid and Sony Music via Epic Records.
To coincide with the residency, Carey is set to release "#1 to Infinity", a greatest hits compilation which will contain all of her eighteen "Billboard" Hot 100 number one singles, along with a new recording, "Infinity", which will be released as a single on April 27.
Philanthropy and other activities.
Carey is a philanthropist who has been involved with several charitable organizations. She became associated with the Fresh Air Fund in the early 1990s, and is the co-founder of a camp located in Fishkill, New York, that enables inner-city youth to embrace the arts and introduces them to career opportunities. The camp was called Camp Mariah "for her generous support and dedication to Fresh Air children", and she received a Congressional Horizon Award for her youth-related charity work. Carey also donated royalties from her hits "Hero" and "One Sweet Day" to charities. She is well-known nationally for her work with the Make-A-Wish Foundation in granting the wishes of children with life-threatening illnesses, and in November 2006 she was awarded the Foundation's Wish Idol for her "extraordinary generosity and her many wish granting achievements". Carey has volunteered for the New York City Police Athletic League and contributed to the obstetrics department of New York Presbyterian Hospital Cornell Medical Center. A percentage of the sales of "MTV Unplugged" was donated to various other charities. In 2008, Carey was named Hunger Ambassador of the World Hunger Relief Movement. In February 2010, the song, "100%", which was originally written and recorded for the film, "Precious", was used as one of the theme songs for the 2010 Winter Olympics, with all money proceeds going to Team USA.
One of Carey's most high-profile benefit concert appearances was on VH1's 1998 "Divas Live" special, during which she performed alongside other female singers in support of the Save the Music Foundation. The concert was a ratings success, and Carey participated in the Divas 2000 special. In 2007, the Save the Music Foundation honored Carey at their tenth gala event for her support towards the foundation since its inception. She appeared at the "" nationally televised fundraiser in the aftermath of the September 11 attacks, and in December 2001, she performed before peacekeeping troops in Kosovo. Carey hosted the CBS television special "At Home for the Holidays", which documented real-life stories of adopted children and foster families. In 2005, Carey performed for Live 8 in London and at the Hurricane Katrina relief telethon "Shelter from the Storm". In August 2008, Carey and other singers recorded the charity single, "Just Stand Up" produced by Babyface and L. A. Reid, to support "Stand Up to Cancer". In 2008, Carey performed in a New Year's Eve concert for the family of Libyan dictator Muammar Gaddafi, something she later claimed to "feel horrible and embarrassed to have participated in". In March 2011, Carey's representative Cindi Berger stated that royalties for the song "Save The Day", which was written for her fourteenth studio album, will be donated to charities that create awareness to human rights issues to make amends for the Gadaffi error. Berger also said that "Mariah has and continues to donate her time, money and countless hours of personal service to many organizations both here and abroad".
Declining offers to appear in commercials in the United States during her early career, Carey was not involved in brand marketing initiatives until 2006, when she participated in endorsements for Intel Centrino personal computers and launched a jewelry and accessories line for teenagers, Glamorized, in American Claire's and Icing stores. During this period, as part of a partnership with Pepsi and Motorola, Carey recorded and promoted a series of exclusive ringtones, including "Time of Your Life". She signed a licensing deal with the cosmetics company Elizabeth Arden, and in 2007, she released her own fragrance, "M". The Elizabeth Arden deal has netted her $150 million. In 2007, "Forbes" named her as the fifth richest woman in entertainment, with an estimated net worth of US$270 million. In November 2011, it was reported that Carey's net worth was valued at more than $500 million. On November 29, 2010, she debuted a collection on HSN, which included jewelry, shoes and fragrances. In November 2011, Carey was announced as the new global ambassador for Jenny Craig, following her weight loss with the program after giving birth to fraternal twins in April. Carey claims she lost 70 lb on the program. In 2013, human rights activists criticized Carey for performing in a concert for Angola's "father-daughter kleptocracy" and accused her of accepting "dictator cash".
Artistry.
Musical style.
Love is the subject of the majority of Carey's lyrics, although she has written about themes such as racism, social alienation, death, world hunger, and spirituality. She has said that much of her work is partly autobiographical, but "Time" magazine wrote: "If only Mariah Carey's music had the drama of her life. Her songs are often sugary and artificial—NutraSweet soul. But her life has passion and conflict," applying it to the first stages of her career. He commented that as her albums progressed, so too her songwriting and music blossomed into more mature and meaningful material. Jim Faber of the "New York Daily News", made similar comments, "For Carey, vocalizing is all about the performance, not the emotions that inspired it. Singing, to her, represents a physical challenge, not an emotional unburdening." While reviewing "Music Box", Stephen Holden from "Rolling Stone" commented that Carey sang with "sustained passion", while Arion Berger of "Entertainment Weekly" wrote that during some vocal moments, Carey becomes "too overwhelmed to put her passion into words." In 2001, "The Village Voice" wrote in regards to what they considered Carey's "centerless ballads", writing, "Carey's Strawberry Shortcake soul still provides the template with which teen-pop cuties draw curlicues around those centerless [Diane] Warren ballads [...] it's largely because of [Blige] that the new R&B demands a greater range of emotional expression, smarter poetry, more from-the-gut testifying, and less [sic] unnecessary notes than the squeaky-clean and just plain squeaky Mariah era. Nowadays it's the Christina Aguileras and Jessica Simpsons who awkwardly oversing, while the women with roof-raising lung power keep it in check when tune or lyric demands."
Carey's output makes use of electronic instruments such as drum machines, keyboards and synthesizers. Many of her songs contain piano-driven melodies, as she was given piano lessons when she was six years old. Carey said that she cannot read sheet music and prefers to collaborate with a pianist when composing her material, but feels that it is easier to experiment with faster and less conventional melodies and chord progressions using this technique. While Carey learned to play the piano at a young age, and incorporates several ranges of production and instrumentation into her music, she has maintained that her voice has always been her most important asset: "My voice is my instrument; it always has been." Carey began commissioning remixes of her material early in her career and helped to spearhead the practice of recording entirely new vocals for remixes. Disc jockey David Morales has collaborated with Carey on several occasions, starting with "Dreamlover" (1993), which popularized the tradition of remixing R&B songs into house records, and which "Slant" magazine named one of the greatest dance songs of all time. From "Fantasy" (1995) onward, Carey enlisted both hip-hop and house producers to re-structure her album compositions. "Entertainment Weekly" included two remixes of "Fantasy" on a list of Carey's greatest recordings compiled in 2005: a National Dance Music Award-winning remix produced by Morales, and a Sean Combs production featuring rapper Ol' Dirty Bastard. The latter has been credited with popularizing the R&B/hip-hop collaboration trend that has continued into the 2000s, through artists such as Ashanti and Beyoncé. Combs said that Carey "knows the importance of mixes, so you feel like you're with an artist who appreciates your work—an artist who wants to come up with something with you".
Voice and timbre.
"I have nodules on my vocal cords. My mother says I've had them since I was a kid. That's why I have the high register and the belting register and I can still be husky. A lot of people couldn't sing through the nodules the way I do; I've learned to sing "through" my vocal cords. The only thing that really affects my voice is sleep. Sometimes if I'm exhausted, I can't hit the really high notes. My doctors showed me my vocal cords and why I can hit those high notes. It's a certain part of the cord that not many people use—the very top. My natural voice is low. I have a raspy voice. I'm really more of an alto. But my airy voice can be high if I'm rested. [...] When I was little, I'd talk in this really high whisper, and my mom would be like, 'You're being ridiculous'. I thought if I can talk like that I can sing like that. So I started just messing around with it. I'd practice and practice, and she'd be like, 'You're gonna hurt yourself'. I'd tell her, it doesn't hurt. If I were to try and belt two octaves lower than that, that would be a strain."
—Carey on her usage of the whistle register
Carey possesses a five-octave vocal range, and has the ability to reach notes beyond the 7th octave. Referred to as the "songbird supreme" by the "Guinness World Records", she was ranked first in a 2003 MTV and "Blender" magazine countdown of the 22 Greatest Voices in Music, as voted by fans and readers in an online poll. Carey said of the poll, "What it really means is voice of the MTV generation. Of course, it's an enormous compliment, but I don't feel that way about myself." She also placed second in "Cove" magazine's list of "The 100 Outstanding Pop Vocalists".
Regarding her voice type, Carey said that she is an alto, though several critics have described her as a soprano. However, within contemporary forms of music, singers are classified by the style of music they sing. There is currently no authoritative voice classification system within non-classical music. Attempts have been made to adopt classical voice type terms to other forms of singing, but they are controversial, because the development of classical voice categorizations were made with the understanding that the singer would amplify his or her voice with their natural resonators, without a microphone.
Jon Pareles of "The New York Times" described Carey's lower register as a "rich, husky alto" that extends to "dog-whistle high notes". Additionally, towards the late 1990s, Carey began incorporating breathy vocals into her material. Tim Levell from the BBC News described her vocals as "sultry close-to-the-mic breathiness", while "USA Today"‍ '​s Elysa Gardner wrote "it's impossible to deny the impact her vocal style, a florid blend of breathy riffing and resonant belting, has had on today's young pop and R&B stars."
Sasha Frere-Jones of "The New Yorker" adds her timbre possesses various colors, saying, "Carey's sound changes with nearly every line, mutating from a steely tone to a vibrating growl and then to a humid, breathy coo. Her wide vocal range allows Carey to take melodies from alto bottom notes to coloratura soprano upper register." Carey also possesses a "whisper register". In an interview with the singer, Ron Givens of "Entertainment Weekly" described it this way, "first, a rippling, soulful ooh comes rolling effortlessly from her throat: alto. Then, after a quick breath, she goes for the stratosphere, with a sound that nearly changes the barometric pressure in the room. In one brief swoop, she seems to squeal and roar at the same time."
Her sense of pitch is admired and Jon Pareles adds "she can linger over sensual turns, growl with playful confidence, syncopate like a scat singer... with startlingly exact pitch."
Influences.
Carey has said that from childhood she has been influenced by Billie Holiday, Sarah Vaughan, and R&B and soul musicians such as Gladys Knight and Aretha Franklin. Her music contains strong influences of gospel music, and she credits The Clark Sisters, Shirley Caesar and Edwin Hawkins as the most influential in her early years. When Carey incorporated hip-hop into her sound, speculation arose that she was making an attempt to take advantage of the genre's popularity, but she told "Newsweek", "People just don't understand. I grew up with this music". She has expressed appreciation for rappers such as The Sugarhill Gang, Eric B. & Rakim, the Wu-Tang Clan, The Notorious B.I.G. and Mobb Deep, with whom she collaborated on the single "The Roof (Back in Time)" (1998). Carey was heavily influenced by Minnie Riperton, and began experimenting with the whistle register due to her original practice of the range.
During Carey's career, her vocal and musical style, along with her level of success, has been compared to Whitney Houston, who she has also cited as an influence, and Celine Dion. Carey and her peers, according to Garry Mulholland, are "the princesses of wails [...] virtuoso vocalists who blend chart-oriented pop with mature MOR torch song". Author and writer Lucy O'Brien attributed the comeback of Barbra Streisand's "old-fashioned showgirl" to Carey and Dion, and described them and Houston as "groomed, airbrushed and overblown to perfection". Carey's musical transition and use of more revealing clothing during the late 1990s were, in part, initiated to distance herself from this image, and she subsequently said that most of her early work was "schmaltzy MOR". Some have noted that unlike Houston and Dion, Carey co-writes and produces her own songs.
Legacy.
Carey's vocal style and singing ability have significantly impacted popular and contemporary music. As music critic G. Brown from "The Denver Post" wrote, "For better or worse, Mariah Carey's five-octave range and melismatic style have influenced a generation of pop singers." According to "Rolling Stone", "Her mastery of melisma, the fluttering strings of notes that decorate songs like "Vision of Love", inspired the entire "American Idol" vocal school, for better or worse, and virtually every other female R&B singer since the Nineties." Jody Rosen of "Slate" wrote of Carey's influence in modern music, calling her the most influential vocal stylist of the last two decades, the person who made rococo melismatic singing. Rosen further exemplified Carey's influence by drawing parallel with American Idol, which to her, "often played out as a clash of melisma-mad Mariah wannabes. And, today, nearly 20 years after Carey's debut, major labels continue to bet the farm on young stars such as the winner of Britain's X Factor show, Leona Lewis, with her Generation Next gloss on Mariah's big voice and big hair." Sean Daly of "St. Petersburg Times" wrote, "Depending on how you feel about public humiliation, the best/worst parts of American Idol are the audition shows, which normally break down into three distinct parts:(1) The Talented Kids.(2) The Weird Kids.(3) The Mariahs." Daly further commented, "The Mariahs are the hardest ones to watch, mainly because most of them think they're reeeaaally good. The poor, disillusioned hopefuls plant themselves in front of judges Simon Cowell, Paula Abdul and Randy Jackson – then proceed to stretch, break and mutilate every note of a song, often Mariah's Hero, a tune that has ruined more throats than smoker's cough." "New York Magazine's" editor Roger Deckker said that in regarding Carey as an influential artist in music, he commented that "Whitney Houston may have introduced melisma (the vocally acrobatic style of lending a word an extra syllable or twenty) to the charts, but it was Mariah—with her jaw-dropping range—who made it into America's default sound." Deckker also added that "Every time you turn on American Idol, you are watching her children". Despite her vocal prowess, Carey's vocal technique particularly with the use of melisma and belting, has been subject to public scrutiny mainly because of young singers such as from talent shows have been overly imitating her singing technique in which critics commented "Mariah Carey is, without a doubt, the worst thing to happen to amateur singing since the karaoke machine". As Professor Katherine L. Meizel noted in her book, "The Mediation of Identity Politics in American Idol", "Carey's influence not just stops in the emulation of melisma or her singing amongst the wannabe's, it's also her persona, her diva, her stardom which inspires them... a pre-fame conic look."
Among the hip hop, pop, and R&B artists who have cited Carey as an influence are; Aneeka, Ariana Grande, Britney Spears, Beyoncé, Christina Aguilera, Jessica Simpson, Rihanna, Grimes, Kelly Clarkson, Nelly Furtado, Leona Lewis, Brandy Norwood, Pink, Mary J. Blige, Melanie Fiona, Missy Elliott and Jessica Sanchez According to Stevie Wonder, "When people talk about the great influential singers, they talk about Aretha, Whitney and Mariah. That's a testament to her talent. Her range is that amazing." Beyoncé credits Carey's singing and her song "Vision of Love" as influencing her to begin practicing vocal "runs" as a child, as well as helping her pursue a career as a musician. Rihanna has stated that Carey is one of her major influences and idol. Christina Aguilera said in the early stages of her career that Carey was a big influence in her singing career and one of her idols. According to Pier Dominguez, author of "Christina Aguilera: A star is made", Aguilera has stated how she loved listening to Whitney Houston, but it was Carey who had the biggest influence on her vocal styling. Carey's carefully choreographed image of a grown woman struck a chord with Aguilera. Her influence on Aguilera also grew from the fact that both are of mixed heritage. Philip Brasor, editor of "The Japan Times", expressed how Carey's vocal and melismatic style even influenced Asian singers. He wrote that Japanese singer Utada Hikaru "sang what she heard, from the diaphragm and with her own take on the kind of melisma that became de rigueur in American pop after the ascendance of Mariah Carey."
In an article titled "Out With Mariah's Melisma, In With Kesha's Kick", writer David Browne of "The New York Times" discusses how the once ubiquitous melisma pop style suddenly lost in favor of the now ubiquitous autotune in which the former was heavily popularized by the likes of Mariah Carey and Whitney Houston. Browne had commented "But beginning two decades ago, melisma overtook pop in a way it hadn't before. Mariah Carey's debut hit from 1990, "Vision of Love," followed two years later by Whitney Houston's version of "I Will Always Love You," set the bar insanely high for notes stretched louder, longer and knottier than most pop fans had ever heard." Browne further added "A subsequent generation of singers, including Ms. Aguilera, Jennifer Hudson and Beyoncé, built their careers around melisma. (Men like Brian McKnight and Tyrese also indulged in it, but women tended to dominate the form.)"
Carey is also credited for introducing R&B and hip hop into mainstream pop culture, and for popularizing rap as a featuring act through her post-1995 songs. Sasha Frere-Jones, editor of "The New Yorker" commented, "It became standard for R&B/hip-hop stars like Missy Elliott and Beyoncé, to combine melodies with rapped verses. And young white pop stars—including Britney Spears, Jessica Simpson, Christina Aguilera, and 'N Sync—have spent much of the past ten years making pop music that is unmistakably R&B." Moreover Jones concludes that "[Carey's] idea of pairing a female songbird with the leading male MCs of hip-hop changed R&B and, eventually, all of pop. Although now anyone is free to use this idea, the success of "The Emancipation of Mimi" suggests that it still belongs to Carey." Judnick Mayard, writer of "The Fader", wrote that in regarding of R&B and hip hop collaboration, "The champion of this movement is Mariah Carey." Mayard also expressed that "To this day ODB and Mariah may still be the best and most random hip hop collaboration of all time", citing that due to the record "Fantasy", "R&B and Hip Hop were the best of step siblings."
Kelefa Sanneh of "The New York Times" wrote, "In the mid-1990s Ms. Carey pioneered a subgenre that some people call the thug-love duet. Nowadays clean-cut pop stars are expected to collaborate with roughneck rappers, but when Ms. Carey teamed up with Ol' Dirty Bastard, of the Wu-Tang Clan, for the 1995 hit "Fantasy (Remix)", it was a surprise, and a smash." Aside from her pop culture and musical influence, Carey is credited for releasing a classic Christmas song called "All I Want for Christmas Is You". In a retrospective look at Carey's career, Sasha Frere-Jones of "The New Yorker" said, the "charming" song was one of Carey's biggest accomplishments, calling it "one of the few worthy modern additions to the holiday canon". "Rolling Stone" ranked "All I Want for Christmas Is You" fourth on its Greatest Rock and Roll Christmas Songs list, calling it a "holiday standard." In a review of her "Greatest Hits" album, Devon Powers of PopMatters writes that "She has influenced countless female vocalists after her. At 32, she is already a living legend—even if she never sings another note." While reviewing a concert of Carey in Sydney, Elise Vout of "MTV Australia" wrote that "it's not amazing choreography or high production value you're going to see, it's the larger than life personality, unique voice, and legend that is Mariah Carey."
Personal life.
Carey began dating Mottola while recording "Music Box", and married him on June 5, 1993. After the release of "Daydream" and the success that followed, Carey began focusing on her personal life, which was a constant struggle at the time. Carey's relationship with Mottola began to deteriorate, due to their growing creative differences in terms of her albums, as well as his controlling nature. The couple divorced in 1998.
Carey met actor and comedian Nick Cannon while they shot her music video for her song "Bye Bye" on an island off the coast of Antigua. On April 30, 2008, Carey married Cannon in The Bahamas. 35 weeks into her pregnancy, she gave birth to their fraternal twins, Monroe and Moroccan, on April 30, 2011.
In August 2014, Cannon confirmed that he and Carey had separated a few months earlier.
Mariah Carey is a Christian. She said in 2006: "I do believe that I have been born again in a lot of ways. I think what I've changed are my priorities and my relationships with God. I feel the difference when I don't have my private moments to pray. ... I'm a fighter, but I learned that I'm not in charge. Whatever God wants to happen is what's going to happen. I feel like I've had endless second, third, fourth, fifth and sixth chances. It's by the grace of God I'm still here."
Honors and awards.
Throughout Carey's career, she has collected many honors and awards, including the World Music Awards' Best Selling Female Artist of the Millennium, the Grammy's Best New Artist in 1991, and "Billboard"'s Special Achievement Award for the Artist of the Decade during the 1990s. In a career spanning over 20 years, Carey has sold over 200 million records worldwide, making her one of the biggest-selling artists in music history. Carey is ranked as the best-selling female artist of the Nielsen SoundScan era, with over 52 million copies sold. Possessing a five-octave vocal range, Carey was ranked first in MTV and "Blender" magazine's 2003 countdown of the 22 Greatest Voices in Music, and was placed second in "Cove" magazine's list of "The 100 Outstanding Pop Vocalists". Aside from her voice, she has become known for her songwriting. Yahoo Music editor Jason Ankeny wrote, "She earned frequent comparison to rivals Whitney Houston and Celine Dion, but did them both one better by composing all of her own material." According to "Billboard" magazine, she was the most successful artist of the 1990s in the United States. At the 2000 World Music Awards, Carey was given a Legend Award for being the "best-selling female pop artist of the millennium", as well as the "Best-selling artist of the 90s" in the United States, after releasing a series of albums of multiplatinum status in Asia and Europe, such as "Music Box" and "Number 1's". She is also a recipient of the Chopard Diamond award in 2003, recognizing sales of over 100 million albums worldwide. Additionally, the Recording Industry Association of America (RIAA) lists Carey as the third-best-selling female artist, with shipments of over 63 million units in the US. In Japan, Carey has the top four highest-selling albums of all time by a non-Asian artist.
Carey has spent 79 weeks at the number-one position on "Billboard" Hot 100, the greatest number for any artist in US chart history. On that same chart, she has accumulated 18 number-one singles, the most for any solo artist (and second after The Beatles). In 1994, Carey released her holiday album "Merry Christmas" has sold over 15 million copies worldwide, and is the best-selling Christmas album of all time. It also produced the successful single "All I Want for Christmas Is You", which became the only holiday song and ringtone to reach multi-platinum status in the US. In Japan, "Number 1's" has sold over 3,250,000 copies and is the best-selling album of all time in Japan by a non-Asian artist. Her hit single "One Sweet Day", which featured Boyz II Men, spent sixteen consecutive weeks at the top of "Billboard"‍ '​s Hot 100 chart in 1996, setting the record for the most weeks atop the Hot 100 chart in history. After Carey's success in Asia with "Merry Christmas", "Billboard" estimated Carey as the all-time best-selling international artist in Japan. In 2008, "Billboard" listed "We Belong Together" ninth on The "Billboard" Hot 100 All-Time Top Songs and second on Top Billboard Hot 100 R&B/Hip-Hop Songs. The song was also declared the most popular song of the 2000s decade by "Billboard". In 2009, Carey's cover of Foreigner's song "I Want to Know What Love Is" became the longest-running number-one song in Brazilian singles chart history, spending 27 consecutive weeks at number-one. Additionally, Carey has had three songs debut at number-one on the "Billboard" Hot 100: "Fantasy", "One Sweet Day" and "Honey", making her the artist with the most number-one debuts in the chart's 52-year history. Also, she is the first female artist to debut at number 1 in the U.S. with "Fantasy". In 2010, Carey's 13th album and second Christmas album, "Merry Christmas II You", debuted at No.1 on the R&B/Hip-Hop Albums chart, making it only the second Christmas album to top that chart. On November 19, 2010, "Billboard" magazine named Carey in their "Top 50 R&B/Hip-Hop Artists of the Past 25 Years" chart at number four. In 2012, Carey was ranked second on VH1's list of the "100 Greatest Women in Music".
References.
Sources.
</dl>

</doc>
<doc id="19500" url="http://en.wikipedia.org/wiki?curid=19500" title="Mervyn Peake">
Mervyn Peake

Mervyn Laurence Peake (9 July 1911 – 17 November 1968) was an English writer, artist, poet and illustrator. He is best known for what are usually referred to as the "Gormenghast" books. The three works were part of what Peake conceived as a lengthy cycle, the completion of which was prevented by his death. They are sometimes compared to the work of his older contemporary J. R. R. Tolkien, but his surreal fiction was influenced by his early love for Charles Dickens and Robert Louis Stevenson rather than Tolkien's studies of mythology and philology.
Peake also wrote poetry and literary nonsense in verse form, short stories for adults and children ("Letters from a Lost Uncle"), stage and radio plays, and "Mr Pye", a relatively tightly-structured novel in which God implicitly mocks the evangelical pretensions and cosy world-view of the eponymous hero.
Peake first made his reputation as a painter and illustrator during the 1930s and 1940s, when he lived in London, and he was commissioned to produce portraits of well-known people. For a short time at the end of World War II he was commissioned by various newspapers to depict war scenes. A collection of his drawings is still in the possession of his family. Although he gained little popular success in his lifetime, his work was highly respected by his peers, and his friends included Dylan Thomas and Graham Greene. His works are now included in the collections of the National Portrait Gallery, the Imperial War Museum and The National Archives.
In 2008, "The Times" named Peake among their list of "The 50 greatest British writers since 1945".
Early life.
Mervyn Peake was born of British parents in Kuling (Lushan) in Jiangxi Province of central China in 1911, only three months before the revolution and the founding of the Republic of China. His father Ernest Cromwell Peake was a medical missionary doctor with the London Missionary Society of the Congregationalist tradition and his mother, Amanda Elizabeth Powell, had come to China as a missionary assistant.
The Peakes were given leave to visit England just before World War I in 1914 and returned to China in 1916. Mervyn Peake attended Tientsin Grammar School until the family left for England in December 1922 via the Trans-Siberian Railway. About this time he wrote a novella, "The White Chief of the Umzimbooboo Kaffirs". Peake never returned to China but it has been noted that Chinese influences can be detected in his works, not least in the castle of Gormenghast itself, which in some respects echoes the ancient walled city of Beijing, as well as the enclosed compound where he grew up in Tianjin. It is also likely that his early exposure to the contrasts between the lives of the Europeans and of the Chinese, and between the poor and the wealthy in China, also exerted an influence on the Gormenghast books.
His education continued at Eltham College, Mottingham (1923–29), where his talents were encouraged by his English teacher, Eric Drake. Peake completed his formal education at Croydon School of Art in the autumn of 1929 and then from December 1929 to 1933 at the Royal Academy Schools, where he first painted in oils. By this time he had written his first long poem, "A Touch o' the Ash". In 1931 he had a painting accepted for display by the Royal Academy and exhibited his work with the so-called "Soho Group".
Career.
His early career in the 1930s was as a painter in London, although he lived on the Channel Island of Sark for a time. He first moved to Sark in 1932 where his former teacher Eric Drake was setting up an artists' colony. In 1934 he exhibited with the Sark artists both in the Sark Gallery built by Drake and at the Cooling Galleries in London. In 1935 he exhibited at the Royal Academy and at the Leger Galleries in London.
In 1936 he returned to London and was commissioned to design the sets and costumes for "Insect Play" and his work was acclaimed in "The Sunday Times". He also began teaching life drawing at Westminster School of Art where he met the painter Maeve Gilmore, whom he married in 1937. They had three children, Sebastian (1940–2012), Fabian (b. 1942), and Clare (b. 1949).
He had a very successful exhibition of paintings at the Calmann Gallery in London in 1938 and his first book, the self-illustrated children's pirate romance "Captain Slaughterboard Drops Anchor" (based on a story he had written around 1936) was first published in 1939 by Country Life. In December 1939 he was commissioned by Chatto & Windus to illustrate a children's book, "Ride a Cock Horse and Other Nursery Rhymes", published for the Christmas market in 1940.
Enlistment.
At the outbreak of World War II he applied to become a war artist for he was keen to put his skills at the service of his country. He imagined "An Exhibition by the Artist, Adolf Hitler", in which horrific images of war with ironic titles were offered as 'artworks' by the Nazi leader. Although the drawings were bought by the British Ministry of Information, his application was turned down and he was conscripted in the Army, where he served first with the Royal Artillery, then with the Royal Engineers. He began writing "Titus Groan" at this time.
In April 1942, after his requests for commissions as a war artist – or even leave to depict war damage in London – had been consistently refused, he suffered a nervous breakdown and was sent to Southport Hospital. That autumn he was taken on as a graphic artist by the Ministry of Information for a period of six months. The next spring he was invalided out of the Army. In 1943 he was commissioned by the War Artists' Advisory Committee, WAAC, to paint glassblowers at a Birmingham factory. Peake was next given a full-time, three-month WAAC contract to depict various factory subjects, including the production of cathode ray tubes for early radar sets, and was also asked to submitt a large painting showing RAF pilots being debriefed. Some of these paintings are on permanent display in Manchester Art Gallery whilst other examples are in the Imperial War Museum collection.
Illustration and writing.
The five years between 1943 and 1948 were some of the most productive of his career. He finished "Titus Groan" and "Gormenghast" and completed some of his most acclaimed illustrations for books by other authors, including Lewis Carroll's "Hunting of the Snark" (for which he was reportedly paid only £5) and "Alice in Wonderland", Samuel Taylor Coleridge's "The Rime of the Ancient Mariner", the Brothers Grimm's "Household Tales", "All This and Bevin Too" by Quentin Crisp and Robert Louis Stevenson's "Strange Case of Dr Jekyll and Mr Hyde", as well as producing many original poems, drawings, and paintings.
Peake designed the logo for Pan Books. The publishers offered him either a flat fee of £10 or a royalty of one farthing per book. On the advice of Graham Greene, who told him that paperback books were a passing fad that wouldn't last, Peake opted for the £10.
A book of nonsense poems, "Rhymes Without Reason", was published in 1944 and was described by John Betjeman as "outstanding". Shortly after the war ended in 1945 he was commissioned by a magazine to visit France and Germany. With writer Tom Pocock he was among the first British civilians to witness the horrors of the Nazi concentration camp at Belsen, where the remaining prisoners, too sick to be moved, were dying before his very eyes. He made several drawings, but not surprisingly he found the experience profoundly harrowing, and expressed in deeply felt poems the ambiguity of turning their suffering into art.
In 1946 the family moved to Sark, where Peake continued to write and illustrate, and Maeve painted. "Gormenghast" was published in 1950, and the family moved back to England, settling in Smarden, Kent. Peake taught part-time at the Central School of Art, began his comic novel "Mr Pye", and renewed his interest in theatre. His father died that year and left his house in Hillside Gardens in Wallington, Surrey to Mervyn. "Mr Pye" was published in 1953, and he later adapted it as a radio play. The BBC broadcast other plays of his in 1954 and 1956.
Later life.
In 1956 Mervyn and Maeve visited Spain, financed by a friend who hoped that Peake's health, which was already declining, would be improved by the holiday. That year his novella "Boy in Darkness" was published beside stories by William Golding and John Wyndham in a volume called "Sometime, Never". On 18 December the BBC broadcast his radio play "The Eye of the Beholder" (later revised as "The Voice of One") in which an avant-garde artist is commissioned to paint a church mural. Peake placed much hope in his play "The Wit To Woo" which was finally staged in London's West End in 1957, but it was a critical and commercial failure. This affected him greatly – his health degenerated rapidly and he was again admitted to hospital with a nervous breakdown.
Declining health.
He was showing unmistakable early symptoms of dementia, for which he was given electroconvulsive therapy, to little avail. Over the next few years he gradually lost the ability to draw steadily and quickly, although he still managed to produce some drawings with the help of his wife. Among his last completed works were the illustrations for Balzac's "Droll Stories" (1961) and for his own poem "The Rhyme of the Flying Bomb" (1962), which he had written some 15 years earlier.
"Titus Alone" was published in 1959 and was revised by Langdon Jones in 1970 to remove apparent inconsistencies introduced by the publisher's careless editing. A 1995 edition of all three completed Gormenghast novels includes a very short fragment of the beginning of what would have been the fourth Gormenghast novel, "Titus Awakes", as well as a listing of events and themes he wanted to address in that and later Gormenghast novels.
Death.
In the late 1950s, while writing "Titus Alone", Peake's health subsequently declined into physical and mental incapacitation, and he died on 17 November 1968 at a care home run by his brother in law, at Burcot, near Oxford. He was buried in the churchyard of St Mary's in the village of Burpham, Sussex.
A 2003 study published in JAMA Neurology diagnosed Peake as dying from dementia with Lewy bodies (DLB).
His work, especially the Gormenghast series, became much better known and more widely appreciated after his death. They have since been translated into more than two dozen languages.
Publications.
Six volumes of Peake's verse were published during his lifetime; "Shapes & Sounds" (1941), "Rhymes without Reason" 1944, "The Glassblowers" (1950), "The Rhyme of the Flying Bomb" (1962), "Poems & Drawings" (1965), and "A Reverie of Bone" (1967). After his death came "Selected Poems" (1972), followed by "Peake's Progress" in (1979 – though the Penguin edition of 1982, with many corrections, including a whole stanza inadvertently omitted from the hardback edition, is to be preferred). "The Collected Poems of Mervyn Peake" was published by Carcanet Press in June 2008. Other collections include "The Drawings of Mervyn Peake" (1974), "Writings and Drawings" (1974), and "Mervyn Peake: the man and his art" (2006). A collected edition of the works, issued to celebrate Peake's centenary year, has been announced for publication by Queen Anne Press (2012).
Archive.
In 2010 an archive consisting of 28 containers of material, which included correspondence between Peake and Laurie Lee, Walter de la Mare and C. S. Lewis, plus 39 Gormenghast notebooks and original drawings for both "Alice Through the Looking Glass" and "Alice's Adventures in Wonderland", was acquired by the British Library.
Dramatic adaptations of Peake's work.
In 1983, the Australian Broadcasting Corporation broadcast eight hour-long episodes for radio dramatising the complete Gormenghast Trilogy. This was the first to include the third book Titus Alone.
In 1984, BBC Radio 4 broadcast two 90-minute plays based on "Titus Groan" and "Gormenghast", adapted by Brian Sibley and starring Sting as Steerpike and Freddie Jones as the Artist (narrator). A slightly abridged compilation of the two, running to 160 minutes, and entitled "Titus Groan of Gormenghast", was broadcast on Christmas Day, 1992. BBC 7 repeated the original versions on 21 and 28 September 2003.
In 1986, "Mr Pye" was adapted as a four-part Channel 4 miniseries starring Derek Jacobi.
In 2000, the BBC and WGBH Boston co-produced a lavish miniseries, titled "Gormenghast", based on the first two books of the series. It starred Jonathan Rhys-Meyers as Steerpike, Neve McIntosh as Fuchsia, June Brown as Nannie Slagg, Ian Richardson as Lord Groan, Christopher Lee as Flay, Richard Griffiths as Swelter, Warren Mitchell as Barquentine, Celia Imrie as Countess Gertrude, Lynsey Baxter and Zoë Wanamaker as the twins, Cora and Clarice, and John Sessions as Dr Prunesquallor. The supporting cast included Olga Sosnovska, Stephen Fry and Eric Sykes and the series is also notable as the last screen performance by comedy legend Spike Milligan (as the Headmaster).
A minimalist stage version of Gormenghast performed by the David Glass Ensemble was adapted by John Constable and directed by David Glass. The production features atmospheric music and lighting and relies heavily on mime, all to convey the immense vastness of the Gormenghast castle on the small stage. It toured theatres in the UK during 2006 and 2007.
A 30-minute TV short film "A Boy in Darkness" (also made in 2000 and adapted from Peake's novella) was the first production from the BBC Drama Lab. It was set in a 'virtual' computer-generated world created by young computer game designers, and starred Jack Ryder (from "EastEnders") as Titus, with Terry Jones ("Monty Python's Flying Circus") narrating.
Irmin Schmidt, founder of seminal German 'Krautrock' group Can wrote an opera called "Gormenghast", based on the novels; it was first performed in Wuppertal, Germany, in November 1998. A number of early songs by New Zealand rock group Split Enz were inspired by Peake's work. The song "The Drowning Man", by British band The Cure, is inspired by events in "Gormenghast," and the song "Lady Fuchsia" by another British band, Strawbs, is also based on events in the novels.
Peake's play "The Cave", which dates from the mid-1950s, was given a first public reading at the Blue Elephant Theatre in Camberwell (London) in 2009, and had its world premiere in the same theatre, directed by Aaron Paterson, on 19 October 2010.
In 2011 Brian Sibley adapted the story again, this time as six one-hour episodes broadcast on BBC Radio 4 as the Classic Serial starting on 10 July 2011. The serial was titled "The History of Titus Groan" and adapted all three novels written by Mervyn Peake and the recently discovered concluding volume, "Titus Awakes" completed by his widow, Maeve Gilmore. It starred Luke Treadaway as Titus, David Warner as the Artist and Carl Prekopp as Steerpike. It also starred Paul Rhys, Miranda Richardson, James Fleet, Tamsin Greig, Fenella Woolgar, Adrian Scarborough and Mark Benton among others.
Sting has purchased the film rights to the "Gormenghast" novels.

</doc>
<doc id="19501" url="http://en.wikipedia.org/wiki?curid=19501" title="Martial arts">
Martial arts

Martial arts are codified systems and traditions of combat practices, which are practiced for a variety of reasons: self-defense, competition, physical health and fitness, entertainment, as well as mental, physical, and spiritual development.
Although the term "martial art" has become associated with the fighting arts of eastern Asia, it originally referred to the combat systems of Europe as early as the 1550s. The term is derived from Latin, and means "arts of Mars", the Roman god of war. Some authors have argued that fighting arts or fighting systems would be more appropriate on the basis that many martial arts were never "martial" in the sense of being used or created by professional warriors.
Variation and scope.
Martial arts may be categorized along a variety of criteria, including:
By technical focus.
Unarmed martial arts can be broadly grouped into focusing on strikes, those focusing on grappling and those that cover both fields, often described as hybrid martial arts.
Strikes
Grappling
Those traditional martial arts which train armed combat often encompass a wide spectrum of melee weapons, including bladed weapons and polearms. Such traditions include eskrima, silat, kalaripayat, kobudo, and historical European martial arts, especially those of the German Renaissance. Many Chinese martial arts also feature weapons as part of their curriculum.
Sometimes, training with one specific weapon will be considered a style of martial arts in its own right, which is especially the case in Japanese martial arts with disciplines such as kenjutsu and kendo (sword), bojutsu (staff), and kyudo (archery). Similarly, modern Western martial arts and sports include modern fencing, stick-fighting systems like canne de combat or singlestick, and modern competitive archery.
By application or intent.
Many martial arts, especially those from Asia, also teach side disciplines which pertain to medicinal practices. This is particularly prevalent in traditional Asian martial arts which may teach bone-setting, herbalism, and other aspects of traditional medicine.
Martial arts can also be linked with religion and spirituality. Numerous systems are reputed to have been founded, disseminated, or practiced by monks or nuns.
Throughout Asia, meditation may be incorporated as part of training. In those countries influenced by Hindu-Buddhist philosophy, the art itself may be used as an aid to attaining enlightenment.
Japanese styles, when concerning non-physical qualities of the combat, are often strongly influenced by Mahayana Buddhist philosophy. Concepts like "empty mind" and "beginner's mind" are recurrent. Aikido, for instance, can have a strong philosophical belief of the flow of energy and peace fostering, as idealised by its founder Morihei Ueshiba.
Traditional Korean martial arts place emphasis on the development of the practitioner's spiritual and philosophical development. A common theme in most Korean styles, such as taekkyeon and taekwondo, is the value of "inner peace" in a practitioner, which is stressed to be only achieved through individual meditation and training. The Koreans believe that the use of physical force is only justified through defense.
Systema draws upon breathing and relaxation techniques, as well as elements of Russian Orthodox thought, to foster self-conscience and calmness, and to benefit the practitioner in different levels: the physical, the psychological and the spiritual.
Some martial arts in various cultures can be performed in dance-like settings for various reasons, such as for evoking ferocity in preparation for battle or showing off skill in a more stylized manner. Many such martial arts incorporate music, especially strong percussive rhythms. (See also war dance.)
History.
Historical martial arts.
The oldest work of art depicting scenes of battle, dating back 3400 BC, was the Ancient Egyptian paintings showing some form of struggle. Dating back to 3000 BC in Mesopotamia (Babylon), reliefs and the poems depicting struggle were found. In Vietnam, drawings and sketches from 2879 BC describe certain ways of combat using sword, stick, bow, and spears.
Chinese martial arts originated during the Xia Dynasty more than 4000 years ago. It is said the Yellow Emperor Huangdi (legendary date of ascension 2698 BC) introduced the earliest fighting systems to China. The Yellow Emperor is described as a famous general who, before becoming China's leader, wrote lengthy treatises on medicine, astrology and the martial arts. One of his main opponents was Chi You who was credited as the creator of jiao di, a forerunner to the modern art of Chinese wrestling.
The foundation of modern Asian martial arts is likely a blend of early Chinese and Indian martial arts. During the Warring States period of Chinese history (480-221 BC) extensive development in martial philosophy and strategy emerged, as described by Sun Tzu in "The Art of War" (c. 350 BC). Legendary accounts link the origin of Shaolinquan to the spread of Buddhism from India during the early 5th century AD, with the figure of Bodhidharma, to China.
In Europe, the earliest sources of martial arts traditions date to Ancient Greece. Boxing ("pygme", "pyx"), wrestling ("pale") and pankration were represented in the Ancient Olympic Games. The Romans produced gladiatorial combat as a public spectacle.
A number of historical combat manuals have survived from the European Middle Ages. This includes such styles as sword and shield, two-handed swordfighting and other types of melee weapons besides unarmed combat. Amongst these are transcriptions of the (possibly apocryphal) Johannes Lichtenauer's mnemonic poem on the longsword dating back to the late fourteenth century. Likewise, Asian martial arts become well-documented during the medieval period, Japanese martial arts beginning with the establishment of the samurai nobility in the 12th century, Chinese martial arts with Ming era treatises such as Ji Xiao Xin Shu, Indian martial arts in medieval texts such as the Agni Purana and the Malla Purana, and Korean martial arts from the Joseon era and texts such as Muyejebo (1598).
European swordsmanship always had a sportive component, but the duel was always a possibility until World War I. Modern sport fencing began developing during the 19th century as the French and Italian military academies began codifying instruction. The Olympic games led to standard international rules, with the Féderation Internationale d'Escrime founded in 1913. Modern boxing originates with Jack Broughton's rules in the 18th century, and reaches its present form with the Marquess of Queensberry Rules of 1867. Europe's colonization of Asian countries also brought about a decline in local martial arts, especially with the introduction of firearms. This can clearly be seen in India after the full establishment of British Raj in the 19th century. Similar phenomena occurred in Southeast Asian colonies such as Malaysia, Indonesia, Vietnam, Cambodia and the Philippines.
Folk styles.
Certain traditional combat sports and fighting styles exist all over the world, rooted in local culture and folklore. The most common of these are styles of folk wrestling, some of which have been practiced since antiquity, and are found in the most remote areas. Other examples include forms of stick fighting and boxing. While these arts are based on historical traditions of folklore, they are not "historical" in the sense that they reconstruct or preserve a historical system from a specific era. They are rather contemporary regional sports that coexist with the modern forms of martial arts sports as they have developed since the 19th century, often including cross-fertilization between sports and folk styles; thus, the traditional Thai art of muay boran developed into the modern national sport of muay Thai, which in turn came to be practiced worldwide and contributed significantly to modern hybrid styles like kickboxing and mixed martial arts. Singlestick, an English martial art can be seen often utilised in morris dancing.
Modern history.
The mid to late 19th century marks the beginning of the history of martial arts as modern sports developed out of earlier traditional fighting systems. In Europe, this concerns the developments of boxing and fencing as sports. In Japan, the same period marks the formation of the modern forms of judo, jujutsu, karate, and kendo (among others) based on revivals of old schools of Edo period martial arts which had been suppressed during the Meiji Restoration. Modern muay Thai rules date to the 1920s. In China, the modern history of martial arts begins in the Nanjing decade (1930s) following the foundation of the Central Guoshu Institute in 1928 under the Kuomintang government.
Western interest in Asian martial arts arises towards the end of the 19th century, due to the increase in trade between the United States with China and Japan. Relatively few Westerners actually practiced the arts, considering it to be mere performance. Edward William Barton-Wright, a railway engineer who had studied jujutsu while working in Japan between 1894 and 1897, was the first man known to have taught Asian martial arts in Europe. He also founded an eclectic style named Bartitsu which combined jujutsu, judo, boxing, savate and stick fighting.
Fencing and Greco-Roman wrestling was included in the 1896 Summer Olympics.
FILA Wrestling World Championships and Boxing at the Summer Olympics were introduced in 1904.
The tradition of awarding championship belts in wrestling and boxing can be traced to the Lonsdale Belt, introduced in 1909.
The International Boxing Association was established in 1920. World Fencing Championships have been held since 1921.
As Western influence grew in Asia a greater number of military personnel spent time in China, Japan and South Korea during World War II and the Korean War and were exposed to local fighting styles. Jujutsu, judo and karate first became popular among the mainstream from the 1950s-60s. Due in part to Asian and Hollywood martial arts movies, most modern American martial arts are either Asian-derived or Asian influenced.
The term kickboxing (キックボクシング) was created by the Japanese boxing promoter Osamu Noguchi for a variant of muay Thai and karate that he created in the 1950s. American kickboxing was developed in the 1970s, as a combination of boxing and karate. Taekwondo was developed in the context of the Korean War in the 1950s.
The later 1960s and 1970s witnessed an increased media interest in Chinese martial arts, influenced by martial artist Bruce Lee. Jeet Kune Do, the system he founded, has its roots in Wing Chun, western boxing, savate and fencing. Bruce Lee is credited as one of the first instructors to openly teach Chinese martial arts to Westerners. World Judo Championships have been held since 1956, Judo at the Summer Olympics was introduced in 1964. Karate World Championships were introduced in 1970.
Following the "kung fu wave" in Hong Kong action cinema in the 1970s, a number of mainstream films produced during the 1980s contributed significantly to the perception of martial arts in western popular culture. These include "The Karate Kid" (1984) and "Bloodsport" (1988). This era produced some Hollywood action stars with martial arts background, such as Jean-Claude Van Damme and Chuck Norris.
Also during the 20th century, a number of martial arts were adapted for self-defense purposes for military hand-to-hand combat. World War II combatives, KAPAP (1930s) and Krav Maga (1950s) in Israel, Systema in Soviet-era Russia, and Sanshou in the People's Republic of China are examples of such systems. The US military de-emphasized hand-to-hand combat training during the Cold War period, but revived it with the introduction of LINE in 1989.
During the 1990s Brazilian Jiu-Jitsu became popular and proved to be effective in mixed martial arts competitions such as the UFC and PRIDE.
In 1993 the first Pancrase event was held. The K-1 rules of kickboxing were introduced based on 1980s Seidokaikan karate.
Jackie Chan and Jet Li are prominent movie figures who have been responsible for promoting Chinese martial arts in recent years.
With the continual discovery of more medieval and Renaissance fighting manuals, the practice of Historical European Martial Arts and other Western Martial Arts are growing in popularity across the United States and Europe.
November 29, 2011, UNESCO inscribed taekkyeon onto its Intangible Cultural Heritage of Humanity List.
Testing and competition.
Testing or evaluation is important to martial art practitioners of many disciplines who wish to determine their progression or own level of skill in specific contexts. Students within individual martial art systems often undergo periodic testing and grading by their own teacher in order to advance to a higher level of recognized achievement, such as a different belt color or title. The type of testing used varies from system to system but may include forms or sparring.
Various forms and sparring are commonly used in martial art exhibitions and tournaments. Some competitions pit practitioners of different disciplines against each other using a common set of rules, these are referred to as mixed martial arts competitions. Rules for sparring vary between art and organization but can generally be divided into "light-contact", "medium-contact", and "full-contact" variants, reflecting the amount of force that should be used on an opponent.
Light- and medium-contact.
These types of sparring restrict the amount of force that may be used to hit an opponent, in the case of light sparring this is usual to 'touch' contact, e.g. a punch should be 'pulled' as soon as or before contact is made. In medium-contact (sometimes referred to as semi-contact) the punch would not be 'pulled' but not hit with full force. As the amount of force used is restricted, the aim of these types of sparring is not to knock out an opponent; a point system is used in competitions.
A referee acts to monitor for fouls and to control the match, while judges mark down scores, as in boxing. Particular targets may be prohibited, certain techniques may be forbidden (such as headbutting or groin hits), and fighters may be required to wear protective equipment on their head, hands, chest, groin, shins or feet. Some grappling arts, such as aikido, use a similar method of compliant training that is equivalent to light or medium contact.
In some styles (such as fencing and some styles of Taekwondo sparring), competitors score points based on the landing of a single technique or strike as judged by the referee, whereupon the referee will briefly stop the match, award a point, then restart the match. Alternatively, sparring may continue with the point noted by the judges. Some critics of point sparring feel that this method of training teaches habits that result in lower combat effectiveness. Lighter-contact sparring may be used exclusively, for children or in other situations when heavy contact would be inappropriate (such as beginners), medium-contact sparring is often used as training for full contact
Full-contact.
Full-contact sparring or competition, where strikes are not pulled but thrown with full force as the name implies, has a number of tactical differences from light and medium-contact sparring. It is considered by some to be requisite in learning realistic unarmed combat.
In full-contact sparring, the aim of a competitive match is either to knock out the opponent or to force the opponent to submit.
Where scoring takes place it may be a subsidiary measure, only used if no clear winner has been established by other means; in some competitions, such as the UFC 1, there was no scoring, though most now use some form of judging as a backup. Due to these factors, full-contact matches tend to be more aggressive in character, but rule sets may still mandate the use of protective equipment, or limit the techniques allowed.
Nearly all mixed martial arts organizations such as UFC, Pancrase, Shooto use a form of full-contact rules, as do professional boxing organizations and K-1. Kyokushin karate requires advanced practitioners to engage in bare-knuckled, full-contact sparring while wearing only a karate "gi" and groin protector but does not allow punches to the face, only kicks and knees. Brazilian Jiu-Jitsu and judo matches do not allow striking, but are full-contact in the sense that full force is applied in the permitted grappling and submission techniques. Competitions held by the World Taekwondo Federation requires the use of Headgear and padded vest, but are full contact in the sense that full force is applied to strikes to the head and body, and win by knockout is possible.
Martial sport.
Martial arts have crossed over into sports when forms of sparring become competitive, becoming a sport in its own right that is dissociated from the original combative origin, such as with western fencing. The Summer Olympic Games includes judo, taekwondo, western archery, boxing, javelin, wrestling and fencing as events, while Chinese wushu recently failed in its bid to be included, but is still actively performed in tournaments across the world. Practitioners in some arts such as kickboxing and Brazilian Jiu-Jitsu often train for sport matches, whereas those in other arts such as aikido generally spurn such competitions. Some schools believe that competition breeds better and more efficient practitioners, and gives a sense of good sportsmanship. Others believe that the rules under which competition takes place have diminished the combat effectiveness of martial arts or encourage a kind of practice which focuses on winning trophies rather than a focus such as cultivating a particular moral character.
The question of "which is the best martial art" has led to inter style competitions fought with very few rules allowing a variety of fighting styles to enter with few limitations. This was the origin of the first Ultimate Fighting Championship tournament (later renamed UFC 1: The Beginning) in the U.S. inspired by the Brazilian Vale tudo tradition and along with other minimal rule competitions, most notably those from Japan such as Shooto and Pancrase, have evolved into the combat sport of Mixed Martial Arts (MMA).
Some martial artists compete in non-sparring competitions such as breaking or choreographed routines of techniques such as poomse, kata and aka, or modern variations of the martial arts which include dance-influenced competitions such as tricking. Martial traditions have been influenced by governments to become more sport-like for political purposes; the central impetus for the attempt by the People's Republic of China in transforming Chinese martial arts into the committee-regulated sport of wushu was suppressing what they saw as the potentially subversive aspects of martial training, especially under the traditional system of family lineages.
Health and fitness benefits.
Martial arts training aims to result in several benefits to trainees, such as their physical, mental, emotional and spiritual health.
Through systematic practice in the martial arts a person's physical fitness may be boosted (strength, stamina, flexibility, movement coordination, etc.) as the whole body is exercised and the entire muscular system is activated.
Beyond contributing to physical fitness, martial arts training also has benefits for mental health, contributing to self-esteem, self-control, emotional and spiritual well-being. For this reason, a number of martial arts schools have focused purely on therapeutic aspects, de-emphasizing the historical aspect of self-defense or combat completely.
According to Bruce Lee, martial arts also have the nature of an art, since there is emotional communication and complete emotional expression.
Self-defense, military and law enforcement applications.
Some traditional martial concepts have seen new use within modern military training. Perhaps the most recent example of this is point shooting which relies on muscle memory to more effectively utilize a firearm in a variety of awkward situations, much the way an iaidoka would master movements with their sword.
During the World War II era William E. Fairbairn and Eric A. Sykes were recruited by the Special Operations Executive (SOE) to teach their martial art of defendu (itself drawing on Western boxing and jujutsu) and pistol shooting to UK, US, and Canadian special forces. The book "Kill or Get Killed", written by Colonel Rex Applegate, was based on the defendu taught by Sykes and Fairbairn. Both Fairbairn's "Get Tough" and Appelgate's "Kill or Get Killed" became classic works on hand-to-hand combat.
Traditional hand-to-hand, knife, and spear techniques continue to see use in the composite systems developed for today's wars. Examples of this include European Unifight, the US Army's Combatives system developed by Matt Larsen, the Israeli army's KAPAP and Krav Maga, and the US Marine Corps's "Marine Corps Martial Arts Program" (MCMAP). Unarmed dagger defenses identical to those found in the manual of Fiore dei Liberi and the Codex Wallerstein were integrated into the U.S. Army's training manuals in 1942
and continue to influence today's systems along with other traditional systems such as eskrima and silat.
The rifle-mounted bayonet, which has its origin in the spear, has seen use by the United States Army, the United States Marine Corps, and the British Army as recently as the Iraq War.
Many martial arts are also seen and used in Law Enforcement hand to hand training. For example, the Tokyo Riot Police's use of aikido.
Martial arts industry.
Martial arts since the 1970s has become a significant industry, a subset of the wider sport industry (including cinema and sports television).
Hundreds of millions of people worldwide practice some form of martial art.
Web Japan (sponsored by the Japanese Ministry of Foreign Affairs) claims there are 50 million karate practitioners worldwide.
The South Korean government in 2009 published an estimate that taekwondo is practiced by 70 million people in 190 countries.
The wholesale value of martial arts related sporting equipment shipped in the United States was estimated at 314 million USD in 2007; participation in the same year was estimated at 6.9 million (ages 6 or older, 2% of US population).
R. A. Court, CEO of Martial Arts Channel, stated the total revenue of the US martial arts industry at USD 40 billion and the number of US practitioners at 30 million in 2003.
Ultimate Fighting Championship generated a revenue of about USD 250 million in 2008, about 90% of the entire Mixed Martial Arts industry.
Equipment.
Martial arts equipment can include that used for conditioning, protection and weapons. Specialized conditioning equipment can include breaking boards, dummy partners such as the wooden dummy, and targets such as punching bags and the makiwara. Protective equipment for sparring and competition includes boxing gloves and headgear.
Martial arts fraud.
Asian martial arts experienced a surge of popularity in the west during the 1970s, and the rising demand resulted in numerous low quality or fraudulent schools. Fueled by fictional depictions in martial arts movies, this led to the ninja craze of the 1980s in the United States. Somewhat outdated, but there were also numerous fraudulent ads for martial arts training programs, inserted into comic books circa the 1960s and 1970s, which were read primarily by adolescent boys.
When the martial arts came to the United States in the seventies, lower ranks (kyu) began to be given colorful belts to show progress. This proved to be commercially viable and colored-belt systems were adopted in many martial arts degree mills (also known as McDojos) as a means to generate additional cash. This was covered in - (June 2010).

</doc>
<doc id="19508" url="http://en.wikipedia.org/wiki?curid=19508" title="Murat Ses">
Murat Ses

Murat Ses ("Ses means sound or voice in Turkish") (born 1946, Bayrakli, Izmir, Turkey) is a Turkish keyboard player and composer with strong Eurasian electronic elements. He is creator of the Anadolu Pop style, a synthesis of Anatolian Music and Western elements that has been influencing Turkish music scene for decades.
He worked with several bands: Meteorlar (Meteors) (1966-1967), Silüetler (Silhouette) (1967), Moğollar (Mongols) (1967-1972), Barış Manço and Kurtalan Ekspres (Express) (1973-1974), Edip Akbayram and Dostlar (Friends) (1974) and Cem Karaca and Dervişan (Dervishes) (1975-1976). Also, he founded Ağrı Dağı Efsanesi (Legend of Mount Ararat) band. This band was dissolved in 1976 and 3 45 rpms. He migrated to Austria in 1979. 
His album "Danses et Rythmes de la Turquie d'hier à aujourd'hui" was awarded the Grand Prix du Disque by the Charles Cros Academie in Paris, France with Moğollar. The albums "Automaton (Slave with Ewer Device)", "Binfen (feat.Tan)" and "Culduz", all released in the 1990s, are parts of a trilogy with the concept: "The Timeless and Boundaryless Context of Culture and Civilization". Ses has had excellent press (US Keyboard, Audion, i/e, Expose ...) and airplay (Automaton² was no.1 in Rhode Island, Binfen no.7 in Ohio). His main influences are Pink Floyd, Traffic, Jimmy Smith, Eastern Mediterranean music, Levantine, and Central Asian cultures and music. He is the most important Turkish artist still internationally active and shaping today's independent electronic music scene.
His earlier (late 60s early 70s) psychedelic-Anatolian works with English lyrics released under US, Dutch, German and Canadian labels in the late 1990s through 2002. Murat's album with his "San Francisco/Miami Impressions" was recorded in Miami, Florida and was published in 2005 as Automaton² (Automaton Squared) followed by "Binfen 2005 Remix", "Electric Levantine" (2006), "Umami" (2007), "Beside the Sun" (2010), "Light Cone" (2012) and "Sundial" (2013). His newest release is "Kiosk Torba" (2014), his eleventh solo album in a row.
In the early 1990s Murat Ses developed a musical style he terms "Electric Levantine". The main elements of the style are microtonal properties created on authentic Levantine scales, electronically produced instrument timbres and Western music. It's an experimental form of "Anadolu Pop". His typical "Electric Levantine" sound can be heard on his album "AUTOMATON (Slave with Ewer Device)" and on the subsequent albums of his 90's trilogy.
In 2007 Advertising agency TBWA decided to use the early 70s Moğollar song 'Garip Çoban' (meaning Poor Shepherd in Turkish), composed by Murat Ses, in PlayStation 3 campaigns commercial.

</doc>
<doc id="19509" url="http://en.wikipedia.org/wiki?curid=19509" title="Finitary relation">
Finitary relation

In mathematics, a finitary relation has a finite number of "places". In set theory and logic, a "relation" is a property that assigns truth values to formula_1-tuples of individuals. Typically, the property describes a possible connection between the components of a formula_1-tuple. For a given set of formula_1-tuples, a truth value is assigned to each formula_1-tuple according to whether the property does or does not hold.
An example of a "ternary relation" (i.e., between three individuals) is: "formula_5 was introduced to formula_6 by formula_7", where formula_8 is a 3-tuple of persons; for example, "Beatrice Wood was introduced to Henri-Pierre Roché by Marcel Duchamp" is true, while "Karl Marx was introduced to Friedrich Engels by Queen Victoria" is false.
Informal introduction.
"Relation" is formally defined in the next section. In this section we introduce the concept of a relation with a familiar everyday example. Consider the relation involving three roles that people might play, expressed in a statement of the form ""X" thinks that "Y" likes "Z" ". The facts of a concrete situation could be organized in a table like the following:
Each row of the table records a fact or makes an assertion of the form ""X" thinks that "Y" likes "Z" ". For instance, the first row says, in effect, "Alice thinks that Bob likes Denise". The table represents a relation "S" over the set "P" of people under discussion:
The data of the table are equivalent to the following set of ordered triples:
By a slight abuse of notation, it is usual to write "S"(Alice, Bob, Denise) to say the same thing as the first row of the table. The relation "S" is a "ternary" relation, since there are "three" items involved in each row. The relation itself is a mathematical object defined in terms of concepts from set theory (i.e., the relation is a subset of the Cartesian product on {Person X, Person Y, Person Z}), that carries all of the information from the table in one neat package. Mathematically, then, a relation is simply an "ordered set".
The table for relation "S" is an extremely simple example of a relational database. The theoretical aspects of databases are the specialty of one branch of computer science, while their practical impacts have become all too familiar in our everyday lives. Computer scientists, logicians, and mathematicians, however, tend to see different things when they look at these concrete examples and samples of the more general concept of a relation.
For one thing, databases are designed to deal with empirical data, and experience is always finite, whereas mathematics at the very least concerns itself with potential infinity. This difference in perspective brings up a number of ideas that may be usefully introduced at this point, if by no means covered in depth.
Relations with a small number of "places".
The variable formula_1 giving the number of "places" in the relation, 3 for the above example, is a non-negative integer, called the relation's "arity", "adicity", or "dimension". A relation with formula_1 places is variously called a formula_1"-ary", a formula_1"-adic", or a formula_1"-dimensional" relation. Relations with a finite number of places are called "finite-place" or "finitary" relations. It is possible to generalize the concept to include "infinitary" relations between infinitudes of individuals, for example infinite sequences; however, in this article only finitary relations are discussed, which will from now on simply be called relations.
Since there is only one 0-tuple, the so-called empty tuple ( ), there are only two zero-place relations: the one that always holds, and the one that never holds. They are sometimes useful for constructing the base case of an induction argument. One-place relations are called "unary relations". For instance, any set (such as the collection of Nobel laureates) can be viewed as a collection of individuals having some property (such as that of having been awarded the Nobel prize). Two-place relations are called binary relations or, in the past, "dyadic relations". Binary relations are very common, given the ubiquity of relations such as:
A formula_1"-ary" relation is a straightforward generalization of a binary relation.
Formal definitions.
When two objects, qualities, classes, or attributes, viewed together by the mind, are seen under some connexion, that connexion is called a relation.—Augustus De Morgan
The simpler of the two definitions of "k"-place relations encountered in mathematics is:
Definition 1. A relation "L" over the sets "X"1, …, "X""k" is a subset of their Cartesian product, written "L" ⊆ "X"1 × … × "X""k".
Relations are classified according to the number of sets in the defining Cartesian product, in other words, according to the number of terms following "L". Hence:
Relations with more than four terms are usually referred to as "k"-ary or "n"-ary, for example, "a 5-ary relation". A "k"-ary relation is simply a set of "k"-tuples.
The second definition makes use of an idiom that is common in mathematics, stipulating that "such and such is an "n"-tuple" in order to ensure that such and such a mathematical object is determined by the specification of "n" component mathematical objects. In the case of a relation "L" over "k" sets, there are "k" + 1 things to specify, namely, the "k" sets plus a subset of their Cartesian product. In the idiom, this is expressed by saying that "L" is a ("k" + 1)-tuple.
Definition 2. A relation "L" over the sets "X"1, …, "X""k" is a ("k" + 1)-tuple "L" = ("X"1, …, "X""k", "G"("L")), where "G"("L") is a subset of the Cartesian product "X"1 × … × "X""k". "G"("L") is called the "graph" of "L".
Elements of a relation are more briefly denoted by using boldface characters, for example, the constant element formula_22 = (a1, …, a"k") or the variable element formula_23 = ("x"1, …, "x""k").
A statement of the form "formula_22 is in the relation "L" " is taken to mean that formula_22 is in "L" under the first definition and that formula_22 is in "G"("L") under the second definition.
The following considerations apply under either definition:
As a rule, whatever definition best fits the application at hand will be chosen for that purpose, and anything that falls under it will be called a relation for the duration of that discussion. If it becomes necessary to distinguish the two definitions, an entity satisfying the second definition may be called an "embedded" or "included" relation.
If "L" is a relation over the domains "X"1, …, "X""k", it is conventional to consider a sequence of terms called "variables", "x"1, …, "x""k", that are said to "range over" the respective domains.
Let a Boolean domain B be a two-element set, say, B = {0, 1}, whose elements can be interpreted as logical values, typically 0 = false and 1 = true. The characteristic function of the relation "L", written "ƒ""L" or χ("L"), is the Boolean-valued function "ƒ""L" : "X"1 × … × "X""k" → B, defined in such a way that "ƒ""L"(formula_23) = 1 just in case the "k"-tuple formula_23 is in the relation "L". Such a function can also be called an indicator function, particularly in probability and statistics, to avoid confusion with the notion of a characteristic function in probability theory.
It is conventional in applied mathematics, computer science, and statistics to refer to a Boolean-valued function like "ƒ""L" as a "k"-place predicate. From the more abstract viewpoint of formal logic and model theory, the relation "L" constitutes a "logical model" or a "relational structure" that serves as one of many possible interpretations of some "k"-place predicate symbol.
Because relations arise in many scientific disciplines as well as in many branches of mathematics and logic, there is considerable variation in terminology. This article treats a relation as the set-theoretic extension of a relational concept or term. A variant usage reserves the term "relation" to the corresponding logical entity, either the logical comprehension, which is the totality of intensions or abstract properties that all of the elements of the relation in extension have in common, or else the symbols that are taken to denote these elements and intensions. Further, some writers of the latter persuasion introduce terms with more concrete connotations, like "relational structure", for the set-theoretic extension of a given relational concept.
History.
The logician Augustus De Morgan, in work published around 1860, was the first to articulate the notion of relation in anything like its present sense. He also stated the first formal results in the theory of relations (on De Morgan and relations, see Merrill 1990). Charles Sanders Peirce restated and extended De Morgan's results. Bertrand Russell (1938; 1st ed. 1903) was historically important, in that it brought together in one place many 19th century results on relations, especially orders, by Peirce, Gottlob Frege, Georg Cantor, Richard Dedekind, and others. Russell and A. N. Whitehead made free use of these results in their "Principia Mathematica".

</doc>
<doc id="19510" url="http://en.wikipedia.org/wiki?curid=19510" title="Mokele-mbembe">
Mokele-mbembe

Mokèlé-mbèmbé, meaning "one who stops the flow of rivers" in the Lingala language, is a legendary water-dwelling creature of Congo River basin folklore, sometimes described as a living creature, sometimes as a spirit, and loosely analogous to the Loch Ness Monster in Western culture. It is claimed to be a sauropod by some cryptozoologists.
Expeditions mounted in the hope of finding evidence of the Mokèlé-mbèmbé have failed, and the subject has been covered in a number of books and by a number of television documentaries. According to skeptic Robert T. Carroll, "Reports of the Mokèlé-mbèmbé have been circulating for the past two hundred years, yet no one has photographed the creature or produced any physical evidence of its existence." The Mokèlé-mbèmbé and its associated folklore also appear in several works of fiction and popular culture.
Overview.
According to the traditions of the Congo River basin the Mokèlé-mbèmbé is a large territorial herbivore. It is said to dwell in Lake Tele and the surrounding area, with a preference for deep water, and with local folklore holding that its haunts of choice are river bends.
Descriptions of the Mokèlé-mbèmbé vary. Some legends describe it as having an elephant-like body with a long neck and tail and a small head, a description which has been suggested to be similar in appearance to that of the extinct Sauropoda, while others describe it as more closely resembling elephants, rhinoceros, and other known animals. It is usually described as being gray-brown in color. Some traditions, such as those of Boha Village, describe it as a spirit rather than a flesh and blood creature.
The BBC/Discovery Channel documentary "Congo" (2001) interviewed a number of tribe members who identified a photograph of a rhinoceros as being a Mokèlé-mbèmbé. Neither species of African rhinoceros is common in the Congo Basin, and the Mokèlé-mbèmbé may be a mixture of mythology and folk memory from a time when rhinoceros were found in the area.
History.
Numerous expeditions have been undertaken to Africa in search of Mokèlé-mbèmbé. During these, there were some sightings that have been argued by cryptozoologists to involve some unidentified dinosaur-like creature. Additionally, there have been several specific Mokèlé-mbèmbé-hunting expeditions. Although several of the expeditions have reported close encounters, none have been able to provide incontrovertible proof that the creature exists. The sole evidence that has been found is the presence of widespread folklore and anecdotal accounts covering a considerable period of time.
1776: Bonaventure.
The earliest reference that might be relevant to Mokèlé-mbèmbé stories (though the term is not used in the source) comes from the 1776 book "History of Loango, Kakonga, and Other Kingdoms in Africa" by Abbé Lievain Bonaventure Proyart, a French missionary to the Congo River region. Among many other observations about flora, fauna, and native inhabitants related in his book, Bonaventure claimed to have seen enormous footprints in the region. The creature that left the prints was not witnessed, but Bonaventure wrote that it "must have been monstrous: the marks of the claws were noted on the ground, and these formed a print about three feet in circumference."
1909: Gratz.
According to Lt. Paul Gratz's account from 1909, indigenous legends of the Congo River Basin in modern day Zambia spoke of a creature known by native people as the "Nsanga", which was said to inhabit the Lake Bangweulu region. Gratz described the creature as resembling a sauropod. This is one of the earliest references linking an area legend with dinosaurs, and has been argued to describe a Mokèlé-mbèmbé-like creature. In addition to hearing stories of the "Nsanga" Gratz was shown a hide which he was told belonged to the creature, while visiting Mbawala Island.
1909: Hagenbeck.
1909 saw another mention of a Mokèlé-mbèmbé-like creature, in "Beasts and Men", the autobiography of famed big-game hunter Carl Hagenbeck. He claimed to have heard from multiple independent sources about a creature living in the Congo region which was described as "half elephant, half dragon." Naturalist Joseph Menges had also told Hagenbeck about an animal alleged to live in Africa, described as "some kind of dinosaur, seemingly akin to the brontosaurs." Another of Hagenbeck's sources, Hans Schomburgk, asserted that while at Lake Bangweulu, he noted a lack of hippopotami; his native guides informed him of a large hippo-killing creature that lived in Lake Bangweulu; however, as noted below, Schomburgk thought that native testimony was sometimes unreliable.
Reports of dinosaur-like creatures in Africa caused a minor sensation in the mass media, and newspapers in Europe and North America carried many articles on the subject in 1910-1911; some took the reports at face value, others were more skeptical.
1913: von Stein.
Another report comes from the writings of German Captain Freiherr von Stein zu Lausnitz, who was ordered to conduct a survey of German colonies in what is now Cameroon in 1913. He heard stories of an enormous reptile alleged to live in the jungles, and included a description of the beast in his official report. According to Willy Ley, "von Stein worded his report with utmost caution," knowing it might be seen as unbelievable. Nonetheless, von Stein thought the tales were credible: trusted native guides had related the tales to him, and the stories were related to him by independent sources, yet featured many of the same details. Though von Stein's report was never formally published, portions were included in later works, including a 1959 book by Ley. Von Stein wrote:
The animal is said to be of a brownish-gray color with a smooth skin, its size is approximately that of an elephant; at least that of a hippopotamus. It is said to have a long and very flexible neck and only one tooth but a very long one; some say it is a horn. A few spoke about a long, muscular tail like that of an alligator. Canoes coming near it are said to be doomed; the animal is said to attack the vessels at once and to kill the crews but without eating the bodies. The creature is said to live in the caves that have been washed out by the river in the clay of its shores at sharp bends. It is said to climb the shores even at daytime in search of food; its diet is said to be entirely vegetable. This feature disagrees with a possible explanation as a myth. The preferred plant was shown to me, it is a kind of liana with large white blossoms, with a milky sap and applelike fruits. At the Ssombo River I was shown a path said to have been made by this animal in order to get at its food. The path was fresh and there were plants of the described type nearby. But since there were too many tracks of elephants, hippos, and other large mammals it was impossible to make out a particular spoor with any amount of certainty.
1919-1920: Smithsonian Institution.
A 32-man expedition was sent to Africa from the Smithsonian Institution in Washington D.C. between 1919 and 1920. The objective of this expedition was to secure additional specimens of plants and animals. Moving picture photographers from the Universal Film Manufacturing Company accompanied the expedition, in order to document the life of interior Africa. According to cryptozoologists Loren Coleman and Patrick Huyghe, authors of the "Field Guide to Lake Monsters", "African guides found large, unexplained tracks along the bank of a river and later in a swamp the team heard mysterious roars, which had no resemblance with any known animal". However, the expedition was to end in tragedy. During a train-ride through a flooded area where an entire tribe was said to have seen the dinosaur, the locomotive suddenly derailed and turned over. Four team members were crushed to death under the cars and another half dozen seriously injured. The expedition was documented in the H.L. Shantz papers.
1927: Smith.
1927 saw the publication of "Trader Horn", the memoir of Alfred Aloysius Smith, who had worked for a British trading company in what is now Gabon in the late 1800s. In the book, Smith related tales told him by natives and explorers about a creature given two different names: "jago-nini" and "amali". The creature was said to be very large, according to Smith, and to leave large, round, three-clawed footprints.
1932: Sanderson.
Cryptozoologist Ivan T. Sanderson claimed that, while in Cameroon in 1932, he witnessed an enormous creature in the Mainyu River. The creature, seemingly badly wounded, was only briefly visible as it lurched into the water. Darkly colored, the animal's head alone was nearly the size of a hippo, according to Sanderson. His native guides termed the creature "m'koo m'bemboo", in Sanderson's phonetic spelling.
1938: von Boxberger.
In 1938, explorer Leo von Boxberger mounted an expedition in part to investigate Mokèlé-mbèmbé reports. He collected much information from natives, but his notes and sketches had to be abandoned during a conflagration with local tribesmen.
1939: von Nolde.
In 1939, the "German Colonial Gazette" (of Angola) published a letter by Frau Ilse von Nolde, who asserted that she had heard of the animal called "coye ya menia" ("water lion") from many claimed eyewitnesses, both natives and settlers. She described the long necked creature as living in the rivers, and being about the size of a hippo, if not somewhat larger. It was known especially for attacking hippos - even coming on to land to do so - though it never ate them.
1966: Ridel.
In August or September 1966, Yvan Ridel took a picture of a large footprint with three toes, north-east of Loubomo, notable as hippopotami have four toes.
1976: Powell.
In 1960, an expedition to Zaire was planned by herpetologist James H. Powell, Jr., scheduled for 1972, but was canceled by legal complications. By 1976, however, he had sorted out the international travel problems, and went to Gabon instead, inspired by the book "Trader Horn". He secured finances from the Explorer's Club. Although Powell’s ostensible research aim was to study crocodiles, he also planned to study Mokèlé-mbèmbé.
On this journey, Powell located a claimed eyewitness to an animal called "n'yamala", or "jago-nini", which Powell thought was the same as the "amali" of Smith's 1920's books. Natives also stated – without Powell's asking - that "n'yamala" ate the flowering liana, just as von Stein had been told half a century earlier. When Powell showed illustrations of various animals, both alive and extinct, to natives, they generally suggested that the "Diplodocus" was the closest match to "n'yamala".
1979: Powell.
Powell returned to the same region in 1979, and claimed to receive further stories about "n'yamala" from additional natives. He also made an especially valuable contact in American missionary Eugene Thomas, who was able to introduce Powell to several claimed eyewitnesses. He decided that the n'yamala was probably identical to the Mokèlé-mbèmbé. Though seemingly herbivores, witnesses reported that the creatures were fearsome, and were known to attack canoes that were steered too close.
1979: Thomas.
Reverend Eugene Thomas from Ohio, USA, told James Powell and Roy P. Mackal in 1979 a story that involved the purported killing of a Mokèlé-mbèmbé near Lake Tele in 1959. Thomas was a missionary who had served in the Congo since 1955, gathering much of the earliest evidence and reports, and claiming to have had two close-encounters himself. Natives of the Bangombe tribe who lived near Lake Tele were said to have constructed a large spiked fence in a tributary of Tele to keep Mokèlé-mbèmbé from interfering with their fishing. A Mokele-mbembe managed to break through, though it was wounded on the spikes, and the natives then killed the creature. As William Gibbons writes, "Pastor Thomas also mentioned that the two pygmies mimicked the cry of the animal as it was being attacked and speared... Later, a victory feast was held, during which parts of the animal were cooked and eaten. However, those who participated in the feast eventually died, either from food poisoning or from natural causes. I also believe that the mythification (magical powers, etc) surrounding Mokèlé-mbèmbés ["sic"] began with this incident." Furthermore, Mackal heard from witnesses that the stakes were in the same location in the tributary as of the early 1980s.
1980: Mackal-Powell.
For his third expedition in February 1980, Powell was joined by Roy P. Mackal. Based on the testimony of claimed eyewitnesses, Powell and Mackal decided to focus their efforts on visiting the northern Congo regions, near the Likouala aux Herbes River and isolated Lake Tele. As of 1980, this region was little explored and largely unmapped, and the expedition was unable to reach Lake Tele. Powell and Mackal interviewed several people who claimed to have seen Mokèlé-mbèmbé, and Clark writes that the descriptions of the creature were "strikingly similar ... animals 15 to long (most of that a snakelike head and neck, plus long thin tail). The body was reminiscent of a hippo's, only more bulbous ... again, informants invariably pointed to a picture of a sauropod when shown pictures of various animals to which mokele-mbembe might be compared." Mackal and Powell were interviewed before and after this expedition for the TV program "Arthur C. Clarke's Mysterious World".
1981: Mackal-Bryan.
Mackal and Jack Bryan mounted an expedition to the same area in late 1981. He was supposed to be joined by Herman Regusters, but they came in conflict in terms of finance, equipment and leadership and decided to split and make separate expeditions. Although, once again, Mackal was unable to reach Lake Tele, he gathered details on other cryptids and possible living dinosaurs, like the Emela-ntouka, Mbielu-Mbielu-Mbielu, Nguma-monene, Ndendeki (giant turtle), Mahamba (a giant crocodile of 15 meters), and Ngoima (a giant monkey-eating Eagle). Among his company were J. Richard Greenwell, M. Justin Wilkinson, and Congolese zoologist Marcellin Agnagna.
The 1981 expedition would feature the only "close encounters" of the Mackal expeditions. It occurred when, while on a river, they heard a loud splash and saw what Greenwell described as "[a] large wake (about 5") ... originating from the east bank". Greenwell asserted that the wake must have been caused by an "animate object" that was unlike a crocodile or hippo. Additionally, Greenwell noted that the encounter occurred at a sharp river bend where, according to natives, Mokèlé-mbèmbé frequently lived due to deep waters at those points.
1987 saw the publication of Mackal's book, "A Living Dinosaur?", in which Mackal detailed his expedition and his conclusions about the Mokèlé-mbèmbé. Mackal tried, unsuccessfully, to raise funds for additional trips to Africa.
1981: Regusters.
In 1981, American engineer Herman Regusters led his own Mokèlé-mbèmbé expedition, after having a conflict with the Mackal-Bryan expedition that he intended to join. Regusters and his wife Kai reached Lake Tele, staying there for about two weeks. Of the 30 expedition members (28 were men from the Boha village), only Herman Regusters and his wife claim to have observed a "long-necked member" traveling across Lake Tele. They also claim to have tried filming the being, but said their motion picture film was ruined by the heat and humidity. Only one picture was released showing a large, but unidentifiable, object in the lake. The Regusters expedition returned with droppings and footprint casts, which Regusters believed were from the mokele-mbembe.
It also returned with sound recordings of "low windy roar [that] increased to a deep throated trumpeting growl", which Regusters believed to be the Mokèlé-mbèmbé's call. This recording was submitted for technical evaluation with a noted zoological source, but were inconclusive, except to note that the sounds were not attributable to any known wildlife. Despite this result, Regusters' conclusions about this tape were later challenged by Mackal, who asserted that the Mokèlé-mbèmbé did not have a vocal call. Mackal asserts that vocalizations are more correctly associated with the Emela-ntouka, a similarly described creature found in the Central African legends.
Herman Alphanso Regusters died on 19 December 2005, aged 72.
1983: Agnagna.
Congolese biologist Marcellin Agnagna led the 1983 expedition of Congolese to Lake Tele. According to his own account, Agnagna claimed to have seen a Mokèlé-mbèmbé at close distance for about 20 minutes. He tried to film it, but said that in his excitement, he forgot to remove the motion picture camera's lens cap. In a 1984 interview, Agnagna claimed, contradictorily, that the film was ruined not because of the lens cap, but because he had the Super 8 camera on the wrong setting: macro instead of telephoto.
1985: Nugent.
In December 1985 Rory Nugent spotted an anomaly moving through the middle of Lake Tele, approximately 1 kilometer from his position on the shore. In his account published as a book, Nugent claimed that it was shaped like a "slender french curve" and moving through the water with little wake. When he went to launch a boat to investigate he was ordered at gunpoint by the natives not to approach it. Nugent wrote that they view the creature as a god "that you can not approach, but if he chooses, this god can approach you." He also provided some pictures, which are too blurry to be identifiable.
1985-1986: Operation Congo.
Operation Congo took place between December 1985 and early 1986 by "four enthusiastic but naïve young Englishmen," led by Young Earth Creationist William Gibbons, They hired Agnagna to take them to Lake Tele, but did not report any Mokèlé-mbèmbé sightings. The British men did, however, assert that Agnagna did "little more than lie, cheat and steal (our film and supplies) and turn the porters against us." After criminal charges were filed against him, a Congolese court ordered Agnagna to return the items he had taken from the expedition.
Although the party found no evidence of the Mokèlé-mbèmbé, they discovered a new subspecies of monkey, which was later classified as the Crested mangabey monkey ("Cerocebus galeritus"), as well as fish and insect specimens.
1986: Botterweg.
In 1986 another expedition was mounted, consisting of four Dutchmen, organized and led by Dutch biologist Ronald Botterweg, who already had experience with tropical rainforest research in the Democratic Republic of the Congo, and who later visited, lived, and worked in several African countries. This expedition entered the Congo down the Ubangi River from Bangui in the Central African Republic, and managed, with considerable organizational challenges, to reach Lake Tele, with a group of guides from the village of Boha, some of which had also accompanied Regusters. Since they had only managed to obtain permission from the local authorities (not having passed by Brazzaville) for a very limited period in the area, they only spent about three days at the lake before returning to Boha. During their stay at the lake they spent as much time as possible observing the lake and its surroundings through from their provisional camp on the north-eastern shore, and navigating part of it by dug-out canoe. No signs of any large unknown animal were found. 
On the way back, arriving at the town of Impfondo, they were detained by Congolese biologist Agnagna and his team, who had just arrived there for an expedition with the British team of Operation Congo, allegedly for not possessing the proper documents. They were detained for a short while, and the largest part of their film and color slides were confiscated, before being released and leaving the country (again by the Ubangui river and Bangui).
No signs, tracks or anything tangible or visible of the alleged animals was seen or shown whatsoever. Tracks, droppings, and other signs of forest elephants and gorillas were commonly seen, as well as crocodiles in the lake. Despite the fact that the African guides were extremely capable and experienced hunters, guides and experts of the African rainforest, they were not able to show any track or sign of the Mokèlé-mbèmbé and none of the several interviewed guides even claimed ever to have seen one personally, nor its tracks. Remarkable is the fact that the guides that were interviewed by the Dutch expedition and that also accompanied Regusters, stated that they never saw a Mokèlé-mbèmbé during that expedition, although Regusters himself claims to have seen one.
This expedition received some attention in the Dutch media (radio, TV, and newspapers) from 1985 to 1987, and again in a nostalgic radio show by Dutch radio station KRO on channel Radio 2, on 7 March 2011. Furthermore, this expedition features in a slightly romanticized form as a short story by Dutch novelist author Margriet de Moor ('Hij Bestaat', meaning It exists, in the novel 'Op de Rug Gezien', meaning Seen from behind).
1988 Japanese expedition.
In 1988 a Japanese expedition went to the area, led by the Congolese wildlife official Jose Bourges. In 1992, members of a Japanese film crew allegedly filmed video Mokele-mbembe. As they were filming aerial footage from a small plane over the area of Lake Tele, intending to obtain some shots for a documentary, the cameraman noticed a disturbance in the water. He struggled to maintain focus on the object, which was creating a noticeable wake. About 15 seconds of footage was captured, which skeptics have identified as either two men in a canoe or swimming elephants.
1989 O'Hanlon.
British writer Redmond O'Hanlon traveled to the region in 1989 and not only failed to discover any evidence of Mokèlé-mbèmbé but found out that many local people believe the creature to be a spirit rather than a physical being, and that claims for its authentic existence have been fabricated. His experience is chronicled in "Granta" no. 39 (1992) and in his book "Congo Journey" (UK, 1996), published as "No Mercy" in the USA (1997).
1992 Operation Congo 2.
William Gibbons launched a second expedition in 1992 which he dubbed "Operation Congo 2". Along with Rory Nugent, Gibbons searched almost two thirds of the Bai River along with two poorly charted lakes: Lake Fouloukuo and Lake Tibeke, both of which local folklore held to be sites of Mokèlé-mbèmbé activity. The expedition failed to provide any conclusive evidence of the Mokèlé-mbèmbé, though they did further document local legends and Nugent took two photographs of unidentified objects in the water, one of which he claimed was the creature's head. 
2000: Extreme Expeditions.
In January 2000, the Congo Millennium Expedition (aka. DINO2000) took place, the second one by Extreme Expeditions, consisting of Andrew Sanderson, Adam Davies, Keith Townley, Swedish explorer Jan-Ove Sundberg, and five others. (Adam Davies has spoken of the Mokèlé-mbèmbé on a 2011 BBC video.)
2000: Gibbons.
In November 2000, William Gibbons did some preliminary research in Cameroon for a future expedition. He was accompanied by David Wetzel, and videographer Elena Dugan. While visiting with a group of pygmies, they were informed about an animal called Ngoubou, a horned creature. The pygmies asserted it was not a regular rhinoceros, as it had more than one horn (six horns on the frill in one eyewitness account), and that the father of one of the senior members of the community had killed one with a spear a number of years ago. The locals have noted a firm dwindle in the population of these animals lately, and that they are hard to find. Gibbons identified the animal with a "Styracosaurus", but, in addition to being extinct, these are only known to have inhabited North America.
2001: CryptoSafari/BCSCC.
In February 2001, in a joint venture between CryptoSafari and the British Columbia Scientific Cryptozoology Club (BCSCC), a research team traveled to Cameroon consisting of William Gibbons, Scott T. Norman, John Kirk and writer Robert A. Mullin. Their local guide was Pierre Sima Noutchegeni. They were also accompanied by a BBC film crew. No evidence of Mokèlé-mbèmbé was found.
2001: BBC Congo.
In 2001, BBC broadcast in the TV series "Congo" a collective interview with a group of BiAka pygmies, who identified the "mokele mbembe" as the rhino while looking at an illustrated manual of local wildlife.
2004: Cryptid Hunters.
In December 2004 Roland Smith published the book "Cryptid Hunters", which includes a search for the elusive creature at Lake Tele in the Congo.
In the sequels, "Tentacles" and "Chupacabra", they also pursued the kraken and the chupacabra, also known as the "goat sucker". In "Cryptid Hunters", one of the characters stated that he thought that it may be an animal grown in a lab.
2006: Marcy.
In January 2006, the Milt Marcy Expedition traveled to the Dja river in Cameroon, near the Congolese border. It consisted of Milt Marcy, Peter Beach, Rob Mullin and Pierre Sima. They spoke to witnesses that claimed to have observed a Mokèlé-mbèmbé only two days before, but they did not discover the animal themselves. However, they did return with what they believe to be a plaster cast of a Mokèlé-mbèmbé footprint.
2006: National Geographic.
A May 2006 episode called "Super Snake" of the National Geographic series "Dangerous Encounters" included an expedition headed by Brady Barr to Lake Tele. No unknown animals were found.
2006: Vice Guide to Travel.
In 2006, David Choe travelled to the Republic of Congo in search of the creature for Vice in the segment "The Last Dinosaur of the Congo". Choe and his companions failed to find the animal and the focus of the documentary turned to the rituals of their Pygmy guides.
2008: "Destination Truth".
In March 2008, an episode of the SyFy (formerly the SciFi Channel) series "Destination Truth" involved investigator Joshua Gates and crew searching for the creature. They did not visit the Likouala Region, which includes Lake Tele, but they visited Lake Bangweulu in Zambia instead, which had reports of a similar creature in the early 20th century, called the "'nsanga". The crew of "Destination Truth" kept calling the animal "Mokèlé-mbèmbé" to the locals, when that name is only used in the Republic of the Congo. The name used in that particular spot is "chipekwe". Their episode featured a videotaped encounter filmed from a great distance. On applying digital video enhancement techniques, the encounter proved to be nothing more than two submerged hippopotami.
2009: "MonsterQuest".
In March 2009 an episode of the History Channel series "MonsterQuest" involved William Gibbons, Rob Mullin, local guide Pierre Sima and a two-man film crew from White Wolf Productions. It took place in Cameroon, in the region of Dja River, Boumba River, and Nkogo River, near the border with the Republic of the Congo. The episode aired in the summer of 2009, and also featured an interview with Roy P. Mackal and Peter Beach of the Milt Marcy Expedition, 2006. While no sightings were reported on the expedition, the team found evidence of a large underground cave with air vents. The team also received sonar readings of very long, serpentine shapes underwater.
2011: "Beast Hunter".
A March 2011 episode of Beast Hunter on the National Geographic Channel featured a search for Mokele-mbembe in the Congo Basin.
2012: The Newmac Expedition.
In April 2012 Stephen McCullah & Sam Newton launched a Kickstarter campaign to fund an expedition to the Congo region to search for Mokele-mbembe. Despite raising some $29,000 the expedition suffered financial difficulties and is believed to have been abandoned shortly after the party reached the Congo in July 2012.
In popular culture.
Several films based on the Mokele Mbembe legend have been released. The film "", starring William Katt, was released in 1985. Another film, "The Dinosaur Project", starring Richard Dillane, was released in 2012.
In May 2013 the Norwegian experimental music outfit "Sturle Dagsland" released a song entitled "Mokèlé-mbèmbé".
In cryptozoology.
According to science writer and cryptozoologist Willy Ley, while there are sufficient anecdotal accounts to suggest "that there is a large and dangerous animal hiding in the shallow waters and rivers of Central Africa", the body of evidence remains insufficient for any realistic conclusions to be drawn on what the Mokèlé-mbèmbé may be.
According to the writings of biologist and cryptozoologist Roy Mackal, who mounted two unsuccessful expeditions to find it, it is unlikely that the Mokèlé-mbèmbé is a mammal or an amphibian, leaving a reptile as the only plausible candidate. Of all the living reptiles, Mackal argues that the iguana and the monitor lizards bear the closest resemblance to the Mokèlé-mbèmbé, though, at 15 to 30 ft long, the Mokèlé-mbèmbé would exceed the size of any known living examples of such reptiles. Mackal believes the description of the Mokèlé-mbèmbé is "consistent with a small sauropod dinosaur", although new discoveries regarding sauropods prove this to be inaccurate, as shown by paleontologists such as Darren Naish.
Mackal also judged the existence of an undiscovered relict sauropod to be plausible on the grounds that there were large amounts of uninhabited and unexplored territory in the region where a creature might live, and on the grounds that other large creatures such as elephants exist in the region, living in large open clearings (called "bai") as well as in thicker wooded areas.
However, other researchers have argued against the existence of Mokele Mbembe. According to Daniel Loxton and Donald Prothero, the conventional image of Mokele Mbembe held by cryptozoologists such as Roy Mackal is based on an outdated image of sauropod dinosaurs from the early twentieth century. For example, most sauropods did not live in swampy areas and subsist on aquatic plants. Instead, they lived in seasonally dry woodlands and ate tough conifers and cycads. This suggests that Mokele Mbembe sightings are not of a real sauropod dinosaur population but are instead the attempts of cryptozoologists to fit ambiguous eyewitness accounts into an outdated image of sauropod dinosaurs. Loxton and Prothero also argue that a surviving population of sauropod dinosaurs would leave behind skeletal remains like other large animals do and the rich fossil record of Africa should contain dinosaur bones younger that 65 million years old if a group of non-avian dinosaurs had survived to the present. The absence of this evidence despite several centuries of Western contact with the region and numerous expeditions in search of the animal argues against the existence of Mokele Mbembe. The failure of aerial surveillance and satellite imagery to detect these large animals while being able to detect other large animals like elephants also argues against the existence of Mokele Mbembe.

</doc>
<doc id="19513" url="http://en.wikipedia.org/wiki?curid=19513" title="Intuitionism">
Intuitionism

In the philosophy of mathematics, intuitionism, or neointuitionism (opposed to preintuitionism), is an approach where mathematics is considered to be purely the result of the constructive mental activity of humans rather than the discovery of fundamental principles claimed to exist in an objective reality. That is, logic and mathematics are not considered analytic activities wherein deep properties of objective reality are revealed and applied but are instead considered the application of internally consistent methods used to realize more complex mental constructs, regardless of their possible independent existence in an objective reality.
Truth and proof.
The fundamental distinguishing characteristic of intuitionism is its interpretation of what it means for a mathematical statement to be true. In Brouwer's original intuitionism, the truth of a mathematical statement is a subjective claim: a mathematical statement corresponds to a mental construction, and a mathematician can assert the truth of a statement only by verifying the validity of that construction by intuition. The vagueness of the intuitionistic notion of truth often leads to misinterpretations about its meaning. Kleene formally defined intuitionistic truth from a realist position, yet Brouwer would likely reject this formalization as meaningless, given his rejection of the realist/Platonist position. Intuitionistic truth therefore remains somewhat ill-defined. However, because the intuitionistic notion of truth is more restrictive than that of classical mathematics, the intuitionist must reject some assumptions of classical logic to ensure that everything he proves is in fact intuitionistically true. This gives rise to intuitionistic logic.
To an intuitionist, the claim that an object with certain properties exists is a claim that an object with those properties can be constructed. Any mathematical object is considered to be a product of a construction of a mind, and therefore, the existence of an object is equivalent to the possibility of its construction. This contrasts with the classical approach, which states that the existence of an entity can be proved by refuting its non-existence. For the intuitionist, this is not valid; the refutation of the non-existence does not mean that it is possible to find a construction for the putative object, as is required in order to assert its existence. Existence is construction, not proof of non-existence (Fenstad). As such, intuitionism is a variety of mathematical constructivism; but it is not the only kind.
The interpretation of negation is different in intuitionist logic than in classical logic. In classical logic, the negation of a statement asserts that the statement is "false"; to an intuitionist, it means the statement is "refutable" (e.g., that there is a counterexample). There is thus an asymmetry between a positive and negative statement in intuitionism. If a statement "P" is provable, then it is certainly impossible to prove that there is no proof of "P". But even if it can be shown that no disproof of "P" is possible, we cannot conclude from this absence that there "is" a proof of "P". Thus "P" is a stronger statement than "not-not-P".
Similarly, to assert that "A" or "B" holds, to an intuitionist, is to claim that either "A" or "B" can be "proved". In particular, the law of excluded middle, ""A" or not "A", is not accepted as a valid principle. For example, if "A" is some mathematical statement that an intuitionist has not yet proved or disproved, then that intuitionist will not assert the truth of "A" or not "A". However, the intuitionist will accept that "A" and not "A"" cannot be true. Thus the connectives "and" and "or" of intuitionistic logic do not satisfy de Morgan's laws as they do in classical logic.
Intuitionistic logic substitutes constructability for abstract truth and is associated with a transition from the proof to model theory of abstract truth in modern mathematics. The logical calculus preserves justification, rather than truth, across transformations yielding derived propositions. It has been taken as giving philosophical support to several schools of philosophy, most notably the Anti-realism of Michael Dummett. Thus, contrary to the first impression its name might convey, and as realized in specific approaches and disciplines (e.g. Fuzzy Sets and Systems), intuitionist mathematics is more rigorous than conventionally founded mathematics, where, ironically, the foundational elements which Intuitionism attempts to construct/refute/refound are taken as intuitively given.
Intuitionism and infinity.
Among the different formulations of intuitionism, there are several different positions on the meaning and reality of infinity.
The term potential infinity refers to a mathematical procedure in which there is an unending series of steps. After each step has been completed, there is always another step to be performed. For example, consider the process of counting: 1, 2, 3, …
The term actual infinity refers to a completed mathematical object which contains an infinite number of elements. An example is the set of natural numbers, N = {1, 2, …}.
In Cantor's formulation of set theory, there are many different infinite sets, some of which are larger than others. For example, the set of all real numbers R is larger than N, because any procedure that you attempt to use to put the natural numbers into one-to-one correspondence with the real numbers will always fail: there will always be an infinite number of real numbers "left over". Any infinite set that can be placed in one-to-one correspondence with the natural numbers is said to be "countable" or "denumerable". Infinite sets larger than this are said to be "uncountable".
Cantor's set theory led to the axiomatic system of Zermelo–Fraenkel set theory (ZFC), now the most common foundation of modern mathematics. Intuitionism was created, in part, as a reaction to Cantor's set theory.
Modern constructive set theory includes the axiom of infinity from ZFC (or a revised version of this axiom) and the set N of natural numbers. Most modern constructive mathematicians accept the reality of countably infinite sets (however, see Alexander Esenin-Volpin for a counter-example).
Brouwer rejected the concept of actual infinity, but admitted the idea of potential infinity.
Finitism is an extreme version of Intuitionism that rejects the idea of potential infinity. According to Finitism, a mathematical object does not exist unless it can be constructed from the natural numbers in a finite number of steps.
History of Intuitionism.
Intuitionism's history can be traced to two controversies in nineteenth century mathematics.
The first of these was the invention of transfinite arithmetic by Georg Cantor and its subsequent rejection by a number of prominent mathematicians including most famously his teacher Leopold Kronecker — a confirmed finitist.
The second of these was Gottlob Frege's effort to reduce all of mathematics to a logical formulation via set theory and its derailing by a youthful Bertrand Russell, the discoverer of Russell's paradox. Frege had planned a three volume definitive work, but shortly after the first volume had been published, Russell sent Frege a letter outlining his paradox which demonstrated that one of Frege's rules of self-reference was self-contradictory.
Frege, the story goes, plunged into depression and did not publish the second and third volumes of his work as he had planned. For more see Davis (2000) Chapters 3 and 4: Frege: "From Breakthrough to Despair" and Cantor: "Detour through Infinity." See van Heijenoort for the original works and van Heijenoort's commentary.
These controversies are strongly linked as the logical methods used by Cantor in proving his results in transfinite arithmetic are essentially the same as those used by Russell in constructing his paradox. Hence how one chooses to resolve Russell's paradox has direct implications on the status accorded to Cantor's transfinite arithmetic.
In the early twentieth century L. E. J. Brouwer represented the "intuitionist" position and David Hilbert the formalist position — see van Heijenoort. Kurt Gödel offered opinions referred to as "Platonist" (see various sources re Gödel). Alan Turing considers:
"non-constructive systems of logic with which not all the steps in a proof are mechanical, some being intuitive". (Turing 1939, reprinted in Davis 2004, p. 210) Later, Stephen Cole Kleene brought forth a more rational consideration of intuitionism in his Introduction to Meta-mathematics (1952).

</doc>
<doc id="19514" url="http://en.wikipedia.org/wiki?curid=19514" title="May 6">
May 6

May 6 is the day of the year in the Gregorian calendar.

</doc>
<doc id="19516" url="http://en.wikipedia.org/wiki?curid=19516" title="March 2">
March 2

March 2 is the day of the year in the Gregorian calendar.

</doc>
<doc id="19518" url="http://en.wikipedia.org/wiki?curid=19518" title="Mishnah">
Mishnah

The Mishnah or Mishna (; Hebrew: מִשְׁנָה, "study by repetition"), from the verb "shanah" שנה, or "to study and review", also "secondary," is the first major written redaction of the Jewish oral traditions known as the "Oral Torah". It is also the first major work of Rabbinic literature. The earliest known copy of the Mishnah has additions, and is contained within a book featuring commentary that was printed in Naples Italy during the late 15th century.
The Mishnah was redacted by Rabbi Yehudah HaNasi before his death around 217 CE, in a time when, according to the Talmud, the persecution of the Jews and the passage of time raised the possibility that the details of the oral traditions of the Pharisees from the Second Temple period (536 BCE – 70 CE) would be forgotten. The majority of the Mishnah is written in Mishnaic Hebrew, while some parts are Aramaic.
The Mishnah consists of six orders ("sedarim", singular "seder" סדר), each containing 7–12 tractates ("masechtot", singular "masechet" מסכת; lit. "web"), 63 in total, and further subdivided into chapters and paragraphs or verses.
The word "Mishnah" can also indicate a single paragraph or a verse of the work itself, i.e. the smallest unit of structure in the Mishnah. For this reason the whole work is sometimes called by the plural, "Mishnayot".
Structure.
The term "Mishnah" originally referred to a method of teaching by presenting topics in a systematic order, as contrasted with "Midrash", which meant teaching by following the order of the Bible. The Mishnah as a written compilation accordingly orders its content by subject matter, instead of by biblical context as the Midrashim do. Likewise it includes a much broader selection of halakhic subjects, and discusses individual subjects more thoroughly, than the Midrashim.
The Mishnah consists of six orders ("sedarim", singular "seder" סדר), each containing 7–12 tractates ("masechtot", singular "masechet" מסכת; lit. "web"), 63 in total. Each "masechet" is divided into chapters ("peraqim", singular "pereq") and then paragraphs ("mishnayot", singular "mishnah"). In this last context, the word "mishnah" means a single paragraph of the work, i.e. the smallest unit of structure, leading to the use of the plural, "Mishnayot", for the whole work.
Because of the division into six orders, the Mishnah is sometimes called "Shas" (an acronym for "Shisha Sedarim" – the "six orders"), though that term is more often used for the Talmud as a whole.
The six orders are:
In each order (with the exception of Zeraim), tractates are arranged from biggest (in number of chapters) to smallest. A popular mnemonic consists of the acronym "Z'MaN NaKaT."
The Babylonian Talmud (Hagiga 14a) states that there were either six hundred or seven hundred orders of the Mishnah. Hillel the Elder organized them into six orders to make it easier to remember. The historical accuracy of this tradition is disputed. There is also a tradition that Ezra the scribe dictated from memory not only the 24 books of the Tanakh but 60 esoteric books. It is not known whether this is a reference to the Mishnah, but there is a case for saying that the Mishnah does consist of 60 tractates. (The current total is 63, but Makkot was originally part of Sanhedrin, and Bava Kamma, Bava Metzia and Bava Batra may be regarded as subdivisions of a single tractate Nezikin.)
Interestingly, Reuvein Margolies (1889–1971) posited that there were originally seven orders of Mishnah, citing a Gaonic tradition on the existence of a seventh order containing the laws of "Sta"m" (scribal practice) and Berachot (blessings).
Omissions.
A number of important laws are not elaborated upon in the Mishnah. These include the laws of tzitzit, tefillin (phylacteries), mezuzot, the holiday of Hanukkah, and the laws of gerim (converts). These were later discussed in the minor tractates.
Rabbi Nissim Gaon in his "Hakdamah Le'mafteach Hatalmud" writes that many of these laws were so well known that it was unnecessary for Rabbi Judah to discuss them. Reuvein Margolies suggests that as the Mishnah was redacted after the Bar Kochba revolt, Rabbi Judah could not have included discussion of Hanukkah which commemorates the Jewish revolt against the Syrian-Greeks (the Romans would not have tolerated this overt nationalism). Similarly, there were then several decrees in place aimed at suppressing outward signs of national identity, including decrees against wearing tefillin and tzitzit; as Conversion to Judaism was against Roman law, Rabbi Judah would not have discussed this.
David Zvi Hoffman suggests that there existed ancient texts in the form of the present day Shulchan Aruch that discussed the basic laws of day to day living and it was therefore not necessary to focus on these laws in the Mishnah.
Mishnah, Gemara and Talmud.
Rabbinic commentaries on the Mishnah from the next four centuries, done in the land of Israel and in Babylonia, were eventually redacted and compiled as well. In themselves they are known as Gemara. The books which set out the Mishnah in its original structure, together with the associated Gemara, are known as Talmuds. Two Talmuds were compiled, Babylonian Talmud (to which the term "Talmud" normally refers) and Jerusalem Talmud. Unlike the Hebrew Mishnah, the Gemara is written primarily in Aramaic.
Content and purpose.
The Mishnah teaches the oral traditions by example, presenting actual cases being brought to judgment, usually along with the debate on the matter and the judgment that was given by a notable rabbi based on the halacha, "mitzvot", and spirit of the teaching ("Torah") that guided his decision. In this way, it brings to everyday reality the practice of the "mitzvot" as presented in the Bible, and aims to cover all aspects of human living, serve as an example for future judgments, and, most important, demonstrate pragmatic exercise of the Biblical laws, which was much needed since the time when the Second Temple was destroyed (70 CE). The Mishnah does not claim to be the development of new laws, but rather the collection of existing traditions.
The term "Mishnah" is related to the verb "shanah", to teach or repeat, and to the adjectives "sheni" and "mishneh", meaning "second". It is thus named for being both the one written authority (codex) secondary (only) to the Tanakh as a basis for the passing of judgment, a source and a tool for creating laws, and the first of many books to complement the Bible in certain aspects.
Oral law.
Before the publication of the Mishnah, Jewish scholarship and judgement were predominantly oral, as it was not permitted to write them down. The earliest recorded oral law may have been of the midrashic form, in which halakhic discussion is structured as exegetical commentary on the Torah. Rabbis expounded on and debated the Tanakh (Hebrew: תַּנַ"ךְ), the Hebrew Bible, without the benefit of written works (other than the Biblical books themselves), though some may have made private notes (Hebrew: מגילות סתרים‎, "megillot setarim"), for example of court decisions. The oral traditions were far from monolithic, and varied among various schools, the most famous of which were the House of Shammai and the House of Hillel.
After First Jewish–Roman War in 70 CE, with the end of the Second Temple Jewish center in Jerusalem, Jewish social and legal norms were in upheaval. The Rabbis were faced with the new reality of Judaism without a Temple (to serve as the center of teaching and study) and Judea without autonomy. It is during this period that Rabbinic discourse began to be recorded in writing. The possibility was felt that the details of the oral traditions of the Pharisees from the Second Temple period (530s BCE – 70 CE) would be forgotten, so the justification was found to have these oral laws transcribed.
Over time, different traditions of the Oral Law came into being, raising problems of interpretation. According to the "Mevo Hatalmud" many rulings were given in a specific context, but would be taken out of it; or a ruling was revisited but the second ruling would not become popularly known. To correct this, Rabbi Yehuda haNasi took up the redaction of the Mishnah. If a point was of no conflict, he kept its language; where there was conflict, he reordered the opinions and ruled; and he clarified where context was not given. The idea was not to use his own discretion, but rather to examine the tradition as far back as he could, and only supplement as required.
The Mishnah and the Hebrew Bible.
According to Rabbinical Judaism, the Oral Torah (Hebrew: תורה שבעל-פה‎, "Torah she-be'al-peh") was given to Moses with the Torah at Mount Sinai, as an exposition to the latter. The accumulated traditions of the Oral Law, expounded by scholars in each generation from Moses onward, is considered as the necessary basis for the interpretation, and often for the reading, of the Written Law. Jews sometimes refer to this as the "Masorah (Hebrew: מסורה‎)", roughly translated as tradition, though that word is often used in a narrower sense to mean traditions concerning the editing and reading of the Biblical text (see Masorah). The resulting Jewish law and custom is called "halakha (Hebrew: הלכה‎").
While most discussions in the Mishnah concern the correct way to carry out laws recorded in the Torah, it usually presents its conclusions without explicitly linking them to any scriptural passage, though scriptural quotations do occur. For this reason it is arranged in order of topics rather than in the form of a Biblical commentary. (In a very few cases, there is no scriptural source at all and the law is described as "Halakha le-Moshe mi-Sinai", law to Moses from Sinai.) The "Midrash halakha", by contrast, while presenting similar laws, does so in the form of a Biblical commentary and explicitly links its conclusions to details in the Biblical text. These Midrashim often predate the Mishnah.
The Mishnah also quotes the Torah for principles not associated with law, but just as practical advice, even at times for humor or as guidance for understanding historical debates.
Authorship.
The rabbis who contributed to the Mishnah are known as the "Tannaim", of whom approximately 120 are known. The period during which the Mishnah was assembled spanned about 130 years, or five generations, in the 1st and 2nd centuries CE. Yehudah haNasi is credited with the final redaction and publication of the Mishnah, though there have been a few additions since his time: those passages that cite him or his grandson, Rabbi Yehuda Nesi'ah, and the end of Tractate Sotah, which refers to the period after Rabbi's death. One must also note that in addition to redacting the Mishnah, Rabbi and his court also ruled on which opinions should be followed, though the rulings do not always appear in the text.
Most of the Mishnah is related without attribution ("stam"). This usually indicates that many sages taught so, or that Yehudah HaNasi (often called simply "Rabbi") ruled so. The "halakhic" ruling usually follows that view. Sometimes, however, it appears to be the opinion of a single sage, and the view of the sages collectively (Hebrew: חכמים‎, "hachamim") is given separately.
As Yehuda haNasi went through the tractates, the Mishnah was set forth, but throughout his life some parts were updated as new information came to light. Because of the proliferation of earlier versions, it was deemed too hard to retract anything already released, and therefore a second version of certain laws were released. The Talmud refers to these differing versions as "Mishnah Rishonah" ("First Mishnah") and "Mishnah Acharonah" ("Last Mishnah"). David Zvi Hoffman suggests that "Mishnah Rishonah" actually refers to texts from earlier Sages upon which Rabbi based his Mishnah.
The Talmud records a tradition that unattributed statements of the law represent the views of Rabbi Meir (Sanhedrin 86a), which supports the theory (recorded by Sherira Gaon in his famous "Iggeret") that he was the author of an earlier collection. For this reason, the few passages that actually say "this is the view of Rabbi Meir" represent cases where the author intended to present Rabbi Meir's view as a "minority opinion" not representing the accepted law.
There are also references to the "Mishnah of Rabbi Akiva", suggesting a still earlier collection; on the other hand, these references may simply mean his teachings in general. Another possibility is that Rabbi Akiva and Rabbi Meir established the divisions and order of subjects in the Mishnah, making them the authors of a school curriculum rather than of a book.
Authorities are divided on whether Rabbi recorded the Mishnah in writing or established it as an oral text for memorisation. The most important early account of its composition, the Epistle of Sherira Gaon, is ambiguous on the point, though the "Spanish" recension leans to the theory that the Mishnah was written. However, the Talmud records that, in every study session, there was a person called the "tanna" appointed to recite the Mishnah passage under discussion. This may indicate that, even if the Mishnah was reduced to writing, it was not available on general distribution.
Acceptance.
Some Jews did not accept the written codification of the oral law at all; known as Karaites, they comprised a significant portion of the world Jewish population in the 10th and 11th centuries CE, and remain extant, although they currently number in the thousands.
Mishnah studies.
Textual variants.
Very roughly, there are two traditions of Mishnah text. One is found in manuscripts and printed editions of the Mishnah on its own, or as part of the Jerusalem Talmud. The other is found in manuscripts and editions of the Babylonian Talmud; though there is sometimes a difference between the text of a whole paragraph printed at the beginning of a discussion (which may be edited to conform with the text of the Mishnah-only editions) and the line-by-line citations in the course of the discussion. 
Robert Brody, in his "Mishna and Tosefta Studies" (Jerusalem 2014), warns against over-simplifying the picture by assuming that the Mishnah-only tradition is always the more authentic, or that it represents a "Palestinian" as against a "Babylonian" tradition. Manuscripts from the Cairo Geniza, or citations in other works, may support either type of reading or other readings altogether.
Printed editions.
The first printed edition of the Mishnah was published in Naples. There have been many subsequent editions, including the late 19th century Vilna edition, which is the basis of the editions now used by the religious public.
Vocalized editions were published in Italy, culminating in the edition of David ben Solomon Altaras, publ. Venice 1737. The Altaras edition was republished in Mantua in 1777, in Pisa in 1797 and 1810 and in Livorno in many editions from 1823 until 1936: reprints of Livorno editions were published in Israel in 1913, 1962, 1968 and 1976. Most of these editions contain notes of textual variants as well as vocalization. The Livorno editions are the basis of the Sephardic tradition for recitation, for example in memory of a deceased person (see link "Tradition and Relevance" at end of article).
As well as being printed on its own, the Mishnah is included in all editions of the Babylonian and Jerusalem Talmuds. Each paragraph is printed on its own, and followed by the relevant Gemara discussion. However, that discussion itself often cites the Mishnah line by line. While the text printed in paragraph form has generally been standardized to follow the Vilna edition, the text cited line by line in the Gemara often preserves important variants, which sometimes reflect the readings of older manuscripts.
The nearest approach to a critical edition is that of Hanoch Albeck. There is also an edition by Yosef Qafiḥ of the Mishnah together with the commentary of Maimonides, which compares the base text used by Maimonides with the Napoli and Vilna editions and other sources.
Oral traditions and pronunciation.
The Mishnah was and still is traditionally studied through recitation (out loud). Many medieval manuscripts of the Mishnah are vowelized, and some of these contain partial Tiberian cantillation. Jewish communities around the world preserved local melodies for chanting the Mishnah, and distinctive ways of pronouncing its words.
Most vowelized editions of the Mishnah today reflect standard Ashkenazic vowelization, and often contain mistakes. The Albeck edition of the Mishnah was vowelized by Hanokh Yalon, who made careful eclectic use of both medieval manuscripts and current oral traditions of pronunciation from Jewish communities all over the world. The Albeck edition includes an introduction by Yalon detailing his eclectic method.
Two institutes at the Hebrew University in Jerusalem have collected major oral archives which hold (among other things) extensive recordings of Jews chanting the Mishnah using a variety of melodies and many different kinds of pronunciation. These institutes are the Jewish Oral Traditions Research Center and the National Voice Archives (the "Phonoteca" at the Jewish National and University Library). See below for external links.
As a historical source.
Both the Mishnah and Talmud contain little serious biographical studies of the people discussed therein, and the same tractate will conflate the points of view of many different people. Yet, sketchy biographies of the Mishnaic sages can often be constructed with historical detail from Talmudic and Midrashic sources.
Many modern historical scholars have focused on the timing and the formation of the Mishnah. A vital question is whether it is composed of sources which date from its editor's lifetime, and to what extent is it composed of earlier, or later sources. Are Mishnaic disputes distinguishable along theological or communal lines, and in what ways do different sections derive from different schools of thought within early Judaism? Can these early sources be identified, and if so, how? In response to these questions, modern scholars have adopted a number of different approaches.
Cultural references.
The most notable literary work on the composition of the Mishnah is probably Milton Steinberg's novel As a Driven Leaf.

</doc>
<doc id="19521" url="http://en.wikipedia.org/wiki?curid=19521" title="Marathon (disambiguation)">
Marathon (disambiguation)

A marathon is a distance race of 42.195 km, and often refers by analogy to any arduous or time-consuming undertaking.
Marathon may also refer to:

</doc>
<doc id="19522" url="http://en.wikipedia.org/wiki?curid=19522" title="Monotheism">
Monotheism

"Monotheism" is defined by the "Encyclopædia Britannica" as belief in the existence of one god or in the oneness of God. The "Oxford Dictionary of the Christian Church" gives a more restricted definition: "belief in one personal and transcendent God", as opposed to polytheism and pantheism. A distinction may be made between exclusive monotheism, and both inclusive monotheism and pluriform monotheism which, while recognising many distinct gods, postulate some underlying unity.
Monotheism characterizes the traditions of Babism, the Bahá'í Faith, Cao Dai (Caodaiism), Cheondoism (Cheondogyo), Christianity, Deism, Eckankar, Islam, Judaism, Rastafari, Ravidassia religion, Seicho no Ie, Shaivism, Shaktism, Sikhism, Tenrikyo (Tenriism), Vaishnavism, and Zoroastrianism and elements of the belief are discernible in numerous other religions including Atenism.
Origin and development.
The word "monotheism" comes from the Greek μόνος ("monos") meaning "single" and θεός ("theos") meaning "god". The English term was first used by Henry More (1614–1687).
According to Christian tradition, monotheism was the original religion of humanity but was generally lost after the fall of man. This theory was largely abandoned in the 19th century in favour of an evolutionary progression from animism via polytheism to monotheism, but by 1974 this theory was less widely held. Austrian anthropologist Wilhelm Schmidt had postulated an "Urmonotheismus", "original" or "primitive monotheism" in the 1910s. It was objected that Judaism, Christianity, and Islam had grown up in opposition to polytheism as had Greek philosophical monotheism. Furthermore, while belief in a "high god" is not universal, it is found in many parts of Africa and numerous other areas of the world.
Monolatrism can be a stage in the development of monotheism from polytheism. Three examples of this are the Aten cult in the reign of the Egyptian pharaoh Akhenaten, the rise of Marduk from the tutelary of Babylon to the claim of universal supremacy, and the rise of Yahweh from among the Israelite gods to the sole God of later Judaism.
In Zoroastrianism, Ahura Mazda appears as a supreme and transcendental deity. Depending on the date of Zoroaster (usually considered to be contemporary with the Vedas), this may be one of the earliest documented instances of the emergence of monism in an Indo-European religion.
In the cities of the Ancient Near East, each city had a local patron deity, such as Shamash at Larsa or Sin at Ur. The first claims of global supremacy of a specific god date to the Late Bronze Age, with Akhenaten's "Great Hymn to the Aten" (speculatively connected to Judaism by Sigmund Freud in his "Moses and Monotheism"). However the historicity of the Exodus is disputed. Furthermore it is not clear to what extent Akhenaten's Atenism was monotheistic rather than henotheistic with Akhenaten himself identified with the god Aten.
Currents of monism or monotheism emerge in Vedic India earlier, chiefly with worship of Lord Krishna, which is full-fledged monotheism, but also with e.g. the Nasadiya Sukta. In the Indo-Iranian tradition, the Rigveda exhibits notions of monism, in particular in the comparatively late tenth book, also dated to the early Iron Age, e.g. in the Nasadiya sukta.
Ethical monotheism and the associated concept of absolute good and evil emerge in Zoroastrianism and Judaism, later culminating in the doctrines of Christology in early Christianity and later (by the 7th century) in the "tawhid" in Islam.
Abrahamic religions.
Abrahamic religions are Monotheistic faiths of Middle Eastern origin, emphasizing and tracing their origins to Abraham or recognizing a spiritual tradition identified with him. As of the early twenty-first century, the majority of the World's population (54% or 3.8 billion people) consider themselves as monotheists and adherents of the Abrahamic religions.
The major scriptures of monotheism in the World are the narratives of the Torah, New Testament and Quran. These are the religious scriptures of Judaism, Christianity and Islam respectively - the three main Abrahamic religions. While adherents of Abrahamic religions consider themselves to be monotheists, Judaism and Islam only recognize each other as being monotheistic. Since they share a common theology, their differences are in that Judaism sees Islam as a closely related gentile monotheistic faith, and Islam sees Judaism as closely related, but incomplete religion due to the lack of recognition of the prophethoods both of Jesus and Muhammad.
Judaism.
The text of the Bible states that Judaism began with divine revelations from "God most high" to Abraham [Gen. 14-15] and to the Israelites at biblical Mount Sinai [Exodus 20]. The traditional interpretation of the Bible is that it uniformly presents one God as creator of the world and the only power controlling history. References to other "gods" are explained as references to non-existent entities or angelic servants of God, to whom humans mistakenly ascribe reality and power. e.g., Babylonian Talmud, Megilla 7b-17a.
However, the text is consistent with the hypothesis that Judaism was "originally" a form of monolatrism. Archeological evidence and literary criticism both suggest that the actual origins of Judaism lie in the history of the kingdoms of Judah and Israel, c.1,000-586 BCE. Both kingdoms had Yahweh as their state god (i.e., the god of the royal court and of the kingdom), while acknowledging the existence of other gods. In the 8th century the Assyrian royal propaganda claimed universal dominion (meaning dominion over all other gods) for the Assyrian state god Ashur. In reaction to this, certain circles in Israel stressed the unique power of Yahweh as a sign of national independence. When Israel was destroyed by Assyria (c.721 BCE) refugees brought this form of theism to Judah, where it was upheld during the reigns of at least two kings. At this stage (late 7th century), Judaism was not strictly monotheistic, but Yahweh was recognised as without peer and supreme over all other gods. The hypothesis posits a next stage, beginning with the fall of Judah to Babylon, when a small circle of priests and scribes gathered around the exiled royal court developed the first idea of Yahweh as the sole God of the world. The tendency to monotheism was accelerated by the fall of Babylon to the Persians in 538, which allowed the exiles to seize control of the new Persian province of Judah.
God in religious Judaism today is strictly monotheistic. This God of Israel is regarded as the God of Abraham, Isaac and Jacob, and is believed to be the ultimate cause of all existence. YHWH (Hebrew: יהוה‎) is the proper Name of God in Judaism. Another name of God is Elohim. God is an indivisible one God; as the Shema Yisrael states, its first, pivotal, words are:
The Hebrew Bible commands the Israelites not to worship other gods, but only the God of Israel who brought them out of Egypt (Ex. 20:1-4; Deut. 5:6-7).
The concept of Yahweh enlarged through the exile of Babylon and Yahweh was responsible for what happened to Israel. All the events and enemies around Israel were instruments in the divine hand because Yahweh is the only God and no other gods existed.
One of the best-known statements of Rabbinical Judaism on monotheism occurs in Maimonides' 13 Principles of faith, Second Principle:
God, the Cause of all, is one. This does not mean one as in one of a pair, nor one like a species (which encompasses many individuals), nor one as in an object that is made up of many elements, nor as a single simple object that is infinitely divisible. Rather, God is a unity unlike any other possible unity. This is referred to in the Torah (Deuteronomy 6:4): "Hear Israel, the Lord is our God, the Lord is one."
The ancient roots of monotheistic Judaism lie in the Bronze Age polytheistic Ancient Semitic religions, specifically Canaanite religion, a syncretization with elements of Zoroastrianism and of the worship of Yahweh reflected in the early prophetic books of the Hebrew Bible. Both archaeological evidence and the Biblical texts document tensions between groups comfortable with the worship of Yahweh alongside local deities such as Asherah and Baal and those insistent on the worship of Yahweh alone during the monarchal period.
According to the Hebrew Bible, Jerusalem was a Jebusite fortress, conquered by the Israelites and made into their capital around 1000 BCE (Edwin R. Thiele dates David's conquest of Jerusalem to 1003 BCE). As a result, the Jebusite cult exerted considerable influence on Israelite religion. The Jebusites observed an astral cult involving "Shalem", an astral deity identified with the Evening star in Ugaritic mythology, besides Tzedek "righteousness" and El Elyon, the "most high God".
During the 8th century BCE, worship of Yahweh in Israel was in competition with many other cults, described by the Yahwist faction collectively as Baals. The oldest books of the Hebrew Bible, written in the 8th century BCE reflect this competition, as in the books of Hosea and Nahum, whose authors lament the "apostasy" of the people of Israel, threatening them with the wrath of God if they do not give up their polytheistic cults. Worship of a pantheon or a form of duality may have lasted up until the Babylonian captivity.
The oldest writings of Judaism that survive directly date from the Hellenistic period. This includes Hebrew and Aramaic papyri with biblical fragments such as the Dead Sea Scrolls, and Greek documents such as the Septuagint. Scholars contend that the development of a strict monotheism was the result of cultural diffusion between Persians and Hebrews, or as a result of the contact of Israelite and Greek cultures.
As they traditionally profess a concept of monotheism with a singular God, Judaism and Islam reject the Christian idea of monotheism. Judaism uses the term Shituf to refer to ways of worshiping God not believed to be monotheistic. Muslims deny the Christian doctrine of the Trinity and divinity of Jesus, considering it to be polytheism.
The Shema.
Judaism's earliest history, beliefs, laws, and practices are preserved and taught in the Torah (the first part of the Hebrew Bible). It provides a clear textual source for the rise and development of what is named Judaism's ethical monotheism which means that:
When Moses returned with the Ten Commandments, the second of those stated that "you shall have no other gods before me" (Exodus 20:3), right after the first, which affirmed the existence of God. Furthermore, Israelites recite the Shema Yisrael ("Hear, O Israel") which partly says, "Hear, O Israel: YHWH is our God, YHWH is one", meaning that Israel was to worship none of the gods of other peoples. Monotheism was and is the central tenet of the Israelite and the Jewish religion.
The literal word meanings are roughly as follows:
In this case, "Elohim" is used in the plural as a form of respect and not polytheism.
"Gen.1:26" And Elohim said, Let "us" make man in "our" image, after "our" likeness: and let them have dominion over the fish of the sea, and over the fowl of the air, and over the cattle, and over all the earth, and over every creeping thing that creepeth upon the earth.
Elohim is morphologically plural in form in Hebrew, but generally takes singular agreement when it refers to the God of Israel (so the verb meaning "said" in this verse is "vayyomer" ויאמר with singular inflection, and not "vayyomru" ויאמרו with plural inflection), and yet in this case the "our" and "us" seems to create a presumption of plurality, though it may just be God talking to angels and not another god.
Judaism, however, insists that the "Lord is One" as in the Shema, and at least two interpretations exist to explain the Torah's use of the plural form. The first is that the plural form "Elohim" is analogous to the royal plural as used in English. The second is that, in order to set an example for human kings, Elohim consulted with his court (the angels, just created) before making a major decision (creating man). An alternative explanation by Mark S. Smith is that the notion of divinity underwent radical changes throughout the period of early Israelite identity. Smith has said that the ambiguity of the term "Elohim" is the result of such changes, cast in terms of "vertical translatability" by Smith (2008); i.e., the re-interpretation of the gods of the earliest recalled period as the national god of the monolatrism as it emerged in the 7th to 6th century BCE in the Kingdom of Judah and during the Babylonian captivity, and further in terms of monotheism by the emergence of Rabbinical Judaism in the 2nd century CE.
Christianity.
From earlier than the times of the Nicene Creed, 325 CE, various Christian figures advocated the triune mystery-nature of God as a normative profession of faith. According to Roger E. Olson and Christopher Hall, through prayer, meditation, study and practice, the Christian community concluded "that God must exist as both a unity and trinity", codifying this in ecumenical council at the end of the 4th century.
Christians have held that in scriptural references to 'God the Father' (Philippians , 1 Peter ) 'God the Son' (John, , Hebrews , Colossians ) and 'God the Holy Spirit' (Acts ) are referring to or describing the different divine persons. But they also still believe that passages of the New Testament, such as "there is none other God but one... to us there is but one God, the Father, of whom are all things, and we in him; and one Lord Jesus Christ, by whom are all things, and we by him" and the Old Testament, such as "I am the Lord, and there is none else, there is no God beside me... there is none beside me. I am the Lord, and there is none else", claim God as being 'one'.
Many modern Christians believe the Godhead is triune meaning that the three persons of the Trinity are in one union in which each person is also wholly God. They also hold to the doctrine of a man-god Christ Jesus as God incarnate. These Christians also do not believe that one of the three divine figures is God alone and the other two are not but that all three are mysteriously God and one. Other Christian religions including Unitarian Universalism, Jehovah's Witnesses, Mormonism and others do not share those views on the Trinity.
Historically, most Christian churches have taught that the nature of God is a "mystery", in the original, technical meaning; something that must be revealed by special revelation rather than deduced through general revelation. Among early Christians there was considerable debate over the nature of the Godhead, with some denying the incarnation but not the deity of Jesus (Docetism) and others later calling for an Arian conception of God. Despite at least one earlier local synod rejecting the claim of Arius, this Christological issue was to be one of the items addressed at the First Council of Nicaea.
However, some Christian faiths such as Mormonism argue that the Godhead is in fact three separate individuals which include God the Father, His Son Jesus Christ, and the Holy Ghost. Each individual having a distinct purpose in the grand existence of human kind. Furthermore, Mormons believe that before the "Council of Nicaea," the predominant belief among many early Christians was that the Godhead was three separate individuals. In support of this view, they cite early Christian examples of belief in subordinationism.
The First Council of Nicaea, held in Nicaea (in present-day Turkey), convoked by the Roman Emperor Constantine I in 325, was the first ecumenical council of bishops of the Roman Empire, and most significantly resulted in the first uniform Christian doctrine, called the Nicene Creed. With the creation of the creed, a precedent was established for subsequent 'general (ecumenical) councils of bishops' (synods) to create statements of belief and canons of doctrinal orthodoxy— the intent being to define a common creed for the Church and address heretical ideas.
One purpose of the council was to resolve disagreements in Alexandria over the nature of Jesus in relationship to the Father; in particular, whether Jesus was of the same substance as God the Father or merely of similar substance. All but two bishops took the first position; while Arius' argument failed.
Christian orthodox traditions (Eastern Orthodox, Oriental Orthodox, Roman Catholic, and most Protestants) follow this decision, which was reaffirmed in 381 at the First Council of Constantinople and reached its full development through the work of the Cappadocian Fathers. They consider God to be a triune entity, called the Trinity, comprising the three "persons" God the Father, God the Son, and God the Holy Spirit, the three of this unity are described as being "of the same substance" (ὁμοούσιος). Christians overwhelmingly assert that monotheism is central to the Christian faith, as the Nicene Creed (and others), which gives the orthodox Christian definition of the Trinity, begins: "I believe in one God".
Deism is a philosophy of religion which arises in the Christian tradition during the Early Modern period. It postulates that there is a God who however does not intervene in human affairs.
Unitarianism is a theological movement, named for its understanding of God as one person, in direct contrast to Trinitarianism.
Islam.
Islam emerged in the 7th century CE as a reaction to both Christianity and Judaism, with thematic elements similar to Gnosticism. Islamic belief states that Muhammad did not bring a new religion from God, but is rather the same religion as practiced by Abraham, Moses, David, Jesus and all the other prophets of God. The assertion of Islam is that the message of God had been corrupted, distorted or lost over time and the Quran was sent to Muhammad in order to correct the lost message of the Torah, New Testament and prior scriptures from God.
In Islam, Allāh (God) is all-powerful and all-knowing, the creator, sustainer, ordainer and judge of the universe. God in Islam is strictly singular ("tawhid") unique ("wahid") and inherently One ("ahad"), all-merciful and omnipotent. Allāh exists without place and the Qur'an states that "No vision can grasp Him, but His grasp is over all vision. God is above all comprehension, yet is acquainted with all things" (Qur'an 6:103) Allāh is the only God and the same God worshiped in Christianity and Judaism. ().
The Qur'an asserts the existence of a single and absolute truth that transcends the world; a unique and indivisible being who is independent of the creation. The Qur'an rejects binary modes of thinking such as the idea of a duality of God by arguing that both good and evil generate from God's creative act. God is a universal god rather than a local, tribal or parochial one; an absolute who integrates all affirmative values and brooks no evil.
"Tawhid" constitutes the foremost article of the Muslim profession of faith, "There is no god but God, Muhammad is the messenger of God. To attribute divinity to a created entity is the only unpardonable sin mentioned in the Qur'an. The entirety of the Islamic teaching rests on the principle of "tawhid".
As they traditionally profess a concept of monotheism with a singular person as God, Judaism and Islam reject the Christian idea of monotheism. Judaism uses the term Shituf to refer to ways of worshiping God that Jews don't think is monotheistic. Though Muslims believe in Jesus (Isa in Arabic), they do not affirm that he was a begotten son of God. Jesus is mentioned more times in the Qur'an than Muhammad, but not in conjunction with the Christian doctrine of the Trinity () constituting this to be "shirk", deviation from the true Abrahamic religion (), and unrealistic excess in religion ().
Sabianism.
According to the Quran, the Sabians were a monotheistic religious group. Some Hadiths account them as converts to Islam. However this interpretation may be related to the fact that Quraysh polytheists used to describe anyone who converted to Islam with the word "Saba" (صبى/صبوت) which may either mean that this term was used for anyone who changed his religion or that they identified the message of Muhammed as a "Sabian belief". The former linguistic explanation (i.e. "saba" = "changed his religion") is the one adopted by most Muslim scholars.
Sabians are often identified with Mandaeism, a small monotheistic community which lives today in Iraq and call themselves "Yahyawiya" (Arabic: يحياوية‎). Muslim scholars traditionally viewed them as followers of the prophets Noah and "Yahya" (i.e. John the Baptist).
Bahá'í Faith.
God in the Bahá'í Faith is taught to be a personal god, too great for humans to fully comprehend. Human primitive understanding of God is achieved through his revelations via his divine intermediary Manifestations. In the Bahá'í faith, such Christian doctrines as the Trinity are seen as compromising the Bahá'í view that God is single and has no equal.
And the very existence of the Bahá'í Faith is a challenge to the Islamic doctrine of the finality of Muhammad's revelation.
God in the Bahá'í Faith communicates to humanity through divine intermediaries, known as Manifestations of God. These Manifestations establish religion in the world. It is through these divine intermediaries that humans can approach God, and through them God brings divine revelation and law.
The Oneness of God is one of the core teachings of the Bahá'í Faith. The obligatory prayers in the Bahá'í Faith involve explicit monotheistic testimony. God is the imperishable, uncreated being who is the source of all existence. He is described as "a personal God, unknowable, inaccessible, the source of all Revelation, eternal, omniscient, omnipresent and almighty". Although transcendent and inaccessible directly, his image is reflected in his creation. The purpose of creation is for the created to have the capacity to know and love its creator. God communicates his will and purpose to humanity through intermediaries, known as Manifestations of God, who are the prophets and messengers that have founded religions from prehistoric times up to the present day.
Atenism.
Amenhotep IV initially introduced Atenism in Year 5 of his reign (1348/1346 BCE), raising Aten to the status of Supreme God, after initially permitting the continued worship of the traditional gods. To emphasise the change, Aten's name was written in the cartouche form normally reserved for Pharaohs, an innovation of Atenism. This religious reformation appears to coincide with the proclamation of a Sed festival, a sort of royal jubilee intended to reinforce the Pharaoh's divine powers of kingship. Traditionally held in the thirtieth year of the Pharaoh's reign, this possibly was a festival in honour of Amenhotep III, whom some Egyptologists think had a coregency with his son Amenhotep IV of two to twelve years.
Year 5 is believed to mark the beginning of Amenhotep IV's construction of a new capital, Akhetaten ("Horizon of the Aten"), at the site known today as Amarna. Evidence of this appears on three of the boundary stelae used to mark the boundaries of this new capital. At this time, Amenhotep IV officially changed his name to Akhenaten ("Agreeable to Aten") as evidence of his new worship. The date given for the event has been estimated to fall around January 2 of that year. In Year 7 of his reign (1346/1344 BCE) the capital was moved from Thebes to Akhetaten (near modern Amarna), though construction of the city seems to have continued for two more years. In shifting his court from the traditional ceremonial centres Akhenaten was signalling a dramatic transformation in the focus of religious and political power.
The move separated the Pharaoh and his court from the influence of the priesthood and from the traditional centres of worship, but his decree had deeper religious significance too—taken in conjunction with his name change, it is possible that the move to Amarna was also meant as a signal of Akhenaten's symbolic death and rebirth. It may also have coincided with the death of his father and the end of the coregency. In addition to constructing a new capital in honor of Aten, Akhenaten also oversaw the construction of some of the most massive temple complexes in ancient Egypt, including one at Karnak and one at Thebes, close to the old temple of Amun.
In Year 9 (1344/1342 BCE), Akhenaten strengthened the Atenist regime, declaring the Aten to be not merely the supreme god, but the "only" god, a universal deity, and forbidding worship of all others, including the veneration of idols, even privately in people's homes—an arena the Egyptian state had previously not touched in religious terms. Aten was addressed by Akhenaten in prayers, such as the "Great Hymn to the Aten": "O Sole God beside whom there is none". The Egyptian people were to worship Akhenaten; only Akhenaten and Nefertiti could worship Aten.
Chinese view.
The orthodox faith system held by most dynasties of China since at least the Shang Dynasty (1766 BCE) until the modern period centered on the worship of "Shangdi" (literally "Above Sovereign", generally translated as "God") or Heaven as an omnipotent force. This faith system pre-dated the development of Confucianism and Taoism and the introduction of Buddhism and Christianity. It has features of monotheism in that Heaven is seen as an omnipotent entity, endowed with personality but no corporeal form. From the writings of Confucius in the "Analects", we find that Confucius himself believed that Heaven cannot be deceived, Heaven guides people's lives and maintains a personal relationship with them, and that Heaven gives tasks for people to fulfill in order to teach them of virtues and morality. However, this faith system was not truly monotheistic since other lesser gods and spirits, which varied with locality, were also worshiped along with "Shangdi". Still, variants such as Mohism approached high monotheism, teaching that the function of lesser gods and ancestral spirits is merely to carry out the will of "Shangdi", akin to angels in Western civilization. In Mozi's "Will of Heaven" (天志), he writes:
"I know Heaven loves men dearly not without reason. Heaven ordered the sun, the moon, and the stars to enlighten and guide them. Heaven ordained the four seasons, Spring, Autumn, Winter, and Summer, to regulate them. Heaven sent down snow, frost, rain, and dew to grow the five grains and flax and silk that so the people could use and enjoy them. Heaven established the hills and rivers, ravines and valleys, and arranged many things to minister to man's good or bring him evil. He appointed the dukes and lords to reward the virtuous and punish the wicked, and to gather metal and wood, birds and beasts, and to engage in cultivating the five grains and flax and silk to provide for the people's food and clothing. This has been so from antiquity to the present."
且吾所以知天之愛民之厚者有矣，曰以磨為日月星辰，以昭道之；制為四時春秋冬夏，以紀綱之；雷降雪霜雨露，以長遂五穀麻絲，使民得而財利之；列為山川谿谷，播賦百事，以臨司民之善否；為王公侯伯，使之賞賢而罰暴；賊金木鳥獸，從事乎五穀麻絲，以為民衣食之財。自古及今，未嘗不有此也。
"Will of Heaven", Chapter 27, Paragraph 6, ca. 5th Century BCE
Worship of "Shangdi" and Heaven in ancient China includes the erection of shrines, the last and greatest being the Temple of Heaven in Beijing, and the offering of prayers. The ruler of China in every Chinese dynasty would perform annual sacrificial rituals to "Shangdi", usually by slaughtering a completely healthy bull as sacrifice. Although its popularity gradually diminished after the advent of Taoism and Buddhism, among other religions, its concepts remained in use throughout the pre-modern period and have been incorporated in later religions in China, including terminology used by early Christians in China. Despite the rising of non-theistic and pantheistic spirituality contributed by Taoism and Buddhism, Shangdi was still praised up until the end of the Qing Dynasty as the last ruler of Qing declared himself son of heaven.
Islam and Christianity became the forerunners of Monotheism in China there on.
The 100-word eulogy written by the founder of the Ming dynasty states his comment on Islam.
Indigenous African religion.
The Himba people of Namibia are monotheistic and worship the god Mukuru.
The Igbo people are monotheistic and worship the god Chukwu.
The Oromo people follow a monotheistic religion called Waaqeffannaa and God called Waaq.
Indo-European religions.
Proto-Indo-European religion.
In the Proto-Indo-European religion, the supreme god is Dyeus, as the word "Dyeus" is literally used in many Indo-European language cognates to denote a supreme god.
In western Eurasia, the ancient traditions of the Slavic religion had elements of monotheism, of a supreme deity known by many names worshiped by some tribes. The most common name of the supreme deity is Perun and was identified with the Christian God after Christianization.
In speaking of Henotheism, Indo-European religions have had shifting tendencies regarding their supreme god. Consider the ruler of lightning: the supreme god Zeus, Perun, Jupiter controlled lightning himself; while in Norse mythology Odin delegated the power of lightning to his son Thor. In this vein, phenomena controlled by any single henotheistic god differ widely among various Indo-European religions.
Indo-Iranian religions.
Hinduism.
As an old religion, Hinduism inherits religious concepts spanning monotheism, polytheism, panentheism, pantheism, monism, and atheism among others; and its concept of God is complex and depends upon each individual and the tradition and philosophy followed.
Hindu views are broad and range from monism, through pantheism and panentheism (alternatively called monistic theism by some scholars) to monotheism and even atheism. Hinduism cannot be said to be purely polytheistic. Hindu religious leaders have repeatedly stressed that while God's forms are many and the ways to communicate with him are many, God is one. The "puja" of the "murti" is a way to communicate with the abstract one god ("Brahman") which creates, sustains and dissolves creation.
Rig Veda 1.164.46,
Traditions of Gaudiya Vaishnavas, the Nimbarka Sampradaya and followers of Swaminarayan and Vallabha consider Krishna to be the source of all avatars, and the source of Vishnu himself, or to be the same as Narayana. As such, he is therefore regarded as "Svayam Bhagavan".
When Krishna is recognized to be "Svayam Bhagavan", it can be understood that this is the belief of Gaudiya Vaishnavism, the Vallabha Sampradaya, and the Nimbarka Sampradaya, where Krishna is accepted to be the source of all other avatars, and the source of Vishnu himself. This belief is drawn primarily "from the famous statement of the Bhagavatam" (1.3.28). A viewpoint differing from this theological concept is the concept of Krishna as an "avatar" of Narayana or Vishnu. It should be however noted that although it is usual to speak of Vishnu as the source of the avataras, this is only one of the names of the God of Vaishnavism, who is also known as Narayana, Vasudeva and Krishna and behind each of those names there is a divine figure with attributed supremacy in Vaishnavism.
The Rig Veda discusses monotheistic thought, as do the Atharva Veda and Yajur Veda:
"Devas are always looking to the supreme abode of Vishnu" ("tad viṣṇoḥ paramaṁ padaṁ sadā paśyanti sṻrayaḥ" Rig Veda 1.22.20)
"The One Truth, sages know by many names" (Rig Veda 1.164.46)
"When at first the unborn sprung into being, He won His own dominion beyond which nothing higher has been in existence" (Atharva Veda 10.7.31)
"There is none to compare with Him. There is no parallel to Him, whose glory, verily, is great." (Yajur Veda 32.3)
The number of auspicious qualities of God are countless, with the following six qualities ("bhaga") being the most important:
In the Shaivite tradition, the "Shri Rudram" (Sanskrit श्रि रुद्रम्), to which the Chamakam (चमकम्) is added by scriptural tradition, is a Hindu "stotra" dedicated to Rudra (an epithet of Shiva), taken from the Yajurveda (TS 4.5, 4.7). Shri Rudram is also known as "Sri Rudraprasna", "Śatarudrīya", and "Rudradhyaya". The text is important in Vedanta where Shiva is equated to the Universal supreme God. The hymn is an early example of enumerating the names of a deity, a tradition developed extensively in the sahasranama literature of Hinduism.
The Nyaya school of Hinduism has made several arguments regarding a monotheistic view. The Naiyanikas have given an argument that such a god can only be one. In the "Nyaya Kusumanjali", this is discussed against the proposition of the "Mimamsa" school that let us assume there were many demigods ("devas") and sages ("rishis") in the beginning, who wrote the Vedas and created the world. Nyaya says that:
[If they assume such] omniscient beings, those endowed with the various superhuman faculties of assuming infinitesimal size, and so on, and capable of creating everything, then we reply that the "law of parsimony" bids us assume only one such, namely Him, the adorable Lord. There can be no confidence in a non-eternal and non-omniscient being, and hence it follows that according to the system which rejects God, the tradition of the Veda is simultaneously overthrown; there is no other way open.
In other words, Nyaya says that the polytheist would have to give elaborate proofs for the existence and origin of his several celestial spirits, none of which would be logical, and that it is more logical to assume one eternal, omniscient god.
Sikhism.
Sikhi is a monotheistic and a revealed religion.
God in Sikhi is called "Vāhigurū", and is shapeless, timeless, and sightless: "niraṅkār", "akaal", and "alakh". God is present ("sarav viāpak") in all of creation. God must be seen from "the inward eye", or the "heart". Sikhi devotees must meditate to progress towards enlightenment, as its rigorous application permits the existence of communication between God and human beings.
Sikhism is a monotheistic faith that arose in northern India during the 16th and 17th centuries. Sikhs believe in one, timeless, omnipresent, supreme creator. The opening verse of the Guru Granth Sahib, known as the Mul Mantra, signifies this:
The word "ੴ" ("Ik ōaṅkār") has two components. The first is ੧, the digit "1" in Gurmukhi signifying the singularity of the creator. Together the word means: "One Universal creator God".
It is often said that the 1430 pages of the Guru Granth Sahib are all expansions on the Mul Mantra. Although the Sikhs have many names for God, some derived from Islam and Hinduism, they all refer to the same Supreme Being.
The Sikh holy scriptures refer to the One God who pervades the whole of space and is the creator of all beings in the universe. The following quotation from the Guru Granth Sahib highlights this point:
"Chant, and meditate on the One God, who permeates and pervades the many beings of the whole Universe. God created it, and God spreads through it everywhere. Everywhere I look, I see God. The Perfect Lord is perfectly pervading and permeating the water, the land and the sky; there is no place without Him."—Guru Granth Sahib, Page 782
However there is a strong case for arguing that the Guru Granth Sahib teaches monism due to its non-dualistic tendencies:
Punjabi: ਸਹਸ ਪਦ ਬਿਮਲ ਨਨ ਏਕ ਪਦ ਗੰਧ ਬਿਨੁ ਸਹਸ ਤਵ ਗੰਧ ਇਵ ਚਲਤ ਮੋਹੀ ॥੨॥<br>
"You have thousands of Lotus Feet, and yet You do not have even one foot. You have no nose, but you have thousands of noses. This Play of Yours entrances me." —Guru Granth Sahib, Page 13
Sikhs believe that God has been given many names, but they all refer to the One God, VāhiGurū. Sikhs believe that members of other religions such as Islam, Hinduism and Christianity all worship the same God, and the names Allah, Rahim, Karim, Hari, Raam and Paarbrahm are frequently mentioned in the Sikh holy scriptures. Although there is no set reference to God in Sikhism, the most commonly used Sikh reference to God is Akal Purakh (which means "the true immortal") or Waheguru, the Primal Being.
Zoroastrianism.
Zoroastrianism combines cosmogonic dualism and eschatological monotheism which makes it unique among the religions of the world. Zoroastrianism proclaims an evolution through time from dualism to monotheism.
Zoroastrianism is a monotheistic religion, although Zoroastrianism is often regarded as dualistic, duotheistic or bitheistic. It was once one of the largest religions on Earth. Zoroastrianism is generally believed to have been founded during the 1st millennium BCE. By some scholars, the Zoroastrians ("Parsis" or "Zartoshtis") are credited with being some of the first monotheists and having had influence on other world religions. Gathered statistics shows the number of adherents at as many as 3.5 million, with adherents living in many regions, including South Asia.
Hellenistic religion.
"The One" (Τὸ Ἕν) is a concept that arises in Platonism, although the writings of Plato himself are polytheistic. The Euthyphro dilemma, for example, is formulated as "Is the pious loved by the gods because it is pious, or is it pious because it is loved by the gods?"
The development of pure (philosophical) monotheism is a product of the Late Antiquity. During the 2nd to 3rd centuries, early Christianity was just one of several competing religious movements advocating monotheism.
A number of oracles of Apollo from Didyma and Clarus, the so-called "theological oracles", dated to the 2nd and 3rd century CE, proclaim that there is only one highest god, of whom the gods of polytheistic religions are mere manifestations or servants. 4th century CE Cyprus had, besides Christianity, an apparently monotheistic cult of Dionysus.
Aristotle's concept of the "Uncaused Cause"—never incorporated into the polytheistic ancient Greek religion—has been used by many exponents of Abrahamic religions to justify their arguments for the existence of the Judeo-Christian-Islamic God of the Abrahamic religions.
The Hypsistarians were a religious group who believed in a most high god, according to Greek documents. Later revisions of this Hellenic religion were adjusted towards Monotheism as it gained consideration among a wider populace. The worship of Zeus as the head-god signaled a trend in the direction of monotheism, with less honour paid to the fragmented powers of the lesser gods.
New religious movements.
Various New religious movements, such as Cao Đài, Tenrikyo, Seicho no Ie, and Cheondoism, are monotheistic.
Tengriism.
Tengrism (sometimes stylized as Tengriism), occasionally referred to as Tengrianism , is a modern term for a Central Asian religion characterized by features of shamanism, animism, totemism, both polytheism and monotheism, and ancestor worship. Historically, it was the prevailing religion of the Turks, Mongols, and Hungarians, as well as the Xiongnu and the Huns. It was the state religion of the six ancient Turkic states: Göktürks Khaganate, Avar Khaganate, Western Turkic Khaganate, Great Bulgaria, Bulgarian Empire and Eastern Tourkia. In "Irk Bitig", Tengri is mentioned as "Türük Tängrisi" (God of Turks). The term is perceived among Turkic peoples as a "national" religion.
In Sino-Tibetan and Turco-Mongol traditions, the Supreme God is commonly referred to as the ruler of Heaven, or the Sky Lord granted with omnipotent powers, but it has largely diminished in those regions due to ancestor worship, Taoism's pantheistic views and Buddhism's rejection of a creator God, although Mahayana Buddhism does seem to keep a sense of divinity. On some occasions in the mythology, the Sky Lord as identified as a male has been associated to mate with an Earth Mother, while some traditions kept the omnipotence of the Sky Lord unshared.

</doc>
<doc id="19524" url="http://en.wikipedia.org/wiki?curid=19524" title="May 9">
May 9

May 9 is the day of the year in the Gregorian calendar.

</doc>
<doc id="19525" url="http://en.wikipedia.org/wiki?curid=19525" title="Muay Thai">
Muay Thai

Muay Thai (Thai: มวยไทย, rtgs: "Muai Thai",  ]) is a combat sport of Thailand that uses stand-up striking along with various clinching techniques.
This physical and mental discipline which includes combat on shins is known as "the art of eight limbs" because it is characterized by the combined use of fists, elbows, knees, shins, being associated with a good physical preparation that makes a full-contact fighter very efficient.
Muay Thai became widespread internationally in the twentieth century, when practitioners defeated notable practitioners of other martial arts. A professional league is governed by the World Muay Thai Council.
History.
"Muay" (มวย) in Thai meaning "To bind into rounded form". The act of binding a person's hair into rounded form is "Muay Phom"(มวยผม). As Siamese boxers wraped their hands with hump rope and hold their fists into rounded shapes when strikes, Siamese(Thai) called this act as "Toi Muay", "ToiMoi" or "Tee Muay" (ต่อยมวย or ตีมวย) and finally shorten it to just the word "Muay"(มวย)
There's a record In the book "Du Royaume de Siam", by the French envoy who visited Ayuttaya during the 1600s named "Simon De La Loubere" described the Siamese boxing as " boxers whom punched with fists and elbows with their hands wraped with hump rope which never to be seen in other neighboring kingdom."
The history of Muay Thai can also be traced to the middle of the 16th century. During the battles between the Burmese of the Konbaung Dynasty and Siam, the famous fighter, Nai Khanomtom, was captured in the year 1767. The Burmese knew of his expertise in hand-to-hand combat and gave him an opportunity to fight for his freedom. Soon after winning the match, he was freed by his captors and allowed to return to Siam. He was acknowledged as a hero, and his fighting style became known as Siamese-Style boxing, later to be known as Muay Thai. This fighting style was soon to be recognized as a national sport. 
Muay boran, and therefore Muay Thai, was originally called by more generic names such as "Toi muay" or simply "muay". As well as being a practical fighting technique for use in actual warfare, muay became a sport in which the opponents fought in front of spectators who went to watch for entertainment. These muay contests gradually became an integral part of local festivals and celebrations, especially those held at temples. Eventually, the previously bare-fisted fighters started wearing lengths of hemp rope around their hands and forearms. This type of match was called muay khat chueak (มวยคาดเชือก). Kickboxing was also a component of military training and gained prominence during the reign of King Naresuan in 1560 CE.
Muay Thai is referred to as the "Art of Eight Limbs" or the "Science of Eight Limbs", because it makes use of punches, kicks, elbows and knee strikes, thus using eight "points of contact", as opposed to "two points" (fists) in boxing and "four points" (hands and feet) used in other more regulated combat sports, such as kickboxing and savate. A practitioner of muay Thai is known as a "nak muay". Western practitioners are sometimes called "Nak Muay Farang", meaning "foreign boxer."
Muay Thai is also used as a form of close-combat using your entire body as a weapon. For example, The hands become the sword or the dagger; the shins and forearms are trained to be like armor so you can defend yourself against heavy blows and the elbow is related to a heavy mace or hammer; the legs and knees are the axe or a staff. 
19th century.
The ascension of King Chulalongkorn (Rama V) to the throne in 1868 ushered in a golden age not only for muay but for the whole country of Thailand. Muay progressed greatly during the reign of Rama V as a direct result of the king's personal interest in the sport. The country was at peace and muay functioned as a means of physical exercise, self-defense, attacking, recreation, and personal advancement.
Masters of the handcraft started education Muay in instruction bivouacs wherever scholars were presented with nourishment and cover. Trainees ought to be handled like one kin, and it was usual for scholars to take on the camp's designation like their personal last name. Scouts ought to be dispatched by the regal kin to arrange equals amid dissimilar bivouacs. 
Modernization.
1909-1910: King Chulankorn formalizes Muay (Boran) by awarding (in 1910) 3 muen to victors at the funeral fights for his son (in 1909). The region style: Lopburi, Khorat and Chaiya. 
1913: British boxing introduced into the curriculum of the Suan Kulap College. The 1st descriptive use of the term “Muay Thai”
1919: British boxing and Muay taught as one sport in the curriculum of the Suan Kulap College. Judo also offered.
1921: 1st permanent ring in Siam at Suan Kulap College. Used for both Muay and British Boxing.
1923: Suan Sanuk Stadium. First international style 3-rope ring with red and blue padded corners, near Lumpinee Park. Muay and British Boxing. 
King Rama VII (r. 1925–35) pushed for codified rules for muay, and they were put into place. Thailand's first boxing ring was built in 1921 at Suan Kularp. Referees were introduced and rounds were now timed by kick. Fighters at the Lumpinee Kickboxing Stadium began wearing modern gloves, as well as hard groin protectors, during training and in boxing matches against foreigners. Traditional rope-binding (Kaad Chuek) made the hands a hardened, dangerous striking tool. The use of knots in the rope over the knuckles made the strikes more abrasive and damaging for the opponent while protecting the hands of the fighter. This rope-binding was still used in fights between Thais but after the occurrence of a death in the ring, it was decided that fighters should wear gloves and cotton coverlets over the feet and ankles. It was also around this time that the term muay Thai became commonly used while the older form of the style came to be known as muay boran, which is now performed primarily as an exhibition art form.
In 1993, the International Federation of Muaythai Amateur, or IFMA was inaugurated. It became the governing body of amateur Muay Thai consisting of 128 member countries worldwide and is recognized by Olympic Council of Asia.
In 1995, World Muaythai Council, the oldest and largest professional sanctioning organizations of Muay Thai was set up by the Royal Thai Government and sanctioned by the Sports Authority of Thailand.
In 1995, the World Muay Thai Federation was founded via the merger of two existing organizations, and established in Bangkok. as of August 2012, it had over 70 member countries. Its President is elected at the World Muay Thai Congress.
In 2006, Muay Thai was included in SportAccord with IFMA becoming the member federation governing international Muay Thai under the SportAccord umbrella. One of the requirements of SportAccord was that no sport can have a name of a country in its name, as a result, an amendment was made in the IFMA constitution to change the name of the sport from 'Muay Thai’ to ‘Muaythai’ – written in one word in order accordance to Olympic requirements.
In 2014 Muay Thai was included in the International World Games Association (IWGA) and will be represented in the official programme of The World Games 2017 in Wroclaw, Poland.
In January 2015, Muay Thai was granted the Patronage of the International University Sports Federation (FISU) and on March the 16th to the 23rd, 2015 the first University World Muaythai Cup will be held in Bangkok.
Today, there are thousands of gyms spread out across the globe. The clothing which competitors typically wear is bright and flamboyant. Recently such designs have become quite popular globally and companies such as Infightstyle Inc., from Canada, have contributed to the popularization of the style throughout the world. It is expected that this style will become more and more mainstream as a cult style much like surfwear did in the late 90s.
Folklore.
French Brothers.
In 1788, during the reign of Rama I, two brothers from France traveled throughout S.E. Asia to study, wager, and fight against the different styles of combat they would encounter from the foreign tribes and counties, and peoples of the region. The brothers arrived in Thailand and arranged a match for prestige and money with the monarchy of the period. The Frenchmen were loud, and bragging of their victories in many different countries. The Thai King ordered his captain of the palace guard, a well respected Thai fighter, to fight one of the brothers for the honor of his country and sport, and a large sum of money was wagered on the fight.
When the fight began, the Thai danced around the fighting area moving quickly in and out of the reach of the French fighter and kept him at a distance by kicking him in the abdomen and legs. The Frenchman became enraged and angry he could not hit his Thai opponent. The Frenchman was not used to this style that used the entire body as a weapon. The other brother, watching from the side, decided to cheat and help his brother by grabbing the Thai from behind and pushing him within the reach of his brother's attacks. This angered the Thai fighters and audience, and violated the spirit and rules of Muay Thai. The two Frenchman suddenly found themselves in trouble as the Thai fighters grappled and tackled the brothers to the ground until they were so exhausted and in pain that they could not rise. The two French brothers left the next day in defeat and humiliation. The popularity of Muay Thai continued to grow as did the national pride of the Thai people for their martial art.
Nai Khanomtom.
According to Thai folklore at the time of the fall of the ancient Siamese capital of Ayutthaya Kingdom in 1767, the invading Burmese troops rounded up thousands of Siamese and took them to Burma as prisoners. Among them were a large number of kickboxers, who were taken to the city of Ava.
In 1774, in the Burmese city of Rangoon, the Burmese King Hsinbyushin (known in Thai as "King Mangra") decided to organize a seven-day, seven-night religious festival in honor of Buddha's relics. The festivities included many forms of entertainment, such as the costume plays called "likay", comedies and farces, and sword-fighting matches. At one point, King Hsinbyushin wanted to see how Muay Boran would compare to the Burmese Lethwei (Burmese Boxing). "Nai Khanomtom" was selected to fight against the Burmese champion. The boxing ring was set up in front of the throne and Nai Khanomtom did a traditional Wai Kru pre-fight dance, to pay his respects to his teachers and ancestors, as well as the spectators, dancing around his opponent. This amazed and perplexed the Burmese people, who thought it was black magic. When the fight began, Nai Khanomtom charged out, using punches, kicks, elbows, and knees to pummel his opponent until he collapsed.
However the Burmese referee said the Burmese champion was too distracted by the dance, and declared the knockout invalid. The King then asked if Nai Khanomtom would fight nine other Burmese champions to prove himself. He agreed and fought them all, one after the other with no rest periods in between. His last opponent was a great kickboxing teacher from Rakhine. Nai Khanomtom mangled him by his kicks and no one else dared to challenge him.
King Mangra was so impressed that he allegedly remarked, "Every part of the Siamese is blessed with venom. Even with his bare hands, he can fell nine or ten opponents. But his Lord was incompetent and lost the country to the enemy. If he had been any good, there was no way the City of Ayutthaya would ever have fallen." 
King Mangra granted Nai Khanomtom freedom along with either riches or two beautiful Burmese wives. Nai Khanomtom chose the wives as he said that money was easier to find. He then departed with his wives for Siam. Other variations of this story had him also winning the release of his fellow Thai prisoners. His feat is celebrated every March 17 as Boxer's Day or National Muay Boran Day in his honor and that of muay boran's.
Today, some have wrongly attributed the legend of Nai Khanomtom to King Naresuan, who spent his youth as a royal hostage in Burma while Ayutthaya was a Burmese vassal. However, Nai Khanomtom and King Naresuan lived almost two centuries apart.
Technique.
Formal muay Thai techniques are divided into two groups: "mae mai" or major techniques and "luk mai" or minor techniques. Muay Thai is often a fighting art of attrition, where opponents exchange blows with one another. This is certainly the case with traditional stylists in Thailand, but is a less popular form of fighting in the contemporary world fighting circuit where the Thai style of exchanging blow for blow is no longer favorable. Almost all techniques in muay Thai use the entire body movement, rotating the hip with each kick, punch, elbow and block.
Punching ("Chok").
The punch techniques in muay Thai were originally quite limited being crosses and a long (or lazy) circular strike made with a straight (but not locked) arm and landing with the heel of the palm. Cross-fertilization with Western boxing and western martial arts mean the full range of western boxing punches are now used: lead jab, straight/cross, hook, uppercut, shovel and corkscrew punches and overhands as well as hammer fists and back fists.
As a tactic, body punching is used less in muay Thai than most other striking combat sports to avoid exposing the attacker's head to counter strikes from knees or elbows. To utilize the range of targeting points, in keeping with the center line theory, the fighter can use either the Western or Thai stance which allows for either long range or short range attacks to be undertaken effectively without compromising guard.
Elbow ("Sok").
The elbow can be used in several ways as a striking weapon: horizontal, diagonal-upwards, diagonal-downwards, uppercut, downward, backward-spinning and flying. From the side it can be used as either a finishing move or as a way to cut the opponent's eyebrow so that blood might block his vision. The diagonal elbows are faster than the other forms, but are less powerful. The Elbow strike is considered the most dangerous form of attack in the sport.
There is also a distinct difference between a single elbow and a follow-up elbow. The single elbow is an elbow move independent from any other move, whereas a follow-up elbow is the second strike from the same arm, being a hook or straight punch first with an elbow follow-up. Such elbows, and most other elbow strikes, are used when the distance between fighters becomes too small and there is too little space to throw a hook at the opponent's head. Elbows can also be utilized to great effect as blocks or defenses against, for example, spring knees, side body knees, body kicks or punches. When well connected, an elbow strike can cause serious damage to the opponent, including cuts or even a knockout.
Kicking "(Te)".
The two most common kicks in muay Thai are known as the "thip" (literally "foot jab") and the "te chiang" (kicking upwards in the shape of a triangle cutting under the arm and ribs) or roundhouse kick. The Thai roundhouse kick uses a rotational movement of the entire body and has been widely adopted by practitioners of other combat sports. it is done from a circular stance with the back leg just a little ways back (roughly shoulder width apart) in comparison to instinctive upper body fighting (boxing) where the legs must create a wider base. The roundhouse kick draws its power entirely from the rotational movement of the body; the hips. It is thought many fighters use a counter rotation of the arms to intensify the power of this kick, but in actuality the power is from the hips and the arms are put in said position to get them out of the way.
If a roundhouse kick is attempted by the opponent, the Thai boxer will normally check the kick, that is he will block the kick with his own shin. Thai boxers are trained to always connect with the shin. The foot contains many fine bones and is much weaker. A fighter may end up hurting himself if he tries to strike with his foot or instep.
Foot-thrust ("Thip").
The foot-thrust or literally "foot jab" is one of the techniques in muay Thai. It is mainly used as a defensive technique to control distance or block attacks. Foot-thrusts should be thrown quickly but yet with enough force to knock an opponent off balance.
Clinch and neck wrestling ("Chap kho").
In Western boxing the two fighters are separated when they clinch; in muay Thai, however, they are not. It is often in the clinch where knee and elbow techniques are used. To strike and bind the opponent for both offensive and defensive purposes, small amounts of stand-up grappling are used in the clinch. The front clinch should be performed with the palm of one hand on the back of the other. There are three reasons why the fingers must not be intertwined. 1) In the ring fighters are wearing boxing gloves and cannot intertwine their fingers. 2) The Thai front clinch involves pressing the head of the opponent downwards, which is easier if the hands are locked behind the back of the head instead of behind the neck. Furthermore the arms should be putting as much pressure on the neck as possible. 3) A fighter may incur an injury to one or more fingers if they are intertwined, and it becomes more difficult to release the grip in order to quickly elbow the opponent's head.
A correct clinch also involves the fighter's forearms pressing against the opponent's collar bone while the hands are around the opponent's head rather than the opponent's neck. The general way to get out of a clinch is to push the opponent's head backwards or elbow them, as the clinch requires both participants to be very close to one another. Additionally, the non-dominant clincher can try to "swim" their arm underneath and inside the opponent's clinch, establishing the previously non-dominant clincher as the dominant clincher.
Muay Thai has several other variants of the clinch or "chap kho"  ], including:
Defense against attacks.
Defenses in muay Thai are categorized in six groups:
Punches and kicks.
Defensively, the concept of "wall of defense" is used, in which shoulders, arms and legs are used to hinder the attacker from successfully executing techniques. Blocking is a critical element in muay Thai and compounds the level of conditioning a successful practitioner must possess. Low and mid body roundhouse kicks are normally blocked with the upper portion of a raised shin (this block is known as a 'check'). High body strikes are blocked ideally with the forearms and shoulder together, or if enough time is allowed for a parry, the glove (elusively), elbow, or shin will be used. Midsection roundhouse kicks can also be caught/trapped, allowing for a sweep or counter-attack to the remaining leg of the opponent. Punches are blocked with an ordinary boxing guard and techniques similar, if not identical, to basic boxing technique. A common means of blocking a punch is using the hand on the same side as the oncoming punch. For example, if an orthodox fighter throws a jab (being the left hand), the defender will make a slight tap to redirect the punch's angle with the right hand. The deflection is always as small and precise as possible to avoid unnecessary energy expenditure and return the hand to the guard as quickly as possible. Hooks are often blocked with a motion sometimes described as "combing the hair", that is, raising the elbow forward and effectively shielding the head with the forearm, flexed biceps and shoulder. More advanced muay Thai blocks are usually in the form of counter-strikes, using the opponents weight (as they strike) to amplify the damage that the countering opponent can deliver. This requires impeccable timing and thus can generally only be learned by many repetitions.
Conditioning.
Like most competitive full contact fighting sports, muay Thai has a heavy focus on body conditioning. Muay Thai is specifically designed to promote the level of fitness and toughness required for ring competition. Training regimens include many staples of combat sport conditioning such as running, shadowboxing, rope jumping, body weight resistance exercises, medicine ball exercises, abdominal exercises, and in some cases weight training. Thai boxers rely heavily on kicks utilizing the shin bone. As such, practitioners of muay Thai will repeatedly hit a dense heavy bag with their shins, conditioning it, hardening the bone through a process called cortical remodeling. Striking a sand filled bag will also have the same effect.
Training that is specific to a Thai fighter includes training with coaches on Thai Pads, focus mitts, heavy bag, and sparring. The daily training includes many rounds (3–5 minute periods broken up by a short rest, often 1–2 minutes) of these various methods of practice. Thai Pad training is a cornerstone of muay Thai conditioning which involves practicing punches, kicks, knees, and elbow strikes with a trainer wearing thick pads which cover the forearms and hands. These special pads (often referred to as Thai pads) are used to absorb the impact of the fighter’s strikes and allow the fighter to react to the attacks of the pad holder in a live situation. The trainer will often also wear a belly pad around the abdominal area so that the fighter can attack with straight kicks or knees to the body at anytime during the round.
Focus mitts are specific to training a fighter’s hand speed, punch combinations, timing, punching power, defense, and counter-punching and may also be used to practice elbow strikes. Heavy bag training is a conditioning and power exercise that reinforces the techniques practiced on the pads. Sparring is a means to test technique, skills, range, strategy, and timing against a partner. Sparring is often a light to medium contact exercise because competitive fighters on a full schedule are not advised to risk injury by sparring hard. Specific tactics and strategies can be trained with sparring including in close fighting, clinching and kneeing only, cutting off the ring, or using reach and distance to keep an aggressive fighter away.
Due to the rigorous training regimen (some Thai boxers fight almost every other week) professional boxers in Thailand have relatively short careers in the ring. Many retire from competition to begin instructing the next generation of Thai fighters. Most professional Thai boxers come from the lower economic backgrounds, and the fight money (after the other parties get their cut) is sought as means of support for the fighters and their families. Very few higher economic strata Thais join the professional muay Thai ranks; they usually either do not practice the sport or practice it only as amateur muay Thai boxers.
Rules.
After Muay Thai received the Royal Patronage from His Majesty the King of Thailand which was granted to the International Federation of Muaythai Amateur (IFMA) IFMA rules are taken as the universal rules for Muay Thai with its subordinate organizations (Federation of Amateur Muaythai of Asia(FAMA) and other organizations recognized by IFMA (such as Amateur Muaythai Association of Thailand— AMAT or European Muaythai Federation – EMF).
Kids and teenagers.
IFMA Rules for Bouts of Tykes, Kids & Cadets Divisions:
In Thailand, children are also allowed to fight in the ring (only in large fights where the organizers obtained a special permission). If special permission has not been obtained, it remains illegal. Since it is nonetheless allowed for large fights, many children have taken up the Muay Thai sport from a very young age and train and engage in training fights daily. This has resulted in reduced intelligence and dementia due to brain traumas from being hit on the head.
Use in other combat sports.
Mixed martial arts.
Muay Thai, is recognized as a very effective striking base within MMA, and is very widely practiced among mixed martial artists. Fighters (some of whom have won titles) such as Maurício Rua, Wanderlei Silva, Jose Aldo, Renan Barão, Anderson Silva, Thiago Silva, Gina Carano and Cristiane Santos employ a broad range of tactics born of Muay Thai. Countless other mixed martial artists have trained in the art and it is often taught at MMA gyms as is BJJ and Wrestling.
Many techniques associated with muay Thai are often seen in MMA, such as punches, elbows, clinch fighting, high kicks, leg kicks and knees.

</doc>
<doc id="19527" url="http://en.wikipedia.org/wiki?curid=19527" title="Mao Zedong">
Mao Zedong

Mao Zedong (), also transliterated as Mao Tse-tung and commonly referred to as Chairman Mao (December 26, 1893 – September 9, 1976), was a Chinese Communist revolutionary and the founding father of the People's Republic of China, which he governed as Chairman of the Communist Party of China from its establishment in 1949 until his death in 1976. His Marxist-Leninist theories, military strategies and political policies are collectively known as Marxism-Leninism-Maoism or Mao Zedong Thought.
Born the son of a wealthy farmer in Shaoshan, Hunan, Mao adopted a Chinese nationalist and anti-imperialist outlook in early life, particularly influenced by the events of the Xinhai Revolution of 1911 and May Fourth Movement of 1919. Mao converted to Marxism-Leninism while working at Peking University and became a founding member of the Communist Party of China (CPC), leading the Autumn Harvest Uprising in 1927. During the Chinese Civil War between the Kuomintang (KMT) and the CPC, Mao helped to found the Red Army, led the Jiangxi Soviet's radical land policies and ultimately became head of the CPC during the Long March. Although the CPC temporarily allied with the KMT under the United Front during the Second Sino-Japanese War (1937–45), after Japan's defeat China's civil war resumed and in 1949 Mao's forces defeated the Nationalists who withdrew to Taiwan.
On October 1, 1949, Mao proclaimed the foundation of the People's Republic of China (PRC), a single-party state controlled by the CPC. In the following years Mao solidified his control through land reform campaigns against landlords, and perceived enemies of the state he termed as "counter-revolutionaries". In 1957 he launched a campaign known as the Great Leap Forward that aimed to rapidly transform China's economy from an agrarian economy to an industrial one, which led to widespread famine. In 1966, he initiated the Great Proletarian Cultural Revolution, a program to remove "counter-revolutionary" elements of Chinese society that lasted 10 years and which was marked by violent class struggle, widespread destruction of cultural artifacts and unprecedented elevation of Mao's personality cult .
In 1972, Mao welcomed US president Richard Nixon in Beijing, signalling a policy of opening China, which was furthered under Deng Xiaoping's rule in China.
A controversial figure, Mao is regarded as one of the most important individuals in modern world history. Supporters credit him with driving imperialism out of China, modernising China and building it into a world power, promoting the status of women, improving education and health care, and increasing life expectancy as China's population grew from around 550 to over 900 million during the period of his leadership. He is also known as a theorist, military strategist, poet, and visionary. In contrast, critics consider him a dictator who severely damaged traditional Chinese culture, perpetrated systematic human rights abuses, and who is responsible for an estimated 40 to 70 million deaths through starvation, forced labour, and executions, ranking his tenure as the top incidence of democide in human history.
Early life.
Youth and the Xinhai Revolution: 1893–1911.
Mao was born on December 26, 1893 in Shaoshan village, Hunan Province, China. His father, Mao Yichang, was an impoverished peasant who had become one of the wealthiest farmers in Shaoshan. Zedong described his father as a stern disciplinarian, who would beat him and his three siblings, the boys Zemin and Zetan, and an adopted girl, Zejian. Yichang's wife, Wen Qimei, was a devout Buddhist who tried to temper her husband's strict attitude. Zedong too became a Buddhist, but abandoned this faith in his mid-teenage years. Aged 8, Mao was sent to Shaoshan Primary School. Learning the value systems of Confucianism, he later admitted that he didn't enjoy the classical Chinese texts preaching Confucian morals, instead favouring popular novels like "Romance of the Three Kingdoms" and "Water Margin". Aged 13, Mao finished primary education, and his father had him married to the 17-year-old Luo Yigu, uniting their land-owning families. Mao refused to recognise her as his wife, becoming a fierce critic of arranged marriage and temporarily moving away. Luo was locally disgraced and died in 1910.
Working on his father's farm, Mao read voraciously, developing a "political consciousness" from Zheng Guanying's booklet which lamented the deterioration of Chinese power and argued for the adoption of representative democracy. Interested in history, Mao was inspired by the military prowess and nationalistic fervour of George Washington and Napoleon Bonaparte. His political views were shaped by Gelaohui-led protests which erupted following a famine in Hunanese capital Changsha; Mao supported the protesters' demands, but the armed forces suppressed the dissenters and executed their leaders. The famine spread to Shaoshan, where starving peasants seized his father's grain; disapproving of their actions as morally wrong, Mao nevertheless claimed sympathy for their situation. Aged 16, Mao moved to a higher primary school in nearby Dongshan, where he was bullied for his peasant background.
In 1911, Mao began middle school in Changsha. Revolutionary sentiment was strong in the city, with widespread animosity towards Emperor Puyi's absolute monarchy and many advocating republicanism. The republicans' figurehead was Sun Yat-sen, an American-educated Christian who led the Tongmenghui society. In Changsha, Mao was influenced by Sun's newspaper, "The People's Independence" ("Minli bao"), and called for Sun to become president in a school essay. As a symbol of rebellion against the Manchu monarch, Mao and a friend cut off their queue pigtails, a sign of subservience to the emperor.
Inspired by Sun's republicanism, the army rose up across southern China, sparking the Xinhai Revolution. Changsha's governor fled, leaving the city in republican control. Supporting the revolution, Mao joined the rebel army as a private soldier, but was not involved in fighting. The northern provinces remained loyal to the emperor, and hoping to avoid a civil war, Sun—proclaimed "provisional president" by his supporters—compromised with the monarchist general Yuan Shikai. The monarchy would be abolished, creating the Republic of China, but the monarchist Yuan would become president. The revolution over, Mao resigned from the army in 1912, after six months of being a soldier. Around this time, Mao discovered socialism from a newspaper article; proceeding to read pamphlets by Jiang Kanghu, the student founder of the Chinese Socialist Party, Mao remained interested yet unconvinced by the idea.
Fourth Normal School of Changsha: 1912–19.
Mao enrolled and dropped out of a police academy, a soap-production school, a law school, an economics school, and the government-run Changsha Middle School. Studying independently, he spent much time in Changsha's library, reading core works of classical liberalism such as Adam Smith's "The Wealth of Nations" and Montesquieu's "The Spirit of the Laws", as well as the works of western scientists and philosophers such as Darwin, Mill, Rousseau, and Spencer. Viewing himself as an intellectual, years later he admitted that at this time he thought himself better than working people. Inspired by Friedrich Paulsen, the liberal emphasis on individualism led Mao to believe that strong individuals were not bound by moral codes but should strive for the greater good; that the end justifies the means. Seeing no use in his son's intellectual pursuits, Mao's father cut off his allowance, forcing him to move into a hostel for the destitute.
Desiring to become a teacher, Mao enrolled at the Fourth Normal School of Changsha, which soon merged with the First Normal School of Changsha, widely seen as the best school in Hunan. Befriending Mao, professor Yang Changji urged him to read a radical newspaper, "New Youth" ("Xin qingnian"), the creation of his friend Chen Duxiu, a dean at Peking University. Although a Chinese nationalist, Chen argued that China must look to the west to cleanse itself of superstition and autocracy. Mao published his first article in "New Youth" in April 1917, instructing readers to increase their physical strength to serve the revolution. He joined the Society for the Study of Wang Fuzhi ("Chuan-shan Hsüeh-she"), a revolutionary group founded by Changsha literati who wished to emulate the philosopher Wang Fuzhi.
In his first school year, Mao befriended an older student, Xiao Yu; together they went on a walking tour of Hunan, begging and writing literary couplets to obtain food. A popular student, in 1915 Mao was elected secretary of the Students Society. Forging an Association for Student Self-Government, he led protests against school rules. In spring 1917, he was elected to command the students' volunteer army, set up to defend the school from marauding soldiers. Increasingly interested in the techniques of war, he took a keen interest in World War I, and also began to develop a sense of solidarity with workers. Mao undertook feats of physical endurance with Xiao Yu and Cai Hesen, and with other young revolutionaries they formed the Renovation of the People Study Society in April 1918 to debate Chen Duxiu's ideas. Desiring personal and societal transformation, the Society gained 70–80 members, many of whom would later join the Communist Party. Mao graduated in June 1919, being ranked third in the year.
Early Revolutionary Activity.
Beijing, Anarchism, and Marxism: 1917–19.
Mao moved to Beijing, where his mentor Yang Changji had taken a job at Peking University. Yang thought Mao exceptionally "intelligent and handsome", securing him a job as assistant to the university librarian Li Dazhao, an early Chinese Communist. Li authored a series of "New Youth" articles on the October Revolution in Russia, during which the Communist Bolshevik Party under the leadership of Vladimir Lenin had seized power. Lenin was an advocate of the socio-political theory of Marxism, first developed by the German sociologists Karl Marx and Friedrich Engels, and Li's articles brought an understanding of Marxism to the Chinese revolutionary movement. Becoming "more and more radical", Mao was influenced by Peter Kropotkin's anarchism but joined Li's Study Group and "developed rapidly toward Marxism" during the winter of 1919.
Paid a low wage, Mao lived in a cramped room with seven other Hunanese students, but believed that Beijing's beauty offered "vivid and living compensation". At the university, Mao was widely snubbed due to his rural accent and lowly position. By joining the university's Philosophy and Journalism Societies, he attended lectures and seminars by the likes of Chen Duxiu, Hu Shi, and Qian Xuantong. Mao's time in Beijing ended in the spring of 1919, when he travelled to Shanghai with friends departing for France, before returning to Shaoshan, where his mother was terminally ill; she died in October 1919, with her husband dying in January 1920.
New Culture and political protests, 1919–20.
On May 4, 1919, students in Beijing gathered at the Gate of Heavenly Peace to protest the Chinese government's weak resistance to Japanese expansion in China. Patriots had been outraged at the influence given to Japan in the Twenty-One Demands in 1915, the complicity of Duan Qirui’s Beiyang Government, and the betrayal of China at the Treaty of Versailles by allowing Japan to receive territories in Shandong which had been surrendered by Germany. These demonstrations ignited the nation-wide May Fourth Movement and fueled the New Culture Movement which blamed China’s diplomatic defeats on social and cultural backwardness.
In Changsha, Mao had begun teaching history at the Xiuye Primary School and organizing protests against the pro-Duan Governor of Hunan Province, Zhang Jingyao, popularly known as "Zhang the Venomous" due to his corrupt and violent rule. In late May, Mao co-founded the Hunanese Student Association with He Shuheng and Deng Zhongxia, organizing a student strike for June and in July 1919 began production of a weekly radical magazine, "Xiang River Review" ("Xiangjiang pinglun"). Using vernacular language that would be understandable to the majority of China's populace, he advocated the need for a "Great Union of the Popular Masses", strengthened trade unions able to wage non-violent revolution; his ideas were not Marxist, but heavily influenced by Kropotkin's concept of .
Zhang banned the Student Association, but Mao continued publishing after assuming editorship of liberal magazine "New Hunan" ("Xin Hunan") and offering articles in popular local newspaper "Justice" ("Ta Kung Po"). Several of these articles advocated feminist views, calling for the liberation of women in Chinese society; Mao was influenced by his forced arranged-marriage. In December 1919, Mao helped organise a general strike in Hunan, securing some concessions, but Mao and other student leaders felt threatened by Zhang, and Mao returned to Beijing, visiting the terminally ill Yang Changji. Mao found that his articles had achieved a level of fame among the revolutionary movement, and set about soliciting support in overthrowing Zhang. Coming across newly translated Marxist literature by Thomas Kirkup, Karl Kautsky, and Marx and Engels—notably "The Communist Manifesto"—he came under their increasing influence, but was still eclectic in his views.
Mao visited Tianjin, Jinan, and Qufu, before moving to Shanghai, where he worked as a laundryman and met Chen Duxiu, noting that Chen's adoption of Marxism "deeply impressed me at what was probably a critical period in my life". In Shanghai, Mao met an old teacher of his, Yi Peiji, a revolutionary and member of the Kuomintang (KMT), or Chinese Nationalist Party, which was gaining increasing support and influence. Yi introduced Mao to General Tan Yankai, a senior KMT member who held the loyalty of troops stationed along the Hunanese border with Guangdong. Tan was plotting to overthrow Zhang, and Mao aided him by organizing the Changsha students. In June 1920, Tan led his troops into Changsha, while Zhang fled. In the subsequent reorganization of the provincial administration, Mao was appointed headmaster of the junior section of the First Normal School. Now receiving a large income, he married Yang Kaihui in the winter of 1920.
Founding the Communist Party of China: 1921–22.
The Communist Party of China was founded by Chen Duxiu and Li Dazhao in the French concession of Shanghai in 1921 as a study society and informal network. Mao set up a Changsha branch, also establishing a branch of the Socialist Youth Corps. Opening a bookstore under the control of his new Cultural Book Society, its purpose was to propagate revolutionary literature throughout Hunan. Helping to organise workers' strikes in the winter of 1920–21, he was involved in the movement for Hunan autonomy, hoping that a Hunanese constitution would increase civil liberties in the province, making his revolutionary activity easier; although the movement was successful, in later life, he denied any involvement. By 1921, small Marxist groups existed in Shanghai, Beijing, Changsha, Wuhan, Canton and Jinan, and it was decided to hold a central meeting, which began in Shanghai on July 23, 1921. The first session of the National Congress of the Communist Party of China was attended by 13 delegates, Mao included, and met in a girls' school that was closed for the summer. After the authorities sent a police spy to the congress, the delegates moved to a boat on South Lake near Chiahsing to escape detection. Although Soviet and Comintern delegates attended, the first congress ignored Lenin's advice to accept a temporary alliance between the Communists and the "bourgeois democrats" who also advocated national revolution; instead they stuck to the orthodox Marxist belief that only the urban proletariat could lead a socialist revolution.
Now party secretary for Hunan, Mao was stationed in Changsha, from which he went on a Communist recruitment drive. In August 1921, he founded the Self-Study University, through which readers could gain access to revolutionary literature, housed in the premises of the Society for the Study of Wang Fuzhi. Taking part in the YMCA mass education movement to fight illiteracy, he opened a Changsha branch, though replaced the usual textbooks with revolutionary tracts in order to spread Marxism among the students. He continued organizing the labour movement to strike against the administration of Hunan Governor Zhao Hengti, particularly following the execution of two anarchists. In July 1922, the Second Congress of the Communist Party took place in Shanghai, though Mao lost the address and couldn't attend. Adopting Lenin's advice, the delegates agreed to an alliance with the "bourgeois democrats" of the KMT for the good of the "national revolution". Communist Party members joined the KMT, hoping to push its politics leftward.
Mao enthusiastically agreed with this decision, arguing for an alliance across China's socio-economic classes; a vocal anti-imperialist, in his writings he lambasted the governments of Japan, UK and US, describing the latter as "the most murderous of hangmen". Mao's strategy for the successful and famous Anyuan coal mines strikes (contrary to later Party historians) depended on both "proletarian" and "bourgeois" strategies. The success depended on innovative organizing by Liu Shaoqi and Li Lisan who not only mobilised the miners, but formed schools and cooperatives. They also engaged local intellectuals, gentry, military officers, merchants, Red Gang dragon heads and church clergy in support.
Collaboration with the Kuomintang: 1922–27.
At the Third Congress of the Communist Party in Shanghai in June 1923, the delegates reaffirmed their commitment to working with the KMT against the Beiyang government and imperialists. Supporting this position, Mao was elected to the Party Committee, taking up residence in Shanghai.
 Attending the First KMT Congress, held in Guangzhou in early 1924, Mao was elected an alternate member of the KMT Central Executive Committee, and put forward four resolutions to decentralise power to urban and rural bureaus. His enthusiastic support for the KMT earned him the suspicion of some Communists. In late 1924, Mao returned to Shaoshan to recuperate from an illness. Discovering that the peasantry were increasingly restless due to the upheaval of the past decade, some had seized land from wealthy landowners to found communes; this convinced him of the revolutionary potential of the peasantry, an idea advocated by the KMT but not the Communists. As a result, he was appointed to run the KMT's Peasant Movement Training Institute, also becoming Director of its Propaganda Department and editing its "Political Weekly" ("Zhengzhi zhoubao") newsletter.
Through the Peasant Movement Training Institute, Mao took an active role in organizing the revolutionary Hunanese peasants and preparing them for militant activity, taking them through military training exercises and getting them to study various left-wing texts. In the winter of 1925, Mao fled to Canton after his revolutionary activities attracted the attention of Zhao's regional authorities.
The Communists controlled the left wing of the KMT, struggling for power with the party's right wing. When party leader Sun Yat-sen died in May 1925, he was succeeded by a rightist, Chiang Kai-shek, who initiated moves to marginalise the position of the Communists. Mao nevertheless supported Chiang's decision to overthrow the Beiyang government and their foreign imperialist allies using the National Revolutionary Army, who embarked on the Northern Expedition in 1926. In the wake of this expedition, peasants rose up, appropriating the land of the wealthy landowners, whom were in many cases killed. Such uprisings angered senior KMT figures, who were themselves landowners, emphasizing the growing class and ideological divide within the revolutionary movement.
"Revolution is not a dinner party, nor an essay, nor a painting, nor a piece of embroidery; it cannot be so refined, so leisurely and gentle, so temperate, kind, courteous, restrained and magnanimous. A revolution is an insurrection, an act of violence by which one class overthrows another."
— Mao, February 1927.
In March 1927, Mao appeared at the Third Plenum of the KMT Central Executive Committee in Wuhan, which sought to strip General Chiang of his power by appointing Wang Jingwei leader. There, Mao played an active role in the discussions regarding the peasant issue, defending a set of "Regulations for the Repression of Local Bullies and Bad Gentry", which advocated the death penalty or life imprisonment for anyone found guilty of counter-revolutionary activity, arguing that in a revolutionary situation, "peaceful methods cannot suffice". In April 1927, Mao was appointed to the KMT's five-member Central Land Committee, urging peasants to refuse to pay rent. Mao led another group to put together a "Draft Resolution on the Land Question", which called for the confiscation of land belonging to "local bullies and bad gentry, corrupt officials, militarists and all counter-revolutionary elements in the villages". Proceeding to carry out a "Land Survey", he stated that anyone owning over 30 "mou" (four and a half acres), constituting 13% of the population, were uniformly counter-revolutionary. He accepted that there was great variation in revolutionary enthusiasm across the country, and that a flexible policy of land redistribution was necessary. Presenting his conclusions at the Enlarged Land Committee meeting, many expressed reservations, some believing that it went too far, and others not far enough. Ultimately, his suggestions were only partially implemented.
Civil War.
The Nanchang and Autumn Harvest Uprisings: 1927.
Fresh from the success of the Northern Expedition to overthrow the warlords, Chiang turned on the Communists, who by now numbered in the tens of thousands across China. Ignoring the orders of the Wuhan-based KMT government, he marched on Shanghai, a city controlled by Communist militias. Although the Communists welcomed Chiang's arrival, he turned on them, massacring 5000 with the aid of the Green Gang. Chiang's army then marched on Wuhan, but was prevented from taking the city by Communist General Ye Ting and his troops. Chiang's allies also attacked Communists; in Beijing, 19 leading Communists were killed by Zhang Zuolin, while in Changsha, He Jian's forces machine gunned hundreds of peasant militiamen. That May, tens of thousands of Communists and their sympathisers were killed by nationalists, with the CPC losing approximately of its members.
"'Eagles cleave the air,<br>Fish glide in the limpid deep;<br>Under freezing skies a million<br>creatures contend in freedom.<br>Brooding over this immensity,<br>I ask, on this boundless land<br>Who rules over man's destiny?"
— Excerpt from Mao's<br> poem "Changsha", September 1927.
The CPC continued supporting the Wuhan KMT government, a position Mao initially supported, but he had changed his mind by the time of the CPC's Fifth Congress, deciding to stake all hope on the peasant militia. The question was rendered moot when the Wuhan government expelled all Communists from the KMT on July 15. The CPC founded the Workers' and Peasants' Red Army of China, better known as the "Red Army", to battle Chiang. A battalion led by General Zhu De was ordered to take the city of Nanchang on August 1, 1927 in what became known as the Nanchang Uprising; initially successful, they were forced into retreat after five days, marching south to Shantou, and from there being driven into the wilderness of Fujian. Appointed commander-in-chief of the Red Army, Mao led four regiments against Changsha in the Autumn Harvest Uprising, hoping to spark peasant uprisings across Hunan. On the eve of the attack, Mao composed a poem—the earliest of his to survive—titled "Changsha". His plan was to attack the KMT-held city from three directions on September 9, but the Fourth Regiment deserted to the KMT cause, attacking the Third Regiment. Mao's army made it to Changsha, but could not take it; by September 15, he accepted defeat, with 1000 survivors marching east to the Jinggang Mountains of Jiangxi.
In their biography of Mao, "", Jung Chang and Jon Halliday dispute this version of events. Chang and Halliday claim that the uprising was in fact sabotaged by Mao to allow him to snare a force of Nationalist mutineers from Nanchang who were crossing over to the CPC, prevent them from defecting to any other CPC leader, and enhance his own personal power within the CPC. They claim that Mao's three-day delay in seeing the other leaders of the Hunan uprising, scheduled for August 15 but delayed by Mao until August 18, was to allow Mao to check that the mutineers would still be passing close by and that if Mao had not had the opportunity of adding this force to his own forces within the CPC he would not have gone to south Hunan.
Chang and Halliday also claim that Mao lobbied to narrow down the uprising and talked the other leaders (including Russian diplomats at the Soviet consulate in Changsha who, Chang and Halliday claim, had been controlling much of the CPC activity) into striking only at Changsha. This, they say, was in order to allow Mao to also gain control of a force of 1,700 peasant rebels and defectors from the Nationalist army who were near Changsha. Chang and Halliday point out that once Mao had gained control of these men, he then moved to a position 100 km east of Changsha at Wenjiashi and was there on September 11, the uprising's launch date, far from his troops, and that on September 14, before the troops had reached Changsha or met heavy resistance, Mao ordered them to abandon the assault on Changsha and converge on his position. Chang and Halliday report a view sent to Moscow by the secretary of the Soviet Consulate in Changsha that the retreat was "the most despicable treachery and cowardice."
Chang and Halliday allege that Mao later fabricated the version of events in order to hide the fact that far from leading a peasant uprising, he hijacked it for his own personal ends, sabotaged the organisation, and departed with the new troops before the attack on Changsha had begun.
Base in Jinggangshan: 1927–1928.
Hiding in Shanghai, the CPC Central Committee expelled Mao from their ranks and from the Hunan Provincial Committee, punishment for his "military opportunism", for his focus on rural activity, and for being too lenient with "bad gentry". They nevertheless adopted three policies he had long championed: the immediate formation of Workers' councils, the confiscation of all land without exemption, and the rejection of the KMT. Mao's response was to ignore them. Setting up base in Jinggangshan City, an area of the Jinggang Mountains, Mao united five villages as a self-governing state, supporting the confiscation of land from rich landlords, who were "re-educated" and sometimes executed. He ensured that no massacres took place in the region, pursuing a more lenient approach than that advocated by the Central Committee. Proclaiming that "Even the lame, the deaf and the blind could all come in useful for the revolutionary struggle", he boosted the army's numbers, incorporating two groups of bandits into his army, building a force of around troops. He laid down rules for his soldiers: prompt obedience to orders, all confiscations were to be turned over to the government, and nothing was to be confiscated from poorer peasants. In doing so, he molded his men into a disciplined, efficient fighting force.
"When the enemy advances, we retreat.<br>When the enemy rests, we harass him.<br>When the enemy avoids a battle, we attack.<br>When the enemy retreats, we advance."
Mao's advice in combating the Kuomintang, 1928.
In spring 1928, the Central Committee ordered Mao's troops to southern Hunan, hoping to spark peasant uprisings. Mao was skeptical, but complied. Reaching Hunan, they were attacked by the KMT and fled after heavy losses. Meanwhile, KMT troops had invaded Jinggangshan, leaving them without a base. Wandering the countryside, Mao's forces came across a CPC regiment led by General Zhu De and Lin Biao; they united, attempting to retake Jinggangshan. Initially successful, the KMT counter-attacked, pushing the CPC back; over the next few weeks, they fought an entrenched guerrilla war in the mountains. Central Committee again ordered Mao to march to south Hunan, but he refused, remaining at his base. Contrastingly, Zhu complied, leading his armies away; the KMT attacked Mao's base, and although his troops fended them off for 25 days, Mao left the camp at night to find reinforcements. Reuniting with the decimated Zhu's army, they returned to Jinggangshan and retook the base. Joined by a defecting KMT regiment and Peng Dehuai's Fifth Red Army, the mountainous area was unable to grow enough crops to feed everyone, leading to food shortages throughout the winter.
Jiangxi Soviet Republic of China: 1929–1934.
In January 1929, Mao and Zhu evacuated the base and took their armies south, to the area around Tonggu and Xinfeng in Jiangxi, which they consolidated as a new base. Together having 2000 men, with a further 800 provided by Peng, the evacuation led to a drop in morale, and many troops became disobedient and began thieving; this worried Li Lisan and the Central Committee, who saw Mao's army as "lumpenproletariat", unable to share in proletariat class consciousness. In keeping with orthodox Marxist thought, Li believed that only the urban proletariat could lead a successful revolution, and saw little need for Mao's peasant guerrillas; he ordered Mao to disband his army into units to be sent out to spread the revolutionary message. Mao replied that while concurring with Li's theoretical position, he would not disband his army or abandon his base. Both Li and Mao saw the Chinese revolution as the key to world revolution, believing that a CPC victory would spark the overthrow of global imperialism and capitalism. In this, they disagreed with the official line of the Soviet government and Comintern. Officials in Moscow desired greater control over the CPC, removing Li from power by calling him to Russia for an inquest into his errors. They replaced him with Soviet-educated Chinese Communists, known as the "28 Bolsheviks", two of whom, Bo Gu and Zhang Wentian, took control of the Central Committee. Mao disagreed with the new leadership, believing they grasped little of the Chinese situation, and soon emerged as their key rival.
In February 1930, Mao created the Southwest Jiangxi Provincial Soviet Government in the region under his control, in November suffering emotional trauma after his wife and sister were captured and beheaded by KMT general He Jian. He then married He Zizhen, an 18-year-old revolutionary who bore him five children over the following nine years. Facing internal problems, members of the Jiangxi Soviet accused him of being too moderate, and hence anti-revolutionary. In December, they tried to overthrow Mao, resulting in the Futian incident; putting down the rebels, Mao's loyalists tortured many and executed between 2000 and 3000 dissenters. Seeing it as a secure area, the CPC Central Committee moved to Jiangxi, which in November was proclaimed to be the Soviet Republic of China, an independent Communist-governed state. Although proclaimed Chairman of the Council of People's Commissars, Mao's power was diminished, with control of the Red Army being allocated to Zhou Enlai; Mao meanwhile recovered from tuberculosis.
Attempting to defeat the Communists, the KMT armies adopted a policy of encirclement and annihilation; outnumbered, Mao responded with guerrilla tactics influenced by the works of ancient military strategists like Sun Tzu, but Zhou and the new leadership replaced this approach with a policy of open confrontation and conventional warfare. In doing so the Red Army successfully defeated the first and second encirclements. Angered at his armies' failure, Chiang Kai-shek personally arrived to lead the operation; also facing setbacks, he retreated to deal with the further Japanese incursions into China. As a result of the KMT's change of focus to the defence of China against Japanese expansionism, the Red Army expanded its area of control, eventually encompassing a population of 3 million. Mao proceeded with his land reform program, in November 1931 announcing the start of a "land verification project" which was expanded in June 1933, also orchestrating education programs and implementing measures to increase female political participation. Viewing the Communists as a greater threat than the Japanese, Chiang returned to Jiangxi, initiating the fifth encirclement campaign, involving the construction of a concrete and barbed wire "wall of fire" around the state, accompanied by aerial bombardment, to which Zhou's tactics proved ineffective. Trapped inside, morale among the Red Army dropped as food and medicine became scarce, and the leadership decided to evacuate.
The Long March: 1934–1935.
On October 14, 1934, the Red Army broke through the KMT line on the Jiangxi Soviet's south-west corner at Xinfeng with soldiers and party cadres and embarked on the "Long March". In order to make the escape, many of the wounded and the ill, as well as women and children, were left behind, defended by a group of guerrilla fighters whom the KMT massacred. The who escaped headed to southern Hunan, first crossing the Xiang River after heavy fighting, and then the Wu River, in Guizhou where they took Zunyi in January 1935. Temporarily resting in the city, they held a conference; here, Mao was elected to a position of leadership, becoming Chairman of the Politburo, and "de facto" leader of both Party and Red Army, in part because his candidacy was supported by Soviet Premier Joseph Stalin. Insisting that they operate as a guerrilla force, he laid out a destination: the Shenshi Soviet in Shaanxi, Northern China, from where the Communists could focus on fighting the Japanese. Mao believed that in focusing on the anti-imperialist struggle, the Communists would earn the trust of the Chinese people, who in turn would renounce the KMT.
From Zunyi, Mao led his troops to Loushan Pass, where they faced armed opposition but successfully crossed the river. Chiang flew into the area to lead his armies against Mao, but the Communists outmanoeuvred him and crossed the Jinsha River. Faced with the more difficult task of crossing the Tatu River, they managed it by fighting a battle over the Luding Bridge in May, taking Luding. Marching through the mountain ranges around Ma'anshan, in Moukung, Western Szechuan they encountered the -strong CPC Fourth Front Army of Zhang Guotao, together proceeding to Maoerhkai and then Gansu. However, Zhang and Mao disagreed over what to do; the latter wished to proceed to Shaanxi, while Zhang wanted to flee east to Tibet or Sikkim, far from the KMT threat. It was agreed that they would go their separate ways, with Zhu De joining Zhang. Mao's forces proceeded north, through hundreds of miles of Grasslands, an area of quagmire where they were attacked by Manchu tribesman and where many soldiers succumbed to famine and disease. Finally reaching Shaanxi, they fought off both the KMT and an Islamic cavalry militia before crossing over the Min Mountains and Mount Liupan and reaching the Shenshi Soviet; only 7-8000 had survived. The Long March cemented Mao's status as the dominant figure in the party. In November 1935, he was named chairman of the Military Commission. From this point onward, Mao was the Communist Party's undisputed leader, even though he would not become party chairman until 1943.
Many if not most of the events as later described by Mao and which the CPC claims are true are seen as false by historians such as Jung Chang. During the decade spent researching the book, "Mao: The Unknown Story", for instance, Chang found evidence that there was no battle at Luding and that the CPC crossed the bridge unopposed. Chang interviewed an eye witness to the crossing of the Dadu (Tatu) River at Luding, Mrs Zhu De, then 93 years old, who recalled no deaths, except for two people who fell from the bridge at Luding while repairing it. Chang also points out the contradictions in the version of events as told by the CPC, which said the bridge was taken by a suicide attack by 22 men, but that these men were also present at a ceremony following the crossing of the bridge.
Chang and Halliday also dispute the Communist Party of China's official version by claiming that far from the Long March being a masterful piece of strategy by the CPC, it was in fact devised by Chiang Kai-shek, leader of the KMT. Chiang's aim was to give the CPC an easy route to follow through warlord controlled areas. Hemmed in by Nationalist troops on three sides, the CPC was forced to follow the route dictated by the KMT. The aim of this was to allow KMT forces to follow the reds into warlord controlled areas such as Sichuan and win over warlords scared of the sudden arrival of the Communist force. The only glitch in this plan came when Mao refused to follow the easy route into Sichuan where he was to meet up with a red army much larger than his own and led by a more senior CPC member, Chang Kuo Tao. Mao recognised the threat Chang posed to his rising position in the CPC and doubled back to give himself time to further cement his political power, causing the needless deaths of thousands of his own troops.
Chang and Halliday also claim that Mao and other top CPC leaders did not walk the Long March, but were carried on litters – Mao himself told his staff that being carried on the Long March gave him much time to read – with the litter bearers' knees being worn to the bone when forced to carry Mao up mountains.
Alliance with the Kuomintang: 1935–1940.
Arriving at the Yan'an Soviet during October 1935, Mao's troops settled in Pao An. Remaining there till spring 1936, they developed links with local communities, redistributed and farmed the land, offered medical treatment and began literacy programs. Mao now commanded soldiers, boosted by the arrival of He Long's men from Hunan and the armies of Zhu Den and Zhang Guotao, returning from Tibet. In February 1936 they established the North West Anti-Japanese Red Army University in Yan'an, through which they trained increasing numbers of new recruits. In January 1937 they began the "anti-Japanese expedition", sending groups of guerrilla fighters into Japanese-controlled territory to undertake sporadic attacks, while in May 1937, a Communist Conference was held in Yan'an to discuss the situation. Western reporters also arrived in the "Border Region" (as the Soviet had been renamed); most notable were Edgar Snow, who used his experiences as a basis for "Red Star Over China", and Agnes Smedley, whose accounts brought international attention to Mao's cause.
On the Long March, Mao's wife He Zizen had been injured from a shrapnel wound to the head, and so traveled to Moscow for medical treatment; Mao proceeded to divorce her and marry an actress, Jiang Qing. Mao moved into a cave-house and spent much of his time reading, tending his garden and theorizing. He came to believe that the Red Army alone was unable to defeat the Japanese, and that a Communist-led "government of national defence" should be formed with the KMT and other "bourgeois nationalist" elements to achieve this goal. Although despising Chiang Kai-shek as a "traitor to the nation", on May 5 he telegrammed the Military Council of the Nanking National Government proposing a military alliance, a course of action advocated by Stalin. Although Chiang intended to ignore Mao's message and continue the civil war, he was arrested by one of his own generals, Zhang Xueliang, in Xi'an, leading to the Xi'an Incident; Zhang forced Chiang to discuss the issue with the Communists, resulting in the formation of a United Front with concessions on both sides on December 25, 1937.
The Japanese had taken both Shanghai and Nanking (Nanjing)—resulting in the Nanking Massacre, an atrocity Mao never spoke of all his life—pushing the Kuomintang government inland to Chungking. The Japanese's brutality led increasing numbers of Chinese joining the fight, with the Red Army growing from to . In August 1938, the Red Army formed the New Fourth Army and the Eighth Route Army, which were nominally under the command of Chiang's National Revolutionary Army. In August 1940, the Red Army initiated the Hundred Regiments Campaign, in which troops attacked the Japanese simultaneously in five provinces; a military success, it resulted in the death of Japanese, the disruption of railways and the loss of a coal mine. From his base in Yan'an, Mao authored several texts for his troops, including "Philosophy of Revolution", which offered an introduction to the Marxist theory of knowledge, "Protracted Warfare", which dealt with guerilla and mobile military tactics, and "New Democracy", which laid forward ideas for China's future.
Resuming civil war: 1940–1949.
In 1944, the Americans sent a special diplomatic envoy, called the Dixie Mission, to the Communist Party of China. According to Edwin Moise, in "Modern China: A History 2nd Edition":
"Most of the Americans were favourably impressed. The CPC seemed less corrupt, more unified, and more vigorous in its resistance to Japan than the KMT. United States fliers shot down over North China ... confirmed to their superiors that the CPC was both strong and popular over a broad area. In the end, the contacts with the USA developed with the CPC led to very little."
After the end of World War II, the U.S. continued their military assistance to Chiang Kai-shek and his KMT government forces against the People's Liberation Army (PLA) led by Mao Zedong in the civil war for control of China. Likewise, the Soviet Union gave quasi-covert support to Mao by their occupation of north east China, which allowed the PLA to move in en masse and took large supplies of arms left by the Japanese's Kwantung Army.
Mao, to enhance the Red Army's military operations named his close associate, then General Zhu De to be its Commander-in-Chief under his supervision and control as the Chairman of the Communist Party
of China that has jurisdiction over the said army through the party's Central Military Commission headed by future Premier Zhou En-Lai
In 1948, under direct orders from Mao, the People's Liberation Army starved out the Kuomintang forces occupying the city of Changchun. At least civilians are believed to have perished during the siege, which lasted from June until October. PLA lieutenant colonel Zhang Zhenglu, who documented the siege in his book "White Snow, Red Blood", compared it to Hiroshima: "The casualties were about the same. Hiroshima took nine seconds; Changchun took five months." On January 21, 1949, Kuomintang forces suffered great losses in battles against Mao's forces. In the early morning of December 10, 1949, PLA troops laid siege to Chengdu, the last KMT-held city in mainland China, and Chiang Kai-shek evacuated from the mainland to Taiwan.
Leadership of China.
The People's Republic of China was established on October 1, 1949. It was the culmination of over two decades of civil and international wars. Mao famously announced: "We (the Chinese people) have stood up."
Mao took up residence in Zhongnanhai, a compound next to the Forbidden City in Beijing, and there he ordered the construction of an indoor swimming pool and other buildings. Mao's physician Li Zhisui described him as conducting business either in bed or by the side of the pool, preferring not to wear formal clothes unless absolutely necessary. Li's book, "The Private Life of Chairman Mao", is regarded as controversial, especially by those sympathetic to Mao.
In October 1950, Mao made the decision to send the People's Volunteer Army, a special unit of the People's Liberation Army, China's armed forces into the war in Korea and fight against the United Nations forces and the South Korean armies led by the U.S as well as to reinforce the armed forces of North Korea, the Korean People's Army which had been in full retreat. Historical records showed that Mao directed the PVA campaigns in the Korean War to the minute details as Chairman of the ruling CPC's Central Military Commission that oversees the country's armed forces. Since he was the Chairman of the CPC's CMC, he was also the Supreme Commander in Chief of the PLA aside from being the Chairman of the People's Republic and Chairman of the ruling CPC. The PVA was under the overall command of then newly installed Premier Zhou Enlai and with General Peng Dehuai as field commander and political commissar as well.
Along with land reform, during which significant numbers of landlords and well-to-do peasants were beaten to death at mass meetings organised by the Communist Party as land was taken from them and given to poorer peasants, there was also the Campaign to Suppress Counter-revolutionaries, which involved public executions targeting mainly former Kuomintang officials, businessmen accused of "disturbing" the market, former employees of Western companies and intellectuals whose loyalty was suspect. The U.S. State department in 1976 estimated that there may have been a million killed in the land reform, and killed in the counter-revolutionary campaign.
Mao himself claimed that a total of people were killed in attacks on "counter-revolutionaries" during the years 1950–52. However, because there was a policy to select "at least one landlord, and usually several, in virtually every village for public execution", the number of deaths range between 2 million and 5 million. In addition, at least 1.5 million people, perhaps as many as 4 to 6 million, were sent to "reform through labour" camps where many perished. Mao played a personal role in organizing the mass repressions and established a system of execution quotas, which were often exceeded. He defended these killings as necessary for the securing of power.
Starting in 1951, Mao initiated two successive movements in an effort to rid urban areas of corruption by targeting wealthy capitalists and political opponents, known as the three-anti/five-anti campaigns. While the three-anti campaign was a focused purge of government, industrial and party officials, the five-anti campaign set its sights slightly broader, targeting capitalist elements in general. Workers denounced their bosses, spouses turned on their spouses, and children informed on their parents; the victims were often humiliated at struggle sessions, a method designed to intimidate and terrify people to the maximum. Mao insisted that minor offenders be criticised and reformed or sent to labour camps, "while the worst among them should be shot." These campaigns took several hundred thousand additional lives, the vast majority via suicide.
In Shanghai, suicide by jumping from tall buildings became so commonplace that residents avoided walking on the pavement near skyscrapers for fear that suicides might land on them. Some biographers have pointed out that driving those perceived as enemies to suicide was a common tactic during the Mao-era. For example, in his biography of Mao, Philip Short notes that in the Yan'an Rectification Movement, Mao gave explicit instructions that "no cadre is to be killed," but in practice allowed security chief Kang Sheng to drive opponents to suicide and that "this pattern was repeated throughout his leadership of the People's Republic."
Following the consolidation of power, Mao launched the First Five-Year Plan (1953–58). The plan aimed to end Chinese dependence upon agriculture in order to become a world power. With the Soviet Union's assistance, new industrial plants were built and agricultural production eventually fell to a point where industry was beginning to produce enough capital that China no longer needed the USSR's support. The success of the First-Five Year Plan was to encourage Mao to instigate the Second Five-Year Plan, the Great Leap Forward, in 1958. Mao also launched a phase of rapid collectivization. The CPC introduced price controls as well as a Chinese character simplification aimed at increasing literacy. Large-scale industrialization projects were also undertaken.
Programs pursued during this time include the Hundred Flowers Campaign, in which Mao indicated his supposed willingness to consider different opinions about how China should be governed. Given the freedom to express themselves, liberal and intellectual Chinese began opposing the Communist Party and questioning its leadership. This was initially tolerated and encouraged. After a few months, Mao's government reversed its policy and persecuted those, totalling perhaps , who criticised, as well as those who were merely alleged to have criticised, the party in what is called the Anti-Rightist Movement. Authors such as Jung Chang have alleged that the Hundred Flowers Campaign was merely a ruse to root out "dangerous" thinking.
Li Zhisui, Mao's physician, suggested that Mao had initially seen the policy as a way of weakening those within his party who opposed him and was surprised by the extent of criticism and the fact that it began to be directed at his own leadership. It was only then that he used it as a method of identifying and subsequently persecuting those critical of his government. The Hundred Flowers movement led to the condemnation, silencing, and death of many citizens, also linked to Mao's Anti-Rightist Movement, with death tolls possibly in the millions.
Great Leap Forward.
In January 1958, Mao launched the second Five-Year Plan, known as the Great Leap Forward, a plan intended as an alternative model for economic growth to the Soviet model focusing on heavy industry that was advocated by others in the party. Under this economic program, the relatively small agricultural collectives which had been formed to date were rapidly merged into far larger people's communes, and many of the peasants were ordered to work on massive infrastructure projects and on the production of iron and steel. Some private food production was banned; livestock and farm implements were brought under collective ownership.
Under the Great Leap Forward, Mao and other party leaders ordered the implementation of a variety of unproven and unscientific new agricultural techniques by the new communes. Combined with the diversion of labour to steel production and infrastructure projects, these projects combined with cyclical natural disasters led to an approximately 15% drop in grain production in 1959 followed by a further 10% decline in 1960 and no recovery in 1961.
In an effort to win favour with their superiors and avoid being purged, each layer in the party hierarchy exaggerated the amount of grain produced under them. Based upon the fabricated success, party cadres were ordered to requisition a disproportionately high amount of the true harvest for state use, primarily in the cities and urban areas but also for export. The net result, which was compounded in some areas by drought and in others by floods, left rural peasants with little food for themselves and many millions starved to death in the largest famine known as the Great Chinese Famine. This famine was a direct cause of the death of some 30 million Chinese peasants between 1959 and 1962. Further, many children who became emaciated and malnourished during years of hardship and struggle for survival died shortly after the Great Leap Forward came to an end in 1962.
The extent of Mao's knowledge of the severity of the situation has been disputed. Mao's physician believed that he may have been unaware of the extent of the famine, partly due to a reluctance to criticise his policies and decisions and the willingness of his staff to exaggerate or outright fake reports regarding food production. Upon learning of the extent of the starvation, Mao vowed to stop eating meat, an action followed by his staff.
Hong Kong-based historian Frank Dikötter, challenged the notion that Mao did not know about the famine until it was too late:
The idea that the state mistakenly took too much grain from the countryside because it assumed that the harvest was much larger than it was is largely a myth—at most partially true for the autumn of 1958 only. In most cases the party knew very well that it was starving its own people to death. At a secret meeting in the Jinjiang Hotel in Shanghai dated March 25, 1959, Mao specifically ordered the party to procure up to one third of all the grain, much more than had ever been the case. At the meeting he announced that "To distribute resources evenly will only ruin the Great Leap Forward. When there is not enough to eat, people starve to death. It is better to let half of the people die so that the other half can eat their fill."
Professor Emeritus Thomas P. Bernstein of the Columbia University offered his view on Mao's statement on starvation in the March 25, 1959 meeting:
Some scholars believe that this shows Mao’s readiness to accept mass death on an immense scale. My own view is that this is an instance of Mao’s use of hyperbole, another being his casual acceptance of death of half the population during a nuclear war. In other contexts, Mao did not in fact accept mass death. Zhou’s Chronology shows that in October 1958, Mao expressed real concern that 40,000 people in Yunnan had starved to death (p. 173). Shortly after the March 25 meeting, he worried about 25.2 million people who were at risk of starvation. But from late summer on, Mao essentially forgot about this issue, until, as noted, the "Xinyang Incident" came to light in October 1960.
In the article "Mao Zedong and the Famine of 1959–1960: A Study in Wilfulness", published in 2006 in "The China Quarterly", Professor Thomas P. Bernstein also discussed Mao's change of attitudes during different phases of the Great Leap Forward:
In late autumn 1958, Mao Zedong strongly condemned widespread practices of the Great Leap Forward (GLF) such as subjecting peasants to exhausting labour without adequate food and rest, which had resulted in epidemics, starvation and deaths. At that time Mao explicitly recognized that anti-rightist pressures on officialdom were a major cause of "production at the expense of livelihood." While he was not willing to acknowledge that only abandonment of the GLF could solve these problems, he did strongly demand that they be addressed. After the July 1959 clash at Lushan with Peng Dehuai, Mao revived the GLF in the context of a new, extremely harsh anti-rightist campaign, which he relentlessly promoted into the spring of 1960 together with the radical policies that he previously condemned. Not until spring 1960 did Mao again express concern about abnormal deaths and other abuses, but he failed to apply the pressure needed to stop them. Given what he had already learned about the costs to the peasants of GLF extremism, the Chairman should have known that the revival of GLF radicalism would exact a similar or even bigger price. Instead, he wilfully ignored the lessons of the first radical phase for the sake of achieving extreme ideological and developmental goals.
In "", Jasper Becker notes that Mao was dismissive of reports he received of food shortages in the countryside and refused to change course, believing that peasants were lying and that rightists and kulaks were hoarding grain. He refused to open state granaries, and instead launched a series of "anti-grain concealment" drives that resulted in numerous purges and suicides. Other violent campaigns followed in which party leaders went from village to village in search of hidden food reserves, and not only grain, as Mao issued quotas for pigs, chickens, ducks and eggs. Many peasants accused of hiding food were tortured and beaten to death.
Whatever the case, the Great Leap Forward caused Mao to lose esteem among many of the top party cadres and was eventually forced to abandon the policy in 1962, while losing some political power to moderate leaders, perhaps most notably Liu Shaoqi and Deng Xiaoping in the process. However, Mao, supported by national propaganda, claimed that he was only partly to blame. As a result, he was able to remain Chairman of the Communist Party, with the Presidency transferred to Liu Shaoqi.
The Great Leap Forward was a tragedy for the vast majority of the Chinese. Although the steel quotas were officially reached, almost all of the supposed steel made in the countryside was iron, as it had been made from assorted scrap metal in home-made furnaces with no reliable source of fuel such as coal. This meant that proper smelting conditions could not be achieved. According to Zhang Rongmei, a geometry teacher in rural Shanghai during the Great Leap Forward:
"We took all the furniture, pots, and pans we had in our house, and all our neighbours did likewise. We put everything in a big fire and melted down all the metal."
The worst of the famine was steered towards enemies of the state. As Jasper Becker explains:
"The most vulnerable section of China's population, around five per cent, were those whom Mao called 'enemies of the people'. Anyone who had in previous campaigns of repression been labeled a 'black element' was given the lowest priority in the allocation of food. Landlords, rich peasants, former members of the nationalist regime, religious leaders, rightists, counter-revolutionaries and the families of such individuals died in the greatest numbers.""
At a large Communist Party conference in Beijing in January 1962, called the "Conference of the Seven Thousand," State Chairman Liu Shaoqi denounced the Great Leap Forward as responsible for widespread famine. The overwhelming majority of delegates expressed agreement, but Defense Minister Lin Biao staunchly defended Mao. A brief period of liberalization followed while Mao and Lin plotted a comeback. Liu Shaoqi and Deng Xiaoping rescued the economy by disbanding the people's communes, introducing elements of private control of peasant smallholdings and importing grain from Canada and Australia to mitigate the worst effects of famine.
Consequences.
At the Lushan Conference in July/August 1959, several leaders expressed concern that the Great Leap Forward had not proved as successful as planned. The most direct of these was Minister of Defence and Korean War General Peng Dehuai. Following Peng's criticism of the Great Leap Forward, Mao orchestrated a purge of Peng and his supporters, stifling criticism of the Great Leap policies. Senior officials who reported the truth of the famine to Mao were branded as "right opportunists." A campaign against right opportunism was launched and resulted in party members and ordinary peasants being sent to camps where many would subsequently die in the famine. Years later the CPC would conclude that 6 million people were wrongly punished in the campaign.
The number of deaths by starvation during the Great Leap Forward is deeply controversial. Until the mid-1980s, when official census figures were finally published by the Chinese Government, little was known about the scale of the disaster in the Chinese countryside, as the handful of Western observers allowed access during this time had been restricted to model villages where they were deceived into believing that the Great Leap Forward had been a great success. There was also an assumption that the flow of individual reports of starvation that had been reaching the West, primarily through Hong Kong and Taiwan, must have been localised or exaggerated as China was continuing to claim record harvests and was a net exporter of grain through the period. Because Mao wanted to pay back early to the Soviets debts totalling 1.973 billion yuan from 1960 to 1962, exports increased by 50%, and fellow Communist regimes in North Korea, North Vietnam and Albania were provided grain free of charge.
Censuses were carried out in China in 1953, 1964 and 1982. The first attempt to analyse this data to estimate the number of famine deaths was carried out by American demographer Dr. Judith Banister and published in 1984. Given the lengthy gaps between the censuses and doubts over the reliability of the data, an accurate figure is difficult to ascertain. Nevertheless, Banister concluded that the official data implied that around 15 million excess deaths incurred in China during 1958–61, and that based on her modelling of Chinese demographics during the period and taking account of assumed under-reporting during the famine years, the figure was around 30 million. The official statistic is 20 million deaths, as given by Hu Yaobang. Yang Jisheng, a former Xinhua News Agency reporter who had privileged access and connections available to no other scholars, estimates a death toll of 36 million. Frank Dikötter estimates that there were at least 45 million premature deaths attributable to the Great Leap Forward from 1958 to 1962. Various other sources have put the figure at between 20 and 46 million.
Split from Soviet Union.
On the international front, the period was dominated by the further isolation of China. The Sino-Soviet split resulted in Nikita Khrushchev's withdrawal of all Soviet technical experts and aid from the country. The split concerned the leadership of world Communism. The USSR had a network of Communist parties it supported; China now created its own rival network to battle it out for local control of the left in numerous countries. Lorenz M. Lüthi argues:
The split resulted from Nikita Khrushchev's more moderate Soviet leadership after the death of Stalin in March 1953. Only Albania openly sided with China, thereby forming an alliance between the two countries which would last until after Mao's death in 1976. Warned that the Soviets had nuclear weapons, Mao minimized the threat. Becker says that, "Mao believed that the bomb was a 'paper tiger', declaring to Khrushchev that it would not matter if China lost 300 million people in a nuclear war: the other half of the population would survive to ensure victory."
Stalin had established himself as the successor of "correct" Marxist thought well before Mao controlled the Communist Party of China, and therefore Mao never challenged the suitability of any Stalinist doctrine (at least while Stalin was alive). Upon the death of Stalin, Mao believed (perhaps because of seniority) that the leadership of the "correct" Marxist doctrine would fall to him. The resulting tension between Khrushchev (at the head of a politically and militarily superior government), and Mao (believing he had a superior understanding of Marxist ideology) eroded the previous patron-client relationship between the Communist Party of the Soviet Union and the CPC. In China, the formerly favourable Soviets were now denounced as "revisionists" and listed alongside "American imperialism" as movements to oppose.
Partly surrounded by hostile American military bases (in South Korea, Japan, and Taiwan), China was now confronted with a new Soviet threat from the north and west. Both the internal crisis and the external threat called for extraordinary statesmanship from Mao, but as China entered the new decade the statesmen of the People's Republic were in hostile confrontation with each other.
Great Proletarian Cultural Revolution.
Mao was concerned with the nature of post-1959 China. He saw that the revolution had replaced the old elite with a new one. He was concerned that those in power were becoming estranged from the people they were supposed to serve. Mao believed that a revolution of culture would unseat and unsettle the "ruling class" and keep China in a state of "perpetual revolution" that, theoretically, would serve the interests of the majority, not a tiny elite. Liu Shaoqi and Deng Xiaoping, then the State Chairman and General Secretary, respectively, had favoured the idea that Mao should be removed from actual power but maintain his ceremonial and symbolic role, with the party upholding all of his positive contributions to the revolution. They attempted to marginalise Mao by taking control of economic policy and asserting themselves politically as well. Many claim that Mao responded to Liu and Deng's movements by launching the Great Proletarian Cultural Revolution in 1966. Some scholars, such as Mobo Gao, claim the case for this is perhaps overstated. Others, such as Frank Dikötter, hold that Mao launched the Cultural Revolution to wreak revenge on those who had dared to challenge him over the Great Leap Forward.
Believing that certain liberal bourgeois elements of society continued to threaten the socialist framework, groups of young people known as the Red Guards struggled against authorities at all levels of society and even set up their own tribunals. Chaos reigned in much of the nation, and millions were persecuted, including a famous philosopher, Chen Yuen. During the Cultural Revolution, the schools in China were closed and the young intellectuals living in cities were ordered to the countryside to be "re-educated" by the peasants, where they performed hard manual labour and other work.
The Revolution led to the destruction of much of China's traditional cultural heritage and the imprisonment of a huge number of Chinese citizens, as well as creating general economic and social chaos in the country. Millions of lives were ruined during this period, as the Cultural Revolution pierced into every part of Chinese life, depicted by such Chinese films as "To Live", "The Blue Kite" and "Farewell My Concubine". It is estimated that hundreds of thousands, perhaps millions, perished in the violence of the Cultural Revolution.
When Mao was informed of such losses, particularly that people had been driven to suicide, he is alleged to have commented: "People who try to commit suicide — don't attempt to save them! . . . China is such a populous nation, it is not as if we cannot do without a few people." The authorities allowed the Red Guards to abuse and kill opponents of the regime. Said Xie Fuzhi, national police chief: "Don't say it is wrong of them to beat up bad persons: if in anger they beat someone to death, then so be it." As a result, in August and September 1966, there were 1,772 people murdered in Beijing alone.
It was during this period that Mao chose Lin Biao, who seemed to echo all of Mao's ideas, to become his successor. Lin was later officially named as Mao's successor. By 1971, however, a divide between the two men became apparent. Official history in China states that Lin was planning a military coup or an assassination attempt on Mao. Lin Biao died in a plane crash over the air space of Mongolia, presumably on his way to flee China, probably anticipating his arrest. The CPC declared that Lin was planning to depose Mao, and posthumously expelled Lin from the party. At this time, Mao lost trust in many of the top CPC figures. The highest-ranking Soviet Bloc intelligence defector, Lt. Gen. Ion Mihai Pacepa described his conversation with Nicolae Ceauşescu who told him about a plot to kill Mao Zedong with the help of Lin Biao organised by the KGB.
In 1969, Mao declared the Cultural Revolution to be over, although the official history of the People's Republic of China marks the end of the Cultural Revolution in 1976 with Mao's death. In the last years of his life, Mao was faced with declining health due to either Parkinson's disease or, according to his physician, amyotrophic lateral sclerosis, as well as lung ailments due to smoking and heart trouble. Some also attributed Mao's decline in health to the betrayal of Lin Biao. Mao remained passive as various factions within the Communist Party mobilised for the power struggle anticipated after his death.
This period is often looked at in official circles in China and in the West as a great stagnation or even of reversal for China. While many—an estimated 100 million—did suffer, some scholars, such as Lee Feigon and Mobo Gao, claim there were many great advances, and in some sectors the Chinese economy continued to outperform the west. They hold that the Cultural Revolution period laid the foundation for the spectacular growth that continues in China. During the Cultural Revolution, China exploded its first H-Bomb (1967), launched the Dong Fang Hong satellite (January 30, 1970), commissioned its first nuclear submarines and made various advances in science and technology. Healthcare was free, and living standards in the countryside continued to improve.
State visits.
Mao stepped down as head of state in 1959. Further state visits of the Mao era were therefore undertaken by president Liu Shaoqi rather than Mao personally.
Death and aftermath.
Mao was a heavy smoker and drinker during most of his adult life. He was also overweight and had multiple lung and heart ailments during his later years. There are unconfirmed reports that he possibly had Parkinson's disease in addition to amyotrophic lateral sclerosis, also known as Lou Gehrig's disease.
Mao's last public appearance—and the last known photograph of him alive—was on May 27, 1976, when he met the visiting Pakistani Prime Minister Zulfikar Ali Bhutto during the latter's one-day visit to Beijing. Mao suffered two major heart attacks in 1976, one in March and another in July, before a third struck on September 5, rendering him an invalid. Mao Zedong died nearly four days later just after midnight, at 00:10, on September 9, 1976, at age 82. The Communist Party of China delayed the announcement of his death until 16:00 that day, when a radio message broadcast across the nation announced the news while appealing for party unity.
Mao's embalmed, CPC-flag-draped body lay in state at the Great Hall of the People for one week. During this period, millions of Chinese—the majority crying openly or otherwise displaying some kind of sadness—and many foreign dignitaries (including heads of state such as Albania's Enver Hoxha and North Korea's Kim Il-sung) filed past Mao to pay their final respects. At 15:00 Beijing time on September 18, a somber cacophony of guns, sirens, whistles and horns all across China was spontaneously blown in observance of a three-minute silence. Simultaneously, those who heard the sustained noise ceased all activity. After that, a band in Tiananmen Square, packed with and surrounded by millions of people, played "The Internationale". The final service on that day was concluded by Hua Guofeng's 20-minute-long eulogy atop Tiananmen Gate. Mao's body was later permanently interred in a mausoleum in Beijing.
Legacy.
"Had Mao died in 1956, his achievements would have been immortal. Had he died in 1966, he would still have been a great man but flawed. But he died in 1976. Alas, what can one say?"
—Chen Yun, a leading Communist Party official under Mao and Deng Xiaoping.
Mao remains a controversial figure and there is little agreement over his legacy both in China and abroad. Supporters generally credit him with and praise him for having unified China and for ending the previous decades of civil war. He is also credited for having improved the status of women in China and for improving literacy and education. His policies caused the deaths of tens of millions of people during his 27-year reign, more than any other Twentieth Century leader, however supporters point out that in spite of this, life expectancy improved during his reign. His supporters claim that he rapidly industrialised China; however, others have claimed that his policies such as the "Great Leap Forward" and the "Great Proletarian Cultural Revolution", were impediments to industrialisation and modernisation. His supporters claim that his policies laid the groundwork for China's later rise to become an economic superpower, while others claim that his policies delayed economic development and that China's economy only underwent its rapid growth after Mao's policies had been widely abandoned. Mao's revolutionary tactics continue to be used by insurgents, and his political ideology continues to be embraced by many Communist organizations around the world.
In mainland China, Mao is still revered by many supporters of the Communist Party and respected by the majority of the general population as the "Founding Father of modern China", credited for giving "the Chinese people dignity and self-respect." Mobo Gao in his 2008 book "The Battle for China's Past: Mao and the Cultural Revolution", credits Mao for raising the average life expectancy from 35 in 1949 to 63 by 1975, bringing "unity and stability to a country that had been plagued by civil wars and foreign invasions", and laying the foundation for China to "become the equal of the great global powers". Gao also lauds Mao for carrying out massive land reform, promoting the status of women, improving popular literacy, and positively "transform(ing) Chinese society beyond recognition."
However, Mao has many Chinese critics, both those who live inside and outside China. Opposition to Mao is subject to restriction and censorship in mainland China, but is especially strong elsewhere, where he is often reviled as a brutish ideologue. In the West, his name is generally associated with tyranny and his economic theories are widely discredited—though to some political activists he remains a symbol against capitalism, imperialism and western influence. Even in China, key pillars of his economic theory have been largely dismantled by market reformers like Deng Xiaoping and Zhao Ziyang, who succeeded him as leaders of the Communist Party.
Though the Chinese Communist Party, which Mao led to power, has rejected in practice the economic fundamentals of much of Mao's ideology, it retains for itself many of the powers established under Mao's reign: it controls the Chinese army, police, courts and media and does not permit multi-party elections at the national or local level, except in Hong Kong. Thus it is difficult to gauge the true extent of support for the Chinese Communist Party and Mao's legacy within mainland China. For its part, the Chinese government continues to officially regard Mao as a national hero. In 2008, China opened the Mao Zedong Square to visitors in his home town of central Hunan Province to mark the 115th anniversary of his birth.
There continue to be disagreements on Mao's legacy. Former Party official Su Shachi, has opined that "he was a great historical criminal, but he was also a great force for good." In a similar vein, journalist Liu Binyan has described Mao as "both monster and a genius." Some historians argue that Mao Zedong was "one of the great tyrants of the twentieth century", and a dictator comparable to Adolf Hitler and Joseph Stalin, with a death toll surpassing both. In "The Black Book of Communism", Jean Louis Margolin writes that "Mao Zedong was so powerful that he was often known as the Red Emperor ... the violence he erected into a whole system far exceeds any national tradition of violence that we might find in China." Mao was frequently likened to China's First Emperor Qin Shi Huang, notorious for burying alive hundreds of scholars, and personally enjoyed the comparison. During a speech to party cadre in 1958, Mao said he had far outdone Qin Shi Huang in his policy against intellectuals: "He buried 460 scholars alive; we have buried forty-six thousand scholars alive ... You [intellectuals] revile us for being Qin Shi Huangs. You are wrong. We have surpassed Qin Shi Huang a hundredfold." As a result of such tactics, critics have pointed out that:
The People's Republic of China under Mao exhibited the oppressive tendencies that were discernible in all the major absolutist regimes of the twentieth century. There are obvious parallels between Mao's China, Nazi Germany and Soviet Russia. Each of these regimes witnessed deliberately ordered mass 'cleansing' and extermination.
Others, such as Philip Short, reject such comparisons in "Mao: A Life", arguing that whereas the deaths caused by Nazi Germany and Soviet Russia were largely systematic and deliberate, the overwhelming majority of the deaths under Mao were unintended consequences of famine. Short noted that landlord class were not exterminated as a people due to Mao's belief in redemption through thought reform. He instead compared Mao with 19th-century Chinese reformers who challenged China's traditional beliefs in the era of China's clashes with Western colonial powers. Short argues, "Mao's tragedy and his grandeur were that he remained to the end in thrall to his own revolutionary dreams ... He freed China from the straitjacket of its Confucian past, but the bright Red future he promised turned out to be a sterile purgatory.
Mao's English interpreter Sidney Rittenberg wrote in his memoir "The Man Who Stayed Behind" that whilst Mao "was a great leader in history", he was also "a great criminal because, not that he wanted to, not that he intended to, but in fact, his wild fantasies led to the deaths of tens of millions of people." Li Rui, Mao's personal secretary, goes further and claims he was dismissive of the suffering and death caused by his policies: "Mao's way of thinking and governing was terrifying. He put no value on human life. The deaths of others meant nothing to him."
In their 832-page biography, "", Jung Chang and Jon Halliday take a very critical view of Mao's life and influence. For example, they note that Mao was well aware that his policies would be responsible for the deaths of millions; While discussing labour-intensive projects such as waterworks and making steel, Mao said to his inner circle in November 1958: "Working like this, with all these projects, half of China may well have to die. If not half, one-third, or one-tenth—50 million—die."
Thomas Bernstein of Columbia University argues that this quotation is taken out of context, claiming:
The Chinese original, however, is not quite as shocking. In the speech, Mao talks about massive earthmoving irrigation projects and numerous big industrial ones, all requiring huge numbers of people. If the projects, he said, are all undertaken simultaneously "half of China's population unquestionably will die; and if it's not half, it'll be a third or ten percent, a death toll of 50 million people." Mao then pointed to the example of Guangxi provincial Party secretary, Chén Mànyuǎn (陈漫远) who had been dismissed in 1957 for failing to prevent famine in the previous year, adding: "If with a death toll of 50 million you didn't lose your jobs, I at least should lose mine; whether I should lose my head would also be in question. Anhui wants to do so much, which is quite all right, but make it a principle to have no deaths."
Jasper Becker notes, "archive material gathered by Dikötter ... confirms that far from being ignorant or misled about the famine, the Chinese leadership were kept informed about it all the time. And he exposes the extent of the violence used against the peasants":
<poem>Mass killings are not usually associated with Mao and the Great Leap Forward, and China continues to benefit from a more favourable comparison with Cambodia or the Soviet Union. But as fresh and abundant archival evidence shows, coercion, terror and systematic violence were the foundation of the Great Leap, and between 1958 to 1962, by a rough approximation, some 6 to 8 per cent of those who died were tortured to death or summarily killed—amounting to at least 3 million victims.
Countless others were deliberately deprived of food and consequently starved to death. Many more vanished because they were too old, weak or sick to work—and hence unable to earn their keep. People were killed selectively because they had the wrong class background, because they dragged their feet, because they spoke out or simply because they were not liked, for whatever reason, by the man who wielded the ladle in the canteen.</poem>
Dikötter argues that CPC leaders "glorified violence and were inured to massive loss of life. And all of them shared an ideology in which the end justified the means. In 1962, having lost millions of people in his province, Li Jingquan compared the Great Leap Forward to the Long March in which only one in ten had made it to the end: 'We are not weak, we are stronger, we have kept the backbone.'"
Regarding the large-scale irrigation projects, Dikötter stresses that, in spite of Mao being in a good position to see the human cost, they continued unabated for several years, and ultimately claimed the lives of hundreds of thousands of exhausted villagers. He also notes that "In a chilling precursor of Cambodia under the Khmer Rouge, villagers in Qingshui and Gansu called these projects the 'killing fields'."
The United States placed a trade embargo on the People's Republic as a result of its involvement in the Korean War, lasting until Richard Nixon decided that developing relations with the PRC would be useful in dealing with the Soviet Union.
The television series Biography stated: "[Mao] turned China from a feudal backwater into one of the most powerful countries in the World ... The Chinese system he overthrew was backward and corrupt; few would argue the fact that he dragged China into the 20th century. But at a cost in human lives that is staggering."
In the book "China in the 21st Century: What Everyone Needs to Know" published in 2010, Professor Jeffrey N. Wasserstrom of the University of California, Irvine compares China’s relationship to Mao Zedong to American’s remembrance of Andrew Jackson: both countries regard the leaders in a positive light, despite their respective roles in devastating policies. Jackson forcibly moved Native Americans, resulting in thousands of deaths, while Mao was at the helm during the violent years of the Cultural Revolution and the Great Leap Forward:
Though admittedly far from perfect, the comparison is based on the fact that Jackson is remembered both as someone who played a significant role in the development of a political organization (the Democratic Party) that still has many partisans, and as someone responsible for brutal policies toward Native Americans that are now referred to as genocidal.
Both men are thought of as having done terrible things yet this does not necessarily prevent them from being used as positive symbols. And Jackson still appears on $20 bills, even though Americans tend to view as heinous the institution of slavery (of which he was a passionate defender) and the early 19th-century military campaigns against Native Americans (in which he took part).
At times Jackson, for all his flaws, is invoked as representing an egalitarian strain within the American democratic tradition, a self-made man of the people who rose to power via straight talk and was not allied with moneyed interests. Mao stands for something roughly similar.
Mao's military writings continue to have a large amount of influence both among those who seek to create an insurgency and those who seek to crush one, especially in manners of guerilla warfare, at which Mao is popularly regarded as a genius. As an example, the Communist Party of Nepal (Maoist) followed Mao's examples of guerilla warfare to considerable political and military success even in the 21st century. Mao's major contribution to the military science is his theory of People's War, with not only guerrilla warfare but more importantly, Mobile Warfare methodologies. Mao had successfully applied Mobile Warfare in the Korean War, and was able to encircle, push back and then halt the UN forces in Korea, despite the clear superiority of UN firepower. Mao also gave the impression that he might even welcome a nuclear war.
"Let us imagine how many people would die if war breaks out. There are 2.7 billion people in the world, and a third could be lost. If it is a little higher, it could be half ... I say that if the worst came to the worst and one-half dies, there will still be one-half left, but imperialism would be razed to the ground and the whole world would become socialist. After a few years there would be 2.7 billion people again"
But historians dispute the sincerity of Mao's words. Robert Service says that Mao "was deadly serious," while Frank Dikötter claims that "He was bluffing ... the sabre-rattling was to show that he, not Khrushchev, was the more determined revolutionary."
Mao's poems and writings are frequently cited by both Chinese and non-Chinese. The official Chinese translation of President Barack Obama's inauguration speech used a famous line from one of Mao's poems. Republican senator John McCain misattributed a campaign quote to Mao several times during his 2008 presidential election bid, saying "Remember the words of Chairman Mao: 'It's always darkest before it's totally black.'"
The ideology of Maoism has influenced many Communists, mainly in the Third World, including revolutionary movements such as Cambodia's Khmer Rouge, Peru's Shining Path, and the Nepalese revolutionary movement. Under the influence of Mao's agrarian socialism and Cultural Revolution, Cambodia's Pol Pot conceived of his disastrous Year Zero policies which purged the nation of its teachers, artists and intellectuals and emptied its cities, resulting in the Cambodian Genocide.
The Revolutionary Communist Party, USA also claims Marxism-Leninism-Maoism as its ideology, as do other Communist Parties around the world which are part of the Revolutionary Internationalist Movement. China itself has moved sharply away from Maoism since Mao's death, and most people outside of China who describe themselves as Maoist regard the Deng Xiaoping reforms to be a betrayal of Maoism, in line with Mao's view of "Capitalist roaders" within the Communist Party.
As the Chinese government instituted free market economic reforms starting in the late 1970s and as later Chinese leaders took power, less recognition was given to the status of Mao. This accompanied a decline in state recognition of Mao in later years in contrast to previous years when the state organised numerous events and seminars commemorating Mao's 100th birthday. Nevertheless, the Chinese government has never officially repudiated the tactics of Mao. Deng Xiaoping, who was opposed to the Great Leap Forward and the Cultural Revolution, has to a certain extent rejected Mao's legacy, famously saying that Mao was "70% right and 30% wrong".
In the mid-1990s, Mao Zedong's picture began to appear on all new renminbi (人民幣) currency from the People's Republic of China. This was officially instituted as an anti-counterfeiting measure as Mao's face is widely recognised in contrast to the generic figures that appear in older currency. On March 13, 2006, a story in the "People's Daily" reported that a proposal had been made to print the portraits of Sun Yat-sen and Deng Xiaoping.
In 2006, the government in Shanghai issued a new set of high school history textbooks which omit Mao, with the exception of a single mention in a section on etiquette. Students in Shanghai now only learn about Mao in junior high school.
Public image.
Mao gave contradicting statements on the subject of personality cults. In 1955, as a response to the Khrushchev Report that criticised Joseph Stalin, Mao stated that personality cults are "poisonous ideological survivals of the old society", and reaffirmed China's commitment to collective leadership. But at the 1958 Party congress in Chengdu, Mao expressed support for the personality cults of people whom he labelled as genuinely worthy figures; not those that expressed "blind worship".
In 1962, Mao proposed the Socialist Education Movement (SEM) in an attempt to educate the peasants to resist the "temptations" of feudalism and the sprouts of capitalism that he saw re-emerging in the countryside from Liu's economic reforms. Large quantities of politicised art were produced and circulated — with Mao at the centre. Numerous posters, badges and musical compositions referenced Mao in the phrase "Chairman Mao is the red sun in our hearts" (毛主席是我们心中的红太阳, "Máo Zhǔxí Shì Wǒmen Xīnzhōng De Hóng Tàiyáng") and a "Savior of the people" (人民的大救星, "Rénmín De Dà Jiùxīng").
In October 1966, Mao's "Quotations from Chairman Mao Tse-tung", which was known as the "Little Red Book" was published. Party members were encouraged to carry a copy with them and possession was almost mandatory as a criterion for membership. Over the years, Mao's image became displayed almost everywhere, present in homes, offices and shops. His quotations were typographically emphasised by putting them in boldface or red type in even the most obscure writings. Music from the period emphasised Mao's stature, as did children's rhymes. The phrase "Long Live Chairman Mao for ten thousand years" was commonly heard during the era.
Mao also has a presence in China and around the world in popular culture, where his face adorns everything from T-shirts to coffee cups. Mao's granddaughter, Kong Dongmei, defended the phenomenon, stating that "it shows his influence, that he exists in people's consciousness and has influenced several generations of Chinese people's way of life. Just like Che Guevara's image, his has become a symbol of revolutionary culture." Since 1950, over 40 million people have visited Mao's birthplace in Shaoshan, Hunan.
Genealogy.
Ancestors.
His ancestors were:
Wives.
Mao Zedong had four wives who gave birth to a total of 10 children. These were:
Siblings.
He had several siblings:
Note that the character "zé" (泽) appears in all of the siblings' given names. This is a common Chinese naming convention.
From the next generation, Zemin's son, Mao Yuanxin, was raised by Mao Zedong's family. He became Mao Zedong's liaison with the Politburo in 1975. In Li Zhisui's "The Private Life of Chairman Mao", Mao Yuanxin played a role in the final power-struggles.
Children.
Mao Zedong had a total of ten children, including:
Mao's first and second daughters were left to local villagers because it was too dangerous to raise them while fighting the Kuomintang and later the Japanese. Their youngest daughter (born in early 1938 in Moscow after Mao separated) and one other child (born 1933) died in infancy. Two English researchers who retraced the entire Long March route in 2002–2003 located a woman whom they believe might well be one of the missing children abandoned by Mao to peasants in 1935. Ed Jocelyn and Andrew McEwen hope a member of the Mao family will respond to requests for a DNA test.
Through his ten children, Mao became grandfather to twelve grandchildren, many of whom he never knew. He has many great-grandchildren alive today. One of his granddaughters is business woman Kong Dongmei, one of the richest people in China and mother to three of Mao's great-grandchildren. His grandson Mao Xinyu, father of two, is a general in the Chinese army.
Personal life.
Mao's private life was very secretive at the time of his rule. However, after Mao's death, Li Zhisui, his personal physician, published "The Private Life of Chairman Mao", a memoir which mentions some aspects of Mao's private life, such as chain-smoking cigarettes, rare bathing or dental habits, laziness, addiction to sleeping pills and large number of sexual partners. Some scholars and some other people who also personally knew and worked with Mao, however, have disputed the accuracy of these characterizaions.
Having grown up in Hunan, Mao spoke Mandarin with a marked Hunanese accent.
Ross Terrill noted Mao was a "son of the soil ... rural and unsophisticated" in origins, while Clare Hollingworth asserted he was proud of his "peasant ways and manners", having a strong Hunanese accent and providing "earthy" comments on sexual matters. Lee Feigon noted that Mao's "earthiness" meant that he remained connected to "everyday Chinese life."
Mao's private doctor has reported on his personal hygiene. He never brushed his teeth, preferring to rinse out his mouth with tea and chew the leaves. By the time of his death, his gums were severely infected and his teeth were coated with green film, with several of them coming loose. Rather than bathe, he had a servant rub him down with a hot towel; according to at least one account, he went a quarter-century without taking a bath.
Biographer Peter Carter described Mao as having "an attractive personality" who could for much of the time be a "moderate and balanced man", but noted that he could also be ruthless, and showed no mercy to his opponents. This description was echoed by Sinologist Stuart Schram, who emphasised Mao's ruthlessness, but who also noted that he showed no sign of taking pleasure in torture or killing in the revolutionary cause. Lee Feigon considered Mao "draconian and authoritarian" when threatened, but opined that he was not the "kind of villain that his mentor Stalin was". Alexander Pantsov and Steven I. Levine claimed that Mao was a "man of complex moods", who "tried his best to bring about prosperity and gain international respect" for China, being "neither a saint nor a demon." They noted that in early life, he strived to be "a strong, wilful, and purposeful hero, not bound by any moral chains", and that he "passionately desired fame and power".
Carter noted that throughout his life, Mao had the ability to gain people's trust, and that as such he gathered around him "an extraordinarily wide range of friends" in his early years.
Writings and calligraphy.
Mao was a prolific writer of political and philosophical literature. He is the attributed author of "Quotations From Chairman Mao Tse-Tung", known in the West as the "Little Red Book" and in Cultural Revolution China as the "Red Treasure Book" (红宝书): this is a collection of short extracts from his speeches and articles, edited by Lin Biao and ordered topically. Mao wrote several other philosophical treatises, both before and after he assumed power. These include:
Mao was also a skilled Chinese calligrapher with a highly personal style. In China, Mao was considered a master calligrapher during his lifetime. His calligraphy can be seen today throughout mainland China. His work gave rise to a new form of Chinese calligraphy called "Mao-style" or "Maoti", which has gained increasing popularity since his death. There currently exist various competitions specialising in Mao-style calligraphy.
Literary works.
As did most Chinese intellectuals of his generation, Mao's education began with Chinese classical literature. Mao told Edgar Snow in 1936 that he had started the study of the Confucian Analects and the Four Books at a village school when he was eight, but that the books he most enjoyed reading were "Water Margin", "Journey to the West", the "Romance of the Three Kingdoms" and "Dream of the Red Chamber".
Mao published poems in classical forms starting in his youth and his abilities as a poet contributed to his image in China after he came to power in 1949. His style was influenced by the great Tang dynasty poets Li Bai and Li He.
Some of his most well-known poems are "Changsha" (1925), "The Double Ninth" (1929.10), "Loushan Pass" (1935), "The Long March" (1935), "Snow" (1936), "The PLA Captures Nanjing" (1949), "Reply to Li Shuyi" (1957.05.11) and "Ode to the Plum Blossom" (1961.12).
Portrayal in film and television.
Mao has been portrayed in film and television numerous times. Some notable actors include: Han Shi, the first actor ever to have portrayed Mao, in a 1978 drama "Dielianhua" and later again in a 1980 film "Cross the Dadu River"; Gu Yue, who had portrayed Mao 84 times on screen throughout his 27-year career and had won the Best Actor title at the Hundred Flowers Awards in 1990 and 1993; Liu Ye, who played a young Mao in "The Founding of a Party" (2011); Tang Guoqiang, who has frequently portrayed Mao in more recent times, in the films "The Long March" (1996) and "The Founding of a Republic" (2009), and the television series "Huang Yanpei" (2010), among others. Mao is a principal character in American composer John Adams' opera "Nixon in China" (1987).
Mao and Tibet.
After Mao Zedong won the Chinese civil war in 1949, his goal became the unification of the "five nationalities" under the big family, the People's Republic of China, and under a single political system, the Communist Party of China Aware of Mao's vision, the Tibetan government in Lhasa (Tibet) sent a representative, Ngapo Ngawang Jigme to Chamdo, Kham, a strategically high valued town near the border. Ngapo had orders to hold the position while reinforcements were coming from the Lhasa and fight off the Chinese. On October 16, 1950, news came that the People's Liberation Army was advancing towards Chamdo and had also taken another strategic town named, Riwoche, which could block the route to Lhasa. With new orders, Ngapo and his men retreated to a monastery where the People's Liberation Army finally surrounded and captured them, though they were treated with respect. Ngapo wrote to Lhasa suggesting a peaceful surrender instead of war. During the negotiation, the Chinese negotiator laid the cards straight on the table, "It is up to you to choose whether Tibet would be liberated peacefully or by force. It is only a matter of sending a telegram to the PLA group to recommence their march to Lhasa." Ngapo accepted Mao’s "Seventeen-Point Agreement", which constituted Tibet as part of the People's Republic China, in return for which Tibet would be granted autonomy. In the face of discouraging lack of support from the rest of the world, the Dalai Lama on August 1951, sent a telegram to Mao accepting the Seventeen-Point Agreement.
References.
Sources.
</dl>

</doc>
<doc id="19528" url="http://en.wikipedia.org/wiki?curid=19528" title="Mechanical engineering">
Mechanical engineering

Mechanical engineering is the discipline that applies the principles of engineering, physics, and materials science for the design, analysis, manufacturing, and maintenance of mechanical systems. It is the branch of engineering that involves the design, production, and operation of machinery. It is one of the oldest and broadest of the engineering disciplines.
The engineering field requires an understanding of core concepts including mechanics, kinematics, thermodynamics, materials science, structural analysis, and electricity. Mechanical engineers use these core principles along with tools like computer-aided design, and product lifecycle management to design and analyze manufacturing plants, industrial equipment and machinery, heating and cooling systems, transport systems, aircraft, watercraft, robotics, medical devices, weapons, and others.
Mechanical engineering emerged as a field during the industrial revolution in Europe in the 18th century; however, its development can be traced back several thousand years around the world. Mechanical engineering science emerged in the 19th century as a result of developments in the field of physics. The field has continually evolved to incorporate advancements in technology, and mechanical engineers today are pursuing developments in such fields as composites, mechatronics, and nanotechnology. Mechanical engineering overlaps with aerospace engineering, metallurgical engineering, civil engineering, electrical engineering, manufacturing engineering, chemical engineering, and other engineering disciplines to varying amounts. Mechanical engineers may also work in the field of Biomedical engineering, specifically with biomechanics, transport phenomena, biomechatronics, bionanotechnology, and modeling of biological systems.
History.
Mechanical engineering finds its application in the archives of various ancient and medieval societies throughout mankind. In ancient Greece, the works of Archimedes (287–212 BC) deeply influenced mechanics in the Western tradition and Heron of Alexandria (c. 10–70 AD) created the first steam engine (Aeolipile). In China, Zhang Heng (78–139 AD) improved a water clock and invented a seismometer, and Ma Jun (200–265 AD) invented a chariot with differential gears. The medieval Chinese horologist and engineer Su Song (1020–1101 AD) incorporated an escapement mechanism into his astronomical clock tower two centuries before any escapement can be found in clocks of medieval Europe, as well as the world's first known endless power-transmitting chain drive.
During the years from 7th to 15th century, the era called the Islamic Golden Age, there were remarkable contributions from Muslim inventors in the field of mechanical technology. Al-Jazari, who was one of them, wrote his famous "Book of Knowledge of Ingenious Mechanical Devices" in 1206, and presented many mechanical designs. He is also considered to be the inventor of such mechanical devices which now form the very basic of mechanisms, such as the crankshaft and camshaft.
Important breakthroughs in the foundations of mechanical engineering occurred in England during the 17th century when Sir Isaac Newton both formulated the three Newton's Laws of Motion and developed Calculus, the mathematical basis of physics. Newton was reluctant to publish his methods and laws for years, but he was finally persuaded to do so by his colleagues, such as Sir Edmund Halley, much to the benefit of all mankind. Gottfried Wilhelm Leibniz is also credited with creating Calculus during the same time frame.
During the early 19th century in England, Germany and Scotland, the development of machine tools led mechanical engineering to develop as a separate field within engineering, providing manufacturing machines and the engines to power them. The first British professional society of mechanical engineers was formed in 1847 Institution of Mechanical Engineers, thirty years after the civil engineers formed the first such professional society Institution of Civil Engineers. On the European continent, Johann von Zimmermann (1820–1901) founded the first factory for grinding machines in Chemnitz, Germany in 1848.
In the United States, the American Society of Mechanical Engineers (ASME) was formed in 1880, becoming the third such professional engineering society, after the American Society of Civil Engineers (1852) and the American Institute of Mining Engineers (1871). The first schools in the United States to offer an engineering education were the United States Military Academy in 1817, an institution now known as Norwich University in 1819, and Rensselaer Polytechnic Institute in 1825. Education in mechanical engineering has historically been based on a strong foundation in mathematics and science.
Education.
Degrees in mechanical engineering are offered at various universities worldwide. In Brazil, Ireland, Philippines, Pakistan, China, Greece, Turkey, North America, South Asia, India, Dominican Republic and the United Kingdom, mechanical engineering programs typically take four to five years of study and result in a Bachelor of Engineering (B.Eng. or B.E.), Bachelor of Science (B.Sc. or B.S.), Bachelor of Science Engineering (B.Sc.Eng.), Bachelor of Technology (B.Tech.), Bachelor of Mechanical Engineering (B.M.E.), or Bachelor of Applied Science (B.A.Sc.) degree, in or with emphasis in mechanical engineering. In Spain, Portugal and most of South America, where neither B.Sc. nor B.Tech. programs have been adopted, the formal name for the degree is "Mechanical Engineer", and the course work is based on five or six years of training. In Italy the course work is based on five years of training, but in order to qualify as an Engineer one has to pass a state exam at the end of the course. In Greece, the coursework is based on a five year curriculum and the requirement of a 'Diploma' Thesis, which upon completion a 'Diploma' is awarded rather than a B.Sc.
In Australia, mechanical engineering degrees are awarded as Bachelor of Engineering (Mechanical) or similar nomenclature although there are an increasing number of specialisations. The degree takes four years of full-time study to achieve. To ensure quality in engineering degrees, Engineers Australia accredits engineering degrees awarded by Australian universities in accordance with the global Washington Accord. Before the degree can be awarded, the student must complete at least 3 months of on the job work experience in an engineering firm. Similar systems are also present in South Africa and are overseen by the Engineering Council of South Africa (ECSA).
In the United States, most undergraduate mechanical engineering programs are accredited by the Accreditation Board for Engineering and Technology (ABET) to ensure similar course requirements and standards among universities. The ABET web site lists 302 accredited mechanical engineering programs as of 11 March 2014. Mechanical engineering programs in Canada are accredited by the Canadian Engineering Accreditation Board (CEAB), and most other countries offering engineering degrees have similar accreditation societies.
Some mechanical engineers go on to pursue a postgraduate degree such as a Master of Engineering, Master of Technology, Master of Science, Master of Engineering Management (M.Eng.Mgt. or M.E.M.), a Doctor of Philosophy in engineering (Eng.D. or Ph.D.) or an engineer's degree. The master's and engineer's degrees may or may not include research. The Doctor of Philosophy includes a significant research component and is often viewed as the entry point to academia. The Engineer's degree exists at a few institutions at an intermediate level between the master's degree and the doctorate.
Coursework.
Standards set by each country's accreditation society are intended to provide uniformity in fundamental subject material, promote competence among graduating engineers, and to maintain confidence in the engineering profession as a whole. Engineering programs in the U.S., for example, are required by ABET to show that their students can "work professionally in both thermal and mechanical systems areas." The specific courses required to graduate, however, may differ from program to program. Universities and Institutes of technology will often combine multiple subjects into a single class or split a subject into multiple classes, depending on the faculty available and the university's major area(s) of research.
The fundamental subjects of mechanical engineering usually include:
Mechanical engineers are also expected to understand and be able to apply basic concepts from chemistry, physics, chemical engineering, civil engineering, and electrical engineering. All mechanical engineering programs include multiple semesters of mathematical classes including calculus, and advanced mathematical concepts including differential equations, partial differential equations, linear algebra, abstract algebra, and differential geometry, among others.
In addition to the core mechanical engineering curriculum, many mechanical engineering programs offer more specialized programs and classes, such as control systems, robotics, transport and logistics, cryogenics, fuel technology, automotive engineering, biomechanics, vibration, optics and others, if a separate department does not exist for these subjects.
Most mechanical engineering programs also require varying amounts of research or community projects to gain practical problem-solving experience. In the United States it is common for mechanical engineering students to complete one or more internships while studying, though this is not typically mandated by the university. Cooperative education is another option. Future work skills research puts demand on study components that feed student's creativity and innovation.
License and regulation.
Engineers may seek license by a state, provincial, or national government. The purpose of this process is to ensure that engineers possess the necessary technical knowledge, real-world experience, and knowledge of the local legal system to practice engineering at a professional level. Once certified, the engineer is given the title of Professional Engineer (in the United States, Canada, Japan, South Korea, Bangladesh and South Africa), Chartered Engineer (in the United Kingdom, Ireland, India and Zimbabwe), "Chartered Professional Engineer" (in Australia and New Zealand) or "European Engineer" (much of the European Union), Registered Engineer or Professional Engineer in Philippines and Pakistan. The Chartered Engineer and European Engineer are not licenses to practice - they are qualifications.
In the U.S., to become a licensed Professional Engineer (PE), an engineer must pass the comprehensive FE (Fundamentals of Engineering) exam, work a minimum of 4 years as an "Engineering Intern (EI)" or "Engineer-in-Training (EIT)", and pass the "Principles and Practice" or PE (Practicing Engineer or Professional Engineer) exams. The requirements and steps of this process are set forth by the National Council of Examiners for Engineering and Surveying (NCEES), a composed of engineering and land surveying licensing boards representing all U.S. states and territories.
In the UK, current graduates require a BEng plus an appropriate master's degree or an integrated MEng degree, a minimum of 4 years post graduate on the job competency development, and a peer reviewed project report in the candidates specialty area in order to become a Chartered Mechanical Engineer (CEng, MIMechE) through the Institution of Mechanical Engineers. CEng MIMechE can also be obtained via an examination route through the City and Guilds of London Institute.
In most developed countries, certain engineering tasks, such as the design of bridges, electric power plants, and chemical plants, must be approved by a Professional Engineer or a Chartered Engineer. "Only a licensed engineer, for instance, may prepare, sign, seal and submit engineering plans and drawings to a public authority for approval, or to seal engineering work for public and private clients." This requirement can be written into state and provincial legislation, such as in the Canadian provinces, for example the Ontario or Quebec's Engineer Act.
In other countries, such as Australia, and the UK, no such legislation exists; however, practically all certifying bodies maintain a code of ethics independent of legislation, that they expect all members to abide by or risk expulsion.
Salaries and workforce statistics.
The total number of engineers employed in the U.S. in 2009 was roughly 1.6 million. Of these, 239,000 were mechanical engineers (14.9%), the second largest discipline by size behind civil (278,000). The total number of mechanical engineering jobs in 2009 was projected to grow 6% over the next decade, with average starting salaries being $58,800 with a bachelor's degree. The median annual income of mechanical engineers in the U.S. workforce was $80,580. The median income was highest when working for the government ($92,030), and lowest in education ($57,090) as of 2012.
Modern tools.
Many mechanical engineering companies, especially those in industrialized nations, have begun to incorporate computer-aided engineering (CAE) programs into their existing design and analysis processes, including 2D and 3D solid modeling computer-aided design (CAD). This method has many benefits, including easier and more exhaustive visualization of products, the ability to create virtual assemblies of parts, and the ease of use in designing mating interfaces and tolerances.
Other CAE programs commonly used by mechanical engineers include product lifecycle management (PLM) tools and analysis tools used to perform complex simulations. Analysis tools may be used to predict product response to expected loads, including fatigue life and manufacturability. These tools include finite element analysis (FEA), computational fluid dynamics (CFD), and computer-aided manufacturing (CAM).
Using CAE programs, a mechanical design team can quickly and cheaply iterate the design process to develop a product that better meets cost, performance, and other constraints. No physical prototype need be created until the design nears completion, allowing hundreds or thousands of designs to be evaluated, instead of a relative few. In addition, CAE analysis programs can model complicated physical phenomena which cannot be solved by hand, such as viscoelasticity, complex contact between mating parts, or non-Newtonian flows.
As mechanical engineering begins to merge with other disciplines, as seen in mechatronics, multidisciplinary design optimization (MDO) is being used with other CAE programs to automate and improve the iterative design process. MDO tools wrap around existing CAE processes, allowing product evaluation to continue even after the analyst goes home for the day. They also utilize sophisticated optimization algorithms to more intelligently explore possible designs, often finding better, innovative solutions to difficult multidisciplinary design problems.
Subdisciplines.
The field of mechanical engineering can be thought of as a collection of many mechanical engineering science disciplines. Several of these subdisciplines which are typically taught at the undergraduate level are listed below, with a brief explanation and the most common application of each. Some of these subdisciplines are unique to mechanical engineering, while others are a combination of mechanical engineering and one or more other disciplines. Most work that a mechanical engineer does uses skills and techniques from several of these subdisciplines, as well as specialized subdisciplines. Specialized subdisciplines, as used in this article, are more likely to be the subject of graduate studies or on-the-job training than undergraduate research. Several specialized subdisciplines are discussed in this section.
Mechanics.
Mechanics is, in the most general sense, the study of forces and their effect upon matter. Typically, engineering mechanics is used to analyze and predict the acceleration and deformation (both elastic and plastic) of objects under known forces (also called loads) or stresses. Subdisciplines of mechanics include
Mechanical engineers typically use mechanics in the design or analysis phases of engineering. If the engineering project were the design of a vehicle, statics might be employed to design the frame of the vehicle, in order to evaluate where the stresses will be most intense. Dynamics might be used when designing the car's engine, to evaluate the forces in the pistons and cams as the engine cycles. Mechanics of materials might be used to choose appropriate materials for the frame and engine. Fluid mechanics might be used to design a ventilation system for the vehicle (see HVAC), or to design the intake system for the engine.
Mechatronics and robotics.
Mechatronics is the combination of mechanics and electronics. It is an interdisciplinary branch of mechanical engineering, electrical engineering and software engineering that is concerned with integrating electrical and mechanical engineering to create hybrid systems. In this way, machines can be automated through the use of electric motors, servo-mechanisms, and other electrical systems in conjunction with special software. A common example of a mechatronics system is a CD-ROM drive. Mechanical systems open and close the drive, spin the CD and move the laser, while an optical system reads the data on the CD and converts it to bits. Integrated software controls the process and communicates the contents of the CD to the computer.
Robotics is the application of mechatronics to create robots, which are often used in industry to perform tasks that are dangerous, unpleasant, or repetitive. These robots may be of any shape and size, but all are preprogrammed and interact physically with the world. To create a robot, an engineer typically employs kinematics (to determine the robot's range of motion) and mechanics (to determine the stresses within the robot).
Robots are used extensively in industrial engineering. They allow businesses to save money on labor, perform tasks that are either too dangerous or too precise for humans to perform them economically, and to ensure better quality. Many companies employ assembly lines of robots,especially in Automotive Industries and some factories are so robotized that they can run by themselves. Outside the factory, robots have been employed in bomb disposal, space exploration, and many other fields. Robots are also sold for various residential applications, from recreation to domestic applications.
Structural analysis.
Structural analysis is the branch of mechanical engineering (and also civil engineering) devoted to examining why and how objects fail and to fix the objects and their performance. Structural failures occur in two general modes: static failure, and fatigue failure. "Static structural failure" occurs when, upon being loaded (having a force applied) the object being analyzed either breaks or is deformed plastically, depending on the criterion for failure. "Fatigue failure" occurs when an object fails after a number of repeated loading and unloading cycles. Fatigue failure occurs because of imperfections in the object: a microscopic crack on the surface of the object, for instance, will grow slightly with each cycle (propagation) until the crack is large enough to cause ultimate failure.
Failure is not simply defined as when a part breaks, however; it is defined as when a part does not operate as intended. Some systems, such as the perforated top sections of some plastic bags, are designed to break. If these systems do not break, failure analysis might be employed to determine the cause.
Structural analysis is often used by mechanical engineers after a failure has occurred, or when designing to prevent failure. Engineers often use online documents and books such as those published by ASM to aid them in determining the type of failure and possible causes.
Structural analysis may be used in the office when designing parts, in the field to analyze failed parts, or in laboratories where parts might undergo controlled failure tests.
Thermodynamics and thermo-science.
Thermodynamics is an applied science used in several branches of engineering, including mechanical and chemical engineering. At its simplest, thermodynamics is the study of energy, its use and transformation through a system. Typically, engineering thermodynamics is concerned with changing energy from one form to another. As an example, automotive engines convert chemical energy (enthalpy) from the fuel into heat, and then into mechanical work that eventually turns the wheels.
Thermodynamics principles are used by mechanical engineers in the fields of heat transfer, thermofluids, and energy conversion. Mechanical engineers use thermo-science to design engines and power plants, heating, ventilation, and air-conditioning (HVAC) systems, heat exchangers, heat sinks, radiators, refrigeration, insulation, and others.
Design and drafting.
Drafting or technical drawing is the means by which mechanical engineers design products and create instructions for manufacturing parts. A technical drawing can be a computer model or hand-drawn schematic showing all the dimensions necessary to manufacture a part, as well as assembly notes, a list of required materials, and other pertinent information. A U.S. mechanical engineer or skilled worker who creates technical drawings may be referred to as a drafter or draftsman. Drafting has historically been a two-dimensional process, but computer-aided design (CAD) programs now allow the designer to create in three dimensions.
Instructions for manufacturing a part must be fed to the necessary machinery, either manually, through programmed instructions, or through the use of a computer-aided manufacturing (CAM) or combined CAD/CAM program. Optionally, an engineer may also manually manufacture a part using the technical drawings, but this is becoming an increasing rarity, with the advent of computer numerically controlled (CNC) manufacturing. Engineers primarily manually manufacture parts in the areas of applied spray coatings, finishes, and other processes that cannot economically or practically be done by a machine.
Drafting is used in nearly every subdiscipline of mechanical engineering, and by many other branches of engineering and architecture. Three-dimensional models created using CAD software are also commonly used in finite element analysis (FEA) and computational fluid dynamics (CFD).
Frontiers of research.
Mechanical engineers are constantly pushing the boundaries of what is physically possible in order to produce safer, cheaper, and more efficient machines and mechanical systems. Some technologies at the cutting edge of mechanical engineering are listed below (see also exploratory engineering).
Micro electro-mechanical systems (MEMS).
Micron-scale mechanical components such as springs, gears, fluidic and heat transfer devices are fabricated from a variety of substrate materials such as silicon, glass and polymers like SU8. Examples of MEMS components are the accelerometers that are used as car airbag sensors, modern cell phones, gyroscopes for precise positioning and microfluidic devices used in biomedical applications.
Friction stir welding (FSW).
Friction stir welding, a new type of welding, was discovered in 1991 by The Welding Institute (TWI). The innovative steady state (non-fusion) welding technique joins materials previously un-weldable, including several aluminum alloys. It plays an important role in the future construction of airplanes, potentially replacing rivets. Current uses of this technology to date include welding the seams of the aluminum main Space Shuttle external tank, Orion Crew Vehicle test article, Boeing Delta II and Delta IV Expendable Launch Vehicles and the SpaceX Falcon 1 rocket, armor plating for amphibious assault ships, and welding the wings and fuselage panels of the new Eclipse 500 aircraft from Eclipse Aviation among an increasingly growing pool of uses.
Composites.
Composites or composite materials are a combination of materials which provide different physical characteristics than either material separately. Composite material research within mechanical engineering typically focuses on designing (and, subsequently, finding applications for) stronger or more rigid materials while attempting to reduce weight, susceptibility to corrosion, and other undesirable factors. Carbon fiber reinforced composites, for instance, have been used in such diverse applications as spacecraft and fishing rods.
Mechatronics.
Mechatronics is the synergistic combination of mechanical engineering, electronic engineering, and software engineering. The purpose of this interdisciplinary engineering field is the study of automation from an engineering perspective and serves the purposes of controlling advanced hybrid systems.
Nanotechnology.
At the smallest scales, mechanical engineering becomes nanotechnology—one speculative goal of which is to create a molecular assembler to build molecules and materials via mechanosynthesis. For now that goal remains within exploratory engineering. Areas of current mechanical engineering research in nanotechnology include nanofilters, nanofilms, and nanostructures, among others.
Finite element analysis.
This field is not new, as the basis of Finite Element Analysis (FEA) or Finite Element Method (FEM) dates back to 1941. But evolution of computers has made FEA/FEM a viable option for analysis of structural problems. Many commercial codes such as ANSYS, Nastran and ABAQUS are widely used in industry for research and design of components. Calculix is an open source and free finite element program. Some 3D modeling and CAD software packages have added FEA modules.
Other techniques such as finite difference method (FDM) and finite-volume method (FVM) are employed to solve problems relating heat and mass transfer, fluid flows, fluid surface interaction etc.
Biomechanics.
Biomechanics is the application of mechanical principles to biological systems, such as humans, animals, plants, organs, and cells. Biomechanics also aids in creating prosthetic limbs and artificial organs for humans.
Biomechanics is closely related to engineering, because it often uses traditional engineering sciences to analyse biological systems. Some simple applications of Newtonian mechanics and/or materials sciences can supply correct approximations to the mechanics of many biological systems.
Over the past decade the Finite element method (FEM) has also entered the Biomedical sector highlighting further engineering aspects of Biomechanics. FEM has since then established itself as an alternative to in vivo surgical assessment and gained the wide acceptance of academia. The main advantage of Computational Biomechanics lies in its ability to determine the endo-anatomical response of an anatomy, without being subject to ethical restrictions. This has led FE modelling to the point of becoming ubiquitous in several fields of Biomechanics while several projects have even adopted an open source philosophy (e.g. BioSpine).
Computational fluid dynamics.
Computational fluid dynamics, usually abbreviated as CFD, is a branch of fluid mechanics that uses numerical methods and algorithms to solve and analyze problems that involve fluid flows. Computers are used to perform the calculations required to simulate the interaction of liquids and gases with surfaces defined by boundary conditions. With high-speed supercomputers, better solutions can be achieved. Ongoing research yields software that improves the accuracy and speed of complex simulation scenarios such as transonic or turbulent flows. Initial validation of such software is performed using a wind tunnel with the final validation coming in full-scale testing, e.g. flight tests.
Acoustical engineering.
Acoustical engineering is one of many other sub disciplines of mechanical engineering and is the application of acoustics. Acoustical engineering is the study of Sound and Vibration. These engineers work effectively to reduce noise pollution in mechanical devices and in buildings by soundproofing or removing sources of unwanted noise. The study of acoustics can range from designing a more efficient hearing aid, microphone, headphone, or recording studio to enhancing the sound quality of an orchestra hall. Acoustical engineering also deals with the vibration of different mechanical systems.
Related fields.
Manufacturing engineering, Aerospace engineering and Automotive engineering are sometimes grouped with mechanical engineering. A bachelor's degree in these areas will typically have a difference of a few specialized classes.

</doc>
<doc id="19529" url="http://en.wikipedia.org/wiki?curid=19529" title="Minister">
Minister

Minister may refer to:

</doc>
<doc id="19530" url="http://en.wikipedia.org/wiki?curid=19530" title="March 11">
March 11

March 11 is the day of the year in the Gregorian calendar.

</doc>
<doc id="19531" url="http://en.wikipedia.org/wiki?curid=19531" title="Monkey Island (series)">
Monkey Island (series)

Monkey Island is the collective name given to a series of five graphic adventure games. The first four games in the series were produced and published by LucasArts, formerly known as Lucasfilm Games. The fifth installment of the franchise was developed by Telltale Games in collaboration with LucasArts. The games follow the misadventures of the hapless Guybrush Threepwood as he struggles to become the most notorious pirate in the Caribbean, defeat the plans of the evil undead pirate LeChuck and win the heart of governess Elaine Marley. Each game's plot usually involves the mysterious Monkey Island and its impenetrable secrets.
The first game in the series was created as a collaborative effort among Ron Gilbert, Tim Schafer and Dave Grossman. Gilbert worked on the first two games before leaving LucasArts. Grossman and Schafer, who also worked on the first two games, would enjoy success on other titles before they both left LucasArts as well. The rights to "Monkey Island" remained with LucasArts, and the third and fourth games were created without direct involvement from the original writing staff. Dave Grossman was the project leader of the fifth game in the series and Ron Gilbert was involved with the initial design of the game.
Overview.
The Monkey Island series is known for its humor and "player-friendly" qualities. The player cannot permanently place the game in an unwinnable state or cause Guybrush to die without great effort. This "player-friendly" approach was unusual at the time of the first game's release in 1990; prominent adventure-game rivals included Sierra On-Line and Infocom, both of which were known for games with sudden and frequent character deaths or "lock-outs". LucasArts itself used such closed plot paths for its drama games like ' (1989), but preferred the open format for other humor-oriented adventure games such as "Sam & Max Hit the Road" (1993) and "Day of the Tentacle" (1993). After ' in 1991, the series went in hiatus until 1997, when it resumed with "The Curse of Monkey Island". After the fourth entry, "Escape from Monkey Island", the franchise again went on hiatus, though numerous rumors persisted about a revival until the announcement of "Tales of Monkey Island" by Telltale Games in early 2009.
Much of the music of the games is composed by Michael Land. The score largely consists of reggae, Caribbean and dub-inspired music.
The series also tends to break the Fourth wall, as several of the characters acknowledge that they are in a video game.
Setting.
Each of the games takes place on in the Caribbean around the Golden Age of Piracy sometime between the 17th and 18th centuries. The islands teem with pirates dressed in outfits that seem to come from movies and comic books rather than history, and there are many deliberate anachronisms and references to modern-day popular culture.
The main setting of the "Monkey Island" games is the "Tri-Island Area", a fictional archipelago in the Caribbean. Since the first game in the series, "The Secret of Monkey Island", three of the games have visited the titular island of Monkey Island, while all have introduced their own set of islands to explore. "Monkey Island 2: LeChuck's Revenge" features four new islands, but does not return to Monkey Island until the final cutscene. "The Curse of Monkey Island" introduces three, and "Escape from Monkey Island", which revisits some of the older islands, features three new islands as well. As such, the "Tri-Island area" actually comprises a total of 13 visitable islands. "Tales of Monkey Island" takes place in a new area of the Caribbean called the "Gulf of Melange".
The main islands of the Tri-Island Area are Mêlée Island, Booty Island, and Plunder Island governed by Elaine Marley in place of her long lost grandfather, Horatio Torquemada Marley. Elaine moves from island to island at her convenience, though she considers her governor's mansion on Mêlée Island, the capital island of the area, as home.
Other islands in the region are considered under the umbrella of Tri-Island Area as well, even though not directly governed by Elaine include: Lucre Island, Jambalaya Island, Scabb Island, Phatt Island, Plunder Island, Hook Island, Skull Island, Knuttin Atoll, Blood Island, Spittle Island and Pinchpenny Island.
The Gulf of Melange has its own set of islands: Flotsam Island, the Jerkbait Islands (Spinner Cay, Spoon Island, Roe Island), Brillig Island, Boulder Beach, Isle of Ewe, and the Rock of Gelato.
Monkey Island and Dinky Island are not officially part of any island area, but nonetheless are central to the series' overall back-story and canon.
Characters.
The games have a wide cast of characters, many of which reappear throughout the series. Each entry in the series revolves around three main characters: the hero Guybrush Threepwood; his love interest Elaine Marley; and the villain the pirate LeChuck.
Inspiration.
Ron Gilbert's two main inspirations for the story were Disneyland's Pirates of the Caribbean ride and Tim Powers' book "On Stranger Tides". The book was the inspiration for the story and characters, while the ride was the inspiration for the ambiance. "[The POTC Ride] keeps you moving through the adventure," Gilbert said in an interview, "but I've always wished I could get off and wander around, learn more about the characters, and find a way onto those pirate ships. So with The Secret of Monkey Island(TM) I wanted to create a game that had the same flavor, but where you could step off the boat and enter that whole storybook world."
Several specific references to the ride are made throughout the series, including a puzzle in the based on the ride's famous Jail Cell/Dog With Keys scene (the dog in the scene is even named Walt). The banjo music in the opening menu of the third game is also very reminiscent of the banjo music at the beginning of the ride. Additional references are made to Disneyland and theme parks in general throughout the series, including Guybrush finding an E ticket.
Media.
Games.
"The Secret of Monkey Island".
The series debuted in 1990 with "The Secret of Monkey Island" on the Amiga, MS-DOS, Atari ST and Macintosh platforms; the game was later ported FM Towns and Mega-CD (1993). A remastered version with updated graphics and new voiceovers was released for PlayStation Network, PC Windows, Xbox Live Arcade and Mac OS X. An iPhone version was also released on July 23, 2009.
The game starts off with the main character Guybrush Threepwood stating "I want to be a pirate!" To do so, he must prove himself to three old pirate captains. During the perilous pirate trials, he meets the beautiful governor Elaine Marley, with whom he falls in love, unaware that the ghost pirate LeChuck also has his eyes on her. When Elaine is kidnapped, Guybrush procures crew and ship to track LeChuck down, defeat him and rescue his love.
"Monkey Island 2: LeChuck's Revenge".
The second game, "Monkey Island 2: LeChuck's Revenge" from 1991, was available for fewer platforms; it was only released for PC MS-DOS, Amiga, Macintosh, and later for FM Towns. A Special Edition version, in a similar style as The Secret of Monkey Island: Special Edition, was released in July 2010 for iPhone, iPad, iPod Touch, Mac, PC, PS3 and Xbox 360.
As Guybrush, with a treasure chest in hand, and Elaine hang onto ropes in a void, he tells her the story of the game. He has decided to find the greatest of all treasures, that of Big Whoop. Unwittingly, he helps revive LeChuck, who is now in zombie form. Guybrush is eventually captured by his nemesis, but escapes with help from Wally and finds the treasure only to find himself dangling from a rope, as depicted at the beginning of the game. As Guybrush concludes his story, his rope breaks and he finds himself facing LeChuck, whom he finally defeats using voodoo. The surrealistic ending is open to a number of interpretations. In the manual of The Curse of Monkey Island, it is stated that Guybrush falls victim to a hex implemented by LeChuck.
"The Curse of Monkey Island".
"The Curse of Monkey Island", the third in the series, was exclusively available for PC Windows in 1997.
Being a 6 year gap after the last title, The Curse of Monkey Island was released after what could be said as being the biggest technological change in the gaming industry. This new era saw the advent of digital audio, CD-ROM technology and advancements in graphics.
Monkey Island I and II were originally released on floppy discs with text dialog only, no recorded speech.
The visuals were also a huge advancement over the old titles, using a unique cartoon-like cel drawn animation style.
The Curse of Monkey Island is the only title in the series to feature this style of animation. The subsequent titles abandoned this style in favor of 3D polygon animation.
Guybrush unwittingly turns Elaine into a gold statue with a cursed ring and she is soon stolen by pirates. He tracks her down before searching for a ring that can lift the curse. LeChuck appears in a fiery demon form, and is on the heels of Guybrush until a stand-off in LeChuck's amusement park ride, Monkey Mountain.
"Escape from Monkey Island".
"Escape from Monkey Island", the fourth installment, was released in 2000 for PC Windows, and in 2001 for Macintosh and PlayStation 2.
When Guybrush Threepwood and Elaine Marley return from their honeymoon, they find that Elaine has been declared officially dead, her mansion is under destruction order, and her position as governor is up for election. Guybrush investigates and unearths a conspiracy by LeChuck and evil real estate developer Ozzie Mandrill to use a voodoo talisman, "The Ultimate Insult," to make all pirates docile in order to turn the Caribbean into a center of tourism.
"Tales of Monkey Island".
"Tales of Monkey Island" is the fifth installment within the series, co-developed by Telltale Games and LucasArts, with a simultaneous release both on WiiWare and PC. Unlike other installments, "Tales" is an episodic adventure consisting of five different episodes. The first episode was released on July 7, with the last one released on December 8, 2009.
During a heated battle with his nemesis, the evil pirate LeChuck, Guybrush unwittingly unleashes an insidious pox that rapidly spreads across the Caribbean, turning pirates into zombie-like monsters. The Voodoo Lady sends Guybrush in search of a legendary sea sponge to stem the epidemic, but this seemingly straightforward quest has surprises around every corner.
Tales of Monkey Island also released on PlayStation Network as a bundle for US$20.00.
Future of the series.
In November 2011, when CEO of Telltale games Dan Conners was asked a question about another season of Monkey island, he replied "I wish we had the rights to do more Monkey but we don't. Right now what I gather is LA is focused on building AAA titles internally but honestly we don't talk much these days."
There has also been some speculation on Telltale Games forums about a possible sequel to "Tales of Monkey Island", although this was dismissed by Ron Gilbert who stated, "Basically, when we were working on Tales, I understood that [...] I'm too old for that job now" in an interview with "Edge Magazine" in March 2010. The "Tales" team claims that, despite a considerably increasing fanbase since 2009–10, there are not any plans to continue the series within the next five-year interval.
With the purchase of LucasArts by The Walt Disney Company in 2012, the rights to the franchise are now property of Disney. Ron Gilbert has been quoted in November 2012 as not being optimistic about the franchise's future, believing that Disney might abandon the franchise in favour of "Pirates of the Caribbean"; however, in December 2012, he was also quoted as wishing to contact Disney, hoping to "make the game he wants to make".
Appearances in other media.
In "", Guybrush appears as an unlockable playable skin for Starkiller.
In "Poker Night at the Inventory" and its sequel "Poker Night 2", both by Telltale Games, Reginald Van Winslow is the proprietor of the Inventory. Also, a painting of a Vaycaylian appears behind Tycho in the first game.
In "Dark Seed", the name G. Threepwood is engraved on a tombstone in the cemetery.
In "Indiana Jones and the Infernal Machine", the cheat-code MAKEMEAPIRATE transforms Indiana Jones into Guybrush Threepwood. There is also a secret room that can be entered on the final level that is a 3D rendition of the barbershop from Curse of Monkey Island, and Indy also changes into Guybrush.
In "", fights begin by insulting your opponent in a similar fashion to Monkey Island. One of the Insults included in both games was "Look, a three-headed-monkey!".
In the "Return to Zork" PC game Guybrush appears underwater in a sunken ship although this is not part of the game.
In a scene from Fate of Atlantis, Indiana Jones can die from drowning because he is unable to "hold his breath as long as Guybrush Threepwood".
In "" by Sierra On-Line, the developers added a nod to their rivals at LucasArts in the form of a rhyme that is shown when the Hero drowns after staying under water for too long: "This is the lesson you've been taught — Guybrush Threepwood you are not. When by water you are surrounded – Get to shore before you're drown-ed".
In the flash game "Crunchball 3000", Guybrush Threepwood is one of the players of the "Butchers" and Herman Toothrot is one of the players of the "Thuggs."
In "The Longest Journey", April Ryan has a small toy monkey she calls "Officer Guybrush."
In "", also published by Telltale Games, multiple references to Monkey Island are made, such as when Hector says "Murray?" to a skull, or when using the eyepatch on Lambert causes him to say "I'm a mighty pirate!"
In the book "Blazed Union" by H. O. Charles, Morghiad declares that Artemi fights "like a blazed dairy farmer", to which she replies, "How appropriate, because I am going to milk your blood!"
In the roguelike "Dungeons of Dredmor" a number of references to the Monkey Island series are made, including a drink called Grog which has the same ingredient list as the grog mentioned in the Secret of Monkey Island.
At the "A Pirate's Adventure: Treasures of the Seven Seas" interactive game attraction at the Magic Kingdom at Walt Disney World, the theme to Monkey Island can be heard as one of the songs in the loop of background music when signing up for a quest and collecting your treasure map.
In "", by Ubisoft, one of Edward Kenway's assassination targets is named "Mancomb Seepgood". Mancomb Seepgood is one of the first pirates Guybrush meets in the Scumm Bar in "The Secret of Monkey Island".
In Telltale's Xbox 360 version of The Walking Dead (video game) one of the gamer achievements is called "You fight like a dairy farmer!", which is an insult used in the sword fighting scenes in "The Secret of Monkey Island".
Cancelled film.
In 2000, Lucasfilm together with Industrial Light & Magic were working on an animated film to be called "Curse of Monkey Island", which would be based on the series. Steve Purcell created the concept paintings and Ted Elliott wrote the story. However, during development the film was cancelled. Concept art of the film was released via Purcell's official blog.
In 2007, fan site World of Monkey Island was contacted by an anonymous source who told them that Ted Elliot had written the script for the film who before then remained unknown to the project.
Elliot would later go on to write the "Pirates of the Caribbean" film series.
Common themes.
The games in the series share several minigames, puzzles, in-jokes, and references.
Maps.
Each game contains a map puzzle, wherein Guybrush must use an unconventional map to find his way through a maze. The first game features a set of dance instructions that point the way through the dense forest of Mêlée IslandTM to find the Island's fabled treasure. In the second game, Guybrush must use a song from a dream sequence to find his way through LeChuck's dungeon. The third game is the reverse of this, as the instructions the player receives are traditional directions and need to be used on a theatre light board. The fourth game has a set of directions based on time, and the fifth based on animal sounds and the direction of the wind and finally a map to get one of the items needed for "The Feast of the Senses".
Recipes.
Each game features a sequence of some sort, where players must gather the ingredients to create an item. Then, later in the game, the player has to create the item again, but this time around with improvised materials. In 'Secret', Guybrush must brew a voodoo concoction but, lacking ingredients, must improvise with the contents of his inventory, leading to amusing puns. In Monkey Island 2, at two points of the game, Guybrush has to create a voodoo doll, one of Largo LaGrande with legitimate ingredients, and one of LeChuck with improvised ingredients. The same goes with the hangover medicine in 'Curse' and the Ultimate Insult in 'Escape'. 'Tales' starts with Guybrush having to obtain fizzy root-beer then dropping it and him having to instead put together some fizzy root-grog. Later 'Tales' requires Guybrush to put together a 'feast of the senses' to increase the size of La Esponja Grande, and later track down a reversed recipe for the 'diet of the senses'.
Minigames.
Each game also contains a minigame based on learning and repetition of a sequence in order to become more proficient: Insult Swordfighting in the first and third games, a number-based "password" as well as a spitting contest in the second, banjo fighting in the third, insult arm wrestling and Monkey Kombat in the fourth, and Pirate Face-Off in the fifth. The first, second and fourth games also feature a puzzle which involves following another character through several locations, a trick also used in "Indiana Jones and the Fate of Atlantis". Some other minigames include naval cannon battles, and platform diving.
Pop-culture references.
The Monkey Island series is full of spoofs, in-jokes, humorous references, and Easter eggs: so many, in fact, that entire web sites are dedicated to their detection and listing.
Running gags include lines such as "Look behind you, a three-headed monkey!", the introduction "My name is Guybrush Threepwood and I'm a mighty pirate", "How appropriate, you fight like a cow", "I'm selling these fine leather jackets" (a reference to ""), and "That's the second biggest [object] I've ever seen", a catchphrase from the TV series "Get Smart" (and in EMI "That's the second largest... No, that IS the "largest" conch shell I've ever seen!"), and the astounding fact that Guybrush can hold his breath for ten minutes.
"The Secret of Monkey Island" poked fun at rival company Sierra's game-over screens. For example, when Guybrush falls off a cliff, a "game over" window appears, but then Guybrush bounces back to the top of the cliff, explaining that he landed in a "rubber tree".
The "stump joke" made fun about the use of multiple floppy disks for one program, but was not initially recognized by gamers as a joke. In "The Secret of Monkey Island", Guybrush comes across a passageway hidden beneath a stump, at which point a screen says to insert Disk No. 144. Later, in "The Curse of Monkey Island", Guybrush looks through a crack in the ceiling of an underground crypt to find himself peeking out of the same stump.
Ron Gilbert has openly admitted that sections of "Monkey Island 2" borrowed extensively from the original Pirates of the Caribbean Disneyland ride, such as the famous "dog holding the keys to the jail-cell". He has also said that he thought the second movie ("") may have 'borrowed' from the "Monkey Island" series. The opening menu banjo music in "Curse" is also very reminiscent of the beginning of the Disneyland ride.
Each game in the series features cameo appearances by Steve Purcell's characters Sam & Max, who were featured in their own LucasArts adventure game, "Sam & Max Hit the Road". These are replaced by the purple tentacle from yet another LucasArts adventure game Day of the Tentacle in the special edition versions.
There are many comic references to various Lucas projects, especially Star Wars. For instance, in "Curse," when you click on the fort that has been damaged by cannon fire from LeChuck's ship, Guybrush replies "That's funny, the damage doesn't look as bad from out here," which is C-3PO's line after he and R2-D2 escape from Princess Leia's ship in the escape pod.
In LeChuck' Revenge, the Governor of Phatt Island, Governor Phatt, says in his sleep "Because careful with those snacks, Eugene." in reference to the Pink Floyd song "be careful with that Axe Eugene"
The Secret of Monkey Island.
None of the games explicitly reveal the "Secret of Monkey Island" (although creator Ron Gilbert has stated that the secret was not revealed in any of the games, and that the true secret would be revealed if he got to work on the fifth entry in the series). LeChuck himself, when asked in the second and third games, refuses to answer the question; Guybrush can eventually prod LeChuck to confess that he does not know what the secret is.
Gilbert stated that he never told anyone what the true secret of Monkey Island is.
Gilbert stated in a 2004 interview that when the game was originally conceived it was considered "too big", so they split it into three parts. He added that he "knows what the third [part] is" and "how the story's supposed to end," indicating that he had a definite concept of the secret and a conclusive third game.
The team behind "Escape from Monkey Island" attempted to resolve the issue by showing that the Giant Monkey Head was actually the control room of a Giant Monkey Robot. The cut-scene in which the revelation was made is called "The Real Secret of Monkey Island".
External links.
Listen to this article ()
This audio file was created from a revision of the "Monkey Island (series)" article dated 2009-08-10, and does not reflect subsequent edits to the article. ()
More spoken articles

</doc>
<doc id="19532" url="http://en.wikipedia.org/wiki?curid=19532" title="Cardiff Arms Park">
Cardiff Arms Park

Cardiff Arms Park (Welsh: "Parc yr Arfau Caerdydd"), also known as The Arms Park and the BT Sport Cardiff Arms Park for sponsorship reasons from September 2014, is situated in the centre of Cardiff, Wales. It is primarily known as a rugby union stadium, but it also has a bowling green. The Arms Park was host to the British Empire and Commonwealth Games in 1958, and hosted four games in the 1991 Rugby World Cup, including the third-place play-off. The Arms Park also hosted the inaugural Heineken Cup final of 1995–96 and the following year in 1996–97.
The history of the rugby ground begins with the first stands appearing for spectators in the ground in 1881–1882. Originally the Arms Park had a cricket ground to the north and a rugby union stadium to the south. By 1969, the cricket ground had been demolished to make way for the present day rugby ground to the north and a second rugby stadium to the south, called the National Stadium. The National Stadium, which was used by Wales national rugby union team, was officially opened on 7 April 1984, however in 1997 it was demolished to make way for the Millennium Stadium in 1999, which hosted the 1999 Rugby World Cup and became the national stadium of Wales. The rugby ground has remained the home of the semi-professional Cardiff RFC yet the professional Cardiff Blues regional rugby union team moved to the Cardiff City Stadium in 2009, but returned three years later.
The site is owned by Cardiff Athletic Club and has been host to many sports, apart from rugby union and cricket; they include athletics, association football, greyhound racing, tennis, British baseball and boxing. The site also has a bowling green to the north of the rugby ground, which is used by Cardiff Athletic Bowls Club, which is the bowls section of the Cardiff Athletic Club. The National Stadium also hosted many music concerts including Michael Jackson, David Bowie, Bon Jovi, The Rolling Stones and U2.
History.
Early history of the site.
The Cardiff Arms Park site was originally called the Great Park, a swampy meadow behind the Cardiff Arms Hotel. The hotel was built by Sir Thomas Morgan, during the reign of Charles I. Cardiff Arms Park was named after this hotel. From 1803, the Cardiff Arms Hotel and the Park had become the property of the Bute family. The Arms Park soon became a popular place for sporting events, and by 1848, Cardiff Cricket Club was using the site for its cricket matches. However by 1878, Cardiff Arms Hotel had been demolished.
The 3rd Marquess of Bute stipulated that the ground could only be used for "recreational purposes". At that time Cardiff Arms Park had a cricket ground to the north and a rugby union ground to the south. 1881–2 saw the first stands for spectators; they held 300 spectators and cost £50. The architect was Archibald Leitch, famous for designing Ibrox Stadium and Old Trafford, amongst others. In 1890, new standing areas were constructed along the entire length of the ground, with additional stands erected in 1896.
1912 redevelopment.
By 1912, the Cardiff Football Ground, as it was then known, had a new south stand and temporary stands on the north, east and west ends of the ground. The south stand was covered, while the north terrace was initially without a roof. The improvements were partly funded by the Welsh Rugby Union (WRU). The opening ceremony took place on 5 October 1912, with a match between Newport RFC and Cardiff RFC. The new ground was opened by Lord Ninian Crichton-Stuart. This new development increased the ground capacity to 43,000 and much improved the facilities at the ground compared to the earlier stands.
In 1922 John Crichton-Stuart, 4th Marquess of Bute, had sold the entire site and it was bought by the Cardiff Arms Park Company Limited for £30,000, it was then leased to the Cardiff Athletic Club (cricket and rugby sections) for 99 years at a cost of £200 per annum.
North and South Stand redevelopments.
During 1934 the cricket pavilion had been demolished to make way for the new North Stand, which was built on the rugby union ground, costing around £20,000. However in 1941 the new North Stand and part of the west terracing had been badly damaged in the Blitz by the Luftwaffe during the Second World War.
At a general meeting of the WRU in June 1953, they made a decision, "That until such time as the facilities at Swansea were improved, all international matches be played at Cardiff". At the same time, plans were made for a new South Stand, which was estimated to cost £60,000, however the tender price came out at £90,000, a compromise was made, and it was decided to build a new upper South Stand costing £64,000 instead, with the Cardiff Athletic Club contributing £15,000 and the remainder coming from the WRU. The new South Stand opened in 1956, in time for the 1958 British Empire and Commonwealth Games. This brought the overall capacity of the Arms Park up to 60,000, of which 12,800 spectators were seated and the remainder standing.
The Arms Park hosted the 1958 British Empire and Commonwealth Games, which was used for the athletics events, but this event caused damage to the drainage system, so much so, that other rugby unions (England, Scotland and Ireland) complained after the Games about the state of the pitch. On 4 December 1960, due to torrential rain, the River Taff burst its banks with the Arms Park pitch being left under 4 ft of water. The Development Committee was set up to resolve these issues on a permanent basis. They looked at various sites in Cardiff, but they all proved to be unsatisfactory. They also could not agree a solution with the Cardiff Athletic Club, so they purchased about 80 acre of land at Island Farm in Bridgend, which was previously used as a prisoner-of-war camp. It is best known for being the camp where the biggest escape attempt was made by German prisoners of war in Great Britain during the Second World War. Due to problems including transport issues Glamorgan County Council never gave outline planning permission for the proposals and by June 1964 the scheme was abandoned. At that stage, the cricket ground to the north was still being used by Glamorgan County Cricket Club, and the rugby union ground to the south was used by the national Wales team and Cardiff RFC.
By 7 October 1966, the first floodlit game was held at Cardiff Arms Park, a game in which Cardiff RFC beat the Barbarians by 12 points to 8.
National Stadium.
The National Stadium, which was also known as the Welsh National Rugby Ground, was designed by Osborne V Webb & Partners and built by G A Williamson & Associates of Porthcawl and Andrew Scott & Company of Port Talbot.
After agreement from the Cardiff Athletic Club, the freehold of the south ground was transferred solely to the WRU in July 1968. Work could then begin on the new National Stadium. Glamorgan County Cricket Club would move to Sophia Gardens and the cricket ground to the north would be demolished and a new rugby union stadium built for Cardiff RFC, who would move out of the south ground, allowing the National Stadium to be built, for the sole use of the national rugby union team.
On 17 October 1970, the new North Stand and the Cardiff RFC ground was completed, the North Stand cost just over £1 million. The West Stand was opened in 1977 and the new East Terrace was completed by March 1980. By the time the final South Stand had been completed and the Stadium officially opened on 7 April 1984, the South Stand had cost £4.5 million. At the start of the project, the total cost was estimated at £2.25 million, although by time it was finished in 1984, it had risen by nearly four times that amount.
Both stadia had approximately east-west alignment: the rugby ground to the north (Castle Street) end; the National Stadium to the south (Wood Street) end. The original capacity was 65,000 but this had to be reduced in later years to 53,000 for safety reasons. 11,000 of these were on the East Terrace and the conversion to all-seater stadium would have reduced the stadium capacity still further to 47,500. This capacity would have been much less than Twickenham and the other major rugby venues and also less than the demand for tickets to major events.
A world record crowd of 56,000 for a rugby union club match watched Llanelli RFC beat Neath RFC by 28 points to 13 points in the final of the Schweppes Cup (WRU Challenge Cup) on 7 May 1988. The first evening game to be played under floodlights was held on 4 September 1991 at 8.00 pm, between Wales and France. The last international match to be held at the National Stadium was between Wales and England on 15 March 1997, and the last ever match that was held at the National Stadium was on 26 April 1997 between Cardiff and Swansea, Cardiff won the SWALEC Cup (WRU Challenge Cup) by 33 points to 26 points.
Millennium Stadium.
In 1997, just thirteen years after the National Stadium had opened, it was considered too small and did not have the facilities required of the time and it was demolished and a new stadium, the Millennium Stadium, was built in its place (completed to a north-south alignment and opened in June 1999). This would become the fourth redevelopment of the Cardiff Arms Park site. Although the Millennium Stadium is on roughly two thirds of the National Stadium, Cardiff Arms Park site, it is currently no longer using the Arms Park name. The official website confuses the issue as well, one part states that "The Millennium Stadium is located on Westgate Street in Cardiff; next to the Cardiff Arms Park". whereas another section specifically refers to the stadium as "The Millennium Stadium, on the Cardiff Arms Park"
Rugby ground.
Only the rugby ground and the Cardiff Athletic Bowls Club now use the name Cardiff Arms Park. The rugby ground has two main stands, the North Stand, which was renamed the Bmibaby Stand in August 2002, and the South Stand. Both the Bmibaby Stand and the South Stand have terracing below seating. The other ends of the ground are the Westgate Street end (east), which has rows of seating below executive boxes, plus the club shop, and the River Taff end (west), which has 26 executive boxes. The rugby ground has two main entrances, the south entrance, and the Gwyn Nicholls Memorial Gates (north entrance), which was unveiled on 26 December 1949 in honour of the Welsh international rugby player Gwyn Nicholls. The Cardiff Athletic Clubhouse is situated in the corner of the ground between the South Stand and the Westgate Street end.
The South Stand of the rugby ground formed a complete unit with the North Stand of the National Stadium. Now the same structure of the South Stand of the rugby ground is also physically attached to the North Stand of the Millennium Stadium. This section is known colloquially as Glanmor's Gap, after Glanmor Griffiths, former chair and President of the WRU. This came about because the WRU were unable to secure enough funding to include the North Stand in the Millennium Stadium, and the National Lottery Commission would not provide any additional funds to be used for the construction of a new ground for Cardiff RFC. The Millennium Stadium was therefore built with the old reinforced concrete structure of the National Stadium (North Stand) and the new steel Millennium Stadium structure built around it.
There was doubt about the future of the Arms Park after 2010 following the move of the Cardiff Blues to the Cardiff City Stadium. Cardiff RFC Ltd, the company that runs Cardiff Blues and Cardiff RFC, still has a 15-year lease on the Arms Park, but talks are underway to release the rugby club from the terms of the lease, to enable the Millennium Stadium to be redeveloped with a new North Stand and adjoining convention centre. However, it still has the original requirement on the lease, that the land will only be used for "recreational purposes", as stipulated by the Bute family. But the Arms Park site is a prime piece of real estate in the centre of Cardiff, which means that it may be difficult to sell the land to property developers. The estimated value of the whole Arms Park site could be at least £25 million, although with the "recreational use" requirement, its actual value could be a lot less than that figure. A decision by Cardiff Athletic Club on the future of the Arms Park has yet to be made. In 2011, the Cardiff Blues regional rugby union team made a £6 million bid for the Arms Park, later the WRU made an increased bid of £10 million for the site. Both bids were rejected by the trustees of the Cardiff Athletic Club. However, in 2012 Cardiff Blues announced that they would be making a permanent return to Cardiff Arms Park following declining attendances at the Cardiff City Stadium. In the 2013 off-season, the pitch at the Arms Park will be replaced with an artificial FieldTurf surface in time for the start of the 2013–14 season. This change is intended to prevent any adverse weather conditions from affecting the rugby.
Bowling green.
Cardiff Arms Park is best known as a rugby union stadium, but Cardiff Athletic Bowls Club (CABC) was established in 1923, and ever since then, the club has used the Arms Park as its bowling green. The bowls club is a section of the Cardiff Athletic Club and shares many of the facilities of the Cardiff Arms Park athletics centre.
The Les Spence Memorial Gates were erected in memory of the former Cardiff RFU player, who captained the team in 1936-37. He was born in 1907 and became chairman of the Cardiff RFU and president of the WRU between 1973 and 1974. He was awarded an MBE and died in 1988.
The Club has produced two Welsh international bowlers; Mr. C Standfast in 1937 and Mr. B Hawkins who represented Wales in the 1982 World Pairs and captained Wales in 1982 and 1984.
Usage.
Association football.
The Riverside Football Club, founded in 1899, played some matches at the Arms Park until 1910, when they moved to Ninian Park, and later became Cardiff City Football Club.
On 31 May 1989, Wales played its first international game against West Germany at the National Stadium in a World Cup qualifying match, which ended goalless. It was also the first ever international football match held in Great Britain that was watched by all-seater spectators.
Athletics.
In 1958, the British Empire and Commonwealth Games were held in Cardiff. The event was (to date) the biggest sporting event ever held in Wales; however, it would not have been possible without the financial support given by the WRU and the Cardiff Athletic Club. Both the opening and closing ceremonies took place at Cardiff Arms Park, plus all the track and field events, on what had been the greyhound track. It would turn out to be the last time that South Africa would participate in the Games until 1994. South Africa withdrew from the Commonwealth Games in 1961.
Baseball & British baseball.
Baseball was established early on in Cardiff, and one of the earliest of games to be held at the Arms Park was on 18 May 1918. It was a charity match in aid of the Prisoner of War Fund between Welsh and American teams of the U.S. Beaufort & U.S. Jupiter. British baseball matches have also regularly taken place at the Arms Park and hosted the annual England versus Wales international game every four years. The games are now usually held at Roath Park.
Boxing.
The first boxing contest held at the Arms Park was on 24 January 1914, when Bombadier Billy Wells beat Gaston Pigot by a knockout in the first round of a 20 round contest. Boxing contests were held later on 14 June 1943, 12 August 1944, 4 October 1951 and 10 September 1952.
Around 25,000 spectators watched international boxing on 1 October 1993, at the National Stadium with a World Boxing Council (WBC) Heavyweight title bout between Lennox Lewis and Frank Bruno. It was the first time that two British-born boxers had fought for the world heavyweight title. Lewis beat Bruno by a technical knockout in the 7th round, in what was called the "Battle of Britain". On 30 September 1995, Steve Robinson the World Boxing Organization (WBO) World Featherweight Champion, lost against Prince Naseem Hamed at the rugby ground in 8 rounds.
Cricket.
In 1819 Cardiff Cricket Club was formed, by 1848 they had moved to their new home at the Arms Park. Glamorgan Cricket Club, at the time not a first-class county, played their first match at Cardiff Arms Park in June 1869, against Monmouthshire Cricket Club. They played their first-ever County Championship match there in 1921, competing there every season (except while first-class cricket was suspended during the Second World War), their last match being against Somerset County Cricket Club in August 1966. Cardiff Cricket Club played their final game at the ground against Lydney Cricket Club on 17 September 1966. Both Cardiff Cricket Club and Glamorgan then moved to a new ground at Sophia Gardens on the opposite bank of the River Taff to the Arms Park, following work on the creation of a national rugby stadium, later named the National Stadium.
The first first-class cricket match actually to be held on the ground was between West of England and East of England, on 20 June 1910. In all more than 240 first-class cricket matches were played at Cardiff Arms Park.
Only one List A game was ever played at the ground, and this was only the second match of its type: Glamorgan's Gillette Cup fixture against Somerset on 22 May 1963. Except for the aforementioned 1910 game, the only major match not to involve Glamorgan was a Test Trial in July 1932, which was badly affected by the weather and saw play on only one of the scheduled three days.
Greyhound racing.
To help pay for the upkeep of the site, a greyhound track was built in 1927. The first meeting was held on 7 April 1928. The Arms Park (Cardiff) Greyhound Racing Company Limited signed a 50-year lease in 1937, with Cardiff Athletic Club – the owners of the Arms Park – having no rights to break the agreement or to review the rental until 50 years expired. A neighbouring track, the White City closed in 1939 and the Welsh Greyhound Derby was transferred to the Arms Park from White City, Cardiff in 1945. This was one of the three races that formed the triple crown along with the English Greyhound Derby and Scottish Greyhound Derby. The track continued to host the race annually. In 1958 the entire surface required relaying after the Commonwealth Games had finished. In 1971 the Welsh Greyhound Derby was given 'classic' status. In 1977 the Cardiff City Council announced that a revamp of the Arms Park site would not include greyhound racing. The Welsh Rugby Union required the Arms Park track to extend terracing at the National Stadium. The last Welsh Greyhound Derby was on 9 July and the last meeting was held on 30 July. 1,128 greyhound fans saw Lillyput Queen, owned by Cardiff butcher Malcolm Davies and trained by Freddie Goodman, win the last race. Cardiff City Council had taken less than ten minutes to reject a plan to switch greyhound racing to nearby Maindy Stadium.
Rugby union.
In 1876, the Cardiff RFC was formed and soon after they also used the park. On 12 April 1884, the first international match was played at the ground between Wales and Ireland, when 5,000 people watched Wales beat Ireland by two tries and a drop goal to nil.
The Arms Park rugby ground became the permanent home of the Wales national rugby union team in 1964. Later, the National Stadium was also home to the WRU Challenge Cup from 1972 until the match held at the Stadium on 26 April 1997, at a much reduced capacity, between Cardiff RFC and Swansea RFC. Cardiff RFC won the match 33–26.
The game (between the Barbarians and the New Zealand All Blacks) is one I will never forget and those of us who played in it will never be allowed to forget. It is a match that will live with me forever. People tend only to remember the first four minutes of the game because of the try, but what they forgot is the great deal of good rugby played afterwards, much of which came from the All Blacks. After the success of the 1971 Lions tour, which captured the imagination of the whole country, it was an opportunity to bring a lot of that side together again.
Gareth Edwards
The National Stadium is best known as the venue for what is considered to be "the greatest try ever scored" by Gareth Edwards for the Barbarians against New Zealand in what is also called "the greatest match ever played" on 27 January 1973. The final result was a win for the Barbarians. The score, 23–11, which translates to 27–13 in today's scoring system.
The scorers were:
Barbarians: Tries: Gareth Edwards, Fergus Slattery, John Bevan, J P R Williams; Conversions: Phil Bennett (2); Penalty: Phil Bennett.
All Blacks: Tries: Grant Batty (2); Penalty: Joseph Karam.
The National Stadium hosted four games in the 1991 Rugby World Cup, including the third-place play-off. The National Stadium was also host to the inaugural Heineken Cup final of 1995–96 when Toulouse beat Cardiff RFC by 21–18 after extra time, in front of 21,800 spectators. The following final in 1996–97 was also held at the National Stadium, this time it was between Brive and Leicester Tigers. Brive won the match 28–9, in front of a crowd of 41,664.
In 2008, the rugby ground hosted all the games in Pool A of the 2008 IRB Junior World Championship and also the semi-final on 18 June 2008, in which England beat South Africa 26–18.
Until February 2012, it had been assumed that the last professional rugby union game to take place at the Arms Park was on 17 May 2009, when Edinburgh beat the Cardiff Blues 36–14 in a Celtic League match during the 2008–09 season.
However, on Tuesday, 7 February 2012, it was confirmed that Cardiff Blues would face Connacht at the Arms Park on Friday, 10 February 2012. The Pro12 League game result was a win for the Cardiff Blues 22–15 and attendance of 8,000. The following Tuesday, it was announced that the match against Ulster on Friday, 17 February, would also be at the Arms Park, resulting in a Blues win, 21–14 and attendance of 8,600. The agreement signed during 2009 tied Cardiff Blues to a 20-year contract to play a maximum of 18 games per season for a set fee, rather than per match at Cardiff City Stadium. But on 23 February, it was announced that the two Welsh 'derbies' against the Scarlets and the Ospreys would be played at Cardiff City Stadium, rather than the Arms Park, because of Cardiff Blues' anticipation that the attendance figures would far exceed the maximum capacity of 9,000. On 8 May 2012, it was announced that Cardiff Blues would be returning to the Arms Park on a permanent basis after just three years at the Cardiff City Stadium.
On 23 May 2014, the rugby ground hosted the final of the 2013–14 Amlin Challenge Cup in which Northampton Saints beat Bath 30-16.
Tennis.
Tennis courts were laid out in the Arms Park for Cardiff Tennis Club until the club moved to Sophia Gardens in 1967. In 2003, the club amalgamated with Lisvane Tennis Club to form Lisvane (CAC) Tennis Club, which is still a section of Cardiff Athletic Club (CAC).
Music concerts.
Major music concerts were also held at the National Stadium from 1987 until 1996, they included Tina Turner,U2, Michael Jackson, The Rolling Stones, Dire Straits, Bon Jovi and R.E.M. The last music concert was held on 14 July 1996. Jehovah's Witnesses held their annual conventions at the National Stadium.
Singing tradition.
The National Stadium was known primarily as the venue for massed voices singing such hymns as "Cwm Rhondda", "Calon Lân", "Men of Harlech" and "Hen Wlad Fy Nhadau" ("Land of my Fathers" – the national anthem of Wales). The legendary atmosphere including singing of the crowd was said to be worth at least a try or a goal to the home nation. This tradition of singing has now passed on to the Millennium Stadium.
The Arms Park has its own choir, called the Cardiff Arms Park Male Choir. It was formed in 1966 as the Cardiff Athletic Club Male Voice Choir, and today performs internationally with a schedule of concerts and tours. In 2000, the choir changed their name to become the Cardiff Arms Park Male Choir.
External links.
class="wikitable succession-box" style="margin:0.5em auto; font-size:95%;clear:both;"

</doc>
<doc id="19535" url="http://en.wikipedia.org/wiki?curid=19535" title="Mikhail Kalashnikov">
Mikhail Kalashnikov

Lieutenant-General Mikhail Timofeyevich Kalashnikov (Russian: Михаи́л Тимофе́евич Кала́шников; 10 November 1919 – 23 December 2013) was a Russian general, inventor, military engineer, writer and small arms designer. He is most famous for developing the AK-47 assault rifle and its improvements, AKM and AK-74, as well as the PK machine gun.
Kalashnikov was, according to himself, a self-taught tinkerer who combined innate mechanical skills with the study of weaponry to design arms that achieved battlefield ubiquity. Even though Kalashnikov felt sorrow at the weapons' uncontrolled distribution, he took pride in his inventions and in their reputation for reliability, emphasizing that his rifle is "a weapon of defense" and "not a weapon for offense".
Early life.
Kalashnikov was born in Kurya, Altai Governorate, Russian SFSR, now Altai Krai, Russia, to Aleksandra Frolovna Kalashnikova (née Kaverina) and Timofey Aleksandrovich Kalashnikov. In 1930, his father and most of his family were deprived of property and deported to the village of Nizhnyaya Mokhovaya, Tomsk Oblast. In his youth, Mikhail suffered from various illnesses and was on the verge of death at age six. He was attracted to all kinds of machinery, but also wrote poetry, dreaming of becoming a poet. He went on to write six books and continued to write poetry all of his life. Kalashnikov's parents were peasants, but, after deportation to Tomsk Oblast, had to combine farming with hunting, and thus Mikhail frequently used his father's rifle in his teens. Kalashnikov continued hunting into his 90s.
After completing seventh grade, Mikhail, with his stepfather's permission, left his family and returned to Kurya, hitchhiking for nearly 1,000 km. In Kurya he found a job in mechanics at a tractor station and developed a passion for weaponry. In 1938, he was conscripted into the Red Army. Because of his small size and engineering skills he was assigned as a tank mechanic, and later became a tank commander. While training, he made his first inventions, which concerned not only tanks, but also small weapons, and was personally awarded a wrist watch by Georgy Zhukov. Kalashnikov served on the T-34s of the 24th Tank Regiment, 108th Tank Division stationed in Stryi before the regiment retreated after the Battle of Brody in June 1941. He was wounded in combat in the Battle of Bryansk in October 1941 and hospitalised until April 1942. While in the hospital, he overheard some fellow soldiers complaining about the Soviet rifles of the time.
Seeing the drawbacks of the standard infantry weapons at the time, he decided to construct a new rifle for the Soviet military. During this time Kalashnikov began designing a submachine gun. Although his first submachine gun design was not accepted into service, his talent as a designer was noticed. From 1942 onwards Kalashnikov was assigned to the Central Scientific-developmental Firing Range for Rifle Firearms of the Chief Artillery Directorate of the Red Army.
In 1944, he designed a gas-operated carbine for the new 7.62x39 mm cartridge. This weapon, influenced by the M1 Garand rifle, lost out to the new Simonov carbine which would be eventually adopted as the SKS; but it became a basis for his entry in an assault rifle competition in 1946.
His winning entry, the "Mikhtim" (so named by taking the first letters of his name and patronymic, Mikhail Timofeyevich) became the prototype for the development of a family of prototype rifles. This process culminated in 1947, when he designed the AK-47 (standing for "Avtomat Kalashnikova model 1947"). In 1949, the AK-47 became the standard issue assault rifle of the Soviet Army and went on to become Kalashnikov's most famous invention. While developing his first assault rifles, Kalashnikov competed with two much more experienced weapon designers, Vasily Degtyaryov and Georgy Shpagin, who both accepted the superiority of the AK-47. Kalashnikov named Alexandr Zaitsev and Vladimir Deikin as his major collaborators during those years.
Later career.
From 1949, Mikhail Kalashnikov lived and worked in Izhevsk, Udmurtia. He held a degree of Doctor of Technical Sciences (1971) and was a member of 16 academies.
Over the course of his career, he evolved the basic design into a weapons family. The AKM (Russian: "Автомат Кала́шникова Модернизированный" – Kalashnikov modernized assault rifle) first appeared in 1963, was lighter and cheaper to manufacture owing to the use of a stamped steel receiver (in place of the AK47's milled steel receiver), and contained detail improvements such as a re-shaped stock and muzzle compensator. From the AKM he developed a squad automatic weapon variant, known as the RPK (Russian: "Ручной пулемет Кала́шникова" – Kalashnikov light machine gun).
He also developed the general-purpose PK machine gun (Russian: "Пулемет Кала́шникова" – Kalashnikov machine gun), which used the more powerful 7.62×54R cartridge of the Mosin-Nagant rifle. It is cartridge belt-fed, not magazine-fed, as it is intended to provide heavy sustained fire from a tripod mount, or be used as a light, bipod-mounted weapon. The common characteristics of all these weapons are simple design, ruggedness and ease of maintenance in all operating conditions.
Approximately 100 million AK-47 assault rifles had been produced by 2009, and about half of them are counterfeit, manufactured at a rate of about a million per year. Izhmash, the official manufacturer of AK-47 in Russia, did not patent the weapon until 1997, and in 2006 accounted for only 10% of the world's production. Kalashnikov himself claimed he was always motivated by service to his country rather than money, and made no direct profit from weapon production. He did however own 30% of a German company Marken Marketing International (MMI) run by his grandson Igor. The company revamps trademarks and produces merchandise carrying the Kalashnikov name, such as vodka, umbrellas and knives. One of the items is a knife named for the AK-74.
During a visit to the United States in the early 2000s, Kalashnikov was invited to tour a Virginia holding site for the forthcoming American Wartime Museum. The former tanker Kalashnikov became visibly moved at the sight of his old tank in action, painted with his name in Cyrillic.
On 17 November 2013, Kalashnikov was hospitalized in an Udmurtian medical facility. He died on 23 December 2013 at a hospital after a prolonged illness.
Death.
Kalashnikov died 23 December 2013, at age 94 in a hospital in Izhevsk, the capital of Udmurtia and where he lived, from gastric hemorrhage. In January 2014 a letter that Kalashnikov wrote six months before his death to the leader of the Russian Orthodox Church, Patriarch Kirill, was published by the Russian daily newspaper "Izvestia". In the letter he stated that he was suffering "spiritual pain" about whether he was responsible for the deaths caused by the weapons he created. Translated from the published letter he states, "My heartache unbearable same insoluble question: if my rifle deprive people of life, and therefore I, Mikhail Kalashnikov, ninety-three years old, the son of a peasant, and Orthodox Christian according to his faith, responsible for the death of people, let even an enemy?"
The patriarch wrote back, thanked Kalashnikov, and said that he "was an example of patriotism and a correct attitude toward the country". Kirill added about the design responsibility for the deaths by the rifle, "the church has a well-defined position when the weapon is defense of the Motherland, the Church supports its creators and the military, which use it."
Family.
Kalashnikov's father, Timofey Aleksandrovich Kalashnikov (1883–1930), was a peasant. He completed two grades of parochial school and could read and write. In 1901 he married Aleksandra Frolovna Kaverina (1884–1957), who was illiterate throughout her life. They had 19 children, but only eight survived to adult age; Kalashnikov was born 17th, and was close to death at age six.
In 1930, the government labeled Timofey Aleksandrovich a kulak, confiscated his property, and deported him to Siberia, along with most of the family. The eldest three siblings, daughters Agasha (b. 1905) and Anna and son Victor, were already married by 1930, and remained in Kuriya. After her husband's death in 1930, Aleksandra Frolovna married Efrem Kosach, a widower who had three children of his own.
Mikhail Kalashnikov married twice, the first time to Ekaterina Danilovna Astakhova of Altai Krai. He married the second time to Ekaterina Viktorovna Moiseyeva (1921–1977). She was an engineer and did much technical drawing work for her husband. They had four children: daughters Nelli (b. 1942), Elena (b. 1948) and Natalya (1953–1983), and a son Victor (b. 1942). Victor also became a prominent small arms designer.
Weapon designs.
During his career, Kalashnikov designed about 150 models of small weapons. The most famous of them are:
Awards and tribute.
"Incorporates information from the corresponding article in the Russian Wikipedia"

</doc>
<doc id="19537" url="http://en.wikipedia.org/wiki?curid=19537" title="MUD">
MUD

A MUD (; originally Multi-User Dungeon, with later variants Multi-User Dimension and Multi-User Domain), is a multiplayer real-time virtual world, usually text-based. MUDs combine elements of role-playing games, hack and slash, player versus player, interactive fiction, and online chat. Players can read or view descriptions of rooms, objects, other players, non-player characters, and actions performed in the virtual world. Players typically interact with each other and the world by typing commands that resemble a natural language.
Traditional MUDs implement a role-playing video game set in a fantasy world populated by fictional races and monsters, with players choosing classes in order to gain specific skills or powers. The objective of this sort of game is to slay monsters, explore a fantasy world, complete quests, go on adventures, create a story by roleplaying, and advance the created character. Many MUDs were fashioned around the dice-rolling rules of the "Dungeons & Dragons" series of games.
Such fantasy settings for MUDs are common, while many others have science fiction settings or are based on popular books, movies, animations, periods of history, worlds populated by anthropomorphic animals, and so on. Not all MUDs are games; some are designed for educational purposes, while others are purely chat environments, and the flexible nature of many MUD servers leads to their occasional use in areas ranging from computer science research to geoinformatics to medical informatics to analytical chemistry. MUDs have attracted the interest of academic scholars from many fields, including communications, sociology, law, and economics. At one time, there was interest from the United States military in using them for teleconferencing.
Most MUDs are run as hobbies and are free to players; some may accept donations or allow players to purchase virtual items, while others charge a monthly subscription fee. MUDs can be accessed via standard telnet clients, or specialized MUD clients which are designed to improve the user experience. Numerous games are listed at various web portals, such as The Mud Connector.
The history of modern massively multiplayer online role-playing games (MMORPGs) like "EverQuest" and "Ultima Online", and related virtual world genres such as the social virtual worlds exemplified by "Second Life", traces directly back to the MUD genre. Indeed, before the invention of the term MMORPG, games of this style were simply called graphical MUDs. A number of influential MMORPG designers began as and/or players (such as Raph Koster, Brad McQuaid, Matt Firor, and Brian Green) or were involved with early MUDs (like Mark Jacobs and J. Todd Coleman).
Origins.
"Colossal Cave Adventure", created in 1975 by Will Crowther on a DEC PDP-10 computer, was the first widely used adventure game. The game was significantly expanded in 1976 by Don Woods. Also called "Adventure", it contained many D&D features and references, including a computer controlled dungeon master.
Inspired by "Adventure", a group of students at MIT in the summer of 1977 wrote a game for the PDP-10 minicomputer; called "Zork", it became quite popular on the ARPANET. "Zork" was ported, under the filename DUNGEN ("dungeon"), to FORTRAN by a programmer working at DEC in 1978.
In 1978 Roy Trubshaw, a student at Essex University in the UK, started working on a multi-user adventure game in the MACRO-10 assembly language for a DEC PDP-10. He named the game "MUD" ("Multi-User Dungeon"), in tribute to the "Dungeon" variant of "Zork", which Trubshaw had greatly enjoyed playing. Trubshaw converted MUD to BCPL (the predecessor of C), before handing over development to Richard Bartle, a fellow student at Essex University, in 1980.
"MUD", better known as "Essex MUD" and "MUD1" in later years, ran on the Essex University network until late 1987, becoming the first Internet multiplayer online role-playing game in 1980, when Essex University connected its internal network to ARPANet. The game revolved around gaining points till one achieved the Wizard rank, giving the character immortality and special powers over mortals. The game became more widely accessible when a guest account was set up that allowed users on JANET (a British academic X.25 computer network) to connect on weekends and between the hours of 2 AM and 8 AM on weekdays. "MUD1" was reportedly closed down when Richard Bartle licensed "MUD1" to CompuServe, and was getting pressure from them to close "Essex MUD". This left "MIST", a derivative of "MUD1" with similar gameplay, as the only remaining MUD running on the Essex University network, becoming one of the first of its kind to attain broad popularity. "MIST" ran until the machine that hosted it, a PDP-10, was superseded in early 1991.
During the Christmas of 1985, Neil Newell, an avid "MUD1" player, started programming his own MUD called "SHADES" because "MUD1" was closed down during the holidays. Starting out as a hobby, "SHADES" became accessible in the UK as a commercial MUD via British Telecom's Prestel and Micronet networks. A scandal on "SHADES" led to the closure of Micronet, as described in Indra Sinha's net-memoir, "The Cybergypsies".
In 1985 Pip Cordrey gathered some people on a BBS he ran to create a "MUD1" clone that would run on a home computer. The tolkienesque MUD went live in 1986 and was named "MirrorWorld".
1985 also saw the creation of "Gods" by Ben Laurie, a "MUD1" clone that included online creation in its endgame. "Gods" became a commercial MUD in 1988.
In 1985 CompuNet started a project named "Multi-User Galaxy Game" as a Science Fiction alternative to "MUD1" which ran on their system at the time. When one of the two programmers left CompuNet, the remaining programmer, Alan Lenton, decided to rewrite the game from scratch and named it Federation II (at the time no Federation I existed). The MUD was officially launched in 1989. Federation II was later picked up by AOL, where it became known simply as "Federation: Adult Space Fantasy". Federation later left AOL to run on its own after AOL began offering unlimited service.
In 1978, around the same time Roy Trubshaw wrote MUD, Alan E. Klietz wrote a game called "Milieu" using Multi-Pascal on a CDC Cyber 6600 series mainframe which was operated by the Minnesota Educational Computing Consortium. Klietz ported "Milieu" to an IBM XT in 1983, naming the new port "Scepter of Goth". "Scepter" supported 10 to 16 simultaneous users, typically connecting in by modem. It was one of the first commercial MUDs; franchises were sold to a number of locations. "Scepter" was first owned and run by GamBit (of Minneapolis, Minnesota), founded by Bob Alberti. GamBit's assets were later sold to Interplay Productions. Interplay eventually went bankrupt.
In 1984, Mark Peterson wrote "The Realm of Angmar", beginning as a clone of "Scepter of Goth". In 1994, Peterson rewrote "The Realm of Angmar", adapting it to MS-DOS (the basis for many dial-in BBS systems), and renamed it "Swords of Chaos". For a few years this was a very popular form of MUD, hosted on a number of BBS systems, until widespread Internet access eliminated most BBSes. 
In 1984, Mark Jacobs created and deployed a commercial gaming site, "Gamers World". The site featured two games coded and designed by Jacobs, a MUD called "Aradath" (which was later renamed, upgraded and ported to "GEnie" as "Dragon's Gate") and a 4X science-fiction game called "Galaxy", which was also ported to "GEnie". At its peak, the site had about 100 monthly subscribers to both "Aradath" and "Galaxy". GEnie was shut down in the late 1980s, although "Dragon's Gate" was later brought to "America Online" before it was finally released on its own. Dragon's Gate was closed on February 10, 2007.
In the summer of 1980 University of Virginia classmates John Taylor and Kelton Flinn wrote "Dungeons of Kesmai", a six player game inspired by "Dungeons & Dragons" which used Roguelike ASCII graphics. They founded the Kesmai company in 1982 and in 1985 an enhanced version of "Dungeons of Kesmai", "Island of Kesmai", was launched on CompuServe. Later, its 2-D graphical descendant "Legends of Kesmai" was launched on AOL in 1996. The games were retired commercially in 2000.
The popularity of MUDs of the Essex University tradition escalated in the USA during the late 1980s when affordable personal computers with 300 to 2400 bit/s modems enabled role-players to log into multi-line Bulletin Board Systems and online service providers such as CompuServe. During this time it was sometimes said that MUD stands for "Multi Undergraduate Destroyer" due to their popularity among college students and the amount of time devoted to them.
Spread.
AberMUD.
The first popular MUD codebase was AberMUD, written in 1987 by Alan Cox, named after the University of Wales, Aberystwyth. Alan Cox had played the original University of Essex MUD, and the gameplay was heavily influenced by it. AberMUD was initially written in B for a Honeywell L66 mainframe under GCOS3/TSS. In late 1988 it was ported to C, which enabled it to spread rapidly to many Unix platforms upon its release in 1989. AberMUD's popularity resulted in several inspired works, the most notable of which were TinyMUD, LPMud, and DikuMUD.
TinyMUD.
"Monster" was a multi-user adventure game created by Richard Skrenta for the VAX and written in VMS Pascal. It was publicly released in November 1988. "Monster" was disk-based and modifications to the game were immediate. "Monster" pioneered the approach of allowing players to build the game world, setting new puzzles or creating dungeons for other players to explore. Monster, which comprised about 60,000 lines of code, had a lot of features which appeared to be designed to allow "Colossal Cave Adventure" to work in it. Though there never were many network-accessible Monster servers, it inspired James Aspnes to create a stripped down version of "Monster" which he called TinyMUD.
TinyMUD, written in C and released in late 1989, spawned a number of descendants, including TinyMUCK and TinyMUSH. TinyMUCK version 2 contained a full programming language named MUF (Multi-User Forth), while MUSH greatly expanded the command interface. To distance itself from the combat-oriented traditional MUDs it was said that the "D" in TinyMUD stood for Multi-User "Domain" or "Dimension"; this, along with the eventual popularity of acronyms other than MUD (such as MUCK, MUSH, MUSE, and so on) for this kind of server, led to the eventual adoption of the term MU* to refer to the TinyMUD family. UberMUD, UnterMUD, and MOO were inspired by TinyMUD but are not direct descendants.
LPMud.
In 1989 LPMud was developed by Lars Pensjö (hence the LP in LPMud). Pensjö had been an avid player of TinyMUD and AberMUD and wanted to create a world with the flexibility of TinyMUD and the gameplay of AberMUD. In order to accomplish this he wrote what is nowadays known as a virtual machine, which he called the LPMud driver, that ran the C-like LPC programming language used to create the game world. Pensjö's interest in LPMud eventually waned and development was carried on by others such as Jörn "Amylaar" Rennecke, Felix "Dworkin" Croes, Tim "Beek" Hollebeek and Lars Düning. During the early 1990s, LPMud was one of the most popular MUD codebases. Descendants of the original LPMud include MudOS, DGD, SWLPC, FluffOS, and the Pike programming language, the latter the work of long-time LPMud developer Fredrik "Profezzorn" Hübinette.
DikuMUD.
In 1990, the release of DikuMUD, which was inspired by AberMUD, led to a virtual explosion of hack and slash MUDs based upon its code. DikuMUD inspired numerous derivative codebases, including CircleMUD, Merc, ROM, SMAUG, and GodWars. The original Diku team comprised Sebastian Hammer, Tom Madsen, Katja Nyboe, Michael Seifert, and Hans Henrik Staerfeldt. DikuMUD had a key influence on the early evolution of the MMORPG genre, with "EverQuest" (created by avid DikuMUD player Brad McQuaid) displaying such Diku-like gameplay that Verant developers were made to issue a sworn statement that no actual DikuMUD code was incorporated.
Simutronics.
In 1987 David Whatley, having previously played "Scepter of Goth" and "Island of Kesmai", founded Simutronics with Tom and Susan Zelinski. In the same year they demonstrated a prototype of "GemStone" to GEnie. After a short-lived instance of "GemStone II", "GemStone III" was officially launched in February 1990. "GemStone III" became available on AOL in September 1995, followed by the release of "DragonRealms" in February 1996. By the end of 1997 "GemStone III" and "DragonRealms" had become the first and second most played games on AOL.
Gameplay.
The typical MUD will describe to you the room or area you are standing in, listing the objects, players and NPCs in the area, as well as all of the exits. To carry out a task the player would enter a text command such as take apple or attack dragon. Movement around the game environment is generally accomplished by entering the direction (or an abbreviation of it) in which the player wishes to move, for example typing north or just n would cause the player to exit the current area via the path to the north.
MUD clients often contain functions which make certain tasks within a MUD easier to carry out, for example commands buttons which you can click in order to move in a particular direction or to pick up an item. There are also tools available which add hotkey-activated macros to telnet and MUD clients giving the player the ability to move around the MUD using the arrow keys on their keyboard for example.
Style.
While there have been many variations in overall focus, gameplay and features in MUDs, some distinct sub-groups have formed that can be used to help categorize different game mechanics, game genres and non-game uses.
Hack and Slash MUDs.
Perhaps the most common approach to game design in MUDs is to loosely emulate the structure of a "Dungeons & Dragons" campaign focused more on fighting and advancement than role-playing. When these MUDs restrict player-killing in favor of player versus environment conflict and questing, they are labeled Hack and Slash MUDs. This may be considered particularly appropriate since, due to the room-based nature of traditional MUDs, ranged combat is typically difficult to implement, resulting in most MUDs equipping characters mainly with close-combat weapons. This style of game was also historically referred to within the MUD genre as "adventure games", but video gaming as a whole has developed a meaning of "adventure game" that is greatly at odds with this usage.
Player versus player MUDs.
Most MUDs restrict player versus player combat, often abbreviated as PK (Player Killing). This is accomplished through hard coded restrictions and various forms of social intervention. MUDs without these restrictions are commonly known as PK MUDs. Taking this a step further are MUDs devoted "solely" to this sort of conflict, called pure PK MUDs, the first of which was "Genocide" in 1992. "Genocide"‍‍ '​‍s ideas were influential in the evolution of player versus player online gaming.
Roleplaying MUDs.
Roleplaying MUDs, generally abbreviated as RP MUDs, encourage or enforce that players act out the role of their playing characters at all times. Some RP MUDs provide an immersive gaming environment, while others only provide a virtual world with no game elements. MUDs where roleplay is enforced and the game world is heavily computer-modeled are sometimes known as Roleplay Intensive MUDs, or RPIMUDs. In many cases, Role-Playing muds attempt to differentiate themselves from hack and slash types, by dropping the "MUD" name entirely, and instead using MUX (Multi User Experience) or MUSH (Multi User Shared Hallucination.)
Social MUDs.
Social MUDs de-emphasize game elements in favor of an environment designed primarily for socializing. They are differentiated from talkers by retaining elements beyond online chat, typically online creation as a community activity and some element of role-playing. Often such MUDs have broadly defined contingents of socializers and roleplayers. Server software in the TinyMUD family, or MU*, is traditionally used to implement social MUDs.
Talkers.
A less-known MUD variant is the talker, a variety of online chat environment typically based on server software like ew-too or NUTS. Most of the early Internet talkers were LPMuds with the majority of the complex game machinery stripped away, leaving just the communication commands. The first Internet talker was "Cat Chat" in 1990. Avid users of talkers are called spods.
Educational MUDs.
Taking advantage of the flexibility of MUD server software, some MUDs are designed for educational purposes rather than gaming or chat. "MicroMUSE" is considered by some to have been the first educational MUD, but it can be argued that its evolution into this role was not complete until 1994, which would make the first of many educational MOOs, "Diversity University" in 1993, also the first educational MUD. The MUD medium lends itself naturally to constructionist learning pedagogical approaches. The Mud Institute (TMI) was an LPMud opened in February 1992 as a gathering place for people interested in developing LPMud and teaching LPC after it became clear that Lars Pensjö had lost interest in the project. TMI focussed on both the LPMud driver and library, the driver evolving into MudOS, the TMI Mudlib was never officially released, but was influential in the development of other libraries.
Graphical MUDs.
A graphical MUD is a MUD that uses computer graphics to represent parts of the virtual world and its visitors. A prominent early graphical MUD was "Habitat", written by Randy Farmer and Chip Morningstar for Lucasfilm in 1985. Graphical MUDs require players to download a special client and the game's artwork. They range from simply enhancing the user interface to simulating 3D worlds with visual spatial relationships and customized avatar appearances.
Games such as "Meridian 59", "EverQuest", "Ultima Online" and "Dark Age of Camelot" were routinely called graphical MUDs in their earlier years. "RuneScape" was actually originally intended to be a "text-based" MUD, but graphics were added very early in development. However, with the increase in computing power and Internet connectivity during the late nineties, and the shift of online gaming to the mass market, the term "graphical MUD" fell out of favor, being replaced by MMORPG, Massively Multiplayer Online Role-Playing Game, a term coined by Richard Garriott in 1997.
Psychology and engagement.
Sherry Turkle developed a theory that the constant use (and in many cases, overuse) of MUDs allows users to develop different personalities in their environments. She uses examples, dating back to the text-based MUDs of the mid-1990s, showing college students who simultaneously live different lives through characters in separate MUDs, up to three at a time, all while doing schoolwork. The students claimed that it was a way to "shut off" their own lives for a while and become part of another reality. Turkle claims that this could present a psychological problem of identity for today's youths.
"A Story About A Tree" is a short essay written by Raph Koster regarding the death of a "LegendMUD" player named Karyn, raising the subject of inter-human relationships in virtual worlds.
Observations of MUD-play show styles of play that can be roughly categorized. Achievers focus on concrete measurements of success such as experience points, levels, and wealth; Explorers investigate every nook and cranny of the game, and evaluate different game mechanical options; Socializers devote most of their energy to interacting with other players; and then there are Killers who focus on interacting negatively with other players, if permitted, killing the other characters or otherwise thwarting their play. Few players play only one way, or play one way all the time; most exhibit a diverse style. According to Richard Bartle, "People go there as part of a hero's journey—a means of self-discovery".
Research has suggested that various factors combine in MUDs to provide users with a sense of "presence" rather than simply communication.
Grammatical usage and derived terms.
As a noun, the word MUD is variously written MUD, Mud, and mud, depending on speaker and context. It is also used as a verb, with to mud meaning to play or interact with a MUD and mudding referring to the act of doing so. A mudder is, naturally, one who MUDs. Compound words and portmanteaux such as mudlist, mudsex, and mudflation are also regularly coined. Puns on the "wet dirt" meaning of "mud" are endemic, as with, for example, the names of the ROM (Rivers of MUD), MUCK, MUSH, and CoffeeMUD codebases and the MUD "Muddy Waters".

</doc>
<doc id="19541" url="http://en.wikipedia.org/wiki?curid=19541" title="Muslim">
Muslim

A Muslim, sometimes spelled Moslem, relates to a person who follows the religion of Islam, a monotheistic and Abrahamic religion based on the Quran. Muslims consider the Quran to be the verbatim word of God as revealed to the Islamic prophet Muhammad. They also follow the teachings and practices of Muhammad as recorded in traditional accounts called "hadith". "Muslim" is an Arabic word meaning "one who submits (to God)". A female Muslim is sometimes called a "Muslimah". There are customs holding that a man and woman or teenager and adolescent above the age of fifteen of a lunar or solar calendar who possesses the faculties of rationality, logic or sanity, but misses numerous successive Jumu'ahs without a valid excuse, no longer qualifies as a Muslim. 
Most Muslims will accept anyone who has publicly pronounced the declaration of faith ("shahadah") as a Muslim. The "shahadah" states:
There is no god but God, Muhammad is the messenger of God.
Islamic beliefs commonly held by Muslims include: that God (Arabic: الله‎ "Allāh") is eternal, transcendent and absolutely one (monotheism); that God is incomparable, self-sustaining and neither begets nor was begotten; that Islam is the complete and universal version of a primordial faith that has been revealed before through many prophets including Abraham, Moses, Ishmael and Jesus; that these previous messages and revelations have been partially changed or corrupted over time and that the Qur'an is the final unaltered revelation from God (The Final Testament).
The religious practices of Muslims are enumerated in the Five Pillars of Islam, which, in addition to Shahadah, consist of daily prayers (salat), fasting during the Islamic month of Ramzan/ Ramadan (sawm), almsgiving (zakat), and the pilgrimage to Mecca (hajj) at least once in a lifetime.
Lexicology.
The word "muslim" (Arabic: مسلم‎, ]; , , or "moslem" , ) is the participle of the same verb of which "islām" is the infinitive, based on the triliteral "S-L-M" "to be whole, intact". It is a liturgical phonology that is formed from two components; the pronoun prefix "mu" and the triconsonantal root "slim". A female adherent is a "muslima" (Arabic: مسلمة‎). The plural form in Arabic is "muslimūn" (مسلمون), and its feminine equivalent is "muslimāt" (مسلمات). The Arabic form "muslimun" is the stem IV participle of the triliteral "S-L-M". A female Muslim can variously be called in their etymologically Arabic form of "Muslimah", also spelled "Muslima", "Muslimette", "Muslimess" or simple the standard term of Muslim. General alternative epithets or designations given to Muslims include "mosquegoer", "masjidgoer", or archaic, dated and obsolete terms such as "Muslimite" or "Muslimist".
The ordinary word in English is "Muslim". It is sometimes transliterated as "Moslem", which is an older spelling. The word "Mosalman" (Persian: مسلمان‎, alternatively "Mussalman") is a common equivalent for "Muslim" used in Central Asia. Until at least the mid-1960s, many English-language writers used the term "Mohammedans" or "Mahometans". Although such terms were not necessarily intended to be pejorative, Muslims argue that the terms are offensive because they allegedly imply that Muslims worship Muhammad rather than God.
Meaning.
In defining "Muslim", the Sufi spiritual leader Ibn Arabi said:
A Muslim is a person who has dedicated his worship exclusively to God..."Islam" means making one's religion and faith God's alone.
Used to describe earlier prophets in the Qur'an.
The Qur'an describes many prophets and messengers as well as their respective followers as Muslim: Adam, Noah, Abraham, Jacob, Moses and Jesus and his apostles are all considered to be Muslims in the Qur'an. The Qur'an states that these men were Muslims because they submitted to God, preached His message and upheld His values, which included praying, charity, fasting and pilgrimage. Thus, in Surah 3:52 of the Qur'an, Jesus' disciples tell Jesus, "We believe in God; and you be our witness that we are Muslims ("wa-shahad be anna muslimūn")." In Muslim belief, before the Qur'an, God had given the Torah to Moses, the Psalms to David and the Gospel to Jesus, who are all considered important Muslim prophets.
Demographics.
About 13% of Muslims live in Indonesia, the largest Muslim country, 25% in South Asia, 20% in the Middle East and North Africa, 2% in Central Asia, 4% in the remaining South East Asian countries, and 15% in Sub-saharan Africa. Sizable communities are also found in China and Russia, and parts of the Caribbean. The country with the highest proportion of self-described Muslims as a proportion of its total population is Morocco. Converts and immigrant communities are found in almost every part of the world.
The majority of Muslims are Sunni, being over 75–90% of all Muslims. The second and third largest sects, Shia and Ahmadiyya, make up 10–20%, and 1% respectively. The most populous Muslim-majority country is Indonesia home to 12.7% of the world's Muslims followed by Pakistan (11.0%), Bangladesh (9.2%), and Egypt (4.9%). Sizable minorities are also found in India, China, Russia, Ethiopia, Americas, Australia and parts of Europe. With about 1.6 billion followers, almost a quarter of earth's population, Islam is the second-largest and one of the fastest-growing religions in the world.

</doc>
<doc id="19542" url="http://en.wikipedia.org/wiki?curid=19542" title="MUSH">
MUSH

In multiplayer online games, a MUSH (a backronymed pun on MUD most often expanded as Multi-User Shared Hallucination, though Multi-User Shared Hack, Habitat, and Holodeck are also observed) is a text-based online social medium to which multiple users are connected at the same time. MUSHes are often used for online social intercourse and role-playing games, although the first forms of MUSH do not appear to be coded specifically to implement gaming activity. MUSH software was originally derived from MUDs; today's two major MUSH variants are descended from TinyMUD, which was fundamentally a social game.
MUSH has forked over the years and there are now different varieties with different features, although most have strong similarities and one who is fluent in coding one variety can switch to coding for the other with only a little effort. The source code for most widely used MUSH servers is open source and available from its current maintainers.
A primary feature of MUSH codebases that tends to distinguish it from other multi-user environments is the ability, by default, of any player to extend the world by creating new rooms or objects and specifying their behavior in the MUSH's internal scripting language. Another is the default lack of much player or administrative hierarchy imposed by the server itself. Over the years, both of these traits have become less pronounced, as many server administrators choose to eliminate or heavily restrict player-controlled building, and several games have custom coded systems to restore more of a hierarchal system.
The programming language for MUSH, usually referred to as "MUSHcode" or "softcode" (to distinguish it from "hardcode" – the language in which the MUSH server itself is written) was developed by Larry Foard. TinyMUSH started life as a set of enhancements to the original TinyMUD code. "MUSHcode" is similar in syntax to Lisp. Most customization is done in "softcode" rather than by directly modifying the hardcode.
Roleplay on MUSHes.
Traditionally, roleplay consists of a series of "poses". Each character makes a "pose" – that is, writes a description of speech, actions, etc. which the character performs. Special commands allow players to print OOC (out of character) messages, distinguished by a prefixed tag from IC (in character) action. This medium borrows traits from both improvisational stage acting and writing. Roleplaying is one of the primary activities of MUSHes, along with socializing.
There is nothing in the code base that restricts a new MUSH from being a traditional hack-and-slash MUD-style game. However, the earliest uses of MUSH servers were for roleplaying and socializing, and these early trends have largely governed their descendants.
A large number of roleplaying MUSHes have custom combat systems and other tools coded by their administrators in order to further encourage roleplay. However, as roleplay is the primary goal, many MUSHes have varying ideas of how these programs are used.
Administration of MUSHes.
All MUSH servers provide a flag that, when set on a player, bestows the ability to view and modify nearly everything in the game's database. Such players are usually called Wizards, and typically form the basis for the MUSH administration.
Although MUSH servers do not impose strong administrative hierarchies, most MUSH games establish additional levels of management besides Wizards. Some do so on a purely organizational basis, naming some Wizards "Head Wizards" or "Junior Wizards" or assigning sphere of responsibility to Wizards, despite the technical equality of their abilities in the game world. Others provide finer-grained control over capabilities that can be assigned to players so that some players can be granted the ability to view, but not modify, the entire game world, or to perform limited modifications. Other levels of power can include added control over one's own character, or fewer limits on resources. PennMUSH, TinyMUSH, and TinyMUX include the "Royalty" flag, which gives a player the powers to do most anything that doesn't involve modifying the database. RhostMUSH has a wide array of staff flags that differ in many ways from its sister servers.
MUSH Software.
Maintainers and developers of MUSH servers have traditionally shared ideas with one another, so most MUSH servers include concepts or code developed originally in other servers. There is particular interest in ensuring that common MUSHcode features work similarly across servers.
PennMUSH, TinyMUSH, TinyMUX and RhostMUSH are all open-source MUSH servers. Some enthusiasts may exclude one or more of the above on the basis of distribution method, name, or parentage, but all are free-form MUSH servers. Differences in the software tend to focus more on the administrative or softcode side (slightly different function syntax; or different functions altogether; more, or less, administrative controls). The set of commands that players use to interface to the game are essentially standard amongst servers bearing the appellation "MUSH".

</doc>
<doc id="19544" url="http://en.wikipedia.org/wiki?curid=19544" title="Microevolution">
Microevolution

Microevolution is the change in allele frequencies that occur over time within a population. This change is due to four different processes: mutation, selection (natural and artificial), gene flow, and genetic drift.
Population genetics is the branch of biology that provides the mathematical structure for the study of the process of microevolution. Ecological genetics concerns itself with observing microevolution in the wild. Typically, observable instances of evolution are examples of microevolution; for example, bacterial strains that have antibiotic resistance.
Microevolution over time may lead to speciation or the appearance of novel structure, sometimes classified as macroevolution. Macro and microevolution describe fundamentally identical processes on different scales.
Contrast with macroevolution.
Microevolution can be contrasted with macroevolution, which is the occurrence of large-scale changes in gene frequencies in a population over a geological time period (i.e. consisting of either rapid or extended microevolution). The difference is largely one of approach. Microevolution is reductionist, but macroevolution is holistic. Each approach offers different insights into the evolution process. Macroevolution can be seen as the sum of periods of microevolution, and thus the two are qualitatively identical while being quantitatively different.
The four processes.
Mutation.
Mutations are changes in the DNA sequence of a cell's genome and are caused by radiation, viruses, transposons and mutagenic chemicals, as well as errors that occur during meiosis or DNA replication. Errors are introduced particularly often in the process of DNA replication, in the polymerization of the second strand. These errors can also be induced by the organism itself, by cellular processes such as hypermutation. 
During the process of DNA replication, errors occasionally occur in the polymerization of the second strand. These errors, called mutations, can have an impact on the phenotype of an organism, especially if they occur within the protein coding sequence of a gene. Error rates are usually very low—1 error in every 10–100 million bases—due to the "proofreading" ability of DNA polymerases. (Without proofreading error rates are a thousandfold higher; because many viruses rely on DNA and RNA polymerases that lack proofreading ability, they experience higher mutation rates.) Processes that increase the rate of changes in DNA are called mutagenic: mutagenic chemicals promote errors in DNA replication, often by interfering with the structure of base-pairing, while UV radiation induces mutations by causing damage to the DNA structure. Chemical damage to DNA occurs naturally as well, and cells use DNA repair mechanisms to repair mismatches and breaks in DNA—nevertheless, the repair sometimes fails to return the DNA to its original sequence.
In organisms that use chromosomal crossover to exchange DNA and recombine genes, errors in alignment during meiosis can also cause mutations. Errors in crossover are especially likely when similar sequences cause partner chromosomes to adopt a mistaken alignment; this makes some regions in genomes more prone to mutating in this way. These errors create large structural changes in DNA sequence—duplications, inversions or deletions of entire regions, or the accidental exchanging of whole parts between different chromosomes (called translocation).
Mutation can result in several different types of change in DNA sequences; these can either have no effect, alter the product of a gene, or prevent the gene from functioning. Studies in the fly "Drosophila melanogaster" suggest that if a mutation changes a protein produced by a gene, this will probably be harmful, with about 70 percent of these mutations having damaging effects, and the remainder being either neutral or weakly beneficial. Due to the damaging effects that mutations can have on cells, organisms have evolved mechanisms such as DNA repair to remove mutations. Therefore, the optimal mutation rate for a species is a trade-off between costs of a high mutation rate, such as deleterious mutations, and the metabolic costs of maintaining systems to reduce the mutation rate, such as DNA repair enzymes. Viruses that use RNA as their genetic material have rapid mutation rates, which can be an advantage since these viruses will evolve constantly and rapidly, and thus evade the defensive responses of e.g. the human immune system.
Mutations can involve large sections of DNA becoming duplicated, usually through genetic recombination. These duplications are a major source of raw material for evolving new genes, with tens to hundreds of genes duplicated in animal genomes every million years. Most genes belong to larger families of genes of shared ancestry. Novel genes are produced by several methods, commonly through the duplication and mutation of an ancestral gene, or by recombining parts of different genes to form new combinations with new functions.
Here, domains act as modules, each with a particular and independent function, that can be mixed together to produce genes encoding new proteins with novel properties. For example, the human eye uses four genes to make structures that sense light: three for color vision and one for night vision; all four arose from a single ancestral gene. Another advantage of duplicating a gene (or even an entire genome) is that this increases redundancy; this allows one gene in the pair to acquire a new function while the other copy performs the original function. Other types of mutation occasionally create new genes from previously noncoding DNA.
Selection.
"Selection" is the process by which heritable traits that make it more likely for an organism to survive and successfully reproduce become more common in a population over successive generations.
It is sometimes valuable to distinguish between naturally occurring selection, natural selection, and selection that is a manifestation of choices made by humans, artificial selection. This distinction is rather diffuse. Natural selection is nevertheless the dominant part of selection.
The natural genetic variation within a population of organisms means that some individuals will survive more successfully than others in their current environment. Factors which affect reproductive success are also important, an issue which Charles Darwin developed in his ideas on sexual selection.
Natural selection acts on the phenotype, or the observable characteristics of an organism, but the genetic (heritable) basis of any phenotype which gives a reproductive advantage will become more common in a population (see allele frequency). Over time, this process can result in adaptations that specialize organisms for particular ecological niches and may eventually result in the speciation (the emergence of new species).
Natural selection is one of the cornerstones of modern biology. The term was introduced by Darwin in his groundbreaking 1859 book "On the Origin of Species", in which natural selection was described by analogy to artificial selection, a process by which animals and plants with traits considered desirable by human breeders are systematically favored for reproduction. The concept of natural selection was originally developed in the absence of a valid theory of heredity; at the time of Darwin's writing, nothing was known of modern genetics. The union of traditional Darwinian evolution with subsequent discoveries in classical and molecular genetics is termed the "modern evolutionary synthesis". Natural selection remains the primary explanation for adaptive evolution.
Genetic drift.
"Genetic drift" is the change in the relative frequency in which a gene variant (allele) occurs in a population due to random sampling. That is, the alleles in the offspring in the population are a random sample of those in the parents. And chance has a role in determining whether a given individual survives and reproduces. A population's allele frequency is the fraction or percentage of its gene copies compared to the total number of gene alleles that share a particular form.
Genetic drift is an evolutionary process which leads to changes in allele frequencies over time. It may cause gene variants to disappear completely, and thereby reduce genetic variability. In contrast to natural selection, which makes gene variants more common or less common depending on their reproductive success, the changes due to genetic drift are not driven by environmental or adaptive pressures, and may be beneficial, neutral, or detrimental to reproductive success.
The effect of genetic drift is larger in small populations, and smaller in large populations. Vigorous debates wage among scientists over the relative importance of genetic drift compared with natural selection. Ronald Fisher held the view that genetic drift plays at the most a minor role in evolution, and this remained the dominant view for several decades. In 1968 Motoo Kimura rekindled the debate with his neutral theory of molecular evolution which claims that most of the changes in the genetic material are caused by genetic drift. The predictions of neutral theory, based on genetic drift, do not fit recent data on whole genomes well: these data suggest that the frequencies of neutral alleles change primarily due to selection at linked sites, rather than due to genetic drift by means of sampling error.
Gene flow.
Gene flow is the exchange of genes between populations, which are usually of the same species. Examples of gene flow within a species include the migration and then breeding of organisms, or the exchange of pollen. Gene transfer between species includes the formation of hybrid organisms and horizontal gene transfer.
Migration into or out of a population can change allele frequencies, as well as introducing genetic variation into a population. Immigration may add new genetic material to the established gene pool of a population. Conversely, emigration may remove genetic material. As barriers to reproduction between two diverging populations are required for the populations to become new species, gene flow may slow this process by spreading genetic differences between the populations. Gene flow is hindered by mountain ranges, oceans and deserts or even man-made structures such as the Great Wall of China, which has hindered the flow of plant genes.
Depending on how far two species have diverged since their most recent common ancestor, it may still be possible for them to produce offspring, as with horses and donkeys mating to produce mules. Such hybrids are generally infertile, due to the two different sets of chromosomes being unable to pair up during meiosis. In this case, closely related species may regularly interbreed, but hybrids will be selected against and the species will remain distinct. However, viable hybrids are occasionally formed and these new species can either have properties intermediate between their parent species, or possess a totally new phenotype. The importance of hybridization in creating new species of animals is unclear, although cases have been seen in many types of animals, with the gray tree frog being a particularly well-studied example.
Hybridization is, however, an important means of speciation in plants, since polyploidy (having more than two copies of each chromosome) is tolerated in plants more readily than in animals. Polyploidy is important in hybrids as it allows reproduction, with the two different sets of chromosomes each being able to pair with an identical partner during meiosis. Polyploid hybrids also have more genetic diversity, which allows them to avoid inbreeding depression in small populations.
Horizontal gene transfer is the transfer of genetic material from one organism to another organism that is not its offspring; this is most common among bacteria. In medicine, this contributes to the spread of antibiotic resistance, as when one bacteria acquires resistance genes it can rapidly transfer them to other species. Horizontal transfer of genes from bacteria to eukaryotes such as the yeast "Saccharomyces cerevisiae" and the adzuki bean beetle "Callosobruchus chinensis" may also have occurred. An example of larger-scale transfers are the eukaryotic bdelloid rotifers, which appear to have received a range of genes from bacteria, fungi, and plants. Viruses can also carry DNA between organisms, allowing transfer of genes even across biological domains. Large-scale gene transfer has also occurred between the ancestors of eukaryotic cells and prokaryotes, during the acquisition of chloroplasts and mitochondria.
"Gene flow" is the transfer of alleles from one population to another.
Migration into or out of a population may be responsible for a marked change in allele frequencies. Immigration may also result in the addition of new genetic variants to the established gene pool of a particular species or population.
There are a number of factors that affect the rate of gene flow between different populations. One of the most significant factors is mobility, as greater mobility of an individual tends to give it greater migratory potential. Animals tend to be more mobile than plants, although pollen and seeds may be carried great distances by animals or wind.
Maintained gene flow between two populations can also lead to a combination of the two gene pools, reducing the genetic variation between the two groups. It is for this reason that gene flow strongly acts against speciation, by recombining the gene pools of the groups, and thus, repairing the developing differences in genetic variation that would have led to full speciation and creation of daughter species.
For example, if a species of grass grows on both sides of a highway, pollen is likely to be transported from one side to the other and vice versa. If this pollen is able to fertilise the plant where it ends up and produce viable offspring, then the alleles in the pollen have effectively been able to move from the population on one side of the highway to the other.
Origin and extended use of the term.
Origin.
The term "microevolution" was first used by botanist Robert Greenleaf Leavitt in the journal "Botanical Gazette" in 1909, addressing what he called the "mystery" of how formlessness gives rise to form.
However, Leavitt was using the term to describe what we would now call developmental biology; it was not until Russian Entomologist Yuri Filipchenko used the terms "macroevolution" and "microevolution" in 1927 in his German language work, "Variabilität und Variation", that it attained its modern usage. The term was later brought into the English-speaking world by Theodosius Dobzhansky in his book Genetics and the Origin of Species (1937).
Use in Creationism.
In young Earth creationism and baraminology a central tenet is that evolution can explain diversity in a limited number of created kinds which can interbreed (which they call "microevolution") while the formation of new "kinds" (which they call "macroevolution") is impossible. This acceptance of "microevolution" only within a "kind" is also typical of old Earth creationism.
Scientific organizations such as the American Association for the Advancement of Science describe microevolution as small scale change within species, and macroevolution as the formation of new species, but otherwise not being different from microevolution. In macroevolution, an accumulation of microevolutionary changes leads to speciation. The main difference between the two processes is that one occurs within a few generations, whilst the other takes place over thousands of years (i.e. a quantitative difference). Essentially they describe the same process; although evolution beyond the species level results in beginning and ending generations which could not interbreed, the intermediate generations could.
Opponents to creationism argue that changes in the number of chromosomes can be accounted for by intermediate stages in which a single chromosome divides in generational stages, or multiple chromosomes fuse, and cite the chromosome difference between humans and the other great apes as an example. Creationists insist that since the actual divergence between the other great apes and humans was not observed, the evidence is circumstantial.
Describing the fundamental similarity between macro and microevolution in his authoritative textbook "Evolutionary Biology," biologist Douglas Futuyma writes,
Contrary to the claims of some antievolution proponents, evolution of life forms beyond the species level (i.e. speciation) has indeed been observed and documented by scientists on numerous occasions. In creation science, creationists accepted speciation as occurring within a "created kind" or "baramin", but objected to what they called "third level-macroevolution" of a new genus or higher rank in taxonomy. There is ambiguity in the ideas as to where to draw a line on "species", "created kinds", and what events and lineages fall within the rubric of microevolution or macroevolution.

</doc>
<doc id="19545" url="http://en.wikipedia.org/wiki?curid=19545" title="MySQL">
MySQL

MySQL ( "My S-Q-L", officially, but also called "My Sequel") is (as of 2013[ [update]]) the world's second most widely used relational database management system (RDBMS) and most widely used open-source RDBMS. It is named after co-founder Michael Widenius's daughter, My. The SQL acronym stands for Structured Query Language.
The MySQL development project has made its source code available under the terms of the GNU General Public License, as well as under a variety of proprietary agreements. MySQL was owned and sponsored by a single for-profit firm, the Swedish company MySQL AB, now owned by Oracle Corporation.
MySQL is a popular choice of database for use in web applications, and is a central component of the widely used LAMP open source web application software stack (and other 'AMP' stacks). LAMP is an acronym for "Linux, Apache, MySQL, Perl/PHP/Python." Free-software-open source projects that require a full-featured database management system often use MySQL.
For proprietary use, several paid editions are available, and offer additional functionality. Applications which use MySQL databases include: TYPO3, MODx, Joomla, WordPress, phpBB, MyBB, Drupal and other software. MySQL is also used in many high-profile, large-scale websites, including Google (though not for searches), Facebook, Twitter, Flickr, and YouTube.
Interfaces.
MySQL is a relational database management system (RDBMS), and ships with no GUI tools to administer MySQL databases or manage data contained within the databases. Users may use the included command line tools, or use MySQL "front-ends", desktop software and web applications that create and manage MySQL databases, build database structures, back up data, inspect status, and work with data records. The official set of MySQL front-end tools, MySQL Workbench is actively developed by Oracle, and is freely available for use.
Graphical.
The official MySQL Workbench is a free integrated environment developed by MySQL AB, that enables users to graphically administer MySQL databases and visually design database structures. MySQL Workbench replaces the previous package of software, MySQL GUI Tools. Similar to other third-party packages, but still considered the authoritative MySQL front end, MySQL Workbench lets users manage database design & modeling, SQL development (replacing MySQL Query Browser) and Database administration (replacing MySQL Administrator).
MySQL Workbench is available in two editions, the regular free and open source "Community Edition" which may be downloaded from the MySQL website, and the proprietary "Standard Edition" which extends and improves the feature set of the Community Edition.
Third-party proprietary and free graphical administration applications (or "front ends") are available that integrate with MySQL and enable users to work with database structure and data visually. Some well-known front ends, in alphabetical order, are:
Other available proprietary MySQL front ends include dbForge Studio for MySQL, DBStudio, Epictetus, Microsoft Access, Oracle SQL Developer, SchemaBank, SQLPro SQL Client, Toad Data Modeler and DaDaBIK.
Command line.
MySQL ships with many command line tools, from which the main interface is 'mysql' client. Third parties have also developed tools to manage MySQL servers.
Programming.
MySQL works on many system platforms, including AIX, BSDi, FreeBSD, HP-UX, eComStation, i5/OS, IRIX, Linux, OS X, Microsoft Windows, NetBSD, Novell NetWare, OpenBSD, OpenSolaris, OS/2 Warp, QNX, Oracle Solaris, Symbian, SunOS, SCO OpenServer, SCO UnixWare, Sanos and Tru64. A port of MySQL to OpenVMS also exists.
MySQL is written in C and C++. Its SQL parser is written in yacc, but it uses a home-brewed lexical analyzer. Many programming languages with language-specific APIs include libraries for accessing MySQL databases. These include MySQL Connector/Net for integration with Microsoft's Visual Studio (languages such as C# and VB are most commonly used) and the JDBC driver for Java. In addition, an ODBC interface called MyODBC allows additional programming languages that support the ODBC interface to communicate with a MySQL database, such as ASP or ColdFusion. The HTSQL – URL-based query method also ships with a MySQL adapter, allowing direct interaction between a MySQL database and any web client via structured URLs.
Features.
MySQL is offered under two different editions: the open source MySQL Community Server and the proprietary Enterprise Server. MySQL Enterprise Server is differentiated by a series of proprietary extensions which install as server plugins, but otherwise shares the version numbering system and is built from the same code base.
Major features as available in MySQL 5.6:
The developers release minor updates of the MySQL Server approximately every two months. The sources can be obtained from MySQL's website or from MySQL's Bazaar repository, both under the GPL license.
Limitations.
Like other SQL databases, MySQL does not currently comply with the full SQL standard for some of the implemented functionality, including foreign key references when using some storage engines other than the default of InnoDB, and check constraints.
Up until MySQL 5.7, triggers are limited to one per action / timing, meaning that at most one trigger can be defined to be executed after an INSERT operation, and one before INSERT on the same table.
No triggers can be defined on views.
MySQL, like most other transactional relational databases, is strongly limited by hard disk performance. This is especially true in terms of write latency. Given the recent appearance (as of 2012[ [update]]) of very affordable consumer-grade SATA-interface solid-state drives that offer zero mechanical latency, a fivefold speedup over even an eight-drive RAID array can be had for a smaller investment.
MySQL database's inbuilt functions like UNIX_TIMESTAMP() will return 0 after 03:14:07 UTC on 19 January 2038.
Deployment.
MySQL can be built and installed manually from source code, but this can be tedious so it is more commonly installed from a binary package unless special customizations are required. On most Linux distributions the package management system can download and install MySQL with minimal effort, though further configuration is often required to adjust security and optimization settings.
Though MySQL began as a low-end alternative to more powerful proprietary databases, it has gradually evolved to support higher-scale needs as well. It is still most commonly used in small to medium scale single-server deployments, either as a component in a LAMP-based web application or as a standalone database server. Much of MySQL's appeal originates in its relative simplicity and ease of use, which is enabled by an ecosystem of open source tools such as phpMyAdmin.
In the medium range, MySQL can be scaled by deploying it on more powerful hardware, such as a multi-processor server with gigabytes of memory.
There are however limits to how far performance can scale on a single server ('scaling up'), so on larger scales, multi-server MySQL ('scaling out') deployments are required to provide improved performance and reliability. A typical high-end configuration can include a powerful master database which handles data write operations and is replicated to multiple slaves that handle all read operations. The master server synchronizes continually with its slaves so in the event of failure a slave can be promoted to become the new master, minimizing downtime. Further improvements in performance can be achieved by caching the results from database queries in memory using memcached, or breaking down a database into smaller chunks called shards which can be spread across a number of distributed server clusters.
High availability.
Ensuring high availability requires a certain amount of redundancy in the system. For database systems, the redundancy traditionally takes the form of having a primary server acting as a master, and using replication to keep secondaries available to take over in case the primary fails. This means that the "server" that the application connects to is in reality a collection of servers, not a single server. In a similar manner, if the application is using a sharded database, it is in reality working with a collection of servers, not a single server. In this case, a collection of servers is usually referred to as a "farm."
One of the projects aiming to provide high availability for MySQL is "MySQL Fabric", an integrated system for managing a collection of MySQL servers, and a framework on top of which high availability and database sharding is built. MySQL Fabric is open-source and is intended to be extensible, easy to use, and to support procedure execution even in the presence of failure, providing an execution model usually called "resilient execution." MySQL client libraries are extended so they are hiding the complexities of handling failover in the event of a server failure, as well as correctly dispatching transactions to the shards. As of September 2013, there is currently support for Fabric-aware versions of Connector/J, Connector/PHP, Connector/Python, as well as some rudimentary support for Hibernate and Doctrine. As of May 2014, MySQL Fabric is in the general availability stage of development.
Cloud deployment.
MySQL can also be run on cloud computing platforms such as Amazon EC2. Listed below are some common deployment models for MySQL on the cloud:
Community.
The MySQL server software itself and the client libraries use dual-licensing distribution. They are offered under GPL version 2, beginning from 28 June 2000 (which in 2009 has been extended with a FLOSS License Exception) or to use a proprietary license.
Support can be obtained from the official manual. Free support additionally is available in different IRC channels and forums. Oracle offers paid support via its MySQL Enterprise products. They differ in the scope of services and in price. Additionally, a number of third party organisations exist to provide support and services, including SkySQL Ab and Percona.
MySQL has received positive reviews, and reviewers noticed it "performs extremely well in the average case." and that the "developer interfaces are there, and the documentation (not to mention feedback in the real world via Web sites and the like) is very, very good". It has also been tested to be a "fast, stable and true multi-user, multi-threaded sql database server".
History.
MySQL was created by a Swedish company, MySQL AB, founded by David Axmark, Allan Larsson and Michael "Monty" Widenius. The first version of MySQL appeared on 23 May 1995. It was initially created for personal usage from mSQL based on the low-level language ISAM, which the creators considered too slow and inflexible. They created a new SQL interface, while keeping the same API as mSQL. By keeping the API consistent with the mSQL system, many developers were able to use MySQL instead of the (proprietarily licensed) mSQL antecedent.
Legal and acquisition impacts.
On 15 June 2001, NuSphere sued MySQL AB, TcX DataKonsult AB and its original authors Michael ("Monty") Widenius and David Axmark in U.S District Court in Boston for "breach of contract, tortious interference with third party contracts and relationships and unfair competition".
In 2002, MySQL AB sued Progress NuSphere for copyright and trademark infringement in United States district court. NuSphere had allegedly violated MySQL's copyright by linking MySQL's GPL'ed code with NuSphere Gemini table without being in compliance with the license. After a preliminary hearing before Judge Patti Saris on 27 February 2002, the parties entered settlement talks and eventually settled. After the hearing, FSF commented that "Judge Saris made clear that she sees the GNU GPL to be an enforceable and binding license."
In October 2005, Oracle Corporation acquired Innobase OY, the Finnish company that developed the third-party InnoDB storage engine that allows MySQL to provide such functionality as transactions and foreign keys. After the acquisition, an Oracle press release mentioned that the contracts that make the company's software available to MySQL AB would be due for renewal (and presumably renegotiation) some time in 2006. During the MySQL Users Conference in April 2006, MySQL issued a press release that confirmed that MySQL and Innobase OY agreed to a "multi-year" extension of their licensing agreement.
In February 2006, Oracle Corporation acquired Sleepycat Software, makers of the Berkeley DB, a database engine providing the basis for another MySQL storage engine. This had little effect, as Berkeley DB was not widely used, and was dropped (due to lack of use) in MySQL 5.1.12, a pre-GA release of MySQL 5.1 released in October 2006.
In January 2008, Sun Microsystems bought MySQL for $1 billion.
In April 2009, Oracle Corporation entered into an agreement to purchase Sun Microsystems, then owners of MySQL copyright and trademark. Sun's board of directors unanimously approved the deal, it was also approved by Sun's shareholders, and by the U.S. government on 20 August 2009. On 14 December 2009, Oracle pledged to continue to enhance MySQL as it had done for the previous four years.
A movement against Oracle's acquisition of MySQL, to "Save MySQL" from Oracle was started by one of the MySQL founders, Monty Widenius. The petition of 50,000+ developers and users called upon the European Commission to block approval of the acquisition. At the same time, several Free Software opinion leaders (including Eben Moglen, Pamela Jones of Groklaw, Jan Wildeboer and Carlo Piana, who also acted as co-counsel in the merger regulation procedure) advocated for the unconditional approval of the merger. As part of the negotiations with the European Commission, Oracle committed that MySQL server will continue until at least 2015 to use the dual-licensing strategy long used by MySQL AB, with proprietary and GPL versions available. The antitrust of the EU had been "pressuring it to divest MySQL as a condition for approval of the merger". But, as revealed by WikiLeaks, the US Department of Justice and Antitrust, at the request of Oracle, pressured the EU to unconditionally approve the merger. The European Commission eventually unconditionally approved Oracle's acquisition of MySQL on 21 January 2010.
In January 2009, prior to Oracle's acquisition of MySQL, Monty Widenius started a GPL-only fork, MariaDB. MariaDB is based on the same code base as MySQL server 5.1 and strives to maintain compatibility with Oracle-provided versions.
Milestones.
Notable milestones in MySQL development include:
Versions.
The following chart provides an overview of various MySQL versions and their current development statuses:

</doc>
<doc id="19547" url="http://en.wikipedia.org/wiki?curid=19547" title="Modernism">
Modernism

Modernism is a philosophical movement that, along with cultural trends and changes, arose from wide-scale and far-reaching transformations in Western society in the late 19th and early 20th centuries. Among the factors that shaped Modernism were the development of modern industrial societies and the rapid growth of cities, followed then by the horror of World War I. Modernism also rejected the certainty of Enlightenment thinking, and many modernists rejected religious belief.
Modernism, in general, includes the activities and creations of those who felt the traditional forms of art, architecture, literature, religious faith, philosophy, social organization, activities of daily life, and even the sciences, were becoming ill-fitted to their tasks and outdated in the new economic, social, and political environment of an emerging fully industrialized world. The poet Ezra Pound's 1934 injunction to "Make it new!" was the touchstone of the movement's approach towards what it saw as the now obsolete culture of the past. In this spirit, its innovations, like the stream-of-consciousness novel, atonal (or pantonal) and twelve-tone music, quantum physics, genetics, neuron networks, set theory, analytic philosophy, the moving-picture show, divisionist painting and abstract art, all had precursors in the 19th century.
A notable characteristic of Modernism is self-consciousness, which often led to experiments with form, along with the use of techniques that drew attention to the processes and materials used in creating a painting, poem, building, etc. Modernism explicitly rejected the ideology of realism and makes use of the works of the past by the employment of reprise, incorporation, rewriting, recapitulation, revision and parody.
Some commentators define Modernism as a mode of thinking—one or more philosophically defined characteristics, like self-consciousness or self-reference, that run across all the novelties in the arts and the disciplines. More common, especially in the West, are those who see it as a socially progressive trend of thought that affirms the power of human beings to create, improve and reshape their environment with the aid of practical experimentation, scientific knowledge, or technology. From this perspective, Modernism encouraged the re-examination of every aspect of existence, from commerce to philosophy, with the goal of finding that which was 'holding back' progress, and replacing it with new ways of reaching the same end. Others focus on Modernism as an aesthetic introspection. This facilitates consideration of specific reactions to the use of technology in the First World War, and anti-technological and nihilistic aspects of the works of diverse thinkers and artists spanning the period from Friedrich Nietzsche (1844–1900) to Samuel Beckett (1906–1989).
History.
Beginnings: the 19th century.
According to one critic, modernism developed out of Romanticism's revolt against the effects of the Industrial Revolution and bourgeois values: "The ground motive of modernism, Graff asserts, was criticism of the nineteenth-century bourgeois social order and its world view […] the modernists, carrying the torch of romanticism". While J. M. W. Turner (1775–1851), one of the greatest landscape painters of the 19th century, was a member of the Romantic movement, as "a pioneer in the study of light, colour, and atmosphere", he "anticipated the French Impressionists" and therefore Modernism "in breaking down conventional formulas of representation; [though] unlike them, he believed that his works should always express significant historical, mythological, literary, or other narrative themes".
The dominant trends of industrial Victorian England, were also opposed, from about 1850, by the English poets and painters that constituted the Pre-Raphaelite Brotherhood, because of their "opposition to technical skill without inspiration". They were influenced by the writings of the art critic John Ruskin (1819–1900), who had strong feelings about the role of art in helping to improve the lives of the urban working classes, in the rapidly expanding industrial cities of Britain. Art critic Clement Greenberg describes the Pre-Raphaelite Brotherhood as proto-Modernists: "There the proto-Modernists were, of all people, the pre-Raphaelites (and even before them, as proto-proto-Modernists, the German Nazarenes. The Pre-Raphaelites actually foreshadowed Manet (1832–83), with whom Modernist painting most definitely begins. They acted on a dissatisfaction with painting as practiced in their time, holding that its realism wasn't truthful enough". Rationalism has also had opponents in the philosophers Søren Kierkegaard (1813–55) and later Friedrich Nietzsche (1844–1900), both of whom had significant influence on existentialism.
However, the Industrial Revolution continued. Influential innovations included steam-powered industrialization, and especially the development of railways, starting in Britain in the 1830s, and the subsequent advancements in physics, engineering, and architecture associated with this. A major 19th-century engineering achievement was The Crystal Palace, the huge cast-iron and plate glass exhibition hall built for The Great Exhibition of 1851 in London. Glass and iron were used in a similar monumental style in the construction of major railway terminals in London, such as Paddington Station (1854) and King's Cross Station (1852). These technological advances led to the building of later structures like the Brooklyn Bridge (1883) and the Eiffel Tower (1889). The latter broke all previous limitations on how tall man-made objects could be. These engineering marvels radically altered the 19th-century urban environment and the daily lives of people. The human experience of time itself was altered, with the development of electric telegraph from 1837, and the adoption of standard time by British railway companies from 1845, and in the rest of the world over the next fifty years.
But despite continuing technological advances, from the 1870s onward, the idea that history and civilization were inherently progressive, and that progress was always good, came under increasing attack. Arguments arose that the values of the artist and those of society were not merely different, but that Society was antithetical to Progress, and could not move forward in its present form. The philosopher Schopenhauer (1788–1860) ("The World as Will and Idea", 1819) called into question the previous optimism, and his ideas had an important influence on later thinkers, including Nietzsche. Two of the most significant thinkers of the period were biologist Charles Darwin (1809–82), author of "On the Origin of Species by Means of Natural Selection" (1859), and political scientist Karl Marx (1818–83), author of "Das Kapital" (1867). Darwin's theory of evolution by natural selection undermined religious certainty and the idea of human uniqueness. In particular, the notion that human beings were driven by the same impulses as "lower animals" proved to be difficult to reconcile with the idea of an ennobling spirituality. Karl Marx argued that there were fundamental contradictions within the capitalist system, and that the workers were anything but free.
The beginnings of modernism in France.
Historians, and writers in different disciplines, have suggested various dates as starting points for modernism. Historian William Everdell, for example, has argued that Modernism began in the 1870s, when metaphorical (or ontological) continuity began to yield to the discrete with mathematician Richard Dedekind's (1831–1916) Dedekind cut, and Ludwig Boltzmann's (1844–1906) statistical thermodynamics. Everdell also thinks Modernism in painting began in 1885–86 with Seurat's Divisionism, the "dots" used to paint "A Sunday Afternoon on the Island of La Grande Jatte." On the other hand visual art critic Clement Greenberg called Immanuel Kant (1724–1804) "the first real Modernist", though he also wrote, "What can be safely called Modernism emerged in the middle of the last century—and rather locally, in France, with Baudelaire in literature and Manet in painting, and perhaps with Flaubert, too, in prose fiction. (It was a while later, and not so locally, that Modernism appeared in music and architecture)." The poet Baudelaire's "Les Fleurs du mal" ("The Flowers of Evil"), and Flaubert's novel Madame Bovary were both published in 1857.
In the arts and letters, two important approaches developed separately in France. The first was impressionism, a school of painting that initially focused on work done, not in studios, but outdoors ("en plein air"). Impressionist paintings demonstrated that human beings do not see objects, but instead see light itself. The school gathered adherents despite internal divisions among its leading practitioners, and became increasingly influential. Initially rejected from the most important commercial show of the time, the government-sponsored Paris Salon, the Impressionists organized yearly group exhibitions in commercial venues during the 1870s and 1880s, timing them to coincide with the official Salon. A significant event of 1863 was the Salon des Refusés, created by Emperor Napoleon III to display all of the paintings rejected by the Paris Salon. While most were in standard styles, but by inferior artists, the work of Manet attracted tremendous attention, and opened commercial doors to the movement. The second French school was Symbolism, which literary historians see beginning with Charles Baudelaire (1821–67), and including the later poets, Arthur Rimbaud (1854–91) "Une Saison en Enfer" ("A Season in Hell", 1873), Paul Verlaine (1844–96), Stéphane Mallarmé (1842–98), and Paul Valéry (1871–1945). The symbolists "stressed the priority of suggestion and evocation over direct description and explicit analogy," and were especially interested in "the musical properties of language."
Cabaret, which gave birth to so many of the arts of modernism, including the immediate precursors of film, may be said to have begun in France in 1881 with the opening of the Black Cat in Montmartre, the beginning of the ironic monologue, and the founding of the Society of Incoherent Arts.
Influential in the early days of Modernism were the theories of Sigmund Freud (1856–1939). Freud's first major work was "Studies on Hysteria" (with Josef Breuer) (1895). Central to Freud's thinking is the idea "of the primacy of the unconscious mind in mental life", so that all subjective reality was based on the play of basic drives and instincts, through which the outside world was perceived. Freud's description of subjective states involved an unconscious mind full of primal impulses, and counterbalancing self-imposed restrictions derived from social values.
Friedrich Nietzsche (1844–1900) was another major precursor of modernism, with a philosophy in which psychological drives, specifically the 'will to power', was of central importance: "Nietzsche often identified life itself with “will to power,” that is, with an instinct for growth and durability". Henri Bergson (1859–1941), on the other hand, emphasized the difference between scientific, clock time and the direct, subjective, human experience of time. His work on time and consciousness "had a great influence on twentieth-century novelists," especially those modernists who used the stream of consciousness technique, such as Dorothy Richardson, James Joyce, and Virginia Woolf (1882–1941). Also important in Bergson's philosophy was the idea of "élan vital", the life force, which "brings about the creative evolution of everything". His philosophy also placed a high value on intuition, though without rejecting the importance of the intellect.
Important literary precursors of Modernism were: Fyodor Dostoyevsky (1821–81) "Crime and Punishment" (1866), "The Brothers Karamazov" (1880); Walt Whitman (1819–92) ("Leaves of Grass") (1855–91); August Strindberg (1849–1912), especially his later plays, including, the trilogy "To Damascus" 1898–1901, "A Dream Play" (1902), "The Ghost Sonata" (1907). Henry James has also been suggested as a significant precursor, in a work as early as "Portrait of a Lady" (1881).
Out of the collision of ideals derived from Romanticism, and an attempt to find a way for knowledge to explain that which was as yet unknown, came the first wave of works in the first decade of the 20th century, which, while their authors considered them extensions of existing trends in art, broke the implicit contract with the general public that artists were the interpreters and representatives of bourgeois culture and ideas. These "modernist" landmarks include the atonal ending of Arnold Schoenberg's Second String Quartet in 1908, the expressionist paintings of Wassily Kandinsky starting in 1903, and culminating with his first abstract painting and the founding of the Blue Rider group in Munich in 1911, and the rise of fauvism and the inventions of cubism from the studios of Henri Matisse, Pablo Picasso, Georges Braque, and others, in the years between 1900 and 1910.
Explosion, early 20th century to 1930.
An important aspect of Modernism is how it relates to tradition through its adoption of techniques like reprise, incorporation, rewriting, recapitulation, revision and parody in new forms.
T. S. Eliot made significant comments on the relation of the artist to tradition, including:
However, relationship of modernism with tradition was complex, as literary scholar Peter Childs indicates:
An example of how modernist art can be both revolutionary and yet be related to past tradition, is the music of the composer Arnold Schoenberg. On the one hand Schoenberg rejected traditional tonal harmony, the hierarchical system of organizing works of music that had guided music making for at least a century and a half. He believed he had discovered a wholly new way of organizing sound, based in the use of twelve-note rows. Yet while this was indeed wholly new, its origins can be traced back in the work of earlier composers, such as Franz Liszt, Richard Wagner, Gustav Mahler, Richard Strauss and Max Reger. Furthermore it must be noted that Schoenberg also wrote tonal music throughout his career.
In the world of art, in the first decade of the 20th century, young painters such as Pablo Picasso and Henri Matisse were causing a shock with their rejection of traditional perspective as the means of structuring paintings, though the impressionist Monet had already been innovative in his use of perspective. In 1907, as Picasso was painting "Les Demoiselles d'Avignon", Oskar Kokoschka was writing "Mörder, Hoffnung der Frauen" ("Murderer, Hope of Women"), the first Expressionist play (produced with scandal in 1909), and Arnold Schoenberg was composing his "String Quartet No.2 in F-sharp minor" (1908), his first composition without a tonal centre.
A primary influence that led to Cubism was the representation of three-dimensional form in the late works of Paul Cézanne, which were displayed in a retrospective at the 1907 Salon d'Automne. In Cubist artwork, objects are analyzed, broken up and reassembled in an abstracted form and instead of depicting objects from one viewpoint, the artist depicts the subject from a multitude of viewpoints to represent the subject in a greater context. Cubism was brought to the attention of the general public for the first time in 1911 at the Salon des Indépendants in Paris (held 21 April – 13 June). Jean Metzinger, Albert Gleizes, Henri Le Fauconnier, Robert Delaunay, Fernand Léger and Roger de La Fresnaye were shown together in Room 41, provoking a 'scandal' out of which Cubism emerged and spread throughout Paris and beyond. Also in 1911, Kandinsky painted "Bild mit Kreis" ("Picture With a Circle") which he later called the first abstract painting. In 1912 Jean Metzinger and Albert Gleizes wrote the first (and only) major Cubist manifesto, "Du "Cubisme"", published in time for the Salon de la Section d'Or, the largest Cubist exhibition to date. In 1912 Metzinger painted and exhibited his enchanting "La Femme au Cheval (Woman with a horse)" and "Danseuse au café (Dancer in a café)". Albert Gleizes painted and exhibited his "Les Baigneuses (The Bathers)" and his monumental "Le Dépiquage des Moissons (Harvest Threshing)". This work, along with "La Ville de Paris" ("City of Paris") by Robert Delaunay, is the largest and most ambitious Cubist painting undertaken during the pre-War Cubist period.
In 1905, a group of four German artists, led by Ernst Ludwig Kirchner, formed Die Brücke (the Bridge) in the city of Dresden. This was arguably the founding organization for the German Expressionist movement, though they did not use the word itself. A few years later, in 1911, a like-minded group of young artists formed Der Blaue Reiter (The Blue Rider) in Munich. The name came from Wassily Kandinsky's Der Blaue Reiter painting of 1903. Among their members were Kandinsky, Franz Marc, Paul Klee, and Auguste Macke. However, the term "Expressionism" did not firmly establish itself until 1913. Though initially mainly a German artistic movement, most predominant in painting, poetry and the theatre between 1910–30, most precursors of the movement were not German. Furthermore there have been expressionist writers of prose fiction, as well as non-German speaking expressionist writers, and, while the movement had declined in Germany with the rise of Adolf Hitler in the 1930s, there were subsequent expressionist works.
Expressionism is notoriously difficult to define, in part because it "overlapped with other major 'isms' of the modernist period: with Futurism, Vorticism, Cubism, Surrealism and Dada." Richard Murphy also comments: "the search for an all-inclusive definition is problematic to the extent that the most challenging expressionists" such as the novelist Franz Kafka, poet Gottfried Benn, and novelist Alfred Döblin were simultaneously the most vociferous anti-expressionists. What, however, can be said, is that it was a movement that developed in the early twentieth-century mainly in Germany in reaction to the dehumanizing effect of industrialization and the growth of cities, and that "one of the central means by which expressionism identifies itself as an avant-garde movement, and by which it marks its distance to traditions and the cultural institution as a whole is through its relationship to realism and the dominant conventions of representation." More explicitly: that the expressionists rejected the ideology of realism.
There was a concentrated Expressionist movement in early 20th century German theatre of which Georg Kaiser and Ernst Toller were the most famous playwrights. Other notable Expressionist dramatists included Reinhard Sorge, Walter Hasenclever, Hans Henny Jahnn, and Arnolt Bronnen. They looked back to Swedish playwright August Strindberg and German actor and dramatist Frank Wedekind as precursors of their dramaturgical experiments.
Oskar Kokoschka's "Murderer, the Hope of Women" was the first fully Expressionist work for the theatre, which opened on 4 July 1909 in Vienna. The extreme simplification of characters to mythic types, choral effects, declamatory dialogue and heightened intensity would become characteristic of later Expressionist plays. The first full-length Expressionist play was "The Son" by Walter Hasenclever, which was published in 1914 and first performed in 1916.
Futurism is yet another modernist movement and in 1909, the Parisian newspaper "Le Figaro" published F. T. Marinetti's first manifesto. Soon afterwards a group of painters (Giacomo Balla, Umberto Boccioni, Carlo Carrà, Luigi Russolo, and Gino Severini) co-signed the Futurist Manifesto. Modeled on Marx and Engels' famous "Communist Manifesto" (1848), such manifestoes put forward ideas that were meant to provoke and to gather followers. However, arguments in favor of geometric or purely abstract painting were, at this time, largely confined to "little magazines" which had only tiny circulations. Modernist primitivism and pessimism were controversial, and the mainstream in the first decade of the 20th century was still inclined towards a faith in progress and liberal optimism.
Abstract artists, taking as their examples the impressionists, as well as Paul Cézanne (1839–1906) and Edvard Munch (1863–1944), began with the assumption that color and shape, not the depiction of the natural world, formed the essential characteristics of art. Western art had been, from the Renaissance up to the middle of the 19th century, underpinned by the logic of perspective and an attempt to reproduce an illusion of visible reality. The arts of cultures other than the European had become accessible and showed alternative ways of describing visual experience to the artist. By the end of the 19th century many artists felt a need to create a new kind of art which would encompass the fundamental changes taking place in technology, science and philosophy. The sources from which individual artists drew their theoretical arguments were diverse, and reflected the social and intellectual preoccupations in all areas of Western culture at that time. Wassily Kandinsky, Piet Mondrian, and Kazimir Malevich all believed in redefining art as the arrangement of pure color. The use of photography, which had rendered much of the representational function of visual art obsolete, strongly affected this aspect of modernism.
Modernist architects and designers, such as Frank Lloyd Wright and Le Corbusier, believed that new technology rendered old styles of building obsolete. Le Corbusier thought that buildings should function as "machines for living in", analogous to cars, which he saw as machines for traveling in. Just as cars had replaced the horse, so modernist design should reject the old styles and structures inherited from Ancient Greece or from the Middle Ages. Following this machine aesthetic, modernist designers typically rejected decorative motifs in design, preferring to emphasize the materials used and pure geometrical forms. The skyscraper is the archetypal modernist building and the Wainwright Building, a 10-story office building built 1890-91, in St. Louis, Missouri, US, is among the first skyscrapers in the world. Ludwig Mies van der Rohe's Seagram Building in New York (1956–1958) is often regarded as the pinnacle of this modernist high-rise architecture.
Modernism reversed the 19th-century relationship of public and private: in the 19th century, public buildings were horizontally expansive for a variety of technical reasons, and private buildings emphasized verticality, so as to fit more private space on increasingly limited land. Conversely, in the 20th century, public buildings became vertically oriented and private buildings became organized horizontally. Many aspects of modernist design still persist within the mainstream of contemporary architecture, though previous dogmatism has given way to a more playful use of decoration, historical quotation, and spatial drama.
In 1913—which was the year of philosopher Edmund Husserl's "Ideas"; physicist Niels Bohr's quantized atom; Ezra Pound's founding of imagism; the Armory Show in New York; and, in Saint Petersburg, the "first futurist opera", Mikhail Matyushin's "Victory Over the Sun"—another Russian composer, Igor Stravinsky, composed "The Rite of Spring", a ballet that depicts human sacrifice, and has a musical score full of dissonance and primitive rhythm. This caused uproar on its first performance in Paris. At this time though Modernism was still "progressive", increasingly it saw traditional forms and traditional social arrangements as hindering progress, and was recasting the artist as a revolutionary, engaged in overthrowing rather than enlightening society. Also in 1913 a less violent event occurred in France with the publication of the first volume of Marcel Proust's important novel sequence "À la recherche du temps perdu" (1913–1927) ("In Search of Lost Time"). This often presented as an early example of a writer using the stream-of-consciousness technique, but Robert Humphrey comments that Proust "is concerned only with the reminiscent aspect of consciousness" and that he "was deliberately recapturing the past for the purpose of communicating; hence he did not write a stream-of-consciousness novel".
Stream of consciousness was an important modernist literary innovationas, and it has been suggested that Arthur Schnitzler (1862–1931), was the first to make full use it in his short story '"Leutnant Gustl" ("None but the Brave" ) (1900). Dorothy Richardson was the first English writer to use it, in the early volumes of her novel sequence "Pilgrimage" (1915–67). The other modernist novelists that are associated with the use of this narrative technique include James Joyce in "Ulysses" (1922), and Italo Svevo in "La coscienza di Zeno" (1923).
However, with the coming of Great War of 1914-18, and the Russian Revolution of 1917, the world was drastically changed and doubt cast on the beliefs and institutions of the past. The failure of the previous status quo seemed self-evident to a generation that had seen millions die fighting over scraps of earth: prior to 1914 it had been argued that no one would fight such a war, since the cost was too high. The birth of a machine age which had made major changes in the conditions of daily life in the 19th century now had radically changed the nature of warfare. The traumatic nature of recent experience altered basic assumptions, and realistic depiction of life in the arts seemed inadequate when faced with the fantastically surreal nature of trench warfare, The view that mankind was making steady moral progress now seemed ridiculous in the face of the senseless slaughter, that was described in works such as Erich Maria Remarque's novel "All Quiet on the Western Front" (1929). Therefore Modernism's view of reality, which had been a minority taste before the war, became to more generally accepted in the 1920s.
In literature and visual art some modernists sought to defy expectations mainly in order to make their art more vivid, or to force the audience to take the trouble to question their own preconceptions. This aspect of Modernism has often seemed a reaction to consumer culture, which developed in Europe and North America in the late 19th century. Whereas most manufacturers try to make products that will be marketable by appealing to preferences and prejudices, high modernists rejected such consumerist attitudes in order to undermine conventional thinking. The art critic Clement Greenberg expounded this theory of Modernism in his essay "Avant-Garde and Kitsch". Greenberg labelled the products of consumer culture "kitsch", because their design aimed simply to have maximum appeal, with any difficult features removed. For Greenberg, Modernism thus formed a reaction against the development of such examples of modern consumer culture as commercial popular music, Hollywood, and advertising. Greenberg associated this with the revolutionary rejection of capitalism.
Some modernists saw themselves as part of a revolutionary culture, that included political revolution. In Russia after the 1917 Revolution there was indeed initially a burgeoning of avant garde cultural activity, which included Russian futurism. However others rejected conventional politics as well as artistic conventions, believing that a revolution of political consciousness had greater importance than a change in political structures. But many modernists saw themselves as apolitical. Others, such as T. S. Eliot, rejected mass popular culture from a conservative position. Some even argue that Modernism in literature and art functioned to sustain an elite culture which excluded the majority of the population.
Surrealism, which originated in the early 1920s, came to be regarded by the public as the most extreme form of modernism, or "the avant-garde of modernism". The word "surrealist" was coined by Guillaume Apollinaire and first appeared in the preface to his play "Les Mamelles de Tirésias", which was written in 1903 and first performed in 1917.
Major surrealists include Paul Éluard, Robert Desnos, Max Ernst, Hans Arp, Antonin Artaud, Raymond Queneau, Joan Miró, and Marcel Duchamp.
By 1930, Modernism won a place in the establishment, including the political and artistic establishment, although by this time Modernism itself had changed.
Modernism continues: 1930–1945.
Modernism continued to evolve during the 1930s. Between 1930 and 1932 composer Arnold Schoenberg worked on "Moses und Aaron" one of the first operas to make use of the twelfth note technique, Pablo Picasso painted in 1937 "Guernica", his cubist condemnation of fascism, while in 1939 James Joyce pushed the boundaries of the modern novel further with "Finnegans Wake". 
Also by 1930 modernism began to influence mainstream culture, so that, for example, "The New Yorker" magazine began publishing work, which was influenced by modernism, by young writers and humorists like Dorothy Parker, Robert Benchley, E. B. White, S. J. Perelman, and James Thurber, amongst others. Perelman is highly regarded for his humorous short stories that he published in magazines in the 1930s and 1940s, most often in "The New Yorker", which are considered to be the first examples of surrealist humor in America. Modern ideas in art also began to appear more frequently in commercials and logos, an early example of which, from 1919, is the famous London Underground logo designed by Edward Johnston.
One of the most visible changes of this period was the adoption of new technologies into daily life of ordinary people in Western Europe and North America. Electricity, the telephone, the radio, the automobile—and the need to work with them, repair them and live with them—created social change. The kind of disruptive moment that only a few knew in the 1880s became a common occurrence. For example, the speed of communication reserved for the stock brokers of 1890 became part of family life, at least in middle class North America. Associated with urbanization and changing social mores also came smaller families and changed relationships between parents and their children.
Another strong influence at this time was Marxism. After the generally primitivistic/irrationalist aspect of pre-World War I Modernism, which for many modernists precluded any attachment to merely political solutions, and the neoclassicism of the 1920s, as represented most famously by T. S. Eliot and Igor Stravinsky—which rejected popular solutions to modern problems—the rise of Fascism, the Great Depression, and the march to war helped to radicalise a generation. Bertolt Brecht, W. H. Auden, André Breton, Louis Aragon and the philosophers Antonio Gramsci and Walter Benjamin are perhaps the most famous exemplars of this modernist form of Marxism. There were, however, also Modernists explicitly of 'the right', including Salvador Dalí, Wyndham Lewis, T. S. Eliot, Ezra Pound, the Dutch author Menno ter Braak and others.
Significant modernist literary works continued to be created in the 1920s and 1930s, including further novels by Marcel Proust, Virginia Woolf, Robert Musil, and Dorothy Richardson. The American modernist dramatist Eugene O'Neill's career began in 1914, but his major works appeared in the 1920s and 1930s and early 1940s. Two other significant modernist dramatists writing in the 1920s and 1930s were Bertolt Brecht and Federico García Lorca. D. H. Lawrence's "Lady Chatterley's Lover" was privately published in 1928, while another important landmark for the history of the modern novel came with the publication of William Faulkner's "The Sound and the Fury" in 1929. In the 1930s, in addition to further major works by Faulkner, Samuel Beckett's published his first major work, the novel "Murphy" (1938). Then in 1939 James Joyce's "Finnegans Wake" appeared. This is written in a largely idiosyncratic language, consisting of a mixture of standard English lexical items and neologistic multilingual puns and portmanteau words, which attempts to recreate the experience of sleep and dreams. In poetry T. S. Eliot, E. E. Cummings, and Wallace Stevens were writing from the 1920s until the 1950s. While modernist poetry in English is often viewed as an American phenomenon, with leading exponents including Ezra Pound, T. S. Eliot, Marianne Moore, William Carlos Williams, H.D., and Louis Zukofsky, there were important British modernist poets, including David Jones, Hugh MacDiarmid, Basil Bunting, and W. H. Auden. European modernist poets include Federico García Lorca, Anna Akhmatova, Constantine Cavafy, and Paul Valéry.
The modernist movement continued during this period in Soviet Russia and in 1930 composer Dimitri Shostakovich's (1906–75) opera "The Nose" was premiered, in which he uses a montage of different styles, including folk music, popular song and atonality. Amongst his influences was Alban Berg's (1985–1935) opera "Wozzeck" (1925), which "had made a tremendous impression on Shostakovich when it was staged in Leningrad". However, from 1932 Socialist realism began to oust modernism in the Soviet Union, and in 1936 Shostakovich was attacked and forced to withdraw his 4th Symphony. Alban Berg wrote another significant, though incomplete, modernist opera, "Lulu", which premiered in 1937. Berg's violin concerto was first performed in 1935. Like Shostakovich other composers faced difficulties in this period. In Germany Arnold Schoenberg (1874–1951) was forced to flee to the US when Hitler came to power in 1933, because of both his modernist atonal-style, as well as his Jewish ancestry. His major works from this period are a Violin Concerto, Op. 36 (1934/36), Piano Concerto, Op. 42 (1942). Schoenberg also wrote tonal music in this period with the Suite for Strings in G major (1935), and the Chamber Symphony No. 2 in E♭ minor, Op. 38 (begun in 1906, completed in 1939). During this time Hungarian modernist Béla Bartók (1881–1945) produced a number of major works, including "Music for Strings, Percussion and Celesta" (1936) and "Divertimento for String Orchestra BB 118" (1939), String Quartet No. 5 (1934), and No. 6 (his last, 1939). But he too left for the US in 1940, because of the rise of fascism in Hungary. Igor Stravinsky (1882–1971) continued writing in his neoclassical style during the 1930s and 1940s, writing works like "Symphony of Psalms" (1930), Symphony in C (1940) and "Symphony in Three Movements" (1945). He also emigrated to the US because of World War II. Olivier Messiaen (1908–1992), however, served in the French army during the war and was imprisoned at Stalag VIII-A by the Germans, where he composed his famous "Quatuor pour la fin du temps" ("Quartet for the End of Time"). The Quartet was first performed in January 1941 to an audience of prisoners and prison guards.
In painting, during the 1920s and the 1930s and the Great Depression, modernism is defined by Surrealism, late Cubism, the Bauhaus, De Stijl, Dada, German Expressionism, Expressionism, and modernist and masterful color painters like Henri Matisse and Pierre Bonnard as well as the abstractions of artists like Piet Mondrian and Wassily Kandinsky which characterized the European art scene. In Germany Max Beckmann, Otto Dix, George Grosz and others politicized their paintings, foreshadowing the coming of World War II. While in America modernism is seen in the form of American Scene painting and the social realism and regionalism movements that contained both political and social commentary dominated the art world. Artists like Ben Shahn, Thomas Hart Benton, Grant Wood, George Tooker, John Steuart Curry, Reginald Marsh, and others became prominent. Modernism is defined in Latin America by painters Joaquín Torres García from Uruguay and Rufino Tamayo from Mexico, while the muralist movement with Diego Rivera, David Siqueiros, José Orozco, Pedro Nel Gómez and Santiago Martinez Delgado, and Symbolist paintings by Frida Kahlo, began a renaissance of the arts for the region, characterized by a freer use of color and an emphasis on political messages.
Diego Rivera is perhaps best known by the public world for his 1933 mural, "Man at the Crossroads", in the lobby of the RCA Building at Rockefeller Center. When his patron Nelson Rockefeller discovered that the mural included a portrait of Vladimir Lenin and other communist imagery, he fired Rivera, and the unfinished work was eventually destroyed by Rockefeller's staff. Frida Kahlo (Rivera's wife's) works are often characterized by their stark portrayals of pain. Kahlo was deeply influenced by indigenous Mexican culture, which is apparent in her paintings' bright colors and dramatic symbolism. Christian and Jewish themes are often depicted in her work as well; she combined elements of the classic religious Mexican tradition—which were often bloody and violent. Frida Kahlo's Symbolist works relate strongly to Surrealism and to the Magic Realism movement in literature.
Political activism was an important piece of David Siqueiros' life, and frequently inspired him to set aside his artistic career. His art was deeply rooted in the Mexican Revolution. The period from the 1920s to the 1950s is known as the Mexican Renaissance, and Siqueiros was active in the attempt to create an art that was at once Mexican and universal. The young Jackson Pollock attended the workshop and helped build floats for the parade.
During the 1930s radical leftist politics characterized many of the artists connected to Surrealism, including Pablo Picasso. On 26 April 1937, during the Spanish Civil War, the Basque town of Gernika was the scene of the "Bombing of Gernika" by the Nazi Germany's Luftwaffe. The Germans were attacking to support the efforts of Francisco Franco to overthrow the Basque Government and the Spanish Republican government. Pablo Picasso painted his mural sized "Guernica" to commemorate the horrors of the bombing.
During the Great Depression of the 1930s, through the years of World War II American art was characterized by Social Realism and American Scene Painting, in the work of Grant Wood, Edward Hopper, Ben Shahn, Thomas Hart Benton, and several others. "Nighthawks" (1942) is a painting by Edward Hopper that portrays people sitting in a downtown diner late at night. It is not only Hopper's most famous painting, but one of the most recognizable in American art. The scene was inspired by a diner in Greenwich Village. Hopper began painting it immediately after the attack on Pearl Harbor. After this event there was a large feeling of gloominess over the country, a feeling that is portrayed in the painting. The urban street is empty outside the diner, and inside none of the three patrons is apparently looking or talking to the others but instead is lost in their own thoughts. This portrayal of modern urban life as empty or lonely is a common theme throughout Hopper's work.
"American Gothic" is a painting by Grant Wood from 1930. Portraying a pitchfork-holding farmer and a younger woman in front of a house of Carpenter Gothic style, it is one of the most familiar images in 20th-century American art. Art critics had favorable opinions about the painting; like Gertrude Stein and Christopher Morley, they assumed the painting was meant to be a satire of rural small-town life. It was thus seen as part of the trend towards increasingly critical depictions of rural America, along the lines of Sherwood Anderson's "1919 Winesburg, Ohio", Sinclair Lewis' 1920 "Main Street", and Carl Van Vechten's "The Tattooed Countess" in literature. However, with the onset of the Great Depression, the painting came to be seen as a depiction of steadfast American pioneer spirit.
The situation for artists in Europe during the 1930s deteriorated rapidly as the Nazis' power in Germany and across Eastern Europe increased. "Degenerate art" was a term adopted by the Nazi regime in Germany for virtually all modern art. Such art was banned on the grounds that it was un-German or Jewish Bolshevist in nature, and those identified as degenerate artists were subjected to sanctions. These included being dismissed from teaching positions, being forbidden to exhibit or to sell their art, and in some cases being forbidden to produce art entirely. Degenerate Art was also the title of an exhibition, mounted by the Nazis in Munich in 1937. The climate became so hostile for artists and art associated with Modernism and abstraction that many left for the Americas. German artist Max Beckmann and scores of others fled Europe for New York. In New York City a new generation of young and exciting Modernist painters led by Arshile Gorky, Willem de Kooning, and others were just beginning to come of age.
Arshile Gorky's portrait of someone who might be Willem de Kooning is an example of the evolution of abstract expressionism from the context of figure painting, cubism and surrealism. Along with his friends de Kooning and John D. Graham Gorky created bio-morphically shaped and abstracted figurative compositions that by the 1940s evolved into totally abstract paintings. Gorky's work seems to be a careful analysis of memory, emotion and shape, using line and color to express feeling and nature.
After World War II (mainly the visual and performing arts).
Introduction.
Though "The Oxford Encyclopedia of British Literature" sees Modernism ending by c. 1939, with regard to British and American literature, "When (if) Modernism petered out and postmodernism began has been contested almost as hotly as when the transition from Victorianism to Modernism occurred". Clement Greenberg sees Modernism ending in the 1930s, with the exception of the visual and performing arts, but with regard to music, Paul Griffiths notes that, while Modernism "seemed to be a spent force" by the late 1920s, after World War II, "a new generation of composers — Boulez, Barraqué, Babbitt, Nono, Stockhausen, Xenakis" revived modernism". In fact many literary modernists lived into the 1950s and 1960s, though generally speaking they were no longer producing major works. The term "late modernism" is also sometimes applied to modernist works published after 1930. Among modernists (or late modernists) still publishing after 1945 were Wallace Stevens, Gottfried Benn, T. S. Eliot, Anna Akhmatova, William Faulkner, Dorothy Richardson, John Cowper Powys, and Ezra Pound. Basil Bunting, born in 1901, published his most important modernist poem "Briggflatts" in 1965. In addition Hermann Broch's "The Death of Virgil" was published in 1945 and Thomas Mann's "Doctor Faustus" in 1947. Samuel Beckett, who died in 1989, has been described as a "later modernist". Beckett is a writer with roots in the expressionist tradition of modernism, who produced works from the 1930s until the 1980s, including "Molloy" (1951), "En attendant Godot" (1953), "Happy Days" (1961), "Rockaby" (1981). The terms "minimalist" and "post-modernist" have also been applied to his later works. The poets Charles Olson (1910–1970) and J. H. Prynne (born 1936) are among the writers in the second half of the 20th century who have been described as late modernists.
More recently the term "late modernism" has been redefined by at least one critic and used to refer to works written after 1945, rather than 1930. With this usage goes the idea that the ideology of modernism was significantly re-shaped by the events of World War II, especially the Holocaust and the dropping of the atom bomb.
The post-war period left the capitals of Europe in upheaval with an urgency to economically and physically rebuild and to politically regroup. In Paris (the former center of European culture and the former capital of the art world) the climate for art was a disaster. Important collectors, dealers, and modernist artists, writers, and poets had fled Europe for New York and America. The surrealists and modern artists from every cultural center of Europe had fled the onslaught of the Nazis for safe haven in the United States. Many of those who didn't flee perished. A few artists, notably Pablo Picasso, Henri Matisse, and Pierre Bonnard, remained in France and survived.
The 1940s in New York City heralded the triumph of American abstract expressionism, a modernist movement that combined lessons learned from Henri Matisse, Pablo Picasso, surrealism, Joan Miró, cubism, Fauvism, and early Modernism via great teachers in America like Hans Hofmann and John D. Graham. American artists benefited from the presence of Piet Mondrian, Fernand Léger, Max Ernst and the André Breton group, Pierre Matisse's gallery, and Peggy Guggenheim's gallery "The Art of This Century", as well as other factors.
Theatre of the Absurd.
The term "Theatre of the Absurd" is applied to plays written by primarily European playwrights, that express the belief that human existence has no meaning or purpose and therefore all communication breaks down. Logical construction and argument gives way to irrational and illogical speech and to its ultimate conclusion, silence. While there are significant precursors, including Alfred Jarry (1873–1907), the Theatre of the Absurd is generally seen as beginning in the 1950s with the plays of Samuel Beckett.
Critic Martin Esslin coined the term in his 1960 essay "Theatre of the Absurd." He related these plays based on a broad theme of the Absurd, similar to the way Albert Camus uses the term in his 1942 essay, "The Myth of Sisyphus". The Absurd in these plays takes the form of man’s reaction to a world apparently without meaning, and/or man as a puppet controlled or menaced by invisible outside forces. Though the term is applied to a wide range of plays, some characteristics coincide in many of the plays: broad comedy, often similar to Vaudeville, mixed with horrific or tragic images; characters caught in hopeless situations forced to do repetitive or meaningless actions; dialogue full of clichés, wordplay, and nonsense; plots that are cyclical or absurdly expansive; either a parody or dismissal of realism and the concept of the "well-made play".
Playwrights commonly associated with the Theatre of the Absurd include Samuel Beckett (1906–1989), Eugène Ionesco (1909–1994), Jean Genet (1910–1986), Harold Pinter (1930–2008), Tom Stoppard (born 1937), Friedrich Dürrenmatt (1921–1990), Alejandro Jodorowsky (born 1929), Fernando Arrabal (born 1932), Václav Havel (1936–2011) and Edward Albee (born 1928).
Pollock and abstract influences.
During the late 1940s Jackson Pollock's radical approach to painting revolutionized the potential for all contemporary art that followed him. To some extent Pollock realized that the journey toward making a work of art was as important as the work of art itself. Like Pablo Picasso's innovative reinventions of painting and sculpture in the early 20th century via cubism and constructed sculpture, Pollock redefined the way art gets made. His move away from easel painting and conventionality was a liberating signal to the artists of his era and to all who came after. Artists realized that Jackson Pollock's process—placing unstretched raw canvas on the floor where it could be attacked from all four sides using artistic and industrial materials; dripping and throwing linear skeins of paint; drawing, staining, and brushing; using imagery and non-imagery—essentially blasted artmaking beyond any prior boundary. Abstract expressionism generally expanded and developed the definitions and possibilities available to artists for the creation of new works of art.
The other abstract expressionists followed Pollock's breakthrough with new breakthroughs of their own. In a sense the innovations of Jackson Pollock, Willem de Kooning, Franz Kline, Mark Rothko, Philip Guston, Hans Hofmann, Clyfford Still, Barnett Newman, Ad Reinhardt, Robert Motherwell, Peter Voulkos and others opened the floodgates to the diversity and scope of all the art that followed them. Rereadings into abstract art by art historians such as Linda Nochlin, Griselda Pollock and Catherine de Zegher critically show, however, that pioneering women artists who produced major innovations in modern art had been ignored by official accounts of its history.
International figures from British art.
Henry Moore (1898 – 1986) emerged after World War II as Britain's leading sculptor. He was best known for his semi-abstract monumental bronze sculptures which are located around the world as public works of art. His forms are usually abstractions of the human figure, typically depicting mother-and-child or reclining figures, usually suggestive of the female body, apart from a phase in the 1950s when he sculpted family groups. His forms are generally pierced or contain hollow spaces. 
In the 1950s, Moore began to receive increasingly significant commissions, including a reclining figurefor the UNESCO building in Paris in 1958. With many more public works of art, the scale of Moore's sculptures grew significantly. The last three decades of Moore's life continued in a similar vein with several major retrospectives took place around the world, notably a very prominent exhibition in the summer of 1972 in the grounds of the Forte di Belvedere overlooking Florence. By the end of the 1970s, there were some 40 exhibitions a year featuring his work. On the campus of the University of Chicago in December 1967, 25 years to the minute after the team of physicists led by Enrico Fermi achieved the first controlled, self-sustaining nuclear chain reaction, Moore's "Nuclear Energy" was unveiled. Also in Chicago Moore also commemorated science with a large bronze sundial, locally named "Man Enters the Cosmos" (1980), which was commissioned to recognise the space exploration program.
The "London School" of figurative painters, including Francis Bacon (1909 –1992), Lucian Freud (1922 – 2011), Frank Auerbach (born 1931), Leon Kossoff (born 1926), and Michael Andrews (1928 – 1995), have received widespread international recognition.
Francis Bacon was an Irish-born British figurative painter known for his bold, graphic and emotionally raw imagery. His painterly but abstracted figures typically appear isolated in glass or steel geometrical cages set against flat, nondescript backgrounds. Bacon began painting during his early 20s but worked only sporadically until his mid-30s. His breakthrough came with the 1944 triptych "Three Studies for Figures at the Base of a Crucifixion" which sealed his reputation as a uniquely bleak chronicler of the human condition. His output can be crudely drawn as consisting of sequences or variations on a single motif; beginning with the 1940s male heads isolated in rooms, the early 1950s screaming popes, and mid to late 1950s animals and lone figures suspended in geometric structures. These were followed by his early 1960s modern variations of the crucifixion in the triptych format. From the mid-1960s to early 1970s, Bacon mainly produced strikingly compassionate portraits of friends. Following the suicide of his lover George Dyer in 1971, his art became more personal, inward looking and preoccupied with themes and motifs of death. During his lifetime, Bacon was equally reviled and acclaimed.
According to William Grimes of the New York Times, 
Lucian Freud was a German-born British painter, known chiefly for his thickly impastoed portrait and figure paintings, who was widely considered the pre-eminent British artist of his time. 
His works are noted for their psychological penetration, and for their often discomforting examination of the relationship between artist and model.
In the 1960s after abstract expressionism.
In abstract painting during the 1950s and 1960s several new directions like hard-edge painting and other forms of geometric abstraction began to appear in artist studios and in radical avant-garde circles as a reaction against the subjectivism of abstract expressionism. Clement Greenberg became the voice of post-painterly Abstraction when he curated an influential exhibition of new painting that toured important art museums throughout the United States in 1964. Color Field painting, hard-edge painting and Lyrical Abstraction emerged as radical new directions.
By the late 1960s however, postminimalism, process art and Arte Povera also emerged as revolutionary concepts and movements that encompassed both painting and sculpture, via lyrical abstraction and the postminimalist movement, and in early conceptual art. Process art as inspired by Pollock enabled artists to experiment with and make use of a diverse encyclopedia of style, content, material, placement, sense of time, and plastic and real space. Nancy Graves, Ronald Davis, Howard Hodgkin, Larry Poons, Jannis Kounellis, Brice Marden, Bruce Nauman, Richard Tuttle, Alan Saret, Walter Darby Bannard, Lynda Benglis, Dan Christensen, Larry Zox, Ronnie Landfield, Eva Hesse, Keith Sonnier, Richard Serra, Sam Gilliam, Mario Merz and Peter Reginato were some of the younger artists who emerged during the era of late modernism that spawned the heyday of the art of the late 1960s.
Pop art.
In 1962 the Sidney Janis Gallery mounted "The New Realists", the first major pop art group exhibition in an uptown art gallery in New York City. Janis mounted the exhibition in a 57th Street storefront near his gallery at 15 E. 57th Street. The show sent shockwaves through the New York School and reverberated worldwide. Earlier in England in 1958 the term "Pop Art" was used by Lawrence Alloway to describe paintings that celebrated consumerism of the post World War II era. This movement rejected abstract expressionism and its focus on the hermeneutic and psychological interior in favor of art that depicted and often celebrated material consumer culture, advertising, and iconography of the mass production age. The early works of David Hockney and the works of Richard Hamilton and Eduardo Paolozzi (who created the groundbreaking "I was a Rich Man's Plaything", 1947) are considered seminal examples in the movement. Meanwhile in the downtown scene in New York's East Village 10th Street galleries, artists were formulating an American version of pop art. Claes Oldenburg had his storefront, and the Green Gallery on 57th Street began to show the works of Tom Wesselmann and James Rosenquist. Later Leo Castelli exhibited the works of other American artists, including those of Andy Warhol and Roy Lichtenstein for most of their careers. There is a connection between the radical works of Marcel Duchamp and Man Ray, the rebellious Dadaists with a sense of humor, and pop artists like Claes Oldenburg, Andy Warhol, and Roy Lichtenstein, whose paintings reproduce the look of Benday dots, a technique used in commercial reproduction.
Minimalism.
Minimalism describes movements in various forms of art and design, especially visual art and music, wherein artists intend to expose the essence or identity of a subject through eliminating all non-essential forms, features or concepts. Minimalism is any design or style wherein the simplest and fewest elements are used to create the maximum effect.
As a specific movement in the arts it is identified with developments in post–World War II Western Art, most strongly with American visual arts in the 1960s and early 1970s. Prominent artists associated with this movement include Donald Judd, John McCracken, Agnes Martin, Dan Flavin, Robert Morris, Ronald Bladen, Anne Truitt, and Frank Stella.
It derives from the reductive aspects of Modernism and is often interpreted as a reaction against Abstract expressionism and a bridge to Postminimal art practices. By the early 1960s minimalism emerged as an abstract movement in art (with roots in geometric abstraction of Kazimir Malevich, the Bauhaus and Piet Mondrian) that rejected the idea of relational and subjective painting, the complexity of abstract expressionist surfaces, and the emotional zeitgeist and polemics present in the arena of action painting. Minimalism argued that extreme simplicity could capture all of the sublime representation needed in art. Minimalism is variously construed either as a precursor to postmodernism, or as a postmodern movement itself. In the latter perspective, early minimalism yielded advanced modernist works, but the movement partially abandoned this direction when some artists like Robert Morris changed direction in favor of the anti-form movement.
Hal Foster, in his essay "The Crux of Minimalism", examines the extent to which Donald Judd and Robert Morris both acknowledge and exceed Greenbergian Modernism in their published definitions of minimalism. He argues that minimalism is not a "dead end" of modernism, but a "paradigm shift toward postmodern practices that continue to be elaborated today."
The terms have expanded to encompass a movement in music that features such repetition and iteration as those of the compositions of La Monte Young, Terry Riley, Steve Reich, Philip Glass, and John Adams. Minimalist compositions are sometimes known as systems music. The term "minimalist" often colloquially refers to anything that is spare or stripped to its essentials. It has also been used to describe the plays and novels of Samuel Beckett, the films of Robert Bresson, the stories of Raymond Carver, and the automobile designs of Colin Chapman.
Postminimalism.
In the late 1960s Robert Pincus-Witten coined the term postminimalism to describe minimalist-derived art which had content and contextual overtones that minimalism rejected. The term was applied by Pincus-Whitten to the work of Eva Hesse, Keith Sonnier, Richard Serra and new work by former minimalists Robert Smithson, Robert Morris, and Sol LeWitt, and Barry Le Va, and others. Other minimalists including Donald Judd, Dan Flavin, Carl Andre, Agnes Martin, John McCracken and others continued to produce late modernist paintings and sculpture for the remainders of their careers.
In the 1960s the work of the avant-garde minimalist composers La Monte Young, Philip Glass, Steve Reich, and Terry Riley also achieved prominence in the New York art world.
Since then, many artists have embraced minimal or postminimal styles and the label "postmodern" has been attached to them.
Collage, assemblage, installations.
Related to abstract expressionism was the emergence of combining manufactured items with artist materials, moving away from previous conventions of painting and sculpture. The work of Robert Rauschenberg exemplifies this trend. His "combines" of the 1950s were forerunners of pop art and installation art, and used assemblages of large physical objects, including stuffed animals, birds and commercial photographs. Rauschenberg, Jasper Johns, Larry Rivers, John Chamberlain, Claes Oldenburg, George Segal, Jim Dine, and Edward Kienholz were among important pioneers of both abstraction and pop art. Creating new conventions of art-making, they made acceptable in serious contemporary art circles the radical inclusion in their works of unlikely materials. Another pioneer of collage was Joseph Cornell, whose more intimately scaled works were seen as radical because of both his personal iconography and his use of found objects.
Neo-Dada.
In the early 20th century Marcel Duchamp exhibited a urinal as a sculpture. He professed his intent that people look at the urinal as if it were a work of art because he said it was a work of art. He referred to his work as "readymades". "Fountain" was a urinal signed with the pseudonym R. Mutt, the exhibition of which shocked the art world in 1917. This and Duchamp's other works are generally labelled as Dada. Duchamp can be seen as a precursor to conceptual art, other famous examples being John Cage's "4'33"", which is four minutes and thirty three seconds of silence, and Rauschenberg's "Erased de Kooning Drawing". Many conceptual works take the position that art is the result of the viewer viewing an object or act as art, not of the intrinsic qualities of the work itself. Thus, because "Fountain" was exhibited, it was a sculpture.
Marcel Duchamp famously gave up "art" in favor of chess. Avant-garde composer David Tudor created a piece, "Reunion" (1968), written jointly with Lowell Cross, that features a chess game in which each move triggers a lighting effect or projection. Duchamp and Cage played the game at the work's premier.
Steven Best and Douglas Kellner identify Rauschenberg and Jasper Johns as part of the transitional phase, influenced by Marcel Duchamp, between modernism and postmodernism. Both used images of ordinary objects, or the objects themselves, in their work, while retaining the abstraction and painterly gestures of high modernism.
Another trend in art associated with neo-Dada is the use of a number of different media together. Intermedia, a term coined by Dick Higgins and meant to convey new art forms along the lines of Fluxus, concrete poetry, found objects, performance art, and computer art. Higgins was publisher of the Something Else Press, a concrete poet, husband of artist Alison Knowles and an admirer of Marcel Duchamp.
Performance and happenings.
During the late 1950s and 1960s artists with a wide range of interests began to push the boundaries of contemporary art. Yves Klein in France, and in New York City, Carolee Schneemann, Yayoi Kusama, Charlotte Moorman and Yoko Ono and in Germany Joseph Beuys, Wolf Vostell and Nam June Paik were pioneers of performance-based works of art. Groups like The Living Theater with Julian Beck and Judith Malina collaborated with sculptors and painters creating environments, radically changing the relationship between audience and performer especially in their piece "Paradise Now". The Judson Dance Theater, located at the Judson Memorial Church, New York; and the Judson dancers, notably Yvonne Rainer, Trisha Brown, Elaine Summers, Sally Gross, Simonne Forti, Deborah Hay, Lucinda Childs, Steve Paxton and others; collaborated with artists Robert Morris, Robert Whitman, John Cage, Robert Rauschenberg, and engineers like Billy Klüver. Park Place Gallery was a center for musical performances by electronic composers Steve Reich, Philip Glass and other notable performance artists including Joan Jonas.
These performances were intended as works of a new art form combining sculpture, dance, and music or sound, often with audience participation. They were characterized by the reductive philosophies of minimalism and the spontaneous improvisation and expressivity of abstract expressionism. Images of Schneeman's performances of pieces meant to shock are occasionally used to illustrate these kinds of art, and she is often seen photographed while performing her piece "Interior Scroll". However, the images of her performing this piece are illustrating precisely what performance art is not. In performance art, the performance itself is the medium. Other media cannot illustrate performance art. Performance art is performed, not captured. By its nature performance is momentary and evanescent, which is part of the point of the medium as art. Representations of performance art in other media, whether by image, video, narrative or otherwise, select certain points of view in space or time or otherwise involve the inherent limitations of each medium, and which therefore cannot truly illustrate the medium of performance as art.
During the same period, various avant-garde artists created Happenings. Happenings were mysterious and often spontaneous and unscripted gatherings of artists and their friends and relatives in various specified locations, often incorporating exercises in absurdity, physicality, costuming, spontaneous nudity, and various random or seemingly disconnected acts. Notable creators of happenings included Allan Kaprow—who first used the term in 1958, Claes Oldenburg, Jim Dine, Red Grooms, and Robert Whitman.
Intermedia, multi-media.
Another trend in art which has been associated with the term postmodern is the use of a number of different media together. Intermedia, a term coined by Dick Higgins and meant to convey new art forms along the lines of Fluxus, concrete poetry, found objects, performance art, and computer art. Higgins was the publisher of the Something Else Press, a concrete poet married to artist Alison Knowles and an admirer of Marcel Duchamp. Ihab Hassan includes, "Intermedia, the fusion of forms, the confusion of realms," in his list of the characteristics of postmodern art. One of the most common forms of "multi-media art" is the use of video-tape and CRT monitors, termed video art. While the theory of combining multiple arts into one art is quite old, and has been revived periodically, the postmodern manifestation is often in combination with performance art, where the dramatic subtext is removed, and what is left is the specific statements of the artist in question or the conceptual statement of their action.
Fluxus.
Fluxus was named and loosely organized in 1962 by George Maciunas (1931–78), a Lithuanian-born American artist. Fluxus traces its beginnings to John Cage's 1957 to 1959 Experimental Composition classes at the New School for Social Research in New York City. Many of his students were artists working in other media with little or no background in music. Cage's students included Fluxus founding members Jackson Mac Low, Al Hansen, George Brecht and Dick Higgins.
Fluxus encouraged a do-it-yourself aesthetic and valued simplicity over complexity. Like Dada before it, Fluxus included a strong current of anti-commercialism and an anti-art sensibility, disparaging the conventional market-driven art world in favor of an artist-centered creative practice. Fluxus artists preferred to work with whatever materials were at hand, and either created their own work or collaborated in the creation process with their colleagues.
Andreas Huyssen criticises attempts to claim Fluxus for postmodernism as "either the master-code of postmodernism or the ultimately unrepresentable art movement – as it were, postmodernism's sublime." Instead he sees Fluxus as a major Neo-Dadaist phenomena within the avant-garde tradition. It did not represent a major advance in the development of artistic strategies, though it did express a rebellion against "the administered culture of the 1950s, in which a moderate, domesticated Modernism served as ideological prop to the Cold War."
Late period.
The continuation of abstract expressionism, color field painting, lyrical abstraction, geometric abstraction, minimalism, abstract illusionism, process art, pop art, postminimalism, and other late 20th-century modernist movements in both painting and sculpture continue through the first decade of the 21st century and constitute radical new directions in those mediums.
At the turn of the 21st century, well-established artists such as Sir Anthony Caro, Lucian Freud, Cy Twombly, Robert Rauschenberg, Jasper Johns, Agnes Martin, Al Held, Ellsworth Kelly, Helen Frankenthaler, Frank Stella, Kenneth Noland, Jules Olitski, Claes Oldenburg, Jim Dine, James Rosenquist, Alex Katz, Philip Pearlstein, and younger artists including Brice Marden, Chuck Close, Sam Gilliam, Isaac Witkin, Sean Scully, Mahirwan Mamtani, Joseph Nechvatal, Elizabeth Murray, Larry Poons, Richard Serra, Walter Darby Bannard, Larry Zox, Ronnie Landfield, Ronald Davis, Dan Christensen, Joel Shapiro, Tom Otterness, Joan Snyder, Ross Bleckner, Archie Rand, Susan Crile, and dozens of others continued to produce vital and influential paintings and sculpture.
Differences between modernism and postmodernism.
By the early 1980s the postmodern movement in art and architecture began to establish its position through various conceptual and intermedia formats. Postmodernism in music and literature began to take hold earlier. In music postmodernism is described in one reference work, as a "term introduced in the 1970s". while in British literature, "The Oxford Encyclopedia of British Literature" sees Modernism "ceding its predominance to postmodernism" as early as 1939. However dates are highly debatable, especially as according to Andreas Huyssen: "one critic's postmodernism is another critic's modernism". This includes those who are critical of the division between the two and see them as two aspects of the same movement, and believe that late Modernism continues.
Modernism is an encompassing label for a wide variety of cultural movements. Postmodernism is essentially a centralized movement that named itself, based on socio-political theory, although the term is now used in a wider sense to refer to activities from the 20th century onwards which exhibit awareness of and reinterpret the modern.
Postmodern theory asserts that the attempt to canonise Modernism "after the fact" is doomed to undisambiguable contradictions.
In a narrower sense, what was modernist was not necessarily also postmodern. Those elements of Modernism which accentuated the benefits of rationality and socio-technological progress were only modernist.
Criticism and hostility to modernism.
 Modernism's stress on freedom of expression, experimentation, radicalism, and primitivism disregards conventional expectations. In many art forms this often meant startling and alienating audiences with bizarre and unpredictable effects, as in the strange and disturbing combinations of motifs in surrealism or the use of extreme dissonance and atonality in modernist music. In literature this often involved the rejection of intelligible plots or characterization in novels, or the creation of poetry that defied clear interpretation.
After the rise of Joseph Stalin, the Soviet government rejected Modernism on the grounds of alleged elitism, although it had previously endorsed futurism and constructivism. The Nazi government of Germany deemed Modernism narcissistic and nonsensical, as well as "Jewish" (see Anti-semitism) and "Negro". The Nazis exhibited modernist paintings alongside works by the mentally ill in an exhibition entitled "Degenerate Art". Accusations of "formalism" could lead to the end of a career, or worse. For this reason many modernists of the post-war generation felt that they were the most important bulwark against totalitarianism, the "canary in the coal mine", whose repression by a government or other group with supposed authority represented a warning that individual liberties were being threatened. Louis A. Sass compared madness, specifically schizophrenia, and Modernism in a less fascist manner by noting their shared disjunctive narratives, surreal images, and incoherence.
In fact, Modernism flourished mainly in consumer/capitalist societies, despite the fact that its proponents often rejected consumerism itself. However, high modernism began to merge with consumer culture after World War II, especially during the 1960s. In Britain, a youth sub-culture emerged calling itself "modernist" (usually shortened to Mod), following such representative music groups as The Who and The Kinks. The likes of Bob Dylan, Serge Gainsbourg and The Rolling Stones combined popular musical traditions with modernist verse, adopting literary devices derived from James Joyce, Samuel Beckett, James Thurber, T. S. Eliot, Guillaume Apollinaire, Allen Ginsberg, and others. The Beatles developed along similar lines, creating various modernist musical effects on several albums, while musicians such as Frank Zappa, Syd Barrett and Captain Beefheart proved even more experimental. Modernist devices also started to appear in popular cinema, and later on in music videos. Modernist design also began to enter the mainstream of popular culture, as simplified and stylized forms became popular, often associated with dreams of a space age high-tech future.
This merging of consumer and high versions of modernist culture led to a radical transformation of the meaning of "modernism". First, it implied that a movement based on the rejection of tradition had become a tradition of its own. Second, it demonstrated that the distinction between elite modernist and mass consumerist culture had lost its precision. Some writers declared that Modernism had become so institutionalized that it was now "post avant-garde", indicating that it had lost its power as a revolutionary movement. Many have interpreted this transformation as the beginning of the phase that became known as postmodernism. For others, such as art critic Robert Hughes, postmodernism represents an extension of modernism.
"Anti-modern" or "counter-modern" movements seek to emphasize holism, connection and spirituality as remedies or antidotes to modernism. Such movements see Modernism as reductionist, and therefore subject to an inability to see systemic and emergent effects. Many modernists came to this viewpoint, for example Paul Hindemith in his late turn towards mysticism. Writers such as Paul H. Ray and Sherry Ruth Anderson, in "" (2000), Fredrick Turner in "A Culture of Hope" and Lester Brown in "Plan B", have articulated a critique of the basic idea of Modernism itself – that individual creative expression should conform to the realities of technology. Instead, they argue, individual creativity should make everyday life more emotionally acceptable.
Some traditionalist artists like Alexander Stoddart reject Modernism generally as the product of "an epoch of false money allied with false culture".
In some fields the effects of Modernism have remained stronger and more persistent than in others. Visual art has made the most complete break with its past. Most major capital cities have museums devoted to Modern Art as distinct from post-Renaissance art ("circa" 1400 to "circa" 1900). Examples include the Museum of Modern Art in New York, the Tate Modern in London, and the Centre Pompidou in Paris. These galleries make no distinction between modernist and postmodernist phases, seeing both as developments within Modern Art.
Further reading.
</dl>

</doc>
<doc id="19548" url="http://en.wikipedia.org/wiki?curid=19548" title="Marshall McLuhan">
Marshall McLuhan

Herbert Marshall McLuhan, CC (July 21, 1911 – December 31, 1980) was a Canadian philosopher of communication theory and a public intellectual. His work is viewed as one of the cornerstones of the study of media theory, as well as having practical applications in the advertising and television industries.
McLuhan is known for coining the expressions "the medium is the message" and the "global village", and for predicting the World Wide Web almost thirty years before it was invented. Although he was a fixture in media discourse in the late 1960s, his influence began to wane in the early 1970s. In the years after his death, he continued to be a controversial figure in academic circles. With the arrival of the internet, however, interest in his work and perspective has renewed.
Life and career.
Herbert Marshall McLuhan was born in Edmonton, Alberta, to Elsie Naomi (née Hall) and Herbert Ernest McLuhan. His brother, Maurice, was born two years later. "Marshall" was a family name: his maternal grandmother's surname. Both of his parents were born in Canada. His mother was a Baptist schoolteacher who later became an actress. His father was a Methodist and had a real estate business in Edmonton. When World War I broke out, the business failed, and McLuhan's father enlisted in the Canadian army. After a year of service he contracted influenza and remained in Canada, away from the front. After Herbert's discharge from the army in 1915, the McLuhan family moved to Winnipeg, Manitoba, where Marshall grew up and went to school, attending Kelvin Technical School before enrolling in the University of Manitoba in 1928.
At Manitoba, McLuhan explored his conflicted relationship with religion and turned to literature to "gratify his soul's hunger for truth and beauty," later referring to this stage as agnosticism. After studying for one year as an engineering student, McLuhan changed majors and earned a BA (1933)—winning a University Gold Medal in Arts and Sciences—and later, in 1934, an MA (1934) in English from the University of Manitoba. He had long desired to pursue graduate studies in England and, having failed to secure a Rhodes scholarship to Oxford, he was accepted to the University of Cambridge.
Although he had already earned a BA and an MA degree at Manitoba, Cambridge required him to enroll as an undergraduate "affiliated" student, with one year's credit towards a three-year Bachelor's degree, before entering any doctoral studies. He entered Trinity Hall, Cambridge in the autumn of 1934, where he studied under I. A. Richards and F. R. Leavis, and was influenced by New Criticism. Upon reflection years afterward, he credited the faculty there with influencing the direction of his later work because of their emphasis on the "training of perception" and such concepts as Richards's notion of "feedforward". These studies formed an important precursor to his later ideas on technological forms. He received the required bachelor's degree from Cambridge in 1936 and entered their graduate program. Later, he returned from England to take a job as a teaching assistant at the University of Wisconsin–Madison that he held for the 1936–37 academic year, being unable to find a suitable job in Canada.
While studying the trivium at Cambridge he took the first steps toward his eventual conversion to Roman Catholicism in 1937, founded on his reading of G. K. Chesterton. In 1935 he wrote to his mother: "[H]ad I not encountered Chesterton, I would have remained agnostic for many years at least". At the end of March 1937, McLuhan completed what was a slow, but total conversion process, when he was formally received into the Roman Catholic Church. After consulting a minister, his father accepted the decision to convert. His mother, however, felt that his conversion would hurt his career and was inconsolable. McLuhan was devout throughout his life, but his religion remained a private matter. He had a lifelong interest in the number three —the trivium, the Trinity—and sometimes said that the Virgin Mary provided intellectual guidance for him. For the rest of his career he taught in Roman Catholic institutions of higher education. From 1937 to 1944 he taught English at Saint Louis University (with an interruption from 1939 to 1940, when he returned to Cambridge). At Saint Louis he tutored and befriended Walter J. Ong, S.J. (1912–2003), who would go on to write his Ph.D. dissertation on a topic McLuhan had called to his attention, and who also would later become a well-known authority on communication and technology.
While in St. Louis, he also met his future wife. On August 4, 1939, McLuhan married teacher and aspiring actress Corinne Lewis (1912–2008) of Fort Worth, Texas, and they spent 1939–40 in Cambridge, where he completed his master's degree (awarded in January 1940) and began to work on his doctoral dissertation on Thomas Nashe and the verbal arts. War had broken out in Europe while the McLuhans were in England, and he obtained permission to complete and submit his dissertation from the United States, without having to return to Cambridge for an oral defence. In 1940 the McLuhans returned to Saint Louis University, where he continued teaching and they started a family. He was awarded a Ph.D. in December 1943. Returning to Canada, from 1944 to 1946 McLuhan taught at Assumption College in Windsor, Ontario. Moving to Toronto in 1946, McLuhan joined the faculty of St. Michael's College, a Catholic college of the University of Toronto. Hugh Kenner was one of his students and Canadian economist and communications scholar Harold Innis was a university colleague who had a strong influence on McLuhan's work. McLuhan wrote in 1964: "I am pleased to think of my own book "The Gutenberg Galaxy" as a footnote to the observations of Innis on the subject of the psychic and social consequences, first of writing then of printing."
In the early 1950s, McLuhan began the Communication and Culture seminars, funded by the Ford Foundation, at the University of Toronto. As his reputation grew, he received a growing number of offers from other universities and, to keep him, the university created the Centre for Culture and Technology in 1963. He published his first major work during this period: "" (1951) was an examination of the effect of advertising on society and culture. He also produced an important journal, "Explorations", with Edmund Carpenter, throughout the 1950s. Together with Harold Innis, Eric A. Havelock, and Northrop Frye, McLuhan and Carpenter have been characterized as the Toronto School of communication theory. During this time McLuhan supervised the doctoral thesis of modernist writer Sheila Watson, on the subject of Wyndham Lewis. McLuhan remained at the University of Toronto through 1979, spending much of this time as head of his Centre for Culture and Technology.
McLuhan was named to the Albert Schweitzer Chair in Humanities at Fordham University in the Bronx, New York, for one year (1967–68). While at Fordham, McLuhan was diagnosed with a benign brain tumor; it was treated successfully. He returned to Toronto, where, for the rest of his life, he taught at the University of Toronto and lived in Wychwood Park, a bucolic enclave on a hill overlooking the downtown where Anatol Rapoport was his neighbour. In 1970, McLuhan was made a Companion of the Order of Canada. In 1975 the University of Dallas hosted him from April to May, appointing him to the McDermott Chair.
Marshall and Corinne McLuhan had six children: Eric, twins Mary and Teresa, Stephanie, Elizabeth and Michael. The associated costs of a large family eventually drove McLuhan to advertising work and accepting frequent consulting and speaking engagements for large corporations, IBM and AT&T among them. In September 1979 he suffered a stroke, which affected his ability to speak. The University of Toronto's School of Graduate Studies tried to close his research centre shortly thereafter, but was deterred by substantial protests, most notably by Woody Allen. Allen's Oscar-winning motion picture "Annie Hall" (1977) had McLuhan in a cameo as himself: a pompous academic arguing with Allen in a cinema queue is silenced by McLuhan suddenly appearing and saying, "You know nothing of my work." This was one of McLuhan's most frequent statements to and about those who would disagree with him.
He never fully recovered from the stroke, and died in his sleep on December 31, 1980.
Major works.
During his years at Saint Louis University (1937–1944), McLuhan worked concurrently on two projects: his doctoral dissertation and the manuscript that was eventually published in 1951 as the book "The Mechanical Bride: Folklore of Industrial Man", which included only a representative selection of the materials that McLuhan had prepared for it.
McLuhan's 1942 Cambridge University doctoral dissertation surveys the history of the verbal arts (grammar, logic, and rhetoric—collectively known as the trivium) from the time of Cicero down to the time of Thomas Nashe. In his later publications, McLuhan at times uses the Latin concept of the "trivium" to outline an orderly and systematic picture of certain periods in the history of Western culture. McLuhan suggests that the Middle Ages, for instance, was characterized by the heavy emphasis on the formal study of logic. The key development that led to the Renaissance was not the rediscovery of ancient texts but a shift in emphasis from the formal study of logic to rhetoric and language. Modern life is characterized by the reemergence of grammar as its most salient feature—a trend McLuhan felt was exemplified by the New Criticism of Richards and Leavis.
In "The Mechanical Bride", McLuhan turned his attention to analysing and commenting on numerous examples of persuasion in contemporary popular culture. This followed naturally from his earlier work as both dialectic and rhetoric in the classical trivium aimed at persuasion. At this point his focus shifted dramatically, turning inward to study the influence of communication media independent of their content. His famous aphorism "the medium is the message" (elaborated in his 1964 book, "") calls attention to this intrinsic effect of communications media.
McLuhan also started the journal "Explorations" with anthropologist Edmund "Ted" Carpenter. In a letter to Walter Ong dated May 31, 1953, McLuhan reported that he had received a two-year grant of $43,000 from the Ford Foundation to carry out a communication project at the University of Toronto involving faculty from different disciplines, which led to the creation of the journal.
Tom Wolfe suggests that a hidden influence on McLuhan's work is the Catholic philosopher Teilhard de Chardin whose ideas anticipated those of McLuhan, especially the evolution of the human mind into the "noosphere". Wolfe theorizes that McLuhan may have thought that association of his ideas with those of a Catholic theologian, albeit one suppressed by Rome, might have denied him the intellectual audience he wanted to reach and so omitted all reference of de Chardin from his published work, while privately acknowledging his influence.
"The Mechanical Bride" (1951).
McLuhan's first book, "" (1951), is a pioneering study in the field now known as popular culture. His interest in the critical study of popular culture was influenced by the 1933 book "Culture and Environment" by F. R. Leavis and Denys Thompson, and the title "The Mechanical Bride" is derived from a piece by the Dadaist artist, Marcel Duchamp.
Like his 1962 book "The Gutenberg Galaxy", "The Mechanical Bride" is unique and composed of a number of short essays that can be read in any order—what he styled the "mosaic approach" to writing a book. Each essay begins with a newspaper or magazine article or an advertisement, followed by McLuhan's analysis thereof. The analyses bear on aesthetic considerations as well as on the implications behind the imagery and text. McLuhan chose the ads and articles included in his book not only to draw attention to their symbolism and their implications for the corporate entities that created and disseminated them, but also to mull over what such advertising implies about the wider society at which it is aimed.
"The Gutenberg Galaxy" (1962).
McLuhan's "The Gutenberg Galaxy: The Making of Typographic Man" (written in 1961, first published in Canada by University of Toronto Press in 1962) is a pioneering study in the fields of oral culture, print culture, cultural studies, and media ecology.
Throughout the book, McLuhan takes pains to reveal how communication technology (alphabetic writing, the printing press, and the electronic media) affects cognitive organization, which in turn has profound ramifications for social organization:
...[I]f a new technology extends one or more of our senses outside us into the social world, then new ratios among all of our senses will occur in that particular culture. It is comparable to what happens when a new note is added to a melody. And when the sense ratios alter in any culture then what had appeared lucid before may suddenly become opaque, and what had been vague or opaque will become translucent.
Movable type.
His episodic history takes the reader from pre-alphabetic tribal humankind to the electronic age. According to McLuhan, the invention of movable type greatly accelerated, intensified, and ultimately enabled cultural and cognitive changes that had already been taking place since the invention and implementation of the alphabet, by which McLuhan means phonemic orthography. (McLuhan is careful to distinguish the phonetic alphabet from logographic/logogramic writing systems, like hieroglyphics or ideograms.)
Print culture, ushered in by the Gutenberg press in the middle of the fifteenth century, brought about the cultural predominance of the visual over the aural/oral. Quoting with approval an observation on the nature of the printed word from "Prints and Visual Communication" by William Ivins, McLuhan remarks:
In this passage [Ivins] not only notes the ingraining of lineal, sequential habits, but, even more important, points out the visual homogenizing of experience of print culture, and the relegation of auditory and other sensuous complexity to the background. [...] The technology and social effects of typography incline us to abstain from noting interplay and, as it were, "formal" causality, both in our inner and external lives. Print exists by virtue of the static separation of functions and fosters a mentality that gradually resists any but a separative and compartmentalizing or specialist outlook.
The main concept of McLuhan's argument (later elaborated upon in "The Medium is the Massage") is that new technologies (like alphabets, printing presses, and even speech itself) exert a gravitational effect on cognition, which in turn affects social organization: print technology changes our perceptual habits ("visual homogenizing of experience"), which in turn affects social interactions ("fosters a mentality that gradually resists all but a... specialist outlook"). According to McLuhan, the advent of print technology contributed to and made possible most of the salient trends in the Modern period in the Western world: individualism, democracy, Protestantism, capitalism and nationalism. For McLuhan, these trends all reverberate with print technology's principle of "segmentation of actions and functions and principle of visual quantification."
The Global Village.
In the early 1960s, McLuhan wrote that the visual, individualistic print culture would soon be brought to an end by what he called "electronic interdependence": when electronic media replace visual culture with aural/oral culture. In this new age, humankind will move from individualism and fragmentation to a collective identity, with a "tribal base." McLuhan's coinage for this new social organization is the "global village".
The term is sometimes described as having negative connotations in "The Gutenberg Galaxy", but McLuhan himself was interested in exploring effects, not making value judgments:
Instead of tending towards a vast Alexandrian library the world has become a computer, an electronic brain, exactly as an infantile piece of science fiction. And as our senses have gone outside us, Big Brother goes inside. So, unless aware of this dynamic, we shall at once move into a phase of panic terrors, exactly befitting a small world of tribal drums, total interdependence, and superimposed co-existence. [...] Terror is the normal state of any oral society, for in it everything affects everything all the time. [...] In our long striving to recover for the Western world a unity of sensibility and of thought and feeling we have no more been prepared to accept the tribal consequences of such unity than we were ready for the fragmentation of the human psyche by print culture.
Key to McLuhan's argument is the idea that technology has no "per se" moral bent—it is a tool that profoundly shapes an individual's and, by extension, a society's self-conception and realization:
Is it not obvious that there are always enough moral problems without also taking a moral stand on technological grounds? [...] Print is the extreme phase of alphabet culture that detribalizes or decollectivizes man in the first instance. Print raises the visual features of alphabet to highest intensity of definition. Thus print carries the individuating power of the phonetic alphabet much further than manuscript culture could ever do. Print is the technology of individualism. If men decided to modify this visual technology by an electric technology, individualism would also be modified. To raise a moral complaint about this is like cussing a buzz-saw for lopping off fingers. "But", someone says, "we didn't know it would happen." Yet even witlessness is not a moral issue. It is a problem, but not a moral problem; and it would be nice to clear away some of the moral fogs that surround our technologies. It would be good for morality.
The moral valence of technology's effects on cognition is, for McLuhan, a matter of perspective. For instance, McLuhan contrasts the considerable alarm and revulsion that the growing quantity of books aroused in the latter seventeenth century with the modern concern for the "end of the book". If there can be no universal moral sentence passed on technology, McLuhan believes that "there can only be disaster arising from unawareness of the causalities and effects inherent in our technologies".
Though the World Wide Web was invented almost thirty years after "The Gutenberg Galaxy", and ten years after his death, McLuhan prophesied the web technology seen today as early as 1962:
The next medium, whatever it is—it may be the extension of consciousness—will include television as its content, not as its environment, and will transform television into an art form. A computer as a research and communication instrument could enhance retrieval, obsolesce mass library organization, retrieve the individual's encyclopedic function and flip into a private line to speedily tailored data of a saleable kind. (1962)
Furthermore, McLuhan coined and certainly popularized the usage of the term "surfing" to refer to rapid, irregular and multidirectional movement through a heterogeneous body of documents or knowledge, e.g., statements like "Heidegger surf-boards along on the electronic wave as triumphantly as Descartes rode the mechanical wave." Paul Levinson's 1999 book "Digital McLuhan" explores the ways that McLuhan's work can be better understood through the lens of the digital revolution.
McLuhan frequently quoted Walter Ong's "Ramus, Method, and the Decay of Dialogue" (1958), which evidently had prompted McLuhan to write "The Gutenberg Galaxy". Ong wrote a highly favorable review of this new book in "America". However, Ong later tempered his praise, by describing McLuhan's "The Gutenberg Galaxy" as "a racy survey, indifferent to some scholarly detail, but uniquely valuable in suggesting the sweep and depth of the cultural and psychological changes entailed in the passage from illiteracy to print and beyond." McLuhan himself said of the book, "I'm not concerned to get any kudos out of ["The Gutenberg Galaxy"]. It seems to me a book that somebody should have written a century ago. I wish somebody else had written it. It will be a useful prelude to the rewrite of "Understanding Media" [the 1960 NAEB report] that I'm doing now." 
McLuhan's "The Gutenberg Galaxy" won Canada's highest literary award, the Governor-General's Award for Non-Fiction, in 1962. The chairman of the selection committee was McLuhan's colleague at the University of Toronto and oftentime intellectual sparring partner, Northrop Frye.
"Understanding Media" (1964).
McLuhan's most widely known work, "Understanding Media: The Extensions of Man" (1964), is a pioneering study in media theory. Dismayed by the way people approached and used new media such as television, McLuhan famously argued that in the modern world "we live mythically and integrally ... but continue to think in the old, fragmented space and time patterns of the pre-electric age."
McLuhan proposed that media themselves, not the content they carry, should be the focus of study—popularly quoted as "the medium is the message". McLuhan's insight was that a medium affects the society in which it plays a role not by the content delivered over the medium, but by the characteristics of the medium itself. McLuhan pointed to the light bulb as a clear demonstration of this concept. A light bulb does not have content in the way that a newspaper has articles or a television has programs, yet it is a medium that has a social effect; that is, a light bulb enables people to create spaces during nighttime that would otherwise be enveloped by darkness. He describes the light bulb as a medium without any content. McLuhan states that "a light bulb creates an environment by its mere presence." More controversially, he postulated that content had little effect on society—in other words, it did not matter if television broadcasts children's shows or violent programming, to illustrate one example—the effect of television on society would be identical. He noted that all media have characteristics that engage the viewer in different ways; for instance, a passage in a book could be reread at will, but a movie had to be screened again in its entirety to study any individual part of it.
"Hot" and "cool" media.
In the first part of "Understanding Media," McLuhan also stated that different media invite different degrees of participation on the part of a person who chooses to consume a medium. Some media, like the movies, were "hot"—that is, they enhance one single sense, in this case vision, in such a manner that a person does not need to exert much effort in filling in the details of a movie image. McLuhan contrasted this with "cool" TV, which he claimed requires more effort on the part of the viewer to determine meaning, and comics, which due to their minimal presentation of visual detail require a high degree of effort to fill in details that the cartoonist may have intended to portray. A movie is thus said by McLuhan to be "hot", intensifying one single sense "high definition", demanding a viewer's attention, and a comic book to be "cool" and "low definition", requiring much more conscious participation by the reader to extract value.
"Any hot medium allows of less participation than a cool one, as a lecture makes for less participation than a seminar, and a book for less than a dialogue."
Hot media usually, but not always, provide complete involvement without considerable stimulus. For example, print occupies visual space, uses visual senses, but can immerse its reader. Hot media favour analytical precision, quantitative analysis and sequential ordering, as they are usually sequential, linear and logical. They emphasize one sense (for example, of sight or sound) over the others. For this reason, hot media also include radio, as well as film, the lecture and photography.
Cool media, on the other hand, are usually, but not always, those that provide little involvement with substantial stimulus. They require more active participation on the part of the user, including the perception of abstract patterning and simultaneous comprehension of all parts. Therefore, according to McLuhan cool media include television, as well as the seminar and cartoons. McLuhan describes the term "cool media" as emerging from jazz and popular music and, in this context, is used to mean "detached."
This concept appears to force media into binary categories. However, McLuhan's hot and cool exist on a continuum: they are more correctly measured on a scale than as dichotomous terms.
Critiques of "Understanding Media".
Some theorists have attacked McLuhan’s definition and treatment of the word "medium" for being too simplistic. Umberto Eco, for instance, contends that McLuhan’s medium conflates channels, codes, and messages under the overarching term of the medium, confusing the vehicle, internal code, and content of a given message in his framework.
In "Media Manifestos", Régis Debray also takes issue with McLuhan’s envisioning of the medium. Like Eco, he too is ill at ease with this reductionist approach, summarizing its ramifications as follows:
 The list of objections could be and has been lengthened indefinitely: confusing technology itself with its use of the media makes of the media an abstract, undifferentiated force and produces its image in an imaginary "public" for mass consumption; the magical naivete of supposed causalities turns the media into a catch-all and contagious "mana"; apocalyptic millenarianism invents the figure of a homo mass-mediaticus without ties to historical and social context, and so on.
Furthermore, when "Wired" interviewed him in 1995, Debray stated that he views McLuhan "more as a poet than a historian, a master of intellectual collage rather than a systematic analyst ... McLuhan overemphasizes the technology behind cultural change at the expense of the usage that the messages and codes make of that technology."
Dwight Macdonald, in turn, reproached McLuhan for his focus on television and for his "aphoristic" style of prose, which he believes left "Understanding Media" filled with "contradictions, non-sequiturs, facts that are distorted and facts that are not facts, exaggerations, and chronic rhetorical vagueness." 
Additionally, Brian Winston’s "Misunderstanding Media", published in 1986, chides McLuhan for what he sees as his technologically deterministic stances. Raymond Williams and James W. Carey further this point of contention, claiming:
The work of McLuhan was a particular culmination of an aesthetic theory which became, negatively, a social theory [...] It is an apparently sophisticated technological determinism which has the significant effect of indicating a social and cultural determinism [...] If the medium - whether print or television – is the cause, of all other causes, all that men ordinarily see as history is at once reduced to effects. (Williams 1990, 126/7)
David Carr states that there has been a long line of "academics who have made a career out of deconstructing McLuhan’s effort to define the modern media ecosystem," whether it be due to what they see as McLuhan’s ignorance toward sociohistorical context or the style of his argument.
While some critics have taken issue with McLuhan’s writing style and mode of argument, McLuhan himself urged readers to think of his work as "probes" or "mosaics" offering a toolkit approach to thinking about the media. His eclectic writing style has also been praised for its postmodern sensibilities and suitability for virtual space.
"The Medium Is the Massage: An Inventory of Effects" (1967).
"The Medium Is the Massage", published in 1967, was McLuhan's best seller, "eventually selling nearly a million copies worldwide." Initiated by Quentin Fiore, McLuhan adopted the term "massage" to denote the effect each medium has on the human sensorium, taking inventory of the "effects" of numerous media in terms of how they "massage" the sensorium.
Fiore, at the time a prominent graphic designer and communications consultant, set about composing the visual illustration of these effects which were compiled by Jerome Agel. Near the beginning of the book, Fiore adopted a pattern in which an image demonstrating a media effect was presented with a textual synopsis on the facing page. The reader experiences a repeated shifting of analytic registers—from "reading" typographic print to "scanning" photographic facsimiles—reinforcing McLuhan's overarching argument in this book: namely, that each medium produces a different "massage" or "effect" on the human sensorium.
In "The Medium is the Massage", McLuhan also rehashed the argument—which first appeared in the Prologue to 1962's "The Gutenberg Galaxy"—that all media are "extensions" of our human senses, bodies and minds.
Finally, McLuhan described key points of change in how man has viewed the world and how these views were changed by the adoption of new media. "The technique of invention was the discovery of the nineteenth [century]", brought on by the adoption of fixed points of view and perspective by typography, while "[t]he technique of the suspended judgment is the discovery of the twentieth century", brought on by the bard abilities of radio, movies and television.
An audio recording version of McLuhan's famous work was made by Columbia Records. The recording consists of a pastiche of statements made by McLuhan "interrupted" by other speakers, including people speaking in various phonations and falsettos, discordant sounds and 1960s incidental music in what could be considered a deliberate attempt to translate the disconnected images seen on TV into an audio format, resulting in the prevention of a connected stream of conscious thought. Various audio recording techniques and statements are used to illustrate the relationship between spoken, literary speech and the characteristics of electronic audio media. McLuhan biographer Philip Marchand called the recording "the 1967 equivalent of a McLuhan video."
"War and Peace in the Global Village" (1968).
McLuhan used James Joyce's "Finnegans Wake", an inspiration for this study of war throughout history, as an indicator as to how war may be conducted in the future.
Joyce's "Wake" is claimed to be a gigantic cryptogram which reveals a cyclic pattern for the whole history of man through its Ten Thunders. Each "thunder" below is a 100-character portmanteau of other words to create a statement he likens to an effect that each technology has on the society into which it is introduced. In order to glean the most understanding out of each, the reader must break the portmanteau into separate words (and many of these are themselves portmanteaus of words taken from multiple languages other than English) and speak them aloud for the spoken effect of each word. There is much dispute over what each portmanteau truly denotes.
McLuhan claims that the ten thunders in "Wake" represent different stages in the history of man:
"From Cliché to Archetype" (1970).
In his 1970 book, "From Cliché to Archetype", McLuhan, collaborating with Canadian poet Wilfred Watson, approached the various implications of the verbal cliché and of the archetype. One major facet in McLuhan's overall framework introduced in this book that is seldom noticed is the provision of a new term that actually succeeds the global village; the "global theater".
In McLuhan's terms, a cliché is a "normal" action, phrase, etc. which becomes so often used that we are "anesthetized" to its effects.
An example of this given by McLuhan is Eugène Ionesco's play "The Bald Soprano", whose dialogue consists entirely of phrases Ionesco pulled from an Assimil language book. "Ionesco originally put all these idiomatic English clichés into literary French which presented the English in the most absurd aspect possible."
McLuhan's "archetype" "is a quoted extension, medium, technology or environment." "Environment" would also include the kinds of "awareness" and cognitive shifts brought upon people by it, not totally unlike the psychological context Carl Jung described.
McLuhan also posits that there is a factor of interplay between the cliché and the archetype, or a "doubleness":
Another theme of the Wake ["Finnegans Wake"] that helps in the understanding of the paradoxical shift from cliché to archetype is 'past time are pastimes.' The dominant technologies of one age become the games and pastimes of a later age. In the 20th century, the number of 'past times' that are simultaneously available is so vast as to create cultural anarchy. When all the cultures of the world are simultaneously present, the work of the artist in the elucidation of form takes on new scope and new urgency. Most men are pushed into the artist's role. The artist cannot dispense with the principle of 'doubleness' or 'interplay' because this type of hendiadys dialogue is essential to the very structure of consciousness, awareness, and autonomy.
McLuhan relates the cliché-to-archetype process to the Theater of the Absurd:
Pascal, in the seventeenth century, tells us that the heart has many reasons of which the head knows nothing. The Theater of the Absurd is essentially a communicating to the head of some of the silent languages of the heart which in two or three hundred years it has tried to forget all about. In the seventeenth century world the languages of the heart were pushed down into the unconscious by the dominant print cliché.
The "languages of the heart", or what McLuhan would otherwise define as oral culture, were thus made archetype by means of the printing press, and turned into cliché.
The satellite medium, McLuhan states, encloses the Earth in a man-made environment, which "ends 'Nature' and turns the globe into a repertory theater to be programmed." All previous environments (book, newspaper, radio, etc.) and their artifacts are retrieved under these conditions ("past times are pastimes"). McLuhan thereby meshes this into the term "global theater". It serves as an update to his older concept of the global village, which, in its own definitions, can be said to be subsumed into the overall condition described by that of the global theater.
"The Global Village: Transformations in World Life and Media in the 21st Century" (1989).
In his 1989 posthumous book, "The Global Village", McLuhan, collaborating with Bruce R. Powers, provided a strong conceptual framework for understanding the cultural implications of the technological advances associated with the rise of a worldwide electronic network. This is a major work of McLuhan's because it contains the most extensive elaboration of his concept of Acoustic Space, and it provides a critique of standard 20th century communication models like the Shannon–Weaver model. McLuhan distinguishes between the existing worldview of Visual Space - a linear, quantitative, classically geometric model - and that of Acoustic Space - a holistic, qualitative order with a complex intricate paradoxical topology. "Acoustic Space has the basic character of a sphere whose focus or center is simultaneously everywhere and whose margin is nowhere." The transition from Visual to Acoustic Space was not automatic with the advent of the global network, but would have to be a conscious project. The "universal environment of simultaneous electronic flow" inherently favors right-brain Acoustic Space, yet we are held back by habits of adhering to a fixed point of view. There are no boundaries to sound. We hear from all directions at once. Yet Acoustic and Visual Space are in fact inseparable. The resonant interval is the invisible borderline between Visual and Acoustic Space. This is like the television camera that the Apollo 8 astronauts focused on the Earth after they had orbited the moon.
Reading, writing, and hierarchical ordering are associated with the left brain, as are the linear concept of time and phonetic literacy. The left brain is the locus of analysis, classification, and rationality. The right brain is the locus of the spatial, tactile, and musical. "Comprehensive awareness" results when the two sides of the brain are in true balance. Visual Space is associated with the simplified worldview of Euclidean geometry, the intuitive three dimensions useful for the architecture of buildings and the surveying of land. It is too rational and has no grasp of the acoustic. Acoustic Space is multisensory.
McLuhan writes about robotism in the context of Japanese Zen Buddhism and how it can offer us new ways of thinking about technology. The Western way of thinking about technology is too much related to the left hemisphere of our brain, which has a rational and linear focus. What he called robotism might better be called androidism in the wake of "Blade Runner" and the novels of Philip K. Dick. Robotism-androidism emerges from the further development of the right hemisphere of the brain, creativity and a new relationship to spacetime (most humans are still living in 17th century classical Newtonian physics spacetime). Robots-androids will have much greater flexibility than humans have had until now, in both mind and body. Robots-androids will teach humanity this new flexibility. And this flexibility of androids (what McLuhan calls robotism) has a strong affinity with Japanese culture and life. McLuhan quotes from Ruth Benedict, "The Chrysanthemum and the Sword", an anthropological study of Japanese culture published in 1946: “Occidentals cannot easily credit the ability of the Japanese to swing from one behavior to another without psychic cost. Such extreme possibilities are not included in our experience. Yet in Japanese life the contradictions, as they seem to us, are as deeply based in their view of life as our uniformities are in ours.” The ability to live in the present and instantly readjust.
Beyond existing communication models.
"All Western scientific models of communication are—like the Shannon–Weaver model—linear, sequential, and logical as a reflection of the late medieval emphasis on the Greek notion of efficient causality." McLuhan and Powers criticize the Shannon-Weaver model of communication as emblematic of left-hemisphere bias and linearity, descended from Aristotelean causality.
A third term of "The Global Village" that McLuhan and Powers develop at length is The Tetrad. The tetrad is something like threads in a complexly interwoven flowing superspace, a four-fold pattern of transformation. "At full maturity the tetrad reveals the metaphoric structure of the artifact as having two figures and two grounds in dynamic and analogical relationship to each other." Like the camera focused on the Earth by the Apollo 8 astronauts, the tetrad reveals figure (Moon) and ground (Earth) simultaneously. The right-brain hemisphere thinking is the capability of being in many places at the same time. Electricity is acoustic. It is simultaneously everywhere. The Tetrad, with its fourfold Möbius topological structure of enhancement, reversal, retrieval and obsolescence, is mobilized by McLuhan and Powers to illuminate the media or technological inventions of cash money, the compass, the computer, the database, the satellite, and the global media network.
Key concepts.
Tetrad.
In "Laws of Media" (1988), published posthumously by his son Eric, McLuhan summarized his ideas about media in a concise tetrad of media effects. The tetrad is a means of examining the effects on society of any technology (i.e., any medium) by dividing its effects into four categories and displaying them simultaneously. McLuhan designed the tetrad as a pedagogical tool, phrasing his laws as questions with which to consider any medium:
The laws of the tetrad exist simultaneously, not successively or chronologically, and allow the questioner to explore the "grammar and syntax" of the "language" of media. McLuhan departs from his mentor Harold Innis in suggesting that a medium "overheats", or reverses into an opposing form, when taken to its extreme.
Visually, a tetrad can be depicted as four diamonds forming an X, with the name of a medium in the centre. The two diamonds on the left of a tetrad are the "Enhancement" and "Retrieval" qualities of the medium, both "Figure" qualities. The two diamonds on the right of a tetrad are the "Obsolescence" and "Reversal" qualities, both "Ground" qualities.
Using the example of radio:
Figure and ground.
McLuhan adapted the Gestalt psychology idea of a "figure and a ground", which underpins the meaning of "The medium is the message." He used this concept to explain how a form of communications technology, the medium or "figure", necessarily operates through its context, or "ground".
McLuhan believed that in order to grasp fully the effect of a new technology, one must examine figure (medium) and ground (context) together, since neither is completely intelligible without the other. McLuhan argued that we must study media in their historical context, particularly in relation to the technologies that preceded them. The present environment, itself made up of the effects of previous technologies, gives rise to new technologies, which, in their turn, further affect society and individuals.
All technologies have embedded within them their own assumptions about time and space. The message which the medium conveys can only be understood if the medium and the environment in which the medium is used—and which, simultaneously, it effectively creates—are analysed together. He believed that an examination of the figure-ground relationship can offer a critical commentary on culture and society.
Legacy.
After the publication of "Understanding Media", McLuhan received an astonishing amount of publicity, making him perhaps the most publicized English teacher in the twentieth century and arguably the most controversial. This publicity had much to do with the work of two California advertising executives, Gerald Feigen and Howard Gossage, who used personal funds to fund their practice of "genius scouting." Much enamoured with McLuhan's work, Feigen and Gossage arranged for McLuhan to meet with editors of several major New York magazines in May 1965 at the Lombardy Hotel in New York. Philip Marchand reports that, as a direct consequence of these meetings, McLuhan was offered the use of an office in the headquarters of both "Time" and "Newsweek", any time he needed it.
In August 1965, Feigen and Gossage held what they called a "McLuhan festival" in the offices of Gossage's advertising agency in San Francisco. During this "festival", McLuhan met with advertising executives, members of the mayor's office, and editors from the San Francisco Chronicle and Ramparts magazine. Perhaps more significant, however, was Tom Wolfe's presence at the festival, which he would later write about in his article, "What If He Is Right?", published in "New York Magazine" and Wolfe's own "The Pump House Gang". According to Feigen and Gossage, however, their work had only a moderate effect on McLuhan's eventual celebrity: they later claimed that their work only "probably speeded up the recognition of [McLuhan's] genius by about six months." In any case, McLuhan soon became a fixture of media discourse. "Newsweek" magazine did a cover story on him; articles appeared in "Life Magazine", "Harper's", "Fortune", "Esquire", and others. Cartoons about him appeared in "The New Yorker". In 1969 "Playboy" magazine published a lengthy interview with him.
McLuhan was credited with coining the phrase "Turn on, tune in, drop out" by its popularizer, Timothy Leary, in the 1960s. In a 1988 interview with Neil Strauss, Leary stated that slogan was "given to him" by McLuhan during a lunch in New York City. Leary said McLuhan "was very much interested in ideas and marketing, and he started singing something like, 'Psychedelics hit the spot / Five hundred micrograms, that’s a lot,' to the tune of a Pepsi commercial. Then he started going, 'Tune in, turn on, and drop out.'"
During his lifetime and afterward, McLuhan heavily influenced cultural critics, thinkers, and media theorists such as Neil Postman, Jean Baudrillard, Timothy Leary, Terence McKenna, William Irwin Thompson, Paul Levinson, Douglas Rushkoff, Jaron Lanier, Hugh Kenner, and John David Ebert, as well as political leaders such as Pierre Elliott Trudeau and Jerry Brown. Andy Warhol was paraphrasing McLuhan with his now famous 15 minutes of fame quote. When asked in the 70s for a way to sedate violences in Angola, he suggested a massive spread of TV devices. The character "Brian O'Blivion" in David Cronenberg's 1983 film Videodrome is a "media oracle" based on McLuhan. In 1991 McLuhan was named as the "patron saint" of "Wired Magazine" and a quote of his appeared on the masthead for the first ten years of its publication. He is mentioned by name in a Peter Gabriel-penned lyric in the song "Fly on a Windshield". This song appears on the concept album "The Lamb Lies Down on Broadway", from progressive rock band Genesis. The lyric is: "Marshall McLuhan, casual viewin' head buried in the sand." McLuhan is also jokingly referred to during an episode of "The Sopranos" entitled "House Arrest". Despite his death in 1980, someone claiming to be McLuhan was posting on a "Wired" mailing list in 1996. The information this individual provided convinced one writer for "Wired" that "if the poster was not McLuhan himself, it was a bot programmed with an eerie command of McLuhan's life and inimitable perspective."
A new centre known as the McLuhan Program in Culture and Technology, formed soon after his death in 1980, is the successor to McLuhan's Centre for Culture and Technology at the University of Toronto and since 1994 it has been part of the University of Toronto Faculty of Information. The first director was literacy scholar and OISE professor David R. Olsen. From 1983 until 2008, the McLuhan Program was under the direction of Dr. Derrick de Kerckhove who was McLuhan's student and translator. Since 2008 Professor Dominique Scheffel-Dunand has been Director of the Program.
Works cited.
This is a partial list of works cited in this article. See Bibliography of Marshall McLuhan for a more comprehensive list of works by and about McLuhan.

</doc>
<doc id="19549" url="http://en.wikipedia.org/wiki?curid=19549" title="Masochism">
Masochism

The word masochism could refer to:

</doc>
<doc id="19550" url="http://en.wikipedia.org/wiki?curid=19550" title="Multiple inheritance">
Multiple inheritance

Multiple inheritance is a feature of some object-oriented computer programming languages in which an object or class can inherit characteristics and features from more than one parent object or parent class. It is distinct from single inheritance, where an object or class may only inherit from one particular object or class.
Multiple inheritance has been a sensitive issue for many years, with opponents pointing to its increased complexity and ambiguity in situations such as the "diamond problem", where it may be ambiguous as to which parent class a particular feature is inherited from if more than one parent class implements said feature. This can be addressed in various ways, including using virtual inheritance. Alternate methods of object composition not based on inheritance such as mixins and traits have also been proposed to address the ambiguity.
Details.
In object-oriented programming (OOPs), "inheritance" describes a relationship between two classes in which one class (the "child" class) "subclassses" the "parent" class. The child inherits methods and attributes of the parent, allowing for shared functionality. For example, one might create a variable class "Mammal" with features such as eating, reproducing, etc.; then define a child class "Cat" that inherits those features without having to explicitly program them, while adding new features like "chasing mice".
Multiple inheritance allows programmers to use more than one totally orthogonal hierarchy simultaneously, such as allowing "Cat" to inherit from "Cartoon character" and "Pet" and "Mammal" and access features from within all of those classes.
Implementations.
Languages that support multiple inheritance include: C++, Common Lisp (via Common Lisp Object System (CLOS)), EuLisp (via The EuLisp Object System TELOS), Curl, Dylan, Eiffel, Logtalk, Object REXX, Scala (via use of mixin classes), OCaml, Perl, Perl 6, POP-11, Python, and Tcl (built-in from 8.6 or via Incremental Tcl (Incr Tcl) in earlier versions).
Some object-oriented languages, such as C#, Java, and Ruby implement "single inheritance", although protocols, or "interfaces," provide some of the functionality of true multiple inheritance.
PHP uses traits classes to inherit multiple functions. Ruby uses modules to inherit multiple methods.
The diamond problem.
The "diamond problem" (sometimes referred to as the "deadly diamond of death") is an ambiguity that arises when two classes B and C inherit from A, and class D inherits from both B and C. If there is a method in A that B and/or C has overridden, and D does not override it, then which version of the method does D inherit: that of B, or that of C?
For example, in the context of GUI software development, a class codice_1 may inherit from both classes codice_2 (for appearance) and codice_3 (for functionality/input handling), and classes codice_2 and codice_3 both inherit from the codice_6 class. Now if the codice_7 method is called for a codice_1 object and there is no such method in the codice_1 class but there is an overridden codice_7 method in codice_2 or codice_3 (or both), which method should be eventually called?
It is called the "diamond problem" because of the shape of the class inheritance diagram in this situation. In this case, class A is at the top, both B and C separately beneath it, and D joins the two together at the bottom to form a diamond shape.
Mitigation.
Languages have different ways of dealing with these problems of repeated inheritance.
Languages that allow only single inheritance, where a class can only derive from one base class, do not have the diamond problem. The reason for this is that such languages have at most one implementation of any method at any level in the inheritance chain regardless of the repetition or placement of methods. Typically these languages allow classes to implement multiple protocols, called interfaces in Java. These protocols define methods but do not provide concrete implementations. This strategy has been used by ActionScript, C#, D, Java, Nemerle, Object Pascal (Delphi), Objective-C, Smalltalk, and Swift. All but Smalltalk allow classes to implement multiple protocols.
Moreover, languages such as Ada, Objective-C, C#, Delphi/Free Pascal, Java, and Swift allow multiple-inheritance of interfaces (called protocols in Objective-C and Swift). Interfaces are like abstract base classes that specify method signatures without implementing any behavior. ("Pure" interfaces such as the ones in Java up to version 7 do not permit any implementation or instance data in the interface.) Nevertheless, even when several interfaces declare the same method signature, as soon as that method is implemented (defined) anywhere in the inheritance chain, it overrides any implementation of that method in the chain above it (in its superclasses). Hence, at any given level in the inheritance chain, there can be at most one implementation of any method. Thus, single-inheritance method implementation does not exhibit the Diamond Problem even with multiple-inheritance of interfaces.

</doc>
<doc id="19552" url="http://en.wikipedia.org/wiki?curid=19552" title="Media studies">
Media studies

 Media studies is a discipline and field of study that deals with the content, history and effects of various media; in particular, the mass media. Media studies may draw on traditions from both the social sciences and the humanities, but mostly from its core disciplines of mass communication, communication, communication sciences and communication studies. Researchers may also develop and employ theories and methods from disciplines including cultural studies, rhetoric (including digital rhetoric), philosophy, literary theory, psychology, political science, political economy, economics, sociology, anthropology, social theory, art history and criticism, film theory, feminist theory, and information theory. McLuhan's aphorism "the medium is the message" was not restricted to mass media, and for him all human artifacts and technologies are media. A medium is anything that mediates our interaction with the world or other humans. Given this perspective of McLuhan's media theory is not restricted to just media of communications but all forms of technology. Another insight of McLuhan's relevant to media theory is that media and their users form an ecosystem and the study of this ecosystem is known as media ecology.
Media studies throughout the world.
Australia.
Media is studied as a broad subject in most states in Australia, with the state of Victoria being a world leader in curriculum development. Media studies in Australia was first developed as an area of study in Victorian universities in the early 1960s, and in secondary schools in the mid 1960s.
Today, almost all Australian universities teach media studies. According to the Government of Australia's "Excellence in Research for Australia" report, the leading universities in the country for media studies (which were ranked well above World standards by the report's scoring methodology) are Monash University, QUT, RMIT, University of Melbourne, University of Queensland and UTS.
In secondary schools, an early film studies course first began being taught as part of the Victorian junior secondary curriculum during the mid 1960s. And, by the early 1970s, an expanded media studies course was being taught. The course became part of the senior secondary curriculum (later known as the Victorian Certificate of Education or "VCE") in the 1980s. It has since become, and continues to be, a strong component of the VCE. Notable figures in the development of the Victorian secondary school curriculum were the long time Rusden College media teacher Peter Greenaway (not the British film director), Trevor Barr (who authored one of the first media text books "Reflections of Reality") and later John Murray (who authored "The Box in the Corner", "In Focus", and "10 Lessons in Film Appreciation"). 
Today, Australian states and territories that teach media studies at a secondary level are Australian Capital Territory, Northern Territory, Queensland, South Australia, Victoria and Western Australia. Media studies does not appear to be taught in the state of New South Wales at a secondary level. 
In Victoria, the VCE media studies course is structured as: Unit 1 - Representation, Technologies of Representation, and New Media; Unit 2 - Media Production, Australian Media Organisations; Unit 3 - Narrative Texts, Production Planning; and Unit 4 - Media Process, Social Values, and Media Influence. Media studies also form a major part of the primary and junior secondary curriculum, and includes areas such as photography, print media and television.
Victoria also hosts the peak media teaching body known as ATOM which publishes "Metro" and "Screen Education" magazines.
China.
There are two universities in China that specialize in media studies. Communication University of China, formerly known as the Beijing Broadcasting Institute, that dates back to 1954. CUC has 15,307 full-time students, including 9264 undergraduates, 3512 candidates for doctor and master degrees and 16780 students in programs of continuing education. The other university known for media studies in China is Zhejiang University of Media and Communications (ZUMC) which has campuses in Hangzhou and Tongxiang. Almost 10,000 full-time students are currently studying in over 50 programs at the 13 Colleges and Schools of ZUMC. Both institutions have produced some of China's brightest broadcasting talents for television as well as leading journalists at magazines and newspapers.
France.
One prominent French media critic is the sociologist Pierre Bourdieu who wrote among other books "On Television" (New Press, 1999). Bourdieu's analysis is that television provides far less autonomy, or freedom, than we think. In his view, the market (which implies the hunt for higher advertising revenue) not only imposes uniformity and banality, but also a form of invisible censorship. When, for example, television producers "pre-interview" participants in news and public affairs programs, to insure that they will speak in simple, attention-grabbing terms, and when the search for viewers leads to an emphasis on the sensational and the spectacular, people with complex or nuanced views are not allowed a hearing.
Germany.
In Germany two main branches of Media Theory or Media Studies can be identified.
The first major branch of media theory has its roots in the humanities and cultural studies, such as theater studies ("Theaterwissenschaft") and German language and literature studies. This branch has broadened out substantially since the 1990s. And it is on this initial basis that media studies in Germany has primarily developed and established itself.
One of the early publications in this new direction is a volume edited by Helmut Kreuzer, "Literature Studies - Media Studies" ("Literaturwissenschaft – Medienwissenschaft"), which summarizes the presentations given at the Düsseldorfer Germanistentag 1976.
The second branch of media studies in Germany is comparable to Communication Studies. Pioneered by Elisabeth Noelle-Neumann in the 1940s, this branch studies mass media, its institutions and its effects on society and individuals. The German Institute for Media and Communication Policy, founded in 2005 by media scholar Lutz Hachmeister, is one of the few independent research institutions that is dedicated to issues surrounding media and communications policies.
The term "Wissenschaft" cannot be translated straightforwardly as "studies", as it calls to mind both scientific methods and the humanities. Accordingly, German media theory combines philosophy, psychoanalysis, history, and scienctific studies with media-specific research.
"Medienwissenschaften" is currently one of the most popular courses of study at universities in Germany, with many applicants mistakenly assuming that studying it will automatically lead to a career in TV or other media. This has led to widespread disillusionment, with students blaming the universities for offering highly theoretical course content. The universities maintain that practical journalistic training is not the aim of the academic studies they offer.
India.
The media industry is growing in India at the rate of 20 percent per annum. Together, entertainment and media form the country's sixth biggest industry, with 3.5 million people working in it. Within the next 4–5 years, the industry is expected to gross eighty thousand crores (800 billion rupees) annually.
With a view to making the best use of communication facilities for information, publicity and development, the Government of India in 1962-63 sought the advice of the Ford Foundation/UNESCO team of internationally known mass communication specialists who recommended the setting up of a national institute for training, teaching and research in mass communication.
Anna University is the first university to take up the idea of India's University Grants Commission (UGC) to start Master of Science in Electronic Media programmes. It offers a five-year integrated programme and a two-year programme in Electronic Media. The was started in January 2002, branching off from the UGC's Educational Multimedia Research Centre (EMMRC).
Netherlands.
In the Netherlands, media studies are split into several academic courses such as (applied) communication sciences, communication- and information sciences, communication and media, media and culture or theater, film and television sciences. Whereas communication sciences focuses on the way people communicate, be it mediated or unmediated, media studies tends to narrow the communication down to just mediated communication. However, it would be a mistake to consider media studies a specialism of communication sciences, since media make up just a small portion of the overall course. Indeed, both studies tend to borrow elements from one another.
Communication sciences (or a derivative thereof) can be studied at Erasmus University Rotterdam, Radboud University, Tilburg University, University of Amsterdam, University of Groningen, University of Twente, Roosevelt Academy, University of Utrecht, VU University Amsterdam and Wageningen University and Research Centre.
Media studies (or something similar) can be studied at the University of Amsterdam, VU University Amsterdam, Erasmus University Rotterdam and the University of Utrecht.
New Zealand.
Media Studies in New Zealand is very healthy, especially due to the NZ film industry and is taught at both secondary and tertiary education institutes. One of the main features of the industry, Weta Digital can be credited with the popularity of Media Studies in NZ. Media Studies in NZ can be regarded as a singular success, with the subject well-established in the tertiary sector (such as at the University of Waikato; Media Studies, Victoria University of Wellington; Film, Television and Media Studies, University of Auckland; Media Studies, Massey University; Communication Studies, University of Otago).
Pakistan.
Media Studies Program is offered in Pakistan by Karachi university, Pakistan this was formerly known as Mass communication. Islamabad is also offering Undergraduate and Postgraduate degree programs in Media Studies, Mass Communications and Media Production. Riphah International University also have its own broadcast facilities such as . Szabist University also offers undergraduate program in various cities across Pakistan, Dubai and UAE.
Switzerland.
In Switzerland, media and communication studies are offered by several higher education institutions including the .
UK.
In the UK, media studies developed in the 1960s from the academic study of English, and from literary criticism more broadly. The key date, according to Andrew Crisell, is 1959:
When Joseph Trenaman left the BBC's Further Education Unit to become the first holder of the Granada Research Fellowship in Television at Leeds University. Soon after in 1966, the Centre for Mass Communication Research was founded at Leicester University, and degree programmes in media studies began to sprout at polytechnics and other universities during the 1970s and 1980s.
James Halloran at Leicester University is credited with much influence in the development of media studies and communication studies, as the head of the university's Centre for Mass Communication Research, and founder of the International Association for Media and Communication Research. Media Studies is now taught all over the UK. It is taught at Key Stages 1– 3, Entry Level, GCSE and at A level and the Scottish Qualifications Authority offers formal qualifications at a number of different levels. It is offered through a large area of exam boards including AQA and WJEC.
United States.
Mass communication, Communications studies or simply 'Communications' may be more popular names than “media studies” for academic departments in the United States. However, the focus of such programs sometimes excludes certain media—film, book publishing, video games, etc. The title “media studies” may be used alone, to designate film studies and rhetorical or critical theory, or it may appear in combinations like “media studies and communication” to join two fields or emphasize a different focus. 
In 1999, the MIT Comparative Media Studies program started under the leadership of Henry Jenkins, since growing into a graduate program, MIT's largest humanities major, and, following a 2012 merger with the Writing and Humanistic Studies program, a roster of twenty faculty, including Pulitzer Prize-winning author Junot Diaz, science fiction writer Joe Haldeman, games scholar T. L. Taylor, and media scholars William Uricchio (a CMS co-founder), Edward Schiappa, and Heather Hendershot. Now named Comparative Media Studies/Writing, the department places an emphasis on what Jenkins and colleagues had termed "applied humanities": it hosts several research groups for civic media, digital humanities, games, computational media, documentary, and mobile design, and these groups are used to provide graduate students with research assistantships to cover the cost of tuition and living expenses. The incorporation of Writing and Humanistic Studies also placed MIT's Science Writing program, Writing Across the Curriculum, and Writing and Communications Center under the same roof.
Formerly an interdisciplinary major at the University of Virginia the Department of Media Studies was officially established in 2001 and has quickly grown to wide recognition. This is partly thanks to the acquisition of Professor Siva Vaidhyanathan, a cultural historian and media scholar, as well as the Inaugural Verklin Media Policy and Ethics Conference, endowed by the CEO of Canoe Ventures and UVA alumnus David Verklin. In 2010, a group of undergraduate students in the Media Studies Department established the Movable Type Academic Journal, the first ever undergraduate academic journal of its kind. The department is expanding rapidly and doubled in size in 2011.
Brooklyn College, part of the City University of New York, has been offering graduate studies in television and media since 1961. Currently, the Department of Television and Radio administers an MS in Media Studies, and hosts the Center for the Study of World Television.
The University of Southern California has three distinct centers for media studies: the Center for Visual Anthropology (founded in 1984), the Institute for Media Literacy at the School of Cinematic Arts (founded in 1998) and the Annenberg School for Communication and Journalism (founded in 1971).
University of California, Irvine had in Mark Poster one of the first and foremost theorists of media culture in the US, and can boast a strong Department of Film & Media Studies. University of California, Berkeley has three institutional structures within which media studies can take place: the department of Film and Media (formerly Film Studies Program), including famous theorists as Mary Ann Doane and Linda Williams, the Center for New Media, and a long established interdisciplinary program formerly titled Mass Communications, which recently changed its name to Media Studies, dropping any connotations which accompany the term “Mass” in the former title. Until recently, Radford University in Virginia used the title "media studies" for a department that taught practitioner-oriented major concentrations in journalism, advertising, broadcast production and Web design. In 2008, those programs were combined with a previous department of communication (speech and public relations) to create a School of Communication. (A media studies major at Radford still means someone concentrating on journalism, broadcasting, advertising or Web production.)
The University of Denver has a renowned program for digital media studies. It is an interdisciplinary program combining Communications, Computer Science, and the arts. 
In 2002 Bernard Luskin of Fielding Graduate University established an EdD program in Media Studies and a PhD program in Media Psychology with a concentration in Media Studies. Courses in Media Studies were started by Luskin at Touro University Worldwide in 2009.

</doc>
<doc id="19553" url="http://en.wikipedia.org/wiki?curid=19553" title="Microprocessor">
Microprocessor

A microprocessor is a computer processor that incorporates the functions of a computer's central processing unit (CPU) on a single integrated circuit (IC), or at most a few integrated circuits. The microprocessor is a multipurpose, programmable device that accepts digital data as input, processes it according to instructions stored in its memory, and provides results as output. It is an example of sequential digital logic, as it has internal memory. Microprocessors operate on numbers and symbols represented in the binary numeral system.
The integration of a whole CPU onto a single chip or on a few chips greatly reduced the cost of processing power. The integrated circuit processor was produced in large numbers by highly automated processes, so unit cost was low. Single-chip processors increase reliability as there are many fewer electrical connections to fail. As microprocessor designs get faster, the cost of manufacturing a chip (with smaller components built on a semiconductor chip the same size) generally stays the same.
Before microprocessors, small computers had been implemented using racks of circuit boards with many medium- and small-scale integrated circuits. Microprocessors integrated this into one or a few large-scale ICs. Continued increases in microprocessor capacity have since rendered other forms of computers almost completely obsolete (see history of computing hardware), with one or more microprocessors used in everything from the smallest embedded systems and handheld devices to the largest mainframes and supercomputers.
Structure.
The internal arrangement of a microprocessor varies depending on the age of the design and the intended purposes of the microprocessor. The complexity of an integrated circuit is bounded by physical limitations of the number of transistors that can be put onto one chip, the number of package terminations that can connect the processor to other parts of the system, the number of interconnections it is possible to make on the chip, and the heat that the chip can dissipate. Advancing technology makes more complex and powerful chips feasible to manufacture.
A minimal hypothetical microprocessor might only include an arithmetic logic unit (ALU) and a control logic section. The ALU performs operations such as addition, subtraction, and operations such as AND or OR. Each operation of the ALU sets one or more flags in a status register, which indicate the results of the last operation (zero value, negative number, overflow, or others). The control logic section retrieves instruction operation codes from memory, and initiates whatever sequence of operations of the ALU requires to carry out the instruction. A single operation code might affect many individual data paths, registers, and other elements of the processor.
As integrated circuit technology advanced, it was feasible to manufacture more and more complex processors on a single chip. The size of data objects became larger; allowing more transistors on a chip allowed word sizes to increase from 4- and 8-bit words up to today's 64-bit words. Additional features were added to the processor architecture; more on-chip registers sped up programs, and complex instructions could be used to make more compact programs. Floating-point arithmetic, for example, was often not available on 8-bit microprocessors, but had to be carried out in software. Integration of the floating point unit first as a separate integrated circuit and then as part of the same microprocessor chip, sped up floating point calculations.
Occasionally, physical limitations of integrated circuits made such practices as a bit slice approach necessary. Instead of processing all of a long word on one integrated circuit, multiple circuits in parallel processed subsets of each data word. While this required extra logic to handle, for example, carry and overflow within each slice, the result was a system that could handle, say, 32-bit words using integrated circuits with a capacity for only four bits each.
With the ability to put large numbers of transistors on one chip, it becomes feasible to integrate memory on the same die as the processor. This CPU cache has the advantage of faster access than off-chip memory, and increases the processing speed of the system for many applications. Processor clock frequency has increased more rapidly than external memory speed, except in the recent past, so cache memory is necessary if the processor is not delayed by slower external memory.
Special-purpose designs.
A microprocessor is a general purpose system. Several specialized processing devices have followed from the technology. Microcontrollers integrate a microprocessor with peripheral devices in embedded systems. A digital signal processor (DSP) is specialized for signal processing. Graphics processing units may have no, limited, or general programming facilities. For example, GPUs through the 1990s were mostly non-programmable and have only recently gained limited facilities like programmable vertex shaders.
32-bit processors have more digital logic than narrower processors, so 32-bit (and wider) processors produce more digital noise and have higher static consumption than narrower processors.
So, 8-bit or 16-bit processors are better than 32-bit processors for system on a chip and microcontrollers that require extremely low-power electronics. Nevertheless, trade-offs apply: Running 32 bit arithmetic on a 8 bit chip could end up using more power, as the chip must execute software with multiple instructions. Modern microprocessors go into low power states when possible, and a 8 bit chip running 32 bit software is active most of the time. This creates a delicate balance between software, hardware and use patterns, plus costs. 
When manufactured on a similar process, 8-bit micros use less power when operating and less power when sleeping than 32-bit micros.
However, some people say a 32-bit micro may use less average power than an 8-bit micro, when the application requires certain operations, such as floating-point math,
that take many more clock cycles on an 8-bit micro than a 32-bit micro,
and so the 8-bit micro spends more time in high-power operating mode.
Embedded applications.
Thousands of items that were traditionally not computer-related include microprocessors. These include large and small household appliances, cars (and their accessory equipment units), car keys, tools and test instruments, toys, light switches/dimmers and electrical circuit breakers, smoke alarms, battery packs, and hi-fi audio/visual components (from DVD players to phonograph turntables). Such products as cellular telephones, DVD video system and HDTV broadcast systems fundamentally require consumer devices with powerful, low-cost, microprocessors. Increasingly stringent pollution control standards effectively require automobile manufacturers to use microprocessor engine management systems, to allow optimal control of emissions over widely varying operating conditions of an automobile. Non-programmable controls would require complex, bulky, or costly implementation to achieve the results possible with a microprocessor.
A microprocessor control program (embedded software) can be easily tailored to different needs of a product line, allowing upgrades in performance with minimal redesign of the product. Different features can be implemented in different models of a product line at negligible production cost.
Microprocessor control of a system can provide control strategies that would be impractical to implement using electromechanical controls or purpose-built electronic controls. For example, an engine control system in an automobile can adjust ignition timing based on engine speed, load on the engine, ambient temperature, and any observed tendency for knocking—allowing an automobile to operate on a range of fuel grades.
History.
The advent of low-cost computers on integrated circuits has transformed modern society. General-purpose microprocessors in personal computers are used for computation, text editing, multimedia display, and communication over the Internet. Many more microprocessors are part of embedded systems, providing digital control over myriad objects from appliances to automobiles to cellular phones and industrial process control.
The first use of the term "microprocessor" is attributed to Viatron Computer Systems describing the custom integrated circuit used in their System 21 small computer system announced in 1968.
Intel introduced its first 4-bit microprocessor 4004 in 1971 and its 8-bit microprocessor 8008 in 1972. During the 1960s, computer processors were constructed out of small and medium-scale ICs—each containing from tens of transistors to a few hundred. These were placed and soldered onto printed circuit boards, and often multiple boards were interconnected in a chassis. The large number of discrete logic gates used more electrical power—and therefore produced more heat—than a more integrated design with fewer ICs. The distance that signals had to travel between ICs on the boards limited a computer's operating speed.
In the NASA Apollo space missions to the moon in the 1960s and 1970s, all onboard computations for primary guidance, navigation and control were provided by a small custom processor called "The Apollo Guidance Computer". It used wire wrap circuit boards whose only logic elements were three-input NOR gates.
The first microprocessors emerged in the early 1970s and were used for electronic calculators, using binary-coded decimal (BCD) arithmetic on 4-bit words. Other embedded uses of 4-bit and 8-bit microprocessors, such as terminals, printers, various kinds of automation etc., followed soon after. Affordable 8-bit microprocessors with 16-bit addressing also led to the first general-purpose microcomputers from the mid-1970s on.
Since the early 1970s, the increase in capacity of microprocessors has followed Moore's law; this originally suggested that the number of components that can be fitted onto a chip doubles every year. With present technology, it is actually every two years, and as such Moore later changed the period to two years.
Firsts.
Three projects delivered a microprocessor at about the same time: Garrett AiResearch's Central Air Data Computer (CADC), Texas Instruments (TI) TMS 1000 (1971 September), and Intel's 4004 (1971 November).
CADC.
In 1968, Garrett AiResearch (which employed designers Ray Holt and Steve Geller) was invited to produce a digital computer to compete with electromechanical systems then under development for the main flight control computer in the US Navy's new F-14 Tomcat fighter. The design was complete by 1970, and used a MOS-based chipset as the core CPU. The design was significantly (approximately 20 times) smaller and much more reliable than the mechanical systems it competed against, and was used in all of the early Tomcat models. This system contained "a 20-bit, pipelined, parallel multi-microprocessor". The Navy refused to allow publication of the design until 1997. For this reason the CADC, and the MP944 chipset it used, are fairly unknown.
Ray Holt graduated California Polytechnic University in 1968, and began his computer design career with the CADC. From its inception, it was shrouded in secrecy until 1998 when at Holt's request, the US Navy allowed the documents into the public domain. Since then people have debated whether this was the first microprocessor. Holt has stated that no one has compared this microprocessor with those that came later. According to Parab et al. (2007), "The scientific papers and literature published around 1971 reveal that the MP944 digital processor used for the F-14 Tomcat aircraft of the US Navy qualifies as the first microprocessor. Although interesting, it was not a single-chip processor, as was not the Intel 4004 – they both were more like a set of parallel building blocks you could use to make a general-purpose form. It contains a CPU, RAM, ROM, and two other support chips like the Intel 4004. It was made from the same P-channel technology, operated at military specifications and had larger chips -- an excellent computer engineering design by any standards. Its design indicates a major advance over Intel, and two year earlier. It actually worked and was flying in the F-14 when the Intel 4004 was announced. It indicates that today’s industry theme of converging DSP-microcontroller architectures was started in 1971." This convergence of DSP and microcontroller architectures is known as a digital signal controller.
Gilbert Hyatt.
Gilbert Hyatt was awarded a patent claiming an invention pre-dating both TI and Intel, describing a "microcontroller". The patent was later invalidated, but not before substantial royalties were paid out.
TMS 1000.
The Smithsonian Institution says TI engineers Gary Boone and Michael Cochran succeeded in creating the first microcontroller (also called a microcomputer) and the first single-chip CPU in 1971. The result of their work was the TMS 1000, which went commercial in 1974.
TI stressed the 4-bit TMS 1000 for use in pre-programmed embedded applications, introducing a version called the TMS1802NC on September 17, 1971 that implemented a calculator on a chip.
TI filed for a patent on the microprocessor. Gary Boone was awarded U.S. Patent for the single-chip microprocessor architecture on September 4, 1973. In 1971 and again in 1976, Intel and TI entered into broad patent cross-licensing agreements, with Intel paying royalties to TI for the microprocessor patent. A history of these events is contained in court documentation from a legal dispute between Cyrix and Intel, with TI as inventor and owner of the microprocessor patent.
A computer-on-a-chip combines the microprocessor core (CPU), memory, and I/O (input/output) lines onto one chip. The computer-on-a-chip patent, called the "microcomputer patent" at the time, U.S. Patent , was awarded to Gary Boone and Michael J. Cochran of TI. Aside from this patent, the standard meaning of microcomputer is a computer using one or more microprocessors as its CPU(s), while the concept defined in the patent is more akin to a microcontroller.
Intel 4004.
The Intel 4004 is generally regarded as the first commercially available microprocessor, and cost $60. The first known advertisement for the 4004 is dated November 15, 1971 and appeared in Electronic News. The project that produced the 4004 originated in 1969, when Busicom, a Japanese calculator manufacturer, asked Intel to build a chipset for high-performance desktop calculators. Busicom's original design called for a programmable chip set consisting of seven different chips. Three of the chips were to make a special-purpose CPU with its program stored in ROM and its data stored in shift register read-write memory. Ted Hoff, the Intel engineer assigned to evaluate the project, believed the Busicom design could be simplified by using dynamic RAM storage for data, rather than shift register memory, and a more traditional general-purpose CPU architecture. Hoff came up with a four–chip architectural proposal: a ROM chip for storing the programs, a dynamic RAM chip for storing data, a simple I/O device and a 4-bit central processing unit (CPU). Although not a chip designer, he felt the CPU could be integrated into a single chip, but as he lacked the technical know-how the idea remained just a wish for the time being.
While the architecture and specifications of the MCS-4 came from the interaction of Hoff with Stanley Mazor, a software engineer reporting to him, and with Busicom engineer Masatoshi Shima, during 1969, Mazor and Hoff moved on to other projects. In April 1970, Intel hired Italian-born engineer Federico Faggin as project leader, a move that ultimately made the single-chip CPU final design a reality (Shima meanwhile designed the Busicom calculator firmware and assisted Faggin during the first six months of the implementation). Faggin, who originally developed the silicon gate technology (SGT) in 1968 at Fairchild Semiconductor and designed the world’s first commercial integrated circuit using SGT, the Fairchild 3708, had the correct background to lead the project into what would become the first commercial general purpose microprocessor. Since SGT was his very own invention, Faggin also used it to create his new methodology for random logic design that made it possible to implement a single-chip CPU with the proper speed, power dissipation and cost. The manager of Intel's MOS Design Department was Leslie L. Vadász at the time of the MCS-4 development, but Vadasz's attention was completely focused on the mainstream business of semiconductor memories and he left the leadership and the management of the MCS-4 project to Faggin, who was ultimately responsible for leading the 4004 project to its realization. Production units of the 4004 were first delivered to Busicom in March 1971 and shipped to other customers in late 1971.
Pico/General Instrument.
In 1971 Pico Electronics and General Instrument (GI) introduced their first collaboration in ICs, a complete single chip calculator IC for the Monroe/Litton Royal Digital III calculator. This chip could also arguably lay claim to be one of the first microprocessors or microcontrollers having ROM, RAM and a RISC instruction set on-chip. The layout for the four layers of the PMOS process was hand drawn at x500 scale on mylar film, a significant task at the time given the complexity of the chip.
Pico was a spinout by five GI design engineers whose vision was to create single chip calculator ICs. They had significant previous design experience on multiple calculator chipsets with both GI and Marconi-Elliott. The key team members had originally been tasked by Elliott Automation to create an 8-bit computer in MOS and had helped establish a MOS Research Laboratory in Glenrothes, Scotland in 1967.
Calculators were becoming the largest single market for semiconductors and Pico and GI went on to have significant success in this burgeoning market. GI continued to innovate in microprocessors and microcontrollers with products including the CP1600, IOB1680 and PIC1650. In 1987 the GI Microelectronics business was spun out into the Microchip PIC microcontroller business.
Four-Phase Systems AL1.
The Four-Phase Systems AL1 was an 8-bit bit slice chip containing eight registers and an ALU. It was designed by Lee Boysel in 1969. At the time, it formed part of a nine-chip, 24-bit CPU with three AL1s, but it was later called a microprocessor when, in response to 1990s litigation by Texas Instruments, a demonstration system was constructed where a single AL1 formed part of a courtroom demonstration computer system, together with RAM, ROM, and an input-output device.
8-bit designs.
The Intel 4004 was followed in 1972 by the Intel 8008, the world's first 8-bit microprocessor. The 8008 was not, however, an extension of the 4004 design, but instead the culmination of a separate design project at Intel, arising from a contract with Computer Terminals Corporation, of San Antonio TX, for a chip for a terminal they were designing, the Datapoint 2200 — fundamental aspects of the design came not from Intel but from CTC. In 1968, CTC's Vic Poor and Harry Pyle developed the original design for the instruction set and operation of the processor. In 1969, CTC contracted two companies, Intel and Texas Instruments, to make a single-chip implementation, known as the CTC 1201. In late 1970 or early 1971, TI dropped out being unable to make a reliable part. In 1970, with Intel yet to deliver the part, CTC opted to use their own implementation in the Datapoint 2200, using traditional TTL logic instead (thus the first machine to run “8008 code” was not in fact a microprocessor at all and was delivered a year earlier). Intel's version of the 1201 microprocessor arrived in late 1971, but was too late, slow, and required a number of additional support chips. CTC had no interest in using it. CTC had originally contracted Intel for the chip, and would have owed them $50,000 for their design work. To avoid paying for a chip they did not want (and could not use), CTC released Intel from their contract and allowed them free use of the design. Intel marketed it as the 8008 in April, 1972, as the world's first 8-bit microprocessor. It was the basis for the famous "Mark-8" computer kit advertised in the magazine "Radio-Electronics" in 1974. This processor had an 8-bit data bus and a 14-bit address bus.
The 8008 was the precursor to the successful Intel 8080 (1974), which offered improved performance over the 8008 and required fewer support chips. Federico Faggin conceived and designed it using high voltage N channel MOS. The Zilog Z80 (1976) was also a Faggin design, using low voltage N channel with depletion load and derivative Intel 8-bit processors: all designed with the methodology Faggin created for the 4004. Motorola released the competing 6800 in August 1974, and the similar MOS Technology 6502 in 1975 (both designed largely by the same people). The 6502 family rivaled the Z80 in popularity during the 1980s.
A low overall cost, small packaging, simple computer bus requirements, and sometimes the integration of extra circuitry (e.g. the Z80's built-in memory refresh circuitry) allowed the home computer "revolution" to accelerate sharply in the early 1980s. This delivered such inexpensive machines as the Sinclair ZX-81, which sold for US$99. A variation of the 6502, the MOS Technology 6510 was used in the Commodore 64 and yet another variant, the 8502, powered the Commodore 128.
The Western Design Center, Inc (WDC) introduced the CMOS 65C02 in 1982 and licensed the design to several firms. It was used as the CPU in the Apple IIe and IIc personal computers as well as in medical implantable grade pacemakers and defibrillators, automotive, industrial and consumer devices. WDC pioneered the licensing of microprocessor designs, later followed by ARM (32-bit) and other microprocessor intellectual property (IP) providers in the 1990s.
Motorola introduced the MC6809 in 1978. It was an ambitious and well thought-through 8-bit design that was source compatible with the 6800, and implemented using purely hard-wired logic. (Subsequent 16-bit microprocessors typically used microcode to some extent, as CISC design requirements were becoming too complex for pure hard-wired logic.)
Another early 8-bit microprocessor was the Signetics 2650, which enjoyed a brief surge of interest due to its innovative and powerful instruction set architecture.
A seminal microprocessor in the world of spaceflight was RCA's RCA 1802 (aka CDP1802, RCA COSMAC) (introduced in 1976), which was used on board the Galileo probe to Jupiter (launched 1989, arrived 1995). RCA COSMAC was the first to implement CMOS technology. The CDP1802 was used because it could be run at very low power, and because a variant was available fabricated using a special production process, silicon on sapphire (SOS), which provided much better protection against cosmic radiation and electrostatic discharge than that of any other processor of the era. Thus, the SOS version of the 1802 was said to be the first radiation-hardened microprocessor.
The RCA 1802 had what is called a static design, meaning that the clock frequency could be made arbitrarily low, even to 0 Hz, a total stop condition. This let the Galileo spacecraft use minimum electric power for long uneventful stretches of a voyage. Timers or sensors would awaken the processor in time for important tasks, such as navigation updates, attitude control, data acquisition, and radio communication. Current versions of the Western Design Center 65C02 and 65C816 have static cores, and thus retain data even when the clock is completely halted.
12-bit designs.
The Intersil 6100 family consisted of a 12-bit microprocessor (the 6100) and a range of peripheral support and memory ICs. The microprocessor recognised the DEC PDP-8 minicomputer instruction set. As such it was sometimes referred to as the CMOS-PDP8. Since it was also produced by Harris Corporation, it was also known as the Harris HM-6100. By virtue of its CMOS technology and associated benefits, the 6100 was being incorporated into some military designs until the early 1980s.
16-bit designs.
The first multi-chip 16-bit microprocessor was the National Semiconductor IMP-16, introduced in early 1973. An 8-bit version of the chipset was introduced in 1974 as the IMP-8.
Other early multi-chip 16-bit microprocessors include one that Digital Equipment Corporation (DEC) used in the LSI-11 OEM board set and the packaged PDP 11/03 minicomputer—and the Fairchild Semiconductor MicroFlame 9440, both introduced in 1975–1976.
In 1975, National introduced the first 16-bit single-chip microprocessor, the National Semiconductor PACE, which was later followed by an NMOS version, the INS8900.
Another early single-chip 16-bit microprocessor was TI's TMS 9900, which was also compatible with their TI-990 line of minicomputers. The 9900 was used in the TI 990/4 minicomputer, the TI-99/4A home computer, and the TM990 line of OEM microcomputer boards. The chip was packaged in a large ceramic 64-pin DIP package, while most 8-bit microprocessors such as the Intel 8080 used the more common, smaller, and less expensive plastic 40-pin DIP. A follow-on chip, the TMS 9980, was designed to compete with the Intel 8080, had the full TI 990 16-bit instruction set, used a plastic 40-pin package, moved data 8 bits at a time, but could only address 16 KB. A third chip, the TMS 9995, was a new design. The family later expanded to include the 99105 and 99110.
The Western Design Center (WDC) introduced the CMOS 65816 16-bit upgrade of the WDC CMOS 65C02 in 1984. The 65816 16-bit microprocessor was the core of the Apple IIgs and later the Super Nintendo Entertainment System, making it one of the most popular 16-bit designs of all time.
Intel "upsized" their 8080 design into the 16-bit Intel 8086, the first member of the x86 family, which powers most modern PC type computers. Intel introduced the 8086 as a cost-effective way of porting software from the 8080 lines, and succeeded in winning much business on that premise. The 8088, a version of the 8086 that used an 8-bit external data bus, was the microprocessor in the first IBM PC. Intel then released the 80186 and 80188, the 80286 and, in 1985, the 32-bit 80386, cementing their PC market dominance with the processor family's backwards compatibility. The 80186 and 80188 were essentially versions of the 8086 and 8088, enhanced with some onboard peripherals and a few new instructions. Although Intel's 80186 and 80188 were not used in IBM PC type designs, second source versions from NEC, the V20 and V30 frequently were. The 8086 and successors had an innovative but limited method of memory segmentation, while the 80286 introduced a full-featured segmented memory management unit (MMU). The 80386 introduced a flat 32-bit memory model with paged memory management.
The 16-bit Intel x86 processors up to and including the 80386 do not include floating-point units (FPUs). Intel introduced the 8087, 80187, 80287 and 80387 math coprocessors to add hardware floating-point and transcendental function capabilities to the 8086 through 80386 CPUs. The 8087 works with the 8086/8088 and 80186/80188, the 80187 works with the 80186 but not the 80188, the 80287 works with the 80286 and the 80387 works with the 80386. The combination of an x86 CPU and an x87 coprocessor forms a single multi-chip microprocessor; the two chips are programmed as a unit using a single integrated instruction set. The 8087 and 80187 coprocessors are connected in parallel with the data and address buses of their parent processor and directly execute instructions intended for them. The 80287 and 80387 coprocessors are interfaced to the CPU through I/O ports in the CPU's address space, this is transparent to the program, which does not need to know about or access these I/O ports directly; the program accesses the coprocessor and its registers through normal instruction opcodes.
32-bit designs.
16-bit designs had only been on the market briefly when 32-bit implementations started to appear.
The most significant of the 32-bit designs is the Motorola MC68000, introduced in 1979. The 68k, as it was widely known, had 32-bit registers in its programming model but used 16-bit internal data paths, three 16-bit Arithmetic Logic Units, and a 16-bit external data bus (to reduce pin count), and externally supported only 24-bit addresses (internally it worked with full 32 bit addresses). In PC-based IBM-compatible mainframes the MC68000 internal microcode was modified to emulate the 32-bit System/370 IBM mainframe. Motorola generally described it as a 16-bit processor, though it clearly has 32-bit capable architecture. The combination of high performance, large (16 megabytes or 224 bytes) memory space and fairly low cost made it the most popular CPU design of its class. The Apple Lisa and Macintosh designs made use of the 68000, as did a host of other designs in the mid-1980s, including the Atari ST and Commodore Amiga.
The world's first single-chip fully 32-bit microprocessor, with 32-bit data paths, 32-bit buses, and 32-bit addresses, was the AT&T Bell Labs BELLMAC-32A, with first samples in 1980, and general production in 1982. After the divestiture of AT&T in 1984, it was renamed the WE 32000 (WE for Western Electric), and had two follow-on generations, the WE 32100 and WE 32200. These microprocessors were used in the AT&T 3B5 and 3B15 minicomputers; in the 3B2, the world's first desktop super microcomputer; in the "Companion", the world's first 32-bit laptop computer; and in "Alexander", the world's first book-sized super microcomputer, featuring ROM-pack memory cartridges similar to today's gaming consoles. All these systems ran the UNIX System V operating system.
The first commercial, single chip, fully 32-bit microprocessor available on the market was the HP FOCUS.
Intel's first 32-bit microprocessor was the iAPX 432, which was introduced in 1981 but was not a commercial success. It had an advanced capability-based object-oriented architecture, but poor performance compared to contemporary architectures such as Intel's own 80286 (introduced 1982), which was almost four times as fast on typical benchmark tests. However, the results for the iAPX432 was partly due to a rushed and therefore suboptimal Ada compiler.
Motorola's success with the 68000 led to the MC68010, which added virtual memory support. The MC68020, introduced in 1984 added full 32-bit data and address buses. The 68020 became hugely popular in the Unix supermicrocomputer market, and many small companies (e.g., Altos, Charles River Data Systems, Cromemco) produced desktop-size systems. The MC68030 was introduced next, improving upon the previous design by integrating the MMU into the chip. The continued success led to the MC68040, which included an FPU for better math performance. A 68050 failed to achieve its performance goals and was not released, and the follow-up MC68060 was released into a market saturated by much faster RISC designs. The 68k family faded from the desktop in the early 1990s.
Other large companies designed the 68020 and follow-ons into embedded equipment. At one point, there were more 68020s in embedded equipment than there were Intel Pentiums in PCs. The ColdFire processor cores are derivatives of the venerable 68020.
During this time (early to mid-1980s), National Semiconductor introduced a very similar 16-bit pinout, 32-bit internal microprocessor called the NS 16032 (later renamed 32016), the full 32-bit version named the NS 32032. Later, National Semiconductor produced the NS 32132, which allowed two CPUs to reside on the same memory bus with built in arbitration. The NS32016/32 outperformed the MC68000/10, but the NS32332—which arrived at approximately the same time as the MC68020—did not have enough performance. The third generation chip, the NS32532, was different. It had about double the performance of the MC68030, which was released around the same time. The appearance of RISC processors like the AM29000 and MC88000 (now both dead) influenced the architecture of the final core, the NS32764. Technically advanced—with a superscalar RISC core, 64-bit bus, and internally overclocked—it could still execute Series 32000 instructions through real-time translation.
When National Semiconductor decided to leave the Unix market, the chip was redesigned into the Swordfish Embedded processor with a set of on chip peripherals. The chip turned out to be too expensive for the laser printer market and was killed. The design team went to Intel and there designed the Pentium processor, which is very similar to the NS32764 core internally. The big success of the Series 32000 was in the laser printer market, where the NS32CG16 with microcoded BitBlt instructions had very good price/performance and was adopted by large companies like Canon. By the mid-1980s, Sequent introduced the first SMP server-class computer using the NS 32032. This was one of the design's few wins, and it disappeared in the late 1980s. The MIPS R2000 (1984) and R3000 (1989) were highly successful 32-bit RISC microprocessors. They were used in high-end workstations and servers by SGI, among others. Other designs included the Zilog Z80000, which arrived too late to market to stand a chance and disappeared quickly.
The ARM first appeared in 1985. This is a RISC processor design, which has since come to dominate the 32-bit embedded systems processor space due in large part to its power efficiency, its licensing model, and its wide selection of system development tools. Semiconductor manufacturers generally license cores and integrate them into their own system on a chip products; only a few such vendors are licensed to modify the ARM cores. Most cell phones include an ARM processor, as do a wide variety of other products. There are microcontroller-oriented ARM cores without virtual memory support, as well as symmetric multiprocessor (SMP) applications processors with virtual memory.
In the late 1980s, "microprocessor wars" started killing off some of the microprocessors. Apparently, with only one bigger design win, Sequent, the NS 32032 just faded out of existence, and Sequent switched to Intel microprocessors.
From 1993 to 2003, the 32-bit x86 architectures became increasingly dominant in desktop, laptop, and server markets, and these microprocessors became faster and more capable. Intel had licensed early versions of the architecture to other companies, but declined to license the Pentium, so AMD and Cyrix built later versions of the architecture based on their own designs. During this span, these processors increased in complexity (transistor count) and capability (instructions/second) by at least three orders of magnitude. Intel's Pentium line is probably the most famous and recognizable 32-bit processor model, at least with the public at broad.
64-bit designs in personal computers.
While 64-bit microprocessor designs have been in use in several markets since the early 1990s (including the Nintendo 64 gaming console in 1996), the early 2000s saw the introduction of 64-bit microprocessors targeted at the PC market.
With AMD's introduction of a 64-bit architecture backwards-compatible with x86, x86-64 (also called AMD64), in September 2003, followed by Intel's near fully compatible 64-bit extensions (first called IA-32e or EM64T, later renamed Intel 64), the 64-bit desktop era began. Both versions can run 32-bit legacy applications without any performance penalty as well as new 64-bit software. With operating systems Windows XP x64, Windows Vista x64, Windows 7 x64, Linux, BSD, and Mac OS X that run 64-bit native, the software is also geared to fully utilize the capabilities of such processors. The move to 64 bits is more than just an increase in register size from the IA-32 as it also doubles the number of general-purpose registers.
The move to 64 bits by PowerPC processors had been intended since the processors' design in the early 90s and was not a major cause of incompatibility. Existing integer registers are extended as are all related data pathways, but, as was the case with IA-32, both floating point and vector units had been operating at or above 64 bits for several years. Unlike what happened when IA-32 was extended to x86-64, no new general purpose registers were added in 64-bit PowerPC, so any performance gained when using the 64-bit mode for applications making no use of the larger address space is minimal.
In 2011, ARM introduced a new 64-bit ARM architecture.
Multi-core designs.
A different approach to improving a computer's performance is to add extra processors, as in symmetric multiprocessing designs, which have been popular in servers and workstations since the early 1990s. Keeping up with Moore's Law is becoming increasingly challenging as chip-making technologies approach their physical limits. In response, microprocessor manufacturers look for other ways to improve performance so they can maintain the momentum of constant upgrades.
A multi-core processor is a single chip that contains more than one microprocessor core. Each core can simultaneously execute processor instructions in parallel. This effectively multiplies the processor's potential performance by the number of cores, if the software is designed to take advantage of more than one processor core. Some components, such as bus interface and cache, may be shared between cores. Because the cores are physically close to each other, they can communicate with each other much faster than separate (off-chip) processors in a multiprocessor system, which improves overall system performance.
In 2005, AMD released the first native dual-core processor, the Athlon X2. Intel's Pentium D had beaten the X2 to market by a few weeks, but it used two separate CPU dies and was less efficient than AMD's native design. As of 2012, dual- and quad-core processors are widely used in home PCs and laptops, while quad-, six-, eight-, ten-, twelve-, and sixteen-core processors are common in the professional and enterprise markets with workstations and servers.
Sun Microsystems has released the Niagara and Niagara 2 chips, both of which feature an eight-core design. The Niagara 2 supports more threads and operates at 1.6 GHz.
High-end Intel Xeon processors that are on the LGA 771, LGA 1366, and LGA 2011 sockets and high-end AMD Opteron processors that are on the C32 and G34 sockets are DP (dual processor) capable, as well as the older Intel Core 2 Extreme QX9775 also used in an older Mac Pro by Apple and the Intel Skulltrail motherboard. AMD's G34 motherboards can support up to four CPUs and Intel's LGA 1567 motherboards can support up to eight CPUs.
Modern desktop computers support systems with multiple CPUs, but few applications outside of the professional market can make good use of more than four cores. Both Intel and AMD currently offer fast quad- and six-core desktop CPUs, making multi-CPU systems obsolete for many purposes. AMD also offers the first and currently the only eight-core desktop CPUs with the FX-8xxx line.
The desktop market has been in a transition towards quad-core CPUs since Intel's Core 2 Quad was released and are now common, although dual-core CPUs are still more prevalent. Older or mobile computers are less likely to have more than two cores than newer desktops. Not all software is optimised for multi-core CPUs, making fewer, more powerful cores preferable.
AMD offers CPUs with more cores for a given amount of money than similarly priced Intel CPUs—but the AMD cores are somewhat slower, so the two trade blows in different applications depending on how well-threaded the programs running are. For example, Intel's cheapest Sandy Bridge quad-core CPUs often cost almost twice as much as AMD's cheapest Athlon II, Phenom II, and FX quad-core CPUs but Intel has dual-core CPUs in the same price ranges as AMD's cheaper quad-core CPUs. In an application that uses one or two threads, the Intel dual-core CPUs outperform AMD's similarly priced quad-core CPUs—and if a program supports three or four threads the cheap AMD quad-core CPUs outperform the similarly priced Intel dual-core CPUs.
Historically, AMD and Intel have switched places as the company with the fastest CPU several times. Intel currently leads on the desktop side of the computer CPU market, with their Sandy Bridge and Ivy Bridge series. In servers, AMD's new Opterons seem to have superior performance for their price point. This means that AMD are currently more competitive in low- to mid-end servers and workstations that more effectively use fewer cores and threads.
RISC.
In the mid-1980s to early 1990s, a crop of new high-performance reduced instruction set computer (RISC) microprocessors appeared, influenced by discrete RISC-like CPU designs such as the IBM 801 and others. RISC microprocessors were initially used in special-purpose machines and Unix workstations, but then gained wide acceptance in other roles.
In 1986, HP released its first system with a PA-RISC CPU. The first commercial RISC microprocessor design was released in 1984 by MIPS Computer Systems, the 32-bit R2000 (the R1000 was not released). In 1987 in the non-Unix Acorn computers' 32-bit, then cache-less, ARM2-based Acorn Archimedes the fist commercial success using the ARM architecture, then known as Acorn RISC Machine (ARM); first silicon ARM1 in 1985. The R3000 made the design truly practical, and the R4000 introduced the world's first commercially available 64-bit RISC microprocessor. Competing projects would result in the IBM POWER and Sun SPARC architectures. Soon every major vendor was releasing a RISC design, including the AT&T CRISP, AMD 29000, Intel i860 and Intel i960, Motorola 88000, DEC Alpha.
In the late 1990s, only two 64-bit RISC architectures were still produced in volume for non-embedded applications: SPARC and Power ISA, but as ARM has become increasingly powerful, in the early 2010s, it became the third RISC architecture in the general computing segment.
Market statistics.
In 2003, about US$44 billion worth of microprocessors were manufactured and sold. Although about half of that money was spent on CPUs used in desktop or laptop personal computers, those count for only about 2% of all CPUs sold. The quality-adjusted price of laptop microprocessors improved -25% to -35% per year in 2004–2010, and the rate of improvement slowed to -15% to -25% per year in 2010–2013.
About 55% of all CPUs sold in the world are 8-bit microcontrollers, over two billion of which were sold in 1997.
In 2002, less than 10% of all the CPUs sold in the world were 32-bit or more. Of all the 32-bit CPUs sold, about 2% are used in desktop or laptop personal computers. Most microprocessors are used in embedded control applications such as household appliances, automobiles, and computer peripherals. Taken as a whole, the average price for a microprocessor, microcontroller, or DSP is just over $6.
About ten billion CPUs were manufactured in 2008. About 98% of new CPUs produced each year are embedded.
References.
</dl>

</doc>
<doc id="19555" url="http://en.wikipedia.org/wiki?curid=19555" title="Molecule">
Molecule

A molecule is an electrically neutral group of two or more atoms held together by chemical bonds. Molecules are distinguished from ions by their lack of electrical charge. However, in quantum physics, organic chemistry, and biochemistry, the term "molecule" is often used less strictly, also being applied to polyatomic ions.
In the kinetic theory of gases, the term "molecule" is often used for any gaseous particle regardless of its composition. According to this definition, noble gas atoms are considered molecules despite being composed of a single non-bonded atom.
A molecule may be homonuclear, that is, it consists of atoms of a single chemical element, as with oxygen (O2); or it may be heteronuclear, a chemical compound composed of more than one element, as with water (H2O). Atoms and complexes connected by non-covalent bonds such as hydrogen bonds or ionic bonds are generally not considered single molecules.
Molecules as components of matter are common in organic substances (and therefore biochemistry). They also make up most of the oceans and atmosphere. However, the majority of familiar solid substances on Earth, including most of the minerals that make up the crust, mantle, and core of the Earth, contain many chemical bonds, but are "not" made of identifiable molecules. Also, no typical molecule can be defined for ionic crystals (salts) and covalent crystals (network solids), although these are often composed of repeating unit cells that extend either in a plane (such as in graphene) or three-dimensionally (such as in diamond, quartz, or sodium chloride). The theme of repeated unit-cellular-structure also holds for most condensed phases with metallic bonding, which means that solid metals are also not made of molecules. In glasses (solids that exist in a vitreous disordered state), atoms may also be held together by chemical bonds without presence of any definable molecule, but also without any of the regularity of repeating units that characterizes crystals.
Molecular science.
The science of molecules is called "molecular chemistry" or "molecular physics", depending on whether the focus is on chemistry or physics. Molecular chemistry deals with the laws governing the interaction between molecules that results in the formation and breakage of chemical bonds, while molecular physics deals with the laws governing their structure and properties. In practice, however, this distinction is vague. In molecular sciences, a molecule consists of a stable system (bound state) composed of two or more atoms. Polyatomic ions may sometimes be usefully thought of as electrically charged molecules. The term "unstable molecule" is used for very reactive species, i.e., short-lived assemblies (resonances) of electrons and nuclei, such as radicals, molecular ions, Rydberg molecules, transition states, van der Waals complexes, or systems of colliding atoms as in Bose–Einstein condensate.
History and etymology.
According to Merriam-Webster and the Online Etymology Dictionary, the word "molecule" derives from the Latin "moles" or small unit of mass.
The definition of the molecule has evolved as knowledge of the structure of molecules has increased. Earlier definitions were less precise, defining molecules as the smallest particles of pure chemical substances that still retain their composition and chemical properties. This definition often breaks down since many substances in ordinary experience, such as rocks, salts, and metals, are composed of large crystalline networks of chemically bonded atoms or ions, but are not made of discrete molecules.
Molecular size.
Most molecules are far too small to be seen with the naked eye, but there are exceptions. DNA, a macromolecule, can reach macroscopic sizes, as can molecules of many polymers. Molecules commonly used as building blocks for organic synthesis have a dimension of a few angstroms (Å) to several dozen Å. Single molecules cannot usually be observed by light (as noted above), but small molecules and even the outlines of individual atoms may be traced in some circumstances by use of an atomic force microscope. Some of the largest molecules are macromolecules or supermolecules.
Smallest molecule diameter.
The smallest molecule is the diatomic hydrogen (H2), with a bond length of 0.74 Å.
Largest molecule diameter.
Mesoporous silica have been produced with a diameter of 1000 Å (100 nm)
Radius.
"Effective molecular radius" is the size a molecule displays in solution.
The table of permselectivity for different substances contains examples.
Formulas for molecules.
Chemical formula types.
The chemical formula for a molecule uses a single line of chemical element symbols, numbers, and sometimes also other symbols, such as parentheses, dashes, brackets, and "plus" (+) and "minus" (−) signs. These are limited to a single typographic line of symbols, which may include subscripts and superscripts.
A compound's empirical formula is a very simple type of chemical formula. It is the simplest integer ratio of the chemical elements that constitute it. For example, water is always composed of a 2:1 ratio of hydrogen to oxygen atoms, and ethyl alcohol or ethanol is always composed of carbon, hydrogen, and oxygen in a 2:6:1 ratio. However, this does not determine the kind of molecule uniquely – dimethyl ether has the same ratios as ethanol, for instance. Molecules with the same atoms in different arrangements are called isomers. Also carbohydrates, for example, have the same ratio (carbon:hydrogen:oxygen = 1:2:1) (and thus the same empirical formula) but different total numbers of atoms in the molecule.
The molecular formula reflects the exact number of atoms that compose the molecule and so characterizes different molecules. However different isomers can have the same atomic composition while being different molecules.
The empirical formula is often the same as the molecular formula but not always. For example, the molecule acetylene has molecular formula C2H2, but the simplest integer ratio of elements is CH.
The molecular mass can be calculated from the chemical formula and is expressed in conventional atomic mass units equal to 1/12 of the mass of a neutral carbon-12 (12C isotope) atom. For network solids, the term formula unit is used in stoichiometric calculations.
Structural formula.
For molecules with a complicated 3-dimensional structure, especially involving atoms bonded to four different substituents, a simple molecular formula or even semi-structural chemical formula may not be enough to completely specify the molecule. In this case, a graphical type of formula called a structural formula may be needed. Structural formulas may in turn be represented with a one-dimensional chemical name, but such chemical nomenclature requires many words and terms which are not part of chemical formulas.
Molecular geometry.
Molecules have fixed equilibrium geometries—bond lengths and angles— about which they continuously oscillate through vibrational and rotational motions. A pure substance is composed of molecules with the same average geometrical structure. The chemical formula and the structure of a molecule are the two important factors that determine its properties, particularly its reactivity. Isomers share a chemical formula but normally have very different properties because of their different structures. Stereoisomers, a particular type of isomers, may have very similar physico-chemical properties and at the same time different biochemical activities.
Molecular spectroscopy.
Molecular spectroscopy deals with the response (spectrum) of molecules interacting with probing signals of known energy (or frequency, according to Planck's formula). Molecules have quantized energy levels that can be analyzed by detecting the molecule's energy exchange through absorbance or emission.
Spectroscopy does not generally refer to diffraction studies where particles such as neutrons, electrons, or high energy X-rays interact with a regular arrangement of molecules (as in a crystal).
Theoretical aspects.
The study of molecules by molecular physics and theoretical chemistry is largely based on quantum mechanics and is essential for the understanding of the chemical bond. The simplest of molecules is the hydrogen molecule-ion, H2+, and the simplest of all the chemical bonds is the one-electron bond. H2+ is composed of two positively charged protons and one negatively charged electron, which means that the Schrödinger equation for the system can be solved more easily due to the lack of electron–electron repulsion. With the development of fast digital computers, approximate solutions for more complicated molecules became possible and are one of the main aspects of computational chemistry.
When trying to define rigorously whether an arrangement of atoms is "sufficiently stable" to be considered a molecule, IUPAC suggests that it "must correspond to a depression on the potential energy surface that is deep enough to confine at least one vibrational state". This definition does not depend on the nature of the interaction between the atoms, but only on the strength of the interaction. In fact, it includes weakly bound species that would not traditionally be considered molecules, such as the helium dimer, He2, which has one vibrational bound state and is so loosely bound that it is only likely to be observed at very low temperatures.
Whether or not an arrangement of atoms is "sufficiently stable" to be considered a molecule is inherently an operational definition. Philosophically, therefore, a molecule is not a fundamental entity (in contrast, for instance, to an elementary particle); rather, the concept of a molecule is the chemist's way of making a useful statement about the strengths of atomic-scale interactions in the world that we observe.

</doc>
<doc id="19556" url="http://en.wikipedia.org/wiki?curid=19556" title="Mode (music)">
Mode (music)

In the theory of Western music, mode (from Latin "modus," "measure, standard, manner, way, size, limit of quantity, method") (; OED) generally refers to a type of scale, coupled with a set of characteristic melodic behaviours. This use, still the most common in recent years, reflects a tradition dating to the Middle Ages, itself inspired by the theory of ancient Greek music.
Mode as a general concept.
Regarding the concept of mode as applied to pitch relationships generally, Harold S. Powers describes a continuum between abstract scale and specific tune, with "most of the area between ... being in the domain of mode" . In this sense the concept had been extrapolated (long before Powers's article) not only to the Western cantus planus monodic tradition but to Byzantine chant (e.g. ), and to Russian Znamenny chant as well. Since the end of the eighteenth century, the term "mode" has also applied to pitch structures in non-European musical cultures, sometimes with doubtful compatibility . The concept is also heavily used in regard to the Western polyphony before advent of the so-called common-practice music, as for example "modale Mehrstimmigkeit" by Carl Dahlhaus or "Tonarten" of the 16th and 17th centuries found by Bernhard Meier (; ).
Additional meanings.
The word encompasses several additional meanings, however. Authors from the ninth century until the early eighteenth century (e.g. Guido of Arezzo) sometimes employed the Latin "modus" for interval. In the theory of late-medieval mensural polyphony (e.g. Franco of Cologne), "modus" is a rhythmic relationship between long and short values or a pattern made from them ; in mensural music most often theorists applied it to division of longa into 3 or 2 breves.
Modes and scales.
A "scale" is an ordered series of pitches that, with the key or tonic (first tone) as a reference point, defines that scale's intervals, or steps. The concept of "mode" in Western music theory has three successive stages: in Gregorian chant theory, in Renaissance polyphonic theory, and in tonal harmonic music of the common practice period. In all three contexts, "mode" incorporates the idea of the diatonic scale, but differs from it by also involving an element of melody type. This concerns particular repertories of short musical figures or groups of tones within a certain scale so that, depending on the point of view, mode takes on the meaning of either a "particularized scale" or a "generalized tune". Modern musicological practice has extended the concept of mode to earlier musical systems, such as those of Ancient Greek music, Jewish cantillation, and the Byzantine system of "octoechos", as well as to other non-Western musics (; ).
By the early 19th century, the word "mode" had taken on an additional meaning, in reference to the difference between major and minor keys, specified as "major mode" and "minor mode". At the same time, composers were beginning to conceive of "modality" as something outside of the major/minor system that could be used to evoke religious feelings or to suggest folk-music idioms .
Greek.
Early Greek treatises on music do not use the term "mode" (which comes from Latin), but do describe three interrelated concepts that are related to the later, medieval idea of "mode": (1) scales (or "systems"), (2) "tonos"—pl. "tonoi"—(the more usual term used in medieval theory for what later came to be called "mode"), and (3) "harmonia" (harmony)—pl. "harmoniai"—this third term subsuming the corresponding "tonoi" but not necessarily the converse .
Greek scales.
The Greek scales in the Aristoxenian tradition were (; ):
These names are derived from Ancient Greek subgroups (Dorians), one small region in central Greece (Locris), and certain neighboring (non-Greek) peoples from Asia Minor (Lydia, Phrygia). The association of these ethnic names with the octave species appears to precede Aristoxenus, who criticized their application to the "tonoi" by the earlier theorists whom he called the Harmonicists .
Depending on the positioning (spacing) of the interposed tones in the tetrachords, three "genera" of the seven octave species can be recognized. The diatonic genus (composed of tones and semitones), the chromatic genus (semitones and a minor third), and the enharmonic genus (with a major third and two quarter tones or dieses) . The framing interval of the perfect fourth is fixed, while the two internal pitches are movable. Within the basic forms, the intervals of the chromatic and diatonic genera were varied further by three and two "shades" ("chroai"), respectively (; ).
In contrast to the medieval modal system, these scales and their related "tonoi" and "harmoniai" appear to have had no hierarchical relationships amongst the notes that could establish contrasting points of tension and rest, although the "mese" ("middle note") may have had some sort of gravitational function .
"Tonoi".
The term "tonos" (pl. "tonoi") was used in four senses: "as note, interval, region of the voice, and pitch. We use it of the region of the voice whenever we speak of Dorian, or Phrygian, or Lydian, or any of the other tones" . Cleonides attributes thirteen "tonoi" to Aristoxenus, which represent a progressive transposition of the entire system (or scale) by semitone over the range of an octave between the Hypodorian and the Hypermixolydian . Aristoxenus's transpositional "tonoi", according to , were named analogously to the octave species, supplemented with new terms to raise the number of degrees from seven to thirteen. However, according to the interpretation of at least two modern authorities, in these transpositional "tonoi" the Hypodorian is the lowest, and the Mixolydian next-to-highest—the reverse of the case of the octave species (; ), with nominal base pitches as follows (descending order):
Ptolemy, in his "Harmonics", ii.3–11, construed the "tonoi" differently, presenting all seven octave species within a fixed octave, through chromatic inflection of the scale degrees (comparable to the modern conception of building all seven modal scales on a single tonic). In Ptolemy's system, therefore there are only seven "tonoi" (; ). Pythagoras also construed the intervals arithmetically (if somewhat more rigorously, initially allowing for 1:1 = Unison, 2:1 = Octave, 3:2 = Fifth, 4:3 = Fourth and 5:4 = Major Third within the octave). In their diatonic genus, these "tonoi" and corresponding "harmoniai" correspond with the intervals of the familiar modern major and minor scales. See Pythagorean tuning and Pythagorean interval.
"Harmoniai".
In music theory the Greek word "harmonia" can signify the enharmonic genus of tetrachord, the seven octave species, or a style of music associated with one of the ethnic types or the "tonoi" named by them .
Particularly in the earliest surviving writings, "harmonia" is regarded not as a scale, but as the epitome of the stylised singing of a particular district or people or occupation . When the late 6th-century poet Lasus of Hermione referred to the Aeolian "harmonia", for example, he was more likely thinking of a melodic style characteristic of Greeks speaking the Aeolic dialect than of a scale pattern . By the late fifth century BC these regional types are being described in terms of differences in what is called "harmonia"—a word with several senses, but here referring to the pattern of intervals between the notes sounded by the strings of a lyra or a kithara. However, there is no reason to suppose that, at this time, these tuning patterns stood in any straightforward and organised relations to one another. It was only around the year 400 that attempts were made by a group of theorists known as the harmonicists to bring these "harmoniai" into a single system, and to express them as orderly transformations of a single structure. Eratocles was the most prominent of the harmonicists, though his ideas are known only at second hand, through Aristoxenus, from whom we learn they represented the "harmoniai" as cyclic reorderings of a given series of intervals within the octave, producing seven octave species. We also learn that Eratocles confined his descriptions to the enharmonic genus .
In "The Republic", Plato uses the term inclusively to encompass a particular type of scale, range and register, characteristic rhythmic pattern, textual subject, etc. (Mathiesen 2001a, 6(iii)(e)). He held that playing music in a particular "harmonia" would incline one towards specific behaviors associated with it, and suggested that soldiers should listen to music in Dorian or Phrygian "harmoniai" to help make them stronger, but avoid music in Lydian, Mixolydian or Ionian "harmoniai", for fear of being softened. Plato believed that a change in the musical modes of the state would cause a wide-scale social revolution (Plato, Rep. III.10–III.12 = 398C–403C)
The philosophical writings of Plato and Aristotle (c. 350 BC) include sections that describe the effect of different "harmoniai" on mood and character formation. For example, Aristotle in the "Politics" (viii:1340a:40–1340b:5):
But melodies themselves do contain imitations of character. This is perfectly clear, for the "harmoniai" have quite distinct natures from one another, so that those who hear them are differently affected and do not respond in the same way to each. To some, such as the one called Mixolydian, they respond with more grief and anxiety, to others, such as the relaxed "harmoniai", with more mellowness of mind, and to one another with a special degree of moderation and firmness, Dorian being apparently the only one of the "harmoniai" to have this effect, while Phrygian creates ecstatic excitement. These points have been well expressed by those who have thought deeply about this kind of education; for they cull the evidence for what they say from the facts themselves.
Aristotle continues by describing the effects of rhythm, and concludes about the combined effect of rhythm and "harmonia" (viii:1340b:10–13): From all this it is clear that music is capable of creating a particular quality of character [ἦθος] in the soul, and if it can do that, it is plain that it should be made use of, and that the young should be educated in it.
The word "ethos" (ἦθος) in this context means "moral character", and Greek ethos theory concerns the ways in which music can convey, foster, and even generate ethical states .
Melos.
Some treatises also describe "melic" composition (μελοποιΐα), "the employment of the materials subject to harmonic practice with due regard to the requirements of each of the subjects under consideration" —which, together with the scales, "tonoi", and "harmoniai" resemble elements found in medieval modal theory . According to Aristides Quintilianus ("On Music", i.12), melic composition is subdivided into three classes: dithyrambic, nomic, and tragic. These parallel his three classes of rhythmic composition: systaltic, diastaltic and hesychastic. Each of these broad classes of melic composition may contain various subclasses, such as erotic, comic and panegyric, and any composition might be elevating (diastaltic), depressing (systaltic), or soothing (hesychastic) .
According to Mathiesen, music as a performing art was called melos, which in its perfect form (μέλος τέλειον) comprised not only the melody and the text (including its elements of rhythm and diction) but also stylized dance movement. Melic and rhythmic composition (respectively, μελοποιΐα and ῥυθμοποιΐα) were the processes of selecting and applying the various components of melos and rhythm to create a complete work. Aristides Quintilianus: 
And we might fairly speak of perfect melos, for it is necessary that melody, rhythm and diction be considered so that the perfection of the song may be produced: in the case of melody, simply a certain sound; in the case of rhythm, a motion of sound; and in the case of diction, the meter. The things contingent to perfect melos are motion-both of sound and body-and also chronoi and the rhythms based on these. ().
Western Church.
Tonaries, which are lists of chant titles grouped by mode, appear in western sources around the turn of the 9th century. The influence of developments in Byzantium, from Jerusalem and Damascus, for instance the works of Saints John of Damascus (d. 749) and Cosmas of Maiouma (; ), are still not fully understood. The eight-fold division of the Latin modal system, in a four-by-two matrix, was certainly of Eastern provenance, originating probably in Syria or even in Jerusalem, and was transmitted from Byzantine sources to Carolingian practice and theory during the 8th century. However, the earlier Greek model for the Carolingian system was probably ordered like the later Byzantine "oktōēchos", that is, with the four principal (authentic) modes first, then the four plagals, whereas the Latin modes were always grouped the other way, with the authentics and plagals paired .
The 6th century scholar Boethius had translated Greek music theory treatises by Nicomachus and Ptolemy into Latin . Later authors created confusion by applying mode as described by Boethius to explain plainchant modes, which were a wholly different system . In his "De institutione musica", book 4 chapter 15, Boethius, like his Hellenistic sources, twice used the term "harmonia" to describe what would likely correspond to the later notion of "mode", but also used the word "modus"—probably translating the Greek word τρόπος ("tropos"), which he also rendered as Latin "tropus"—in connection with the system of transpositions required to produce seven diatonic octave species , so the term was simply a means of describing transposition and had nothing to do with the church modes .
Later, 9th-century theorists applied Boethius’s terms "tropus" and "modus" (along with "tonus") to the system of church modes. The treatise "De Musica" (or "De harmonica institutione") of Hucbald synthesized the three previously disparate strands of modal theory: chant theory, the Byzantine "oktōēchos" and Boethius's account of Hellenistic theory . The later 9th-century treatise known as the "Alia musica" imposed the seven species of the octave described by Boethius onto the eight church modes . Thus, the names of the modes used today do not actually reflect those used by the Greeks.
The eight church modes, or Gregorian modes, can be divided into four pairs, where each pair shares the "final" note and the four notes above the final, but have different ambituses, or ranges. If the "scale" is completed by adding three higher notes, the mode is termed "authentic", if the scale is completed by adding three lower notes, it is called "plagal" (from Greek πλάγιος, "oblique, sideways"). Otherwise explained: if the melody moves mostly above the final, with an occasional cadence to the sub-final, the mode is authentic. Plagal modes shift range and also explore the fourth below the final as well as the fifth above. In both cases, the strict ambitus of the mode is one octave. A melody that remains confined to the mode's ambitus is called "perfect"; if it falls short of it, "imperfect"; if it exceeds it, "superfluous"; and a melody that combines the ambituses of both the plagal and authentic is said to be in a "mixed mode" .
Although the earlier (Greek) model for the Carolingian system was probably ordered like the Byzantine "oktōēchos", with the four authentic modes first, followed by the four plagals, the earliest extant sources for the Latin system are organized in four pairs of authentic and plagal modes sharing the same final: protus authentic/plagal, deuterus authentic/plagal, tritus authentic/plagal, and tetrardus authentic/plagal .
Each mode has, in addition to its final, a "reciting tone", sometimes called the "dominant" (; ). It is also sometimes called the "tenor", from Latin "tenere" "to hold", meaning the tone around which the melody principally centres . The reciting tones of all authentic modes began a fifth above the final, with those of the plagal modes a third above. However, the reciting tones of modes 3, 4, and 8 rose one step during the tenth and eleventh centuries with 3 and 8 moving from B to C (half step) and that of 4 moving from G to A (whole step) .
After the reciting tone, every mode is distinguished by scale degrees called "mediant" and "participant". The mediant is named from its position between the final and reciting tone. In the authentic modes it is the third of the scale, unless that note should happen to be B, in which case C substitutes for it. In the plagal modes, its position is somewhat irregular. The participant is an auxiliary note, generally adjacent to the mediant in authentic modes and, in the plagal forms, coincident with the reciting tone of the corresponding authentic mode (some modes have a second participant) .
Only one accidental is used commonly in Gregorian chant—B may be lowered by a half-step to B♭. This usually (but not always) occurs in modes V and VI, as well as in the upper tetrachord of IV, and is optional in other modes except III, VII and VIII .
In 1547, the Swiss theorist Henricus Glareanus published the "Dodecachordon", in which he solidified the concept of the church modes, and added four additional modes: the Aeolian (mode 9), Hypoaeolian (mode 10), Ionian (mode 11), and Hypoionian (mode 12). A little later in the century, the Italian Gioseffo Zarlino at first adopted Glarean's system in 1558, but later (1571 and 1573) revised the numbering and naming conventions in a manner he deemed more logical, resulting in the widespread promulgation of two conflicting systems. Zarlino's system reassigned the six pairs of authentic–plagal mode numbers to finals in the order of the natural hexachord, C D E F G A, and transferred the Greek names as well, so that modes 1 through 8 now became C-authentic to F-plagal, and were now called by the names Dorian to Hypomixolydian. The pair of G modes were numbered 9 and 10 and were named Ionian and Hypoionian, while the pair of A modes retained both the numbers and names (11, Aeolian, and 12 Hypoaeolian) of Glarean's system. While Zarlino's system became popular in France, Italian composers preferred Glarean's scheme because it retained the traditional eight modes, while expanding them. Luzzasco Luzzaschi was an exception in Italy, in that he used Zarlino’s new system .
In the late-eighteenth and nineteenth centuries, some chant reformers (notably the editors of the Mechlin, Pustet-Ratisbon (Regensburg), and Rheims-Cambrai Office-Books, collectively referred to as the Cecilian Movement) renumbered the modes once again, this time retaining the original eight mode numbers and Glareanus's modes 9 and 10, but assigning numbers 11 and 12 to the modes on the final B, which they named Locrian and Hypolocrian (even while rejecting their use in chant). The Ionian and Hypoionian modes (on C) become in this system modes 13 and 14 .
Given the confusion between ancient, medieval, and modern terminology, "today it is more consistent and practical to use the traditional designation of the modes with numbers one to eight" (), using Roman numeral (I–VIII), rather than using the pseudo-Greek naming system. Contemporary terms, also used by scholars, are simply the Greek ordinals ("first", "second", etc.), usually transliterated into the Latin alphabet: protus (πρῶτος), deuterus (δεύτερος), tritus (τρίτος), and tetrardus (τέταρτος), in practice used as: protus authentus / plagalis.
Use.
A mode indicated a primary pitch (a final); the organization of pitches in relation to the final; suggested range; melodic formulas associated with different modes; location and importance of cadences; and affect (i.e., emotional effect/character). Liane Curtis writes that "Modes should not be equated with scales: principles of melodic organization, placement of cadences, and emotional affect are essential parts of modal content" in Medieval and Renaissance music (, in ).
Carl lists "three factors that form the respective starting points for the modal theories of Aurelian of Réôme, Hermannus Contractus, and Guido of Arezzo:
The oldest medieval treatise regarding modes is "Musica disciplina" by Aurelian of Réôme (dating from around 850) while Hermannus Contractus was the first to define modes as partitionings of the octave . However, the earliest Western source using the system of eight modes is the Tonary of St Riquier, dated between about 795 and 800 .
Various interpretations of the "character" imparted by the different modes have been suggested. Three such interpretations, from Guido of Arezzo (995–1050), Adam of Fulda (1445–1505), and Juan de Espinosa Medrano (1632–1688), follow:
, which is the fifth (above) for authentic modes and the third below for plagal modes.
Modern.
The modern Western modes consist of seven scales related to the familiar major and minor keys.
Although the names of the modern modes are Greek and some have names used in ancient Greek theory for some of the "harmoniai", the names of the modern modes are conventional and do not indicate a link between them and ancient Greek theory, and they do not present the sequences of intervals found even in the diatonic genus of the Greek octave species sharing the same name.
Modern Western modes use the same set of notes as the major scale, in the same order, but starting from one of its seven degrees in turn as a "tonic", and so present a different sequence of whole and half steps. The interval sequence of the major scale being T-T-s-T-T-T-s, where "s" means a semitone (half step) and "T" means a whole tone (whole step), it is thus possible to generate the following scales:
For the sake of simplicity, the examples shown above are formed by natural notes (also called "white-notes", as they can be played using the white keys of a piano keyboard). However, any transposition of each of these scales is a valid example of the corresponding mode. In other words, transposition preserves mode.
Analysis.
Each mode has characteristic intervals and chords that give it its distinctive sound.
The following is an analysis of each of the seven modern modes. The examples are provided in a key signature with no sharps or flats (scales composed of natural notes).
Ionian (I).
Ionian may arbitrarily be designated the first mode. It is the modern major scale. The example composed of natural notes begins on C, and is also known as the C-major scale: 
Dorian (II).
Dorian is the second mode. The example composed of natural notes begins on D: 
The Dorian mode is very similar to the modern natural minor scale (see Aeolian mode below). The only difference with respect to the natural minor scale is in the sixth scale degree, which is a major sixth (M6) above the tonic, rather than a minor sixth (m6).
Phrygian (III).
Phrygian is the third mode. The example composed of natural notes starts on E: 
The Phrygian mode is very similar to the modern natural minor scale (see Aeolian mode below). The only difference with respect to the natural minor scale is in the second scale degree, which is a minor second (m2) above the tonic, rather than a major second (M2).
Lydian (IV).
Lydian is the fourth mode. The example composed of natural notes starts on F: 
The single tone that differentiates this scale from the major scale (Ionian mode), is its fourth degree, which is an augmented fourth (A4) above the tonic (F), rather than a perfect fourth (P4).
Mixolydian (V).
Mixolydian is the fifth mode. The example composed of natural notes begins on G: 
The single tone that differentiates this scale from the major scale (Ionian mode), is its seventh degree, which is a minor seventh (m7) above the tonic (G), rather than a major seventh (M7).
Aeolian (VI).
Aeolian is the sixth mode. It is also called the natural minor scale. The example composed of natural notes begins on A, and is also known as the A-minor scale:
Locrian (VII).
Locrian is the seventh and final mode. The example composed of natural notes begins on B:
The distinctive scale degree here is the diminished fifth (d5). This makes the tonic triad diminished, so this mode is the only one in which the chords built on the tonic and dominant scale degrees have their roots separated by a diminished, rather than perfect, fifth. Similarly the tonic seventh chord is half-diminished.
Summary.
The modes can be arranged in the following sequence, which follows the circle of fifths. In this sequence, each mode has one more lowered interval relative to the tonic than the mode preceding it. Thus taking Lydian as reference, Ionian (major) has a lowered fourth; Mixolydian, a lowered fourth and seventh; Dorian, a lowered fourth, seventh, and third; Aeolian (Natural Minor), a lowered fourth, seventh, third, and sixth; Phrygian, a lowered fourth, seventh, third, sixth, and second; and Locrian, a lowered fourth, seventh, third, sixth, second, and fifth. Put another way, the augmented fourth of the Lydian scale has been reduced to a perfect fourth in Ionian, the major seventh in Ionian, to a minor seventh in Mixolydian, etc.
The tonic of a transposed mode is at the same number of 5ths down (resp. up) from the natural tonic of the mode as there are flats (resp. sharps) in its signature: e.g. the Dorian scale with 3 ♭ is F dorian as F is three 5ths down from D (F - C - G - D) and the Dorian scale with 3 ♯ is B dorian as B is three 5ths up from D (D - A - E - B). Or equivalently it is at the same interval from the tonic of the major scale with the same signature (its relative major) as that formed by its natural tonic and C: e.g. the Lydian scale with 2 ♭ is E♭ Lydian and the Lydian scale with 2 ♯ is G Lydian as E♭ forms with B♭ (relative major) and G forms with D (relative major), the same interval as between F and C.
Conversely the signature of a transposed mode has as many sharps (resp. flats) as there are 5ths up (resp. down) between the tonic of the natural mode and the tonic of the transposed mode: e.g. B♭ Dorian's signature is 4 ♭ as B♭ is four 5ths down from D (B♭ - F - C - G - D) and A lydian's signature is 4 ♯ as A is four 5ths up from F (F - C - G - D - A). Or again equivalently the signature of a transposed mode is the same as that of its relative major. That forms with the tonic of the transposed mode the same interval as C with the tonic of the natural mode: e.g. B♭ Phrygian's signature is 6 ♭ as its relative major is G♭ (C is a major 3rd down from E) and C♯ Mixolydian's signature is 6 ♯ as its relative major is F♯ (C is a 5th down from G).
For example the modes transposed to a common tonic of C have the following signatures:
The first three modes are sometimes called major, the next three minor, and the last one diminished (Locrian), according to the quality of their tonic triads.
The Locrian mode is traditionally considered theoretical rather than practical because the triad built on the first scale degree is diminished. Diminished triads are not consonant and therefore do not lend themselves to cadential endings. A diminished chord cannot be tonicized according to tonal phrasing practice.
Major modes.
The Ionian mode (  ) corresponds to the major scale. Scales in the Lydian mode (  ) are major scales with the fourth degree raised a semitone. The Mixolydian mode (  ) corresponds to the major scale with the seventh degree lowered a semitone.
Minor modes.
The Aeolian mode (  ) is identical to the natural minor scale. The Dorian mode (  ) corresponds to the natural minor scale with the sixth degree raised a semitone. The Phrygian mode (  ) corresponds to the natural minor scale with the second degree lowered a semitone.
Diminished mode.
The Locrian (  ) is neither a major nor a minor mode because, although its third scale degree is minor, the fifth degree is diminished instead of perfect. For this reason it is sometimes called a "diminished" scale, though in jazz theory this term is also applied to the octatonic scale. This interval is enharmonically equivalent to the augmented fourth found between scale-degrees 1 and 4 in the Lydian mode and is also referred to as the tritone.
Use.
Use and conception of modes or modality today is different from that in early music. As Jim Samson explains, "Clearly any comparison of medieval and modern modality would recognize that the latter takes place against a background of some three centuries of harmonic tonality, permitting, and in the nineteenth century requiring, a dialogue between modal and diatonic procedure" . Indeed, when 19th-century composers revived the modes, they rendered them more strictly than Renaissance composers had, to make their qualities distinct from the prevailing major-minor system. Renaissance composers routinely sharped leading tones at cadences and lowered the fourth in the Lydian mode .
The Ionian, or Iastian (; ; ; ; ; ; ; ) mode is another name for the major scale used in much Western music. The Aeolian forms the base of the most common Western minor scale; in modern practice the Aeolian mode is differentiated from the minor by using only the seven notes of the Aeolian scale. By contrast, minor mode compositions of the common practice period frequently raise the seventh scale degree by a semitone to strengthen the cadences, and in conjunction also raise the sixth scale degree by a semitone to avoid the awkward interval of an augmented second. This is particularly true of vocal music .
Traditional folk music provides countless examples of modal melodies. For example, Irish traditional music makes extensive usage not only of the major mode, but also the Mixolydian, Dorian, and Aeolian modes . Much Flamenco music is in the Phrygian mode.
Zoltán Kodály, Gustav Holst, Manuel de Falla use modal elements as modifications of a diatonic background, while in the music of Debussy and Béla Bartók modality replaces diatonic tonality (, )
Other types.
While the term "mode" is still most commonly understood to refer to Ionian, Dorian, Phrygian, Lydian, Mixolydian, Aeolian, or Locrian scales, in modern music theory the word is sometimes applied to scales other than the diatonic. This is seen, for example, in "melodic minor" scale harmony, which is based on the seven rotations of the ascending melodic minor scale, yielding some interesting scales as shown below. The "chord" row lists tetrads that can be built from the pitches in the given mode (); see also Avoid note.
The number of possible modes for any intervallic set is dictated by the pattern of intervals in the scale. For scales built of a pattern of intervals that only repeats at the octave (like the diatonic set), the number of modes is equal to the number of notes in the scale. Scales with a recurring interval pattern smaller than an octave, however, have only as many modes as notes within that subdivision: e.g., the diminished scale, which is built of alternating whole and half steps, has only two distinct modes, since all odd-numbered modes are equivalent to the first (starting with a whole step) and all even-numbered modes are equivalent to the second (starting with a half step). The chromatic and whole-tone scales, each containing only steps of uniform size, have only a single mode each, as any rotation of the sequence results in the same sequence. Another general definition excludes these equal-division scales, and defines modal scales as subsets of them: "If we leave out certain steps of a[n equal-step] scale we get a modal construction" (Karlheinz Stockhausen, in ). In "Messiaen's narrow sense, "a mode is any scale" made up from the 'chromatic total,' the twelve tones of the tempered system" .

</doc>
<doc id="19559" url="http://en.wikipedia.org/wiki?curid=19559" title="Mechanics">
Mechanics

Mechanics (Greek μηχανική) is an area of science concerned with the behavior of physical bodies when subjected to forces or displacements, and the subsequent effects of the bodies on their environment.
The scientific discipline has its origins in Ancient Greece with the writings of Aristotle and Archimedes (see History of classical mechanics and Timeline of classical mechanics). During the early modern period, scientists such as Galileo, Kepler, and especially Newton, laid the foundation for what is now known as classical mechanics.
It is a branch of classical physics that deals with particles that are either at rest or are moving with velocities significantly less than the speed of light. 
It can also be defined as a branch of science which deals with the motion of and forces on objects.
Classical versus quantum.
The major division of the mechanics discipline separates classical mechanics from quantum mechanics.
Historically, classical mechanics came first, while quantum mechanics is a comparatively recent invention. Classical mechanics originated with Isaac Newton's laws of motion in "Principia Mathematica"; Quantum Mechanics was discovered in 1925. Both are commonly held to constitute the most certain knowledge that exists about physical nature. Classical mechanics has especially often been viewed as a model for other so-called exact sciences. Essential in this respect is the relentless use of mathematics in theories, as well as the decisive role played by experiment in generating and testing them.
Quantum mechanics is of a wider scope, as it encompasses classical mechanics as a sub-discipline which applies under certain restricted circumstances. According to the correspondence principle, there is no contradiction or conflict between the two subjects, each simply pertains to specific situations. The correspondence principle states that the behavior of systems described by quantum theories reproduces classical physics in the limit of large quantum numbers. Quantum mechanics has superseded classical mechanics at the foundational level and is indispensable for the explanation and prediction of processes at molecular and (sub)atomic level. However, for macroscopic processes classical mechanics is able to solve problems which are unmanageably difficult in quantum mechanics and hence remains useful and well used.
Modern descriptions of such behavior begin with a careful definition of such quantities as displacement (distance moved), time, velocity, acceleration, mass, and force. Until about 400 years ago, however, motion was explained from a very different point of view. For example, following the ideas of Greek philosopher and scientist Aristotle, scientists reasoned that a cannonball falls down because its natural position is in the Earth; the sun, the moon, and the stars travel in circles around the earth because it is the nature of heavenly objects to travel in perfect circles.
The Italian physicist and astronomer Galileo brought together the ideas of other great thinkers of his time and began to analyze motion in terms of distance traveled from some starting position and the time that it took. He showed that the speed of falling objects increases steadily during the time of their fall. This acceleration is the same for heavy objects as for light ones, provided air friction (air resistance) is discounted. The English mathematician and physicist Isaac Newton improved this analysis by defining force and mass and relating these to acceleration. For objects traveling at speeds close to the speed of light, Newton’s laws were superseded by Albert Einstein’s theory of relativity. For atomic and subatomic particles, Newton’s laws were superseded by quantum theory. For everyday phenomena, however, Newton’s three laws of motion remain the cornerstone of dynamics, which is the study of what causes motion.
Relativistic versus Newtonian mechanics.
In analogy to the distinction between quantum and classical mechanics, Einstein's general and special theories of relativity have expanded the scope of Newton and Galileo's formulation of mechanics. The differences between relativistic and Newtonian mechanics become significant and even dominant as the velocity of a massive body approaches the speed of light. For instance, in Newtonian mechanics, Newton's laws of motion specify that formula_1, whereas in Relativistic mechanics and Lorentz transformations, which were first discovered by Hendrik Lorentz, formula_2 (formula_3 is the Lorentz factor, which is almost equal to 1 for low speeds).
General relativistic versus quantum.
Relativistic corrections are also needed for quantum mechanics, although general relativity has not been integrated. The two theories remain incompatible, a hurdle which must be overcome in developing a theory of everything.
History.
Antiquity.
The main theory of mechanics in antiquity was Aristotelian mechanics. A later developer in this tradition is Hipparchus.
Medieval age.
In the Middle Ages, Aristotle's theories were criticized and modified by a number of figures, beginning with John Philoponus in the 6th century. A central problem was that of projectile motion, which was discussed by Hipparchus and Philoponus. This led to the development of the theory of impetus by 14th century French Jean Buridan, which developed into the modern theories of inertia, velocity, acceleration and momentum. This work and others was developed in 14th century England by the Oxford Calculators such as Thomas Bradwardine, who studied and formulated various laws regarding falling bodies.
On the question of a body subject to a constant (uniform) force, the 12th century Jewish-Arab Nathanel (Iraqi, of Baghdad) stated that constant force imparts constant acceleration, while the main properties are uniformly accelerated motion (as of falling bodies) was worked out by the 14th century Oxford Calculators.
Early modern age.
Two central figures in the early modern age are Galileo Galilei and Isaac Newton. Galileo's final statement of his mechanics, particularly of falling bodies, is his "Two New Sciences" (1638). Newton's 1687 "Philosophiæ Naturalis Principia Mathematica" provided a detailed mathematical account of mechanics, using the newly developed mathematics of calculus and providing the basis of Newtonian mechanics.
There is some dispute over priority of various ideas: Newton's "Principia" is certainly the seminal work and has been tremendously influential, and the systematic mathematics therein did not and could not have been stated earlier because calculus had not been developed. However, many of the ideas, particularly as pertain to inertia (impetus) and falling bodies had been developed and stated by earlier researchers, both the then-recent Galileo and the less-known medieval predecessors. Precise credit is at times difficult or contentious because scientific language and standards of proof changed, so whether medieval statements are "equivalent" to modern statements or "sufficient" proof, or instead "similar" to modern statements and "hypotheses" is often debatable.
Modern age.
Two main modern developments in mechanics are general relativity of Einstein, and quantum mechanics, both developed in the 20th century based in part on earlier 19th century ideas.
Types of mechanical bodies.
The often-used term body needs to stand for a wide assortment of objects, including particles, projectiles, spacecraft, stars, parts of machinery, parts of solids, parts of fluids (gases and liquids), etc.
Other distinctions between the various sub-disciplines of mechanics, concern the nature of the bodies being described. Particles are bodies with little (known) internal structure, treated as mathematical points in classical mechanics. Rigid bodies have size and shape, but retain a simplicity close to that of the particle, adding just a few so-called degrees of freedom, such as orientation in space.
Otherwise, bodies may be semi-rigid, i.e. elastic, or non-rigid, i.e. fluid. These subjects have both classical and quantum divisions of study.
For instance, the motion of a spacecraft, regarding its orbit and attitude (rotation), is described by the relativistic theory of classical mechanics, while the analogous movements of an atomic nucleus are described by quantum mechanics.
Sub-disciplines in mechanics.
The following are two lists of various subjects that are studied in mechanics.
Note that there is also the "theory of fields" which constitutes a separate discipline in physics, formally treated as distinct from mechanics, whether classical fields or quantum fields. But in actual practice, subjects belonging to mechanics and fields are closely interwoven. Thus, for instance, forces that act on particles are frequently derived from fields (electromagnetic or gravitational), and particles generate fields by acting as sources. In fact, in quantum mechanics, particles themselves are fields, as described theoretically by the wave function.
Classical mechanics.
The following are described as forming classical mechanics:
Quantum mechanics.
The following are categorized as being part of quantum mechanics:

</doc>
<doc id="19562" url="http://en.wikipedia.org/wiki?curid=19562" title="Mandelbrot set">
Mandelbrot set

The Mandelbrot set is the set of complex numbers 'c' for which the sequence ( c, c² + c, (c²+c)² + c, ((c²+c)²+c)² + c, (((c²+c)²+c)²+c)² + c, ...) does not approach infinity. The set is closely related to Julia sets (which include similarly complex shapes) and is named after the mathematician Benoit Mandelbrot, who studied and popularized it.
Mandelbrot set images are made by sampling complex numbers and determining for each whether the result tends towards infinity when a particular mathematical operation is iterated on it. Treating the real and imaginary parts of each number as image coordinates, pixels are colored according to how rapidly the sequence diverges, if at all.
More precisely, the Mandelbrot set is the set of values of "c" in the complex plane for which the orbit of 0 under iteration of the complex quadratic polynomial
remains bounded. That is, a complex number "c" is part of the Mandelbrot set if, when starting with "z"0 = 0 and applying the iteration repeatedly, the absolute value of "z""n" remains bounded however large "n" gets.
For example, letting "c" = 1 gives the sequence 0, 1, 2, 5, 26,…, which tends to infinity. As this sequence is unbounded, 1 is not an element of the Mandelbrot set. On the other hand, "c" = −1 gives the sequence 0, −1, 0, −1, 0..., which is bounded, and so −1 belongs to the Mandelbrot set.
Images of the Mandelbrot set display an elaborate boundary that reveals progressively ever-finer recursive detail at increasing magnifications. The "style" of this repeating detail depends on the region of the set being examined. The set's boundary also incorporates smaller versions of the main shape, so the fractal property of self-similarity applies to the entire set, and not just to its parts.
The Mandelbrot set has become popular outside mathematics both for its aesthetic appeal and as an example of a complex structure arising from the application of simple rules, and is one of the best-known examples of mathematical visualization.
History.
The Mandelbrot set has its place in complex dynamics, a field first investigated by the French mathematicians Pierre Fatou and Gaston Julia at the beginning of the 20th century. The first pictures of this fractal were drawn in 1978 by Robert W. Brooks and Peter Matelski as part of a study of Kleinian groups. On 1 March 1980, at IBM's Thomas J. Watson Research Center in Yorktown, Heights, New York, Benoit Mandelbrot first saw a visualization of the set.
Mandelbrot studied the parameter space of quadratic polynomials in an article that appeared in 1980. The mathematical study of the Mandelbrot set really began with work by the mathematicians Adrien Douady and John H. Hubbard, who established many of its fundamental properties and named the set in honor of Mandelbrot.
The mathematicians Heinz-Otto Peitgen and Peter Richter became well known for promoting the set with photographs, books, and an internationally touring exhibit of the German Goethe-Institut.
The cover article of the August 1985 "Scientific American" introduced the algorithm for computing the Mandelbrot set to a wide audience. The cover featured an image created by Peitgen, et al. The Mandelbrot set became prominent in the mid-1980s as a computer graphics demo, when personal computers became powerful enough to plot and display the set in high resolution.
The work of Douady and Hubbard coincided with a huge increase in interest in complex dynamics and abstract mathematics, and the study of the Mandelbrot set has been a centerpiece of this field ever since. An exhaustive list of all the mathematicians who have contributed to the understanding of this set since then is beyond the scope of this article, but such a list would notably include Mikhail Lyubich, Curt McMullen, John Milnor, Mitsuhiro Shishikura, and Jean-Christophe Yoccoz.
Formal definition.
The Mandelbrot set formula_2 is defined by a family of complex quadratic polynomials
given by
where formula_5 is a complex parameter. For each formula_5, one considers the behavior of the sequence
obtained by iterating formula_8 starting at critical point formula_9, which either escapes to infinity or stays within a disk of some finite radius. The Mandelbrot set is defined as the set of all points formula_5 such that the above sequence does "not" escape to infinity.
More formally, if formula_11 denotes the "n"th iterate of formula_8 (i.e. formula_8 composed with itself "n" times), the Mandelbrot set is the subset of the complex plane given by
As explained below, it is in fact possible to simplify this definition by taking formula_15.
Mathematically, the Mandelbrot set is just a set of complex numbers. A given complex number "c" either belongs to "M" or it does not. A picture of the Mandelbrot set can be made by coloring all the points formula_5 that belong to "M" black, and all other points white. The more colorful pictures usually seen are generated by coloring points not in the set according to which term in the sequence formula_17 is the first term with an absolute value greater than a certain cutoff value, usually 2. See the section on computer drawings below for more details.
The Mandelbrot set can also be defined as the connectedness locus of the family of polynomials formula_8. That is, it is the subset of the complex plane consisting of those parameters formula_5 for which the Julia set of formula_20 is connected.
Basic properties.
The Mandelbrot set is a compact set, contained in the closed disk of radius 2 around the origin. In fact, a point formula_5 belongs to the Mandelbrot set if and only if
In other words, if the absolute value of formula_24 ever becomes larger than 2, the sequence will escape to infinity.
The intersection of formula_2 with the real axis is precisely the interval [-2, 0.25]. The parameters along this interval can be put in one-to-one correspondence with those of the
real logistic family,
The correspondence is given by
In fact, this gives a correspondence between the entire parameter space of the logistic family and that of the Mandelbrot set.
As of October 2012, the area of the Mandelbrot is estimated to be ± .
Douady and Hubbard have shown that the Mandelbrot set is connected. In fact, they constructed an explicit conformal isomorphism between the complement of the Mandelbrot set and the complement of the closed unit disk. Mandelbrot had originally conjectured that the Mandelbrot set is disconnected. This conjecture was based on computer pictures generated by programs that are unable to detect the thin filaments connecting different parts of formula_2. Upon further experiments, he revised his conjecture, deciding that formula_2 should be connected.
The dynamical formula for the uniformisation of the complement of the Mandelbrot set, arising from Douady and Hubbard's proof of the connectedness of formula_2, gives rise to external rays of the Mandelbrot set. These rays can be used to study the Mandelbrot set in combinatorial terms and form the backbone of the Yoccoz parapuzzle.
The boundary of the Mandelbrot set is exactly the bifurcation locus of the quadratic family; that is, the set of parameters formula_5 for which the dynamics changes abruptly under small changes of formula_32 It can be constructed as the limit set of a sequence of plane algebraic curves, the "Mandelbrot curves", of the general type known as polynomial lemniscates. The Mandelbrot curves are defined by setting p0=z, pn+1=pn2+z, and then interpreting the set of points |pn(z)|=2 in the complex plane as a curve in the real Cartesian plane of degree 2n+1 in x and y.
Other properties.
Main cardioid and period bulbs.
Upon looking at a picture of the Mandelbrot set, one immediately notices the large cardioid-shaped region in the center. This "main cardioid"
is the region of parameters formula_5 for which formula_20 has an attracting fixed point. It consists of all parameters of the form
for some formula_36 in the open unit disk.
To the left of the main cardioid, attached to it at the point formula_37, a circular-shaped bulb is visible. This bulb consists of those parameters formula_5 for which formula_20 has an attracting cycle of period 2. This set of parameters is an actual circle, namely that of radius 1/4 around -1.
There are infinitely many other bulbs tangent to the main cardioid: for every rational number formula_40, with "p" and "q" coprime, there is such a bulb that is tangent at the parameter
This bulb is called the "formula_40-bulb" of the Mandelbrot set. It consists of parameters that have an attracting cycle of period formula_43 and combinatorial rotation number formula_40. More precisely, the formula_43 periodic Fatou components containing the attracting cycle all touch at a common point (commonly called the "formula_46-fixed point"). If we label these components formula_47 in counterclockwise orientation, then formula_20 maps the component formula_49 to the component formula_50.
The change of behavior occurring at formula_51 is known as a bifurcation: the attracting fixed point "collides" with a repelling period "q"-cycle. As we pass through the bifurcation parameter into the formula_40-bulb, the attracting fixed point turns into a repelling fixed point (the formula_46-fixed point), and the period "q"-cycle becomes attracting.
Hyperbolic components.
All the bulbs we encountered in the previous section were interior components of
the Mandelbrot set in which the maps formula_20 have an attracting periodic cycle. Such components are called "hyperbolic components".
It is conjectured that these are the "only" interior regions of formula_2. This problem, known as "density of hyperbolicity", may be the most important open problem in the field of complex dynamics. Hypothetical non-hyperbolic components of the Mandelbrot set are often referred to as "queer" or ghost components.
For "real" quadratic polynomials, this question was answered positively in the 1990s independently by Lyubich and by Graczyk and Świątek. (Note that hyperbolic components intersecting the real axis correspond exactly to periodic windows in the Feigenbaum diagram. So this result states that such windows exist near every parameter in the diagram.)
Not every hyperbolic component can be reached by a sequence of direct bifurcations from the main cardioid of the Mandelbrot set. However, such a component "can" be reached by a sequence of direct bifurcations from the main cardioid of a little Mandelbrot copy (see below).
Each of the hyperbolic components has a "centre", which is a point "c" such that the inner Fatou domain for formula_8 has a super-attracting cycle - that is, that the attraction is infinite. (see the image ) This means that the cycle contains the critical point 0, so that 0 is iterated back to itself after some iterations. We therefore have that formula_20nformula_58 for some "n". If we call this polynomial formula_59 (letting it depend on c instead of z), we have that formula_60 and that the degree of formula_59 is formula_62. We can therefore construct the centres of the hyperbolic components, by successive solvation of the equations formula_63. Note that for each step, we get just as many new centres as we have found so far.
Local connectivity.
It is conjectured that the Mandelbrot set is locally connected. This famous conjecture is known as "MLC" (for "Mandelbrot Locally Connected"). By the work of Adrien Douady and John H. Hubbard, this conjecture would result in a simple abstract "pinched disk" model of the Mandelbrot set. In particular, it would imply the important "hyperbolicity conjecture" mentioned above.
The work of Jean-Christophe Yoccoz established local connectivity of the Mandelbrot set at all finitely renormalizable parameters; that is, roughly speaking those contained only in finitely many small Mandelbrot copies. Since then, local connectivity has been proved at many other points of formula_2, but the full conjecture is still open.
Self-similarity.
 The Mandelbrot set is self-similar under magnification in the neighborhoods of the Misiurewicz points. It is also conjectured to be self-similar around generalized Feigenbaum points (e.g., −1.401155 or −0.1528 + 1.0397"i"), in the sense of converging to a limit set.
The Mandelbrot set in general is not strictly self-similar but it is quasi-self-similar, as small slightly different versions of itself can be found at arbitrarily small scales.
The little copies of the Mandelbrot set are all slightly different, mostly because of the thin threads connecting them to the main body of the set.
Further results.
The Hausdorff dimension of the boundary of the Mandelbrot set equals 2 as determined by a result of Mitsuhiro Shishikura. It is not known whether the boundary of the Mandelbrot set has positive planar Lebesgue measure.
In the Blum-Shub-Smale model of real computation, the Mandelbrot set is not computable, but its complement is computably enumerable. However, many simple objects ("e.g.", the graph of exponentiation) are also not computable in the BSS model.
At present it is unknown whether the Mandelbrot set is computable in models of real computation based on computable analysis, which correspond more closely to the intuitive notion of "plotting the set by a computer." Hertling has shown that the Mandelbrot set is computable in this model if the hyperbolicity conjecture is true.
The occurrence of π in the Mandelbrot set was discovered by David Boll in 1991. He found that when looking at the pinch points of the Mandelbrot set, the number of iterations needed for the point (-.75,ε) before escaping, multiplied by ε, was equal to π. Based on this initial finding, Aaron Klebanoff developed a further test near another pinch point (.25+ε,0) in the Mandelbrot set and found that the number of iterations times the square root of ε was equal to π.
Relationship with Julia sets.
As a consequence of the definition of the Mandelbrot set, there is a close correspondence between the geometry of the Mandelbrot set at a given point and the structure of the corresponding Julia set. For instance, a point is in the Mandelbrot set exactly when the corresponding Julia set is connected.
This principle is exploited in virtually all deep results on the Mandelbrot set. For example, Shishikura proves that, for a dense set of parameters in the boundary of the Mandelbrot set, the Julia set has Hausdorff dimension two, and then transfers this information to the parameter plane. Similarly, Yoccoz first proved the local connectivity of Julia sets, before establishing it for the Mandelbrot set at the corresponding parameters. Adrien Douady phrases this principle as:
Geometry.
For every rational number formula_40, where "p" and "q" are relatively prime, a hyperbolic component of period "q" bifurcates from the main cardioid. The part of the Mandelbrot set connected to the main cardioid at this bifurcation point is called the "p "/"q"-limb. Computer experiments suggest that the diameter of the limb tends to zero like formula_66. The best current estimate known is the "Yoccoz-inequality", which states that the size tends to zero like formula_67.
A period-"q" limb will have "q" − 1 "antennae" at the top of its limb. We can thus determine the period of a given bulb by counting these antennas.
In an attempt to demonstrate that the thickness of the p/q-limb is zero, David Boll carried out a computer experiment in 1991, where he computed the number of iterations required for the series to converge for z = formula_68 (formula_69 being the location thereof). As the series doesn't converge for the exact value of z = formula_69, the number of iterations required increases with a small ε. It turns out that multiplying the value of ε with the number of iterations required yields an approximation of π that becomes better the smaller ε. For example, for ε = 0.0000001 the number of iterations is 31415928 and the product is 3.1415928.
Image gallery of a zoom sequence.
The Mandelbrot set shows more intricate detail the closer one looks or magnifies the image, usually called "zooming in". The following example of an image sequence zooming to a selected "c" value gives an impression of the infinite richness of different geometrical structures, and explains some of their typical rules.
The magnification of the last image relative to the first one is about 10,000,000,000 to 1. Relating to an ordinary monitor, it represents a section of a Mandelbrot set with a diameter of 4 million kilometres. Its border would show an astronomical number of different fractal structures.
The seahorse "body" is composed by 25 "spokes" consisting of two groups of 12 "spokes" each and one "spoke" connecting to the main cardioid. These two groups can be attributed by some kind of metamorphosis to the two "fingers" of the "upper hand" of the Mandelbrot set; therefore, the number of "spokes" increases from one "seahorse" to the next by 2; the "hub" is a so-called Misiurewicz point. Between the "upper part of the body" and the "tail" a distorted small copy of the Mandelbrot set called satellite may be recognized.
The islands above seem to consist of infinitely many parts like Cantor sets, as is actually the case for the corresponding Julia set "Jc". However they are connected by tiny structures so that the whole represents a simply connected set. The tiny structures meet each other at a satellite in the center that is too small to be recognized at this magnification. The value of "c" for the corresponding "Jc" is not that of the image center but, relative to the main body of the Mandelbrot set, has the same position as the center of this image relative to the satellite shown in the 6th zoom step.
Generalizations.
Multibrot sets are bounded sets found in the complex plane for members of the general monic univariate polynomial family of recursions
For integer d, these sets are connectedness loci for the Julia sets built from the same formula. The full cubic connectedness map has also been studied; here one considers the two-parameter recursion formula_72, whose two critical points are the complex square roots of the parameter "k". A point is in the map if either critical point is stable.
For general families of holomorphic functions, the "boundary" of the Mandelbrot set generalizes to the bifurcation locus, which is a natural object to study even when the connectedness locus is not useful.
Other, non-analytic, mappings.
Of particular interest is the
tricorn fractal, the connectedness locus of the anti-holomorphic family
The tricorn (also sometimes called the "Mandelbar set") was encountered by Milnor in his study of parameter slices of real cubic polynomials. It is "not" locally connected. This property is inherited by the connectedness locus of real cubic polynomials.
Another non-analytic generalization is the Burning Ship fractal, which is obtained by iterating the mapping
The Multibrot set is obtained by varying the value of the exponent "d". The article has a video that shows the development from "d" = 0 to 7 at which point there are 6 i.e. ("d" - 1) lobes around the perimeter. A similar development with negative exponents results in (1 - "d") clefts on the inside of a ring.
Computer drawings.
There are many programs used to generate the Mandelbrot set and other fractals, some of which are described in fractal-generating software. These programs use a variety of algorithms to determine the color of individual pixels and achieve efficient computation.
Escape time algorithm.
The simplest algorithm for generating a representation of the Mandelbrot set is known as the "escape time" algorithm. A repeating calculation is performed for each "x", "y" point in the plot area and based on the behavior of that calculation, a color is chosen for that pixel.
The "x" and "y" locations of each point are used as starting values in a repeating, or iterating calculation (described in detail below). The result of each iteration is used as the starting values for the next. The values are checked during each iteration to see if they have reached a critical 'escape' condition or 'bailout'. If that condition is reached, the calculation is stopped, the pixel is drawn, and the next x, y point is examined. For some starting values, escape occurs quickly, after only a small number of iterations. For starting values very close to but not in the set, it may take hundreds or thousands of iterations to escape. For values within the Mandelbrot set, escape will never occur. The programmer or user must choose how much iteration, or 'depth,' they wish to examine. The higher the maximum number of iterations, the more detail and subtlety emerge in the final image, but the longer time it will take to calculate the fractal image.
Escape conditions can be simple or complex. Because no complex number with a real or imaginary part greater than 2 can be part of the set, a common bailout is to escape when either coefficient exceeds 2. A more computationally complex method that detects escapes sooner, is to compute distance from the origin using the Pythagorean theorem, i.e., to determine the absolute value, or "modulus", of the complex number. If this value exceeds two, the point has reached escape. More computationally intensive rendering variations include the Buddhabrot method, which finds escaping points and plots their iterated coordinates.
The color of each point represents how quickly the values reached the escape point. Often black is used to show values that fail to escape before the iteration limit, and gradually brighter colors are used for points that escape. This gives a visual representation of how many cycles were required before reaching the escape condition.
To render such an image, the region of the complex plane we are considering is subdivided into a certain number of pixels. To color any such pixel, let formula_5 be the midpoint of that pixel. We now iterate the critical point 0 under formula_20, checking at each step whether the orbit point has modulus larger than 2. When this is the case, we know that formula_5 does not belong to the Mandelbrot set, and we color our pixel according to the number of iterations used to find out. Otherwise, we keep iterating up to a fixed number of steps, after which we decide that our parameter is "probably" in the Mandelbrot set, or at least very close to it, and color the pixel black.
In pseudocode, this algorithm would look as follows. The algorithm does not use complex numbers, and manually simulates complex number operations using two real numbers, for those who do not have a complex data type. The program may be simplified if the programming language includes complex data type operations.
where, relating the pseudocode to formula_5, formula_79 and formula_20:
and so, as can be seen in the pseudocode in the computation of "x" and "y":
To get colorful images of the set, the assignment of a color to each value of the number of executed iterations can be made using one of a variety of functions (linear, exponential, etc.). One practical way, without slowing down calculations, is to use the number of executed iterations as an entry to a look-up color palette table initialized at startup. If the color table has, for instance, 500 entries, then the color selection is "n" mod 500, where "n" is the number of iterations.
Histogram coloring.
A more accurate coloring method involves using a histogram, which keeps track of how many pixels reached each iteration number, from 1 to n. This method will equally distribute colors to the same overall area, and, importantly, is independent of the maximum number of iterations chosen.
First, create an array of size n. For each pixel, which took i iterations, find the ith element and increment it. This creates the histogram during computation of the image. Then, when finished, perform a second "rendering" pass over each pixel, utilizing the completed histogram. If you had a continuous color palette ranging from [0.0, 1.0], you could find the normalized color of each pixel as follows, using the variables from above.
This method may be combined with the smooth coloring method below for more aesthetically pleasing images.
Continuous (smooth) coloring.
The Escape Time Algorithm is popular for its simplicity. However, it creates bands of color, which, as a type of aliasing, can detract from an image's aesthetic value. This can be improved using an algorithm known as "Normalized Iteration Count", which provides a smooth transition of colors between iterations. The algorithm associates a real number formula_86 with each value of "z" by using the connection of the iteration number with the potential function. This function is given by
where "z""n" is the value after "n" iterations and "P" is the power for which "z" is raised to in the Mandelbrot set equation ("z""n"+1 = "z"n"""P" + "c", "P" is generally 2).
If we choose a large bailout radius "N" (e.g., 10100), we have that
for some real number formula_89, and this is
and as "n" is the first iteration number such that |"z""n"| > "N", the number we subtract from "n" is in the interval [0, 1).
For the coloring we must have a cyclic scale of colors (constructed mathematically, for instance) and containing "H" colors numbered from 0 to "H" − 1 ("H" = 500, for instance). We multiply the real number formula_89 by a fixed real number determining the density of the colors in the picture, and take the integral part of this number modulo "H", and use it to look up the corresponding color in the color table.
For example, modifying the above pseudocode and also using the concept of linear interpolation would yield
Distance estimates.
One can compute the distance from point "c" (in exterior or interior) to nearest point on the boundary of the Mandelbrot set.
Exterior distance estimation.
The proof of the connectedness of the Mandelbrot set in fact gives a formula for the uniformizing map of the complement of formula_2 (and the derivative of this map). By the Koebe 1/4 theorem, one can then estimate the distance between the midpoint of our pixel and the Mandelbrot set up to a factor of 4.
In other words, provided that the maximal number of iterations is sufficiently high, one obtains a picture of the Mandelbrot set with the following properties:
The distance estimate "b" of a pixel "c" (a complex number) from the Mandelbrot set is given by
where 
The idea behind this formula is simple: When the equipotential lines for the potential function formula_105 lie close, the number formula_106 is large, and conversely, therefore the equipotential lines for the function formula_107 should lie approximately regularly.
From a mathematician's point of view, this formula only works in limit where "n" goes to infinity, but very reasonable estimates can be found with just a few additional iterations after the main loop exits.
Once "b" is found, by the Koebe 1/4-theorem, we know there's no point of the Mandelbrot set with distance from "c" smaller than b/4.
The distance estimation can be used for drawing of the boundary of the Mandelbrot set, see the article Julia set.
Interior distance estimation.
It is also possible to estimate the distance of a limitly periodic (i.e., inner) point to the boundary of the Mandelbrot set. The estimate is given by
where
Analogous to the exterior case, once "b" is found, we know that all points within the distance of "b"/4 from "c" are inside the Mandelbrot set.
There are two practical problems with the interior distance estimate: first, we need to find formula_117 precisely, and second, we need to find formula_109 precisely.
The problem with formula_117 is that the convergence to formula_117 by iterating formula_8 requires, theoretically, an infinite number of operations.
The problem with any given formula_109 is that, sometimes, due to rounding errors, a period is falsely identified to be an integer multiple of the real period (e.g., a period of 86 is detected, while the real period is only 43=86/2). In such case, the distance is overestimated, i.e., the reported radius could contain points outside the Mandelbrot set.
Optimizations.
Cardioid / bulb checking.
One way to improve calculations is to find out beforehand whether the given point lies within the cardioid or in the period-2 bulb. Before passing the complex value through the escape time algorithm, first check if:
where x represents the real value of the point and y the imaginary value. The first two equations determine if the point is within the cardioid, the last the period-2 bulb.
The cardioid test can equivalently be performed without the square root:
3rd- and higher-order buds do not have equivalent tests, because they are not perfectly circular. However, it is possible to find whether the points are within circles that are circumscribed by these higher order bulbs, preventing many, though not all, of the points in the bulb from being iterated.
Periodicity checking.
To prevent having to do huge numbers of iterations for points in the set, one can perform periodicity checking. Check if a point reached in iterating a pixel has been reached before. If so, the pixel cannot diverge and must be in the set.
Periodicity checking is, of course, a trade-off. The need to remember points costs memory and "data management" instructions, whereas it saves "computational" instructions.
However, checking against only one previous iteration can detect many periods with little performance overhead. For example, within the while loop of the pseudocode above, make the following modifications.
Border tracing / edge checking.
It can be shown that if a solid shape can be drawn on the Mandelbrot set, with all the border colors being the same, then the shape can be filled in with that color. This is a result of the Mandelbrot set being simply connected. Boundary tracing works by following the edges of the various iteration levels (colored bands) all around the set, and then filling the entire band at once. This can be a good speed increase, because it means that large numbers of points can be skipped.
A similar method operation on the same principle uses rectangles instead of arbitrary border shapes. It is usually faster than boundary tracing because it requires fewer calculations to work out the rectangle. It is inefficient however because boundaries are not rectangular, and so some areas can be missed. This issue can be minimized by created a recursive algorithm that, if a rectangle border fails, will subdivide it into four smaller rectangles and test those, and either fill each or subdivide again and repeat the process.
However, this only works using discrete colors in the escape time algorithm. It will not work for smooth/continuous coloring.
Perturbation theory and series approximation.
Very highly magnified images require more than the standard 64-128 or so bits of precision most hardware floating-point units provide, requiring renderers to use slow "bignum" or "arbitrary precision" math libraries to calculate. However, this can be sped up by the exploitation of perturbation theory. Given
as the iteration, and a small epsilon, it is the case that
or
so if one defines
one can calculate a single point (e.g. the center of an image) using normal, high-precision arithmetic ("z"), giving a "reference orbit", and then compute many points around it in terms of various initial offsets epsilon-zero plus the above iteration for epsilon. For most iterations, epsilon does not need more than 16 significant figures, and consequently hardware floating-point may be used to get a mostly accurate image. There will often be some areas where the orbits of points diverge enough from the reference orbit that extra precision is needed on those points, or else additional local high-precision-calculated reference orbits are needed. By measuring the orbit distance between the reference point and the point calculated with low precision, it can be detected that it is not possible to calculate the point correctly, and the calculation can be stopped. These incorrect points can later be re-calculated e.g. from another closer reference point.
Further it is possible to approximate the starting values for the low precision points with a truncated Taylor series, which often enables a significant amount of iterations to be skipped.
Renderers implementing these techniques are publicly available and offer speedups for highly magnified images by around two orders of magnitude.

</doc>
<doc id="19565" url="http://en.wikipedia.org/wiki?curid=19565" title="Michael Mann (director)">
Michael Mann (director)

Michael Kenneth Mann (born February 5, 1943) is an American film director, screenwriter, and producer.
For his work, he has received nominations from international organizations and juries, including those at the British Academy of Film and Television Arts, Cannes and the Academy of Motion Picture Arts and Sciences. His major films include the historical epic "The Last of the Mohicans" (1992), the drama "The Insider" (1999), the biopic "Ali" (2001), and the crime films "Heat" (1995) and "Collateral" (2004).
"Total Film" ranked Mann No. 28 on their 100 The Greatest Directors Ever, "Sight and Sound" ranked him No. 5 on their list of the 10 Best Directors of the Last 25 Years, and "Entertainment Weekly" ranked Mann No. 8 on their 25 Greatest Active Film Directors list.
Early life and education.
Mann was born on February 5, 1943 in Chicago, Illinois, of Jewish ancestry, the son of grocers Esther and Jack Mann.
He received a B.A. in English at the University of Wisconsin–Madison where he developed interests in history, philosophy and architecture. It was at this time that he first saw Stanley Kubrick's "Dr. Strangelove" and fell in love with movies. In a recent "L.A. Weekly" interview, he describes the film's impact on him: "It said to my whole generation of filmmakers that you could make an individual statement of high integrity and have that film be successfully seen by a mass audience all at the same time. In other words, you didn't have to be making "Seven Brides for Seven Brothers" if you wanted to work in the mainstream film industry, or be reduced to niche filmmaking if you wanted to be serious about cinema. So that's what Kubrick meant, aside from the fact that "Strangelove" was a revelation." His daughter Ami Canaan Mann is also a film director and producer.
Career.
1960s-1970s.
Mann later moved to London in the mid 1960s to go to graduate school in cinema. He went on to receive a graduate degree at the London Film School. He spent seven years in the United Kingdom going to film school and then working on commercials along with contemporaries Alan Parker, Ridley Scott and Adrian Lyne. In 1968, footage he shot of the Paris student revolt for a documentary, "Insurrection", aired on NBC's "First Tuesday" news program and he developed his '68 experiences into the short film "Jaunpuri" which won the Jury Prize at Cannes in 1970.
Mann returned to United States after divorcing his first wife in 1971. He went on to direct a road trip documentary, "17 Days Down the Line". Three years later, "Hawaii Five-O" veteran Robert Lewin gave Mann a shot and a crash course on television writing and story structure. Mann wrote four episodes of "Starsky and Hutch" (three in the first series and one in the second ) and the pilot episode for "Vega$". Around this time, he worked on a show called "Police Story" with cop-turned-novelist Joseph Wambaugh. "Police Story" concentrated on the detailed realism of a real cop's life and taught Mann that first-hand research was essential to bring authenticity to his work. His first feature movie was a television special called "The Jericho Mile", which was released theatrically in Europe. It won the Emmy for best MOW in 1979 and the DGA Best Director award.
1980s.
His television work also includes being the executive producer on "Miami Vice" and "Crime Story". Contrary to popular belief, he was not the creator of these shows, but the executive producer and showrunner. They were produced by his production company and his cinematic influence is felt throughout each show in terms of casting and style. Mann is now known primarily as a feature film director. He has a distinctive style that is reflected in his works: his trademarks are intricate scene setups, during "Miami Vice" to such an extent that a whole scene was completely color-coordinated, from props to backgrounds to actors' wardrobes, as well as powerfully-lit night scenes and combining exterior filming in such a way that shots of completely unrelated filming locations can appear as being of the same building or landmark. In terms of sound, he is known for unusual scores, such as Tangerine Dream in "Thief" or the new-age score to "Manhunter". Dante Spinotti is a frequent cinematographer of Mann's pictures.
Mann's first cinema feature as director was "Thief" (1981) starring James Caan. His next film "The Keep" (1983) was, in retrospect, an uncharacteristic choice, being that it is a supernatural thriller set in Nazi-occupied Romania. Though it was a commercial flop, the film has since attained cult status amongst fans.
In 1986, Mann was the first to bring Thomas Harris's character of serial killer Hannibal Lecter to the screen with "Manhunter", his adaptation of the novel "Red Dragon", which starred Brian Cox as a more down-to-earth Hannibal. The story was remade less than 20 years after it came out by Brett Ratner presumably because Anthony Hopkins reprisal of the role in Ridley Scott's "Hannibal" had made the character a highly lucrative property. In an interview on the "Manhunter" DVD, star William Petersen comments that because Mann is so focused on his creations, it takes several years for Mann to complete a film; Petersen believes that this is why Mann does not make films very often.
1990s.
He gained widespread recognition in 1992 for his film adaptation of James Fenimore Cooper's book into the epic history film "Last of the Mohicans". His biggest critical successes in the 1990s began with the release of "Heat" in 1995 and "The Insider" in 1999. The films, which featured Al Pacino along with Robert De Niro in "Heat" and Russell Crowe in "The Insider", showcased Mann's cinematic style and adeptness at creating rich, complex storylines as well as directing actors. "The Insider" was nominated for seven Academy Awards as a result, including a nomination for Mann's direction.
2000s.
With his next film "Ali" starring Will Smith in 2001, he started experimenting with digital cameras. The film helped catapult Will Smith to greater fame, and he was nominated for an Academy Award for his performance. For his crime film "Collateral", which cast Tom Cruise against type by giving him the role of a hitman, Mann shot all of the exterior scenes digitally so that he could achieve more depth and detail during the night scenes while shooting most of the interiors on film stock. In 2004, Mann produced "The Aviator", based on the life of Howard Hughes, which he had developed with Leonardo DiCaprio. "The Aviator" was nominated for an Academy Award for Best Picture but lost to "Million Dollar Baby". After "Collateral", Mann directed the film adaptation of "Miami Vice" which he also executive produced. It stars a completely new cast with Colin Farrell as Don Johnson's character Sonny Crockett, and Jamie Foxx filling Philip Michael Thomas' shoes.
Mann served as a producer and Peter Berg as director for "The Kingdom" and "Hancock". "Hancock" stars Will Smith as a hard-drinking superhero who has fallen out of favor with the public and who begins to have a relationship with the wife (Charlize Theron) of a public relations expert (Jason Bateman), who is helping him to repair his image. Mann also makes a cameo appearance in the film as an executive. In the fall of 2007, Mann directed two commercials for Nike. The ad campaign "Leave Nothing" features football action scenes with current NFL players Shawne Merriman and Steven Jackson.
In 2009, Mann wrote and directed "Public Enemies" for Universal Pictures, about the Depression-era crime wave, based on Brian Burrough's nonfiction book, "Public Enemies: America's Greatest Crime Wave and the Birth of the FBI, 1933–34". It starred Johnny Depp and Christian Bale. Depp played John Dillinger in the film, and Bale played Melvin Purvis, the FBI agent in charge of capturing Dillinger.
2010s.
In January 2010 it was reported by "Variety" that Mann, alongside David Milch, would serve as co-executive producer of new TV series "Luck". The series was an hour-long HBO production, and Mann directed the series' pilot. Although initially renewed for a second season after the airing of the pilot, it was eventually cancelled due to the death of three horses during production.
On February 14, 2013, it was announced that Mann had been developing an untitled thriller film with screenwriter Morgan Davis Foehl for over a year, for Legendary Pictures. In May 2013, Mann started filming the thriller, named "Blackhat", in Los Angeles, Kuala Lumpur, Hong Kong and Jakarta. The film, starring Chris Hemsworth as a hacker who gets released from prison to pursue a cyberterrorist across the globe, was released on January 16, 2015.
In January 2015, it was reported in "The New Yorker" that Mann is developing a film about Ferrari founder Enzo Ferrari.
Filming style.
Mann's films often contain one to four deadpan male protagonists who are expert in some profession. Importantly, his films often involve a tragic rather than a happy ending, such as in "Miami Vice", when of the two undercover police officers, one has his girlfriend (also an undercover officer) come out of a coma and the other tearfully separates from his romantic interest. Mann's films contain fast-paced, artful scenes that strongly depend on powerful music, where often two opposing sides intermix, such as undercover policework and undercover drug trafficking, so that it is hard to distinguish between the two. For example, in "Heat", the criminal and the police detective meet for coffee, as if old business partners. Often it is hard to distinguish between opposing sides (police vs. criminals, etc.), where the actions, dress, and mannerisms of the characters are extremely similar. Also, Mann's work often involves landscapes and modes where the heroic protagonists occupy a somewhat secret world, away from ordinary concerns (law, life and death, money, daily-life survival duties, family duties, and so on), where the secret world may or may not coincide with ordinary reality. Protagonists often find impassioned romantic interests which are severed under tragic situations near the end of the film ("Last of the Mohicans", "Heat", "Collateral", "Miami Vice, Public Enemies"). Overall, Mann's films mix artistry (via music, stylishness and emotional intensity) with sexuality, strong violence, humorless noir-like stoicism, and complex plot twists.
Advertising.
Mann directed the 2002 "Lucky Star" advertisement for Mercedes-Benz, which took the form of a film trailer for a purported thriller featuring Benicio del Toro. Mann also directed the 2008 promotional video for Ferrari's California sports car. In 2009 Mann also directed a commercial for Nike that featured several stylistic cues, most notably the use of "Promontory" from the soundtrack of "The Last of the Mohicans".
Reception.
Awards and honors.
Mann received an Emmy in 1979 for Outstanding Writing in a Limited Series or a Special for "The Jericho Mile". The following year he was honored by the Directors Guild of America for Outstanding Directorial Achievement for "The Jericho Mile". In 1990, he won another Emmy for Outstanding Miniseries for "". Mann was the recipient of the Humanitas Prize and the Writers Guild of America's Paul Selvin Award in 2000 for "The Insider". In 2005, he received the BAFTA Film Award for co-producing "The Aviator".
To date he has received four Academy Award nominations: in 2000, the Best Adapted Screenplay, Best Director and Best Motion Picture of the Year all for "The Insider", in 2005 Mann received nomination for production of Scorsese's "The Aviator".

</doc>
<doc id="19566" url="http://en.wikipedia.org/wiki?curid=19566" title="Main-group element">
Main-group element

In chemistry and atomic physics, the main group is the group of elements whose lightest members are represented by helium, lithium, beryllium, boron, carbon, nitrogen, oxygen, and fluorine as arranged in the periodic table of the elements. The main group includes the elements (except hydrogen) in groups 1 and 2 (s-block), and groups 13 to 18 (p-block). Group 12 elements are usually considered to be transition metals; however, zinc (Zn), cadmium (Cd), and mercury (Hg) share some properties of both groups, and some scientists believe they should be included in the main group.
In older nomenclature the main-group elements are groups IA and IIA, and groups IIIB to 0 (CAS groups IIIA to VIIIA). Group 12 is labelled as group IIB in both systems.
Main-group elements (with some of the lighter transition metals) are the most abundant elements on Earth, in the Solar System, and in the Universe. They are sometimes also called the representative elements.

</doc>
<doc id="19567" url="http://en.wikipedia.org/wiki?curid=19567" title="Microscopy">
Microscopy

Microscopy is the technical field of using microscopes to view objects and areas of objects that cannot be seen with the naked eye (objects that are not within the resolution range of the normal eye). There are three well-known branches of microscopy: optical, electron, and scanning probe microscopy.
Optical and electron microscopy involve the diffraction, reflection, or refraction of electromagnetic radiation/electron beams interacting with the specimen, and the collection of the scattered radiation or another signal in order to create an image. This process may be carried out by wide-field irradiation of the sample (for example standard light microscopy and transmission electron microscopy) or by scanning of a fine beam over the sample (for example confocal laser scanning microscopy and scanning electron microscopy). Scanning probe microscopy involves the interaction of a scanning probe with the surface of the object of interest. The development of microscopy revolutionized biology and remains an essential technique in the life and physical sciences.
Optical microscopy.
Optical or light microscopy involves passing visible light transmitted through or reflected from the sample through a single or multiple lenses to allow a magnified view of the sample. The resulting image can be detected directly by the eye, imaged on a photographic plate or captured digitally. The single lens with its attachments, or the system of lenses and imaging equipment, along with the appropriate lighting equipment, sample stage and support, makes up the basic light microscope. The most recent development is the digital microscope, which uses a CCD camera to focus on the exhibit of interest. The image is shown on a computer screen, so eye-pieces are unnecessary.
Limitations.
Limitations of standard optical microscopy (bright field microscopy) lie in three areas;
Live cells in particular generally lack sufficient contrast to be studied successfully, since the internal structures of the cell are colourless and transparent. The most common way to increase contrast is to stain the different structures with selective dyes, but this often involves killing and fixing the sample. Staining may also introduce artifacts, apparent structural details that are caused by the processing of the specimen and are thus not legitimate features of the specimen. In general, these techniques make use of differences in the refractive index of cell structures. It is comparable to looking through a glass window: you (bright field microscopy) don't see the glass but merely the dirt on the glass. There is a difference, as glass is a denser material, and this creates a difference in phase of the light passing through. The human eye is not sensitive to this difference in phase, but clever optical solutions have been thought out to change this difference in phase into a difference in amplitude (light intensity).
Techniques.
In order to improve specimen contrast or highlight certain structures in a sample special techniques must be used. A huge selection of microscopy techniques are available to increase contrast or label a sample.
<gallery caption="Four examples of transilumination techniques used to generate contrast in a sample of tissue paper. 1.559 μm/pixel." align="center">
Image:Paper_Micrograph_Bright.png|Bright field illumination, sample contrast comes from absorbance of light in the sample.
Image:Paper_Micrograph_Cross-Polarised.png|Cross-polarized light illumination, sample contrast comes from rotation of polarized light through the sample.
Image:Paper_Micrograph_Dark.png|Dark field illumination, sample contrast comes from light scattered by the sample.
Image:Paper_Micrograph_Phase.png|Phase contrast illumination, sample contrast comes from interference of different path lengths of light through the sample.
</gallery>
Bright field.
Bright field microscopy is the simplest of all the light microscopy techniques. Sample illumination is via transmitted white light, i.e. illuminated from below and observed from above. Limitations include low contrast of most biological samples and low apparent resolution due to the blur of out of focus material. The simplicity of the technique and the minimal sample preparation required are significant advantages.
Oblique illumination.
The use of oblique (from the side) illumination gives the image a 3-dimensional appearance and can highlight otherwise invisible features. A more recent technique based on this method is "Hoffmann's modulation contrast", a system found on inverted microscopes for use in cell culture. Oblique illumination suffers from the same limitations as bright field microscopy (low contrast of many biological samples; low apparent resolution due to out of focus objects).
Dark field.
Dark field microscopy is a technique for improving the contrast of unstained, transparent specimens. Dark field illumination uses a carefully aligned light source to minimize the quantity of directly transmitted (unscattered) light entering the image plane, collecting only the light scattered by the sample. Dark field can dramatically improve image contrast – especially of transparent objects – while requiring little equipment setup or sample preparation. However, the technique suffers from low light intensity in final image of many biological samples, and continues to be affected by low apparent resolution.
"Rheinberg illumination" is a special variant of dark field illumination in which transparent, colored filters are inserted just before the condenser so that light rays at high aperture are differently colored than those at low aperture (i.e. the background to the specimen may be blue while the object appears self-luminous red). Other color combinations are possible but their effectiveness is quite variable.
Dispersion staining.
Dispersion staining is an optical technique that results in a colored image of a colorless object. This is an optical staining technique and requires no stains or dyes to produce a color effect. There are five different microscope configurations used in the broader technique of dispersion staining. They include brightfield Becke line, oblique, darkfield, phase contrast, and objective stop dispersion staining.
Phase contrast.
More sophisticated techniques will show proportional differences in optical density. Phase contrast is a widely used technique that shows differences in refractive index as difference in contrast. It was developed by the Dutch physicist Frits Zernike in the 1930s (for which he was awarded the Nobel Prize in 1953). The nucleus in a cell for example will show up darkly against the surrounding cytoplasm. Contrast is excellent; however it is not for use with thick objects. Frequently, a halo is formed even around small objects, which obscures detail. The system consists of a circular annulus in the condenser, which produces a cone of light. This cone is superimposed on a similar sized ring within the phase-objective. Every objective has a different size ring, so for every objective another condenser setting has to be chosen. The ring in the objective has special optical properties: it, first of all, reduces the direct light in intensity, but more importantly, it creates an artificial phase difference of about a quarter wavelength. As the physical properties of this direct light have changed, interference with the diffracted light occurs, resulting in the phase contrast image. One disadvantage of phase-contrast microscopy is halo formation (halo-light ring).
Differential interference contrast.
Superior and much more expensive is the use of interference contrast. Differences in optical density will show up as differences in relief. A nucleus within a cell will actually show up as a globule in the most often used differential interference contrast system according to Georges Nomarski. However, it has to be kept in mind that this is an "optical effect", and the relief does not necessarily resemble the true shape. Contrast is very good and the condenser aperture can be used fully open, thereby reducing the depth of field and maximizing resolution.
The system consists of a special prism (Nomarski prism, Wollaston prism) in the condenser that splits light in an ordinary and an extraordinary beam. The spatial difference between the two beams is minimal (less than the maximum resolution of the objective). After passage through the specimen, the beams are reunited by a similar prism in the objective.
In a homogeneous specimen, there is no difference between the two beams, and no contrast is being generated. However, near a refractive boundary (say a nucleus within the cytoplasm), the difference between the ordinary and the extraordinary beam will generate a relief in the image. Differential interference contrast requires a polarized light source to function; two polarizing filters have to be fitted in the light path, one below the condenser (the polarizer), and the other above the objective (the analyzer).
Note: In cases where the optical design of a microscope produces an appreciable lateral separation of the two beams we have the case of classical interference microscopy, which does not result in relief images, but can nevertheless be used for the quantitative determination of mass-thicknesses of microscopic objects.
Interference reflection microscopy.
An additional technique using interference is interference reflection microscopy (also known as reflected interference contrast, or RIC). It relies on cell adhesion to the slide to produce an interference signal. If there is no cell attached to the glass, there will be no interference.
Interference reflection microscopy can be obtained by using the same elements used by DIC, but without the prisms. Also, the light that is being detected is reflected and not transmitted as it is when DIC is employed.
Fluorescence.
When certain compounds are illuminated with high energy light, they emit light of a lower frequency. This effect is known as fluorescence. Often specimens show their characteristic autofluorescence image, based on their chemical makeup.
This method is of critical importance in the modern life sciences, as it can be extremely sensitive, allowing the detection of single molecules. Many different fluorescent dyes can be used to stain different structures or chemical compounds. One particularly powerful method is the combination of antibodies coupled to a fluorophore as in immunostaining. Examples of commonly used fluorophores are fluorescein or rhodamine.
The antibodies can be tailor-made for a chemical compound. For example, one strategy often in use is the artificial production of proteins, based on the genetic code (DNA). These proteins can then be used to immunize rabbits, forming antibodies which bind to the protein. The antibodies are then coupled chemically to a fluorophore and used to trace the proteins in the cells under study.
Highly efficient fluorescent proteins such as the green fluorescent protein (GFP) have been developed using the molecular biology technique of gene fusion, a process that links the expression of the fluorescent compound to that of the target protein. This combined fluorescent protein is, in general, non-toxic to the organism and rarely interferes with the function of the protein under study. Genetically modified cells or organisms directly express the fluorescently tagged proteins, which enables the study of the function of the original protein in vivo.
Growth of protein crystals results in both protein and salt crystals. Both are colorless and microscopic. Recovery of the protein crystals requires imaging which can be done by the intrinsic fluorescence of the protein or by using transmission microscopy. Both methods require an ultraviolet microscope as protein absorbs light at 280 nm. Protein will also fluorescence at approximately 353 nm when excited with 280 nm light.
Since fluorescence emission differs in wavelength (color) from the excitation light, an ideal fluorescent image shows only the structure of interest that was labeled with the fluorescent dye. This high specificity led to the widespread use of fluorescence light microscopy in biomedical research. Different fluorescent dyes can be used to stain different biological structures, which can then be detected simultaneously, while still being specific due to the individual color of the dye.
To block the excitation light from reaching the observer or the detector, filter sets of high quality are needed. These typically consist of an excitation filter selecting the range of excitation wavelengths, a dichroic mirror, and an emission filter blocking the excitation light. Most fluorescence microscopes are operated in the Epi-illumination mode (illumination and detection from one side of the sample) to further decrease the amount of excitation light entering the detector.
An example of fluorescence microscopy today is two-photon or multi-photon imaging. Two photon imaging allows imaging of living tissues up to a very high depth by enabling greater excitation light penetration and reduced background emission signal. A recent development using this technique is called , which allows imaging at greater depths than two-photon or multi-photon imaging would by implementing adaptive optics into the system. Pioneered by the and recently reported by Boston University on focusing light through static and dynamic strongly scattering media. By utilizing adaptive optics,it has allowed the optical wavelength control needed for transformative impacts on deep tissue imaging.
See also:
total internal reflection fluorescence microscope
Neuroscience
Confocal.
Confocal microscopy uses a scanning point of light and a pinhole to prevent out of focus light from reaching the detector. Compared to full sample illumination, confocal microscopy gives slightly higher resolution, and significantly improves optical sectioning. Confocal microscopy is, therefore, commonly used where 3D structure is important.
Single plane illumination microscopy and light sheet fluorescence microscopy.
Using a plane of light formed by focusing light through a cylindrical lens at a narrow angle or by scanning a line of light in a plane perpendicular to the axis of objective, high resolution optical sections can be taken. Single plane illumination is also accomplished using beam shaping techniques incorporating multiple-prism beam expanders. The images are captured by CCDs. These variants allow very fast and high signal to noise ratio image capture.
Deconvolution.
Fluorescence microscopy is a powerful technique to show specifically labeled structures within a complex environment and to provide three-dimensional information of biological structures. However, this information is blurred by the fact that, upon illumination, all fluorescently labeled structures emit light, irrespective of whether they are in focus or not. So an image of a certain structure is always blurred by the contribution of light from structures that are out of focus. This phenomenon results in a loss of contrast especially when using objectives with a high resolving power, typically oil immersion objectives with a high numerical aperture.
However, blurring is not caused by random processes, such as light scattering, but can be well defined by the optical properties of the image formation in the microscope imaging system. If one considers a small fluorescent light source (essentially a bright spot), light coming from this spot spreads out further from our perspective as the spot becomes more out of focus. Under ideal conditions, this produces an "hourglass" shape of this point source in the third (axial) dimension. This shape is called the point spread function (PSF) of the microscope imaging system. Since any fluorescence image is made up of a large number of such small fluorescent light sources, the image is said to be "convolved by the point spread function".
Knowing this point spread function means that it is possible to reverse this process to a certain extent by computer-based methods commonly known as deconvolution microscopy. There are various algorithms available for 2D or 3D deconvolution. They can be roughly classified in "nonrestorative" and "restorative" methods. While the nonrestorative methods can improve contrast by removing out-of-focus light from focal planes, only the restorative methods can actually reassign light to its proper place of origin. Processing fluorescent images in this manner can be an advantage over directly acquiring images without out-of-focus light, such as images from confocal microscopy, because light signals otherwise eliminated become useful information. For 3D deconvolution, one typically provides a series of images taken from different focal planes (called a Z-stack) plus the knowledge of the PSF, which can be derived either experimentally or theoretically from knowing all contributing parameters of the microscope.
Sub-diffraction techniques.
A multitude of super-resolution microscopy techniques have been developed in recent times which circumvent the diffraction barrier.
This is mostly achieved by imaging a sufficiently static sample multiple times and either modifying the excitation light or observing stochastic changes in the image.
Knowledge of and chemical control over fluorophore photophysics is at the core of these techniques, by which resolutions of ~20 nanometers are regularly obtained.
Serial time-encoded amplified microscopy.
Serial time encoded amplified microscopy (STEAM) is an imaging method that provides ultrafast shutter speed and frame rate, by using optical image amplification to circumvent the fundamental trade-off between sensitivity and speed, and a single-pixel photodetector to eliminate the need for a detector array and readout time limitations The method is at least 1000 times faster than the state-of-the-art CCD and CMOS cameras. Consequently, it is potentially useful for a broad range of scientific, industrial, and biomedical applications that require high image acquisition rates, including real-time diagnosis and evaluation of shockwaves, microfluidics, MEMS, and laser surgery. 
Extensions.
Most modern instruments provide simple solutions for micro-photography and image recording electronically. However such capabilities are not always present and the more experienced microscopist will, in many cases, still prefer a hand drawn image to a photograph. This is because a microscopist with knowledge of the subject can accurately convert a three-dimensional image into a precise two-dimensional drawing. In a photograph or other image capture system however, only one thin plane is ever in good focus.
The creation of careful and accurate micrographs requires a microscopical technique using a monocular eyepiece. It is essential that both eyes are open and that the eye that is not observing down the microscope is instead concentrated on a sheet of paper on the bench besides the microscope. With practice, and without moving the head or eyes, it is possible to accurately record the observed details by tracing round the observed shapes by simultaneously "seeing" the pencil point in the microscopical image.
Practicing this technique also establishes good general microscopical technique. It is always less tiring to observe with the microscope focused so that the image is seen at infinity and with both eyes open at all times.
Other enhancements.
Microspectroscopy:spectroscopy with a microscope
X-ray.
As resolution depends on the wavelength of the light. Electron microscopy has been developed since the 1930s that use electron beams instead of light. Because of the much smaller wavelength of the electron beam, resolution is far higher.
Though less common, X-ray microscopy has also been developed since the late 1940s. The resolution of X-ray microscopy lies between that of light microscopy and electron microscopy.
Electron microscopy.
Until the invention of sub-diffraction microscopy, the wavelength of the light limited the resolution of traditional microscopy to around 0.2 micrometers. In order to gain higher resolution, the use of an electron beam with a far smaller wavelength is used in electron microscopes.
Electron microscopes equipped for X-ray spectroscopy can provide qualitative and quantitative elemental analysis.
Scanning probe microscopy.
This is a sub-diffraction technique. Examples of scanning probe microscopes are the atomic force microscope (AFM), the Scanning tunneling microscope, the photonic force microscope and the recurrence tracking microscope. All such methods use the physical contact of a solid probe tip to scan the surface of an object, which is supposed to be almost flat.
Ultrasonic force.
Ultrasonic Force Microscopy (UFM) has been developed in order to improve the details and image contrast on "flat" areas of interest where AFM images are limited in contrast. The combination of AFM-UFM allows a near field acoustic microscopic image to be generated. The AFM tip is used to detect the ultrasonic waves and overcomes the limitation of wavelength that occurs in acoustic microscopy. By using the elastic changes under the AFM tip, an image of much greater detail than the AFM topography can be generated.
Ultrasonic force microscopy allows the local mapping of elasticity in atomic force microscopy by the application of ultrasonic vibration to the cantilever or sample. In an attempt to analyze the results of ultrasonic force microscopy in a quantitative fashion, a force-distance curve measurement is done with ultrasonic vibration applied to the cantilever base, and the results are compared with a model of the cantilever dynamics and tip-sample interaction based on the finite-difference technique.
Ultraviolet microscopy.
Ultraviolet microscopes have two main purposes. The first is to utilize the shorter wavelength of ultraviolet electromagnetic energy to improve the image resolution beyond that of the diffraction limit of standard optical microscopes. This technique is used for non-destructive inspection of devices with very small features such as those found in modern semiconductors. The second application for UV microscopes is contrast enhancement where the response of individual samples is enhanced, relative to their surrounding, due to the interaction of light with the molecules within the sample itself. One example is in the growth of protein crystals. Protein crystals are formed in salt solutions. As salt and protein crystals are both formed in the growth process, and both are commonly transparent to the human eye, they cannot be differentiated with a standard optical microscope. As the tryptophan of protein absorbs light at 280 nm, imaging with a UV microscope with 280 nm bandpass filters makes it simple to differentiate between the two types of crystals. The protein crystals appear dark while the salt crystals are transparent.
Infrared microscopy.
The term "infrared microscopy" refers to microscopy performed at infrared wavelengths. In the typical instrument configuration a Fourier Transform Infrared Spectrometer (FTIR) is combined with an optical microscope and an infrared detector. The infrared detector can be a single point detector, a linear array or a 2D focal plane array. The FTIR provides the ability to perform chemical analysis via infrared spectroscopy and the microscope and point or array detector enable this chemical analysis to be spatially resolved, i.e. performed at different regions of the sample. As such technique is also called infrared microspectroscopy. Infrared microspectroscopy is frequently used for infrared chemical imaging, where the image contrast is determined by the response of individual sample regions to particular IR wavelengths selected by the user, usually specific IR absorption bands and associated molecular resonances . A key limitation of conventional infrared microspectroscopy is that the spatial resolution is diffraction-limited. Specifically the spatial resolution is limited to a figure related to the wavelength of the light. For practical IR microscopes, the spatial resolution is limited to 1-3X the wavelength, depending on the specific technique and instrument used. For mid-IR wavelengths, this sets a practical spatial resolution limit of ~3-30 μm.
IR versions of sub-diffraction microscopy (see above) also exist. These include IR NSOM, photothermal microspectroscopy, and atomic force microscope based infrared spectroscopy (AFM-IR).
Digital holographic microscopy.
In digital holographic microscopy (DHM), interfering wave fronts from a coherent (monochromatic) light-source are recorded on a sensor. The image is digitally reconstructed by a computer from the recorded hologram. Besides the ordinary bright field image, a phase shift image is created.
DHM can operate both in reflection and transmission mode. In reflection mode, the phase shift image provides a relative distance measurement and thus represents a topography map of the reflecting surface. In transmission mode, the phase shift image provides a label-free quantitative measurement of the optical thickness of the specimen. Phase shift images of biological cells are very similar to images of stained cells and have successfully been analyzed by high content analysis software.
A unique feature of DHM is the ability to adjust focus after the image is recorded, since all focus planes are recorded simultaneously by the hologram. This feature makes it possible to image moving particles in a volume or to rapidly scan a surface. Another attractive feature is DHM’s ability to use low cost optics by correcting optical aberrations by software.
Digital pathology (virtual microscopy).
Digital pathology is an image-based information environment enabled by computer technology that allows for the management of information generated from a digital slide. Digital pathology is enabled in part by virtual microscopy, which is the practice of converting glass slides into digital slides that can be viewed, managed, and analyzed.
Laser microscopy.
Laser microscopy is a rapidly growing field that uses laser illumination sources in various forms of microscopy. For instance, laser microscopy focused on biological applications uses ultrashort pulse lasers, in a number of techniques labeled as nonlinear microscopy, saturation microscopy, and multiphoton fluorescence microscopy.
Amateur microscopy.
"Amateur Microscopy" is the investigation and observation of biological and non-biological specimens for recreational purposes. Collectors of minerals, insects, seashells, and plants may use microscopes as tools to uncover features that help them classify their collected items. Other amateurs may be interested in observing the life found in pond water and of other samples. Microscopes may also prove useful for the water quality assessment for people that keep a home aquarium. Photographic documentation and drawing of the microscopic images are additional tasks that augment the spectrum of tasks of the amateur. There are even competitions for photomicrograph art. Participants of this pastime may either use commercially prepared microscopic slides or engage in the task of specimen preparation.
While microscopy is a central tool in the documentation of biological specimens, it is, in general, insufficient to justify the description of a new species based on microscopic investigations alone. Often genetic and biochemical tests are necessary to confirm the discovery of a new species. A laboratory and access to academic literature is a necessity, which is specialized and, in general, not available to amateurs. There is, however, one huge advantage that amateurs have above professionals: time to explore their surroundings. Often, advanced amateurs team up with professionals to validate their findings and (possibly) describe new species.
In the late 1800s, amateur microscopy became a popular hobby in the United States and Europe. Several 'professional amateurs' were being paid for their sampling trips and microscopic explorations by philanthropists, to keep them amused on the Sunday afternoon (e.g., the diatom specialist A. Grunow, being paid by (among others) a Belgian industrialist). Professor John Phin published "Practical Hints on the Selection and Use of the Microscope (Second Edition, 1878)," and was also the editor of the "American Journal of Microscopy."
In 1995, a loose group of amateur microscopists, drawn from several organizations in the UK and US, founded a site () for microscopy based on the knowledge and input of amateur (perhaps better referred to as 'enthusiast') microscopists. This was the first attempt to establish 'amateur' microscopy as a serious subject in the then-emerging new media of the Internet. Today, is an established resource for all ages, to input their findings and share information. It is a non-profit web presence dedicated to the pursuit of science and understanding of the small-scale world.
Examples of amateur microscopy images:
Further reading.
</dl>

</doc>
<doc id="19568" url="http://en.wikipedia.org/wiki?curid=19568" title="Microscope">
Microscope

A microscope (from the Ancient Greek: μικρός, "mikrós", "small" and σκοπεῖν, "skopeîn", "to look" or "see") is an instrument used to see objects that are too small for the naked eye. The science of investigating small objects using such an instrument is called microscopy. Microscopic means invisible to the eye unless aided by a microscope.
There are many types of microscopes. The most common (and the first to be invented) is the optical microscope, which uses light to image the sample. Other major types of microscopes are the electron microscope (both the transmission electron microscope and the scanning electron microscope), the ultramicroscope, and the various types of scanning probe microscope.
On October 8, 2014, the Nobel Prize in Chemistry was awarded to Eric Betzig, William Moerner and Stefan Hell for "the development of super-resolved fluorescence microscopy," which brings "optical microscopy into the nanodimension".
History.
The first microscope to be developed was the optical microscope, although the original inventor is not easy to identify. Evidence points to the first compound microscope appearing in the Netherlands in the late 1590s, probably an invention of eyeglass makers there: Hans Lippershey (who developed an early telescope) and Zacharias Janssen (also claimed as the inventor of the telescope). There are other claims that the microscope and the telescope were invented by Roger Bacon in the 1200s, but this is not substantiated. Giovanni Faber coined the name microscope for Galileo Galilei's compound microscope in 1625 (Galileo had called it the ""occhiolino" or "little eye"").
Rise of modern light microscopy.
The first detailed account of the interior construction of living tissue based on the use of a microscope did not appear until 1644, in Giambattista Odierna's "L'occhio della mosca", or "The Fly's Eye".
It was not until the 1660s and 1670s that the microscope was used extensively for research in Italy, the Netherlands and England. Marcelo Malpighi in Italy began the analysis of biological structures beginning with the lungs. Robert Hooke's "Micrographia" had a huge impact, largely because of its impressive illustrations. The greatest contribution came from Antonie van Leeuwenhoek who discovered red blood cells and spermatozoa and helped popularise microscopy as a technique. On 9 October 1676, Van Leeuwenhoek reported the discovery of micro-organisms.
The performance of light microscopy depends as much on how the sample is illuminated as on how it is observed. Early instruments were limited until this principle was fully appreciated and developed, and until electric lamps were available as light sources. In 1893 August Köhler developed a key principle of sample illumination, Köhler illumination, which is central to achieving the theoretical limits of light microscopy. This method of sample illumination produces even lighting and overcomes the limited contrast and resolution imposed by early techniques of sample illumination. Further developments in sample illumination came from the discovery of Phase Contrast by Frits Zernike in 1953, and Differential Interference Contrast illumination by Georges Nomarski in 1955; both of which allow imaging of unstained, transparent samples.
Electron microscopy.
In the early 1900s a significant alternative to light microscopy was developed, using electrons rather than light to generate the image. Ernst Ruska started development of the first electron microscope in 1931 which was the transmission electron microscope (TEM). The transmission electron microscope works on the same principle as an optical microscope but uses electrons in the place of light and electromagnets in the place of glass lenses. Use of electrons instead of light allows a much higher resolution.
Development of the transmission electron microscope was quickly followed in 1935 by the development of the scanning electron microscope by Max Knoll.
Electron microscopes quickly became popular following the Second World War. Ernst Ruska, working at Siemens developed the first commercial transmission electron microscope and major scientific conferences on electron microscopy started being held in the 1950s. In 1965 the first commercial scanning electron microscope was developed by Professor Sir Charles Oatley and his postgraduate student Gary Stewart and marketed by the Cambridge Instrument Company as the "Stereoscan".
Scanning probe microscopy.
The 1980s saw the development of the first scanning probe microscopes. The first was the scanning tunneling microscope in 1981, developed by Gerd Binnig and Heinrich Rohrer. This was closely followed in 1986 with Gerd Binnig, Quate, and Gerber's invention of the atomic force microscope.
Fluorescence and light microscopy.
The most recent developments in light microscope largely centre on the rise of fluorescence microscopy in biology. During the last decades of the 20th century, particularly in the post-genomic era, many techniques for fluorescent labeling of cellular structures were developed. The main groups of techniques are small chemical staining of cellular structures, for example DAPI to label DNA, use of antibodies conjugated to fluorescent reporters, see
immunofluorescence, and fluorescent proteins, such as green fluorescent protein. These techniques use these different fluorophores for analysis of cell structure at a molecular level in both live and fixed samples.
The rise of fluorescence microscopy drove the development of a major modern microscope design, the confocal microscope. The principle was patented in 1957 by Marvin Minsky, although laser technology limited practical application of the technique. It was not until 1978 when Thomas and Christoph Cremer developed the first practical confocal laser scanning microscope and the technique rapidly gained popularity through the 1980s.
Much current research (in the early 21st century) on optical microscope techniques is focused on development of superresolution analysis of fluorescently labeled samples. Structured illumination can improve resolution by around two to four times and techniques like stimulated Emission Depletion microscopy are approaching the resolution of electron microscopes.
Types.
Microscopes can be separated into several different classes. One grouping is based on what interacts with the sample to generate the image, i.e., light or photons (optical microscopes), electrons (electron microscopes) or a probe (scanning probe microscopes). Alternatively, microscopes can be classed on whether they analyse the sample via a scanning point (confocal optical microscopes, scanning electron microscopes and scanning probe microscopes) or analyse the sample all at once (wide field optical microscope and transmission electron microscopes).
Wide field optical microscopes and transmission electron microscopes both use the theory of lenses (optics for light microscopes and electromagnet lenses for electron microscopes) in order to magnify the image generated by the passage of a wave transmitted through the sample, or reflected by the sample. The waves used are electromagnetic (in optical microscopes) or electron beams (in electron microscopes). Resolution in these microscopes is limited by the wavelength of the radiation used to image the sample, where shorter wavelengths allow for a higher resolution.
Scanning optical and electron microscopes, like the confocal microscope and scanning electron microscope, use lenses to focus a spot of light or electrons onto the sample then analyze the reflected or transmitted waves. The point is then scanned over the sample to analyze a rectangular region. Magnification of the image is achieved by displaying the data from scanning a physically small sample area on a relatively large screen. These microscopes have the same resolution limit as wide field optical, probe, and electron microscopes.
Scanning probe microscopes also analyze a single point in the sample and then scan the probe over a rectangular sample region to build up an image. As these microscopes do not use electromagnetic or electron radiation for imaging they are not subject to the same resolution limit as the optical and electron microscopes described above.
Optical.
The most common type of microscope (and the first invented) is the optical microscope. This is an optical instrument containing one or more lenses producing an enlarged image of a sample placed in the focal plane. Optical microscopes have refractive glass and occasionally of plastic or quartz, to focus light into the eye or another light detector. Mirror-based optical microscopes operate in the same manner. Typical magnification of a light microscope, assuming visible range light, is up to 1250x with a theoretical resolution limit of around 0.250 micrometres or 250 nanometres. This limits the practical magnification limit to ~1500x. Specialized techniques (e.g., scanning confocal microscopy, Vertico SMI) may exceed this magnification but the resolution is diffraction limited. The use of shorter wavelengths of light, such as the ultraviolet, is one way to improve the spatial resolution of the optical microscope, as are devices such as the near-field scanning optical microscope.Sarfus, a recent optical technique increases the sensitivity of standard optical microscope to a point it becomes possible to directly visualize nanometric films (down to 0.3 nanometre) and isolated nano-objects (down to 2 nm-diameter). The technique is based on the use of non-reflecting substrates for cross-polarized reflected light microscopy.
Ultraviolet light enables the resolution of microscopic features, as well as to image samples that are transparent to the eye. Near infrared light can be used to visualize circuitry embedded in bonded silicon devices, since silicon is transparent in this region of wavelengths.
In fluorescence microscopy, many wavelengths of light, ranging from the ultraviolet to the visible can be used to cause samples to fluoresce to allow viewing by eye or with the use of specifically sensitive cameras.
Phase contrast microscopy is an optical microscopy illumination technique in which small phase shifts in the light passing through a transparent specimen are converted into amplitude or contrast changes in the image.
The use of phase contrast does not require staining to view the slide. This microscope technique made it possible to study the cell cycle in live cells.
The traditional optical microscope has more recently evolved into the digital microscope. In addition to, or instead of, directly viewing the object through the eyepieces, a type of sensor similar to those used in a digital camera is used to obtain an image, which is then displayed on a computer monitor. These sensors may use CMOS or charge-coupled device (CCD) technology, depending on the application.
Electron.
Three major types of electron microscopes exist:
Scanning probe.
Of these techniques AFM and STM are the most commonly used.
Other types.
Scanning acoustic microscopes use sound waves to measure variations in acoustic impedance. Similar to Sonar in principle, they are used for such jobs as detecting defects in the subsurfaces of materials including those found in integrated circuits. On February 4, 2013, Australian engineers built a "quantum microscope" which provides unparalleled precision.

</doc>
<doc id="19570" url="http://en.wikipedia.org/wiki?curid=19570" title="Midrash">
Midrash

In Judaism, the Midrash (; Hebrew: מדרש‎; plural "midrashim") is the body of exegesis of Torah texts along with homiletic stories as taught by Chazal (Rabbinical Jewish sages of the post-Temple era) that provide an intrinsic analysis to passages in the Tanakh.
Midrash is a method of interpreting biblical stories that goes beyond simple distillation of religious, legal, or moral teachings. It fills in gaps left in the biblical narrative regarding events and personalities that are only hinted at.
The purpose of midrash was to resolve problems in the interpretation of difficult passages of the text of the Hebrew Bible, using Rabbinic principles of hermeneutics and philology to align them with the religious and ethical values of religious teachers.
Etymology.
Gesenius ascribes the etymology of "midrash" to the Qal of the common Hebrew verb "darash" (דָּרַשׁ) "to seek, study, inquire". The word "midrash" occurs twice in the Hebrew Bible: 2 Chronicles 13:22 "in the midrash of the prophet Iddo", and 24:27 "in the midrash of the Book of the Kings".
Methodology.
According to the PaRDeS approaches to exegesis, interpretation of Biblical texts in Judaism is realized through "peshat" (literal or plain meaning, lit. "plain" or "simple"), "remez" (deep meaning, lit. "hints"), "derash" (comparative meaning, from Hebrew "darash"—"to inquire" or "to seek") and "sod" (hidden meaning or philosophy, lit. "secret" or "mystery"). The Midrash concentrates somewhat on "remez" but mostly on "derash" (Some thinkers divide PaRDeS into pshat, remez, "din" (law) and sod. In this understanding, midrash aggada deals with remez and midrash halakha deals with din).
Many different exegetical methods are employed to derive deeper meaning from a text. This is not limited to the traditional thirteen textual tools attributed to the Tanna Rabbi Ishmael, which are used in the interpretation of "halakha" (Jewish law). Presence of apparently superfluous words or letters, chronology of events, parallel narratives or other textual anomalies are often a springboard for interpretation of segments of Biblical text. In many cases, a dialogue is expanded manifold: handfuls of lines in the Biblical narrative may become long philosophical discussions. It is unclear whether the midrash assumes these dialogues took place in reality or if this refers only to subtext or religious implication.
Many midrashim start off with a seemingly unrelated sentence from the Biblical books of Psalms, Proverbs or the Prophets. This sentence later turns out to metaphorically reflect the content of the rabbinical interpretation offered. This strategy is used particularly in a subgenre of midrash known as the "petikhta".
Some Midrash discussions are highly metaphorical, and many Jewish authors stress that they are not intended to be taken literally. Rather, other midrashic sources may sometimes serve as a key to particularly esoteric discussions. Later authors maintain that this was done to make this material less accessible to the casual reader and prevent its abuse by detractors.
Forms of Midrashic literature.
In general the midrash is focused on either halakha (legal) or Aggadic (non-legal and chiefly homiletical) subject matter. Both kinds of midrashim were at first preserved only orally; but their writing down commenced in the 2nd century, and they now exist in the shape chiefly of exegetical or homiletical commentaries on Tanakh (the Hebrew Bible). Midrashic literature is worthwhile reading not only for its insights into Judaism and the history of Jewish thought, but also for the more incidental data it provides to historians, philologists, philosophers, and scholars of either historical-critical Bible study or comparative religion.
Halakhic midrashim.
"Midrash halakha" are the works in which the sources in the Tanakh (Hebrew Bible) of the traditionally received laws are identified. These Midrashim often predate the Mishnah. The Midrash linking a verse to a "halakha" will often function as a proof of a law's authenticity; a correct elucidation of the Torah carries with it the support of the "halakhah", and often the reason for the rule's existence (although many rabbinical laws have no direct Biblical source). The term is applied also to the derivation of new laws, either by means of a correct interpretation of the obvious meaning of scriptural words themselves or by the application of certain hermeneutic rules.
Origins.
After the return of Jewish refugees from their exile in Babylon, some argue that the Torah was central to Jewish life at home and abroad. This is certainly the case in some strains of Judaism, although scholars agree the period was marked by wide diversity, so the centrality of Torah would vary greatly for different groups. A significant concern of Jewish authorities was to ensure compliance with the Torah's commandments, the enactments of the Mosaic Law; yet, as these laws had been written in circumstances of the past, they seemed to call for adaptation or explication if they were to fit the circumstances of contemporary life. Explanations of the terms of the Mosaic legislation are legal, or halakhic midrashim. Relatedly, the Mishnah does not generally cite a scriptural basis for its laws; connecting the Mishnaic law with the Torah law is also undertaken by the later midrash (and Talmuds).
Aggadic midrashim.
Homiletic midrashim embraces the interpretation of the non-legal portions of the Hebrew Bible. These midrashim are sometimes referred to as "aggadah" or "haggadah", a loosely defined term that may refer to all non-legal discourse in classical rabbinic literature.
Aggadic explanations of the non-legal parts of Scripture are characterized by a much greater freedom of exposition than the halakhic Midrashim (midrashim on Jewish law.) Aggadic expositors availed themselves of various techniques, including sayings of prominent rabbis. These aggadic explanations could be philosophical or mystical disquisitions concerning angels, demons, paradise, hell, the messiah, Satan, feasts and fasts, parables, legends, satirical assaults on those who practice idolatry, etc.
Some of these midrashim entail mystical teachings. The presentation is such that the Midrash is a simple lesson to the uninitiated, and a direct allusion, or analogy, to a Mystical teaching for those educated in this area.
An example of a Midrashic interpretation:
Contemporary Midrash.
A wealth of literature and artwork has been created in the 20th and 21st centuries by people aspiring to create "Contemporary Midrash". Forms include poetry, prose, Bibliodrama (the acting out of Bible stories), murals, masks, and music, among others. was formed to facilitate these reinterpretations of sacred texts. The institute hosted several week-long intensives between 1995 and 2004, and published eight issues of "Living Text: The Journal of Contemporary Midrash" from 1997 to 2000.

</doc>
<doc id="19571" url="http://en.wikipedia.org/wiki?curid=19571" title="Missouri">
Missouri

Missouri (see pronunciations) is a state located in the Midwestern United States. It is the 21st most extensive, and the 18th most populous of the fifty states. The state comprises 114 counties, and the independent city of St. Louis.
The four largest urban areas in order of population are: St. Louis, Kansas City, Springfield, and Columbia, as defined by the US 2010 census. The mean center of the United States population at the 2010 census was at the town of Plato in Texas County.
The state's capital is Jefferson City. The land that is now Missouri was acquired from France as part of the Louisiana Purchase and became known as the Missouri Territory. Part of this territory was admitted into the union as the 24th state on August 10, 1821.
Missouri's geography is highly varied. The northern part of the state lies in dissected till plains, while the southern portion lies in the Ozark Mountains (a dissected plateau), with the Missouri River dividing the regions. The state lies at the intersection of the three greatest rivers of North America, with the confluence of the Mississippi and Missouri Rivers near St. Louis, and the confluence of the Ohio River with the Mississippi north of the Bootheel. The starting points for the Pony Express, Santa Fe Trail, and Oregon Trail were all located in Missouri.
Etymology.
The state is named for the Missouri River, which was named after the indigenous Missouri Indians, a Siouan-language tribe. They were called the "ouemessourita" ("wimihsoorita"), meaning "those who have dugout canoes", by the Miami-Illinois language speakers. As the Illini were the first natives encountered by Europeans in the region, the latter adopted the Illini name for the Missouri people.
The name "Missouri" has several different pronunciations even among its present-day natives— the two most common pronunciations are and . This situation of differing pronunciations has existed since the late 1600s. Further pronunciations also exist in Missouri or elsewhere in the United States, involving the realization of the first syllable as either or ; the medial consonant as either or ; the stressed second syllable as either or ; and the third syllable as , , centralized ([ɪ̈]), or even ∅ (in other words, a non-existent third syllable). Any combination of these phonetic realizations may be observed coming from speakers of American English.
Politicians often employ multiple pronunciations, even during a single speech, to appeal to a greater number of listeners. Often, informal respellings of the state's name, such as "Missour-"ee"" or "Missour-"uh"", are used informally to phonetically distinguish pronunciations.
Nicknames.
There is no official state nickname. However Missouri's unofficial nickname is the "Show-Me-State", and that appears on its license plates. This phrase has several origins. One is popularly ascribed to a speech by Congressman Willard Vandiver in 1899, who declared that "I come from a state that raises corn and cotton, cockleburs and Democrats, and frothy eloquence neither convinces nor satisfies me. I'm from Missouri, and you have got to show me." This is in keeping with the saying "I'm from Missouri" which means "I'm skeptical of the matter and not easily convinced." However, according to researchers, the phrase "show me" was already in use before the 1890s. Another states that it is a reference to Missouri miners who were taken to Leadville, Colorado to replace striking workers. As the new men were unfamiliar with the mining methods, they required frequent instruction.
Other nicknames for Missouri include "The Lead State", "The Bullion State", "The Ozark State", "The Mother of the West", "The Iron Mountain State", and "Pennsylvania of the West". It is also known as "The Cave State" because there are more than 6000 recorded caves in Missouri (second to Tennessee). The largest number of caves (and the single longest cave) are all in Perry County.
The official state motto is Latin: "Salus Populi Suprema Lex Esto", which means "Let the welfare of the people be the supreme law."
Geography.
Missouri borders eight different states, as does its neighbor, Tennessee. No state in the U.S. touches more than eight states. Missouri is bounded on the north by Iowa; on the east, across the Mississippi River, by Illinois, Kentucky, and Tennessee; on the south by Arkansas; and on the west by Oklahoma, Kansas, and Nebraska (the last across the Missouri River). The two largest Missouri rivers are the Mississippi, which defines the eastern boundary of the state, and the Missouri River, which flows from west to east through the state, essentially connecting the two largest metros, Kansas City and St. Louis.
Although today the state is usually considered part of the Midwest, historically Missouri was considered by many to be a border state, chiefly because of the settlement of migrants from the South and its status as a slave state before the Civil War, balanced by the influence of the St. Louis. The counties that made up "Little Dixie" were those along the Missouri River in the center of the state, settled by Southern migrants who held the greatest concentration of slaves.
In 2005, Missouri received 16,695,000 visitors to its national parks and other recreational areas totaling 202000 acre, giving it $7.41 million in annual revenues, 26.6% of its operating expenditures.
Topography.
North of, and in some cases just south of, the Missouri River lie the Northern Plains that stretch into Iowa, Nebraska, and Kansas. Here, rolling hills remain from the glaciation that once extended from the Canadian Shield to the Missouri River. Missouri has many large river bluffs along the Mississippi, Missouri, and Meramec rivers. Southern Missouri rises to the Ozark Mountains, a dissected plateau surrounding the Precambrian igneous St. Francois Mountains. This region also hosts karst topography characterized by high limestone content with the formation of sinkholes and caves.
The southeastern part of the state is the Bootheel region, part of the Mississippi Alluvial Plain or Mississippi embayment. This region is the lowest, flattest, and wettest part of the state. It is also among the poorest, as the economy is mostly agricultural. It is also the most fertile, with cotton and rice crops predominant. The Bootheel was the epicenter of the four New Madrid Earthquakes of 1811–1812.
Climate.
Missouri generally has a humid continental climate ( Dfa) with cold winters and hot and humid summers. In the southern part of the state, particularly in the Bootheel, the climate turns into a humid subtropical climate. Located in the interior United States, Missouri often experiences extremes in temperatures. Without high mountains or oceans nearby to moderate temperature, its climate is alternately influenced by air from the cold Arctic and the hot and humid Gulf of Mexico. Missouri's highest recorded temperature is 118 F at Warsaw and Union on July 14, 1954 while the lowest recorded temperature is -40 F also at Warsaw on February 13, 1905.
Missouri also receives extreme weather in the form of thunderstorms and tornadoes. The most recent tornado in the state to cause damage and casualties was the 2011 Joplin tornado, which destroyed roughly 1/3 of the city of Joplin. The tornado caused an estimated $1–3 billion in damages, killed 159 (+1 non-tornadic), and injured over 1,000 people. The tornado was the first EF5 to hit the state since 1957. The tornado was the deadliest in the U.S. since 1947, making it the 7th deadliest tornado in American history, but the 27th deadliest in the world. St. Louis and its suburbs also have a history of experiencing particularly severe tornadoes; the most recent memorable one being an EF4 tornado that damaged Lambert International Airport on April 22, 2011. In fact, one of the worst tornadoes in American history struck St. Louis on May 27, 1896.
History.
Indigenous peoples inhabited Missouri for thousands of years before European exploration and settlement. Archaeological excavations along the rivers have shown continuous habitation for more than 7,000 years. Beginning before 1000 CE, there arose the complex Mississippian culture, whose people created regional political centers at present-day St. Louis and across the Mississippi River at Cahokia, near present-day Collinsville, Illinois. Their large cities included thousands of individual residences, but they are known for their surviving massive earthwork mounds, built for religious, political and social reasons, in platform, ridgetop and conical shapes. Cahokia was the center of a regional trading network that reached from the Great Lakes to the Gulf of Mexico. The civilization declined by 1400 CE, and most descendants left the area long before the arrival of Europeans. St. Louis was at one time known as Mound City by the European Americans, because of the numerous surviving prehistoric mounds, since lost to urban development. The Mississippian culture left mounds throughout the middle Mississippi and Ohio river valleys, extending into the southeast as well as the upper river.
The first European settlers were mostly ethnic French Canadians, who created their first settlement in Missouri at present-day Ste. Genevieve, about an hour south of St. Louis. They had migrated about 1750 from the Illinois Country. They came from colonial villages on the east side of the Mississippi River, where soils were becoming exhausted and there was insufficient river bottom land for the growing population. Sainte-Geneviève became a thriving agricultural center, producing enough surplus wheat, corn and tobacco to ship tons of grain annually downriver to Lower Louisiana for trade. Grain production in the Illinois Country was critical to the survival of Lower Louisiana and especially the city of New Orleans.
St. Louis was founded soon after by French from New Orleans in 1764. From 1764 to 1803, European control of the area west of the Mississippi to the northernmost part of the Missouri River basin, called Louisiana, was assumed by the Spanish as part of the Viceroyalty of New Spain, due to Treaty of Fontainebleau (in order to have Spain join with France in the war against England). The arrival of the Spanish in St. Louis was in September 1767.
St. Louis became the center of a regional fur trade with Native American tribes that extended up the Missouri and Mississippi rivers, which dominated the regional economy for decades. Trading partners of major firms shipped their furs from St. Louis by river down to New Orleans for export to Europe. They provided a variety of goods to traders, for sale and trade with their Native American clients. The fur trade and associated businesses made St. Louis an early financial center and provided the wealth for some to build fine houses and import luxury items. Its location near the confluence of the Illinois River meant it also handled produce from the agricultural areas. River traffic and trade along the Mississippi were integral to the state's economy, and as the area's first major city, St. Louis expanded greatly after the invention of the steamboat and the increased river trade.
Early nineteenth century.
Napoleon Bonaparte had gained Louisiana for French ownership from Spain in 1800 under the Treaty of San Ildefonso, after it had been a Spanish colony since 1762. But, the treaty was kept secret. Louisiana remained nominally under Spanish control until a transfer of power to France on November 30, 1803, just three weeks before the cession to the United States.
Part of the 1803 Louisiana Purchase by the United States, Missouri earned the nickname "Gateway to the West" because it served as a major departure point for expeditions and settlers heading to the West during the 19th century. St. Charles, just west of St. Louis, was the starting point and the return destination of the Lewis and Clark Expedition, which ascended the Missouri River in 1804, in order to explore the western lands to the Pacific Ocean. St. Louis was a major supply point for decades, for parties of settlers heading west.
As many of the early settlers in western Missouri migrated from the Upper South, they brought enslaved African Americans as agricultural laborers, and they desired to continue their culture and the institution of slavery. They settled predominantly in 17 counties along the Missouri River, in an area of flatlands that enabled plantation agriculture and became known as "Little Dixie." In 1821 the former Missouri Territory was admitted as a slave state, in accordance with the Missouri Compromise, and with a temporary state capital in St. Charles. In 1826, the capital was shifted to its current, permanent location of Jefferson City, also on the Missouri River.
The state was rocked by the 1812 New Madrid earthquake. Casualties were few due to the sparse population.
Originally the state's western border was a straight line, defined as the meridian passing through the Kawsmouth, the point where the Kansas River enters the Missouri River. The river has moved since this designation. This line is known as the Osage Boundary. In 1836 the Platte Purchase was added to the northwest corner of the state after purchase of the land from the native tribes, making the Missouri River the border north of the Kansas River. This addition increased the land area of what was already the largest state in the Union at the time (about 66500 sqmi to Virginia's 65,000 square miles, which then included West Virginia).
In the early 1830s, Mormon migrants from northern states and Canada began settling near Independence and areas just north of there. Conflicts over religion and slavery arose between the 'old settlers' (mainly from the South) and the Mormons (mainly from the North). The Mormon War erupted in 1838. By 1839, with the help of an "Extermination Order" by Governor Lilburn Boggs, the old settlers forcefully expelled the Mormons from Missouri and confiscated their lands.
Conflicts over slavery exacerbated border tensions among the states and territories. From 1838 to 1839, a border dispute with Iowa over the so-called Honey Lands resulted in both states' calling-up of militias along the border.
With increasing migration, from the 1830s to the 1860s Missouri's population almost doubled with every decade. Most of the newcomers were American-born, but many Irish and German immigrants arrived in the late 1840s and 1850s. As a majority were Catholic, they set up their own religious institutions in the state, which had been mostly Protestant. Having fled famine and oppression in Ireland, and revolutionary upheaval in Germany, the immigrants were not sympathetic to slavery. Many settled in cities, where they created a regional and then state network of Catholic churches and schools. Nineteenth-century German immigrants created the wine industry along the Missouri River and the beer industry in St. Louis.
Most Missouri farmers practiced subsistence farming before the American Civil War. The majority of those who held slaves had fewer than five each. Planters, defined by some historians as those holding twenty slaves or more, were concentrated in the counties known as "Little Dixie," in the central part of the state along the Missouri River. The tensions over slavery chiefly had to do with the future of the state and nation. In 1860, enslaved African Americans made up less than 10% of the state's population of 1,182,012. In order to control the flooding of farmland and low-lying villages along the Mississippi, the state had completed construction of 140 mi of levees along the river by 1860.
American Civil War.
After the secession of Southern states began in 1861, the Missouri legislature called for the election of a special convention on secession. The convention voted decisively to remain within the Union. Pro-Southern Governor Claiborne F. Jackson ordered the mobilization of several hundred members of the state militia who had gathered in a camp in St. Louis for training. Alarmed at this action, Union General Nathaniel Lyon struck first, encircling the camp and forcing the state troops to surrender. Lyon directed his soldiers, largely non-English-speaking German immigrants, to march the prisoners through the streets, and they opened fire on the largely hostile crowds of civilians who gathered around them. Soldiers killed unarmed prisoners as well as men, women and children of St. Louis in the incident that became known as the "St. Louis Massacre".
These events heightened Confederate support within the state. Governor Jackson appointed Sterling Price, president of the convention on secession, as head of the new Missouri State Guard. In the face of Union General Lyon's rapid advance through the state, Jackson and Price were forced to flee the capital of Jefferson City on June 14, 1861. In the town of Neosho, Missouri, Jackson called the state legislature into session. They enacted a secession ordinance. However, even under the Southern view of secession, only the state convention had the power to secede. Since the convention was dominated by unionists, and the state was more pro-Union than pro-Confederate in any event, the ordinance of secession adopted by the legislature is generally given little credence. The Confederacy nonetheless recognized it on October 30, 1861.
With the elected governor absent from the capital and the legislators largely dispersed, the state convention was reassembled with most of its members present, save 20 that fled south with Jackson's forces. The convention declared all offices vacant, and installed Hamilton Gamble as the new governor of Missouri. President Lincoln's administration immediately recognized Gamble's government as the legal Missouri government. The federal government's decision enabled raising pro-Union militia forces for service within the state as well as volunteer regiments for the Union Army.
Fighting ensued between Union forces and a combined army of General Price's Missouri State Guard and Confederate troops from Arkansas and Texas under General Ben McCulloch. After winning victories at the battle of Wilson's Creek and the siege of Lexington, Missouri and suffering losses elsewhere, the Confederate forces retreated to Arkansas and later Marshall, Texas, in the face of a largely reinforced Union Army.
Though regular Confederate troops staged some large-scale raids into Missouri, the fighting in the state for the next three years consisted chiefly of guerrilla warfare. "Citizen soldiers" or insurgents such as Captain William Quantrill, Frank and Jesse James, the Younger brothers, and William T. Anderson made use of quick, small-unit tactics. Pioneered by the Missouri Partisan Rangers, such insurgencies also arose in portions of the Confederacy occupied by the Union during the Civil War. Historians have portrayed stories of the James brothers' outlaw years as an American "Robin Hood" myth. The vigilante activities of the Bald Knobbers of the Ozarks in the 1880s were an unofficial continuation of insurgent mentality long after the official end of the war, and they are a favorite theme in Branson's self-image.
20th century to present.
The Progressive Era (1890s to 1920s) saw numerous prominent leaders from Missouri trying to end corruption and modernize politics, government and society. Joseph "Holy Joe" Folk was a key leader who made a strong appeal to middle class and rural evangelical Protestants. Folk was elected governor as a progressive reformer and Democrat in the 1904 election. He promoted what he called "the Missouri Idea", the concept of Missouri as a leader in public morality through popular control of law and strict enforcement. He successfully conducted antitrust prosecutions, ended free railroad passes for state officials, extended bribery statues, improved election laws, required formal registration for lobbyists, made racetrack gambling illegal, and enforced the Sunday-closing law. He helped enact Progressive legislation, including an initiative and referendum provision, regulation of elections, education, employment and child labor, railroads, food, business, and public utilities. A number of efficiency-oriented examiner boards and commissions were established during Folk's administration, including many agricultural boards and the Missouri library commission.
Between the Civil War and the end of World War II, Missouri transitioned from a rural economy to a hybrid industrial-service-agricultural economy as the Midwest rapidly industrialized. The expansion of railroads to the West transformed Kansas City into a major transportation hub within the nation. The growth of the Texas cattle industry along with this increased rail infrastructure and the invention of the refrigerated boxcar also made Kansas City a major meatpacking center, as large cattle drives from Texas brought herds of cattle to Dodge City and other Kansas towns. There, the cattle were loaded onto trains destined for Kansas City, where they were butchered and distributed to the eastern markets. The first half of the twentieth century was the height of Kansas City's prominence and its downtown became a showcase for stylish Art Deco skyscrapers as construction boomed.
In 1930, there was a diphtheria epidemic in the area around Springfield, which killed approximately 100 people. Serum was rushed to the area, and medical personnel stopped the epidemic.
During the mid-1950s and 1960s, St. Louis and Kansas City suffered deindustrialization and loss of jobs in railroads and manufacturing, as did other Midwestern industrial cities. In 1956 St. Charles claims to be the site of the first interstate highway project. Such highway construction made it easy for middle-class residents to leave the city for newer housing developed in the suburbs, often former farmland where land was available at lower prices. These major cities have gone through decades of readjustment to develop different economies and adjust to demographic changes. Suburban areas have developed separate job markets, both in knowledge industries and services, such as major retail malls.
Demographics.
The United States Census Bureau estimates that the population of Missouri was 6,063,589 on July 1, 2014, a 1.25% increase since the 2010 United States Census.
Missouri had a population of 5,988,927, according to the 2010 Census; an increase of 392,369 (7.0 percent) since the year 2000. From 2000 to 2007, this includes a natural increase of 137,564 people since the last census (480,763 births less 343,199 deaths), and an increase of 88,088 people due to net migration into the state. Immigration from outside the United States resulted in a net increase of 50,450 people, and migration within the country produced a net increase of 37,638 people. Over half of Missourians (3,294,936 people, or 55.0%) live within the state's two largest metropolitan areas–St. Louis and Kansas City. The state's population density 86.9 in 2009, is also closer to the national average (86.8 in 2009) than any other state.
In 2011, the racial composition of the state was:
In 2011, 3.7% of the total population was of Hispanic or Latino origin (they may be of any race). In 2011, 28.1% of Missouri's population younger than age 1 were minorities.
The U.S. Census of 2000 found that the population center of the United States is in Phelps County, Missouri. The center of population of Missouri itself is located in Osage County, in the city of Westphalia.
In 2004, the population included 194,000 foreign-born (3.4 percent of the state population).
The five largest ancestry groups in Missouri are: German (27.4 percent), Irish (14.8 percent), English (10.2 percent), American (8.5 percent) and French (3.7 percent).
German Americans are an ancestry group present throughout Missouri. African Americans are a substantial part of the population in St. Louis (56.6% of African Americans in the state lived in St. Louis or St. Louis County as of the 2010 census), Kansas City, Boone County and in the southeastern Bootheel and some parts of the Missouri River Valley, where plantation agriculture was once important. Missouri Creoles of French ancestry are concentrated in the Mississippi River Valley south of St. Louis (see Missouri French). Kansas City is home to large and growing immigrant communities from Latin America esp. Mexico, Africa (i.e. Sudan, Somalia and Nigeria), and Southeast Asia including China and the Philippines; and Europe like the former Yugoslavia (see Bosnian American). A notable Cherokee Indian population exists in Missouri.
In 2004, 6.6 percent of the state's population was reported as younger than 5 years old, 25.5 percent younger than 18, and 13.5 percent was 65 or older. Females were approximately 51.4 percent of the population. 81.3 percent of Missouri residents were high school graduates (more than the national average), and 21.6 percent had a bachelor's degree or higher. 3.4 percent of Missourians were foreign-born, and 5.1 percent reported speaking a language other than English at home.
In 2010, there were 2,349,955 households in Missouri, with 2.45 people per household. The home ownership rate was 70.0 percent, and the median value of an owner-occupied housing unit was $137,700. The median household income for 2010 was $46,262, or $24,724 per capita. There were 14.0 percent (1,018,118) Missourians living below the poverty line in 2010.
The mean commute time to work was 23.8 minutes.
Language.
The vast majority of people in Missouri speak English. Approximately 5.1% of the population reported speaking a language other than English at home. The Spanish language is spoken in small Latino communities in the St. Louis and Kansas City Metro areas.
Missouri is home to an endangered dialect of the French language known as Missouri French. Speakers of the dialect, who call themselves "Créoles", are descendants of the French pioneers who settled the area then known as the Illinois Country beginning in the late 17th century. It developed in isolation from French speakers in Canada and Louisiana, becoming quite distinct from the varieties of Canadian French and Louisiana Creole French. Once widely spoken throughout the area, Missouri French is now nearly extinct, with only a few elderly speakers able to use it.
Religion.
Of those Missourians who identify with a religion, three out of five are Protestants of various denominations. The largest classified demographic in the state are Southern Baptists at 22%. The second largest, at 19%, are Roman Catholics with populations located in Jefferson City, St. Louis and stretches west and south of St. Louis. The third ranked demographic are the non religious at 15%.
The religious affiliations of the people of Missouri according to the American Religious Identification Survey:
The largest denominations by number of adherents in 2010 were the Southern Baptist Convention with 749,685; the Roman Catholic Church with 724,315; and the United Methodist Church with 226,409.
Among the other denominations there are approximately 93,000 Mormons in 253 congregations, 25,000 Jewish adherents in 21 temples, 12,000 Muslims in 39 masjids, 7,000 Buddhists in 34 temples, 7,000 Hindus in 17 temples, 2,500 Unitarians in 9 congregations, 2,000 Baha'i in 17 temples, 5 Sikh temples, a Zorastrian temple, a Jain temple and an uncounted number of neopagans.
Several religious organizations have headquarters in Missouri, including the Lutheran Church–Missouri Synod, which has its headquarters in Kirkwood, as well as the United Pentecostal Church International in Hazelwood, both outside St. Louis.
Independence, near Kansas City, is the headquarters for the Community of Christ (formerly the Reorganized Church of Jesus Christ of Latter Day Saints), the Church of Christ (Temple Lot) and the group Remnant Church of Jesus Christ of Latter Day Saints. This area and other parts of Missouri are also of significant religious and historical importance to The Church of Jesus Christ of Latter-day Saints (LDS Church), which maintains several sites and visitors centers.
Springfield is the headquarters of the Assemblies of God USA and the Baptist Bible Fellowship International. The General Association of General Baptists has its headquarters in Poplar Bluff. The Unity Church is headquartered in Unity Village.
Economy.
The Bureau of Economic Analysis estimates that Missouri's total state product in 2006 was $225.9 billion. Per capita personal income in 2006 was $32,705, ranking 26th in the nation.
Major industries include aerospace, transportation equipment, food processing, chemicals, printing/publishing, electrical equipment, light manufacturing, and beer.
The agriculture products of the state are beef, soybeans, pork, dairy products, hay, corn, poultry, sorghum, cotton, rice, and eggs. Missouri is ranked 6th in the nation for the production of hogs and 7th for cattle. Missouri is ranked in the top five states in the nation for production of soy beans, and it is ranked fourth in the nation for the production of rice. In 2001, there were 108,000 farms, the second-largest number in any state after Texas. Missouri actively promotes its rapidly growing wine industry.
Missouri has vast quantities of limestone. Other resources mined are lead, coal, and crushed stone. Missouri produces the most lead of all of the states. Most of the lead mines are in the central eastern portion of the state. Missouri also ranks first or near first in the production of lime, a key ingredient in Portland cement.
Missouri also has a growing science and biotechnology field. Monsanto, one of the largest gene companies in America is based in St. Louis.
Tourism, services and wholesale/retail trade follow manufacturing in importance.
Missouri is the only state in the Union to have two Federal Reserve Banks: one in Kansas City (serving western Missouri, Kansas, Nebraska, Oklahoma, Colorado, northern New Mexico, and Wyoming) and one in St. Louis (serving eastern Missouri, southern Illinois, southern Indiana, western Kentucky, western Tennessee, northern Mississippi, and all of Arkansas).
As of November 2014, the state's unemployment rate was 4.8%, while the nation overall was 5.5%.
Taxation.
Personal income is taxed in ten different earning brackets, ranging from 1.5% to 6.0%. Missouri's sales tax rate for most items is 4.225% with some additional local levies. More than 2,500 Missouri local governments rely on property taxes levied on real property (real estate) and personal property.
Most personal property is exempt, except for motorized vehicles. Exempt real estate includes property owned by governments and property used as nonprofit cemeteries, exclusively for religious worship, for schools and colleges and for purely charitable purposes. There is no inheritance tax and limited Missouri estate tax related to federal estate tax collection.
Energy.
In 2012, Missouri had roughly 22,000 MW of installed electricity generation capacity. In 2011, 82% of Missouri's electricity was generated by coal. 10% was generated from the state's only nuclear power plant, the Callaway Plant in Callaway County, northeast of Jefferson City. 5% was generated by natural gas. 1% was generated by hydroelectric sources, such as the dams for Truman Lake and Lake of the Ozarks. Missouri has a small but growing amount of wind and solar power—wind capacity increased from 309 MW in 2009 to 459 MW in 2011, while photovoltaics have increased from 0.2 MW to 1.3 MW over the same period.
Oil wells in Missouri produced 120,000 barrels of crude oil in fiscal 2012. There are no oil refineries in Missouri.
Transportation.
Air.
Missouri has two major airport hubs: Lambert–St. Louis International Airport and Kansas City International Airport.
Rail.
Two of the nation's three busiest rail centers are located in Missouri. Kansas City is a major railroad hub for BNSF Railway, Norfolk Southern Railway, Kansas City Southern Railway, and Union Pacific Railroad. Kansas City is the second largest freight rail center in the US (but is first in the amount of tonnage handled). Like Kansas City, St. Louis is a major destination for train freight. Springfield remains an operational hub for BNSF Railway.
Amtrak passenger trains serve Kansas City, La Plata, Jefferson City, St. Louis, Lee's Summit, Independence, Warrensburg, Hermann, Washington, Kirkwood, Sedalia, and Poplar Bluff. A proposed high-speed rail route in Missouri as part of the Chicago Hub Network has received $31 million in funding.
The only urban light rail/subway system operating in Missouri is MetroLink, which connects the city of St. Louis with suburbs in Illinois and St. Louis County. It is one of the largest systems (by track mileage) in the United States. A streetcar line in downtown Kansas City is scheduled to open in 2015.
The Gateway Multimodal Transportation Center in St. Louis is the largest active multi-use transportation center in the state. It is located in downtown St. Louis, next to the historic Union Station complex. It serves as a hub center/station for MetroLink, the MetroBus regional bus system, Greyhound, Amtrak, and taxi services.
Bus.
Many cities have regular fixed-route systems, and many rural counties have rural public transit services. Greyhound, Trailways, and Megabus all provide inter-city bus service in Missouri.
Rivers.
The Mississippi River and Missouri River are commercially navigable over their entire lengths in Missouri. The Missouri was channelized through dredging and jettys and the Mississippi was given a series of locks and dams to avoid rocks and deepen the river. St. Louis is a major destination for barge traffic on the Mississippi.
Roads.
Several highways, detailed below, traverse the state.
Following the passage of Amendment 3 in late 2004, the Missouri Department of Transportation (MoDOT) began its Smoother, Safer, Sooner road-building program with a goal of bringing 2200 mi of highways up to good condition by December 2007. From 2006–2010 traffic deaths have decreased annually from 1,257 in 2005, to 1,096 in 2006, to 992 for 2007, to 960 for 2008, to 878 in 2009, to 821 in 2010.
Interstate freeways.
The only section of freeway in Missouri to have High-Occupancy Vehicle Lane (HOV) is Interstate 55 from Ste. Genevieve, Missouri to Interstate 270-255 Interchange in St. Louis County. They were striped, registered, and opened on February 10, 2013. HOV Lanes are also being striped on Interstate 70 in St. Charles County through Interstate 270 in Saint Louis County, and on the North-South corridor of Interstate 270 in central St. Louis County.
Law and government.
Framework.
The current Constitution of Missouri, the fourth constitution for the state, was adopted in 1945. It provides for three branches of government: the legislative, judicial, and executive branches. The legislative branch consists of two bodies: the House of Representatives and the Senate. These bodies comprise the Missouri General Assembly.
The House of Representatives has 163 members who are apportioned based on the last decennial census. The Senate consists of 34 members from districts of approximately equal populations. The judicial department comprises the Supreme Court of Missouri, which has seven judges, the Missouri Court of Appeals (an intermediate appellate court divided into three districts), sitting in Kansas City, St. Louis, and Springfield, and 45 Circuit Courts which function as local trial courts. The executive branch is headed by the Governor of Missouri and includes five other statewide elected offices. Following the death of Tom Schweich in 2015, all but one of Missouri's statewide elected offices are held by Democrats.
Harry S Truman (1884–1972), the 33rd President of the United States (Democrat, 1945–1953), was born in Lamar. He was a judge in Jackson County and then represented the state in the United States Senate for ten years, before being elected Vice-President in 1944. He lived in Independence after retiring.
Status as a political bellwether.
Missouri is widely regarded as a bellwether in American politics, often making it a swing state. The state had a longer stretch of supporting the winning presidential candidate than any other state, having voted with the nation in every election since 1904 with three exceptions: in 1956 it voted for Democratic Governor Adlai Stevenson of neighboring Illinois over the winner, incumbent Republican President Dwight Eisenhower of neighboring Kansas, and in 2008 it voted for Republican Senator John McCain of Arizona over national winner Senator Barack Obama of neighboring Illinois. Missouri was still the closest state in the nation in both of these races, which were decided by extremely narrow margins of fewer than 4,000 votes each. However, in 2012, Missouri swung strongly Republican when it voted for former Governor Mitt Romney of Massachusetts over the winner, incumbent President Barack Obama, by a nearly 10-point margin.
On October 24, 2012, there were 4,190,936 registered voters. At the state level, both Democratic Senator Claire McCaskill and Democratic Governor Jay Nixon were re-elected.
Laissez-faire alcohol and tobacco laws.
Missouri has been known for its population's generally "stalwart, conservative, noncredulous" attitude toward regulatory regimes, which is one of the origins of the state's unofficial nickname, the "Show-Me State." As a result, and combined with the fact that Missouri is one of America's leading alcohol and tobacco-producing states, regulation of alcohol and tobacco in Missouri is among the most laissez-faire in America. For 2013, the annual "Freedom in the 50 States" study prepared by the Mercatus Center at George Mason University ranked Missouri as #3 in America for alcohol freedom and #1 for tobacco freedom (#7 for freedom overall). The study notes that Missouri's "alcohol regime is one of the least restrictive in the United States, with no blue laws and taxes well below average," and that "Missouri ranks best in the nation on tobacco freedom."
Missouri law makes it "an improper employment practice" for an employer to refuse to hire, to fire, or otherwise to disadvantage any person because that person lawfully uses alcohol and/or tobacco products when he or she is not at work.
Alcohol.
With a large German immigrant population and the development of a brewing industry, Missouri always has had among the most permissive alcohol laws in the United States. It never enacted statewide prohibition. Missouri voters rejected prohibition in three separate referenda in 1910, 1912, and 1918. Alcohol regulation did not begin in Missouri until 1934.
Today, alcohol laws are controlled by the state government, and local jurisdictions are prohibited from going beyond those state laws. Missouri has no statewide open container law or prohibition on drinking in public, no alcohol-related blue laws, no local option, no precise locations for selling liquor by the package (allowing even drug stores and gas stations to sell any kind of liquor), and no differentiation of laws based on alcohol percentage. Missouri has no laws prohibiting "consumption" of alcohol by minors (as opposed to possession), and state law protects persons from arrest or criminal penalty for public intoxication.
Missouri law expressly prohibits any jurisdiction from going dry. Missouri law also expressly allows parents and guardians to serve alcohol to their children. The Power & Light District in Kansas City is one of the few places in the United States where a state law explicitly allows persons over the age of 21 to possess and consume open containers of alcohol in the street (as long as the beverage is in a plastic cup).
Tobacco.
As for tobacco (as of June 2014), Missouri has the lowest cigarette excise taxes in the United States, at 17 cents per pack, and the state electorate voted in 2002, 2006, and 2012 to keep it that way. In 2007, "Forbes" named Missouri's largest metropolitan area, St. Louis, America's "best city for smokers."
According to the Centers for Disease Control and Prevention, in 2008 Missouri had the fourth highest percentage of adult smokers among U.S states, at 24.5%. Although Missouri's minimum age for purchase and distribution of tobacco products is 18, tobacco products can be distributed to persons under 18 by family members on private property.
No statewide smoking ban ever has been seriously entertained before the Missouri General Assembly, and in October 2008, a statewide survey by the Missouri Department of Health and Senior Services found that only 27.5% of Missourians support a statewide ban on smoking in all bars and restaurants. Missouri state law permits restaurants seating less than 50 people, bars, bowling alleys, and billiard parlors to decide their own smoking policies, without limitation.
Counties.
Missouri has 114 counties and one independent city (St. Louis).
The largest county by size is Texas County (1,179 sq. miles) and Shannon County is second (1,004 sq. miles). Worth County is the smallest (266 sq. miles). The independent city of St. Louis has only 62 sqmi of area. St. Louis City is the most densely populated area (5,140.1 per sq. mi.) in Missouri.
The largest county by population (2012 estimate) is St. Louis County (1,000,438 residents), with Jackson County second (677,377 residents), St. Charles third (368,666), and St. Louis fourth (318,172). Worth County is the least populous with 2,171 (2010 census) residents.
Major cities.
Jefferson City is the capital of Missouri.
The five largest cities in Missouri are Kansas City, St. Louis, Springfield, Independence, and Columbia.
St. Louis is the principal city of the largest metropolitan area in Missouri, composed of 17 counties and the independent city of St. Louis; eight of those counties lie in Illinois. As of 2009, St. Louis was the 18th largest metropolitan area in the nation with 2.83 million people. However, if ranked using Combined Statistical Area, it is 15th largest with 2.89 million people. Some of the major cities making up the St. Louis Metro area in Missouri are St. Charles, St. Peters, Florissant, Chesterfield, Creve Coeur, Wildwood, Maryland Heights, O'Fallon, Clayton, Ballwin, and University City.
Kansas City is Missouri's largest city and the principal city of the fifteen-county Kansas City Metropolitan Statistical Area, including six counties in the state of Kansas. As of 2009, it was the 29th largest metropolitan area in the nation, with 2.068 million people. Some of the other major cities comprising the Kansas City metro area in Missouri include Independence, Lee's Summit, Blue Springs, Raytown, Liberty, and Gladstone.
Branson is a major tourist attraction in the Ozarks of southwestern Missouri.
Education.
Missouri State Board of education.
The Missouri State Board of Education has general authority over all public education in the state of Missouri. It is made up of eight citizens appointed by the governor and confirmed by the Missouri Senate.
Primary and secondary schools.
Education is compulsory from ages seven to seventeen, and it is required that any parent, guardian or other person with custody of a child between the ages of seven and seventeen the compulsory attendance age for the district, must ensure that the child is enrolled in and regularly attends public, private, parochial school, home school or a combination of schools for the full term of the school year. Compulsory attendance also ends when children complete sixteen credits in high school..
Children in Missouri between the ages of five and seven are not required to be enrolled in school. However, if they are enrolled in a public school their parent, guardian or custodian must ensure that they regularly attend.
Missouri schools are commonly but not exclusively divided into three tiers of primary and secondary education: elementary school, middle school or junior high school and high school. The public schools system includes kindergarten to 12th grade. District territories are often complex in structure. In some cases, elementary, middle and junior high schools of a single district feed into high schools in another district. High school athletics and competitions are governed by the Missouri State High School Activities Association (MSHSAA).
Homeschooling is legal in Missouri and is an option to meet the compulsory education requirement. It is neither monitored nor regulated by the state's Department of Elementary and Secondary Education
A supplemental education program, the Missouri Scholars Academy, provides an extracurricular learning experience for gifted high school students in the state of Missouri. The official MSA website describes the goals of the Academy to be as such: "The academy reflects Missouri's desire to strive for excellence in education at all levels. The program is based on the premise that Missouri's gifted youth must be provided with special opportunities for learning and personal development in order for them to realize their full potential."
Another gifted school is the Missouri Academy of Science, Mathematics and Computing, which is located at the Northwest Missouri State University.
Colleges and universities.
The University of Missouri System is Missouri's statewide public university system. The flagship institution and largest university in the state is the University of Missouri in Columbia. The others in the system are University of Missouri–Kansas City, University of Missouri–St. Louis, and Missouri University of Science and Technology in Rolla.
During the late nineteenth and early twentieth century the state established a series of normal schools in each region of the state, originally named after the geographic districts: Northeast Missouri State University (now Truman State University) (1867), Central Missouri State University (now the University of Central Missouri) (1871), Southeast Missouri State University (1873), Southwest Missouri State University (now Missouri State University) (1905), Northwest Missouri State University (1905), Missouri Western State University (1915), and Missouri Southern State University (1937). Lincoln University and Harris–Stowe State University were established in the mid-nineteenth century and are historically black colleges and universities.
Among private institutions Washington University in St. Louis and Saint Louis University are two top ranked schools in the US. There are numerous junior colleges, trade schools, church universities and other private universities in the state. A.T. Still University was the first osteopathic medical school in the world. Hannibal–LaGrange University in Hannibal, Missouri, was one of the first colleges west of the Mississippi (founded 1858 in LaGrange, Missouri, and moved to Hannibal in 1928).
The state funds a $2000, renewable merit-based scholarship, Bright Flight, given to the top three percent of Missouri high school graduates who attend a university in-state.
The 19th century border wars between Missouri and Kansas have continued as a sports rivalry between the University of Missouri and University of Kansas. The rivalry is chiefly expressed through football and basketball games between the two universities. It is the oldest college rivalry west of the Mississippi River and the second oldest in the nation. Each year when the universities meet to play, the game is coined "Border War." An exchange occurs following the game where the winner gets to take a historic Indian War Drum, which has been passed back and forth for decades.
Culture and entertainment.
Music.
Many well-known musicians were born or have lived in Missouri. These include guitarist and rock pioneer Chuck Berry, singer and actress Josephine Baker, "Queen of Rock" Tina Turner, pop singer-songwriter Sheryl Crow, Michael McDonald of the Doobie Brothers, and rappers Nelly, Chingy and Akon, all of whom are either current or former residents of St. Louis.
Country singers from Missouri include New Franklin native Sara Evans, Cantwell native Ferlin Husky, West Plains native Porter Wagoner, Tyler Farr of Garden City, and Mora native Leroy Van Dyke, along with bluegrass musician Rhonda Vincent, a native of Greentop.
Rapper Eminem was born in St. Joseph and also lived in Savannah and Kansas City.
Ragtime composer Scott Joplin lived in St. Louis and Sedalia.
Jazz saxophonist Charlie Parker lived in Kansas City.
Rock and Roll singer Steve Walsh of the group Kansas was born in St. Louis and grew up in St. Joseph.
The Kansas City Symphony and the St. Louis Symphony Orchestra are the state's major orchestras. The latter is the nation's second-oldest symphony orchestra and achieved prominence in recent years under conductor Leonard Slatkin.
Branson is well known for its music theaters, most of which bear the name of a star performer or musical group. These facilities have made Branson one of America's most popular tourist destinations..
Literature.
Missouri is the native state of Mark Twain. His novels "The Adventures of Tom Sawyer" and "The Adventures of Huckleberry Finn" are set in his boyhood hometown of Hannibal.
Kansas City-born writer William Least Heat-Moon currently resides in Rocheport. He is best known for "Blue Highways", a chronicle of his travels to small towns across America. The book was on the New York Times Bestseller list for nearly a year in 1982-1983.
Famed authors Kate Chopin, T. S. Eliot and Tennessee Williams were all from St. Louis.
Film.
Filmmaker, animator, and businessman Walt Disney spent part of his childhood in the Linn County town of Marceline before moving to Kansas City, Missouri. Disney began his artistic career in Kansas City, where he founded the Laugh-O-Gram Studio.
Several Film versions of Mark Twain's novels "The Adventures of Tom Sawyer" and "The Adventures of Huckleberry Finn" have been made.
"Meet Me in St. Louis", a musical involving the 1904 St. Louis World's Fair, starred Judy Garland.
Part of the 1983 road movie National Lampoon's Vacation was shot on location in Missouri, for the Griswold's trip from Chicago to Los Angeles.
The Thanksgiving holiday film Planes, Trains, and Automobiles was partially shot at Lambert–St. Louis International Airport.
"White Palace" was filmed in St. Louis.
The award-winning 2010 film "Winter's Bone" was shot in the Ozarks of Missouri.
Up in the Air starring George Clooney was filmed in St. Louis.
John Carpernter's "Escape from New York" was filmed in Saint Louis in the early eighties, due to the high number of abandoned buildings in the city.
Part of the 1973 movie, "Paper Moon", which starred Ryan and Tatum O'Neal, was filmed in St. Joseph.
Most of HBO's film "Truman" were filmed in Kansas City, Independence, and the surrounding area. Gary Sinise won an Emmy for his portrayal of Harry Truman in the 1995 film.
"Ride With the Devil" starring Jewel and Tobey Maguire were also filmed in the countryside of Jackson County (also where the historic events of the film took place).
"Gone Girl", A 2014 film starring Ben Affleck, Rosamund Pike, Neil Patrick Harris, and Tyler Perry was filmed in "Cape Girardeau".
Sports.
Missouri hosted the 1904 Summer Olympics at St. Louis, the first time the games were hosted in the United States.
Naval vessels.
Four US Navy vessels have been named after the state.
Wildlife.
Missouri is home to a diversity of both flora and fauna. There is a large amount of fresh water present due to the Mississippi River, Missouri River, and Lake of the Ozarks, with numerous smaller tributary rivers, streams, and lakes. North of the Missouri River, the state is primarily rolling hills of the Great Plains, whereas south of the Missouri River, the state is dominated by the Oak-Hickory Central U.S. hardwood forest.
Some of the native species found in Missouri include:
Mammals.
Within historic times, pronghorn, gray wolf, and brown bear were all found in Missouri, but have since been eliminated. Wapiti and American bison were formerly common, but are currently confined to private farms and parks.
Birds.
Year-round:
Summer/breeders: 
Winter residents: 
Within historic times, the passenger pigeon, the carolina parakeet, and the ivory-billed woodpecker were all found in Missouri, but they have since been eliminated.
Reptiles and amphibians.
Reptiles: 
Amphibians:
Trees and shrubs.
The trees and shrubs growing in Missouri include the following:
Insect migrations.
There has also been a migration of insects from the south to Missouri. One example of this is the wasp "Polistes exclamans".
Famous Missourians.
See entire collection at List of people from Missouri.

</doc>
<doc id="19574" url="http://en.wikipedia.org/wiki?curid=19574" title="Monitor">
Monitor

Monitor or monitor may refer to:

</doc>
