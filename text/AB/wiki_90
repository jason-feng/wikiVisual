<doc id="24837" url="http://en.wikipedia.org/wiki?curid=24837" title="Pinochle">
Pinochle

Pinochle or Binocle (sometimes pinocle, or penuchle) is a trick-taking card game typically for two to four players and played with a 48-card deck. It is derived from the card game bezique; players score points by trick-taking and also by forming combinations of cards into melds. It is thus considered part of a "trick-and-meld" category which also includes a cousin, belote. Each hand is played in three phases: bidding, melds, and tricks. The standard game today is called "partnership auction pinochle."
History.
Pinochle derives from the game bezique. The French word "binocle" also meant "eyeglasses". The word is also possibly derived from the French word, "binage", for the combination of cards called "binocle". This latter pronunciation of the game would be adopted by German speakers. German immigrants brought the game to America, where it was later mispronounced and misspelled "Pinochle."
Auction pinochle for three players has some similarities with the German game skat, although the bidding is more similar to that of bid whist.
During World War I, the city of Syracuse, New York outlawed the playing of pinochle in a fit of anti-German sentiment. Pinochle was the favorite card game of American Jews and Irish immigrants, while skat was the preferred game of a majority of German immigrants.
The deck.
A pinochle deck consists of two copies of each of the 9, 10, jack, queen, king, and ace cards of all four suits, for 48 cards per deck. Aces are always considered high. Pinochle follows a nonstandard card ordering. The complete ordering from highest to lowest is A, 10, K, Q, J, 9. The game can also be played using standard ranking with a simple change to scoring.
Originally, the deck had to be composed by combining two poker, piquet or euchre decks and removing unneeded cards (a piquet deck does not have the 2-6, making it easier to modify, and a euchre deck is exactly half a pinochle deck), but with the game's popularity in the United States in the early 1900s, a single boxed deck with the necessary cards was marketed, and these specialized pinochle decks are now widely available in similar styles to common 52-card counterparts. Variants of pinochle can be played with five, six, eight or more players. These larger variations can combine two pinochle decks called a "double deck". The double deck can also be used when playing with 4 players; hand sizes, average scores and minimum bids are doubled.
Partnership Auction Pinochle.
Dealing.
The game is played with a pinochle deck of 48 cards and 4 players; one player is the dealer.
After the shuffle, the dealer will offer a cut to the player on their right, then distribute the cards. All the cards are dealt in partnership pinochle. In variations for odd numbers of players like three, a "widow's hand"' (also called a "kitty", "talon", or "stock") of cards remain. Traditionally, the deal is done clockwise, dealing a packet of three or four cards at a time, starting with the player to the left (the eldest hand) and ending with the dealer. The deal rotates clockwise, so the dealer's left-hand opponent will deal next.
Some players use a house rule that if a player receives a hand with an abundance of nines (variously, "a hand of 6 nines, or 5 nines and no meld", or "4 nines and no Aces, or 5 nines and only one Ace", for example), they can toss in their hand and declare a misdeal; the cards are then re-dealt by the same dealer. An accompanying rule sometimes limits the number of re-deals to three.
The auction.
In auction pinochle, players bid for the points they predict their hand could earn. The highest bidder earns the right to declare the trump suit. One of the players, usually the player to the left of the dealer, or the dealer themselves, is obligated to open with a first bid. The size of bids is based on the point scale and number of decks used; traditionally, points are in multiples of 10, thus a minimum opening bid might be agreed to be 100 or 250. However, many alternate scoring rules drop the unnecessary trailing zero; in that case, bids of 10 and 25, respectively, have the same value. When a player has the turn to bid, the player may do either of the following:
Each bid must be greater than the previous one, and be a multiple of 10 or 25 (if playing without trailing zeroes, the bid must be one or two greater respectively). When a player passes, they can no longer bid. The auction ends when all subsequent players in rotation have passed after the last bid. The last bid becomes the "contract". The player that made this final bid will then declare trump in the suit that is desired. In some house rules, trump cannot be declared in any suit not containing a "run", "marriage" or "dix" meld.
In order for the winning bidder to win the hand, the combined total of "melding" and "trick" points must be equal to or greater than the winning bid. Thus bidding involves anticipating the points that will be accumulated from melds and from the points accumulated from winning tricks. If the combined score is lower than the bid, then the bidding team or player has been "set". This means that the total bid amount is subtracted from the total game score, often accompanied by losing the points scored in meld for that hand as well. This can result in a negative score.
A related though different style of bidding is for the players to bid individually, and partners' bids are then summed. The winning bid only decides trump; both (or all) teams' bids become their contract, meaning any team can score or be set. This creates a more balanced game. A house rule often used with this style of bidding is that a player or partnership must have a minimum number of meld points (usually 20 or 200 depending on point scales) in order to bid, and if it is discovered that they do not, a mis-bid is declared and the team's contract is null, with or without a penalty.
Passing cards.
In some versions of Pinochle, after the bid has been taken and trump declared in a partnership game, the bid winning team exchanges cards. It may be two, three, or four cards, depending on the version of the game. The partner of the bid winner passes first. The objective of the partner is either to add to the total points in meld or to pass trick-winning cards. After receiving the cards, the bid winner examines what will create the strongest hand and then discards an equal number of cards back to their partner. Variations are for the bid winner and partner to exchange the designated number of cards simultaneously, or for no passing to occur.
Melding.
Melding consists of displaying specific combinations of cards to all players. Typically this is done by placing the combination of cards face up on the playing surface until all players have had the opportunity to examine them. All players meld after the bid winner shows meld first. The types of melds include arounds, marriages, flushes and pinochles. These melds are placed under "headings" where a card which is melded under a particular heading can be used again under another heading, but cannot be melded again under the same heading.
"{NOTE: trailing zeros in the counting of meld may be done consistent with the bidding process}"
The "group melds" containing four of the same face cards – ace, king, queen or jack – must include one card from each of the different suits. They are scored as follows:
The marriages and flush are the "sequence melds":
A marriage in each suit is worth 240 or 24 total points, which is nothing more than the sum of the marriages, plus kings around and queens around. As a shortcut, this is called a "roundtable", "marriages around", "Round House", or a "Round Robin".
The pinochle and dix are the "special melds", the pinochle being the game's namesake.
In the most common form of the game (see variations below), any one card may be used in only one meld of each type. Thus, a queen card can be used in one marriage with one king, regardless if the player has the other king of the same suit. However, a queen can be used to score a marriage and a pinochle if the player also has the correct jack.
After the melds are displayed, the points are counted and each player totals their individual meld scores.
Because all of these values are multiples of ten, one can arrive at simplified values by removing the trailing zero from each point total. For instance, a Pinochle has a simplified score of 4, a double Pinochle would score 30.
Playing tricks.
In playing cards for tricks, there are strict rules of forced play, which limit a player's ability to strategically retain high cards: The high bidder leads the play with the first card, which can be any card in the contract winner's hand, although some rules require the first card led to be a trump card. Then there are two variations of following suit depending if you are playing post-1945 or pre-1945 rules.
Pre-1945 rules: Every player must follow the lead suit if possible. Usually every player must play a winning card against those played so far, if it is possible to do so, even when the current player expects a later player to win the hand with a better card. The only exception is if a player played a trump card when trump was not the suit led. In that case, those following that player may play any card of the lead suit, since they must follow the lead suit but are already losing to the player who played trump. So if a player can play a card in suit, higher than any played so far, the player must do so, even if the player expects to lose to a later played card. Likewise, if a player cannot follow suit, but has trump, they must play trump. Again, if a player does not have any cards of the lead suit and can play a trump card higher than any other trump played so far, the player must do so, even if the player expects that a later player will beat the card. If another trump has already been played that a player cannot beat, then they can play any trump in their hand, but they still must play a trump card if they can. Only when a player has no cards in suit, and has no trump, can the player choose to play any card in their hand.
Post-1945 rules: Most books today say that unless trump is led you need not try to win the trick. It is only when trump is led that "heading" the trick is mandatory. In pinochle circles and tournaments the post-1945 rules are played about 50% of the time according to Pagat and Hoyle.
If two identical cards are played, the first one outranks the second.
After the first trick, the winner of each trick leads the first card for the next trick, until all the cards are played.
Scoring tricks.
Points are scored based on the tricks won in the hand. There are several ways to count up the points for play, but they always add up to 250 points. The last trick is always worth an additional 10 points added to any existing points in the actual trick cards. The classic counting system of Pinochle is where aces are worth 11, tens are worth 10, kings are worth 4, queens are worth 3, jacks are worth 2, and nines are worth zero. This method takes longer to count the score at the end of each hand. A simpler method is to count aces and tens for 10 points, kings and queens for 5 points, and jacks and nines are worth zero.
An even simpler method has aces, tens, and kings worth 10 (and known as "counters"), and everything else zero ("garbage"). Since all points are multiples of ten in the third method, most players drop the redundant zero. Aces, tens, and kings won in tricks are worth one point. The meld scoring can also avoid the zero in the tenth place. Melds like 1,000 aces are thus worth 100. The terms "1,000 aces", "800 kings" and so on are often used, even though the point values are one-tenth.
Game variations.
Two-handed Pinochle.
Two-handed Pinochle is the original Pinochle game, while partnership, auction, and all other variants are derivatives from it. It is the game most similar to the original Bezique game, whence Pinochle derived. The only significant difference in its rules from Bezique is the scoring.
The original version of Pinochle involves a partial deal of twelve cards to both players in sets of four, leaving a stock of 24 cards. A player can score one meld after each trick won of the first 12 tricks. Melded cards can even be used to win tricks. After each trick, players draw one card from the stock into their hand starting with the trick-winning player. For the last 12 tricks, melds are taken into each player's hand and are no longer announced by the player who wins the trick. The traditional trick-taking rules apply only for these last 12 tricks.
In variations of two-handed play, no cards are initially dealt, a distinction from all other variations. Instead, the entire deck is placed face-down on the playing surface between the two players to form the widow. One player begins the hand-building process by drawing the top card of the widow. The player can either keep that card for her or his hand or reject the card. If the player chooses to hold the initial card, the player then draws a second card from the widow, then places it face-down, without looking at it, creating a discard pile. If the player rejects the first card, the card becomes the first card in the discard pile. The second card drawn from the widow must be kept, regardless of whether she or he preferred the first card. Players alternate turns in this hand-building process until all cards are chosen.
With bidding, the player winning the bid declares trump, then lays all meld face-up on the table. The other player shows her or his melds as well. Meld points are tallied, and players return meld cards to their hands. Some varieties accept a "Round house", kings and queens of each suit, and earn a bonus 10 points awarding a total of 250 points.
Trick-taking commences and continues until all held cards have been played. One variation has no "leading" requirement for the bid winner or subsequent trick winner to lead a specific card, however the rules of "following" are still observed.
When adding counters, cards from each player's discard pile are included in totals for a total of 240 counters per round, plus one counter for winning the final trick. One variation to make it more difficult for the bid-winning player, the discard pile created by drawing cards is used by the non-bidding player to score towards tricks.
Three-handed Pinochle.
In Three-handed pinochle each player plays for himself. The dealer deals 15 cards to each player and three cards to the widow—a separate pile in the middle.
All players review their cards and silently count meld, determining their bids. The player to the dealer's left initiates the bidding process. If the player has a meld, he or she is required to open the bidding; otherwise, they may pass or bid. If he or she passes, the obligation to bid passes to the next player, if meld is held. Once a player passes, he or she is out of the auction.
Bidding begins at 300, or as little as 150 for "under-the-gun" bids, and increases in multiples of 10. The highest bidder wins the auction and turns up the three-card widow for all to see. The three widow cards are placed in the bid winner's hand. The bid winner then declares trump and lays down meld. The other two players also lay meld face-up for count. After the appropriate points have been tallied the bid winner must set aside any three cards that have not been melded, though if not enough cards remain in the hand they may be taken from melded cards. This will reduce the bid winner's hand to 15 cards. For all three players, meld is now returned to each respective player's hand, and the round is played. During the round, a player must take at least one trick to "save one's meld", even if the trick contains no points; otherwise, no meld points will be counted for that player during that round.
After all tricks are taken, counters are tallied for each player. The three discards by the highest bidder count toward their counter score for the hand, so there is always a total of 250 points for the trick score among the three players. If the highest bidder fails to make their contract by adding meld points and trick points from the play, then their score is negative the amount of the bid for that hand.
The game is won when one player reaches 1000 points. It is possible for two or all three players to go over 1000 on the same hand. There are 3 methods of resolving ties:
Renege
Any time a player accidentally misplays during the play portion of the hand, it is called a renege. There are various forms of misplay:
If the bidder reneges, he automatically takes a double set and the amount of his bid is subtracted from his score. The 2-opposing players get to count their meld points and the remainder of the hand is thrown in.
If either of the 2 nonbidders accidentally misplay, the bidder automatically makes his bid. The bidder gets to score the amount of his bid and his meld, the player that misplayed loses all meld and takes a single set, and the third player scores only his meld.
Cutthroat Pinochle.
Similar to Three-handed Pinochle, Cutthroat is a simple modification. The dealer deals the entire deck out (16 cards to each player), in packets of 4. The player to the left of the dealer begins the bidding once meld has been silently determined by all players. Play continues normally in terms of scoring and trick taking, according to house rules. The only way to win in Cutthroat Pinochle, however, is to "Bid and Out," or to have taken the bid and surpassed the predetermined winning score. It is then possible for multiple players to go over the winning score, yet if none has taken a bid and met the resulting contract, a win has not happened and play continues. It is also possible for a person to lose with the high score if they do not take a winning bid.
Four-handed Pinochle.
Four-handed Pinochle, or partnership Pinochle is played with two teams consisting of two players each. Partners are seated opposite from each other. Each player is dealt 12 cards. The opening bid is typically 150, but can be a higher agreed on value. All four players may bid. Both the bidder and his partner have their score count towards making the contract. High bidder names trump. There typically is no kitty. With a kitty, the four cards are distributed, one to each player, by the bid winner. Each hand must meld separately: If your partner has a spade marriage, you may not put down the diamond jack for a pinochle; you must also have a spade queen. As in the three-handed version, the first player is forced to bid when holding meld. Play is often to 1000 but can increase to 1500 during partnership.
Optional rules for partnership Pinochle include forcing the dealer to bid 190, or some other agreed amount, if the first 3 players pass initially because they have no meld. In another variation, the winning partnership must, before melding, exchange 3 or 4 cards from each of their hands. This version is usually played to 1500. A player may announce they will "Shoot the Moon" or "Go Alone", declaring to all the other players that they are going to attempt to capture all the tricks in the current hand. If so, they earn 1,000 points and win the game. If they do not, they subtract 1,000 points from their score. This must be declared just before the tricks are going to be played out. Some versions give the game to a team which successfully 'shoots the moon', others automatically give 250 points for this no matter what the bid was.
Five-handed and larger Pinochle.
Games with five hands or more typically modify partnership Pinochle in a variety of ways. They are generally played with 1 1/2 or doubled decks, with extra dix added or withheld to make an even deal. With an odd number of players, the bidder asks for a desired card in the trump suit, with the first matching player being partner for that hand. Everyone else plays against the team. In larger groups, one or more players can sit out each hand allowing the remaining players to follow the appropriate rules for the respective number of players.
Check Pinochle.
Check pinochle is a gambling variant of three-hand. It is the same as to 1000, except that players keep track of "checks". If you are playing $1 stakes, each check you gain means that the other 2 players owe you a dollar. The following events cause a gain/loss of checks.
Double-deck Pinochle.
Today "Double Deck" pinochle is a popular form of the game, exclusively played by the National Pinochle Association, the American Pinochle Association, the Cambridge Pinochle Association, and is played for the "World Series of Pinochle".
Double-Deck Pinochle is played with 2 Pinochle decks, minus the nines. This makes for an 80 card deck.
Play is similar to regular Pinochle, except 20 cards are dealt to each person and minimum bid is increased to 500 points. In some variations, bids are made in increments of 10 or more points until 600 is reached, then by 50 points. This version often features "meld bidding", a bid to your partner letting them know what you have in your hand. This can be any numerical bid, and it is advised that you talk to your partner before the game so you have a better understanding of what their bids mean. For instance, a bid of "510" after an opening bid of "500" by the first bidder could signal "aces around" (but ONLY in this specific bid sequence). Alternatively, this could mean that the bidder is asking for meld from their partner (anytime a player bids 10 more than the player before them). A bid raise of 20 or more is to let your partner know what you have in your hand. Remember, it is best for all to talk to your partner before the game begins. You may not use a passing bid of "by me" to signal ten points held. The only communication during bidding should be a numerical number or "pass". Any other way of communicating is called "talking across the table" and is forbidden.
There are occasionally different meld values for a run and a pinochle; a run being 250 or 150 points, and a pinochle being 150 or 40 points. All other aspects of the game generally remain the same.
Other variants in double deck:
1. You must have a marriage (KQ) to take the bid and call trump.
2. You must have at least 20 meld points between you and your partner and be within 50 points of the bid to play the hand.
2. You must always make the difference between your meld and bid with your trick-points, never making less than 20 or you shall go set.
4. The non-bidding team must have 20 meld between them to have it counted and make at least 20 trick-points to save it.
5. You must either deal four or five cards and a time.
6. There are 50 possible points, 48 trick-points and 2 for taking the last trick.
Triple Deck, Six Handed Pinochle.
In triple-deck pinochle six play in two partnerships of three each; each player has an opponent at his right and left. Three pinochle decks(no nines), are mixed together, making a pack of 120 cards. Each player is dealt 20 cards, and the rules of double deck pinochle apply, except that the minimum bid is 75, and the last trick is worth 3 points. most of the extra melds made possible by the triple pack do not count extra. i.e. if a player should hold twenty aces, five of each suit, the value would be that of double aces and triple aces combined.
Internet Pinochle.
Internet Pinochle is almost always "double deck" except for a few applications for some smart phones. Today the Internet is host to many live professional cash tournaments, although many are still cautious about playing online because of potential cheating.
Racehorse Pinochle.
"Note that this use of the term "racehorse" is inconsistent with the commonly understood meaning of the term when applied to Pinochle. As aptly summarized by Dave LeVasseur: "Racehorse means that, after the winning bidder has named trump, that player's partner passes cards across the table""
Played much as the same as "double deck" but to 6 hands, the point values are inflated.
Two teams are formed, 20 cards are then dealt to each player and 4 cards are dealt to the blind. Bidding commences with the person immediately to the left of the dealer automatically bidding 500. The winner of the bid includes the blind into his hand, calls trump and melds.
Note: All Runs, Double, Triple, and Quadruple, Marriages must be in Trump.
The game continues with the standard rules of play. When the play is over each team adds up their points in the "count" with kings, 10s, and aces worth ten points, while queens and jacks are worth zero. If a team count plus meld does not equal their bid, they "go set". By going set the amount of the bid is subtracted from the teams score and their count is discarded. The other team retains both their meld and their count provided they took at least 10 points in the count.
Double-deck Pinochle for eight players.
Two full decks are dealt between eight players, forming four teams. Team members are spaced so that they are not able to see any other hands. The game is usually played to a score of 5,000 or higher. Other than this, the four player rules apply, and any variations may also be used. There is an increased possibility that when one team declares trump another team may have an equal number of trump also, which may lead to an interesting game. An optional scoring rule rewards 1,000 points for a quadruple pinochle--four jacks of diamonds and four queens of spades in a meld.

</doc>
<doc id="24838" url="http://en.wikipedia.org/wiki?curid=24838" title="Peptidoglycan">
Peptidoglycan

Peptidoglycan, also known as murein, is a polymer consisting of sugars and amino acids that forms a mesh-like layer outside the plasma membrane of most bacteria, forming the cell wall. The sugar component consists of alternating residues of β-(1,4) linked "N"-acetylglucosamine and "N"-acetylmuramic acid. Attached to the "N"-acetylmuramic acid is a peptide chain of three to five amino acids. The peptide chain can be cross-linked to the peptide chain of another strand forming the 3D mesh-like layer. Some Archaea have a similar layer of pseudopeptidoglycan or pseudomurein, where the sugar residues are β-(1,3) linked "N"-acetylglucosamine and "N"-acetyltalosaminuronic acid. That is why the cell wall of Archaea is insensitive to lysozyme. Peptidoglycan serves a structural role in the bacterial cell wall, giving structural strength, as well as counteracting the osmotic pressure of the cytoplasm. A common misconception is that peptidoglycan gives the cell its shape; however, whereas peptidoglycan helps maintain the structural strength of the cell, it is actually the MreB protein that facilitates cell shape . Peptidoglycan is also involved in binary fission during bacterial cell reproduction.
The peptidoglycan layer is substantially thicker in Gram-positive bacteria (20 to 80 nanometers) than in Gram-negative bacteria (7 to 8 nanometers), with the attachment of the S-layer. Peptidoglycan forms around 90% of the dry weight of Gram-positive bacteria but only 10% of Gram-negative strains. Thus, presence of high levels of peptidoglycan is the primary determinant of the characterisation of bacteria as Gram-positive. In Gram-positive strains, it is important in attachment roles and serotyping purposes. For both Gram-positive and Gram-negative bacteria, particles of approximately 2 nm can pass through the peptidoglycan.
Structure.
The peptidoglycan layer in the bacterial cell wall is a crystal lattice structure formed from linear chains of two alternating amino sugars, namely "N"-acetylglucosamine (GlcNAc or NAG) and "N"-acetylmuramic acid (MurNAc or NAM). The alternating sugars are connected by a β-(1,4)-glycosidic bond. Each MurNAc is attached to a short (4- to 5-residue) amino acid chain, containing -alanine, -glutamic acid, "meso"-diaminopimelic acid, and -alanine in the case of "Escherichia coli" (a Gram-negative bacterium) or -alanine, -glutamine, -lysine, and -alanine with a 5-glycine interbridge between tetrapeptides in the case of "Staphylococcus aureus" (a Gram-positive bacterium).
Cross-linking between amino acids in different linear amino sugar chains occurs with the help of the enzyme transpeptidase and results in a 3-dimensional structure that is strong and rigid. The specific amino acid sequence and molecular structure vary with the bacterial species.
Antibiotic inhibition.
Some antibacterial drugs such as penicillin interfere with the production of peptidoglycan by binding to bacterial enzymes known as penicillin-binding proteins or transpeptidases. Penicillin-binding proteins form the bonds between oligopeptide crosslinks in peptidoglycan. For a bacterial cell to reproduce through binary fission, more than a million peptidoglycan subunits (NAM-NAG+oligopeptide) must be attached to existing subunits. Mutations in genes coding for transpeptidases that lead to reduced interactions with an antibiotic are a significant source of emerging antibiotic resistance.
Considered the human body's "own antibiotic", lysozymes found in tears work by breaking the β-(1,4)-glycosidic bonds in peptidoglycan (see below) and thereby destroying many bacterial cells. Antibiotics such as penicillin commonly target bacterial cell wall formation (of which peptidoglycan is an important component) because animal cells do not have cell walls.
Biosynthesis.
The peptidoglycan monomers are synthesized in the cytosol and are then attached to a membrane carrier bactoprenol. Bactoprenol transports peptidoglycan monomers across the cell membrane where they are inserted into the existing peptidoglycan.
In the first step of peptidoglycan synthesis, the glutamine, which is an amino acid, donates an amino group to a sugar, fructose 6-phosphate. This turns fructose 6-phosphate into glucosamine-6-phosphate. In step two, an acetyl group is transferred from acetyl CoA to the amino group on the glucosamine-6-phosphate creating "N"-acetyl-glucosamine-6-phosphate. In step three of the synthesis process, the "N"-acetyl-glucosamine-6-phosphate is isomerized, which will change "N"-acetyl-glucosamine-6-phosphate to "N"-acetyl-glucosamine-1-phosphate.
In step 4, the "N"-acetyl-glucosamine-1-phosphate, which is now a monophosphate, attacks UTP. Uridine triphosphate, which is a pyrimidine nucleotide, has the ability to act as an energy source. In this particular reaction, after the monophosphate has attacked the UTP, an inorganic pyrophosphate is given off and is replaced by the monophosphate, creating UDP-N-acetylglucosamine (2,4). (When UDP is used as an energy source, it gives off an inorganic phosphate.) This initial stage, is used to create the precursor for the NAG in peptidoglycan.
In step 5, some of the UDP-N-acetylglucosamine (UDP-GlcNAc) is converted to UDP-MurNAc (UDP-N-acetylmuramic acid) by the addition of a lactyl group to the glucosamine. Also in this reaction, the C3 hydroxyl group will remove a phosphate from the alpha carbon of phosphenol pyruvate. This creates what is called an enol derivative that will be reduced to a “lactyl moiety” by NADPH in step six.
In step 7, the UDP–MurNAc is converted to UDP-MurNAc pentapeptide by the addition of five amino acids, usually including the dipeptide -alanyl--alanine. Each of these reactions requires the energy source ATP. This is all referred to as Stage one.
Stage two occurs in the cytoplasmic membrane. It is in the membrane where a lipid carrier called bactoprenol carries peptidoglycan precursors through the cell membrane. Bactoprenol will attack the UDP-MurNAc penta, creating a PP-MurNac penta, which is now a lipid. UDP-GlcNAc is then transported to MurNAc, creating Lipid-PP-MurNAc penta-GlcNAc, a disaccharide, also a precursor to peptidoglycan. How this molecule is transported through the membrane is still not understood. However, once it is there, it is added to the growing glycan chain. The next reaction is known as tranglycosylation. In the reaction, the hydroxyl group of the GlcNAc will attach to the MurNAc in the glycan, which will displace the lipid-PP from the glycan chain. The enzyme responsible for this is transglycosylase.

</doc>
<doc id="24844" url="http://en.wikipedia.org/wiki?curid=24844" title="PDE">
PDE

The initials PDE can stand for:

</doc>
<doc id="24845" url="http://en.wikipedia.org/wiki?curid=24845" title="Pope Sixtus IV">
Pope Sixtus IV

Pope Sixtus IV (Latin: "Xystus IV"; 21 July 1414 – 12 August 1484), born Francesco della Rovere, was Pope from 9 August 1471 to his death in 1484. His accomplishments as pope included building the Sistine Chapel; the group of artists that he brought together introduced the Early Renaissance into Rome with the first masterpieces of the city's new artistic age. He also established the Vatican Archives. Sixtus furthered the agenda of the Spanish Inquisition and annulled the decrees of the Council of Constance. He was famed for his nepotism and was personally involved in the infamous Pazzi Conspiracy.
Biography.
Early career.
Francesco was born to a family of modest means from Liguria, Italy, the son of Leonardo della Rovere and Luchina Monleoni. He was born in Celle Ligure, a town near Savona.
As a young man Della Rovere joined the Franciscan Order, an unlikely choice for a political career, and his intellectual qualities were revealed while he was studying philosophy and theology at the University of Pavia. He went on to lecture at Padua and many other Italian universities.
In 1464, Della Rovere was elected Minister General of the Franciscan order at the age of 50. In 1467, he was appointed Cardinal by Pope Paul II with the titular church being the Basilica of San Pietro in Vincoli. Before his papal election, Cardinal della Rovere was renowned for his unworldliness and had even written learned treatises entitled "On the Blood of Christ" and "On the Power of God". His pious reputation was one of the deciding factors that prompted the College of Cardinals to elect him pope upon the unexpected death of Paul II at the age of fifty-four.
Papal election.
Upon being elected pope Della Rovere adopted the name Sixtus – a name that had not been used since the 5th century. One of his first acts was to declare a renewed crusade against the Ottoman Turks in Smyrna. However, after the conquest of Smyrna, the fleet disbanded. Some fruitless attempts were made towards unification with the Greek Church. For the remainder of his pontificate, Sixtus turned to temporal issues and dynastic considerations.
Nepotism.
Sixtus IV sought to strengthen his position by surrounding himself with relatives and friends. In the fresco by Melozzo da Forlì he is accompanied by his Della Rovere and Riario nephews, not all of whom were made cardinals: the protonotary apostolic Pietro Riario (on his right), the future Pope Julius II standing before him, and Girolamo Riario and Giovanni della Rovere behind the kneeling Platina, author of the first humanist history of the Popes. His nephew Pietro Riario also benefited from his nepotism. Pietro became one of the richest men in Rome and was entrusted with Pope Sixtus' foreign policy. However, Pietro died prematurely in 1474, and his role passed to Giuliano della Rovere.
The secular fortunes of the Della Rovere family began when Sixtus invested his nephew Giovanni with the lordship of Senigallia and arranged his marriage to the daughter of Federico III da Montefeltro, duke of Urbino; from this union came a line of Della Rovere dukes of Urbino that lasted until the line expired in 1631. Six of the thirty-four cardinals that he created were his nephews.
In his territorial aggrandizement of the Papal States, Sixtus' niece's son Cardinal Raffaele Riario, for whom the Palazzo della Cancelleria was constructed, was a leader in the failed "Pazzi conspiracy" of 1478 to assassinate both Lorenzo de' Medici and his brother Giuliano and replace them in Florence with Sixtus IV's other nephew, Girolamo Riario. Francesco Salviati, Archbishop of Pisa and a main organizer of the plot, was hanged on the walls of the Florentine Palazzo della Signoria. To this, Sixtus IV replied with an interdict and two years' of war with Florence.
According to the later published chronicle of the Italian historian Stefano Infessura, "Diary of the City of Rome", Sixtus was a "lover of boys and sodomites" - awarding benefices and bishoprics in return for sexual favours, and nominating a number of young men as cardinals; some of whom were celebrated for their good looks. However, Infessura had partisan allegiances to the Colonna and so is not considered to be always reliable or impartial. The English churchman and protestant polemicist John Bale writing a century later, attributed to Sixtus "the authorisation to practice sodomy during periods of warm weather" to the "Cardinal of Santa Lucia". However, such accusations are easily dismissed as anti-Catholic propaganda, but did nevertheless prompt the noted historian of the Catholic Church, Ludwig von Pastor, to issue a firm rebuttal.
Foreign policy.
Sixtus continued a dispute with King Louis XI of France, who upheld the Pragmatic Sanction of Bourges (1438), according to which papal decrees needed royal assent before they could be promulgated in France. This was a cornerstone of the privileges claimed for the Gallican Church, and could never be shifted as long as Louis XI maneuvered to replace King Ferdinand I of Naples with a French prince. Louis was thus in conflict with the papacy and Sixtus could not permit it.
On 1 November 1478, Sixtus published the papal bull "Exigit Sincerae Devotionis Affectus", through which the Spanish Inquisition was established in the Kingdom of Castile. Sixtus consented under political pressure from Ferdinand of Aragon, who threatened to withhold military support from his kingdom of Sicily. Nevertheless, Sixtus IV quarrelled over protocol and prerogatives of jurisdiction, was unhappy with the excesses of the Inquisition and condemned the most flagrant abuses in 1482.
As a temporal prince who constructed stout fortresses in the Papal States, he encouraged the Venetians to attack Ferrara, which he wished to obtain for another nephew. Ercole I d'Este, Duke of Ferrara, was allied with the Sforzas of Milan, the Medicis of Florence along with the King of Naples, normally a hereditary ally and champion of the papacy. The angered Italian princes allied to force Sixtus IV to make peace, to his great annoyance. For refusing to desist from the very hostilities that he himself had instigated (and for being a dangerous rival to Della Rovere dynastic ambitions in the Marche), Sixtus placed Venice under interdict in 1483. He also lined the coffers of the state by unscrupulously selling high offices and privileges.
In ecclesiastical affairs, Sixtus promoted the cult of the Immaculate Conception, which had been confirmed at the Council of Basle in 1439 and designated 8 December as the Feast day of the Immaculate Conception of Mary. He formally annulled the decrees of the Council of Constance in 1478.
Slavery.
The two papal bulls issued by Pope Nicholas V, "Dum Diversas" of 1452 and "Romanus Pontifex" of 1455, had effectively given the Portuguese the rights to acquire slaves along the African coast by force or trade. These concessions were confirmed by Sixtus in his own bull, "Aeterni regis" of 21 June 1481. Arguably the "ideology of conquest" expounded in these texts became the means by which commerce and conversion were facilitated.
In November 1476 Isabel and Fernando ordered an investigation into rights of conquest in the Canary Islands, and in the spring of 1478 they sent Juan Rejon with sixty soldiers and thirty cavalry to the Grand Canary, where the natives retreated inland.
Sixtus' earlier threats to excommunicate all captains or pirates who enslaved Christians in the bull "Regimini Gregis" of 1476 could have been intended to emphasise the need to convert the natives of the Canary Islands and Guinea and establish a clear difference in status between those who had converted and those who resisted. The ecclesiastical penalties were directed towards those who were enslaving the recent converts.
Princely patronage.
As a civic patron in Rome, even the anti-papal chronicler Stefano Infessura agreed that Sixtus should be admired. The dedicatory inscription in the fresco by Melozzo da Forlì in the Vatican Palace records: "You gave your city temples, streets, squares, fortifications, bridges and restored the Acqua Vergine as far as the Trevi..." In addition to restoring the aqueduct that provided Rome an alternative to the river water that had made the city famously unhealthy, he restored or rebuilt over 30 of Rome's dilapidated churches, among them San Vitale (1475) and Santa Maria del Popolo, and added seven new ones. The Sistine Chapel was sponsored by Sixtus IV, as was the "Ponte Sisto", the Sistine Bridge – the first new bridge across the Tiber since antiquity – and the building of "Via Sistina" (later named "Borgo Sant'Angelo"), a road leading from Castel Sant'Angelo to Saint Peter. All this was done to facilitate the integration of the Vatican Hill and Borgo with the heart of old Rome. This was part of a broader scheme of urbanization carried out under Sixtus IV, who swept the long-established markets from the Campidoglio in 1477 and decreed in a bull of 1480 the widening of streets and the first post-Roman paving, the removal of porticoes and other post-classical impediments to free public passage.
At the beginning of his papacy in 1471, Sixtus donated several historically important Roman sculptures that founded a papal collection of art that would eventually develop into the collections of the Capitoline Museums. He also re-founded, enriched and enlarged the Vatican Library. He had Regiomontanus attempt the first sanctioned reorganization of the Julian calendar and increased the size and prestige of the papal chapel choir, bringing singers and some prominent composers (Gaspar van Weerbeke, Marbrianus de Orto, and Bertrandus Vaqueras) to Rome from the North.
In addition to being a patron of the arts, Sixtus was a patron of the sciences. Before becoming pope, he spent time at the then very liberal and cosmopolitan University of Padua, which maintained considerable independence from the Church and had a very international character. As Pope, he issued a papal bull allowing local bishops to give the bodies of executed criminals and unidentified corpses to physicians and artists for dissection. It was this access to corpses which allowed the anatomist Vesalius, along with Titian's pupil Jan Stephen van Calcar, to complete the revolutionary medical/anatomical text "De humani corporis fabrica".
Death.
Pope Sixtus' tomb was destroyed in the Sack of Rome in 1527. Today, his remains, along with the remains of his nephew Pope Julius II (Giuliano della Rovere), are interred in St. Peter's Basilica in the floor in front of the monument to Pope Clement X. A simple marble tombstone marks the site.
His bronze funerary monument, now in the basement Treasury of St. Peter's Basilica, like a giant casket of goldsmith's work, is by Antonio Pollaiuolo. The top of the casket is a lifelike depiction of the Pope lying in state. Around the sides are bas relief panels, depicting with allegorical female figures the arts and sciences (Grammar, Rhetoric, Arithmetic, Geometry, Music, Painting, Astronomy, Philosophy, and Theology). Each figure incorporates the oak tree ("rovere" in Italian) symbol of Sixtus IV. The overall program of these panels, their beauty, complex symbolism, classical references, and arrangement relative to each other is one of the most compelling and comprehensive illustrations of the Renaissance worldview.
The cardinals of Sixtus IV.
Sixtus created an unusually large number of cardinals during his pontificate (twenty-three), drawn from the roster of the princely houses of Italy, France and Spain; thus ensuring that many of his policies continued after his death:
Portrayals.
Pope Sixtus is portrayed by James Faulkner in the historical fantasy "Da Vinci's Demons". In this show, he is portrayed as having an identical twin, Alessandro. Shortly after the true Pope Sixtus, Francesco, was elected on conclave, Alessandro usurped the Holy See and had his brother locked up in Castel Sant'Angelo.

</doc>
<doc id="24849" url="http://en.wikipedia.org/wiki?curid=24849" title="Panama Canal">
Panama Canal

The Panama Canal (Spanish: "Canal de Panamá") is a 77.1 km ship canal in Panama that connects the Atlantic Ocean (via the Caribbean Sea) to the Pacific Ocean. The canal cuts across the Isthmus of Panama and is a key conduit for international maritime trade. There are locks at each end to lift ships up to Gatun Lake, an artificial lake created to reduce the amount of excavation work required for the canal, 26 m above sea level. The current locks are 33.5 m wide. A third, wider lane of locks is currently under construction and is due to open in 2016.
France began work on the canal in 1881, but had to stop because of engineering problems and high mortality due to disease. The United States took over the project in 1904, and took a decade to complete the canal, which was officially opened on August 15, 1914. One of the largest and most difficult engineering projects ever undertaken, the Panama Canal shortcut greatly reduced the time for ships to travel between the Atlantic and Pacific Oceans, enabling them to avoid the lengthy, hazardous Cape Horn route around the southernmost tip of South America via the Drake Passage or Strait of Magellan. The shorter, faster, and safer route to the U.S. West Coast and to nations in and around the Pacific Ocean allowed those places to become more integrated with the world economy. It takes 20 to 30 hours to go through the Panama Canal.
During construction, ownership of the territory that the Panama Canal now passes through was first Colombian, then French, and then American. The US continued to control the canal and surrounding Panama Canal Zone until the 1977 Torrijos–Carter Treaties provided for handover to Panama. After a period of joint American–Panamanian control, the canal was taken over by the Panamanian government in 1999, and is now managed and operated by the Panama Canal Authority, a Panamanian government agency.
Annual traffic has risen from about 1,000 ships in 1914, when the canal opened, to 14,702 vessels in 2008, the latter measuring a total of 309.6 million Panama Canal/Universal Measurement System (PC/UMS) tons. By 2008, more than 815,000 vessels had passed through the canal; the largest ships that can transit the canal today are called "Panamax". The American Society of Civil Engineers has named the Panama Canal one of the seven wonders of the modern world.
History.
Early proposals.
The earliest mention of a canal across the Isthmus of Panama dates back to 1534, when Charles V, Holy Roman Emperor and King of Spain, ordered a survey for a route through the Americas that would ease the voyage for ships traveling between Spain and Peru. Such a route would have given the Spanish a military advantage over the Portuguese. In 1788, Thomas Jefferson suggested that the Spanish should create it since it would be a less treacherous route than going around the southern tip of South America, which tropical ocean currents would naturally widen thereafter. During an expedition from 1788 to 1793, Alessandro Malaspina outlined plans for its construction.
Given the strategic location of Panama and the potential offered by its narrow isthmus separating two great oceans, other trade links in the area were attempted over the years. The ill-fated Darien scheme was launched by the Kingdom of Scotland in 1698 to set up an overland trade route. Generally inhospitable conditions thwarted the effort, and it was abandoned in April 1700.
Another effort was made in 1843. According to the New York Daily Tribune, August 24, 1843, a contract was entered into by Barings of London and the Republic of New Granada for the construction of a canal across the Isthmus of Darien (Isthmus of Panama). They referred to it as the Atlantic and Pacific Canal and was a wholly British endeavor. The article states that it was expected to be completed in five years. Unfortunately, the plan was not carried out. At nearly the same time, other ideas were floated, including a canal (and or a railroad) across Mexico's Isthmus of Tehuantepec. Nothing came of that plan either. (See the original newspaper article here:)
In 1849, the discovery of gold in California created great interest in a crossing between the Atlantic and Pacific Oceans. The Panama Railway was built to cross the isthmus, and opened in 1855. This overland link became a vital piece of Western Hemisphere infrastructure, greatly facilitating trade and largely determining the later canal route.
An all-water route between the oceans was still seen as the ideal solution, and in 1855 William Kennish, a Manx-born engineer working for the United States government, surveyed the isthmus and issued a report on a route for a proposed Panama Canal. His report was published in a book entitled "The Practicality and Importance of a Ship Canal to Connect the Atlantic and Pacific Oceans".
In 1877 Armand Reclus, an officer with the French Navy, and Lucien Napoléon Bonaparte Wyse, two engineers, surveyed the route and published a French proposal for a canal. French success in building the Suez Canal, while a lengthy project, encouraged planning for one to cross the isthmus.
French construction attempts, 1881–1894.
The first attempt to construct a canal through what was then Colombia's province of Panama began on 1 January 1881. The project was inspired by the diplomat Ferdinand de Lesseps, who was able to raise considerable finance in France as a result of the huge profits generated by his successful construction of the Suez Canal.
De Lesseps wanted a sea-level canal as at Suez, but only visited the site a few times, during the dry season which lasts only four months of the year. His men were totally unprepared for the rainy season, during which the Chagres River, where the canal started, became a raging torrent, rising up to 35 feet (10m). The dense jungle was alive with venomous snakes, insects and spiders and the worst aspect was the yellow fever and malaria (and other tropical diseases) which killed thousands of workers: by 1884 the death rate was over 200 per month. Public health measures were ineffective because the role of the mosquito as a disease vector was then unknown. Conditions were downplayed in France to avoid recruitment problems, but the high mortality made it difficult to maintain an experienced workforce.
The main cut through the mountain at Culebra had to continually be widened, and its slopes reduced, to minimize landslides into the canal. Steam shovels had been invented but were still primitive. Other mechanical and electrical equipment was limited in its capabilities, and steel equipment rusted rapidly in the climate.
In France, de Lesseps had kept the investment and supply of workers flowing long after it was obvious that the targets were not being met but eventually the money ran out. The French effort went bankrupt in 1889 after reportedly spending US$287,000,000 and losing an estimated 22,000 lives (mostly blacks from the Caribbean) to disease and accident, wiping out the savings of 800,000 investors who placed their trust in him. Work was suspended on May 15 and in the ensuing scandal, known as the Panama affair, various of those deemed responsible were prosecuted. De Lesseps and his son Charles were found guilty of misappropriation of funds and sentenced to five years' imprisonment, though this was later overturned and the father, at 88, was never imprisoned.
In 1894, a second French company, the "Compagnie Nouvelle du Canal de Panama", was created to take over the project. A minimal workforce of a few thousand people was employed primarily to comply with the terms of the Colombian Panama Canal concession, to run the Panama Railroad, and to maintain the existing excavation and equipment in salable condition. The company sought a buyer for these assets, with an asking price of US$109,000,000. In the meanwhile they continued with enough activity to maintain their franchise and Bunau-Varilla eventually managed to persuade de Lesseps that a lock and lake canal was more realistic than a sea-level canal.
U.S. acquisition.
At this time, the President and the Senate of the United States were interested in establishing a canal across the isthmus, with some favoring a canal across Nicaragua and others advocating the purchase of the French interests in Panama. The French manager of the New Panama Canal Company, Phillipe Bunau-Varilla, who was seeking American involvement, asked for $100m for their interests but accepted $40m in the face of the Nicaraguan option. In June 1902, the U.S. Senate voted in favor of pursuing the Panamanian option, provided the necessary rights could be obtained, in the Spooner Act.
On January 22, 1903, the Hay–Herrán Treaty was signed by United States Secretary of State John M. Hay and Colombian Chargé Dr. Tomás Herrán. For $10m and an annual payment it would have granted the United States a renewable lease in perpetuity from Colombia on the land proposed for the canal. The treaty was ratified by the U.S. Senate on March 14, 1903, but the Senate of Colombia did not ratify it. Bunau-Varilla told President Theodore Roosevelt and Hay of a possible revolt by Panamanian rebels who aimed to separate from Colombia, and hoped that the United States would support the rebels with U.S. troops and money. Roosevelt changed tactics, actively supported the separation of Panama from Colombia and, shortly after recognizing Panama, signed a treaty with the new Panamanian government under similar terms to the Hay–Herrán Treaty.
On November 2, 1903, U.S. warships blocked sea lanes for possible Colombian troop movements en route to put down the rebellion. Panama declared independence on November 3, 1903. The United States quickly recognized the new nation. On November 6, 1903, Philippe Bunau-Varilla, as Panama's ambassador to the United States, signed the Hay–Bunau-Varilla Treaty, granting rights to the United States to build and indefinitely administer the Panama Canal Zone and its defenses. This is sometimes misinterpreted as the "99-year lease" because of misleading wording included in article 22 of the agreement. Almost immediately, the treaty was condemned by many Panamanians as an infringement on their country’s new national sovereignty. This would later become a contentious diplomatic issue between Colombia, Panama and the United States.
President Roosevelt infamously stated that "I took the Isthmus, started the canal and then left Congress not to debate the canal, but to debate me." Several parties in the United States proposed this to be an act of war on Colombia: the New York Times called the support given by the United States to Mr. Bunau-Varilla an "act of sordid conquest." The New York Evening Post called it a "vulgar and mercenary venture." More recently, historian George Tindall labeled it "one of the greatest blunders in American foreign policy." It is often cited as the classic example of U.S. gunboat diplomacy in Latin America, and the best illustration of what Roosevelt meant by the old African adage, "speak softly and carry a big stick [and] you will go far." After the revolution in 1903, the Republic of Panama became a U.S. protectorate until 1939.
Thus in 1904, the United States purchased the French equipment and excavations, including the Panama Railroad, for US$40 million, of which $30 million related to excavations completed, primarily in the Gaillard Cut (then called the Culebra Cut), valued at about $1.00 per cubic yard. The United States also paid the new country of Panama $10 million plus $250,000 more each year. (In 1921, the United States paid Colombia US$10 million, plus US$250,000 per annum for several years; in return, Colombia recognized Panama under the terms of the Thomson–Urrutia Treaty.)
U.S. construction, 1904–1914.
The U.S. formally took control of the canal property on May 4, 1904, inheriting from the French a depleted workforce and a vast jumble of buildings, infrastructure and equipment, much of it in poor condition. A U.S. government commission, the Isthmian Canal Commission (ICC), was established to oversee construction and was given control of the Panama Canal Zone, over which the United States exercised sovereignty. The commission reported directly to Secretary of War William Howard Taft and was directed to avoid the inefficiency and corruption that had plagued the French 15 years earlier.
On May 6, 1904, President Theodore Roosevelt appointed John Findlay Wallace, formerly chief engineer and finally general manager of the Illinois Central Railroad, as chief engineer of the Panama Canal Project. Overwhelmed by the disease-plagued country and forced to use often dilapidated French infrastructure and equipment, as well as being frustrated by the overly bureaucratic ICC, Wallace resigned abruptly in June 1905. He was succeeded by John Frank Stevens, a self-educated engineer who had built the Great Northern Railroad. Stevens was not a member of the ICC; he increasingly viewed its bureaucracy as a serious hindrance and ended up bypassing the commission and sending requests and demands directly to the Roosevelt Administration in Washington.
One of Stevens' first achievements in Panama was in building and rebuilding the housing, cafeterias, hotels, water systems, repair shops, warehouses, and other infrastructure needed by the thousands of incoming workers. Stevens began the recruitment effort to entice thousands of workers from the United States and other areas to come to the Canal Zone to work, and tried to provide accommodation in which the incoming workers could work and live in reasonable safety and comfort. He also re-established and enlarged the railway that was to prove crucial in transporting millions of tons of spoil from the cut through the mountains to the dam across the Chagres river.
Colonel William C. Gorgas had been appointed chief sanitation officer of the canal construction project in 1904. Gorgas implemented a range of measures to minimize the spread of deadly diseases, particularly yellow fever and malaria which had recently been shown to be mosquito-borne following the work of Dr. Carlos Finlay and Dr. Walter Reed. There was investment in extensive sanitation projects, including city water systems, fumigation of buildings, spraying of insect-breeding areas with oil and larvicide, installation of mosquito netting and window screens, and elimination of stagnant water. Despite opposition from the Commission (one member said his ideas were barmy), Gorgas persisted and when Stevens arrived, he threw his weight behind the project. After two years of extensive work, the mosquito-spread diseases were nearly eliminated. Nevertheless, even with all this effort, about 5,600 workers died of disease and accidents during the U.S. construction phase of the canal.
In 1905, a U.S. engineering panel was commissioned to review the canal design, which still had not been finalised. It recommended to President Roosevelt a sea-level canal, as had been attempted by the French. However, in 1906 Stevens, who had seen the Chagres in full flood, was summoned to Washington and declared a sea-level approach to be 'an entirely untenable proposition'. He argued in favor of a canal using a lock system to raise and lower ships from a large reservoir 85 ft above sea level. This would create both the largest dam (Gatun Dam) and the largest man-made lake (Gatun Lake) in the world at that time. The water to refill the locks would be taken from Gatun Lake by opening and closing enormous gates and valves and letting gravity propel the water from the lake. Gatun Lake would connect to the Pacific through the mountains at the Gaillard (Culebra) Cut. Stevens successfully convinced Roosevelt of the necessity and feasibility of the alternative scheme.
The construction of a canal with locks required the excavation of more than an additional 170000000 cuyd of material over and above the 30000000 cuyd excavated by the French. As quickly as possible, the Americans replaced or upgraded the old, unusable French equipment with new construction equipment that was designed for a much larger and faster scale of work. About 102 new large, railroad-mounted steam shovels were purchased and brought in from the United States. These were joined by enormous steam-powered cranes, giant hydraulic rock crushers, cement mixers, dredges, and pneumatic power drills, nearly all of which was manufactured by new, extensive machine-building technology developed and built in the United States. The railroad also had to be comprehensively upgraded with heavy-duty, double-tracked rails over most of the line to accommodate new rolling stock. In many places, the new Gatun Lake flooded over the original rail line, and a new line had to be constructed above Gatun Lake's waterline.
In 1907, Stevens resigned as chief engineer, having in his view made success certain. His replacement, appointed by President Theodore Roosevelt, was U.S. Army Major George Washington Goethals of the U.S. Army Corps of Engineers (soon to be promoted to lieutenant colonel and later to colonel), a strong, United States Military Academy–trained leader and civil engineer with experience of canals (unlike Stevens). Goethals would direct the work in Panama to a successful conclusion.
Goethals divided the engineering and excavation work into three divisions: Atlantic, Central, and Pacific. The Atlantic division, under Major William L. Sibert, was responsible for construction of the massive breakwater at the entrance to Limon Bay, the Gatun locks and their 3.5 mi approach channel, and the immense Gatun Dam. The Pacific Division, under Sydney B. Williamson (the only civilian member of this high-level team), was similarly responsible for the Pacific 4.8 km breakwater in Panama Bay, the approach channel to the locks, and the Miraflores and Pedro Miguel locks and their associated dams and reservoirs.
The Central division, under Major David du Bose Gaillard of the United States Army Corps of Engineers, was assigned one of the most difficult parts: excavating the Culebra Cut through the continental divide to connect Gatun Lake to the Pacific Panama Canal locks.
The building of the canal was completed in 1914, 401 years after Panama was first crossed by Vasco Núñez de Balboa. The United States spent almost $375,000,000 (roughly equivalent to $8,600,000,000 now) to finish the project. This was by far the largest American engineering project to date. The canal was formally opened on August 15, 1914, with the passage of the cargo ship SS "Ancon".
The opening of Panama Canal in 1914 caused a severe drop in traffic along Chilean ports due to shifts in the maritime trade routes.
Throughout this time, Ernest "Red" Hallen was hired by the Isthmian Canal Commission to document the progress of the work.
Later developments.
By the 1930s it was seen that water supply would be an issue for the canal; this prompted the building of the Madden Dam across the Chagres River above Gatun Lake. The dam, completed in 1935, created Madden Lake (later Alajuela Lake), which provides additional water storage for the canal. In 1939, construction began on a further major improvement: a new set of locks for the canal, large enough to carry the larger warships that the United States was building at the time and had planned to continue building. The work proceeded for several years, and significant excavation was carried out on the new approach channels, but the project was canceled after World War II.
After World War II, U.S. control of the canal and the Canal Zone surrounding it became contentious; relations between Panama and the United States became increasingly tense. Many Panamanians felt that the Canal Zone rightfully belonged to Panama; student protests were met by the fencing-in of the zone and an increased military presence there. Demands for the United States to hand over the canal to Panama increased after the Suez Crisis in 1956, when the US used financial and diplomatic pressure to force France and the UK to abandon their attempt to retake control of the Suez Canal, previously nationalized by the Nasser regime in Egypt. Unrest culminated in riots on Martyr's Day, January 9, 1964, when about 20 Panamanians and 3–5 U.S. soldiers were killed.
A decade later, in 1974, negotiations toward a settlement began and resulted in the Torrijos–Carter Treaties. On September 7, 1977, the treaty was signed by President of the United States Jimmy Carter and Omar Torrijos, de facto leader of Panama. This mobilized the process of granting the Panamanians free control of the canal so long as Panama signed a treaty guaranteeing the permanent neutrality of the canal. The treaty led to full Panamanian control effective at noon on December 31, 1999, and the Panama Canal Authority (ACP) assumed command of the waterway. The Panama Canal remains one of the chief revenue sources for Panama.
Before this handover, the government of Panama held an international bid to negotiate a 25-year contract for operation of the container shipping ports located at the canal's Atlantic and Pacific outlets. The contract was not affiliated with the ACP or Panama Canal operations and was won by the firm Hutchison Whampoa, a Hong Kong–based shipping interest owned by Li Ka-shing.
Canal.
Layout.
While, globally, the Atlantic Ocean is east of the isthmus and the Pacific to the west, the general direction of the canal passage from the Atlantic to the Pacific is from northwest to southeast. This is because of a local anomaly in the shape of the isthmus at the point the canal occupies. The Bridge of the Americas (Spanish: "Puente de las Américas") at the Pacific side is about a third of a degree east of the Colón end on the Atlantic side. Still, in formal nautical communications, the simplified directions "Southbound" and "Northbound" are used.
The canal consists of artificial lakes, several improved and artificial channels, and three sets of locks. An additional artificial lake, Alajuela Lake (known during the American era as Madden Lake), acts as a reservoir for the canal. The layout of the canal as seen by a ship passing from the Atlantic to the Pacific is as follows:
Thus, the total length of the canal is 77.1 km.
Gatun Lake.
Artificially created in 1913 by the damming of the Chagres River, Gatun Lake is an essential part of the Panama Canal which forms a water passage between the Atlantic and Pacific Oceans, permitting ship transit in both directions. At the time it was formed, Gatun Lake was the largest man-made lake in the world. The impassable rainforest around the lake has been the best defense of the Panama Canal. Today these areas remain practically unscathed by human interference and are one of the few accessible areas on earth where various native Central American animal and plant species can be observed undisturbed in their natural habitat. World famous Barro Colorado Island, which was established for scientific study when the lake was formed and is today operated by the Smithsonian Institution, is the largest island on Gatun Lake. Many of the most important groundbreaking scientific and biological discoveries of the tropical animal and plant kingdom originated here. Gatun Lake covers about 180 sqmi, a vast tropical ecological zone part of the Atlantic Forest Corridor. Ecotourism on the lake has become a worthwhile industry for Panamanians.
Gatun Lake also serves to provide the millions of gallons of water necessary to operate the Panama Canal locks each time a ship passes through, and provides drinking water for Panama City and Colón. Fishing is one of the primary recreational pursuits on Gatun Lake. Non-native peacock bass were introduced by accident to Gatun Lake around 1967 by a local businessman, and have since flourished to become the dominant angling game fish in Gatun Lake. Locally called Sargento and believed to be the species "Cichla pleiozona", these peacock bass are not a native game fish of Panama but originate from the Amazon, Rio Negro, and Orinoco river basins of South America, where they are called Tucanare or Pavon and considered a premier game fish.
Lock size.
The size of the locks determines the maximum size of a ship that can pass through them. Because of the importance of the canal to international trade, many ships are built to the maximum size allowed. These are known as Panamax vessels. A Panamax cargo ship typically has a deadweight tonnage (DWT) of 65,000–80,000 tonnes, but its actual cargo is restricted to about 52,500 tonnes because of the 41.2 ft draft restrictions within the canal. The longest ship ever to transit the canal was the "San Juan Prospector" (now "Marcona Prospector"), an ore-bulk-oil carrier that is 973 ft long with a beam of 106 ft.
Initially the locks at Gatun had been designed to be 28.5 m wide. In 1908, the United States Navy requested that width be increased to at least 36 m, which would allow the passage of U.S. naval ships. Eventually a compromise was made and the locks were built 33.53 m wide. Each lock is 320 m long, with the walls ranging in thickness from 15 m at the base to 3 m at the top. The central wall between the parallel locks at Gatun is 18 m thick and over 24 m high. The steel lock gates measure an average of 2 m thick, 19.5 m wide, and 20 m high. It is the size of the locks, specifically the Pedro Miguel Locks, along with the height of the Bridge of the Americas at Balboa, that determine the Panamax metric and limit the size of ships that may use the canal.
The 2006 third set of locks project will create larger locks, allowing bigger ships to transit through deeper and wider channels. The allowed dimensions of ships will increase by 25% in length, 51% in beam, and 26% in draft, as defined by New Panamax metrics.
Tolls.
Tolls for the canal are set by the Panama Canal Authority and are based on vessel type, size, and the type of cargo carried.
For container ships, the toll is assessed on the ship's capacity expressed in twenty-foot equivalent units (TEUs), one TEU being the size of a standard intermodal shipping container. Effective May 1, 2009, this toll is US$72.00 per TEU. A Panamax container ship may carry up to 4,400 TEU. The toll is calculated differently for passenger ships and for container ships carrying no cargo ("in ballast"). s of 1, 2009[ [update]], the ballast rate is US$57.60 per TEU.
Passenger vessels in excess of 30,000 tons (PC/UMS), known popularly as cruise ships, pay a rate based on the number of berths, that is, the number of passengers that can be accommodated in permanent beds. The per-berth charge is currently $92 for unoccupied berths and $115 for occupied berths. Started in 2007, this fee has greatly increased the tolls for such ships. Passenger vessels of less than 30,000 tons or less than 33 tons per passenger are charged according to the same per-ton schedule as are freighters.
Most other types of vessel pay a toll per PC/UMS net ton, in which one "ton" is actually a volume of 100 cuft. (The calculation of tonnage for commercial vessels is quite complex.) As of fiscal year 2008[ [update]], this toll is US$3.90 per ton for the first 10,000 tons, US$3.19 per ton for the next 10,000 tons, US$3.82 per ton for the next 10,000 tons, and US$3.76 per ton thereafter. As with container ships, a reduced toll is charged for freight ships "in ballast."
Small vessels up to 583 PC/UMS net tons when carrying passengers or cargo, or up to 735 PC/UMS net tons when in ballast, or up to 1,048 fully loaded displacement tons, are assessed minimum tolls based upon their length overall, according to the following table:
Morgan Adams of Los Angeles, California, holds the distinction of paying the first toll received by the United States Government for the use of the Panama Canal by a pleasure boat. His boat "Lasata" passed through the Zone on August 14, 1914. The crossing occurred during a 6,000-mile sea voyage from Jacksonville, Florida, to Los Angeles in 1914.
The most expensive regular toll for canal passage to date was charged on April 14, 2010 to the cruise ship "Norwegian Pearl," which paid US$375,600. The average toll is around US$54,000. The highest fee for priority passage charged through the Transit Slot Auction System was US$220,300, paid on August 24, 2006, by the Panamax tanker "Erikoussa", bypassing a 90-ship queue waiting for the end of maintenance works on the Gatun locks, thus avoiding a seven-day delay. The normal fee would have been just US$13,430.
The lowest toll paid was 36 cents by American Richard Halliburton who swam the Panama Canal in 1928.
Current issues.
Panorama of Pacific entrance of the canal. Left: Pacific Ocean and Puente de las Americas (Bridge of Pan-American Highway); far right: Miraflores locks.
In the 100 years since its opening, the canal continues to enjoy great success. Even though world shipping—and the size of ships themselves—has changed markedly since the canal was designed, it continues to be a vital link in world trade, carrying more cargo than ever before, with fewer overhead costs. Nevertheless, the canal faces a number of potential concerns.
Efficiency and maintenance.
Opponents to the 1977 Torrijos-Carter Treaties feared that efficiency and maintenance would suffer following the U.S. withdrawal from the Panama Canal Zone; however, this has been proven not to be the case. Capitalizing on practices developed during the American administration, canal operations are improving under Panamanian control. Canal Waters Time (CWT), the average time it takes a vessel to navigate the canal, including waiting time, is a key measure of efficiency; according to the ACP, since 2000, it has ranged between 20 and 30 hours. The accident rate has also not changed appreciably in the past decade, varying between 10 and 30 accidents each year from about 14,000 total annual transits. An official accident is one in which a formal investigation is requested and conducted.
Increasing volumes of imports from Asia, which previously landed on U.S. West Coast ports, are now passing through the canal to the American East Coast. The total number of ocean-going transits increased from 11,725 in 2003 to 13,233 in 2007, falling to 12,855 in 2009. (The canal's fiscal year runs from October through September.) This has been coupled with a steady rise in average ship size and in the numbers of Panamax vessels passing through the canal, so that the total tonnage carried rose from 227.9 million PC/UMS tons in fiscal year 1999 to a record high of 312.9 million tons in 2007, falling to 299.1 million tons in 2009. Despite the reduction in total transits due to the negative impact of vessel size (e.g., the inability of large vessels to pass each other in the Gaillard Cut), this represents significant overall growth in canal capacity.
The Panama Canal Authority (ACP) has invested nearly US$1 billion in widening and modernizing the canal, with the aim of increasing capacity by 20%. The ACP cites a number of major improvements, including the widening and straightening of the Gaillard Cut to reduce restrictions on passing vessels, the deepening of the navigational channel in Gatun Lake to reduce draft restrictions and improve water supply, and the deepening of the Atlantic and Pacific entrances to the canal. This is supported by new equipment, such as a new drill barge and suction dredger, and an increase of the tug boat fleet by 20%. In addition, improvements have been made to the canal's operating machinery, including an increased and improved tug locomotive fleet, the replacement of more than 16 km of locomotive track, and new lock machinery controls. Improvements have been made to the traffic management system to allow more efficient control over ships in the canal.
In December 2010, record-breaking rains caused a 17-hour closure of the canal; this was the first closure since the United States invasion of Panama in 1989. The rains also caused an access road to the Centenario bridge to collapse.
Capacity.
The canal is currently handling more vessel traffic than had ever been envisioned by its builders. In 1934 it was estimated that the maximum capacity of the canal would be around 80 million tons per year; as noted above, canal traffic in 2009 reached 299.1 million tons of shipping.
To improve capacity, a number of improvements have been imposed on the current canal system. These improvements aim to maximize the possible use of current locking system:
These improvements enlarged the capacity from 280–90 million PCUMS (2008) to 330–40 PCUMS (2012).
It should be noted that these improvements were started before the new locks project, and are complementary to it.
Competition.
Despite having enjoyed a privileged position for many years, the canal is increasingly facing competition from other quarters. Because canal tolls have risen and as ships have become larger, some critics have suggested that the Suez Canal is now a viable alternative for cargo en route from Asia to the U.S. East Coast. The Panama Canal, however, continues to serve more than 144 of the world's trade routes and the majority of canal traffic comes from the "all-water route" from Asia to the U.S. East and Gulf Coasts via the Panama Canal.
On June 15, 2013, Nicaragua awarded the Hong Kong-based a 50-year concession to develop a canal through the country.
The increasing rate of melting of ice in the Arctic Ocean has led to speculation that the Northwest Passage or Arctic Bridge may become viable for commercial shipping at some point in the future. This route would save 9,300 km on the route from Asia to Europe compared with the Panama Canal, possibly leading to a diversion of some traffic to that route. However, such a route is beset by unresolved territorial issues and would still hold significant problems owing to ice.
Water issues.
Gatun Lake is filled with rainwater, and the lake accumulates excess water during wet months. The water is lost to the oceans at a rate of 101000 m3 per downward lock cycle. Since a ship will have to go upward to Gatun Lake first and then descend, a single passing will cost double the amount; but the same waterflow cycle can be used for another ship passing in the opposite direction. The ship's submerged volume is not relevant to this amount of water. During the dry season, when there is less rainfall, there is also a shortfall of water in Gatun Lake.
As a signatory to the United Nations Global Compact and member of the World Business Council for Sustainable Development, the ACP has developed an environmentally and socially sustainable program for expansion, which will protect the aquatic and terrestrial resources of the canal watershed. After completion, expansion will guarantee the availability and quality of water resources by using water-saving basins at each new lock. These water-saving basins will diminish water loss and preserve freshwater resources along the waterway by reusing water from the basins into the locks. Each lock chamber will have three water-saving basins, which will reuse 60% of the water in each transit. There are a total of nine basins for each of the two lock complexes, and a total of 18 basins for the entire project.
The sea level at the Pacific side is about 20 cm higher than that of the Atlantic side due to differences in ocean conditions such as water densities and weather.
Future developments.
As demand is rising for efficient global shipping of goods, the canal is positioned to be a significant feature of world shipping for the foreseeable future. However, changes in shipping patterns—particularly the increasing numbers of larger-than-Panamax ships—will necessitate changes to the canal if it is to retain a significant market share. In 2006 it was anticipated that by 2011, 37% of the world's container ships would be too large for the present canal, and hence a failure to expand would result in a significant loss of market share. The maximum sustainable capacity of the present canal, given some relatively minor improvement work, is estimated at 330–40 million PC/UMS tons per year; it was anticipated that this capacity would be reached between 2009 and 2012. Close to 50% of transiting vessels were already using the full width of the locks.
An enlargement scheme similar to the 1939 Third Lock Scheme, to allow for a greater number of transits and the ability to handle larger ships, has been under consideration for some time, has been approved by the government of Panama, and is in progress, with completion originally expected by the end of 2014. The cost is estimated at US$5.25 billion, and the project will double the canal's capacity, allowing more traffic and the passage of longer and wider ships. This proposal to expand the canal was approved in a national referendum by about 80% on October 22, 2006.
Third set of locks project.
The current plan is for two new flights of locks to be built parallel to, and operated in addition to, the old locks: one east of the existing Gatun locks, and one southwest of the Miraflores locks, each supported by approach channels. Each flight will ascend from sea level directly to the level of Gatun Lake; the existing two-stage ascent at Miraflores and Pedro Miguel locks will not be replicated. The new lock chambers will feature sliding gates, doubled for safety, and will be 427 m long, 55 m wide, and 18.3 m deep. This will allow the transit of vessels with a beam of up to 49 m, an overall length of up to 366 m and a draft of up to 15 m, equivalent to a container ship carrying around 12,000 containers, each 20 ft in length (TEU).
The new locks will be supported by new approach channels, including a 6.2 km channel at Miraflores from the locks to the Gaillard Cut, skirting Miraflores Lake. Each of these channels will be 218 m wide, which will require post-Panamax vessels to navigate the channels in one direction at a time. The Gaillard Cut and the channel through Gatun Lake will be widened to at least 280 m on the straight portions and at least 366 m on the bends. The maximum level of Gatun Lake will be raised from 26.7 m to 27.1 m.
Each flight of locks will be accompanied by nine water reutilization basins (three per lock chamber), each basin being about 70 m wide, 430 m long and 5.50 m deep. These gravity-fed basins will allow 60% of the water used in each transit to be reused; the new locks will consequently use 7% less water per transit than each of the existing lock lanes. The deepening of Gatun Lake and the raising of its maximum water level will also provide capacity for significantly more water storage. These measures are intended to allow the expanded canal to operate without constructing new reservoirs.
The estimated cost of the project is US$5.25 billion. The project is designed to allow for an anticipated growth in traffic from 280 million PC/UMS tons in 2005 to nearly 510 million PC/UMS tons in 2025. The expanded canal will have a maximum sustainable capacity of about 600 million PC/UMS tons per year. Tolls will continue to be calculated based on vessel tonnage, and will not depend on the locks used.
The new locks are expected to open for traffic in 2016. The present locks, which will be 100 years old by that time, will then be able to give engineers greater access for maintenance, and are projected to continue operating indefinitely. An article in the February 2007 issue of "Popular Mechanics" magazine describes the plans for the canal, focusing on the engineering aspects of the expansion project. There is also a follow-up article in the February 2010 issue of "Popular Mechanics".
On September 3, 2007, thousands of Panamanians stood across from Paraíso Hill in Panama to witness a huge initial explosion and launch of the Expansion Program. The first phase of the project will be dry excavations of the 218 m wide trench connecting the Gaillard Cut with the Pacific coast, removing 47 million cubic meters of earth and rock. By June 2012, a 30 m reinforced concrete monolith had been completed, the first of 46 such monoliths which will line the new Pacific-side lock walls. By early July 2012, however, it was announced that the canal expansion project had fallen six months behind schedule, leading expectations for the expansion to open in April 2015 rather than October 2014, as originally planned. By September, 2014, the new gates were projected to be open for transit at the "beginning of 2016."
It was announced in July 2009 that the Belgian dredging company Jan De Nul, together with a consortium of contractors consisting of the Spanish Sacyr Vallehermoso, the Italian Impregilo, and the Panamanian company Grupo Cusa, had been awarded the contract to build the six new locks. The contract will result in $100 million in dredging works over the next few years for the Belgian company and a great deal of work for its construction division. The design of the locks is a carbon copy of the Berendrecht Lock, which is 68 m wide and 500 m long, making it the largest lock in the world. Completed in 1989 by the Port of Antwerp, which De Nul helped build, the company still has engineers and specialists who were part of that project.
In January 2014 a contract dispute threatened the progress of the project.
 There was a delay of less than 2 months however, with work by the consortium members reaching goals by June 2014.
Rival Colombia rail link.
China is investigating a proposal to construct a 220 km railway between Colombia's Pacific and Caribbean coasts.
Rival canal in Nicaragua.
The Nicaraguan parliament has approved plans for a Chinese company to build a 173-mile canal through Nicaragua. According to the deal, the company will also be responsible for operating and maintaining the canal for a 50-year period. Construction began on this project in December 2014. The government of Nicaragua hopes this will boost the economy, but the opposition is deeply concerned with its massive environmental impact. Hundreds of thousands of local residents will be displaced by the canal and nearly a million acres of delicate ecosystems will be destroyed by time construction is complete in early 2019.
On July 7, 2014, Wang Jing, chairman of the HK Nicaragua Canal Development Investment Co. Ltd. (HKND Group), during a discussion group with students from the National Engineering University in Managua, advised that a route for Nicaragua's proposed canal has been approved. The construction work began in December 2014 and is projected by HKND to take 5 years.
Other projects.
Individuals, companies, and governments have explored the possibility of constructing deep water ports and rail links connecting coasts as a "dry canal" in Guatemala, Costa Rica, and El Salvador/Honduras. However, plans to construct these sea-rail-sea links have yet to materialize.
Panama Canal Honorary Pilots.
During the last one hundred years, the Panama Canal Authority has appointed a few "Panama Canal Honorary Pilots." The most recent of these were Commodore Ronald Warwick, a former Master of the Cunard Line's RMS "Queen Mary 2", who has traversed the Canal more than 50 times, and Captain Raffaele Minotauro, Master Senior
Grade, of the former Italian governmental navigation company known as the "Italian Line."

</doc>
<doc id="24850" url="http://en.wikipedia.org/wiki?curid=24850" title="Political fiction">
Political fiction

Political fiction is a subgenre of fiction that deals with political affairs. Political fiction has often used narrative to provide commentary on political events, systems and theories. Works of political fiction often "directly criticize an existing society or present an alternative, sometimes fantastic, reality."
Prominent pieces of political fiction have included the totalitarian dystopias of the early 20th century, such as Jack London's "The Iron Heel" and Sinclair Lewis' "It Can't Happen Here". Other highly influential novels were earlier works such as "Gulliver's Travels" (1726), "Candide" (1759), and "Uncle Tom's Cabin" (1852). Political fiction frequently employs the literary modes of satire, often in the genres of Utopian and dystopian fiction, or social science fiction.
Notable examples.
"This is a list of a few of the early or notable examples; others belong on the main list"

</doc>
<doc id="24851" url="http://en.wikipedia.org/wiki?curid=24851" title="Potato chip">
Potato chip

A potato chip (American English) or crisp (British English) is a thin slice of potato that has been deep fried or baked until crunchy. Potato chips are commonly served as a snack, side dish, or appetizer. The basic chips are cooked and salted; additional varieties are manufactured using various flavorings and ingredients including herbs, spices, cheeses, and artificial additives.
"Crisps", however, may also refer to many different types of savory snack products sold in the United Kingdom and Ireland, some made from potato, but some made from corn, tapioca or other cereals, just as there are other varieties of chips in the United States.
Potato chips are a predominant part of the snack food market in Western countries. The global potato chip market generated total revenues of US$16.49 billion in 2005. This accounted for 35.5% of the total savory snacks market in that year ($46.1 billion).
History.
According to a traditional story in the United States, the original potato chip recipe was created in Saratoga Springs, New York. By the late 19th century, popular version of the story attributed the dish to George Crum, a half black, half Native American cook at Moon's Lake House, who was trying to appease an unhappy customer on August 24, 1853. The customer kept sending his fried potatoes back, complaining that they were too thick. Frustrated, he sliced the potatoes razor thin, fried them until crisp and seasoned them with extra salt. To Crum's surprise, the customer loved them. They soon became called "Saratoga Chips", a name that persisted into at least the mid-20th century. A version of this story popularized in a 1973 national advertising campaign by St. Regis Paper Company, which manufactured packaging for chips, said that Crum's customer was Cornelius Vanderbilt. Crum was renowned as a chef and by 1860 owned his own lakeside restaurant, Crum's House.
In the United Kingdom, the origin of the potato chip is attributed to English food writer William Kitchiner's 1822 cookbook "The Cook's Oracle", which was a bestseller in England and the United States, and includes a recipe for "Potatoes fried in Slices or Shavings", which instructs readers to "peel large potatoes, slice them about a quarter of an inch thick, or cut them in shavings round and round, as you would peel a lemon; dry them well in a clean cloth, and fry them in lard or dripping". The earliest reference of the potato chip in the United States is in Mary Randolph's "The Virginia House-Wife" (1824), which includes a recipe explicitly derived from Kitchiner's earlier cookbook. Boston Housekeeper N.K.M. Lee's cookbook, "The Cook's Own Book" (1832), also contains a recipe for the potato chip that references Kitchiner's cookbook.
American author Brian D'Ambrosio writes, "William Kitchiner's "The Cook's Oracle" includes a recipe for what can only be described as a potato chip. Whether one called it a potato chip or not, it would seem that a thinly sliced potato cooked in hot oil and served sprinkled with salt existed before George Crum or his sister Katie Speck Wicks "invented" the potato chip."
In the 20th century, potato chips spread beyond chef-cooked restaurant fare and began to be mass-produced for home consumption. The Dayton, Ohio-based Mike-sell's Potato Chip Company, founded in 1910, identifies as the "oldest potato chip company in the United States". New England-based Tri-Sum Potato Chips, originally founded in 1908 as the Leominster Potato Chip Company, in Leominster, Massachusetts claim to be America's first potato chip manufacturer. Chips sold in markets were usually sold in tins or scooped out of storefront glass bins and delivered by horse and wagon. The early potato chip bag was wax paper with the ends ironed or stapled together. At first, potato chips were packaged in barrels or tins, which left chips at the bottom stale and crumbled.
Laura Scudder, an entrepreneur in Monterey Park, California started having her workers take home sheets of wax paper to iron into the form of bags, which were filled with chips at her factory the next day. This pioneering method reduced crumbling and kept the chips fresh and crisp longer. This innovation, along with the invention of cellophane, allowed potato chips to become a mass market product. Today, chips are packaged in plastic bags, with nitrogen gas blown in prior to sealing to lengthen shelf life, and provide protection against crushing.
Flavored chips.
In an idea originated by the Smiths Potato Crisps Company Ltd, formed in 1920, Frank Smith packaged a twist of salt with his chips in greaseproof paper bags, which were sold around London.
The potato chip remained otherwise unseasoned until an innovation by Joe "Spud" Murphy, the owner of an Irish chip company called Tayto, who in the 1950s developed a technology to add seasoning during manufacture. After some trial and error, Murphy and his employee, Seamus Burke, produced the world's first seasoned chips: Cheese & Onion, Barbecue, and Salt & Vinegar. This innovation was notable in the food industry. Companies worldwide sought to buy the rights to Tayto's technique.
Concurrently, the first flavored chips in the United States, barbecue flavor, were being manufactured and sold by 1954. There is no agreement on which company was the first company to manufacture these chips, or if this development had predated the introduction of season chips in Europe. In 1958, Herr's was the first company to introduce barbecue-flavored potato chips in Pennsylvania.
Nomenclature.
There is little consistency in the English-speaking world for names of fried potato slices, thick or thin. American and Canadian English use "chips" for the above-mentioned dish — this term is also used (but not universally) in other parts of the world, due to the influence of American culture — and sometimes "crisps" for the same made from batter.
In the United Kingdom and Ireland, "crisps" are potato chips which are eaten cold, whilst "chips" are similar to french fries (as in "fish and chips") and are served hot. In Australia, some parts of South Africa, New Zealand, India, the general West Indies especially in Barbados, both forms of potato product are simply known as "chips", as are the larger "home-style" potato crisps. In the north of New Zealand, they are known as "chippies" but are marketed as "chips" throughout the country. In Australia and New Zealand, sometimes the distinction is made between "hot chips" (fried potatoes) and "potato chips". In Bangladesh, they are generally known as "chip" or "chips", and much less frequently as "crisps" (pronounced "kirisp") and locally, "Álu Bhaja" (for their similarity to the native potato bhajji).
In countries of the former SFR Yugoslavia, fried thin potato slices are known as "chips" (locally pronounced very similar to the actual English pronunciation), with a clear distinction from french fries. In Brazil, "home-style" potato chips are known as "batatas portuguesas" ("Portuguese potatoes") if their sides are relatively smooth and "batatas prussianas" ("Prussian potatoes") if their sides show a wafer biscuit-like pattern, whilst American-like industrial uniform potato chips made from a fried potato purée-based dough are known as "batata chips" (""chips" potato", alike "shredded potato"), or just "chips".
Health concerns.
Potato chips were originally deep-fried in lard and seasoned with salt. Later other fats were used, including vegetable oils and trans fats, the latter identified as having such serious adverse health effects they have been phased out by many manufacturers in the 21st century. Following concerns about nutrition, and the 20th-century formulation of Dietary Reference Intake guidelines in the US and Canada and similar guidelines in various countries, for decades consumers, advocacy groups, and health organizations have focused on the nutritional value (or lack thereof) of junk foods, including potato chips.
A recent long-term study determined that potato chip consumption was the greatest contributor to weight gain, having a stronger effect on weight gain than consumption of potatoes and soft drinks.
Some potato chip companies have responded to the criticism by investing in research and development to modify existing recipes and create health-conscious products. Kettle Foods was founded in 1978 and currently sells only trans fat–free products, including potato chips. PepsiCo research shows that approximately 80% of salt on chips is not sensed by the tongue before being swallowed. Frito-Lay spent $414 million in 2009 on product development, including development of salt crystals that would reduce the salt content of Lay's potato chips without adversely affecting flavor.
A big concern about the nutrition of potato chips is that because they are usually made with salt, they contain substantial levels of sodium. This had been linked to health issues such as high blood pressure, and potato chips' taste appeal caused people to overeat and become obese. But, researchers at Queen Mary, University of London in 2004 noted that a small "bag of ready-salted crisps" contains less salt than a serving of "Special K, All-Bran, Golden Grahams, Cheerios, Shreddies and every brand of cornflakes on sale in the UK."
Some chip vendors offer chips that have been baked instead of fried. Although these chips offer much lower fat content, many of the commercially produced baked potato chips contained more sodium than their fried counterpart from the same manufacturer. A better alternative is to bake your own potato chips and lower the sodium content by adding less or no salt.
There is also the option of non-ready-salted chips, e.g. the longstanding British brand Salt 'n' Shake, whose chips are not seasoned, but instead include a small salt sachet in the bag, such that the chips can be salted as much or as little as the purchaser would like.
Similar foods.
Another type of potato chip, notably the Pringles and Lay's Stax brands, is made by extruding or pressing a dough made from ground potatoes into the desired shape before frying. This makes chips that are uniform in size and shape, which allows them to be stacked and packaged in rigid tubes. In America, the official term for Pringles is "potato crisps", but they are rarely referred to as such. Conversely Pringles may be termed "potato chips" in Britain, to distinguish them from traditional "crisps". Munchos, another brand that uses the term "potato crisps", has deep air pockets in its chips that give it a curved shape, though the chips themselves resemble regular bagged chips.
An additional variant of potato chips exists in the form of "potato sticks", also called "shoestring potatoes". These are made as extremely thin (2–3 mm) versions of the popular French fry, but are fried in the manner of regular salted potato chips. A hickory-smoke flavor version is popular in Canada, going by the vending machine name "Hickory Sticks". Potato sticks are typically packaged in rigid containers, although some manufacturers use flexible pouches, similar to potato chip bags. Potato sticks were originally packed in hermetically sealed steel cans. In the 1960s, manufacturers switched to the less expensive composite canister (similar to the Pringle's container). Reckitt Benckiser was a market leader in this category under the "Durkee" Potato Stix and French's Potato Sticks names, but exited the business in 2008.
A larger variant (approximately 1 cm thick) made with dehydrated potatoes is marketed as Andy Capp's Pub Fries, using the theme of a long-running British comic strip, which are baked and come in a variety of flavors.
Walkers make a similar product (using the Smiths brand) called "Chipsticks" which come in Ready Salted and Salt and Vinegar flavors.
Some companies have also marketed baked potato chips as an alternative with lower fat content. Additionally, some varieties of fat-free chips have been made using artificial, and indigestible, fat substitutes. These became well known in the media when an ingredient many contained, Olestra, was linked in some individuals to abdominal discomfort and loose stools.
The success of crisp fried potato chips also gave birth to fried corn chips, with such brands as Fritos, CC's and Doritos dominating the market. "Swamp chips" are similarly made from a variety of root vegetables, such as parsnips, rutabagas and carrots. Japanese-style variants include extruded chips, like products made from rice or cassava. In South Indian snack cuisine, there is an item called "HappLa" in Kannada/"vadam" in Tamil, which is a chip made of an extruded rice/sago or multigrain base that has been around for many centuries.
There are many other products which might be called "crisps" in Britain, but would not be classed as "potato chips" because they aren't made with potato and/or aren't chipped (for example, Wotsits, Quavers, Skips, Hula Hoops and Monster Munch).
Kettle-style chips (known as hand-cooked in the UK/Europe) are traditionally made by the "batch-style" process, where all chips are fried all at once at a low temperature profile, and continuously raked to prevent them from sticking together. There has been some development recently where kettle-style chips are able to be produced by a "continuous-style" process (like a long conveyor belt), creating the same old-fashioned texture and flavor of a real kettle-cooked chip.
Non-potato based chips also exist. Kumara (sweet potato) chips are eaten in Korea, New Zealand and Japan; parsnip, beetroot and carrot crisps are available in the United Kingdom. India is famous for a large number of localized 'chips shops', selling not only potato chips but also other varieties such as plantain chips, tapioca chips, yam chips and even carrot chips. Plantain chips, also known as chifles or tostones, are also sold in the Western Hemisphere from Canada to Chile. In the Philippines, banana chips can be found sold at local stores. In Kenya, chips are made even from arrowroot and casava. In the United Kingdom, Sweden, Finland and Australia, a new variety of Pringles made from rice have been released and marketed as lower in fat than their potato counterparts.

</doc>
<doc id="24853" url="http://en.wikipedia.org/wiki?curid=24853" title="Political media">
Political media

Political media are communication vehicles owned, ruled, managed, or otherwise influenced by political entities, meant to propagate views of the related entity. A similar term, "normative media", emphasizes technical and social characteristics of the media itself in shaping decisions. Harold Innis and later Marshall McLuhan,both Canadian media theorists, were influential in developing this theory.
While it is simple to recognize a political medium in an official newspaper, magazine, TV channel that directly declares to belong to a group, deep concerns might regard submission of communications to political interests and impartiality of media that do not declare their party alliances. This influence is not always conspicuous and causes people to accept ideas put forth by those who wish to control communication for the good of society, or causes those who support freedom of communication and minority empowerment to oppose them.
Some believe that big societies actually need to canalize communication. In this sense political media would often be meant to form or at least influence public opinion, a least-common-denominator for all members of society. They are a one-way street and sometimes misused. The Greeks could learn from the Egypt of the Pharaos that some risks could be suffered when "medium" and executives occur in personal union, concentrating too much power in one hand. This, however, implies the acceptation of a concept of media as power, which is widely but not generally shared. Opponents do argue that the simple fact of producing a communication is not by itself leading to a direct result on the public opinion, unless this one is considered as a merely passive mass in front of an irresistible communication...
Modern Democratic theories and implementations, especially after Montesquieu's theories, rely on the separation of powers: Executive (government and police), legislative (parliament) and judicial (court) branches of power are separated. Commonly in recent times, and especially in journalistic jargon, media are however defined as an alleged fourth power, and a difference from the others is often outlined in the fact that the power to (eventually) influence the public opinion using media is not much controlled, because media are so "ethereal", and it would be hard to weight them. Others instead suggest that this would not be a difference, since the control over official powers is extremely hard to be verified in practice. Often it is not easy, indeed, to find out who really controls a medium and how much potential efficacy it effectively could have for such goals. It is then argued that when one of the three "canonic" Montesquieu's powers gains an additional power on media, this would be extremely dangerous for the survival of democracy, and an eventual conflict of interests is contested.
As a matter of fact, private media companies became very powerful since the invention of the printing press, cinema, radio and TV, and in history the age of "amanuenses" (the manual copysts of Middle Ages) is perhaps characteristic in demonstrating the attention that usually official powers attribute to communication. Back to our times, in some cases people in media careers have been previously selected by ruling apparatus, and often openly declared their political beliefs, admitting a lack of impartiality. Their work has sometimes been seen as becoming a part of the executive or parliamentar communication.
It is indeed very often said that media could be useful (in the point of view of someone looking for a control over the forming of consensus) in order to discipline the popular sentiments, by detracting the public from the apocalyptic problems of mankind (e.g. global warming, ozone hole, radioactive waste, ...), and by the "psychological warfare" threatening their own public until it accepts foreign or external interventions. But, as said, this needs to encounter an audience mainly composed by people without sufficient means to "resist" this intellectual pression. The lack of a sufficient individual education, due to a perhaps intentionally provoked low quality of school, is then considered one of the major reasons for the success of such attempts.
Education is by some included in social media, and in this sense it could eventually be used as a powerful mean to introduce in individuals some "politically useful" concepts: what a man learns in his youth, in the phasis in which the fundaments of character are created (which many believe will seldom greatly vary after), is brought to him by family, schools and other clubs, and mass media. Apart from the studies of facts, education could be used (some suggest) as a mean for conditioning, usually practiced by emotional and mechanical learning. Education could be then interwoven with political media, although the respective effects of a conditioning in these two fields might be much different, in the average (and admitting many exceptions) for different classes of society. This matter is however very hard to distinguish from a cultural bias, which is a common argument for "ordinary" media too.
The power of technology is also be recalled sometimes, since western civilizations use media to carry forth knowledge and enable technical progression. Some civilization critics point out that modern societies rely on technology to invent and promote new technology, often resulting in a degree of pro-technology propaganda, and this backpropagation would mean that mankind hands over control to a living machine. As with any self-reproducing system, this dynamic makes it hard to control. Some view this as leading to the so-called technological singularity as persuasion technology advocates the creation of more persuasion technology until all are persuaded to do nothing but work on improving technology - handing effective control of society to it.
At present, however, many view this process as being benevolent - the internet is both a mass and a personal medium, flexible and scalable. The internet enables a way of communication which was impossible to be foreseen in past societies.As McLuhan has written, "In this electric age we see ourselves being translated more and more into the form of information, moving toward the technological extension of consciousness (McLuhan, 86)." The software could potentially allow to cement structures which stand against democracy and competition of ideas, as well as structures which could gain a quite complete control over private communications and isolate eventual dissenting voices. Currently the Net is not completely identifiable as a political medium, given the lack of a central authority and a common political communication. Locally, governments could in the reality use censorship, the first experiments of which have been received with relatively little scandal. 
References.
McLuhan, Marshall. "Understanding Media: The Extensions of Man." Giddings, Seth and Martin Lister. The New Media and Technocultures Reader. New York: Routledge, 2011. 79-91. Document.
See also: anti-globalization movement, Indymedia, Wikimedia, Second Superpower

</doc>
<doc id="24856" url="http://en.wikipedia.org/wiki?curid=24856" title="Prohibition">
Prohibition

Prohibition is the legal act of prohibiting the manufacture, storage in barrels, bottles, transportation and sale of alcohol including alcoholic beverages. The term can also apply to periods in the histories of countries during which the prohibition of alcohol was enforced.
History.
The earliest records of prohibition of alcohol date to the Xia Dynasty (ca. 2070 BC–ca. 1600 BC) in China. Yu the Great, the first ruler of the Xia Dynasty, prohibited alcohol throughout the kingdom. It was legalized again after his death, during the reign of his son Qi. 
Another record was in the Code of Hammurabi (ca.1772 BCE) specifically banning the selling of beer for money. It could only be bartered for barley: "If a beer seller do not receive barley as the price for beer, but if she receive money or make the beer a measure smaller than the barley measure received, they shall throw her into the water." (from Pearson textbook "Arts and Culture, An Introduction to the Humanities", Volume One, Fourth Edition, Benton & DiYanni, pg. 16).
In the early twentieth century, much of the impetus for the prohibition movement in the Nordic countries and North America came from moralistic convictions of pietistic Protestants. Prohibition movements in the West coincided with the advent of women's suffrage, with newly empowered women as part of the political process strongly supporting policies that curbed alcohol consumption.
The first half of the 20th century saw periods of prohibition of alcoholic beverages in several countries:
After several years, prohibition became a failure in North America and elsewhere, as rum-running became widespread and organized crime took control of the distribution of alcohol. Distilleries and breweries in Canada, Mexico and the Caribbean flourished as their products were either consumed by visiting Americans or illegally exported to the United States. Chicago became notorious as a haven for prohibition dodgers during the time known as the Roaring Twenties. Prohibition generally came to an end in the late 1920s or early 1930s in most of North America and Europe, although a few locations continued prohibition for many more years.
In some countries where the dominant religion forbids the use of alcohol, the production, sale, and consumption of alcoholic beverages is prohibited or restricted today. For example, in Saudi Arabia and Libya alcohol is banned; in Pakistan and Iran it is illegal with exceptions.
Asia.
Afghanistan.
Sale of Alcohol is banned in Afghanistan
Bangladesh.
In Bangladesh, alcohol is generally prohibited due to its proscription in the Islamic faith. However, the purchase and consumption is allowed for non-Muslims in the country such as the Garo tribe who consume a type of rice beer. Additionally, Christians drink and purchase alcohol for their holy communion.
Brunei.
In Brunei, alcohol consumption in public and sale of alcohol is banned. Non-Muslims are allowed to purchase a limited amount of alcohol from their point of embarkation overseas for their own private consumption, and non-Muslims who are at least the age of 18 are allowed to bring in not more than two bottles of liquor (about two litres) and twelve cans of beer per person into the country.
India.
 In India alcohol is a state subject and individual states can legislate prohibition, but currently most states do not have prohibition. Prohibition is in force in the states of Gujarat and Nagaland, parts of Manipur, and the union territory of Lakshadweep. The state of Kerala has placed some limitations on sale of alcohol. All other States and union territories of India permit the sale of alcohol.
Election days and Certain national holidays such as "Gandhi Jayanti" (birthdate of Mahatma Gandhi) are meant to be "dry days" when liquor sale is not permitted. The state of Andhra Pradesh had imposed Prohibition under the Chief Ministership of N. T. Rama Rao but this was thereafter lifted. Prohibition was also observed from 1996 to 1998 in Haryana. Some Indian states observe dry days on major religious festivals/occasions depending on the popularity of the festival in that region.
Iran.
Since the 1979 Islamic Revolution, the sale and consumption of alcohol is banned in Iran
Maldives.
The Maldives ban the import of alcohol, x-raying all baggage on arrival. Alcoholic beverages are available only to foreign tourists on resort islands and may not be taken off the resort.
Pakistan.
Pakistan allowed the free sale and consumption of alcohol for three decades from 1947, but restrictions were introduced by Zulfikar Ali Bhutto just weeks before he was removed as prime minister in 1977. Since then, only members of non-Muslim minorities such as Hindus, Christians and Zoroastrians are allowed to apply for alcohol permits. The monthly quota is dependent upon one's income, but usually is about five bottles of liquor or 100 bottles of beer. In a country of 180 million, only about 60 outlets are allowed to sell alcohol. The Murree Brewery in Rawalpindi was once the only legal brewery, but today there are more. The ban officially is enforced by the country's Islamic Ideology Council, but it is not strictly policed. Members of religious minorities, however, often sell their liquor permits to Muslims as part of a continuing black market trade in alcohol.
Philippines.
There are only restrictions during elections in the Philippines. Alcohol is prohibited to be bought two days prior to an election. The Commission on Elections may opt to extend the period of time of the liquor ban. In the 2010 elections, the liquor ban was on a minimum two days; in the 2013 elections, there was a proposal that it be extended to five days. This was overturned by the Supreme Court.
Other than election-related prohibition, alcohol is freely sold to anyone above the legal drinking age.
Thailand.
Alcohol is prohibited from being sold during election time, from 6pm the day prior to voting, until the end of the day of voting itself. Alcohol is also prohibited on major Buddhist holy days, and sometimes on Royal Commemoration days, such as birthdays.
Kuwait.
Kuwait bans alcohol, only small quantities are available on the black market.
Saudi Arabia.
Saudi Arabia bans alcohol.
Yemen.
Yemen bans alcohol.
Europe.
Czech Republic.
On 14 September 2012, the government of the Czech Republic banned all sales of liquor with more than 20% alcohol. From this date on it was illegal to sell (and/or offer for sale) such alcoholic beverages in shops, supermarkets, bars, restaurants, gas stations, e-shops etc. This measure was taken in response to the wave of methanol poisoning cases resulting in the deaths of 18 people in the Czech Republic. Since the beginning of the "methanol affair" the total number of deaths has increased to 25. The ban was to be valid until further notice, though restrictions were eased towards the end of September. The last bans on Czech alcohol with regard to the poisoning cases were lifted on 10 October 2012, when neighbouring Slovakia and Poland allowed its import once again.
Nordic countries.
The Nordic countries, with the exception of Denmark, have had a strong temperance movement since the late 1800s, closely linked to the Christian revival movement of the late 19th century, but also to several worker organisations. As an example, in 1910 the temperance organisations in Sweden had some 330,000 members, which was 6% of a population of 5.5 million. Naturally, this heavily influenced the decisions of Nordic politicians in the early 20th century.
Already in 1907, the Faroe Islands passed a law prohibiting all sale of alcohol, which was in force until 1992. However, very restricted private importation from Denmark was allowed from 1928.
In 1914, Sweden put in place a rationing system, the Bratt System, in force until 1955. However a referendum in 1922 rejected an attempt to enforce total prohibition.
In 1915, Iceland instituted total prohibition. The ban for wine and spirits was lifted in 1935, but beer remained prohibited until 1989.
In 1916, Norway prohibited distilled beverages, and in 1917 the prohibition was extended to also include fortified wine and beer. The wine and beer ban was lifted in 1923, and in 1927 the ban of distilled beverages was also lifted.
In 1919, Finland enacted prohibition, as one of the first acts after independence from the Russian Empire. Four previous attempts to institute prohibition in the early 20th century had failed due to opposition from the tsar. After a development similar to the one in the United States during its prohibition, with large-scale smuggling and increasing violence and crime rates, public opinion turned against the prohibition, and after a national referendum where 70% voted for a repeal of the law, prohibition was ended in early 1932.
Today, all Nordic countries (with the exception of Denmark) continue to have strict controls on the sale of alcohol which is highly taxed (dutied) to the public. There are government monopolies in place for selling spirits, wine and stronger beers in Norway (Vinmonopolet), Sweden (Systembolaget), Iceland (Vínbúðin), the Faroe Islands (Rúsdrekkasøla landsins) and Finland (Alko). Bars and restaurants may, however, import alcoholic beverages directly or through other companies.
Greenland, which is part of the kingdom of Denmark does not share its easier controls on the sale of alcohol.
Russian Empire and Soviet Union.
In the Russian Empire, a limited version of a Dry Law was introduced in 1914. It continued through the turmoil of the Russian Revolution of 1917 and the Russian Civil War into the period of Soviet Russia and the Soviet Union until 1925.
United Kingdom.
Although the sale or consumption of commercial alcohol has never been prohibited by law, historically various groups in the UK have campaigned for the prohibition of alcohol, including the Society of Friends (Quakers), The Methodist Church and other non-conformist Christians, as well as temperance movements such as Band of Hope and temperance Chartist movements of the 19th century.
Formed in 1853 and inspired by the Maine law in the USA, the United Kingdom Alliance aimed at promoting a similar law prohibiting the sale of alcohol in the UK. This hard-line group of prohibitionists was opposed by other temperance organisations who preferred moral persuasion to a legal ban. This division in the ranks limited the effectiveness of the temperance movement as a whole. The impotence of legislation in this field was demonstrated when the Sale of Beer Act 1854 which restricted Sunday opening hours had to be repealed, following widespread rioting. In 1859 a prototype prohibition bill was overwhelmingly defeated in the House of Commons.
North America.
Canada.
An official, but non-binding, federal referendum on prohibition was held in 1898. Prime Minister Wilfrid Laurier's government chose not to introduce a federal bill on prohibition, mindful of the strong antipathy in Quebec. As a result, Canadian prohibition was instead enacted through laws passed by the provinces during the first twenty years of the 20th century. The provinces repealed their prohibition laws, mostly during the 1920s.
Mexico.
Zapatista Communities often ban alcohol as part of a collective decision. This has been used by many villages as a way to decrease domestic violence and has generally been favored by women. However, this is not recognized by federal Mexican law as the Zapatista movement is strongly opposed by the federal government.
The sale and purchase of alcohol is prohibited on and the night before certain national holidays, such as "Natalicio de Benito Juárez" (birthdate of Benito Juárez) and "Día de la Revolución", which are meant to be dry nationally. The same "dry law" applies to the days before presidential elections every six years.
United States.
Prohibition focused on the manufacture, transportation, and sale of alcoholic beverages; however, exceptions were made for medicinal and religious uses. Alcohol consumption was never illegal under federal law. Nationwide prohibition did not begin in the United States until January 1920, when the Eighteenth Amendment to the U.S. Constitution went into effect, and was repealed in 1933, with the ratification of the Twenty-first Amendment. 
Concern over excessive alcohol consumption began during the American colonial era, when fines were imposed for drunken behavior and for selling liquor without a license. In the eighteenth century, when drinking was a part of everyday American life, Protestant religious groups, especially the Methodists, and health reformers, including Benjamin Rush and others, urged Americans to curb their drinking habits for moral and health reasons. In particular, Benjamin Rush believed Americans were drinking hard spirits in excess, so he created "A Moral and Physical Thermometer," displaying the progression of behaviors caused by the consumption of various alcohols. By the 1840s the temperance movement was actively encouraging individuals to reduce alcohol consumption. Many took a pledge of total abstinence (teetotalism) from drinking distilled liquor as well as beer and wine. Prohibition remained a major reform movement from the 1840s until the 1920s, when nationwide prohibition went into effect, and was supported by evangelical Protestant churches, especially the Methodists, Baptists, Presbyterians, Disciples of Christ, and Congregationalists. Kansas and Maine were early adopters of statewide prohibition. Following passage of the Maine law, Delaware, Ohio, Illinois, Rhode Island, Minnesota, Massachusetts, Connecticut, Pennsylvania, and New York, among others, soon passed statewide prohibition legislation; however, a number of these laws were overturned.
As temperance groups continued to promote prohibition, other groups opposed increased alcohol restrictions. For example, Chicago's citizens fought against enforcing Sunday closings laws in the 1850s, which included mob violence. It was also during this time when patent medicines, many of which contained alcohol, gained popularity. During the American Civil War efforts at increasing federal revenue included imposition of taxes on liquor and beer. The liquor industry responded to the taxes by forming an industry lobby, the United States Brewers Association, that succeeded in reducing the tax rate on beer from $1 to 60 cents. The Women's Crusade of 1873 and the Women's Christian Temperance Union (WCTU), founded in 1874, "marked the formal entrance of women into the temperance movement." It was also the first time that women had organized and acted together politically, using their influence to fight against the drunken culture of the time. Organizations such as the Women's Christian Temperance Movement would set the stage for women to organize and demand political action as a group with common interests and common goals. The WCTU and the Prohibition Party, organized in 1869, remained major players in the temperance movement until the early twentieth century, when the Anti-Saloon League, formed in 1895, emerged as the movement's leader.
Between 1880 and 1890, although several states enacted local option laws that allowed counties or towns to go dry by referendum, only six states had statewide prohibition by state statute or constitutional amendment. The League, with the support of evangelical Protestant churches including the Episcopalians and Lutherans, and other Progressive-era reformers continued to press for prohibition legislation. Opposition to prohibition was strong in America's urban industrial centers, where a large, immigrant, working-class population generally opposed it, as did Jewish and Catholic religious groups. In the years leading up to World War I, nativism, American patriotism, distrust of immigrants, and anti-German sentiment became associated with the prohibition movement. Through the use of pressure politics on legislators, the League and other temperance reformers achieved the goal of nationwide prohibition by emphasizing the need to destroy the moral corruption of the saloons and the political power of the brewing industry, and to reduce domestic violence in the home. By 1913 nine states had stateside prohibition and thirty-one others had local option laws in effect, which included nearly fifty percent of the U.S. population. At that time the League and other reformers turned their efforts toward attaining a constitutional amendment and grassroots support for nationwide prohibition.
In December 1917, after two previous attempts had failed (one in 1913; the other in 1915), Congress approved a resolution to submit a constitutional amendment on nationwide prohibition to the states for ratification. The new constitutional amendment prohibited "the manufacture, sale, or transportation of intoxicating liquors within, the importation thereof into, or the exportation thereof from the United States and all territory subject to the jurisdiction thereof for beverage purposes". On January 8, 1918, Mississippi became the first state to ratify the amendment, and on January 16, 1919, Nebraska became the thirty-sixth state to ratify it, assuring is passage into federal law. On October 28, 1919, Congress passed the National Prohibition Act, also known as the Volstead Act, which provided enabling legislation to implement the Eighteenth Amendment. When the National Prohibition Act was passed on October 28, 1919, thirty-three of the forty-eight states were already dry. Congress ratified the Eighteenth Amendment on January 16, 1920, and nationwide prohibition began on January 17, 1920.
During the first years of Prohibition, the new federal law was enforced in regions such as the rural South and western states, where it had popular support; however, in large urban cities and in small industrial or mining towns, residents defied or ignored the law. The Ku Klux Klan was a major supporter of the Prohibition and once it was passed they helped with the enforcement of it. For example, in 1923, Klansmen traded pistol shots with bootleggers, burned down roadhouses, and whipped liquor sellers, and anybody else who broke the moral code. The Prohibition was effective in reducing per-capita consumption, and consumption remained lower for a quarter-century after Prohibition had been repealed. Sale of alcoholic beverages remained illegal during Prohibition, but alcoholic drinks were still available. Large quantities of alcohol were smuggled into the United States from Canada, over land, by sea routes along both ocean coasts, and through the Great Lakes. While the federal government cracked down on alcohol consumption on land within the United States, it was a different story along the U.S. coastlines, where vessels outside the 3-mile limit were exempt. In addition, home brewing was popular during Prohibition. Malt and hops stores popped up across the country and some former breweries turned to selling malt extract syrup, ostensibly for baking and beverage purposes.
Prohibition became increasingly unpopular during the Great Depression. Some believe that the demand for increased employment and tax revenues during this time brought an end to Prohibition. Others argue it was the result the economic motivations of American businessmen as well as the stress and excesses of the era that kept it from surviving, even under optimal economic conditions.
Repeal.
The repeal movement was initiated and financed by the Association Against the Prohibition Amendment, who worked to elect Congressmen who agreed to support repeal. The group's wealthy supporters included John D. Rockefeller, Jr., S. S. Kresge, and the Du Pont family, among others, who had abandoned the dry cause. Pauline Sabin, a wealthy Republican who founded the Women's Organization for National Prohibition Reform (WONPR), argued that Prohibition should be repealed because it made the United States a nation of hypocrites and undermined its respect for the rule of law. This hypocrisy and the fact that women had initially led the prohibition movement convinced Sabin to establish the WONPR. Their efforts eventually led to the repeal of prohibition.
When Sabin's fellow Republicans would not support her efforts, she went to the Democrats, who switched their support of the dry cause to endorse repeal under the leadership of liberal politicians such as Fiorello La Guardia and Franklin D. Roosevelt. Sabin and her supporters emphasized that repeal would generate enormous sums of much-needed tax revenue, and weaken the base of organized crime.
Repeal of Prohibition was accomplished with the ratification of the Twenty-first Amendment on December 5, 1933. Under its terms, states were allowed to set their own laws for the control of alcohol. Following repeal, public interest in an organized prohibition movement dwindled. However, it survived for a while in a few southern and border states. To this day, however, there are still counties and parishes within the US known as "dry", where the sale of liquor (whiskey, wine) -not beer- is prohibited; several such municipalities have adopted liquor-by-the-drink, however in order to expand tax revenue.
Al Capone.
Al Capone was the most notorious gangster of his generation. Born on January 17, 1899 in Brooklyn, New York; Capone settled in Chicago to take over Johnny Torrio's business dealing with outlawed liquor. Within three years, Capone had nearly 700 men at his disposal. As the profits came in, Capone acquired finesse—particularly in the management of politicians. By the middle of the decade, he had gained control of the suburb of Cicero, and had installed his own mayor. Capone's rise to fame did not come without bloodshed. Rival gangs, such as the Gennas and the Aiellos, started wars with Capone, eventually leading to a rash of killings of proportions. In 1927, Capone and his gang were pulling in approximately $60 million per year- most of it from beer. Capone not only controlled the sale of liquor to over 10,000 speakeasies, but he also controlled the supply from Canada to Florida. Capone was imprisoned for tax violations and died January 25, 1947, from a heart attack and pneumonia.
South America.
Venezuela.
In Venezuela, twenty-one hours before every election, the government prohibits the sale and distribution of alcoholic beverages throughout the national territory, including the restriction to all dealers, liquor stores, supermarkets, restaurants, wineries, pubs, bars, public entertainment, clubs and any establishment that markets alcoholic beverages. This is done to prevent violent alcohol induced confrontations because of the high political polarization. The same is done during the holy week as a measure to reduce the alarming rate of road traffic accidents during these holidays.
Oceania.
Australia.
More recently, alcohol has been prohibited in many remote indigenous communities. Penalties for transporting alcohol into these "dry" communities are severe and can result in confiscation of any vehicles involved; in dry areas within the Northern Territory, all vehicles used to transport alcohol are seized.
New Zealand.
In New Zealand, prohibition was a moralistic reform movement begun in the mid-1880s by the Protestant evangelical and Nonconformist churches and the Woman's Christian Temperance Union and after 1890 by the Prohibition League. It assumed that individual virtue was all that was needed to carry the colony forward from a pioneering society to a more mature one, but it never achieved its goal of national prohibition. However, both the Church of England and the largely Irish Catholic Church rejected prohibition as an intrusion of government into the church's domain, while the growing labor movement saw capitalism rather than alcohol as the enemy.
Reformers hoped that the women's vote, in which New Zealand was a pioneer, would swing the balance, but the women were not as well organized as in other countries. Prohibition had a majority in a national referendum in 1911, but needed a 60% vote to pass. The movement kept trying in the 1920s, losing three more referenda by close votes; it managed to keep in place a 6pm closing hour for pubs and Sunday closing. The Depression and war years effectively ended the movement.
Elections.
In many countries in Latin America, the Philippines, Turkey and several US states, the sale but not the consumption of alcohol is prohibited before and during elections.

</doc>
<doc id="24857" url="http://en.wikipedia.org/wiki?curid=24857" title="Phenothiazine">
Phenothiazine

Phenothiazine is an organic compound that occurs in various antipsychotic and antihistaminic drugs. It has the formula S(C6H4)2NH. This yellow tricyclic compound is soluble in acetic acid, benzene, and ether. The compound is related to the thiazine-class of heterocyclic compounds. Derivatives of the parent compound find wide use as drugs.
Synthesis.
The compound was originally prepared by Bernthsen in 1883 via the reaction of diphenylamine with sulfur, but more recent syntheses rely on the cyclization of 2-substituted diphenyl sulfides. Some of the pharmaceutically significant derivatives of phenothiazine are not prepared directly from phenothiazine, although some of them are.
Nondrug applications.
The synthetic dye methylene blue, containing the structure, was described in 1876. Phenothiazine itself was introduced by DuPont as an insecticide in 1935. It is sometimes used as an antihelminthic in livestock.
In the manufacture of monomers, phenothiazine is used as a chemical stabilizer or inhibitor to prolong storage and shelf life of products such as acryloyl chloride.
Many water-soluble phenothiazine derivatives, such as methylene blue, methylene green, thionine, and others, can be electropolymerized into conductive polymers used as electrocatalysts for NADH oxidation in enzymatic biosensors and biofuel cells. 
Phenothiazine-derived drugs.
The phenothiazine structure occurs in various neuroleptic drugs, e.g. chlorpromazine, and antihistaminic drugs, e.g. promethazine. 
The term "phenothiazines" describes the largest of the five main classes of neuroleptic antipsychotic drugs. These drugs have antipsychotic and, often, antiemetic properties, although they may also cause severe side effects such as extrapyramidal symptoms (including akathisia and tardive dyskinesia), hyperprolactinaemia, and the rare but potentially fatal neuroleptic malignant syndrome, as well as substantial weight gain.
Phenothiazines are used as inodilators in congestive heart failure, acting upon the type I calcium/calmodulin-dependent phosphodiesterase. 
Phenothiazines, particularly prochlorperazine and chlorpromazine, are also used in emergency rooms to treat migraine and other intractable headaches.
Phenothiazine antipsychotics are classified into three groups that differ with respect to the substituent on nitrogen: the aliphatic compounds (bearing acyclic groups), the "piperidines" (bearing piperidine-derived groups), and the piperazine (bearing piperazine-derived substituents).
Trade Names.
Like many commercially significant compounds, phenothiazine has numerous trade names, including AFI-Tiazin, Agrazine, Antiverm, Biverm, Dibenzothiazine, Orimon, Lethelmin, Souframine, Nemazene, Vermitin, Padophene, Fenoverm, Fentiazine, Contaverm, Fenothiazine, Phenovarm, Ieeno, ENT 38, Helmetina, Helmetine, Penthazine, XL-50, Wurm-thional, Phenegic, Phenovis, Phenoxur, and Reconox.

</doc>
<doc id="24861" url="http://en.wikipedia.org/wiki?curid=24861" title="Pale Fire">
Pale Fire

Pale Fire (1962) is a postmodern novel by Vladimir Nabokov. The novel is presented as a 999-line poem titled "Pale Fire", written by the fictional John Shade, with a foreword and lengthy commentary by a neighbor and academic colleague of the poet, Charles Kinbote. Together these elements form a narrative in which both authors are central characters. "Pale Fire" has spawned a wide variety of interpretations and a large body of written criticism, which Pekka Tammi estimated in 1995 as over 80 studies. The Nabokov authority Brian Boyd has called it "Nabokov's most perfect novel", and the critic Harold Bloom called it "the surest demonstration of his own genius ... that remarkable tour de force". It was ranked at number 53 on the list of the Modern Library 100 Best Novels and number 1 on Larry McCaffery's .
Novel structure.
Starting with the table of contents, "Pale Fire" looks like the publication of a 999-line poem in four cantos ("Pale Fire") by the fictional John Shade with a Foreword, extensive Commentary, and Index by his self-appointed editor, Charles Kinbote. Kinbote's Commentary takes the form of notes to various numbered lines of the poem. Here and in the rest of his critical apparatus, Kinbote explicates the poem surprisingly little. Focusing instead on his own concerns, he divulges what proves to be the plot piece by piece, some of which can be connected by following the many cross-references. Espen Aarseth noted that "Pale Fire" "can be read either unicursally, straight through, or multicursally, jumping between the comments and the poem." Thus although the narration is non-linear and multidimensional, the reader can still choose to read the novel in a linear manner without risking misinterpretation.
The novel's unusual structure has attracted much attention, and it is often cited as an important example of metafiction; it has also been called a poioumenon. The connection between "Pale Fire" and hypertext was stated soon after its publication; in 1969, the information-technology researcher Ted Nelson obtained permission from the novel's publishers to use it for a hypertext demonstration at Brown University. A 2009 paper also compares "Pale Fire" to hypertext.
The interaction between Kinbote and Shade takes place in the fictitious small college town of New Wye, Appalachia, where they live across a lane from each other, from February to July 1959. Kinbote writes his commentary from then to October 1959 in a tourist cabin in the equally fictitious western town of Cedarn, Utana. Both authors recount many earlier events, Shade mostly in New Wye and Kinbote in New Wye and in Europe, especially the "distant northern land" of Zembla.
Plot summary.
Shade's poem digressively describes many aspects of his life. Canto 1 includes his early encounters with death and glimpses of what he takes to be the supernatural. Canto 2 is about his family and the apparent suicide of his daughter, Hazel Shade. Canto 3 focuses on Shade's search for knowledge about an afterlife, culminating in a "faint hope" in higher powers "playing a game of worlds" as indicated by apparent coincidences. Canto 4 offers details on Shade's daily life and creative process, as well as thoughts on his poetry, which he finds to be a means of somehow understanding the universe.
In Kinbote's editorial contributions he tells three stories intermixed with each other. One is his own story, notably including what he thinks of as his friendship with Shade. After Shade was murdered, Kinbote acquired the manuscript, including some variants, and has taken it upon himself to oversee the poem's publication, telling readers that it lacks only line 1000. Kinbote's second story deals with King Charles II, "The Beloved," the deposed king of Zembla. King Charles escaped imprisonment by Soviet-backed revolutionaries, making use of a secret passage and brave adherents in disguise. Kinbote repeatedly claims that he inspired Shade to write the poem by recounting King Charles's escape to him and that possible allusions to the king, and to Zembla, appear in Shade's poem, especially in rejected drafts. However, no explicit reference to King Charles is to be found in the poem. Kinbote's third story is that of Gradus, an assassin dispatched by the new rulers of Zembla to kill the exiled King Charles. Gradus makes his way from Zembla through Europe and America to New Wye, suffering comic mishaps. In the last note, to the missing line 1000, Kinbote narrates how Gradus killed Shade by mistake.
The reader soon realizes that Kinbote is King Charles, living incognito—or, though Kinbote builds an elaborate picture of Zembla complete with samples of a constructed language, that he is insane and that his identification with King Charles is a delusion, as perhaps all of Zembla is.
Nabokov said in an interview that Kinbote committed suicide after finishing the book. The critic Michael Wood has stated, "This is authorial trespassing, and we don't have to pay attention to it," but Brian Boyd has argued that internal evidence points to Kinbote's suicide. One of Kinbote's annotations to Shade's poem (corresponding to line 493) addresses the subject of suicide at some length.
Explanation of the title.
As Nabokov pointed out himself, the title of John Shade's poem is from Shakespeare's "Timon of Athens:" "The moon's an arrant thief, / And her pale fire she snatches from the sun" (Act IV, scene 3), a line often taken as a metaphor about creativity and inspiration. Kinbote quotes the passage but does not recognize it, as he says he has access only to an inaccurate Zemblan translation of the play "in his Timonian cave", and in a separate note he even rails against the common practice of using quotations as titles.
Some critics have noted a secondary reference in the book's title to "Hamlet", where the Ghost remarks how the glow-worm "'gins to pale his uneffectual fire" (Act I, scene 5).
The title is first mentioned in the foreword: "I recall seeing him from my porch, on a brilliant morning, burning a whole stack of them in the pale fire of the incinerator...".
Initial reception.
The editor of a book of Nabokov criticism states that "Pale Fire" excited as diverse criticism as any of Nabokov's novels. Mary McCarthy's review was extremely laudatory; the Vintage edition excerpts it on the front cover. She tried to explicate hidden references and connections. Dwight Macdonald responded by saying the book was "unreadable" and both it and McCarthy's review were as pedantic as Kinbote. Anthony Burgess, like McCarthy, extolled the book, while Alfred Chester condemned it as "a total wreck".
Some other early reviews were less decided, praising the book's satire and comedy but noting its difficulty and finding its subject slight or saying that its artistry offers "only a kibitzer's pleasure". MacDonald called the reviews he had seen, other than McCarthy's, "cautiously unfavorable". "TIME" magazine's 1962 review stated that "Pale Fire does not really cohere as a satire; good as it is, the novel in the end seems to be mostly an exercise in agility – or perhaps in bewilderment", though this did not prevent "TIME" from including the book in its 2005 list of the 100 best English-Language novels published since 1923.
In the 1980s, after Nabokov's reputation was rehabilitated in the Soviet Union, the novel was translated into Russian by his wife Véra, its dedicatee.
Interpretations.
Some readers concentrate on the apparent story, focusing on traditional aspects of fiction such as the relationship among the characters. In 1997, Brian Boyd published a much-discussed study arguing that the ghost of John Shade influenced Kinbote's contributions. He expanded this essay into a book in which he also argues that, in order to trigger Shade's poem, Hazel Shade's ghost induced Kinbote to recount his Zemblan delusions to Shade.
Some readers, starting with Mary McCarthy and including Boyd, Nabokov's annotator Alfred Appel, and D. Barton Johnson, see Charles Kinbote as an alter-ego of the insane Professor V. Botkin, to whose delusions John Shade and the rest of the faculty of Wordsmith College generally condescend. Nabokov himself endorsed this reading, stating in an interview in 1962 (the novel's year of publication) that "Pale Fire" "is full of plums that I keep hoping somebody will find. For instance, the nasty commentator is not an ex-King of Zembla nor is he professor Kinbote. He is professor Botkin, or Botkine, a Russian and a madman." The novel's intricate structure of teasing cross-references leads readers to this "plum". The Index, supposedly created by Kinbote, features an entry for a "Botkin, V.," describing this Botkin as an "American scholar of Russian descent"—and referring to a note in the Commentary on line 894 of Shade's poem, in which no such person is directly mentioned but a character suggests that "Kinbote" is "a kind of anagram of Botkin or Botkine". In this interpretation, "Gradus" the murderer is an American named Jack Grey who wanted to kill Judge Goldsworth, whose house "Pale Fire's" commentator—whatever his "true" name is—is renting. Goldsworth had condemned Grey to an asylum from which he escaped shortly before mistakenly killing Shade, who resembled Goldsworth.
Other readers see a story quite different from the apparent narrative. "Shadeans" maintain that John Shade wrote not only the poem, but the commentary as well, having invented his own death and the character of Kinbote as a literary device. According to Boyd, Andrew Field invented the Shadean theory and Julia Bader expanded it; Boyd himself espoused the theory for a time. In an alternative version of the Shadean theory, Tiffany DeRewal and Matthew Roth argued that Kinbote is not a separate person but is a dissociated, alternative personality of John Shade. (An early reviewer had mentioned that "a case might be made" for such a reading.)
"Kinboteans", a decidedly smaller group, believe that Kinbote invented the existence of John Shade. Boyd credits the Kinbotean theory to Page Stegner and adds that most of its adherents are newcomers to the book. Some readers see the book as oscillating undecidably between these alternatives, like the Rubin vase (a drawing that may be two profiles or a goblet).
Though a minority of commentators believe or at least accept the possibility that Zembla is as "real" as New Wye, most assume that Zembla, or at least the operetta-quaint and homosexually gratified palace life enjoyed by Charles Xavier before he is overthrown, is imaginary in the context of the story. The name "Zembla" (taken from "Nova Zembla", a former latinization of Novaya Zemlya) may evoke popular fantasy literature about royalty such as "The Prisoner of Zenda". As in other Nabokov books, however, the fiction is an exaggerated or comically distorted version of his own life as a son of privilege before the Russian Revolution and an exile afterwards, and the central murder has resemblances (emphasized by Priscilla Meyer) to Nabokov's father's murder by an assassin who was trying to kill someone else.
Still other readers de-emphasize any sort of "real story" and may doubt the existence of such a thing. In the interplay of allusions and thematic links, they find a multifaceted image of English literature, criticism, or glimpses of a higher world and an afterlife.
Allusions and references.
The first two lines of John Shade's 999-line poem, "Pale Fire", have become Nabokov's most quoted couplet:
<poem>I was the shadow of the waxwing slain
By the false azure in the window pane</poem>
Like many of Nabokov's books, "Pale Fire" alludes to others. "Hurricane Lolita" is mentioned, and Pnin appears as a minor character. There are many resemblances to "Ultima Thule" and "Solus Rex", two short stories by Nabokov intended to be the first two chapters of a novel in Russian that he never continued. The placename Thule appears in "Pale Fire", as does the phrase "solus rex" (a chess problem in which Black has no pieces but the king).
The book is also full of references to culture, nature, and literature. They include:
See also "The Ambidextrous Universe", a later book referencing "Pale Fire" which in turn triggered a reciprocal response in a subsequent Nabokov novel ("", 1969).

</doc>
<doc id="24862" url="http://en.wikipedia.org/wiki?curid=24862" title="Preservative">
Preservative

A preservative is a substance that is added to products such as foods, pharmaceuticals, paints, biological samples, wood, etc. to prevent decomposition by microbial growth or by undesirable chemical changes. In general preservation is implemented in two modes, chemical and physical. Chemical preservation entails adding chemical compounds to the product. Physical preservation entails refrigeration and drying. They are used in foods, cosmetics, and many other products. Artificial preservatives reduce the risk of foodborne infections, decrease microbial spoilage, and preserve fresh attributes and nutritional quality. Some physical techniques for preservation include dehydration, UV-C radiation, freeze-drying, and refrigeration. Generally both chemical preservatives and physical preservation are combined.
Antimicrobial additives.
Antimicrobial preservatives prevent degradation by bacteria. This method is the most traditional and ancient type of preserving—ancient methods such as pickling and adding honey prevent microorganism growth by modifying the pH level. The most commonly used antimicrobial preservative is lactic acid. Common antimicrobial preservatives are presented in the table. Nitrates and nitrites are also antimicrobial. The detailed mechanism of these chemical compounds range from inhibiting growth of the bacteria to the inhibition of specific enzymes.
Antioxidants.
The oxidation process spoils most food, especially those with a high fat content. Fats quickly turn rancid when exposed to oxygen. Antioxidants prevent or inhibit the oxidation process. The most common antioxidant additives are ascorbic acid (vitamin C ) and ascorbates. Thus, antioxidants are commonly added to oils, cheese, and chips. Other antioxidants include the phenol derivatives BHA, BHT, TBHQ and propyl gallate. These agents suppress the formation of hydroperoxides. Other preservatives include ethanol and methylchloroisothiazolinone.
A variety of agents are added to sequester (deactivate) metal ions that otherwise catalyze the oxidation of fats. Common sequestering agents are disodium EDTA, citric acid (and citrates), tartaric acid, and lecithin.
Nonsynthetic compounds for food preservation.
Citric and ascorbic acids target enzymes that degrade fruits and vegetables, e.g., phenolase which turns surfaces of cut apples and potatoes brown. Ascorbic acid and tocopherol, which are vitamins, are common preservatives. Smoking entails exposing food to a variety of phenols, which are antioxidants. Natural preservatives include rosemary extract, hops, salt, sugar, vinegar, alcohol, diatomaceous earth and castor oil.
Traditional preservatives such as sodium benzoate have raised health concerns. Benzoate was shown in a study to cause hypersensitivity in some athsma sufferers. This has caused reexamination of natural preservatives which occur in vegetables.
History.
The preservation of foods has evolved greatly over the centuries, and has been instrumental in increasing food security. The use of preservatives other than traditional oils, salts, etc. in food began in the late 19th century, but was not widespread until the 20th century.
The use of food preservatives varies greatly depending on country. Many developing countries that do not have strong governments to regulate food additives face either harmful levels of preservatives in foods, or a complete avoidance of foods that are considered unnatural or foreign. These countries have also proven useful in case studies surrounding chemical preservatives, as they have been only recently introduced. In urban slums of highly populated countries the knowledge about contents of food tends to be extremely low, despite consumption of these imported foods.
Public awareness of food preservation.
Public awareness of food preservatives is uneven. Americans have a perception that food-borne illnesses happen more often in other counties. This may be true, but the occurrence of illnesses, hospitalizations, and deaths are still high. It is estimated by the Center for Disease Control (CDC) that each year there are 76 million illnesses, 325,000 hospitalizations, and 5,000 deaths linked to food-borne illness.
In the U.S., the FDA standards do not currently require fruit and vegetable product labels to reflect the type of chemical preservative(s) used on the produce.
The increasing demand for ready-to-eat fresh food products has led to challenges for food distributors regarding the safety and quality of their foods. Artificial preservatives meet some of these challenges by preserving freshness for longer periods of time, but these preservatives can cause negative side-effects as well. Sodium nitrite is a preservative used in lunch meats, hams, sausages, hot dogs, and bacon to prevent botulism. It serves the important function of controlling the bacteria that cause botulism, but sodium nitrite can react with proteins, or during cooking at high heats, to form carcinogenic N-nitrosamines. It has also been linked to cancer in lab animals. The commonly used sodium benzoate has been found to extend the shelf life of bottled tomato paste to 40 weeks without loss of quality. However, it can form the carcinogen benzene when combined with vitamin C. Many food manufacturers have reformed their products to eliminate this combination, but a risk still exists. Consumption of sodium benzoate may also cause hyperactivity. For over 30 years, there has been a debate about whether or not preservatives and other food additives can cause hyperactivity. Studies have found that there may be increases in hyperactivity amongst children who consume artificial colorings and benzoate preservatives and who are already genetically predisposed to hyperactivity, but these studies were not entirely conclusive. Hyperactivity only increased moderately, and it was not determined if the preservatives, colorings, or a combination of the two were responsible for the increase.

</doc>
<doc id="24863" url="http://en.wikipedia.org/wiki?curid=24863" title="Proteobacteria">
Proteobacteria

The Proteobacteria are a major group (phylum) of bacteria. They include a wide variety of pathogens, such as "Escherichia", "Salmonella", "Vibrio", "Helicobacter", and "Yersinia", and many other notable genera.
Others are free-living (nonparasitic), and include many of the bacteria responsible for nitrogen fixation.
Carl Woese established this grouping in 1987, calling it informally the "purple bacteria and their relatives".
Because of the great diversity of forms found in this group, the Proteobacteria are named after Proteus, a Greek god of the sea capable of assuming many different shapes; it is not named after the genus "Proteus".
Alphaproteobacteria grow at very low levels of nutrients and have unusual morphology such as stalks and buds. They include agriculturally important bacteria capable of inducing nitrogen fixation in symbiosis with plants. An example of alphaproteobacteria is "Wolbachia" which is the most common infectious bacterial genus in the world that lives only inside the cells of their hosts, usually insects. 
Betaproteobacteria often use nutrient substances that diffuse away from areas of anaerobic decomposition of organic matter (hydrogen gas, ammonia, methane) and includes chemoautotrophs. An example of betaproteobacteria is "Bordetella pertussis" which causes pertussis, or whooping cough.
Gammaproteobacteria are the largest subgroup which include "Acinetobacter", "Pseudomonas", "Escherichia coli", "Salmonella", and "Serratia marcescens".
Deltaproteobacteria include bacteria that are predators on other bacteria and are important contributors to the sulfur cycle. An example is "Desulfovibrio" which is found in anaerobic sediments and in the intestinal tracts of humans and animals.
Epsilonproteobacteria are slender Gram-negative rods that are helical or curved. They are also motile by flagella and are microaerophilic. An example is "Helicobacter" which has been identified as the most common cause of peptic ulcers in humans and a cause of stomach cancer.
Characteristics.
All proteobacteria are Gram-negative, with an outer membrane mainly composed of lipopolysaccharides. Many move about using flagella, but some are nonmotile or rely on bacterial gliding. The last include the myxobacteria, a unique group of bacteria that can aggregate to form multicellular fruiting bodies. Also a wide variety in the types of metabolism exists. Most members are facultatively or obligately anaerobic, chemoautotrophs, and heterotrophic, but numerous exceptions occur. A variety of genera, which are not closely related to each other, convert energy from light through photosynthesis. These are called purple bacteria, referring to their mostly reddish pigmentation.
Taxonomy.
The group is defined primarily in terms of ribosomal RNA (rRNA) sequences. The Proteobacteria are divided into six sections, referred to by the Greek letters alpha through zeta. These were previously regarded as subclasses of the phylum, but they are now treated as classes. 
The alpha, beta, delta, and epsilon classes are monophyletic. The genus "Acidithiobacillus", part of the "Gammaproteobacteria" until it was transferred to Class "Acidithiobacillia" in 2013, is paraphyletic to "Betaproteobacteria" according to multigenome alignment studies.

</doc>
<doc id="24864" url="http://en.wikipedia.org/wiki?curid=24864" title="Professional wrestling">
Professional wrestling

Professional wrestling (often shortened pro wrestling, wrestling) is an athletic performance that combines athletics with theatrical performance. It takes the form of events, held by touring companies, which mimic a title match combat sport. The unique form of sport portrayed is fundamentally based on classical and "catch" wrestling, with modern additions of striking attacks, strength-based holds and throws, and acrobatic maneuvers; much of these derive from the influence of various international martial arts. An additional aspect of combat with improvised weaponry is sometimes included to varying degrees.
The matches have predetermined outcomes in order to heighten entertainment value, and all combative maneuvers are executed with the full cooperation of those involved and carefully performed in specific manners intended to lessen the chance of actual injury. These facts were once kept highly secretive but are now a widely accepted open secret. By and large, the true nature of the performance is not discussed by the performing company in official media in order to sustain and promote the willing suspension of disbelief for the audience by maintaining an aura of verisimilitude. Fan communications by individual wrestlers and promotions through outside media (i.e. interviews) will often directly acknowledge the dramatic and "fixed" nature of the spectacle.
History.
Originating as a popular form of entertainment in 19th-century Europe and later as a sideshow exhibition in North American traveling carnivals and vaudeville halls, professional wrestling grew into a standalone genre of entertainment with many diverse variations in cultures around the globe, and is now considered a multi-million dollar entertainment industry. While it has greatly declined in Europe, in North America, it has experienced several different periods of prominent cultural popularity during its century and a half of existence. The advent of television gave professional wrestling a new outlet, and wrestling (along with boxing) was instrumental in making pay-per-view a viable method of content delivery.
Scope and influence.
Unlike in Europe, show wrestling has become especially prominent in Japan and in Central and North America. In Brazil, there was a very popular wrestling television program from the 1960s to the early 1980s called "Telecatch". High-profile figures in the sport have become celebrities or cultural icons in their native or adopted home countries.
Although professional wrestling started out as petty acts in sideshows, traveling circuses and carnivals, today it is a billion-dollar industry. Revenue is drawn from ticket sales, network television broadcasts, pay-per-view broadcasts, branded merchandise and home video. Pro wrestling was instrumental in making pay-per-view a viable method of content delivery. Annual shows such as WrestleMania, SummerSlam, Royal Rumble, and formerly Bash at the Beach, Halloween Havoc & Starrcade are among the highest-selling pay-per-view programming each year. In modern day, internet programming has been utilized by a number of companies to air web shows, internet pay per views (IPPVs) or on-demand content, helping to generate internet-related revenue earnings from the evolving World Wide Web.
Home video sales dominate the Billboard charts Recreational Sports DVD sales, with wrestling holding anywhere from 3 to 9 of the top 10 spots every week.
Due to its persistent cultural presence and to its novelty within the performing arts, wrestling constitutes a recurring topic in both academia and the media. Several documentaries have been produced looking at professional wrestling, most notably, "Beyond the Mat" directed by Barry W. Blaustein, and "" featuring wrestler Bret Hart and directed by Paul Jay. There have also been many fictional depictions of wrestling; the 2008 film "The Wrestler" received several Oscar nominations and began a career revival for star Mickey Rourke.
Currently, the largest professional wrestling company worldwide is the United States-based WWE, which bought out many smaller regional companies in the late 20th century, as well as its primary US competitors World Championship Wrestling (WCW) and Extreme Championship Wrestling (ECW) in early 2001. Other prominent professional wrestling companies worldwide include the US-based Total Nonstop Action Wrestling (TNA) and Ring of Honor (ROH), Consejo Mundial de Lucha Libre and Asistencia Asesoría y Administración in Mexico, and the Japanese New Japan Pro Wrestling, All Japan Pro Wrestling, and Pro Wrestling Noah leagues.
Genre conventions.
When talking about professional wrestling, there are two levels: the "in-show" happenings that are presented through the shows, and happenings which are outside the scope of performance (in other words, are real life) but have implications on the performance, such as performer contracts, legitimate injuries, etc. Because actual events are often co-opted by writers for incorporation into storylines for the performers, the lines are often blurred and become confused.
Special care must be taken when talking about people who perform under their own name. The actions of the character should be considered fictional events, wholly separate from the life of the performer. This is similar to other entertainers who perform with a persona that shares their own name (such as Stephen Colbert and his fictional persona).
Some wrestlers will incorporate elements of their real-life personalities into their characters, even if they and their in-ring persona have different names.
Kayfabe.
Historians are unsure at what point wrestling changed from competitive catch wrestling into worked entertainment. Those who participated felt that maintenance of a constant and complete illusion for all who were not involved was necessary to keep audience interest. For decades, wrestlers lived their public lives as though they were their characters.
The practice of keeping the illusion, and the various methods used to do so, came to be known as "kayfabe" within wrestling circles, or "working the marks". An entire lexicon of slang jargon and euphemism developed to allow performers to communicate without outsiders' knowledge of what was being said.
Occasionally a performer will deviate from the intended sequence of events. This is known as a shoot. Sometimes shoot-like elements are included in wrestling stories to blur the line between performance and reality. These are known as "worked shoots". However, the vast majority of events in professional wrestling are preplanned and improvised within accepted boundaries.
Gradually, the predetermined nature of professional wrestling became an open secret, as prominent figures in the wrestling business (including World Wrestling Entertainment owner Vince McMahon) began to publicly admit that wrestling was entertainment, not competition. This public reveal has garnered mixed reactions from the wrestling community, as some feel that exposure ruins the experience to the spectators as does exposure in illusionism. Despite the public admission of the theatrical nature of professional wrestling, many U.S. states still regulate professional wrestling as they do other professional competitive sports. For example, New York State still regulates "professional wrestling" through the New York State Athletic Commission (SAC).
Aspects of performing art.
Professional wrestling shows can be considered a form of theatre in the round, with the ring, ringside area, and entryway comprising a thrust stage. However, there is a much more limited concept of a fourth wall than in most theatric performances. The audience is recognized and acknowledged by the performers as spectators to the sporting event being portrayed, and are encouraged to interact as such. This leads to a high level of audience participation; in fact, their reactions can dictate how the performance unfolds. Often, individual matches will be part of a longer storyline conflict between "babyfaces" (often shortened to just "faces") and "heels". "Faces" (the "good guys") are those whose actions are intended to encourage the audience to cheer, while "heels" (the "bad guys") act to draw the spectators' ire.
Rules.
There is no governing authority for professional wrestling rules, although there is a general standard which has developed. Each promotion has their own variation, but all are similar enough to avoid confusion most of the time. Any rule described here is simply a standard, and may or may not correspond exactly with any given promotion's ruleset.
It should be noted that, due to the staged nature of wrestling, these are not actual "rules" in the sense that they would be considered in similar articles about actual sports like freestyle wrestling. Instead, the "rules" in this article are implemented and supposedly enforced for the sake of suspension of disbelief (known as kayfabe in the jargon of the business).
General structure.
Matches are held between two or more sides ("corners"). Each corner may consist of one wrestler, or a team of two or more. Most team matches are governed by tag team rules (see below). Other matches are free-for-alls, with multiple combatants but no teams. In all variants, there can be only one winning team or wrestler.
The standard method of scoring is the "fall", which is accomplished by:
These are each explained in greater detail below. Typically, pinfalls and submissions must occur within the ring area, however there are times where it may be stipulated otherwise.
Most wrestling matches last for a set number of falls, with the first side to achieve the majority number of pinfalls, submissions, or countouts being the winner. Historically, matches were wrestled to 3 falls ("best 2 out of 3") or 5 falls ("best 3 out of 5"). The standard for modern matches is one fall. However, even though it is now standard, many announcers will explicitly state this (e.g. "The following contest is set for one fall with a 20-minute time limit."). These matches are given a time limit; if not enough falls are scored by the end of the time limit, the match is declared a draw. Modern matches are generally given a 10- to 30-minute time limit for standard matches; title matches can go for up to one hour. British wrestling matches held under Admiral-Lord Mountevans rules are 2 out of 3 falls.
An alternative is a match set for a prescribed length of time, with a running tally of falls. The entrant with the most falls at the end of the time limit is declared the winner. This is usually for 20, 30 or 60 minutes, and is commonly called an Iron Man match. This type of match can be modified so that fewer types of falls are allowed.
In matches with multiple competitors, an elimination system may be used. Any wrestler who has a fall scored against them is forced out of the match, and the match continues until only one remains. However, it is much more common when more than two wrestlers are involved to simply go one fall, with the one scoring the fall, regardless of who they scored it against, being the winner. In championship matches, this means that, unlike one-on-one matches (where the champion can simply disqualify themselves or get themselves counted out to retain the title via the Champion's Advantage), the champion does "not" have to be pinned or involved in the decision to lose the championship. However, heel champions often find advantages, not in Champion's Advantage, but in the use of weapons and outside interference, as these poly-sided matches tend to involve no holds barred rules.
Many modern specialty matches have been devised, with unique winning conditions. The most common of these is the ladder match. In the basic ladder match, the wrestlers or teams of wrestlers must climb a ladder to obtain a prize that is hoisted above the ring. The key to winning this match is that the wrestler or team of wrestlers must try to incapacitate each other long enough for one wrestler to climb the ladder and secure that prize for their team. As a result, the ladder can be used as a weapon. The prizes include but are not limited to any given championship belt (the traditional prize), a document granting the winner the right to a future title shot, or any document that matters to the wrestlers involved in the match (such as one granting the winner a cash prize). Another common specialty match is known as the battle royal. In a battle royal, all the wrestlers enter the ring to the point that there are 20-30 wrestlers in the ring at one time. When the match begins, the simple objective is to throw the opponent over the top rope and out of the ring with both feet on the floor in order to eliminate that opponent. The last wrestler standing is declared the winner. A variant on this type of match is the WWE's Royal Rumble where two wrestlers enter the ring to start the match and other wrestlers follow in 90 second intervals (previously 2 minutes) until 30-40 wrestlers have entered the ring. All other rules stay the same. For more match types, see Professional wrestling match types.
Every match must be assigned a rule keeper known as a referee, who is the final arbitrator. In multi-man lucha libre matches, two referees are used, one inside the ring and one outside.
Due to the legitimate role that referees play in wrestling of serving as liaison between the bookers backstage and the wrestlers in the ring (the role of being a final arbitrator is merely kayfabe), the referee is present, even in matches that do not at first glance appear to require a referee (such as a ladder match, as it is no holds barred, and the criteria for victory could theoretically be assessed from afar). Although their actions are also frequently scripted for dramatic effect, referees are subject to certain general rules and requirements in order to maintain the theatrical appearance of unbiased authority. The most basic rule is that an action must be seen by a referee to be declared for a fall or disqualification. This allows for heel characters to gain a scripted advantage by distracting or disabling the referee in order to perform some ostensibly illegal maneuver on their opponent. Most referees are unnamed and essentially anonymous, though the WWE has let their officials reveal their names.
Special guest referees may be used from time to time; by virtue of their celebrity status, they are often scripted to dispense with the appearance of neutrality and use their influence to unfairly influence the outcome of the match for added dramatic impact. Face special referees will often fight back against hostile heel wrestlers, particularly if the special referee is either a wrestler themselves or a famous martial artist (such as Tito Ortiz at the main event at TNA Hard Justice 2005).
For heel special referees, common ways of assisting the heel wrestler to obtain victory include, but are not limited to, the following:
Matches are held within a wrestling ring, an elevated square canvas mat with posts on each corner. A cloth apron hangs over the edges of the ring. Three horizontal ropes or cables surround the ring, suspended with turnbuckles which are connected to the posts. For safety, the ropes are padded at the turnbuckles and cushioned mats surround the floor outside the ring. Guardrails or a similar barrier enclose this area from the audience. Wrestlers are generally expected to stay within the confines of the ring, though matches sometimes end up outside the ring, and even in the audience, to add excitement.
Tag rules.
In some team matches, only one entrant from each team may be designated as the "legal" or "active" wrestler at any given moment. Two wrestlers must make physical contact (typically palm-to-palm) in order to transfer this legal status. This is known as a tag, with the participants "tagging out" and "tagging in". Typically the wrestler who is tagging out has a 5-second count to leave the ring, whereas the one tagging in can enter the ring at any time, resulting in heels legally double-teaming a face.
The non-legal wrestlers must remain outside the ring or other legal area at all times (and avoid purposeful contact with the opposing wrestlers) or face reprimand from the referee. In most promotions, the wrestler to be tagged in must be touching the turnbuckle on their corner, or a cloth strap attached to the turnbuckle.
Some multi-wrestler matches allow for a set number of legal wrestlers, and a legal wrestler may tag out to any other wrestler, regardless of team. In these matches, the tag need not be a mutual effort, and this results in active wrestlers being tagged out against their will, or non-legal wrestlers forced to enter the battle.
Sometimes, poly-sided matches that pit every one for themselves will incorporate tagging rules. Outside of kayfabe, this is done to give wrestlers a break from the action (as these matches tend to go on for long periods of time), and to make the action in the ring easier to choreograph. One of the most mainstream examples of this is the Four-Corner match, the most common type of match in the WWE before it was replaced with its equivalent Fatal Four-Way; four wrestlers, each for themselves, fight in a match, but only two wrestlers can be in the match at any given time. The other two are positioned in the corner, and tags can be made between any two wrestlers.
In a Texas Tornado Tag Team match, all the competitors are legal in the match, and tagging in and out is not necessary. All matches fought under hardcore rules (such as no disqualification, no holds barred, ladder match, etc.) are all contested under "de facto" Texas Tornado rules, since the lack of ability of a referee to issue a disqualification renders any tagging requirements moot.
Regardless of rules of tagging, a wrestler cannot pin his or her own tag team partner, even if it is technically possible from the rules of the match (e.g. Texas Tornado rules, or a three-way tag team match). This is called the "Outlaw Rule" because the first team to attempt to use that (in an attempt to unfairly retain their tag team titles) was the New Age Outlaws.
Decisions.
Pinfall.
In order to score by pinfall, a wrestler must pin both their opponent's shoulders against the mat while the referee slaps the mat three times (referred to as a "three count"). This is the most common form of defeat. The pinned wrestler must also be on their back; if they are lying on their belly, it usually does not count.
A count may be started at any time that a wrestler's shoulders are down (both shoulders touching the mat), back-first and any part of the opponent's body is lying over the wrestler. This often results in pins that can easily be kicked out of, if the defensive wrestler is even slightly conscious. For example, an attacking wrestler who is half-conscious may simply drape an arm over an opponent, or a cocky wrestler may place their foot gently on the opponent's body, prompting a three-count from the referee.
However, although almost any scenario where one wrestler is covering another prone, back-first wrestler can be considered a pin attempt, there is one important exception to that rule: Pin attempts broken up by other wrestlers. In matches involving multiple wrestlers (such as triple threat matches or tag team matches), wrestlers who see a pin attempt that, if successful, would result in them losing the match are expected to run in and break the pin attempt by performing some sort of offensive maneuver on the wrestler attempting the pin. The most common attacks for breaking pins are a stomp to the back and an elbow to the back of the head, as they are simple to pull off in the spur of the moment. However, these moves, simple as they are, still leave the pinning wrestler on top of the pinned wrestler. Despite the pinning wrestler still technically being on top of the pinned wrestler, the referee will still consider the pin attempt to be broken.
Illegal pinning methods include using the ropes for leverage and hooking the opponent's clothing, which are therefore popular cheating methods for heels, unless certain stipulations make such an advantage legal. Such pins as these are rarely seen by the referee and are subsequently often used by heels and on occasion by cheating faces to win matches. Even if it is noticed, it is rare for such an attempt to result in a disqualification (see below), and instead it simply results in nullification of the pin attempt, so the heel wrestler rarely has anything to lose for trying it, anyway.
Occasionally, there are instances where a pinfall is made where both wrestlers' shoulders were on the mat for the three-count. This situation will most likely lead to a draw, and in some cases a continuation of the match or a future match to determine the winner.
Submission, knockout and incapacitating the opponent.
To score by submission, the wrestler must make their opponent give up, usually, but not necessarily, by putting them in a submission hold (e.g. figure four leg-lock, arm-lock, sleeper-hold).
A wrestler may voluntarily submit by verbally informing the referee (usually used in moves such as the Mexican Surfboard, where all four limbs are incapacitated, making tapping impossible). Also, since Ken Shamrock popularized it in 1997, a wrestler can indicate a voluntary submission by "tapping out", that is, tapping a free hand against the mat or against an opponent. Occasionally, a wrestler will reach for a rope (see rope breaks below), only to put their hand back on the mat so they can crawl towards the rope some more; this is NOT a submission, and the referee decides what their intent is.
Submission was initially a large factor in professional wrestling, but following the decline of the submission-oriented catch-as-catch-can style from mainstream professional wrestling, the submission largely faded. Despite this, some wrestlers, such as Chris Jericho, Ric Flair, Bret Hart, Kurt Angle, Ken Shamrock, Dean Malenko, Chris Benoit, and Tazz, became famous for winning matches via submission. A wrestler with a signature submission technique is portrayed as better at applying the hold, making it more painful or more difficult to get out of than others who use it, or can be falsely credited as inventing the hold (such as when Tazz popularized the kata ha jime judo choke in pro wrestling as the "Tazzmission").
Since all contact between the wrestlers must cease if any part of the body is touching, or underneath, the ropes, many wrestlers will attempt to break submission holds by deliberately grabbing the bottom ropes. This is called a rope break, and it is one of the most common ways to break a submission hold. Most holds leave an arm or leg free, so that the person can tap out if they want. Instead, they use these free limbs to either grab one of the ring ropes (the bottom one is the most common, as it is nearest the wrestlers, though other ropes sometimes are used for standing holds such as Chris Masters' Master Lock) or drape their foot across, or underneath one. Once this has been accomplished, and the accomplishment is witnessed by the referee, the referee will demand that the offending wrestler break the hold, and start counting to five if the wrestler does not. If the referee reaches the count of five, and the wrestler still does not break the hold, they are disqualified.
If a manager decides that their client wrestler should tap out, but cannot convince the wrestler themselves to do so, they may throw in the towel (by literally taking a gym towel and hurling it into the ring where the referee can see it); this is the same as a submission, as the manager is, in kayfabe, considered the wrestler's agent, and therefore, authorized to make formal decisions (such as forfeiting a match) on the client's behalf.
Knockout.
Passing out in a submission hold constitutes a loss by knockout. To determine if a wrestler has passed out in WWE, the referee usually picks up and drops their hand. If it drops to the mat or floor three consecutive times without the wrestler having the strength to hold it up, the wrestler is considered to have passed out. At one point this was largely ignored. However, the rule is now much more commonly observed for safety reasons. If the wrestler has passed out, the opponent then scores by submission.
Also, a wrestler can win by knockout if they do not resort to submission holds, but stills pummels their opponent to the point that they are completely out cold. To check for a knockout in "this" manner, a referee will wave their hand in front of the wrestler's face; if the wrestler does not react in any way, the referee will award the victory to the other wrestler.
Countout.
A countout (alternatively "count-out" or "count out") happens when a wrestler is out of the ring long enough for the referee to count to ten (twenty in some promotions) and thus disqualified. The count is broken and restarted when a wrestler in the ring exits the ring. Playing into this, some wrestlers will "milk" the count by sliding in the ring, and immediately sliding back out. As they were technically inside the ring for a split second before exiting again, it is sufficient to restart the count. This is often referred to by commentators as "breaking the count." Heels often use this tactic in order to buy themselves more time to catch their breath, or to attempt to frustrate their babyface opponents.
If all the active wrestlers in a match are down inside the ring at the same time, the referee will begin a count (usually ten seconds, twenty in Japan). If nobody rises to their feet by the end of the count, the match is ruled a draw. Any participant who stands up in time will end the count for everyone else. In a Last Man Standing match, this form of a countout is the only way that the match can end, so the referee will count when one or more wrestlers are down, and one wrestler standing up before the 10-count doesn't stop the count for another wrestler who is still down.
In some promotions (and most major modern ones), championships cannot change hands via a countout, unless the on-screen authority declares it for at least one match, although in others, championships may change hands via countout. Heels are known to take advantage of this and will intentionally get counted out when facing difficult opponents, especially when defending championships.
Disqualification.
Disqualification (sometimes abbreviated as "DQ") occurs when a wrestler violates the match's rules, thus losing automatically. Although a countout can technically be considered a disqualification (as it is, for all intents and purposes, an automatic loss suffered as a result of violating a match rule), the two concepts are often distinct in wrestling. A no disqualification match can still end by countout (although this is rare); typically, a match must be declared a "no holds barred" match, a "street fight" or some other term, in order for "both" DQs and countouts to be waived.
Disqualification from a match is called for a number of reasons:
In practice, not all rule violations will result in a disqualification as the referee may use their own judgement and is not obligated to stop the match. Usually, the only offenses that the referee will see and "immediately" disqualify the match on (as opposed to having multiple offenses) are low blows, weapon usage, interference, or assaulting the referee. In WWE, a referee must see the violation with their own eyes to rule that the match end in a disqualification (simply watching the video tape is not usually enough) and the referee's ruling is almost always final, although "dusty finishes" (named after, and made famous by, Dusty Rhodes) will often result in the referee's decision being overturned. It is not uncommon for the referees themselves to get knocked out during a match, which is commonly referred to by the term "ref bump". While the referee remains "unconscious", wrestlers are free to violate rules until the referee is revived or replaced. In some cases, a referee might disqualify a person under the presumption that it was that wrestler who knocked them out; most referee knockouts are arranged to allow a wrestler, usually a heel, to gain an advantage. For example, a wrestler may get whipped into a referee at a slower speed, knocking the ref down for short amount of time; during that interim period, one wrestler may pin their opponent for a three-count and would have won the match but for the referee being down (sometimes, another referee will sprint to the ring from backstage to attempt to make the count, but by then, the other wrestler has had enough time to kick out on their own accord).
If all participants in a match continue to breach the referee's instructions, the match may end in a double disqualification, where both wrestlers or teams (in a tag team match) have been disqualified. The match is essentially nullified, and called a draw or in some cases a restart or the same match being held at a pay-per-view or next night's show.
Draw.
A professional wrestling match can end in a draw. A draw occurs if both opponents are simultaneously disqualified (as via countout or if the referee loses complete control of the match and both opponents attack each other with no regard to being in a match, like Brock Lesnar vs. Undertaker at 2002 Unforgiven), neither opponent is able to answer a ten-count, or both opponents simultaneously win the match. The latter can occur if, for example, one opponent's shoulders touch the mat while maintaining a submission hold against another opponent. If the opponent in the hold begins to tap out at the same time a referee counts to three for pinning the opponent delivering the hold, both opponents have legally achieved scoring conditions simultaneously. Traditionally, a championship may not change hands in the event of a draw (though it may become vacant), though some promotions such as Total Nonstop Action Wrestling have endorsed rules where the champion may lose a title by disqualification. A variant of the draw is the time-limit draw, where the match does not have a winner by a specified time period (a one-hour draw, which was once common, is known in wrestling circles as a "Broadway").
Also if two wrestlers have been given DQ by either the referee or the chairman this is a no contest. if there is a belt on the line the champion keeps the title.
No contest.
A wrestling match may be declared a no contest if the winning conditions are unable to occur. This can be due to excessive interference, loss of referee's control over the match, one or more participants sustaining debilitating injury not caused by the opponent, or the inability of a scheduled match to even begin. A no contest is a state separate and distinct from a draw — a draw indicates winning conditions were met. Although the terms are sometimes used interchangeably in practice, this usage is technically incorrect.
Dramatic elements.
While each wrestling match is ostensibly a competition of athletics and strategy, the goal of each match from a business standpoint is to excite and entertain the audience. Although the competition is staged, dramatic emphasis can be utilized to draw out the most intense reaction from the audience. Heightened interest results in higher attendance rates, increased ticket sales, higher ratings on television broadcasts (which result in greater ad revenue), higher pay-per-view buyrates, and sales of branded merchandise and recorded video footage. All of these contribute to the profit of the promotion company.
Character/gimmick.
In Latin America and English-speaking countries, most wrestlers (and other on-stage performers) portray character roles, sometimes with personalities wildly different from their own. These personalities are a gimmick intended to heighten interest in a wrestler without regard to athletic ability. Some can be unrealistic and cartoon-like (such as Doink the Clown), while others carry more verisimilitude (such as Chris Jericho, The Rock, John Cena, Steve Austin, and CM Punk). In lucha libre, many characters wear masks, adopting a secret identity akin to a superhero, a near-sacred tradition.
An individual wrestler may sometimes use their real name, or a minor variation of it, for much of their career, such as Bret Hart, John Cena and Randy Orton. Others can keep one ring name for their entire career (cases in point include Chris Jericho, Shawn Michaels, CM Punk and Ricky Steamboat), or may change from time to time to better suit the demands of the audience or company. Sometimes a character is owned and trademarked by the company, forcing the wrestler to find a new one when they leave (although a simple typeset change, such as changing Rhyno to Rhino, can usually get around this), and sometimes a character is owned by the wrestler. Sometimes, a wrestler may change their legal name in order to obtain ownership of their ring name (examples include Andrew Martin and Warrior). Many wrestlers (such as The Rock and The Undertaker) are strongly identified with their character, even responding to the name in public or between friends. It's actually considered proper decorum for fellow wrestlers to refer to each other by their stage names/characters rather than their birth/legal names, unless otherwise introduced. A professional wrestling character's popularity can grow to the point that it makes appearances in other media (see Hulk Hogan and El Santo) or even give the performer enough visibility to enter politics (Antonio Inoki and Jesse Ventura, among others).
Typically, matches are staged between a protagonist (historically an audience favorite, known as a babyface, or "the good guy") and an antagonist (historically a villain with arrogance, a tendency to break rules, or other unlikable qualities, called a heel). In recent years, however, antiheroes have also become prominent in professional wrestling. There is also a less common role of a "tweener", who is neither fully face nor fully heel yet able to play either role effectively (case in point, Samoa Joe during his first run in TNA Wrestling from June 2005 to November 2006).
At times a character may "turn", altering their face/heel alignment. This may be an abrupt, surprising event, or it may slowly build up over time. It almost always is accomplished with a markable change in behavior on the part of the character. Some turns become defining points in a wrestler's career, as was the case when Hulk Hogan turned heel after being a top face for over a decade. Others may have no noticeable effect on the character's status. If a character repeatedly switches between being a face and heel, this lessens the effect of such turns, and may result in apathy from the audience. Vince McMahon is a good example of having more heel and face turns than anyone in WWE history.
As with personae in general, a character's face or heel alignment may change with time, or remain constant over its lifetime (the most famous example of the latter is Ricky Steamboat, a WWE Hall of Famer who remained a babyface throughout his entire career). Sometimes a character's heel turn will become so popular that eventually the audience response will alter the character's heel-face cycle to the point where the heel persona will, in practice, become a face persona, and what was previously the face persona, will turn into the heel persona, such as when Dwayne Johnson first began using "The Rock" persona as a heel character, as opposed to his original "Rocky Maivia" babyface persona. Another legendary example is Stone Cold Steve Austin, who was originally booked as a heel, with such mannerisms as drinking on the job, using profanity, breaking company property, and even breaking into people's private homes. However, much to WWF's surprise, the fans got such a charge out of Austin's antics that he effectively became one of the greatest antiheroes in the history of the business. He, along with the stable of D-Generation X, is generally credited with ushering in the Attitude Era of WWF programming.
Story.
While true exhibition matches are not uncommon, most matches tell a story analogous to a scene in a play or film, or an episode of a serial drama: The face will sometimes win (triumph) or sometimes lose (tragedy). Longer story arcs can result from multiple matches over the course of time. Since most promotions have a championship title, competition for the championship is a common impetus for stories. Also, anything from a character's own hair to their job with the promotion can be wagered in a match. (The same type of good vs. evil storylines were also once popular in roller derby).
Some matches are designed to further a story of only one participant. It could be intended to portray him or her as a strong unstoppable force, a lucky underdog, a sore loser, or any other characterization. Sometimes non-wrestling vignettes are shown in order to enhance a character's image without the need for matches.
Other stories result from a natural rivalry between two or more characters. Outside of performance, these are referred to as feuds. A feud can exist between any number of participants and can last for a few days up to multiple decades. The feud between Ric Flair and Ricky Steamboat lasted from the late 1970s into the early 1990s and allegedly spanned over two thousand matches (although most of those matches were mere dark matches). The career-spanning history between characters Mike Awesome and Masato Tanaka is another example of a long-running feud, as is the case of Steve Austin vs. Vince McMahon, one of the most lucrative feuds in the World Wrestling Federation during 1998 and 1999.
In theory, the longer a feud is built up, the more audience interest (aka heat) will exist. The main event of a wrestling show is generally the one with the most heat behind it. Commonly, a heel will hold the upper hand over a face until a final showdown, heightening dramatic tension as the face's fans desire to see them win.
Throughout the history of professional wrestling, many other elements and forms of media have been utilized in professional wrestling storytelling: pre- and post-match interviews, "backstage" skits, positions of authority and worked behind-the-scenes feuds, division rankings (typically the #1-contendership spot), contracts, lotteries, news stories on websites, and in recent years social media.
Also, anything that can be used as an element of drama can exist in professional wrestling stories: romantic relationships (including love triangles and marriage), racism, classism, nepotism, favoritism, corporate corruption, family bonds, personal histories, grudges, theft, cheating, assault, betrayal, bribery, seduction, stalking, confidence tricks, extortion, blackmail, substance abuse, self-doubt, self-sacrifice; even kidnapping, sexual fetishism, necrophilia, misogyny, rape and death have been portrayed in wrestling. Some promotions have included supernatural elements such as magic, curses, the undead and Satanic imagery (most notably the Undertaker and his Ministry of Darkness, a stable that regularly performed evil rituals and human sacrifice in Satanic-like worship of a hidden power figure). Celebrities would also be involved in storylines.
Commentators have become important in communicating the relevance of the characters' actions to the story at hand, filling in past details and pointing out subtle actions that may otherwise go unnoticed.
Promos.
A main part of the story-telling part of wrestling is a promo, or promotional interview. Promos are performed, or "cut", in wrestling jargon, for a variety of reasons, including to heighten interest in a wrestler, or to hype an upcoming match.
Since the crowd is often too loud or the venue too large for promos to be heard naturally, wrestlers will use amplification when speaking in the ring. Unlike most Hollywood acting, large and highly visible handheld microphones are typically used and wrestlers often speak directly to the audience.
Championships.
Professional wrestling mimics the structure of title match combat sports. Participants compete for a championship, and must defend it after winning it. These titles are represented physically by a belt that can be worn by the champion. In the case of team wrestling, there is a belt for each member of the team.
Almost all professional wrestling promotions have one major title, and some have more. Championships are designated by divisions of weight, height, gender, wrestling style and other qualifications.
Typically, each promotion only recognizes the "legitimacy" of their own titles, although cross-promotion does happen. When one promotion absorbs or purchases another, the titles from the defunct promotion may continue to be defended in the new promotion or be decommissioned.
Behind the scenes, the bookers in a company will place the title on the most accomplished performer, or those the bookers believe will generate fan interest in terms of event attendance and television viewership. Lower ranked titles may also be used on the performers who show potential, thus allowing them greater exposure to the audience. However other circumstances may also determine the use of a championship. A combination of a championship's lineage, the caliber of performers as champion, and the frequency and manner of title changes, dictates the audience's perception of the title's quality, significance and reputation.
A wrestler's championship accomplishments can be central to their career, becoming a measure of their performance ability and drawing power. In general, a wrestler with multiple title reigns or an extended title reign is indicative of a wrestler's ability to maintain audience interest and/or a wrestler's ability to perform in the ring. As such, the most accomplished or decorated wrestlers tend to be revered as legends despite the predetermined nature of title reigns. American wrestler Ric Flair has had multiple world heavyweight championship reigns spanning over three decades. Japanese wrestler Último Dragón once held and defended a record 10 titles simultaneously.
Non-standard matches.
Often a match will take place under additional rules, usually serving as a special attraction or a climactic point in a feud or storyline. Sometimes this will be the culmination of an entire feud, ending it for the immediate future (known as a blowoff match).
Perhaps the most well-known non-standard match is the cage match, in which the ring is surrounded by a fence or similar metal structure, with the express intention of preventing escape or outside interference—and with the added bonus of the cage being a potentially brutal weapon or platform for launching attacks. The WWE has another provision where a standard cage match can end with one wrestler or wrestling team escaping the cage through the door or over the top.
Another example is the WWE's Royal Rumble match, which involves thirty participants in a random and unknown order. The Rumble match is itself a spectacle in that it is a once-yearly event with multiple participants, including individuals who might not interact otherwise. It also serves as a catalyst for the company's ongoing feuds, as well as a springboard for new storylines. It is common for legendary wrestlers to make one-time cameo appearances during the Royal Rumble match.
Ring entrance.
While the wrestling matches themselves are the primary focus of professional wrestling, a key dramatic element of the business can be entrances of the wrestlers to the arena and ring. It is typical for a wrestler to get their biggest crowd reaction (or "pop") for their ring entrance, rather than for anything they do in the wrestling match itself, especially if former main event stars are returning to a promotion after a long absence.
All notable wrestlers now enter the ring accompanied by music, and regularly add other elements to their entrance. The music played during the ring entrance will usually mirror the wrestler's personality. Many wrestlers, particularly in America, have music and lyrics specially written for their ring entrance. While invented long before, the practice of including music with the entrance gained rapid popularity during the 1980s, largely as a result of the huge success of Hulk Hogan and the WWF, and their Rock 'n' Wrestling Connection. When a match is won, the victor's theme music is usually also played in celebration.
With the introduction of the Titantron entrance screen in 1997, WWF/WWE wrestlers also had entrance videos made that would play along with the their entrance music.
Other dramatic elements of a ring entrance can include:
Another method of entry involves descending from the ceiling with a Zip-line or rappel line and stunt harness. This has been done by Shawn Michaels at WrestleMania XII, by Sting many times in WCW and TNA, and has gained major controversy over its role in the death of wrestler Owen Hart at Over the Edge.
Special ring entrances are also developed for big occasions, most notably the WrestleMania event. For example, WrestleMania III and VI both saw all wrestlers enter the arena on motorized miniature wrestling rings. Live bands are sometimes hired to perform live entrance music at special events. John Cena and Triple H are particularly notable in recent years for their highly theatrical entrances at WrestleMania.
Wrestlers.
Women's wrestling.
The women's division of professional wrestling has maintained a recognized world champion since 1937, when Mildred Burke won the original World Women's title. She then formed the World Women's Wrestling Association in the early 1950s and recognized herself as the first champion, although the championship would be vacated upon her retirement in 1956. The NWA however, ceased to acknowledge Burke as "their" Women's World champion in 1954, and instead acknowledged June Byers as champion after a controversial finish to a high-profile match between Burke and Byers that year. Upon Byers' retirement in 1964, The Fabulous Moolah, who won a junior heavyweight version of the NWA World Women's Championship (the predecessor to the WWE Women's Championship) in a tournament back in 1958, was recognized by most NWA promoters as champion by default.
Intergender wrestling.
For most of its history, men and women would rarely compete against each other in professional wrestling, as it was deemed to be unfair and unchivalrous. Andy Kaufman used this to gain notoriety when he created an Intergender Championship and declared it open to any female challenger. This led to a long (worked) feud with Jerry Lawler.
In the 1980s, mixed tag team matches began to take place, with a male and female on each team and a rule stating that each wrestler could only attack the opponent of the same gender. If a tag was made, the other team had to automatically switch their legal wrestler as well. Despite these restrictions, many mixed tag matches do feature some physical interaction between participants of different genders. For example, a heel may take a cheap shot at the female wrestler of the opposing team to draw a negative crowd reaction. In lucha libre, cheap-shots and male-female attacks are not uncommon.
Intergender singles bouts were first fought on a national level in the 1990s. This began with Luna Vachon, who faced men in ECW and WWF. Later, Chyna became the first female to hold a belt that was not exclusive to women when she won the WWF Intercontinental Championship. While it is a rare feat in WWE, in TNA, ODB participates in singles intergender matches. Also, ODB's kayfabe husband and tag team partner Eric Young held the Knockouts tag team titles for a record 478 days before it was stripped by Brooke Hogan because Young was a male.
Midget wrestling.
Midget wrestling can be traced to professional wrestling's carnival and vaudeville origins. In recent years, the popularity and prevalence of midgets in wrestling has greatly decreased due to wrestling companies depriving midget divisions of storyline and/or feud. However, WWE has made a few attempts to enter this market with their "minis" in the 1990s and the "junior's league" as recent as 2006. It is still a popular form of entertainment in Mexican wrestling, mostly as a "sideshow".
Some wrestlers may have their own specific "mini me", like Mascarita Sagrada, Alebrije has Quije, etc. There are also cases in which midgets can become valets for a wrestler, and even get physically involved in matches, like Alushe, who often accompanies Tinieblas, or KeMonito, who is portrayed as Consejo Mundial de Lucha Libre's mascot and is also a valet for Mistico. Dave Finlay was often aided in his matches by a midget known mainly as Hornswoggle while in WWE, who hid under the ring and gave a shillelagh to Finlay to use on his opponent. Finlay also occasionally threw him at his opponent(s). Hornswoggle has also been given a run with the WWE Cruiserweight Championship and feuded with D-X in 2009.
Bear wrestling.
Though they have not had the level of exposure as other wrestlers, bears have long been a part of professional wrestling. Usually declawed and muzzled, they often wrestled shoot matches against audience members, offered a cash reward if they could pin the bear. They also wrestled professionals in worked, often battle royale or handicap, matches (usually booked so the bear won). Though they have wrestled around the world and continue to do so, wrestling bears enjoyed their greatest popularity in the Southern United States, during the 1960s and 1970s. The practice of bear wrestling has met strong opposition from animal rights activists in recent decades, contributing to its lack of mainstream acceptance. As of 2006, it is banned in 20 US states. Perhaps the most famous wrestling bears are Ginger, Victor, Hercules and Terrible Ted.
Styles and characteristics in different countries.
The U.S., Japan and Mexico are three countries where there is a huge market and high popularity for professional wrestling. But the styles of professional wrestling are different, given their independent development for a long period.
Professional wrestling in the U.S. tends to have a heavy focus on story building and the establishment of characters (and their personalities). There is a story for each match, and even a longer story for successive matches. The stories usually contain characters like faces and heels, and less often antiheroes and tweeners. It is a "triumph" if the face wins, while it is a "tragedy" if the heel wins. The characters usually have strong and sharp personalities, with examples like Doink the Clown, whose personality is melodramatic, slapstick and fantastical. The opposition between faces and heels is very intense in the story, and the heels may even attack the faces during TV interviews. The relationship between different characters can also be very complex.
Although professional wrestling in Mexico (Lucha libre) also has stories and characters, they are less emphasized. Wrestlers in Mexico are traditionally more agile and perform more aerial maneuvers than professional wrestlers in the U.S. who, more often, rely on power moves and strikes to subdue their opponents. The difference in styles is due to the independent evolution of the sport in Mexico beginning in the 1930s and the fact that wrestlers in the cruiserweight division ("peso semicompleto") are often the most popular wrestlers in Mexican lucha libre. Wrestlers often execute high flying moves characteristic of lucha libre by utilizing the wrestling ring's ropes to catapult themselves towards their opponents, using intricate combinations in rapid-fire succession, and applying complex submission holds. Lucha libre is also known for its tag team wrestling matches, in which the teams are often made up of three members, instead of two as is common in the U.S.
The style of Japanese professional wrestling (Puroresu) is again different. With its origins in traditional American style of wrestling and still being under the same genre, it has become an entity in itself. Despite the similarity to its American counterpart in that the outcome of the matches remains predetermined, the phenomena are different in the form of the psychology and presentation of the sport; it is treated as a full contact combat sport as it mixes hard hitting martial arts strikes with shoot style submission holds, while in the U.S. it is rather more regarded as an entertainment show. Wrestlers incorporate kicks and strikes from martial arts disciplines, and a strong emphasis is placed on submission wrestling, and unlike the use of involved storylines in the U.S., they are not as intricate in Japan, more emphasis is placed on the concept of Fighting Spirit, meaning the Wrestlers display of physical and mental stamina are valued a lot more than theatrics. Many of Japan's wrestlers including top stars such as Shinya Hashimoto, Riki Chōshū and Keiji Mutoh came from a legitimate martial arts background and many Japanese Pro Wrestlers in the 1990s began to pursue careers in Mixed Martial Arts Organizations such as Pancrase and Shooto which at the time retained the original look of Puroresu but were actual competitions.
Culture.
Professional wrestling has developed its own cultures, both internal and external.
Those involved in producing professional wrestling have developed a kind of global fraternity, with familial bonds, shared language and passed-down traditions. New performers are expected to "pay their dues" for a few years by working in lower-profile promotions and working as ring crew before working their way upward. The permanent rosters of most promotions develop a backstage pecking order, with veterans mediating conflicts and mentoring younger wrestlers. For many decades (and still to a lesser extent today) performers were expected to keep the illusions of wrestling's legitimacy alive even while not performing, essentially acting in character any time they were in public. Some veterans speak of a "sickness" among wrestling performers, an inexplicable pull to remain active in the wrestling world despite the devastating effects the job can have on one's life and health.
Fans of professional wrestling have their own subculture, comparable to those of science fiction, video games, or comic books. Those who are interested in the backstage occurrences, future storylines and reasonings behind company decisions read newsletters written by journalists with inside ties to the wrestling industry. These "rags" or "dirt sheets" have expanded into the Internet, where their information can be dispensed on an up-to-the-minute basis. Some have expanded into radio shows.
Some fans enjoy a pastime of collecting tapes of wrestling shows from specific companies, of certain wrestlers, or of specific genres. The internet has given fans exposure to worldwide variations of wrestling they would be unable to see otherwise. Since the 1990s, many companies have been founded which deal primarily in wrestling footage. When the WWE purchased both WCW and ECW in 2001, they also obtained the entire past video libraries of both productions and have released many past matches online and on home video.
Like some other sports, fantasy leagues have developed around professional wrestling. Some take this concept further by creating E-feds (electronic federations), where a user can create their own fictional wrestling character, and role-playing storylines with other users, leading to scheduled "shows" where match results are determined by the organizers, usually based on a combination of the characters' statistics and the players' roleplaying aptitude, sometimes with audience voting.
Professional wrestling in mainstream culture.
From the first established world championship, the top professional wrestlers have garnered fame within mainstream society. Each successive generation has produced a number of wrestlers who extend their careers into the realms of music, acting, writing, business, politics or public speaking, and are known to those who are unfamiliar with wrestling in general. Conversely, celebrities from other sports or general pop culture also become involved with wrestling for brief periods of time. A prime example of this is The Rock 'n' Wrestling Connection of the 1980s, which combined wrestling with MTV.
Professional wrestling is often portrayed within other works using parody, and its general elements have become familiar tropes and memes in American culture.
Some terminology originating in professional wrestling has found its way into the common vernacular. Phrases such as "body slam", "sleeper hold" and "tag team" are used by those who do not follow professional wrestling. The term "smackdown", popularized by The Rock and "WWE SmackDown" in the 1990s, has been included in Merriam-Webster dictionaries since 2007.
Many television shows and films have been produced which portray in-character professional wrestlers as protagonists, such as "Ready to Rumble", "¡Mucha Lucha!", "Nacho Libre", and the Santo film series. At least two stage plays set in the world of pro wrestling have been produced: "The Baron" is a comedy that retells the life of an actual performer known as Baron von Raschke. "From Parts Unknown..." is an award-nominated Canadian drama about the rise and fall of a fictional wrestler. The 2009 "South Park" episode "W.T.F." played on the soap operatic elements of professional wrestling. One of the lead characters on the Disney Channel series "Kim Possible" was a huge fan of pro wrestling and actually featured it on an episode (with two former WWE wrestlers voicing the two fictitious wrestlers featured in the episode). The 2008 film "The Wrestler", about a washed-up professional wrestler, garnered several Oscar nominations.
The 1950 film noir Night and the City, directed by Jules Dassin and starring Richard Widmark and Gene Tierney, told the story of a promoter in London trying to make it big, and featured a match involving real professional wrestler Stanislaus Zbyszko.
Study and analysis of professional wrestling.
With its growing popularity, professional wrestling has attracted attention as a subject of serious academic study and journalistic criticism. Many courses, theses, essays and dissertations have analyzed wrestling's conventions, content, and its role in modern society. It is often included as part of studies on theatre, sociology, performance, and media. The Massachusetts Institute of Technology developed a course of study on the cultural significance of professional wrestling, and anthropologist Heather Levi has written an ethnography about the culture of lucha libre in Mexico.
But this was not always the case; in the early 20th century, once it became apparent that the "sport" was worked, pro wrestling was looked down on as a cheap entertainment for the uneducated working class—an attitude that still exists to varying degrees today. The French theorist Roland Barthes was among the first to propose that wrestling was worthy of deeper analysis, in his essay "The World of Wrestling" from his book "Mythologies", first published in 1957. Barthes argued that it should be looked at not as a scamming of the ignorant, but as spectacle; a mode of theatric performance for a willing, if bloodthirsty, audience. Wrestling is described as performed art which demands an immediate reading of the juxtaposed meanings. The logical conclusion is given least importance over the theatrical performers of the wrestlers and the referee. According to Barthes the function of a wrestler is not to win: it is to go exactly through the motions which are expected of them and to give the audience a theatrical spectacle. This work is considered a foundation of all later study.
While pro wrestling is often described simplistically as a "soap opera for males", it has also been cited as filling the role of past forms of literature and theatre; a of classical heroics, commedia dell'arte, revenge tragedies, morality plays, and burlesque. The characters and storylines portrayed by a successful promotion are seen to reflect the current mood, attitudes, and concerns of that promotion's society (and can, in turn, influence those same things). Wrestling's high levels of violence and masculinity make it a vicarious outlet for aggression during peacetime.
Documentary filmmakers have studied the lives of wrestlers and the effects the profession has on them and their families. The 1999 theatrical documentary "Beyond the Mat" focused on Terry Funk, a wrestler nearing retirement; Mick Foley, a wrestler within his prime; Jake Roberts, a former star fallen from grace; and a school of wrestling student trying to break into the business. The 2005 release ' chronicled the development of women's wrestling throughout the 20th century. Pro wrestling has been featured several times on HBO's "Real Sports with Bryant Gumbel". MTV's documentary series "True Life" featured two episodes titled "I'm a Professional Wrestler" and "I Want to Be a Professional Wrestler". Other documentaries have been produced by The Learning Channel ("The Secret World of Professional Wrestling") and A&E ('). Bloodstained Memoirs explored the careers of several pro wrestlers, including Chris Jericho, Rob Van Dam and Roddy Piper.
Injury and fatality.
Although professional wrestling is worked, there is a high chance of injury, and even death. Strikes are often stiff especially in Japan and in independent wrestling promotions such as Combat Zone Wrestling and Ring of Honor. The ring is often made out of 2 by 8 timber planks. There have been many brutal accidents, hits and injuries. Many of the injuries that occur in pro wrestling are shoulders, knee, back, neck, and rib injuries. Professional wrestler Davey Richards said in 2015 "We train to take damage, we know we are going to take damage and we accept that."
Less than 25 years after the 1990 WrestleMania VI one third of its 36 competitors had died including André the Giant and main event winner the "Ultimate Warrior"; all of these deaths had occurred before the age of 64.
See also.
In fiction.
Independent wrestling promotions: 

</doc>
<doc id="24868" url="http://en.wikipedia.org/wiki?curid=24868" title="Pauli matrices">
Pauli matrices

In mathematical physics and mathematics, the Pauli matrices are a set of three 2 × 2 complex matrices which are Hermitian and unitary. Usually indicated by the Greek letter sigma (σ), they are occasionally denoted by tau (τ) when used in connection with isospin symmetries. They are
These matrices are named after the physicist Wolfgang Pauli. In quantum mechanics, they occur in the Pauli equation which takes into account the interaction of the spin of a particle with an external electromagnetic field.
Each Pauli matrix is Hermitian, and together with the identity matrix I (sometimes considered as the zeroth Pauli matrix "σ"0), the Pauli matrices (multiplied by "real" coefficients) span the full vector space of 2 × 2 Hermitian matrices.
In the language of quantum mechanics, Hermitian matrices are observables, so the Pauli matrices span the space of observables of the 2-dimensional complex Hilbert space. In the context of Pauli's work, "σ""k" is the observable corresponding to spin along the kth coordinate axis in three-dimensional Euclidean space ℝ3.
The Pauli matrices (after multiplication by i to make them anti-Hermitian), also generate transformations in the sense of Lie algebras: the matrices "iσ"1, "iσ"2, "iσ"3 form a basis for su(2), which exponentiates to the special unitary group SU(2). The algebra generated by the three matrices "σ"1, "σ"2, "σ"3 is isomorphic to the Clifford algebra of ℝ3, called the algebra of physical space.
Algebraic properties.
All three of the Pauli matrices can be compacted into a single expression:
where is the imaginary unit, and "δab" is the Kronecker delta, which equals +1 if and 0 otherwise. This expression is useful for "selecting" any one of the matrices numerically by substituting values of , in turn useful when any of the matrices (but no particular one) is to be used in algebraic manipulations.
The matrices are involutory:
where "I" is the identity matrix.
From above we can deduce that the eigenvalues of each "σ""i" are ±1.
Eigenvectors and eigenvalues.
Each of the (Hermitian) Pauli matrices has two eigenvalues, +1 and −1. The corresponding normalized eigenvectors are:
Pauli vector.
The Pauli vector is defined by
and provides a mapping mechanism from a vector basis to a Pauli matrix basis as follows,
using the summation convention. Further,
and also (see completeness, below) 
Commutation relations.
The Pauli matrices obey the following commutation relations:
and anticommutation relations:
where "εabc" is the Levi-Civita symbol, Einstein summation notation is used, "δab" is the Kronecker delta, and "I" is the 2 × 2 identity matrix.
For example,
Relation to dot and cross product.
Pauli vectors elegantly map these commutation and anticommutation relations to corresponding vector products. Adding the commutator to the anticommutator gives
so that, cancelling the factors of 2,
Contracting each side of the equation with components of two 3-vectors "ap" and "bq" (which commute with the Pauli matrices, i.e., for each matrix "σq" and vector component "ap" (and likewise with "bq"), and relabeling indices "a", "b", "c" → "p", "q", "r", to prevent notational conflicts, yields
Finally, translating the index notation for the dot product and cross product results in 
Exponential of a Pauli vector.
For 
one has, for even powers,
which can be shown first for the case using the anticommutation relations.
Thus, for odd powers,
Matrix exponentiating, and using the Taylor series for sine and cosine,
and, in the last line, the first sum is the cosine, while the second sum is the sine; so, finally,
which is analogous to Euler's formula. Note 
while the determinant of the exponential itself is just 1, which makes it the generic group element of SU(2).
A more abstract version of formula (2) for a general 2 × 2 matrix can be found in the article on matrix exponentials.
The group composition law of SU(2).
A straightforward application of this formula provides a parameterization of the composition law of the group SU(2). One may directly solve for c in 
which specifies the generic group multiplication, where, manifestly, 
the spherical law of cosines. Given c, then, 
Consequently, the composite rotation parameters in this group element (a closed form of the respective BCH expansion in this case) simply amount to 
The fact that any 2 × 2 complex Hermitian matrices can be expressed in terms of the identity matrix and the Pauli matrices also leads to the Bloch sphere representation of 2 × 2 mixed states' density matrix, (2 × 2 positive semidefinite matrices with trace 1). This can be seen by simply first writing an arbitrary Hermitian matrix as a real linear combination of {"σ"0, "σ"1, "σ"2, "σ"3} as above, and then imposing the positive-semidefinite and trace 1 conditions.
Completeness relation.
An alternative notation that is commonly used for the Pauli matrices is to write the vector index i in the superscript, and the matrix indices as subscripts, so that the element in row α and column β of the i-th Pauli matrix is "σ" "i""αβ".
In this notation, the completeness relation for the Pauli matrices can be written
Proof
The fact that the Pauli matrices, along with the identity matrix "I", form an orthogonal basis for the complex Hilbert space of all 2 × 2 matrices means that we can express any matrix "M" as
where "c" is a complex number, and "a" is a 3-component complex vector. It is straightforward to show, using the properties listed above, that
where "tr" denotes the trace, and hence that formula_27 and formula_28.
This therefore gives
which can be rewritten in terms of matrix indices as
where summation is implied over the repeated indices "γ" and "δ". Since this is true for any choice of the matrix "M", the completeness relation follows as stated above.
As noted above, it is common to denote the 2 × 2 unit matrix by "σ"0, so "σ"0"αβ" = "δ""αβ". The completeness relation can therefore alternatively be expressed as
Relation with the permutation operator.
Let "Pij" be the transposition (also known as a permutation) between two spins "σ""i" and "σ""j" living in the tensor product space ℂ2 ⊗ ℂ2,
This operator can also be written more explicitly as Dirac's spin exchange operator,
Its eigenvalues are therefore 1 or −1. It may thus be utilized as an interaction term in a Hamiltonian, splitting the energy eigenvalues of its symmetric versus antisymmetric eigenstates.
SU(2).
The group SU(2) is the Lie group of unitary 2×2 matrices with unit determinant; its Lie algebra is the set of all 2×2 anti-Hermitian matrices with trace 0. Direct calculation, as above, shows that the Lie algebra formula_34 is the 3-dimensional real algebra spanned by the set {"iσj"}. In compact notation,
As a result, each "iσj" can be seen as an infinitesimal generator of SU(2). The elements of SU(2) are exponentials of linear combinations of these three generators, and multiply as indicated above in discussing the Pauli vector. Although this suffices to generate SU(2), it is not a proper representation of su(2), as the Pauli eigenvalues are scaled unconventionally. The conventional normalization is "λ" = 1/2, so that
As SU(2) is a compact group, its Cartan decomposition is trivial.
SO(3).
The Lie algebra su(2) is isomorphic to the Lie algebra so(3), which corresponds to the Lie group SO(3), the group of rotations in three-dimensional space. In other words, one can say that the "iσj" are a realization (and, in fact, the lowest-dimensional realization) of "infinitesimal" rotations in three-dimensional space. However, even though su(2) and so(3) are isomorphic as Lie algebras, SU(2) and SO(3) are not isomorphic as Lie groups. SU(2) is actually a double cover of SO(3), meaning that there is a two-to-one group homomorphism from SU(2) to SO(3), see relationship between SO(3) and SU(2).
Quaternions.
The real linear span of {"I", "iσ"1, "iσ"2, "iσ"3} is isomorphic to the real algebra of quaternions ℍ. The isomorphism from ℍ to this set is given by the following map (notice the reversed signs for the Pauli matrices):
Alternatively, the isomorphism can be achieved by a map using the Pauli matrices in reversed order,
As the quaternions of unit norm is group-isomorphic to SU(2), this gives yet another way of describing SU(2) via the Pauli matrices. The two-to-one homomorphism from SU(2) to SO(3) can also be explicitly given in terms of the Pauli matrices in this formulation.
Quaternions form a division algebra—every non-zero element has an inverse—whereas Pauli matrices do not. For a quaternionic version of the algebra generated by Pauli matrices see biquaternions, which is a venerable algebra of eight real dimensions.
Physics.
Quantum mechanics.
In quantum mechanics, each Pauli matrix is related to an angular momentum operator that corresponds to an observable describing the spin of a spin ½ particle, in each of the three spatial directions. As an immediate consequence of the Cartan decomposition mentioned above, "iσj" are the generators of a projective representation (spin representation) of the rotation group SO(3) acting on non-relativistic particles with spin ½. The states of the particles are represented as two-component spinors. In the same way, the Pauli matrices are related to the isospin operator
An interesting property of spin ½ particles is that they must be rotated by an angle of 4π in order to return to their original configuration. This is due to the two-to-one correspondence between SU(2) and SO(3) mentioned above, and the fact that, although one visualizes spin up/down as the north/south pole on the 2-sphere S 2, they are actually represented by orthogonal vectors in the two dimensional complex Hilbert space.
For a spin ½ particle, the spin operator is given by , the fundamental representation of "SU(2)". By taking Kronecker products of this representation with itself repeatedly, one may construct all higher irreducible representations. That is, the resulting spin operators for higher spin systems in three spatial dimensions, for arbitrarily large "j", can be calculated using this spin operator and ladder operators. They can be found in Rotation group SO(3)#A note on representations. The analog formula to the above generalization of Euler's formula for Pauli matrices, the group element in terms of spin matrices, is tractable, but less simple.
Also useful in the quantum mechanics of multiparticle systems, the general Pauli group "Gn" is defined to consist of all n-fold tensor products of Pauli matrices.

</doc>
<doc id="24869" url="http://en.wikipedia.org/wiki?curid=24869" title="Pie menu">
Pie menu

In computer interface design, a pie menu (also known as a radial menu) is a circular context menu where selection depends on direction. It is a graphical control element. A pie menu is made of several "pie slices" around an inactive center and works best with stylus input, and well with a mouse. Pie slices are drawn with a hole in the middle for an easy way to exit the menu.
Pie menus work well with keyboard acceleration, particularly four and eight item menus, on the cursor keys and the number pad. A goal of pie menus is to provide a smooth, reliable gestural style of interaction for novices and experts.
A slice can lead to another pie menu; selecting this may center the pointer in the new menu. A marking menu is a variant of the technique.
As a kind of context menu, pie menus are often context-sensitive, showing different options depending on what the pointer was pointing at when the menu was requested.
History.
The first documented radial menu is attributed to a system called PIXIE in 1969. Some universities explored alternative visual layouts.
In 1986, Mike Gallaher and Don Hopkins together independently arrived at the concept of a context menu based on the angle to the origin where the exact angle and radius could be passed as parameters to a command, or the radius could be used to trigger a submenu.
The first performance comparison to linear menus was performed in 1988 showing an increase in performance of 15% less time and a reduction of selection errors.
Usage.
For the novice, pie menus are easy because they are a self-revealing gestural interface: They show what you can do and direct you how to do it. By clicking and popping up a pie menu, looking at the labels, moving the pointer in the desired direction, then clicking to make a selection, you learn the menu and practice the gesture to "mark ahead" ("mouse ahead" in the case of a mouse, "wave ahead" in the case of a dataglove). With a little practice, it becomes quite easy to mark ahead even through nested pie menus.
For the expert, they're efficient because—without even looking—you can move in any direction, and mark ahead so fast that the menu doesn't even pop up. Only when used more slowly like a traditional menu, does a pie menu pop up on the screen, to reveal the available selections.
Most importantly, novices soon become experts, because every time you select from a pie menu, you practice the motion to mark ahead, so you naturally learn to do it by feel. As Jaron Lanier of VPL Research has remarked, "The mind may forget, but the body remembers." Pie menus take advantage of the body's ability to remember muscle motion and direction, even when the mind has forgotten the corresponding symbolic labels.
Comparison with other interaction techniques.
Pie menus are faster and more reliable to select from than linear menus, because selection depends on direction instead of distance. The circular menu slices are large in size and near the pointer for fast interaction (see Fitts's law). Experienced users use muscle memory without looking at the menu while selecting from it. Nested pie menus can efficiently offer many options, and some pie menus can pop up linear menus, and combine linear and radial items in the same menu. Pie menus just like any popup menu are shown only when requested, resulting in less visual distraction and cognitive load than toolbars and menu bars that are always shown.
Pie menus show available options, in contrast to invisible mouse gestures. Pie menus, which delay appearance until the pointer is not moving, reduce intrusiveness to the same level as mouse gestures for experienced users. Pie menus take up more screen space than linear menus, and the number of slices in an individual menu must be kept low for effectiveness by using submenus. When using pie menus, submenus may overlap with the parent menu, but the parent menu may become translucent or hidden.
Pie menus are most suited for actions that have been laid out by humans, and have logical grouping choices. Linear menus are most suited for dynamic, large menus that have many possible options, without any logical grouping, since pie menus can only show a limited number of menu items. Around 3-12 items can be reasonably accommodated in a radial layout, but additional items past that tend to counteract the benefits of using pie menus in the first place. This can be overcome with related techniques that allow chaining commands in one single gesture through submenus.
However, using interaction techniques that are not pointer-based have proven problematic with both pie and linear menus for cluttered digital tabletop, where physical objects might occlude menu items .
Pie menus are unavailable as standard graphical control element in common commercial toolkits. Video games often require custom widget development, so pie menu cost is lower in that particular scenario.

</doc>
<doc id="24872" url="http://en.wikipedia.org/wiki?curid=24872" title="Pollution">
Pollution

Pollution is the introduction of contaminants into the natural environment that cause adverse change. Pollution can take the form of chemical substances or energy, such as noise, heat or light. Pollutants, the components of pollution, can be either foreign substances/energies or naturally occurring contaminants. Pollution is often classed as point source or nonpoint source pollution.
Ancient cultures.
Air pollution has always accompanied civilizations. Pollution started from prehistoric times when man created the first fires. According to a 1983 article in the journal "Science," "soot found on ceilings of prehistoric caves provides ample evidence of the high levels of pollution that was associated with inadequate ventilation of open fires." Metal forging appears to be a key turning point in the creation of significant air pollution levels outside the home. Core samples of glaciers in Greenland indicate increases in pollution associated with Greek, Roman and Chinese metal production, but at that time the pollution was comparatively small and could be handled by nature.
Urban pollution.
The burning of coal and wood, and the presence of many horses in concentrated areas made the cities the cesspools of pollution. The Industrial Revolution brought an infusion of untreated chemicals and wastes into local streams that served as the water supply. King Edward I of England banned the burning of sea-coal by proclamation in London in 1272, after its smoke became a problem. But the fuel was so common in England that this earliest of names for it was acquired because it could be carted away from some shores by the wheelbarrow.
It was the industrial revolution that gave birth to environmental pollution as we know it today. London also recorded one of the earlier extreme cases of water quality problems with the Great Stink on the Thames of 1858, which led to construction of the London sewerage system soon afterward. Pollution issues escalated as population growth far exceeded view ability of neighborhoods to handle their waste problem. Reformers began to demand sewer systems, and clean water.
In 1870, the sanitary conditions in Berlin were among the worst in Europe. August Bebel recalled conditions before a modern sewer system was built in the late 1870s:
The primitive conditions were intolerable for a world national capital, and the Imperial German government brought in its scientists, engineers and urban planners to not only solve the deficiencies but to forge Berlin as the world's model city. A British expert in 1906 concluded that Berlin represented "the most complete application of science, order and method of public life," adding "it is a marvel of civic administration, the most modern and most perfectly organized city that there is."
The emergence of great factories and consumption of immense quantities of coal gave rise to unprecedented air pollution and the large volume of industrial chemical discharges added to the growing load of untreated human waste. Chicago and Cincinnati were the first two American cities to enact laws ensuring cleaner air in 1881. Pollution became a major issue in the United States in the early twentieth century, as progressive reformers took issue with air pollution caused by coal burning, water pollution caused by bad sanitation, and street pollution caused by the 3 million horses who worked in American cities in 1900, generating large quantities of urine and manure. As historian Martin Melosi notes, The generation that first saw automobiles replacing the horses saw cars as "miracles of cleanliness.". By the 1940s, however, automobile-caused smog was a major issue in Los Angeles.
Other cities followed around the country until early in the 20th century, when the short lived Office of Air Pollution was created under the Department of the Interior. Extreme smog events were experienced by the cities of Los Angeles and Donora, Pennsylvania in the late 1940s, serving as another public reminder.
Air pollution would continue to be a problem in England, especially later during the industrial revolution, and extending into the recent past with the Great Smog of 1952.
Awareness of atmospheric pollution spread widely after World War II, with fears triggered by reports of radioactive fallout from atomic warfare and testing. Then a non-nuclear event, The Great Smog of 1952 in London, killed at least 4000 people. This prompted some of the first major modern environmental legislation, The Clean Air Act of 1956.
Pollution began to draw major public attention in the United States between the mid-1950s and early 1970s, when Congress passed the Noise Control Act, the Clean Air Act, the Clean Water Act and the National Environmental Policy Act.
Severe incidents of pollution helped increase consciousness. PCB dumping in the Hudson River resulted in a ban by the EPA on consumption of its fish in 1974. Long-term dioxin contamination at Love Canal starting in 1947 became a national news story in 1978 and led to the Superfund legislation of 1980. The pollution of industrial land gave rise to the name brownfield, a term now common in city planning.
The development of nuclear science introduced radioactive contamination, which can remain lethally radioactive for hundreds of thousands of years. Lake Karachay, named by the Worldwatch Institute as the "most polluted spot" on earth, served as a disposal site for the Soviet Union throughout the 1950s and 1960s. Second place may go to the area of Chelyabinsk Russian as the "Most polluted place on the planet".
Nuclear weapons continued to be tested in the Cold War, especially in the earlier stages of their development. The toll on the worst-affected populations and the growth since then in understanding about the critical threat to human health posed by radioactivity has also been a prohibitive complication associated with nuclear power. Though extreme care is practiced in that industry, the potential for disaster suggested by incidents such as those at Three Mile Island and Chernobyl pose a lingering specter of public mistrust. Worldwide publicity has been intense on those disasters. Widespread support for test ban treaties has ended almost all nuclear testing in the atmosphere.
International catastrophes such as the wreck of the Amoco Cadiz oil tanker off the coast of Brittany in 1978 and the Bhopal disaster in 1984 have demonstrated the universality of such events and the scale on which efforts to address them needed to engage. The borderless nature of atmosphere and oceans inevitably resulted in the implication of pollution on a planetary level with the issue of global warming. Most recently the term persistent organic pollutant (POP) has come to describe a group of chemicals such as PBDEs and PFCs among others. Though their effects remain somewhat less well understood owing to a lack of experimental data, they have been detected in various ecological habitats far removed from industrial activity such as the Arctic, demonstrating diffusion and bioaccumulation after only a relatively brief period of widespread use.
A much more recently discovered problem is the Great Pacific Garbage Patch, a huge concentration of plastics, chemical sludge and other debris which has been collected into a large area of the Pacific Ocean by the North Pacific Gyre. This is a less well known pollution problem than the others described above, but nonetheless has multiple and serious consequences such as increasing wildlife mortality, the spread of invasive species and human ingestion of toxic chemicals. Organizations such as 5 Gyres have researched the pollution and, along with artists like Marina DeBris, are working toward publicizing the issue.
Growing evidence of local and global pollution and an increasingly informed public over time have given rise to environmentalism and the environmental movement, which generally seek to limit human impact on the environment.
Forms of pollution.
The major forms of pollution are listed below along with the particular contaminant relevant to each of them:
Pollutants.
A pollutant is a waste material that pollutes air, water or soil. Three factors determine the severity of a pollutant: its chemical nature, the concentration and the persistence.
Cost of pollution.
Pollution has cost. Manufacturing activities that cause air pollution impose health and clean-up costs on the whole society, whereas the neighbors of an individual who chooses to fire-proof his home may benefit from a reduced risk of a fire spreading to their own houses. If external costs exist, such as pollution, the producer may choose to produce more of the product than would be produced if the producer were required to pay all associated environmental costs. Because responsibility or consequence for self-directed action lies partly outside the self, an element of externalization is involved. If there are external benefits, such as in public safety, less of the good may be produced than would be the case if the producer were to receive payment for the external benefits to others.
Sources and causes.
Air pollution comes from both natural and human-made (anthropogenic) sources. However, globally human-made pollutants from combustion, construction, mining, agriculture and warfare are increasingly significant in the air pollution equation.
Motor vehicle emissions are one of the leading causes of air pollution. China, United States, Russia, India Mexico, and Japan are the world leaders in air pollution emissions. Principal stationary pollution sources include chemical plants, coal-fired power plants, oil refineries, petrochemical plants, nuclear waste disposal activity, incinerators, large livestock farms (dairy cows, pigs, poultry, etc.), PVC factories, metals production factories, plastics factories, and other heavy industry. Agricultural air pollution comes from contemporary practices which include clear felling and burning of natural vegetation as well as spraying of pesticides and herbicides
About 400 million metric tons of hazardous wastes are generated each year. The United States alone produces about 250 million metric tons. Americans constitute less than 5% of the world's population, but produce roughly 25% of the world’s CO2, and generate approximately 30% of world’s waste. In 2007, China has overtaken the United States as the world's biggest producer of CO2, while still far behind based on per capita pollution - ranked 78th among the world's nations.
In February 2007, a report by the Intergovernmental Panel on Climate Change (IPCC), representing the work of 2,500 scientists, economists, and policymakers from more than 120 countries, said that humans have been the primary cause of global warming since 1950. Humans have ways to cut greenhouse gas emissions and avoid the consequences of global warming, a major climate report concluded. But to change the climate, the transition from fossil fuels like coal and oil needs to occur within decades, according to the final report this year from the UN's Intergovernmental Panel on Climate Change (IPCC).
Some of the more common soil contaminants are chlorinated hydrocarbons (CFH), heavy metals (such as chromium, cadmium–found in rechargeable batteries, and lead–found in lead paint, aviation fuel and still in some countries, gasoline), MTBE, zinc, arsenic and benzene. In 2001 a series of press reports culminating in a book called "Fateful Harvest" unveiled a widespread practice of recycling industrial byproducts into fertilizer, resulting in the contamination of the soil with various metals. Ordinary municipal landfills are the source of many chemical substances entering the soil environment (and often groundwater), emanating from the wide variety of refuse accepted, especially substances illegally discarded there, or from pre-1970 landfills that may have been subject to little control in the U.S. or EU. There have also been some unusual releases of polychlorinated dibenzodioxins, commonly called "dioxins" for simplicity, such as TCDD.
Pollution can also be the consequence of a natural disaster. For example, hurricanes often involve water contamination from sewage, and petrochemical spills from ruptured boats or automobiles. Larger scale and environmental damage is not uncommon when coastal oil rigs or refineries are involved. Some sources of pollution, such as nuclear power plants or oil tankers, can produce widespread and potentially hazardous releases when accidents occur.
In the case of noise pollution the dominant source class is the motor vehicle, producing about ninety percent of all unwanted noise worldwide.
Effects.
Human health.
Adverse air quality can kill many organisms including humans. Ozone pollution can cause respiratory disease, cardiovascular disease, throat inflammation, chest pain, and congestion. Water pollution causes approximately 14,000 deaths per day, mostly due to contamination of drinking water by untreated sewage in developing countries. An estimated 500 million Indians have no access to a proper toilet, Over ten million people in India fell ill with waterborne illnesses in 2013, and 1,535 people died, most of them children. Nearly 500 million Chinese lack access to safe drinking water. A 2010 analysis estimated that 1.2 million people died prematurely each year in China because of air pollution. The WHO estimated in 2007 that air pollution causes half a million deaths per year in India. Studies have estimated that the number of people killed annually in the United States could be over 50,000.
Oil spills can cause skin irritations and rashes. Noise pollution induces hearing loss, high blood pressure, stress, and sleep disturbance. Mercury has been linked to developmental deficits in children and neurologic symptoms. Older people are majorly exposed to diseases induced by air pollution. Those with heart or lung disorders are at additional risk. Children and infants are also at serious risk. Lead and other heavy metals have been shown to cause neurological problems. Chemical and radioactive substances can cause cancer and as well as birth defects.
Environment.
Pollution has been found to be present widely in the environment. There are a number of effects of this:
Environmental health information.
The Toxicology and Environmental Health Information Program (TEHIP) at the United States National Library of Medicine (NLM) maintains a comprehensive toxicology and environmental health web site that includes access to resources produced by TEHIP and by other government agencies and organizations. This web site includes links to databases, bibliographies, tutorials, and other scientific and consumer-oriented resources. TEHIP also is responsible for the Toxicology Data Network (TOXNET) an integrated system of toxicology and environmental health databases that are available free of charge on the web.
TOXMAP is a Geographic Information System (GIS) that is part of TOXNET. TOXMAP uses maps of the United States to help users visually explore data from the United States Environmental Protection Agency's (EPA) Toxics Release Inventory and Superfund Basic Research Programs.
Regulation and monitoring.
To protect the environment from the adverse effects of pollution, many nations worldwide have enacted legislation to regulate various types of pollution as well as to mitigate the adverse effects of pollution.
Pollution control.
Pollution control is a term used in environmental management. It means the control of emissions and effluents into air, water or soil. Without pollution control, the waste products from consumption, heating, agriculture, mining, manufacturing, transportation and other human activities, whether they accumulate or disperse, will degrade the environment. In the hierarchy of controls, pollution prevention and waste minimization are more desirable than pollution control. In the field of land development, low impact development is a similar technique for the prevention of urban runoff.
Perspectives.
The earliest precursor of pollution generated by life forms would have been a natural function of their existence. The attendant consequences on viability and population levels fell within the sphere of natural selection. These would have included the demise of a population locally or ultimately, species extinction. Processes that were untenable would have resulted in a new balance brought about by changes and adaptations. At the extremes, for any form of life, consideration of pollution is superseded by that of survival.
For humankind, the factor of technology is a distinguishing and critical consideration, both as an enabler and an additional source of byproducts. Short of survival, human concerns include the range from quality of life to health hazards. Since science holds experimental demonstration to be definitive, modern treatment of toxicity or environmental harm involves defining a level at which an effect is observable. Common examples of fields where practical measurement is crucial include automobile emissions control, industrial exposure (e.g. Occupational Safety and Health Administration (OSHA) PELs), toxicology (e.g. LD50), and medicine (e.g. medication and radiation doses).
"The solution to pollution is dilution", is a dictum which summarizes a traditional approach to pollution management whereby sufficiently diluted pollution is not harmful. It is well-suited to some other modern, locally scoped applications such as laboratory safety procedure and hazardous material release emergency management. But it assumes that the dilutant is in virtually unlimited supply for the application or that resulting dilutions are acceptable in all cases.
Such simple treatment for environmental pollution on a wider scale might have had greater merit in earlier centuries when physical survival was often the highest imperative, human population and densities were lower, technologies were simpler and their byproducts more benign. But these are often no longer the case. Furthermore, advances have enabled measurement of concentrations not possible before. The use of statistical methods in evaluating outcomes has given currency to the principle of probable harm in cases where assessment is warranted but resorting to deterministic models is impractical or infeasible. In addition, consideration of the environment beyond direct impact on human beings has gained prominence.
Yet in the absence of a superseding principle, this older approach predominates practices throughout the world. It is the basis by which to gauge concentrations of effluent for legal release, exceeding which penalties are assessed or restrictions applied. One such superseding principle is contained in modern hazardous waste laws in developed countries, as the process of diluting hazardous waste to make it non-hazardous is usually a regulated treatment process. Migration from pollution dilution to elimination in many cases can be confronted by challenging economical and technological barriers.
Greenhouse gases and global warming.
Carbon dioxide, while vital for photosynthesis, is sometimes referred to as pollution, because raised levels of the gas in the atmosphere are affecting the Earth's climate. Disruption of the environment can also highlight the connection between areas of pollution that would normally be classified separately, such as those of water and air. Recent studies have investigated the potential for long-term rising levels of atmospheric carbon dioxide to cause slight but critical increases in the acidity of ocean waters, and the possible effects of this on marine ecosystems.
Most polluted places in the developing world.
The Blacksmith Institute, an international non-for-profit organization dedicated to eliminating life-threatening pollution in the developing world, issues an annual list of some of the world's worst polluted places. In the 2007 issues the ten top nominees, already industrialized countries excluded, are located in Azerbaijan, China, India, Peru, Russia, Ukraine and Zambia.
External links.
 Media related to at Wikimedia Commons

</doc>
<doc id="24873" url="http://en.wikipedia.org/wiki?curid=24873" title="Pole weapon">
Pole weapon

A pole weapon or polearm is a close combat weapon in which the main fighting part of the weapon is fitted to the end of a long shaft, typically of wood, thereby extending the user's effective range. Glaives, poleaxes, halberds, and naginata are all varieties of polearms.
The purpose of using pole weapons is either to extend reach or to increase angular momentum—and thus striking power—when the weapon is swung. Because they contain relatively little metal, polearms are cheap to make. This has made them the favored weapon of peasant levies and peasants in rebellion the world over. Many are adapted from farm implements, or other tools.
Polearms were common weapons on medieval European battlefields. Their range and impact force made them effective weapons against armored warriors on horseback, because they could penetrate armor. The Renaissance saw a plethora of different varieties. Polearms in modern times are largely constrained to ceremonial military units such as the Papal Swiss Guard or Yeomen of the Guard or traditional martial arts. Chinese Martial Arts in particular have preserved a wide variety of weapons and techniques.
Classification difficulties.
The classification of pole weapons can be difficult, and European weapon classifications in particular can be confusing. This can be due to a number of factors, including uncertainty in original descriptions, changes in weapons or nomenclature through time, mistranslation of terms, and the well-meaning inventiveness of later experts. For example, the word 'halberd' is also used to translate the Chinese ji and also a range of medieval Scandinavian weapons as described in sagas, such as the atgeir.
In the words of the arms expert Ewart Oakeshott,
Staff-weapons in Medieval or Renaissance England were lumped together under the generic term "staves" but when dealing with them in detail we are faced with terminological difficulty. There never seems to have been a clear definition of what was what; there were apparently far fewer staff-weapons in use than there were names to call them by; and contemporary writers up to the seventeenth century use these names with abandon, calling different weapons by the same name and similar weapons by different names. To add to this, we have various nineteenth century terminologies used by scholars. We must remember too that any particular weapon ... had everywhere a different name.
List of pole weapons.
Dark Ages/Medieval Europe.
Danish axe.
The Danish Axe (also Broad Axe, Dane-axe) is a weapon with a heavy crescent-shaped head mounted on a haft 4 ft. to 6 ft. (1.2-1.8 m.) in length. Originally a Viking weapon, it was adopted by the Anglo-Saxons and Normans in the 11th century, spreading through Europe in the 12th and 13th centuries. Variants of this basic weapon continued in use in Scotland and Ireland into the 16th century. A form of 'Long Axe'.
Sparth axe.
In the 13th century, variants on the Danish axe are seen. Described in English as a "sparth" (from the Old Norse "sparðr") or "pale-axe", the weapon featured a larger head with broader blade, the rearward part of the crescent sweeping up to contact (or even be attached to) the haft.
In Ireland, this axe was known as a "Sparr Axe". Originating in either Western Scotland or Ireland, the "sparr" was widely used by the galloglass. Although sometimes said to derive from the Irish for a joist or beam, a more likely definition is as a variant of sparth. Although attempts have been made to suggest that the sparr had a distinctive shaped head, illustrations and surviving weapons show there was considerable variation and the distinctive feature of the weapon was its long haft.
Fauchard.
A fauchard is a type of polearm which was used in medieval Europe from the 11th through the 14th centuries. The design consisted of a curved blade put atop a 6 to pole. The blade bore a moderate to strong curve along its length; however, unlike a glaive, the cutting edge was on the concave side (similar to a scythe or sickle). Later variants had one or more spear points attached to the back or top of the blade for stabbing. The later variant can easily be confused with the guisarme or bill-guisarme, since it superficially appears to have a "hook".
Guisarme.
A guisarme (sometimes gisarme, giserne or bisarme) was a pole weapon used in Europe primarily between 1000–1400. It was used primarily to dismount knights and horsemen. Like most polearms it was developed by peasants by combining hand tools with long poles, in this case by putting a pruning hook onto a spear shaft. While hooks are fine for dismounting horsemen from mounts, they lack the stopping power of a spear especially when dealing with static opponents. While early designs were simply a hook on the end of a long pole, later designs implemented a small reverse spike on the back of the blade. Eventually weapon makers incorporated the usefulness of the hook in a variety of different polearms and "guisarme" became a catch-all for any weapon that included a hook on the blade. Ewart Oakeshott has proposed an alternative description of the weapon as a crescent shaped socketed axe.
Glaive.
A glaive is a polearm consisting of a single-edged tapering blade similar in shape to a modern kitchen knife on the end of a pole. The blade was around 18 inches (55 cm) long, on the end of a pole 6 or 7 feet (180–210 cm) long However, instead of having a tang like a sword or naginata, the blade is affixed in a socket-shaft configuration similar to an axe head, both the blade and shaft varying in length. Illustrations in the 13th century Maciejowski Bible show a short staffed weapon with a long blade used by both infantry and cavalry. Occasionally glaive blades were created with a small hook or spike on the reverse side. Such glaives are named glaive-guisarme.
Voulge.
A voulge (occasionally called a pole cleaver) is a curved blade attached to a pole by binding the lower 2/3 of the blade to the side of the pole, to form a sort of axe. Looks very similar to a glaive. Similar to the Sparth Ax(?).
Svärdstav.
A svärdstav (literally sword-staff) is a Swedish medieval polearm that consists of a two-edged sword blade attached to a 2 metre staff. The illustrations often show the weapon being equipped with sword-like quillons. The illustrations sometimes show a socket mount and reinforcing langets being used, but sometimes they are missing; it is possible this weapon was sometimes manufactured by simply attaching an old sword blade onto a long pole on its tang, not unlike the naginata.
Renaissance Europe.
Corseque.
A corseque has a three-bladed head on a 6–8 ft. (1.8m-2.5m.) haft which, like the partisan, similar to the winged spear or spetum in the later Middle Ages. It was popular in Europe in the 16th and 17th centuries. Surviving examples have a variety of head forms but there are two main variants, one with the side blades (known as flukes or wings) branching from the neck of the central blade at 45 degrees, the other with hooked blades curving back towards the haft. The corseque is usually associated with the rawcon, ranseur and runka. Another possible association is with the "three-grayned staff" listed as being in the armoury of Henry VIII in 1547 (though the same list also features 84 rawcons, suggesting the weapons were not identical in 16th century English eyes). Another modern term used for particularly ornate-bladed corseques is the "chauve-souris".
Halberd.
A halberd (or Swiss voulge) is a two-handed pole weapon that came to prominent use during the 14th and 15th centuries but has continued in use as a ceremonial weapon to the present day. First recorded as "hellembart" in 1279, the word "halberd" possibly comes from the German words "Halm" (staff) or "Helm" (helmet), and "Barte" (axe). The halberd consists of an axe blade topped with a spike mounted on a long shaft. It always has a hook or thorn on the back side of the axe blade for grappling mounted combatants. Early forms are very similar in many ways to certain forms of voulge, while 16th century and later forms are similar to the pollaxe. The Swiss were famous users of the halberd in the medieval and renaissance eras, with various cantons evolving regional variations of the basic form.
Poleaxe.
In the 14th century, the basic long axe gained an armour piercing spike on the back and another on the end of the haft for thrusting. This is similar to the pollaxe of 15th century. The poleaxe emerged in response to the need for a weapon that could penetrate plate armour and featured various combinations of an axe-blade, a back-spike and a hammer. It was the favoured weapon for men-at-arms fighting on foot into the sixteenth century.
See also Bec de corbin, lucerne hammer
Asia.
Dagger-axe.
The dagger-axe, or "gee" (Chinese: 戈; pinyin: gē; Wade–Giles: ko; sometimes confusingly translated "halberd") is a type of weapon that was in use from Shang dynasty until at least Han dynasty China. It consists of a dagger-shaped blade made of bronze (or later iron) mounted by the tang perpendicular wooden shaft. A common Bronze Age infantry weapon. Also used by charioteers. Some dagger axes include a spear-point. There is a (rare) variant type with a divided two-part head, consisting of the usual straight blade and a scythe-like blade. Other rarities include archaeology findings with 2 or sometimes 3 blades stacked in line on top of a pole, but were generally thought as ceremonial polearms. Though the weapon saw frequent use in ancient China, the use of the dagger-axe decreased dramatically after the Qin and Han dynasties. By the medieval Chinese dynasties, with the decline of chariot warfare, the use of the dagger-axe was almost nonexistent.
Guan dao.
A Guan dao or Kwan tou is a type of Chinese pole weapon. In Chinese it is properly called a Yanyue dao (偃月刀) which translates as "reclining moon blade". Some believed it comes from the late Han Era and supposedly used by the late Eastern Han Dynasty general Guan Yu, but archaeological findings so far showed that Han dynasty armies were generally using straight single-edged blades, as curved blades came several centuries later. There is no reason to believe their polearms had curved-blades on them. Besides, historical accounts of the Three Kingdoms era had several specific records of Guan Yu thrusting his opponents down (probably with a spear-like polearm) in battles, instead of cutting them down with a curved-blade. Alternatively the guan dao is also known as "Chun Qiu Da Dao" ("Spring Autumn Great Knife"), again probably related to Guan Yu's loyal image depicted in the Ming dynasty novel "Romance of the Three Kingdoms", but possibly a Ming author's invention. It consists of a heavy blade mounted atop a 5 to wooden or metal pole with a pointed metal counter weight used for striking and stabbing on the opposite end.
The blade is very deep and curved on its face; this resembles a Chinese Sabre or Dao. Used by cavalry. Supposed to take great physical prowess to wield in combat due to great weight. Variants include having rings along the length of the straight back edge as found in the nine-ring guan dao for use as distractions or entanglements for incoming enemy weapons, having the tip curl into a rounded spiral as in the elephant guan dao, or featuring a more ornate design as exemplified by the dragon head guan dao.
Pu Dao.
Chinese polearm, a 'long-handled sabre', also known as the zhan ma dao (horsecutter sabre) which has a lighter blade and a ring at the end in that it. A pu dao is an infantryman's weapon mainly used for cutting the legs off oncoming charging horses to bring down the riders.
Ji.
Ji (Chinese: 戟), the Chinese halberd, was used as a military weapon in one form or another from at least as early as the Shang dynasty until the end of the Qing dynasty. The ji resembles a Chinese spear with a crescent blade attached to the head, as sort of an axe blade. Sometimes double-bladed with 2 crescent blades on opposing sides of the spearhead.(refer to the right most weapons in the 2 Chinese polearm pictures)
Naginata.
A naginata (なぎなた or 薙刀) is a Japanese polearm that was traditionally used by members of the samurai class. A naginata consists of a wood shaft with a curved blade on the end; it is descended from the Chinese guan dao. Usually it also had a sword-like guard (tsuba) between the blade and shaft. It was mounted with a tang and held in place with a pin or pins, rather than going over the shaft using a socket.
Nagamaki.
A nagamaki is a pole weapon that was traditionally used in Japan by members of the samurai class, typically against mounted opponents. It had a much shorter grip and longer blade than the naginata, and was developed later. Unlike most Japanese weapons, there were no specific rules about exact measurements and proportions for nagamaki. It varies from typical European construction of polearms in that, like most Japanese weapons, it was mounted with a tang and held in place with a pin or pins, rather than going over the shaft using a socket. It may have been manufactured using a remounted sword blade.
Woldo.
The Korean woldo was a variation of the Chinese guan dao. It was originally used by the medieval Shilla warriors. Wielding the woldo took time due to its weight, but in the hands of a trained soldier, the woldo was a fearsome, agile weapon famous for enabling a single soldier to cut down ranks of infantrymen. The woldo was continually in use for the military in Korea with various modifications made over the decades. Unlike the Chinese with the guan dao, the Koreans found the woldo unwieldy on horseback, and thus, it was specifically tailored to the needs of infantrymen. The Joseon government implemented rigorous training regimens requiring soldiers to be proficient with swordsmanship, and the use of the woldo. Though it was never widely used as a standard weapon, the woldo saw action on many fronts and was considered by many Korean troops to be a versatile weapon. Recently, a contemporary revival in various martial arts in Korea has brought interest into the application of the woldo and its history.
Ngao.
The ngao or ngau (ง้าว,ของ้าว) is a Thai polearm that was traditionally used by elephant-riding infantry and is still used by practitioners of krabi krabong. Known in Malay as a "dap", it consists of a wooden shaft with a curved blade fashioned onto the end, and is similar in design to the Korean woldo. Usually, it also had a hook (ขอ) between the blade and shaft used for commanding the elephant. The elephant warrior used the ngao like a blade from atop an elephant or horse during battle.

</doc>
<doc id="24874" url="http://en.wikipedia.org/wiki?curid=24874" title="PHD">
PHD

PHD or PhD may refer to:

</doc>
<doc id="24875" url="http://en.wikipedia.org/wiki?curid=24875" title="Personal jurisdiction">
Personal jurisdiction

Personal jurisdiction is a court's jurisdiction over the "parties" to a lawsuit, as opposed to subject-matter jurisdiction, which is jurisdiction over the "law and facts" involved in the suit. If a court does not have "personal" jurisdiction over a party, its rulings or decrees cannot be enforced upon that party, except by comity, that is, to the extent the sovereign that does have jurisdiction over the party allows the court to enforce them upon that party. A court that has "personal" jurisdiction has both the authority to rule on the law and facts of a suit and the power to enforce its decision upon a party to the suit. In some cases, territorial jurisdiction may also constrain a court's reach, such as preventing hearing of a case concerning events occurring on foreign territory between two citizens of the home jurisdiction.
International principles.
Since there is no world government which all countries recognize to arbitrate disputes over jurisdiction, sovereign powers can find themselves in conflict over which is the more appropriate venue to hear a case, or which country's laws should apply. These conflicts are sometimes resolved de facto by physical factors, such as which country has physical possession of a defendant or property, or sometimes by use of physical police or military force to seize people or property. A country with loose rule of law - for example an absolute monarchy with no independent judiciary - may arbitrarily choose to assert jurisdiction over a case without citing any particular justification. Such assertion can cause problems, such as encouraging other countries to take arbitrary actions over foreign citizens and property, or even provoking skirmishes or armed conflict.
In practice, many countries operate by one or another principles, either in written law or in practice, which communicate when the country will and will not assert jurisdiction.
Different principles are applied by different countries, and different principles may be applied by the same country in different circumstances. Determination of whether or not a court has jurisdiction to hear a case is the first stage of a conflict of laws proceeding, potentially followed by choice of law to determine which jurisdiction's laws apply. Executive prosecutorial authority and foreign policy also play a role in scope and practical impact of jurisdiction choices.
Any assertion of jurisdiction based on anything other than the territorial principle is known as extraterritorial jurisdiction. Prosecution of a case against an out-of-territory defendant is known as assertion of long arm jurisdiction.
When a person commits a crime in a foreign country against the laws of that country, usually the host country is responsible for prosecution. The Vienna Convention on Consular Relations requires that the host country notify the foreign embassy, potentially allowing the foreign country to assist in legal defense and monitor conditions of detention. (Most countries protect their citizens against foreign powers in general.)
Foreign diplomats enjoy diplomatic immunity in many countries based on the Vienna Convention on Diplomatic Relations or bilateral agreement, and foreign military personnel may be subject to the jurisdiction of their home country based on a status of forces agreement or Visiting Forces Agreement.
If a person is not physically present in the country which wishes to prosecute a case, that country may either wait until the person enters the national territory, or pursue extradition by legal or extralegal means, and with or without a general extradition treaty. Some countries (like China) prefer to prosecute their own citizens for crimes committed abroad rather than extradite them. Other countries defer to the host country.
When a crime is committed outside the territory of any country, such as in Antarctica, on watercraft in international waters, on aircraft in international airspace, and on spacecraft, jurisdiction is usually determined by the nationality of defendants or victims, or by the flag state of the vessel. This is determined by the admiralty law of the countries involved and in international agreements.
History in English and U.S. law.
The concept of personal jurisdiction in English law has its origin in the idea that a monarch could not exercise power over persons or property located outside of his or her kingdom. To some degree, this was a de facto rule; the monarch's men could not arrest people or seize property outside the kingdom without risking physical conflict with the soldiers and police of other kingdoms. Slowly this principle was incorporated into written law, but problems arose in cases where property owners could not be sued because they had left the kingdom or had died and therefore were not present within the kingdom at the time they were being sued. To solve this problem, the courts created another type of jurisdiction, called "quasi in rem", that is, jurisdiction over the land itself, even if the person who owned the land was not in the country. However, this jurisdiction was limited to the settlement of debts owed by the owner of the land.
In the United States, the exercise of personal jurisdiction by a court must both comply with Constitutional limitations, and be authorized by a statute. In the United Kingdom, the exercise of personal jurisdiction does not need a statutory basis, since the United Kingdom does not have a written constitution.
United States.
The intersection of American federalism and the rules and theories of jurisdiction inherited from the common law of England has resulted in a highly complex body of law respecting personal jurisdiction in the United States. These rules limit both state and federal courts in their ability to hear cases.
Principles of personal jurisdiction.
Three fundamentals of personal jurisdiction constrain the ability of courts in the United States to bind individuals or property to its decisions: consent, power, and notice.
Consent.
The United States legal system is an adversarial system. Civil suits cannot be initiated by third parties, but must be filed by the aggrieved party who seeks redress. Generally, the action is initiated in the jurisdiction where the event occurred, where the defendant can be served or where the parties have agreed to have the case located. The filing of a complaint or "prayer for relief" is a voluntary action by the person aggrieved, and as a necessity of this request, the person seeking relief consents to be bound by the judgment of the court. The doctrine of consent is also extended to defendants who attend and litigate actions without challenging the court's personal jurisdiction. Consent may also derive from a pre-litigation agreement by the parties, such as a forum selection clause in a contract (not to be confused with a choice of law clause). Doctrines such as claim preclusion prevent re-litigation of failed complaints in alternative forums. Claim preclusion does not, however, prevent the refiling of a claim that was filed in a court that did not have personal jurisdiction over the defendant.
Power.
In cases where a defendant challenges personal jurisdiction, a court may still exercise personal jurisdiction if it has independent power to do so. This power is founded in the inherent nature of the State: sovereignty over affairs within its territory.
Notice.
The Fifth and Fourteenth Amendment to the United States Constitution preserve the right of the individual to "due process". Due process requires that notice be given in a manner "reasonably calculated" to inform a party of the action affecting him. Originally, "Notice" (and the power of the State) was often exercised more forcefully, the defendant in a civil case sometimes being seized and brought before the court under a writ of "capias ad respondendum". Notice in such a case is inferred from consent of the defendant to go with the officer. Nowadays, when exercising power over an individual without consent, notice is usually given by formal delivery of suitable papers to the defendant (service of process).
Historical background: territorial jurisdiction.
Originally, jurisdiction over parties in the United States was determined by strict interpretation of the geographic boundaries of each state's sovereign power. In "Pennoyer v. Neff", the Supreme Court discussed that though each state ceded certain powers (e.g. foreign relations) to the Federal Government or to no entity at all (e.g. the powers that are eliminated by the protections of the bill of rights), the states retained all the other powers of sovereignty, including the exclusive power to regulate the affairs of individuals and property within its territory. Necessarily following from this, one state's exercise of power could not infringe upon the sovereignty of another state. Thus, Constitutional limitations applied to the validity of state court judgments.
Three types of jurisdiction developed, collectively termed territorial jurisdiction because of their reliance upon territorial control: "in personam" jurisdiction, "in rem" jurisdiction, and "quasi in rem" jurisdiction. Some sources refer to all three types of territorial jurisdiction as personal jurisdiction, since most actions against property (in rem jurisdiction) bear, in the end, upon the rights and obligations of persons. Others continue to recognize the traditional distinction between personal jurisdiction and jurisdiction over property, even after "Shaffer v. Heitner" (discussed below). 
In personam jurisdiction referred to jurisdiction over a particular person (or entity, such as a company). "In personam" jurisdiction, if held by a state court, permitted that court to rule upon any case over which it otherwise held jurisdiction. Under territorial jurisdiction, pure "in personam" jurisdiction could only be established by serving notice upon the individual while that individual was within the territory of the state.
In rem jurisdiction referred to jurisdiction over a particular piece of property, most commonly real estate or land. Certain cases, notably government suits for unpaid property taxes, proceed not against an individual but against their property directly. Under territorial jurisdiction, "in rem" jurisdiction could be exercised by the courts of a state by seizing the property in question. Since an actual tract of land could not literally be brought into a courtroom as a person could, this was effected by giving notice upon the real property itself. "In rem" jurisdiction was thus supported by the assumption that the owner of that property, having a concrete economic interest in the property, had a duty to look after the affairs of their property, and would be notified of the pending case by such seizure. "In rem" jurisdiction was limited to deciding issues regarding the specific property in question.
Quasi in rem jurisdiction involved the seizure of property held by the individual against whom the suit was brought, and attachment of that property to the case in question. This form of territorial jurisdiction developed from the rationale of "in rem" jurisdiction, namely that seizure of the property was reasonably calculated to inform an individual of the proceedings against them.
Once a valid judgment was obtained against an individual, however, the plaintiff could pursue recovery against the assets of the defendant regardless of their location, as other states were obligated by the Full Faith and Credit Clause of the Constitution to recognize such a judgment (i.e. had ceded their power to refuse comity to fellow states of the Union). Violations by a rogue state could be checked via collateral attack: when a plaintiff sought recovery against a defendant's assets in another state, that state could refuse judgment on the grounds that the original judgment was invalid.
Difficulties in applying "Pennoyer" territorial jurisdiction.
Following "Pennoyer", extreme applications of territorial jurisdiction revealed imperfections in the doctrine, and societal changes began to present new problems as the United States' national economy became more integrated by increasingly efficient multi-state transportation technology and business practices.
While determining the physical location of an individual for the purposes of "in personam" jurisdiction was easy enough, applying the same principle to non-physical entities became difficult. Courts were presented with the question of where a company was present and amenable to service for the purpose of "in personam" jurisdiction over the company.
Extension of "quasi in rem" jurisdiction led to extreme results that threatened the justification for the jurisdiction. Bearing in mind that territorial jurisdiction existed in a pre-industrial society where transportation across the country was difficult, long, and potentially treacherous, and consider the hypothetical wherein A owes B money, and B owes C, a resident of New York, money. C seeks to recover on B's debt to C, however cannot do so because B avoids C by travelling to California. A, however, happens to travel through New York. C serves notice upon A, and attaches A's debt to B (considered to be property within the state) to the proceeding. A can no more certainly provide notice to B in California than C could provide, and the transient and involuntary exposure of B to being haled into court in New York by this attachment seems to erode the original rationale of "quasi in rem" jurisdiction. 
The US Supreme Court, largely abolished the exercise of jurisdiction on the basis of 'quasi in rem' in "Shaffer v. Heitner", except in exceptional circumstances, which sometimes would arise while dealing with real property such as land, and when the owner of the land cannot be found.
Modern Constitutional doctrine: "International Shoe" doctrine.
In the modern era, the reach of personal jurisdiction has been expanded by judicial re-interpretation and legislative enactments. Under the new and current doctrine, a state court may only exert personal jurisdiction over an individual or entity with "sufficient minimal contacts" with the forum state such that the particular suit "does not offend 'traditional notions of fair play and justice.'" The "minimum contacts" must be purposefully directed towards the state by the defendant. This jurisdiction was initially limited to the particulars of the International Shoe Co. v. Washington holding, that is to jurisdictional inquiries regarding companies, but was soon extended to apply to all questions of personal jurisdiction. When an individual, or entity, has no "minimum contacts" with a forum State, the Due Process Clause of the Fourteenth Amendment prohibits that State from acting against that individual, or entity. The lack of "minimum contacts" with the owner of property also constitutionally prohibits action against that property (in rem jurisdiction) even when the property is located within the forum state.
What constitutes sufficient "minimum contacts" has been delineated in numerous cases which followed the International Shoe decision. For example, in "Hanson v. Denckla", the Court proclaimed the "unilateral activity of those who claim some relationship with a nonresident cannot satisfy the requirement of contact with the forum State. The application of that rule will vary with the nature and quality of the defendant's activity, but it is essential in each case that there be some act by which the defendant purposefully avails itself of the privilege of conducting activities within the forum State, thus invoking the benefits and protection of its laws."
The additional requirement of "'purposeful availment' ensures that a defendant will not be hauled into a jurisdiction solely as a result of 'random,' 'fortuitous,' or 'attenuated' contacts, [citations omitted] or of the unilateral activity of another party or a third person [citation omitted] Jurisdiction may, however, be exercised, under some circumstances, even though the defendant never physically entered the forum State.
In addition, the claim must arise from the those contacts to which the defendant had with the forum state. In addition to the minimum contacts test asserted in International Shoe, the assertion of specific personal jurisdiction must be reasonable. The court in "World-Wide" asserted a five part test for determining if the assertion of personal jurisdiction in a forum state was reasonable. This test considers: the burden on the defendant from litigating the forum state; the interest of the forum state to have the case adjudicated there; the interests of the plaintiff in adjudicating in the forum state; the interests of the inter-state judiciary—that is, that a court's assertion of personal jurisdiction over an out-of state defendant would not overreach and preempt the interests and judicial sovereignty of another state and; the interests in preserving the judicial integrity of the several states—that is, ensuring one court's assertion of personal jurisdiction over an out of state defendant does not violate the Due Process Clause of the Fourteenth Amendment.
In another recent case of "Goodyear Dunlop Tires Operations, S. A. v. Brown" Justice Ginsburg held that for the exercise of general jurisdiction in personam, the defendant must be "essentially at home". This applies when the defendant has contacts with the forum state, but the claim that arises is not related to those contacts. For example, if Harrods (UK) sets up an office in California, to export and sell goods there and because of that someone gets injured, it would be amenable to suit in California for that injury. But, on the other hand if someone is injured in Harrods, London and for some reason finds that California law is more favorable decides to sue in California, the suit would not be maintainable since the contacts that Harrods have is not continuous and systematic, and they are not 'essentially at home' in California.
This holding was reaffirmed in 2014 by the Supreme Court in Daimler.
Statutory authorization.
While the "Pennoyer" and later "Shoe" doctrines limit the maximum power of a sovereign state, courts must also have authorization to exercise the state's power; an individual state may choose to not grant its courts the full power that the state is Constitutionally permitted to exercise. Similarly, the jurisdiction of Federal courts (other than the Supreme Court) are statutorily-defined. Thus, a particular exercise of personal jurisdiction must not only be permitted by Constitutional doctrine, but be statutorily authorized as well. Under "Pennoyer", personal jurisdiction was authorized by statutes authorizing service of process, but these methods of service often lacked because they required such service to be effected by officers of the state, such as sheriffs – an untenable method for defendants located outside of the state but still subject to jurisdiction due to their contacts with the state. Subsequent to the development of the "Shoe" Doctrine, states have enacted so-called long-arm statutes, by which courts in a state can serve process and thus exercise jurisdiction over a party located outside the state. The doctrine of International shoe applies only in cases where there is no presence in the forum state. For example, if A committed a tort in State X. He is sued by B and B serves him with process just before he leaves State X before the flight was took off, the service would be valid and State X would have jurisdiction over A. If A did not comply with the final judgement passed by the courts of State X, B could enforce that judgement in the state where A resides under the full faith and credit clause of the US Constitution. There was one case where a defendant was served while the airplane was in the air over the forum State, and the federal district court held that this was valid service, since at law the territory of a state includes the airspace above the State. , 170 F. Supp. 442 (E.D. Ark. 1959). 
Relationship to venue.
Venue and personal jurisdiction are closely related for practical purposes. A lawyer should usually perform joint analysis of personal jurisdiction and venue issues. Personal jurisdiction is largely a constitutional requirement, though also shaped by state long-arm statutes and Rule 4 of the Federal Rules of Civil Procedure, while venue is purely statutory.
It is possible for either venue or personal jurisdiction to preclude a court from hearing a case. Consider these examples:

</doc>
<doc id="24877" url="http://en.wikipedia.org/wiki?curid=24877" title="Pell's equation">
Pell's equation

Pell's equation is any Diophantine equation of the form
where "n" is a given positive nonsquare integer and integer solutions are sought for "x" and "y". In Cartesian coordinates, the equation has the form of a hyperbola; solutions occur wherever the curve passes through a point whose "x" and "y" coordinates are both integers, such as the trivial solution with "x" = 1 and "y" = 0. Joseph Louis Lagrange proved that, as long as "n" is not a perfect square, Pell's equation has infinitely many distinct integer solutions. These solutions may be used to accurately approximate the square root of "n" by rational numbers of the form "x/y".
This equation was first studied extensively in India, starting with Brahmagupta, who developed the "chakravala" method to solve Pell's equation and other quadratic indeterminate equations in his "Brahma Sphuta Siddhanta" in 628, about a thousand years before Pell's time. His "Brahma Sphuta Siddhanta" was translated into Arabic in 773 and was subsequently translated into Latin in 1126. Bhaskara II in the 12th century and Narayana Pandit in the 14th century both found general solutions to Pell's equation and other quadratic indeterminate equations. Solutions to specific examples of the Pell equation, such as the Pell numbers arising from the equation with "n" = 2, had been known for much longer, since the time of Pythagoras in Greece and to a similar date in India. The name of Pell's equation arose from Leonhard Euler's mistakenly attributing its study to John Pell. Euler was aware of the work of Lord Brouncker, the first European mathematician to find a general solution of the equation, but apparently confused Brouncker with Pell.
For a more detailed discussion of much of the material here, see Lenstra (2002) and Barbeau (2003).
History.
As early as 400 BC in India and Greece, mathematicians studied the numbers arising from the "n" = 2 case of Pell's equation,
and from the closely related equation
because of the connection of these equations to the square root of two. Indeed, if "x" and "y" are positive integers satisfying this equation, then "x"/"y" is an approximation of √2. The numbers "x" and "y" appearing in these approximations, called side and diameter numbers, were known to the Pythagoreans, and Proclus observed that in the opposite direction these numbers obeyed one of these two equations. Similarly, Baudhayana discovered that "x" = 17, "y" = 12 and "x" = 577, "y" = 408 are two solutions to the Pell equation, and that 17/12 and 577/408 are very close approximations to the square root of two.
Later, Archimedes approximated the square root of 3 by the rational number 1351/780. Although he did not explain his methods, this approximation may be obtained in the same way, as a solution to Pell's equation.
Around AD 250, Diophantus considered the equation
where "a" and "c" are fixed numbers and "x" and "y" are the variables to be solved for.
This equation is different in form from Pell's equation but equivalent to it.
Diophantus solved the equation for ("a","c") equal to (1,1), (1,−1), (1,12), and (3,9). Al-Karaji, a 10th-century Persian mathematician, worked on similar problems to Diophantus.
In Indian mathematics, Brahmagupta discovered that
(see Brahmagupta's identity). Using this, he was able to "compose" triples formula_6 and formula_7 that were solutions of formula_8, to generate the new triple
Not only did this give a way to generate infinitely many solutions to formula_11 starting with one solution, but also, by dividing such a composition by formula_12, integer or "nearly integer" solutions could often be obtained. For instance, for formula_13, Brahmagupta composed the triple formula_14 (since formula_15) with itself to get the new triple formula_16. Dividing throughout by 64 gave the triple formula_17, which when composed with itself gave the desired integer solution formula_18. Brahmagupta solved many Pell equations with this method; in particular he showed how to obtain solutions starting from an integer solution of formula_8 for "k" = ±1, ±2, or ±4.
The first general method for solving the Pell equation (for all "N") was given by Bhaskara II in 1150, extending the methods of Brahmagupta. Called the chakravala (cyclic) method, it starts by composing any triple formula_20 (that is, one which satisfies formula_21) with the trivial triple formula_22 to get the triple formula_23, which can be scaled down to
When "m" is chosen so that "(a+bm)/k" is an integer, so are the other two numbers in the triple. Among such "m", the method chooses one that minimizes "(m²-N)/k", and repeats the process. This method always terminates with a solution (proved by Lagrange in 1768). Bhaskara used it to give the solution "x"=1766319049, "y"=226153980 to the notorious "N" = 61 case.
The general theory of Pell's equation, based on continued fractions and algebraic manipulations with numbers of the form formula_25 was developed by Lagrange in 1766–1769.
Solutions.
Fundamental solution via continued fractions.
Let formula_26 denote the sequence of convergents to the regular continued fraction for formula_27. This sequence is unique. Then the pair ("x"1,"y"1) solving Pell's equation and minimizing "x" satisfies "x"1 = "hi" and "y"1 = "ki" for some "i". This pair is called the "fundamental solution". Thus, the fundamental solution may be found by performing the continued fraction expansion and testing each successive convergent until a solution to Pell's equation is found.
As describes, the time for finding the fundamental solution using the continued fraction method, with the aid of the Schönhage–Strassen algorithm for fast integer multiplication, is within a logarithmic factor of the solution size, the number of digits in the pair ("x"1,"y"1). However, this is not a polynomial time algorithm because the number of digits in the solution may be as large as √"n", far larger than a polynomial in the number of digits in the input value "n" .
Additional solutions from the fundamental solution.
Once the fundamental solution is found, all remaining solutions may be calculated algebraically as
Equivalently, we may calculate subsequent solutions via the recurrence relations
An alternative method to solving, once finding the first non-trivial solution, one could take the original equation formula_31 and factor the left hand side as a difference of squares, yielding formula_32 Once in this form, one can simply raise each side of the equation to the kth power, and recombining the factored form to a single difference statement. The solution formula_33 will be of the form formula_34
Concise representation and faster algorithms.
Although writing out the fundamental solution ("x"1,"y"1) as a pair of binary numbers may require a large number of bits, it may in many cases be represented more compactly in the form
using much smaller coefficients "a""i", "b""i", and "c""i".
For instance, Archimedes' cattle problem may be solved using a Pell equation, the fundamental solution of which has 206545 digits if written out explicitly. However, instead of writing the solution as a pair of numbers, it may be written using the formula
where
and formula_38 and formula_39 only have 45 and 41 decimal digits, respectively. Alternatively, one may write even more concisely
In fact, it is equivalent to solving the Pell equation formula_41.
Methods related to the quadratic sieve approach for integer factorization may be used to collect relations between prime numbers in the number field generated by √"n", and to combine these relations to find a product representation of this type. The resulting algorithm for solving Pell's equation is more efficient than the continued fraction method, though it still does not take polynomial time. Under the assumption of the generalized Riemann hypothesis, it can be shown to take time
where "N" = log "n" is the input size, similarly to the quadratic sieve .
Quantum algorithms.
 showed that a quantum computer can find a product representation, as described above, for the solution to Pell's equation in polynomial time. Hallgren's algorithm, which can be interpreted as an algorithm for finding the group of units of a real quadratic number field, was extended to more general fields by .
Example.
As an example, consider the instance of Pell's equation for "n" = 7; that is,
The sequence of convergents for the square root of seven are
Therefore, the fundamental solution is formed by the pair (8, 3). Applying the recurrence formula to this solution generates the infinite sequence of solutions
The smallest solution can be very large. For example, the smallest solution to formula_44 is (32188120829134849, 1819380158564160), and this is the equation which Frenicle challenged Wallis to solve. Values of "n" such that the smallest solution of formula_45 sets a record are
(For these records, see   ("x"), and   ("y")). All such "n"s are squarefree and all such "n"s > 53 are congruent to 13 to mod 24.
The smallest solution of Pell equations.
The following is a list of the smallest solution to formula_31 with "n" ≤ 128. For square "n", there are no solutions except (1, 0). (sequence ("x") and ("y") in OEIS, or   ("x") and   ("y") (for nonsquare "n"))
Connections.
Pell's equation has connections to several other important subjects in mathematics.
Algebraic number theory.
Pell's equation is closely related to the theory of algebraic numbers, as the formula
is the norm for the ring formula_48 and for the closely related quadratic field formula_49. Thus, a pair of integers formula_50 solves Pell's equation if and only if formula_51 is a unit with norm 1 in formula_48. Dirichlet's unit theorem, that all units of formula_48 can be expressed as powers of a single fundamental unit (and multiplication by a sign), is an algebraic restatement of the fact that all solutions to the Pell equation can be generated from the fundamental solution. The fundamental unit can in general be found by solving a Pell-like equation but it does not always correspond directly to the fundamental solution of Pell's equation itself.
Chebyshev polynomials.
Demeyer (2007) mentions a connection between Pell's equation and the Chebyshev polynomials:
If "Ti" ("x") and "Ui" ("x") are the Chebyshev polynomials of the first and second kind, respectively, then these polynomials satisfy a form of Pell's equation in any polynomial ring "R"["x"], with "n" = "x"2 − 1:
Thus, these polynomials can be generated by the standard technique for Pell equations of taking powers of a fundamental solution:
It may further be observed that, if ("xi","yi") are the solutions to any integer Pell equation, then "xi" = "Ti" ("x"1) and "yi" = "y"1"U""i" − 1("x"1) (Barbeau, chapter 3).
Continued fractions.
A general development of solutions of Pell's equation formula_45 in terms of continued fractions of formula_27 can be presented, as the solutions "x" and "y" are approximates to the square root of "n" and thus are a special case of continued fraction approximations for quadratic irrationals.
The relationship to the continued fractions implies that the solutions to Pell's equation form a semigroup subset of the modular group. Thus, for example, if "p" and "q" satisfy Pell's equation, then
is a matrix of unit determinant. Products of such matrices take exactly the same form, and thus all such products yield solutions to Pell's equation. This can be understood in part to arise from the fact that successive convergents of a continued fraction share the same property: If "p""k"−1/"q""k"−1 and "p""k"/"q""k" are two successive convergents of a continued fraction, then the matrix
has determinant (−1)"k".
Størmer's theorem applies Pell equations to find pairs of consecutive smooth numbers. As part of this theory, Størmer also investigated divisibility relations among solutions to Pell's equation; in particular, he showed that each solution other than the fundamental solution has a prime factor that does not divide "n".
As Lenstra (2002) describes, Pell's equation can also be used to solve Archimedes' cattle problem.
The negative Pell equation.
The negative Pell equation is given by
It has also been extensively studied; it can be solved by the same method of using continued fractions and will have solutions when the period of the continued fraction has odd length. However we do not know which roots have odd period lengths so we do not know when the negative Pell equation is solvable. But we can eliminate certain "n" since a necessary but not sufficient condition for solvability is that "n" is not divisible by a prime of form 4"m"+3. Thus, for example, "x"2-3"py"2 = -1 is never solvable, but "x"2-5"py"2 = -1 may be, such as when "p" = 13 or 17 (of course, "p" needs to be with the form 4"m"+1), though not when "p" = 41.
Numbers "n" for which "x"2-"ny"2 = -1 is solvable are
The solutions of "x" (while "n" is in this sequence) are listed in  .
These "n"s are divisible neither by 4 nor by a prime of the form 4"m" + 3, but these conditions are not sufficient --- the counterexamples are listed in  , the first few such "n"s are 34, 146, 178, 194, 205, 221, 305, 377, 386, 410, 466, 482, ... In fact, if and only if the period length of the continued fraction for formula_27 ( ) is odd, then "x"2-"ny"2 = -1 is solvable.
 demonstrate that the proportion of square-free "n" divisible by "k" primes of the form 4m+1 for which the negative Pell equation is solvable is at least 40%. If it does have a solution, then it can be shown that its fundamental solution leads to the fundamental one for the positive case by squaring both sides of eq. 1,
to get,
Or, since ny2 = x2+1 from eq.1, then,
showing that fundamental solutions to the positive case are bigger than those for the negative case.
Transformations.
I. The related equation,
can be used to find solutions to the positive Pell equation for certain "d". Legendre proved that all primes of form "d" = 4"m" + 3 solve one case of eq.2, with the form 8"m" + 3 solving the negative, and 8"m" + 7 for the positive. Their fundamental solution then leads to the one for "x"2−"dy"2 = 1. This can be shown by squaring both sides of eq. 2,
to get,
Since formula_68 from eq.2, then,
or simply,
showing that fundamental solutions to eq.2 are smaller than eq.1. For example, u2-3v2 = -2 is {"u","v"} = {1,1}, so "x"2 − 3"y"2 = 1 has {"x","y"} = {2,1}. On the other hand, "u"2 − 7"v"2 = 2 is {"u","v"} = {3,1}, so "x"2 − 7y2 = 1 has {"x","y"} = {8,3}.
II. Another related equation,
can also be used to find solutions to Pell equations for certain "d", this time for the positive and negative case. For the following transformations, if fundamental {"u","v"} are both odd, then it leads to fundamental {x,y}.
1. If u2 − dv2 = −4, and {x,y} = {("u"2 + 3)"u"/2, ("u"2 + 1)"v"/2}, then "x"2 − "dy"2 = −1.
Ex. Let "d" = 13, then {"u","v"} = {3, 1} and {"x","y"} = {18, 5}.
2. If "u"2 − "dv"2 = 4, and {"x","y"} = {("u"2 − 3)"u"/2, ("u"2 − 1)"v"/2}, then "x"2 − "dy"2 = 1.
Ex. Let "d" = 13, then {u,v} = {11, 3} and {x,y} = {649, 180}.
3. If "u"2 − "dv"2 = −4, and {"x","y"} = {("u"4 + 4"u"2 + 1)("u"2 + 2)/2, ("u"2 + 3)("u"2 + 1)"uv"/2}, then "x"2 − "dy"2 = 1.
Ex. Let "d" = 61, then {"u","v"} = {39, 5} and {"x","y"} = {1766319049, 226153980}.
Especially for the last transformation, it can be seen how solutions to {"u","v"} are "much" smaller than {"x","y"}, since the latter are sextic and quintic polynomials in terms of "u".

</doc>
<doc id="24879" url="http://en.wikipedia.org/wiki?curid=24879" title="Telephone card">
Telephone card

A telephone card, calling card or phonecard for short, is a credit card size plastic card, used to pay for telephone services. It is not necessary to have the physical card except with a stored-value system; knowledge of the access telephone number to dial and the PIN is sufficient. Standard cards which can be purchased and used without any sort of account facility give a fixed amount of credit and are discarded when used up; rechargeable cards can be topped up, or collect payment in arrears. The system for payment and the way in which the card is used to place a telephone call vary from card to card.
Calling cards usually come equipped with PIN for user protection and security. Most companies require user to enter the PIN before granting you access to the calling card’s funds. PINs often are printed on a piece of paper found inside the calling card’s packaging. Once the user makes his first call, some companies offer the option of eliminating the PIN altogether to speed up the calling process. Companies that sell virtual calling cards online typically PIN via email.
Stored-value phone cards.
A stored-value phonecard contains the balance available on the card. This balance can be read by a public payphone machine when the card is inserted into the payphone's card reader. This is superficially similar to a bank automated teller machine, but a stored-value card is more closely analogous to a change purse. While ATMs (as well as the remote memory systems discussed below) use the card merely to identify the associated account and record changes in a central database, stored-value systems make a physical alteration to the card to reflect the new balance after a call. Used primarily for payphones, stored-value systems avoid the time lag and expense of communication with a central database, which would have been prohibitive before the 1990s. There are several ways in which the value can be encoded on the card.
The earliest system used a magnetic stripe as information carrier, similar to the technology of ATMs and key cards. The first magnetic strip phonecard, manufactured by SIDA, was issued in 1976 in Italy.
The next technology used optical storage. Optical phonecards get their name from optical structure embossed inside the cards. This optical structure is heated and destroyed after use of the units. Visible marks are left on the top of the cards, so that the user can see the balance of remaining units. Optical cards were produced by Landis+Gyr and Sodeco from Switzerland and were popular early phonecards in many countries with first optical phonecards successfully introduced in 1977 in Belgium. Such technology was very secure and not easily hackable but chip cards phased out the optical phone cards around the world and the last Landis+Gyr factory closed in May 2006 when optical phonecards were still in use in few countries like Austria, Israel and Egypt.
The third system of stored-value phonecards is chip cards, first launched on a large scale in 1986 in Germany by Deutsche Bundespost after three years of testing, and in France by France Télécom. Many other countries followed suit, including Ireland in 1990 and the UK circa 1994-1995, which phased out the old green Landis+Gyr cards in favor of the chip (smart) cards. The initial microchips were easy to hack, typically by scratching off the programming-voltage contact on the card, which rendered the phone unable to reduce the card's value after a call. But by the mid-to-late 1990s, highly secure technology aided the spread of chip phonecards worldwide.
Making a prepaid or calling card call requires the user to make two calls. Regardless of the type of card it is necessary to dial an access telephone number to connect to the calling card system. There are several methods. One is via a toll-free number, with larger companies offering this internationally. Access through a local number has become increasingly popular in recent years. Toll-free calls are paid for by the recipient (the calling card company), which passes on the cost through higher call charges; total cost of a call to the user is often lower using a local number. When travelling through several local areas a toll-free service may be preferable.
Once connected to the access number, the account is identified by keying in a PIN (the most popular method) or by swiping a card with embedded chip or magnetic stripe. After validation the balance remaining on the card may be announced, and the desired number may be keyed in. The available minutes may be announced, and the call is connected. Many cards make a verbal announcement if credit is running out.
Prepaid or calling cards are usually much cheaper than other telephone services, particularly for travelers who do not have easy access to other services. Hotel telephones can be very expensive, particularly for long-distance calls. Cellular services are flexible, but may attract high roaming charges away from the home area.
Remote memory systems.
Telephone accounts symbolized by a card.
The second main technology of phonecards is remote memory, which uses a toll or toll-free access number to reach the database and check for balance on product. As the United States never had a single nationalized telephone service (or even the same firm for every part of a state), and with the deregulation of its major telecommunications providers, there was no incentive to be consistent with the rest of the world. The ease of use of sliding a card into a machine just as in a teller machine was countered by fears of vandalism of the machines.
The first public prepaid remote memory phonecard was issued in the United States in December 1980 by Phone Line. As telecom industries around the world became deregulated, remote memory cards were issued in various countries. Remote memory phonecards can be used from any tone-mode phone and do not require special card readers. Since remote memory cards are more accessible and have lower costs, remote memory phone cards have proliferated. However, the utility of these cards is reduced by the large number of digits that need to be entered during usage. To call a long distance number, the user first dials the local access number, then keys in the secret code, followed by the actual long distance number. Based on the long distance number entered, the time remaining on the card is announced, and the call is finally processed through.
Remote memory phonecards are in essence text; requiring an access number, a unique PIN and instructions. Therefore the instructions can be printed on virtually anything, or can be delivered via e-mail or the Internet. Currently many websites post phone card details through e-mail.
Phone cards are available in most countries in retail stores, retail chains and commonly post offices or corner stores. In general, remote memory phonecards can be issued by any company and come in countless varieties. They can focus on calling to certain countries or regions and have specific features such as rechargeability, pinless dial, speed dial and more. Phone cards may have connection fees, taxes and maintenance fees, all influencing the rates.
Accounts without a card (Virtual phonecards).
Since the early 2000s calling card service providers have introduced calling accounts not associated with a physical card. Calling accounts can be purchased over the Internet using credit cards and are instantly delivered to the customer via e-mail. This e-mail contains the PIN and instructions for using the service. The service may be prepaid, or may take payment from a credit card or by direct debit. Some prepaid card companies allow accounts to be recharged online manually or automatically via a method called auto-top-up.
Some virtual cards offer PINless Dialing, either by dialling a number unique to the customer, or by recognising the telephone number which originated the call by Caller ID and relating it to the appropriate account. Some virtual phone cards allow customers to view their call detail reports (CDRs) online by logging into their account.
The virtual phonecard has become a multi-billion US dollar industry as of 2009, with a number of large corporations and smaller Dot Com companies. While long-distance inland calls have been offered by calling cards, by the mid-2000s conventional carriers reduced their rates to be competitive; however in many countries calling-card type indirect services can be much cheaper than normal calls.
Phonecard as an artifact or collectible.
Telecom companies have placed advertising on phonecards, or featured celebrity portraits, artwork, or attractive photography. As the supply of any one design is limited, this has led some people to collect disposable phonecards.
The hobby is sometimes called "fusilately" in the UK and a collector is known as a "fusilatelist"; In the USA it is called "telegery". Phonecards have been collected worldwide since the mid-1970s and peaked in the mid-1990s, when over 2 million people collected phonecards.
There are many web sites dedicated to this hobby, some of which offer catalogs and show the stories behind the cards. Colnect is a site providing the world's most extensive online phonecards catalog.
Support in telephones.
Most modern telephones, both mobile and fixed, have memory locations in which telephone numbers can be stored. Some telephones have facilities to make calls through a calling card service whose access details and PIN are also stored in the telephone's memory. This may be implemented in different ways, often by pressing one button before making a call; some telephones support "chain dialing", allowing additional numbers to be dialed when on a call (e.g., dial a PIN and a second number after connecting to an access number). So long as long enough sequences can be stored it is possible to store an access number, pause, PIN, and ultimate telephone number in a single normal phone memory location. Software applications which add calling card support are available for a small charge or free for some smartphones.

</doc>
<doc id="24883" url="http://en.wikipedia.org/wiki?curid=24883" title="Philips CD-i">
Philips CD-i

The Philips CD-i (Compact Disc Interactive) is an interactive multimedia CD player developed and marketed by Royal Philips Electronics N.V. This category of device was created to provide more functionality than an audio CD player or game console, but at a lower price than a personal computer with a CD-ROM drive at the time. The cost savings were due to the lack of a hard drive, floppy drive, keyboard, mouse, monitor (a standard television is used), and less operating system software.
In addition to games, educational and multimedia reference titles were produced, such as interactive encyclopedias, museum tours, etc., which were popular before public Internet access was widespread. Competitors included the Tandy VIS and Commodore CDTV.
CD-i also refers to the multimedia Compact Disc standard used by the CD-i console, also known as Green Book, which was developed by Philips and Sony (not to be confused with MMCD, the pre-DVD format also co-developed by Philips and Sony). Work on the CD-i began in 1984 and it was first publicly announced in 1986. The first Philips CD-i player, released in 1991 and initially priced around US$700, was capable of playing interactive CD-i discs, Audio CDs, CD+G (CD+Graphics), Karaoke CDs, Photo CDs and Video CDs (VCDs), though the latter required an optional "Digital Video Card" to provide MPEG-1 decoding.
Seen as a game console, the CD-i format proved to be a commercial failure. The device was sold until 1998, aside claims that Philips had planned a discontinuation in 1996. The company lost nearly one billion dollars on the entire project. The failure of the CD-i caused Philips to leave the video game industry after it was discontinued. 
The CD-i is also one of the earliest consoles to implement internet features, including subscriptions, web browsing, downloading, e-mail, and online play. This was facilitated by the use of an additional hardware modem that Philips released in 1996 for $150.
Applications.
Early software releases in the CD-i format focused heavily on educational, music, and self-improvement titles, with only a handful of video games, many of them adaptations of board games such as "Connect Four". Later attempts to develop a foothold in the games market were rendered irrelevant by the arrival of cheaper and more powerful consoles, such as the Nintendo 64 and PlayStation. Earlier CD-i games included entries in popular Nintendo franchises, although those games were not developed by Nintendo. Specifically, a Mario game (titled "Hotel Mario"), and three Legend of Zelda games were released: ', ' and "Zelda's Adventure". Another notable title is "The Flowers of Robert Mappelthorpe.", an educational game showing flowers painted by the artist. Nintendo and Philips had established an agreement to co-develop a CD-ROM enhancement for the Super Nintendo Entertainment System due to licensing disagreements with Nintendo's previous partner Sony (an agreement that produced a prototype console called the Play Station). While Philips and Nintendo never released such a CD-ROM add-on, Philips was still contractually allowed to continue using Nintendo characters.
Applications were developed using authoring software produced by OptImage. This included OptImage's Balboa Runtime Libraries and MediaMogul. The second company that produced authoring software was Script Systems; they produced ABCD-I.
Philips also released several versions of popular TV game shows for the CD-i, including versions of "Jeopardy!" (hosted by Alex Trebek), "Name That Tune" (hosted by Bob Goen), and two versions of "The Joker's Wild" (one for adults hosted by Wink Martindale and one for kids hosted by Marc Summers). All CD-i games in North America (with the exception of "Name That Tune") had Charlie O'Donnell as announcer. The Netherlands also released its version of "Lingo" on the CD-i in 1994.
In 1993, American musician Todd Rundgren created the first music-only fully interactive CD, "No World Order", for the CD-i. This application allows the user to completely arrange the whole album in their own personal way with over 15,000 points of customization.
CD-i has a series of learning games ("edutainment") targeted at children from infancy to adolescence. Those intended for a younger audience included "Busytown", "The Berenstain Bears", and various others which usually had vivid cartoon-like settings accompanied by music and logic puzzles.
Although extensively marketed by Philips, notably via infomercial, consumer interest in CD-i titles remained low. By 1994, sales of CD-i systems had begun to slow, and in 1998 the product line was dropped.
A large number of full motion video titles such as "Dragon's Lair" and "Mad Dog McCree" appeared on the system. One of these, "", is considered one of the stronger CD-i titles and was later ported to PC. The February 1994 issue of "Electronic Gaming Monthly" remarked that the CD-i's full motion video capabilities were its strongest point, and that nearly all of its best software required the MPEG upgrade card.
With the home market exhausted, Philips tried with some success to position the technology as a solution for kiosk applications and industrial multimedia. The console still maintains a cult following on the Internet.
Player models.
Philips models.
In addition to consumer models, professional and development players were sold by Philips Interactive Media Systems and their VARs. Philips marketed several CD-i player models.
There also exist a number of hard-to-categorize models, such as the FW380i, an integrated mini-stereo and CD-i player; the 21TCDi30, a television with a built-in CD-i device; and the CD-i 180/181/182 modular system, the first CD-i system produced.
Other manufacturers.
In addition to Philips, several manufacturers produced CD-i players, including Magnavox, GoldStar / LG Electronics, Digital Video Systems, Memorex, Grundig, Sony (Intelligent Discman, a portable CD-i player), Kyocera, NBS, Highscreen, and Bang & Olufsen, who produced a television with a built-in CD-i device (Beocenter AV5).
TeleCD-i and CD-MATICS.
Recognizing the growing need among marketers for networked multimedia, Philips partnered in 1992 with Amsterdam-based CDMATICS to develop TeleCD-i (also TeleCD). In this concept, the CD-i player is connected to a network such as PSTN or Internet, enabling data-communication and rich media presentation. Dutch grocery chain Albert Heijn and mail-order company were early adopters and introduced award-winning TeleCD-i applications for their home-shopping and home-delivery services. CDMATICS also developed the special Philips TeleCD-i Assistant and a set of software tools to help the worldwide multimedia industry to develop and implement TeleCD-i. TeleCD-i is the world's first networked multimedia application at the time of its introduction. In 1996, Philips acquired source code rights from CDMATICS.
Market competition.
Panasonic M2 is an interactive kiosk. Multipurpose audiovisual and video game systems include Commodore CDTV, Pioneer LaserActive, 3DO Interactive Multiplayer, and Tandy Video Information System. Dedicated video game consoles based on CD-ROM media include Sega Mega Drive/Genesis with Sega Mega-CD/Sega CD expansion, 3DO Interactive Multiplayer, and Commodore CDTV.
Reception.
Although Philips had aggressively promoted CD-i, by 1993 "Computer Gaming World" reported that "skepticism persists about its long-term prospects" compared to other platforms like IBM PC compatibles, Apple Macintosh, and Sega Genesis. An early 1995 review of the system in "GamePro" stated that "inconsistent game quality puts the CD-i at a disadvantage against other high-powered game producers."
After its discontinuation, the CD-i was overwhelmingly panned by critics about its price, graphics, games and controls. The CD-i's various controllers were ranked the fifth worst video game controller by IGN editor Craig Harris. "PC World" ranked it as fourth on their list of "The 10 Worst Video Game Systems of All Time". Gamepro.com listed it as number four on their list of "The 10 Worst-Selling Consoles of All Time." In 2008, CNET listed the system on its list of "The worst game console(s) ever." In 2007, GameTrailers ranked the Philips CD-i as the fourth worst console of all time in its Top 10 Worst Console lineup.
Games that were most heavily criticized include "Hotel Mario", ', ', and "Zelda's Adventure". EGM's Seanbaby rated "The Wand of Gamelon" as one of the worst games of all time. However, "" was positively received by critics, and has often been held up as the standout title for the CD-i.

</doc>
<doc id="24884" url="http://en.wikipedia.org/wiki?curid=24884" title="Peppered moth">
Peppered moth

The peppered moth ("Biston betularia") is a temperate species of night-flying moth. Peppered moth evolution is often used by educators as an example of natural selection.
Description.
The wingspan is 55mm. median (45–62 mm.) Relatively stout-bodied. Forewings relatively narrow-elongate. The wings are white, "peppered" with black, and with more or less distinct cross lines, also black. The black speckling varies in amount, in some examples it is almost absent, whilst in others it is so dense that the wings appear to be black sprinkled with white. Antennae of males strongly bipectinate.
Distribution.
"Biston betularia" is found in China (Heilongjiang, Jilin, Inner Mongolia, Beijing, Hebei, Shanxi, Shandong, Henan, Shaanxi, Ningxia, Gansu, Qinghai, Xinjiang, Fujian, Sichuan, Yunnan,
Tibet), Russia, Mongolia, Japan, North Korea, South Korea, Nepal, Kazakhstan, Kirghizstan, Turkmenistan, Georgia, Azerbaijan, Armenia, Europe and North America.
Ecology and life cycle.
In Britain and Ireland, the peppered moth is univoltine ("i.e.", it has one generation per year), whilst in south-eastern North America it is bivoltine (two generations per year). The lepidopteran life cycle consists of four stages: ova (eggs), several larval instars (caterpillars), pupae, which overwinter live in the soil, and imagines (adults). During the day, the moths typically rest on trees, where they are preyed on by birds.
The caterpillar is a twig mimic, varying in colour between green and brown. On a historical note, it was one of the first animals to be identified as being camouflaged with countershading to make it appear flat (shading being the main visual cue that makes things appear solid), in a paper by Edward Bagnall Poulton in 1887.
It goes into the soil late in the season, where it pupates in order to spend the winter. The imagines emerge from the pupae between late May and August, the males slightly before the females (this is common and expected from sexual selection). They emerge late in the day and dry their wings before flying that night.
The males fly every night of their lives in search of females, whereas the females only fly on the first night. Thereafter, the females release pheromones to attract males. Since the pheromone is carried by the wind, males tend to travel up the concentration gradient, i.e., toward the source. During flight, they are subject to predation by bats. The males guard the female from other males until she lays the eggs. The female lays about 2,000 pale-green ovoid eggs about 1 mm in length into crevices in bark with her ovipositor.
Resting behaviour.
A mating pair or a lone individual will spend the day hiding from predators, particularly birds. In the case of the former, the male stays with the female to ensure paternity. The best evidence for resting positions is given by data collected by the peppered moth researcher Michael Majerus, and it is given in the accompanying charts. These data were originally published in Howlett and Majerus (1987), and an updated version published in Majerus (1998), who concluded that the moths rest in the upper part of the trees. Majerus notes:
Creationist critics of the peppered moth have often pointed to a statement made by Clarke "et al". (1985): "... In 25 years we have only found two "betularia" on the tree trunks or walls adjacent to our traps, and none elsewhere". The reason now seems obvious. Few people spend their time looking for moths up in the trees. That is where peppered moths rest by day.
From their original data, Howlett and Majerus (1987) concluded that peppered moths generally rest in unexposed positions, using three main types of site. Firstly, a few inches below a branch-trunk joint on a tree trunk where the moth is in shadow; secondly, on the underside of branches and thirdly on foliate twigs. The above data would appear to support this.
Further support for these resting positions is given from experiments watching captive moths taking up resting positions in both males (Mikkola, 1979; 1984) and females (Liebert and Brakefield, 1987).
Majerus, "et al.", (2000) have shown that peppered moths are cryptically camouflaged against their backgrounds when they rest in the boughs of trees. It is clear that in human visible wavelengths, "typica" are camouflaged against lichens and "carbonaria" against plain bark. However, birds are capable of seeing ultraviolet light that humans cannot see. Using an ultraviolet-sensitive video camera, Majerus et al. showed that "typica" reflect ultraviolet light in a speckled fashion and are camouflaged against crustose lichens common on branches, both in ultraviolet and human-visible wavelengths. However, "typica" are not as well camouflaged against foliose lichens common on tree trunks; though they are camouflaged in human wavelengths, in ultraviolet wavelengths, foliose lichens do not reflect ultraviolet light.
During an experiment in Cambridge over the seven years 2001–2007 Majerus noted the natural resting positions of peppered moths, and of the 135 moths examined over half were on tree branches, mostly on the lower half of the branch, 37% were on tree trunks, mostly on the north side, and only 12.6% were resting on or under twigs.
Morphs.
There are several melanic and non-melanic morphs of the peppered moth. These are controlled genetically. A particular morph can be indicated in a standard way by following the species name in the form "morpha "morph name".
It is a common mistake to confuse the name of the morph with that of the species or subspecies, hence mistakes such as "Biston carbonaria" and "Biston betularia carbonaria"". This might lead to the erroneous belief that speciation was involved in the observed evolution of the peppered moth. This is not the case; individuals of each morph interbreed and produce fertile offspring with individuals of all other morphs; hence there is only one peppered moth species.
By contrast, different subspecies of the same species can theoretically interbreed with one another and will produce fully fertile and healthy offspring but in practice do not, as they live in different regions or reproduce in different seasons. Full-fledged species are either unable to produce fertile and healthy offspring, or do not recognize each other's courtship signals, or both.
In continental Europe, there are three morphs: morpha "typica", the typical white morph (also known as "morpha "betularia""), morpha "carbonaria", the melanic black morph (also previously known as "morpha "doubledayaria""), and morpha "medionigra", an intermediate semi-melanic morph. European breeding experiments have shown that in "Biston betularia betularia", the allele for melanism producing morpha "carbonaria" is controlled by a single locus. The melanic allele is dominant to the non-melanic allele. This situation is, however, somewhat complicated by the presence of three other alleles that produce indistinguishable morphs of morpha "medionigra". These are of intermediate dominance, but this is not complete (Majerus, 1998).
In Britain, the typical white speckled morph is known as morpha "typica", the melanic morph is morpha "carbonaria", and the intermediate phenotype is morpha "insularia".
In North America, the melanic black morph is morpha "swettaria". In "Biston betularia cognataria", the melanic allele (producing morpha "swettaria") is similarly dominant to the non-melanic allele. There are also some intermediate morphs. In Japan, no melanic morphs have been recorded; they are all morpha "typica".
At present, the precise molecular genetics and biochemistry of the melanism in this species remains unknown. True (2003) has reviewed this and suggests work based on candidate genes from other insects such as the fruit fly "Drosophila melanogaster". In any case, it is rather likely that the underlying mechanism is not overly complex and, as indicated above, does not involve very many genes and alleles: Unlike for example the variation seen in human skin color, Peppered Moth morphs are not clinal and can generally be readily distinguished from another.
Evolution.
The evolution of the peppered moth over the last two hundred years has been studied in detail.
At the start of this period, the vast majority of peppered moths had light coloured wing patterns which effectively camouflaged them against the light-coloured trees and lichens upon which they rested. However, due to widespread pollution during the Industrial Revolution in England, many of the lichens died out, and the trees which peppered moths rested on became blackened by soot, causing most of the light-coloured moths, or "typica", to die off due to predation. At the same time, the dark-coloured, or melanic, moths, "carbonaria", flourished because they could hide on the darkened trees.
Since then, with improved environmental standards, light-coloured peppered moths have again become common, and the dramatic change in the peppered moth's population has remained a subject of much interest and study. This has led to the coining of the term "industrial melanism" to refer to the genetic darkening of species in response to pollutants. As a result of the relatively simple and easy-to-understand circumstances of the adaptation, the peppered moth has become a common example used in explaining or demonstrating natural selection to laypeople and classroom students through simulations.
The first "carbonaria" morph was recorded by Edleston in Manchester in 1848, and over the subsequent years it increased in frequency. Predation experiments, particularly by Bernard Kettlewell, established that the agent of selection was birds who preyed on the "carbonaria" morph.
Jonathan Wells is one of a number of creationists who have criticized the use of peppered moth melanism as an example of evolution in action. In his book "Icons of Evolution", Wells alleges that peppered moth studies, and in particular Kettlewell's experiments, were erroneous. Similarly, in 2002 Judith Hooper repeatedly implied fraud and error in Kettlewell's experiments in her book titled "Of moths and men". Despite some valid criticisms of the early experiments, there has been no evidence of fraud. Subsequent experiments and observations have supported the initial evolutionary explanation of the phenomenon.

</doc>
<doc id="24886" url="http://en.wikipedia.org/wiki?curid=24886" title="Power Macintosh">
Power Macintosh

Power Macintosh, later Power Mac, is a line of Apple Macintosh workstation-class personal computers based on various models of PowerPC microprocessors that were developed, marketed, and supported by Apple Inc. from March 1994 until August 2006. The first models were the Power Macintosh 6100, 7100, and 8100, which offered speeds ranging from 60 to 110 MHz. These machines replaced Apple's Quadra series of personal computers, and were housed in cases very similar to systems sold by Apple up to that point. The Power Mac went on to become the mainstay of Apple's top-end offerings for twelve years, through a succession of case designs, four major generations of PowerPC chips, and a great deal of press coverage, design accolades, and technical controversy. In August 2006, the Power Mac's retirement was announced at Apple's Worldwide Developers Conference by Steve Jobs and Phil Schiller, making way for its Intel-based replacement, the Mac Pro.
Models.
New World ROM.
The following are recent Power Mac lines based on the New World ROM.
Timeline of New World ROM Power Macintosh models.
"The Power Macintosh G3 All-In-One was replaced with the series."
Processor and software.
The ROM and Mac OS operating system released with the new Power Mac machines included an Mac 68K emulator to enable programs written for Motorola 68k series CPUs, including nearly all prior Mac software, to run without changes. (A similar scheme is employed to run 68K software on modern x86 Alpha Microsystems machines.) As the Power Mac was originally intended to be a part of the high end of Apple's product line, for a number of years the company continued to offer less expensive 68k-based computers alongside the more expensive Power Mac lineup. However, for many of these so-called 68K transition Macs, Apple offered an upgrade path in the form of a PowerPC Macintosh Processor Upgrade Card and aggressively marketed it to assure a wary consumer of their investment. In April 1996, Apple discontinued the Macintosh LC 580 (released in 1995), the last remaining desktop model of the 68k-based Macintosh line. The PowerBook 190cs, the last 68k-based PowerBook, was discontinued in October 1996. In 2005, Apple released Intel-based Power Mac to Apple developers at WWDC. All subsequent Macintosh computers would be based on PowerPC processors until January 2006, when Apple switched to Intel processors.
Naming.
All Power Macs prior to 1997 used PowerPC 60x-series processors, and 4-digit model numbers (e.g. Power Mac 8600). In 1997 the first third-generation ("G3") Power Macintosh was introduced, using the PowerPC 750 processor. From this model onward, Apple no longer used a numbering scheme to identify their Power Mac models, but instead referred to them by their PowerPC processor generation number (i.e. G3, G4, and G5). Later models based on the same generation of PowerPC processor relied on descriptive characteristics to differentiate them, e.g. the color scheme ("Power Macintosh G3 – Blue and White") or a technical feature of a particular model ("Power Mac G4 – Gigabit Ethernet"). This same identification scheme was used in the iMac, PowerBook, and iBook lines of Macintosh computers.
The marketing name was changed from "Power Macintosh" to "Power Mac" with the introduction of the G4 models, meaning all G3 and earlier models are referred to as "Power Macintosh", while all G4 and G5 models are "Power Mac"s. Not all Apple documentation follows this rule, but the vast majority does.
Usage.
The Power Mac brand name was used for Apple's high-end tower style computers, targeted primarily at businesses and creative professionals, in differentiation to their more compact "iMac" line (intended for home use) and the "eMac" line (for the education markets). They were usually equipped with Apple's newest technologies, and commanded the highest prices among Apple desktop models. Some Power Mac G4 and G5 models were offered in dual-processor configurations. 
Prior to the "Power Mac" name change, certain "Power Macintosh" models were otherwise identical to their lower-cost re-branded siblings sold as the Macintosh LC and Macintosh Performa, as well as the dedicated Apple Workgroup Server and Macintosh Server G3 & G4 lines. Other past Macintosh lines which used PowerPC processors include the PowerBook 5300 and later models, iMac, iBook and Xserve as well as the Apple Network Server, which was not technically a Macintosh.
Successor.
The Intel-based successor of the Power Mac is the Mac Pro, in line with the renaming of Apple's professional notebooks from PowerBook to MacBook Pro.
The successor to the All-In-One Power Macintosh models (5x00 series), the last of which was the Power Macintosh G3 "All-In-One", was re-branded the iMac, which persisted through the Intel transition to the present.
Advertising and marketing.
Apple introduced the Power Mac series of high-end personal computers aimed at businesses and creative professionals in 1994 with an advertising campaign consisting of several television commercials and print ads. The television commercials used the slogan "The Future Is Better Than You Expected", featuring the first three Power Macintosh computers to showcase special features such as networking and MS-DOS compatibility.
See also.
<br>

</doc>
<doc id="24888" url="http://en.wikipedia.org/wiki?curid=24888" title="Promoter (genetics)">
Promoter (genetics)

In genetics, a promoter is a region of DNA that initiates transcription of a particular gene. Promoters are located near the transcription start sites of genes, on the same strand and upstream on the DNA (towards the 5' region of the sense strand).
Promoters can be about 100–1000 base pairs long.
Overview.
For the transcription to take place, the enzyme that synthesizes RNA, known as RNA polymerase, must attach to the DNA near a gene. Promoters contain specific DNA sequences such as response elements that provide a secure initial binding site for RNA polymerase and for proteins called transcription factors that recruit RNA polymerase. These transcription factors have specific activator or repressor sequences of corresponding nucleotides that attach to specific promoters and regulate gene expression.
Promoters represent critical elements that can work in concert with other regulatory regions (enhancers, silencers, boundary elements/insulators) to direct the level of transcription of a given gene.
Identification of relative location.
As promoters are typically immediately adjacent to the gene in question, positions in the promoter are designated relative to the transcriptional start site, where transcription of DNA begins for a particular gene (i.e., positions upstream are negative numbers counting back from -1, for example -100 is a position 100 base pairs upstream).
Relative location in the cell nucleus.
In the cell nucleus, it seems that promoters are distributed preferentially at the edge of the chromosomal territories, likely for the co-expression of genes on different chromosomes. Furthermore, in humans, promoters show certain structural features characteristic for each chromosome.
Promoter elements.
Bacterial promoters.
In bacteria, the promoter contains two short sequence elements approximately -10 and -35 nucleotides "upstream" from the transcription start site.
It should be noted that the above promoter sequences are recognized only by RNA polymerase holoenzyme containing sigma-70. RNA polymerase holoenzymes containing other sigma factors recognize different core promoter sequences.
 <-- upstream downstream -->
 5'-XXXXXXXPPPPPXXXXXXPPPPPPXXXXGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGXXXX-3'
 -35 -10 Gene to be transcribed
Probability of occurrence of each nucleotide.
 for -10 sequence
 T A T A A T
 77% 76% 60% 61% 56% 82%
 for -35 sequence
 T T G A C A
 69% 79% 61% 56% 54% 54%
Eukaryotic promoters.
Eukaryotic promoters are diverse and can be difficult to characterize, however, recent studies show that they are divided in more than 10 classes.
Gene promoters are typically located upstream of the gene and can have regulatory elements several kilobases away from the transcriptional start site (enhancers). In eukaryotes, the transcriptional complex can cause the DNA to bend back on itself, which allows for placement of regulatory sequences far from the actual site of transcription. Eukaryotic RNA-polymerase-II-dependent promoters can contain a TATA element (consensus sequence TATAAA), which is recognized by the general transcription factor TATA-binding protein (TBP); and a B recognition element (BRE), which is recognized by the general transcription factor TFIIB. The TATA element and BRE typically are located close to the transcriptional start site (typically within 30 to 40 base pairs).
Eukaryotic promoter regulatory sequences typically bind proteins called transcription factors that are involved in the formation of the transcriptional complex. An example is the E-box (sequence CACGTG), which binds transcription factors in the basic helix-loop-helix (bHLH) family (e.g. BMAL1-Clock, cMyc).
Bidirectional promoters (mammalian).
Bidirectional promoters are short (<1 kbp), intergenic regions of DNA between the 5' ends of the genes in a bidirectional gene pair. A “bidirectional gene pair” refers to two adjacent genes coded on opposite strands, with their 5' ends oriented toward one another. The two genes are often functionally related, and modification of their shared promoter region allows them to be co-regulated and thus co-expressed. Bidirectional promoters are a common feature of mammalian genomes. About 11% of human genes are bidirectionally paired.
Bidirectionally paired genes in the Gene Ontology database shared at least one database-assigned functional category with their partners 47% of the time. Microarray analysis has shown bidirectionally paired genes to be co-expressed to a higher degree than random genes or neighboring unidirectional genes. Although co-expression does not necessarily indicate co-regulation, methylation of bidirectional promoter regions has been shown to downregulate both genes, and demethylation to upregulate both genes. There are exceptions to this, however. In some cases (about 11%), only one gene of a bidirectional pair is expressed. In these cases, the promoter is implicated in suppression of the non-expressed gene. The mechanism behind this could be competition for the same polymerases, or chromatin modification. Divergent transcription could shift nucleosomes to upregulate transcription of one gene, or remove bound transcription factors to downregulate transcription of one gene.
Some functional classes of genes are more likely to be bidirectionally paired than others. Genes implicated in DNA repair are five times more likely to be regulated by bidirectional promoters than by unidirectional promoters. Chaperone proteins are three times more likely, and mitochondrial genes are more than twice as likely. Many basic housekeeping and cellular metabolic genes are regulated by bidirectional promoters.
The overrepresentation of bidirectionally paired DNA repair genes associates these promoters with cancer. Forty-five percent of human somatic oncogenes seem to be regulated by bidirectional promoters - significantly more than non-cancer causing genes. Hypermethylation of the promoters between gene pairs WNT9A/CD558500, CTDSPL/BC040563, and KCNK15/BF195580 has been associated with tumors.
Certain sequence characteristics have been observed in bidirectional promoters, including a lack of TATA boxes, an abundance of CpG islands, and a symmetry around the midpoint of dominant Cs and As on one side and Gs and Ts on the other. CCAAT boxes are common, as they are in many promoters that lack TATA boxes. In addition, the motifs NRF-1, GABPA, YY1,and ACTACAnnTCCC are represented in bidirectional promoters at significantly higher rates than in unidirectional promoters. The absence of TATA boxes suggests that they play a role in determining the directionality of promoters, but counterexamples of bidirectional promoters do possess TATA boxes and unidirectional promoters without them indicates that they cannot be the only factor.
Although the term "bidirectional promoter" refers specifically to promoter regions of mRNA-encoding genes, luciferase assays have shown that over half of human genes do not have a strong directional bias. Research suggests that non-coding RNAs are frequently associated with the promoter regions of mRNA-encoding genes. It has been hypothesized that the recruitment and initiation of RNA Polymerase II usually begins bidirectionally, but divergent transcription is halted at a checkpoint later during elongation. Possible mechanisms behind this regulation include sequences in the promoter region, chromatin modification, and the spatial orientation of the DNA.
Subgenomic promoters.
A subgenomic promoter is a promoter added to a virus for a specific heterologous gene, resulting in the formation of mRNA for that gene alone.
Detection of promoters.
A wide variety of algorithms have been developed to facilitate detection of promoters in genomic sequence, and promoter prediction is a common element of many gene prediction methods. A promoter region is located before the -35 and -10 Consensus sequences. The closer the promoter region is to the consensus sequences the more often transcription of that gene will take place. There is not a set pattern for promoter regions as there are for consensus sequences.
Evolutionary change.
A major question in evolutionary biology is how important tinkering with promoter sequences is to evolutionary change, for example, the changes that have occurred in the human lineage after separating from other primates.
Some evolutionary biologists, for example Allan Wilson, have proposed that evolution in promoter or regulatory regions may be more important than changes in coding sequences over such time frames.
A key reason for the importance of promoters is the potential to incorporate endocrine and environmental signals into changes in gene expression:
A great variety of changes in the extracellular or intracellular environment may have impact on gene expression, depending on the exact configuration of a given promoter: the combination and arrangement of specific DNA sequences that constitute the promoter defines the exact groups of proteins that can be bound to the promoter, at a given timepoint. Once the cell receives a physiological, pathological, or pharmacological stimulus, a number of cellular proteins are modified biochemically by signal cascades. By changes in structure, specific proteins acquire the capability to enter the nucleus of the cell and bind to promoter DNA, or to other proteins that themselves are already bound to a given promoter. The multi-protein complexes that are formed have the potential to change levels of gene expression. As a result the gene product may increase or decrease inside the cell.
Binding.
The binding of RNAP (R) to a promoter (P) is a two-step process:
Diseases associated with aberrant promoter function.
Though OMIM is a major resource for gathering information on the relationship between mutations and natural variation in gene sequence and susceptibility to hundreds of diseases, a sophisticated search strategy is required to extract diseases associated with defects in transcriptional control where the promoter is believed to have direct involvement.
This is a list of diseases where evidence suggests some promoter malfunction, through either direct mutation of a promoter sequence or mutation in a transcription factor or transcriptional co-activator.
Most diseases are heterogeneous in etiology, meaning that one "disease" is often many different diseases at the molecular level, though symptoms exhibited and response to treatment may be identical. How diseases of different molecular origin respond to treatments is partially addressed in the discipline of pharmacogenomics.
Not listed here are the many kinds of cancers involving aberrant transcriptional regulation owing to creation of chimeric genes through pathological chromosomal translocation. Importantly, intervention on the number or structure of promoter-bound proteins is one key to treating a disease without affecting expression of unrelated genes sharing elements with the target gene. Genes where change is not desirable are capable of influencing the potential of a cell to become cancerous and form a tumor.
Canonical sequences and wild-type.
The usage of canonical sequence for a promoter is often problematic, and can lead to misunderstandings about promoter sequences. Canonical implies perfect, in some sense.
In the case of a transcription factor binding site, then there may be a single sequence that binds the protein most strongly under specified cellular conditions. This might be called canonical.
However, natural selection may favor less energetic binding as a way of regulating transcriptional output. In this case, we may call the most common sequence in a population, the wild-type sequence. It may not even be the most advantageous sequence to have under prevailing conditions.
Recent evidence also indicates that several genes (including the proto-oncogene c-myc) have G-quadruplex motifs as potential regulatory signals.
Diseases that may be associated with promoter variations.
Some cases of many genetic diseases are associated with variations in promoters or transcription factors.
Examples include:
Constitutive vs regulated promoters.
Some promoters are called constitutive as they are active in all circumstances in the cell, while others are regulated, becoming active in the cell only in response to specific stimuli.
Use of the word promoter.
When referring to a promoter some authors actually mean promoter + operator. i.e. the lac promoter is IPTG inducible, meaning that besides the lac promoter, the lac operator is also present. If the lac operator were not present the IPTG would not have an inducible effect.
Another example is the tac promoter system (Ptac). Notice how it is written down as tac promoter, while in fact it means both promoter and operator.

</doc>
<doc id="24893" url="http://en.wikipedia.org/wiki?curid=24893" title="Adobe Photoshop">
Adobe Photoshop

Adobe Photoshop is a raster graphics editor developed and published by Adobe Systems for Windows and OS X.
Photoshop was created in 1988 by Thomas and John Knoll. Since then, it has become the "de facto" industry standard in raster graphics editing, such that the word "photoshop" has become a verb as in "to photoshop an image," "photoshopping," and "photoshop contest," etc. It can edit and compose raster images in multiple layers and supports masks, alpha compositing and several color models including RGB, CMYK, Lab color space (with capital L), spot color and duotone. Photoshop has vast support for graphic file formats but also uses its own codice_1 and codice_2 file formats which support all the aforementioned features. In addition to raster graphics, it has limited abilities to edit or render text, vector graphics (especially through clipping path), 3D graphics and video. Photoshop's featureset can be expanded by Photoshop plug-ins, programs developed and distributed independently of Photoshop that can run inside it and offer new or enhanced features.
Photoshop's naming scheme was initially based on version numbers. However, on October 2004, following the introduction of Creative Suite branding, each new version of Photoshop was designated with "CS" plus a number; e.g. the eighth major version of Photoshop was Photoshop CS and the ninth major version was Photoshop CS2. Photoshop CS3 through CS6 were also distributed in two different editions: Standard and Extended. In June 2013, with the introduction of Creative Cloud branding, Photoshop's licensing scheme was changed to that of software as a service and the "CS" suffixes were replaced with "CC". Historically, Photoshop was bundled with additional software such as Adobe ImageReady, Adobe Fireworks, Adobe Bridge, Adobe Device Central and Adobe Camera RAW.
Alongside Photoshop, Adobe also develops and publishes Photoshop Elements, Photoshop Lightroom, Photoshop Express and Photoshop Touch. Collectively, they are branded as "The Adobe Photoshop Family". It is currently a licensed software.
Early history.
Adobe Photoshop, computer application software used to edit and manipulate digital images. Photoshop was developed in 1987 by the American brothers Thomas and John Knoll, who sold the distribution license to Adobe Systems Incorporated In 1988, Thomas Knoll, a PhD student at the University of Michigan, began writing a program on his Macintosh Plus to display grayscale images on a monochrome display. This program, called Display, caught the attention of his brother John Knoll, an Industrial Light & Magic employee, who recommended that Thomas turn it into a full-fledged image editing program. Thomas took a six-month break from his studies in 1988 to collaborate with his brother on the program. Thomas renamed the program ImagePro, but the name was already taken. Later that year, Thomas renamed his program Photoshop and worked out a short-term deal with scanner manufacturer Barneyscan to distribute copies of the program with a slide scanner; a "total of about 200 copies of Photoshop were shipped" this way.
During this time, John traveled to Silicon Valley and gave a demonstration of the program to engineers at Apple and Russell Brown, art director at Adobe. Both showings were successful, and Adobe decided to purchase the license to distribute in September 1988. While John worked on plug-ins in California, Thomas remained in Ann Arbor writing code. "Photoshop" 1.0 was released on 19 February 1990 for Macintosh exclusively. The Barneyscan version included advanced color editing features that were stripped from the first Adobe shipped version. The handling of color slowly improved with each release from Adobe and Photoshop quickly became the industry standard in digital color editing. At the time Photoshop 1.0 was released, digital retouching on dedicated high end systems, such as the SciTex, cost around $300 an hour for basic photo retouching.
File format.
Photoshop files have default file extension as .PSD, which stands for "Photoshop Document." A PSD file stores an image with support for most imaging options available in Photoshop. These include layers with masks, transparency, text, alpha channels and spot colors, clipping paths, and duotone settings. This is in contrast to many other file formats (e.g. .JPG or .GIF) that restrict content to provide streamlined, predictable functionality. A PSD file has a maximum height and width of 30,000 pixels, and a length limit of 2 Gigabytes.
Photoshop files sometimes have the file extension .PSB, which stands for "Photoshop Big" (also known as "large document format"). A PSB file extends the PSD file format, increasing the maximum height and width to 300,000 pixels and the length limit to around 4 Exabytes. The dimension limit was apparently chosen arbitrarily by Adobe, not based on computer arithmetic constraints (it is not close to a power of two, as is 30,000) but for ease of software testing. PSD and PSB formats are documented.
Because of Photoshop's popularity, PSD files are widely used and supported to some extent by most competing software. The .PSD file format can be exported to and from Adobe's other apps like Adobe Illustrator, Adobe Premiere Pro, and After Effects, to make professional standard DVDs and provide non-linear editing and special effects services, such as backgrounds, textures, and so on, for television, film, and the web. Photoshop's primary strength is as a pixel-based image editor, unlike vector-based image editors. Photoshop also enables vector graphics editing through its Paths, Pen tools, Shape tools, Shape Layers, Type tools, Import command, and Smart Object functions. These tools and commands are convenient to combine pixel-based and vector-based images in one Photoshop document, because it may not be necessary to use more than one program. To create very complex vector graphics with numerous shapes and colors, it may be easier to use software that was created primarily for that purpose, such as Adobe Illustrator or CorelDRAW. Photoshop's non-destructive Smart Objects can also import complex vector shapes.
Plugins.
Photoshop functionality can be extended by add-on programs called Photoshop plugins (or plug-ins). Adobe creates some plugins, such as Adobe Camera Raw, but third-party companies develop most plugins, according to Adobe's specifications. Some are free and some are commercial software.
Most plugins work with only Photoshop or Photoshop-compatible hosts, but a few can also be run as standalone applications.
There are various types of plugins, such as filter, export, import, selection, color correction, and automation. The most popular plugins are the filter plugins (also known as a 8bf plugins), available under the Filter menu in Photoshop.
Filter plugins can either modify the current image or create content. Below are some popular types of plugins, and some well-known companies associated with them:
Adobe Camera Raw (also known as ACR and Camera Raw) is a special plugin, supplied free by Adobe, used primarily to read and process raw image files so that the resultant images can be processed by Photoshop. It can also be used from within Adobe Bridge.
Tools.
Upon loading Photoshop, a sidebar with a variety of tools with multiple image-editing functions appears to the left of the screen. These tools typically fall under the categories of drawing; painting; measuring and navigation; selection; typing; and retouching. Some tools contain a small triangle in the bottom right of the toolbox icon. These can be expanded to reveal similar tools. While newer versions of Photoshop are updated to include new tools and features, several recurring tools that exist in most versions are discussed below.
Pen tool.
Photoshop includes a few versions of the "pen" tool. The pen tool creates precise paths that can be manipulated using anchor points. The "free form pen" tool allows the user to draw paths freehand, and with the "magnetic pen" tool, the drawn path attaches closely to outlines of objects in an image, which is useful for isolating them from a background.
Measuring and navigation.
The "eyedropper" tool selects a color from an area of the image that is clicked, and samples it for future use. The "hand" tool navigates an image by moving it in any direction, and the "zoom" tool enlarges the part of an image that is clicked on, allowing for a closer view.
Selection.
Selection tools are used to select all or any part of a picture to perform cut, copy, edit, or retouching operations.
Cropping.
The "crop" tool can be used to select a particular area of an image and discard the portions outside the chosen section. This tool assists in creating a focus point on an image and excluding unnecessary or excess space. Cropping allows enhancement of a photo’s composition while decreasing the file size. The "crop" tool is in the tools palette, which is located on the right side of the document. By placing the cursor over the image, the user can drag the cursor to the desired area. Once the Enter key is pressed, the area outside the rectangle will be cropped. The area outside the rectangle is the discarded data, which allows for the file size to be decreased. The "crop" tool can alternatively be used to extend the canvas size by clicking and dragging outside the existing image borders.
Slicing.
The "slice" and "slice select" tools, like the crop tool, are used in isolating parts of images. The slice tool can be used to divide an image into different sections, and these separate parts can be used as pieces of a web page design once HTML and CSS are applied. The slice select tool allows sliced sections of an image to be adjusted and shifted.
Moving.
The move tool can be used to drag the entirety of a single layer or more if they are selected. Alternatively, once an area of an image is highlighted, the "move" tool can be used to manually relocate the selected piece to anywhere on the canvas.
Marquee.
The "marquee" tool can make selections that are single row, single column, rectangular and elliptical. An area that has been selected can be edited without affecting the rest of the image. This tool can also crop an image; it allows for better control. In contrast to the "crop" tool, the "marquee" tool allows for more adjustments to the selected area before cropping. The only "marquee" tool that does not allow cropping is the elliptical. Although the single row and column "marquee" tools allow for cropping, they are not ideal, because they only crop a line. The "rectangular marquee" tool is the preferred option. Once the tool has been selected, dragging the tool across the desired area will select it. The selected area will be outlined by dotted lines, referred to as "marching ants". These dotted lines are called "marching ants", because the dashes look like ants marching around the selected area. To set a specific size or ratio, the tool option bar provides these settings. Before making a selecting an area, the desired size or ratio must be set by adjusting the width and height. Any changes such as color, filters, location, etc. should be made before cropping. To crop the selection, the user must go to image tab and select crop.
Lasso.
The "lasso" tool is similar to the "marquee" tool, however, the user can make a custom selection by drawing it freehand. There are three options for the "lasso" tool – regular, polygonal, and magnetic. The regular "lasso" tool allows the user to have drawing capabilities. Photoshop will complete the selection once the mouse button is released. The user may also complete the selection by connecting the end point to the starting point. The "marching ants" will indicate if a selection has been made. The "polygonal lasso" tool will draw only straight lines, which makes it an ideal choice for images with many straight lines. Unlike the regular "lasso" tool, the user must continually click around the image to outline the shape. To complete the selection, the user must connect the end point to the starting point just like the regular lasso tool. "Magnetic lasso" tool is considered the smart tool. It can do the same as the other two, but it can also detect the edges of an image once the user selects a starting point. It detects by examining the color pixels as the cursor move over the desired area. A pixel is the smallest element in an image. Closing the selection is the same as the other two, which should also should display the "marching ants" once the selection has been closed.
The "quick selection" tool selects areas based on edges, similarly to the "magnetic lasso" tool. The difference between this tool and the "lasso" tool is that there is no starting and ending point. Since there isn’t a starting and ending point, the selected area can be added onto as much as possible without starting over. By dragging the cursor over the desired area, the "quick selection" tool detects the edges of the image. The "marching ants" allow the user to know what is currently being selected. Once the user is done, the selected area can be edited without affecting the rest of the image. One of the features that makes this tool especially user friendly is that the SHIFT key is not needed to add more to the selection; by default, extra mouse clicks will be added to the selection rather than creating a new selection.
Magic Wand.
The "magic wand" tool selects areas based on pixels of similar values. One click will select all neighboring pixels of similar value within a tolerance level set by the user. If the "eyedropper" tool is selected in the options bar, then the magic wand can determine the value needed to evaluate the pixels; this is based on the sample size setting in the "eyedropper" tool. This tool is inferior to the quick selection tool which works much the same but with much better results and more intuitive controls. The user must decide what settings to use or if the image is right for this tool.
Eraser.
The "Eraser" tool erases content based on the active layer. If the user is on the text layer, then any text across which the tool is dragged will be erased. The eraser will convert the pixels to transparent, unless the background layer is selected. The size and style of the eraser can be selected in the options bar. This tool is unique in that it can take the form of the paintbrush and pencil tools. In addition to the straight eraser tool, there are two more available options – background eraser and magic eraser. The "background eraser" deletes any part of the image that is on the edge of an object. This tool is often used to extract objects from the background. The "magic eraser" tool deletes based on similar colored pixels. It is very similar to the "magic wand" tool. This tool is ideal for deleting areas with the same color or tone that contrasts with the rest of the image.
Video editing.
In Adobe CS5 Extended edition, video editing is comprehensive and efficient with a broad compatibility of video file formats such as "MOV", "AVI", "MPEG-4", and "FLV" formats and easy workflow. Using simple combination of keys video layers can easily be modified, with other features such as adding text and the creation of animations using single images.
3D extrusion.
With the Extended version of Photoshop CS5, 2D elements of an artwork can easily become three-dimensional with the click of a button. Extrusions of texts, an available library of materials for three-dimensional, and even wrapping two-dimensional images around 3D geometry.
Mobile integration.
Third-party plugins have also been added to the most recent version of Photoshop where technologies such as the iPad have integrated the software with different types of applications. Applications like the Adobe Eazel painting app allows the user to easily create paintings with their fingertips and use an array of different paint from dry to wet in order to create rich color blending.
Camera Raw.
With the Camera Raw plug-in, RAW images can be processed without the use of Adobe Photoshop Lightroom, along with other image file formats such as "JPEGs", "TIFFs", or "PNGs". The plug-in allows users to remove noise without the side-effect of over-sharpening, add grain, and even perform "post-crop vignetting".
3D printing tools.
Requiring Photoshop version 14.1, users can now create and edit designs for 3D printing. After downloading 3D photo models from numerous online services, users can add color, adjust the shape or rotate the angles. Artists can also design 3D models from scratch. http://mashable.com/2014/01/16/photoshop-3d-printing/
Color replacement tool.
The Color Replacement Tool allows you to change the color, while maintaining the highlights and shadows of the original image, of pieces of the image. By selecting Brushs and right clicking, the Color Replacement Tool is the third option down. What is important to note with this tool is the foreground color. The foreground color is what will be applied when painting along the chosen part of the image with the Color Replacement Tool.
Cultural impact.
"Photoshop" and derivatives such as "Photoshopped" (or just "Shopped") have become verbs that are sometimes used to refer to images edited by Photoshop, or any image manipulating program. Such derivatives are discouraged by Adobe because, in order to maintain validity and protect the trademark from becoming generic, trademarks must be used as proper nouns.
Magazines.
Before any type of print media is published, whether it is a magazine, newspaper, or even novel, it is likely the case that Photoshop has been used to enhance and clean up the imagery on many if not all of the pages. Magazines use Photoshop and many of its tools in order to enhance the imagery and text in their publications. Many Health and Beauty Magazines employ in-house designers to retouch photos of models to enhance their beauty. They add finishing touches to the imagery by using tools that balance color and add drop shadows, among other edits.
Photoshop disasters.
For comedic effect, some websites publish so-called "Photoshop disasters", that is, pictures that contain obvious Photoshop mistakes. Those mistakes range from missing limbs to overdone photo retouching on fashion models.
Photoshop contest.
A Photoshop contest (or "photochop contest") is an online game in which someone posts an image, and other people manipulate the image using a raster graphics editor such as Photoshop.
Version history.
Older versions.
Photoshop's naming scheme was initially based on version numbers. Adobe published thirteen versions (major and minor changes) before the October 2003 introduction of Creative Suite branding. In February 2013 Adobe donated the source code of the 1990 1.0.1 version of Photoshop to the Computer History Museum.
CS.
The first Photoshop CS was commercially released in October 2003 as the eighth major version of Photoshop. Photoshop CS increased user control with a reworked file browser augmenting search versatility, sorting and sharing capabilities and the Histogram Palette which monitors changes in the image as they are made to the document. Match Color was also introduced in CS, which reads color data to achieve a uniform expression throughout a series of pictures.
CS2.
Photoshop CS2, released in May 2005, expanded on its predecessor with a new set of tools and features. It included an upgraded Spot Healing Brush, which is mainly used for handling common photographic problems such as blemishes, red-eye, noise, blurring and lens distortion. One of the most significant inclusions in CS2 was the implementation of Smart Objects, which allows users to scale and transform images and vector illustrations without losing image quality, as well as create linked duplicates of embedded graphics so that a single edit updates across multiple iterations.
Adobe responded to feedback from the professional media industry by implementing non-destructive editing as well as the producing and modifying of 32-Bit High Dynamic Range (HDR) images, which are optimal for 3D rendering and advanced compositing. FireWire Previews could also be viewed on a monitor via a direct export feature.
Photoshop CS2 brought the Vanishing Point and Image Warping tools. Vanishing Point makes tedious graphic and photo retouching endeavors much simpler by letting users clone, paint and transform image objects while maintaining visual perspective. Image Warping makes it easy to digitally distort an image into a shape by choosing on-demand presets or by dragging control points.
The File Browser was upgraded to Adobe Bridge, which functioned as a hub for productivity, imagery and creativity, providing multi-view file browsing and smooth cross-product integration across Adobe Creative Suite 2 software. Adobe Bridge also provided access to Adobe Stock Photos, a new stock photography service that offered users one-stop shopping across five elite stock image providers to deliver high-quality, royalty-free images for layout and design.
Camera Raw version 3.0 was a new addition in CS2, and it allowed settings for multiple raw files to be modified simultaneously. In addition, processing multiple raw files to other formats including JPEG, TIFF, DNG or PSD, could be done in the background without executing Photoshop itself.
Photoshop CS2 brought a streamlined interface, making it easier to access features for specific instances. In CS2 users were also given the ability to create their own custom presets, which was meant to save time and increase productivity.
CS3.
CS3 improves on features from previous versions of Photoshop and introduces new tools. One of the most significant is the streamline interface which allows increased performance, speed, and efficiency. There is also improved support for Camera RAW files which allow users to process images with higher speed and conversion quality. CS3 supports over 150 RAW formats as well as JPEG, TIFF and PDF. Enhancements were made to the Black and White Conversion, Brightness and Contrast Adjustment and Vanishing Point Module tools. The Black and White adjustment option improves control over manual grayscale conversions with a dialog box similar to that of Channel Mixer. There is more control over print options and better management with Adobe Bridge. The Clone Source palette is introduced, adding more options to the clone stamp tool. Other features include the nondestructive Smart Filters, optimizing graphics for mobile devices, Fill Light and Dust Busting tools. Compositing is assisted with Photoshop's new Quick Selection and Refine Edge tools and improved image stitching technology.
CS3 Extended includes everything in CS3 and additional features. There are tools for 3D graphic file formats, video enhancement and animation, and comprehensive image measurement and analysis tools with DICOM file support. The 3D graphic formats allow 3D content to be incorporated into 2D compositions. As for video editing, CS3 supports layers and video formatting so users can edit video files per frame.
CS3 and CS3 Extended were released in April 2007 to the United States and Canada. They were also made available through Adobe’s online store and Adobe Authorized Resellers. Both CS3 and CS3 Extended are offered as either a stand-alone application or feature of Adobe Creative Suite. The price for CS3 is US$649 and the extended version is US$999. Both products are compatible with Intel-based Macs and PowerPCs, supporting Windows XP and Windows Vista. CS3 is the first release of Photoshop that will run natively on Macs with Intel processors: previous versions can only run through the translation layer Rosetta, and will not run at all on Macs running OS X 10.7 or later.
CS4.
CS4 features smoother panning and zooming, allowing faster image editing at a high magnification. The interface is more simplified with its tab-based interface making it cleaner to work with. Photoshop CS4 features a new 3D engine allowing the conversion of gradient maps to 3D objects, adding depth to layers and text, and getting print-quality output with the new ray-tracing rendering engine. It supports common 3D formats; the new Adjustment and Mask Panels; Content-aware scaling (seam carving); Fluid Canvas Rotation and File display options. The Content-aware scaling allows users to intelligently size and scale images, and the Canvas Rotation tool makes it easier to rotate and edit images from any angle.
Adobe released Photoshop CS4 Extended, which has the features of Adobe Photoshop CS4, plus capabilities for scientific imaging, 3D, motion graphics, accurate image analysis and high-end film and video users. The faster 3D engine allows users to paint directly on 3D models, wrap 2D images around 3D shapes and animate 3D objects. As the successor to Photoshop CS3, Photoshop CS4 is the first x64 edition of Photoshop on consumer computers for Windows. The color correction tool has also been improved significantly.
CS4 and CS4 Extended were released on 15 October 2008. They were also made available through Adobe’s online store and Adobe Authorized Resellers. Both CS4 and CS4 Extended are offered as either a stand-alone application or feature of Adobe Creative Suite. The price for CS4 is US$699 and the extended version is US$999. Both products are compatible with Intel-based Mac OS X and PowerPCs, supporting Windows XP and Windows Vista.
CS5.
Photoshop CS5 was launched on 12 April 2010. In a video posted on its official Facebook page, the development team revealed the new technologies under development, including three-dimensional brushes and warping tools.
In May 2011, Adobe Creative Suite 5.5 (CS5.5) was released, with new versions of some of the applications. Its version of Photoshop, 12.1, is identical to the concurrently released update for Photoshop CS5, version 12.0.4, except for support for the new subscription pricing that was introduced with CS5.5.
CS5 introduces new tools such as the Content-Aware Fill, Refine Edge, Mixer Brush, Bristle Tips and Puppet Warp. The community also had a hand in the additions made to CS5 as 30 new features and improvements were included by request. These include automatic image straightening, the Rule-of-Thirds cropping tool, color pickup, and saving a 16-bit image as a JPEG. Another feature includes the Adobe Mini Bridge, which allows for efficient file browsing and management.
CS5 Extended includes everything in CS5 plus features in 3D and video editing. A new materials library was added, providing more options such as Chrome, Glass, and Cork. The new Shadow Catcher tool can be used to further enhance 3D objects. For motion graphics, the tools can be applied to over more than one frame in a video sequence.
CS5 and CS5 Extended were made available through Adobe's online store, Adobe Authorized Resellers and Adobe direct sales. Both CS5 and CS5 Extended are offered as either a stand-alone application or a feature of Adobe Creative Suite 5. The price for CS5 is US$699 and the extended version is US$999. Both products are compatible with Intel-based Mac OS and Windows XP, Windows Vista, and Windows 7.
CS6.
Photoshop CS6, released in May 2012, added new creative design tools and provided a redesigned interface with a focus on enhanced performance. New features have been added to the Content-Aware tool such as the Content-Aware Patch and Content-Aware Move.
Adobe Photoshop CS6 brought a suite of tools for video editing. Color and exposure adjustments, as well as layers, are among a few things that are featured in this new editor. Upon completion of editing, the user is presented with a handful of options of exporting into a few popular formats.
CS6 brings the "straighten" tool to Photoshop, where a user simply draws a line anywhere on an image, and the canvas will reorient itself so that the line drawn becomes horizontal, and adjusts the media accordingly. This was created with the intention that users will draw a line parallel to a plane in the image, and reorient the image to that plane to more easily achieve certain perspectives.
CS6 allows background saving, which means that while another document is compiling and archiving itself, it is possible to simultaneously edit an image. CS6 also features a customizable auto-save feature, preventing any work from being lost.
Photoshop CS6 was released on 7 May 2012. The price for CS6 is US$699 and the extended version is US$999. Students, however, even those who are homeschooled, can receive a significant discount on Photoshop.
With the newest Photoshop version 13.1.3, Adobe has dropped support for Windows XP (even on native x64 for Windows XP x64); thus, the last version that works on Windows XP is 13.0.1. Adobe also announced that it will quit selling perpetual licenses to new creative suite packages, but will continue to support Photoshop CS6 for OS compatibility and will provide bug fixes and security updates as necessary.
CC.
Photoshop CC (14.0) was launched on 18 June 2013. As the next major version after CS6, it is only available as part of a Creative Cloud subscription, the full version of which costs $49 every month. Major features in this version include All-new Smart Sharpen, Intelligent Upsampling, and Camera Shake Reduction for reducing blur caused by camera shake. Editable Rounded Rectangles and an update to Adobe Camera Raw (8.0) were also included.
Since the initial launch, Adobe has released two additional feature-bearing updates. The first, version 14.1, was launched on 9 September 2013. The major features in this version were Adobe Generator, a Node.js-based platform for creating plug-ins for Photoshop. Photoshop 14.1 shipped with two plug-ins, one to automatically generate image assets based on an extension in the layer name, and another to automatically generate assets for Adobe Edge Reflow.
Version 14.2 was released on 15 January 2014. Major features include Perspective Warp, Linked Smart Objects, and 3D Printing support.
CC 2014.
Photoshop CC 2014 (15.0) was released on 18 June 2014. CC 2014 features improvements to content-aware tools, two new blur tools (spin blur and path blur) and a new focus mask feature that enables the user to select parts of an image based on whether they are in focus or not. Other minor improvements have been made, including speed increases for certain tasks.
Photoshop Touch.
Photoshop Touch is an application designed specifically for tablets and touchscreen devices. It includes many of the features of the personal computer version, including layers, selection tools, adjustments, and filters. Edited files can be synced with Adobe Creative Cloud. Photoshop touch is currently available on iOS and Android. There are two iOS versions—one designed for iPad and the other for iPhone and iPod touch; both require iOS 5.0 or later. Android versions can be installed on any Android handset (4.0 and up) and tablets (3.1 and up).

</doc>
<doc id="24894" url="http://en.wikipedia.org/wiki?curid=24894" title="PaintShop Pro">
PaintShop Pro

PaintShop Pro (PSP) is a raster and vector graphics editor for Microsoft Windows. It was originally published by Jasc Software. In October 2004, Corel purchased Jasc Software and the distribution rights to Paint Shop Pro. PSP functionality can be extended by Photoshop-compatible plugins.
Although often written as Paint Shop Pro, Corel's website shows the name for the product as PaintShop Pro. The X-numbered editions have been sold in two versions: PaintShop Pro, which is the basic editing program, and PaintShop Pro Ultimate, which bundles in other standalone programs. The particular bundled programs have varied with each numbered version and have not been sold by Corel as separate products.
PSP comes with an interface for automating tasks with scripts written in the Python programming language. 
History.
Originally called simply Paint Shop, the first version, 1.0, was a basic picture converter between BMP, GIF and PCX formats, released by Robert Voit in August 1990. Paint Shop was originally distributed as shareware and is still available at many download sites (4.12 being a popular version). Most newer versions are only commercially available although some have been distributed in the United Kingdom in computer magazine CDs after they became obsolete.
On November 28, 2007, Corel announced that the office in Eden Prairie, Minnesota, where Paint Shop Pro was created, would be shut down, with development moving to offices in California and China.
From 2006 to 2011 (versions XI to X3), PaintShop Pro was marketed as "Corel Paint Shop Pro Photo". Having dropped the "Photo" part of the name in version X4, Paintshop Pro X5 was derived from Ulead Photo Explorer after Corel's acquisition of Ulead.
Paint Shop Pro X5 added support for layers as well as CMYK and HSL colour modes, included JASC Animation Shop for creating animations and in fact was marketed as "Paint Shop Pro 5.0 with Animation Shop". PaintShop Pro X6 was the first to be available as a native 64 bit version (purchase includes both versions). PaintShop Pro X7 includes content-aware features such as "Magic Fill" and "Smart Edge" as well as support for XMP sidecar files that preserve edit settings for raw formats.
Picture tubes.
Picture tubes are graphic images with no background. They are often used as a starting point for complex images; that is, they are combined with other image elements to produce a final work. Tubes can also be regarded as graphic brushes based on a pre-created image; this was their original use. Instead of leaving a trace of color on the canvas, they would leave a trail of images. Popular tube subjects include alphabets, human (also known as dollz), animal and toy figures, flowers, love messages and seasonal symbols.
The tube system originated with PSP Pro version 5. Native tube files may be in .tub, .psp, .pspimage, and .psptube formats. XnView, IrfanView, and TubeEx are separate graphics programs that can convert tube files (.tub) to .png.
Ultimate edition.
PaintShop Pro Photo X2 Ultimate was released towards the end of life of PaintShop Pro Photo X2, in September 2008. It included 150 additional picture frames and Picture Tubes, the programs Background Remover, Corel Painter Photo Essentials 4, and Photorecovery, as well as RAW support for 250 cameras and a 2GB flash drive.
Subsequent Ultimate editions were released contemporaneously with the basic version. PaintShop Pro X4 Ultimate included Nik Color Efex Pro 3.0, a voucher for 21 images from Fotolia at high quality, and additional Picture Tubes. X5 Ultimate included Reallusion FaceFilter Studio 2.0, NIK Color Efex Pro 3.0, and "over 100 unique brushes, textures and royalty-free backgrounds". PaintShop Pro X6 Ultimate includes Athentech Imaging's Perfectly Clear and Reallusion's FaceFilter3 Standard. PaintShop Pro X7 Ultimate includes those same two items.
License management software.
Versions XI, X2, X3 and X4 install a third party program named PSIService.exe, a Windows service called ProtexisLicensing. Written by Protexis, this runs in the background and collects licensing information. This program communicates with a remote host. Manually disabling the Protexis Licensing service may cause Corel Paint Shop Pro Photo to cease functioning.
Criticism of pricing policy.
There have been criticisms of Corel's pricing policy that pitches international versions at higher prices than those charged in the US.

</doc>
<doc id="24897" url="http://en.wikipedia.org/wiki?curid=24897" title="Persuasion">
Persuasion

Persuasion is an umbrella term of influence. Persuasion can attempt to influence a person's beliefs, attitudes, intentions, motivations, or behaviors. In business,
persuasion is a process aimed at changing a person's (or a group's) attitude or behavior toward some event, idea, object, or other person(s), by using written or spoken words to convey information, feelings, or reasoning, or a combination thereof. Persuasion is also an often used tool in the pursuit of personal gain, such as election campaigning, giving a sales pitch, or in trial advocacy. Persuasion can also be interpreted as using one's personal or positional resources to change people's behaviors or attitudes.
Systematic persuasion is the process through which attitudes or beliefs are leveraged by appeals to logic and reason. Heuristic persuasion on the other hand is the process through which attitudes or beliefs are leveraged by appeals to habit or emotion.
Brief history.
Persuasion began with the Greeks, who emphasized rhetoric and elocution as the highest standard for a successful politician. All trials were held in front of the Assembly, and both the prosecution and the defense rested, as they often do today, on the persuasiveness of the speaker. Rhetoric was the ability to find the available means of persuasion in any instance.
The Greek philosopher Aristotle listed four reasons why one should learn the art of persuasion:
Theories.
Attribution theory.
Humans attempt to explain the actions of others through either dispositional attribution or situational attribution.
Dispositional attribution, also referred to as internal attribution, attempts to point to a person’s traits, abilities, motives, or dispositions as a cause or explanation for their actions. A citizen criticizing a president by saying the nation is lacking economic progress and health because the president is either lazy or lacking in economic intuition is utilizing a dispositional attribution.
Situational attribution, also referred to as external attribution, attempts to point to the context around the person and factors of his surroundings, particularly things that are completely out of his control. A citizen claiming that a lack of economic progress is not a fault of the president but rather the fact that he inherited a poor economy from the previous president is situational attribution.
Fundamental attribution error occurs when people wrongly attribute either a shortcoming or accomplishment to internal or external factors, when in fact the inverse is true. In general, people tend to make dispositional attributions more often than situational attributions when trying to explain or understand a person’s behavior. This happens when we are much more focused on the individual because we do not know much about their situation or context. When trying to persuade others to like us or another person, we tend to explain positive behaviors and accomplishments with dispositional attribution, but our own negative behaviors and shortcomings with situational attributions.
Conditioning theories.
Conditioning plays a huge part in the concept of persuasion. It is more often about leading someone into taking certain actions of their own, rather than giving direct commands. In advertisements for example, this is done by attempting to connect a positive emotion to a brand/product logo. This is often done by creating commercials that make people laugh, using a sexual undertone, inserting uplifting images and/or music etc. and then ending the commercial with a brand/product logo. Great examples of this are professional athletes. They are paid to connect themselves to things that can be directly related to their roles; sport shoes, tennis rackets, golf balls, or completely irrelevant things like soft drinks, popcorn poppers and panty hose. The important thing for the advertiser is to establish a connection to the consumer.
This conditioning is thought to affect how people view certain products, knowing that most purchases are made on the basis of emotion. Just like you sometimes recall a memory from a certain smell or sound, the objective of some ads is solely to bring back certain emotions when you see their logo in your local store. The hope is that by repeating the message several times it will cause the consumer to be more likely to purchase the product because he/she already connects it with a good emotion and a positive experience.
Stefano DellaVigna and Matthew Gentzkow did a comprehensive study on the effects of persuasion in different domains. They discovered that persuasion has little or no effect on advertisement; however, there was a substantial effect of persuasion on voting if there was face-to-face contact.
Cognitive dissonance theory.
Leon Festinger originally proposed the theory of cognitive dissonance in 1956. He theorized that human beings constantly strive for mental consistency. Our cognition (thoughts, beliefs, or attitudes) can be in agreement, unrelated, or in disagreement with each other. Our cognition can also be in agreement or disagreement with our behaviors. When we detect conflicting cognition, or dissonance, it gives us a sense of incompleteness and discomfort. For example, a person who is addicted to smoking cigarettes but also suspects it could be detrimental to his health suffers from cognitive dissonance.
Festinger suggests that we are motivated to reduce this dissonance until our cognition is in harmony with itself. We strive for mental consistency. There are four main ways we go about reducing or eliminating our dissonance:
Revisiting the example of the smoker, he can either quit smoking, reduce the importance of his health, convince himself he is not at risk, or evaluate the reward of his smoking to be worth the cost of his health.
Cognitive dissonance is powerful when it relates to competition and self-concept. The most famous example of how cognitive dissonance can be used for persuasion comes from Festinger and Carlsmith’s 1959 experiment in which participants were asked to complete a very dull task for an hour. Some were paid $20, while others were paid $1, and afterwards they were instructed to tell the next waiting participants that the experiment was fun and exciting. Those who were paid $1 were much more likely to convince the next participants that the experiment really was enjoyable than those who received $20. This is because $20 is enough reason to participate in a dull task for an hour, so there is no dissonance. Those who received $1 experienced great dissonance, so they had to truly convince themselves that the task actually was enjoyable in order to avoid feeling like they were taken advantage of, and therefore reduce their dissonance.
Elaboration likelihood model.
Persuasion has traditionally been associated with two routes.
The Elaboration likelihood model (ELM) forms a new facet of the route theory. It holds that the probability of effective persuasion depends on how successful the communication is at bringing to mind a relevant mental representation, which is the elaboration likelihood. Thus if the target of the communication is personally relevant, this increases the elaboration likelihood of the intended outcome and would be more persuasive if it were through the central route. Communication which does not require careful thought would be better suited to the peripheral route.
Functional theories.
Functional theorists attempt to understand the divergent attitudes individuals have towards people, objects or issues in different situations. There are four main functional attitudes:
When communication is targeted at an underlying function its degree of persuasiveness will influence whether the individual will change their attitude, after determining that another attitude will be more effective in fulfilling that function.
Inoculation theory.
A vaccine introduces a weak form of a virus that can easily be defeated to prepare the immune system should it need to fight off a stronger form of the same virus. In much the same way, the theory of inoculation suggests a certain party can introduce a weak form of an argument that can easily be thwarted in order to prepare the audience to disregard a stronger, full-fledged form of the argument from an opposing party.
This is often practiced in negative advertisements and comparative advertisements, both for products and political causes. An example would be a manufacturer of a product displaying an ad that refutes one particular claim made about a rival’s product, so that when the audience sees an ad for said rival product, they will refute all the claims of the product without a second thought.
Narrative transportation theory.
Narrative transportation theory proposes that when people lose themselves in a story, their attitudes and intentions change to reflect that story. The mental state of narrative transportation can explain the persuasive effect of stories on people, who may experience narrative transportation when certain contextual and personal preconditions are met, as Green and Brock postulate for the transportation-imagery model. Narrative transportation occurs whenever the story receiver experiences a feeling of entering a world evoked by the narrative because of empathy for the story characters and imagination of the story plot.
Social judgment theory.
Social judgment theory suggests that when people are presented with an idea or any kind of persuasive proposal, their natural reaction is to immediately seek a way to sort the information subconsciously and react to it. We evaluate the information and compare it with the attitude we already have, which is called the initial attitude or anchor point.
When attempting to sort the incoming persuasive information, an audience will evaluate whether it lands in their latitude of acceptance, latitude of non-commitment or indifference, or the latitude of rejection. The size of these latitudes will vary from topic to topic. Our “ego-involvement” generally plays one of the largest roles in determining the size of these latitudes. When a topic is closely connected to how we define and perceive ourselves, or deals with anything we care passionately about, our latitudes of acceptance and non-commitment are likely to be much smaller and our attitude of rejection much larger. A person’s anchor point is considered to be the center of his latitude of acceptance, the position that is most acceptable to him.
An audience is likely to distort incoming information to fit into their unique latitudes. If something falls within the latitude of acceptance, the subject tends to assimilate the information and consider it closer to his anchor point than it really is. Inversely, if something falls within the latitude of rejection, the subject tends to contrast the information and convince himself the information is farther away from his anchor point than it really is.
When trying to persuade an individual target or an entire audience, it is vital to first learn the average latitudes of acceptance, non-commitment, and rejection of your audience. It is ideal to use persuasive information that lands near the boundary of the latitude of acceptance if the goal is to change the audience’s anchor point. Repeatedly suggesting ideas on the fringe of the acceptance latitude will cause people to gradually adjust their anchor points, while suggesting ideas in the rejection latitude or even the non-commitment latitude will not result in any change to the audience’s anchor point.
Methods.
Persuasion methods are also sometimes referred to as "persuasion tactics" or "persuasion strategies".
Usage of force.
There is the usage of force in persuasion, which does not have any scientific theories, except for its use to make demands. The use of force is then a precedent to the failure of less direct means of persuasion. Application of this strategy can be interpreted as a threat since the persuader does not give options to his or her request.
Weapons of influence.
Robert Cialdini, in "Influence", his book on persuasion, defined six "influence cues or weapons of influence": Influence is the process of changing.
Reciprocity.
The principle of reciprocity states that when a person provides us with something, we attempt to repay him or her in kind. Reciprocation produces a sense of obligation, which can be a powerful tool in persuasion. The reciprocity rule is effective because it can be overpowering and instill in us a sense of obligation. Generally, we have a dislike for individuals who neglect to return a favor or provide payment when offered a free service or gift. As a result, reciprocation is a widely held principle. This societal standard makes reciprocity extremely powerful persuasive technique, as it can result in unequal exchanges and can even apply to an uninvited first favor.
Commitment and consistency.
Consistency is an important aspect of persuasion because it:
Consistency allows us to more effectively make decisions and process information. The concept of consistency states that if a person commits, either orally or in writing, he or she is more likely to honor that particular commitment. This is especially true for written commitments, as they appear psychologically more concrete and can be backed up with hard proof. Once a person commits to a stance, he or she has a tendency to behave according to that commitment. Commitment is an effective persuasive technique because once you get someone to make a commitment, they are more likely to engage in self-persuasion, providing themselves and others with reasons and justifications to support his or her commitment in order to avoid dissonance.
Social proof.
We are influenced by others around us; we want to be doing what everyone else is doing. People often base their actions and beliefs on what others around them are doing, how others act or what others believe.
“The power of the crowd” is very effective. We all want to know what others are doing around us. We are so obsessed with what others do and how others act, that we then try to be just like other people. Cialdini gives an example that is somewhat like this: in a phone–a–thon, the host will say something along the line of, “Operators are waiting, please call now.” The only context that you have from that statement is that the operators are waiting and they are not busy. Rather the host may say: “If operators are busy, please call again.” This is proving the technique of social proof. Just by changing three words, it sounds like the lines are busy and other people are calling; so it must be a good, legitimate organization.
Social proof is most effective when people are uncertain or when there are similarities in a situation. In uncertain or ambiguous situations, when there are multiple possibilities or choices that need to be made, people are likely to conform to what others do/are doing. We become more influenced by the people around us, in situations that cause us to make a decision. The other effective situation for social proofing is when there are similarities. We are more prone to change/conform around people who are similar to us. If someone who is similar to you is being controlling and a leader, you are more likely to listen and follow what it is they are saying.
Liking.
This principle is simple and concise. People say “yes” to people that they like. Two major factors contribute to overall liking. The first is physical attractiveness. People who are more physically attractive seem to be more persuasive; they get what they want and they can easily change others' attitudes. This attractiveness is proven to send favorable messages/impressions of other traits that a person may have, such as talent, kindness, and intelligence. The second factor is similarity. This is the simpler aspect of "liking." The idea of similarity states if people like you, they are more likely to say “yes” to what you ask them. When we do this, we usually don’t think about it, it just comes naturally.
Authority.
We have the tendency to believe that if an expert says something, then it must be true. People like to listen to those who are knowledgeable and trustworthy, so if you can be those two things, then you are already on your way to getting people to believe and listen to you.
In the Milgram study, a series of experiments begun in 1961, a "teacher" and a "learner" were placed in two different rooms. The "learner" was attached to an electric harness that could administer shock. The "teacher" was told by a supervisor, dressed in a white scientist's coat, to ask the learner questions and punish him when he got a question wrong. The teacher was instructed by the study supervisor to deliver an electric shock from a panel under the teacher's control. After delivery, the teacher had to up the voltage to the next notch. The voltage went up to 450 volts. The catch to this experiment was that the teacher did not know that the learner was an actor faking the pain sounds he heard and was not actually being harmed. The experiment was being done to see how obedient we are to authority. “When an authority tells ordinary people it is their job to deliver harm, how much suffering will each subject be willing to inflict on an entirely innocent other person if the instructions come 'from above'?”. In this study the results show that most teachers were willing to give as much pain as was available to them. The conclusion was that people are willing to bring pain upon others when they are directed to do so by some authority figure.
Scarcity.
Scarcity is a principle that people underestimate. When something has limited availability, people assign it more value. According to Cialdini, “people want more of what they cannot have.” When scarcity is an issue, the context matters. This means that within certain contexts, scarcity “works” better. To get people to believe that something is scarcer, you need to explain what about that certain product will give them what no other product will. You have to work the audience in the correct way. Something else, that you can do to get people to believe that something is scarce, is to tell them what they will lose, not what they will gain. Saying things like “you will lose $5”, rather than saying “you could save $5”. You are making something sound more scarce.
There are two major reasons why the scarcity principle works:
When this happens, we assign the scarce item or service more value simply because it is harder to acquire.
This principle is that we all want things that are out of our reach. If we see something is easily available, we do not want it as much as something that is very rare.
Machiavellianism.
Machiavellianism employs the tools of manipulation and deceit to gain wealth and power.
Relationship based persuasion of Shell and Moussa.
In their book "The Art of Woo", G. Richard Shell and Mario Moussa present a four-step approach to strategic persuasion. They explain that persuasion means to win others over, not to defeat them. Thus it is important to be able to see the topic from different angles in order to anticipate the reaction others have to a proposal.
Step 1: "Survey your situation"<br>
This step includes an analysis of the persuader's situation, goals, and challenges that the persuader faces in his or her organization.
Step 2: "Confront the five barriers"<br>
Five obstacles pose the greatest risks to a successful influence encounter: relationships, credibility, communication mismatches, belief systems, and interest and needs.
Step 3: "Make your pitch"<br>
People need a solid reason to justify a decision, yet at the same time many decisions are made on the basis of intuition. This step also deals with presentation skills.
Step 4: "Secure your commitments"<br>
In order to safeguard the longtime success of a persuasive decision, it is vital to deal with politics at both the individual and organizational level.
List of methods.
By appeal to reason:
By appeal to emotion:
Aids to persuasion:
Other techniques:
Coercive techniques, some of which are highly controversial and/or not scientifically proven to be effective:
In culture.
It is through a basic cultural personal definition of persuasion that everyday people understand how others are attempting to influence them and then how they influence others. The dialogue surrounding persuasion is constantly evolving because of the necessity to use persuasion in everyday life. Persuasion tactics traded in society have influences from researchers, which may sometimes be misinterpreted.
To keep evolutionary advantage, in the sense of wealth and survival, you must persuade and not be persuaded. In order to understand cultural persuasion, researchers will gather knowledge from domains such as “buying, selling, advertising, and shopping, as well as parenting and courting.”
Methods of persuasion vary by culture, both in prevalence and effectiveness. For example, advertisements tend to appeal to different values according to whether they are used in collectivistic or individualistic cultures.
Persuasion Knowledge Model (PKM).
The Persuasion Knowledge Model (PKM) was created by Friestad and Wright in 1994. This framework allows the researchers to analyze the process of gaining and using everyday persuasion knowledge. The researchers suggest the necessity of including “the relationship and interplay between everyday folk knowledge and scientific knowledge on persuasion, advertising, selling, and marketing in general.”
In order to educate the general population about research findings and new knowledge about persuasion, a teacher must draw on their pre-existing beliefs from folk persuasion in order to make the research relevant and informative to lay people, which creates “mingling of their scientific insights and commonsense beliefs.”
As a result of this constant mingling, the issue of persuasion expertise becomes messy. Expertise status can be interpreted from a variety of sources like job titles, celebrity, or published scholarship.
It is through this multimodal process that we create concepts like "stay away from car salesmen, they will try to trick you.” The kind of persuasion techniques blatantly employed by car salesmen creates an innate distrust of them in popular culture. According to Psychology Today, they employ tactics ranging from making personal life ties with the customer to altering reality by handing the customer the new car keys before the purchase.
Neurobiology.
Attitudes and persuasion are among the central issues of social behavior. One of the classic questions is when are attitudes a predictor of behavior. Previous research suggested that selective activation of left prefrontal cortex might increase the likelihood that an attitude would predict a relevant behavior. Using lateral attentional manipulation, this was supported.
An earlier article showed that EEG measures of anterior prefrontal asymmetry might be a predictor of persuasion. Research participants were presented with arguments that favored and arguments that opposed the attitudes they already held. Those whose brain was more active in left prefrontal areas said that they paid the most attention to statements with which they agreed while those with a more active right prefrontal area said that they paid attention to statements that disagreed. This is an example of defensive repression, the avoidance or forgetting of unpleasant information. Research has shown that the trait of defensive repression is related to relative left prefrontal activation. In addition, when pleasant or unpleasant words, probably analogous to agreement or disagreement, were seen incidental to the main task, an fMRI scan showed preferential left prefrontal activation to the pleasant words.
One way therefore to increase persuasion would seem to be to selectively activate the right prefrontal cortex. This is easily done by monaural stimulation to the contralateral ear. The effect apparently depends on selective attention rather than merely the source of stimulation. This manipulation had the expected outcome: more persuasion for messages coming from the left.

</doc>
<doc id="24898" url="http://en.wikipedia.org/wiki?curid=24898" title="Prime Minister of Israel">
Prime Minister of Israel

The Prime Minister of Israel (Hebrew: רֹאשׁ הַמֶּמְשָׁלָה, "Rosh HaMemshala", "lit." Head of the Government, Hebrew acronym: #redirect ) is the head of the Israeli government and the most powerful figure in Israeli politics. Although the President of Israel is the country's head of state and nominal chief executive, his powers are largely ceremonial; the Prime Minister holds most of the real power. The official residence of the prime minister, "Beit Rosh Hamemshala" is in Jerusalem. The current prime minister is Benjamin Netanyahu of Likud, the ninth person to hold the position (excluding caretakers).
Following an election, the President nominates a member of the Knesset to become prime minister after asking party leaders whom they support for the position. The nominee then presents a government platform and must receive a vote of confidence in order to become prime minister. In practice, the prime minister is usually the leader of the largest party in the governing coalition.
Between 1996 and 2001, the Prime Minister was directly elected, separately from the Knesset.
History.
The office of prime minister came into existence on 14 May 1948, the date of the Declaration of the Establishment of the State of Israel, when the provisional government was created. David Ben-Gurion, leader of Mapai and head of the Jewish Agency became Israel's first Prime Minister. The position became permanent on 8 March 1949, when the first government was formed. Ben-Gurion retained his role until late 1953, when he resigned in order to settle in the Kibbutz of Sde Boker. He was replaced by Moshe Sharett. However, Ben-Gurion returned in a little under two years to reclaim his position. He resigned for a second time in 1963, breaking away from Mapai to form Rafi. Levi Eshkol took over as head of Mapai and prime minister. He became the first prime minister to head the country under the banner of two parties when Mapai formed the Alignment with Ahdut HaAvoda in 1965. In 1968 he also became the only party leader to command an absolute majority in the Knesset, after Mapam and Rafi merged into the Alignment, giving it 63 seats in the 120-seat Knesset.
On 26 February 1969, Eshkol became the first prime minister to die in office, and was temporarily replaced by Yigal Allon. However, Allon's stint lasted less than a month, as the party persuaded Golda Meir to return to political life and become prime minister in March 1969. Meir was Israel's first woman prime minister, and the third in the world (after Sirimavo Bandaranaike and Indira Gandhi).
Meir resigned in 1974 after the Agranat Commission published its findings on the Yom Kippur War, even though it had absolved her of blame. Yitzhak Rabin took over, though he also resigned towards the end of the eighth Knesset's term following a series of scandals. Those included the suicide of Housing Minister Avraham Ofer after police began investigating allegations that he had used party funds illegally, and the affair involving Asher Yadlin (the governor-designate of the Bank of Israel), who was sentenced to five years in prison for having accepted bribes. Rabin's wife, Leah, was also found to have had an overseas bank account, which was illegal in Israel at the time.
Menachem Begin became the first right-wing prime minister when his Likud won the 1977 elections, and retained the post in the 1981 elections. He resigned in 1983 for health reasons, passing the reins of power to Yitzhak Shamir.
After the 1984 elections had proved inconclusive with neither the Alignment nor Likud able to form a government, a national unity government was formed with a rotating prime ministership – Shimon Peres took the first two years, and was replaced by Shamir midway through the Knesset term.
Although the 1988 elections produced another national unity government, Shamir was able to take the role alone. Peres made an abortive bid to form a left-wing government in 1990, but failed, leaving Shamir in power until 1992.
Rabin became prime minister for the second time when he led Labour to victory in the 1992 elections. After his assassination on 4 November 1995, Peres took over as prime minister.
Direct election.
During the thirteenth Knesset (1992–1996) it was decided to hold a separate ballot for prime minister modeled after American presidential elections. This system was instituted in part because the Israeli electoral system makes it all but impossible for one party to win a majority. While only two parties--Mapai/Labour and Likud--had ever led governments, the large number of parties or factions in a typical Knesset usually prevents one party from winning the 61 seats needed for a majority. 
In 1996, when the first such election took place, the outcome was a surprise win for Benjamin Netanyahu after election polls predicted that Peres was the winner. However, in the Knesset election held at the same time, Labour won more votes than any other party (27%). Thus Netanyahu, despite his theoretical position of power, needed the support of the religious parties to form a viable government.
Ultimately Netanyahu failed to hold the government together, and early elections for both Prime Minister and the Knesset were called in 1999. Although five candidates announced their intention to run, the three representing minor parties (Benny Begin of Herut – The National Movement, Azmi Bishara of Balad and Yitzhak Mordechai of the Centre Party) dropped out before election day, and Ehud Barak beat Netanyahu in the election. However, the new system again appeared to have failed, as although Barak's One Israel party (an alliance of Labour, Gesher and Meimad) won more votes than any other party in the Knesset election, they garnered only 26 seats, the lowest ever by a winning party, meaning that a coalition with six smaller parties was once again necessary.
In early 2001, Barak resigned following the outbreak of the al-Aqsa Intifada. However, the government was not brought down, and only elections for prime minister were necessary. In the election itself, Ariel Sharon comfortably beat Barak, taking 62.4% of the vote. However, because Likud only had 21 seats in the Knesset, Sharon had to form a national unity government. Following Sharon's victory, it was decided to do away with separate elections for prime minister and return to the previous system.
2003 onwards.
The 2003 elections were carried out in the same manner as prior to 1996. Likud won 38 seats, the highest by a party for over a decade, and as party leader Sharon was duly appointed PM. However, towards the end of his term and largely as a result of the deep divisions within Likud over Israel's unilateral disengagement plan, Sharon broke away from his party to form Kadima, managing to maintain his position as Prime Minister and also becoming the first Prime Minister not to be a member of either Labour or Likud (or their predecessors). However, he suffered a stroke in January 2006, in the midst of election season, leading Ehud Olmert to become Acting Prime Minister in the weeks leading to the elections. He was voted by the cabinet to be Interim Prime Minister just after the 2006 elections, when Sharon had reached 100 days of incapacitation. He thus became Israel's third Interim Prime Minister, only days before forming his own new Government as the official Prime Minister of Israel.
In 2008, amid accusations of corruption and challenges from his own party, Olmert announced that he would resign. However his successor Tzipi Livni was unable to form a coalition government. In the election in the following year, while Kadima won the most seats, it was the Likud leader Benjamin Netanyahu who was given the task of forming a government. He was able to do so, thus beginning his second term as Prime Minister of Israel.
In the 2013 election, the Likud Yisrael Beiteinu alliance emerged as the largest faction. After forming a coalition, Netanyahu secured his third Prime Ministership.
Order of succession.
If the Prime Minister dies in office, the Cabinet chooses an Interim Prime Minister, to run the government until a new government is placed in power. Yigal Allon served as Interim Prime Minister following Levi Eshkol's death, as did Shimon Peres following the assassination of Yitzhak Rabin.
According to Israeli law, if a Prime Minister is temporarily incapacitated rather than dies (as was the case following Ariel Sharon's stroke in early 2006), power is transferred to the Acting Prime Minister, until the prime minister recovers (Ehud Olmert took over from Sharon), for up to 100 days. If the prime minister is declared permanently incapacitated, or that period expires, the President of Israel oversees the process of assembling a new governing coalition, and in the meantime the acting prime minister or other incumbent minister is appointed by the Cabinet to serve as Interim Prime Minister.
In the case of Sharon, elections were already due to occur within 100 days of the beginning of his coma thus the post-election coalition building process pre-empted the emergency provisions for the selection of a new prime minister. Nevertheless, Olmert was appointed interim prime minister on 16 April 2006, after the elections, just days before he had formed a government on 4 May 2006, to become the official prime minister.
Acting, vice and deputy prime minister.
Aside from the position of acting prime Minister, there are also vice prime ministers and deputy prime ministers.
Prime Minister's residence.
During his term of office, the Prime Minister lives in Jerusalem. Since 1974, the official residence of the Prime Minister is Beit Aghion, at the corner of Balfour and Smolenskin streets in Rehavia.

</doc>
<doc id="24899" url="http://en.wikipedia.org/wiki?curid=24899" title="President of France">
President of France

The President of the French Republic (French: "Président de la République française", ]), is the executive head of state of the French Fifth Republic. The powers, functions and duties of prior presidential offices, and their relation with the first minister and cabinets has over time differed with the various French constitutions.
The President of France is also the "ex officio" Co-Prince of Andorra, Grand Master of the Légion d'honneur and the Ordre national du Mérite and honorary proto-canon of the Basilica of St. John Lateran in Rome.
The current President of France is François Hollande, who took office on 15 May 2012.
Election.
Since the Referendum on the Direct Election of the President of the French Republic, 1962, the President has been directly elected by universal suffrage; he or she was previously elected by an electoral college.
After the Referendum on the Reduction of the Mandate of the President of the French Republic, 2000, the length of the term was reduced from seven to five years; the first election to a shorter term was held in 2002. President Chirac was first elected in 1995 and again in 2002. At that time, there was no limit on the number of terms, so Chirac could have run again, but chose not to. He was succeeded by Nicolas Sarkozy on 16 May 2007.
Following a further change, the Constitutional law on the Modernisation of the Institutions of the Fifth Republic, 2008, a president cannot serve more than two consecutive terms. François Mitterrand and Jacques Chirac are the only Presidents to date who have served a full two terms (14 years for the former, 12 years for the latter).
In order to be admitted as an official candidate, potential candidates must receive signed nominations (informally known as "parrainages", for "godfathering") from more than 500 elected officials, mostly mayors. These officials must be from at least 30 "départements" or overseas collectivities, and no more than 10% of them should be from the same "département" or collectivity. Furthermore, each official may nominate only one candidate. There are exactly 45,543 elected officials, including 33,872 mayors.
Spending and financing of campaigns and political parties are highly regulated. There is a cap on spending, at approximately 20 million euros, and government public financing of 50% of spending if the candidate scores more than 5%. If the candidate receives less than 5% of the vote, the government funds €8,000,000 to the party (€4,000,000 paid in advance). Advertising on TV is forbidden but official time is given to candidates on public TV. An independent agency regulates election and party financing.
French presidential elections are conducted via run-off voting which ensures that the elected President always obtains a majority: if no candidate receives a majority of votes in the first round of voting, the two highest-scoring candidates arrive at a run-off. After the president is elected, he goes through a solemn investiture ceremony called a "passation des pouvoirs" ("handing over of powers").
Powers.
The French Fifth Republic is a semi-presidential system. Unlike many other European presidents, the French President is quite powerful. Although it is the Prime Minister of France and parliament that oversee much of the nation's actual day-to-day affairs, the French President wields significant influence and authority, especially in the fields of national security and foreign policy. The president holds the nation's most senior office, and outranks all other politicians.
The president's greatest power is his/her ability to choose the prime minister. However, since the French National Assembly has the sole power to dismiss the Prime Minister's government, the president is forced to name a prime minister who can command the support of a majority in the assembly.
Since 2002, the mandate of the president and the Assembly are both 5 years and the two elections are close to each other. Therefore, the likelihood of a "cohabitation" is lower. Among the powers of the government:
All decisions of the president must be countersigned by the prime minister, except dissolving the French National Assembly, choice of prime minister, dispositions of Article 19, .
Detailed constitutional powers.
The constitutional attributions of the president are defined in Title II of the Constitution of France.
Article 5
The President of the Republic shall see that the Constitution is observed. He shall ensure, by his arbitration, the proper functioning of the public authorities and the continuity of the State.
He shall be the guarantor of national independence, territorial integrity and observance of treaties.
Article 8
The President of the Republic shall appoint the Prime Minister. He shall terminate the appointment of the Prime Minister when the latter tenders the resignation of the Government.
On the proposal of the Prime Minister, he shall appoint the other members of the Government and terminate their appointments.
Article 9
The President of the Republic shall preside over the Council of Ministers.
Article 10
The President of the Republic shall promulgate Acts of Parliament within fifteen days following the final adoption of an Act and its transmission to the Government.
He may, before the expiry of this time limit, ask Parliament to reconsider the Act or sections of the Act. Reconsideration shall not be refused.
"While the president has to sign all acts adopted by parliament into law, he cannot refuse to do so and exercise a kind of right of veto; his only power in that matter is to ask for a single reconsideration of the law by parliament and this power is subject to countersigning by the Prime minister."
Article 11 The president could submit laws to the people in a referendum with advice and consent of the cabinet.
Article 12
The President of the Republic may, after consulting the Prime Minister and the Presidents of the assemblies, declare the National Assembly dissolved.
A general election shall take place not less than twenty days and not more than forty days after the dissolution.
The National Assembly shall convene as of right on the second Thursday following its election. Should it so convene outside the period prescribed for the ordinary session, a session shall be called by right for a fifteen-day period.
No further dissolution shall take place within a year following this election.
Article 13
The President of the Republic shall sign the ordinances and decrees deliberated upon in the Council of Ministers.
He shall make appointments to the civil and military posts of the State. [...]
Article 14
The President of the Republic shall accredit ambassadors and envoys extraordinary to foreign powers ; foreign ambassadors and envoys extraordinary shall be accredited to him.
Article 15
The President of the Republic shall be commander-in-chief of the armed forces. He shall preside over the higher national defence councils and committees.
Article 16
Where the institutions of the Republic, the independence of the Nation, the integrity of its territory or the fulfilment of its international commitments are under serious and immediate threat, and where the proper functioning of the constitutional public authorities is interrupted, the President of the Republic shall take the measures required by these circumstances, after formally consulting the Prime Minister, the Presidents of the assemblies and the Constitutional Council. He shall inform the Nation of these measures in a message.
The measures must stem from the desire to provide the constitutional public authorities, in the shortest possible time, with the means to carry out their duties. The Constitutional Council shall be consulted with regard to such measures. Parliament shall convene as of right. The National Assembly shall not be dissolved during the exercise of the emergency powers.
"Article 16, allowing the president a limited form of rule by decree for a limited period of time in exceptional circumstance, has been used only once, by Charles de Gaulle during the Algerian War, from 23 April to 29 September 1961."
Article 17
The President of the Republic has the right to grant pardon.
Article 18
The President of the Republic shall communicate with the two assemblies of Parliament by means of messages, which he shall cause to be read and which shall not be the occasion for any debate. He can also give an address in front of the Congress of France in Versailles.
Outside sessions, Parliament shall be convened especially for this purpose.
"From 1875 to 2008, the President was prohibited from entering the houses of Parliament."
Article 19
Acts of the President of the Republic, other than those provided for under articles 8 (first paragraph), 11, 12, 16, 18, 54, 56 and 61, shall be countersigned by the Prime Minister and, where required, by the appropriate ministers.
Article 49 Para 3 allows the president to adopt a law on his authority. To this end, the prime minister goes before the lower and upper houses, reads out the bill to the legislators and closes with "the administration engages its responsibility" on the foregoing. Deprived of Gaullist party support halfway into his seven-year term spanning 1974 to 1981, Pres. Valéry Giscard d'Estaing relied heavily on this provision to stalemate Paris Mayor Jacques Chirac's attempt to bring him back under Gaullist control.
Presidential amnesties.
There is a tradition of so-called "presidential amnesties", which are something of a misnomer: after the election of a president, and of a National Assembly of the same party, parliament traditionally votes a law granting amnesty for some petty crimes. This practice has been increasingly criticized, particularly because it is believed to incite people to commit traffic offences in the months preceding the election. Such an amnesty law may also authorize the president to designate individuals who have committed certain categories of crimes to be offered amnesty, if certain conditions are met. Such individual measures have been criticized for the political patronage that they allow. Still, it is argued that such amnesty laws help reduce prison overpopulation. An amnesty law was passed in 2002; none have yet been passed as of January 2008.
The difference between an amnesty and a presidential pardon is that the former clears all subsequent effects of the sentencing, as though the crime had not been committed, while pardon simply relieves the sentenced individual from part or all of the remainder of the sentence.
Criminal responsibility and impeachment.
Articles 67 and 68 organize the regime of criminal responsibility of the President. They were reformed by a 2007 constitutional act, in order to clarify a situation that previously resulted in legal controversies.
The President of the Republic enjoys immunity during his term: he cannot be requested to testify before any jurisdiction, he cannot be prosecuted, etc. However, the statute of limitation is suspended during his term, and enquiries and prosecutions can be restarted, at the latest one month after he leaves office.
The President is not deemed personally responsible for his actions in his official capacity, except where his actions are indicted before the International Criminal Court or where impeachment is moved against him. Impeachment can be pronounced by the High Court, a special court convened from both houses of Parliament on the proposal of either House, should the president have failed to discharge his duties in a way that evidently precludes the continuation of his term.
Succession and incapacity.
Upon the death or resignation of the President, the President of the Senate acts as interim president. Alain Poher is the only person to have served in this temporary position twice. The first time was in 1969 after Charles de Gaulle's resignation and a second time in 1974 after Georges Pompidou's death. It is important to note that, in this situation, the President of the Senate became an Interim President of the Republic; they do not become the new President of the Republic as elected and therefore do not have to resign from their position as President of the Senate. In spite of his title as Interim President of the Republic, Poher is regarded in France as a former President and is listed in the presidents' gallery on . This is in contrast to acting presidents from the Third Republic.
The first round of a new presidential election must be organized no sooner than twenty days and no later than thirty-five days following the vacancy of the presidency. Because fifteen days can separate the first and second rounds of a presidential election, this means that the President of the Senate can only act as President of the Republic for a maximum period of fifty days. During this period of Interim president is not allowed to dismiss the national assembly nor are they allowed to call for a referendum or initiate any constitutional changes.
If there is no acting president of the senate, the powers of the president of the republic are exercised by the "Gouvernement", meaning the Cabinet. This has been interpreted by some constitutional academics as meaning first the Prime Minister and, if he is himself not able to act, the members of the cabinet in the order of the list of the decree that nominated them. This is in fact unlikely to happen, because if the president of the Senate is not able to act, the Senate will normally name a new president of the Senate, that will act as President of the Republic.
During the Third French Republic the President of the Council of Ministers acted as President whenever office was vacant. According to article 7 of the Constitution, if the presidency becomes vacant for any reason, or if the president becomes incapacitated, upon the request of the "gouvernement", the Constitutional Council may rule, by a majority vote, that the presidency is to be temporarily assumed by the President of the Senate. If the Council rules that the incapacity is permanent, the same procedure as for the resignation is applied, as described above.
If the President cannot attend meetings, including meetings of the Council of Ministers, he can ask the Prime Minister to attend in his stead (Constitution, article 21). This clause has been applied by presidents travelling abroad, ill, or undergoing surgery.
Pay and official residences.
The President of the Republic is paid a salary according to a pay grade defined in comparison to the pay grades of the most seniors members of the French Civil Service ("out of scale", "hors échelle", those whose pay grades are known as letters and not as numeric indices). In addition he is paid a residence stipend of 3%, and a function stipend of 25% on top of the salary and residence indemnity. This gross salary and these indemnities are the same as those of the Prime Minister, and are 50% higher than the highest paid to other members of the government, which is itself defined as twice the average of the highest (pay grade G) and the lowest (pay grade A1) salaries in the "out of scale" pay grades. Using the 2008 "out of scale" pay grades this amounts to a monthly pay of 20,963 €, which fits the 19,000 € quoted to the press in early 2008. Using the pay grades starting from 1 July 2009, this amounts to a gross monthly pay of 21,131 €.
The salary and the residence stipend are taxable for income tax.
The official residence and office of the president is the Élysée Palace in Paris. Other presidential residences include:
Former Presidents.
s of 2015[ [update]] there are three living former Presidents:
According to French law, Former Presidents have guaranteed lifetime pension defined according to the pay grade of the Councillors of State, a courtesy diplomatic passport, and, according to the French Constitution (Article 56), membership of the Constitutional Council.
They also get personnel, an apartment and/or office, and other amenities, though the legal basis for these is disputed. In 2008, according to an answer by the services of the Prime Minister to a question from member of the National Assembly René Dosière, these facilities comprised: a security detail, a car with a chauffeur, office or housing space, maintained by the State. Two people service this space. In addition, the State funds 7 permanent collaborators.
History.
Under the Third and Fourth Republic, which were parliamentary systems, the office of President of the Republic was a largely ceremonial and powerless one.
The constitution of the Fifth Republic greatly increased the President's powers. A 1962 referendum changed the constitution, so that the President would be directly elected by universal suffrage and not by the Parliament.
In 2000, a referendum shortened the presidential term from seven years to five years.
A maximum of two consecutive terms was imposed after the 2008 constitutional reform.

</doc>
<doc id="24900" url="http://en.wikipedia.org/wiki?curid=24900" title="Plastic explosive">
Plastic explosive

Plastic explosive is a soft and hand moldable solid form of explosive material. Within the field of explosives engineering, plastic explosives are also known as putty explosives.
Plastic explosives are especially suited for explosive demolition. Common plastic explosives include Semtex and C-4.
Usage.
Plastic explosives are especially suited for explosive demolition of obstacles and fortifications by engineers and combat engineers as they can be easily formed into the best shapes for cutting structural members and have a high enough velocity of detonation and density for metal cutting work.
An early use of plastic explosives was in the warhead of the British Armoured Vehicle Royal Engineers's (AVRE)'s Petard demolition mortar, used to destroy concrete fortifications encountered during Operation Overlord (D-Day). The original use of Nobel 808 supplied by the SOE was for sabotage of German installations and railways in Occupied Europe.
They are generally not used for ordinary blasting as they tend to be significantly more expensive than other materials that perform just as well in this application. A common commercial use of plastic explosives is for shock hardening high manganese percentage steel, a material typically used for train rail components and earth digging implements.
Some terrorist groups have used plastic explosives. In October 2000, al-Qa'ida used C-4 to attack the USS "Cole", killing 17 sailors In 1996, terrorists used C-4 to blow up the Khobar Towers U.S. military housing complex in Saudi Arabia.
History.
The first plastic explosive was gelignite, invented by Alfred Nobel in 1875.
Prior to World War I, the British explosives chemist Oswald Silberrad obtained British and U.S. patents for a series of plastic explosives called "Nitrols", composed of nitrated aromatics, collodion, and oxidising inorganic salts. The language of the patents indicate that at this time, Silberrad saw no need to explain to "those versed in the art" either what he meant by plasticity nor why it may be advantageous, as he only explains why his plastic explosive is superior to others of that type.
One of the simplest plastic explosives was Nobel's Explosive No. 808, also known as "Nobel 808" (often just called "Explosive 808" in the British Armed Forces during the Second World War), developed by the British company Nobel Chemicals Ltd well before World War II. It had the appearance of green plasticine with a distinctive smell of almonds. During World War II it was extensively used by the British Special Operations Executive (SOE) for sabotage missions. It is also the explosive used in HESH anti-tank shells and was an essential factor in the devising of the Gammon grenade. Captured SOE-supplied Nobel 808 was the explosive used in the failed 20 July plot assassination attempt on Adolf Hitler in 1944.
During and after World War II a number of new RDX-based explosives were developed, including Compositions C, C2, and eventually C3. Together with RDX these incorporate various plasticisers to decrease sensitivity and make the composition plastic. The origin of the obsolete term "plastique" dates back to the Nobel 808 explosive introduced to the U.S. by the British in 1940. The samples of explosive brought to the U.S. by the Tizard Mission had already been packaged by the SOE ready for dropping to the French Resistance and were therefore labelled in French, as "Explosif Plastique". It is still referred to by this name in France and also by some Americans.
C3 was effective but proved to be too brittle in cold weather. In the 1960s it was replaced by C-4, also using RDX but with polyisobutylene and di(2-ethylhexyl)sebacate as the binder and plasticizer. 

</doc>
<doc id="24902" url="http://en.wikipedia.org/wiki?curid=24902" title="Post-structuralism">
Post-structuralism

Post-structuralism is a label formulated by American academics to denote the heterogeneous works of a series of mid-20th-century French and continental philosophers and critical theorists who came to international prominence in the 1960s and '70s. A major theme of post-structuralism is instability in the human sciences, due to the complexity of humans themselves and the impossibility of fully escaping structures in order that we might study them.
Post-structuralism is a response to structuralism. Structuralism is an intellectual movement developed in Europe from the early to mid-20th century. It argued that human culture may be understood by means of a structure—modeled on language (i.e., structural linguistics)—that differs from concrete reality and from abstract ideas—a "third order" that mediates between the two. Post-structuralist authors all present different critiques of structuralism, but common themes include the rejection of the self-sufficiency of the structures that structuralism posits and an interrogation of the binary oppositions that constitute those structures. Writers whose work is often characterised as post-structuralist include Jacques Derrida, Michel Foucault, Gilles Deleuze, Judith Butler, Jacques Lacan, Jean Baudrillard, and Julia Kristeva, although many theorists who have been called "post-structuralist" have rejected the label.
The movement is closely related to postmodernism. As with structuralism, antihumanism is often a central tenet. Existential phenomenology is a significant influence; Colin Davis has argued that post-structuralists might just as accurately be called "post-phenomenologists". Some commentators have criticized post-structuralism for being radically relativistic or nihilistic; others have objected to its extremity and linguistic complexity. Others see it as a threat to traditional values or professional scholarly standards.
Theory.
Destabilized meaning.
In the post-structuralist approach to textual analysis, the reader replaces the author as the primary subject of inquiry. This displacement is often referred to as the "destabilizing" or "decentering" of the author, though it has its greatest effect on the text itself. Without a central fixation on the author, post-structuralists examine other sources for meaning (e.g., readers, cultural norms, other literature, etc.). These alternative sources are never authoritative, and promise no consistency.
In his essay "Signification and Sense," Emmanuel Levinas remarked on this new field of semantic inquiry:
 ...language refers to the position of the listener and the speaker, that is, to the contingency of their story. To seize by inventory all the contexts of language and all possible positions of interlocutors is a senseless task. Every verbal signification lies at the confluence of countless semantic rivers. Experience, like language, no longer seems made of isolated elements lodged somehow in a Euclidean space... [Words] signify from the "world" and from the position of one who is looking.
 — Levinas, "Signification and Sense", Humanism of the Other, "tr. Nidra Poller"
Deconstruction.
A major theory associated with Structuralism was binary opposition. This theory proposed that there are certain theoretical and conceptual opposites, often arranged in a hierarchy, which human logic has given to text. Such binary pairs could include Enlightenment/Romantic, male/female, speech/writing, rational/emotional, signifier/signified, symbolic/imaginary.
Post-structuralism rejects the notion of the essential quality of the dominant relation in the hierarchy, choosing rather to expose these relations and the dependency of the dominant term on its apparently subservient counterpart. The only way to properly understand these meanings is to deconstruct the assumptions and knowledge systems that produce multiplicity, the illusion of singular meaning.
Post-structuralism and structuralism.
Structuralism was an intellectual movement in France in the 1950s and 1960s that studied the underlying structures in cultural products (such as texts) and used analytical concepts from linguistics, psychology, anthropology, and other fields to interpret those structures. It emphasized the logical and scientific nature of its results.
Post-structuralism offers a way of studying how knowledge is produced and critiques structuralist premises. It argues that because history and culture condition the study of underlying structures, both are subject to biases and misinterpretations. A post-structuralist approach argues that to understand an object (e.g., a text), it is necessary to study both the object itself and the systems of knowledge that produced the object.
Historical vs. descriptive view.
Post-structuralists generally assert that post-structuralism is historical, and they classify structuralism as descriptive. This terminology relates to Ferdinand de Saussure's distinction between the views of historical (diachronic) and descriptive (synchronic) reading. From this basic distinction, post-structuralist studies often emphasize history to analyze descriptive concepts. By studying how cultural concepts have changed over time, post-structuralists seek to understand how those same concepts are understood by readers in the present. For example, Michel Foucault's "Madness and Civilization" is both a history and an inspection of cultural attitudes about madness. The theme of history in modern Continental thought can be linked to such influences as Georg Wilhelm Friedrich Hegel, Friedrich Nietzsche's "On the Genealogy of Morals" and Martin Heidegger's "Being and Time".
Structuralists also seek to understand the historical interpretation of cultural concepts, but focus their efforts on understanding how those concepts were understood by the author in his or her own time, rather than how they may be understood by the reader in the present.
Scholars between both movements.
The uncertain distance between structuralism and post-structuralism is further blurred by the fact that scholars generally do not label themselves as post-structuralists. Some scholars associated with structuralism, such as Roland Barthes, also became noteworthy in post-structuralism. Lévi-Strauss, Lacan, Barthes, and Foucault were the so-called "Gang of Four" of structuralism. All but Lévi-Strauss became prominent post-structuralists. The works of Jacques Derrida, Gilles Deleuze, Michel Foucault and Julia Kristeva are also counted as prominent examples of post-structuralism.
The critical reading carried out by these thinkers sought to find contradictions that an author includes, supposedly inevitably, in his work. Those inconsistencies are used to show that the interpretation and criticism of any literature is in the hands of the reader and includes that reader's own cultural biases and assumptions. While many structuralists first thought that they could tease out an author's intention by close scrutiny, they soon argued that textual analysis discovered so many disconnections that it was obvious that their own experiences lent a view that was unique to them.
Some observers from outside the post-structuralist camp have questioned the rigor and legitimacy of the field. American philosopher John Searle argued in 1990 that "The spread of 'poststructuralist' literary theory is perhaps the best known example of a silly but noncatastrophic phenomenon." Similarly, physicist Alan Sokal in 1997 criticized "the postmodernist/poststructuralist gibberish that is now hegemonic in some sectors of the American academy." Literature scholar Norman Holland argued that post-structuralism was flawed due to reliance on Saussure's linguistic model, which was seriously challenged by the 1950s and was soon abandoned by linguists: "Saussure's views are not held, so far as I know, by modern linguists, only by literary critics and the occasional philosopher. [Strict adherence to Saussure] has elicited wrong film and literary theory on a grand scale. One can find dozens of books of literary theory bogged down in signifiers and signifieds, but only a handful that refer to Chomsky."
History.
Post-structuralism emerged in France during the 1960s as a movement critiquing structuralism. According to J.G. Merquior a love–hate relationship with structuralism developed amongst many leading French thinkers in the 1960s. 
The period was marked by political anxiety, as students and workers alike rebelled against the state in May 1968, nearly causing the downfall of the French government. At the same time, however, the support of the French Communist Party (FCP) for the oppressive policies of the USSR contributed to popular disillusionment with orthodox Marxism. As a result, there was increased interest in alternative radical philosophies, including feminism, western Marxism, anarchism, phenomenology, and nihilism. These disparate perspectives, which Michel Foucault later labeled "subjugated knowledges," were all linked by being critical of dominant Western philosophy and culture. Post-structuralism offered a means of justifying these criticisms, by exposing the underlying assumptions of many Western norms.
Two key figures in the early post-structuralist movement were Jacques Derrida and Roland Barthes. In a 1966 lecture "Structure, Sign, and Play in the Discourse of the Human Sciences", Jacques Derrida presented a thesis on an apparent rupture in intellectual life. Derrida interpreted this event as a "decentering" of the former intellectual cosmos. Instead of progress or divergence from an identified centre, Derrida described this "event" as a kind of "play."
Although Barthes was originally a structuralist, during the 1960s he increasingly favored post-structuralist views. In 1967, Barthes published "The Death of the Author" in which he announced a metaphorical event: the "death" of the author as an authentic source of meaning for a given text. Barthes argued that any literary text has multiple meanings, and that the author was not the prime source of the work's semantic content. The "Death of the Author," Barthes maintained, was the "Birth of the Reader," as the source of the proliferation of meanings of the text.
In a 1976 lecture series, Foucault briefly summarized the general impetus of the post-structuralist movement:
 ...For the last ten or fifteen years, the immense and proliferating criticizability of things, institutions, practices, and discourses; a sort of general feeling that the ground was crumbling beneath our feet, especially in places where it seemed most familiar, most solid, and closest to us, to our bodies, to our everyday gestures. But alongside this crumbling and the astonishing efficacy of discontinuous, particular, and local critiques, the facts were also revealing something... beneath this whole thematic, through it and even within it, we have seen what might be called the insurrection of subjugated knowledges.
 — Foucault, "Society Must be Defended", 7th January 1976, " tr. David Macey"
Post-structuralist philosophers like Derrida and Foucault did not form a self-conscious group, but each responded to the traditions of phenomenology and structuralism. Phenomenology, often associated with two German philosophers Edmund Husserl and Martin Heidegger, rejected previous systems of knowledge and attempted to examine life "just as it appears" (as phenomena). Both movements rejected the idea that knowledge could be centred on the human knower, and sought what they considered a more secure foundation for knowledge.
In phenomenology this foundation would be experience itself; in structuralism, knowledge is founded on the "structures" that make experience possible: concepts, and language or signs. Post-structuralism, in turn, argues that founding knowledge either on pure experience (phenomenology) or systematic structures (structuralism) is impossible. This impossibility was meant not a failure or loss, but a cause for "celebration and liberation."
Major works.
Eco and the open text.
Umberto Eco's (1962) "The Open Work" satisfies the criteria of a post-structuralist work. Eco's thesis is that a work of art, and especially of contemporary art, has an undefined meaning, and that the will of the artist was exactly that of producing such indeterminacy or openness. These "open works" (Eco cites Luciano Berio's musical compositions, among many others) have then to be completed by the interpreter, according to that particular interpreter's knowledge. This idea—now accepted by many philosophers and critics (and was popularized by reader-response theories as well as by hermeneutically informed theories, such as those by Jauss or Iser)—was considered "heretical" at the time, and received a very strong opposition, notably from Claude Lévi-Strauss and the writer Eugenio Montale in Italy. These attacks were documented by Eco himself in the prefaces of later editions of this text. The "Open Work" is seen by some to be the very first post-structural book, and considered as a classic in semiotics and continental aesthetics.
In 1968 Eco published "La struttura assente" (literally from Italian: "The Absent Structure"), another book that had a great impact on the transition between structuralism and post-structuralism. Eco suggests that structures are not entities existing "de facto", ontologically, but formal instruments and representations by which scholars can understand cultural concepts, articulating various systems of differences. In 1968, when structuralism was the main theorical reference for many, this book received massive criticism in France and abroad. Later, several structuralists used to define themselves as either "nominalists", if following Eco's path, or "realists", if following Lévi-Strauss's and others' interpretations of what a structure is.
In his later works, especially in "A Theory of Semiotics" (1975), "The Role of the Reader" (1979) and "Semiotics and Philosophy of Language" (1984), Eco defined a semiotic theory taking into account the post-structural innovations, with concepts like "encyclopedia", "symbolic mode" or "model reader".
Barthes and the need for metalanguage.
Although many may have felt the necessity to move beyond structuralism, there was clearly no consensus on how this ought to occur. Much of the study of post-structuralism is based on the common critiques of structuralism. Roland Barthes is of great significance with respect to post-structuralist theory. In his work, "Elements of Semiology" (1967), he advanced the concept of the "metalanguage". A metalanguage is a systematized way of talking about concepts like meaning and grammar beyond the constraints of a traditional (first-order) language; in a metalanguage, symbols replace words and phrases. Insofar as one metalanguage is required for one explanation of first-order language, another may be required, so metalanguages may actually replace first-order languages. Barthes exposes how this structuralist system is regressive; orders of language rely upon a metalanguage by which it is explained, and therefore deconstruction itself is in danger of becoming a metalanguage, thus exposing all languages and discourse to scrutiny. Barthes' other works contributed deconstructive theories about texts.
Derrida's lecture at Johns Hopkins.
The occasional designation of post-structuralism as a movement can be tied to the fact that mounting criticism of structuralism became evident at approximately the same time that structuralism became a topic of interest in universities in the United States. This interest led to a colloquium being held at Johns Hopkins University in 1966 titled "The Languages of Criticism and the Sciences of Man" which saw such French scholars such as Derrida, Barthes, and Lacan invited to speak.
Derrida's lecture at that conference, "Structure, Sign, and Play in the Human Sciences," often appears in collections as a manifesto against structuralism. Derrida's essay was one of the earliest to propose some theoretical limitations to structuralism, and to attempt to theorize on terms that were clearly no longer structuralist.
The element of "play" in the title of Derrida's essay is often erroneously interpreted as "play" in a linguistic sense, based on a general tendency towards puns and humour, while social constructionism as developed in the later work of Michel Foucault is said to create a sense of strategic agency by laying bare the levers of historical change. Many see the importance of Foucault's work as in its synthesis of this social/historical account of the operations of power (see governmentality).
Judith Butler and "Gender Trouble".
A major American thinker associated with post structuralist thought is Judith Butler. Trained in Continental philosophy and published on Hegel, Butler is better known for her engagement with feminist theory and as the 'mother' (along with English literature scholar Eve Sedgwick) of Queer Theory. In "Gender Trouble: Feminism and the Subversion of Identity", Butler explored the persistence of biological sex in feminist theory as the source and cause of the unequal social treatment and status of women. Using ideas about power and subjectification first broached by Michel Foucault in Discipline and Punish, and the linguistic theories of J. L. Austin, Butler argued that sex was an effect rather than the cause of social gender difference, and that the fiction of a stable core gender identity was maintained through socially coerced performances of gender. Butler's ideas depend greatly on the notion of "performativity" and she is widely credited with introducing the term into gender studies. Austin described performative words as those that both describe and produce a thing. The classic example is a minister's statement, "I now pronounce you husband and wife," which both describes and produces two people as married. Similarly, Butler argued that repetitive socially coerced gender performances, which aspire to replicate a normative gender ideal, actually produce the sexed body and gender identity.
In "Gender Trouble", Butler also relied on deconstructionist language theory and Freudian psychoanalysis to argue that heterosexuality is structured in an ongoing series of losses stemming from a repudiation of homosexuality; as such homosexuality can be seen as constitutive of heterosexuality, necessitating its repeated repudiations. Butler embraced the Foucauldian notion that there is no "outside" to culture, and therefore resistance—even consciousness, volition, the self—to forms of oppression is always already structured in terms of that oppression. Therefore, resistance can only take the form of failed imitations of social norms, whose very failure reveals the structures of power that often masquerade as natural or inevitable. For this reason, Butler's work has been taken up by gay, lesbian, bisexual, and transgender people because it re-imagines sexual and gender non-conformity—not to mention the way that heterosexual and cisgender norms are often reproduced in gay and lesbian culture and relationships—as a form of resistance to a heteronormative society that attempts (but always fails) to naturalize the relationships among sex, gender, and sexual orientation.
See also.
Authors.
The following are often said to be post-structuralists, or to have had a post-structuralist period:
Sources.
</dl>

</doc>
<doc id="24903" url="http://en.wikipedia.org/wiki?curid=24903" title="Peace process">
Peace process

Peace process may refer to:

</doc>
<doc id="24905" url="http://en.wikipedia.org/wiki?curid=24905" title="Peyton Randolph">
Peyton Randolph

Peyton Randolph (September 10, 1721 – October 22, 1775) was a planter and public official from the Colony of Virginia. He served as speaker of the Virginia House of Burgesses, chairman of the Virginia Conventions, and the first President of the Continental Congress.
Early life.
Randolph was born in Tazewell Hall Williamsburg, Virginia to a prominent family. His parents were Sir John Randolph, the son of William Randolph, and Susannah Beverley, the daughter of Peter Beverley; his brother was John Randolph. His father died when he was 16.
Randolph attended the College of William and Mary, and later studied law at Middle Temple at the Inns of Court in London, becoming a member of the bar in 1743.
Political career.
Randolph returned to Williamsburg after he became a member of the bar, and was appointed Attorney General of the Colony of Virginia the next year.
He served several terms in the Virginia House of Burgesses, beginning in 1748. It was Randolph's dual roles as attorney general and as burgess that would lead to an extraordinary conflict of interest in 1751.
The new governor, Robert Dinwiddie, had imposed a fee for the certification of land patents, which the House of Burgesses strongly objected to. The House selected Peyton Randolph to represent their cause to Crown authorities in London. In his role as attorney general, though, he was responsible for defending actions taken by the governor. Randolph left for London, over the objections of Governor Dinwiddie, and was replaced for a short time as attorney general by George Wythe. Randolph resumed his post on his return at the behest of Wythe as well as officials in London, who also recommended the Governor drop the new fee.
In 1765 Randolph found himself at odds with a freshman burgess, Patrick Henry, over the matter of a response to the Stamp Act. The House appointed Randolph to draft objections to the act, but his more conservative plan was trumped when Henry obtained passage of five of his seven Virginia Stamp Act Resolutions. This was accomplished at a meeting of the House in which most of the members were absent, and over which Randolph was presiding in the absence of the Speaker.
Randolph resigned as king's attorney (attorney general) in 1766, as fellow Burgesses elected him as their Speaker upon the death of his relative, the powerful Speaker John Robinson. Sitting as the General Court, they also appointed Randolph one of the executors (with George Wythe and Edmund Pendleton) of the former speaker's estate, which was a major financial scandal. As friction between Britain and the colonies progressed, Randolph grew to favor independence. In 1769 the House of Burgesses was dissolved by the Governor in response to its actions against the Townshend Acts. Randolph was thus its last Speaker. Afterwards, Randolph chaired meetings of a group of former House members, principally at a Williamsburg tavern, which worked toward responses to the unwelcome tax measures imposed by the British government. In 1773, he chaired the Virginia committee of correspondence, and on March 21, 1775 he chaired a meeting in Richmond that debated independence (the site of Patrick Henry's famous "give me liberty" speech). A few months later, Randolph negotiated with Lord Dunmore for gunpowder removed from the Williamsburg arsenal.
Virginia selected Randolph as one of its delegates to the Continental Congress in Philadelphia in 1774 and 1775. Fellow delegates elected him their President (Speaker) of both the First Continental Congress (which requested that King George III repeal the Coercive Acts) as well as Second Continental Congress (which extended the Olive Branch Petition as a final attempt at reconciliation). However, Randolph fell ill during each term. Henry Middleton of South Carolina succeeded him as President from his resignation on October 22, 1774 until his return on May 10, 1775. Randolph suffered a fit of apoplexy and died in Philadelphia on October 22, eventually succeeded by John Hancock of Massachusetts as President of the Continental Congress.
Death and legacy.
His remains were returned to Williamsburg, where they remain in the chapel of the College of William and Mary. Because the Continental Congress assumed governmental duties for the American colonies as a whole, such as appointing ambassadors, some consider Randolph to have been the first President of the United States, even though he died before the Declaration of Independence.
The Continental Congress honored their late speaker by naming one of the first frigates for him (USS Randolph (1776)), as well as a crucial fort at the junction of the Ohio and Kanawa Rivers (Fort Randolph (West Virginia)). Randolph County, North Carolina and Randolph County, Indiana were named to honor the colonial statesman.
More recently, during World War II, the early (Essex-Class) Aircraft Carrier USS Randolph (CV-15) was named for Peyton Randolph. Furthermore, the Peyton Randolph House in Colonial Williamsburg was declared a National
Historic Landmark in 1970.

</doc>
<doc id="24910" url="http://en.wikipedia.org/wiki?curid=24910" title="Product topology">
Product topology

In topology and related areas of mathematics, a product space is the cartesian product of a family of topological spaces equipped with a natural topology called the product topology. This topology differs from another, perhaps more obvious, topology called the box topology, which can also be given to a product space and which agrees with the product topology when the product is over only finitely many spaces. However, the product topology is "correct" in that it makes the product space a categorical product of its factors, whereas the box topology is too fine; this is the sense in which the product topology is "natural".
Definition.
Given "X" such that
is the Cartesian product of the topological spaces "Xi", indexed by formula_2, and the canonical projections "pi" : "X" → "Xi", the product topology on "X" is defined to be the coarsest topology (i.e. the topology with the fewest open sets) for which all the projections "pi" are continuous. The product topology is sometimes called the Tychonoff topology.
The open sets in the product topology are unions (finite or infinite) of sets of the form formula_3, where each "Ui" is open in "Xi" and "U""i" ≠ "X""i" for only finitely many "i". In particular, for a finite product (in particular, for the product of two topological spaces), the products of base elements of the "Xi" gives a basis for the product formula_4.
The product topology on "X" is the topology generated by sets of the form "pi"−1("U"), where "i" is in "I " and "U" is an open subset of "Xi". In other words, the sets {"pi"−1("U")} form a subbase for the topology on "X". A subset of "X" is open if and only if it is a (possibly infinite) union of intersections of finitely many sets of the form "pi"−1("U"). The "pi"−1("U") are sometimes called open cylinders, and their intersections are cylinder sets.
In general, the product of the topologies of each "Xi" forms a basis for what is called the box topology on "X". In general, the box topology is finer than the product topology, but for finite products they coincide.
Examples.
If one starts with the standard topology on the real line R and defines a topology on the product of "n" copies of R in this fashion, one obtains the ordinary Euclidean topology on R"n".
The Cantor set is homeomorphic to the product of countably many copies of the discrete space {0,1} and the space of irrational numbers is homeomorphic to the product of countably many copies of the natural numbers, where again each copy carries the discrete topology.
Several additional examples are given in the article on the initial topology.
Properties.
The product space "X", together with the canonical projections, can be characterized by the following universal property: If "Y" is a topological space, and for every "i" in "I", "fi" : "Y" → "Xi" is a continuous map, then there exists "precisely one" continuous map "f" : "Y" → "X" such that for each "i" in "I" the following diagram commutes:
This shows that the product space is a product in the category of topological spaces. It follows from the above universal property that a map "f" : "Y" → "X" is continuous if and only if "fi" = "pi" o "f" is continuous for all "i" in "I". In many cases it is easier to check that the component functions "fi" are continuous. Checking whether a map "f" : "Y" → "X" is continuous is usually more difficult; one tries to use the fact that the "pi" are continuous in some way.
In addition to being continuous, the canonical projections "pi" : "X" → "Xi" are open maps. This means that any open subset of the product space remains open when projected down to the "Xi". The converse is not true: if "W" is a subspace of the product space whose projections down to all the "Xi" are open, then "W" need not be open in "X". (Consider for instance "W" = R2 \ (0,1)2.) The canonical projections are not generally closed maps (consider for example the closed set formula_5 whose projections onto both axes are R \ {0}).
The product topology is also called the "topology of pointwise convergence" because of the following fact: a sequence (or net) in "X" converges if and only if all its projections to the spaces "X""i" converge. In particular, if one considers the space "X" = R"I" of all real valued functions on "I", convergence in the product topology is the same as pointwise convergence of functions.
Any product of closed subsets of "Xi" is a closed set in "X".
An important theorem about the product topology is Tychonoff's theorem: any product of compact spaces is compact. This is easy to show for finite products, while the general statement is equivalent to the axiom of choice.
Axiom of choice.
The axiom of choice is equivalent to the statement that the product of a collection of non-empty sets is non-empty. The proof is easy enough: one needs only to pick an element from each set to find a representative in the product. Conversely, a representative of the product is a set which contains exactly one element from each component.
The axiom of choice occurs again in the study of (topological) product spaces; for example, Tychonoff's theorem on compact sets is a more complex and subtle example of a statement that is equivalent to the axiom of choice.

</doc>
<doc id="24913" url="http://en.wikipedia.org/wiki?curid=24913" title="Playdia">
Playdia

The Playdia (プレイディア, Pureidia) (developed under the codename "BA-X") is a home video game console released exclusively in Japan in 1994 at the initial price of ¥24,800. It was intended for a young audience and, like many consoles of the era (e.g. the LaserActive and the 3DO Interactive Multiplayer), was marketed more as a multimedia home entertainment system than as a dedicated gaming console, with anime quiz software and edutainment making up most of the game library. The Playdia uses a single infrared joypad with simple controls. Bandai, the Playdia's manufacturer, was the only software publisher to support this console.

</doc>
<doc id="24915" url="http://en.wikipedia.org/wiki?curid=24915" title="Pidgin">
Pidgin

A pidgin , or pidgin language, is a simplified version of a language that develops as a means of communication between two or more groups that do not have a language in common. It is most commonly employed in situations such as trade, or where both groups speak languages different from the language of the country in which they reside (but where there is no common language between the groups). Fundamentally, a pidgin is a simplified means of linguistic communication, as it is constructed impromptu, or by convention, between individuals or groups of people. A pidgin is not the native language of any speech community, but is instead learned as a second language. A pidgin may be built from words, sounds, or body language from multiple other languages and cultures. They allow people who have no common language to communicate with each other. Pidgins usually have low prestige with respect to other languages.
Not all simplified or "broken" forms of a language are pidgins. Each pidgin has its own norms of usage which must be learned for proficiency in the pidgin.
Etymology.
The origin of the word is uncertain. "Pidgin" first appeared in print in 1850. The most widely accepted etymology is from the Chinese pronunciation of the English word "business".
Another etymology that has been proposed is English "pigeon", a bird sometimes used for carrying brief written messages, especially in times prior to modern telecommunications.
Terminology.
The word "pidgin", formerly also spelled "pigion", used to refer originally to Chinese Pidgin English, but was later generalized to refer to any pidgin. "Pidgin" may also be used as the specific name for local pidgins or creoles, in places where they are spoken. For example, the name of the creole language Tok Pisin derives from the English words "talk pidgin". Its speakers usually refer to it simply as "pidgin" when speaking English. Likewise, Hawaiian Creole English is commonly referred to by its speakers as "Pidgin".
The term "jargon" has also been used to refer to pidgins, and is found in the names of some pidgins, such as Chinook Jargon. In this context, linguists today use "jargon" to denote a particularly rudimentary type of pidgin; however, this usage is rather rare, and the term "jargon" most often refers to the words particular to a given profession.
Pidgins may start out as or become trade languages, such as Tok Pisin. Trade languages are often fully developed languages in their own right such as Swahili. Trade languages tend to be "vehicular languages", while pidgins can evolve into the vernacular.
Common traits among pidgin languages.
Since a pidgin language is a fundamentally simpler form of communication, the grammar and phonology are usually as simple as possible, and usually consist of:
Pidgin development.
The initial development of a pidgin usually requires:
Keith Whinnom (in ) suggests that pidgins need three languages to form, with one (the superstrate) being clearly dominant over the others.
Linguists sometimes posit that pidgins can become creole languages when a generation of children learn a pidgin as their first language,
a process that regularizes speaker-dependent variation in grammar. Creoles can then replace the existing mix of languages to become the native language of a community (such as the Chavacano language in the Philippines, Krio in Sierra Leone, and Tok Pisin in Papua New Guinea). However, not all pidgins become creole languages; a pidgin may die out before this phase would occur (e.g. the Mediterranean Lingua Franca).
Other scholars, such as Salikoko Mufwene, argue that pidgins and creoles arise independently under different circumstances, and that a pidgin need not always precede a creole nor a creole evolve from a pidgin. Pidgins, according to Mufwene, emerged among trade colonies among "users who preserved their native vernaculars for their day-to-day interactions". Creoles, meanwhile, developed in settlement colonies in which speakers of a European language, often indentured servants whose language would be far from the standard in the first place, interacted extensively with non-European slaves, absorbing certain words and features from the slaves' non-European native languages, resulting in a heavily basilectalized version of the original language. These servants and slaves would come to use the creole as an everyday vernacular, rather than merely in situations in which contact with a speaker of the superstrate was necessary.

</doc>
<doc id="24916" url="http://en.wikipedia.org/wiki?curid=24916" title="Polish">
Polish

Polish may refer to:
Polish may refer to:

</doc>
<doc id="24918" url="http://en.wikipedia.org/wiki?curid=24918" title="People's Liberation Army Navy">
People's Liberation Army Navy

The People's Liberation Army Navy (PLAN or PLA Navy) is the naval warfare branch of the People's Liberation Army, the national armed forces of the People's Republic of China. The PLAN can trace its lineage to naval units fighting during the Chinese Civil War and was established in September 1950. Throughout the 1950s and early 1960s the Soviet Union provided assistance to the PLAN in the form of naval advisers and export of equipment and technology. Until the late 1980s, the PLAN was largely a riverine and littoral force (brown-water navy). However, by the 1990s, following the fall of the Soviet Union and a shift towards a more forward-oriented foreign and security policy, the leaders of the Chinese military were freed from worrying over land border disputes, and instead turned their attention towards the seas. This led to the development of the People's Liberation Army Navy into the green-water navy it is today. Before the 1990s the PLAN had traditionally played a subordinate role to the People's Liberation Army Ground Force.
In 2008, General Qian Lihua confirmed that China plans to operate a small fleet of aircraft carriers in the near future, but for the purpose of regional defence as opposed to "global reach". As of 2013 PLA officials have also outlined plans to operate in the first and second island chains. Chinese strategists term the development of the PLAN from a green-water navy into "a regional blue-water defensive and offensive navy."
The People's Liberation Army Navy is composed of five branches; the People's Liberation Army Navy Submarine Force, the People's Liberation Army Navy Surface Force, the People's Liberation Army Navy Coastal Defense Force, the People's Liberation Army Marine Corps and the People's Liberation Army Naval Air Force. With a personnel strength of 255,000 servicemen and women, including 10,000 marines and 26,000 naval air force personnel, it is the second largest navy in the world in terms of tonnage, behind only the United States Navy, and has the largest number of major combatants of any navy.
History.
The PLAN traces its lineage to units of the Republic of China Navy who defected to the People's Liberation Army towards the end of the Chinese Civil War. In 1949, Mao Zedong asserted that "to oppose imperialist aggression, we must build a powerful navy". During the Landing Operation on Hainan Island, the communists used wooden junks fitted with mountain guns as both transport and warships against the Republic of China Navy. The Naval Academy was set up at Dalian on 22 November 1949, mostly with Soviet instructors. The navy was established in September 1950 by consolidating regional naval forces under General Staff Department command in Jiangyan, now in Taizhou, Jiangsu province. It then consisted of a motley collection of ships and boats acquired from the Kuomintang forces. The Naval Air Force was added two years later. By 1954 an estimated 2,500 Soviet naval advisers were in China—possibly one adviser to every thirty Chinese naval personnel—and the Soviet Union began providing modern ships. With Soviet assistance, the navy reorganized in 1954 and 1955 into the North Sea Fleet, East Sea Fleet, and South Sea Fleet, and a corps of admirals and other naval officers was established from the ranks of the ground forces. In shipbuilding the Soviets first assisted the Chinese, then the Chinese copied Soviet designs without assistance, and finally the Chinese produced vessels of their own design. Eventually Soviet assistance progressed to the point that a joint Sino-Soviet Pacific Ocean fleet was under discussion.
1950s and 1960s.
Through the upheavals of the late 1950s and 1960s the Navy remained relatively undisturbed. Under the leadership of Minister of National Defense Lin Biao, large investments were made in naval construction during the frugal years immediately after the Great Leap Forward. During the Cultural Revolution, a number of top naval commissars and commanders were purged, and naval forces were used to suppress a revolt in Wuhan in July 1967, but the service largely avoided the turmoil affecting the country. Although it paid lip service to Mao and assigned political commissars aboard ships, the Navy continued to train, build, and maintain the fleets as well the coastal defense and aviation arms, as well as in the performance of its mission.
1970s and 1980s.
In the 1970s, when approximately 20 percent of the defense budget was allocated to naval forces, the Navy grew dramatically. The conventional submarine force increased from 35 to 100 boats, the number of missile-carrying ships grew from 20 to 200, and the production of larger surface ships, including support ships for oceangoing operations, increased. The Navy also began development of nuclear attack submarines (SSN) and nuclear-powered ballistic missile submarines (SSBN).
In the 1980s, under the leadership of Chief Naval Commander Liu Huaqing, the navy developed into a regional naval power, though naval construction continued at a level somewhat below the 1970s rate. Liu Huaqing was an Army Officer who spent most of his career in administrative positions involving science and technology. It was not until 1988 that the People's Liberation Army Navy was led by a Naval Officer. Liu was also very close to Deng Xiaoping as his modernization efforts were very much in keeping with Deng's national policies. While under his leadership Naval construction yards produced fewer ships than the 1970s, greater emphasis was placed on technology and qualitative improvement. Modernization efforts also encompassed higher educational and technical standards for personnel; reformulation of the traditional coastal defense doctrine and force structure in favor of more green-water operations; and training in naval combined-arms operations involving submarine, surface, naval aviation, and coastal defense forces. Examples of the expansion of China's capabilities were the 1980 recovery of an intercontinental ballistic missile (ICBM) in the Western Pacific by a twenty-ship fleet, extended naval operations in the South China Sea in 1984 and 1985, and the visit of two naval ships to three South Asian nations in 1985. In 1982 the navy conducted a successful test of an underwater-launched ballistic missile. The navy also had some success in developing a variety of surface-to-surface and air-to-surface missiles, improving basic capabilities.
In 1986 the Navy's order of battle included two Xia-class SSBNs armed with twelve CSS-N-3 missiles and three Han-class SSNs armed with six SY-2 cruise missiles. In the late 1980s, major deficiencies reportedly remained in antisubmarine warfare, mine warfare, naval electronics (including electronic countermeasures equipment), and naval aviation capabilities.
The PLA Navy was ranked in 1987 as the third largest navy in the world, although naval personnel had comprised only 12 percent of PLA strength. In 1987 the Navy consisted (as it does now) of the naval headquarters in Beijing; three fleet commands – the North Sea Fleet, based at Qingdao, Shandong; the East Sea Fleet, based at Ningbo; and the South Sea Fleet, based at Zhanjiang, Guangdong – and about 2,000 ships. The 350,000-person Navy included Naval Air Force units of 34,000 men, the Coastal Defense Forces of 38,000, and the Marine Corps of 56,500. Navy Headquarters, which controlled the three fleet commands, was subordinate to the PLA General Staff Department. In 1987, China's 1,500 km coastline was protected by more than 100 diesel-powered Romeo- and Whiskey-class submarines, which could remain at sea only a limited time. Inside this protective ring and within range of shore-based aircraft were destroyers and frigates mounting Styx anti-ship missiles, depth-charge projectors, and guns up to 130 mm. Any invader penetrating the destroyer and frigate protection would have been swarmed by almost 900 fast-attack craft. Stormy weather limited the range of these small boats, however, and curtailed air support. Behind the inner ring were Coastal Defense Force personnel operating naval shore batteries of Styx missiles and guns, backed by ground force units deployed in depth.
Into the 21st century.
As the 21st century approached, the PLAN began to transition to an off-shore defensive strategy that entailed more out-of-area operations away from its traditional territorial waters. Between 1989 and 1993, the training ship "Zhenghe" paid ports visits to Hawaii, Thailand, Bangladesh, Pakistan, and India. PLAN vessels visited Vladivostok in 1993, 1994, 1995, and 1996. PLAN task groups also paid visits to Indonesia in 1995; North Korea in 1997; New Zealand, Australia, and the Philippines in 1998; Malaysia, Tanzania, South Africa, the United States, and Canada in 2000; and India, Pakistan, France, Italy, Germany, Britain, Hong Kong, Australia, and New Zealand in 2001. In March 1997, the "Luhu"-class guided missile destroyer "Harbin", the "Luda"-class guided missile destroyer "Zhuhai", and the replenishment oiler "Nancang" began the PLA Navy's first circumnavigation of the Pacific Ocean, a 98-day voyage with port visits to Mexico, Peru, Chile, and the United States, including Pearl Harbor and San Diego. The flotilla was under the command of Vice Admiral Wang Yongguo, the commander-in-chief of the South Sea Fleet.
The "Luhu"-class guided missile destroyer "Qingdao" and the replenishment oiler "Taicang" completed the PLA Navy's first circumnavigation of the world "(pictured)", a 123-day voyage covering 32000 nmi between 15 May – 23 September 2002. Port visits included Changi, Singapore; Alexandria, Egypt; Aksis, Turkey; Sevastopol, Ukraine; Piraeus, Greece; Lisbon, Portugal; Fortaleza, Brazil; Guayaquil, Ecuador; Callao, Peru; and Papeete in French Polynesia. The PLA naval vessels participated in naval exercises with the French frigates "Nivôse" and "Prairial", as well as exercises with the Peruvian Navy. The flotilla was under the command of Vice Admiral Ding Yiping, the commander-in-chief of the North Sea Fleet, and Captain Li Yujie was the commanding officer of the "Qingdao". Overall, between 1985 and 2006, PLAN naval vessels visited 18 Asian-Pacific nations, 4 South American nations, 8 European nations, 3 African nations, and 3 North American nations. In 2003, the PLAN conducted its first joint naval exercises during separate visits to Pakistan and India. Bi-lateral naval exercises were also carried out with exercises with the French, British, Australian, Canadian, Philippine, and United States navies.
On 26 December 2008, the PLAN dispatched a task group consisting of the guided missile destroyer "Haikou" (flagship), the guided missile destroyer "Wuhan", and the supply ship "Weishanhu" to the Gulf of Aden to participate in anti-piracy operations off the coast of Somalia. A team of 16 Chinese Special Forces members from its Marine Corps armed with attack helicopters were on board. Since then, China has maintained a three-ship flotilla of two warships and one supply ship in the Gulf of Aden by assigning ships to the Gulf of Aden on a three monthly basis. Other recent PLAN incidents include the 2001 Hainan Island incident, a major submarine accident in 2003, and naval incidents involving the U.S. MSC-operated ocean surveillance ships "Victorious" and "Impeccable" during 2009. At the occasion of the 60th anniversary of the PLAN, 52 vessels were shown in manoeuvres off Qingdao in April 2009 including previously unseen nuclear submarines. The demonstration was seen as a sign of the growing status of China, while the CMC Chairman, Hu Jintao, indicated that China is neither seeking regional hegemony nor entering an arms race. Predictions by Western analysts that the PLAN would outnumber the USN submarine force as early as 2011 have failed to come true because the PRC curtailed both imports and domestic production of submarines.
Between 5–12 July 2013, a seven-ship task force from the Northern Fleet joined warships from the Russian Pacific Fleet to participate in Joint Sea 2013, bilateral naval maneuvers held in the Peter the Great Bay of the Sea of Japan. To date, Joint Sea 2013 was the largest naval drills yet undertaken by the People's Liberation Army Navy with a foreign navy.
On 2 April 2015, during the violent aftermath of a coup d'état in Yemen and amid an international bombing campaign, the PLAN helped 10 countries get their citizens out of Yemen safely, evacuating them aboard a missile frigate from the besieged port city of Aden. The operation was described by Reuters as "the first time that China's military has helped other countries evacuate their people during an international crisis".
PRC military expert Yin Zhuo has said that due to present weaknesses in the PLAN's ability to replenish their ships at sea, their future aircraft carriers will be forced to operate in pairs.
Organization.
The PLAN is organized into several departments for purposes of command, control and coordination. Main operating forces are organized into fleets, each with its own headquarters, a commander (a Rear Admiral or Vice Admiral) and a Political Commisar. All PLAN headquarters are subordinate to the PLA General Staff Department and the Chairman of the Central Military Committee.
Fleets.
The People's Liberation Army Navy is divided into three fleets:
Each fleet consists of surface forces (destroyers, frigates, amphibious vessels etc.), submarine forces, coastal defence units, and aircraft.
Branches.
PLAN Submarine Force.
The People's Liberation Army Navy Submarine Force is one of five branches in the navy and consists of all submarines both nuclear-powered and conventionally-powered in service with the PLAN. They are organised into flotillas spread across the three main fleets.
The PRC plans to be the last of the permanent members of the United Nations Security Council to conduct an operational ballistic missile submarine patrol.
PLAN Surface Force.
The People's Liberation Army Surface Force is one of five branches in the navy and consists of all surface warfare ships in service with the PLAN. They are organised into flotillas spread across the three main fleets.
PLAN Coastal Defence Force.
The PLAN Coastal Defence Force is a land-based fighting force and branch of the PLAN with a strength of around 25,000 personnel. Also known as the coastal defense troops, they serve to defend China's coastal areas from invasion via amphibious landings or air-attack. Throughout the 1960s to 1980s, the Coastal Defense Force was focused on defending China's coast from a possible Soviet sea-borne invasion. With the fall of the Soviet Union, the threat of an amphibious invasion of China has diminished and therefore the branch is often considered to no-longer to be a vital component of the PLAN. Especially as the surface warships of the PLAN continue to improve in terms of anti-ship and air-defence capabilities.
Today the primary weapons of the coastal defense troops are the HY-2, YJ-82, and C-602 anti-ship missiles.
PLA Marine Corps.
The PLA Marine Corps was originally established in the 1950s and then re-established in 1979 under PLAN organisation. It consists of around 12,000 marines organised into two 6000-man brigades and is based in the South China Sea with the South Sea Fleet. The Marine Corps are considered elite troops, and are rapid mobilization forces trained primarily in amphibious warfare and as Paratroopers to establish a beachhead or act as a fighting spearhead during operations against enemy targets. The marines are equipped with the standard Type 95 Assault Rifle as well as other small arms and personnel equipment, and a blue/littoral camouflage uniform as standard. The marines are also equipped with armoured fighting vehicles (including amphibious light tanks such as the Type 63), artillery, and anti-aircraft artillery systems and short range surface-to-air missiles.
With the PLAN's accelerating efforts to expand its capabilities beyond territorial waters, it would be likely for the Marine Corps to play a greater role in terms of being an offshore expeditionary force similar to the USMC and Royal Marines.
PLA Naval Air Force.
The People's Liberation Army Naval Air Force is the "air force" of the PLAN and has a strength of around 25,000 personnel and 430 aircraft. It operates similar aircraft to the People's Liberation Army Air Force, including fighter aircraft, bombers, strike aircraft, tankers, reconnaissance aircraft, electronic warfare aircraft, maritime patrol aircraft, transport aircraft, and helicopters of various roles. The PLA Naval Air Force has traditionally received older aircraft than the PLAAF and has taken less ambitious steps towards mass modernization. Advancements in new technologies, weaponry and aircraft acquisition were made after 2000. With the introduction of China's first aircraft carrier, Liaoning the Naval Air Force is for the first time conducting aircraft carrier operations. Naval Air Bases includes:
Relationship with other maritime organisations of China.
The PLAN is complemented by paramilitary maritime services such as the China Coast Guard. The Chinese Coast Guard was previously not under an independent command, considered part of the armed police, under the local (provincial) border defense force command, prior to its reorganization and consolidation as an unified service. It was formed from the integration of several formerly separate services (such as China Marine Surveillance (CMS), Hai Guang, People's Armed Police and sea militia). The CMS performed mostly coastal and ocean search and rescue or patrols. The CMS received quite a few large patrol ships that significantly enhanced their operations, while Hai Guang, militia, police and other services operated hundreds of small patrol craft. For maritime patrol services, these craft are usually quite well armed with machine guns and 37mm antiaircraft guns. In addition, these services operated their own small aviation units to assist their maritime patrol capabilities, with Hai Guang and CMS operating a handful of Harbin Z-9 helicopters, and a maritime patrol aircraft based on the Harbin Y-12 STOL transport.
Every coastal province has 1 to 3 Coast Guard squadrons:
Ranks.
The ranks in the People's Liberation Army Navy are similar to those of the People's Liberation Army Ground Force. The current system of officer ranks and insignia dates from 1988 and is a revision of the ranks and insignia used from 1955 to 1965. The rank of Hai Jun Yi Ji Shang Jiang (First Class Admiral) was never held and was abolished in 1994. With the official introduction of the Type 07 uniforms all officer insignia are on either shoulders or sleeves depending on the type of uniform used. The current system of enlisted ranks and insignia dates from 1998.
Today.
Strategy, plans, priorities.
The People's Liberation Army Navy has become more prominent in recent years owing to a change in Chinese strategic priorities. The new strategic threats include possible conflict with the United States and/or a resurgent Japan in areas such as the Taiwan Strait or the South China Sea. As part of its overall program of naval modernization, the PLAN has a long-term plan of developing a blue water navy. Robert D. Kaplan has said that it was the collapse of the Soviet Union that allowed China to transfer resources from its army to its navy and other force projection assets. China is constructing a major underground nuclear submarine base near Sanya, Hainan. In December 2007 the first Type 094 submarine was moved to Sanya.
The Daily Telegraph on 1 May 2008 reported that tunnels were being built into hillsides which could be capable of hiding up to 20 nuclear submarines from spy satellites. According to the Western news media the base is reportedly to help China project seapower well into the Pacific Ocean area, including challenging United States naval power.
During a 2008 interview with the BBC, Major General Qian Lihua, a senior Chinese defense official, stated that the PLAN aspired to possess a small number of aircraft carriers to allow it to expand China's air defense perimeter. According to Qian the important issue was not whether China had an aircraft carrier, but what it did with it. On 13 January 2009, Adm. Robert F. Willard, head of the U.S. Pacific Command, called the PLAN's modernization "aggressive," and that it raised concerns in the region. On 15 July 2009, Senator Jim Webb of the Senate Foreign Relations Committee declared that only the "United States has both the stature and the national power to confront the obvious imbalance of power that China brings" to situations such as the claims to the Spratly and Paracel islands.
Ronald O'Rourke of the Congressional Research Service wrote that the PLAN "continues to exhibit limitations or weaknesses in several areas, including capabilities for sustained operations by larger formations in distant waters, joint operations with other parts of China’s military, C4ISR systems, anti-air warfare (AAW), antisubmarine warfare (ASW), MCM, and a dependence on foreign suppliers for certain key ship components." In 1998 China purchased the discarded Ukrainian ship Varyag and began retrofitting it for naval deployment. On 25 September 2012, the People's Liberation Army Navy took delivery of China's first aircraft carrier, the Liaoning. The 60,000 ton ship can accommodate 33 fixed wing aircraft. It is widely speculated that these aircraft will be the J15 fighter (the Chinese version of Russia's SU-33).
Japan has raised concerns about the PLAN's growing capability and the lack of transparency as its naval strength keeps on expanding. China has reportedly entered into service the world's first anti-ship ballistic missile called DF-21D. The potential threat from the DF-21D against U.S. aircraft carriers has reportedly caused major changes in U.S. strategy.
Territorial disputes.
Spratly Islands dispute.
The Spratly Islands dispute is a territorial dispute over the ownership of the Spratly Islands, a group of islands located in the South China Sea. States staking claims to various islands are Brunei, Malaysia, the Philippines, Taiwan, Vietnam, and People's Republic of China. All except Brunei occupy some of the islands in dispute. The People's Republic of China conducted naval patrols in the Spratly Islands and established a permanent base.
On 14 March 1988, Chinese and Vietnamese naval forces clashed over Johnson South Reef in the Spratly Islands, which involved three PLAN frigates/
In February 2011, the Chinese frigate "Dongguan" fired three shots at Philippine fishing boats in the vicinity of Jackson atoll. The shots were fired after the frigate instructed the fishing boats to leave, and one of those boats experienced trouble removing its anchor. In May 2011, the Chinese patrol boats attacked and cut the cable of Vietnamese oil exploration ships near Spratly islands. The incidence sparked several anti-China protests in Vietnam. In June, the Chinese navy conducted three days of exercises, including live fire drills, in the disputed waters. This was widely seen as a warning to Vietnam, which had also conducted live fire drills near the Spratly Islands. Chinese patrol boats fired repeated rounds at a target on an apparently uninhabited island, as twin fighter jets streaked in tandem overhead. 14 vessels participated in the maneuvers, staging antisubmarine and beach landing drills aimed at "defending atolls and protecting sea lanes."
In May 2013, the Chinese navy's three operational fleets deployed together for the first time since 2010. This combined naval maneuvers in the South China Sea coincided with the ongoing Spratly Islands dispute between China and the Philippines as well as deployment of the U.S. Navy's Carrier Strike Group Eleven to the U.S. Seventh Fleet.
Diaoyu (Senkaku) Islands dispute.
The Diaoyu Islands dispute concerns a territorial dispute over a group of uninhabited islands known as the Diaoyu Islands in China, the Senkaku in Japan, and Tiaoyutai Islands in Taiwan. Aside from a 1945 to 1972 period of administration by the United States, the archipelago has been controlled by Japan since 1895, when it invaded the Korea and Taiwan. The People's Republic of China disputed the proposed U.S. handover of authority to Japan in 1971. and has asserted its claims to the islands since that time. Taiwan also has claimed these islands. The disputed territory is close to key shipping lanes and rich fishing grounds, and it may have major oil reserves in the area.
On some occasions, ships and planes from various Mainland Chinese and Taiwanese government and military agencies have entered the disputed area. In addition to the cases where they escorted fishing and activist vessels, there have been other incursions. In an eight-month period in 2012, over forty maritime incursions and 160 aerial incursions occurred. For example, in July 2012, three Chinese patrol vessels entered the disputed waters around the islands.
Military escalation continued in 2013. In February, Japanese Defense Minister Itsunori Onodera claimed that a Chinese frigate had locked weapons-targeting radar onto a Japanese destroyer and helicopter on two occasions in January. A Chinese Jiangwei II class frigate and a Japanese destroyer were three kilometers apart, and the crew of the latter vessel went to battle stations. The Chinese state media responded that their frigates had been engaged in routine training at the time. In late February 2013, U.S. intelligence detected China moving road-mobile ballistic missiles closer to the coast near the disputed islands, including medium-range DF-16 anti-ship ballistic missiles. In May, a flotilla of Chinese warships from its North Sea Fleet deployed from Qingdao for training exercises western North Pacific Ocean. It is not known if this deployment is related to the ongoing islands dispute between China and Japan.
Other incidents.
On 22 July 2011, following its Vietnam port-call, the Indian amphibious assault vessel "Airavat" was reportedly contacted 45 nautical miles from the Vietnamese coast in the disputed South China Sea by a party identifying itself as the Chinese Navy and stating that the Indian warship was entering Chinese waters. According to a spokesperson for the Indian Navy, since there were no Chinese ships or aircraft were visible, the INS "Airavat" proceeded on her onward journey as scheduled. The Indian Navy further clarified that "[t]here was no confrontation involving the INS "Airavat". India supports freedom of navigation in international waters, including in the South China Sea, and the right of passage in accordance with accepted principles of international law. These principles should be respected by all."
On 11 July 2012, the Chinese frigate "Dongguan" ran aground on Hasa Hasa Shoal ("pictured") located 60 nmi west of Rizal, which was within the Philippines' 200 nmi-EEZ. By 15 July, the frigate had been refloated and was returning to port with no injuries and only minor damage. During this incident, the 2012 ASEAN summit took place in Phnom Penh, Cambodia, amid the rising regional tensions.
Support for North Korea.
In July 2010, all three operational fleets of the Chinese Navy operated together in the South China Sea. This combined fleet deployment was in response to the bi-lateral naval maneuvers of the United States Seventh Fleet and the South Korean Navy following the sinking of a South Korean frigate by North Korea in March 2010.
2008 anti-piracy operations.
On 18 December 2008, Chinese authorities deployed People's Liberation Army Navy vessels to escort Chinese shipping in the Gulf of Aden. This deployment came after a series of attacks and attempted hijackings on Chinese vessels by Somali pirates. Reports suggest two destroyers (Type 052C 171 Haikou and Type 052B 169 Wuhan) and a supply ship are the ones being used. This move was welcomed by the international community as the warships complement a multinational fleet already operating along the coast of Africa. Since this operation PLAN has sought the leadership of the ‘Shared Awareness and Deconfliction’ body (SHADE), which would require an increase in the number of ships contributing to the anti-piracy fleet. This is the first time Chinese warships have deployed outside the Asia-Pacific region for a military operation since Zheng He's expeditions in the 15th century.
Sine then more than 30 People's Liberation Army Navy ships has deployed to the Gulf of Aden in 18 Escort Task Groups.
Libyan civil war.
In the lead-up to the Libyan Civil War, the "Xuzhou" (530) was deployed from anti-piracy operations in the Gulf of Aden to help evacuate Chinese nationals from Libya.
Yemen Conflict.
In the current Yemen conflict, the Chinese Navy diverted their anti-piracy frigates from Somalia to evacuate at least over 600 Chinese and 225 foreign citizen working in Yemen, the non-Chinese evacuees are 176 Pakistani citizen and smaller numbers from other countries, including Ethiopia, Singapore, the UK, Italy and Germany. The Chinese embassy in Yemen is still in operation.
Future of the People's Liberation Army Navy.
The PLAN's ambitions include operating out to the first and second island chains, as far as the South Pacific near Australia, and spanning to the Aleutian islands, and operations extending to the Straits of Malacca near the Indian Ocean. The future PLAN fleet will be composed of a balance of combatant assets aimed at maximising the PLAN's fighting effectiveness. On the high end, there would be modern destroyers equipped with long-range air defense missiles (Type 052B, Type 052C, Type 052D, Type 051C and Type 055); destroyers armed with supersonic anti-ship missiles ("Sovremenny" class); advanced nuclear-powered attack and ballistic missile submarines (Type 093, Type 095, Type 094, Type 096); advanced conventional attack submarines ("Kilo" and "Yuan" classes); aircraft carriers and large amphibious warfare vessels capable of mobilizing troops at long distances. On the medium and low end, there would be more economical multi-role capable frigates and destroyers ("Luhu", "Jiangwei II" and "Jiangkai" classes); corvettes ("Jiangdao" class); fast littoral missile attack craft ("Houjian", "Houxin" and "Houbei" classes); various landing ships and light craft; and conventionally powered coastal patrol submarines ("Song" class). The obsolete combat ships (based on 1960s designs) will be phased out in the coming decades as more modern designs enter full production. It may take a decade for the bulk of these older ships to be retired. Until then, they will serve principally on the low end, as multi-role patrol/escort platforms. Their use could be further enhanced in the future by being used as fast transports or fire support platforms. This system of phasing out would see a reversal in the decline in quantity of PLAN vessels by 2015, and cuts in inventory after the end of the Cold War could be made up for by 2020.
During 2001–2006 there has been a rapid building and acquisition program. There were more than a dozen new classes of ships built in these last five years, totaling some 60 brand new ships (including landing ships and auxiliaries). Simultaneously, dozens of other ships have been either phased out of service or refitted with new equipment. Submarines play a significant role in the development of the PLAN's future fleet. This is made evident by the construction of a new type of nuclear ballistic missile submarine, the Type 094 and the Type 093 nuclear attack submarine. This will provide the PLAN with a more modern response for the need of a seaborne nuclear deterrent. The new submarines will also be capable of performing conventional strike and other special warfare requirements.
The European Union has provided much of the propulsion technology for the PLAN's modernization.
Ronald O'Rourke of the Congressional Research Service reported that the long-term goals of PLAN planning include:
During the military parade on the 60th anniversary of the People's Republic of China, the YJ-62 naval cruise missile made its first public appearance; the YJ-62 represents the next generation in naval weapons technology in the PLA.
A Chinese website stated that the PLAN is going to build a 110,000 ton aircraft carrier, essentially a larger version of the "Liaoning".
The PLA Navy plans to establish three aircraft carrier battle groups by 2020. The Liaoning and China's first domestically built carrier, currently under construction, will be part of the battle groups. One of the battle groups is to be deployed in the East China Sea, while the other two are to be deployed to the South China Sea.
The PLAN may also operate from Gwadar or Seychelles for anti-piracy missions and to protect vital trade routes which may endanger China's energy security in the case of a conflict.
References.
 This article incorporates public domain material from websites or documents of the .

</doc>
<doc id="24921" url="http://en.wikipedia.org/wiki?curid=24921" title="Patrick Macnee">
Patrick Macnee

Patrick Macnee (born 6 February 1922) is an English-American actor, best known, especially to American audiences, for his role as the secret agent John Steed in the series "The Avengers."
Early life.
Daniel Patrick Macnee, the elder of two sons, was born in London, to Daniel and Dorothea Mary (née Hastings) Macnee. His father trained race horses in Lambourn. His maternal grandmother was Frances Alice Hastings, who was descended from the Earls of Huntingdon.
His parents divorced after his mother declared her lesbianism and had a live-in partner (referred to in the memoirs Macnee dictated to Marie Cameron, "Blind in One Ear: The Avenger Returns," as "Uncle Evelyn") who helped pay for young Patrick's schooling. He was educated at Summer Fields School & Eton College, where he was a member of the Officer Training Corps and was one of the honour guard for King George V at St George's Chapel in 1936. He was later expelled from Eton for selling pornography and being a bookmaker for his fellow students.
He enlisted in the Royal Navy as an Ordinary Seaman in 1942 and was commissioned a Sub-Lieutenant in 1943 becoming a navigator on Motor Torpedo Boats in the English Channel and North Sea.
After nurturing his acting career in Canada, Macnee appeared in supporting roles in a number of films, notably as an extra in Laurence Olivier's "Hamlet" (1948), in the Gene Kelly vehicle "Les Girls" (1957), as an Old Bailey barrister, and with Anthony Quayle in the war film "The Battle of the River Plate" (1956). He had a small role in "Scrooge" (US: "A Christmas Carol" 1951) as the young Jacob Marley. Between these occasional movie roles, Macnee spent the better part of the 1950s working at dozens of small parts in American and Canadian television and theatre. 
Not long before his career-making role in "The Avengers," Macnee took a break from acting and served as one of the London-based producers for the classic documentary series "The Valiant Years," based on the World War II memoirs of Winston Churchill.
"The Avengers".
While working in London on the Churchill series, Macnee was offered a part originally known as Jonathan Steed. Despite numerous roles in theatre, on television and in cinema, Macnee is best known as John Steed in the series "The Avengers" (1961−69). The series was originally conceived as a vehicle for Ian Hendry, who played the lead role of Dr. David Keel, while Steed was his assistant. Macnee, though, became the lead after Hendry's departure at the end of the first season.
He played opposite a succession of female partners who included Honor Blackman, Diana Rigg and finally Linda Thorson. Steed was also the central character of a revival, follow-on series, "The New Avengers" (1976–77), in which he was teamed with agents named Purdey (Joanna Lumley) and Mike Gambit (Gareth Hunt). Lumley later said she did all the gun-slinging because Macnee, having served in the Second World War, would have nothing to do with guns. 
Although Macnee evolved in the role as the series progressed, the key elements of Steed's persona and appearance were there from very early on: the slightly mysterious demeanour and, increasingly, the light, suave, flirting tone with ladies (and always with his female assistants). Finally, from the episodes with Honor Blackman onwards, the trademark bowler hat and umbrella completed the image. Though it was traditionally associated with London 'city gents,' the ensemble of suit, umbrella and bowler had developed in the post-war years as mufti for ex-servicemen attending Armistice Day ceremonies. Macnee, alongside designer Pierre Cardin, adapted the look into a style all his own, and he went on to design several outfits himself for Steed based on the same basic theme. During the 1960s, Macnee co-wrote two original novels based upon "The Avengers", which he titled "Dead Duck" and "Deadline." In 1988, he dictated his autobiography, which he titled "Blind in One Ear: The Avenger Returns," to Marie Cameron. In 1995, he hosted a documentary, "The Avengers: The Journey Back," directed by Clyde Lucas. 
When asked in June 1982 which "Avengers" female lead was his favourite, Macnee declined to give a specific answer. "Well, I'd rather not say. To do so would invite trouble," he told "TV Week" magazine. Macnee did provide his evaluation of the female leads. Of Honor Blackman he said, "She was wonderful, presenting the concept of a strong-willed, independent and liberated woman just as that sort of woman was beginning to emerge in society." Diana Rigg was "One of the world's great actresses. A superb comedienne. I'm convinced that one day she'll be Dame Diana." (His prediction actually came true in 1994.) Linda Thorson was "one of the sexiest women alive" while Joanna Lumley was "superb in the role of Purdey. An actress who is only now realising her immense potential."
Other roles.
Macnee's other significant roles have included playing Sir Godfrey Tibbett opposite Roger Moore in the James Bond film "A View to a Kill," as Major Crossley in "The Sea Wolves" (again with Moore), guest roles in "Encounter," "Alias Smith and Jones" (for Glen Larson), "Hart to Hart," "Murder, She Wrote," "Battlestar Galactica" (again for Larson) and "The Love Boat." He made an appearance in episode 10 of series one of "The Twilight Zone" in 1959 ("Judgment Night"). Though Macnee found fame as the heroic Steed, the majority of his guest appearances have been in villainous roles. (His involvement with "Galactica" typified these roles; in "Galactica," in addition to narrating the opening titles, he provided the voices of two consecutive Imperious Leaders of the Cylon Alliance and, in "War Of The Gods, Parts One And Two," he also appeared on-camera as Count Iblis, who was seemingly a saviour but actually a demon.) He also presented the American paranormal series "Mysteries, Magic and Miracles." Macnee made his Broadway debut as the star of Anthony Shaffer's mystery "Sleuth" in 1972 and subsequently headlined the national tour of that play. 
On television, in 1975, Macnee made a guest appearance on "Columbo" in the episode "Troubled Waters." In 1983 he played Major Vickers in "For the Term of His Natural Life". He had recurring roles in the crime series "Gavilan" with Robert Urich and in the 1984 satire on big business, "Empire," as Dr. Calvin Cromwell. In the original "Battlestar Galactica" series, as stated above, Macnee provided the voice of two consecutive Imperious Leaders of the evil Cylons, and appeared onscreen as the evil Count Iblis. Macnee also narrated the 2000 documentary .
Sherlock Holmes and Doctor Watson.
In 1984, Macnee appeared in "Magnum, P.I." as a retired British agent who believes he is Sherlock Holmes, in a season four episode titled "Holmes is Where the Heart is." He in fact played both Holmes and Doctor Watson on several occasions. He played Watson three times: once alongside Roger Moore's Sherlock Holmes in a 1976 TV film, "Sherlock Holmes in New York," and twice with Christopher Lee, first in "Incident at Victoria Falls" and then in "Sherlock Holmes and the Leading Lady." He played Holmes in another TV film, "The Hound of London" (1993). He is thus one of only a very small number of actors to have portrayed both Sherlock Holmes "and" Doctor Watson on screen.
Later roles.
He also appeared in several cult films: in "The Howling" as 'Dr George Waggner' (named whimsically after the director of 1941's "The Wolf Man") and as 'Sir Denis Eton-Hogg' in the rockumentary comedy "This Is Spinal Tap." In 1981, he played Dr. Stark in "The Creature Wasn't Nice," also called "Spaceship" and "Naked Space." In 1982, according to information provided by Thomas "Duke" Miller, a TV/movie/celebrity expert, Macnee played the role of actor David Mathews in the made-for-television movie "Rehearsal For Murder," which starred Robert Preston and Lynn Redgrave. The movie was from a script written by "Columbo" co-creators Richard Levinson and William Link. He took over Leo G. Carroll's role as the head of U.N.C.L.E. in "The Return of the Man from U.N.C.L.E The Fifteen-Years-Later Affair," produced by Michael Sloan, in 1983; his role differed from Carroll's of Alexander Waverly. Patrick starred in the 1990s science fiction series "Super Force" as E. B. Hungerford (called "MR. H." by lab assistant F.X.) in the pilot and his computer counterpart; his character's original human incarnation was killed. Macnee also appeared as a supporting character in the 1989 science fiction parody, "Lobster Man From Mars," as Prof. Plocostomos and in "Frasier", season 8, episode 12. He also played in the 1989 film "The Return of Sam McCloud" (again for Glen Larson) as Tom Jamison. He would also make a cameo appearance in the Sci-Fi American television series "Nightman" (also for Larson) as Doctor Walton, a psychiatrist who would advise Johnny/Nightman.
Macnee serves as the narrator for several "behind-the-scenes" featurettes, featured on the James Bond series of DVDs. He lent his voice in a cameo as 'Invisible Jones' in the 1998 critically lambasted film version of "The Avengers" (in which Steed was played by Ralph Fiennes), and he also featured in two pop videos: as Steed in original Avengers footage in the The Pretenders's 1986 video "Don't Get Me Wrong," and in the Oasis's video of their song "Don't Look Back in Anger" in 1996, as the band's driver, a role similar to that which he played in the 1985 James Bond film "A View To A Kill."
He has also appeared in various TV commercials including one in 1990 for Swiss Chalet, the Canadian restaurant chain, and recorded numerous audio books, most notably for the audio book releases of many novels by Jack Higgins. He also recorded the children's books "The Musical Life of Gustav Mole," and its sequel, "The Lost Music (Gustav Mole's War on Noise),", both written by Michael Twinn. Patrick Macnee also appeared as a retired agent in the short-lived TV series "Spy Game" (1997), and in two episodes of the revived series of "Kung Fu, the Legend Continues."
Macnee reunited with his former "Avengers" partner Diana Rigg in her short-lived NBC sitcom, "Diana", in a 1973 episode. 
Circa 1989, Macnee did another commercial of note for the Sterling Motor Car Company which presented an inspired matchup of product and spokesman. In this, over the James Bond theme, the car duels with a motorcycle assailant at high speed through mountainous territory, ultimately eludes the foe, and reaches its destination. Here, it is Macnee who steps out of the car and greets us with a smile, saying, "I suppose you were expecting someone else?"
Personal life.
Macnee has two children, Rupert and Jenny, from his first marriage to Barbara Douglas (1942−56). His second marriage (1965−69) was to actress Katherine Woodville. His third marriage was to Baba Majos de Nagyzsenye, and it lasted from 1988 to her death in 2007. Macnee lives in Rancho Mirage, California.
Macnee became a U.S. citizen in 1959.

</doc>
<doc id="24922" url="http://en.wikipedia.org/wiki?curid=24922" title="List of Polish proverbs">
List of Polish proverbs


</doc>
<doc id="24927" url="http://en.wikipedia.org/wiki?curid=24927" title="Pembroke College, Cambridge">
Pembroke College, Cambridge

Pembroke College is a constituent college of the University of Cambridge, England. The college is the third oldest college of the university and has over seven hundred students and fellows. Physically, it is one of the university's larger colleges, with buildings from almost every century since its founding, as well as extensive gardens. 
 the college has a financial endowment of £53.3 million. Pembroke has a level of academic performance among the highest of all the Cambridge colleges; in 2013 and 2014 Pembroke was placed second in the Tompkins Table.
Pembroke is home to the first chapel designed by Sir Christopher Wren and is one of the Cambridge colleges to have educated a British prime minister, William Pitt the Younger. The college library, with a Victorian neo-gothic clock tower, is endowed with an original copy of the first encyclopaedia to contain printed diagrams. 
The college's current master is Sir Richard Dearlove, who was previously the head of the United Kingdom's Secret Intelligence Service.
History.
On Christmas Eve 1347, Edward III granted Marie de St Pol, widow of the Earl of Pembroke, the licence for the foundation of a new educational establishment in the young university at Cambridge. The "Hall of Valence Mary" ("Custos & Scolares Aule Valence Marie in Cantebrigg'"), as it was originally known, was thus founded to house a body of students and fellows. The statutes were notable in that they both gave preference to students born in France who had already studied elsewhere in England, and that they required students to report fellow students if they indulged in excessive drinking or visited disreputable houses.
The college was later renamed Pembroke Hall, and finally became Pembroke College in 1856.
Buildings.
Old Court.
The first buildings comprised a single court (now called Old Court) containing all the component parts of a college – chapel, hall, kitchen and buttery, master's lodgings, students' rooms – and the statutes provided for a manciple, a cook, a barber and a laundress. Both the founding of the college and the building of the city's first college Chapel (1355) required the grant of a papal bull.
The original court was the university's smallest at only 95 ft by 55 ft, but was enlarged to its current size in the nineteenth century by demolishing the south range.
The college's gatehouse is the oldest in Cambridge.
Chapel.
The original Chapel now forms the Old Library and has a striking seventeenth century plaster ceiling, designed by Henry Doogood, showing birds flying overhead. Around the Civil War, one of Pembroke's fellows and Chaplain to the future Charles I, Matthew Wren, was imprisoned by Oliver Cromwell. On his release after eighteen years he fulfilled a promise by hiring his nephew Christopher Wren to build a great Chapel in his former college. The resulting Chapel was consecrated on St Matthew's Day, 1665, and the eastern end was extended by George Gilbert Scott in 1880, when it was consecrated on the Feast of the Annunciation.
Expansion.
An increase in membership over the last 150 years saw a corresponding increase in building activity. The Hall was rebuilt in 1875–6 by Alfred Waterhouse after he had declared the medieval Hall unsafe. As well as the Hall, Waterhouse built a new range of rooms, Red Buildings (1871–72), in French Renaissance style, designed a new Master's Lodge on the site of Paschal Yard (1873, later to become N staircase), pulled down the old Lodge and the south range of Old Court to open a vista to the Chapel, and finally built a new Library (1877–78) in the continental Gothic style.
Waterhouse was dismissed as architect in 1878 and succeeded by George Gilbert Scott, who, after extending the Chapel, provided additional accommodation with the construction of New Court in 1881, with letters on a series of shields along the string course above the first floor spelling out the Psalm text "Nisi Dominus aedificat domum…" ("Except the Lord build the house, their labour is but vain that build it").
Building work continued into the 20th century with W. D. Caröe as architect. He added Pitt Building (M staircase) between Ivy Court and Waterhouse's Lodge, and extended New Court with the construction of O staircase on the other side of the Lodge. He linked his two buildings with an arched stone screen, Caröe Bridge, along Pembroke Street in a late Baroque style, the principal function of which was to act as a bridge by which undergraduates might cross the Master's forecourt at first-floor level from Pitt Building to New Court without leaving the College or trespassing in what was then the Fellows' Garden.
In 1926, as the Fellows had become increasingly disenchanted with Waterhouse's Hall, Maurice Webb was brought in to remove the open roof, put in a flat ceiling and add two storeys of sets above. The wall between the Hall and the Fellows' Parlour was taken down, and the latter made into a High Table dais. A new Senior Parlour was then created on the ground floor of Hitcham Building. The remodelling work was completed in 1949 when Murrary Easton replaced the Gothic tracery of the windows with a simpler design in the style of the medieval Hall.
In 1933 Maurice Webb built a new Master's Lodge in the south-east corner of the College gardens, on land acquired from Peterhouse in 1861. Following the war, further accommodation was created with the construction in 1957 of Orchard Building, so called because it stands on part of the Foundress's orchard. Finally, in a move to accommodate the majority of junior members on the College site rather than in hostels in the town, in the 1990s Eric Parry designed a new range of buildings on the site of the Master's Lodge, with a new Lodge at the west end. "Foundress Court" was opened in 1997 in celebration of the College's 650th Anniversary. In 2001 the Library was extended to the east and modified internally.
Gardens.
Pembroke's enclosed grounds also house some particularly well-kept gardens, sporting a huge array of carefully selected vegetation. Highlights include "The Orchard" (a patch of semi-wild ground in the centre of the college), an impressive row of Plane Trees and an immaculately kept bowling green, re-turfed in 1996, which is reputed to be among the oldest in continual use in Europe.
A panorama of Old Court showing the college's dining Hall, library and chapel.
Student life.
Pembroke College has both graduate and undergraduate students, termed Valencians, after the College's original name. The undergraduate student body is represented by the Junior Parlour Committee (JPC). The graduate community is represented by the Graduate Parlour Committee (GPC). Pembroke is unusual in having its recreational rooms named as "parlours" rather than the more standard "combination room".
There are many clubs and societies organised by the students of the college, such as the boat club Pembroke College Boat Club and the college's dramatic society the Pembroke Players, which has been made famous by alumni such as Peter Cook, Eric Idle, Tim Brooke-Taylor, Clive James and Bill Oddie and is now in its 60th year.
International programmes.
Pembroke is the only Cambridge college to have an International Programmes Department, providing opportunities for international students to spend a semester (mid-January to mid-June), or part of the summer, in Cambridge. The Spring Semester Programme is a competitive programme for academically outstanding students who wish to follow a regular Cambridge degree course as fully matriculated members of the University. There are around thirty places each year.
In the summer there are three programmes for British and international students: the Pembroke-King's Programme, the International Security and Intelligence Programme, and the Pembroke College-National Academy of Writing Summer Programme. For the eight-week Pembroke-King’s Programme (PKP), as well as the academic content, trips are made to locales such as London, and the programme has a series of formal halls, which are described as "three-course candlelit meals" serving "interesting" fare in Pembroke's historic dining hall. The Pembroke-King's Programme is also the programme for which the prestigious Thouron Prize is awarded, fully supporting nine American undergraduates from Harvard, Yale, and UPenn. The International Security and Intelligence and Creative Writing programmes are four-week programmes open to undergraduates, graduates and professionals.
Institutions named after the college.
Pembroke College, the former women's college at Brown University in the United States, was named for the principal building on the women's campus, Pembroke Hall, which was itself named in honour of the Pembroke College (Cambridge) alumnus Roger Williams, a co-founder of Rhode Island.
In 1981, a decade after the merger of Pembroke College into Brown University, the Pembroke Center for Teaching and Research on Women was named in honour of Pembroke College and the history of women's efforts to gain access to higher education.

</doc>
<doc id="24928" url="http://en.wikipedia.org/wiki?curid=24928" title="Prime ideal">
Prime ideal

 In algebra, a prime ideal is a subset of a ring that shares many important properties of a prime number in the ring of integers. The prime ideals for the integers are the sets that contain all the multiples of a given prime number, together with the zero ideal.
Primitive ideals are prime, and prime ideals are both primary and semiprime.
Prime ideals for commutative rings.
An ideal P of a commutative ring R is prime if it has the following two properties:
This generalizes the following property of prime numbers: if "p" is a prime number and if "p" divides a product "ab" of two integers, then "p" divides "a" or "p" divides "b". We can therefore say
Uses.
One use of prime ideals occurs in algebraic geometry, where varieties are defined as the zero sets of ideals in polynomial rings. It turns out that the irreducible varieties correspond to prime ideals. In the modern abstract approach, one starts with an arbitrary commutative ring and turns the set of its prime ideals, also called its spectrum, into a topological space and can thus define generalizations of varieties called schemes, which find applications not only in geometry, but also in number theory.
The introduction of prime ideals in algebraic number theory was a major step forward: it was realized that the important property of unique factorisation expressed in the fundamental theorem of arithmetic does not hold in every ring of algebraic integers, but a substitute was found when Richard Dedekind replaced elements by ideals and prime elements by prime ideals; see Dedekind domain.
Prime ideals for noncommutative rings.
The notion of a prime ideal can be generalized to noncommutative rings by using the commutative definition "ideal-wise". Wolfgang Krull advanced this idea in 1928. The following content can be found in texts such as and . If R is a (possibly noncommutative) ring and P is an ideal in R other than R itself, we say that P is prime if for any two ideals A and B of R:
It can be shown that this definition is equivalent to the commutative one in commutative rings. It is readily verified that if an ideal of a noncommutative ring R satisfies the commutative definition of prime, then it also satisfies the noncommutative version. An ideal P satisfying the commutative definition of prime is sometimes called a completely prime ideal to distinguish it from other merely prime ideals in the ring. Completely prime ideals are prime ideals, but the converse is not true. For example, the zero ideal in the ring of "n" × "n" matrices over a field is a prime ideal, but it is not completely prime.
This is close to the historical point of view of ideals as ideal numbers, as for the ring Z "A is contained in P" is another way of saying "P divides A", and the unit ideal R represents unity.
Equivalent formulations of the ideal "P" ≠ "R" being prime include the following properties:
Prime ideals in commutative rings are characterized by having multiplicatively closed complements in R, and with slight modification, a similar characterization can be formulated for prime ideals in noncommutative rings. A nonempty subset "S" ⊆ "R" is called an m-system if for any a and b in S, there exists r in R such that "arb" is in S. The following item can then be added to the list of equivalent conditions above:
Connection to maximality.
Prime ideals can frequently be produced as maximal elements of certain collections of ideals. For example:

</doc>
<doc id="24929" url="http://en.wikipedia.org/wiki?curid=24929" title="PC-FX">
PC-FX

The PC-FX (ピーシー エフエックス, Pī Shī Efu Ekkusu) is a 32-bit home video game console made by NEC Corporation. It was released in Japan on December 23, 1994, just weeks after Sony's PlayStation and a month after the Sega Saturn. It is the successor to NEC's PC Engine, known as TurboGrafx-16 in North America.
Unlike its predecessor, the PC-FX was only released in Japan. The console is shaped just like a tower PC and was meant to be similarly upgradeable. However the PC-FX was using an outdated graphics chip that made the system underpowered. A lack of developers' support also meant inadequate games and as a result it was unable to compete effectively with its fifth generation peers. The PC-FX was NEC's last home video game console, and was discontinued in February 1998.
History.
NEC launched the PC-FX's predecessor, the PC Engine in 1987, which although had been warmly accepted in Japan, was unable to match the technical specifications put forward by Nintendo and Sega with their consoles, the Super Famicom and the Sega Mega Drive. Plans were therefore drawn up by NEC for a successor in order to reclaim lost ground.
The PC-FX was based on a 32-bit system architecture named "Iron Man", developed in-house by NEC. NEC demonstrated Iron Man at a number of trade shows and events during 1992, and by the middle of the year were discussing an imminent release of an Iron Man-based video game system with many third party developers. At the time, the earlier PC Engine was still quite popular in Japan, and opinions on the Iron Man technology were mixed. Many were uninterested in switching to more powerful hardware while the PC Engine market was still growing, and as a result NEC halted work on the Iron Man project, instead opting for more modifications to the PC Engine technology.
When NEC decided to release the PC-FX, the specs were relatively unchanged from the originally unveiled Iron Man architecture. The most significant difference was the addition of a new 32-bit V-810 RISC CPU.
The console was announced in late 1993. In a special Game Machine Cross Review in May 1995, "Famicom Tsūshin" would score the PC-FX console an 18 out of 40.
Unusual for a fifth generation console, the PC-FX does not have a polygon graphics processor. NEC's reasoning for this was that polygon processors of the time were relatively low-powered, resulting in figures having a blocky appearance, and that it would be better for games to use pre-rendered polygon graphics instead. The shining quality of the PC-FX was the ability to decompress 30 JPEG pictures per second while playing digitally recorded audio (essentially a form of Motion JPEG). This resulted in the PC-FX having superior full motion video quality over all other fifth generation consoles.
The system's target audience was roughly five years older than that of the PC Engine, in hopes that PC Engine fans would be brought over to the successor console. In an interview roughly a year before the system launch, a representative stated that though NEC had not entirely ruled out the possibility of a release outside Japan, they had concluded that unless additional non-gaming uses were developed for the PC-FX, it would sell poorly in the USA due to its high price. According to NEC of Japan, as of August 1995 the PC-FX had sold just under 100,000 units.
Unlike nearly any other console (except for the 3DO and CD-i), the PC-FX was also available as an internal PC card for NEC PC-98 and AT/IBM PC compatibles. This PC card came with two CDs of software to help the user program games for the PC-FX. However, compatibility issues prevented games developed with this software from actually running on the console.
The PC-FX was discontinued in early 1998.
Hardware.
The PC-FX uses CD-ROMs as its storage medium, following on from the expansion released for its predecessor, which originally used HuCards. The game controller is virtually identical to a DUO-RX controller, but the rapid fire switches have been replaced with mode A/B switches. Peripherals include a PC-FX mouse, which is supported by strategy games like "Farland Story FX" and "Power DoLLS FX".
The PC-FX's computer-like design was unusual for consoles at the time. It stands upright like a tower computer while other contemporary consoles lay flat. Another interesting feature is its three expansion ports.
The PC-FX includes an HU 62 series 32-bit system board, an LSI chip, and a 32-bit V-810 RISC CPU. The system can display 16.77 million colors (the same amount as the PlayStation).
Software.
There were 62 games released for the system. The launch titles were "", "Battle Heat" and "Team Innocent" on December 23, 1994 and the final game released was "First Kiss Story" on April 24, 1998. The system and all titles were only released in Japan. A number of demo discs were also released with publications which allowed the user to play the disc in a CD equipped PC-Engine or the PC-FX.
There was no copy protection on any of the PC-FX games, because at the time the system was released, the high price of CD-R burners made piracy expensive.
Emulators.
Below is a list of PC-FX emulators for various platforms.

</doc>
<doc id="24931" url="http://en.wikipedia.org/wiki?curid=24931" title="Psychotherapy">
Psychotherapy

Psychotherapy is therapy in which a person with mental or emotional problems talks with another person (talking therapies). This other person may be a psychiatrist, psychologist, counselor, clinical social worker, member of the clergy, alternative practitioner, or (to use the concept in its broadest sense) any helpful person. With successful psychotherapy, a client experiences positive change, resolves or mitigates troublesome behaviors, beliefs, compulsions, thoughts, or emotions. Ideally, these are replaced with more pleasant and functional alternatives.
Psychotherapy includes interactive processes between a person or group and a psychotherapist. Psychotherapy aims to increase the individual's sense of his/her own well-being. Psychotherapists employ a range of techniques designed to improve the mental health of a client or patient, or to improve group relationships (such as in a family).
Psychotherapy may also be performed by practitioners with different qualifications, including psychiatry, psychology, social work (clinical or psychiatric), counseling psychology, mental health counseling, marriage and family therapy, rehabilitation counseling, school counseling, hypnotherapy, guided imagery, play therapy, music therapy, art therapy, drama therapy, dance/movement therapy, occupational therapy, psychiatric nursing, psychoanalysis, sensorimotor psychotherapy, somatic experiencing, and others. It may be legally regulated, voluntarily regulated or unregulated, depending on the jurisdiction. Requirements of these professions vary, and often require a graduate degree and supervised clinical experience. Psychotherapy in Europe is increasingly seen as an independent profession, rather than restricted to psychologists and psychiatrists as is stipulated in some countries.
Regulation.
Continental Europe.
In Germany, the Psychotherapy Act (PsychThG, 1998) restricts the practice of psychotherapy for adults to the professions of psychology who have completed a five-year course. Children may receive such therapy from social pedagogues and social workers who have completed a five-year postgraduate course. Until 2003, physicians had to complete a residency in psychotherapeutic medicine. A training in psychotherapy is also part of residency in psychiatry and psychosomatic medicine. The title given to such professionals is consultant for psychiatry and psychotherapy and consultant for psychosomatic medicine and psychotherapy. All consultant physicians are able to specialize themselves in psychotherapy for their province e.g. in psychotherapy for oncology in a five-year course.
In Italy, the Ossicini Act (no. 56/1989, art. 3) restricts the practice of psychotherapy to graduates in psychology or medicine who have completed a four-year postgraduate course in psychotherapy at a training school recognised by the state.
French legislation restricts the use of the title "psychotherapist" to professionals on the National Register of Psychotherapists; inscription on this register requires a training in clinical psychopathology and a period of internship which is only open to physicians or titulars of a master's degree in psychology or psychoanalysis.
Sweden has a similar restriction on the title "psychotherapist", which may only be used by professionals who have gone through a post-graduate training in psychotherapy and then applied for a licence, issued by the National Board of Health and Welfare.
Austria and Switzerland (2011) have laws that recognize multidifunctional-disciplinary approaches.
United Kingdom.
In the United Kingdom, psychotherapy is voluntarily regulated. National registers for psychotherapists and counsellors are maintained by three main umbrella bodies:
There are many smaller professional bodies and associations such as the Association of Child Psychotherapists (ACP) and the British Association of Psychotherapists (BAP).
Following a 2007 United Kingdom Government White Paper, "Trust Assurance and Safety – The Regulation of Health Professionals in the 21st Century" the Health Professions Council (HPC) consulted on potential statutory regulation of psychotherapists and counsellors. The HPC is an official state regulator that regulates some 15 professions at present. Research by academics at King's College London subsequently studied the effects of increasing regulation of psychotherapists and counsellors, compared with the effects of statutory regulation of medical doctors. The research found significant unintended effects of statutory regulation, especially defensive practice, and concluded that mandatory professional regulation was a more effective way of regulating the practices of psychotherapists and counsellors.
Government policy subsequently moved away from statutory regulation, and the Professional Standards Authority for Health and Social Care (PSA) launched an Accredited Voluntary Registers scheme.
United States.
In the United States, counselors or therapists must be licensed in order to practice their profession for fees. Licensing regulation is performed by the various states. Practice without a license by the state in which the practice takes place is illegal. Without a license, a practitioner cannot bill insurance companies.
Information about state licensure is provided by the American Psychological Association 
In addition to state laws, the American Psychological Association enacts “Ethical Principles” for its members.
The American Board of Professional Psychology examines and certifies “psychologists who demonstrate competence in approved specialty areas in professional psychology.”
Etymology.
' is an English word of Greek origin, deriving from Ancient Greek ' ( meaning "breath; spirit; soul") and "therapeia" ( "healing; medical treatment").
According to the "Oxford English Dictionary", "psychotherapy" first meant "hypnotherapy" instead of "". The original meaning, "the treatment of disease by ‘psychic’ [i.e., hypnotic] methods", was first recorded in 1853 as "Psychotherapeia, or the remedial influence of mind". The modern meaning, "the treatment of disorders of the mind or personality by psychological or psychophysiological methods", was first used in 1892 by Frederik van Eeden translating "Suggestive Psycho-therapy" for his French "Psychothérapie Suggestive". Van Eeden credited borrowing this term from Daniel Hack Tuke and noted, "Psycho-therapy ... had the misfortune to be taken in tow by hypnotism."
The psychiatrist Jerome Frank defined psychotherapy as the relief of distress or disability in one person by another, using an approach based on a particular theory or paradigm, and a requirement that the agent performing the therapy has had some form of training in delivering this. It is these latter two points which distinguish psychotherapy from other forms of counseling or caregiving. In the United States, a councilor is defined as one who provides specific help for a particular need such as addiction while a therapist works on a broader range of issues and generally for a longer period of time.
Psychologist Hans J. Eysenck, in explaining the relationship between psychotherapy, behavior therapy and behavior modification defines it in its broadest sense as "the use of psychological theories and methods in the treatment of psychiatric disorders." He goes on to state that psychotherapy "has a narrower meaning, namely the use of interpretative (mostly Freudian) methods of therapy."
Forms.
Most forms of psychotherapy use spoken conversation. Some also use various other forms of communication such as the written word, artwork, drama, narrative story or music. Psychotherapy with children and their parents often involves play, dramatization (i.e. role-play), and drawing, with a co-constructed narrative from these non-verbal and displaced modes of interacting. Psychotherapy occurs within a structured encounter between a trained therapist and client(s). Purposeful, theoretically based psychotherapy began in the 19th century with psychoanalysis; since then, scores of other approaches have been developed and continue to be created.
Therapy is generally used in response to a variety of specific or non-specific manifestations of clinically diagnosable and/or existential crises. Treatment of everyday problems is more often referred to as
counseling (a distinction originally adopted by Carl Rogers). However, the term counseling is sometimes used interchangeably with "psychotherapy".
While some psychotherapeutic interventions are designed to treat the patient using the medical model, many psychotherapeutic approaches do not adhere to the symptom-based model of "illness/cure". Some practitioners, such as humanistic therapists, see themselves more in a facilitative/helper role. As sensitive and deeply personal topics are often discussed during psychotherapy, therapists are expected, and usually legally bound, to respect client or patient confidentiality. The critical importance of confidentiality is enshrined in the regulatory psychotherapeutic organizations' codes of ethical practice.
Systems.
There are several main broad systems of psychotherapy:
There are hundreds of psychotherapeutic approaches or schools of thought. By 1980 there were more than 250; by 1996 there were more than 450.
History.
In an informal sense, psychotherapy can be said to have been practiced through the ages, as individuals received psychological counsel and reassurance from others.
According to Colin Feltham, "The Stoics were one of the main Hellenistic schools of philosophy and therapy, along with the Sceptics and Epicureans (Nussbaum, 1994). Philosophers and physicians from these schools practised psychotherapy among the Greeks and Romans from about the late 4th century BC to the 4th century AD." Indeed, Stoic philosophy was explicitly cited by the founders of cognitive therapy and rational-emotive behaviour therapy as the principal precursor and inspiration for their own approaches.
Psychoanalysis was perhaps the first specific school of psychotherapy, developed by Sigmund Freud and others through the early 20th century. Trained as a neurologist, Freud began focusing on problems that appeared to have no discernible organic basis, and theorized that they had psychological causes originating in childhood experiences and the unconscious mind. Techniques such as dream interpretation, free association, transference and analysis of the id, ego and superego were developed. Many theorists, including Anna Freud, Alfred Adler, Carl Jung, Karen Horney, Otto Rank, Erik Erikson, Melanie Klein, and Heinz Kohut, built upon Freud's fundamental ideas and often developed their own systems of psychotherapy. These were all later categorized as "psychodynamic", meaning anything that involved the psyche's conscious/unconscious influence on external relationships and the self. Sessions tended to number into the hundreds over several years.
Behaviorism developed in the 1920s, and behavior modification as a therapy became popularized in the 1950s and 1960s. Notable contributors were Joseph Wolpe in South Africa, M.B. Shipiro and Hans Eysenck in Britain, and John B. Watson and B.F. Skinner in the United States. Behavioral therapy approaches relied on principles of operant conditioning, classical conditioning and social learning theory to bring about therapeutic change in observable symptoms. The approach became commonly used for phobias, as well as other disorders.
Some therapeutic approaches developed out of the European school of existential philosophy. Concerned mainly with the individual's ability to develop and preserve a sense of meaning and purpose throughout life, major contributors to the field in the US (e.g., Irvin Yalom, Rollo May) and Europe (Viktor Frankl, Ludwig Binswanger, Medard Boss, R.D.Laing, Emmy van Deurzen) and later in the 1960s and 1970s both in the United Kingdom and in Canada, Eugene Heimler attempted to create therapies sensitive to common 'life crises' springing from the essential bleakness of human self-awareness, previously accessible only through the complex writings of existential philosophers (e.g., Søren Kierkegaard, Jean-Paul Sartre, Gabriel Marcel, Martin Heidegger, Friedrich Nietzsche). The uniqueness of the patient-therapist relationship thus also forms a vehicle for therapeutic inquiry. A related body of thought in psychotherapy started in the 1950s with Carl Rogers. Based on existentialism and the works of Abraham Maslow and his hierarchy of human needs, Rogers brought person-centered psychotherapy into mainstream focus. The primary requirement of Rogers is that the client should be in receipt of three core 'conditions' from his counsellor or therapist: unconditional positive regard, also sometimes described as 'prizing' the person or valuing the humanity of an individual, congruence [authenticity/genuineness/transparency], and empathic understanding. The aim in using the 'core conditions' is to facilitate therapeutic change within a non-directive relationship conducive to enhancing the client's psychological well being. This type of interaction enables the client to fully experience and express himself. Others developed the approach, like Fritz and Laura Perls in the creation of Gestalt therapy, as well as Marshall Rosenberg, founder of Nonviolent Communication, and Eric Berne, founder of Transactional Analysis. Later these fields of psychotherapy would become what is known as humanistic psychotherapy today. Self-help groups and books became widespread.
During the 1950s, Albert Ellis originated Rational Emotive Behavior Therapy (REBT). A few years later, psychiatrist Aaron T. Beck developed a form of psychotherapy known as cognitive therapy. Both of these generally included relatively short, structured and present-focused therapy aimed at identifying and changing a person's beliefs, appraisals and reaction-patterns, by contrast with the more long-lasting insight-based approach of psychodynamic or humanistic therapies. Cognitive and behavioral therapy approaches were combined and grouped under the heading and umbrella-term Cognitive behavioral therapy (CBT) in the 1970s. Many approaches within CBT are oriented towards active/directive collaborative empiricism and mapping, assessing and modifying clients core beliefs and dysfunctional schemas. These approaches gained widespread acceptance as a primary treatment for numerous disorders. A "third wave" of cognitive and behavioral therapies developed, including Acceptance and Commitment Therapy and Dialectical behavior therapy, which expanded the concepts to other disorders and/or added novel components and mindfulness exercises. Counseling methods developed, including solution-focused therapy and systemic coaching. During the 1960s and 1970s Eugene Heimler, after training in the new discipline of psychiatric social work, developed Heimler method of Human Social Functioning, a methodology based on the principle that frustration is the potential to human flourishing. Positive psychotherapy (PPT) (since 1968) is the name of the method of the psychotherapeutic modality developed by Nossrat Peseschkian and co-workers. Prof. Peseschkian, MD, (1933–2010) was a specialist in neurology, psychiatry, psychotherapy and psychotherapeutic medicine. Positive psychotherapy is a method in the field of humanistic and psychodynamic psychotherapy and is based on a positive image of man, which correlates with a salutogenetic, resource-oriented, humanistic and conflict-centered approach.
Postmodern psychotherapies such as Narrative Therapy and Coherence Therapy did not impose definitions of mental health and illness, but rather saw the goal of therapy as something constructed by the client and therapist in a social context. Systems Therapy also developed, which focuses on family and group dynamics—and Transpersonal psychology, which focuses on the spiritual facet of human experience. Other important orientations developed in the last three decades include Feminist therapy, Brief therapy, Somatic Psychology, Expressive therapy, applied Positive psychology and the Human Givens approach which is building on the best of what has gone before. A survey of over 2,500 US therapists in 2006 revealed the most utilized models of therapy and the ten most influential therapists of the previous quarter-century.
General description.
Psychotherapy can be seen as an interpersonal invitation offered by (often trained and regulated) psychotherapists to aid clients in reaching their full potential or to cope better with problems of life. Psychotherapists usually receive remuneration in some form in return for their time and skills. This is one way in which the relationship can be distinguished from an altruistic offer of assistance.
Psychotherapists and counselors are often required to create a therapeutic environment referred to as the frame, which is characterized by a free yet secure climate that enables the client to open up. The degree to which the client feels related to the therapist may well depend on the methods and approaches used by the therapist or counselor.
Psychotherapy often includes techniques to increase awareness and the capacity for self-observation, change behavior and cognition, and develop insight and empathy. Desired results may be to enable other choices of thought, feeling or action, and to increase the sense of well-being and to better manage subjective discomfort or distress. Perception of reality is hopefully improved. Grieving might be enhanced, producing less long-term depression. Psychotherapy can improve medication response where such medication is also needed. Psychotherapy can be provided on a one-to-one basis, in group therapy, conjointly with couples and with entire families. It can occur face to face (individual), over the telephone, or, much less commonly, the Internet. Its time frame may be a matter of weeks or many years. Therapy may address specific forms of diagnosable mental illness, or everyday problems in managing or maintaining interpersonal relationships or meeting personal goals. Treatment in families with children can favorably influence a child's development, lasting for life and into future generations. Better parenting may be an indirect result of therapy or purposefully learned as parenting techniques. Divorces can be prevented or made far less traumatic. Treatment of everyday problems is more often referred to as counseling (a distinction originally adopted by Carl Rogers), but the term is sometimes used interchangeably with "psychotherapy". Therapeutic skills can be used in mental health consultation to business and public agencies to improve efficiency and assist with coworkers or clients.
Psychotherapists use a range of techniques to influence or persuade the client to adapt or change in the direction the client has chosen. These can be based on clear thinking about their options; experiential relationship building; dialogue, communication and adoption of behavior change strategies. Each is designed to improve the mental health of a client or patient, or to improve group relationships (as in a family). Most forms of psychotherapy use only spoken conversation, though some also use other forms of communication, such as the written word, artwork, drama, narrative story, or therapeutic touch. Psychotherapy occurs within a structured encounter between a trained therapist and client(s). Because sensitive topics are often discussed during psychotherapy, therapists are expected, and usually legally bound, to respect client or patient confidentiality.
Psychotherapists are often trained, certified, and licensed, with a range of different certifications and licensing requirements depending on the jurisdiction. Psychotherapy may be undertaken by clinical psychologists, counseling psychologists, rehabilitation counselors, social workers, marriage-family therapists, adult and child psychiatrists and expressive therapists, trained nurses, psychiatrists, psychoanalysts, mental health counselors, school counselors, or professionals of other mental health disciplines.
Psychiatrists have medical qualifications and may also administer prescription medication. The primary training of a psychiatrist uses the 'Bio-Psycho-Social' model, medical training in practical psychology and applied psychotherapy. Psychiatric training begins in medical school, first in the doctor-patient relationship with ill people, and later in psychiatric residency for specialists. The focus is usually eclectic but includes biological, cultural, and social aspects. They are advanced in understanding patients from the inception of medical training. Today there are two doctoral degrees in psychology, the PsyD and PhD. Training for these degrees overlaps, but the PsyD is more clinical and the Phd stresses research. Both degrees have clinical education components. Clinical social workers have specialized training in clinical casework. They hold a masters in social work, which entails two years of clinical internships, and a period of at least three years in the US of post-masters experience in psychotherapy. Marriage-family therapists have specific training and experience working with relationships and family issues. A licensed professional counselor (LPC) generally has special training in career, mental health, school, or rehabilitation counseling, to include evaluation and assessments as well as psychotherapy. Many of the wide variety of training programs are multiprofessional, that is, psychiatrists, psychologists, mental health nurses, and social workers may be found in the same training group. All these degrees commonly work together as a team, especially in institutional settings. All those doing specialized psychotherapeutic work, in most countries, require a program of continuing education after the basic degree, or involve multiple certifications attached to one specific degree, and 'board certification' in psychiatry. Specialty exams, or board exams with psychiatrists, are used to confirm competence.
Medical and non-medical models.
A distinction can also be made between those psychotherapies that employ a medical model and those that employ a humanistic model. In the medical model the client is seen as unwell and the therapist employs their skill to help the client back to health. The extensive use of the DSM-IV, the diagnostic and statistical manual of mental disorders in the United States, is an example of a medically exclusive model.
The humanistic model of non medical in contrast strives to depathologise the human condition. The therapist attempts to create a relational environment conducive to experiential learning and help build the client's confidence in their own natural process resulting in a deeper understanding of themselves. An example would be gestalt therapy.
Some psychodynamic practitioners distinguish between more uncovering and more supportive psychotherapy. Uncovering psychotherapy emphasizes facilitating the client's insight into the roots of their difficulties. The best-known example of an uncovering psychotherapy is classical psychoanalysis. Supportive psychotherapy by contrast stresses strengthening the client's defenses and often providing encouragement and advice. Depending on the client's personality, a more supportive or more uncovering approach may be optimal. Most psychotherapists use a combination of uncovering and supportive approaches.
Specific schools and approaches.
In practices of experienced psychotherapists, the therapy is typically not of one pure type, but draws aspects from a number of perspectives and schools.
Psychoanalysis.
Psychoanalysis was developed in the late 19th century by Sigmund Freud. His therapy explores the dynamic workings of a mind understood to consist of three parts: the hedonistic "id" (German: "das Es", "the it"), the rational "ego" ("das Ich", "the I"), and the moral "superego" ("das Überich", "the above-I"). Because the majority of these dynamics are said to occur outside people's awareness, Freudian psychoanalysis seeks to probe the unconscious by way of various techniques, including dream interpretation and free association. Freud maintained that the condition of the unconscious mind is profoundly influenced by childhood experiences. So, in addition to dealing with the defense mechanisms used by an overburdened ego, his therapy addresses fixations and other issues by probing deeply into clients' youth.
Other psychodynamic theories and techniques have been developed and used by psychotherapists, psychologists, psychiatrists, personal growth facilitators, occupational therapists and social workers. For example, object relations theory is a psychodynamic theory that has been widely applied to general psychotherapy and to psychiatry by such authors as N. Gregory Hamilton and Glen Gabbard. Techniques for group therapy have also been developed. While behaviour is often a target of the work, many approaches value working with feelings and thoughts. This is especially true of the psychodynamic schools of psychotherapy, which today include Jungian therapy and Psychodrama as well as the psychoanalytic schools and object relations theory.
Gestalt therapy.
Gestalt therapy is a major overhaul of psychoanalysis. In its early development, its founders, Frederick and Laura Perls, called it “concentration therapy”. By the time "Gestalt Therapy, Excitement and Growth in the Human Personality" by Perls, Hefferline, and Goodman was written in 1951, the approach became known as "Gestalt Therapy".
Gestalt therapy stands on top of essentially four load-bearing theoretical walls: phenomenological method, dialogical relationship, field-theoretical strategies, and experimental freedom. Some have considered it an existential phenomenology while others have described it as a phenomenological behaviorism. Gestalt therapy is a humanistic, holistic, and experiential approach that does not rely on talking alone; instead it facilitates awareness in the various contexts of life by moving from talking about relatively remote situations to action and direct current experience.
Positive psychotherapy.
Positive psychotherapy (PPT) (since 1968) is the name of the method of the psychotherapeutic modality developed by Nossrat Peseschkian and co-workers.
Positive psychotherapy is a method in the field of humanistic and psychodynamic psychotherapy and is based on a positive image of man, which correlates with a salutogenetic, resource-oriented, humanistic and conflict-centered approach. It is accredited by several institutions (e.g. State Medical Chamber of Hessen, Germany, European Association for Psychotherapy EAP; World Council for Psychotherapy WCP, International Federation of Psychotherapy IFP and other statutory institutions).
Group psychotherapy.
The term group therapy, was first used around 1920 by Jacob L. Moreno, whose main contribution was the development of psychodrama, in which groups were used as both cast and audience for the exploration of individual problems by reenactment under the direction of the leader. The more analytic and exploratory use of groups in both hospital and out-patient settings was pioneered by a few European psychoanalysts who emigrated to the USA, such as Paul Schilder, who treated severely neurotic and mildly psychotic out-patients in small groups at Bellevue Hospital, New York. The power of groups was most influentially demonstrated in Britain during the Second World War, when several psychoanalysts and psychiatrists proved the value of group methods for officer selection in the War Office Selection Boards. A chance to run an Army psychiatric unit on group lines was then given to several of these pioneers, notably Wilfred Bion and Rickman, followed by S. H. Foulkes, Main, and Bridger. The Northfield Hospital in Birmingham gave its name to what came to be called the two 'Northfield Experiments', which provided the impetus for the development since the war of both social therapy, that is, the therapeutic community movement, and the use of small groups for the treatment of neurotic and personality disorders. Today group therapy is used in clinical settings and in private practice settings.
Cognitive behavioral therapy.
"Cognitive behavioral therapy" (CBT) refers to a range of techniques which focus on the construction and re-construction of people's cognitions, emotions and behaviors. Generally in CBT, the therapist, through a wide array of modalities, helps clients assess, recognize and deal with problematic and dysfunctional ways of thinking, emoting and behaving.
Hypnotherapy.
Hypnotherapy is therapy that is undertaken with a subject in hypnosis. Hypnotherapy is often applied in order to modify a subject's behavior, emotional content, and attitudes, as well as a wide range of conditions including dysfunctional habits, anxiety, stress-related illness, pain management, and personal development.
Behavior therapy.
Behavior therapy focuses on modifying overt behavior and helping clients to achieve goals. This approach is built on the principles of learning theory including operant and respondent conditioning, which makes up the area of applied behavior analysis or behavior modification. This approach includes acceptance and commitment therapy, functional analytic psychotherapy, and dialectical behavior therapy. Sometimes it is integrated with cognitive therapy to make cognitive behavior therapy. By nature, behavioral therapies are empirical (data-driven), contextual (focused on the environment and context), functional (interested in the effect or consequence a behavior ultimately has), probabilistic (viewing behavior as statistically predictable), monistic (rejecting mind-body dualism and treating the person as a unit), and relational (analyzing bidirectional interactions).
Body-oriented psychotherapy.
Body-oriented psychotherapy or body psychotherapy is also known as Somatic Psychology, especially in the USA. There are many very different body-oriented or somatic psychotherapeutic approaches. They generally focus on the link between the mind and the body and try to access deeper levels of the psyche through greater awareness of the physical body and the emotions which gave rise to the various "body-oriented" based psychotherapeutic approaches, such as Reichian (Wilhelm Reich) Character-Analytic Vegetotherapy and Orgonomy; neo-Reichian Alexander Lowen's Bioenergetic analysis; Peter Levine's Somatic Experiencing; Jack Rosenberg's Integrative body psychotherapy; Ron Kurtz's Hakomi psychotherapy; Pat Ogden's sensorimotor psychotherapy; David Boadella's Biosynthesis psychotherapy; Gerda Boyesen's Biodynamic psychotherapy; etc.
These body-oriented psychotherapies are not to be confused with alternative medicine body-work or body-therapies that seek primarily to improve physical health through direct work (touch and manipulation) on the body because, despite the fact that bodywork techniques (for example Alexander Technique, Rolfing, and the Feldenkrais Method) can also affect the emotions, these techniques are not designed to work on psychological issues, neither are their practitioners so trained.
Expressive therapy.
Expressive therapy is a form of therapy that utilizes artistic expression as its core means of treating clients. Expressive therapists use the different disciplines of the creative arts as therapeutic interventions. This includes the modalities dance therapy, drama therapy, art therapy, music therapy, writing therapy, among others. Expressive therapists believe that often the most effective way of treating a client is through the expression of imagination in a creative work and integrating and processing what issues are raised in the act.
Interpersonal psychotherapy.
Interpersonal psychotherapy (IPT) is a time-limited psychotherapy that focuses on the interpersonal context and on building interpersonal skills. IPT is based on the belief that interpersonal factors may contribute heavily to psychological problems. It is commonly distinguished from other forms of therapy in its emphasis on interpersonal processes rather than intrapsychic processes. IPT aims to change a person's interpersonal behavior by fostering adaptation to current interpersonal roles and situations.
Narrative therapy.
Narrative therapy gives attention to each person's "dominant story" by means of therapeutic conversations, which also may involve exploring unhelpful ideas and how they came to prominence. Possible social and cultural influences may be explored if the client deems it helpful.
Integrative psychotherapy.
Integrative psychotherapy is an attempt to combine ideas and strategies from more than one theoretical approach. These approaches include mixing core beliefs and combining proven techniques. Forms of integrative psychotherapy include multimodal therapy, the transtheoretical model, cyclical psychodynamics, systematic treatment selection, cognitive analytic therapy, Internal Family Systems Model, multitheoretical psychotherapy and conceptual interaction. In practice, most experienced psychotherapists develop their own integrative approach over time.
Human givens therapy.
The human givens approach was developed by an Irish and British psychotherapist, Joe Griffin and Ivan Tyrrell. It was first introduced in 1998/9 in the monograph "Psychotherapy, Counselling and the Human Givens (Organising Idea)" and amplified in the 2003 book "Human Givens: A new approach to emotional health and clear thinking". Rather than focusing on symptomatology, the human givens approach works within the framework of emotional needs, such as those for security, autonomy and social connection, which decades of health and social psychology research have shown to be essential for physical and mental health. It is a brief, solution-focused approach which aims to help people identify needs not met, or inadequately or inappropriately met, and to address these using psychoeducation and therapeutic techniques such as cognitive restructuring, cognitive reframing and imaginal exposure – all methods endorsed by the standard-setting National Institute for Health and Clinical Excelllence (NICE).
Adaptations for children.
Counseling and psychotherapy must be adapted to meet the developmental needs of children. It is generally held to be one part of an effective strategy for some purposes and not for others. These are four purposes that are generally considered inappropriate or pointless reasons for placing a child in psychotherapy:
In addition to therapy for the child, or even instead of it, children may benefit if their parents speak to a therapist, take parenting classes, attend grief counseling, or take other actions to resolve stressful situations that affect the child. Parent management training is a highly effective form of psychotherapy that teaches parents skills to reduce their child's behavior problems.
Many counseling preparation programs include courses in human development. Since children often do not have the ability to articulate thoughts and feelings, counselors will use a variety of media such as crayons, paint, clay, puppets, bibliocounseling (books), toys, board games, et cetera. The use of play therapy is often rooted in psychodynamic theory, but other approaches such as Solution Focused Brief Counseling may also employ the use of play in counseling. In many cases the counselor may prefer to work with the care taker of the child, especially if the child is younger than age four. Yet, by doing so, the counselor risks the perpetuation of maladaptive interactive patterns and the adverse effects on development that have already been affected on the child's end of the relationship. Therefore, contemporary thinking on working with this young age group has leaned towards working with parent and child simultaneously within the interaction, as well as individually as needed.
Confidentiality.
Confidentiality is an integral part of the therapeutic relationship and psychotherapy in general.
It includes protecting specific groups of people, like children, while treating private information in a manner that is in line with a professional ethics code.
Criticisms and questions regarding effectiveness.
Within the psychotherapeutic community there has been some discussion of empirically based psychotherapy.
Virtually no comparisons of different psychotherapies with long follow-up times have been done. The Helsinki Psychotherapy Study is a randomized clinical trial, in which patients were monitored for 10 years after the onset of short-term (6 months) psychodynamic or solution-focused, or long-term (3 years) psychodynamic study treatments. The effectiveness, suitability and sufficiency of the therapies were compared also with that of psychoanalysis (5 years), within a quasi-experimental design. The assessments were completed at the baseline and 14 times thereafter during the follow-up. The results of the 3- and 5-year follow-up indicate that the length of therapy is important when predicting the outcome of therapy. Patients in the two short-term therapies improved faster, but in the long run long-term psychotherapy and psychoanalysis gave greater benefits. Several patient and therapist factors appear to predict suitability for different psychotherapies. Follow-up evaluations of this study will continue up to 2014.
There is considerable controversy about which form of psychotherapy is most effective, and more specifically, which types of therapy are optimal for treating which sorts of problems. Furthermore, it is controversial whether the form of therapy or the presence of factors common to many psychotherapies best separates effective therapy from ineffective therapy. Common factors theory asserts it is precisely the factors common to the most psychotherapies that make any psychotherapy successful: this is the quality of the therapeutic relationship, interpretation of problem, and the confrontation of painful emotions.
The therapeutic relationship: its theological assumption
In effective psychotherapy, the therapeutic relationship is marked by acceptance. The therapist accepts the client, with her/his “neurotic guilt feelings and compulsions.” However, the therapist’s acceptance communicates more than human acceptance because psychotherapy implicitly holds a theological assumption.
Successful therapy can provide the “concrete experience of acceptance,” but theology is needed to understand the implicit “ontological foundation” that makes it work. Both therapist and client need an ontological acceptance, that is, “the acceptance of God.” Belief that one is “ontologically acceptable” is to believe that one’s acceptability is “the way things "be" without contingency.”
Therefore, psychotherapy’s implicit theological “assumption is that every person, as a human being, is accepted by being itself.” Effective therapy implicitly conveys this assumption to the client: you are “acceptable as a human being by the ground of being itself, and that the final reality that we confront in life is for us—Deus pro nobis [God is for us].” (The terms “ground of being” and “final reality” are used as names for God.)
Ontological acceptance is not based on a person’s virtue. It is an acceptance given “"in spite of our guilt", not because we "have no guilt".”
Outcome research
The dropout level is quite high; one meta-analysis of 125 studies concluded that the mean dropout rate was 46.86%. The high level of dropout has raised some criticism about the relevance and efficacy of psychotherapy. There are different drop-out rates depending on how drop-out is defined. Another large meta-analysis reports drop-out rates not larger than 20 to 25%.
Psychotherapy outcome research—in which the effectiveness of psychotherapy is measured by questionnaires given to patients before, during, and after treatment—has had difficulty distinguishing between the success or failure of the different approaches to therapy. Those who stay with their therapist for longer periods are more likely to report positively on what develops into a longer-term relationship. This suggests that some "treatment" may be open-ended with concerns associated with ongoing financial costs.
As early as 1952, in one of the earliest studies of psychotherapy treatment, Hans Eysenck reported that two thirds of therapy patients improved significantly or recovered on their own within two years, whether or not they received psychotherapy.
In 1994 the late Frank Pittman published "A Buyer's Guide To Psychotherapy," calling psychotherapy a decision about "whose wisdom to buy" while questioning the value of a profession he had practiced for more than three decades:
 “For 33 years as a psychotherapist, I've sold myself by the hour ... I used to be proud of what I did. That has changed. Perhaps it was the unsettling experience of trying to explain to friends from abroad—for whom American psychotherapy is a foreign culture—how perennial psychotherapy customer Woody Allen could have undergone therapy for most of his life and still not have seen anything incestuous in his sexual relationship with his de facto stepdaughter, the sister of his children. When asked about his analyst's reaction, Allen is rumored to have said, ‘It didn't come up. It wasn't a relevant issue for my therapy.’”
 — Frank Pittman
Many psychotherapists believe that the nuances of psychotherapy cannot be captured by questionnaire-style observation, and prefer to rely on their own clinical experiences and conceptual arguments to support the type of treatment they practice.
In 2001, Bruce Wampold of the University of Wisconsin published the book "The Great Psychotherapy Debate". In it Wampold, who has a degree in mathematics and who went on to train as a counseling psychologist, reported that:
Wampold therefore concludes that "we do not know why psychotherapy works".
Although the "Great Psychotherapy Debate" dealt primarily with data on depressed patients, subsequent articles have made similar findings for post-traumatic stress disorder and youth disorders. There have also been studies of Panic Disorder, where treatment effectiveness is measured in the abatement of panic attacks. Psychoanalytic psychotherapy has been found to be as effective as Cognitive Behavioral Therapy for immediate relief and more effective over the long term.
Some report that by attempting to program or manualize treatment, psychotherapists may be reducing efficacy, although the unstructured approach of many psychotherapists cannot appeal to those patients motivated to solve their difficulties through the application of specific techniques different from their past "mistakes."
Critics of psychotherapy are skeptical of the healing power of a psychotherapeutic relationship. Because any intervention takes time, critics note that the passage of time alone, without therapeutic intervention, often results in psycho-social healing. Social contact with others is universally seen as beneficial for all humans and regularly scheduled visits with anyone would be likely to diminish both mild and severe emotional difficulty.
Yet a large part of effectiveness studies include waiting-list control groups. This type of study design proves psychotherapy to be significantly more effective than passage of time alone.
Many resources available to a person experiencing emotional distress—the friendly support of friends, peers, family members, clergy contacts, personal reading, healthy exercise, research, and independent coping—all present considerable value. Critics note that humans have been dealing with crises, navigating severe social problems and finding solutions to life problems long before the advent of psychotherapy. Of course, it may well be something in the patient that does not develop these "natural" supports that requires therapy.
Further critiques have emerged from feminist, constructionist and discursive sources. Key to these is the issue of power. In this regard there is a concern that clients are persuaded—both inside and outside the consulting room—to understand themselves and their difficulties in ways that are consistent with therapeutic ideas. This means that alternative ideas (e.g., feminist, economic, spiritual) are sometimes implicitly undermined. Critics suggest that we idealize the situation when we think of therapy only as a helping relation, that it is fundamentally a political practice, in that some cultural ideas and practices are supported while others are undermined or disqualified, and while it is seldom intended, the therapist-client relationship always participates in society's power relations and political dynamics.

</doc>
<doc id="24932" url="http://en.wikipedia.org/wiki?curid=24932" title="Posen">
Posen

Posen may refer to: 
Places in Europe:
Places in the United States:
Other:

</doc>
<doc id="24933" url="http://en.wikipedia.org/wiki?curid=24933" title="Polywater">
Polywater

Polywater was a hypothesized polymerized form of water that was the subject of much scientific controversy during the late 1960s. By 1969 the popular press had taken notice and sparked fears of a "polywater gap" in the USA.
Increased press attention also brought with it increased scientific attention, and as early as 1970 doubts about its authenticity were being circulated. By 1973 it was found to be illusory, being just water with any number of common organic compounds contaminating it.
Today, polywater is best known as an example of pathological science.
Background.
The Soviet physicist Nikolai Fedyakin, working at a small government research lab in Kostroma, Russia, had performed measurements on the properties of water that had been condensed in, or repeatedly forced through, narrow quartz capillary tubes. Some of these experiments resulted in what was seemingly a new form of water with a higher boiling point, lower freezing point, and much higher viscosity than ordinary water, about that of a syrup.
Boris Derjaguin, director of the laboratory for surface physics at the Institute for Physical Chemistry in Moscow, heard about Fedyakin's experiments. He improved on the method to produce the new water, and though he still produced very small quantities of this mysterious material, he did so substantially faster than Fedyakin did. Investigations of the material properties showed a substantially lower freezing point of −40 °C or less, a boiling point of 150 °C or greater, a density of approx. 1.1 to 1.2 g/cm³, and increased expansion with increasing temperature. The results were published in Soviet science journals, and short summaries were published in "Chemical Abstracts" in English, but Western scientists took no notice of the work.
In 1966, Derjaguin travelled to England for the "Discussions of the Faraday Society" in Nottingham. There he presented the work again, and this time English scientists took note of what he referred to as anomalous water. English scientists then started researching the effect as well, and by 1968 it was also under study in the United States.
By 1969 the concept had spread to newspapers and magazines. There was fear by the United States military that there was a polywater gap with the Soviet Union.
A scientific furor followed. Some experimentalists were able to reproduce Derjaguin's findings, while others failed. Several theories were advanced to explain the phenomenon. Some proposed that it was the cause for increasing resistance on trans-Atlantic phone cables, while others predicted that if polywater were to contact ordinary water, it would convert that water into polywater, echoing the doomsday scenario in Kurt Vonnegut's novel "Cat's Cradle". By the 1970s, polywater was well known in the general population.
During this time several people questioned the authenticity of what had come to be known in the West as polywater. The main concern was contamination of the water, but the papers went to great lengths to note the care taken to avoid this. Denis Rousseau and Sergio Porto of Bell Labs carried out infrared spectrum analysis which showed polywater was made mostly of chlorine and sodium.
Denis Rousseau undertook to experiment with his own sweat after playing a handball game at the lab, and found it had identical properties. He then published a paper suggesting that polywater was nothing more than water with small amounts of biological impurities.
Another wave of research followed, this time more tightly controlled. Invariably the polywater could no longer be made. Chemical analysis found that samples of polywater were contaminated with other substances (explaining the changes in melting and boiling points due to colligative properties), and examination of polywater via electron microscopy showed that it also contained small particles of various solids from silica to phospholipids, explaining its greater viscosity.
When the experiments that had produced polywater were repeated with thoroughly cleaned glassware, the anomalous properties of the resulting water vanished, and even the scientists who had originally advanced the case for polywater agreed that it did not exist. This took a few years longer in the Soviet Union, where scientists still clung to the idea.
In August, 1973, Derjaguin and N. V. Churaev published a letter in the journal Nature in which they write that, "these [anomalous] properties should be attributed to impurities rather than to the existence of polymeric water molecules."
Denis Rousseau used polywater as a classic example of pathological science, and has since written on other examples as well.
It has been suggested that polywater should have been dismissed on theoretical grounds. The laws of thermodynamics predicted that, since polywater had a higher boiling point than ordinary water, it meant that it was more stable, and the whole column of ordinary water should have turned spontaneously into polywater, instead of just part of it. Richard Feynman remarked that, if such a material existed, then there would exist an animal that would not need food. That animal would just ingest water and excrete polywater, using the energy released on the process to survive.
In fiction.
The story "Polywater Doodle" by Howard L. Myers (writing under the pseudonym "Dr. Dolittle") appeared in the February 1971 issue of "Analog Science Fiction and Fact". It features an animal composed entirely of polywater, with the metabolism described by Richard Feynman. (The title of the story is a pun.)
Polywater is the central idea of the 1972 espionage/thriller novel "A Report from Group 17" by Robert C. O'Brien. The story revolves around the use of a type of polywater to make people controllable and incapable of independent thought or action.
The episodes "The Naked Time" (') and its sequel, "The Naked Now" (') involve forms of polywater intoxication. In the original episode, a scientific research outpost falls victim to polywater, which causes the crew to become so incapacitated that they all die when environmental controls in the compound are shut off. In the sequel, a Starfleet vessel is discovered adrift, its crew frozen in various states due to polywater intoxication.
Further reading.
</dl>

</doc>
<doc id="24935" url="http://en.wikipedia.org/wiki?curid=24935" title="Pathological science">
Pathological science

Pathological science is an area of research where "people are tricked into false results ... by subjective effects, wishful thinking or threshold interactions". The term was first used by Irving Langmuir, Nobel Prize-winning chemist, during a 1953 colloquium at the Knolls Research Laboratory. Langmuir said a pathological science is an area of research that simply will not "go away"—long after it was given up on as "false" by the majority of scientists in the field. He called pathological science "the science of things that aren't so".
Bart Simon lists it among practices pretending to be science: "categories ... such as ... pseudoscience, amateur science, deviant or fraudulent science, bad science, junk science, and popular science ... pathological science, cargo-cult science, and voodoo science". Examples of pathological science may include, Martian canals, N-rays, polywater, and cold fusion. The theories and conclusions behind all of these examples are currently rejected or disregarded by the majority of scientists.
Definition.
Pathological science, as defined by Langmuir, is a psychological process in which a scientist, originally conforming to the scientific method, unconsciously veers from that method, and begins a pathological process of wishful data interpretation (see the Observer-expectancy effect, and cognitive bias). Some characteristics of pathological science are:
Langmuir never intended the term to be rigorously defined; it was simply the title of his talk on some examples of "weird science". As with any attempt to define the scientific endeavor, examples and counterexamples can always be found.
Langmuir's examples.
N-rays.
Langmuir discussed the issue of N-rays as an example of pathological science. It is still considered a traditional case of pathological science.
In 1903, René-Prosper Blondlot was working on X-rays (as were many physicists of the era) and noticed a new visible radiation that could penetrate aluminium. He devised experiments in which a barely visible object was illuminated by these N-rays, and thus became "more visible". Blondlot claimed that N-rays were causing a small visual reaction, too small to be seen under normal illumination, but just visible when most "normal" light sources were removed and the target was just barely visible to begin with.
N-rays became the topic of some debate within the science community. After a time, physicist Robert W. Wood decided to visit Blondlot's lab, which had moved on to the physical characterization of N-rays. An experiment passed the rays from a 2 mm slit through an aluminum prism, from which he was measuring the index of refraction to a precision that required measurements accurate to within 0.01 mm. Wood asked how it was possible that he could measure something to 0.01 mm from a 2 mm source, a physical impossibility in the propagation of any kind of wave. Blondlot replied, "That's one of the fascinating things about the N-rays. They don't follow the ordinary laws of science that you ordinarily think of." Wood then asked to see the experiments being run as usual, which took place in a room required to be very dark so the target was barely visible. Blondlot repeated his most recent experiments and got the same results—despite the fact that Wood had reached over and covertly sabotaged the N-ray apparatus by removing the prism.
Other examples.
Langmuir offered additional examples of what he regarded as pathological science in his original speech:
Later examples.
A 1985 version of Langmuir's speech offered more examples, although at least one of these (polywater) occurred entirely after Langmuir's death in 1957:
Newer examples.
Since Langmuir's original talk, a number of newer examples of what appear to be pathological science have appeared. Denis Rousseau, one of the main debunkers of polywater, gave an update of Langmuir in 1992, and he specifically cited as examples the cases of polywater, Fleischmann's cold fusion and Jacques Benveniste's "infinite dilution".
Polywater.
Polywater was a form of water which appeared to have a much higher boiling point and much lower freezing point than normal water. Many articles were published on the subject, and research on polywater was done around the world with mixed results. Eventually it was determined that many of the properties of polywater could be explained by biological contamination. When more rigorous cleaning of glassware and experimental controls were introduced, polywater could no longer be produced. It took several years for the concept of polywater to die in spite of the later negative results.
Cold fusion.
In 1989, Fleischmann and Pons announced the discovery of a simple and cheap procedure to obtain room-temperature nuclear fusion. Although there were many instances where successful results were reported they lacked consistency and hence cold fusion came to be considered to be an example of pathological science. Two panels convened by the US Department of Energy, one in 1989 and a second in 2004, did not recommend a dedicated federal program for cold fusion research. A small number of researchers continue working on the field.
Water memory.
Jacques Benveniste was a French immunologist who in 1988 published a paper in the prestigious scientific journal "Nature" describing the action of very high dilutions of anti-IgE antibody on the degranulation of human basophils, findings which seemed to support the concept of homeopathy. Biologists were puzzled by Benveniste's results, as only molecules of water, and no molecules of the original antibody, remained in these high dilutions. Benveniste concluded that the configuration of molecules in water was biologically active. Subsequent investigations have not supported Benveniste's findings, which are now cited as an example of pathological science.

</doc>
<doc id="24936" url="http://en.wikipedia.org/wiki?curid=24936" title="Pneumatic tube">
Pneumatic tube

Pneumatic tubes (or capsule pipelines; also known as Pneumatic Tube Transport or PTT) are systems that propel cylindrical containers through a network of tubes by compressed air or by partial vacuum. They are used for transporting solid objects, as opposed to conventional pipelines, which transport fluids. Pneumatic tube networks gained acceptance in the late 19th and early 20th centuries for offices that needed to transport small, urgent packages (such as mail, paperwork, or money) over relatively short distances (within a building, or, at most within a city). Some installations grew to great complexity, but were mostly superseded. In some settings, such as hospitals, they remain widespread and have been further extended and developed in recent decades.
A small number of pneumatic transportation systems were also built for larger cargo, to compete with more standard train and subway systems. However, these never gained popularity.
History.
Historical use.
Pneumatic capsule transportation was invented by William Murdoch. It was considered little more than a novelty until the invention of the capsule in 1836. The Victorians were the first to use "capsule pipelines" to transmit telegrams, to nearby buildings from telegraph stations.
While they are commonly used for small parcels and documents – including as cash carriers at banks or supermarkets – they were originally proposed in the early 19th century for transport of heavy freight. It was once envisaged that networks of these massive tubes might be used to transport people.
Current use.
The technology is still used on a smaller scale. While its use for communicating information has been superseded, pneumatic tubes are widely used for transporting small objects, or where convenience and speed in a local environment is useful.
In the United States, drive-up banks often use pneumatic tubes to transport cash and documents between cars and tellers. Most hospitals have a computer-controlled pneumatic tube system to deliver drugs, documents and specimens to and from laboratories and nurses' stations. Many factories use them to deliver parts quickly across large campuses. Many larger stores use systems to securely transport excess cash from checkout stands to back offices, and to send change back to cashiers. NASA's original Mission Control Center had pneumatic tubes connecting controller consoles with staff support rooms. Denver International Airport uses many pneumatic tube systems, including a 25 cm diameter system for moving aircraft parts to remote concourses, a 10 cm system for United Airlines ticketing, and a robust system in the parking toll collection system with an outlet at every booth.
Pneumatic tube systems are used in science, to transport samples during neutron activation analysis. Samples must be moved from the nuclear reactor core, in which they are bombarded with neutrons, to the instrument that records the resulting radiation. As some of the radioactive isotopes in the sample can have very short half-lives, speed is important. These systems may be automated, with a magazine of sample tubes that are moved into the reactor core in turn for a predetermined time, before being moved to the instrument station and finally to a container for storage and disposal.
Until it closed in early 2011, a McDonald's in Edina, Minnesota claimed to be the "World's Only Pneumatic Air Drive-Thru," sending food from their strip-mall location to a drive-through in the middle of a parking lot.
In Britain, the House of Commons telephone and computer exchange employs a pneumatic tube system.
Technology editor Quentin Hardy notes that renewed interest in transmission of data by pneumatic tube accompanies discussions of digital network security, and he cites research into London's forgotten pneumatic network.
Applications.
In postal service.
Pneumatic post or pneumatic mail is a system to deliver letters through pressurized air tubes. It was invented by the Scottish engineer William Murdoch in the 19th century and was later developed by the London Pneumatic Despatch Company. Pneumatic post systems were used in several large cities starting in the second half of the 19th century (including an 1866 London system powerful and large enough to transport humans during trial runs – though not intended for that purpose), but later were largely abandoned.
A major network of tubes in Paris was in use until 1984, when it was abandoned in favor of computers and fax machines. In Prague, in the Czech Republic, a network of tubes extending approximately 60 km in length is used for delivering mail and parcels.
Pneumatic post stations usually connect post offices, stock exchanges, banks and ministries. Italy was the only country to issue postage stamps (between 1913 and 1966) specifically for pneumatic post. Austria, France, and Germany issued postal stationery for pneumatic use.
Typical current applications are in banks, hospitals and supermarkets. Many large retailers use pneumatic tubes to transport cheques or other documents from cashiers to the accounting office.
In public transportation.
In 1812, George Medhurst first proposed, but never implemented, blowing passenger carriages through a tunnel. Precursors of pneumatic tube systems for passenger transport, the atmospheric railway (for which the tube was laid between the rails, with a piston running in it suspended from the train through a sealable slot in the top of the tube) were operated as follows:
In 1861, the London Pneumatic Despatch Company built a system large enough to move a person, although it was intended for parcels. The inauguration of the new Holborn Station on 10 October 1865 was marked by having the Duke of Buckingham, the chairman, and some company directors blown through the tube to Euston (a five-minute trip).
The 550-meter Crystal Palace pneumatic railway was exhibited at the Crystal Palace in 1864. This was a prototype for a proposed "Waterloo and Whitehall Railway" that would have run under the River Thames linking Waterloo and Charing Cross. Digging commenced in 1865 but was halted in 1868 due to financial problems.
In 1867 at the American Institute Fair in New York, Alfred Ely Beach demonstrated a 32.6 m long, 1.8 m diameter pipe that was capable of moving 12 passengers plus a conductor. In 1869, the Beach Pneumatic Transit Company of New York secretly constructed a 95 m long, 2.7 m diameter pneumatic subway line under Broadway, to demonstrate the possibilities of the new transport mode. The line only operated for a few months, closing after Beach was unsuccessful in getting permission to extend it – Boss Tweed, an immensely powerful local politician, did not want it to go ahead as he was intending to personally invest into competing schemes for an elevated rail line.
In the 1960s, Lockheed and MIT with the United States Department of Commerce conducted feasibility studies on a vactrain system powered by ambient atmospheric pressure and "gravitational pendulum assist" to connect cities on the country's East Coast. They calculated that the run between Philadelphia and New York City would average 174 meters per second, that is 626 km/h (388 mph). When those plans were abandoned as too expensive, Lockheed engineer L.K. Edwards founded Tube Transit, Inc. to develop technology based on "gravity-vacuum transportation". In 1967 he proposed a Bay Area Gravity-Vacuum Transit for California that would run alongside the then-under construction BART system. It was never built.
Research into trains running in partially evacuated tubes is continuing. For further information see Vactrain and Hyperloop.
In money transfer.
In large retail stores, pneumatic tube systems were used to transport sales slips and money from the salesperson to a centralized "tube room", where cashiers could make change, reference credit records, and so on.
Many banks with drive-throughs also use pneumatic tubes.
In medicine.
Many hospitals have pneumatic tube systems which send samples to laboratories.
Technical characteristics.
Modern systems (for smaller, i.e. "normal" tube diameters as used in the transport of small capsules) reach speeds of around 7.5 m per second, though some historical systems already achieved speeds of 10 m per second. Further, modern systems can also be computer-controlled, allowing, among other things, the tracking of any specific capsule. Varying air pressures also allow capsules to brake slowly, removing the jarring arrival that used to characterise earlier systems and make them unsuitable for fragile contents.
In fiction.
When pneumatic tubes first came into use in the 19th century, they symbolized technological progress and it was imagined that they would be common in the future. Jules Verne's "Paris in the Twentieth Century" (1863) includes suspended pneumatic tube trains that stretch across the oceans. Albert Robida's "The Twentieth Century" (1882) describes a 1950s Paris where tube trains have replaced railways, pneumatic mail is ubiquitous, and catering companies compete to deliver meals on tap to people's homes through pneumatic tubes. Edward Bellamy's "Looking Backward" (1888) envisions the world of 2000 as interlinked with tubes for delivering goods, while Michel Verne's "An Express of the Future" (1888) questions the sensibility of a transatlantic pneumatic subway. In Michel & Jules Verne's "The Day of an American Journalist in 2889" (1889) submarine tubes carry people faster than "aero-trains" and the "Society for Supplying Food to the Home" allows subscribers to receive meals pneumatically.
Later, because of their use by governments and large businesses, tubes began to symbolize bureaucracy. In George Orwell's "Nineteen Eighty-Four", pneumatic tubes in the Ministry of Truth deliver newspapers to Winston's desk containing articles to be "rectified". Robert A. Heinlein's 1949 novella Gulf offered a more neutral view of their use in general postal delivery.
Beginning with the 42nd issue of 181-issue "Doc Savage" Magazine ("The Midas Man", Volume VII, No. 6, Aug 1936), Doc Savage's penthouse on the 86th floor of an unnamed New York City skyscraper (implicitly the Empire State Building) is linked to his "Hidalgo Trading Company" warehouse-boathouse-hangar on the Hudson River waterfront by pneumatic bullet-car nicknamed the "Flea Run", "Go-Devil" and "Angel-Wagon" due to its hundred mile per hour speed and that plummets straight down from the penthouse ninety stories to a sub-basement, makes a 90° turn to travel a mile and a quarter (a little over two kilometers) 60 feet (18 meters) below 34th Street and then comes back up to ground floor of the warehouse, presumably at a shallower but still steep incline. The interior of the car is heavily padded, with four seats, one behind the other bobsled fashion. Since the car does not turn around, the seats are designed to rotate 180° so that the passengers always face in the direction of travel. The acceleration is such that, when traveling down the tube from the 86th Floor, no sensation of falling is experienced. The system is driven by enormous air compressors and compressed air receiver vessels housed on the roofs of both the skyscraper and the Hidalgo Trading Company.
In a sequence in the 1968 film "Baisers volés" ("Stolen Kisses"), François Truffaut shows the fast transportation of a letter through the underground pneumatic tubes system in Paris. (This scene was later parodied in "The Simpsons" episode "Marge Gets a Job".)
In 1985, the movie "Brazil" also used tubes (as well as other anachronistic-seeming technologies) to evoke the stagnation of bureaucracy.
At the start of each episode of the 1998 television series "Fantasy Island", a darker version of the original, bookings for would-be visitors to the Island were sent to Mr. Roarke via a pneumatic tube from a dusty old travel agency.
The 1994 film version of "The Shadow" includes a sequence in which the camera follows a message capsule as it speeds through a pneumatic tube system. The implication is that the Shadow maintains a private network of tubes for the transportation of secret messages.
The failure of pneumatic tubes to live up to their potential as envisaged in previous centuries has placed them in the company of flying cars and dirigibles as ripe for ironic retro-futurism. The 1960s cartoon series "The Jetsons" featured pneumatic tubes that people could step into and be sucked up and swiftly spat out at their destination. In the animated television series "Futurama", set in the 31st century, large pneumatic tubes are used in cities for transporting people, whilst smaller ones are used to transport mail. The tubes in "Futurama" are also used to depict the endless confusion of bureaucracy: an immense network of pneumatic tubes connects all offices in New New York City to the "Central Bureaucracy", with all the capsules being deposited directly into a huge pile in the main filing room, with no sorting or organization.
In Ghostbusters II, the "river of slime" under New York city is found by the Ghostbusters boys to be flowing through an old pneumatic tube line – a reference to the Beach Pneumatic Transit tube.
In the 1998 PC game Grim Fandango, pneumatic tubes play a role at Manny's office.
In the American television show "Lost", the Dharma Initiative's Pearl research station has a pneumatic tube system. The character Locke put his drawing of the blast door map in the tube without a capsule. It was sucked up into the tube, indicating the system still functioned. The tube from the Pearl leads to a capsule dump.
In Kurt Vonnegut's "Slaughterhouse-Five" pneumatic tubes are used as a way to transport information from one place to the next when covering news articles.
In the popular video game "Bioshock", pneumatic tubes transport various items throughout the fictional city of Rapture. In Portal and Portal 2, two other popular games, Aperture Science uses Pneumatic tubes to transport larger-scale objects such as boxes of all kinds throughout their "enrichment center".
Douglas Adams's 1998 computer game "Starship Titanic" features the "Succ-U-Bus" in almost every room –a pneumatic pipe transport system which goes all around the ship; players must understand and use the Succ-U-Bus in order to progress and solve the puzzles.
Umberto Eco in his novel "The Prague Cemetery" has one character, Simonini, send a "petit blue message by pneumatic post". Presumably these messages were on small pieces of blue paper.
In the 2004 Movie The Polar Express 'The Pnuematic' transports elves and lead characters from the main control room to various places throughout the North Pole
In the CBS series, Person of Interest, a pneumatic tube network is used to avoid tracking of communication by electronic means. The network is shown in the mafia war in the 21st episode of the fourth season, 'Asylum'.
External links.
London Midland Magazine – February 1963 – article on the Pneumatic Dispatch Railway in London

</doc>
<doc id="24937" url="http://en.wikipedia.org/wiki?curid=24937" title="Pinzgauer">
Pinzgauer

Pinzgauer may refer to:

</doc>
<doc id="24942" url="http://en.wikipedia.org/wiki?curid=24942" title="Patrilineality">
Patrilineality

"Patrilineality", also known as "the male line" or "agnatic kinship", is a common kinship system in which an individual's family membership derives from and is traced through his or her father's lineage. It generally involves the inheritance of property, names, or titles by persons related through one's male kin.
A patriline ("father line") is a person's father, and additional ancestors, as traced only through males. Adjective forms are patrilineal, "agnatic" and "male-line". One's patriline is thus a record of descent from a man in which the individuals in all intervening generations are male. In cultural anthropology, a patrilineage is a consanguineal male and female kinship group, each of whose members is descended from the common ancestor through male forebears. 
In most cultures, this means that a person's family name and a man's genetic Y-DNA have been passed along this line from father to son. In a patrilineal/agnatic descent system, an individual is considered to belong to the same descent group as his or her father, from which the members' family name is commonly derived.
An "agnate" is a person's genetic relative, male or female, with whom kinship is reckoned exclusively through shared male ancestors. (whereas a person to whom one is related through females, or through both males and females, is a "cognate").
Agnatic succession.
Patrilineal or agnatic succession gives priority to or restricts inheritance of a throne or fief to heirs, male or female, descended from the original title holder through males only. Traditionally, agnatic succession is applied in determining the names and membership of European dynasties. The prevalent forms of dynastic succession in Europe Asia and parts of Africa (but see the Rain Queen) were male-preference primogeniture, agnatic primogeniture or agnatic seniority until after World War II.
By the 21st century most European monarchies replaced their traditional agnatic succession with absolute primogeniture, meaning that the first child born to a monarch inherits the throne, regardless of the child's sex. 
Salic Law.
Variations of the Salic Law, generally understood in modern times to mean exclusion of women as hereditary monarchs, restricted succession to thrones and inheritance of fiefs or land to men in parts of medieval and later Europe. Once common, strict Salic inheritance has been officially revoked in all extant European monarchies except the Principality of Liechtenstein. However it still prevails in the transmission of most European titles of nobility, notably excepting Spain.
Genetic genealogy.
The fact that human Y-chromosome DNA (Y-DNA) is paternally inherited enables patrilines, and agnatic kinships, of men to be traced through genetic analysis.
Y-chromosomal Adam (Y-MRCA) is the patrilineal most recent common ancestor from whom all Y-DNA in living men is descended. An identification of a very rare and previously unknown Y-chromosome variant in 2012 led researchers to estimate that Y-chromosomal Adam lived 338,000 years ago (237,000 to 581,000 years ago with 95% confidence), judging from molecular clock and genetic marker studies. Before this discovery, estimates of the date when Y-chromosomal Adam lived were much more recent, estimated to be tens of thousands of years.

</doc>
<doc id="24944" url="http://en.wikipedia.org/wiki?curid=24944" title="Plate tectonics">
Plate tectonics

Plate tectonics (from the Late Latin "tectonicus", from the Greek: τεκτονικός "pertaining to building") is a scientific theory that describes the large-scale motion of Earth's lithosphere. This theoretical model builds on the concept of continental drift which was developed during the first few decades of the 20th century. The geoscientific community accepted the theory after the concepts of seafloor spreading were later developed in the late 1950s and early 1960s.
The lithosphere, which is the rigid outermost shell of a planet (on Earth, the crust and upper mantle), is broken up into tectonic plates. On Earth, there are seven or eight major plates (depending on how they are defined) and many minor plates. Where plates meet, their relative motion determines the type of boundary; convergent, divergent, or transform. Earthquakes, volcanic activity, mountain-building, and oceanic trench formation occur along these plate boundaries. The lateral relative movement of the plates typically varies from zero to 100 mm annually.
Tectonic plates are composed of oceanic lithosphere and thicker continental lithosphere, each topped by its own kind of crust. Along convergent boundaries, subduction carries plates into the mantle; the material lost is roughly balanced by the formation of new (oceanic) crust along divergent margins by seafloor spreading. In this way, the total surface of the globe remains the same. This prediction of plate tectonics is also referred to as the conveyor belt principle. Earlier theories (that still have some supporters) propose gradual shrinking (contraction) or gradual expansion of the globe.
Tectonic plates are able to move because the Earth's lithosphere has greater strength than the underlying asthenosphere. Lateral density variations in the mantle result in convection. Plate movement is thought to be driven by a combination of the motion of the seafloor away from the spreading ridge (due to variations in topography and density of the crust, which result in differences in gravitational forces) and drag, with downward suction, at the subduction zones. Another explanation lies in the different forces generated by the rotation of the globe and the tidal forces of the Sun and Moon. The relative importance of each of these factors and their relationship to each other is unclear, and still the subject of much debate.
Key principles.
The outer layers of the Earth are divided into the lithosphere and asthenosphere. This is based on differences in mechanical properties and in the method for the transfer of heat. Mechanically, the lithosphere is cooler and more rigid, while the asthenosphere is hotter and flows more easily. In terms of heat transfer, the lithosphere loses heat by conduction, whereas the asthenosphere also transfers heat by convection and has a nearly adiabatic temperature gradient. This division should not be confused with the "chemical" subdivision of these same layers into the mantle (comprising both the asthenosphere and the mantle portion of the lithosphere) and the crust: a given piece of mantle may be part of the lithosphere or the asthenosphere at different times depending on its temperature and pressure.
The key principle of plate tectonics is that the lithosphere exists as separate and distinct "tectonic plates", which ride on the fluid-like (visco-elastic solid) asthenosphere. Plate motions range up to a typical 10–40 mm/year (Mid-Atlantic Ridge; about as fast as fingernails grow), to about 160 mm/year (Nazca Plate; about as fast as hair grows). The driving mechanism behind this movement is described below.
Tectonic lithosphere plates consist of lithospheric mantle overlain by either or both of two types of crustal material: oceanic crust (in older texts called "sima" from silicon and magnesium) and continental crust ("sial" from silicon and aluminium). Average oceanic lithosphere is typically 100 km thick; its thickness is a function of its age: as time passes, it conductively cools and subjacent cooling mantle is added to its base. Because it is formed at mid-ocean ridges and spreads outwards, its thickness is therefore a function of its distance from the mid-ocean ridge where it was formed. For a typical distance that oceanic lithosphere must travel before being subducted, the thickness varies from about 6 km thick at mid-ocean ridges to greater than 100 km at subduction zones; for shorter or longer distances, the subduction zone (and therefore also the mean) thickness becomes smaller or larger, respectively. Continental lithosphere is typically ~200 km thick, though this varies considerably between basins, mountain ranges, and stable cratonic interiors of continents. The two types of crust also differ in thickness, with continental crust being considerably thicker than oceanic (35 km vs. 6 km).
The location where two plates meet is called a "plate boundary". Plate boundaries are commonly associated with geological events such as earthquakes and the creation of topographic features such as mountains, volcanoes, mid-ocean ridges, and oceanic trenches. The majority of the world's active volcanoes occur along plate boundaries, with the Pacific Plate's Ring of Fire being the most active and widely known today. These boundaries are discussed in further detail below. Some volcanoes occur in the interiors of plates, and these have been variously attributed to internal plate deformation and to mantle plumes.
As explained above, tectonic plates may include continental crust or oceanic crust, and most plates contain both. For example, the African Plate includes the continent and parts of the floor of the Atlantic and Indian Oceans. The distinction between oceanic crust and continental crust is based on their modes of formation. Oceanic crust is formed at sea-floor spreading centers, and continental crust is formed through arc volcanism and accretion of terranes through tectonic processes, though some of these terranes may contain ophiolite sequences, which are pieces of oceanic crust considered to be part of the continent when they exit the standard cycle of formation and spreading centers and subduction beneath continents. Oceanic crust is also denser than continental crust owing to their different compositions. Oceanic crust is denser because it has less silicon and more heavier elements ("mafic") than continental crust ("felsic"). As a result of this density stratification, oceanic crust generally lies below sea level (for example most of the Pacific Plate), while continental crust buoyantly projects above sea level (see the page isostasy for explanation of this principle).
Types of plate boundaries.
Three types of plate boundaries exist, with a fourth, mixed type, characterized by the way the plates move relative to each other. They are associated with different types of surface phenomena. The different types of plate boundaries are:
Driving forces of plate motion.
Plate tectonics is basically a kinematic phenomenon. Scientists agree on the observation and deduction that the plates have moved with respect to one another but continue to debate as to how and when. A major question remains as to what geodynamic mechanism motors plate movement. Here, science diverges in different theories.
It is generally accepted that tectonic plates are able to move because of the relative density of oceanic lithosphere and the relative weakness of the asthenosphere. Dissipation of heat from the mantle is acknowledged to be the original source of the energy required to drive plate tectonics through convection or large scale upwelling and doming. The current view, though still a matter of some debate, asserts that as a consequence, a powerful source of plate motion is generated due to the excess density of the oceanic lithosphere sinking in subduction zones. When the new crust forms at mid-ocean ridges, this oceanic lithosphere is initially less dense than the underlying asthenosphere, but it becomes denser with age as it conductively cools and thickens. The greater density of old lithosphere relative to the underlying asthenosphere allows it to sink into the deep mantle at subduction zones, providing most of the driving force for plate movement. The weakness of the asthenosphere allows the tectonic plates to move easily towards a subduction zone.
Although subduction is believed to be the strongest force driving plate motions, it cannot be the only force since there are plates such as the North American Plate which are moving, yet are nowhere being subducted. The same is true for the enormous Eurasian Plate. The sources of plate motion are a matter of intensive research and discussion among scientists. One of the main points is that the kinematic pattern of the movement itself should be separated clearly from the possible geodynamic mechanism that is invoked as the driving force of the observed movement, as some patterns may be explained by more than one mechanism. In short, the driving forces advocated at the moment can be divided into three categories based on the relationship to the movement: mantle dynamics related, gravity related (mostly secondary forces), and Earth rotation related.
Driving forces related to mantle dynamics.
For much of the last quarter century, the leading theory of the driving force behind tectonic plate motions envisaged large scale convection currents in the upper mantle which are transmitted through the asthenosphere. This theory was launched by Arthur Holmes and some forerunners in the 1930s and was immediately recognized as the solution for the acceptance of the theory as originally discussed in the papers of Alfred Wegener in the early years of the century. However, despite its acceptance, it was long debated in the scientific community because the leading ("fixist") theory still envisaged a static Earth without moving continents up until the major breakthroughs of the early sixties.
Two- and three-dimensional imaging of Earth's interior (seismic tomography) shows a varying lateral density distribution throughout the mantle. Such density variations can be material (from rock chemistry), mineral (from variations in mineral structures), or thermal (through thermal expansion and contraction from heat energy). The manifestation of this varying lateral density is mantle convection from buoyancy forces.
How mantle convection directly and indirectly relates to plate motion is a matter of ongoing study and discussion in geodynamics. Somehow, this energy must be transferred to the lithosphere for tectonic plates to move. There are essentially two types of forces that are thought to influence plate motion: friction and gravity.
Lately, the convection theory has been much debated as modern techniques based on 3D seismic tomography still fail to recognize these predicted large scale convection cells. Therefore, alternative views have been proposed:
In the theory of plume tectonics developed during the 1990s, a modified concept of mantle convection currents is used. It asserts that super plumes rise from the deeper mantle and are the drivers or substitutes of the major convection cells. These ideas, which find their roots in the early 1930s with the so-called "fixistic" ideas of the European and Russian Earth Science Schools, find resonance in the modern theories which envisage hot spots/mantle plumes which remain fixed and are overridden by oceanic and continental lithosphere plates over time and leave their traces in the geological record (though these phenomena are not invoked as real driving mechanisms, but rather as modulators). Modern theories that continue building on the older mantle doming concepts and see plate movements as a secondary phenomena are beyond the scope of this page and are discussed elsewhere (for example on the plume tectonics page).
Another theory is that the mantle flows neither in cells nor large plumes but rather as a series of channels just below the Earth's crust, which then provide basal friction to the lithosphere. This theory, called "surge tectonics", became quite popular in geophysics and geodynamics during the 1980s and 1990s.
Driving forces related to gravity.
Forces related to gravity are usually invoked as secondary phenomena within the framework of a more general driving mechanism such as the various forms of mantle dynamics described above.
Gravitational sliding away from a spreading ridge: According to many authors, plate motion is driven by the higher elevation of plates at ocean ridges. As oceanic lithosphere is formed at spreading ridges from hot mantle material, it gradually cools and thickens with age (and thus adds distance from the ridge). Cool oceanic lithosphere is significantly denser than the hot mantle material from which it is derived and so with increasing thickness it gradually subsides into the mantle to compensate the greater load. The result is a slight lateral incline with increased distance from the ridge axis.
This force is regarded as a secondary force and is often referred to as "ridge push". This is a misnomer as nothing is "pushing" horizontally and tensional features are dominant along ridges. It is more accurate to refer to this mechanism as gravitational sliding as variable topography across the totality of the plate can vary considerably and the topography of spreading ridges is only the most prominent feature. Other mechanisms generating this gravitational secondary force include flexural bulging of the lithosphere before it dives underneath an adjacent plate which produces a clear topographical feature that can offset, or at least affect, the influence of topographical ocean ridges, and mantle plumes and hot spots, which are postulated to impinge on the underside of tectonic plates.
Slab-pull: Current scientific opinion is that the asthenosphere is insufficiently competent or rigid to directly cause motion by friction along the base of the lithosphere. Slab pull is therefore most widely thought to be the greatest force acting on the plates. In this current understanding, plate motion is mostly driven by the weight of cold, dense plates sinking into the mantle at trenches. Recent models indicate that trench suction plays an important role as well. However, as the North American Plate is nowhere being subducted, yet it is in motion presents a problem. The same holds for the African, Eurasian, and Antarctic plates.
Gravitational sliding away from mantle doming: According to older theories, one of the driving mechanisms of the plates is the existence of large scale asthenosphere/mantle domes which cause the gravitational sliding of lithosphere plates away from them. This gravitational sliding represents a secondary phenomenon of this basically vertically oriented mechanism. This can act on various scales, from the small scale of one island arc up to the larger scale of an entire ocean basin.
Driving forces related to Earth rotation.
Alfred Wegener, being a meteorologist, had proposed tidal forces and pole flight force as the main driving mechanisms behind continental drift; however, these forces were considered far too small to cause continental motion as the concept then was of continents plowing through oceanic crust. Therefore, Wegener later changed his position and asserted that convection currents are the main driving force of plate tectonics in the last edition of his book in 1929.
However, in the plate tectonics context (accepted since the seafloor spreading proposals of Heezen, Hess, Dietz, Morley, Vine, and Matthews (see below) during the early 1960s), oceanic crust is suggested to be in motion "with" the continents which caused the proposals related to Earth rotation to be reconsidered. In more recent literature, these driving forces are:
For these mechanisms to be overall valid, systematic relationships should exist all over the globe between the orientation and kinematics of deformation and the geographical latitudinal and longitudinal grid of the Earth itself. Ironically, these systematic relations studies in the second half of the nineteenth century and the first half of the twentieth century underline exactly the opposite: that the plates had not moved in time, that the deformation grid was fixed with respect to the Earth equator and axis, and that gravitational driving forces were generally acting vertically and caused only local horizontal movements (the so-called pre-plate tectonic, "fixist theories"). Later studies (discussed below on this page), therefore, invoked many of the relationships recognized during this pre-plate tectonics period to support their theories (see the anticipations and reviews in the work of van Dijk and collaborators).
Of the many forces discussed in this paragraph, tidal force is still highly debated and defended as a possible principle driving force of plate tectonics. The other forces are only used in global geodynamic models not using plate tectonics concepts (therefore beyond the discussions treated in this section) or proposed as minor modulations within the overall plate tectonics model.
In 1973, George W. Moore of the USGS and R. C. Bostrom presented evidence for a general westward drift of the Earth's lithosphere with respect to the mantle. He concluded that tidal forces (the tidal lag or "friction") caused by the Earth's rotation and the forces acting upon it by the Moon are a driving force for plate tectonics. As the Earth spins eastward beneath the moon, the moon's gravity ever so slightly pulls the Earth's surface layer back westward, just as proposed by Alfred Wegener (see above). In a more recent 2006 study, scientists reviewed and advocated these earlier proposed ideas. It has also been suggested recently in that this observation may also explain why Venus and Mars have no plate tectonics, as Venus has no moon and Mars' moons are too small to have significant tidal effects on the planet. In a recent paper, it was suggested that, on the other hand, it can easily be observed that many plates are moving north and eastward, and that the dominantly westward motion of the Pacific ocean basins derives simply from the eastward bias of the Pacific spreading center (which is not a predicted manifestation of such lunar forces). In the same paper the authors admit, however, that relative to the lower mantle, there is a slight westward component in the motions of all the plates. They demonstrated though that the westward drift, seen only for the past 30 Ma, is attributed to the increased dominance of the steadily growing and accelerating Pacific plate. The debate is still open.
Relative significance of each driving force mechanism.
The actual vector of a plate's motion is a function of all the forces acting on the plate; however, therein lies the problem regarding the degree to which each process contributes to the overall motion of each tectonic plate.
The diversity of geodynamic settings and the properties of each plate result from the impact of the various processes actively driving each individual plate. One method of dealing with this problem is to consider the relative rate at which each plate is moving as well as the evidence related to the significance of each process to the overall driving force on the plate.
One of the most significant correlations discovered to date is that lithospheric plates attached to downgoing (subducting) plates move much faster than plates not attached to subducting plates. The Pacific plate, for instance, is essentially surrounded by zones of subduction (the so-called Ring of Fire) and moves much faster than the plates of the Atlantic basin, which are attached (perhaps one could say 'welded') to adjacent continents instead of subducting plates. It is thus thought that forces associated with the downgoing plate (slab pull and slab suction) are the driving forces which determine the motion of plates, except for those plates which are not being subducted. The driving forces of plate motion continue to be active subjects of on-going research within geophysics and tectonophysics.
Development of the theory.
Summary.
In line with other previous and contemporaneous proposals, in 1912 the meteorologist Alfred Wegener amply described what he called continental drift, expanded in his 1915 book "The Origin of Continents and Oceans" and the scientific debate started that would end up fifty years later in the theory of plate tectonics. Starting from the idea (also expressed by his forerunners) that the present continents once formed a single land mass (which was called Pangea later on) that drifted apart, thus releasing the continents from the Earth's mantle and likening them to "icebergs" of low density granite floating on a sea of denser basalt. Supporting evidence for the idea came from the dove-tailing outlines of South America's east coast and Africa's west coast, and from the matching of the rock formations along these edges. Confirmation of their previous contiguous nature also came from the fossil plants "Glossopteris" and "Gangamopteris", and the therapsid or mammal-like reptile "Lystrosaurus", all widely distributed over South America, Africa, Antarctica, India and Australia. The evidence for such an erstwhile joining of these continents was patent to field geologists working in the southern hemisphere. The South African Alex du Toit put together a mass of such information in his 1937 publication "Our Wandering Continents", and went further than Wegener in recognising the strong links between the Gondwana fragments.
But without detailed evidence and a force sufficient to drive the movement, the theory was not generally accepted: the Earth might have a solid crust and mantle and a liquid core, but there seemed to be no way that portions of the crust could move around. Distinguished scientists, such as Harold Jeffreys and Charles Schuchert, were outspoken critics of continental drift.
Despite much opposition, the view of continental drift gained support and a lively debate started between "drifters" or "mobilists" (proponents of the theory) and "fixists" (opponents). During the 1920s, 1930s and 1940s, the former reached important milestones proposing that convection currents might have driven the plate movements, and that spreading may have occurred below the sea within the oceanic crust. Concepts close to the elements now incorporated in plate tectonics were proposed by geophysicists and geologists (both fixists and mobilists) like Vening-Meinesz, Holmes, and Umbgrove.
One of the first pieces of geophysical evidence that was used to support the movement of lithospheric plates came from paleomagnetism. This is based on the fact that rocks of different ages show a variable magnetic field direction, evidenced by studies since the mid–nineteenth century. The magnetic north and south poles reverse through time, and, especially important in paleotectonic studies, the relative position of the magnetic north pole varies through time. Initially, during the first half of the twentieth century, the latter phenomenon was explained by introducing what was called "polar wander" (see apparent polar wander), i.e., it was assumed that the north pole location had been shifting through time. An alternative explanation, though, was that the continents had moved (shifted and rotated) relative to the north pole, and each continent, in fact, shows its own "polar wander path". During the late 1950s it was successfully shown on two occasions that these data could show the validity of continental drift: by Keith Runcorn in a paper in 1956, and by Warren Carey in a symposium held in March 1956.
The second piece of evidence in support of continental drift came during the late 1950s and early 60s from data on the bathymetry of the deep ocean floors and the nature of the oceanic crust such as magnetic properties and, more generally, with the development of marine geology which gave evidence for the association of seafloor spreading along the mid-oceanic ridges and magnetic field reversals, published between 1959 and 1963 by Heezen, Dietz, Hess, Mason, Vine & Matthews, and Morley.
Simultaneous advances in early seismic imaging techniques in and around Wadati-Benioff zones along the trenches bounding many continental margins, together with many other geophysical (e.g. gravimetric) and geological observations, showed how the oceanic crust could disappear into the mantle, providing the mechanism to balance the extension of the ocean basins with shortening along its margins.
All this evidence, both from the ocean floor and from the continental margins, made it clear around 1965 that continental drift was feasible and the theory of plate tectonics, which was defined in a series of papers between 1965 and 1967, was born, with all its extraordinary explanatory and predictive power. The theory revolutionized the Earth sciences, explaining a diverse range of geological phenomena and their implications in other studies such as paleogeography and paleobiology.
Continental drift.
In the late 19th and early 20th centuries, geologists assumed that the Earth's major features were fixed, and that most geologic features such as basin development and mountain ranges could be explained by vertical crustal movement, described in what is called the geosynclinal theory. Generally, this was placed in the context of a contracting planet Earth due to heat loss in the course of a relatively short geological time.
It was observed as early as 1596 that the opposite coasts of the Atlantic Ocean—or, more precisely, the edges of the continental shelves—have similar shapes and seem to have once fitted together.
Since that time many theories were proposed to explain this apparent complementarity, but the assumption of a solid Earth made these various proposals difficult to accept.
The discovery of radioactivity and its associated heating properties in 1895 prompted a re-examination of the apparent age of the Earth.
This had previously been estimated by its cooling rate and assumption the Earth's surface radiated like a black body. Those calculations had implied that, even if it started at red heat, the Earth would have dropped to its present temperature in a few tens of millions of years. Armed with the knowledge of a new heat source, scientists realized that the Earth would be much older, and that its core was still sufficiently hot to be liquid.
By 1915, after having published a first article in 1912, Alfred Wegener was making serious arguments for the idea of continental drift in the first edition of "The Origin of Continents and Oceans". In that book (re-issued in four successive editions up to the final one in 1936), he noted how the east coast of South America and the west coast of Africa looked as if they were once attached. Wegener was not the first to note this (Abraham Ortelius, Antonio Snider-Pellegrini, Eduard Suess, Roberto Mantovani and Frank Bursley Taylor preceded him just to mention a few), but he was the first to marshal significant fossil and paleo-topographical and climatological evidence to support this simple observation (and was supported in this by researchers such as Alex du Toit). Furthermore, when the rock strata of the margins of separate continents are very similar it suggests that these rocks were formed in the same way, implying that they were joined initially. For instance, parts of Scotland and Ireland contain rocks very similar to those found in Newfoundland and New Brunswick. Furthermore, the Caledonian Mountains of Europe and parts of the Appalachian Mountains of North America are very similar in structure and lithology.
However, his ideas were not taken seriously by many geologists, who pointed out that there was no apparent mechanism for continental drift. Specifically, they did not see how continental rock could plow through the much denser rock that makes up oceanic crust. Wegener could not explain the force that drove continental drift, and his vindication did not come until after his death in 1930.
Floating continents, paleomagnetism, and seismicity zones.
As it was observed early that although granite existed on continents, seafloor seemed to be composed of denser basalt, the prevailing concept during the first half of the twentieth century was that there were two types of crust, named "sial" (continental type crust) and "sima" (oceanic type crust). Furthermore, it was supposed that a static shell of strata was present under the continents. It therefore looked apparent that a layer of basalt (sial) underlies the continental rocks.
However, based on abnormalities in plumb line deflection by the Andes in Peru, Pierre Bouguer had deduced that less-dense mountains must have a downward projection into the denser layer underneath. The concept that mountains had "roots" was confirmed by George B. Airy a hundred years later, during study of Himalayan gravitation, and seismic studies detected corresponding density variations. Therefore, by the mid-1950s, the question remained unresolved as to whether mountain roots were clenched in surrounding basalt or were floating on it like an iceberg.
During the 20th century, improvements in and greater use of seismic instruments such as seismographs enabled scientists to learn that earthquakes tend to be concentrated in specific areas, most notably along the oceanic trenches and spreading ridges. By the late 1920s, seismologists were beginning to identify several prominent earthquake zones parallel to the trenches that typically were inclined 40–60° from the horizontal and extended several hundred kilometers into the Earth. These zones later became known as Wadati-Benioff zones, or simply Benioff zones, in honor of the seismologists who first recognized them, Kiyoo Wadati of Japan and Hugo Benioff of the United States. The study of global seismicity greatly advanced in the 1960s with the establishment of the Worldwide Standardized Seismograph Network (WWSSN) to monitor the compliance of the 1963 treaty banning above-ground testing of nuclear weapons. The much improved data from the WWSSN instruments allowed seismologists to map precisely the zones of earthquake concentration world wide.
Meanwhile, debates developed around the phenomena of polar wander. Since the early debates of continental drift, scientists had discussed and used evidence that polar drift had occurred because continents seemed to have moved through different climatic zones during the past. Furthermore, paleomagnetic data had shown that the magnetic pole had also shifted during time. Reasoning in an opposite way, the continents might have shifted and rotated, while the pole remained relatively fixed. The first time the evidence of magnetic polar wander was used to support the movements of continents was in a paper by Keith Runcorn in 1956, and successive papers by him and his students Ted Irving (who was actually the first to be convinced of the fact that paleomagnetism supported continental drift) and Ken Creer.
This was immediately followed by a symposium in Tasmania in March 1956. In this symposium, the evidence was used in the theory of an expansion of the global crust. In this hypothesis the shifting of the continents can be simply explained by a large increase in size of the Earth since its formation. However, this was unsatisfactory because its supporters could offer no convincing mechanism to produce a significant expansion of the Earth. Certainly there is no evidence that the moon has expanded in the past 3 billion years; other work would soon show that the evidence was equally in support of continental drift on a globe with a stable radius.
During the thirties up to the late fifties, works by Vening-Meinesz, Holmes, Umbgrove, and numerous others outlined concepts that were close or nearly identical to modern plate tectonics theory. In particular, the English geologist Arthur Holmes proposed in 1920 that plate junctions might lie beneath the sea, and in 1928 that convection currents within the mantle might be the driving force. Often, these contributions are forgotten because:
Mid-oceanic ridge spreading and convection.
In 1947, a team of scientists led by Maurice Ewing utilizing the Woods Hole Oceanographic Institution's research vessel "Atlantis" and an array of instruments, confirmed the existence of a rise in the central Atlantic Ocean, and found that the floor of the seabed beneath the layer of sediments consisted of basalt, not the granite which is the main constituent of continents. They also found that the oceanic crust was much thinner than continental crust. All these new findings raised important and intriguing questions.
The new data that had been collected on the ocean basins also showed particular characteristics regarding the bathymetry. One of the major outcomes of these datasets was that all along the globe, a system of mid-oceanic ridges was detected. An important conclusion was that along this system, new ocean floor was being created, which led to the concept of the "Great Global Rift". This was described in the crucial paper of Bruce Heezen (1960), which would trigger a real revolution in thinking. A profound consequence of seafloor spreading is that new crust was, and still is, being continually created along the oceanic ridges. Therefore, Heezen advocated the so-called "expanding Earth" hypothesis of S. Warren Carey (see above). So, still the question remained: how can new crust be continuously added along the oceanic ridges without increasing the size of the Earth? In reality, this question had been solved already by numerous scientists during the forties and the fifties, like Arthur Holmes, Vening-Meinesz, Coates and many others: The crust in excess disappeared along what were called the oceanic trenches, where so-called "subduction" occurred. Therefore, when various scientists during the early sixties started to reason on the data at their disposal regarding the ocean floor, the pieces of the theory quickly fell into place.
The question particularly intrigued Harry Hammond Hess, a Princeton University geologist and a Naval Reserve Rear Admiral, and Robert S. Dietz, a scientist with the U.S. Coast and Geodetic Survey who first coined the term "seafloor spreading". Dietz and Hess (the former published the same idea one year earlier in "Nature", but priority belongs to Hess who had already distributed an unpublished manuscript of his 1962 article by 1960) were among the small handful who really understood the broad implications of sea floor spreading and how it would eventually agree with the, at that time, unconventional and unaccepted ideas of continental drift and the elegant and mobilistic models proposed by previous workers like Holmes.
In the same year, Robert R. Coats of the U.S. Geological Survey described the main features of island arc subduction in the Aleutian Islands. His paper, though little noted (and even ridiculed) at the time, has since been called "seminal" and "prescient". In reality, it actually shows that the work by the European scientists on island arcs and mountain belts performed and published during the 1930s up until the 1950s was applied and appreciated also in the United States.
If the Earth's crust was expanding along the oceanic ridges, Hess and Dietz reasoned like Holmes and others before them, it must be shrinking elsewhere. Hess followed Heezen, suggesting that new oceanic crust continuously spreads away from the ridges in a conveyor belt–like motion. And, using the mobilistic concepts developed before, he correctly concluded that many millions of years later, the oceanic crust eventually descends along the continental margins where oceanic trenches – very deep, narrow canyons – are formed, e.g. along the rim of the Pacific Ocean basin. The important step Hess made was that convection currents would be the driving force in this process, arriving at the same conclusions as Holmes had decades before with the only difference that the thinning of the ocean crust was performed using Heezen's mechanism of spreading along the ridges. Hess therefore concluded that the Atlantic Ocean was expanding while the Pacific Ocean was shrinking. As old oceanic crust is "consumed" in the trenches (like Holmes and others, he thought this was done by thickening of the continental lithosphere, not, as now understood, by underthrusting at a larger scale of the oceanic crust itself into the mantle), new magma rises and erupts along the spreading ridges to form new crust. In effect, the ocean basins are perpetually being "recycled," with the creation of new crust and the destruction of old oceanic lithosphere occurring simultaneously. Thus, the new mobilistic concepts neatly explained why the Earth does not get bigger with sea floor spreading, why there is so little sediment accumulation on the ocean floor, and why oceanic rocks are much younger than continental rocks.
Magnetic striping.
Beginning in the 1950s, scientists like Victor Vacquier, using magnetic instruments (magnetometers) adapted from airborne devices developed during World War II to detect submarines, began recognizing odd magnetic variations across the ocean floor. This finding, though unexpected, was not entirely surprising because it was known that basalt—the iron-rich, volcanic rock making up the ocean floor—contains a strongly magnetic mineral (magnetite) and can locally distort compass readings. This distortion was recognized by Icelandic mariners as early as the late 18th century. More important, because the presence of magnetite gives the basalt measurable magnetic properties, these newly discovered magnetic variations provided another means to study the deep ocean floor. When newly formed rock cools, such magnetic materials recorded the Earth's magnetic field at the time.
As more and more of the seafloor was mapped during the 1950s, the magnetic variations turned out not to be random or isolated occurrences, but instead revealed recognizable patterns. When these magnetic patterns were mapped over a wide region, the ocean floor showed a zebra-like pattern: one stripe with normal polarity and the adjoining stripe with reversed polarity. The overall pattern, defined by these alternating bands of normally and reversely polarized rock, became known as magnetic striping, and was published by Ron G. Mason and co-workers in 1961, who did not find, though, an explanation for these data in terms of sea floor spreading, like Vine, Matthews and Morley a few years later.
The discovery of magnetic striping called for an explanation. In the early 1960s scientists such as Heezen, Hess and Dietz had begun to theorise that mid-ocean ridges mark structurally weak zones where the ocean floor was being ripped in two lengthwise along the ridge crest (see the previous paragraph). New magma from deep within the Earth rises easily through these weak zones and eventually erupts along the crest of the ridges to create new oceanic crust. This process, at first denominated the "conveyer belt hypothesis" and later called seafloor spreading, operating over many millions of years continues to form new ocean floor all across the 50,000 km-long system of mid-ocean ridges.
Only four years after the maps with the "zebra pattern" of magnetic stripes were published, the link between sea floor spreading and these patterns was correctly placed, independently by Lawrence Morley, and by Fred Vine and Drummond Matthews, in 1963, now called the Vine-Matthews-Morley hypothesis. This hypothesis linked these patterns to geomagnetic reversals and was supported by several lines of evidence:
By explaining both the zebra-like magnetic striping and the construction of the mid-ocean ridge system, the seafloor spreading hypothesis (SFS) quickly gained converts and represented another major advance in the development of the plate-tectonics theory. Furthermore, the oceanic crust now came to be appreciated as a natural "tape recording" of the history of the geomagnetic field reversals (GMFR) of the Earth's magnetic field. Today, extensive studies are dedicated to the calibration of the normal-reversal patterns in the oceanic crust on one hand and known timescales derived from the dating of basalt layers in sedimentary sequences (magnetostratigraphy) on the other, to arrive at estimates of past spreading rates and plate reconstructions.
Definition and refining of the theory.
After all these considerations, Plate Tectonics (or, as it was initially called "New Global Tectonics") became quickly accepted in the scientific world, and numerous papers followed that defined the concepts:
Implications for biogeography.
Continental drift theory helps biogeographers to explain the disjunct biogeographic distribution of present day life found on different continents but having similar ancestors. In particular, it explains the Gondwanan distribution of ratites and the Antarctic flora.
Plate reconstruction.
Reconstruction is used to establish past (and future) plate configurations, helping determine the shape and make-up of ancient supercontinents and providing a basis for paleogeography.
Defining plate boundaries.
Current plate boundaries are defined by their seismicity. Past plate boundaries within existing plates are identified from a variety of evidence, such as the presence of ophiolites that are indicative of vanished oceans.
Past plate motions.
Tectonic motion first began around three billion years ago.
Various types of quantitative and semi-quantitative information are available to constrain past plate motions. The geometric fit between continents, such as between west Africa and South America is still an important part of plate reconstruction. Magnetic stripe patterns provide a reliable guide to relative plate motions going back into the Jurassic period. The tracks of hotspots give absolute reconstructions, but these are only available back to the Cretaceous. Older reconstructions rely mainly on paleomagnetic pole data, although these only constrain the latitude and rotation, but not the longitude. Combining poles of different ages in a particular plate to produce apparent polar wander paths provides a method for comparing the motions of different plates through time. Additional evidence comes from the distribution of certain sedimentary rock types,
faunal provinces shown by particular fossil groups, and the position of orogenic belts.
Formation and break-up of continents.
The movement of plates has caused the formation and break-up of continents over time, including occasional formation of a supercontinent that contains most or all of the continents. The supercontinent Columbia or Nuna formed during a period of 1800 and broke up about 1300. The supercontinent Rodinia is thought to have formed about 1 billion years ago and to have embodied most or all of Earth's continents, and broken up into eight continents around million years ago. The eight continents later re-assembled into another supercontinent called Pangaea; Pangaea broke up into Laurasia (which became North America and Eurasia) and Gondwana (which became the remaining continents).
The Himalayas, the world's tallest mountain range, are assumed to have been formed by the collision of two major plates. Before uplift, they were covered by the Tethys Ocean.
Gallery of past configurations.
Interpretive simulation of past continental movement and shorelines, with time given in millions of years ago (Ma). For more complete timeline of images, see Gallery of continental movement.
Current plates.
Depending on how they are defined, there are usually seven or eight "major" plates: African, Antarctic, Eurasian, North American, South American, Pacific, and Indo-Australian. The latter is sometimes subdivided into the Indian and Australian plates.
There are dozens of smaller plates, the seven largest of which are the Arabian, Caribbean, Juan de Fuca, Cocos, Nazca, Philippine Sea and Scotia.
The current motion of the tectonic plates is today determined by remote sensing satellite data sets, calibrated with ground station measurements.
Other celestial bodies (planets, moons).
The appearance of plate tectonics on terrestrial planets is related to planetary mass, with more massive planets than Earth expected to exhibit plate tectonics. Earth may be a borderline case, owing its tectonic activity to abundant water (silica and water form a deep eutectic.)
Venus.
Venus shows no evidence of active plate tectonics. There is debatable evidence of active tectonics in the planet's distant past; however, events taking place since then (such as the plausible and generally accepted hypothesis that the Venusian lithosphere has thickened greatly over the course of several hundred million years) has made constraining the course of its geologic record difficult. However, the numerous well-preserved impact craters have been utilized as a dating method to approximately date the Venusian surface (since there are thus far no known samples of Venusian rock to be dated by more reliable methods). Dates derived are dominantly in the range 750, although ages of up to million years ago have been calculated. This research has led to the fairly well accepted hypothesis that Venus has undergone an essentially complete volcanic resurfacing at least once in its distant past, with the last event taking place approximately within the range of estimated surface ages. While the mechanism of such an impressive thermal event remains a debated issue in Venusian geosciences, some scientists are advocates of processes involving plate motion to some extent.
One explanation for Venus' lack of plate tectonics is that on Venus temperatures are too high for significant water to be present. The Earth's crust is soaked with water, and water plays an important role in the development of shear zones. Plate tectonics requires weak surfaces in the crust along which crustal slices can move, and it may well be that such weakening never took place on Venus because of the absence of water. However, some researchers remain convinced that plate tectonics is or was once active on this planet.
Mars.
Mars is considerably smaller than Earth and Venus, and there is evidence for ice on its surface and in its crust.
In the 1990s, it was proposed that Martian Crustal Dichotomy was created by plate tectonic processes. Scientists today disagree, and believe that it was created either by upwelling within the Martian mantle that thickened the crust of the Southern Highlands and formed Tharsis or by a giant impact that excavated the Northern Lowlands.
Valles Marineris may be a tectonic boundary.
Observations made of the magnetic field of Mars by the "Mars Global Surveyor" spacecraft in 1999 showed patterns of magnetic striping discovered on this planet. Some scientists interpreted these as requiring plate tectonic processes, such as seafloor spreading. However, their data fail a "magnetic reversal test", which is used to see if they were formed by flipping polarities of a global magnetic field.
Galilean satellites of Jupiter.
Some of the satellites of Jupiter have features that may be related to plate-tectonic style deformation, although the materials and specific mechanisms may be different from plate-tectonic activity on Earth. On 8 September 2014, NASA reported finding evidence of plate tectonics on Europa, a satellite of Jupiter - the first sign of such geological activity on another world other than Earth.
Titan, moon of Saturn.
Titan, the largest moon of Saturn, was reported to show tectonic activity in images taken by the Huygens Probe, which landed on Titan on January 14, 2005.
Exoplanets.
On Earth-sized planets, plate tectonics is more likely if there are oceans of water; however, in 2007, two independent teams of researchers came to opposing conclusions about the likelihood of plate tectonics on larger super-earths with one team saying that plate tectonics would be episodic or stagnant and the other team saying that plate tectonics is very likely on super-earths even if the planet is dry.
References.
Cited books.
</dl>
Cited articles.
</dl>

</doc>
<doc id="24946" url="http://en.wikipedia.org/wiki?curid=24946" title="Philips Videopac + G7400">
Philips Videopac + G7400

The Philips Videopac+ G7400 was a video game console released in limited quantities in 1983, and only in Europe; an American release as the Odyssey³ Command Center was planned but never occurred. The G7400 was the successor to the Philips Videopac G7000, the European counterpart to the American Magnavox Odyssey². The system featured excellently tailored background and foreground graphics.
The G7400 could play three types of games: all normal G7000 games, special G7000 games with additional high-res background graphics that would appear only when played on the G7400, and G7400-only games with high-res sprites and backgrounds.
Odyssey³.
There were plans to release the G7400 in the United States as the Odyssey³ and later as the Odyssey³ Command Center; the system was demonstrated at the 1983 Consumer Electronics Show and some prototypes have been found. The Odyssey³ was never released, mostly because company executives concluded that it was not technologically advanced enough to compete in the marketplace. Also, the video game crash of 1983 ended all lingering hopes for a release.
The Odyssey³ was to feature a real mechanical keyboard, unlike the membrane keyboard found in the G7000 and Odyssey², as well as a built-in joystick holder for dual-joystick games. Prototypes for a 300 baud modem and a speech synthesizer are known to have been made, and a laserdisc interface was planned to allow even more advanced games.
Emulation.
The emulator O2EM allows G7400 games to be played on modern computers.

</doc>
<doc id="24947" url="http://en.wikipedia.org/wiki?curid=24947" title="Pong">
Pong

Pong (marketed as PONG) is one of the earliest arcade video games and the very first sports arcade video game. It is a tennis sports game featuring simple two-dimensional graphics. While other arcade video games such as "Computer Space" came before it, "Pong" was one of the first video games to reach mainstream popularity. The aim is to defeat an opponent in a simulated table-tennis game by earning a higher score. The game was originally manufactured by Atari Incorporated (Atari), which released it in 1972. Allan Alcorn created "Pong" as a training exercise assigned to him by Atari co-founder Nolan Bushnell. Bushnell based the idea on an electronic ping-pong game included in the Magnavox Odyssey, which later resulted in a lawsuit against Atari. Surprised by the quality of Alcorn's work, Bushnell and Atari co-founder Ted Dabney decided to manufacture the game.
"Pong" quickly became a success and is the first commercially successful arcade video game machine, which helped to establish the video game industry along with the first home console, the Magnavox Odyssey. Soon after its release, several companies began producing games that copied "Pong"‍ '​s gameplay, and eventually released new types of games. As a result, Atari encouraged its staff to produce more innovative games. The company released several sequels that built upon the original's gameplay by adding new features. During the 1975 Christmas season, Atari released a home version of "Pong" exclusively through Sears retail stores. It was also a commercial success and led to numerous copies. The game has been remade on numerous home and portable platforms following its release. "Pong" has been referenced and parodied in multiple television shows and video games, and has been a part of several video game and cultural exhibitions.
Gameplay.
"Pong" is a two-dimensional sports game that simulates table tennis. The player controls an in-game paddle by moving it vertically across the left side of the screen, and can compete against either a computer-controlled opponent or another player controlling a second paddle on the opposing side. Players use the paddles to hit a ball back and forth. The aim is for each player to reach eleven points before the opponent; points are earned when one fails to return the ball to the other.
Development and history.
"Pong" was the first game developed by Atari Inc. (incorporated in June 1972 by Nolan Bushnell and Ted Dabney). After producing "Computer Space", Bushnell decided to form a company to produce more games by licensing ideas to other companies. The first contract was with Bally Manufacturing Corporation for a driving game. Soon after the founding, Bushnell hired Allan Alcorn because of his experience with electrical engineering and computer science; Bushnell and Dabney also had previously worked with him at Ampex. Prior to working at Atari, Alcorn had no experience with video games. To acclimate Alcorn to creating games, Bushnell gave him a project secretly meant to be a warm-up exercise. Bushnell told Alcorn that he had a contract with General Electric for a product, and asked Alcorn to create a simple game with one moving spot, two paddles, and digits for score keeping. In 2011, Bushnell stated that the game was inspired by previous versions of electronic tennis he had played before; Bushnell played a version on a PDP-1 computer in 1964 while attending college. However, Alcorn has claimed it was in direct response to Nolan's viewing of the Magnavox Odyssey's Tennis game. In May 1972, Bushnell had visited the Magnavox Profit Caravan in Burlingame, California where he played the Magnavox Odyssey demonstration, specifically the table tennis game. Though he thought the game lacked quality, seeing it prompted Bushnell to assign the project to Alcorn.
Alcorn first examined Bushnell's schematics for "Computer Space", but found them to be illegible. He went on to create his own designs based on his knowledge of transistor–transistor logic and Bushnell's game. Feeling the basic game was too boring, Alcorn added features to give the game more appeal. He divided the paddle into eight segments to change the ball's angle of return. For example, the center segments return the ball a 90° angle in relation to the paddle, while the outer segments return the ball at smaller angles. He also made the ball accelerate the longer it remained in play; missing the ball reset the speed. Another feature was that the in-game paddles were unable to reach the top of screen. This was caused by a simple circuit that had an inherent defect. Instead of dedicating time to fixing the defect, Alcorn decided it gave the game more difficulty and helped limit the time the game could be played; he imagined two skilled players being able to play forever otherwise.
Three months into development, Bushnell told Alcorn he wanted the game to feature realistic sound effects and a roaring crowd. Dabney wanted the game to "boo" and "hiss" when a player lost a round. Alcorn had limited space available for the necessary electronics and was unaware of how to create such sounds with digital circuits. After inspecting the sync generator, he discovered that it could generate different tones and used those for the game's sound effects. To construct the prototype, Alcorn purchased a $75 Hitachi black-and-white television set from a local store, placed it into a 4 ft wooden cabinet, and soldered the wires into boards to create the necessary circuitry. The prototype impressed Bushnell and Dabney so much that they felt it could be a profitable product and decided to test its marketability.
In August 1972, Bushnell and Alcorn installed the "Pong" prototype at a local bar, Andy Capp's Tavern. They selected the bar because of their good working relation with the bar's manager, Bill Gattis; Atari supplied pinball machines to Gattis. Bushnell and Alcorn placed the prototype on one of the tables near the other entertainment machines: a jukebox, pinball machines, and "Computer Space". The game was well received the first night and its popularity continued to grow over the next one and a half weeks. Bushnell then went on a business trip to Chicago to demonstrate "Pong" to executives at Bally and Midway Manufacturing; he intended to use "Pong" to fulfill his contract with Bally, rather than the driving game. A few days later, the prototype began exhibiting technical issues and Gattis contacted Alcorn to fix it. Upon inspecting the machine, Alcorn discovered that the problem was the coin mechanism was overflowing with quarters.
After hearing about the game's success, Bushnell decided there would be more profit for Atari to manufacture the game rather than license it, but the interest of Bally and Midway had already been piqued. Bushnell decided to inform each of the two groups that the other was uninterested—Bushnell told the Bally executives that the Midway executives did not want it and vice versa—to preserve the relationships for future dealings. Upon hearing Bushnell's comment, the two groups declined his offer. Bushnell had difficulty finding financial backing for "Pong"; banks viewed it as a variant of pinball, which at the time the general public associated with the Mafia. Atari eventually obtained a line of credit from Wells Fargo that it used to expand its facilities to house an assembly line. The company announced "Pong" on 29 November 1972. Management sought assembly workers at the local unemployment office, but was unable to keep up with demand. The first arcade cabinets produced were assembled very slowly, about ten machines a day, many of which failed quality testing. Atari eventually streamlined the process and began producing the game in greater quantities. By 1973, they began shipping "Pong" to other countries with the aid of foreign partners.
Home version.
After the success of "Pong", Bushnell pushed his employees to create new products. In 1974, Atari engineer Harold Lee proposed a home version of "Pong" that would connect to a television: "Home Pong". The system began development under the codename "Darlene", named after an attractive female employee at Atari. Alcorn worked with Lee to develop the designs and prototype, and based them on the same digital technology used in their arcade games. The two worked in shifts to save time and money; Lee worked on the design's logic during the day, while Alcorn debugged the designs in the evenings. After the designs were approved, fellow Atari engineer Bob Brown assisted Alcorn and Lee in building a prototype. The prototype consisted of a device attached to a wooden pedestal containing over a hundred wires, which would eventually be replaced with a single chip designed by Alcorn and Lee; the chip had yet to be tested and built before the prototype was constructed. The chip was finished in the latter half of 1974, and was, at the time, the highest performing chip used in a consumer product.
Bushnell and Gene Lipkin, Atari's vice-president of sales, approached toy and electronic retailers to sell "Home Pong", but were rejected. Retailers felt the product was too expensive and would not interest consumers. Atari contacted the Sears Sporting Goods department after noticing a Magnavox Odyssey advertisement in the sporting goods section of its catalog. Atari staff discussed the game with a representative, Tom Quinn, who expressed enthusiasm and offered the company an exclusive deal. Believing they could find more favorable terms elsewhere, Atari's executives declined and continued to pursue toy retailers. In January 1975, Atari staff set up a "Home Pong" booth at a toy trade fair in New York City, but was unsuccessful in soliciting orders due to the fact that they did not know that they needed a private showing.
While at the show, they met Quinn again, and, a few days later, set up a meeting with him to obtain a sales order. In order to gain approval from the Sporting Goods department, Quinn suggested Atari demonstrate the game to executives in Chicago. Alcorn and Lipkin traveled to the Sears Tower and, despite a technical complication in connection with an antenna on top of the building which broadcast on the same channel as the game, obtained approval. Bushnell told Quinn he could produce 75,000 units in time for the Christmas season; however, Quinn requested double the amount. Though Bushnell knew Atari lacked the capacity to manufacture 150,000 units, he agreed. Atari acquired a new factory through funding obtained by venture capitalist Don Valentine. Supervised by Jimm Tubb, the factory fulfilled the Sears order. The first units manufactured were branded with Sears' "Tele-Games" name. Atari later released a version under its own brand in 1976.
Lawsuit from Magnavox.
The success of "Pong" attracted the attention of Ralph Baer, the inventor of the Magnavox Odyssey, and his employer, Sanders Associates. Sanders had an agreement with Magnavox to handle the Odyssey's sublicensing, which included dealing with infringement on its exclusive rights. However, Magnavox had not pursued legal action against Atari and numerous other companies that released "Pong" clones. Sanders continued to apply pressure, and in April 1974 Magnavox filed suit against Atari, Bally Midway, Allied Leisure and Chicago Dynamics. Magnavox argued that Atari had infringed on Baer's patents and his concept of electronic ping-pong based on detailed records Sanders kept of the Odyssey's design process dating back to 1966. Other documents included depositions from witnesses and a signed guest book that demonstrated Bushnell had played the Odyssey's table tennis game prior to releasing "Pong". In response to claims that he saw the Odyssey, Bushnell later stated that, "The fact is that I absolutely did see the Odyssey game and I didn't think it was very clever."
After considering his options, Bushnell decided to settle with Magnavox out of court. Bushnell's lawyer felt they could win; however, he estimated legal costs of US$1.5 million, which would have exceeded Atari's funds. Magnavox offered Atari an agreement to become a licensee for US$0.7 million. Other companies producing ""Pong" clones"—Atari's competitors—would have to pay royalties. In addition, Magnavox would obtain the rights to Atari products developed over the next year. Magnavox continued to pursue legal action against the other companies, and proceedings began shortly after Atari's settlement in June 1976. The first case took place at the district court in Chicago, with Judge John Grady presiding. To avoid Magnavox obtaining rights to its products, Atari decided to delay the release of its products for a year, and withheld information from Magnavox's attorneys during visits to Atari facilities.
Impact and legacy.
The "Pong" arcade games manufactured by Atari were a great success. The prototype was well received by Andy Capp's Tavern patrons; people came to the bar solely to play the game. Following its release, "Pong" consistently earned four times more revenue than other coin-operated machines. Bushnell estimated that the game earned US$35–40 per day, which he described as nothing he'd ever seen before in the coin-operated entertainment industry at the time. The game's earning power resulted in an increase in the number of orders Atari received. This provided Atari with a steady source of income; the company sold the machines at three times the cost of production. By 1973, the company had filled 2,500 orders, and, at the end of 1974, sold more than 8,000 units. The arcade cabinets have since become collector's items with the cocktail-table version being the rarest. Soon after the game's successful testing at Andy Capp's Tavern, other companies began visiting the bar to inspect it. Similar games appeared on the market three months later, produced by companies like Ramtek and Nutting Associates. Atari could do little against the competitors as they had not initially filed for patents on the solid state technology used in the game. When the company did file for patents, complications delayed the process. As a result, the market consisted primarily of ""Pong" clones"; author Steven Kent estimated that Atari had produced less than a third of the machines. Bushnell referred to the competitors as "Jackals" because he felt they had an unfair advantage. His solution to competing against them was to produce more innovative games and concepts.
"Home Pong" was an instant success following its limited 1975 release through Sears; around 150,000 units were sold that holiday season. The game became Sears' most successful product at the time, which earned Atari a Sears Quality Excellence Award. Similar to the arcade version, several companies released clones to capitalize on the home console's success, many of which continued to produce new consoles and video games. Magnavox re-released their Odyssey system with simplified hardware and new features, and would later release updated versions. Coleco entered the video game market with their Telstar console; it features three "Pong" variants and was also succeeded by newer models. Nintendo released the Color TV Game 6 in 1977, which plays six variations of electronic tennis. The next year, it was followed by an updated version, the Color TV Game 15, which features fifteen variations. The systems were Nintendo's entry into the home video game market and the first to produce themselves—they had previously licensed the Magnavox Odyssey. The dedicated "Pong" consoles and the numerous clones have since become varying levels of rare; Atari's "Pong" consoles are common, while APF Electronics' TV Fun consoles are moderately rare. Prices among collectors, however, vary with rarity; the Sears Tele-Games versions are often cheaper than those with the Atari brand.
Several publications consider "Pong" the game that launched the video game industry as a lucrative enterprise. Video game author David Ellis sees the game as the cornerstone of the video game industry's success, and called the arcade game "one of the most historically significant" titles. Kent attributes the "arcade phenomenon" to "Pong" and Atari's games that followed it, and considers the release of the home version the successful beginning of home video game consoles. Bill Loguidice and Matt Barton of Gamasutra referred to the game's release as the start of a new entertainment medium, and commented that its simple, intuitive gameplay made it a success. Many of the companies that produced their own versions of "Pong" eventually became well-known within the industry. Nintendo entered the video game market with clones of "Home Pong". The revenue generated from them—each system sold over a million units—helped the company survive a difficult financial time, and spurred them to pursue video games further. After seeing the success of "Pong", Konami decided to break into the arcade game market and released its first title, "Maze". Its moderate success drove the company to develop more titles.
Sequels and remakes.
Bushnell felt the best way to compete against imitators was to create better products, leading Atari to produce sequels in the years followings the original's release: "Pong Doubles", "Super Pong", "Ultra Pong", "Quadrapong", and "Pin-Pong". The sequels feature similar graphics, but include new gameplay elements; for example, "Pong Doubles" allows four players to compete in pairs, while "Quadrapong" has them compete against each other in a four way field. Bushnell also conceptualized a free-to-play version of "Pong" to entertain children in a Doctor's office. He initially titled it "Snoopy Pong" and fashioned the cabinet after Snoopy's doghouse with the character on top, but retitled it to "Puppy Pong" and altered Snoopy to a generic dog to avoid legal action. Bushnell later used the game in his chain of Chuck E. Cheese's restaurants. In 1976, Atari released "Breakout", a single-player variation of "Pong" where the object of the game is to remove bricks from a wall by hitting them with a ball. Like "Pong", "Breakout" was followed by numerous clones that copied the gameplay: "Arkanoid", "Alleyway", "Break 'Em All".
Atari remade the game on numerous platforms. In 1977, "Pong" and several variants of the game were featured in "Video Olympics", one of the original release titles for the Atari 2600. "Pong" has also been included in several Atari compilations on platforms including the Sega Mega Drive, PlayStation Portable, Nintendo DS, and personal computer. Through an agreement with Atari, Bally Gaming and Systems developed a slot machine version of the game. The Atari developed "TD Overdrive" includes "Pong" as an extra game to be played during the loading screen. In 1999, the game was remade for home computers and the PlayStation with 3D graphics and power-ups.
In popular culture.
"Pong" has appeared in several facets of popular culture. The game is prominently featured in episodes of television series: "That '70s Show", "King of the Hill", and "Saturday Night Live". In 2006, an American Express commercial featured Andy Roddick in a tennis match against the white, in-game paddle. Other video games have also referenced and parodied "Pong"; for example "Neuromancer" for the Commodore 64 and "" for the Xbox 360. The concert event Video Games Live has performed audio from "Pong" as part of a special retro "Classic Arcade Medley". Frank Black's song "Whatever Happened to Pong?" on the album "Teenager of the Year" heavily references the game's elements.
Dutch design studio Buro Vormkrijgers created a "Pong"-themed clock as a fun project within their offices. After the studio decided to manufacture it for retail, Atari took legal action in February 2006. The two companies eventually reached an agreement in which Buro Vormkrijgers could produce a limited number under license.
In 1999, French artist Pierre Huyghe created an installation entitled "Atari Light", in which two people use handheld gaming devices to play "Pong" on an illuminated ceiling. The work was shown at the Venice Biennale in 2001, and the Museo de Arte Contemporáneo de Castilla y León in 2007.
The game was included in the London Barbican Art Gallery's 2002 Game On exhibition meant to showcase the various aspects of video game history, development, and culture.
Pong was shown in the 2008 Disney film 'Wall-E'. The two main characters, the robots 'Wall-E' and 'Eve' are shown in front of the game as 'Wall-E' plays the game by himself as one of many attempts to awaken 'Eve' from her sleep mode. The version shown does not match the appearance of the original game, but rather one of its countless imitations.
Air French Band video "Kelly Watch the Stars" features the band playing them in a retro TV.

</doc>
<doc id="24949" url="http://en.wikipedia.org/wiki?curid=24949" title="Post office">
Post office

A post office is a customer service facility forming part of a national postal system. Post offices offer mail-related services such as acceptance of letters and parcels; provision of post office boxes; and sale of postage stamps, packaging, and stationery. In addition, many post offices offer additional services: providing and accepting government forms (such as passport applications), processing government services and fees (such as road tax), and banking services (such as savings accounts and money orders). The chief administrator of a post office is a postmaster.
Prior to the advent of postal and ZIP codes, postal systems would route items to a specific post office for receipt or delivery. In 19th-century America, this often led to smaller communities being renamed after their post offices, particularly after the Post Office Department ceased to permit duplicate station names within a state.
Name.
The term "post office" or "post-office" has been in use since the 1650s, shortly after the legalization of private mail service in England in 1635. In early Modern England, post riders – mounted couriers – were placed ("posted") every few hours along post roads at "posting houses" or "post houses" between major cities ("post towns"). These stables or inns permitted important correspondence to travel without delay. In early America, post offices were also known as "stations". This term and "post house" fell from use as horse and coach service was replaced by railways, aircraft, and automobiles.
Today, "post office" usually refers to postal facilities providing customer service. The term "General Post Office" is sometimes used for the national headquarters of a postal service, even if it does not provide customer service within the building. A postal facility used exclusively for processing mail is instead known as sorting office or delivery office, which may have a large central area known as a "sorting" or "postal hall". Integrated facilities combining mail processing with railway stations or airports are known as mail exchanges.
History.
There is evidence of corps of royal couriers disseminating the decrees of the Egyptian pharaohs as early as 2,400 BC and the service may greatly precede even that date. Similarly, organized systems of posthouses providing swift mounted courier service seems quite ancient, although sources vary as to precisely who initiated the practice. Certainly, by the time of the Persian Empire, a system of Chapar-Khaneh existed along the Royal Road. The 2nd-Century BC Mauryan and Han dynasties established similar systems in India and China. Suetonius credited Augustus with regularizing the Roman network, the "cursus publicus". Local officials were obliged to provide couriers who would be responsible for their message's entire course. Locally maintained post houses (Latin: "stationes") privately owned rest houses (Latin: "mansiones") were obliged or honored to care for them along their way. Diocletian later established two parallel systems: one providing fresh horses or mules for urgent correspondence and another providing sturdy oxen for bulk shipments. Procopius, though not unbiased, records that this system remained largely intact was dismantled in the surviving empire by Justinian in the 6th Century.
The Princely House of Thurn and Taxis initiated regular mail service from Brussels in the 16th century, directing the Imperial Post of the Holy Roman Empire. The British Postal Museum claims that the oldest functioning post office in the world is on High Street in Sanquhar, Scotland . This post office has functioned continuously since 1712, an era in which horses and stage coaches were used to carry mail.
In parts of Europe, special Postal censorship offices were known as Cabinets Noirs.
The first government post office in Zagreb was established in 1831.[2] The rise of mail volume, as well as the introduction of telegraph in 1850 and a public telephone system in 1887,[3] created a pressing need for a new post office building.[2]
Unstaffed postal facilities.
In many jurisdictions, mail boxes and post office boxes have long been in widespread use for dropoff and pickup (respectively) of mail and small packages outside of post offices or when offices are closed. Deutsche Post introduced the Packstation for package delivery (both dropoff and pickup) in 2001. In the 2000s, the United States Postal Service began to install Automated Postal Centers (APCs) in many locations both in post offices (for when they are closed or busy) and in retail locations. APCs can print postage and accept mail and small packages.

</doc>
<doc id="24951" url="http://en.wikipedia.org/wiki?curid=24951" title="PlayStation 3">
PlayStation 3

The PlayStation 3 (PS3) is a home video game console produced by Sony Computer Entertainment. It is the successor to PlayStation 2, as part of the PlayStation series. It competes with Microsoft's Xbox 360 and Nintendo's Wii as part of the seventh generation of video game consoles. It was first released on November 11, 2006, in Japan, with international markets following shortly thereafter.
The console was first officially announced at the Electronic Entertainment Expo 2005, and was released at the end of 2006. It was the first console to use Blu-ray Disc as its primary storage medium. Major features of the console include its unified online gaming service, PlayStation Network, and its connectivity with PlayStation Portable and PlayStation Vita, In September 2009 the updated PlayStation 3 "Slim", was released. This "Slim" is lighter and thinner than the original version, which notably featured a re-designed logo and marketing design. A further refined "Super Slim" design was released in late 2012. As of November 2, 2013, PlayStation 3 has sold 80 million units worldwide. Its successor, PlayStation 4, was released on November 15, 2013, in North America and in Europe on November 29, 2013. Following the release of PlayStation 4, Sony has stated that they will continue to support PlayStation 3 until 2015.
The PlayStation Now service can be used to stream a selection of PlayStation 3 games on devices such as PlayStation 4, PlayStation Vita, and PlayStation 3 itself.
History.
Sony officially unveiled PlayStation 3 (then marketed as PLAYSTATION 3) to the public on May 16, 2005, at the E3 2005 conference, along with a 'boomerang' shaped prototype design of the Sixaxis controller. A functional version of the system was not present there,
nor at the Tokyo Game Show in September 2005, although demonstrations (such as "") were held at both events on software development kits and comparable personal computer hardware. Video footage based on the predicted PlayStation 3 specifications was also shown (notably a "Final Fantasy VII" tech demo).
The initial prototype shown in May 2005 featured two HDMI ports, three Ethernet ports and six USB ports; however, when the system was shown again a year later at E3 2006, these were reduced to one HDMI port, one Ethernet port and four USB ports, presumably to cut costs. Two hardware configurations were also announced for the console: a 20 GB model and a 60 GB model, priced at US$499 (€499) and US$599 (€599), respectively. The 60 GB model was to be the only configuration to feature an HDMI port, Wi-Fi internet, flash card readers and a chrome trim with the logo in silver. Both models were announced for a simultaneous worldwide release: November 11, 2006, for Japan and November 17, 2006, for North America and Europe.
On September 6, 2006, Sony announced that PAL region PlayStation 3 launch would be delayed until March 2007, because of a shortage of materials used in the Blu-ray drive. At the Tokyo Game Show on September 22, 2006, Sony announced that it would include an HDMI port on the 20 GB system, but a chrome trim, flash card readers, silver logo and Wi-Fi would not be included. Also, the launch price of the Japanese 20 GB model was reduced by over 20%, and the 60 GB model was announced for an open pricing scheme in Japan. During the event, Sony showed 27 playable PS3 games running on final hardware.
Launch.
PlayStation 3 was first released in Japan on November 11, 2006, at 07:00. According to Media Create, 81,639 PS3 systems were sold within 24 hours of its introduction in Japan. Soon after its release in Japan, PS3 was released in North America on November 17, 2006. Reports of violence surrounded the release of PS3. A customer was shot, campers were robbed at gunpoint, customers were shot in a drive-by shooting with BB guns, and 60 campers fought over 10 systems.
The console was originally planned for a global release through November, but at the start of September the release in Europe and the rest of the world was delayed until March. With it being a somewhat last-minute delay, some companies had taken deposits for pre-orders, at which Sony informed customers that they were eligible for full refunds or could continue the pre-order. On January 24, 2007, Sony announced that PlayStation 3 would go on sale on March 23, 2007, in Europe, Australia, the Middle East, Africa and New Zealand. The system sold about 600,000 units in its first two days. On March 7, 2007, the 60 GB PlayStation 3 launched in Singapore with a price of S$799. The console was launched in South Korea on June 16, 2007, as a single version equipped with an 80 GB hard drive and IPTV.
PS3 Slim and console rebranding.
Following speculation that Sony was working on a 'slim' model, Sony officially announced the PS3 CECH-2000 model on August 18, 2009, at the Sony Gamescom press conference. New features included a slimmer form factor, decreased power consumption, and a quieter cooling system. It was released in major territories by September 2009. As part of the release for the slim model, the console logo ceased using the "Spider-Man font" (the same font used for the title of Sony's Spider-Man 3) and the capitalized "PLAYSTATION 3". It instead reverted to a more traditional PlayStation- and PlayStation 2-like 'PlayStation 3' logo with "PS3" imprinted on the console. Along with the redesigning of the console and logo, the boot screen of all consoles changed from "Sony Computer Entertainment" to "PS3 PlayStation 3", with a new chime and the game start splash screen being dropped. The cover art and packaging of games was also changed.
Super Slim model.
In September 2012 at the Tokyo Game Show, Sony announced that a new, slimmer PS3 redesign (CECH-4000) was due for release in late 2012 and that it would be available with either a 250 GB or 500 GB hard drive. Three versions "Super Slim" model were revealed: one with a 500 GB hard drive, a second with a 250 GB hard drive which is not available in PAL regions, and a third with a 12 GB flash storage that was only available in PAL regions. The storage of 12 GB model is upgradable with an official standalone 250 GB hard drive. A vertical stand was also released for the model. In the United Kingdom, the 500 GB model was released on September 28, 2012; and the 12 GB model was released on October 12, 2012. In the United States, the PS3 Super Slim was first released as a bundled console. The 250 GB was model was bundled with "Game of the Year" edition of ' and released on September 25, 2012; and the 500 GB model was bundled with "Assassin's Creed III" and released on October 30, 2012. In Japan, the black colored Super Slim model was released on October 4, 2012; and the white colored Super Slim model was released on November 22, 2012. The Super Slim model is 20 percent smaller and 25 percent lighter than the Slim model and features a manual sliding disc cover instead of a motorized slot-loading disc cover of the Slim model. The white colored Super Slim model was released in the United States on January 27, 2013 as part of the "Instant Game Collection Bundle". The "Garnet Red" and "Azurite Blue" colored models were launched in Japan on February 28, 2013. The "Garnet Red" version was released in North America on March 12, 2013 as part of the ' bundle with 500 GB storage and contained "God of War: Ascension" as well as the "God of War Saga". The "Azurite Blue" model was released as a Gamestop exclusive with 250GB storage.
Games.
PlayStation 3 launched in North America with 14 titles, with another three being released before the end of 2006. After the first week of sales it was confirmed that ' from Insomniac Games was the top-selling launch game in North America. The game was heavily praised by numerous video game websites, including GameSpot and IGN, both of whom awarded it their PlayStation 3 Game of the Year award for 2006. Some titles missed the launch window and were delayed until early 2007, such as ', "F.E.A.R." and "Sonic the Hedgehog". During the Japanese launch, "Ridge Racer 7" was the top-selling game, while ' also fared well in sales, both of which were offerings from Namco Bandai Games. PlayStation 3 launched in Europe with 24 titles, including ones that were not offered in North American and Japanese launches, such as "Formula One Championship Edition", "MotorStorm" and "Virtua Fighter 5". ' and "MotorStorm" were the most successful titles of 2007, and both games subsequently received sequels in the form of "Resistance 2" and "".
At E3 2007, Sony was able to show a number of their upcoming video games for PlayStation 3, including "Heavenly Sword", "Lair", ', "Warhawk" and '; all of which were released in the third and fourth quarters of 2007. They also showed off a number of titles that were set for release in 2008 and 2009; most notably "Killzone 2", "Infamous", "Gran Turismo 5 Prologue", "LittleBigPlanet" and '. A number of third-party exclusives were also shown, including the highly anticipated ', alongside other high-profile third-party titles such as "Grand Theft Auto IV", "", "Assassin's Creed", "Devil May Cry 4" and "Resident Evil 5". Two other important titles for PlayStation 3, "Final Fantasy XIII" and "Final Fantasy Versus XIII", were shown at TGS 2007 in order to appease the Japanese market.
Sony have since launched their budget range of PlayStation 3 titles, known as the Greatest Hits range in North America, the Platinum range in Europe and Australia and The Best range in Japan. Among the titles available in the budget range include ', "MotorStorm", ', ', "Call Of Duty 3", "Assassin's Creed" and "Ninja Gaiden Sigma". As of October 2009 ', ', "Devil May Cry 4", "Army of Two", ' and "" have also joined the list.
As of March 31, 2012, there have been 595 million games sold for PlayStation 3.
Stereoscopic 3D.
In December 2008, the CTO of Blitz Games announced that it would bring stereoscopic 3D gaming and movie viewing to Xbox 360 and PlayStation 3 with its own technology. This was first demonstrated publicly on PS3 using Sony's own technology in January 2009 at the Consumer Electronics Show. Journalists were shown "Wipeout HD" and "Gran Turismo 5 Prologue" in 3D as a demonstration of how the technology might work if it is implemented in the future. Firmware update 3.30 officially allowed PS3 titles to be played in 3D, requiring a compatible display for use. System software update 3.50 prepared it for 3D films. While the game itself must be programmed to take advantage of the 3D technology, titles may be patched to add in the functionality retroactively. Titles with such patches include "Wipeout HD", "Pain", and "Super Stardust HD".
Hardware.
PlayStation 3 is convex on its left side, with the PlayStation logo upright, when vertical (the top side is convex when horizontal) and has a glossy black finish. PlayStation designer Teiyu Goto stated that the Spider-Man-font-inspired logo "was one of the first elements SCEI president Ken Kutaragi decided on and the logo may have been the motivating force behind the shape of PS3".
On March 22, 2007, SCE and Stanford University released the Folding@home software for PlayStation 3. This program allows PS3 owners to lend the computing power of their consoles to help study the process of protein folding for disease research.
Use in supercomputing.
PS3's hardware has also been used to build supercomputers for high-performance computing. Fixstars Solutions sell a version of Yellow Dog Linux for PlayStation 3 (originally sold by Terra Soft Solutions). RapidMind produced a stream programming package for PS3, but were acquired by Intel in 2009. Also, on January 3, 2007, Dr. Frank Mueller, Associate Professor of Computer science at NCSU, clustered 8 PS3s. Mueller commented that the 256 MB of system RAM is a limitation for this particular application and is considering attempting to retrofit more RAM. Software includes: Fedora Core 5 Linux ppc64, MPICH2, OpenMP v 2.5, GNU Compiler Collection and CellSDK 1.1. As a more cost-effective alternative to conventional supercomputers, the U.S. military has purchased clusters of PS3 units for research purposes. Retail PS3 Slim units cannot be used for supercomputing, because PS3 Slim lacks the ability to boot into a third-party OS.
In November 2010 the Air Force Research Laboratory (AFRL) created a powerful supercomputer by connecting together 1,760 Sony PS3s which include 168 separate graphical processing units and 84 coordinating servers in a parallel array capable of performing 500 trillion floating-point operations per second (500 TFLOPS). As built the Condor Cluster was the 33rd largest supercomputer in the world and would be used to analyze high definition satellite imagery.
In December 2008, a group of hackers used a cluster of 200 PlayStation 3 computers to crack SSL authentication.
Technical specifications.
PlayStation 3 features a slot-loading 2x speed Blu-ray Disc drive for games, Blu-ray movies, DVDs, CDs and other optical media. It was originally available with hard drives of 20 and 60 GB (20 GB model was not available in PAL regions) but various sizes up to 500 GB have been made available since then (see: model comparison). All PS3 models have user-upgradeable 2.5" SATA hard drives.
PlayStation 3 uses the Cell microprocessor, designed by Sony, Toshiba and IBM, as its CPU, which is made up of one 3.2 GHz PowerPC-based "Power Processing Element" (PPE) and eight Synergistic Processing Elements (SPEs). The eighth SPE is disabled to improve chip yields. Only six of the seven SPEs are accessible to developers as the seventh SPE is reserved by the console's operating system. Graphics processing is handled by the NVIDIA RSX 'Reality Synthesizer', which can produce resolutions from 480i/576i SD up to 1080p HD. PlayStation 3 has 256 MB of XDR DRAM main memory and 256 MB of GDDR3 video memory for the RSX.
The system has Bluetooth 2.0 (with support for up to 7 bluetooth devices), Gigabit Ethernet, USB 2.0 and HDMI 1.4 built in on all currently shipping models. Wi-Fi networking is also built-in on all but the 20 GB models, while a flash card reader (compatible with Memory Stick, SD/MMC and CompactFlash/Microdrive media) is built-in on 60 GB and CECHExx 80 GB models.
Models.
PlayStation 3 has been produced in various models: the original, the Slim, and the Super Slim. Successive models have added or removed various features.
Controllers and accessories.
Numerous accessories for the console have been developed. These accessories include the wireless Sixaxis and DualShock 3 controllers, the Logitech Driving Force GT, the Logitech Cordless Precision Controller, the BD Remote, the PlayStation Eye camera, and the PlayTV DVB-T tuner/digital video recorder accessory.
At Sony's E3 press conference in 2006, the then standard wireless Sixaxis controller was announced. The controller was based on the same basic design as the PlayStation 2's DualShock 2 controller but was wireless, lacked vibration capabilities, had a built-in accelerometer (that could detect motion in three directional and three rotational axes; six in total, hence the name Sixaxis) and had a few cosmetic tweaks.
At its press conference at the 2007 Tokyo Game Show, Sony announced DualShock 3 (trademarked DUALSHOCK 3), a PlayStation 3 controller with the same function and design as Sixaxis, but with vibration capability included. Hands-on accounts describe the controller as being noticeably heavier than the standard Sixaxis controller and capable of vibration forces comparable to DualShock 2. It was released in Japan on November 11, 2007; in North America on April 5, 2008; in Australia on April 24, 2008; in New Zealand on May 9, 2008; in mainland Europe on July 2, 2008, and in the United Kingdom and Ireland on July 4, 2008.
During E3 2009, Sony unveiled plans to release a motion controller later to be named PlayStation Move at GDC 2010. It was released on September 15, 2010, in Europe; September 19, 2010, in North America and October 21, 2010, in Japan.
On October 13, 2010, Sony announced an official surround sound system for PS3 through the official PlayStation YouTube channel.
Questions regarding reliability.
According to Ars Technica, the number of PlayStation 3 consoles that have experienced failure is well within the normal failure rates in the consumer electronics industry; a 2009 study by SquareTrade, a warranty provider, found a two-year failure rate of 10% for PlayStation 3s.
In September 2009, BBC's "Watchdog" television program aired a report investigating the issue, calling it the "yellow light of death" (YLOD). Among the consoles that experienced the failure, they found that it usually occurred 18–24 months after purchase, while the standard Sony warranty covers one year after purchase. After this time period, PlayStation 3 owners can pay Sony a set fee for a refurbished console.
Sony claimed that, according to its statistics of returned consoles, approximately 0.5% of consoles were reported as showing the YLOD. In response to the televised report, Sony issued a document criticizing the program's accuracy and conclusions; specifically that the faults were evidence of a manufacturing defect. The document also complained that the report had been inappropriate in tone and might damage Sony's brand name.
Software.
System software.
Sony has included the ability for the operating system, referred to as "System Software", to be updated. The updates can be acquired in several ways:
The original PlayStation 3 also included the ability to install other operating systems, such as Linux. This was not included in the newer slim models and was removed from all older PlayStation 3 consoles with the release of firmware update 3.21 in April 2010. The functionality is now only available to users of original consoles who choose not to update their system software beyond version 3.15 or who have installed third-party, modified and unofficial versions of the firmware instead 
Graphical user interface.
The standard PlayStation 3 version of the XrossMediaBar (pronounced Cross Media Bar, or abbreviated XMB) includes nine categories of options. These are: "Users", "Settings", "Photo", "Music", "Video", "Game", "Network", "PlayStation Network" and "Friends" (similar to the PlayStation Portable media bar). A tenth "TV" category is displayed between "Music" and "Video" if PlayTV or torne is installed or if the console meets certain criteria to access select catch-up television services. By default, the "What's New" section of "PlayStation Network" is displayed when the system starts up. PS3 includes the ability to store various master and secondary user profiles, manage and explore photos with or without a musical slide show, play music and copy audio CD tracks to an attached data storage device, play movies and video files from the hard disk drive, an optical disc (Blu-ray Disc or DVD-Video) or an optional USB mass storage or Flash card, compatibility for a USB keyboard and mouse and a web browser supporting in/compatible file download function. Additionally, UPnP media will appear in the respective audio/video/photo categories if a compatible media server or DLNA server is detected on the local network. The Friends menu allows mail with emoticon and attached picture features and video chat which requires an optional PlayStation Eye or EyeToy webcam. The Network menu allows online shopping through the PlayStation Store and connectivity to PlayStation Portable via Remote Play.
Digital rights management.
PlayStation 3 console protects certain types of data and uses digital rights management to limit the data's use. Purchased games and content from the PlayStation Network store are governed by PlayStation's Network Digital Rights Management (NDRM). The NDRM allows users to access the data from up to 2 different PlayStation 3's that have been activated using a user's PlayStation Network ID. PlayStation 3 also limits the transfer of copy protected videos downloaded from its store to other machines and states that copy protected video "may not restore correctly" following certain actions after making a backup such as downloading a new copy protected movie.
Photo management.
Photo Gallery is an optional application to view, create and group photos from PS3, which is installed separately from the system software at 105 MB. It was introduced in system software version 2.60 and provides a range of tools for sorting through and displaying the system's pictures. The key feature of this application is that it can organize photos into groups according to various criteria. Notable categorizations are colors, ages, or facial expressions of the people in the photos. Slideshows can be viewed with the application, along with music and playlists. The software was updated with the release of system software version 3.40 allowing users to upload and browse photos on Facebook and Picasa.
PlayMemories is an optional stereoscopic 3D (and also standard) photo viewing application, which is installed from the PlayStation Store at 956 MB. The application is dedicated specifically to 3D photos and features the ability to zoom into 3D environments and change the angle and perspective of panoramas. It requires system software 3.40 or higher; 3D photos; a 3D HDTV, and an HDMI cable for the 3D images to be viewed properly.
Video services.
A new application was released as part of system software version 3.40 which allows users to edit videos on PlayStation 3 and upload them to the Internet. The software features basic video editing tools including the ability to cut videos and add music and captions. Videos can then be rendered and uploaded to video sharing websites such as Facebook and YouTube.
In addition to the video service provided by the Sony Entertainment Network the PlayStation 3 console has access to a variety of third party video services, dependent on region:
Since June 2009 VidZone has offered a free music video streaming service in Europe, Australia and New Zealand. In October 2009, Sony Computer Entertainment and Netflix announced that the Netflix streaming service would also be available on PlayStation 3 in the United States. A paid Netflix subscription was required for the service. The service became available in November 2009. Initially users had to use a free Blu-ray disc to access the service; however, in October 2010 the requirement to use a disc to gain access was removed.
In April 2010, support for MLB.tv was added, allowing MLB.tv subscribers to watch regular season games live in HD and access new interactive features designed exclusively for PSN.
In November 2010 access to the video and social networking site MUBI was enabled for European, New Zealand, and Australian users; the service integrates elements of social networking with rental or subscription video streaming, allowing users to watch and discuss films with other users. Also in November 2010 the video rental service VUDU, NHL GameCenter Live, and subscription service Hulu Plus launched on PlayStation 3 in the United States.
In August 2011, Sony in partnership with DirecTV added NFL Sunday Ticket. Then in October 2011, Best Buy launched an app for its CinemaNow service. In April 2012, Amazon.com launched an Amazon Instant Video app, accessible to Amazon Prime subscribers (in the US).
Upon reviewing the PlayStation and Netflix collaboration Pocket-Lint said "We've used the Netflix app on Xbox too and, as good as it is, we think the PS3 version might have the edge here." and stated that having Netflix and LoveFilm on PlayStation is "mind-blowingly good."
In July 2013, YuppTV OTT player launched its branded application on the PS3 computer entertainment system in the United States.
OtherOS support.
PlayStation 3 initially shipped with the ability to install an alternative operating system alongside the main system software; Linux and other Unix based operating systems were available. The hardware allowed access to six of the seven "Synergistic Processing Elements" of the Cell microprocessor, but not the RSX 'Reality Synthesizer' graphics chip.
The 'OtherOS' functionality was not present in the updated PS Slim models, and the feature was subsequently removed from previous versions of the PS3 as part of the machine's firmware update version 3.21 which was released on April 1, 2010; Sony cited security concerns as the rationale. The firmware update 3.21 was mandatory for access to the PlayStation Network. The removal caused some controversy; as the update removed officially advertised features from already sold products, and gave rise to several class action lawsuits aimed at making Sony return the feature or provide compensation.
On December 8, 2011, U.S. District Judge Richard Seeborg dismissed the last remaining count of the class action lawsuit (other claims in the suit had previously been dismissed), stating: "As a legal matter, [..] plaintiffs have failed to allege facts or articulate a theory on which Sony may be held liable."
As of January 2014 the U.S. Court of Appeals for the Ninth Circuit partially reversed the dismissal and have sent the case back to the district court.
Leap year bug.
On March 1, 2010 (UTC), many of the original (non-Slim) PlayStation 3 models worldwide were experiencing errors related to their internal system clock. The error had a multitude of symptoms. Initially, the main problem seemed to be the inability to connect to the PlayStation Network. However, the root cause of the problem was unrelated to the PlayStation Network, since even users who had never been online also had problems playing installed offline games (which queried the system timer as part of startup) and using system themes. At the same time many users noted that the console's clock had gone back to December 31, 1999. The event was nicknamed the ApocalyPS3, a play on the word "apocalypse".
The error code displayed was typically 8001050F and affected users were unable to sign in, play games, use dynamic themes and view/sync trophies. The problem only resided within the 1st through to the 3rd generation original PS3 units while the newer "Slim" models were unaffected because of different internal hardware for the clock.
Sony confirmed that there was an error and stated that they were narrowing down the issue and were continuing to work to restore service. By March 2 (UTC), 2010, owners of original PS3 models could connect to PSN successfully and the clock no longer showed December 31, 1999. Sony stated that the affected models incorrectly identified 2010 as a leap year, because of a bug in the BCD method of storing the date. However, for some users, the hardware's operating system clock (mainly updated from the internet and not associated with the internal clock) needed to be updated manually or by re-syncing it via the internet.
On June 29, 2010, Sony released PS3 system software update 3.40, which improved the functionality of the internal clock to properly account for leap years.
Features.
PlayStation Portable connectivity.
PlayStation Portable can connect with PlayStation 3 in many ways, including in-game connectivity. For example, "Formula One Championship Edition", a racing game, was shown at E3 2006 using a PSP as a real-time rear-view mirror. In addition, users are able to download original PlayStation format games from the PlayStation Store, transfer and play them on PSP as well as PS3 itself. It is also possible to use the Remote Play feature to play these and some PlayStation Network games, remotely on PSP over a network or internet connection.
Sony has also demonstrated PSP playing back video content from PlayStation 3 hard disk across an ad hoc wireless network. This feature is referred to as Remote Play located under the browser icon on both PlayStation 3 and PlayStation Portable. Remote play has since expanded to allow remote access to PS3 via PSP from any wireless access point in the world.
PlayStation Network.
PlayStation Network is the unified online multiplayer gaming and digital media delivery service provided by Sony Computer Entertainment for PlayStation 3 and PlayStation Portable, announced during the 2006 PlayStation Business Briefing meeting in Tokyo. The service is always connected, free, and includes multiplayer support. The network enables online gaming, the PlayStation Store, PlayStation Home and other services. PlayStation Network uses real currency and PlayStation Network Cards as seen with the PlayStation Store and PlayStation Home.
PlayStation Plus.
PlayStation Plus (commonly abbreviated "PS+" and occasionally referred to as "PSN Plus") is a premium PlayStation Network subscription service that was officially unveiled at E3 2010 by Jack Tretton, President and CEO of SCEA. Rumors of such service had been in speculation since Kaz Hirai's announcement at TGS 2009 of a possible paid service for PSN but with the current PSN service still available. Launched alongside PS3 firmware 3.40 and PSP firmware 6.30 on June 29, 2010, the paid-for subscription service provides users with enhanced services on the PlayStation Network, on top of the current PSN service which is still available with all of its features. These enhancements include the ability to have demos, game and system software updates download automatically to PlayStation 3. Subscribers also get early or exclusive access to some betas, game demos, premium downloadable content and other PlayStation Store items. North American users also get a free subscription to Qore. Users may choose to purchase either a one-year or a three-month subscription to PlayStation Plus.
PlayStation Store.
The PlayStation Store is an online virtual market available to users of Sony's PlayStation 3 (PS3) and PlayStation Portable (PSP) game consoles via the PlayStation Network. The Store offers a range of downloadable content both for purchase and available free of charge. Available content includes full games, add-on content, playable demos, themes and game and movie trailers. The service is accessible through an icon on the XMB on PS3 and PSP. The PS3 store can also be accessed on PSP via a Remote Play connection to PS3. The PSP store is also available via the PC application, Media Go. As of September 24, 2009, there have been over 600 million downloads from the PlayStation Store worldwide.
The PlayStation Store is updated with new content each Tuesday in North America, and each Wednesday in PAL regions. In May 2010 this was changed from Thursdays to allow PSP games to be released digitally, closer to the time they are released on UMD.
What's New.
What's New was announced at Gamescom 2009 and was released on September 1, 2009, with PlayStation 3 system software 3.0. The feature was to replace the existing [Information Board], which displayed news from the PlayStation website associated with the user's region. The concept was developed further into a major PlayStation Network feature, which interacts with the [Status Indicator] to display a ticker of all content, excluding recently played content (currently in North America and Japan only).
The system displays the What's New screen by default instead of the [Games] menu (or [Video] menu, if a movie was inserted) when starting up. What's New has four sections: "Our Pick", "Recently Played", latest information and new content available in PlayStation Store. There are four kinds of content the What's New screen displays and links to, on the sections. "Recently Played" displays the user's recently played games and online services only, whereas, the other sections can contain website links, links to play videos and access to selected sections of the PlayStation Store.
The PlayStation Store icons in the [Game] and [Video] section act similarly to the What's New screen, except that they only display and link to games and videos in the PlayStation Store, respectively.
PlayStation Home.
PlayStation Home is a virtual 3D social networking service for the PlayStation Network. Home allows users to create a custom avatar, which can be groomed realistically. Users can edit and decorate their personal apartments, avatars or club houses with free, premium or won content. Users can shop for new items or win prizes from PS3 games, or Home activities. Users interact and connect with friends and customise content in a virtual world. Home also acts as a meeting place for users that want to play multiplayer games with others.
A closed beta began in Europe from May 2007 and expanded to other territories soon after. Home was delayed and expanded several times before initially releasing. The Open Beta test was started on December 11, 2008. Home is available directly from the PlayStation 3 XrossMediaBar. Membership is free and requires a PSN account.
Home features places to meet and interact, dedicated game spaces, developer spaces, company spaces and events. The service undergoes a weekly maintenance and frequent updates. As of August 2011, Home has been downloaded by over 23 million users. 
Life with PlayStation.
Life with PlayStation, released on September 18, 2008 to succeed Folding@home, was retired November 6, 2012. "Life with PlayStation" used virtual globe data to display news and information by city. Along with Folding@home functionality, the application provided access to three other information "channels", the first being the "Live Channel" offering news headlines and weather which were provided by Google News, The Weather Channel, the University of Wisconsin–Madison Space Science and Engineering Center, among other sources. The second channel was the World Heritage channel which offered historical information about historical sites. The third channel was the United Village channel. United Village was designed to share information about communities and cultures worldwide. An update allowed video and photo viewing in the application. The fourth channel was the USA exclusive PlayStation Network Game Trailers Channel for direct streaming of game trailers.
Outage.
On April 20, 2011, Sony shut down the PlayStation Network and Qriocity for a prolonged interval, revealing on April 23 that this was due to "an external intrusion on our system". Sony later revealed that the personal information of 77 million users might have been taken, including: names; addresses; countries; email addresses; birthdates; PSN/Qriocity logins, passwords and handles/PSN online IDs.<ref name="PSN/Qriocity Service Update"></ref> They also stated that it was possible that users' profile data, including purchase history and billing address, and PlayStation Network/Qriocity password security answers may have been obtained. There was no evidence that any credit card data had been taken, but the possibility could not be ruled out, and Sony advised customers that their credit card data may have been obtained. Additionally, the credit card numbers were encrypted and Sony never collected the three digit CVC or CSC number from the back of the credit cards which is required for authenticating some transactions. In response to the incident, Sony announced a "Welcome Back" program, 30 days free membership of PlayStation Plus for all PSN members, two free downloadable PS3 games, and a free one-year enrollment in an identity theft protection program.
Sales and production costs.
Although its PlayStation predecessors had been very dominant against the competition and were hugely profitable for Sony, PlayStation 3 had an inauspicious start, and Sony chairman and CEO Sir Howard Stringer initially could not convince investors of a turnaround in its fortunes. The PS3 lacked the unique gameplay of the more affordable Wii which became that generation's most successful console in terms of units sold. Furthermore, PS3 had to compete directly with Xbox 360 which had a market head start, and as a result the platform no longer had exclusive titles that the PS2 enjoyed such as the "Grand Theft Auto" and "Final Fantasy" series (regarding cross-platform games, Xbox 360 versions were generally considered superior in 2006, although by 2008 the PS3 versions had reached parity or surpassed), and it took longer than expected for PS3 to enjoy strong sales and close the gap with Xbox 360. Sony also continued to lose money on each PS3 sold through 2010, although the redesigned "slim" PS3 has cut these losses since then.
PlayStation 3's initial production cost is estimated by iSuppli to have been US$805.85 for the 20 GB model and US$840.35 for the 60 GB model. However, they were priced at US$499 and US$599 respectively, meaning that units may have been sold at an estimated loss of $306 or $241 depending on model, if the cost estimates were correct, and thus may have contributed to Sony's games division posting an operating loss of ¥232.3 billion (US$1.97 billion) in the fiscal year ending March 2007. In April 2007, soon after these results were published, Ken Kutaragi, President of Sony Computer Entertainment, announced plans to retire. Various news agencies, including "The Times" and "The Wall Street Journal" reported that this was due to poor sales, while SCEI maintains that Kutaragi had been planning his retirement for six months prior to the announcement.
In January 2008, Kaz Hirai, CEO of Sony Computer Entertainment, suggested that the console may start making a profit by early 2009, stating that, "the next fiscal year starts in April and if we can try to achieve that in the next fiscal year that would be a great thing" and that "[profitability] is not a definite commitment, but that is what I would like to try to shoot for". However, market analysts Nikko Citigroup have predicted that PlayStation 3 could be profitable by August 2008. In a July 2008 interview, Hirai stated that his objective is for PlayStation 3 to sell 150 million units by its ninth year, surpassing PlayStation 2's sales of 140 million in its nine years on the market. In January 2009 Sony announced that their gaming division was profitable in Q3 2008.
Since the system's launch, production costs have been reduced significantly as a result of phasing out the Emotion Engine chip and falling hardware costs. The cost of manufacturing Cell microprocessors has fallen dramatically as a result of moving to the 65 nm production process, and Blu-ray Disc diodes have become cheaper to manufacture. As of January 2008, each unit cost around $400 to manufacture; by August 2009, Sony had reduced costs by a total of 70%, meaning it only costs Sony around $240 per unit.
Critical reception.
Early PlayStation 3 reviews after launch were critical of its high price and lack of quality games. Game developers regarded the architecture as difficult to program for. PS3 was, however, commended for its hardware including its Blu-ray home theater capabilities and graphics potential.
Critical and commercial reception to PS3 improved over time, after a series of price revisions, Blu-ray's victory over HD DVD, and the release of several well received titles. Ars Technica's original launch review gave PS3 only a 6/10, but second review of the console in June 2008 rated it a 9/10. In September 2009, IGN named PlayStation 3 the 15th best gaming console of all time, behind both of its competitors: Wii (10th) and Xbox 360 (6th). However, PS3 has won IGN's "Console Showdown"—based on which console offers the best selection of games released during each year—in three of the four years since it began (2008, 2009 and 2011, with Xbox winning in 2010). IGN judged PlayStation 3 to have the best game line-up of 2008, based on their review scores in comparison to those of Wii and Xbox 360. In a comparison piece by PC mag's Will Greenwald in June 2012, PS3 was selected as an overall better console compared to Xbox 360.
Pocket-lint said of the console "The PS3 has always been a brilliant games console," and that "For now, this is just about the best media device for the money."
Original model.
PS3 was given the number-eight spot on "PC World" magazine's list of "The Top 21 Tech Screwups of 2006", where it was criticized for being "Late, Expensive and Incompatible". GamesRadar ranked PS3 as the top item in a feature on game-related PR disasters, asking how Sony managed to "take one of the most anticipated game systems of all time and — within the space of a year — turn it into a hate object reviled by the entire internet", but added that despite its problems the system has "untapped potential". "Business Week" summed up the general opinion by stating that it was "more impressed with what [the PlayStation 3] could do than with what it currently does".
Developers also found the machine difficult to program for. In 2007, Gabe Newell of Valve said "The PS3 is a total disaster on so many levels, I think it's really clear that Sony lost track of what customers and what developers wanted". He continued "I'd say, even at this late date, they should just cancel it and do a do over. Just say, 'This was a horrible disaster and we're sorry and we're going to stop selling this and stop trying to convince people to develop for it'". Doug Lombardi VP of Marketing for Valve has since stated that they are interested in developing for the console and are looking to hire talented PS3 programmers for future projects. He later restated Valve's position, "Until we have the ability to get a PS3 team together, until we find the people who want to come to Valve or who are at Valve who want to work on that, I don't really see us moving to that platform". At Sony's E3 2010 press conference, Newell made a live appearance to recant his previous statements, citing Sony's move to make the system more developer friendly, and to announce that Valve would be developing "Portal 2" for the system. He also claimed that the inclusion of Steamworks (Valve's system to automatically update their software independently) would help to make the PS3 version of "Portal 2" the best console version on the market.
Activision Blizzard CEO Bobby Kotick has criticized PS3's high development costs and inferior attach rate and return to that of Xbox 360 and Wii. He believes these factors are pushing developers away from working on the console. In an interview with "The Times" Kotick stated "I'm getting concerned about Sony; the PlayStation 3 is losing a bit of momentum and they don't make it easy for me to support the platform." He continued, "It's expensive to develop for the console, and the Wii and the Xbox are just selling better. Games generate a better return on invested capital (ROIC) on the Xbox than on the PlayStation." Kotick also claimed that Activision Blizzard may stop supporting the system if the situation is not addressed. "[Sony has] to cut the [PS3's retail] price, because if they don't, the attach rates are likely to slow. If we are being realistic, we might have to stop supporting Sony." Kotick received heavy criticism for the statement, notably from developer Bioware who questioned the wisdom of the threatened move, and referred to the statement as "silly."
Despite the initial negative press, several websites have given the system very good reviews mostly regarding its hardware. CNET United Kingdom praised the system saying, "the PS3 is a versatile and impressive piece of home-entertainment equipment that lives up to the hype [...] the PS3 is well worth its hefty price tag." CNET awarded it a score of 8.8 out of 10 and voted it as its number one "must-have" gadget, praising its robust graphical capabilities and stylish exterior design while criticizing its limited selection of available games. In addition, both "Home Theater Magazine" and "Ultimate AV" have given the system's Blu-ray playback very favorable reviews, stating that the quality of playback exceeds that of many current standalone Blu-ray Disc players.
In an interview, Kazuo Hirai, chairman of Sony Computer Entertainment argued for the choice of a complex architecture. Hexus Gaming reviewed the PAL version and summed the review up by saying, "as the PlayStation 3 matures and developers start really pushing it, we'll see the PlayStation 3 emerge as the console of choice for gaming." At GDC 2007, Shiny Entertainment founder Dave Perry stated, "I think that Sony has made the best machine. It's the best piece of hardware, without question".
Slim model and rebranding.
The PlayStation 3 Slim received extremely positive reviews as well as a boost in sales; less than 24 hours after its announcement, PS3 Slim took the number-one bestseller spot on Amazon.com in the video games section for fifteen consecutive days. It regained the number-one position again one day later. PS3 Slim also received praise from PC World giving it a 90 out of 100 praising its new repackaging and the new value it brings at a lower price as well as praising its quietness and the reduction in its power consumption. This is in stark contrast to the original PS3's launch in which it was given position number-eight on their "The Top 21 Tech Screwups of 2006" list.
CNET awarded PS3 Slim four out of five stars praising its Blu-ray capabilities, 120 GB hard drive, free online gaming service and more affordable pricing point, but complained about the lack of backward compatibility for PlayStation 2 games. TechRadar gave PS3 Slim four and a half stars out of five praising its new smaller size and summed up its review stating "Over all, the PS3 Slim is a phenomenal piece of kit. It's amazing that something so small can do so much". However, they criticized the exterior design and the build quality in relation to the original model.
Eurogamer called it "a product where the cost-cutting has - by and large - been tastefully done" and said "It's nothing short of a massive win for Sony."
Super Slim model.
The Super Slim model of PS3 has received positive reviews. Gaming website "Spong" praised the new Super Slim's quietness, stating "The most noticeable noise comes when the drive seeks a new area of the disc, such as when starting to load a game, and this occurs infrequently." They added that the fans are quieter than that of Slim, and went on to praise the new smaller, lighter size. 
Criticism was placed on the new disc loader, stating: "The cover can be moved by hand if you wish, there's also an eject button to do the work for you, but there is no software eject from the triangle button menus in the Xross Media Bar (XMB) interface. In addition, you have to close the cover by hand, which can be a bit fiddly if it's upright, and the PS3 won't start reading a disc unless you do [close the cover]." They also said there is no real drop in retail price.
Tech media website CNET gave new Super Slim 4 out of 5 stars ("Excellent"), saying "The Super Slim PlayStation 3 shrinks a powerful gaming machine into an even tinier package while maintaining the same features as its predecessors: a great gaming library and a strong array of streaming services [...]", whilst also criticising the "cheap" design and disc-loader, stating: "Sometimes [the cover] doesn't catch and you feel like you're using one of those old credit card imprinter machines. In short, it feels cheap. You don't realize how convenient autoloading disc trays are until they're gone. Whether it was to cut costs or save space, this move is ultimately a step back."
The criticism also was due to price, stating the cheapest Super Slim model was still more expensive than the cheapest Slim model, and that the smaller size and bigger hard drive shouldn't be considered an upgrade when the hard drive on a Slim model is easily removed and replaced. They did praise that the hard drive of the Super Slim model is "the easiest yet. Simply sliding off the side panel reveals the drive bay, which can quickly be unscrewed."
They also stated that whilst the Super Slim model is not in any way an upgrade, it could be an indicator as to what's to come. "It may not be revolutionary, but the Super Slim PS3 is the same impressive machine in a much smaller package. There doesn't seem to be any reason for existing PS3 owners to upgrade, but for the prospective PS3 buyer, the Super Slim is probably the way to go if you can deal with not having a slot-loading disc drive."
Pocket-Lint gave Super Slim a very positive review saying "It's much more affordable, brilliant gaming, second-to-none video and media player." They think it is "A blinding good console and one that will serve you for years to come with second-hand games and even new releases. Without doubt, if you don't have a PS3, this is the time to buy." They gave Super Slim 4 and a half stars out of 5.
Technology magazine T3 gave the Super Slim model a positive review, stating the console is almost "nostalgic" in the design similarities to the original "fat" model, "While we don’t know whether it will play PS3 games or Blu-ray discs any differently yet, the look and feel of the new PS3 Slim is an obvious homage to the original PS3, minus the considerable excess weight.
Immediately we would be concerned about the durability of the top loading tray that feels like it could be yanked straight out off the console, but ultimately it all feels like Sony's nostalgic way of signing off the current generation console in anticipation for the PS4."
External links.
Official websites
Auxiliary sites by Sony
Directories

</doc>
<doc id="24953" url="http://en.wikipedia.org/wiki?curid=24953" title="Pelé">
Pelé

Edson Arantes do Nascimento (]), known as Pelé (]) (born on 23 October 1940), is a retired Brazilian professional footballer who is widely regarded to be the greatest player of all time. In 1999, he was voted World Player of the Century by the International Federation of Football History & Statistics (IFFHS). The same year, "France Football" asked their former Ballon d'Or winners to choose the Football Player of the Century; they selected Pelé. In 1999, Pelé was elected Athlete of the Century by the IOC, and "Time" named him in their list of . In 2013 he received the FIFA Ballon d'Or Prix d'Honneur in recognition of his career and achievements as a global icon of football.
According to the IFFHS, Pelé is the most successful league goal scorer in the world, with 541 league goals. In total Pelé scored 1281 goals in 1363 games, including unofficial friendlies and tour games, for which he was listed in the "Guinness World Records" for most career goals scored in football. During his playing days, Pelé was for a period the best-paid athlete in the world. In his native Brazil, he is hailed as a national hero, for his accomplishments in football, and for his vocal support of policies to improve the social conditions of the poor. In 1961, Brazil President Jânio Quadros had Pelé declared a national treasure. During his career, he became known as "The Black Pearl" ("Pérola Negra"), "The King of Football" ("O Rei do Futebol"), "The King Pelé" ("O Rei Pelé") or simply "The King" ("O Rei").
Pelé began playing for Santos at 15 and the Brazil national football team at 16. He won three FIFA World Cups: 1958, 1962 and 1970, the only player ever to do so; and is the all-time leading goalscorer for Brazil with 77 goals in 92 games. At club level he is also the record goalscorer for Santos, and led them to the 1962 and 1963 Copa Libertadores. Pelé’s electrifying play and penchant for spectacular goals made him a star around the world, and his club team Santos toured internationally in order to take full advantage of his popularity.
Since retiring in 1977, Pelé has been a worldwide ambassador for football and has undertaken various acting roles and commercial ventures. In 2010, he was named the Honorary President of the New York Cosmos.
Early years.
"In my mid-teens I also played indoor football, which had just taken off in Bauru, for a team called Radium, and took part in the first futebol de salão championship to be held in Bauru. We won. Futebol de salão was a new thing and I took to it like a fish to water. It’s a lot quicker than football on grass. You have to think really quickly because everyone is close to each other. Learning the game probably helped me think on my feet better. It was through futebol de salão that I first got my chance to play with adults. I was about fourteen, and I can remember that there was a tournament for which I was told I was too young to take part. In the end, I was allowed to play. I ended up top scorer, with fourteen or fifteen goals. That gave me a lot of confidence. I knew then not to be afraid of whatever might come."
— Pelé speaking on Futebol de Salão.
Pelé was born in Três Corações, Minas Gerais, Brazil, the son of Fluminense footballer Dondinho (born João Ramos do Nascimento) and Celeste Arantes. He was the elder of two siblings. He was named after the American inventor Thomas Edison. His parents decided to remove the "i" and call him "Edson", but there was a mistake on the birth certificate, leading many documents to show his name as "Edison", not "Edson", as he is called. He was originally nicknamed Dico by his family. He received the nickname "Pelé" during his school days, when it is claimed he was given it because of his pronunciation of the name of his favorite player, local Vasco da Gama goalkeeper Bilé, which he misspoke but the more he complained the more it stuck. In his autobiography, Pelé stated he had no idea what the name means, nor did his old friends. Apart from the assertion that the name is derived from that of Bilé, and that it is Hebrew for "miracle", the word has no known meaning in Portuguese.
Pelé grew up in poverty in Bauru, São Paulo. He earned extra money by working in tea shops as a servant. Taught to play by his father, he could not afford a proper football and usually played with either a sock stuffed with newspaper and tied with a string or a grapefruit. Pelé played for several amateur teams in his youth, including "Sete de Setembro", "Canto do Rio", "São Paulinho", and "Amériquinha".
Pelé played in Bauru. He led "Bauru Athletic Club" juniors (coached by Waldemar de Brito) to three consecutive São Paulo state youth championships between 1954 and 1956. He also dominated Futebol de Salão (indoor football) competitions in the region and won several championships with local team "Radium".
Club career.
Santos.
In 1956, de Brito took Pelé to Santos, an industrial and port city in the state of São Paulo, to try out for professional club Santos FC, telling the directors at Santos that the 15-year-old would be "the greatest football player in the world." Pelé impressed Santos coach Lula during his trial at the Estádio Vila Belmiro, and he signed a professional contract with the club in June 1956. Pelé was highly promoted in the local media as a future superstar. He made his senior team debut on 7 September 1956 at the age of 16 against "Corinthians Santo Andre" and had an impressive performance in a 7–1 victory. Pelé scored the first of his record 1281 goals in football during the match.
When the 1957 season started, Pelé was given a starting place in the first team and, at the age of 16, became the top scorer in the league. Ten months after signing professionally, the teenager was called up to the Brazil national team. After the 1962 World Cup, wealthy European clubs such as Real Madrid, Juventus and Manchester United tried to sign him, but the government of Brazil declared Pelé an "official national treasure" to prevent him from being transferred out of the country.
Pelé won his first major title with Santos in 1958 as the team won the Campeonato Paulista; Pelé would finish the tournament as top scorer with 58 goals, a record that stands today. A year later, he would help the team earn their first victory in the Torneio Rio-São Paulo with a 3–0 over Vasco da Gama. However, Santos was unable to retain the Paulista title. In 1960, Pelé scored 33 goals to help his team regain the Campeonato Paulista trophy but lost out on the Rio-São Paulo tournament after finishing in 8th place. Another 47 goals from Pelé saw Santos retain the Campeonato Paulista. The club went on to win the Taça Brasil that same year, beating Bahia in the finals; Pelé finished as top scorer of the tournament with 9 goals. The victory allowed Santos to participate in the Copa Libertadores, the most prestigious club tournament in the Western hemisphere.
"I arrived hoping to stop a great man, but I went away convinced I had been undone by someone who was not born on the same planet as the rest of us."
—Benfica goalkeeper Costa Pereira following the loss to Santos in 1962.
Santos's most successful club season started in 1962; the team was seeded in Group 1 alongside Cerro Porteño and Deportivo Municipal Bolivia, winning every match of their group but one (a 1–1 away tie vs Cerro), with Pelé scoring his first goal in a brace against Cerro. Santos defeated Universidad Católica in the semifinals and met defending champions Peñarol in the finals in which Pelé scored another brace in the playoff match to secure the first title for a Brazilian club. Pelé finished as the second best scorer of the competition with 4 goals. That same year, Santos would defend, with success, the Campeonato Brasileiro (with 37 goals from Pelé) and the Taça Brasil (Pelé scoring four goals in the final series against Botafogo). Santos would also win the 1962 Intercontinental Cup against Benfica. Wearing his iconic number 10 shirt, Pelé produced one of his best ever performances and scored a hat-trick in Lisbon, as Santos won 5–2.
As the defending champions, Santos qualified automatically to the semifinal stage of the 1963 Copa Libertadores. The "ballet blanco" managed to retain the title in spectacular fashion after impressive victories over Botafogo and Boca Juniors. Pelé helped Santos overcome a Botafogo team that contained legends such as Garrincha and Jairzinho with an agonizing last-minute goal in the first leg of the semifinals and bring the match to 1–1. In the second leg, Pelé produced one of his best performances as a footballer with a hat-trick in the Estádio do Maracanã as Santos crushed Botafogo, 0–4, in the second leg. Appearing in their second consecutive final, Santos started the series by winning, 3–2, in the first leg and defeating the Boca Juniors of José Sanfilippo and Antonio Rattín, 1–2, in "La Bombonera", with another goal from Pelé, becoming the first (and so far only) Brazilian team to lift the Copa Libertadores in Argentine soil. Pelé finished the tournament as the topscorer runner-up with 5 goals. Santos lost the Campeonato Paulista after finishing in third place but went on to win the Rio-São Paulo tournament after an impressive 0–3 win over Flamengo in the final, with Pelé scoring one. Pelé would also help Santos retain the Intercontinental Cup and the Taça Brasil.
Santos tried to defend their title again in 1964 but they were thoroughly beaten in both legs of the semifinals by Independiente. Santos won again the Campeonato Paulista, with Pelé netting 34 goals. The club also shared the Rio-São Paulo title with Botafogo and win the Taça Brasil for the fourth consecutive year. The "Santistas" would try to resurge in 1965 by winning, for the 9th time, the Campeonato Paulista and the Taça Brasil. In the 1965 Copa Libertadores, Santos started convincingly by winning every match of their group in the first round. In the semifinals, Santos met Peñarol in a rematch of the 1962 final. After two legendary matches, a playoff was needed to break the tie. Unlike 1962, Peñarol came out on top and eliminated Santos 2–1. Pelé would, however, finish as the topscorer of the tournament with eight goals. This proved to be the start of a decline as Santos failed to retain the Torneio Rio-São Paulo.
In 1966, Pelé and Santos also failed to retain the Taça Brasil as "O Rei"'s goals weren't enough to prevent a 9–4 routing by Cruzeiro (led by Tostão) in the final series. Although Santos won the Campeonato Paulista in 1967, 1968 and 1969, Pelé became less and less a contributing factor to the "Santistas" now-limited success. On 19 November 1969, Pelé scored his 1000th goal in all competitions. This was a highly anticipated moment in Brazil. The goal, called popularly "O Milésimo" (The Thousandth), occurred in a match against Vasco da Gama, when Pelé scored from a penalty kick, at the Maracanã Stadium.
Pelé states that his most beautiful goal was scored at Rua Javari stadium on a Campeonato Paulista match against São Paulo rival Juventus on 2 August 1959. As there is no video footage of this match, Pelé asked that a computer animation be made of this specific goal. In March 1961, Pelé scored the "gol de placa" (goal worthy of a plaque), against Fluminense at the Maracanã. Pelé received the ball on the edge of his own penalty area, and ran the length of the field, eluding opposition players with feints, before striking the ball beyond the goalkeeper. The goal was regarded as being so spectacular that a plaque was commissioned with a dedication to "the most beautiful goal in the history of the Maracanã".
Pelé’s electrifying play and penchant for spectacular goals made him a star around the world. His team Santos toured internationally in order to take full advantage of his popularity. In 1967, the two factions involved in the Nigerian Civil War agreed to a 48-hour ceasefire so they could watch Pelé play an exhibition game in Lagos. During his time at Santos, Pelé played alongside many gifted players, including Zito, Pepe, and Coutinho; the latter partnered him in numerous one-two plays, attacks, and goals.
New York Cosmos.
After the 1974 season (his 19th with Santos), Pelé retired from Brazilian club football although he continued to occasionally play for Santos in official competitive matches. Two years later, he came out of semi-retirement to sign with the New York Cosmos of the North American Soccer League (NASL) for the 1975 season. Though well past his prime at this point, Pelé is credited with significantly increasing public awareness and interest in soccer in the United States. He led the Cosmos to the 1977 NASL championship, in his third and final season with the club.
On 1 October 1977, Pelé closed out his career in an exhibition match between the Cosmos and Santos. Santos arrived in New York and New Jersey after previously defeating the Seattle Sounders, 2–0. The match was played in front of a sold out crowd at Giants Stadium and was televised in the United States on ABC's "Wide World of Sports" as well as throughout the world. Pelé's father and wife both attended the match, as well as Muhammad Ali and Bobby Moore. Pelé played the first half for the Cosmos and the second half for Santos. Pelé scored his final goal from a direct free kick, and Cosmos won 2–1.
National team career.
Pelé's first international match was a 2–1 defeat against Argentina on 7 July 1957 at the Maracanã. In that match, he scored his first goal for Brazil aged 16 years and 9 months to become the youngest player to score in International football.
1958 World Cup.
Pelé arrived in Sweden sidelined by a knee injury but on his return from the treatment room, his colleagues closed ranks and insisted upon his selection. His first match was against the USSR in the third match of the first round of the 1958 FIFA World Cup, where he gave the assist to Vavá's second goal. He was the youngest player of that tournament, and at the time the youngest ever to play in the World Cup. He scored his first World Cup goal against Wales in quarter-finals, the only goal of the match, to help Brazil advance to semifinals, while becoming the youngest ever World Cup goalscorer at 17 years and 239 days. Against France in the semifinal, Brazil were leading 2–1 at halftime, and then Pelé scored a hat-trick, becoming the youngest in World Cup history to do so.
On 19 June 1958 Pelé became the youngest player to play in a World Cup final match at 17 years and 249 days. He scored two goals in the final as Brazil beat Sweden 5–2 in the capital of Stockholm. His first goal where he flicked the ball over a defender before volleying into the corner of the net, was selected as one of the best goals in the history of the World Cup. Following Pelé's second goal, Swedish player Sigvard Parling would later comment; "When Pelé scored the fifth goal in that Final, I have to be honest and say I felt like applauding". When the match ended, Pelé passed out on the field, and had to be attended by the medical staff. He then recovered, and was compelled by the victory to weep as he was being congratulated by his teammates. He finished the tournament with six goals in four matches played, tied for second place, behind record-breaker Just Fontaine, and was named best young player of the tournament.
It was in the 1958 World Cup that Pelé began wearing a jersey with number 10. Recently it has become known that the event was the result of disorganization: the leaders did not send the shirt numbers of players and it was up to FIFA to choose the number 10 shirt to Pele who was a substitute on the occasion. The press proclaimed Pelé the greatest revelation of the 1958 World Cup, and he was also retroactively given the Silver Ball as the second best player of the tournament, behind Didi.
1962 World Cup.
This was expected to be Pelé's World Cup, as he was rated as the best player in the world at the time. In the first match of the 1962 World Cup in Chile, against Mexico, Pelé assisted the first goal and then scored the second one, after a run past four defenders, to go up 2–0. He injured himself while attempting a long-range shot against Czechoslovakia. This would keep him out of the rest of the tournament, and forced coach Aymoré Moreira to make his only lineup change of the tournament. The substitute was Amarildo, who performed well for the rest of the tournament. However, it was Garrincha who would take the leading role and carry Brazil to their second World Cup title, after beating Czechoslovakia at the final in the capital of Santiago.
1966 World Cup.
The 1966 World Cup in England was marked, among other things, for the brutal fouling on Pelé, by the Bulgarian and Portuguese defenders. Pelé was the most famous footballer in the world, and Brazil fielded some world champions like Garrincha, Gilmar and Djalma Santos with the addition of other stars like Jairzinho, Tostão and Gérson, leading to high expectations for them. Brazil was eliminated in the first round, playing only three matches.
Pelé scored the first goal from a free kick against Bulgaria, becoming the first player to score in three successive FIFA World Cups, but due to his injury, a result of persistent fouling by the Bulgarians, he missed the second game against Hungary. Brazil lost that game and Pelé, although still recovering, was brought back for the last crucial match against Portugal at Goodison Park in Liverpool by the Brazilian coach Vicente Feola. Feola changed the entire defense, including the goalkeeper, in midfield he returned to the formation of the first match, while in attack he maintained Jairzinho and substituted the other two players, despite knowing that Pelé was still recovering from his serious injuries. During the game, Portugal defender João Morais brutally fouled Pelé, but was not sent off by referee George McCabe, of whom it is acknowledged let "the Portuguese get away with murder". Pelé had to stay on the field limping for the rest of the game, since substitutes were not allowed at that time. After this game he vowed he would never again play in the World Cup, a decision he would later change.
1970 World Cup.
"The most wondrous player of all [Pelé] consecrated Brazil as the cathedral of the beautiful game. Brazil ’70 were a team of superstars dedicated not just to a cause but an ideal, a dream of what football should be."
—Sports writer Jeff Powell.
Pelé was called to the national team in early 1969, he refused at first, but then accepted and played in six World Cup qualifying matches, scoring six goals. The 1970 World Cup in Mexico was to be Pelé's last. Brazil's squad for the tournament featured major changes in relation to the 1966 squad. Players like Garrincha, Nilton Santos, Valdir Pereira, Djalma Santos and Gilmar had already retired, but the team, with Pelé, Rivelino, Jairzinho, Gérson, Carlos Alberto Torres, Tostão and Clodoaldo, is often considered to be the greatest football team in history.
The front five of Jairzinho, Pelé, Gerson, Tostão and Rivelino were all number 10s in their own right and together they created an attacking momentum, with Pelé having a central role in Brazil's way to the final. All of Brazil's matches in the tournament (except the final) were played in Guadalajara, and in the first match against Czechoslovakia, Pelé gave Brazil a 2–1 lead, by controlling Gerson's long pass with his chest and then scoring. In this match Pelé audaciously attempted to lob goalkeeper Ivo Viktor from the half-way line, only narrowly missing the Czechoslovak goal. Brazil went on to win the match, 4–1. In the first half of the match against England, Pelé nearly scored with a header that was spectacularly saved by the England goalkeeper Gordon Banks. In the second half, he controlled a cross from Tostão before nonchanantly flicking the ball to Jairzinho who scored the only goal.
Against Romania in Guadalajara, Pelé scored the first goal with a bending free kick hit with the outside of his right foot. Later in the match he scored again to make it 3–1. Brazil won by a final score of 3–2. In the quarterfinals against Peru, Brazil won 4–2, with Pelé assisting Tostão for Brazil's third goal. In their semi-final match, Brazil faced Uruguay for the first time since the 1950 World Cup final round match. Jairzinho put Brazil ahead 2–1, and Pelé assisted Rivelino for the 3–1. During that match, Pelé made one of his most famous plays. Tostão passed the ball for Pelé to collect which Uruguay's goalkeeper Ladislao Mazurkiewicz took notice of and ran off his line to get the ball before Pelé. However, Pelé got there first and fooled Mazurkiewicz with a feint by not touching the ball, causing it to roll to the goalkeepers left, while Pelé went to the goalkeepers right. Pelé ran around the goalkeeper to retrieve the ball and took a shot while turning towards the goal, but he turned in excess as he shot, and the ball drifted just wide of the far post.
Brazil played Italy in the final at the Azteca Stadium in Mexico City. Pelé scored the opening goal with a header over Italian defender Tarcisio Burgnich. He then made assists on Brazil's third goal, scored by Jairzinho, and the fourth finished by Carlos Alberto which is often considered the greatest team goal of all time, involving all but two of the team's outfield players, and ended with Pelé making a blind pass which rolled perfectly into the path of Carlos Alberto, who came running from behind, and struck the ball without breaking stride to score. Brazil won the match 4–1, keeping the Jules Rimet Trophy indefinitely, and Pelé received the Golden Ball as player of the tournament. Burgnich, who marked Pelé during the final, was quoted saying "I told myself before the game, "he's made of skin and bones just like everyone else" — but I was wrong".
Pelé's last international match was on 18 July 1971 against Yugoslavia in Rio de Janeiro. With Pelé on the field, the Brazilian team's record was 67 wins, 14 draws and 11 losses. Brazil never lost a match while fielding both Pelé and Garrincha.
South American Championship.
Pelé also played in the South American Championship. In the 1959 competition he was named best player of the tournament and was top scorer with 8 goals, as Brazil came second despite being unbeaten in the tournament.
Reception and legacy.
"Pelé is the greatest player of all time. He reigned supreme for 20 years. All the others – Diego Maradona, Johan Cruyff, Michel Platini – rank beneath him. There's no one to compare with Pelé."
—West Germany's 1974 World Cup-winning captain Franz Beckenbauer.
"Pelé was one of the few who contradicted my theory: instead of 15 minutes of fame, he will have 15 centuries."
—Andy Warhol.
"My name is Ronald Reagan, I’m the President of the United States of America. But you don’t need to introduce yourself, because everyone knows who Pelé is."
—U.S. President Ronald Reagan greets Pelé at the White House.
Pelé is one of the most lauded players in history and is frequently ranked the best player ever. Among his contemporaries, Dutch legend Johan Cruyff stated; "Pelé was the only footballer who surpassed the boundaries of logic." Brazil's 1970 FIFA World Cup-winning captain Carlos Alberto Torres opined; "His great secret was improvisation. Those things he did were in one moment. He had an extraordinary perception of the game." Tostão, his strike partner at the 1970 World Cup; "Pelé was the greatest – he was simply flawless. And off the pitch he is always smiling and upbeat. You never see him bad-tempered. He loves being Pelé." His Brazilian teammate Clodoaldo commented on the adulation he witnessed; "In some countries they wanted to touch him, in some they wanted to kiss him. In others they even kissed the ground he walked on. I thought it was beautiful, just beautiful." Former Real Madrid and Hungary legend Ferenc Puskás stated; "The greatest player in history was Di Stefano. I refuse to classify Pelé as a player. He was above that."
Just Fontaine, French striker and leading scorer at the 1958 World Cup; "When I saw Pelé play, it made me feel I should hang up my boots." England's 1966 FIFA World Cup-winning captain Bobby Moore commented: "Pelé was the most complete player I've ever seen, he had everything. Two good feet. Magic in the air. Quick. Powerful. Could beat people with skill. Could outrun people. Only 5 ft 8 in tall, yet he seemed a giant of an athlete on the pitch. Perfect balance and impossible vision. He was the greatest because he could do anything and everything on a football pitch. I remember Saldhana the coach being asked by a Brazilian journalist who was the best goalkeeper in his squad. He said Pelé. The man could play in any position". Former Manchester United striker and member of England's 1966 FIFA World Cup-winning team Sir Bobby Charlton stated; "I sometimes feel as though football was invented for this magical player." During the 1970 World Cup, a British television commentator asked; "How do you spell Pelé?", with the response; "Easy: G-O-D."
Since retiring, Pelé has continued to be lauded by modern day players, coaches, journalists and others. Brazilian attacking midfielder Zico, who represented Brazil at the 1978, 1982 and 1986 FIFA World Cup, stated; "This debate about the player of the century is absurd. There's only one possible answer: Pelé. He's the greatest player of all time, and by some distance I might add". French three time Balon D'or winner Michel Platini said; "There's Pelé the man, and then Pelé the player. And to play like Pelé is to play like God." Joint FIFA Player of the Century, Argentina legend and 1986 FIFA World Cup-winning captain Diego Maradona stated; "It's too bad we never got along, but he was an awesome player". Prolific Brazilian striker Romário, winner of the 1994 FIFA World Cup and player of the tournament stated; "It's only inevitable I look up to Pelé. He's like a God to us". Former FIFA Player and of the Year and current Real Madrid player Cristiano Ronaldo said: "Pelé is the greatest player in football history, and there will only be one Pelé". Jose Mourinho, two time UEFA Champions League winning manager, commented; "I think he is football. You have the real special one - Mr Pelé." Real Madrid honorary president and former player, Alfredo Di Stéfano, opined; "The best player ever? Pelé. Lionel Messi and Cristiano Ronaldo are both great players with specific qualities, but Pelé was better".
Presenting Pelé a lifetime achievement award, former South African president Nelson Mandela said; "To watch him play was to watch the delight of a child combined with the extraordinary grace of a man in full." U.S statesman and political scientist Henry Kissinger stated; "Performance at a high level in any sport is to exceed the ordinary human scale. But Pelé's performance transcended that of the ordinary star by as much as the star exceeds ordinary performance." Former Brazilian ambassador to the United Nations, J.B. Pinheiro, commented; "Pelé played football for 22 years, and in that time he did more to promote world friendship and fraternity than any other ambassador anywhere." With crowds flocking wherever he goes, a reporter asked if his fame compared to that of Jesus Christ's, Pelé in response quipped, "There are parts of the world where Jesus Christ is not so well known."
Personal life.
On 21 February 1966, Pelé married Rosemeri dos Reis Cholbi; they have two daughters, Kelly Cristina (born 13 January 1967), who married Dr. Arthur DeLuca, and Jennifer (b. 1978), as well as a son, Edson ("Edinho", b. 27 August 1970). The couple divorced in 1982. Brazilian media have reported that in 1977 Pelé had his right kidney removed. From 1981 to 1986, Pelé was romantically linked with the model Xuxa, and was seen as influential in launching her career; she was 17 when they started to date. In April 1994 Pelé married psychologist and gospel singer Assíria Lemos Seixas, who gave birth on 28 September 1996 to twins Joshua and Celeste through fertility treatments. The couple are now separated. Pelé had at least two more children from former affairs. Sandra Macedo, his daughter with a housemaid Anizia Machado in 1964, for years fought to be acknowledged by Pelé, who refused to submit to DNA tests.<ref name=PELE/SANDRA/ESPN> Retrieved 3 February 2014</ref><ref name=PELE/SANDRA-CN> Retrieved 3 February 2014</ref><ref name=PELE/SANDRA-ESPN> Retrieved 3 February 2014</ref> Although she was recognized by courts as his daughter based on DNA evidence in 1993, Pelé never acknowledged his eldest daughter even after her death, in 2006, nor her two children, Octavio and Gabriel.<ref name=PELE/SANDRA-CN> Retrieved 3 February 2014</ref><ref name=PELE/SANDRA-ESPN> Retrieved 3 February 2014</ref><ref name=PELE/SANDRA-HT> Retrieved 3 February 2014</ref> Pelé had had another daughter, Flavia Kurts, in an extra-marital affair in 1968 with a journalist called Lenita Kurtz. Flavia was recognized by him as his daughter.<ref name=PELE/SANDRA/ESPN>. ESPN. Retrieved 3 February 2014</ref>
At the age of 73, Pelé announced his intention to marry 41-year-old Marcia Aoki, a Japanese-Brazilian importer of medical equipment from Penápolis, São Paulo, whom he has been dating since 2010. They first met in the mid-1980s in New York, before meeting again in 2008.<ref name=PELE/MARCIA></ref> Pelé is now married to Marcia Aoki who stood by him during his illness in 2014.
In 1970, Pelé was investigated by the Brazilian military dictatorship for suspected leftist sympathies. Declassified documents show Pelé was investigated after being handed a manifesto calling for the release of political prisoners. Pelé himself did not get further involved within political struggles in the country. Eventually Pelé has been criticized in the public opinion for his conservative views. In June 2013, during the Brazilian protests, he asked for people to "forget the demonstrations" and support the Brazilian National Football Team. In November 2012, Pelé underwent a successful hip operation. In May 2014, his son Edinho was jailed for 33 years for laundering money from drug trafficking. Pelé has stated that he is a Catholic.
After football.
In February 2012, Legends 10 began handling the Pelé brand and brought all marketing and management efforts under one roof, including all intellectual property rights, global licensing, branding, endorsements, and public appearances.
The most notable area of Pelé's life since football is his ambassadorial work. In 1992, Pelé was appointed a UN ambassador for ecology and the environment.
He was awarded Brazil's Gold Medal for outstanding services to the sport in 1995; Brazilian President Fernando Henrique Cardoso appointed him to the position of Extraordinary Minister for Sport, and he was appointed a UNESCO Goodwill Ambassador. During this time he proposed legislation to reduce corruption in Brazilian football, which became known as the "Pelé law." Pelé left his position in 2001 after he was accused of involvement in a corruption scandal, although nothing was proven, and it was denied by UNICEF. In 1997, Pelé received an honorary Knight Commander of the Order of the British Empire from Queen Elizabeth II, at a ceremony in Buckingham Palace.
Pelé scouted for Premier League club Fulham in 2002. He made the draw for the qualification groups for the 2006 FIFA World Cup finals.
Pelé publicly accused the Brazilian football administrator Ricardo Teixeira of corruption after Pelé's television company was rejected in a contest for the Brazilian domestic rights. Pelé accusations led to an eight-year feud between the pair. As a consequence of the affair, the President of FIFA, João Havelange banned Pelé from the draw for the 1994 FIFA World Cup in Las Vegas. Criticisms over the ban were perceived to have negatively affected Havelange's chances of re-election as FIFA's president in 1994.
Pelé has published several autobiographies, starred in documentary films, and composed musical pieces, including the entire soundtrack for the film "Pelé" in 1977. He appeared, alongside other footballers of the 1960s and 1970s, with Michael Caine, and Sylvester Stallone, in the 1981 film "Escape to Victory", about an attempted escape from a World War II German POW camp.
In 2005, Pelé received a lifetime achievement award from the BBC and, in June 2006, helped inaugurate the 2006 FIFA World Cup finals, alongside supermodel Claudia Schiffer. Pelé also produced an international ad campaign for drug company Pfizer to promote Viagra and raise world awareness of erectile dysfunction.
Pelé was guest of honour at the world's oldest football club, Sheffield's 150th anniversary match against Inter Milan in November 2007. Inter won 5–2 in front of an appreciative crowd at Bramall Lane. As part of his visit, Pelé opened an exhibition which included the first public showing in 40 years of the original hand-written rules of football.
In 2009, he cooperated with Ubisoft on arcade football game "" for the Wii and appeared in the game as a coach to its players. On "FIFA 14" released in 2013, Pelé features for the Ultimate team known as Legends for the Xbox One, where game-players can acquire classic players from different eras.
In May 2010, Pelé appeared in a commercial for Louis Vuitton, indulging in a game of table football with fellow legends Diego Maradona and Zinedine Zidane.
On 1 August 2010, Pelé was introduced as the Honorary President of a revived New York Cosmos, aiming to field a team in Major League Soccer. On 3 August 2011, it was reported that Santos were considering bringing him out of retirement for a cameo role in the 2011 FIFA Club World Cup, although this later turned out to be false.
In 2012, Pelé was awarded an honorary degree from the University of Edinburgh for "significant contribution to humanitarian and environmental causes, as well as his sporting achievements", his first such degree from a European university.
On 12 August 2012, Pelé was an attendee at the 2012 Olympic hunger summit hosted by UK Prime Minister David Cameron at 10 Downing Street, London, part of a series of international efforts which have sought to respond to the return of hunger as a high profile global issue. Later on the same day, Pelé appeared at the closing ceremony of the 2012 Summer Olympics in London, following the handover section to the next host city for the 2016 Summer Olympics, Rio de Janeiro.
Honours.
Country.
Brazil
Club.
Santos
New York Cosmos
In total Pelé has 40 official titles.
Individual.
In December 2000, Pelé and Maradona shared the prize of FIFA Player of the Century by FIFA. The award was originally intended to be based upon votes in a web poll, but after it became apparent that it favoured Diego Maradona, many observers complained that the Internet nature of the poll would have meant a skewed demographic of younger fans who would have seen Maradona play, but not Pelé. FIFA then appointed a "Family of Football" committee of FIFA members to decide the winner of the award together with the votes of the readers of the FIFA Magazine. The committee chose Pelé. Since Maradona was winning the Internet poll, however, it was decided he and Pelé should share the award.
Career statistics.
Club.
Pelé's goalscoring record is often reported by FIFA among others as being 1281 goals in 1363 games. This figure includes goals scored by Pelé in friendly club matches, for example, international tours Pelé completed with Santos and the New York Cosmos, and a few games Pelé played in for armed forces teams during his national service in Brazil.
The tables below record every goal Pelé scored in major club competitions for Santos and the New York Cosmos. During much of Pelé's playing career in Brazil there was no national league championship. From 1960 onwards the Brazilian Football Confederation (CBF) were required to provide meritocratic entrants for the then-new Copa Libertadores, a South American international club competition broadly equivalent to the European Cup. To enable them to do this, the CBF organised two national competitions: the Taça de Prata and Taça Brasil. A national league championship, the Campeonato Brasileiro, was first played in 1971, alongside traditional state and interstate competitions such as the Campeonato Paulista and the Torneio Rio-São Paulo.
The number of league goals scored by Pelé for Santos and New York Cosmos is listed as 656 in 702 games, which is a world record for League competitions. This number is the sum of the goals scored by Pelé in domestic league-based competitions: the Campeonato Paulista (SPS), Torneio Rio-São Paulo (RSPS), Taça de Prata and Campeonato Brasileiro. The Taça Brasil was a national competition organised on a knockout basis.
National team.
Pelé is the top scorer of the Brazil national football team with 77 goals in 92 official appearances. In addition, he has scored 18 times in 21 unofficial games. This makes an unofficial total of 113 games and 95 goals. He has also scored 12 goals and is credited with 10 assists in 14 World Cup appearances, including 4 goals and 7 assists in 1970. Pelé shares with Uwe Seeler and Miroslav Klose the achievement of being the only three footballers to have scored in four separate World Cup tournaments.
Summary.
Pelé numbers differ between sources mostly due to friendly games. The RSSSF states that Pelé scored 767 goals in 831 official games, 1281 goals in 1367 overall while he was active, 1284 in 1375 taking into account benefit games after retirement. The following table is a compendium of sources that include Santos and FIFA among others.
External links.
class="wikitable succession-box" style="margin:0.5em auto; font-size:95%;clear:both;"

</doc>
<doc id="24955" url="http://en.wikipedia.org/wiki?curid=24955" title="Polycarp">
Polycarp

Polycarp (Greek: Πολύκαρπος, "Polýkarpos"; AD 80 – 167) was a 2nd-century Christian bishop of Smyrna. According to the "Martyrdom of Polycarp" he died a martyr, bound and burned at the stake, then stabbed when the fire failed to touch him. Polycarp is regarded as a saint in the Roman Catholic, Eastern Orthodox, Oriental Orthodox, Anglican, and Lutheran churches.
It is recorded by Irenaeus, who heard him speak in his youth, and by Tertullian, that he had been a disciple of John the Apostle. Saint Jerome wrote that Polycarp was a disciple of John and that John had ordained him bishop of Smyrna.
The early tradition that expanded upon the "Martyrdom" to link Polycarp in competition and contrast with John the Apostle who, though many people had tried to kill him, was not martyred but died of old age after being exiled to the island of Patmos, is embodied in the Coptic language fragmentary papyri (the "Harris fragments") dating to the 3rd to 6th centuries. Frederick Weidmann, their editor, interprets the "Harris fragments" as Smyrnan hagiography addressing Smyrna–Ephesus church rivalries, which "develops the association of Polycarp and John to a degree unwitnessed, so far as we know, either before or since". The fragments echo the "Martyrology", and diverge from it.
With Clement of Rome and Ignatius of Antioch, Polycarp is regarded as one of three chief Apostolic Fathers. The sole surviving work attributed to his authorship is his "Letter to the Philippians"; it is first recorded by Irenaeus of Lyons.
Surviving writings and early accounts.
The sole surviving work attributed to him is "Polycarp's letter to the Philippians", a mosaic of references to the Greek Scriptures, preserved in Irenaeus' account of Polycarp's life. It, and an account of "The Martyrdom of Polycarp" that takes the form of a circular letter from the church of Smyrna to the churches of Pontus, form part of the collection of writings Roman Catholics term "The Apostolic Fathers" to emphasize their particular closeness to the apostles in Church traditions. After the Acts of the Apostles, which describes the death of Saint Stephen, the "Martyrdom" is considered one of the earliest genuine accounts of a Christian martyrdom, and is one of the very few genuine accounts from the actual age of the persecutions.
Life.
There are two chief sources of information concerning the life of Polycarp: the letter of the Smyrnaeans recounting the martyrdom of Polycarp and the passages in Irenaeus' "Adversus Haereses". Other sources are the epistles of Ignatius, which include one to Polycarp and another to the Smyrnaeans, and Polycarp's own letter to the Philippians. In 1999, some third to 6th century Coptic fragments about Polycarp were also published.
Papias.
According to Irenaeus, Polycarp was a companion of Papias, another "hearer of John" as Irenaeus interprets Papias' testimony, and a correspondent of Ignatius of Antioch. Ignatius addressed a letter to him, and mentions him in his letters to the Ephesians and to the Magnesians.
Irenaeus regarded the memory of Polycarp as a link to the apostolic past. He relates how and when he became a Christian, and in his letter to Florinus stated that he saw and heard Polycarp personally in lower Asia. In particular, he heard the account of Polycarp's discussion with John and with others who had seen Jesus. Irenaeus also reports that Polycarp was converted to Christianity by apostles, was consecrated a bishop, and communicated with many who had seen Jesus. He repeatedly emphasizes the very great age of Polycarp.
Visit to Anicetus.
According to Irenaeus, during the time his fellow Syrian, Anicetus, was the Bishop of Rome, in the 150s or 160, Polycarp visited Rome to discuss the differences that existed between Asia and Rome "with regard to certain things" and especially about the time of the Easter festivals. Irenaeus said that on certain things the two bishops speedily came to an understanding, while as to the time of Easter, each adhered to his own custom, without breaking off communion with the other. Polycarp followed the eastern practice of celebrating the feast on the 14th of Nisan, the day of the Jewish Passover, regardless of what day of the week it fell. Anicetus followed the western practice of celebrating the feast on the first Sunday after the first full moon after the Spring equinox (March 21).
Pope Anicetus—the Roman sources offering it as a mark of special honor—allowed Polycarp to celebrate the Eucharist in his own church.
Date of martyrdom.
In the "Martyrdom", Polycarp is recorded as saying on the day of his death, "Eighty and six years I have served Him, and He has done me no wrong", which could indicate that he was then eighty-six years old or that he may have lived eighty-six years after his conversion. Polycarp goes on to say, "How then can I blaspheme my King and Saviour? Bring forth what thou wilt." Polycarp was burned at the stake for refusing to burn incense to the Roman Emperor. The date of Polycarp's death is in dispute. Eusebius dates it to the reign of Marcus Aurelius, c. 166–167. However, a post-Eusebian addition to the "Martyrdom of Polycarp" dates his death to Saturday, February 23, in the proconsulship of Statius Quadratus—which works out to be 155 or 156. These earlier dates better fit the tradition of his association with Ignatius and John the Evangelist. However, the addition to the "Martyrdom" cannot be considered reliable on only its own merits. Lightfoot would argue for the earlier date of Polycarp's death, with which Killen would strongly disagree. In addition, some have proposed a date in 177. However the earlier date of 156 is generally accepted.
Great Sabbath.
Because the Smyrnaean letter known as the "Martyrdom of Polycarp" states that Polycarp was taken "on the day of the Sabbath" and killed on "the Great Sabbath," some believe that this is evidence that the Smyrnaeans under Polycarp observed the seventh day Sabbath.
William Cave wrote "... the Sabbath or 'Saturday' (for so the word sabbatum is constantly used in the writings of the fathers, when speaking of it as it relates to Christians) was held by them in great veneration, and especially in the Eastern parts honoured with all the public solemnities of religion. This is plain, not only from some passages in Ignatius and Clemens' Constitutions, but from writers of more unquestionable credit and authority. Athanasius, bishop of Alexandria, tells us that they assembled on Saturdays... to worship Jesus Christ, the Lord of the Sabbath."
Some feel that the expression "the Great Sabbath" refers to the Christian Passover or another annual holy day. If so, then Polycarp's martyrdom would have had to occur at least a month after the traditional February 23 dating since according to the Hebrew calendar the earliest time Nisan 14, the date of the Passover, can fall on in any given year is late March. Other "Great Sabbaths" (if this is referring to what are commonly considered to be Jewish holy days, though observed by many early professors of Christ) come in the spring, late summer, and the fall. None occur in winter.
It is claimed that the "Great Sabbath" is alluded to in John 7:37. Here it is referred to as "the last day, that great day of the feast" and is a separate annual holy day immediately following the Feast of Tabernacles. Others argue that the gospel writer is referring to the seventh day of the Feast and later refers to the Eighth Day or annual Sabbath in John 9:14. It is more likely that the "Great Sabbath," as referred to in the "Martyrdom of Polycarp" is alluded to in John 19:31 which points out "that [weekly] Sabbath day" following the "[day of the] preparation" was a "high day" or "great." In any event, however, it is disputable whether such biblical references imply a common practice or just onetime events.
Importance.
Polycarp occupies an important place in the history of the early Christian Church. He is among the earliest Christians whose writings survive. Saint Jerome wrote that Polycarp was a "disciple of the apostle John and by him ordained bishop of Smyrna". He was an elder of an important congregation which was a large contributor to the founding of the Christian Church. He is from an era whose orthodoxy is widely accepted by Eastern Orthodox Churches, Oriental Orthodox Churches, Church of God groups, Sabbatarian groups, mainstream Protestants and Catholics alike. According to David Trobisch, Polycarp may have been the one who compiled, edited, and published the New Testament. All of this makes his writings of great interest.
Irenaeus, who had heard him preach in his youth, said of him: "a man who was of much greater weight, and a more steadfast witness of truth, than Valentinus, and Marcion, and the rest of the heretics". Polycarp lived in an age after the deaths of the apostles, when a variety of interpretations of the sayings of Jesus were being preached. His role was to authenticate orthodox teachings through his reputed connection with the apostle John: "a high value was attached to the witness Polycarp could give as to the genuine tradition of old apostolic doctrine", Wace commented, "his testimony condemning as offensive novelties the figments of the heretical teachers". Irenaeus states (iii. 3) that on Polycarp's visit to Rome, his testimony converted many disciples of Marcion and Valentinus.
External links.
 The full text of at Wikisource

</doc>
<doc id="24956" url="http://en.wikipedia.org/wiki?curid=24956" title="Pacifism">
Pacifism

Pacifism is opposition to war and violence. The word "pacifism" was coined by the French peace campaigner Émile Arnaud (1864–1921) and adopted by other peace activists at the tenth Universal Peace Congress in Glasgow in 1901. A related term is "ahimsa" (to do no harm), which is a core philosophy in Buddhism, Jainism, and Hinduism. While modern connotations are recent, having been explicated since the 19th century, ancient references abound.
In Christianity, Jesus Christ's injunction to and asking for forgiveness for his crucifiers "for they know not what they do" have been interpreted as calling for pacifism. In modern times, interest was revived by Leo Tolstoy in his late works, particularly in "The Kingdom of God Is Within You". Mohandas Gandhi (1869–1948) propounded the practice of steadfast nonviolent opposition which he called "satyagraha", instrumental in its role in the Indian Independence Movement. Its effectiveness served as inspiration to Martin Luther King Jr., James Lawson, James Bevel, Thich Nhat Hanh and many others in the 1950s and 1960s American Civil Rights Movement. Pacifism was widely associated with the much publicized image of Tiananmen Square Protests of 1989 with the "Tank Man", where one protester stood in nonviolent opposition to a column of tanks.
Definition.
Pacifism covers a spectrum of views, including the belief that international disputes can and should be peacefully resolved, calls for the abolition of the institutions of the military and war, opposition to any organization of society through governmental force (anarchist or libertarian pacifism), rejection of the use of physical violence to obtain political, economic or social goals, the obliteration of force, and opposition to violence under any circumstance, even defence of self and others. Historians of pacifism Peter Brock and Thomas Paul Socknat define pacifism "in the sense generally accepted in English-speaking areas" as "an unconditional rejection of all forms of warfare". Philosopher Jenny Teichman defines the main form of pacifism as "anti-warism", the rejection of all forms of warfare. Teichman's beliefs have been summarized by Brian Orend as "...A pacifist rejects war and believes there are no moral grounds which can justify resorting to war. War, for the pacifist, is always wrong." In a sense the philosophy is based on the idea that the ends do not justify the means.
Moral considerations.
Pacifism may be based on moral principles (a deontological view) or pragmatism (a consequentialist view). Principled pacifism holds that at some point along the spectrum from war to interpersonal physical violence, such violence becomes morally wrong. Pragmatic pacifism holds that the costs of war and interpersonal violence are so substantial that better ways of resolving disputes must be found. Pacifists generally reject theories of Just War. Some, however, believe that if the foe is willing to hurt others, then it is justified to respond with force, even to the extent of the atomic bomb. Such people can be called semi-pacifists.
A counterargument to this is the belief that even if one side's resort to force can provide more peace in the long run, people on both sides will think they are on that side due to the worse side's propaganda, so it would be safer for both sides to oppose war despite both believing they are on that side which should resort to force.
Nonviolence.
Some pacifists follow principles of nonviolence, believing that nonviolent action is morally superior and/or most effective. Some however, support physical violence for emergency defence of self or others. Others support destruction of property in such emergencies or for conducting symbolic acts of resistance like pouring red paint to represent blood on the outside of military recruiting offices or entering air force bases and hammering on military aircraft.
By no means is all nonviolent resistance (sometimes also called civil resistance) based on a fundamental rejection of all violence in all circumstances. Many leaders and participants in such movements, while recognizing the importance of using non-violent methods in particular circumstances, have not been absolute pacifists. Sometimes, as with the US civil rights movement's march from Selma to Montgomery in 1965, they have called for armed protection. The interconnections between civil resistance and factors of force are numerous and complex.
Dove.
"Dove" or "dovish" are informal terms used, especially in politics, for people who prefer to avoid war or prefer war as a last resort. Similarly, in common parlance, the opposite of a dove is a hawk or war hawk.
Absolute pacifism.
An absolute pacifist is generally described by the British Broadcasting Corporation as one who believes that human life is so valuable, that a human should never be killed and war should never be conducted, even in self-defense. The principle is described as difficult to abide by consistently, due to violence not being available as a tool to aid a person who is being harmed or killed. It is further claimed that such a pacifist could logically argue that violence leads to more undesirable results than non-violence.
Police actions and national liberation.
Although all pacifists are opposed to war between nation states, there have been occasions where pacifists have supported military conflict in the case of civil war or revolution. For instance, during the American Civil War, both the American Peace Society and some former members of the Non-Resistance Society supported the Union's military campaign, arguing they were carrying out a "police action" against the Confederacy, whose act of Secession they regarded as criminal. Following the outbreak of the Spanish Civil War, French pacifist René Gérin (1892-1957) urged support for the Spanish Republic. Gérin argued that the Spanish Nationalists were "comparable to an individual enemy" and the Republic's war effort was equivalent to the action of a domestic police force suppressing crime.
In the 1960s, some pacifists associated with the New Left supported wars of national liberation and supported groups such as the Viet Cong and the Algerian FLN, arguing peaceful attempts to liberate such nations were no longer viable, and war was thus the only option.
Early traditions of pacifism.
Advocacy of pacifism can be found far back in history and literature.
South Asia.
Compassion for all life, human and nonhuman, is central to Buddhism, which was founded by Siddhartha Gautama; and also Jainism, which was founded by Mahavira 599–527 BC. Both the Buddha and Mahavira were by birth kshatriya, the varna (social order) of soldiers and officials. An unusual example is that of Emperor Ashoka who became a pacifist after the bloody Kalinga war.
China.
During the Warring States period, the pacifist Mohist School opposed aggressive war between the feudal states. They took this belief into action by using their famed defensive strategies to defend smaller states from invasion from larger states, hoping to dissuade feudal lords from costly warfare. The Seven Military Classics of ancient China view warfare negatively, and as a last resort. For example, the "Three Strategies of Huang Shigong" says: "As for the military, it is not an auspicious instrument; it is the way of heaven to despise it", and the "Wei Liaozi" writes: "As for the military, it is an inauspicious instrument; as for conflict and contention, it runs counter to virtue".
The Taoist scripture ""Classic of Great Peace" ("Taiping jing")" foretells "the coming Age of Great Peace ("taiping")." The "Taiping Jing" advocates "a world full of peace".
Lemba.
The Lemba religion of southern French Congo, along with its symbolic herb, is named for pacifism : ""lemba, lemba" (peace, peace), describes the action of the plant "lemba-lemba" ("Brillantaisia patula T. Anders"). Likewise in Cabinda, "Lemba" is the spirit of peace, as its name indicates."
Moriori.
The Moriori, of the Chatham Islands, practiced pacifism by order of their ancestor Nunuku-whenua. This enabled the Moriori to preserve what limited resources they had in their harsh climate, avoiding waste through warfare. In turn, this led to their almost complete annihilation in 1835 by invading Ngāti Mutunga and Ngāti Tama Māori from the Taranaki region of the North Island of New Zealand. The invading Māori killed, enslaved and cannibalised the Moriori. A Moriori survivor recalled : "[The Maori] commenced to kill us like sheep... [We] were terrified, fled to the bush, concealed ourselves in holes underground, and in any place to escape our enemies. It was of no avail; we were discovered and killed - men, women and children indiscriminately."
Greece.
In Ancient Greece, pacifism seems not to have existed except as a broad moral guideline against violence between individuals. No philosophical program of rejecting violence between states, or rejecting all forms of violence, seems to have existed. Aristophanes, in his play Lysistrata, creates the scenario of an Athenian woman's anti-war sex strike during the Peloponnesian War of 431–404 BC, and the play has gained an international reputation for its anti-war message. Nevertheless, it is both fictional and comical, and though it offers a pragmatic opposition to the destructiveness of war, its message seems to stem from frustration with the existing conflict (then in its twentieth year) rather than from a philosophical position against violence or war. Equally fictional is the nonviolent protest of Hegetorides of Thasos. Euripides also expressed strong anti-war ideas in his work, especially "The Trojan Women".
Roman Empire.
Several Roman writers rejected the militarism of Roman society and gave voice to anti-war sentiments,
including Propertius, Tibullus and Ovid. The Stoic Seneca the Younger criticised warfare in his book "Naturales quaestiones" (circa 65 AD).
Maximilian of Tebessa was a Christian conscientious objector. He was killed for refusing to be conscripted.
Christianity.
See also Christian pacifism.
Throughout history, many have understood Jesus of Nazareth to have been a pacifist, drawing on his Sermon on the Mount (see Christian pacifism). In the sermon Jesus stated that one should "not resist an evildoer" and promoted his turn the other cheek philosophy. "If anyone strikes you on the right cheek, turn the other also; and if anyone wants to sue you and take your coat, give your cloak as well... Love your enemies, do good to those who hate you, bless those who curse you, pray for those who abuse you." The New Testament story is of Jesus, besides preaching these words, surrendering himself freely to an enemy intent on having him killed and proscribing his followers from defending him.
There are those, however, who deny that Jesus was a pacifist and state that Jesus never said not to fight, citing examples from the New Testament. One such instance portrays an angry Jesus driving dishonest market traders from the temple. A frequently quoted passage is Luke 22:36: "He said to them, 'But now, the one who has a purse must take it, and likewise a bag. And the one who has no sword must sell his cloak and buy one.'" Others have interpreted the non-pacifist statements in the New Testament to be related to self-defense or to be metaphorical and state that on no occasion did Jesus shed blood or urge others to shed blood.
Cathars.
Known in the Balkans as Bogomils and in northern Italy and southern France as Cathars, they were pacifists totally dedicated to nonviolence. The Cathars were actually branded heretics, persecuted, and eventually annihilated by the Catholic Church through the Albigensian Crusade and the Inquisition that followed. "These heretics are worse than the saracens" exclaimed Pope Innocent III, and on March 10, 1208, after the murder of the papal legate Pierre de Castelnau, probably by Raymond VI, Count of Toulouse, the pope took full advantage of it and proclaimed a crusade against a sect in southern France.
Modern history.
Beginning in the 16th century, the Protestant Reformation gave rise to a variety of new Christian sects, including the historic peace churches. Foremost among them were the Religious Society of Friends (Quakers), Amish, Mennonites and Church of the Brethren. The humanist writer Desiderius Erasmus was one of the most outspoken pacifists of the Renaissance, arguing strongly against warfare in his essays "The Praise of Folly" (1509) and "The Complaint of Peace" (1517).
The Quakers were prominent advocates of pacifism, who as early as 1660 had repudiated violence in all forms and adhered to a strictly pacifist interpretation of Christianity. They stated their beliefs in a declaration to King Charles II:
 "We utterly deny all outward wars and strife, and fightings with outward weapons, for any end, or under any pretense whatever; this is our testimony to the whole world. The Spirit of Christ . . . which leads us into all truth, will never move us to fight and war against any man with outward weapons, neither for the kingdom of Christ, nor for the kingdoms of this world.
Throughout the many 18th century wars in which Britain participated, the Quakers maintained a principled commitment not to serve in the army and militia or even to pay the alternative £10 fine.
The English Quaker William Penn, who founded the Province of Pennsylvania, employed an anti-militarist public policy. Unlike residents of many of the colonies, Quakers chose to trade peacefully with the Indians, including for land. The colonial province was, for the 75 years from 1681 to 1756, essentially unarmed and experienced little or no warfare in that period.
From the 16th to the 18th centuries, a number of thinkers devised plans for an international organisation that would promote peace, and reduce or even eliminate the occurrence of war. These included the French politician Duc de Sully, the philosophers Émeric Crucé and the Abbe de Saint-Pierre, and the English Quakers William Penn and John Bellers.
Pacifist ideals emerged from two strands of thought that coalesced at the end of the 18th century. One, rooted in the secular Enlightenment, promoted peace as the rational antidote to the world's ills, while the other was a part of the evangelical religious revival that had played an important part in the campaign for the abolition of slavery. Representatives of the former, included Jean-Jacques Rousseau, in "Extrait du Projet de Paix Perpetuelle de Monsieur l'Abbe Saint-Pierre" (1756), Immanuel Kant, in his "Thoughts on Perpetual Peace" and Jeremy Bentham who proposed the formation of a peace association in 1789. Representative of the latter, was William Wilberforce who thought that strict limits should be imposed on British involvement in the French Revolutionary War based on Christian ideals of peace and brotherhood. Bohemian Bernard Bolzano (1781–1848) taught about the social waste of militarism and the needlessness of war. He urged a total reform of the educational, social, and economic systems that would direct the nation's interests toward peace rather than toward armed conflict between nations.
Peace movements.
During the period of the Napoleonic Wars, although no formal peace movement was established until the end of hostilities, a significant peace movement animated by universalist ideals did emerge, due to the perception of Britain fighting in a reactionary role and the increasingly visible impact of the war on the welfare of the nation in the form of higher taxation levels and high casualty rates. Sixteen peace petitions to Parliament were signed by members of the public, anti-war and anti-Pitt demonstrations convened and peace literature was widely published and disseminated.
The first peace movements appeared in 1815–16. In the United States the first such movement was the New York Peace Society, founded in 1815 by the theologian David Low Dodge, and the Massachusetts Peace Society. It became an active organization, holding regular weekly meetings, and producing literature which was spread as far as Gibraltar and Malta, describing the horrors of war and advocating pacificism on Christian grounds. The London Peace Society (also known as the Society for the Promotion of Permanent and Universal Peace) was formed in 1816 to promote permanent and universal peace by the philanthropist William Allen. In the 1840s, British women formed "Olive Leaf Circles", groups of around 15 to 20 women, to discuss and promote pacifist ideas.
The peace movement began to grow in influence by the mid-nineteenth century. The London Peace Society, under the initiative of American consul to Birmingham Elihu Burritt and the reverend Henry Richard, convened the first International Peace Congress in London in 1843. The congress decided on two aims: the ideal of peaceable arbitration in the affairs of nations and the creation of an international institution to achieve that. Richard became the secretary of the Peace Society in 1850 on a full-time basis, a position which he would keep for the next 40 years, earning himself a reputation as the 'Apostle of Peace'. He helped secure one of the earliest victories for the peace movement by securing a commitment from the Great Powers in the Treaty of Paris (1856) at the end of the Crimean War, in favour of arbitration. On the European continent, wracked by social upheaval, the first peace congress was held in Brussels in 1848 followed by Paris a year later.
After experiencing a recession in support due to the resurgence of militarism during the American Civil War and Crimean War, the movement began to spread across Europe and began to infiltrate the new working class socialist movements. In 1870, Randal Cremer formed the Workman's Peace Association in London. Cremer, alongside the French economist Frédéric Passy was also the founding father of the first international organisation for the arbitration of conflicts in 1889, the Inter-Parliamentary Union. The National Peace Council was founded in after the 17th Universal Peace Congress in London (July August 1908).
An important thinker who contributed to pacifist ideology was Russian writer Leo Tolstoy. In one of his latter works, "The Kingdom of God is Within You", Tolstoy provides a detailed history, account and defense of pacifism. Tolstoy's work inspired a movement named after him advocating pacifism to arise in Russia and elsewhere. The book was a major early influence on Mohandas K. Gandhi (1869–1948), and the two engaged in regular correspondence while Gandhi was active in South Africa.
Bertha von Suttner, the first woman to be a Nobel Peace Prize laureate, became a leading figure in the peace movement with the publication of her novel, "Die Waffen nieder!" ("Lay Down Your Arms!") in 1889 and founded an Austrian pacifist organization in 1891.
Non-violent resistance.
In New Zealand, during the latter half of the 19th century British colonists used many tactics to confiscate land from the indigenous Māori, including warfare. In the 1870s and 1880s, Parihaka, then reputed to be the largest Māori village in New Zealand, became the centre of a major campaign of non-violent resistance to European occupation of confiscated land in the area. One Māori leader, Te Whiti-o-Rongomai, inspired warriors to stand up for their rights without using weapons, which had led to defeat in the past. In 1881 he convinced 2000 Maori to welcome battle-hardened British soldiers into their village and even offered food and drink. He allowed himself and his people to be arrested without resistance for opposing land confiscation. He is remembered as a great leader because the "passive resistance" he practiced prevented British massacres and even protected far more land than violent resistance.
Mohandas K. Gandhi was a major political and spiritual leader of India, instrumental in the Indian independence movement. The Nobel prize winning great poet Rabindranath Tagore, who was also an Indian, gave him the honorific "Mahatma", usually translated "Great Soul." He was the pioneer of a brand of nonviolence (or "ahimsa") which he called "satyagraha"—translated literally as "truth force". This was the resistance of tyranny through civil disobedience that was not only nonviolent but also sought to change the heart of the opponent. He contrasted this with "duragraha", "resistant force," which sought only to change behaviour with stubborn protest.
During his 30 years of work (1917–1947) for the independence of his country from the British Raj, Gandhi led dozens of nonviolent campaigns, spent over seven years in prison, and fasted nearly to the death on several occasions to obtain British compliance with a demand or to stop inter-communal violence. His efforts helped lead India to independence in 1947, and inspired movements for civil rights and freedom worldwide.
World War I.
Although the onset of the First World War was generally greeted with enthusiastic patriotism across Europe, peace groups were still active in condemning the war. In Britain, the prominent peace activist Stephen Henry Hobhouse went to prison for refusing military service, citing his convictions as an "International Socialist and a Christian" Many socialist groups and movements were antimilitarist, arguing that war by its nature was a type of governmental coercion of the working class for the benefit of capitalist elites. The French socialist pacifist leader Jean Jaurès was assassinated by a nationalist fanatic on July 31, 1914. The national parties in the Second International increasingly supported their respective nations in war and the International was dissolved in 1916.
In 1915 the League of Nations Society was formed by British liberal leaders to promote a strong international organisation that could enforce the peaceful resolution of conflict. Later that year the League to Enforce Peace was established in America to promote similar goals. Hamilton Holt published an editorial in his New York City weekly magazine the "Independent" called "The Way to Disarm: A Practical Proposal" on September 28, 1914. It called for an international organization to agree upon the arbitration of disputes and to guarantee the territorial integrity of its members by maintaining military forces sufficient to defeat those of any non-member. The ensuing debate among prominent internationalists modified Holt's plan to align it more closely with proposals offered in Great Britain by Viscount James Bryce, a former ambassador from the U.K. to the U.S. These and other initiatives were pivotal in the change in attitudes that gave birth to the League of Nations after the war.
Some of the many groups that protested against the war, as well as the traditional peace churches, were the Woman's Peace Party (which was organized in 1915 and led by noted reformer Jane Addams), the International Committee of Women for Permanent Peace (ICWPP) (also organized in 1915), the American Union Against Militarism, the Fellowship of Reconciliation, and the American Friends Service Committee. Jeannette Rankin, the first woman elected to Congress, was another fierce advocate of pacifism, the only person to vote no to America's entrance into both World Wars.
Between the two World Wars.
The immense loss of life during the war, for what became regarded as futile reasons, caused a sea-change in public attitudes to militarism. Organisations formed in this period included the War Resisters' International the Women's International League for Peace and Freedom, the No More War Movement and the Peace Pledge Union (PPU). The League of Nations also convened several disarmament conferences in the inter-war period such as the Geneva Conference.
Pacifism and revulsion with war were very popular sentiments in 1920s Britain. A stream of novels and poems on the theme of the futility of war and the slaughter of the youth by old fools were published, including, Death of a Hero by Richard Aldington, Erich Remarque’s translated All Quiet on the Western Front and Beverley Nichols’s expose, Cry Havoc. A debate at the University of Oxford in 1933 on the motion 'one must fight for King and country' captured the changed mood when the motion was resoundingly defeated. Dick Sheppard established the Peace Pledge Union in 1934 totally renouncing war and aggression. The idea of collective security was also popular; instead of outright pacifism the public generally exhibited a determination to stand up to aggression, but preferably with the use of economic sanctions and multilateral negotiations.
The British Labour Party had a strong pacifist wing in the early 1930s and between 1931 and 1935 was led by George Lansbury, a Christian pacifist who later chaired the No More War Movement and was president of the PPU. The 1933 annual conference resolved unanimously to "pledge itself to take no part in war". "Labour's official position, however, although based on the aspiration towards a world socialist commonwealth and the outlawing of war, did not imply a renunciation of force under all circumstances, but rather support for the ill-defined concept of 'collective security' under the League of Nations. At the same time, on the party's left, Stafford Cripps's small but vocal Socialist League opposed the official policy, on the non-pacifist ground that the League of Nations was 'nothing but the tool of the satiated imperialist powers'." Lansbury was eventually persuaded to resign as Labour leader by the non-pacifist wing of the party and was replaced by Clement Attlee. As the threat from Nazi Germany increased in the 1930s, the Labour Party abandoned its pacifist position and supported re-armament, largely due to the efforts of Ernest Bevin and Hugh Dalton who by 1937 had also persuaded the party to oppose Neville Chamberlain's policy of appeasement.
The League of Nations attempted to play its role of ensuring world peace in the 1920s and 30s, although with the increasingly revisionist and aggressive behaviour of Nazi Germany, Fascist Italy and Imperial Japan, it ultimately failed to maintain such a world order. Economic sanctions were used against states that committed aggression, such as Italy when it invaded Abyssinia, but there was no will on the part of the principal League powers, Britain and France, to subordinate their interests to a multilateral process or to disarm at all themselves.
The Spanish Civil War proved a major test for international pacifism, and the work of pacifist organisations (such as War Resisters' International and the Fellowship of Reconciliation) and individuals (such as José Brocca and Amparo Poch) in that arena has until recently been ignored or forgotten by historians, overshadowed by the memory of the International Brigades and other militaristic interventions. Shortly after the war ended, Simone Weil, despite having volunteered for service on the republican side, went on to publish "The Iliad or the Poem of Force", a work that has been described as a pacifist manifesto. In response to the threat of fascism, some pacifist thinkers, such as Richard B. Gregg, devised plans for a campaign of nonviolent resistance in the event of a fascist invasion or takeover.
World War II.
With the start of World War II, pacifist and anti-war sentiment declined in nations affected by war. Even the communist-controlled American Peace Mobilization reversed its anti-war activism once Germany invaded the Soviet Union in 1941. After the Japanese attack on Pearl Harbor, mainstream isolationist groups like the America First Committee, declined, but many smaller religious and socialist groups continued their opposition to war. Bertrand Russell argued that the necessity of defeating Adolf Hitler and the Nazis was a unique circumstance where war was not the worst of the possible evils; he called his position "relative pacifism". Shortly before the outbreak of war, British writers such as E. M. Forster, Leonard Woolf, David Garnett and Storm Jameson all rejected their earlier pacifism and endorsed military action against Nazism. Similarly Albert Einstein wrote: "I loathe all armies and any kind of violence; yet I'm firmly convinced that at present these hateful weapons offer the only effective protection." The British pacifists Reginald Sorensen and C. J. Cadoux, while bitterly disappointed by the outbreak of war, nevertheless urged their fellow pacifists "not to obstruct the war effort".
The French pacifists André and Magda Trocmé helped conceal hundreds of Jews fleeing the Nazis in the village of Le Chambon-sur-Lignon. After the war, the Trocmés were declared Righteous Among the Nations.
Pacifists in the Third Reich were dealt with harshly; German pacifist Carl von Ossietzky, and Olaf Kullmann, a Norwegian pacifist active during the Nazi occupation, were both imprisoned in concentration camps and died as a result of their mistreatment there. Austrian farmer Franz Jägerstätter was executed in 1943 for refusing to serve in the Wehrmacht.
After the end of the war, it was discovered that "The Black Book" or "Sonderfahndungsliste G.B." list of Britons to be arrested in the event of a Nazi invasion of the UK included three active pacifists; Vera Brittain, Sybil Thorndike and Aldous Huxley (who had left the country).
There were conscientious objectors and war tax resisters in both World War I and World War II. The United States government allowed sincere objectors to serve in noncombatant military roles. However, those draft resisters who refused any cooperation with the war effort often spent much of each war in federal prisons. During World War II, pacifist leaders like Dorothy Day and Ammon Hennacy of the Catholic Worker Movement urged young Americans not to enlist in military service.
Later twentieth century.
Martin Luther King, Jr (1929–68), a Baptist minister, led the American civil rights movement which successfully used Gandhian nonviolent resistance to repeal laws enforcing racial segregation and work for integration of schools, businesses and government. In 1957, his wife Coretta Scott King, Albert Schweitzer, Benjamin Spock, and others formed the Committee for a Sane Nuclear Policy (now Peace Action) to resist the nuclear arms race. In 1958 British activists formed the Campaign for Nuclear Disarmament with Bertrand Russell as its president.
In 1960, Thich Nhat Hanh came to the US to study comparative religion at Princeton University and subsequently was appointed lecturer in Buddhism at Columbia University. Thich Nhat Hanh had written a letter to Martin Luther King in 1965 entitled "Searching for the Enemy of Man" and during his 1966 stay in the US met with King and urged him to publicly denounce the Vietnam War. King gave his famous speech at the Riverside Church in New York City in 1967, his first to publicly question the U.S. involvement in Vietnam.
Other examples from this period include the 1986 People Power Revolution in the Philippines led by Cory Aquino, and the 1989 Tiananmen Square Protests which included the broadly publicized "Tank Man" incident.
On December 1, 1948, President José Figueres Ferrer of Costa Rica abolished the Costa Rican military. In 1949, the abolition of the military was introduced in Article 12 of the Costa Rican constitution. The budget previously dedicated to the military is now dedicated to providing health care services and education.
Religious attitudes.
Ahmadiyya.
According to the Ahmadiyya understanding of Islam, pacifism is a strong current, and jihad is one's personal inner struggle and should not be used violently for political motives. Violence is the last option only to be used to protect religion and one's own life in extreme situations of persecution. Mirza Ghulam Ahmad, the founder of the Ahmadiyya Muslim Community, said that in contrary to the current views, Islam "does not allow the use of sword in religion, except in the case of defensive wars, wars waged to punish a tyrant, or those meant to uphold freedom".
Ahmadiyya claims its objective to be the peaceful propagation of Islam with special emphasis on spreading the true message of Islam by the pen. Ahmadis point out that as per prophecy, who they believe was the promised messiah, Mirza Ghulam Ahmad, rendered the concept of violent jihad unnecessary in modern times. They believe that the answer of hate should be given by love.
Bahá'í Faith.
Bahá'u'lláh, the founder of the Bahá'í Faith abolished holy war and emphasized its abolition as a central teaching of his faith. However, the Bahá'í Faith does not have an absolute pacifistic position. For example Bahá'ís are advised to do social service instead of active army service, but when this is not possible because of obligations in certain countries, the Bahá'í law of "loyalty to one's government" is preferred and the individual should perform the army service. Shoghi Effendi, the head of the Bahá'í Faith in the first half of the 20th century, noted that in the Bahá'í view, absolute pacifists are anti-social and exalt the individual over society which could lead to anarchy; instead he noted that the Bahá'í conception of social life follows a moderate view where the individual is not suppressed or exalted.
On the level of society, Bahá'u'lláh promotes the principle of collective security, which does not abolish the use of force, but prescribes "a system in which Force is made the servant of Justice." The idea of collective security from the Bahá'í teachings states that if a government violates a fundamental norm of international law or provision of a future world constitution which Bahá'ís believe will be established by all nations, then the other governments should step in.
Buddhism.
Buddhist Aung San Suu Kyi is a nonviolent pro-democracy activist and leader of the National League for Democracy in Myanmar (Burma). A devout Buddhist, Suu Kyi won the Rafto Prize and the Sakharov Prize for Freedom of Thought in 1990 and in 1991 was awarded the Nobel Peace Prize for her peaceful and non-violent struggle under a repressive military dictatorship. One of her best known speeches is the "Freedom From Fear" speech, which begins, "It is not power that corrupts but fear. Fear of losing power corrupts those who wield it and fear of the scourge of power corrupts those who are subject to it."
Christianity.
Peace churches.
Peace churches are Christian denominations explicitly advocating pacifism. The term "historic peace churches" refers specifically to three church traditions: the Church of the Brethren, the Mennonites (and some other Anabaptists, such as Amish and Hutterites), and the Quakers (Religious Society of Friends). The historic peace churches have, from their origins as far back as the 16th century, always taken the position that Jesus was himself a pacifist who explicitly taught and practiced pacifism, and that his followers must do likewise. Pacifist churches vary on whether physical force can ever be justified in self-defense or protecting others, as many adhere strictly to nonresistance when confronted by violence. But all agree that violence on behalf of a country or a government is prohibited for Christians.
Pentecostal churches.
Jay Beaman's thesis states that 13 of 21, or 62% of American Pentecostal groups formed by 1917 show evidence of being pacifist sometime in their history. Furthermore Jay Beaman has shown in his thesis that there has been a shift away from pacifism in the American Pentecostal churches to more a style of military support and chaplaincy. The major organisation for Pentecostal Christians who believe in pacifism is the PCPF, the Pentecostal Charismatic Peace Fellowship.
The United Pentecostal Church, the largest Apostolic/Oneness denomination, takes an official stand of conscientious objection: its Articles of Faith read, "We are constrained to declare against participating in combatant service in war, armed insurrection... aiding or abetting in or the actual destruction of human life. We believe that we can be consistent in serving our Government in certain noncombatant capacities, but not in the bearing of arms."
Other Christian denominations.
The Peace Pledge Union was a pacifist organisation from which the Anglican Pacifist Fellowship (APF) later emerged within the Anglican Church. The APF succeeded in gaining ratification of the pacifist position at two successive Lambeth Conferences, but many Anglicans would not regard themselves as pacifists. South African Bishop Desmond Tutu is the most prominent Anglican pacifist. Rowan Williams led an almost united Anglican Church in Britain in opposition to the 2003 Iraq War. In Australia Peter Carnley similarly led a front of bishops opposed to the Government of Australia's involvement in the invasion of Iraq.
The Catholic Worker Movement is concerned with both social justice and pacifist issues, and voiced consistent opposition to the Spanish Civil War and World War II. Many of its early members were imprisoned for their opposition to conscription. Within the Roman Catholic Church, the Pax Christi organisation is the premiere pacifist lobby group. It holds positions similar to APF, and the two organisations are known to work together on ecumenical projects. Within Roman Catholicism there has been a discernible move towards a more pacifist position through the twentieth and early twenty-first centuries. Popes Benedict XV, John XXIII and John Paul II were all vocal in their opposition to specific wars. By taking the name Benedict XVI, some suspected that Joseph Ratzinger would continue the strong emphasis upon nonviolent conflict resolution of his predecessor. However, the Roman Catholic Church officially maintains the legitimacy of Just War, which is rejected by some pacifists.
In the twentieth century there was a notable trend among prominent Roman Catholics towards pacifism. Individuals such as Dorothy Day and Henri Nouwen stand out among them. The monk and mystic Thomas Merton was noted for his commitment to pacifism during the Vietnam War era. Murdered Salvadoran Bishop Oscar Romero was notable for using non-violent resistance tactics and wrote meditative sermons focusing on the power of prayer and peace. School of the Americas Watch was founded by Maryknoll Fr. Roy Bourgeois in 1990 and uses strictly pacifist principles to protest the training of Latin American military officers by United States Army officers at the School of the Americas in the state of Georgia.
The Greek Orthodox Church also tends towards pacifism, though it has accepted defensive warfare through most of its history. However, more recently it took a strong stance towards the war in Lebanon and its large community there refused to take up arms during its civil wars. It also supports dialogue with Islam. In 1998 the Third Pre-conciliar Pan-Orthodox Conference drew up a text on "the contribution of the Orthodox Church to the achievement of peace" emphasizing respect for the human person and the inseparability of peace from justice. The text states in part: "Orthodoxy condemns war in general, for she regards it as a consequence of the evil and sin in the world."
The Southern Baptist Convention has stated in the Baptist Faith and Message, "It is the duty of Christians to seek peace with all men on principles of righteousness. In accordance with the spirit and teachings of Christ they should do all in their power to put an end to war."
The United Methodist Church explicitly supports conscientious objection by its members "as an ethically valid position" while simultaneously allowing for differences of opinion and belief for those who do not object to military service.
Members of the Rastafari Movement's Mansion Nyabinghi are specifically noted for having a large population of Pacifist Members, though not all of them are.
Hinduism.
Non violence, or ahimsa, is a central part of Hinduism and is one of the fundamental Yamas - self restraints needed to live a proper life. The concept of ahimsa grew gradually within Hinduism, one of the signs being the discouragement of ritual animal sacrifice. Most Hindus today have a vegetarian diet. There are debates on how far the principle of ahimsa applies and if there is such a thing as a "just war".
Jainism.
Non-violence, Compassion for all life, human and non-human, is central to Jainism. Human life is valued as a unique, rare opportunity to reach enlightenment. Killing any person, no matter what crime he may have committed, is considered unimaginably terrible. It is a religion that requires monks, from all its sects and traditions, to be vegetarian. Some Indian regions, such as Gujarat, Madhya Pradesh have been strongly influenced by Jains and often the majority of the local Hindus of every denomination are also vegetarian.
Judaism.
The attitude of Jews toward pacifism, as with most other aspects of religion, is heavily influenced by the Holocaust which was a program of Nazi Germany to murder every man, woman and child who was Jewish as well as people of other religions who had a Jewish grandparent. As a result, some six million people were exterminated by various means because the Nazis considered them Jews and therefore unworthy of life. In hindsight, there were opportunities for a number of years to defeat Nazi Germany before it could build a military force strong enough to capture and kill most of the Jews of Europe. Forces which deterred the democracies from acting to stop Hitler early on and at a much, much lower cost in human life were pacifism, appeasement, and isolationism. People who offered no resistance to the Nazis enabled them to carry out their oppression and aggression, costing tens of millions of lives lost in World War II and resulted in much of Eastern Europe falling under Soviet control behind the Iron Curtain from the end of the war until the collapse of the Soviet Union. Had pacifism gained more support, the Allies might have lost the war and virtually all Jews killed and democracy and freedom severely limited in the world. 
Some pre-Holocaust Hasidic groups were pacifist. The Jewish Peace Fellowship is a New-York based nonprofit, nondenominational organization set up to provide a Jewish voice in the peace movement. The organization was founded in 1941 in order to support Jewish conscientious objectors who sought exemption from combatant military service. It is affiliated to the International Fellowship of Reconciliation. The small Neturei Karta group of anti-Zionist, ultra-orthodox Jews, supposedly take a pacifist line, saying that "Jews are not allowed to dominate, kill, harm or demean another people and are not allowed to have anything to do with the Zionist enterprise, their political meddling and their wars.". However, the Neturei Karta group do support groups such as Hezbollah and Hamas that are violent towards Israel. Most religious Jews in Europe and North America agree with war when reasoning with the enemy does not work. The Hebrew Bible is full of examples when Jews were told to go and war against enemy lands or within the Israelite community as well as instances where God, as destroyer and protector, goes to war for non-participant Jews. The Holocaust Remembrance Day (called Yom Hashoah in Hebrew) is a day a remembrance for many Jews as they honor those who fought to end the Hitler government which starved, shot, gassed and burned over six million Jews to death. It is observed on the day corresponding to the 27th day of the month of Nisan on the Hebrew calendar.
Raelism.
Non-violence is an important doctrine within Raelism. The founder of this religion Rael has said ""The one holding the weapon is as responsible as the one giving the orders". Other Rael statements include "even if the Elohim asked them to kill someone they should refuse"".
Government and political movements.
While many governments have tolerated pacifist views and even accommodated pacifists' refusal to fight in wars, others at times have outlawed pacifist and anti-war activity. In 1918, The United States Congress passed the Sedition Act of 1918. During the periods between World Wars I and World War II, pacifist literature and public advocacy was banned in Italy under Benito Mussolini, Germany after the rise of Adolf Hitler,
Spain under Francisco Franco,
and the Soviet Union under Joseph Stalin. In these nations, pacifism was denounced as cowardice; indeed, Mussolini referred to pacifist writings as the "propaganda of cowardice".
Today, the United States requires that all young men register for selective service but does not allow them to be classified as conscientious objectors unless they are drafted in some future reinstatement of the draft, allowing them to be discharged or transferred to noncombatant status. Some European governments like Switzerland, Greece, Norway and Germany offer civilian service. However, even during periods of peace, many pacifists still refuse to register for or report for military duty, risking criminal charges.
Anti-war and "pacifist" political parties seeking to win elections may moderate their demands, calling for de-escalation or major arms reduction rather than the outright disarmament which is advocated by many pacifists. Green parties list "non-violence" and "decentralization" towards anarchist co-operatives or minimalist village government as two of their ten key values. However, in power, Greens often compromise. The German Greens in the cabinet of Social Democrat Gerhard Schröder supported an intervention by German troops in Afghanistan in 2001 if that they hosted the peace conference in Berlin. However, during the 2002 election Greens forced Schröder to swear that no German troops would invade Iraq.
The controversial democratic peace theory holds that liberal democracies have never (or rarely) made war on one another and that lesser conflicts and internal violence are rare between and within democracies. It also argues that the growth in the number of democratic states will, in the not so distant future, end warfare.
Some pacifists and multilateralists are in favor of international criminal law as means to prevent and control international aggression. The International Criminal Court has jurisdiction over war crimes, but the crime of aggression has yet to be clearly defined in international law.
The Italian Constitution enforces a mild pacifist character on the Italian Republic, as Article 11 states that "Italy repudiates war as an instrument offending the liberty of the peoples and as a means for settling international disputes..." Similarly, Articles 24, 25 and 26 of the German Constitution (1949), Alinea 15 of the French Constitution (1946), Article 20 of the Danish Constitution (1953), Article 9 of the Japanese Constitution (1947) and several other mostly European constitutions correspond to the United Nations Charter by rejecting the institution of war in favour of collective security and peaceful cooperation.
Pacifism and abstention from political activity.
However, some pacifists, such as the Christian anarchist Leo Tolstoy and autarchist Robert LeFevre, consider the state a form of warfare. In addition, for doctrinal reason that a manmade government is inferior to divine governance and law, many pacifist-identified religions/religious sects also refrain from political activity altogether, including the Anabaptists, Jehovah's Witnesses and Mandaeans. This means that such groups refuse to participate in government office or serve under an oath to a government.
Anarcho-pacifism.
Anarcho-pacifism (also pacifist anarchism or anarchist pacifism) is a form of anarchism which completely rejects the use of violence in any form for any purpose. The main precedent was Henry David Thoreau who through his work Civil Disobedience influenced the advocacy of both Leo Tolstoy and Mohandas Gandhi for nonviolent resistance. As a global movement, Anarchist pacifism emerged shortly before World War II in the Netherlands, Great Britain and the United States and was a strong presence in the subsequent campaigns for nuclear disarmament.
Violence has always been controversial in anarchism. While many anarchists during the 19th century embraced propaganda of the deed, Leo Tolstoy and other anarcho-pacifists directly opposed violence as a means for change. He argued that anarchism must by nature be nonviolent since it is, by definition, opposition to coercion and force and since the state is inherently violent, meaningful pacifism must likewise be anarchistic. His philosophy was cited as a major inspiration by Mohandas Gandhi, an Indian independence leader and pacifist who self-identified as an anarchist. Ferdinand Domela Nieuwenhuis was also instrumental in establishing the pacifist trend within the anarchist movement. In France anti-militarism appeared strongly in individualist anarchist circles as Émile Armand founded "Ligue Antimilitariste" in 1902 with Albert Libertad and George Mathias Paraf-Javal.
Opposition to military taxation.
Many pacifists who would be conscientious objectors to military service are also opposed to paying taxes to fund the military. In the United States, The National Campaign for a Peace Tax Fund works to pass a national law to allow conscientious objectors to redirect their tax money to be used only for non-military purposes.
Criticism.
One common argument against pacifism is the possibility of using violence to prevent further acts of violence (and reduce the "net-sum" of violence). This argument hinges on consequentialism: an otherwise morally objectionable action can be justified if it results in a positive outcome. For example, either violent rebellion, or foreign nations sending in troops to end a dictator's violent oppression "may" save millions of lives, even if many thousands died in the war. Those pacifists who base their beliefs on deontological grounds would oppose such violent action, arguing that nonviolent resistance should be just as effective and with a much lesser loss of life. Others would oppose organized military responses but support individual and small group self-defense against specific attacks if initiated by the dictator's forces. Pacifists may argue that military action could be justified should it subsequently advance the general cause of peace.
Still more pacifists would argue that a nonviolent reaction may not save lives immediately but would in the long run. The acceptance of violence for any reason makes it easier to use in other situations. Learning and committing to pacifism helps to send a message that violence is, in fact, not the most effective way. It can also help people to think more creatively and find more effective ways to stop violence without more violence.
In light of the common criticism of pacifism as not offering a clear alternative policy, one approach to finding "more effective ways" has been the attempt to develop the idea of "defence by civil resistance", also called "social defence". This idea, which is not necessarily dependent on acceptance of pacifist beliefs, is based on relying on nonviolent resistance against possible threats, whether external (such as invasion) or internal (such as coup d'état).
There have been some works on this topic, including by Adam Roberts and Gene Sharp. However, no country has adopted this approach as the sole basis of its defence. (For further information and sources see social defence.)
Japanese, Italian and Nazi aggression that precipitated World War II often is cited as an argument against pacifism. If these forces had not been challenged and defeated militarily, the argument goes, many more people would have died under their oppressive rule. Adolf Hitler told the British Foreign Secretary Lord Halifax in 1937 that the British should "shoot Gandhi, and if this doesn't suffice to reduce them to submission, shoot a dozen leading members of the Congress, and if that doesn't suffice shoot 200, and so on, as you make it clear that you mean business."
Adolf Hitler noted in his Second Book: "...Later, the attempt to adapt the living space to increased population turned into unmotivated wars of conquest, which in their very lack of motivation contained the germ of the subsequent reaction. Pacifism is the answer to it. Pacifism has existed in the world ever since there have been wars whose meaning no longer lay in the conquest of territory for a Folk's sustenance. Since then it has been war's eternal companion. It will again disappear as soon as war ceases to be an instrument of booty hungry or power hungry individuals or nations, and as soon as it again becomes the ultimate weapon with which a Folk fights for its daily bread." 
Hermann Göring described, during an interview at the Nuremberg Trials, how denouncing and outlawing pacifism was an important part of the Nazis' seizure of power: "The people can always be brought to the bidding of the leaders. That is easy. All you have to do is tell them they are being attacked and denounce the pacifists for lack of patriotism and exposing the country to danger. It works the same way in any country."
Some commentators on the most nonviolent forms of pacifism, including Jan Narveson, argue that such pacifism is a self-contradictory doctrine. Narveson claims that everyone has rights and corresponding responsibilities not to violate others' rights. Since pacifists give up their ability to protect themselves from violation of their right not to be harmed, then other people thus have no corresponding responsibility, thus creating a paradox of rights. Narveson said that "the prevention of infractions of that right is precisely what one has a right to when one has a right at all". Narveson then discusses how rational persuasion is a good but often inadequate method of discouraging an aggressor. He considers that everyone has the right to use any means necessary to prevent deprivation of their civil liberties and force could be necessary.
Many pacifists would argue that not only are there other ways to protect oneself but that some of those ways are far more effective than violence, and that physical harm is not the only variety that can be done. Often pacifists would much rather take the physical harm inflicted by another rather than cause themselves emotional or psychological harm, not to mention harming the other.
The ideology and political practice of pacifism also have been criticized by the radical American activist Ward Churchill, in his essay, "". Churchill argues that the social and political advancements pacifists claim resulted from non-violent action always have been made possible by concurrent violent struggles. In the late 1990s, Churchill's work convinced many anarchist and left-wing activists to adopt what they called "diversity of tactics" using "black bloc" formations that engage in property destruction and scuffles with police at larger mainstream protests.
One powerful pacifist reply to Churchill was from American activist George Lakey, a founder of Movement for a New Society, in a detailed response to "Pacifism as Pathology". Lakey quotes Martin Luther King in entitling his 2001 article "Nonviolent Action as the Sword that Heals". However, he takes on Churchill's assumptions and reading of history from a pragmatic viewpoint, arguing the superiority of nonviolent action by describing "some movements that learned, from their own pragmatic experience, that they could wage struggle more successfully through nonviolent direct action than through violence."

</doc>
<doc id="24958" url="http://en.wikipedia.org/wiki?curid=24958" title="Piet Hein">
Piet Hein

Piet Hein is the name of:

</doc>
<doc id="24959" url="http://en.wikipedia.org/wiki?curid=24959" title="Proteinoid">
Proteinoid

Proteinoids, or thermal proteins, are protein-like, often cross-linked molecules formed abiotically from amino acids. A slightly altered definition of proteinoids is from Hayakawa et al. (1967): "macromolecular preparations of mean molecular weights in the thousands, containing most of the twenty amino acids found in protein hydrolyzates. Although these polymers have other properties of contemporary protein as well, identity with the latter is not a necessary inference".
Its discoverer, Sidney W. Fox proposed the hypothesis that proteinoids were a precursor to the first living cells (protocell).
History.
In trying to uncover the intermediate stages of abiogenesis, scientist Sidney W. Fox in the 1950s and 1960s, studied the spontaneous formation of peptide structures under conditions that might plausibly have existed early in Earth's history. He demonstrated that amino acids could spontaneously form small chains called peptides. In one of his experiments, he allowed amino acids to dry out as if puddled in a warm, dry spot in prebiotic conditions. He found that, as they dried, the amino acids formed long, often cross-linked, thread-like microscopic polypeptide globules, he named "proteinoid microspheres".
Polymerization.
The abiotic polymerization of amino acids into proteins through the formation of peptide bonds was thought to occur only at temperatures over 140 °C. However, the biochemist Sidney Walter Fox and his co-workers discovered that phosphoric acid acted as a catalyst for this reaction. They were able to form protein-like chains from a mixture of 18 common amino acids at 70 °C in the presence of phosphoric acid, and dubbed these protein-like chains proteinoids. Fox later found naturally occurring proteinoids similar to those he had created in his laboratory in lava and cinders from Hawaiian volcanic vents and determined that the amino acids present polymerized due to the heat of escaping gases and lava. Other catalysts have since been found; one of them, amidinium carbodiimide, is formed in primitive Earth experiments and is effective in dilute aqueous solutions.
When present in certain concentrations in aqueous solutions, proteinoids form small microspheres. This is because some of the amino acids incorporated into proteinoid chains are more hydrophobic than others, and so proteinoids cluster together like droplets of oil in water. These structures exhibit a few characteristics of living cells:
Fox thought that the microspheres may have provided a cell compartment within which organic molecules could have become concentrated and protected from the outside environment during the process of chemical evolution.
Proteinoid microspheres are today being considered for use in pharmaceuticals, providing microscopic biodegradable capsules in which to package and deliver oral drugs.
In another experiment using a similar method to set suitable conditions for life to form, Fox collected volcanic material from a cinder cone in Hawaii. He discovered that the temperature was over 100 C just 4 in beneath the surface of the cinder cone, and suggested that this might have been the environment in which life was created—molecules could have formed and then been washed through the loose volcanic ash and into the sea. He placed lumps of lava over amino acids derived from methane, ammonia and water, sterilized all materials, and baked the lava over the amino acids for a few hours in a glass oven. A brown, sticky substance formed over the surface and when the lava was drenched in sterilized water a thick, brown liquid leached out. It turned out that the amino acids had combined to form proteinoids, and the proteinoids had combined to form small spheres. Fox called these "microspheres". His protobionts were not cells, although they formed clumps and chains reminiscent of bacteria. Based upon such experiments, Colin S. Pittendrigh stated in December 1967 that "laboratories will be creating a living cell within ten years," a remark that reflected the typical contemporary levels of innocence of the complexity of cell structures.
Legacy.
Fox has likened the amino acid globules to cells, and proposed it bridged the macromolecule to cell transition. However, his hypothesis was later dismissed as proteinoids are not proteins, they feature mostly non-peptide bonds and amino acid cross-linkages not present in living organisms. Furthermore, they have no compartamentalization and there is no information content in the molecules.
His hypothesis, however, was a catalyst to further investigate other mechanisms that could have brought about abiogenesis on Earth, such as RNA world, PAH world hypothesis, Iron–sulfur world theory, protocells, etc.

</doc>
<doc id="24960" url="http://en.wikipedia.org/wiki?curid=24960" title="Permanent Court of International Justice">
Permanent Court of International Justice

The Permanent Court of International Justice, often called the World Court, was an international court attached to the League of Nations. Created in 1922 (although the idea of an international court was several centuries old), the Court was initially met with a good reaction from states and academics alike, with many cases submitted to it for its first decade of operation. With the heightened international tension of the 1930s the Court was used with decreasing regularity; by a resolution by the League of Nations on 18 April 1946, the Court ceased to exist, being replaced by the International Court of Justice.
The Court's mandatory jurisdiction came from three sources; the Optional Clause of the League of Nations, general international conventions and special bipartite international treaties. Cases could also be submitted directly by states, but they were not bound to submit material unless it fell into those three categories. The Court could issue either judgments or advisory opinions; judgments were directly binding, while advisory opinions were not. In practice member states of the League of Nations followed advisory opinions anyway, fearing that to not do so could undermine the moral and legal authority of the Court and League. On occasion the Court was accused of extending its jurisdiction; strictly speaking only allowed to intervene in matters of international law, the Court became involved in municipal law during the Loans Cases.
History.
Founding and early years.
An international court had long been proposed; Pierre Dubois suggested it in 1305, and Émeric Crucé in 1623. An idea of an international court of justice arose in the political world at the First Hague Peace Conference in 1899, where it was declared that arbitration between states was the easiest solution to disputes, providing a temporary panel of judges to arbitrate in such cases, the Permanent Court of Arbitration. At the Second Hague Peace Conference in 1907, a draft convention for a permanent Court of Arbitral Justice was written, although disputes and other pressing business at the Conference meant that such a body was never established, owing to difficulties agreeing on a procedure to select the judges. The outbreak of the First World War, and in particular its conclusion, made it clear to many academics that some kind of world court was needed, and it was widely expected that one would be established. Article 14 of the Covenant of the League of Nations, created after the Treaty of Versailles, allowed the League to investigate setting up an international court. In June 1920, an Advisory Committee of jurists appointed by the League of Nations finally established a working guideline for the appointment of judges, and the Committee was then authorised to draft a constitution for a permanent court, not of arbitration (which is non-binding) but of justice. The Statute of the Permanent Court of International Justice was accepted in Geneva on December 13, 1920.
The Court first sat on 30 January 1922 at the Peace Palace, The Hague, covering preliminary business during the first session (such as establishing procedure and appointing officers) Nine judges sat, along with three deputies, since Antonio Sánchez de Bustamante y Sirven, Ruy Barbosa and Wang Ch'ung-hui were unable to attend, the latter being at the Washington Naval Conference. The Court elected Bernard Loder as President, and Max Huber as Vice-President; Huber was replaced by Charles Andre Weiss a month later. On 14 February the Court was officially opened, and rules of procedure were established on 24 March, when the court ended its first session. The court first sat to decide cases on 15 June. During its first year of business the Court issued three advisory opinions, all related to the International Labour Organisation created by the Treaty of Versailles, and collectively grouped into the International Labour Organisation Questions.
The initial reaction to the Court was a good one, from politicians, practising lawyers and academics alike. Ernest Pollock, the former Attorney General for England and Wales said "May we not as lawyers regard the establishment of an International Court of Justice as an advance in the science that we pursue?", John Henry Wigmore said that the creation of the Court "should have given every lawyer a thrill of cosmic vibration", and James Brown Scott wrote that "the one dream of our ages has been realised in our time". Much praise was heaped upon the appointment of an American judge, despite the fact that the United States had not become a signatory to the Court's protocol, and it was thought that that they would soon do so.
Increasing work and attempted entry of the United States.
The Court faced increasing work as it went on, allaying the fears of those commentators who had believed the Court would become like the Supreme Court of the United States, which was not presented with a case for its first six terms. The Court was given nine cases during 1922 and 1923, however,with judgments called "cases" and advisory opinions called "questions". Three cases were disposed of during the Court's first session, one during an extraordinary sitting between 8 January and 7 February 1923 (the Tunis-Morocco Nationality Question), four during the second ordinary sitting between 15 June 1923 and 15 September 1923 (Eastern Carelia Question, S.S. "Wimbledon" Case, German Settlers Question, Acquisition of Polish Nationality Question) and one during a second extraordinary session from 12 November to 6 December 1923 (Jaworznia Question). A replacement for Ruy Barbosa (who had died on 1 March 1923 without hearing any cases) was also found, with the election of Epitácio Lindolfo da Silva Pessoa on 10 September 1923. The workload the following year was reduced, containing two judgments and one advisory opinion; the Mavrommatis Palestine Concessions Case, the Interpretation of the Treaty of Neuilly Case (the first case of the Court's Chamber of Summary Procedure) and the Monastery of Saint-Naoum Question. During the same year a new President and Vice-President were elected, since they were mandated to serve for a term of 3 years. At the elections on 4 September 1924, Charles Andre Weiss was again elected Vice-President and Max Huber became the second President of the Court. Judicial pensions were created at the same time, with a judge being given 1/30th of his annual pay for every year he had served once he had both retired and turned 65.
1925 was an exceedingly busy year for the court, which sat for 210 days, with four extraordinary sessions as well as the ordinary session, producing 3 judgments and 4 advisory opinions. The first judgment was given in the Exchange of Greek and Turkish Populations Case, the second (by the Court of Summary Procedure) was on the interpretation of the Interpretation of the Treaty of Neuilly Case, and the third in the Mavrommatis Palestine Concessions Case. The 4 advisory opinions issued by the Court were in the Polish Postal Service in Danzig Question, the Expulsion of the Ecumenical Patriarch Question, the Treaty of Lausanne Question and the German Interests in Polish Upper Silesia Question. 1926 saw reduced business, with only one ordinary session and one extraordinary session; it was, however, the first year that all 11 judges had been present to hear cases. The court heard two cases, providing one judgment and one advisory opinion; a second question on German Interests in Polish Upper Silesia, this time a judgment rather than an advisory opinion, and an advisory opinion on the International Labour Organisation, grouped into the International Labour Organisation Questions.
Despite the drop-off of work in 1926, 1927 was another busy year, the Court sitting continuously from 15 June to 16 December, handing down 4 orders, 4 judgments and 1 advisory opinion. The judgments were in the Belgium-China Case, the Case Concerning the Factory at Chorzow, the Lotus Case and a continuation of the Mavrommatis Jerusalem Concessions Case. 3 of the advisory opinions were on the Competence of the European Commission on the Danube, and the 4th was on the Jurisdiction of Danzig Courts. The 4 orders were on the German Interests in Polish Upper Silesia. This year saw another set of elections; on 6 December, with Dionisio Anzilotti elected President and Charles Andre Weiss elected Vice-President. Weiss died the following year, and John Bassett Moore resigned; Max Huber was elected Vice-President on 12 September 1928 to succeed Weiss, while a second death (Lord Finlay) left the Court increasingly understaffed. Replacements for Moore and Finlay were elected on 19 September 1929; Henri Fromageot and Cecil Hurst respectively.
After the second round of elections in September 1930, the Court was reorganised. On 16 January 1931 Mineichirō Adachi was appointed President, and Gustavo Guerrero Vice-President. The United States finally recognised the Court's jurisdiction in, following a long and drawn out process. Warren G. Harding had first suggested US involvement in 1923, and in 9 December 1929, three court protocols were signed by him. On 10 December 1930, these were presented to the United States Senate, who postponed ratifying it on 16 December 1931 pending the discussion of "pressing domestic business". The United States finally accepted the Court's jurisdiction on 28 December 1935, but the treaty was never ratified, something which Francis Boyle attributes to a strong isolationist element in the US Senate, arguing that the ineffectiveness shown by US non-participation in the Court and other international institutions can be linked to the start of the Second World War.
Growing international tension and dissolution of the court.
1933 was a busy year for the court, which cleared its 20th case (and "greatest triumph"); the Eastern Greenland Case. This period was marked by growing international tension, however, with Japan and Germany announcing their withdrawal from the League of Nations, to come into effect in 1935. This did not directly affect the Court, since the protocol accepting Court jurisdiction was separately ratified, but it did influence whether a nation would be willing to bring a case before it, as evidenced by Germany's withdrawal from two pending cases. 1934, the Court's 13th year, "has been in keeping with the traditions associated with that number", with few cases, since the world's governments were more concerned with the growing international tension. The Court's business continued to be small in 1935, 1936, 1937, 1938, and 1939, although 1937 was marked by Monaco's acceptance of the Court protocol. The Court's judicial output in 1940 consisted entirely of a set of orders, completed in a meeting between 19 and 26 February, due to an international situation which left the Court with "uncertain prospects for the future". Following the German invasion of the Netherlands, the Court was unable to meet, although the Registrar and President were afforded full diplomatic immunity. Informed that this would not be tolerated after diplomatic missions from other nations left The Hague on 16 July, the President and Registrar left the Netherlands and moved to Switzerland, accompanied by their staff.
The Court was unable to meet during 1941, 1942, 1943 or 1944, although the framework remained intact, and it soon became apparent that the Court would be dissolved. In 1943 an international panel met to consider "the question of the Permanent Court of International Justice", meeting from 20 March to 10 February 1944. The panel agreed that the name and functioning of the Court should be preserved, but for some future court rather than a continuation of the current one. Between 21 August and 7 October 1944 the Dumbarton Oaks Conference was held, which among other things created an international court attached to the United Nations, to succeed the Permanent Court of International Justice. As a result of these conferences and others, the judges of the Permanent Court of International Justice officially resigned in October 1945, and via a resolution by the League of Nations on 18 April, the Court ceased to exist, being replaced with the International Court of Justice.
Organization.
Judges.
The Court initially consisted of 11 judges and 4 deputy judges, recommended by member states of the League of Nations to the Secretary General of the League of Nations, who would put them before the Council and Assembly for election. The Council and Assembly were to bear in mind that the elected panel of judges was to represent every major legal tradition in the League, along with "every major civilization". Each member state was allowed to recommend 4 potential judges, with a maximum of 2 from its own nation. Judges were elected by a straight majority vote, held independently in the Council and Assembly. The judges served for a period of nine years, with their term limits all expiring at the same time, necessitating a completely new set of elections. The judges were independent and rid themselves of their nationality for the purposes of hearing cases, owing allegiance to no individual member state, although it was forbidden to have more than one judge from the same state. As a sign of their independence from national ties, judges were given full diplomatic immunity when engaged in Court business The only requirements for a judge were "high moral character" and that they have "the qualifications required in their respective countries [for] the highest judicial offices" or be "jurisconsults of recognized competence in international law".
The first panel was elected on 14 September 1921, with the 4 deputies being elected on the 16th. On the first vote, Rafael Altamira y Crevea of Spain, Dionisio Anzilotti of Italy, Bernard Loder of the Netherlands, Ruy Barbosa of Brazil, Yorozu Oda of Japan, Charles Andre Weiss of France, Antonio Sánchez de Bustamante y Sirven of Cuba and Lord Finlay of the United Kingdom were elected by a majority vote of both the Council and Assembly on the first ballot taken. The second ballot elected John Bassett Moore of the United States, and the sixth Didrik Nyholm of Denmark and Max Huber of Switzerland. As the deputy judges, Wang Ch'ung-hui of China, Demetre Negulesco of Romania and Michaelo Yovanovich of Yugoslavia were elected. The Assembly and Council disagreed on the fourth deputy judge, but Frederik Beichmann of Norway was eventually appointed. Deputy judges were only substitutes for absent judges, and were not afforded a vote in altering court procedure or contributing at other times. As such, they were allowed to act as counsel in international cases where they were not sitting as judges.
In 1930 the number of judges was increased to 15, and a new set of elections were held. The election was held on 25 September 1930, with 14 candidates receiving a majority on the first ballot and a 15th, Francisco José Urrutia, receiving a majority on the second. The full court was Urrutia, Mineichiro Adachi, Altamira, Anzilotti, Bustamante, Jonkheer van Eysinga, Henri Fromageot, José Gustavo Guerrero, Cecil Hurst, Edouard Rolin-Jaequemyns, Frank B. Kellogg, Negulesco, Michał Jan Rostworowski, Walther Schücking and Wang Ch'ung-hui.
Judges were paid 15,000 Dutch florins a year, with daily expenses of 50 florins to pay for living expenses, and an additional 45,000 florins for the President, who was required to live at The Hague. Travelling expenses were also provided, and a "duty allowance" of 100 florins was provided when the court was sitting, with 150 for the Vice-President. This duty allowance was limited to 20,000 florins a year for the judges and 30,000 florins for the Vice-President; as such, it provided for 200 days of court hearings, with no allowance provided if the court sat for longer. The deputy judges received no salary, but when called up for service were provided with travel expenses, 50 florins a day for living expenses and 150 florins a day as a duty allowance.
Procedure.
Under the Covenant of the League of Nations, all League members agreed that where there was a dispute between states which they "recognize to be suitable for submission to arbitration and which cannot be satisfactorily settled by diplomacy", the matter would be submitted to the Court for arbitration, with suitable disputes being over the interpretation of an international treaty, a question on international law, the validity of facts which, if true, would breach international obligations and the nature of any reparations to be made for breaching international obligations. The original Statutes of the Court provided that all 11 judges were required to sit in every case. There were three exceptions; when reviewing Labour Clauses from a peace treaty such as the Treaty of Versailles (which was done by a special chamber of 5 judges, appointed every 3 years), when reviewing cases on communications or transport arising from a peace treaty (which used a similar procedure) and when hearing summary procedure cases, which were reviewed by a panel of 3 judges.
To prevent the appearance of any bias in the court's makeup, if there was a judge belonging to one member state on the panel and the other member state was not "represented", they had the ability to select an "ad hoc" judge of their own nationality to hear the case. In a full court hearing this increased the number to 12; in one of the 5-man chambers, the new judge took the place of 1 of the original 5. This did not apply to summary procedure cases. This "ad hoc" judge, selected by the member state, was expected to fulfil all the requirements of a normal judge; the President of the Court had ultimate discretion over whether to authorise him to sit. The Court was mandated to open on 15 June each year, and continue until all cases were finished, with extraordinary sessions if required; by 1927, there were more extraordinary sessions than ordinary ones. The Court's business being conducted in English and French as official languages, and hearings were public, unless otherwise specified.
After receiving files in a case calculated to lead to a judgment, the judges would exchange their views informally on the salient legal points of the case, and a time limit for producing a judgment would then be set. Following this, each judge would write an anonymous summary containing his opinion; these would be circulated among the Court for 2 or 3 days before the President drafted a judgment containing a summary of those submitted by individual judges. The Court would then agree on the decision that they wished to reach, along with the main points of argument they wished to use. Once this was done, a Committee of 4, including the President, the Registrar and two judges elected by secret ballot, drafted a final judgment, which was then voted on by the entire Court. Once a final judgment was set, it was given to the public and the press. Every judgment contained the reasons behind the decision and the judges assenting; if there was a dissenting judge, he was allowed to deliver his own judgment, with all judgments read in open court before the agents of the parties to the dispute. Judgments could only be revised based on the discovery of some fact which was unknown when the Court sat, but not if the fact was known but not discussed due to negligence.
The Court also issued "advisory opinions", which arose from Article 14 of the Covenant creating the Court, which provided "The Court may also give an advisory opinion upon any dispute referred to it by the Council or Assembly", which Goodrich interprets as indicating that the drafters intended a purely advisory capacity for the Court, not a binding one. Manley Ottmer Hudson (who sat as a judge) said that an advisory opinion "was what it purported to be. It is advisory. It is not in any sense a judgement... hence it is not in any way binding on any state", while Charles De Visscher argued that in certain situations, an advisory opinion could be binding on the League of Nations Council and, under certain circumstances, some states; M. Politis agreed, saying that the Court's advisory opinions were equivalent to a binding judgment. In 1927 the Court appointed a committee to look at this issue, and it reported that "where there are in fact contending parties, the difference between contentious cases and advisory cases is only nominal... so the view that advisory opinions are not binding is more theoretical than real". In practice, advisory opinions were usually followed, mostly due to the fear that if this "revolutionary" international court's decisions were "not" followed, it would undermine its authority. The court did retain the discretion to avoid giving an advisory opinion, and did use this on occasion.
Registrar and Registry.
Other than the judges, the Court also included a Registrar and his Secretariat, the Registry. When the Court met for its initial session, opened on 30 January 1922 to allow for the establishment of procedure and the appointment of Court officials, the Secretary-General of the League of Nations passed an emergency resolution through the Assembly which designated an official of the League and his staff as the Registrar and Registry respectively, with the first Registrar being Åke Hammarskjöld. The Registrar, required to reside within The Hague, was initially tasked with drawing up a plan to create an efficient Secretariat, using the smallest number of staff possible and costing as little as possible. As a result he decided to have each member of the Secretariat as the head of a particular Department, meaning that the numbers of actual employees could be increased or decreased as necessary without impacting on the actual Registry. In 1927 the post of Deputy-Registrar was created, tasked with dealing with legal research for the Court and answering all diplomatic correspondence received by the Registry. The first Deputy-Registrar was Paul Ruegger; after his resignation on 17 August 1928, Julio Lopez Olivan was selected to succeed him. Olivan resigned in 1931 to take over from Hammarskjöld as Registrar, and was replaced by M. L. J. H. Jorstad.
The three principal officers of the Registry, after the Registrar and Deputy-Registrar, were the three Editing Secretaries. The first Editing Secretary, known as the Drafting Secretary, was tasked with drafting the Court's publications (including the Confidential Bulletin, a document exclusively received by judges of the court) and Sections D and E of the official journal, comprising the legislative clauses conferring jurisdiction on the Court and the Court's Annual Report. The second Editing Secretary, known as the Oral Secretary, was mainly responsible for the oral interpretation and translation of the Court's discussions. For public hearings he was assisted by interpreters, but for private meetings only he, the Registrar and the Deputy-Registrar were admitted. As a result of this duty, the Oral Secretary is also tasked with writing Section C of the official journal, which comprises the oral interpretations of Court minutes, along with cases and questions put before the court. The third Secretary, known as the Written Secretary, was tasked with the written translations of the Court's business, which were "both numerous and voluminous". He was assisted in this by the other Secretaries and by translators for languages not his own; all Secretaries were expected to speak English and French fluently, and have working knowledges of German and Spanish.
The Registry was split into several Departments; the Archives, the Accounting and Establishment, the Printing Service and the Copying Department. The Archives included a distribution service for the Court's documents and the legal texts used by the Court itself, and was described as one of the most difficult departments to organise. The Accounting and Establishment Department dealt with the requests for and allocation of the Court's yearly budget, which was drawn up by the Registrar, approved by the Court and submitted to the League of Nations. The Printing Department, run from a single printing plant in Leiden, was created to allow the circulation of the Court's publishings. The Copying Department comprised shorthand, typing and copying services, and included secretaries for the Registrar and judges, emergency reporters capable of taking notes down verbatim and copyists; the smallest of the departments, it comprised between 12 and 40 staff depending on the business of the Court.
Jurisdiction.
The Court's jurisdiction was largely optional, but there were some situations in which they had "compulsory jurisdiction", where states were required to refer cases to them. This came from three sources; the Optional Clause of the League of Nations, general international conventions and "special bipartite international treaties". The Optional Clause was a clause attached to the protocol establishing the court which required all signatories to refer certain classes of dispute to the court, with compulsory judgments resulting. There were approximately 30 international conventions which the Court had similar jurisdiction under, including the Treaty of Versailles, the Air Navigation Convention, the Treaty of St. Germain and all mandates signed by the League of Nations. It was also foreseen that there would be clauses inserted in bipartite international treaties which would allow the referral of disputes to the Court; this indeed occurred, with such provisions found in treaties between Czechoslovakia and Austria, and between Czechoslovakia and Poland.
Throughout its existence, the Court widened its jurisdiction as much as possible. Strictly speaking, the Court's jurisdiction was only for disputes between states, although despite this they regularly accepted disputes that were between a state and an individual if a second state brought the individual's case to the Court, arguing that in doing this the second state asserts its rights, and the cases therefore becomes one between 2 states. Despite the proviso that the Court was for disputes "which cannot be satisfactorily settled by diplomacy", the Court never required evidence that diplomatic discussions had been attempted before bringing the case. In the Loan Cases it asserted jurisdiction despite the fact that there was no alleged breach of international law, and it could not be shown that there was any international element to the claim. The Court justified this by saying that the Covenant of the League of Nations allowed them jurisdiction in cases over "the existence of any fact which, if established, would constitute a breach of international obligations", arguing that since the fact "may be of any kind" they have jurisdiction if the dispute is one of municipal law. It was long established that municipal law may be considered as a side point to a dispute over international law, but the Loan Cases discussed municipal law without the application of any international points.
Bibliography.
</dl>

</doc>
<doc id="24961" url="http://en.wikipedia.org/wiki?curid=24961" title="Prince Albert (genital piercing)">
Prince Albert (genital piercing)

The Prince Albert (PA) is one of the more common male genital piercings, but most controversial based on the most educational recent study. The PA is "a ring-style piercing that extends along the underside of the glans from the urethral opening to where the glans meets the shaft of the penis." The related "reverse Prince Albert piercing" enters through the urethra and exits through a hole pierced in the top of the glans.
While some piercers may choose to avoid the nerve bundle that runs along the center of the frenulum altogether, others may choose otherwise. The piercing can be centered if the bearer is circumcised. Otherwise, the piercing must be done off-center so that the surrounding skin is able to reposition itself.
Healing and potential side effects.
The Prince Albert healing time can take from 4 weeks to 6 months. A fresh PA piercing may cause bleeding, swelling and inflammation. In rare cases, it can lead to local infections. Some men find that the dribble caused by the PA when urinating necessitates sitting down to urinate. With practice, some men are able to control the stream while standing.
Some PA wearers report it enhances sexual pleasure for both partners. Some people penetrated by males with this piercing report discomfort. PA rings can cause additional discomfort to female partners in cases when the penis comes in contact with the cervix. Sexual partners of those with piercings may experience complications during oral sex such as chipped teeth, choking, foreign bodies getting stuck between the partner's teeth, and mucosal injury to receptive partners.
As with many piercings, there is risk of the jewelry becoming caught on clothing and being pulled or torn out, but this is usually only a concern with rings. Very large gauge or heavy jewelry can cause thinning of the tissue between the urethral opening and the healed fistula resulting in an accidental tearing or other complications with sexual experiences. Conversely, extremely thin jewelry can cause the same tearing in what is commonly referred to as the "cheese cutter effect", either during sudden torsion or over a long period of wearing, especially if the thin jewelry bears any weight. In some cases this can be corrected surgically.
Jewelry.
Prince Albert piercings are typically pierced at either 10 or 8 gauge. They are often (gradually) stretched soon after, with jewelry within the 8g to 2g range being the most popular. One of the reasons not to perform the initial piercing at a small diameter (16g, 14g or 12g) and/or to immediately stretch it to 8g or 6g using a taper is to prevent the 'cheese cutter effect', although personal preference and individual anatomy also play a role in these decisions.
Further stretching to sizes above 10 mm is possible. If a sufficiently heavy barbell or ring is worn continuously, a mild form of 'auto-stretching' can be observed. This means that stretching to a larger gauge is easier and might not require a taper.
While most wearers find that PAs are comfortable to wear and rarely remove them, even during sex, some individuals might find that extremely large or heavy jewelry is uncomfortable to wear for long periods or interferes with the sexual functioning of the penis.
Jewelry suitably worn in a Prince Albert piercing includes the circular barbell, curved barbell, captive bead, segment ring and the prince's wand. Curved barbells used for PA piercings are usually 7/8" in length, such that one ball sits on the lower side of the penis and the other ball sits at the urethral opening. This type of jewelry prevents discomfort that can come from larger jewelry moving around during daily wear.
Prince's wand.
The prince's wand consists of a hollow tube with a threaded cap at the end. The tube is inserted into the urethra, and a stem is inserted through the PA piercing and into another threaded hole on the side of the tube. The general shape is similar to a policeman's baton. The side stem holds the tube in place. The threaded cap, often just a ball, can be removed so the wearer can urinate through the hollow tube without having to remove the jewelry.
History and culture.
The origin of this piercing is unknown. Many theories suggest that the piercing was used to secure the penis in some manner, rather than having a sexual or cultural purpose.
In modern times, the Prince Albert piercing was popularized by Jim Ward in the early 1970s. In West Hollywood, Ward met Doug Malloy and Fakir Musafar. Together, these men further developed the Prince Albert piercing. Malloy published a pamphlet in which he concocted fanciful histories of genital piercings in particular. These apocryphal tales—which included the notion that Albert, the Prince Consort invented the piercing that shares his name in order to tame the appearance of his large penis in tight trousers—are widely circulated as urban legend. No historical proof of their veracity has been located independent of Malloy's assertions.
Like many other male genital piercings, it had a history of practice in gay male subculture in the twentieth century. It became more prominently known when body piercing expanded in the late 1970s and was gradually embraced by popular culture.

</doc>
<doc id="24962" url="http://en.wikipedia.org/wiki?curid=24962" title="Paint Your Wagon (musical)">
Paint Your Wagon (musical)

Paint Your Wagon is a Broadway musical comedy, with book and lyrics by Alan J. Lerner and music by Frederick Loewe. The story centers on a miner and his daughter and follows the lives and loves of the people in a mining camp in Gold Rush-era California. Popular songs from the show included "Wand'rin' Star", "I Talk to the Trees" and "They Call the Wind Maria".
The musical ran on Broadway in 1951 and in the West End in 1953. In 1969 the film version also titled "Paint Your Wagon" was released. It had a highly revised plot and some new songs composed by Lerner and André Previn.
Synopsis.
In the California Wilderness in May 1853, a crusty old miner, Ben Rumson, is conducting a makeshift funeral for a friend. Meanwhile his 16-year-old daughter Jennifer discovers gold dust. Ben claims the land, and prospectors start flocking to the brand new town of Rumson ("I'm On My Way"). Two months later Rumson has a population of 400, all of whom are men except for Jennifer. Prospector Jake Whippany is waiting to save enough money to send for Cherry and her Fandango girls ("Rumson"), while Jennifer senses the tension building in town ("What's Going On Here?"). Julio Valveras, a handsome young miner forced to live and work outside of town because he is Mexican, comes to town with dirty laundry and runs into Jennifer, who volunteers to do his laundry. They also talk to each other ("I Talk to the Trees"). Steve Bulmarck and the other men ponder the lonely nomadic life they lead in the song "They Call the Wind Maria".
Two months later the men want Ben to send Jennifer away, and he wishes her mother was still alive to help him ("I Still See Elisa"). Jennifer is in love with Julio ("How Can I Wait?"), and when Ben sees Jennifer dancing with Julio's clothes, he decides to send her East on the next stage. Jacob Woodling, a Mormon man with two wives, Sarah and Elizabeth, arrives in Rumson where the men demand Jacob sell one of his wives. To his surprise, Ben finds himself wooing Elizabeth ("In Between") and wins her for $800 ("Whoop-Ti-Yay"). Jennifer is disgusted by her father's actions and runs away, telling Julio that she will be reunited with him in a year's time ("Carino Mio"). Cherry and her Fandango girls arrive ("There's a Coach Comin' In"). Julio learns his claim is running dry which means he has to move on to make a living and that he will not be there to greet Jennifer when she returns.
A year later in October, the miners celebrate the high times in Rumson now that the Fandango girls are around ("Hand Me Down That Can o' Beans"). Edgar Crocker, a miner who has saved his money, falls for Elizabeth and she responds, although Ben does not notice since he thinks Raymond Janney is in love with her (he is). Another miner, Mike Mooney, tells Julio about a lake that has gold dust on the bottom and he considers looking for it ("Another Autumn"). Jennifer returns in December, having learned civilized ways back East ("All for Him"). Ben tells his daughter that he will soon be moving on since he was not meant to stay in one place for long ("Wand'rin' Star"). The next day as Cherry and the girls are packing to leave they tell her about Julio leaving to find the lake with a bottom of gold. Raymond Janney offers to buy Elizabeth from Ben for $3,000, but she runs off with Edgar Crocker.
Word comes of another strike 40 miles south of Rumson and the rest of the town packs up to leave except for Jennifer, who is waiting for Julio to return, and Ben, who suddenly realizes that Rumson is indeed his town. Late in April, Julio appears, a broken man. The now dying Ben welcomes him and Julio is amazed to see Jennifer is there. As they move toward each other, the wagons filled with people move on.
Productions.
The musical opened on Broadway at the Shubert Theatre on November 12, 1951, and closed on July 19, 1952, after 289 performances. The production was directed by Daniel Mann, set design by Oliver Smith, costume design by Motley, lighting design by Peggy Clark, music for dances arranged by Trude Rittmann, with dances and musical ensembles by Agnes de Mille set to the orchestrations of Ted Royal.
It starred James Barton (as Ben Rumson), Olga San Juan (Jennifer Rumson), Tony Bavaar (Julio Valveras), Gemze de Lappe (Yvonne Sorel), James Mitchell (Pete Billings), Kay Medford (Cherry), and Marijane Maricle (Elizabeth Woodling). Burl Ives and Eddie Dowling later took over the role of Ben Rumson. De Mille later restaged the dances as a stand-alone ballet, "Gold Rush".
The West End production opened on February 11, 1953 at Her Majesty's Theatre and ran for 477 performances. It starred real life father and daughter Bobby Howes and Sally Ann Howes.
A new production, with a revised libretto by David Rambo, was premiered at the Brentwood Theatre, produced by the Geffen Playhouse in association with Christopher Allen, D. Constantine Conte, and Larry Spellman in Los Angeles, California, from November 23, 2004, to January 9, 2005. This new world premier adaptation was directed by Gilbert Cates (Academy Awards) and choreographed by Kay Cole. Design team included musical director Steve Orich, who provided arrangements and orchestrations. The design team featured Daniel Ionazzi (scenic and lighting), David Kay Mickeleson (costume) and Phil Allen (sound). The cast included Thomas F. Wilson (Back to the Future I, II, III) as Ben Rumson, Jessica Rush as his daughter Jennifer, Sharon Lawrence (Desperate Housewives, NYPD Blue) as Lily, with other cast members including Erika Amato, Robert Alan Clink, Janelle Dote, Joe Garcia, Steven Hack, David Jennings, Rob Kahn, Daniel Lujan, Alex Mendoza, Harry S. Murphy, Tracy Powell, Morgan Rusler, Jessica Rush, Andy Umberger, and Ian Shen. One change from the original was "They Call the Wind Maria" staged as an ensemble number instead of a showcase solo.
A subsequent production was produced by the Pioneer Theatre Company in Salt Lake City, Utah and ran from September 28, 2007, through October 13, 2007. The director was Charles Morey and choreographer Patti D'Beck, with a cast of nearly 30.
Reception.
"The interwoven use of ballet that worked so well in the highlands was less effective on the Prairies, and the subject matter was harsh and cold. In spite of the show's failure, Loewe displayed ... an uncanny ability to write scores indigenous to the time and locale of the characters and plots."
The reviewer for the "Deseret Morning News "(Salt Lake City), wrote of the 2007 Pioneer Theatre Company production: "Paint Your Wagon" has a lusty new lease on life and is rarin' to go. The original music is intact, although some songs have been shuffled into better positions in the revised plot. And most of the familiar characters are still there. ... Rambo and Orich's overhauled "Wagon" is a vast improvement over the 1951 model, enhanced by Pioneer Theatre Company's usual Broadway-quality scenery, costuming, lighting and sound, along with Mearle Marsh's superb pit orchestra."

</doc>
<doc id="24965" url="http://en.wikipedia.org/wiki?curid=24965" title="Pacific Overtures">
Pacific Overtures

Pacific Overtures is a musical written by Stephen Sondheim and John Weidman. The show is set in 1853 Japan and follows the difficult Westernization of Japan, told from the point of view of the Japanese. In particular, the story focuses on the lives of two friends caught in the change.
The title of the work is drawn directly from text in a letter from Admiral Perry addressed to the Emperor dated July 7, 1853:
"Many of the large ships-of-war destined to visit Japan have not yet arrived in these seas, though they are hourly expected; and the undersigned, as an evidence of his friendly intentions, has brought but four of the smaller ones, designing, should it become necessary, to return to Edo in the ensuing spring with a much larger force. But it is expected that the government of your imperial majesty will render such return unnecessary, by acceding at once to the very reasonable and "pacific overtures" contained in the President's letter, and which will be further explained by the undersigned on the first fitting occasion."
In addition to playing on the musical term "overture" and the geographical reference to the Pacific Ocean there is also the irony, revealed as the story unfolds, that these "pacific overtures" to initiate commercial exploitation of the Pacific nation were backed by a none too subtle threat of force.
Built around a quasi-Japanese pentatonic scale, the music contrasts Japanese contemplation ("There is No Other Way") with Western ingenuousness ("Please Hello"). The score is generally considered to be one of Sondheim's most ambitious and sophisticated efforts.
The original Broadway production of "Pacific Overtures" in 1976 was presented in Kabuki style, with men playing women's parts and set changes made in full view of the audience by people dressed in black. It opened to mixed reviews and closed after six months, despite being nominated for ten Tony Awards.
Given the unusual casting and production demands, "Pacific Overtures" remains one of the least-performed musicals by Stephen Sondheim. The show is occasionally put on by opera companies.
Productions.
"Pacific Overtures" previewed in Boston and ran at The Kennedy Center for a month before opening on Broadway at the Winter Garden Theatre on January 11, 1976. It closed after 193 performances on June 27, 1976. Directed by Harold Prince, the choreography was by Patricia Birch, scenic design by Boris Aronson, costume design by Florence Klotz, and lighting design by Tharon Musser. The original cast recording was released originally by RCA Records and later on CD. This production was nominated for 10 Tony Awards, and won Best Scenic Design (Boris Aronson) and Best Costume Design (Florence Klotz).
An off-Broadway production ran at the Promenade Theatre from October 25, 1984 for 109 performances, transferring from an earlier production at the York Theatre Company. Directed by Fran Soeder with choreography by Janet Watson, the cast featured Ernest Abuba and Kevin Gray.
The European premiere was directed by Howard Lloyd-Lewis (Library Theatre, Manchester) at Wythenshawe Forum in 1986 with choreography by Paul Kerryson who subsequently directed productions in 1993 and 2006 at Leicester Haymarket Theatre.
A major production of the show was mounted in London by the English National Opera in 1987. The production was recorded in its entirety, preserving nearly the entire libretto as well as the score.
A critically acclaimed 2001 Chicago Shakespeare Theater production, directed by Gary Griffin, transferred to the West End Donmar Warehouse, where it ran from June 30, 2003 until September 6, 2003 and received the 2003 Olivier Award for Best Musical Production.
In 2002 the New National Theatre of Tokyo presented two limited engagements of their production, which was performed in Japanese with English supertitles. The production ran at Avery Fisher Hall, Lincoln Center from July 9, 2002 through July 13, and then at the Eisenhower Theater, Kennedy Center, from September 3, 2002 through September 8.
A Broadway revival ran at Studio 54 from December 2, 2004 to January 30, 2005, directed by Amon Miyamoto and starring B.D. Wong as the Narrator and several members of the original cast. A new Broadway recording, with new (reduced) orchestrations by orchestrator Jonathan Tunick was released by PS Classics, with additional material not included on the original cast album. The production was nominated for four Tony Awards, including Best Revival of a Musical.
The Original broadway production was filmed and broadcast on Japanese television in 1976.
Synopsis.
Conceived as a sort of Japanese playwright's version of an American musical about American influences on Japan, "Pacific Overtures" begins its journey to the present day in July 1853. Since the foreigners were driven from the island empire, explains the Reciter, there has been nothing to threaten the changeless cycle of their days. Elsewhere, wars are fought and machines are rumbling but in Nippon they plant rice, exchange bows and enjoy peace and serenity. ("The Advantages of Floating in the Middle of the Sea") But President Millard Fillmore, determined to open up trade with Japan, has sent Commodore Matthew C. Perry across the Pacific.
To the consternation of Lord Abe and the Shogun's other Councillors, the stirrings of trouble begin with the appearance of Manjiro, a fisherman who was lost at sea and rescued by Americans. He returns to Japan and attempts to warn Abe of the presence of warships in the waters around Okinawa, but is instead arrested for consorting with foreigners. A minor samurai, Kayama, is appointed Prefect of the Police at Uraga to drive the Americans away - news which leaves Tamate, his wife, grief-stricken since it will result in certain failure and shame. As he leaves, she expresses her feelings in dance as two Observers describe the scene and reveal her thoughts ("There Is No Other Way"). As a Fisherman, a Thief, and other locals relate the sight of the "Four Black Dragons" roaring through the sea, an extravagant Oriental caricature of the USS Powhatan pulls into harbor. Kayama is sent to meet with the Americans but he is rejected as not important enough. He enlists the aid of Manjiro, the only man in Japan who has dealt with Americans, and disguised as a great lord, Manjiro gets an answer from them: Commodore Perry announces that he must meet the Shogun within six days or else he will shell the city. Faced with this ultimatum, the Shogun refuses to commit himself to an answer and takes to his bed. Exasperated by his indecision, his Mother, with elaborate courtesy, poisons him. ("Chrysanthemum Tea").
With the Shogun dead, Kayama devises a plan by which the Americans, thanks to a covering of tatami mats and a raised Treaty House, can be received without having, technically, to set foot on Japanese soil. He and Manjiro set off for Uraga, forging a band of friendship through the exchange of "Poems". Kayama has saved Japan, but it is too late to save Tamate. He returns home to find her dead from seppuku. Already events are moving beyond the control of the old order: the two men pass a Madam instructing her inexperienced Girls in the art of seduction as they prepare for the arrival of the foreign devils ("Welcome to Kanagowa").
Commodore Perry and his men come ashore and, on their "March to the Treaty House", demonstrate their goodwill by offering such gifts as two bags of Irish potatoes and a copy of Owen's "Geology of Minnesota". The negotiations themselves are seen through the memory of three who were there: a warrior who could hear the debates but not see it from his hiding place under the floor of the house, a young boy who could see the action but not hear it from his perch in the tree outside, and the boy as an old man recalling that without "Someone In a Tree", a silent watcher, history may have been incomplete. Initially, it seems as if Kayama has won: the Americans depart in peace. But then the barbarian figure of Commodore Perry leaps out to perform a traditional Kabuki "Lion Dance", which ends as a strutting, triumphalist, all-American cakewalk.
The child emperor (portrayed by a puppet manipulated by his advisors) reacts with pleasure to the departure of the Americans, promoting Lord Abe to Shogun, Kayama to Governor of Uraga and Manjiro to the rank of Samurai. The crisis appears to have passed, but to the surprise of Lord Abe the Americans return to request formal trading arrangements. To the tune of a Sousa march, they bid Japan "Please Hello" and are followed by a Gilbertian British Admiral, a clog-dancing Dutch Admiral, a gloomy Russian and a dandified Frenchman all vying for access to Japan's markets. With this new western threat, the faction of the Lords of the South grow restless. They send a politically charged gift to the Emperor, a storyteller who tells a vivid, allegorical tale of a brave young emperor who frees himself from his cowardly Shogun.
Fifteen years pass as Kayama and Manjiro dress themselves for tea. As Manjiro continues to dress with painstaking slowness into ceremonial robes for the tea ritual, Kayama slowly adopts the manners and dress of the newcomers, proudly displaying his new pocket watch, cutaway coat and "A Bowler Hat". But there are other less pleasant changes prompted by westernization. Three British Sailors mistake a the daughter of a samurai for a geisha ("Pretty Lady"). Though their approach is initially gentle, they grow more persistent to the point where they offer her money (with insinuations of rape); the girl cries for help and her father kills one of the confused Tars. Reporting on the situation to the Shogun, Kayama witnesses Lord Abe's murder by cloaked assassins and himself is killed by one of their number - his former friend, Manjiro.
In the ensuing turmoil the puppet Emperor seizes real power and vows that Japan will modernize itself. As the country moves from one innovation to the "Next!", the Imperial robes are removed layer by layer to show the Reciter in T-shirt and black trousers. Contemporary Japan - the world of Toyota and Seiko, air pollution and market domination -assembles itself around him. "There was a time when foreigners were not welcome here. But that was long ago..." he says, "Welcome to Japan."
Critical response and analysis.
"Someone in a Tree," where two witnesses describe negotiations between the Japanese and Americans, is Sondheim's favorite song out of everything he's ever written. "A Bowler Hat" presents the show's theme, as a samurai gradually becomes more modernized as he sells out to the Westerners.
The "New York Times" review of the original 1976 production said "The lyrics are totally Western and—as is the custom with Mr. Sondheim—devilish, wittily and delightfully clever. Mr. Sondheim is the most remarkable man in the Broadway musical today—and here he shows it victoriously...Mr. Prince's staging uses all the familiar Kabuki tricks—often with voices screeching in the air like lonely sea birds—and stylizations with screens and things, and stagehands all masked in black to make them invisible to the audience. Like choreography, the direction is designed to meld Kabuki with Western forms...the attempt is so bold and the achievement so fascinating, that its obvious faults demand to be overlooked. It tries to soar—sometimes it only floats, sometimes it actually sinks—but it tries to soar. And the music and lyrics are as pretty and as well-formed as a bonsai tree. "Pacific Overtures" is very, very different."
Walter Kerr's article in the "New York Times" on the original 1976 production said "But no amount of performing, or of incidental charm, can salvage "Pacific Overtures." The occasion is essentially dull and immobile because we are never properly placed in it, drawn neither East nor West, given no specific emotional or cultural bearings."
The "New York Times" review of the 1984 revival stated that "the show attempts an ironic marriage of Broadway and Oriental idioms in its staging, its storytelling techniques and, most of all, in its haunting Stephen Sondheim songs. It's a shotgun marriage, to be sure - with results that are variously sophisticated and simplistic, beautiful and vulgar. But if "Pacific Overtures" is never going to be anyone's favorite Sondheim musical, it is a far more forceful and enjoyable evening at the Promenade than it was eight years ago at the Winter Garden...Many of the songs are brilliant, self-contained playlets. In "Four Black Dragons" various peasants describe the arrival of the American ships with escalating panic, until finally the nightmarish event does seem to be, as claimed, "the end of the world."..."Someone in a Tree," is a compact "Rashomon" - and as fine as anything Mr. Sondheim has written...The single Act II triumph, "Bowler Hat," could well be a V. S. Naipaul tale set to music and illustrated with spare Japanese brushstrokes..."Bowler Hat" delivers the point of "Pacific Overtures" so artfully that the rest of Act II seems superfluous."
The 2004 production was not as well received. Based on a critically praised Japanese language production by director Amon Miyamoto, "Now Mr. Miyamoto and "Pacific Overtures" have returned with an English-speaking, predominantly Asian-American cast, which makes distracting supertitles unnecessary. The show's sets, costumes and governing concept remain more or less the same. Yet unlike the New National Theater of Tokyo production, which was remarkable for its conviction and cohesiveness, this latest incarnation from the Roundabout Theater Company has the bleary, disoriented quality of someone suffering from jet lag after a sleepless trans-Pacific flight. Something has definitely been lost in the retranslation." Speaking of the cast, reviewer Ben Brantley stated, "Even as they sing sweetly and smile engagingly, they appear to be asking themselves, "What am I doing here?""

</doc>
<doc id="24967" url="http://en.wikipedia.org/wiki?curid=24967" title="Paradoxical intention">
Paradoxical intention

In psychotherapy, paradoxical intention is the deliberate practice of a neurotic habit or thought, undertaken to identify and remove it. The concept was termed by Dr. Viktor Frankl, the founder of Logotherapy, who advocated for its use by patients experiencing severe forms of anxiety disorders.
Used as a counseling technique in which the counselor intensifies the client's emotional state in order to help the client understand the irrationality of the emotional reaction.

</doc>
<doc id="24968" url="http://en.wikipedia.org/wiki?curid=24968" title="Peter Stuyvesant">
Peter Stuyvesant

Peter Stuyvesant ( 1612 – August 1672), known as Petrus, served as the last Dutch Director-General of the colony of New Netherland from 1647 until it was ceded provisionally to the English in 1664, after which it was renamed New York. He was a major figure in the early history of New York City.
Stuyvesant's accomplishments as director-general included a great expansion for the settlement of New Amsterdam beyond the southern tip of Manhattan. Among the projects built by Stuyvesant's administration were the protective wall on Wall Street, the canal that became Broad Street, and Broadway.
Life and career.
Stuyvesant was born around 1612 in Peperga, Friesland in the Netherlands, to minister Balthazar Johannes Stuyvesant and Margaretha Hardenstein. He grew up in Scherpenzeel. He studied languages and philosophy in Franeker, and joined the West India Company about 1635, and was director of the Dutch West India Company's colony of Curaçao from 1642 to 1644.
In April 1644, he attacked the Spanish-held island of Saint Martin and lost the lower part of his right leg to a cannonball. He returned to the Netherlands, where his right leg was amputated and replaced with a wooden peg. Supposedly, Stuyvesant was given the nickname "Old Silver Leg" because he used a stick of wood driven full of silver bands as a prosthetic limb.
A year later, in May 1645, Stuyvesant was selected by the Dutch West India Company to replace Willem Kieft as Director-General of the New Netherland colony, in present-day New York. He arrived in New Amsterdam on May 11, 1647. In September 1647, he appointed an advisory council of nine men as representatives of the colonists on New Amsterdam.
He married Judith Bayard ( 1610-1687) of the Bayard family in 1645. Her brother Samuel, was the husband of Pieter's sister Anna. Judith had nursed him back to health following the loss of his right lower leg at Saint Martin and subsequent return to the Netherlands to recuperate. Pieter and Judith's daughter, also named Judith, married Benjamin Winthrop, son of John Still Winthrop of the Dudley–Winthrop family and second wife Elizabeth Shirreff. Pieter and Judith's son, Nicolaes Willem Stuyvesant (1648–1698), married Maria Beeckman, daughter of Willem Beeckman.
In 1648, a conflict started between him and Brant Aertzsz van Slechtenhorst, the commissary of the patroonship Rensselaerwijck, which surrounded Fort Orange (present-day Albany). Stuyvesant claimed he had power over Rensselaerwijck despite special privileges granted to Kiliaen van Rensselaer in the patroonship regulations of 1629. In 1649, Stuyvesant marched to Fort Orange with a military escort and ordered bordering settlement houses to be razed to permit a better defense of the fort in case of an attack from the Native Americans. When Van Slechtenhorst refused, Stuyvesant sent a group of soldiers to enforce his orders. The controversy that followed resulted in the founding of the new settlement, Beverwijck.
Stuyvesant became involved in a dispute with Theophilus Eaton, the governor of English New Haven Colony, over the border of the two colonies. In September 1650, a meeting of the commissioners on boundaries took place in Hartford, Connecticut, called the Treaty of Hartford, to settle the border between New Amsterdam and the English colonies to the north and east. The border was arranged to the dissatisfaction of the Nine Men, who declared that "the governor had ceded away enough territory to found fifty colonies each fifty miles square." Stuyvesant then threatened to dissolve the council. A new plan of municipal government was arranged in the Netherlands, and the name "New Amsterdam" was officially declared on 2 February 1653. Stuyvesant made a speech for the occasion, saying that his authority would remain undiminished.
Petrus was now ordered to the Netherlands, but the order was soon revoked under pressure from the States of Holland and the city of Amsterdam. Stuyvesant prepared against an attack by ordering the citizens to dig a ditch from the North River to the East River and to erect a fortification.
In 1653, a convention of two deputies from each village in New Netherland demanded reforms, and Stuyvesant commanded that assembly to disperse, saying: "We derive our authority from God and the company, not from a few ignorant subjects."
In the summer of 1655, he sailed into the Delaware River with a fleet of seven vessels and about 700 men and took possession of the colony of New Sweden, which was renamed "New Amstel." In his absence, Pavonia was attacked by Native Americans, during the "Peach War" on September 15, 1655.
Religious freedom.
In 1657 Stuyvesant, who did not tolerate full religious freedom in the colony, and was strongly committed to the supremacy of the Dutch Reformed Church, refused to allow Lutherans the right to organize a church. When he also issued an ordinance forbidding them from worshiping in their own homes, the directors of the Dutch West Indies Company, of whom three were Lutherans, told him to rescind the order and allow private gatherings of Lutherans.
Freedom of religion was also tested when Peter Stuyvesant refused to allow Jews from Northern Brazil to settle permanently in New Amsterdam (without passports) and join the existing community of Jews (with passports from Amsterdam). Stuyvesant attempted to have Jews "in a friendly way to depart" the colony. As he wrote to the Amsterdam Chamber of the Dutch West India Company in 1654 he hoped that "the deceitful race, — such hateful enemies and blasphemers of the name of Christ, — be not allowed to further infect and trouble this new colony." He referred to Jews as a "repugnant race" and "usurers", and was concerned that "Jewish settlers should not be granted the same liberties enjoyed by Jews in Holland, lest members of other persecuted minority groups, such as Roman Catholics, be attracted to the colony."
Stuyvesant's decision was rescinded after pressure from the directors of the Company; as a result, Stuyvesant allowed Jewish immigrants to stay in the colony as long as their community was self-supporting, but — with the support of the company — would not allow them to build a synagogue, forcing them to worship instead in a private house.
Then, in 1657, Stuyvesant turned to the newly arrived Quakers in the colony. He ordered the public torture of Robert Hodgson, a 23-year-old Quaker convert who had become an influential preacher. Stuyvesant then made an ordinance, punishable by fine and imprisonment, against anyone found guilty of harboring Quakers. That action led to a protest from the citizens of Flushing, Queens, which came to be known as the Flushing Remonstrance, considered by some a precursor to the United States Constitution's provision on freedom of religion in the Bill of Rights.
Capitulation.
In 1664, King Charles II of England ceded to his brother, the Duke of York, later King James II, a large tract of land that included New Netherland. Four English ships bearing 450 men, commanded by Richard Nicolls, seized the Dutch colony. On 30 August 1664, George Cartwright sent the governor a letter demanding surrender. He promised "life, estate, and liberty to all who would submit to the king's authority." Stuyvesant signed a treaty at his Bouwerij house on 9 September 1664. Nicolls was declared governor, and the city was renamed New York. Stuyvesant obtained civil rights and freedom of religion in the Articles of Capitulation. The Dutch settlers mainly belonged to the Dutch Reformed church, a strict Calvinist denomination. The English were Anglican, theologically closer to the Roman Catholic Church.
In 1665, Stuyvesant went to the Netherlands to report on his term as governor. On his return, he spent the remainder of his life on his farm of sixty-two acres outside the city, called the Great Bouwerie, beyond which stretched the woods and swamps of the village of Haarlem. A pear tree that he reputedly brought from the Netherlands in 1647 remained at the corner of Thirteenth Street and Third Avenue until 1867, bearing fruit almost to the last. The house was destroyed by fire in 1777. He also built an executive mansion of stone called Whitehall. He died in August 1672 and his body was entombed in the east wall of St. Mark's Church in-the-Bowery, which sits on the site of Stuyvesant’s family chapel.
Legacy.
Stuyvesant and his family were large land owners in the northeastern portion of New Amsterdam, and the Stuyvesant name is currently associated with three places in Manhattan's East Side, near present-day Gramercy: the Stuyvesant Town housing complex; Stuyvesant Square, a park in the area; and the Stuyvesant Apartments on East 18th Street. His farm, called the "Bouwerij" — the seventeenth-century Dutch word for "farm" — was the source for the name of the Manhattan street and surrounding neighborhood named the "Bowery". The chapel facing Bouwerie's long approach road (now Stuyvesant Street) became St. Mark's Church in-the-Bowery. The contemporary neighborhood of Bedford-Stuyvesant, Brooklyn includes Stuyvesant Heights and retains its name. Also named after him are the hamlets of Stuyvesant and Stuyvesant Falls in Columbia County, New York, where descendants of the early Dutch settlers still live and where the Dutch Reformed Church remains an important part of the community, as well as shopping centers, yacht clubs and other buildings and facilities throughout the area where the Dutch colony once was. A statue of Stuyvesant by J. Massey Rhind situated at Bergen Square in Jersey City was dedicated in 1915 to mark the 250th anniversary of the Dutch settlement there More modestly, Peter Island in the British Virgin Islands was also named after Stuyvesant during the Dutch West India Company's administration of that Territory.
Stuyvesant was a great believer in education. In 1660 he was quoted as saying that "Nothing is of greater importance than the early instruction of youth." In 1661, New Amsterdam had one grammar school, two free elementary schools, and had licensed 28 masters of school. To honor Stuyvesant's dedication to education and New Amsterdam's legal-cultural tradition of toleration under Stuyvesant, Stuyvesant High School in Manhattan was named after him. This stands in stark contrast to Stuyvesant's criticism of religious minorities, such as the Jews of New Amsterdam, whom he described, in a letter dated 22 September 1654, to the Dutch East India Company, as "deceitful", "very repugnant", and "hateful enemies and blasphemers of the name of Christ," in hopes that they would be made to leave the territory. 
The last direct descendant of Pieter Stuyvesant to bear his surname was Augustus van Horne Stuyvesant, Jr., who died a bachelor in 1953 at the age of 83 in his mansion at 2 East 79th Street. Rutherford Stuyvesant, the 19th century New York developer, and his descendants are also descended from Pieter Stuyvesant, however Rutherford Stuyvesant's name was changed from Stuyvesant Rutherford in 1863 to satisfy the terms of the 1847 will of Peter Gerard Stuyvesant.
References.
Notes
Bibliography

</doc>
<doc id="24969" url="http://en.wikipedia.org/wiki?curid=24969" title="Phish">
Phish

Phish is an American rock band noted for their musical improvisation, extended jams, blending of musical genres, and dedicated fan base. Formed at the University of Vermont in 1983 (with the current line-up solidifying in 1985), the band's four members—Trey Anastasio (guitars, lead vocals), Mike Gordon (bass, vocals), Jon Fishman (drums, percussion, vacuum, vocals), and Page McConnell (keyboards, vocals)—performed together for nearly 20 years before going on hiatus in August 2004. They reunited in March 2009 for a series of three consecutive concerts played in the Hampton Coliseum in Hampton, , and have since resumed performing regularly.
Phish's music blends elements of a wide variety of genres, including rock, progressive rock, psychedelic rock, hard rock, funk, folk, jazz, and blues. Although the band has received little radio play or mainstream exposure, Phish has developed a large and dedicated following by word of mouth, the exchange of live recordings, and selling over 8 million albums and DVDs in the United States. "Rolling Stone" stated that the band helped to "...spawn a new wave of bands oriented around group improvisation and super-extended grooves". They remain a very popular and successful touring act.
History.
Formation and "The White Tape": 1983–1986.
Phish was formed at The University of Vermont in 1983 by guitarists Trey Anastasio and Jeff Holdsworth, bassist Mike Gordon and drummer Jon Fishman. For their first gig, at Harris-Millis Cafeteria at the University of Vermont on December 2, 1983, the band was billed as "Blackwood Convention". ("Blackwood convention" is a term from the card game contract bridge.) The band was joined by percussionist Marc Daubert in the fall of 1984, a time during which they promoted themselves as playing Grateful Dead songs. Daubert left the band early in 1985, and Page McConnell then joined the group on keyboards and made his debut on May 3, 1985 at a show at Wilks/Davis/Wing Dormitory on Redstone Campus at the University of Vermont, Burlington, Vermont. Holdsworth left the group after graduation in 1986, solidifying the band's lineup of "Trey, Page, Mike, and Fish"—the lineup to this day.
Following a prank at UVM with his friend and former bandmate Steve Pollak—also known as "The Dude of Life"—Anastasio decided to leave the college. With the encouragement of McConnell (who received $50 for each transferee), Anastasio and Fishman relocated in mid-1986 to Goddard College, a small school in the hills of Plainfield, Vermont. Phish distributed at least six different experimental self-titled cassettes during this era, including "The White Tape". This first studio recording was circulated in two variations: the first, mixed in a dorm room as late as 1985, received a higher distribution than the second studio remix of the original four tracks, circa 1987. The older version was officially released under the title 'Phish' in August 1998.
The band's identity with its "hometown" of Burlington, Vermont, is evident in their actions. By 1985, the group had encountered Burlington, Vermont, luthier Paul Languedoc, who would eventually design four guitars for Anastasio and two basses for Gordon. In October 1986, he began working as their sound engineer. Since then, Languedoc has built exclusively for the two, and his designs and traditional wood choices have given Phish a unique instrumental identity. Also during the late 1980s, Phish played regularly at Nectar's restaurant and bar in Burlington. In 1992 the album "A Picture of Nectar", named as a tribute to the owner, featured a large orange with Nectar's photo superimposed subtly within the orange.
"The Man Who Stepped into Yesterday" and "Junta": 1987–1989.
As his senior project, Anastasio penned "The Man Who Stepped into Yesterday", a nine-song concept album that would become Phish's second studio experiment. Recorded between 1987 and 1988, it was submitted in July of that year, accompanied by a written thesis. Elements of the story—known as "Gamehendge"—grew to include an additional eight songs. The band performed the suite in concert on five different occasions: in 1988, 1991, 1993, and twice in 1994 without replicating the song list.
Beginning in the spring of 1988, members of the band began practicing in earnest, sometimes locking themselves in a room and jamming for hours on end, dubbed "Oh Kee Pa Ceremonies." One such jam took place at Anastasio's apartment, with a second at Paul Languedoc's house in August 1989. The band attributes the sessions to Anastasio, who discovered the concept in the films "A Man Called Horse" and "Modern Primitives." The product of one of these sessions was included in the band's first mass-released recording, a double album called "Junta", later that year.
On January 26, 1989, Phish played the Paradise Rock Club in Boston. The owners of the club had never heard of Phish and refused to book them, so the band rented the club for the night. The show sold out due to the caravan of fans that had traveled to see the band.
"Lawn Boy" and "A Picture of Nectar": 1990–1992.
By late 1990, Phish's concerts were becoming more and more intricate, often making a consistent effort to involve the audience in the performance. In a special "secret language", the audience would react in a certain manner based on a particular musical cue from the band. For instance, if Anastasio "teased" a motif from "The Simpsons" theme song, the audience would yell, "D'oh!" in imitation of   . In 1992, Phish introduced a collaboration between audience and band called the "Big Ball Jam" in which each band member would throw a large beach ball into the audience and play a note each time his ball was hit. In so doing, the audience was helping to create an original composition.
In an experiment known as "The Rotation Jam", each member would switch instruments with the musician on his left. On occasion, a performance of "You Enjoy Myself" involved Gordon and Anastasio performing synchronized maneuvers, jumping on mini-trampolines while simultaneously playing their instruments.
Phish, along with Bob Dylan, the Grateful Dead, and The Beatles, was one of the first bands to have a Usenet newsgroup, rec.music.phish, which launched in 1991. Aware of the band's growing popularity, Elektra Records signed them that year. The following year "A Picture of Nectar" was complete: their first major studio release, enjoying far more extensive production than either 1988's "Junta" or 1990's "Lawn Boy". These albums were eventually re-released on Elektra, as well.
The first annual H.O.R.D.E. festival in 1992 provided Phish with their first national tour of major amphitheaters. The lineup, among others, included Phish, Blues Traveler, The Spin Doctors, and Widespread Panic. That summer, the band toured Europe with the Violent Femmes and later toured Europe and the U.S. with Carlos Santana.
"Rift," "Hoist" and "Billy Breathes": 1993–1996.
Phish began headlining major amphitheaters in the summer of 1993. That year, the group released "Rift" packaged as a concept album and with heavy promotion from Elektra including artwork by David Welker. In 1994, the band released "Hoist." To promote the album, the band made their only video for MTV, "Down With Disease", airing in June of that year. Foreshadowing their future tradition of festivals, Phish coupled camping with their Summer tour finale at Sugarbush North in Warren, in July 1994, that show eventually being released as "Live Phish Volume 2". On Halloween of that year, the group promised to don a fan-selected "musical costume" by playing an entire album from another band. After an extensive mail-based poll, Phish performed The Beatles' The White Album—as the second of their three sets at the Glens Falls Civic Center in upstate New York. For their 1994 New Years Run, Phish played two sold-out shows at Madison Square Garden and Boston Garden, which were their debuts at both venues. Following the death of Grateful Dead frontman Jerry Garcia in the summer of 1995 and the appearance of "Down With Disease" on "Beavis and Butthead", the band experienced a surge in the growth of their fan base and an increased awareness in popular culture.
In their tradition of playing a well-known album by another band for Halloween, Phish contracted a full horn section for of The Who's "Quadrophenia" in 1995. Their first live album—"A Live One"—which was released during the summer of 1995, became Phish's first RIAA certified gold album in November 1995.
Phish retreated to their Vermont recording studio and recorded hours and hours of improvisations, sometimes overlaying them on one another, and included some of the result on the second half of "Billy Breathes", which they released in the fall of 1996. Alongside traditional rock-based crescendos, the album has more acoustic guitar than their previous records, and was regarded by the band and some fans as their crowning studio achievement. The album's first single, "Free", peaked at No. 24 on the Billboard Hot Modern Rock Tracks chart and No. 11 on the Mainstream Rock Tracks chart, becoming the band's most successful chart single of their career.
"Story of the Ghost" and "Farmhouse": 1997–2000.
By 1997, their improvisational ventures were developing into a new funk-inspired jamming style. Vermont-based ice cream conglomerate Ben & Jerry's launched "Phish Food" that year and proceeds from the flavor are donated to the Lake Champlain Initiative. Part of Phish's new non-profit foundation, The WaterWheel Foundation was also composed of two other now-defunct branches: The Touring Branch and the Vermont Giving Program.
To celebrate the new millennium, Phish hosted a 2-day outdoor festival at the Big Cypress Seminole Indian Reservation, in Big Cypress, FL. The highlight of this festival began when Phish took the stage at 11:35 p.m. on December 31, 1999, and continued to play until sunrise on January 1, 2000, approximately 8 hours later. This concert has been referred to as a peak musical experience by the band.
2000 saw no Halloween show, no summer festival and no new full-band compositions: May's "Farmhouse" contained material dating from 1997 and original material from Anastasio's 1999 solo acoustic/electric club tour. That summer, the band announced that they would take their first "extended time-out" following their upcoming fall tour. During the tour's last concert on October 7, 2000, at the Shoreline Amphitheater in Mountain View, California, they played a regular show and left without saying a word as The Beatles' "Let It Be" played over the sound system.
"Round Room", "Undermind" and break-up: 2001–2004.
Over two years after the hiatus began, Phish announced that they were getting back on the road with a New Year's Eve 2002 concert at Madison Square Garden. They also recorded "Round Room" in only three days. In their return concert, McConnell's brother was introduced as actor Tom Hanks. The impostor sang a line of the song "Wilson", prompting several media outlets to report that the actor had "jammed with Phish".
At the end of the 2003 summer tour, Phish held their first summer festival in four years, returning to Limestone for It. The festival drew crowds of over 60,000 fans, once again making Limestone one of the largest cities in Maine for a weekend. In December, the band celebrated its 20th anniversary with a four-show mini-tour culminating at American Airlines Arena in Miami, FL.
In order to avoid the exhaustion and pitfalls of previous years' high-paced touring, Phish played sporadically after the reunion, with tours lasting about two weeks. After an April 2004 run of shows in Las Vegas, Anastasio announced on the band's website that the band was breaking up after a small summer tour.
Their final album (at the time), "Undermind", was released in late spring. In the summer of 2004, the band jammed with rapper Jay-Z at one show, shot a video called "Live in Brooklyn" for broadcast in movie theaters, and performed a seven-song set atop the marquee of the Ed Sullivan Theater during the "Late Show with David Letterman" to fans who had gathered on the street, a move reminiscent of The Beatles' final performance on the rooftop of the Apple building in London.
Their final show of 2004—Coventry—was named for the town in Vermont that hosted the event. 100,000 people were expected to attend. After a week of rain that prompted fears of a sinking stage, Gordon announced on local radio that no more cars would be allowed in, though only about 20,000 people had arrived. Many concert-goers parked their vehicles on roadsides and hiked to the site; an estimated 65,000 attended the emotional finale.
Reemergence, "Joy" and "Fuego": 2008–2014.
Phish received the Jammys Lifetime Achievement Award on May 7, 2008 in The Theater at Madison Square Garden. After performing three songs together at the September 2008 wedding of their former tour-road manager, Phish announced that they would perform three reunion shows on March 6, 7, and 8, 2009, at the Hampton Coliseum in Hampton, Virginia. Following the reunion weekend, the band played thirteen shows of a summer tour, including an inaugural concert at Fenway Park and headlining Bonnaroo 2009 in June with Bruce Springsteen and the E Street Band, Beastie Boys, and Nine Inch Nails. During their first set of the second day, Phish was joined by Springsteen on guitar for "Mustang Sally", "Bobby Jean", and "Glory Days". Twelve additional dates in July and August were announced as a Late Summer Tour, including four nights at Red Rocks, two nights at The Gorge, a stop in Chicago, and several nights in the Northeast.
Phish's fourteenth studio album, "Joy", produced by Steve Lillywhite, was released September 8, 2009. A single from the album, "Time Turns Elastic", was released on iTunes in late May. The band announced a "save-the-date" for a three-day festival on October 30 & 31 and November 1. Phish.com contained an animated map of the United States, and individual states were slowly removed from the map, leaving California. Confirming several rumors, the band announced that "Festival 8" would take place in Indio, . Footage from Festival 8 was released in April 2010 as a 3D movie titled "Phish 3D". In the late spring and summer of 2010, the band completed a two-legged, 29-show tour. The August Alpine Valley shows have been released as a DVD and CD. Phish made their Hollywood Bowl debut and headlined the Outside Lands Music and Arts Festival in August. They played a show in Essex Junction, Vermont on September 14, and the more than $1.2 million in proceeds were donated to Vermont flood victim relief in the aftermath of Hurricane Irene.
In June 2012, Phish headlined Bonnaroo 2012 with the Red Hot Chili Peppers and Radiohead. Phish also performed for the first time ever a show in Oklahoma at the Zoo Amphitheater in August. For the fourth consecutive year, Phish has performed a set of sold-out New Year's shows at New York City's Madison Square Garden, which culminated with a three-set show to ring in 2013. Phish went back on tour in the summer of 2013 to celebrate their 30th-year anniversary which graced fan favorite venues such as Saratoga Performing Arts Center, PNC Bank Arts Center, Gorge Amphitheater Merriweather Post while also stopping at new destinations such as Darling's Waterfront Pavilion and FirstMerit Bank Pavilion at Northerly Island. The band also announced a fall tour for the first time since 2010, including stops at Hampton Coliseum. The band recently completed a new album known as "Fuego." Phish debuted 12 potential tracks from their 2014 album, which was introduced as "Wingsuit," the working title of the album, during the second of three sets on October 31, 2013.
Solo work and side projects.
The members of Phish have worked on various musical side projects. Anastasio continued the solo career he'd begun in 1998, formed the group Oysterhead, and began conducting an orchestral composition with the Vermont Youth Orchestra. Gordon made an album with acoustic guitar legend Leo Kottke and two films before launching his own solo career. Fishman alternated between Jazz Mandolin Project and his band Pork Tornado, while McConnell formed the trio Vida Blue.
During their break-up, members of Phish maintained various solo projects. Anastasio continued his solo career with his own band and performed with Oysterhead in June 2006. Gordon played with Leo Kottke and the Benevento/Russo Duo. At Rothbury in 2008, he played with his newest project, Ramble Dove, which is the name of the country outfit he fronted in his directorial feature "Outside Out", and also joined Grateful Dead drummers Mickey Hart and Bill Kreutzmann along with Steve Kimock and Jen Durkin as the Rhythm Devils. Anastasio and Gordon toured as a four-piece with the Benevento/Russo Duo in the summer of 2006. McConnell debuted his new solo project at a festival in September 2006 held by jam band moe. and released his self-titled debut on April 17, 2007. Fishman has performed occasional shows with the Everyone Orchestra, The Village and the Yonder Mountain String Band.
Other appearances.
In March 2010, Trey Anastasio was asked to pay tribute to Genesis, one of his favorite bands, upon being inducted into the Rock & Roll Hall of Fame. In addition to Anastasio's speech, Phish appeared and performed two Genesis songs, "Watcher of the Skies" and "No Reply At All". Genesis did not perform. On May 13, 2010, Phish played The Rolling Stones' "Loving Cup" on "Late Night with Jimmy Fallon". The band was introduced by Keith Richards.
Music.
The music of Phish is "oriented around group improvisation and superextended grooves" that draw on a range of rock-oriented influences, including psychedelic rock, funk, reggae, hard rock and various "acoustic" genres, such as folk and bluegrass. Some Phish songs use different vocal approaches, such as a cappella (unaccompanied) sections of barbershop quartet-style vocal harmonies.
Some of their original compositions (such as "Theme from the Bottom") tend towards a psychedelic rock and bluegrass fusion, with more rock, jazz and funk elements than the Grateful Dead and other earlier jam bands like Pink Floyd. Their more ambitious, epic compositions (such as "You Enjoy Myself" and "Guyute") are often said to resemble classical music in a rock setting, much like the music of one of their heroes, Frank Zappa.
Live performances.
The driving force behind Phish is the popularity of their concerts and the fan culture surrounding the event. Each a production unto itself, the band is known to consistently change set lists and details, as well as the addition of their own antics to ensure that no two shows are ever the same. With fans flocking to venues hours before they open, the concert is the centerpiece of an event that includes a temporary community in the parking lot, complete with "Shakedown Street": at times a garment district, art district, food court, or pharmacy. For many, one concert is simply a prelude to the next as the community follows the band around the country.
Because Phish's reputation is so grounded in their live performances, concert recordings are commonly traded commodities. Official soundboard recordings can be purchased through the Live Phish website. Legal field recordings produced by tapers with boom microphones from the audience in compliance with Phish's tape trading policy are frequently traded on any number of music message boards. Although technically not allowed, live videos of Phish shows are also traded by fans and are tolerated as long as they are for non-profit, personal use. Phish fans have been noted for their extensive collections of fan-taped concert recordings; owning recordings of entire tours and years is widespread.
In other media.
Phish began appearing in video games in 2009. Their song "Wilson" (December 30, 1994 at Madison Square Garden, New York, NY as released on "A Live One"), appeared in "Rock Band"'s Bonnaroo song pack, along with other songs by artists playing at the Bonnaroo Festival that year. A Phish "Live Track Pack" for "Guitar Hero World Tour" became available on June 25, 2009. Recordings of "Sample in a Jar" (December 1, 1994 at Salem Armory, Salem, ), "Down With Disease" (December 1, 1995 at Hersheypark Arena, Hershey, ) and "Chalk Dust Torture" (November 16, 1994, Hill Auditorium, University of Michigan, Ann Arbor, , as released on "A Live One") have been released, compatible with Xbox 360, PS3, and Wii. On August 19, 2010, it was confirmed that Llama would be a playable song in Rock Band 3, released on October 26, 2010.
They also have an ice cream flavor named after them, Ben & Jerry's Phish Food, in recognition of their shared Vermont heritage.

</doc>
<doc id="24970" url="http://en.wikipedia.org/wiki?curid=24970" title="PA-RISC">
PA-RISC

PA-RISC is an instruction set architecture (ISA) developed by Hewlett-Packard. As the name implies, it is a reduced instruction set computer (RISC) architecture, where the PA stands for Precision Architecture. The design is also referred to as HP/PA for Hewlett Packard Precision Architecture.
The architecture was introduced on 26 February 1986 when the HP 3000 Series 930 and HP 9000 Model 840 computers were launched featuring the first implementation, the TS1.
PA-RISC has been succeeded by the Itanium (originally IA-64) ISA jointly developed by HP and Intel. HP stopped selling PA-RISC-based HP 9000 systems at the end of 2008 but supported servers running PA-RISC chips until 2013.
History.
In the late 1980s, HP was building four series of computers, all based on CISC CPUs. One line was the IBM PC compatible Intel i286-based Vectra Series, started in 1986. All others were non-Intel systems. One of them was the HP Series 300 of Motorola 68000-based workstations, another Series 200 line of technical workstations based on a custom silicon on sapphire (SOS) chip design, the SOS based 16-bit HP 3000 classic series, and finally the HP 9000 Series 500 minicomputers, based on their own (16 and 32-bit) FOCUS microprocessor. HP planned to use PA-RISC to move all of their non-PC compatible machines to a single RISC CPU family.
Precision Architecture was introduced in 1986. It had thirty-two 32-bit integer registers and sixteen 64-bit floating-point registers. The number of floating-point registers was doubled in the 1.1 version to 32 once it became apparent that 16 were inadequate and restricted performance. The architects included Allen Baum, Hans Jeans, Michael J. Mahon, Ruby Bei-Loh Lee, Russel Kao, Steve Muchnick, Terrence C. Miller, David Fotland, and William S. Worley.
The first implementation was the TS1, a central processing unit built from discrete transistor-transistor logic (74F TTL) devices. Later implementations were multi-chip VLSI designs fabricated in NMOS processes (NS1 and NS2) and CMOS (CS1 and PCX).
They were first used in a new series of HP 3000 machines in the late 1980s – the 930 and 950, commonly known at the time as Spectrum systems, the name given to them in the development labs. These machines ran MPE/iX. The HP 9000 machines were soon upgraded with the PA-RISC processor as well, running the HP-UX version of UNIX.
Other operating systems ported to the PA-RISC architecture include Linux, OpenBSD, NetBSD and NEXTSTEP.
An interesting aspect of the PA-RISC line is that most of its generations have no Level 2 cache. Instead large Level 1 caches are used, formerly as separate chips connected by a bus, and now integrated on-chip. Only the PA-7100LC and PA-7300LC had L2 caches. Another innovation of the PA-RISC was the addition of vectorized instructions (SIMD) in the form of MAX, which were first introduced on the PA-7100LC.
Precision RISC Organization, an industry group led by HP, was founded in 1992 to promote the PA-RISC architecture. 
The ISA was extended in 1996 to 64-bits, with this revision named PA-RISC 2.0. PA-RISC 2.0 also added fused multiply–add instructions, which help certain floating-point intensive algorithms, and the MAX-2 SIMD extension, which provides instructions for accelerating multimedia applications. The first PA-RISC 2.0 implementation was the PA-8000, which was introduced in January 1996.

</doc>
<doc id="24971" url="http://en.wikipedia.org/wiki?curid=24971" title="Preacher (comics)">
Preacher (comics)

Preacher is a comic book series created by writer Garth Ennis and artist Steve Dillon, published by the American comic book label Vertigo (an imprint of DC Comics), with painted covers by Glenn Fabry.
The series consists of 75 issues in total - 66 regular, monthly issues, five one-shot specials and a four-issue "Preacher: Saint of Killers" limited series. The entire run has been collected in nine trade paperback editions. The final monthly issue, number 66, was published in October 2000.
Plot.
"Preacher" tells the story of Jesse Custer, a preacher in the small Texas town of Annville. Custer was accidentally possessed by the supernatural creature named Genesis in an incident which killed his entire congregation and flattened his church.
Genesis, the product of the unauthorized, unnatural coupling of an angel and a demon, is an infant with no sense of individual will. However, as it is composed of both pure goodness and pure evil, it might have enough power to rival that of God Himself. In other words, Jesse Custer, bonded to Genesis, may have become the most powerful being in the whole of living existence.
Custer, driven by a strong sense of right and wrong, goes on a journey across the United States attempting to (literally) find God, who abandoned Heaven the moment Genesis was born. He also begins to discover the truth about his new powers. They allow him, when he wills it, to command the obedience of those who hear and comprehend his words. He is joined by his old girlfriend Tulip O'Hare, as well as a hard-drinking Irish vampire named Cassidy.
During the course of their journeys, the three encounter enemies and obstacles both sacred and profane, including: the Saint of Killers, an invincible, quick-drawing, perfect-aiming, come-lately Angel of Death answering only to "He who sits on the throne"; a disfigured suicide attempt survivor turned rock-star named Arseface; a serial-killer called the 'Reaver-Cleaver'; The Grail, a secret organization controlling the governments of the world and protecting the bloodline of Jesus; Herr Starr, ostensible Allfather of the Grail, a megalomaniac with a penchant for prostitutes, who wishes to use Custer for his own ends; several fallen angels; and Jesse's own redneck 'family' — particularly his nasty Cajun grandmother, her mighty bodyguard Jody, and the 'animal-loving' T.C.
Themes and influences.
"Preacher" draws on movies, particularly Westerns, for many of its stylistic elements. For example: an apparition of John Wayne is a recurring character and serves as a sort of spiritual guide or conscience for Custer; Monument Valley and The Alamo serve as backdrops to various legs of the journey; for a time, Jesse acts as the sheriff of a small town in Texas, and must protect the inhabitants from harm; the image of the Saint of Killers, a reformed bounty hunter-turned-killer-once-more in the tradition of Clint Eastwood's "Unforgiven" character, William Munny, is a nod to the classic Western notion of nemesis, straight and true and terrible.
The series also invokes ideas popularized by such books as "Holy Blood, Holy Grail". As Massimo Introvigne of the Center for Studies on New Religion explains, "Preacher" was "among the popular comic book series which...focused interest on the subject." Within "Preacher" the claims that there is a still-viable bloodline descending from Jesus Christ and Mary Magdalene similar to those in "Holy Blood, Holy Grail" are taken as true. Herr Starr reveals to Cassidy that Jesus had children, and did not die on the cross, but instead lived to middle-age, and was killed by a runaway offal cart. After his death the Grail guardians took away his offspring, who were forced to intermarry with one another in order to keep Jesus' divine power within the bloodline. For over 2000 years this intermarrying perpetuated an incestuous family tree culminating the last of the Jesus line, a mentally handicapped child, in whom the Grail guardians place their hopes.
The original plot and premise of "Preacher" was spun out of Ennis' run on "Hellblazer", which postulated what would happen if an angel and a demon mated, and the spirit of their offspring ended up in a mortal man. Like many comics spun out of DC's 90's work, it incorporates the idea of the Jewish God (Jahve) as the main antagonist of the series, serving as the creator who has left his creation. Other related comics include "Swamp Thing" and "Sandman" (and its spinoffs, like "Lucifer").
Adaptation attempts.
Garth Ennis, feeling "Preacher" would translate perfectly as a film, sold the film rights to Electric Entertainment. Rachel Talalay was hired to direct, with Ennis writing the script. Rupert Harvey and Tom Astor were set as producers. By May 1998, Ennis completed three drafts of the script, based largely on the "Gone to Texas" story arc. The filmmakers found it difficult financing "Preacher" because investors found the idea religiously controversial. Ennis approached Kevin Smith and Scott Mosier to help finance the film under their View Askew Productions banner. Ennis, Smith and Mosier pitched "Preacher" to Bob Weinstein at Miramax Films.
Weinstein was confused by the characterization of Jesse Custer. Miramax also did not want to share the box office gross with Electric Entertainment, ultimately dropping the pitch. By May 2000, Smith and Mosier were still attached to produce with Talalay directing, but Smith did not know the status of "Preacher", feeling it would languish in development hell. By then, Storm Entertainment, a UK-based production company known for their work on independent films, joined the production with Electric Entertainment. In September 2001, the two companies announced "Preacher" had been greenlighted to commence pre-production, with filming to begin in November and Talaly still directing Ennis' script. The production and start dates were pushed back because of financial issues of the $25 million projected budget.
James Marsden was cast in the lead role as Jesse Custer sometime in 2002. He explained, "It was something I never knew anything about, but once I got my hands on the comic books, I was blown away by it." In a March 2004 interview, Marsden said the filmmakers were hoping for filming to start the following August. With the full-length film adaptation eventually abandoned with budgetary concerns, HBO announced in November 2006 that they commissioned Mark Steven Johnson and Howard Deutch to produce a television pilot. Johnson was to write with Deutch directing. Impressed with Johnson's pilot script, HBO had him write the series bible for the first season. Johnson originally planned "to turn each comic book issue into a single episode" on a shot-for-shot basis. "I gave [HBO] the comics, and I said, 'Every issue is an hour'. Garth Ennis said 'You don't have to be so beholden to the comic'. And I'm like, 'No, no, no. It's got to be like the comic'."
Johnson also wanted to make sure that one-shots were included as well. Johnson changed his position, citing new storylines conceived by Ennis. "Well, there would be nothing new to add if we did that, so Garth [Ennis] and I have been creating new stories for the series," he said. "I love the book so much and I was telling Garth that he has to make the stories we are coming up with as comics because I want to see them." By August 2008, new studio executives at HBO decided to abandon the idea, finding it too stylistically dark and religiously controversial. Columbia Pictures then purchased the film rights in October 2008 with Sam Mendes planned to direct. Neal H. Moritz and Jason Netter would have produced the film. The previous scripts written by Ennis would not have been used.
AMC adaptation.
On November 16, 2013, it was announced that AMC will be shooting a pilot for "Preacher". On November 18, 2013, "BleedingCool" confirmed that Seth Rogen and Evan Goldberg developed the series pilot with Sam Catlin, and that it will be distributed by Sony Pictures Television. On February 7, 2014 it was made public that AMC is officially developing the series to television based on the pilot written by Seth Rogen and Evan Goldberg. Rogen has no plans to co-star in the series. On May 9, 2014, AMC announced that Preacher was picked up to series. Rogen tweeted that "Son of a Preacher Man" will be the series theme song. Preacher will premiere mid to late 2015, as announced by Seth Rogen, with the script for the series complete and the pilot ordered by the studio. Comic creators Steve Dillon and Garth Ennis will work on this project as co-executive producer. On February 12, 2015, Superhero Hype reports that the character of Tulip O'Hare will be an African American. According to Nerdist, the series will depart some of things comics and the script featured some character like Cassidy, Sheriff Fruit and Eugene. On April 17, 2015, Seth Rogen tweeted that Dominic Cooper was cast in the role of Jesse Custer, Joseph Gilgun as Cassidy, Ruth Negga as Tulip O'Hare, Ian Colletti as Arseface, and W. Earl Brown as Sheriff Hugo Root. 
Legacy.
Stephen King has said that his comic book series ' was influenced by "Preacher".
The character Yorick from "", has a Zippo lighter with the words "Fuck Communism" engraved, identical to the one owned by Jesse Custer in "Preacher". When asked about it he says it's "from this book I read once...a graphic novel. You know, like a comic book." This lighter appears later in the series when Yorick and Agent 355 are being held by Russian agents at gunpoint, who find the lighter and take offense to it. Also, in volume 4 "Safeword", Yorick says "pardners", which is used several times in "Preacher", in lieu of "partners".
IGN declared Preacher the third-greatest Vertigo comic, after "Swamp Thing" and "Sandman".
Jesse Custer was ranked the 11th Greatest Comic Book Character by "Empire" magazine. The Saint of Killers was ranked at number 42 on the same list.

</doc>
<doc id="24972" url="http://en.wikipedia.org/wiki?curid=24972" title="Preacher">
Preacher

A preacher is typically regarded as a person who delivers sermons or gives homilies, generally on religious topics, although one can also preach any of the components of any worldview or philosophy. Some see a preacher as distinct from a theologian by focusing on the communication rather than the development of doctrine. Others see preaching and theology as being intertwined. Others still define "preacher" as synonymous with "evangelist" (the more ancient definition, based on the Greek words underlying the English Bible). Preaching is not limited to religious views, but it extends to moral and social world-views as well.
History.
Preachers are common throughout most cultures. They can take the form of a Christian minister on a Sunday morning, or an Islamic Imam. A Muslim preacher in general is referred to as a Da'ee, while those giving sermons on a Friday afternoon are described as a khatib. The word "preach" (from the Greek κηρύσσω, "to proclaim") in the Bible usually refers to the proclamation of the gospel of Jesus Christ, i.e. evangelism—that said, since most modern Christians (especially Protestants) now define preaching as a monologue delivered by clergy to laity, the content of this kind of "preaching" typically goes beyond evangelism to other points of theology more relevant for someone who is already a Christian.
The preaching of sermons is prominent in Protestantism. Lay preachers often figure in these traditions of worship, for example the Methodist local preachers. Among Roman Catholics, the Dominican Order is officially known as the "Order of Preachers" ("Ordo Praedicatorum" in Latin); friars of this order were trained to publicly preach in vernacular languages, and the order was created by Saint Dominic to preach to the Cathars of southern France in the early thirteenth century.
In many churches in the United States, the title "Preacher" is synonymous with "Pastor" or "Minister", and the church's minister is often referred to simply as "our/the preacher" or by name such as "Preacher Smith". Sometimes the minister may even be addressed by using the word, such as "Good morning, Preacher".
However, among some Chinese churches, preacher (Chinese:傳道) is different from pastor (Chinese:牧師). A preacher refers to the younger clergy in the Protestant church who are not officially recognised as a pastor until they can prove their capability of leading the church. 
See also.
 Media related to at Wikimedia Commons

</doc>
<doc id="24973" url="http://en.wikipedia.org/wiki?curid=24973" title="Prime time">
Prime time

Prime time or peak time is the block of broadcast programming taking place during the middle of the evening for television programming.
The term "prime time" is often defined in terms of a fixed time period – for example, from 19:00 to 22:00 (Central and Mountain Time) or 20:00 to 23:00 (Eastern and Pacific Time) (7 p.m. to 10 p.m. or 8 p.m. to 11 p.m.).
Timeslot's relationship to radio and television revenue.
Prime time is the daypart (a block of a day's programming schedule) with the most viewers and is generally where television networks and local stations reap much of their advertising revenues. In recent years in the US, for example, advertising expenditure during prime time was highest among drama shows.
The Nielsen ratings system is explicitly designed for the optimum measurement of audience viewership by dayparts with prime time being of most interest. Most people tend to watch television at prime time, as most often, based on standard working time, the end of the work day coincides with prime time viewing hours. Most viewers sit down to watch TV after dinner. This is usually the main reason for the high ratings for television programming at this time, as well as the attraction of the timeslot for advertisers.
The existence of prime time in the United States is largely an artifact of now repealed regulations of the Federal Communications Commission, which limited the number of hours that a network can require its affiliates to broadcast.
Additionally, networks may also choose to provide local affiliates the opportunity to air sporting events or other special events which may fall outside of standard designated network broadcast times. Prime time for radio is called “Drive time” and, in Eastern and Pacific Time, is 6–10 a.m. and 3–7 p.m. and, for Mountain and Central Time, is 5–9 a.m. and 2–6 p.m.
A survey by Nielsen revealed that viewers watched almost two hours worth of TV during prime time.
Asia.
China.
Mainland China.
In Chinese television, the 19:00-to-22:00 time slot is known as Golden Time (Traditional Chinese: 黄金時間; Simplified Chinese: 黄金时间; Pinyin: Huángjīn shíjiān). The term also influenced a nickname of a strip of holidays in known as Golden Week.
Hong Kong and Macau.
Prime time here usually takes place from 20:00 until 22:00. After that, programs classified as “PG” (Parental Guidance) are allowed to be broadcast. Frontline dramas appear during this time slot in Cantonese, as well as movies in English.
Taiwan.
In Taiwan, prime time (called "bādiǎn dàng" [ in Mandarin Chinese) starts at 20:00 in the evening. Taiwanese drama series played then are called 8 o'clock series and are expected to have high viewer ratings.
India.
In India, prime time occurs between 20:00 and 23:00. The main news programs are broadcast at 20:30, and the highest-rated television program follows at 21:00.
Indonesia.
Prime time usually takes place from 18:00 to 23:00 WIB, preceded by a daily newscast at 17:00. After prime time, programs classified as Adult are allowed to be broadcast.
Like another Muslim-majority country, there is also a 'midnight prime time' during sahur time in a month of Ramadan. It takes place from 02:30 and ends at the Fajr prayer call, varies between 04:30 and 05:00. The time slot is usually filled with comedy and religious programming.
Iraq.
In Iraq, prime time runs from 20:00 to 23:00. The main news programs are broadcast at 20:00 and the highest-rated television program airs at 21:00.
Japan.
In Japanese television, the 19:00-to-22:00 time slot is also known as Golden Time (ゴールデン・タイム, gōruden taimu, or just Golden). The term also influenced a nickname of a strip of holidays in known as Golden Week.
Malaysia.
Malaysian prime time starts with the main news from 20:00 to 20:30 (now 20:00 to 21:00) and ends at 23:00. Usually, programmes during prime time are domestic dramas, foreign drama series (mostly American), movies and entertainment programmes. Programmes that classify as 18 are not allowed to be broadcast before 10:00 p.m. but on RTM, most programmes on this slot are rated U (U means "Umum" in Malay and literally General Viewing or General Audiences in English) throughout the whole day. However, programmes broadcast after 23:00 are still considered prime time. As of December 2010, NTV7's prime time continues until 12:00 a.m. Programmes during prime time may have longer commercial breaks due to number of viewers.
Some domestic prime time productions may be affected because of certain major sporting events such as FIFA World Cup. However, only FIFA World Cup in the Americas did not affect the domestic prime time programmes.
Philippines.
In the Philippines, prime time blocks begin at 20:00 and run until about 23:00 on weekdays, and 18:00 to 23:00 on weekends. The weekday prime time blocks usually consists of local teleseryes (soap operas) and foreign television series. The network's highest-rated programs are usually aired right after the evening newscast at 20:00, while a foreign series usually precedes the late night newscast.
On weekends, non-scripted programming such as talent shows, reality shows and current affairs shows air in prime time. For the minor networks, prime time consists of American television series on weekdays, with encores of those shows on weekends. Prime time originally started earlier at around 19:00, but the evening newscasts were lengthened to 90 minutes and now start at 18:30, instead of the original one-hour newscast that starts at 18:00.
Thailand.
In Thailand, prime time dramas (ละคร; la-korn) air from 8:30 p.m. to 10:30 p.m. Most dramas are soap operas. Prime time dramas are popular and influential to Thai society.
Singapore.
In Singapore, prime time begins at 7pm and ends at 11pm for the Channels MediaCorp Channel 5, MediaCorp Channel 8, MediaCorp Channel U, Channel NewsAsia, MediaCorp Suria and MediaCorp Vasantham, which are also the main (Free-to-air) television channels in Singapore.
South Korea.
In South Korea, prime time usually runs from 20:00 to 23:00 during the week, while on Saturdays and Sundays, it runs from 19:00 to 23:00. Family-oriented television shows are broadcast before 22:00, and adult-oriented television shows air after 22:00.
Vietnam.
In Vietnam Prime time is also known as Golden Time(Tiếng Việt: Giờ vàng), prime time starts at 20:00 in the evening and ends at 23:00.
Europe.
Bosnia and Herzegovina.
In Bosnia and Herzegovina, prime time starts at 20:00 and finishes at 22:00. It is preceded by a daily newscast ("Dnevnik") at 19:00 and followed by a late night newscast ("Vijesti") at 22:00.
Croatia.
In Croatia, prime time starts between 20:00 and 20:15. Croatian public broadcaster HRT broadcasts a daily newscast at 19:00 that ends at 20:00. Also, many private broadcasters have daily newscasts before and after it at around 20:05, followed by the start of prime time. Many broadcasters who do not have daily newscasts start with prime time at 20:00. Prime time generally finishes between 22:00 and 23:00, followed by late night edition of the network newscast and adult-oriented programming.
Denmark.
In Denmark, prime time starts at 20:00.
Germany and Austria.
The oldest public national broadcasting network of Germany, Das Erste (The First) airs the "Tagesschau" (simulcasts on the regional affiliates (The Third) and specialty channels), Germany's most-watched news broadcast, at 8:00 p.m. The "Tagesschau" is scheduled for 15 minutes; its end marks the beginning of the prime time and has since the 1950s. Most channels therefore chose to start their prime time at 8:15 p.m. In the 1990s, Sat.1 failed, moving the start of prime time to 8 p.m. suffering significant loss of audience share.
Finland.
In Finland, prime time starts at 21:00. It is preceded by a daily newscast at 20:30.
France.
In France prime time runs from 8:45 p.m. to 10:30 p.m., which usually follows the news.
Greece.
In Greece, prime time runs from 9:00 p.m. to 12:00 a.m., which usually follows the news.
Hungary.
In Hungary, prime time starts weekdays on the two big commercial stations (RTL Klub and TV2) at 7:00 p.m. with game shows, tabloid and docu-reality programmes. At 9:00 p.m., two popular soap operas air, "Barátok közt" and "Jóban Rosszban", which follows at 9:30 p.m. American and other series, movies, talk-shows and magazines run until 11:30 p.m. The prime time lineup is preceded by daily news programmes at 6:30 p.m. Prime time begins at 7:00 p.m. on weekends with blockbuster movies and television shows.
The public television station M1 starts prime time with a game show at 6:30 p.m., which is followed by the daily news programme "Híradó" at 7:30 p.m. After the news, the channel begins to broadcast American and other series, talk shows, magazines and news programmes until 10:00 p.m., which is followed by the daily news magazine "Este".
Ireland.
RTE runs a current affairs programme called “Prime Time” after the 9:00 p.m. news. As of 2011, it is currently hosted by Miriam O'Callaghan.
Iceland.
In Iceland, prime time starts at 19:30. It is preceded by a daily newscast at 19:00.
Italy.
In Italy, prime time is from 9:15 p.m. to 11:30 p.m. It usually follows news and, on some networks (like Rai Uno and Canale 5), a slot called “access prime time”. Shows, movies, and sport events are usually shown during prime time.
Netherlands.
Much like in Germany, prime time in the Netherlands usually begins at 8:30 p.m. in order to not compete with NOS Journaal's flagship 8:00 p.m. newscast.
Norway.
In Norway, prime time starts at 19:45. It is preceded by a daily newscast at 19:00.
Poland.
In Poland, prime time starts around 20:00 (sometimes 20:30). On (TVP 1) It is preceded by a daily newscast at 19:30, on (TVN) the newscast is aired at 19:00 followed by the newsmagazine Uwaga at 19:50 (weekdays)/19:45 (weekends) and then the soap Na Wspólnej at 20:05 (Monday to Thursday, from Friday to Sunday (at 20:00) various: movies on Friday, show or movies (Winter and Summer) at Saturday, and programme or movies (Winter and Summer) at Sunday), on (Polsat) the news is aired at 18:50, followed by a sitcom Świat według Kiepskich at 19:30.
Slovakia.
Public television in Slovakia consists of two channels; on the main channel (Jednotka) prime time starts at 20:10, and on the second one (Dvojka) prime time programming starts at 20:00. The two biggest private broadcasters set the start of prime time programming at 20:20 (Markíza) and 20:30 (JOJ). Generally, however, prime time is considered to be from 20:00 to 23:00.
Slovenia.
In Slovenia, prime time, the period in which the most-watched shows are broadcast, is from 8:00pm to 11:00pm. It is preceded by daily newscasts; Dnevnik RTV SLO (7:00pm–8:00pm) on TV SLO 1, 24ur (6:55pm–8:00pm) on POP TV, Svet na Kanalu A (6:00pm–7:00pm; 7:50pm–8:00pm), and Danes (7:30pm–8:00pm) on Planet TV.
Sweden.
In Sweden, prime time starts at 20:00. It is preceded by a daily newscast at 19:30 and local news at 19:50.
Spain.
In Spain, prime time refers to the time period in which the most-watched shows are broadcast. Prime time in Spain starts quite late when compared to most nations as it runs from 22:30 till 01:00. Most news programmes in Spain air at 21:00 for an hour and prime time follows. However, due to fierce competition, especially among the private stations prime time has even been delayed until 23:00. Most channels are delaying prime time in order to protect their top shows from sporting events.
In the 1990s, prime time in Spain began at 21:00, moving to 21:30 in the latter half of the 1990s and 22:00 in the early 2000s. Commercial broadcaster laSexta and the second channel from the Public broadcasting La 2 have attempted to shift prime time back to 21:30 in 2006 and Spring 2007, but these attempts have been unsuccessful.
The lateness in the start of prime time in Spain is also due to Spanish culture. Spanish people generally work from 09:00-14:00 and then from 17:00-20:00 as opposed to the standard 09:00-17:00. The popular late night show "Crónicas Marcianas" during the late 1990s–2000 also helped to extend prime time well into the early hours with the show being watched by a share of 40%, despite finishing at 02:00.
Spain might also be unique in that it has a second prime time, running from 14:30-17:00 which coincides with the extended Spanish lunch break. Shows airing in the secondary prime time period on many occasions beat those prime time shows at night on a daily basis. The second prime time only occurs on weekdays, though and the slot is usually filled with The Simpsons, news, soap operas and talk shows.
Georgia.
In Georgia, primetime starts at between 18.45-20.00 and mainly ends at 00.00. However, at Friday primetime usually continues until 01.00.
United Kingdom.
In the UK, the term used is peak time, early peak is 5:30 PM to 8:00 PM and late peak is 8:00 PM to 11:00 PM.
North America.
In North America, television networks feed their prime time programming in two blocks: one for the Eastern, Central, and Mountain time zones, and one for the Pacific, Alaskan, and Hawaiian time zones, to their local network affiliates. In Atlantic Canada (including Newfoundland) as well as Alaska and Hawaii, there is no change in the interpretation or usage of “prime time” as the concept is not attached to time zones in any way. Affiliates in the Mountain, Alaskan, and Hawaii-Aleutian zones are either on their own to broadcast delay by an hour or two, or collectively form a small, regional network feed with others in the same time zone.
The hours traditionally constituting prime time in North America are 8:00-11:00 p.m. Eastern/Pacific and 7:00-10:00 p.m. Central/Mountain on Monday–Saturday, and 7:00-11:00 p.m. Eastern/Pacific and 6:00-10:00 p.m. Central/Mountain on Sunday. For cable networks (such as USA Network, TBS, and ABC Family), prime time is 8:00-11:00 p.m. all seven days of the week. Some networks such as Fox, The CW, and MyNetworkTV only broadcast from 8:00-10:00 p.m., a time period known as "common prime". Since September 2009, The CW and MyNetworkTV do not program Saturday or Sunday prime time at all, as The CW turned over its Sunday night schedule and MyNetworkTV its Saturday night schedule over to their affiliates. Also, over the past decade, the major American networks have come to consider Saturday prime time as a graveyard slot and as such have largely abandoned scheduling of new scripted programming on that night; although the networks still maintain a prime time programming schedule on that night, generally featuring rebroadcasts of programs aired earlier in the week, movies, non-scripted reality programs and, occasionally, remnant episodes of cancelled series.
Prime time can be extended or truncated if coverage of sporting events run past their allotted end time. Since the "Heidi Game" incident in 1968, in which NBC cut away on the East Coast from a New York Jets/Oakland Raiders football game in its final minute of play in order to show a movie (and, in the process, missing an unexpected comeback by the Raiders to win the game), the National Football League began to mandate that all games be broadcast in their entirety. Due to this rule, game telecasts may sometimes overrun into the 7:00 p.m. ET hour. Fox previously scheduled repeats of its animated series in the 7:00 hour, allowing themselves to simply pre-empt the reruns if a game ran long. This was later replaced by a half-hour-long wrap-up show, "The OT". In contrast, CBS does not, as its weekly newsmagazine "60 Minutes" has traditionally aired as close to 7:00 p.m. ET as possible. If a game runs long, "60 Minutes" is shown in its entirety at the conclusion of coverage, and the rest of the prime time schedule on the East Coast is shifted to compensate. For example, if game coverage were to end at 7:30 p.m., prime time would end at 11:30 p.m.
However, in the rare case where the NFL game runs excessively late (8 p.m. or later), an episode of a series scheduled for later in the evening may be pre-empted (for example, "Cold Case" in October 2009 after the Bills-Jets game ran excessively late). In an extreme case, CBS's prime time can be extended past midnight during broadcasts of the NCAA Division I Men's Basketball Tournament. This does not necessarily apply universally; in 2001, after an XFL game went into overtime, forcing the delay of a highly promoted episode of "Saturday Night Live", NBC made a decision to cut off all future XFL broadcasts at 11:00 p.m. NBC backed out of the XFL after the end of that season, leading to its failure.
Until the U.S. Federal Communications Commission (FCC) regulated time slots prior to prime time with the now-defunct Prime Time Access Rule in 1971–1972, networks began programming at 7:30 p.m. Eastern and Pacific/6:30 p.m. Central and Mountain on weeknights (that is, the 1970–1971 season was the last season in which the networks began prime time at 7:30). The change helped instigate what is colloquially known as the ”rural purge”, in which rural-themed and older-skewing programs were disproportionately canceled. In the 1987-1988 season, NBC-owned stations in several cities experimented with airing a schedule of syndicated first-run sitcoms at 7:30/6:30 p.m. (known as ) to compete against syndicated reruns or game shows such as "Wheel of Fortune" on rival stations.
The vast majority of prime time programming in English-speaking North America comes from the United States, with only a limited amount produced in Canada (most of which consists of local adaptations of worldwide reality television franchises, such as "Canadian Idol" and "So You Think You Can Dance Canada"). The Canadian Radio-television and Telecommunications Commission mandates quotas for Canadian content in prime time; these quotas indicate at least half of Canadian prime time programs must be Canadian in origin, but the majority of this is served by national and local news.
Likewise, the vast majority of Spanish-language programming in North America comes from Mexico. Televisa, a Mexican network, provides the majority of programming to the dominant U.S.-based Spanish broadcaster, Univision. Univision does produce a fairly large amount of unscripted Spanish-language programming, the best known being the long-running variety show "Sábado Gigante", hosted and created by Chilean national Don Francisco. Univision's distant second-place competitor, Telemundo, produces a much greater share of in-house content, including a long line of telenovelas.
In Quebec, the largest Francophone area of North America, French-language programming consists of originally produced programs (most of which are produced in Montreal, with a few produced in Quebec City) and French-language dubs of English language programs.
Oceania.
Prime time in Australia is officially from 6:00 p.m. to midnight, following Australian Eastern Standard Time, with the highest ratings normally achieved between 6:00 p.m. to 9:00 p.m. Prime time in New Zealand is considered to be 7:30 to 10:30 p.m. (Four's prime time ends at 11 p.m. on Tuesdays to Fridays), but can be extended to cover the entire evening of television (6 to 11 p.m.).
Latin America.
In a great part of Latin American countries, prime time is considered to be from 6:00 or 7:00 p.m. to 10:00 or 11:00 p.m. The time slot is usually used for news, telenovelas and television series, and special time slots are used for reality shows, with great popularity, especially in Mexico and Brazil. In Brazil, it is called "horário nobre" (“noble time”), which is the time the three most famous telenovelas in the country are shown each weekday and on Saturdays. There are also news programs, reality shows, and sitcoms.
Argentina.
In Argentina, prime time is considered to be from 8.00 p.m. until 12.00 a.m.; with the most successful series and telenovelas in the country (such as "Los Roldán" and "Valientes"), and entertainment shows, like CQC (Caiga Quien Caiga).
Chile.
In Chile, prime time is considered to be from 10.30 p.m. until 01.00 a.m.; with the most successful series and telenovelas in the country (such as "Socias" and "Las Vega's"). Investigation entertainment shows (like "Informe Especial", "Contacto", "Apuesto por tí") also air.

</doc>
<doc id="24974" url="http://en.wikipedia.org/wiki?curid=24974" title="Pelton wheel">
Pelton wheel

The Pelton wheel is an impulse type water turbine. It was invented by Lester Allan Pelton in the 1870s. The Pelton wheel extracts energy from the impulse of moving water, as opposed to water's dead weight like the traditional overshot water wheel. Many variations of impulse turbines existed prior to Pelton's design, but they were less efficient than Pelton's design. Water leaving those wheels typically still had high speed, carrying away much of the dynamic energy brought to the wheels. Pelton's paddle geometry was designed so that when the rim ran at half the speed of the water jet, the water left the wheel with very little speed; thus his design extracted almost all of the water's impulse energy—which allowed for a very efficient turbine.
Function.
Nozzles direct forceful, high-speed streams of water against a rotary series of spoon-shaped buckets, also known as impulse blades, which are mounted around the circumferential rim of a drive wheel—also called a runner (see photo, 'Old Pelton wheel..'). As the water jet impinges upon the contoured bucket-blades, the direction of water velocity is changed to follow the contours of the bucket. Water impulse energy exerts torque on the bucket-and-wheel system, spinning the wheel; the water stream itself does a "u-turn" and exits at the outer sides of the bucket, decelerated to a low velocity. In the process, the water jet's momentum is transferred to the wheel and thence to a turbine. Thus, "impulse" energy does work on the turbine. For maximum power and efficiency, the wheel and turbine system is designed such that the water jet velocity is twice the velocity of the rotating buckets. A very small percentage of the water jet's original kinetic energy will remain in the water, which causes the bucket to be emptied at the same rate it is filled, (see conservation of mass) and thereby allows the high-pressure input flow to continue uninterrupted and without waste of energy. Typically two buckets are mounted side-by-side on the wheel, which permits splitting the water jet into two equal streams (see photo). This balances the side-load forces on the wheel and helps to ensure smooth, efficient transfer of momentum of the fluid jet of water to the turbine wheel.
Because water and most liquids are nearly incompressible, almost all of the available energy is extracted in the first stage of the hydraulic turbine. Therefore, Pelton wheels have only one turbine stage, unlike gas turbines that operate with compressible fluid.
Applications.
Pelton wheels are the preferred turbine for hydro-power, when the available water source has relatively high hydraulic head at low flow rates, where the Pelton wheel is most efficient. Thus, more power can be extracted from a water source with high-pressure and low-flow than from a source with low-pressure and high-flow, even when the two flows theoretically contain the same power. Also a comparable amount of pipe material is required for each of the two sources, one requiring a long thin pipe, and the other a short wide pipe. Pelton wheels are made in all sizes. There exist multi-ton Pelton wheels mounted on vertical oil pad bearings in hydroelectric plants. The largest units can be up to 200 megawatts. The smallest Pelton wheels are only a few inches across, and can be used to tap power from mountain streams having flows of a few gallons per minute. Some of these systems use household plumbing fixtures for water delivery. These small units are recommended for use with 30 ft or more of head, in order to generate significant power levels. Depending on water flow and design, Pelton wheels operate best with heads from 49-5905 ft, although there is no theoretical limit.
Design rules.
The specific speed formula_1 of a turbine dictates the turbine's shape in a way that is not related to its size. This allows a new turbine design to be scaled from an existing design of known performance. The specific speed is also the main criterion for matching a specific hydro-electric site with the correct turbine type.
formula_2 (dimensioned parameter), formula_3 = rpm 
where:
The formula implies that the Pelton turbine is most suitable for applications with relatively high hydraulic head "H", due to the 5/4 exponent being greater than unity, and given the characteristically low specific speed of the Pelton.
Turbine physics and derivation.
Energy and initial jet velocity.
In the ideal (frictionless) case, all of the hydraulic potential energy ("E""p" = "mgh") is converted into kinetic energy ("E""k" = "mv"2/2) (see Bernoulli's principle). Equating these two equations and solving for the initial jet velocity ("V""i") indicates that the theoretical (maximum) jet velocity is "V""i" = √(2"gh") . For simplicity, assume that all of the velocity vectors are parallel to each other. Defining the velocity of the wheel runner as: ("u"), then as the jet approaches the runner, the initial jet velocity relative to the runner is: ("V""i" − "u").
The initial jet velocity of jet is "V""i"
Final jet velocity.
Assuming that the jet velocity is higher than the runner velocity, if the water is not to become backed-up in runner, then due to conservation of mass, the mass entering the runner must equal the mass leaving the runner. The fluid is assumed to be incompressible (an accurate assumption for most liquids). Also it is assumed that the cross-sectional area of the jet is constant. The jet "speed" remains constant relative to the runner. So as the jet recedes from the runner, the jet velocity relative to the runner is: −("V""i" − "u") = −"V""i" + "u". In the standard reference frame (relative to the earth), the final velocity is then: "V""f" = (−"V""i" + u) + "u" = −"V""i" + 2"u".
Optimal wheel speed.
We know that the ideal runner speed will cause all of the kinetic energy in the jet to be transferred to the wheel. In this case the final jet velocity must be zero. If we let −"V""i" + 2"u" = 0, then the optimal runner speed will be "u" = "V""i" /2, or half the initial jet velocity.
Torque.
By Newton's second and third laws, the force F imposed by the jet on the runner is equal but opposite to the rate of momentum change of the fluid, so:
where ("ρ") is the density and ("Q") is the volume rate of flow of fluid. If ("D") is the wheel diameter, the torque on the runner is: "T" = "F"("D"/2) = "ρQD"("V"i − "u"). The torque is at a maximum when the runner is stopped (i.e. when "u" = 0, "T" = "ρQDV"i ). When the speed of the runner is equal to the initial jet velocity, the torque is zero (i.e. when "u" = "V"i, then "T" = 0). On a plot of torque versus runner speed, the torque curve is straight between these two points, (0, "pQDV"i) and ("V"i, 0).
Power.
The power "P" = "Fu" = "Tω", where "ω" is the angular velocity of the wheel. Substituting for "F", we have "P" = 2"ρQ"("V""i" − "u")"u". To find the runner speed at maximum power, take the derivative of "P" with respect to "u" and set it equal to zero, ["dP"/"du" = 2"ρQ"("V""i" − 2"u")]. Maximum power occurs when "u" = "V""i" /2. "P"max = "ρQV""i"2/2. Substituting the initial jet power "V""i" = √(2"gh"), this simplifies to "P"max = "ρghQ". This quantity exactly equals the kinetic power of the jet, so in this ideal case, the efficiency is 100%, since all the energy in the jet is converted to shaft output.
Efficiency.
A wheel power divided by the initial jet power, is the turbine efficiency, "η" = 4"u"("V""i" − "u")/"V""i"2. It is zero for "u" = 0 and for "u" = "V""i". As the equations indicate, when a real Pelton wheel is working close to maximum efficiency, the fluid flows off the wheel with very little residual velocity. This basic theory does "not" suggest that efficiency will vary with hydraulic head, and further theory is required to show this.
There are five types of efficiency in Pelton turbine:
System components.
The conduit bringing high-pressure water to the impulse wheel is called the penstock. Originally the penstock was the name of the valve, but the term has been extended to include all of the fluid supply hydraulics. Penstock is now used as a general term for a water passage and control that is under pressure, whether it supplies an impulse turbine or not.

</doc>
<doc id="24975" url="http://en.wikipedia.org/wiki?curid=24975" title="Piezoelectricity">
Piezoelectricity

Piezoelectricity is the electric charge that accumulates in certain solid materials (such as crystals, certain ceramics, and biological matter such as bone, DNA and various proteins) in response to applied mechanical stress. The word "piezoelectricity" means electricity resulting from pressure. It is derived from the Greek "piezo" or "piezein" (πιέζειν), which means to squeeze or press, and "electric" or "electron" (ήλεκτρον), which means amber, an ancient source of electric charge. Piezoelectricity was discovered in 1880 by French physicists Jacques and Pierre Curie.
The piezoelectric effect is understood as the linear electromechanical interaction between the mechanical and the electrical state in crystalline materials with no inversion symmetry. The piezoelectric effect is a reversible process in that materials exhibiting the direct piezoelectric effect (the internal generation of electrical charge resulting from an applied mechanical force) also exhibit the reverse piezoelectric effect (the internal generation of a mechanical strain resulting from an applied electrical field). For example, lead zirconate titanate crystals will generate measurable piezoelectricity when their static structure is deformed by about 0.1% of the original dimension. Conversely, those same crystals will change about 0.1% of their static dimension when an external electric field is applied to the material. The inverse piezoelectric effect is used in production of ultrasonic sound waves.
Piezoelectricity is found in useful applications such as the production and detection of sound, generation of high voltages, electronic frequency generation, microbalances, to drive an ultrasonic nozzle, and ultrafine focusing of optical assemblies. It is also the basis of a number of scientific instrumental techniques with atomic resolution, the scanning probe microscopies such as STM, AFM, MTA, SNOM, etc., and everyday uses such as acting as the ignition source for cigarette lighters, push-start propane barbecues, and quartz watches.
History.
Discovery and early research.
The pyroelectric effect, by which a material generates an electric potential in response to a temperature change, was studied by Carl Linnaeus and Franz Aepinus in the mid-18th century. Drawing on this knowledge, both René Just Haüy and Antoine César Becquerel posited a relationship between mechanical stress and electric charge; however, experiments by both proved inconclusive.
The first demonstration of the direct piezoelectric effect was in 1880 by the brothers Pierre Curie and Jacques Curie. They combined their knowledge of pyroelectricity with their understanding of the underlying crystal structures that gave rise to pyroelectricity to predict crystal behavior, and demonstrated the effect using crystals of tourmaline, quartz, topaz, cane sugar, and Rochelle salt (sodium potassium tartrate tetrahydrate). Quartz and Rochelle salt exhibited the most piezoelectricity.
The Curies, however, did not predict the converse piezoelectric effect. The converse effect was mathematically deduced from fundamental thermodynamic principles by Gabriel Lippmann in 1881. The Curies immediately confirmed the existence of the converse effect, and went on to obtain quantitative proof of the complete reversibility of electro-elasto-mechanical deformations in piezoelectric crystals.
For the next few decades, piezoelectricity remained something of a laboratory curiosity. More work was done to explore and define the crystal structures that exhibited piezoelectricity. This culminated in 1910 with the publication of Woldemar Voigt's "Lehrbuch der Kristallphysik" (Textbook on Crystal Physics), which described the 20 natural crystal classes capable of piezoelectricity, and rigorously defined the piezoelectric constants using tensor analysis.
World War I and post-war.
The first practical application for piezoelectric devices was sonar, first developed during World War I. In France in 1917, Paul Langevin and his coworkers developed an ultrasonic submarine detector. The detector consisted of a transducer, made of thin quartz crystals carefully glued between two steel plates, and a hydrophone to detect the returned echo. By emitting a high-frequency pulse from the transducer, and measuring the amount of time it takes to hear an echo from the sound waves bouncing off an object, one can calculate the distance to that object.
The use of piezoelectricity in sonar, and the success of that project, created intense development interest in piezoelectric devices. Over the next few decades, new piezoelectric materials and new applications for those materials were explored and developed.
Piezoelectric devices found homes in many fields. Ceramic phonograph cartridges simplified player design, were cheap and accurate, and made record players cheaper to maintain and easier to build. The development of the ultrasonic transducer allowed for easy measurement of viscosity and elasticity in fluids and solids, resulting in huge advances in materials research. Ultrasonic time-domain reflectometers (which send an ultrasonic pulse through a material and measure reflections from discontinuities) could find flaws inside cast metal and stone objects, improving structural safety.
World War II and post-war.
During World War II, independent research groups in the United States, Russia, and Japan discovered a new class of synthetic materials, called ferroelectrics, which exhibited piezoelectric constants many times higher than natural materials. This led to intense research to develop barium titanate and later lead zirconate titanate materials with specific properties for particular applications.
One significant example of the use of piezoelectric crystals was developed by Bell Telephone Laboratories. Following World War I, Frederick R. Lack, working in radio telephony in the engineering department, developed the “AT cut” crystal, a crystal that operated through a wide range of temperatures. Lack's crystal didn't need the heavy accessories previous crystal used, facilitating its use on aircraft. This development allowed Allied air forces to engage in coordinated mass attacks through the use of aviation radio.
Development of piezoelectric devices and materials in the United States was kept within the companies doing the development, mostly due to the wartime beginnings of the field, and in the interests of securing profitable patents. New materials were the first to be developed — quartz crystals were the first commercially exploited piezoelectric material, but scientists searched for higher-performance materials. Despite the advances in materials and the maturation of manufacturing processes, the United States market did not grow as quickly as Japan's did. Without many new applications, the growth of the United States' piezoelectric industry suffered.
In contrast, Japanese manufacturers shared their information, quickly overcoming technical and manufacturing challenges and creating new markets. In Japan a temperature stable crystal cut was developed by Issac Koga (Electrical Engineer). Japanese efforts in materials research created piezoceramic materials competitive to the U.S. materials but free of expensive patent restrictions. Major Japanese piezoelectric developments included new designs of piezoceramic filters for radios and televisions, piezo buzzers and audio transducers that can connect directly to electronic circuits, and the piezoelectric igniter, which generates sparks for small engine ignition systems (and gas-grill lighters) by compressing a ceramic disc. Ultrasonic transducers that transmit sound waves through air had existed for quite some time but first saw major commercial use in early television remote controls. These transducers now are mounted on several car models as an echolocation device, helping the driver determine the distance from the rear of the car to any objects that may be in its path.
Mechanism.
The nature of the piezoelectric effect is closely related to the occurrence of electric dipole moments in solids. The latter may either be induced for ions on crystal lattice sites with asymmetric charge surroundings (as in BaTiO3 and PZTs) or may directly be carried by molecular groups (as in cane sugar). The dipole density or polarization (dimensionality [Cm/m3] ) may easily be calculated for crystals by summing up the dipole moments per volume of the crystallographic unit cell. As every dipole is a vector, the dipole density P is a vector field. Dipoles near each other tend to be aligned in regions called Weiss domains. The domains are usually randomly oriented, but can be aligned using the process of "poling" (not the same as magnetic poling), a process by which a strong electric field is applied across the material, usually at elevated temperatures. Not all piezoelectric materials can be poled.
Of decisive importance for the piezoelectric effect is the change of polarization P when applying a mechanical stress. This might either be caused by a re-configuration of the dipole-inducing surrounding or by re-orientation of molecular dipole moments under the influence of the external stress. Piezoelectricity may then manifest in a variation of the polarization strength, its direction or both, with the details depending on 1. the orientation of P within the crystal, 2. crystal symmetry and 3. the applied mechanical stress. The change in P appears as a variation of surface charge density upon the crystal faces, i.e. as a variation of the electric field extending between the faces caused by a change in dipole density in the bulk. For example, a 1 cm3 cube of quartz with 2 kN (500 lbf) of correctly applied force can produce a voltage of 12500 V.
Piezoelectric materials also show the opposite effect, called converse piezoelectric effect, where the application of an electrical field creates mechanical deformation in the crystal.
Mathematical description.
Piezoelectricity is the combined effect of the electrical behavior of the material:
where "D" is the electric charge density displacement (electric displacement), ε is permittivity and "E" is electric field strength, and Hooke's Law:
where "S" is strain, "s" is compliance and "T" is stress.
These may be combined into so-called "coupled equations", of which the strain-charge form is:
In matrix form,
where formula_5 is the matrix for the direct piezoelectric effect and formula_6 is the matrix for the converse piezoelectric effect. The superscript "E" indicates a zero, or constant, electric field; the superscript "T" indicates a zero, or constant, stress field; and the superscript "t" stands for transposition of a matrix.
The strain-charge for a material of the 4mm (C4v) crystal class (such as a poled piezoelectric ceramic such as tetragonal PZT or BaTiO3) as well as the 6mm crystal class may also be written as (ANSI IEEE 176):
where the first equation represents the relationship for the converse piezoelectric effect and the latter for the direct piezoelectric effect.
Although the above equations are the most used form in literature, some comments about the notation are necessary. Generally "D" and "E" are vectors, that is, Cartesian tensor of rank-1; and permittivity ε is Cartesian tensor of rank 2. Strain and stress are, in principle, also rank-2 tensors. But conventionally, because strain and stress are all symmetric tensors, the subscript of strain and stress can be re-labeled in the following fashion: 11 → 1; 22 → 2; 33 → 3; 23 → 4; 13 → 5; 12 → 6. (Different convention may be used by different authors in literature. Say, some use 12 → 4; 23 → 5; 31 → 6 instead.) That is why "S" and "T" appear to have the "vector form" of 6 components. Consequently, "s" appears to be a 6 by 6 matrix instead of rank-4 tensor. Such a re-labeled notation is often called Voigt notation. Whether the shear strain components formula_9 are tensor components or engineering strains is another question. In the equation above, they must be engineering strains for the 6,6 coefficient of the compliance matrix to be written as shown, i.e., formula_10. Engineering shear strains are double the value of the corresponding tensor shear, such as formula_11 and so on. This also means that formula_12, where formula_13 is the shear modulus.
In total, there are 4 piezoelectric coefficients, formula_14, formula_15, formula_16, and formula_17 defined as follows:
where the first set of 4 terms correspond to the direct piezoelectric effect and the second set of 4 terms correspond to the converse piezoelectric effect. A formalism has been worked out for those piezoelectric crystals, for which the polarization is of the crystal-field induced type, that allows for the calculation of piezoelectrical coefficients formula_14 from electrostatic lattice constants or higher-order Madelung constants.
Crystal classes.
Of the thirty-two crystal classes, twenty-one are non-centrosymmetric (not having a centre of symmetry), and of these, twenty exhibit direct piezoelectricity (the 21st is the cubic class 432). Ten of these represent the polar crystal classes, which show a spontaneous polarization without mechanical stress due to a non-vanishing electric dipole moment associated with their unit cell, and which exhibit pyroelectricity. If the dipole moment can be reversed by the application of an electric field, the material is said to be ferroelectric.
For polar crystals, for which P ≠ 0 holds without applying a mechanical load, the piezoelectric effect manifests itself by changing the magnitude or the direction of P or both.
For the non-polar, but piezoelectric crystals, on the other hand, a polarization P different from zero is only elicited by applying a mechanical load. For them the stress can be imagined to transform the material from a non-polar crystal class (P =0) to a polar one, having P ≠ 0.
Materials.
Many materials, both natural and synthetic, exhibit piezoelectricity:
Naturally occurring crystals.
The action of piezoelectricity in Topaz can probably be attributed to ordering of the (F,OH) in its lattice, which is otherwise centrosymmetric: Orthorhombic Bipyramidal (mmm). Topaz has anomalous optical properties which are attributed to such ordering.
Bone.
Dry bone exhibits some piezoelectric properties. Studies of Fukada "et al." showed that these are not due to the apatite crystals, which are centrosymmetric, thus non-piezoelectric, but due to collagen. Collagen exhibits the polar uniaxial orientation of molecular dipoles in its structure and can be considered as bioelectret, a sort of dielectric material exhibiting quasipermanent space charge and dipolar charge. Potentials are thought to occur when a number of collagen molecules are stressed in the same way displacing significant numbers of the charge carriers from the inside to the surface of the specimen. Piezoelectricity of single individual collagen fibrils was measured using piezoresponse force microscopy, and it was shown that collagen fibrils behave predominantly as shear piezoelectric materials.
The piezoelectric effect is generally thought to act as a biological force sensor. This effect was exploited by research conducted at the University of Pennsylvania in the late 1970s and early 1980s, which established that sustained application of electrical potential could stimulate both resorption and growth (depending on the polarity) of bone in-vivo. Further studies in the 1990s provided the mathematical equation to confirm long bone wave propagation as to that of hexagonal (Class 6) crystals.
Other natural materials.
Biological materials exhibiting piezoelectric properties include:
Synthetic ceramics.
Ceramics with randomly oriented grains must be ferroelectric to exhibit piezoelectricty. The macroscopic piezoelectricity is possible in textured polycrystalline non–ferroelectric piezoelectric materials, such as AlN and ZnO. 
The family of ceramics with perovskite, tungsten-bronze and related structures exhibits piezoelectricity:
Lead-free piezoceramics.
More recently, there is growing concern regarding the toxicity in lead-containing devices driven by the result of restriction of hazardous substances directive regulations. To address this concern, there has been a resurgence in the compositional development of lead-free piezoelectric materials.
So far, neither the environmental impact nor the stability of supplying these substances have been confirmed.
III-V and II-VI Semiconductors.
A piezoelectric potential can be created in any bulk or nanostructured semiconductor crystal having non central symmetry, such as the Group III-V and II-VI materials, due to polarization of ions under applied stress and strain. This property is common to both the zincblende and wurtzite crystal structures. To first order there is only one independent piezoelectric coefficient in zincblende, called e14, coupled to shear components of the strain. In wurtzite instead there are 
3 independent piezoelectric coefficients: e31, e33 and e15.
The semiconductors where the strongest piezoelectricity is observed are those commonly found in the wurtzite structure, i.e. GaN, InN, AlN and ZnO.
ZnO is the most used material in the recent field of piezotronics.
Since 2006 there have also been a number of reports of strong non linear piezoelectric effects in polar semiconductors.
Such effects are generally recognized to be at least important if not of the same order of magnitude as the first order approximation.
Organic nanostructures.
A strong shear piezoelectric activity was observed in self-assembled diphenylalanine peptide nanotubes (PNTs), indicating electric polarization directed along the tube axis. Comparison with LiNbO3 and lateral signal calibration yields sufficiently high effective piezoelectric coefficient values of at least 60 pm/V (shear response for tubes of ≈200 nm in diameter). PNTs demonstrate linear deformation without irreversible degradation in a broad range of driving voltages.
Application.
Currently, industrial and manufacturing is the largest application market for piezoelectric devices, followed by the automotive industry. Strong demand also comes from medical instruments as well as information and telecommunications. The global demand for piezoelectric devices was valued at approximately US$14.8 billion in 2010. The largest material group for piezoelectric devices is piezocrystal, and piezopolymer is experiencing the fastest growth due to its low weight and small size.
Piezoelectric crystals are now used in numerous ways:
High voltage and power sources.
Direct piezoelectricity of some substances, like quartz, can generate potential differences of thousands of volts.
Sensors.
The principle of operation of a piezoelectric sensor is that a physical dimension, transformed into a force, acts on two opposing faces of the sensing element. Depending on the design of a sensor, different "modes" to load the piezoelectric element can be used: longitudinal, transversal and shear.
Detection of pressure variations in the form of sound is the most common sensor application, e.g. piezoelectric microphones (sound waves bend the piezoelectric material, creating a changing voltage) and piezoelectric pickups for acoustic-electric guitars. A piezo sensor attached to the body of an instrument is known as a contact microphone.
Piezoelectric sensors especially are used with high frequency sound in ultrasonic transducers for medical imaging and also industrial nondestructive testing (NDT).
For many sensing techniques, the sensor can act as both a sensor and an actuator – often the term "transducer" is preferred when the device acts in this dual capacity, but most piezo devices have this property of reversibility whether it is used or not. Ultrasonic transducers, for example, can inject ultrasound waves into the body, receive the returned wave, and convert it to an electrical signal (a voltage). Most medical ultrasound transducers are piezoelectric.
In addition to those mentioned above, various sensor applications include:
Actuators.
As very high electric fields correspond to only tiny changes in the width of the crystal, this width can be changed with better-than-µm precision, making piezo crystals the most important tool for positioning objects with extreme accuracy — thus their use in actuators.
Multilayer ceramics, using layers thinner than 100 µm, allow reaching high electric fields with voltage lower than 150 V. These ceramics are used within two kinds of actuators: direct piezo actuators and Amplified piezoelectric actuators. While direct actuator's stroke is generally lower than 100 µm, amplified piezo actuators can reach millimeter strokes.
Frequency standard.
The piezoelectrical properties of quartz are useful as standard of frequency.
Piezoelectric motors.
Types of piezoelectric motor include:
All these motors, except the stepping stick-slip motor work on the same principle. Driven by dual orthogonal vibration modes with a phase difference of 90°, the contact point between two surfaces vibrates in an elliptical path, producing a frictional force between the surfaces. Usually, one surface is fixed causing the other to move. In most piezoelectric motors the piezoelectric crystal is excited by a sine wave signal at the resonant frequency of the motor. Using the resonance effect, a much lower voltage can be used to produce a high vibration amplitude.
Stick-slip motor works using the inertia of a mass and the friction of a clamp. Such motors can be very small. Some are used for camera sensor displacement, thus allowing an anti-shake function.
Reduction of vibrations and noise.
Different teams of researchers have been investigating ways to reduce vibrations in materials by attaching piezo elements to the material. When the material is bent by a vibration in one direction, the vibration-reduction system responds to the bend and sends electric power to the piezo element to bend in the other direction. Future applications of this technology are expected in cars and houses to reduce noise. Further applications to flexible structures, such as shells and plates, have also been studied for nearly three decades.
In a demonstration at the Material Vision Fair in Frankfurt in November 2005, a team from TU Darmstadt in Germany showed several panels that were hit with a rubber mallet, and the panel with the piezo element immediately stopped swinging.
Piezoelectric ceramic fiber technology is being used as an electronic damping system on some HEAD tennis rackets.
Infertility treatment.
In people with previous total fertilization failure, piezoelectric activation of oocytes together with intracytoplasmic sperm injection (ICSI) seems to improve fertilization outcomes.
Surgery.
A recent application of piezoelectric ultrasound sources is piezoelectric surgery, also known as piezosurgery. Piezosurgery is a minimally invasive technique that aims to cut a target tissue with little damage to neighboring tissues. For example, Hoigne "et al." reported its use in hand surgery for the cutting of bone, using frequencies in the range 25–29 kHz, causing microvibrations of 60–210 μm. It has the ability to cut mineralized tissue without cutting neurovascular tissue and other soft tissue, thereby maintaining a blood-free operating area, better visibility and greater precision.
Potential applications.
In 2015, Cambridge University researchers working in conjunction with researchers from the National Physical Laboratory and Cambridge-based dielectric antenna company Antenova Ltd, using thin films of piezoelectric materials found that at a certain frequency, these materials become not only efficient resonators, but efficient radiators as well, meaning that they can potentially be used as antennas.
The researchers found that by subjecting the piezoelectric thin films to an asymmetric excitation, the symmetry of the system is similarly broken, resulting in a corresponding symmetry breaking of the electric field, and the generation of electromagnetic radiation.
In recent years, several attempts at the macro-scale application of the piezoelectric technology have emerged to harvest kinetic energy from walking pedestrians. The piezoelectric floors have been trialed since the beginning of 2007 in two Japanese train stations, Tokyo and Shibuya stations. The electricity generated from the foot traffic is used to provide all the electricity needed to run the automatic ticket gates and electronic display systems. In London, a famous nightclub exploited the piezoelectric technology in its dance floor. Parts of the lighting and sound systems in the club can be powered by the energy harvesting tiles. However, the piezoelectric tile deployed on the ground usually harvests energy from low frequency strikes provided by the foot traffic. This working condition may eventually lead to low power generation efficiency.
In this case, locating high traffic areas is critical for optimization of the energy harvesting efficiency, as well as the orientation of the tile pavement significantly affects the total amount of the harvested energy. A Density Flow evaluation is recommended to qualitatively evaluate the piezoelectric power harvesting potential of the considered area based on the number of pedestrian crossings per unit time. In X. Li's study, the potential application of a commercial piezoelectric energy harvester in a central hub building at Macquarie University in Sydney, Australia is examined and discussed. Optimization of the piezoelectric tile deployment is presented according to the frequency of pedestrian mobility and a model is developed where 3.1% of the total floor area with the highest pedestrian mobility is paved with piezoelectric tiles. The modelling results indicate that the total annual energy harvesting potential for the proposed optimized tile pavement model is estimated at 1.1 MW h/year, which would be sufficient to meet close to 0.5% of the annual energy needs of the building.
Photovoltaics.
The efficiency of a hybrid photovoltaic cell that contains piezoelectric materials can be increased simply by placing it near a source of ambient noise or vibration. The effect was demonstrated with organic cells using zinc oxide nanotubes. The electricity generated by the piezoelectric effect itself is a negligible percentage of the overall output. Sound levels as low as 75 decibels improved efficiency by up to 50 percent. Efficiency peaked at 10 kHz, the resonant frequency of the nanotubes. The electrical field set up by the vibrating nanotubes interacts with electrons migrating from the organic polymer layer. This process decreases the likelihood of recombination, in which electrons are energized but settle back into a hole instead of migrating to the electron-accepting ZnO layer.
References.
H.S. Tzou, Piezoelectric shells: distributed sensing & control, Kluwer Academic Publishers, London, 1993.

</doc>
<doc id="24977" url="http://en.wikipedia.org/wiki?curid=24977" title="Product (mathematics)">
Product (mathematics)

In mathematics, a product is the result of multiplying, or an expression that identifies factors to be multiplied. Thus, for instance, 6 is the product of 2 and 3 (the result of multiplication), and formula_1 is the product of formula_2 and formula_3 (indicating that the two factors should be multiplied together).
The order in which real or complex numbers are multiplied has no bearing on the product; this is known as the commutative law of multiplication. When matrices or members of various other associative algebras are multiplied, the product usually depends on the order of the factors. Matrix multiplication, for example, and multiplication in other algebras is in general non-commutative.
Product of two numbers.
Product of two natural numbers.
Placing several stones into a rectangular pattern with formula_4 rows and formula_5 columns gives
stones.
Product of two integers.
Integers allow positive and negative numbers. The two numbers are multiplied just like natural numbers, except we need an additional rule for the signs:
In words, we have:
Product of two fractions.
Two fractions can be multiplied by multiplying their numerators and denominators:
Product of two real numbers.
For a rigorous definition of the product of two real numbers see Construction of the real numbers.
Product of two complex numbers.
Two complex numbers can be multiplied by the distributive law and the fact that formula_9, as follows:
Geometric meaning of complex multiplication.
Complex numbers can be written in polar coordinates:
Furthermore,
The geometric meaning is that we multiply the magnitudes and add the angles.
Product of two quaternions.
The product of two quaternions can be found in the article on quaternions. However, it is interesting to note that in this case, formula_14 and formula_15 are different.
Product of sequences.
The product operator for the product of a sequence is denoted by the capital Greek letter Pi ∏ (in analogy to the use of the capital Sigma ∑ as summation symbol). The product of a sequence consisting of only one number is just that number itself. The product of no factors at all is known as the empty product, and is equal to 1.
Further examples for commutative rings.
Residue classes of integers.
Residue classes in the rings formula_16 can be added:
and multiplied:
Rings of functions.
Functions to the real numbers can be added or multiplied by adding or multiplying their outputs:
Convolution.
Two functions from the reals to itself can be multiplied in another way, called the convolution.
If :formula_21
then the integral
is well defined and is called the convolution.
Under the Fourier transform, convolution becomes multiplication.
Polynomial rings.
The product of two polynomials is given by the following:
with
Products in linear algebra.
Scalar multiplication.
By the very definition of a vector space, one can form the product of any scalar with any vector, giving a map formula_25.
Scalar product.
A scalar product is a bilinear map:
with the following conditions, that formula_27 for all formula_28.
From the scalar product, one can define a norm by letting formula_29.
The scalar product also allows one to define an angle between two vectors:
In formula_31-dimensional Euclidean space, the standard scalar product (called the dot product) is given by:
Cross product in 3-dimensional space.
The cross product of two vectors in 3-dimensions is a vector perpendicular to the two factors, with length equal to the area of the parallelogram spanned by the two factors.
The cross product can also be expressed as the formal determinant:
Composition of linear mappings.
A linear mapping can be defined as a function "f" between two vector spaces "V" and "W" with underlying field F, satisfying
If one only considers finite dimensional vector spaces, then
in which bV andbW denote the bases of "V" and "W", and "vi" denotes the component of v on bV"i", and Einstein summation convention is applied.
Now we consider the composition of two linear mappings between finite dimensional vector spaces. Let the linear mapping "f" map "V" to "W", and let the linear mapping "g" map "W" to "U". Then one can get
Or in matrix form:
in which the "i"-row, "j"-column element of F, denoted by "Fij", is "fji", and "Gij=gji".
The composition of more than two linear mappings can be similarly represented by a chain of matrix multiplication.
Product of two matrices.
Given two matrices
their product is given by
Composition of linear functions as matrix product.
There is a relationship between the composition of linear functions and the product of two matrices. To see this, let r = dim(U), s = dim(V) and t = dim(W) be the (finite) dimensions of vector spaces U, V und W. Let 
formula_41 be a basis von U, 
formula_42 be a basis of V und 
formula_43 be a basis of W. In terms of this basis, let 
formula_44
be the matrix representing f : U → V and 
formula_45 
be the matrix representing g : V → W. Then 
is the matrix representing formula_47. 
In other words: the matrix product is the description in coordinates of the composition of linear functions.
Tensor product of vector spaces.
Given two finite dimensional vector spaces "V" and "W", the tensor product of them can be defined as a (2,0)-tensor satisfying:
where "V*" and "W*" denote the dual spaces of "V" and "W".
Set theoretical product.
In set theory, a Cartesian product is a mathematical operation which returns a set (or product set) from multiple sets. That is, for sets "A" and "B", the Cartesian product "A" × "B" is the set of all ordered pairs (a, b) where a ∈ "A" and b ∈ "B".
Empty product.
The empty product has the value of 1 (the identity element of multiplication) just like the empty sum has the value of 0 (the identity element of addition).
Products in category theory.
It is often possible to form the product of two (or more) mathematical objects to form another object of the same kind. Such products are generically called internal products, as they can be described by the generic notion of a monoidal category. Examples include:
For the general treatment of the concept of a product, see product (category theory), which describes how to combine two objects of some kind to create an object, possibly of a different kind. But also, in category theory, one has:

</doc>
<doc id="24979" url="http://en.wikipedia.org/wiki?curid=24979" title="4-polytope">
4-polytope

In geometry, a 4-polytope (sometimes also called a polychoron, polycell, or polyhedroid) is a four-dimensional polytope. It is a connected and closed figure, composed of lower-dimensional polytopal elements: vertices, edges, faces (polygons), and cells (polyhedra). Each face is shared by exactly two cells.
The two-dimensional analogue of a 4-polytope is a polygon, and the three-dimensional analogue is a polyhedron.
Topologically 4-polytopes are closely related to the uniform honeycombs, such as the cubic honeycomb, which tessellate 3-space; similarly the 3D cube is related to the infinite 2D square tiling. Convex 4-polytopes can be "cut and unfolded" as nets in 3-space.
Definition.
A 4-polytope is a closed four-dimensional figure. It comprises vertices (corner points), edges, faces and cells. A cell is the three-dimensional analogue of a face, and is therefore a polyhedron. Each face must join exactly two cells, analogous to the way in which each edge of a polyhedron joins just two faces. Like any polytope, the elements of a 4-polytope cannot be subdivided into two or more sets which are also 4-polytopes, i.e. it is not a compound.
The most familiar 4-polytope is the tesseract or hypercube, the 4D analogue of the cube.
Visualisation.
4-polytopes cannot be seen in three-dimensional space due to their extra dimension. Several techniques are used to help visualise them.
Orthogonal projections can be used to show various symmetry orientations of a 4-polytope. They can be drawn in 2D as vertex-edge graphs, and can be shown in 3D with solid faces as visible projective envelopes.
Just as a 3D shape can be projected onto a flat sheet, so a 4-D shape can be projected onto 3-space or even onto a flat sheet. One common projection is a Schlegel diagram which uses stereographic projection of points on the surface of a 3-sphere into three dimensions, connected by straight edges, faces, and cells drawn in 3-space.
Just as a slice through a polyhedron reveals a cut surface, so a slice through a 4-polytope reveals a cut "hypersurface" in three dimensions. A sequence of such sections can be used to build up an understanding of the overall shape. The extra dimension can be equated with time to produce a smooth animation of these cross sections.
A net of a 4-polytope is composed of polyhedral cells that are connected by their faces and all occupy the same three-dimensional space, just as the polygon faces of a net of a polyhedron are connected by their edges and all occupy the same plane.
Topological characteristics.
The topology of any given 4-polytope is defined by its Betti numbers and torsion coefficients.
The value of the Euler characteristic used to characterise polyhedra does not generalize usefully to higher dimensions, and is zero for all 4-polytopes, whatever their underlying topology. This inadequacy of the Euler characteristic to reliably distinguish between different topologies in higher dimensions led to the discovery of the more sophisticated Betti numbers.
Similarly, the notion of orientability of a polyhedron is insufficient to characterise the surface twistings of toroidal 4-polytopes, and this led to the use of torsion coefficients.
Classification.
Criteria.
Like all polytopes, 4-polytopes may be classified based on properties like "convexity" and "symmetry".
Classes.
The following lists the various categories of 4-polytopes classified according to the criteria above:
Uniform 4-polytope (vertex-transitive):
Other convex 4-polytopes:
Infinite uniform 4-polytopes of Euclidean 3-space (uniform tessellations of convex uniform cells)
Infinite uniform 4-polytopes of hyperbolic 3-space (uniform tessellations of convex uniform cells)
Dual uniform 4-polytope (cell-transitive):
Others:
Abstract regular 4-polytopes:
These categories include only the 4-polytopes that exhibit a high degree of symmetry. Many other 4-polytopes are possible, but they have not been studied as extensively as the ones included in these categories.

</doc>
<doc id="24980" url="http://en.wikipedia.org/wiki?curid=24980" title="Punctuated equilibrium">
Punctuated equilibrium

Punctuated equilibrium (also called punctuated equilibria) is a theory in evolutionary biology which proposes that once formed most species will exhibit little net evolutionary change for most of their geological history, remaining in an extended state of "stasis". When significant evolutionary change occurs, the theory proposes that it is generally restricted to rare and rapid (on a geologic time scale) events of branching speciation called cladogenesis. Cladogenesis is the process by which a species splits into two distinct species, rather than one species gradually transforming into another. Punctuated equilibrium is commonly contrasted against phyletic gradualism, the belief that evolution generally occurs uniformly and by the steady and gradual transformation of whole lineages (called anagenesis). In this view, evolution is seen as generally smooth and continuous. 
In 1972, paleontologists Niles Eldredge and Stephen Jay Gould published a landmark paper developing their theory and called it "punctuated equilibria". Their paper built upon Ernst Mayr's model of geographic speciation, I. Michael Lerner's theories of developmental and genetic homeostasis, as well as their own empirical research. Eldredge and Gould proposed that the degree of gradualism commonly attributed to Charles Darwin is virtually nonexistent in the fossil record, and that stasis dominates the history of most fossil species.
History.
Punctuated equilibrium originated as a logical extension of Ernst Mayr's concept of genetic revolutions by allopatric and especially peripatric speciation as applied to the fossil record. Although some of the basic workings of the theory were proposed and identified by Mayr in 1954, historians of science generally recognize the 1972 paper by Niles Eldredge and Stephen Jay Gould as the foundation of the new paleobiological research program. Punctuated equilibrium differs from Mayr's theory mainly in that Eldredge and Gould placed considerably greater emphasis on stasis, whereas Mayr was generally concerned with explaining the morphological discontinuity (or "sudden jumps") found in the fossil record. Mayr later complimented Eldredge and Gould's paper, stating that evolutionary stasis had been "unexpected by most evolutionary biologists" and that punctuated equilibrium "had a major impact on paleontology and evolutionary biology".
A year before their 1972 Eldredge and Gould paper, Niles Eldredge published a paper in the journal "Evolution" which suggested that gradual evolution was seldom seen in the fossil record and argued that Ernst Mayr's standard mechanism of allopatric speciation might suggest a possible resolution.
The Eldredge and Gould paper was presented at the Annual Meeting of the Geological Society of America in 1971. The symposium focused its attention on the possibility that modern microevolutionary studies could revitalize various aspects of paleontology and macroevolution. Tom Schopf, who organized that year's meeting, assigned Gould the topic of speciation. Gould recalls that "Eldredge's 1971 publication [on Paleozoic trilobites] had presented the only new and interesting ideas on the paleontological implications of the subject—so I asked Schopf if we could present the paper jointly."
According to Gould "the ideas came mostly from Niles, with yours truly acting as a sounding board and eventual scribe. I coined the term "punctuated equilibrium" and wrote most of our 1972 paper, but Niles is the proper first author in our pairing of Eldredge and Gould." In his book "Time Frames" Eldredge recalls that after much discussion the pair "each wrote roughly half. Some of the parts that would seem obviously the work of one of us were actually first penned by the other—I remember for example, writing the section on Gould's snails. Other parts are harder to reconstruct. Gould edited the entire manuscript for better consistency. We sent it in, and Schopf reacted strongly against it—thus signaling the tenor of the reaction it has engendered, though for shifting reasons, down to the present day."
John Wilkins and Gareth Nelson have argued that French architect Pierre Trémaux proposed an "anticipation of the theory of punctuated equilibrium of Gould and Eldredge."
The fossil record.
The fossil record of an evolutionary progression typically consists of species that suddenly appear, and ultimately disappear, in many cases close to a million years later, without any change in external appearance. Graphically, these fossil species are represented by horizontal lines, whose lengths depict how long each of them existed. The horizontality of the lines illustrates the unchanging appearance of each of the fossil species depicted on the graph. During each species' existence new species appear at random intervals, each also lasting many hundreds of thousands of years before disappearing without a change in appearance. The exact relatedness of these concurrent species is generally impossible to determine. This is illustrated in the following diagram depicting the evolution of modern humans from the time that the Hominins separated from the line that led to the evolution of our closest living primate relatives, the chimpanzees.
For similar evolutionary time lines, showing the identical pattern of evolutionary change, see, for instance, the paleontological list of African dinosaurs, Asian dinosaurs, the Lampriformes and Amiiformes. (Note the different time scales in these different diagrams.)
Theoretical mechanisms.
Punctuational change.
When Eldredge and Gould published their 1972 paper, allopatric speciation was considered the "standard" model of speciation. This model was popularized by Ernst Mayr in his 1954 paper "Change of genetic environment and evolution," and his classic volume "Animal Species and Evolution" (1963).
Allopatric speciation suggests that species with large central populations are stabilized by their large volume and the process of gene flow. New and even beneficial mutations are diluted by the population's large size and are unable to reach fixation, due to such factors as constantly changing environments. If this is the case, then the transformation of whole lineages should be rare, as the fossil record indicates. Smaller populations on the other hand, which are isolated from the parental stock, are decoupled from the homogenizing effects of gene flow. In addition, pressure from natural selection is especially intense, as peripheral isolated populations exist at the outer edges of ecological tolerance. If most evolution happens in these rare instances of allopatric speciation then evidence of gradual evolution in the fossil record should be rare. This stimulating hypothesis was alluded to by Mayr in the closing paragraph of his 1954 paper (p. 179).
As time went on Gould moved away from wedding punctuated equilibrium to allopatric speciation, particularly as evidence accumulated in support of other modes of speciation. Gould was particularly attracted to Douglas Futuyma's work on the importance of reproductive isolating mechanisms.
Other biologists have also applied punctuated equilibrium to non-sexual species, including the evolution of viruses.
Stasis.
Before Eldredge and Gould alerted their colleagues to the prominence of stasis in the fossil record, most evolutionists considered stasis to be rare or unimportant. George Gaylord Simpson, for example, believed that phyletic gradual evolution (called "horotely" in his terminology) comprised "nine-tenths" (90%) of evolution. Many hypotheses have been proposed to explain the putative causes of stasis. Gould was initially attracted to I. Michael Lerner's theories of developmental and genetic homeostasis. However this hypothesis was rejected over time, as evidence accumulated against it. Other plausible mechanisms which have been suggested include: habitat tracking, stabilizing selection, the Stenseth-Maynard Smith stability hypothesis, constraints imposed by the nature of subdivided populations, normalizing clade selection, and koinophilia.
Evidence for the existence of stasis has also been corroborated from the genetics of sibling species, species which are morphologically indistinguishable, but whose proteins have diverged sufficiently to suggest they have been separated for millions of years. A paramount example of evolutionary stasis is the fern "Osmunda claytoniana". Based on paleontological evidence it has remained unchanged, even at the level of fossilized nuclei and chromosomes, for at least 180 million years.
According to Gould, "stasis may emerge as the theory's most important contribution to evolutionary science." Philosopher Kim Sterelny adds, "In claiming that species typically undergo no further evolutionary change once speciation is complete, they are not claiming that there is no change at all between one generation and the next. Lineages do change. But the change between generations does not accumulate. Instead, over time, the species wobbles about its phenotypic mean. Jonathan Weiner's "The Beak of the Finch" describes this very process."
The fossil record includes well documented examples of phyletic gradualism and punctuational evolution. As such, much debate persists over the prominence of stasis in the fossil record.
Hierarchical evolution.
Punctuated equilibrium has also been cited as contributing to the hypothesis that species are Darwinian individuals, and not just classes, thereby providing a stronger framework for a hierarchical theory of evolution.
Common misconceptions.
Much confusion has arisen over what proponents of punctuated equilibrium actually argued, what mechanisms they advocated, how fast the punctuations were, what taxonomic scale their theory applied to, how revolutionary their claims were intended to be, and how punctuated equilibrium related to other ideas like quantum evolution, saltationism, and mass extinction.
Saltationism.
The punctuational nature of punctuated equilibrium has engendered perhaps the most confusion over Eldredge and Gould's theory. Gould's sympathetic treatment of Richard Goldschmidt, the controversial geneticist who advocated the idea of "hopeful monsters," led some biologists to conclude that Gould's punctuations were occurring in single-generation jumps. This interpretation has frequently been exploited by creationists to mischaracterize the weakness of the paleontological record, and to portray contemporary evolutionary biology as advancing neo-saltationism. In an often quoted remark, Gould stated, "Since we proposed punctuated equilibria to explain trends, it is infuriating to be quoted again and again by creationists—whether through design or stupidity, I do not know—as admitting that the fossil record includes no transitional forms. Transitional forms are generally lacking at the species level, but they are abundant between larger groups." Although there exist some debate over how long the punctuations last, supporters of punctuated equilibrium generally place the figure between 50,000 and 100,000 years.
Quantum evolution.
Quantum evolution was a controversial hypothesis advanced by Columbia University paleontologist George Gaylord Simpson, who was regarded by Stephen Jay Gould as "the greatest and most biologically astute paleontologist of the twentieth century." Simpson's conjecture was that according to the geological record, on very rare occasions evolution would proceed very rapidly to form entirely new families, orders, and classes of organisms. This hypothesis differs from punctuated equilibrium in several respects. First, punctuated equilibrium was more modest in scope, in that it was addressing evolution specifically at the species level. Simpson's idea was principally concerned with evolution at higher taxonomic groups. Second, Eldredge and Gould relied upon a different mechanism. Where Simpson relied upon a synergistic interaction between genetic drift and a shift in the adaptive fitness landscape, Eldredge and Gould relied upon ordinary speciation, particularly Ernst Mayr's concept of allopatric speciation. Lastly, and perhaps most significantly, quantum evolution took no position on the issue of stasis. Although Simpson acknowledged the existence of stasis in what he called the bradytelic mode, he considered it (along with rapid evolution) to be unimportant in the larger scope of evolution. In his "Major Features of Evolution" Simpson stated, "Evolutionary change is so nearly the universal rule that a state of motion is, figuratively, normal in evolving populations. The state of rest, as in bradytely, is the exception and it seems that some restraint or force must be required to maintain it." Despite such differences between the two models, earlier critiques—from such eminent commentators as Sewall Wright as well as Simpson himself—have argued that punctuated equilibrium is little more than quantum evolution relabeled.
Multiple meanings of gradualism.
Punctuated equilibrium is often portrayed to oppose the concept of gradualism, when it is actually a form of gradualism. This is because even though evolutionary change appears instantaneous between geological sedimentary layers, change is still occurring incrementally, with no great change from one generation to the next. To this end, Gould later commented that "Most of our paleontological colleagues missed this insight because they had not studied evolutionary theory and either did not know about allopatric speciation or had not considered its translation to geological time. Our evolutionary colleagues also failed to grasp the implication(s), primarily because they did not think at geological scales".
Richard Dawkins dedicated a chapter in "The Blind Watchmaker" to correcting, in his view, the wide confusion regarding "rates of change". His first point is to argue that phyletic gradualism — understood in the sense that evolution proceeds at a single uniform rate of speed, called "constant speedism" by Dawkins — is a "caricature of Darwinism" and "does not really exist." His second argument, which follows from the first, is that once the caricature of "constant speedism" is dismissed, we are left with one logical alternative, which Dawkins terms "variable speedism." Variable speedism may also be distinguished one of two ways: ""discrete variable" speedism" and ""continuously variable" speedism." Eldredge and Gould, believing that evolution jumps between stability and relative rapidity, are described as "discrete variable speedists," and "in this respect they are genuinely radical." They believe that evolution generally proceeds in bursts, or not at all. "Continuously variable speedists," on the other hand believe that "evolutionary rates fluctuate continuously from very fast to very slow and stop, with all intermediates. They see no particular reason to emphasize certain speeds more than others. In particular, stasis, to them, is just an extreme case of ultra-slow evolution. To a punctuationist, there is something very special about stasis." Dawkins therefore commits himself here to an empirical claim about the geological record, in contrast to his earlier claim that "The paleontological evidence can be argued about, and I am not qualified to judge it." It is this particular commitment that Eldredge and Gould have aimed to overturn.
Criticism.
Richard Dawkins believes that the apparent gaps represented in the fossil record document migratory events rather than evolutionary events. According to Dawkins, evolution certainly occurred but "probably gradually" elsewhere. However, the punctuational equilibrium model may still be inferred from both the observation of stasis and examples of rapid and episodic speciation events documented in the fossil record.
Dawkins also emphasizes that punctuated equilibrium has been "oversold by some journalists", but partly due to Eldredge and Gould's "later writings". Dawkins contends that the theory "does not deserve a particularly large measure of publicity". It is a "minor gloss," an "interesting but minor wrinkle on the surface of neo-Darwinian theory," and "lies firmly within the neo-Darwinian synthesis".
In his book "Darwin's Dangerous Idea", philosopher Daniel Dennett is especially critical of Gould's presentation of punctuated equilibrium. Dennett argues that Gould alternated between revolutionary and conservative claims about the theory, and that each time Gould made a revolutionary statement—or appeared to do so—he was criticized, and thus retreated to a traditional neo-Darwinian position. Gould responded to Dennett's claims in "The New York Review of Books", and in his technical volume "The Structure of Evolutionary Theory".
Literary scholar Heidi Scott argued that Gould's use of analogy and metaphor constitutes a non-scientific discourse attempting to validate a scientific hypothesis. She claims that Gould—particularly in his popular essays—uses a variety of strategies from literature, political science, and personal anecdotes to substantiate the general pattern of punctuated equilibrium (long periods of stasis interrupted by rapid, catastrophic change). Gould responded that critics often made the mistake of confusing the context of discovery with the context of justification. While Gould is celebrated for the color and energy of his prose, as well as his massive interdisciplinary knowledge, critics such as Scott have concerns that the theory has gained undeserved credence among non-scientists because of Gould's rhetorical skills.
John Lyne and Henry Howe, in a more positive evaluation, state that "re-analysis of existing fossil data has shown, to the increasing satisfaction of the paleontological community, that Eldredge and Gould were correct in identifying periods of evolutionary stasis which are interrupted by much shorter periods of evolutionary change."
Darwin's theory.
The sudden appearance of most species in the geologic record and the lack of evidence of substantial gradual change in most species—from their initial appearance until their extinction—has long been noted, including by Charles Darwin who appealed to the imperfection of the record as the favored explanation. When presenting his ideas against the prevailing influences of catastrophism and progressive creationism, which envisaged species being supernaturally created at intervals, Darwin needed to forcefully stress the gradual nature of evolution in accordance with the gradualism promoted by his friend Charles Lyell. He privately expressed concern, noting in the margin of his 1844 "Essay", "Better begin with this: If species really, after catastrophes, created in showers world over, my theory false."
It is often incorrectly assumed that he insisted that the rate of change must be constant, or nearly so, but even the first edition of "On the Origin of Species" states that "Species of different genera and classes have not changed at the same rate, or in the same degree. In the oldest tertiary beds a few living shells may still be found in the midst of a multitude of extinct forms... The Silurian "Lingula" differs but little from the living species of this genus". "Lingula" is among the few brachiopods surviving today but also known from fossils over 500 million years old. In the fourth edition (1866) of "On the Origin of Species" Darwin wrote that "the periods during which species have undergone modification, though long as measured in years, have probably been short in comparison with the periods during which they retain the same form." Thus punctuationism in general is consistent with Darwin's conception of evolution.
According to early versions of punctuated equilibrium, "peripheral isolates" are considered to be of critical importance for speciation. However, Darwin wrote, ""I can by no means agree" ... that immigration and isolation are necessary elements... Although isolation is of great importance in the production of new species, on the whole I am inclined to believe that largeness of area is still more important, especially for the production of species which shall prove capable of enduring for a long period, and of spreading widely."
The importance of isolation in forming species had played a significant part in Darwin's early thinking, as shown in his "Essay" of 1844. But by the time he wrote the "Origin" he had downplayed its importance. He explained the reasons for his revised view as follows:
Throughout a great and open area, not only will there be a greater chance of favourable variations, arising from the large number of individuals of the same species there supported, but the conditions of life are much more complex from the large number of already existing species; and if some of these species become modified and improved, others will have to be improved in a corresponding degree, or they will be exterminated. Each new form, also, as soon as it has been improved, will be able to spread over the open and continuous area, and will thus come into competition with many other forms ... the new forms produced on large areas, which have already been victorious over many competitors, will be those that will spread most widely, and will give rise to the greatest number of new varieties and species. They will thus play a more important role in the changing history of the organic world.
Thus punctuated equilibrium contradicts some of Darwin's ideas regarding the specific mechanisms of evolution, but generally accords with Darwin's theory of evolution by natural selection.
Supplemental modes of rapid evolution.
Recent work in developmental biology has identified dynamical and physical mechanisms of tissue morphogenesis that may underlie abrupt morphological transitions during evolution. Consequently, consideration of mechanisms of phylogenetic change that have been found in reality to be non-gradual is increasingly common in the field of evolutionary developmental biology, particularly in studies of the origin of morphological novelty. A description of such mechanisms can be found in the multi-authored volume "Origination of Organismal Form" (MIT Press; 2003).
Language change.
In linguistics, R. M. W. Dixon has proposed a punctuated equilibrium model for language histories, with reference particularly to the prehistory of the indigenous languages of Australia and his objections to the proposed Pama–Nyungan language family there. Although his model has raised considerable interest, it does not command majority support within linguistics. 
Separately, recent work using computational phylogenetic methods claims to show that punctuational bursts play an important factor when languages split from one another, accounting for anywhere from 10 to 33% of the total divergence in vocabulary. Note that punctuational bursts also occurs in mythology in even greater proportions.

</doc>
