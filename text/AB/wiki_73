<doc id="22645" url="http://en.wikipedia.org/wiki?curid=22645" title="Orkney">
Orkney

Orkney (Scottish Gaelic: "Arcaibh"), also known as the Orkney Islands, is an archipelago in northern Scotland, 16 kilometres (10 mi) north of the coast of Caithness. Orkney comprises approximately 70 islands, of which 20 are inhabited.
The largest island, Mainland, often referred to as "the Mainland", has an area of 523.25 square kilometres (202 sq mi), making it the sixth largest Scottish island and the tenth-largest island in the British Isles. The largest settlement and administrative centre is Kirkwall.
The name "Orkney" dates back to the 1st century BC or earlier, and the islands have been inhabited for at least 8,500 years. Originally occupied by Mesolithic and Neolithic tribes and then by the Picts, Orkney was invaded and forcibly annexed by Norway in 875 and settled by the Norse. The Scottish Parliament then re-annexed the earldom to the Scottish Crown in 1472, following the failed payment of a dowry for James III's bride, Margaret of Denmark. Orkney contains some of the oldest and best-preserved Neolithic sites in Europe, and the "Heart of Neolithic Orkney" is a designated UNESCO World Heritage Site.
Orkney is one of the 32 council areas of Scotland, a constituency of the Scottish Parliament, a lieutenancy area, and a former county. The local council is Orkney Islands Council, one of only three Councils in Scotland with a majority of elected members who are independents.
In addition to the Mainland, most of the islands are in two groups, the North and South Isles, all of which have an underlying geological base of Old Red Sandstone. The climate is mild and the soils are extremely fertile, most of the land being farmed. Agriculture is the most important sector of the economy and the significant wind and marine energy resources are of growing importance. The local people are known as Orcadians and have a distinctive Scots dialect and a rich inheritance of folklore. There is an abundance of marine and avian wildlife.
Origin of the name.
Pytheas of Massilia visited Britain – probably sometime between 322 and 285 BC – and described it as triangular in shape, with a northern tip called "Orcas".
This may have referred to Dunnet Head, from which Orkney is visible. Writing in the 1st century AD, the Roman geographer Pomponius Mela called the islands "Orcades", as did Tacitus in AD 98, claiming that his father-in-law Agricola had "discovered and subjugated the Orcades hitherto unknown" (although both Mela and Pliny had previously referred to the islands.)
Etymologists usually interpret the element "orc-" as a Pictish tribal name meaning "young pig" or "young boar".
Speakers of Old Irish referred to the islands as "Insi Orc" ("island of the pigs").
The archipelago is known as "Arcaibh" in modern Scottish Gaelic, the "-aibh" representing a fossilized prepositional case ending.
Norwegian settlers arriving from the late 9th century re-interpreted "orc" as Old Norse "orkn" "seal", with the added suffix "ey" "island". Thus the name became "Orkneyjar" (meaning "seal islands"), later shortened to "Orkney" in English. According to the "Historia Norvegiæ", Orkney was named after an earl called Orkan.
The Norse knew Mainland Orkney as "Megenland" (mainland) or as "Hrossey" (horse island). The island is sometimes referred to as "Pomona" (or "Pomonia"), a name that stems from a sixteenth-century mis-translation by George Buchanan and has rarely been used locally.
History.
Prehistory.
A charred hazelnut shell, recovered in 2007 during excavations in Tankerness on the Mainland has been dated to 6820–6660 BC indicating the presence of Mesolithic nomadic tribes. The earliest known permanent settlement is at Knap of Howar, a Neolithic farmstead on the island of Papa Westray, which dates from 3500 BC. The village of Skara Brae, Europe's best-preserved Neolithic settlement, is believed to have been inhabited from around 3100 BC. Other remains from that era include the Standing Stones of Stenness, the Maeshowe passage grave, the Ring of Brodgar and other standing stones. Many of the Neolithic settlements were abandoned around 2500 BC, possibly due to changes in the climate.
During the Bronze Age fewer large stone structures were built although the great ceremonial circles continued in use as metalworking was slowly introduced to Scotland from Europe over a lengthy period. There are relatively few Orcadian sites dating from this era although there is the impressive Plumcake Mound near the Ring of Brodgar and various islands sites such as Tofts Ness on Sanday and the remains of two houses on Holm of Faray.
Iron Age.
Excavations at Quanterness on the Mainland have revealed an Atlantic roundhouse built about 700 BC and similar finds have been made at Bu on the Mainland and Pierowall Quarry on Westray. The most impressive Iron Age structures of Orkney are the ruins of later round towers called "brochs" and their associated settlements such as the Broch of Burroughston and Broch of Gurness. The nature and origin of these buildings is a subject of ongoing debate. Other structures from this period include underground storehouses, and aisled roundhouses, the latter usually in association with earlier broch sites.
During the Roman invasion of Britain the "King of Orkney" was one of 11 British leaders who is said to have submitted to the Emperor Claudius in AD 43 at Colchester. After the Agricolan fleet had come and gone, possibly anchoring at Shapinsay, direct Roman influence seems to have been limited to trade rather than conquest.
By the late Iron Age, Orkney was part of the Pictish kingdom, and although the archaeological remains from this period are less impressive there is every reason to suppose the fertile soils and rich seas of Orkney provided the Picts with a comfortable living. The Dalriadic Gaels began to influence the islands towards the close of the Pictish era, perhaps principally through the role of Celtic missionaries, as evidenced by several islands bearing the epithet "Papa" in commemoration of these preachers. However, before the Gaelic presence could establish itself the Picts were gradually dispossessed by the Norsemen from the late 8th century onwards. The nature of this transition is controversial, and theories range from peaceful integration to enslavement and genocide.
Norwegian rule.
Both Orkney and Shetland saw a significant influx of Norwegian settlers during the late 8th and early 9th centuries. Vikings made the islands the headquarters of their pirate expeditions carried out against Norway and the coasts of mainland Scotland. In response, Norwegian king Harald Hårfagre ("Harald Fair Hair") annexed the Northern Isles, comprising Orkney and Shetland, in 875. (It is clear that this story, which appears in the "Orkneyinga Saga", is based on the later voyages of Magnus Barelegs and some scholars believe it to be apocryphal.) Rognvald Eysteinsson received Orkney and Shetland from Harald as an earldom as reparation for the death of his son in battle in Scotland, and then passed the earldom on to his brother Sigurd the Mighty.
However, Sigurd's line barely survived him and it was Torf-Einarr, Rognvald's son by a slave, who founded a dynasty that controlled the islands for centuries after his death. He was succeeded by his son Thorfinn Skull-splitter and during this time the deposed Norwegian King Eric Bloodaxe often used Orkney as a raiding base before being killed in 954. Thorfinn's death and presumed burial at the broch of Hoxa, on South Ronaldsay, led to a long period of dynastic strife.
Initially a pagan culture, detailed information about the return of the Christian religion to the islands of Scotland during the Norse-era is elusive. The "Orkneyinga Saga" suggests the islands were Christianised by Olav Tryggvasson in 995 when he stopped at South Walls on his way from Ireland to Norway. The King summoned the "jarl" Sigurd the Stout and said, "I order you and all your subjects to be baptised. If you refuse, I'll have you killed on the spot and I swear I will ravage every island with fire and steel." Unsurprisingly, Sigurd agreed and the islands became Christian at a stroke, receiving their own bishop in the early 11th century.
Thorfinn the Mighty was a son of Sigurd and a grandson of King Máel Coluim mac Cináeda (Malcolm II of Scotland). Along with Sigurd's other sons he ruled Orkney during the first half of the 11th century and extended his authority over a small maritime empire stretching from Dublin to Shetland. Thorfinn died around 1065 and his sons Paul and Erlend succeeded him, fighting at the Battle of Stamford Bridge in 1066. Paul and Erlend quarreled as adults and this dispute carried on to the next generation. The martyrdom of Magnus Erlendsson, who was killed in April 1116 by his cousin Haakon Paulsson, resulted in the building of St. Magnus Cathedral, still today a dominating feature of Kirkwall.
Unusually, from c. 1100 onwards the Norse "jarls" owed allegiance both to Norway for Orkney and to the Scottish crown through their holdings as Earls of Caithness. In 1231 the line of Norse earls, unbroken since Rognvald, ended with Jon Haraldsson's murder in Thurso. The Earldom of Caithness was granted to Magnus, second son of the Earl of Angus, whom Haakon IV of Norway confirmed as Earl of Orkney in 1236. In 1290, the death of the child princess Margaret, Maid of Norway in Orkney, en route to mainland Scotland, created a disputed succession that led to the Wars of Scottish Independence. In 1379 the earldom passed to the Sinclair family, who were also barons of Roslin near Edinburgh.
Evidence of the Viking presence is widespread, and includes the settlement at the Brough of Birsay, the vast majority of place names, and the runic inscriptions at Maeshowe.
Scottish rule.
In 1468 Orkney was pledged by Christian I, in his capacity as king of Norway, as security against the payment of the dowry of his daughter Margaret, betrothed to James III of Scotland. As the money was never paid, the connection with the crown of Scotland has become perpetual.
The history of Orkney prior to this time is largely the history of the ruling aristocracy. From now on the ordinary people emerge with greater clarity. An influx of Scottish entrepreneurs helped to create a diverse and independent community that included farmers, fishermen and merchants that called themselves "comunitas Orcadie" and who proved themselves increasingly able to defend their rights against their feudal overlords.
From at least the 16th century, boats from mainland Scotland and the Netherlands dominated the local herring fishery. There is little evidence of an Orcadian fleet until the 19th century but it grew rapidly and 700 boats were involved by the 1840s with Stronsay and then later Stromness becoming leading centres of development. White fish never became as dominant as in other Scottish ports.
In the 17th century, Orcadians formed the overwhelming majority of employees of the Hudson's Bay Company in Canada. The harsh climate of Orkney and the Orcadian reputation for sobriety and their boat handling skills made them ideal candidates for the rigours of the Canadian north. During this period, burning kelp briefly became a mainstay of the islands' economy. For example on Shapinsay over 3000 LT of burned seaweed were produced per annum to make soda ash, bringing in £20,000 to the local economy. The industry collapsed suddenly in 1830 after the removal of tariffs on imported alkali.
Agricultural improvements beginning in the 17th century resulted in the enclosure of the commons and ultimately in the Victoria era the emergence of large and well-managed farms using a five-shift rotation system and producing high quality beef cattle.
In the 18th century Jacobite Risings Orkney was largely Jacobite in its sympathies. At the end of the 1715 rebellion, a large number of Jacobites who had fled north from mainland Scotland sought refuge on Orkney and were helped on to safety in Sweden. In 1745, the Jacobite lairds on the islands ensured that Orkney remained pro-Jacobite in outlook, and was a safe place to land supplies from Spain to aid their cause. Orkney was the last place in the British Isles that held out for the Jacobites and was not retaken by the British Government until 24 May 1746, over a month after the defeat of the main Jacobite army at Culloden.
20th century.
Orkney was the site of a Royal Navy base at Scapa Flow, which played a major role in World War I and II. After the Armistice in 1918, the German High Seas Fleet was transferred in its entirety to Scapa Flow to await a decision on its future. The German sailors opened the sea-cocks and scuttled all the ships. Most ships were salvaged, but the remaining wrecks are now a favoured haunt of recreational divers. One month into World War II, a German U-boat sank the Royal Navy battleship HMS "Royal Oak" in Scapa Flow. As a result, barriers were built to close most of the access channels; these had the additional advantage of creating causeways enabling travellers to go from island to island by road instead of being obliged to rely on ferries. The causeways were constructed by Italian prisoners of war, who also constructed the ornate Italian Chapel.
During World War II, the politicians of German-occupied Norway asked German authorities to take over Orkney as Norway sought new opportunities for expansion.
The navy base became run down after the war, eventually closing in 1957. The problem of a declining population was significant in the post-war years, though in the last decades of the 20th century there was a recovery and life in Orkney focused on growing prosperity and the emergence of a relatively classless society. Orkney was rated as the best place to live in Scotland in both 2013 and 2014 according to the Halifax Quality of Life survey.
Overview of population trends.
In the modern era, population peaked in the mid 19th century at just over 26,000 and declined for a century thereafter to a low of fewer than 17,000 in the 1970s. Declines were particularly significant in the outlying islands, some of which remain vulnerable to ongoing losses. Although Orkney is in many ways very distinct from the other islands and archipelagos of Scotland these trends are very similar to those experienced elsewhere. The archipelago's population grew by 11% in the decade to 2011 as recorded by the census. During the same period Scottish island populations as a whole grew by 4% to 103,702.
Geography.
Orkney is separated from the mainland of Scotland by the Pentland Firth, a 10 km wide seaway between Brough Ness on the island of South Ronaldsay and Duncansby Head in Caithness. Orkney lies between 58°41′ and 59°24′ North, and 2°22′ and 3°26′ West, measuring 80 km from northeast to southwest and 47 km from east to west, and covers 975 km2.
The islands are mainly low-lying except for some sharply rising sandstone hills on Hoy, Mainland and Rousay and rugged cliffs on some western coasts. Nearly all of the islands have lochs, but the watercourses are merely streams draining the high land. The coastlines are indented, and the islands themselves are divided from each other by straits generally called "sounds" or "firths".
The tidal currents, or "roosts" as some of them are called locally, off many of the isles are swift, with frequent whirlpools. The islands are notable for the absence of trees, which is partly accounted for by the amount of wind.
Islands.
The Mainland.
The Mainland is the largest island of Orkney. Both of Orkney's burghs, Kirkwall and Stromness, are on this island, which is also the heart of Orkney's transportation system, with ferry and air connections to the other islands and to the outside world. The island is more densely populated (75% of Orkney's population) than the other islands and has much fertile farmland. The Mainland is split into areas called East and West Mainland. These areas are determined by whether they lie East or West of Kirkwall. The bulk of the mainland lies West of Kirkwall, with comparatively little land lying East of Kirkwall.
West Mainland parishes are:
Stromness, Sandwick, Birsay, Harray, Stenness, Orphir, Evie, Rendall and Firth.
East Mainland Parishes are:
St Ola, Tankerness, St Andrews, Holm and Deerness.
The island is mostly low-lying (especially East Mainland) but with coastal cliffs to the north and west and two sizeable lochs: the Loch of Harray and the Loch of Stenness. The Mainland contains the remnants of numerous Neolithic, Pictish and Viking constructions. Four of the main Neolithic sites are included in the Heart of Neolithic Orkney World Heritage Site, inscribed in 1999.
The other islands in the group are classified as north or south of the Mainland. Exceptions are the remote islets of Sule Skerry and Sule Stack, which lie 60 km west of the archipelago, but form part of Orkney for local government purposes. In island names, the suffix "a" or "ay" represents the Norse "ey", meaning "island". Those described as "holms" are very small.
The North Isles.
The northern group of islands is the most extensive and consists of a large number of moderately sized islands, linked to the Mainland by ferries and by air services. Farming, fishing and tourism are the main sources of income for most of the islands.
The most northerly is North Ronaldsay, which lies 4 km beyond its nearest neighbour, Sanday. To the west is Westray has a population of 550. It is connected by ferry and air to Papa Westray, also known as "Papay". Eday is at the centre of the North Isles. The centre of the island is moorland and the island's main industries have been peat extraction and limestone quarrying.
Rousay, Egilsay and Gairsay lie north of the west Mainland across the Eynhallow Sound. Rousay is well known for its ancient monuments, including the Quoyness chambered cairn and Egilsay has the ruins of the only round-towered church in Orkney. Wyre to the south east contains the site of Cubbie Roo's castle. Stronsay and Papa Stronsay lie much further to the east across the Stronsay Firth. Auskerry is south of Stronsay and has a population of only five. Shapinsay and its Balfour Castle are a short distance north of Kirkwall.
Other small uninhabited islands in the North Isles group include: Calf of Eday, Damsay, Eynhallow, Faray, Helliar Holm, Holm of Faray, Holm of Huip, Holm of Papa, Holm of Scockness, Kili Holm, Linga Holm, Muckle Green Holm, Rusk Holm and Sweyn Holm.
The South Isles.
The southern group of islands surrounds Scapa Flow. Hoy is the second largest of the Orkney Isles and Ward Hill at its northern end is the highest elevation in the archipelago. The Old Man of Hoy is a well-known seastack. Burray lies to the east of Scapa Flow and is linked by causeway to South Ronaldsay, which hosts the cultural events, the Festival of the Horse and the Boys' Ploughing Match on the third Saturday in August. It is also the location of the Neolithic Tomb of the Eagles. Graemsay and Flotta are both linked by ferry to the Mainland and Hoy, and the latter is known for its large oil terminal. South Walls has a 19th-century Martello tower and is connected to Hoy by the Ayre. South Ronaldsay, Burray, Glims Holm, and Lamb Holm are connected by road to the Mainland by the Churchill Barriers.
Uninhabited South Islands include: Calf of Flotta, Cava, Copinsay, Corn Holm, Fara, Glims Holm, Hunda, Lamb Holm, Rysa Little, Switha and Swona. The Pentland Skerries lie further south, closer to the Scottish mainland.
Geology.
The superficial rock of Orkney is almost entirely Old Red Sandstone, mostly of Middle Devonian age. As in the neighbouring mainland county of Caithness, this sandstone rests upon the metamorphic rocks of the Moine series, as may be seen on the Mainland, where a narrow strip is exposed between Stromness and Inganess, and again in the small island of Graemsay; they are represented by grey gneiss and granite.
The Middle Devonian is divided into three main groups. The lower part of the sequence, mostly Eifelian in age, is dominated by lacustrine beds of the lower and upper Stromness Flagstones that were deposited in Lake Orcadie. The later Rousay flagstone formation is found throughout much of the North and South Isles and East Mainland.
The Old Man of Hoy is formed from sandstone of the uppermost Eday group that is up to 800 m thick in places. It lies unconformably upon steeply inclined flagstones, the interpretation of which is a matter of continuing debate.
The Devonian and older rocks of Orkney are cut by a series of WSW-ENE to N-S trending faults, many of which were active during deposition of the Devonian sequences. A strong synclinal fold traverses Eday and Shapinsay, the axis trending north-south.
Middle Devonian basaltic volcanic rocks are found on western Hoy, on Deerness in eastern Mainland and on Shapinsay. Correlation between the Hoy volcanics and the other two exposures has been proposed, but differences in chemistry means this remains uncertain. Lamprophyre dykes of Late Permian age are found throughout Orkney.
Glacial striation and the presence of chalk and flint erratics that originated from the bed of the North Sea demonstrate the influence of ice action on the geomorphology of the islands. Boulder clay is also abundant and moraines cover substantial areas.
Climate.
Orkney has a cool temperate climate that is remarkably mild and steady for such a northerly latitude, due to the influence of the Gulf Stream. The average temperature for the year is 8 °C; for winter 4 °C and for summer 12 °C.
The average annual rainfall varies from 850 mm to 940 mm. Winds are a key feature of the climate and even in summer there are almost constant breezes. In winter, there are frequent strong winds, with an average of 52 hours of gales being recorded annually.
To tourists, one of the fascinations of the islands is their "nightless" summers. On the longest day, the sun rises at 03:00 and sets at 21:29 GMT and complete darkness is unknown. This long twilight is known in the Northern Isles as the "simmer dim". Winter nights are long. On the shortest day the sun rises at 09:05 and sets at 15:16. At this time of year the aurora borealis can occasionally be seen on the northern horizon during moderate auroral activity.
Politics.
Orkney is represented in the House of Commons as part of the Orkney and Shetland constituency, which elects one Member of Parliament (MP), the current incumbent being Alistair Carmichael. This seat has been held by the Liberal Democrats or their predecessors the Liberal Party since 1950, longer than any other they represent in Great Britain.
In the Scottish Parliament the Orkney constituency elects one Member of the Scottish Parliament (MSP) by the first past the post system. The current MSP is Liam McArthur of the Liberal Democrats. Before McArthur the MSP was Jim Wallace, who was previously Deputy First Minister. Orkney is within the Highlands and Islands electoral region.
Orkney Islands Council consists of 21 members, all of whom are independent, that is they do not stand as representatives of a political party.
The Orkney Movement, a political party that supported devolution for Orkney from the rest of Scotland, contested the 1987 general election as the Orkney and Shetland Movement (a coalition of the Orkney movement and its equivalent for Shetland). The Scottish National Party chose not to contest the seat to give the movement a "free run". Their candidate, John Goodlad, came 4th with 3,095 votes, 14.5% of those cast, but the experiment has not been repeated.
In the 2014 Scottish independence referendum 67.2% of voters in Orkney voted No to the question "Should Scotland be an independent country?" This was the highest % No vote in any council area in Scotland. Turnout for the referendum was at 83.7% in Orkney with 10,004 votes cast in the area against independence by comparison to 4,883 votes for independence.
Economy.
The soil of Orkney is generally very fertile and most of the land is taken up by farms, agriculture being by far the most important sector of the economy and providing employment for a quarter of the workforce. More than 90% of agricultural land is used for grazing for sheep and cattle, with cereal production utilising about 4% (4200 ha) and woodland occupying only 134 ha.
Fishing has declined in importance, but still employed 345 individuals in 2001, about 3.5% of the islands' economically active population, the modern industry concentrating on herring, white fish, lobsters, crabs and other shellfish, and salmon fish farming.
Today, the traditional sectors of the economy export beef, cheese, whisky, beer, fish and other seafood. In recent years there has been growth in other areas including tourism, food and beverage manufacture, jewellery, knitwear, and other crafts production, construction and oil transportation through the Flotta oil terminal. Retailing accounts for 17.5% of total employment, and public services also play a significant role, employing a third of the islands' workforce.
In 2007, of the 1,420 VAT registered enterprises 55% were in agriculture, forestry and fishing, 12% in manufacturing and construction, 12% in wholesale, retail and repairs, and 5% in hotels and restaurants. A further 5% were public service related. 55% of these businesses employ between 5 and 49 people.
Orkney has significant wind and marine energy resources, and renewable energy has recently come into prominence. The European Marine Energy Centre (EMEC) is a Scottish Government-backed research facility that has installed a wave testing system at Billia Croo on the Orkney Mainland and a tidal power testing station on the island of Eday. At the official opening of the Eday project the site was described as "the first of its kind in the world set up to provide developers of wave and tidal energy devices with a purpose-built performance testing facility." Funding for the UK's first wave farm was announced by the Scottish Government in 2007. It will be the world's largest, with a capacity of 3 MW generated by four Pelamis machines at a cost of over £4 million. During 2007 Scottish and Southern Energy plc in conjunction with the University of Strathclyde began the implementation of a Regional Power Zone in the Orkney archipelago. This scheme (that may be the first of its kind in the world) involves "active network management" that will make better use of existing infrastructure and allow a further 15MW of new "non-firm generation" output from renewables onto the network.
Transport.
Air.
Highland and Islands Airports operates the main airport in Orkney, Kirkwall Airport. Loganair, a franchise of Flybe, provides services to the Scottish mainland (Aberdeen, Edinburgh, Glasgow-International and Inverness), as well as to Sumburgh Airport in Shetland.
Within Orkney, the council operates airfields on most of the larger islands including Stronsay, Eday, North Ronaldsay, Westray, Papa Westray, and Sanday. Reputedly the shortest scheduled air service in the world, between the islands of Westray and Papa Westray, is scheduled at two minutes duration but can take less than one minute if the wind is in the right direction.
Ferry.
Ferries serve both to link Orkney to the rest of Scotland, and also to link together the various islands of the Orkney archipelago. Ferry services operate between Orkney and the Scottish mainland and Shetland on the following routes:
Inter-island ferry services connect all the inhabited islands to Orkney Mainland, and are operated by Orkney Ferries, a company owned by Orkney Islands Council.
Media.
Orkney is served by a weekly local newspaper, The Orcadian.
A local BBC radio station, BBC Radio Orkney, the local opt-out of BBC Radio Scotland, broadcasts twice daily, with local news and entertainment. Orkney also had a commercial radio station, The Superstation Orkney, which broadcast to Kirkwall and parts of the mainland and also to most of Caithness until its closure on November 2014. Moray Firth Radio broadcasts throughout Orkney on AM and from an FM transmitter just outside Thurso. The community radio station Caithness FM also broadcasts to Orkney.
Language, literature and folklore.
At the beginning of recorded history the islands were inhabited by the Picts, whose language was Brythonic. The Ogham script on the Buckquoy spindle-whorl is cited as evidence for the pre-Norse existence of Old Irish in Orkney.
After the Norse occupation the toponymy of Orkney became almost wholly West Norse. The Norse language evolved into the local Norn, which lingered until the end of the 18th century, when it finally died out. Norn was replaced by the Orcadian dialect of Insular Scots. This dialect is at a low ebb due to the pervasive influences of television, education and the large number of incomers. However, attempts are being made by some writers and radio presenters to revitalise its use and the distinctive sing-song accent and many dialect words of Norse origin remain in use. The Orcadian word most frequently encountered by visitors is "peedie", meaning "small", which may derive from the French "petit".
Orkney has a rich folklore and many of the former tales concern trows, an Orcadian form of troll that draws on the islands' Scandinavian connections. Local customs in the past included marriage ceremonies at the Odin Stone that formed part of the Stones of Stenness.
The best known literary figures from modern Orkney are the poet Edwin Muir, the poet and novelist George Mackay Brown and the novelist Eric Linklater.
Orcadians.
An Orcadian is a native of Orkney, a term that reflects a strongly held identity with a tradition of understatement. Although the annexation of the earldom by Scotland took place over five centuries ago in 1472, most Orcadians regard themselves as Orcadians first and Scots second.
When an Orcadian speaks of "Scotland", they are talking about the land to the immediate south of the Pentland Firth. When an Orcadian speaks of "the mainland", they mean Mainland, Orkney. Tartan, clans, bagpipes and the like are traditions of the Scottish Highlands and are not a part of the islands' indigenous culture. However, at least two tartans with Orkney connections have been registered and a tartan has been designed for Sanday by one of the island's residents, and there are pipe bands in Orkney.
Native Orcadians refer to the non-native residents of the islands as "ferry loupers", a term that has been in use for nearly two centuries at least.
Natural history.
Orkney has an abundance of wildlife, especially of grey and common seals and seabirds such as puffins, kittiwakes, tysties, ravens, and bonxies. Whales, dolphins, otters are also seen around the coasts. Inland the Orkney vole, a distinct subspecies of the common vole, is an endemic. There are five distinct varieties, found on the islands of Sanday, Westray, Rousay, South Ronaldsay, and the Mainland, all the more remarkable as the species is absent on mainland Britain.
The coastline is well known for its colourful flowers including sea aster, sea squill, sea thrift, common sea-lavender, bell and common heather. The Scottish primrose is found only on the coasts of Orkney and nearby Caithness and Sutherland. Although stands of trees are generally rare, a small forest named Happy Valley with 700 trees and lush gardens was created from a boggy hillside near Stenness during the second half of the 20th century.
The North Ronaldsay sheep is an unusual breed of domesticated animal, subsisting largely on a diet of seaweed, since they are confined to the foreshore for most of the year to conserve the limited grazing inland. The island was also a habitat for the Atlantic walrus until the mid-16th century.
The Orkney char ("Salvelinus inframundus") used to live in Heldale Water on Hoy. It has been considered locally extinct since 1908.
References.
General references.
</dl>
Further reading.
</dl>

</doc>
<doc id="22647" url="http://en.wikipedia.org/wiki?curid=22647" title="Hoy">
Hoy

Hoy (from Norse "Háey" meaning high island) is an island in Orkney, Scotland. With an area of 143 km2 it is the second largest in the archipelago after the Mainland. It is connected by a causeway called The Ayre to South Walls. Unusually, the two islands are treated as one entity by the UK census.
Description.
The dramatic coastline of Hoy greets visitors travelling to Orkney by ferry from the Scottish mainland. It has extremes of many kinds: some of the highest sea cliffs in the UK at St John's Head, which reach 350 m; the impressive and famous sea stack, the Old Man of Hoy; some of the most northerly surviving natural woodland in the British Isles and the remote possibility that the Orkney charr ("Salvelinus inframundus"), last described in 1908, survive in Heldale Water. The most northerly Martello Towers were built to defend the area during the Napoleonic War, but were never used in combat.
The highest point in Orkney, Ward Hill, is on Hoy.
The main naval base for the British fleet Scapa Flow in both the First and Second World Wars was situated at Lyness in the south-east of the island. Some rather incongruous Art Deco structures nearby date from this period.
An unusual rock-cut tomb, the Dwarfie Stane, lies in the Rackwick valley in the north of the island. It is unique in northern Europe, bearing similarity to Neolithic or Bronze Age tombs around the Mediterranean. The tomb gets its name as it is very small and was said to be carved by dwarfs.
In Norse mythology, Hoy is the location of the never-ending battle between Hedin and Högni.
Orkney Ferries serve the island with two routes, one of which links Lyness on Hoy and Longhope on Walls with the island of Flotta and Houton on the Orkney Mainland. The other route links Moaness in Hoy to the island of Graemsay and Stromness on Orkney Mainland.
Hoy is part of the Hoy and West Mainland National Scenic Area, one of 40 in Scotland.
Wildlife.
Hoy is an Important Bird Area.
The northern part of the island is an RSPB reserve due to its importance for birdlife, particularly Great skuas and red-throated divers. It was sold to the RSPB by the Hoy Trust for a minimal amount.
Anastrepta orcadensis, a liverwort also known as Orkney Notchwort, was first discovered on Ward Hill by William Jackson Hooker in 1808.
In popular culture.
Hoy is featured prominently in the 1984 video for "Here Comes The Rain Again" by Eurythmics.

</doc>
<doc id="22648" url="http://en.wikipedia.org/wiki?curid=22648" title="Rousay">
Rousay

Rousay (Old Norse: "Hrólfsey" meaning Rolf's Island) is a small, hilly island about 3 km north of Orkney's Mainland, off the north coast of Scotland, and has been nicknamed "the Egypt of the north", due to its archaeological diversity and importance.
It is separated from mainland Orkney by the Eynhallow Sound, and, like its neighbours Egilsay and Wyre, can be reached by ro-ro ferry from Tingwall, on the mainland of Orkney, which takes 20–25 minutes. This service is operated by Orkney Ferries, and can take up to 95 passengers (reduced to 50 in winter), and 10 cars. The ferry links the islands of Rousay, Egilsay, and Wyre with each other, and with the mainland of Orkney.
Geography and natural history.
In the 2001 census, Rousay had a population of 212 people. Most employment opportunities are in farming, fishing or fish-farming; there are also craft businesses and some seasonal tourism-related work. There is one circular road round the island, about 23 km long, and most arable land lies in the few hundred yards between this and the coastline. With an area of 4860 ha, it is the fifth largest of the Orkney Islands.
There are several freshwater lochs on the island, the biggest of which is Muckle Water.
Rousay is a 'Site of Special Scientific Interest' with notable cliff formations and wildflower colonies, and has an RSPB bird reserve. The hilliest Orkney island after Hoy, it offers good views of neighbouring islands from Blotchnifiold 249 m, and Keirfea or Knitchen (both over 229 m).
Summertime brings visitors drawn by its natural beauty and wildlife, including Rousay's seals and otters, and by its archaeological remains, especially the cluster of important sites connected by a footpath near the western shore.
History.
The island has evidence from every stage in the history of Orkney, with a Neolithic settlement at Rinyo, Bronze Age burnt mounds, Iron Age crannogs and brochs (the highest density anywhere in Scotland: three within 500 m of coastline), Viking boat burials, remains of a medieval church and the stately home at Trumland.
Over 100 archaeological sites have been identified, but only a small fraction of them have been excavated and researched. The best known and most spectacular of the island's archaeological sites is the complex of Midhowe Broch and Midhowe Chambered Cairn. Blackhammer Chambered Cairn, Taversoe Tuick, and Yarso are also important tombs on the island.
Rousay placenames reflect its Norse heritage. 'Hrólfs-øy' or 'Hrolfsey' was based on the male name 'Hrolf' (Rolf). Hugh Marwick's work has shown the name developing from 'Rollesay' in the 14th century, through 'Rolsay' in the 15th, and 'Rowsay' in the early 16th, with the spelling 'Rousay' first recorded in 1549.
Most Rousay people have always earned their living from farming and/or fishing. In the 19th century, records show there were also tradespeople supplying the needs of a rural community: blacksmiths and joiners, shoemakers and shopkeepers, with women doing dressmaking and straw plaiting. Throughout the century, Rousay's landlords demanded high rents from crofters, many of whom were made homeless in a series of clearances along the western coast, ordered by landowner George William Traill in the 1820s and 1830s.
Traill's nephew General Sir Frederick Traill-Burroughs inherited much of the island and bought more. Traill-Burroughs built a large house at Trumland, designed by David Bryce of Edinburgh. From 1870-1883, there were a large number of improvements; the building of Trumland pier, island schools, a public market, the first steamship service, a post office, and the first resident doctor. He was known locally as 'the little general' as he was a man of short stature and the poet Edwin Muir recalled in a memoir of his childhood seeing the little general walking around his estates.
Rousay's population in the mid-19th century was over 900, but emigration following land clearances reduced that to 627 by 1900, and half a century later it had fallen to 342. Depopulation accelerated, and in the next twenty years the number fell to 181, its lowest ever. From the 1970s onward new families started to settle on Rousay: most came from the south, especially from England. The population is now over 200.
The Yetnasteen stone is said to have once been a giant who revives every New Year at midnight and goes down to the Loch of Scockness to drink.
Local education.
There is a primary school, which provides education for boys and girls aged 3 to 12, and has a school roll of 24. Once a child completes his/her primary education, they must then move up to secondary school. Kirkwall Grammar School, Kirkwall, is the usual school, however, in recent years, Stromness Academy, Stromness, has been the secondary school of choice for many of the pupils.
Many of the pupils, both primary and secondary, are entitled to free school transport on the island.
Residents.
The poet Pauline Stainer spent several years on the island, and in 1999 published a collection of her poems about Rousay, "Parable Island".
Robert C. Marwick is a local author whose publications include "From My Rousay Schoolbag"; "Rousay Roots" (1995); "In Dreams We Moor" (2000) ISBN 1-899851-04-6. Marwick was born on the farm of Innister, in the Wasbister district of Rousay.
The astronomer, musician and writer, John Vetterlein first came to Rousay in 1970 and has lived on the island full-time since 1995. He established the small publishing house Spring Ast LIX in 1997, whose publications include: "Braes Woodland Diary - the First Ten Years" by Ann Chapman.
The actor Graham Fellows owns a disused church on the Orkney island, which he intends to turn into an "artists refuge".
The late artist Margaret Gardiner spent a large part of her life on Rousay and founded, in 1979 the Pier Art Gallery in Stromness.

</doc>
<doc id="22649" url="http://en.wikipedia.org/wiki?curid=22649" title="Observation">
Observation

Observation is the active acquisition of information from a primary source. In living beings, observation employs the senses. In science, observation can also involve the recording of data via the use of instruments. The term may also refer to any data collected during the scientific activity.
Observation in science.
The scientific method requires observations of nature to formulate and test hypotheses. It consists of these steps:
Observations play a role in the second and fifth steps of the scientific method. However the need for reproducibility requires that observations by different observers can be comparable. Human sense impressions are subjective and qualitative making them difficult to record or compare. Theed or shared by all observers, and counting how many of the standard units are comparable to the object. Measurement reduces an observation to a number which can be recorded, and two observations which result in the same number are equal within the resolution of the process.
Senses are limited, and are subject to errors in perception such as optical illusions. Scientific instruments were developed to magnify human powers of observation, such as weighing scales, clocks, telescopes, microscopes, thermometers, cameras, and tape recorders, and also translate into perceptible form events that are unobservable by human senses, such as indicator dyes, voltmeters, spectrometers, infrared cameras, oscilloscopes, interferometers, geiger counters, x-ray machines, and radio receivers.
One problem encountered throughout scientific fields is that the observation may affect the process being observed, resulting in a different outcome than if the process was unobserved. This is called the "observer effect". For example, it is not normally possible to check the air pressure in an automobile tire without letting out some of the air, thereby changing the pressure. However, in most fields of science it is possible to reduce the effects of observation to insignificance by using better instruments.
Considered as a physical process itself, all forms of observation (human or instrumental) involve amplification and are thus thermodynamically irreversible processes, increasing entropy.
Observational paradoxes.
In some specific fields of science the results of observation differ depending on factors which are not important in everyday observation. These are usually illustrated with "paradoxes" in which an event appears different when observed from two different points of view, seeming to violate "common sense".
Biases.
The human senses do not function like a video camcorder, impartially recording all observations. Human perception occurs by a complex, unconscious process of abstraction, in which certain details of the incoming sense data are noticed and remembered, and the rest forgotten. What is kept and what is thrown away depends on an internal model or representation of the world, called by psychologists a "schema", that is built up over our entire lives. The data is fitted into this schema. Later when events are remembered, memory gaps may even be filled by "plausible" data the mind makes up to fit the model; this is called "reconstructive memory". How much attention the various perceived data are given depends on an internal value system, which judges how important it is to the individual. Thus two people can view the same event and come away with entirely different perceptions of it, even disagreeing about simple facts. This is why eyewitness testimony is notoriously unreliable.
Several of the more important ways observations can be affected by human psychology are given below.
Confirmation bias.
Human observations are biased toward confirming the observer's conscious and unconscious expectations and view of the world; we "see what we expect to see". In psychology, this is called confirmation bias. Since the object of scientific research is the discovery of new phenomena, this bias can and has caused new discoveries to be overlooked. One example is the discovery of x-rays. It can also result in erroneous scientific support for widely held cultural myths, for example the scientific racism that supported ideas of racial superiority in the early 20th century. Correct scientific technique emphasizes careful recording of observations, separating experimental observations from the conclusions drawn from them, and techniques such as blind or double blind experiments, to minimize observational bias.
"Cargo cult" science.
Another bias, which has become more prevalent with the advent of "big science" and the large rewards of new discoveries, is bias in favor of the researcher's desired hypothesis or outcome; we "see what we want to see". Called pathological science and cargo cult science, this is different from deliberate falsification of results, and can happen to good-faith researchers. Researchers with a great incentive or desire for a given outcome can misinterpret or misjudge results, or even persuade themselves they have seen something they haven't. Possible examples of mistaken discoveries caused by this bias are Martian "canals", N rays, polywater, cold fusion, and perpetual motion machines. Recent decades have seen scientific scandals caused by researchers playing "fast and loose" with observational methods in order to get their pet theories published. This type of bias is rampant in pseudoscience, where correct scientific techniques are not followed. The main defense against this bias, besides correct research techniques, is peer review and repetition of the experiment, or the observation, by other researchers with no incentive to bias. For example, an emerging practice in the competitive field of biotechnology is to require the physical results of experiments, such as serums and tissue cultures, be made available to competing laboratories for independent testing.
Processing bias.
Modern scientific instruments can extensively process "observations" before they are presented to the human senses, and particularly with computerized instruments, there is sometimes a question as to where in the data processing chain "observing" ends and "drawing conclusions" begins. This has recently become an issue with digitally enhanced images published as experimental data in papers in scientific journals. The images are enhanced to bring out features that the researcher wants to emphasize, but this also has the effect of supporting the researcher's conclusions. This is a form of bias that is difficult to quantify. Some scientific journals have begun to set detailed standards for what types of image processing are allowed in research results. Computerized instruments often keep a copy of the "raw data" from sensors before processing, which is the ultimate defense against processing bias, and similarly scientific standards require preservation of the original unenhanced "raw" versions of images used as research data.
Observational bias.
An observational bias occurs when researchers only look where they think they will find positive results, or where it is easy to record observations. This is called the "streetlight effect".
Observations in philosophy.
"Observe always that everything is the result of a change, and get used to thinking that there is nothing Nature loves so well as to change existing forms and to make new ones like them."—Meditations. iv. 36. – Marcus Aurelius
Observation in philosophical terms is the process of filtering sensory information through the thought process. Input is received via hearing, sight, smell, taste, or touch and then analyzed through either rational or irrational thought. You "see" a parent beat their child; you "observe" that such an action is either good or bad. Deductions about what behaviors are good or bad may be based in no way on preferences about building relationships, or study of the consequences resulting from the observed behavior. With the passage of time, impressions stored in the consciousness about many related observations, together with the resulting relationships and consequences, permit the individual to build a construct about the moral implications of behavior.

</doc>
<doc id="22651" url="http://en.wikipedia.org/wiki?curid=22651" title="Oliver Conant">
Oliver Conant

Oliver Conant (born November 15, 1955) is an American actor.
Born in New York City, New York, Conant appeared as "Benji" in the 1971 coming-of-age drama "Summer of '42" and "Class of '44", appearing in both with Gary Grimes and Jerry Houser as a trio of adolescent boys.
He was also in Jean Kerr's 1973 Broadway farce "Finishing Touches", with Barbara Bel Geddes, Robert Lansing, James Woods, and others.
After a three decades or so hiatus from acting, Conant re-emerged on off and off-off Broadway stages in productions ranging from Gene Ruffini's dystopian "Homeland", Anne Fizzard's back-stage comedy "Good Opinions", and Tuvia Tenenbom's absurdist satire "Kabbalah". He serves as Producing Director for Queens Shakespeare Inc, a new classical repertory company based in Flushing, New York. Conant will be appearing in the NICU'S SPOON production of "Elizabeth Rex" in April 2008 in New York City.

</doc>
<doc id="22652" url="http://en.wikipedia.org/wiki?curid=22652" title="Oftel">
Oftel

"Oftel has been superseded as the British telecommunications regulator by Ofcom (the Office of Communications)."
The Office of Telecommunications (Oftel) ("the telecommunications regulator") was a department in the United Kingdom government, under civil service control, charged with promoting competition and maintaining the interests of consumers in the UK telecommunications market. It was set up under the Telecommunications Act 1984 after privatisation of the nationalised operator BT.
Oftel was accused by its critics of having been "captured" by BT, and of giving the dominant operator too much freedom to leverage its monopoly status in fixed line telephony into other markets such as ADSL.
On 28 December 2003 the duties of Oftel were inherited by Ofcom, which is the result of a consolidation of the British telecommunication and broadcasting regulators.
There are allegations of anti-competitive practice in marketing ADSL by BT made by Freeserve being overlooked by Oftel.

</doc>
<doc id="22653" url="http://en.wikipedia.org/wiki?curid=22653" title="OCR">
OCR

OCR may refer to:

</doc>
<doc id="22654" url="http://en.wikipedia.org/wiki?curid=22654" title="Ohio-class submarine">
Ohio-class submarine

The "Ohio" class is a class of nuclear-powered submarines used by the United States Navy. The navy has 18 "Ohio"-class submarines: 14 ballistic missile submarines (SSBN) and four that were later converted to guided missile submarines (SSGN).
The "Ohio" class is named after the lead submarine of this class, USS "Ohio". The 14 Trident II SSBNs together carry approximately fifty percent of the total US active inventory of strategic thermonuclear warheads. The exact number of warheads deployed across the world varies in an unpredictable and classified manner, but always at or below a maximum number set by various Strategic Arms Reduction Treaties. Although the Trident missiles have no pre-set targets when the submarines go on patrol, the warships, when required, are capable of quickly being assigned targets by using secure and constant radio communications links at sea, including very low frequency (VLF) systems.
All the "Ohio"-class submarines, except for , are named for U.S. states, which until that point was a tradition reserved for battleships and cruisers.
The "Ohio"-class submarines are the largest submarines ever built for the U.S. Navy. Two classes of the Russian Navy's submarines have larger total displacements: the Soviet-designed Typhoon-class submarines have more than twice the total displacement, and Russia's Borei-class submarines have roughly 25 percent greater displacement, but the "Ohio"-class warships carry more missiles than either of the other designs: 24 Trident missiles per boat, versus 16 missiles for the Borei class (20 for the Borei II) and 20 for the "Typhoon"-class.
Description.
The "Ohio"-class submarines were designed specifically for extended war-deterrence patrols. Each of these submarines is provided with two complete crews, called the Blue crew and the Gold crew, with each crew serving typically on 70- to 90-day deterrent patrols. To decrease the time in port for crew turnover and replenishment, three large logistics hatches have been installed to provide large-diameter resupply and repair access. These hatches allow rapid transfer of supply pallets, equipment replacement modules, and machinery components, significantly reducing the time required for replenishment and maintenance of the submarines.
The class's design allows the warship to operate for about fifteen years between major overhauls. These submarines are reported to be as quiet at their cruising speed of 20 kn or more than the previous "Lafayette"-class submarines were at 6 kn, although exact information remains classified. Fire control for their Mark 48 torpedoes is carried out by Mark 118 Mod 2 system, while the Missile Fire Control (MFC) system is a Mark 98.
The "Ohio"-class submarines were constructed from sections of hull, with each four-deck section being 42 ft in diameter. The sections were produced at the General Dynamics Electric Boat facility, Quonset Point, Rhode Island, and then assembled at its shipyard at Groton, Connecticut.
The US Navy has a total of 18 "Ohio"-class submarines which consist of 14 ballistic missile submarines (SSBNs), and four cruise missile submarines (SSGNs). The SSBN submarines are also known as "Trident" submarines, and provide the sea-based leg of the U.S. nuclear triad. Each SSBN submarine is armed with up to 24 Trident II submarine-launched ballistic missiles (SLBM). Each SSGN is capable of carrying 154 Tomahawk cruise missiles with either conventional or nuclear warheads, plus a complement of Harpoon missiles to be fired through their torpedo tubes.
History.
The first eight "Ohio"-class submarines were armed at first with 24 Trident I C4 SLBMs. Beginning with the ninth Trident submarine, , the remaining boats were equipped with the larger, three-stage Trident II D5 missile. The Trident I missile carries eight multiple independently targetable reentry vehicles (MIRV), while the Trident II missile carries twelve, in total delivering more destructive power than the Trident I missile and with greater accuracy. Starting with USS "Alaska" in 2000, the Navy began converting its remaining ballistic missile submarines armed with C4 missiles to carry D5 missiles. This task was completed in mid-2008.
The first eight submarines had their home ports at Bangor, Washington, to replace the submarines carrying the Polaris A3 missile that were then being decommissioned. The remaining ten submarines originally had their home ports at Kings Bay, Georgia, replacing the Poseidon and Trident Backfit submarines of the Atlantic Fleet. During the conversion of the first four submarines to SSGNs (see below), five of the submarines, "Pennsylvania", "Kentucky", "Nebraska", "Maine", and "Louisiana", were transferred from Kings Bay to Bangor. Further transfers occur as the strategic weapons goals of the United States change.
In 2011, "Ohio"-class submarines carried out 28 deterrent patrols. Each patrol lasts around 70 days. Four boats are on station ("hard alert") in designated patrol areas at any given time. From August to December 2010, "Maine" carried out a 105-day-long patrol, the longest to date.
SSBN/SSGN conversions.
After the end of the Cold War, plans called for "Ohio" to be retired in 2002, followed by three of her sister boats. However, "Ohio", "Michigan", "Florida", and "Georgia" instead were slated for modification, to remain in service carrying conventionally armed guided missiles, and were redesignated as SSGNs.
Beginning in 2002 through 2010, 22 of the 24 88 in diameter Trident missile tubes were modified to contain large vertical launch systems (VLS), one configuration of which may be a cluster of seven Tomahawk cruise missiles. In this configuration, the number of cruise missiles carried could be a maximum of 154, the equivalent of what is typically deployed in a surface battle group. Other payload possibilities include new generations of supersonic and hypersonic cruise missiles, and Submarine Launched Intermediate Range Ballistic Missiles (SLIRBM), unmanned air vehicles (UAVs), the ADM-160 MALD, sensors for anti-submarine warfare or intelligence, surveillance, and reconnaissance missions, countermine warfare payloads such as the AN/BLQ-11 Long Term Mine Reconnaissance System (LMRS), and the broaching universal buoyant launcher (BUBL) and stealthy affordable capsule system (SACS) specialized payload canisters.
The missile tubes also have room for stowage canisters that can extend the forward deployment time for special forces. The other two Trident tubes are converted to swimmer lockout chambers. For special operations, the Advanced SEAL Delivery System and the dry deck shelter can be mounted on the lockout chamber and the boat will be able to host up to 66 special operations sailors or Marines, such as Navy SEALs, or USMC MARSOC teams. Improved communications equipment installed during the upgrade allows the SSGNs to serve as a forward-deployed, clandestine Small Combatant Joint Command Center.
On 26 September 2002, the Navy awarded the Electric Boat company a US$442.9 million contract to begin the first phase of the SSGN submarine conversion program. Those funds covered only the initial phase of conversion for the first two boats on the schedule. Advanced procurement was funded at $355 million in fiscal year 2002, $825 million in the FY 2003 budget and, through the five-year defense budget plan, at $936 million in FY 2004, $505 million in FY 2005, and $170 million in FY 2006. Thus, the total cost to refit the four boats is just under $700 million per vessel.
In November 2002, "Ohio" entered a drydock, beginning her 36-month refueling and missile conversion overhaul. Electric Boat announced on 9 January 2006 that the conversion had been completed. The converted "Ohio" rejoined the fleet in February 2006, followed by the "Florida" in April 2006. The converted "Michigan" was delivered in November 2006. The converted "Ohio" went to sea for the first time in October 2007. "Georgia" returned to the fleet in March 2008 at Kings Bay. These four SSGNs are expected to remain in service until about 2023–2026. At that point their capabilities will be replaced with Virginia Payload Module equipped "Virginia"-class submarines.
Replacement.
The U.S. Department of Defense anticipates a continued need for a sea-based strategic nuclear force. The first of the current "Ohio" SSBNs are expected to be retired by 2029, meaning that a platform must already be seaworthy by that time. A replacement may cost over $4 billion per unit compared to "Ohio"‍ '​s $2 billion. The U.S. Navy is exploring two options. The first is a variant of the "Virginia"-class nuclear attack submarines. The second is a dedicated SSBN, either with a new hull or based on an overhaul of the current "Ohio".
With the cooperation of both Electric Boat and Newport News Shipbuilding, in 2007, the U.S. Navy began a cost control study. Then in December 2008 the U.S. Navy awarded Electric Boat a contract for the missile compartment design of the "Ohio"-class replacement, worth up to $592 million. Newport News is expected to receive close to 4% of that project. The U.S. Navy has yet to confirm an "Ohio"-class replacement program. However, in April 2009, U.S. Defense Secretary Robert M. Gates confirmed that the U.S. Navy should begin such a program in 2010. The new vessel is scheduled to enter the design phase by 2014. It is anticipated that, if a new hull design is used, the program must be initiated by 2016 in order to meet the 2029 deadline.
In popular culture.
As ballistic missile submarines, the "Ohio" class has occasionally been portrayed in fiction books and films.

</doc>
<doc id="22655" url="http://en.wikipedia.org/wiki?curid=22655" title="Ossian">
Ossian

Ossian (; Scottish Gaelic: "Oisean") is the narrator and purported author of a cycle of epic poems published by the Scottish poet James Macpherson from 1760. Macpherson claimed to have collected word-of-mouth material in Scots Gaelic, said to be from ancient sources, and that the work was his translation of that material. Ossian is based on Oisín, son of Finn or Fionn mac Cumhaill, anglicised to Finn McCool, a legendary bard who is a character in Irish mythology. Contemporary critics were divided in their view of the work's authenticity, but the consensus since is that Macpherson framed the poems himself, based on old folk tales he had collected, and that "Ossian" is, in the words of Thomas Curley, "the most successful literary falsehood in modern history."
The work was internationally popular, translated into all the literary languages of Europe and was influential both in the development of the Romantic movement and the Gaelic revival. "The contest over the authenticity of Macpherson's pseudo-Gaelic productions," Curley asserts, "became a seismograph of the fragile unity within restive diversity of imperial Great Britain in the age of Johnson." Macpherson's fame was crowned by his burial among the literary giants in Westminster Abbey. W.P. Ker, in the "Cambridge History of English Literature", observes that "all Macpherson's craft as a philological impostor would have been nothing without his literary skill."
The poems.
In 1760 Macpherson published the English-language text "Fragments of ancient poetry, collected in the Highlands of Scotland, and translated from the Gaelic or Erse language". Later that year, he claimed to have obtained further manuscripts and in 1761 he claimed to have found an epic on the subject of the hero Fingal, written by Ossian. The name Fingal or "Fionnghall" means "white stranger". According to Macpherson's prefatory material, his publisher, claiming that there was no market for these works except in English, required that they be translated. Macpherson published these translations during the next few years, culminating in a collected edition, "The Works of Ossian", in 1765. The most famous of these Ossianic poems was "Fingal", written in 1762.
The supposed original poems are translated into poetic prose, with short and simple sentences. The mood is epic, but there is no single narrative, although the same characters reappear. The main characters are Ossian himself, relating the stories when old and blind, his father Fingal (very loosely based on the Irish hero Fionn mac Cumhaill), his dead son Oscar (also with an Irish counterpart), and Oscar's lover Malvina (like Fiona a name invented by Macpherson), who looks after Ossian in his old age. Though the stories "are of endless battles and unhappy loves", the enemies and causes of strife are given little explanation and context.
Characters are given to killing loved ones by mistake, and dying of grief, or of joy. There is very little information given on the religion, culture or society of the characters, and buildings are hardly mentioned. The landscape "is more real than the people who inhabit it. Drowned in eternal mist, illuminated by a decrepit sun or by emphemeral meteors, it is a world of greyness." Fingal is king of a region of south-west Scotland perhaps similar to the historical kingdom of Dál Riata and the poems appear to be set around the 3rd century, with the "king of the world" mentioned being the Roman Emperor; Macpherson and his supporters detected references to Caracalla (d. 217, as "Caracul") and Carausius (d. 293, as "Caros", the "king of ships").
Reception.
The poems achieved international success. Napoleon and Diderot were great admirers, and Voltaire wrote parodies of them. Thomas Jefferson thought Ossian "the greatest Poet that has ever existed", and planned to learn Gaelic so as to read his poems in the original. They were proclaimed as a Celtic equivalent of the Classical writers such as Homer. Many writers were influenced by the works, including the young Walter Scott, and painters and composers chose Ossianic subjects.
One poem was translated into French in 1762, and by 1777 the whole "corpus". In the German-speaking states Michael Denis made the first full translation in 1768-69, inspiring the proto-nationalist poets Klopstock and Goethe, whose own German translation of a portion of Macpherson's work figures prominently in a climactic scene of "The Sorrows of Young Werther" (1774). Goethe's associate Johann Gottfried Herder wrote an essay titled "Extract from a correspondence about Ossian and the Songs of Ancient Peoples" (1773) in the early days of the Sturm und Drang movement.
Complete Danish translations were made in 1790, and Swedish ones in 1794-1800. In Scandinavia and Germany the Celtic nature of the setting was ignored or not understood, and Ossian was regarded as a Nordic or Germanic figure who became a symbol for nationalist aspirations. The French general Jean-Baptiste Bernadotte, who was made King Charles XIV John of Sweden and King of Norway, had already named his only son after a character from Ossian; born in 1799, he later became King Oscar I of Sweden and Norway, and was succeeded by his son Oscar II (d. 1907).
Melchiore Cesarotti was an Italian clergyman whose translation into Italian is said by many to improve on the original, and was a tireless promoter of the poems, in Vienna and Warsaw as well as Italy. It was his translation that Napoleon especially admired, and among others it influenced Ugo Foscolo who was Cesarotti's pupil in the University of Padua.
By 1800 Ossian was translated into Spanish and Russian, with Dutch following in 1805, and Polish, Czech and Hungarian in 1827-33. The poems were as much admired in Hungary as in France and Germany; Hungarian János Arany wrote "Homer and Ossian" in response, and several other Hungarian writers – Baróti Szabó, Csokonai, Sándor Kisfaludy, Kazinczy, Kölcsey, Ferenc Toldy, and Ágost Greguss, were also influenced by it.
The first partial Polish translation of Ossian was made by Ignacy Krasicki in 1793. The complete translation appeared in 1838 by Seweryn Goszczyński. The most influential Russian version of Ossian was the 1792 translation by Ermil Kostrov, who based his work on Pierre Le Tourneur's 1777 translation from the original.
The opera "Ossian, ou Les bardes" by Le Sueur was a sell-out at the Paris Opera in 1804, and transformed his career. The poems also exerted an influence on the burgeoning of Romantic music, and Franz Schubert, in particular composed Lieder setting many of Ossian's poems. In 1829 Felix Mendelssohn was inspired to visit the Hebrides and composed the "Hebrides Overture", better known as "Fingal's Cave". His friend Niels Gade devoted his first published work, the concert overture "Efterklange af Ossian" ("Echoes of Ossian") written in 1840, to the same subject.
Authenticity debate.
There were immediate disputes of Macpherson's claims on both literary and political grounds. Macpherson promoted a Scottish origin for the material, and was hotly opposed by Irish historians who felt that their heritage was being appropriated. However, both Scotland and Ireland shared a common Gaelic culture during the period in which the poems are set, and some Fenian literature common in both countries was composed in Scotland.
Samuel Johnson, English author, critic, and biographer, was convinced that Macpherson was "a mountebank, a liar, and a fraud, and that the poems were forgeries". Johnson also dismissed the poems' quality. Upon being asked, "But Doctor Johnson, do you really believe that any man today could write such poetry?" he famously replied, "Yes. Many men. Many women. And many children." Johnson is cited as calling the story of Ossian "as gross an imposition as ever the world was troubled with". In support of his claim, Johnson also called Gaelic the rude speech of a barbarous people, and said there were no manuscripts in it more than 100 years old. In reply, it was proved that the Advocates' library at Edinburgh contained Gaelic manuscripts 500 years old, and one of even greater antiquity.
Scottish author Hugh Blair's 1763 "A Critical Dissertation on the Poems of Ossian" upheld the work's authenticity against Johnson's scathing criticism and from 1765 was included in every edition of "Ossian" to lend the work credibility. The work also had a timely resonance for those swept away by the emerging Romantic movement and the theory of the "noble savage", and it echoed the popularity of Burke's seminal "A Philosophical Enquiry into the Origin of Our Ideas of the Sublime and Beautiful" (1757).
In 1766 the Irish antiquarian and Gaelic scholar Charles O'Conor dismissed Ossian's authenticity in a new chapter "Remarks on Mr. Mac Pherson's translation of Fingal and Temora" that he added to the second edition of his seminal history. In 1775 he expanded his criticism in a new book, "Dissertation on the origin and antiquities of the antient Scots".
Faced with the controversy, the Committee of the Highland Society enquired after the authenticity of Macpherson's supposed original. It was because of these circumstances that the so-called Glenmasan manuscript (Adv. 72.2.3) came to light in the late 18th century, a compilation which contains the tale "Oided mac n-Uisnig". This text is a version of the Irish "Longes mac n-Uislenn" and offers a tale which bears some comparison to Macpherson's "Darthula", although it is radically different in many respects. Donald Smith cited it in his report for the Committee.
The controversy raged on into the early years of the 19th century, with disputes as to whether the poems were based on Irish sources, on sources in English, on Gaelic fragments woven into his own composition as Johnson concluded, or largely on Scots Gaelic oral traditions and manuscripts as Macpherson claimed. Defences of the authenticity of the poems continued to be made. For example Peter Hately Waddell argued in "Ossian and the Clyde" (1875) that poems contained topographical references that could not have been known to Macpherson.
In 1952, Scottish poet Derick Thomson concluded that Macpherson had collected Scottish Gaelic ballads, employing scribes to record those that were preserved orally and collating manuscripts, but had adapted them by altering the original characters and ideas, and had introduced a great deal of his own. The modern American literature professor and translator Bernard Knox refers to the Ossian book as a forged or fake "collective bardic epic".
"The Invention of Scotland" (2008) by Hugh Trevor-Roper follows the evolution of Macpherson's versions and the work's early support by some Scottish intellectuals.
Ossian in art.
Subjects from the Ossian poems were popular in the art of northern Europe, but at rather different periods depending on the country; by the time French artists began to depict Ossian, British artists had largely dropped him. Ossian was especially popular in Danish art, but also found in Germany and the rest of Scandinavia.
Britain, Germany and Scandinavia.
British artists began to depict the Ossian poems early on, with the first major work a cycle of paintings decorating the ceiling the "Grand Hall" of Penicuik House in Midlothian, built by Sir James Clerk, who commissioned the paintings in 1772. These were by the Scottish painter Alexander Runciman and lost when the house burnt down in 1899, though drawings and etchings survive, and two pamphlets describing them were published in the 18th century. A subject from Ossian by Angelica Kauffman was shown in the Royal Academy exhibition of 1773, and Ossian was depicted in "Elysium", part of the Irish painter James Barry's "magnum opus" decorating the Royal Society of Arts, at the Adelphi Buildings in London (still "in situ").
Works on paper by Thomas Girtin and John Sell Cotman have survived, though the Ossianic landscapes by George Augustus Wallis, which the Ossian fan August Wilhelm Schlegel praised in a letter to Goethe, seem to have been lost, as has a picture by J.M.W. Turner exhibited in 1802. Henry Singleton exhibited paintings, some of which were engraved and used in editions of the poems.
The Danish painter Nicolai Abildgaard, Director of the Copenhagen Academy from 1789, painted several scenes from Ossian, as did his pupils including Asmus Jacob Carstens. His friend Joseph Anton Koch painted a number of subjects, and two large series of illustrations for the poems, which never got properly into print; like many Ossianic works by Wallis, Carstens, Krafft and others, some of these were painted in Rome, perhaps not the best place to evoke the dim northern light of the poems. In Germany the request in 1804 to produce some drawings as illustrations so excited Philipp Otto Runge that he planned a series of 100, far more than asked for, in a style heavily influenced by the linear illustrations of John Flaxman; these remain as drawings only. Many other German works are recorded, some as late as the 1840s; word of the British scepticism over the Ossian poems was evidently slow to pentetrate the continent.
France.
In France the enthusiasm of Napoleon for the poems accounts for most artistic depictions, and those by the most famous artists, but a painting exhibited in the Paris Salon in 1800 by Paul Duqueylar (now Musée Granet, Aix-en-Provence) excited "Les Barbus" ("the Bearded Ones") a group of primitivist artists including Pierre-Maurice Quays (or Quaï) who promoted living in the style of "early civilizations as described in Homer, Ossian, and the Bible". Quays is reported as saying: "Homère? Ossian? ... le soleil? la lune? Voilà la question. En vérité, je crois que je préfère la lune. C'est plus simple, plus grand, plus "primitif"". ("Homer? Ossian? ... the sun? the moon? That's the question. Truthfully I think I prefer the moon. It's more simple, more grand, more "primitive""). The same year Napoleon was planning the renovation of the Château de Malmaison as a summer palace, and though he does not seem to have suggested Ossianic subjects for his painters, two large and significant works were among those painted for the reception hall, for which six artists had been commissioned.
These were Girodet's painting of 1801–02 "Ossian receiving the Ghosts of the French Heroes", and "Ossian Evoking ghosts on the Edge of the Lora", by François Pascal Simon Gérard. Gérard's original was lost in a shipwreck after being bought by the King of Sweden after the fall of Napoleon, but survives in three replicas by the artist (a further one in Berlin was lost in 1945). One is now at Malmaison (184.5 × 194.5 cm / 72.6 × 76.6 in), and the Kunsthalle Hamburg has another (180,5 × 198,5 cm). A watercolour copy by Jean-Baptiste Isabey was placed as frontispiece to Napoleon's copy of the poems.
Duqueylar, Girodet and Gérard, like Johann Peter Krafft (above) and most of the "Barbus", were all pupils of David, and the clearly unclassical subjects of the Ossian poems were useful for emergent French Romantic painting, marking a revolt against David's Neoclassical choice of historical subject-matter. David's recorded reactions to the paintings were guarded or hostile; he said of Girodet's work: "Either Girodet is mad or I no longer know anything of the art of painting".
Girodet's painting (still at Malmaison; 192.5 x 184 cm) was a "success de scandale" when exhibited in 1802, and remains a key work in the emergence of French Romantic painting, but the specific allusions to the political situation that he intended it to carry were largely lost on the public, and overtaken by the Peace of Amiens with England, signed in 1802 between the completion and exhibition of the work. He also produced "Malvina dying in the arms of Fingal" (c. 1802), and other works.
Another pupil of David, Jean-Auguste-Dominique Ingres, was to depict Ossianic scenes over most of his long career. He made a drawing in 1809, when studying in Rome, and in 1810 or 1811 was commisissioned to make two paintings, the "Dream of Ossian" and a classical scene, to decorate the bedroom Napoleon was to occupy in the Palazzo Quirinale on a visit to Rome. In fact the visit never came off and in 1835 Ingres repurchased the work, now in poor condition.
Editions.
National Library of Scotland has 327 books and associated materials in its Ossian Collection. The collection was originally assembled by J. Norman Methven of Perth and includes different editions and translations of James MacPherson's epic poem 'Ossian', some with a map of the 'Kingdom of Connor'. It also contains secondary material relating to Ossianic poetry and the Ossian controversy. More than 200 items from the collection have been digitised. 
References.
</dl>
Further reading.
in French:

</doc>
<doc id="22656" url="http://en.wikipedia.org/wiki?curid=22656" title="Operand">
Operand

In mathematics, an operand is the object of a mathematical operation, a quantity on which an operation is performed.
Example.
The following arithmetic expression shows an example of operators and operands:
In the above example, '+' is the symbol for the operation called addition. 
The operand '3' is one of the inputs (quantities) followed by the addition operator, and the operand '6' is the other input necessary for the operation.
The result of the operation is 9. (The number '9' is also called the sum of the addends, 3 and 6.)
An operand, then, is also referred to as "one of the inputs (quantities) for an operation".
Notation.
Expressions as operands.
Operands may be complex, and may consist of expressions also made up of operators with operands.
In the above expression '(3 + 5)' is the first operand for the multiplication operator and '2' the second. The operand '(3 + 5)' is an expression in itself, which contains an addition operator, with the operands '3' and '5'.
Order of operations.
Rules of precedence affect which values form operands for which operators:
In the above expression, the multiplication operator has the higher precedence than the addition operator, so the multiplication operator has operands of '5' and '2'. The addition operator has operands of '3' and '5 × 2'.
Positioning of operands.
Depending on the mathematical notation being used the position of an operator in relation to its operand(s) may vary. In everyday usage infix notation is the most common, however other notations also exist, such as the prefix and postfix notations. These alternate notations are most common within computer science.
Below is a comparison of three different notations — all represent an addition of the numbers '1' and '2'
Infix Notation and the Order of Operation.
With infix notation, one easy mnemonic for remembering the order of operation is:
Please excuse my dear Aunt Sally.
The first letter (in boldtype) of each word in the above mnemonic stands for the following:
In a mathematical expression, the order of operation is carried out from left to right. Start with the left most value and seek the first operation to be carried out in accordance with the order specified above (i.e., start with parentheses and end with the addition/subtraction group). For example, in the expression
the first operation to be acted upon is any and all expressions found inside a parenthesis. So beginning at the left and moving to the right, find the first (and in this case, the only) parenthesis, that is, (2 + 22). Within the parenthesis itself is found the expression 22. The reader is required to find the value of 22 before going any further. The value of 22 is 4. Having found this value, the remaining expression looks like this:
The next step is to calculate the value of expression inside the parenthesis itself, that is, (2 + 4) = 6. Our expression now looks like this:
Having calculated the parenthetical part of the expression, we start over again beginning with the left most value and move right. The next order of operation (according to the rules) is exponents. Start at the left most value, that is, 4, and scan your eyes to the right and search for the first exponent you come across. The first (and only) expression we come across that is expressed with an exponent is 22. We find the value of 22, which is 4. What we have left is the expression
The next order of operation is multiplication. 4 × 4 is 16. Now our expression looks like this:
The next order of operation according to the rules is division. However, there is no division operator sign (÷) in the expression, 16 − 6. So we move on to the next order of operation, i.e., addition. But there is no addition operator sign (+) in the expression 16 − 6. So we move on to the next and final order of operation, which is subtraction.
So the correct value for our original expression, 4 × 22 − (2 + 22), is 10. 
It is important to carry out the order of operation in accordance with rules set by convention. If the reader evaluates an expression but does not follow the correct order of operation, the reader will come forth with a different value. The different value will be the incorrect value because the order of operation was not followed. The reader will arrive at the correct value for the expression if and only if each operation is carried out in the proper order.
Arity.
The number of operands of an operator is called its arity. Based on arity, operators are classified as nullary (no operands), unary (1 operand), binary (2 operands), ternary (3 operands) etc.
Computer science.
In computer programming languages, the definitions of operator and operand are almost the same as in mathematics.
In computing, an operand is the part of a computer instruction which specifies what data is to be manipulated or operated on, while at the same time representing the data itself.
A computer instruction describes an operation such as add or multiply X, while the operand (or operands, as there can be more than one) specify on which X to operate as well as the value of X.
Additionally, in assembly language, an operand is a value (an argument) on which the instruction, named by mnemonic, operates. The operand may be a processor register, a memory address, a literal constant, or a label. A simple example (in the x86 architecture) is
where the value in register operand 'AX' is to be moved into register 'DS'. Depending on the instruction, there may be zero, one, two, or more operands.

</doc>
<doc id="22657" url="http://en.wikipedia.org/wiki?curid=22657" title="Order of magnitude">
Order of magnitude

Orders of magnitude are written in powers of 10. For example, the order of magnitude of 1500 is 3, since 1500 may be written as 1.5 × 103.
Differences in order of magnitude can be measured on the logarithmic scale in "decades" (i.e., factors of ten). Examples of numbers of different magnitudes can be found at Orders of magnitude (numbers).
 We say two numbers have the same order of magnitude of a number if the big one divided by the little one is less than 10. For example, 23 and 82 have the same order of magnitude, but 23 and 820 do not." — John C. Baez
Uses.
Orders of magnitude are used to make approximate comparisons. If numbers differ by 1 order of magnitude, "x" is "about" ten times different in quantity than "y". If values differ by 2 orders of magnitude, they differ by a factor of about 100. Two numbers of the same order of magnitude have roughly the same scale: the larger value is less than ten times the smaller value.
The order of magnitude of a number is, intuitively speaking, the number of powers of 10 contained in the number. More precisely, the order of magnitude of a number can be defined in terms of the common logarithm, usually as the integer part of the logarithm, obtained by truncation. For example, the number 4,000,000 has a logarithm (in base 10) of 6.602; its order of magnitude is 6. When truncating, a number of this order of magnitude is between 106 and 107. In a similar example, with the phrase "He had a seven-figure income", the order of magnitude is the number of figures minus one, so it is very easily determined without a calculator to be 6. An order of magnitude is an approximate position on a logarithmic scale.
An order-of-magnitude estimate of a variable whose precise value is unknown is an estimate rounded to the nearest power of ten. For example, an order-of-magnitude estimate for a variable between about 3 billion and 30 billion (such as the human population of the Earth) is 10 billion. To round a number to its nearest order of magnitude, one rounds its logarithm to the nearest integer. Thus 4,000,000, which has a logarithm (in base 10) of 6.602, has 7 as its nearest order of magnitude, because "nearest" implies rounding rather than truncation. For a number written in scientific notation, this logarithmic rounding scale requires rounding up to the next power of ten when the multiplier is greater than the square root of ten (about 3.162). For example, the nearest order of magnitude for 1.7 × 108 is 8, whereas the nearest order of magnitude for 3.7 × 108 is 9. An order-of-magnitude estimate is sometimes also called a zeroth order approximation.
An order-of-magnitude difference between two values is a factor of 10. For example, the mass of the planet Saturn is 95 times that of Earth, so Saturn is "two orders of magnitude" more massive than Earth. Order-of-magnitude differences are called decades when measured on a logarithmic scale.
Non-decimal orders of magnitude.
Other orders of magnitude may be calculated using bases other than 10. The ancient Greeks ranked the nighttime brightness of celestial bodies by 6 levels in which each level was the fifth root of one hundred (about 2.512) as bright as the nearest weaker level of brightness, and thus the brightest level being 5 orders of magnitude brighter than the weakest indicates that it is (1001/5)5 or a factor of 100 times brighter.
The different decimal numeral systems of the world use a larger base to better envision the size of the number, and have created names for the powers of this larger base. The table shows what number the order of magnitude aim at for base 10 and for base 1,000,000. It can be seen that the order of magnitude is included in the number name in this example, because bi- means 2 and tri- means 3 (these make sense in the long scale only), and the suffix -illion tells that the base is 1,000,000. But the number names billion, trillion themselves (here with other meaning than in the first chapter) are not names of the "orders of" magnitudes, they are names of "magnitudes", that is the "numbers" 1,000,000,000,000 etc.
SI units in the table at right are used together with SI prefixes, which were devised with mainly base 1000 magnitudes in mind. The IEC standard prefixes with base 1024 were invented for use in electronic technology.
The ancient apparent magnitudes for the brightness of stars uses the base formula_1 and is reversed. The modernized version has however turned into a logarithmic scale with non-integer values.
Extremely large numbers.
For extremely large numbers, a generalized order of magnitude can be based on their double logarithm or super-logarithm. Rounding these downward to an integer gives categories between very "round numbers", rounding them to the nearest integer and applying the inverse function gives the "nearest" round number.
The double logarithm yields the categories:
(the first two mentioned, and the extension to the left, may not be very useful, they merely demonstrate how the sequence mathematically continues to the left).
The super-logarithm yields the categories:
The "midpoints" which determine which round number is nearer are in the first case:
and, depending on the interpolation method, in the second case
For extremely small numbers (in the sense of close to zero) neither method is suitable directly, but the generalized order of magnitude of the reciprocal can be considered.
Similar to the logarithmic scale one can have a double logarithmic scale (example provided here) and super-logarithmic scale. The intervals above all have the same length on them, with the "midpoints" actually midway. More generally, a point midway between two points corresponds to the generalised f-mean with "f"("x") the corresponding function log log "x" or slog "x". In the case of log log "x", this mean of two numbers (e.g. 2 and 16 giving 4) does not depend on the base of the logarithm, just like in the case of log "x" (geometric mean, 2 and 8 giving 4), but unlike in the case of log log log "x" (4 and 65536 giving 16 if the base is 2, but, otherwise).

</doc>
<doc id="22659" url="http://en.wikipedia.org/wiki?curid=22659" title="Ockham">
Ockham

Occam or Ockham may refer to:

</doc>
<doc id="22660" url="http://en.wikipedia.org/wiki?curid=22660" title="Occam (programming language)">
Occam (programming language)

occam is a concurrent programming language that builds on the communicating sequential processes (CSP) process algebra, and shares many of its features. It is named after William of Ockham of Occam's Razor fame.
occam is an imperative procedural language (such as Pascal). It was developed by David May and others at INMOS, advised by Tony Hoare, as the native programming language for their transputer microprocessors, but implementations for other platforms are available. The most widely known version is occam 2; its programming manual was written by Steven Ericsson-Zenith and others at INMOS.
Overview.
In the following examples indentation and formatting are critical for parsing the code: expressions are terminated by the end of the line, lists of expressions need to be on the same level of indentation. This feature, named the off-side rule, is also found in other languages such as Haskell and Python.
Communication between processes work through named "channels". One process outputs data to a channel via "!" while another one inputs data with "?". Input and output can not proceed until the other end is ready to accept or offer data. (In the "not proceeding" case it is often said that the process "blocks" on the channel. However, the program will neither spin nor poll; therefore terms like "wait", "hang" or "yield" may also convey the behaviour - also in the light of the fact that it will not "block" other independent processes from running.) Examples (c is a variable):
 keyboard ? c
 screen ! c
SEQ introduces a list of expressions that are evaluated sequentially. This is not implicit as it is in most other programming languages. Example:
 SEQ
 x := x + 1
 y := x * x
PAR begins a list of expressions that may be evaluated concurrently. Example:
 PAR
 p()
 q()
ALT specifies a list of "guarded" commands. The "guards" are a combination of a boolean condition and an input expression (both optional). Each guard for which the condition is true and the input channel is ready is successful. One of the successful alternatives is selected for execution. Example:
 ALT
 count1 < 100 & c1 ? data
 SEQ
 count1 := count1 + 1
 merged ! data
 count2 < 100 & c2 ? data
 SEQ
 count2 := count2 + 1
 merged ! data
 status ? request
 SEQ
 out ! count1
 out ! count2
This will read data from channels c1 or c2 (whichever is ready) and pass it into a merged channel. If countN reaches 100, reads from the corresponding channel will be disabled. A request on the status channel is answered by outputting the counts to out.
Language revisions.
occam 1.
occam 1 (released 1983) was a preliminary version of the language which borrowed from David May's work on EPL and Tony Hoare's CSP. This supported only the VAR data type, which was an integral type corresponding to the native word length of the target architecture, and arrays of only one dimension.
occam 2.
occam 2 is an extension produced by INMOS Ltd in 1987 that adds floating-point support, functions, multi-dimensional arrays and more data types such as varying sizes of integers (INT16, INT32) and bytes.
With this revision, occam became a language capable of expressing useful programs, whereas occam 1 was more suited to examining algorithms and exploring the new language (however, the occam 1 compiler was written in occam 1, so there is an existence proof that reasonably sized, useful programs could be written in occam 1, despite its limitations).
occam 2.1.
occam 2.1 was the last of the series of occam language developments contributed by INMOS. Defined in 1994, it was influenced by an earlier proposal for an occam 3 language (also referred to as "occam91" during its early development) created by Geoff Barrett at INMOS in the early 1990s. A revised Reference Manual describing occam 3 was distributed for community comment, but the language was never fully implemented in a compiler.
occam 2.1 introduced several new features to occam 2, including:
For a full list of the changes see Appendix P of the .
occam-π.
occam-π is the common name for the occam variant implemented by later versions of KRoC, the Kent Retargetable occam Compiler. The addition of the symbol "π" (pi) to the occam name is an allusion to the fact that KRoC occam includes several ideas inspired by the pi-calculus. It contains a significant number of extensions to the occam 2.1 compiler, for example:
External links.
Related projects.
This article is based on material taken from the Free On-line Dictionary of Computing prior to 1 November 2008 and incorporated under the "relicensing" terms of the GFDL, version 1.3 or later.

</doc>
<doc id="22661" url="http://en.wikipedia.org/wiki?curid=22661" title="October Revolution">
October Revolution

The October Revolution (Russian: Октя́брьская револю́ция, "Oktyabr'skaya revolyutsiya"; ]), officially known as the Great October Socialist Revolution (Russian: Вели́кая Октя́брьская социалисти́ческая револю́ция, "Velikaya Oktyabr'skaya sotsialisticheskaya revolyutsiya"), and commonly referred to as Red October, the October Uprising or the Bolshevik Revolution, was a seizure of state power instrumental in the larger Russian Revolution of 1917. It took place with an armed insurrection in Petrograd traditionally dated to 25 October 1917 (by the Julian or Old Style calendar, which corresponds to 7 November 1917 in the Gregorian or New Style calendar).
It followed and capitalized on the February Revolution of the same year, which overthrew the Tsarist autocracy and established a provisional government composed predominantly of former nobles and aristocrats. During this time, urban workers began to organize into councils (Russian: "Soviet") wherein revolutionaries criticized the provisional government and its actions. The October Revolution in Petrograd overthrew the provisional government and gave the power to the local soviets. The Bolshevik party was heavily supported by the soviets. After the Congress of Soviets, now the governing body, had its second session, it elected members of the Bolsheviks and other leftist groups such as the Left Socialist Revolutionaries to key positions within the new state of affairs. This immediately initiated the establishment of the Russian Socialist Federative Soviet Republic, the world's first self-proclaimed socialist state.
The revolution was led by the Bolsheviks, who used their influence in the Petrograd Soviet to organize the armed forces. Bolshevik Red Guards forces under the Military Revolutionary Committee began the takeover of government buildings on 24 October 1917 (O.S.). The following day, the Winter Palace (the seat of the Provisional government located in Petrograd, then capital of Russia), was captured.
The long-awaited Constituent Assembly elections were held on 12 November 1917. The Bolsheviks only won 175 seats in the 715 seat legislative body, coming in second behind the Socialist Revolutionary party, which won 370 seats. The Constituent Assembly was to first meet on 28 November 1917, but its convocation was delayed until January 5, 1918 by the Bolsheviks. On its first and only day in session, the body rejected Soviet decrees on peace and land, and was dissolved the next day by order of the Congress of Soviets.
As the revolution was not universally recognized, there followed the struggles of the Russian Civil War (1917–1922) and the creation of the Soviet Union in 1922.
Etymology.
Initially, the event was referred as the "October coup" (Октябрьский переворот) or the "Uprising of 25th", as seen in contemporary documents (for example, in the first editions of Lenin's complete works). In Russian, however, "переворот" has a similar meaning to "revolution" and also means "upheaval" or "overturn", so "coup" is not necessarily the right translation. With time, the term "October Revolution" (Октябрьская революция) came into use. It is also known as the "November Revolution" having occurred in November according to the Gregorian Calendar.
The Great October Socialist Revolution (Russian: Вели́кая Октя́брьская Социалисти́ческая Революция, "Velikaya Oktyabr'skaya sotsialisticheskaya revolyutsiya") was the official name for the October Revolution in the Soviet Union after the 10th anniversary of the Revolution in 1927.
Background.
The February Revolution had toppled Tsar Nicholas II of Russia, and replaced his government with the Russian Provisional Government. However, the provisional government was weak and riven by internal dissension. It continued to wage World War I, which became increasingly unpopular. A nationwide crisis developed in Russia, affecting social, economic, and political relations. Disorder in industry and transport had intensified, and difficulties in obtaining provisions had increased. Gross industrial production in 1917 had decreased by over 36 percent from what it had been in 1916. In the autumn, as much as 50 percent of all enterprises were closed down in the Urals, the Donbas, and other industrial centers, leading to mass unemployment. At the same time, the cost of living increased sharply. The real wages of the workers fell about 50 percent from what they had been in 1913. Russia's national debt in October 1917 had risen to 50 billion rubles. Of this, debts to foreign governments constituted more than 11 billion rubles. The country faced the threat of financial bankruptcy.
In September and October 1917, there were strikes by the Moscow and Petrograd workers, the miners of the Donbas, the metalworkers of the Urals, the oil workers of Baku, the textile workers of the Central Industrial Region, and the railroad workers on 44 different railway lines. In these months alone more than a million workers took part in mass strike action. Workers established control over production and distribution in many factories and plants in a social revolution.
By October 1917 there had been over four thousand peasant uprisings against landowners. When the Provisional Government sent out punitive detachments it only enraged the peasants. The garrisons in Petrograd, Moscow, and other cities, the Northern and Western fronts, and the sailors of the Baltic Fleet in September openly declared through their elected representative body Tsentrobalt that they did not recognize the authority of the Provisional Government and would not carry out any of its commands.
In a diplomatic note of 1 May, the minister of foreign affairs, Pavel Milyukov, expressed the Provisional Government's desire to carry the war against the Central Powers through "to a victorious conclusion", arousing broad indignation. On 1–4 May about 100,000 workers and soldiers of Petrograd, and after them the workers and soldiers of other cities, led by the Bolsheviks, demonstrated under banners reading "Down with the war!" and "all power to the soviets!" The mass demonstrations resulted in a crisis for the Provisional Government. 1 July saw more demonstrations, as about 500,000 workers and soldiers in Petrograd demonstrated, again demanding "all power to the soviets", "down with the war", and "down with the ten capitalist ministers". The Provisional Government opened an offensive against the Central Powers on 1 July but it soon collapsed. The news of the offensive and its collapse intensified the struggle of the workers and the soldiers. A new crisis in the Provisional Government began on 15 July.
On 16 July spontaneous demonstrations of workers and soldiers began in Petrograd, demanding that power be turned over to the soviets. The Central Committee of the Russian Social Democratic Labour Party provided leadership to the spontaneous movements. On 17 July, over 500,000 people participated in a peaceful demonstration in Petrograd, the so-called July Days. The Provisional Government, with the support of the Socialist-Revolutionary Party-Menshevik leaders of the All-Russian Executive Committee of the Soviets, ordered an armed attack against the peaceful demonstrators, murdering hundreds.
A period of repression followed. On 5–6 July attacks were made on the editorial offices and printing presses of "Pravda" and on the Palace of Kshesinskaya, where the Central Committee and the Petrograd Committee of the Bolsheviks were located. On 7 July a government decree ordering the arrest and trial of Vladimir Lenin was published. He was forced to go underground, just as he had been under the Tsarist regime. Bolsheviks began to be arrested, workers were disarmed, and revolutionary military units in Petrograd were disbanded or sent off to the front. On 12 July the Provisional Government published a law introducing the death penalty at the front. The formation of the second coalition government, with Alexander Kerensky as chairman, was completed on 24 July.
Another problem for the government centered on General Lavr Kornilov, who had been Commander-in-Chief since 18 July. In response to a Bolshevik appeal, Moscow’s working class began a protest strike of 400,000 workers. The Moscow workers were supported by strikes and protest rallies by workers in Kiev, Kharkov, Nizhny Novgorod, Ekaterinburg, and other cities.
In what became known as the Kornilov Affair, Kornilov directed an army under Aleksandr Krymov to march toward Petrograd with Kerensky's agreement. Although the details remain sketchy, Kerensky appeared to become frightened by the possibility of a coup and the order was countermanded (by comparison, historian Richard Pipes has argued that the whole episode was engineered by Kerensky himself). On 27 August, feeling betrayed by the Kerensky government who had previously agreed with his views on how to restore order to Russia, Kornilov pushed on towards Petrograd. With few troops to spare on the front, Kerensky was forced to turn to the Petrograd Soviet for help. Bolsheviks, Mensheviks and Socialist Revolutionaries confronted the army and convinced them to stand down. The Bolsheviks' influence over railroad and telegraph workers also proved vital in stopping the movement of troops. The damage was already done, however. Right-wingers felt betrayed, and the left wing was resurgent.
With Kornilov defeated, the Bolsheviks' popularity with the soviets significantly increased. During and after the defeat of Kornilov, a mass turn of the soviets toward the Bolsheviks began, both in the central and local areas. On 31 August, the Petrograd Soviet of Workers and Soldiers Deputies, and on 5 September, the Moscow Soviet Workers Deputies adopted the Bolshevik resolutions on the question of power. The Bolsheviks won a majority in the Soviets of Briansk, Samara, Saratov, Tsaritsyn, Minsk, Kiev, Tashkent, and other cities.
Events.
On 23 October [O.S. 10 October] 1917, the Bolsheviks' Central Committee voted 10-2 for a resolution saying that "an armed uprising is inevitable, and that the time for it is fully ripe".
On 6 November [O.S. 24 October] 1917, Bolsheviks led their forces in the uprising in Petrograd (modern day Saint Petersburg), the capital of Russia, against the Kerensky Provisional Government. Leon Trotsky distributes arms to the Red Guard, which systematically captures major government facilities, key communication, installations and vantage points with little opposition. The Petrograd Garrison rebels against the Provisional Government, claiming that it is a "tool of the enemies of the people". For the most part, the revolt in Petrograd was bloodless, with the Red Guards led by Bolsheviks finally launching an assault on the poorly defended Winter Palace.
The official Soviet version of events follows: An assault led by Vladimir Lenin was launched at 9:45 p.m. signaled by a blank shot from the cruiser "Aurora". (The "Aurora" was placed in Petrograd and still stands there now.) The Winter Palace was guarded by Cossacks, cadets (military students), and a Women's Battalion. It was taken at about 2 a.m. The earlier date was made the official date of the Revolution, when all offices except the Winter Palace had been taken.
More contemporary research with access to government archives significantly corrects accepted Soviet edited and embellished history. The archival version shows that parties of Bolshevik operatives sent out from the Smolny by Lenin took over all critical centers of power in Petrograd in the early hours of the first night without a shot being fired. This was completed so efficiently that the takeover resembled the changing of the guard. The capture of the Winter Palace was more dramatic, with the Red Guard storming the Winter Palace at 2.10 am on 7 November [O.S. 25 October] 1917. The Cossacks deserted when the Red Guard approached, and the Cadets and the 140 volunteers of the Women's Battalion surrendered rather than resist the 40000 strong army. The "Aurora" was commandeered to then fire blanks at the palace in a symbolic act of rejection of the government. In fact the effectively unoccupied Winter Palace fell not because of acts of courage or a military barrage, but because the back door was left open, allowing the Red Guard to enter. A Red Guard named Adamovich remembered gasping as he burst into the palace, as he had never before seen such luxury and splendour. A small group which broke in, got lost in the cavernous interior, and accidentally happened upon the remnants of Kerensky's provisional government in the imperial family's breakfast room. The illiterate revolutionaries then compelled those arrested to write up their own arrest papers. The Provisional Government was arrested and imprisoned in Peter and Paul Fortress after the ministers resigned to fate and surrendered without a fight, and officially overthrown. The stories of the "defense of the Winter Palace" and the heroic "Storming of the Winter Palace" came later as the creative propaganda product of Bolshevik publicists. Grandiose paintings depicting the "Women's Battalion" and photo stills taken from Sergei Eisenstein's staged film depicting the "politically correct" version of the October events in Petrograd came to be taken as truth. With the Government Petrograd Soviet now in control of government, garrison and proletariat, the Second All Russian Congress of Soviets held its opening session on the day, while Trotsky dismisses the opposing Mensheviks and the Socialist Revolutionaries (SR) from Congress.
Some sources contend that as the leader of Tsentrobalt, Pavlo Dybenko actually played an enormous role in the revolt. It is said that the ten warships that entered the city with ten thousand Baltic fleet mariners was the force that actually took the power in Petrograd and put down the Provisional Government. The same mariners then dispersed by force the elected parliament of Russia, and used machine-gun fire against protesting demonstrators in Petrograd. About a hundred demonstrators were killed, and several hundreds were wounded. Dybenko in his memoirs mentioned this event as "several shots in the air". Later, during the first hours after the taking the Winter Palace, Dybenko personally entered the Ministry of Justice and destroyed there the documents concerning the financing of the Bolshevik party by Germany. These are disputed by various sources such as Louise Bryant, who claims that news outlets in the west at the time reported that the unfortunate loss of life occurred in Moscow not Petrograd and the number was much less than is suggested above. As for the "several shots in the air", there is little evidence suggesting otherwise. The alleged action of Dybenko entering the Ministry of Justice to destroy documents as recalled by Savchenko can also be challenged. According to reports, Pavel Dybenko was in Helsingfors organizing the sailors' departures for Petrograd. From the book Radio October...On the “Krechet” in Helsingfors, radio operator Makarov hands a telegram to Pavel Dybenko with the report of the “Samson” commissar, Grigoriy Borisov: “To Tsentrobalt. Everything is calm in Petrograd. The power is in the hands of the revolutionary committee. You have to immediately get in touch with the front committee of the Northern Army in order to preserve unity of forces and stability."
Later official accounts of the revolution from the Soviet Union would depict the events in October as being far more dramatic than they actually had been. (See firsthand account by British General Knox.) This was helped by the historical reenactment, entitled "The Storming of the Winter Palace", which was staged in 1920. This reenactment, watched by 100,000 spectators, provided the model for official films made much later, which showed a huge storming of the Winter Palace and fierce fighting (See Sergei Eisenstein's ""). In reality the Bolshevik insurgents faced little or no opposition. The insurrection was timed and organized to hand state power to the Second All-Russian Congress of Soviets of Workers' and Soldiers' Deputies, which began on 25 October. After a single day of revolution eighteen people had been arrested and two had been killed.
Outcomes.
The Second Congress of Soviets consisted of 670 elected delegates; 300 were Bolshevik and nearly a hundred were Left Socialist-Revolutionaries, who also supported the overthrow of the Alexander Kerensky Government. When the fall of the Winter Palace was announced, the Congress adopted a decree transferring power to the Soviets of Workers', Soldiers' and Peasants' Deputies, thus ratifying the Revolution.
The transfer of power was not without disagreement. The center and Right wings of the Socialist Revolutionaries as well as the Mensheviks believed that Lenin and the Bolsheviks had illegally seized power and they walked out before the resolution was passed. As they exited, they were taunted by Leon Trotsky who told them "You are pitiful isolated individuals; you are bankrupts; your role is played out. Go where you belong from now on — into the dustbin of history!"
The following day, 8 November [O.S. 26 October] 1917, the Congress elected a Council of People's Commissars (Sovnarkom) with Lenin as leader as the basis of a new Soviet Government, pending the convocation of a Constituent Assembly, and passed the Decree on Peace and the Decree on Land. This new government was also officially called "provisional" until the Assembly was dissolved. The Council of People's Commissars now began to arrest the leaders of opposition parties. Dozens of Constitutional Democratic Party (Kadet) leaders and members of the Constituent Assembly were imprisoned in The Peter and Paul Fortress. These were to be followed by the arrests of Socialist Revolutionary Party and Menshevik leaders.. Posters were pinned on walls and fences by the SRs describing the takeover as a "crime against the motherland and revolution". The is also strong anti-Bolshevik opposition within Petrograd.
On 9 November [O.S. 27 October] 1917, the Mensheviks seize power of Georgia and declare it an independent republic. The Don Cossacks also claim control of their own government. There is strong anti-Bolshevik opposition outside of Petrograd, with Bolshevik control of country still very weak. There are also reports that the Provisional Government has not conceded defeat and are meeting with the army at the Front.
On 10 November [O.S. 28 October] 1917, posters and newspapers start criticizing the actions of the Bolsheviks and refutes their authority. The Executive Committee of Peasants Soviets "refutes with indignation all participation of the organised peasantry in this criminal violation of the will of the working class". Strong opposition to the Bolsheviks still continues from several important proletariat sources.
On 11 November [O.S. 29 October] 1917, opposition to the Bolsheviks develops into major counter-revolutionary action. Cossacks enter Tsarskoye Selo on outskirts of Petrograd with Kerensky riding on a white horse welcomed by church bells. Kerensky gave an ultimatum to the rifle garrison to lay down weapons, which was promptly refused. They were then fired upon by Kerensky’s Cossacks, which resulted in 8 deaths. This turned soldiers in Petrograd against Kerensky because he was just like the Tsarist regime. Kerensky’s failure to assume authority over troops described by John Reed as a ‘fatal blunder’ that signalled the final death of the government.
On 12 November [O.S. 30 October] 1917, the battle against the anti-Bolsheviks continues. The Red Guard fights against Cossacks at Tsarskoye Selo, with the Cossacks breaking rank and fleeing, leaving their artillery behind.
On 13 November [O.S. 31 October] 1917, the Bolsheviks gain control of Moscow after a week of bitter street-fighting. Artillery had been freely used with an estimated 700 casualties. However, there is still continued support for Kerensky in the provinces.
On 14 November [O.S. 1 November] 1917, there is an appeal to anti-Bolsheviks throughout Russia to join new government of the people, with the Bolsheviks gradually winning the support of the Russian people.
On 15 November [O.S. 2 November] 1917, there is only minor public anti-Bolshevik sentiment; for example, the newspaper Novaya Zhizn criticises the lack of manpower and organisation of the Bolsheviks to run a party, let alone a government. Lenin confidently claims that there is "not a shadow of hesitation in the masses of Petrograd, Moscow and the rest of Russia" towards Bolshevik rule.
On 20 December 1917 the Cheka was created by the decree of Vladimir Lenin. These were the beginnings of the Bolsheviks' consolidation of power over their political opponents.
The Decree on Land ratified the actions of the peasants who throughout Russia seized private land and redistributed it among themselves. The Bolsheviks viewed themselves as representing an alliance of workers and peasants and memorialized that understanding with the Hammer and Sickle on the flag and coat of arms of the Soviet Union.
Other decrees:
Bolshevik-led attempts to seize power in other parts of the Russian Empire were largely successful in Russia proper — although the fighting in Moscow lasted for two weeks — but they were less successful in ethnically non-Russian parts of the Empire, which had been clamoring for independence since the February Revolution. For example, the Ukrainian Rada, which had declared autonomy on 23 June 1917, created the Ukrainian People's Republic on 20 November, which was supported by the Ukrainian Congress of Soviets. This led to an armed conflict with the Bolshevik government in Petrograd and, eventually, a Ukrainian declaration of independence from Russia on 25 January 1918. In Estonia, two rival governments emerged: the Estonian Provincial Assembly proclaimed itself the supreme legal authority of Estonia on 28 November 1917 and issued the Declaration of Independence on 24 February 1918, while an Estonian Bolshevik sympathizer, Jaan Anvelt, was recognized by Lenin's government as Estonia's leader on 8 December, although forces loyal to Anvelt controlled only the capital.
The success of the October Revolution transformed the Russian state into a soviet republic. A coalition of anti-Bolshevik groups attempted to unseat the new government in the Russian Civil War from 1918 to 1922.
In an attempt to intervene in the civil war after the Bolsheviks' separate peace with the Central Powers, the Allied powers (United Kingdom, France, United States and Japan) occupied parts of the Soviet Union for over two years before finally withdrawing . The United States did not recognize the new Russian government until 1933. The European powers recognized the Soviet Union in the early 1920s and began to engage in business with it after the New Economic Policy (NEP) was implemented.
Historiography.
Few events in historical research have been as conditioned by political influences as the October Revolution. The historiography of the Revolution generally divides into three camps: the Soviet-Marxist view, the Western-Totalitarian view, and the Revisionist view.
Soviet historiography.
Soviet historiography of the October Revolution is intertwined with Soviet historical development. Many of the initial Soviet interpreters of the Revolution were themselves Bolshevik revolutionaries. After the initial wave of revolutionary narratives, Soviet historians worked within "narrow guidelines" defined by the Soviet government. The rigidity of interpretive possibilities reached its height under Joseph Stalin.
Soviet historians of the October Revolution interpreted the Revolution so as to establish the legitimacy of Marxist ideology, and also the Bolshevik regime. To establish the accuracy of Marxist ideology, Soviet historians generally described the Revolution as the product of class struggle. They maintained that the Revolution was the supreme event in a world history governed by historical laws. The Bolshevik Party is placed at the center of the Revolution, exposing the errors of both the moderate Provisional Government and the spurious "socialist" Mensheviks in the Petrograd Soviet. Guided by Vladimir Lenin's leadership and his firm grasp of scientific Marxist theory, the Party led the "logically predetermined" events of the October Revolution from beginning to end. The events were, according to these historians, logically predetermined because of the socio-economic development of Russia, where the monopoly industrial capitalism alienated the masses. In this view, the Bolshevik party took the leading role in organizing these alienated industrial workers, and thereby established the construction of the first socialist state.
Although Soviet historiography of the October Revolution stayed relatively constant until 1991, it did undergo some changes. Following Stalin’s death, historians such as E. N. Burdzhalov and P. V. Volobuev published historical research that deviated significantly from the party line in refining the doctrine that the Bolshevik victory "was predetermined by the state of Russia’s socio-economic development". These historians, who comprised the "New Directions Group", posited that the complex nature of the October Revolution "could only be explained by a multi-causal analysis, not by recourse to the mono-causality of monopoly capitalism". For them, the central actor is still the Bolshevik party, but this party triumphed "because it alone could solve the preponderance of ‘general democratic’ tasks the country faced" (such as the struggle for peace, the exploitation of landlords, and so on.)
During the late Soviet period, the opening of select Soviet archives during glasnost sparked innovative research that broke away from some aspects of Marxism–Leninism, though the key features of the orthodox Soviet view remained intact.
Western historiography.
During the Cold War, Western historiography of the October Revolution developed in direct response to the assertions of the Soviet view. The Soviet version of the October Revolution conditioned historical interpretations in the United States and the West. As a result, these Western historians exposed what they considered flaws in the Soviet view, thereby undermining the Bolsheviks' original legitimacy, as well as the precepts of Marxism.
These Western historians presented the revolution as the result of a chain of contingent accidents. Examples of these accidental and contingent factors that precipitated the Revolution include World War I's timing, chance, and the poor leadership of Tsar Nicholas II as well as liberal and moderate socialists. According to this historical interpretation, it was not popular support, but rather Bolshevik manipulation of the masses and the organization’s ruthlessness and superior structure which enabled it to survive. For these historians, the Bolsheviks’ defeat in the Constituent Assembly elections of November–December 1917 demonstrated popular opposition to the Bolsheviks’ coup, as did the scale and breadth of the Civil War.
These historians saw the organization of the Bolshevik party as proto-totalitarian. Their interpretation of the October Revolution as a violent coup organized by a proto-totalitarian party reinforced the idea that totalitarianism is an inherent part of Soviet history. For them, Stalinist totalitarianism developed as a natural progression from Leninism and the Bolshevik party’s tactics and organization.
Impact of the dissolution of the USSR on historical research.
The dissolution of the USSR had an impact on historical interpretations of the October Revolution. Since 1991, increasing access to large amounts of Soviet archival materials made it possible to re‑examine the October Revolution. Though both Western and Russian historians now have access to many of these archives, the impact of the dissolution of the USSR can be seen most clearly in the work of historians in the former USSR. While the disintegration essentially helped solidify the Western and Revisionist views, post-USSR Russian historians largely repudiated the former Soviet historical interpretation of the Revolution. In other words, the established Soviet view of the October Revolution has been challenged, and consequently "Russian historians’ outlook has come closer to that of their Western confreres." As Stephen Kotkin argues, 1991 prompted "a return to political history and the apparent resurrection of totalitarianism, the interpretive view that, in different ways…revisionists sought to bury". In other words, after 1991, there has been the revival among some historians of the "continuity thesis", the idea that there was an uncomplicated, natural evolution from the October Revolution’s organizational structure to Stalin’s Gulags.
Legacy.
The term "Red October" (Красный Октябрь, Krasnyy Oktyabr) has also been used to describe the events of the month. This name has in turn been lent to a steel factory made notable by the Battle of Stalingrad, a Moscow sweets factory that is well known in Russia, and a fictional Soviet submarine.
"Ten Days That Shook the World", a book written by American journalist John Reed and first published in 1919, gives a firsthand exposition of the events. Reed died in 1920, shortly after the book was finished.
Dmitri Shostakovich wrote his Symphony No. 2 in B major, Op. 14 and subtitled "To October", for the 10th anniversary of the October Revolution. The choral finale of the work, "To October", is set to a text by Alexander Bezymensky, which praises Lenin and the revolution. The Symphony No. 2 was first performed by the Leningrad Philharmonic Orchestra and the Academy Capella Choir under the direction of Nikolai Malko, on 5 November 1927.
Sergei Eisenstein and Grigori Aleksandrov's film "", first released on 20 January 1928 in the USSR and on 2 November 1928 in New York City, describes and glorifies the revolution and was commissioned to commemorate the event.
7 November, the anniversary of the October Revolution, was the official national day of the Soviet Union from 1918 onward and still is a public holiday in Belarus, Kyrgyzstan, and the breakaway territory of Transnistria.
The October revolution of 1917 also marks the inception of the first communist government in Russia, and thus the first large-scale socialist state in world history. After this Russia became the Russian SFSR and later part of the USSR, which dissolved in late 1991.
References.
</dl>

</doc>
<doc id="22665" url="http://en.wikipedia.org/wiki?curid=22665" title="Opole Voivodeship">
Opole Voivodeship

Opole Voivodeship, or Opole Province (Polish: "województwo opolskie" ]; German: "Woiwodschaft Opole" or "Woiwodschaft Oppeln"; Czech: "Opolské vojvodství" ]), is a Polish voivodeship, or province, created on January 1, 1999, out of the former Opole Voivodeship and parts of Częstochowa Voivodeship, pursuant to the Polish local government reforms adopted in 1998. The province's name derives from that of the region's capital and largest city, Opole. It is part of Silesia, and the territorial successor of the former German Upper Silesia, which had the same city — then Oppeln — as its capital. Almost all of the present territory was part of Germany except for the two Gminas of Praszka and Rudniki. A relatively large German minority lives in the voivodeship, with representatives in the Sejm.
Opole Voivodeship is bordered by Lower Silesian Voivodeship to the west, Greater Poland and Łódź Voivodeships to the north, Silesian Voivodeship to the east, and the Czech Republic to the south.
Opole Province's geographic location, economic potential, and its population's level of education make it an attractive business partner for other Polish regions (especially Lower Silesian and Silesian Voivodeships) and for foreign investors. Formed in 1997, the Praděd/Pradziad Euroregion has facilitated economic, cultural and tourist exchanges between the border areas of Poland and the Czech Republic.
Geography.
The voivodeship lies in southwestern Poland, the major part on the Silesian Lowland ("Nizina Śląska"). To the east, the region touches upon the Silesian Upland (Silesian Uplands, "Wyżyna Śląska") with the famous Saint Anne Mountain; the Sudetes range, the Opawskie Mountains, lies to the southwest. The Oder River cuts across the middle of the voivodeship. The northern part of the voivodeship, along the Mała Panew River, is densely forested, while the southern part consists of arable land.
History.
Until 1945 virtually all of the present Polish voivodeship was part of the Prussian province of "Upper Silesia". The two Gminas of Praszka and Rudniki were already part of Poland in 1939, and were previously part of Russian Congress Poland until 1918. After World War II Silesia was annexed by Poland as a result of the Allied Powers agreement on the realignment of Eastern European states that had been reached at the Yalta Conference (February 1945). The Opole region was originally merged with the pre-existing Polish Silesian Voivodeship, until in 1950 it regained its status as a region, thanks to a reform of Polish regions. The towns of Brzeg and Namysłów were later transferred to Opole from the neighbouring Lower Silesian Voivodeship. As the result of a third regional shake-up in 1975 the voivodeship was broken up and Racibórz was transferred to the new Katowice Voivodeship while a part of Olesno was given up to the Częstochowa Voivodeship.
Finally, as the result of a 1999 land reform; the objective of which was to restore the historical voivodeships of Poland, the Opole Voivodeship as we know it today came into being. Originally, the government, advised by prominent historians, had wanted to disestablish Opolskie and partition its territory between the more historically 'Polish' regions of Lower Silesia and Silesia. The plan was that Brzeg and Namysłów, as the Western part of the region, were to be transferred to Lower Silesia, while the rest was to become, along with a part of the Częstochowa Voivodeship, an integral part of the new 'Silesian' region. However, the plans resulted in an outcry from the German minority population of Opolskie, who feared that should their region be abolished, they would lose all hope of regional representation (in the proposed Silesian Region, they would have formed a very small minority among a great number of ethnic Poles). To the surprise of many of the ethnic Germans in Opole however, the local Polish Silesian population and groups of ethnic Poles also rose up to oppose the planned reforms; this came about as a result of an overwhelming feeling of attachment to the voivodeships that were scheduled to be 'redrawn', as well as a fear of 'alienation' should one find themselves residing in a new, unfamiliar region.
The solution came in late 1999, when Olesno was, after 24 years apart, finally reunited with the Opole Voivodeship to form the new legally defined region. A historic moment came in 2006 when the town of Radłów changed its local laws to make German, alongside Polish, the district's second official language; thus becoming the first town in the region to achieve such a feat.
Demographics.
The Opole Voivodeship is the smallest region in the administrative makeup of the country in terms of both area and population. 
About 15% of the one million inhabitants of this voivodeship are ethnic Germans, which constitutes 90% of all ethnic Germans in Poland. As a result, many areas are officially bilingual in Opolskie, and the German language and culture play a significant role in education in the region. 
Tourism.
The Opole voivodeship is a green region with three large lakes: Turawskie, Nyskie, and Otmuchowskie (the latter two are connected). The Opawskie Mountains are extremely popular. The region also includes the castle in Brzeg, built during the reign of the Piast dynasty—pearl of the Silesian Renaissance, the Franciscan monastery on top of Saint Anne Mountain, as well as the medieval defence fortifications in Paczkow (referred to as the Polish Carcassonne).
The region has the warmest climate in the country.
Protected areas in Opole Voivodeship include the following three areas designated as Landscape Parks:
Transportation.
The transport route from Germany to Ukraine runs through Opole. The region has four border crossings, and direct rail connections to all important Polish cities, as well as to Frankfurt, Munich, Budapest, Kiev, and the Baltic ports.
Cities and towns.
The voivodeship contains 35 cities and towns. These are listed below in descending order of population (according to official figures for 2006):
Administrative division.
Opole Voivodeship is divided into 12 counties (powiats): 1 city county and 11 land counties. These are further divided into 71 gminas.
The counties are listed in the following table (ordering is by decreasing population).
Economy.
The Opole voivodeship is an industrial as well as an agricultural region. With respect to mineral resources, of major importance are deposits of raw materials for building: limestone (Strzelce Opolskie), marl (near Opole), marble, and basalt. The favourable climate, fertile soils, and high farming culture contribute to the development of agriculture, which is among the most productive in the country.
A total of nineteen industries are represented in the voivodeship. The most important are cement and lime, furniture, food, car manufacturing, and chemical industries. In 1997, the biggest production growth in the area was in companies producing wood and wood products, electrical equipment, machinery and appliances, as well as cellulose and paper products. In 1997, the top company in the region was Zakłady Azotowe S.A. in Kędzierzyn-Koźle, whose income was over PLN 860 million. The voivodship's economy consists of more than 53,000 businesses, mostly small and medium-sized, employing over 332,000 people. Manufacturing companies employ over 89,000 people; 95.7% of all the region's business operate in the private sector.
Universities.
There are three state-run universities in the region: the Opole University, the Opole University of Technology, and the State Medical College. All of them are based in the voivodeship's capital. Among the region's private schools, the Opole School of Management and Administration has been certified as a degree-granting institution by the Ministry of National Education.
Previous Opole voivodeships.
Opole Voivodeship was also a unit of administrative division and local government in Poland between 1975 and 1998.
Major cities and towns (population in 1995):
Opole Voivodeship (1950–1975).
This administrative region of the People's Republic of Poland (1950–1975) was created as a result of the partition of Katowice Voivodeship in 1950.

</doc>
<doc id="22666" url="http://en.wikipedia.org/wiki?curid=22666" title="Old Norse">
Old Norse

Old Norse is a North Germanic language that was spoken by inhabitants of Scandinavia and inhabitants of their overseas settlements during the Viking Age, until about 1300.
The Proto-Norse language developed into Old Norse by the 8th century, and Old Norse began to develop into the modern North Germanic languages in the mid- to late 14th century, ending the language phase known as Old Norse. These dates, however, are not absolute, since written Old Norse is found well into the 15th century.
Old Norse was divided into three dialects: Old East Norse, Old West Norse, and Old Gutnish. Old West and East Norse formed a dialect continuum, with no clear geographical boundary between them. For example, Old East Norse traits were found in eastern Norway, although Old Norwegian is classified as Old West Norse, and Old West Norse traits were found in western Sweden. Most speakers spoke Old East Norse in what is present day Denmark and Sweden. Old Gutnish, the more obscure dialectal branch, is sometimes included in the Old East Norse dialect due to geographical associations. It developed its own unique features and shared in changes to both other branches.
The 12th-century Icelandic "Gray Goose Laws" state that Swedes, Norwegians, Icelanders and Danes spoke the same language, "dǫnsk tunga" ("Danish tongue"; speakers of Old East Norse would have said "dansk tunga"). Another commonly used term with reference to West Norse, was "norrœnt mál" ("Nordic speech"). Today Old Norse has developed into the modern North Germanic languages (Icelandic, Faroese, Norwegian, Danish and Swedish), which retain considerable mutual intelligibility.
In some instances the term "Old Norse" refers specifically to Old West Norse.
Geographical distribution.
Old Icelandic was basically identical to Old Norwegian, and together they formed the Old West Norse dialect of Old Norse, which was also spoken in settlements in Ireland, Scotland, the Isle of Man and north-west England, and Norwegian settlements in Normandy. The Old East Norse dialect was spoken in Denmark, Sweden, settlements in Kievan Rus', eastern England, and Danish settlements in Normandy. The Old Gutnish dialect was spoken in Gotland and in various settlements in the East. In the 11th century, Old Norse was the most widely spoken European language, ranging from Vinland in the West to the Volga in the East. In Kievan Rus', it survived the longest in Novgorod, probably lasting into the 13th century there. The age of the Swedish language's presence in Finland is strongly contested (see Swedish-speaking Finns), but at latest by the time of the Second Swedish Crusade in the 13th century, Swedish settlement spread the language into the region.
Modern descendants.
The modern descendants of the Old West Norse dialect are the West Scandinavian languages of Icelandic, Faroese, Norwegian and the extinct Norn language of the Orkney and the Shetland Islands; the descendants of the Old East Norse dialect are the East Scandinavian languages of Danish and Swedish. Norwegian is descended from Old West Norse, but over the centuries it has been heavily influenced by East Norse, particularly during the Denmark–Norway union.
Among these, Icelandic and the closely related Faroese have changed the least from Old Norse in the last thousand years, although with Danish rule of the Faroe Islands, Faroese has also been influenced by Danish. Old Norse also had an influence on English dialects and Lowland Scots, which contain many Old Norse loanwords. It also influenced the development of the Norman language, and through it and to a smaller extent, that of modern French.
Various other languages, which are not closely related, have been heavily influenced by Norse, particularly the Norman dialects, Scottish Gaelic and Waterford Irish. Russian, Belarusian, Lithuanian, Finnish, Latvian and Estonian also have a number of Norse loanwords; the words "Rus" and "Russia", according to one theory, may be named after the Rus' people, a Norse tribe; "see Rus (name)", probably from present-day east-central Sweden. The current Finnish and Estonian words for Sweden are "Ruotsi" and "Rootsi", respectively.
Of the modern languages, Icelandic is the closest to Old Norse. Written modern Icelandic derives from the Old Norse phonemic writing system. Contemporary Icelandic-speakers can read Old Norse, which varies slightly in spelling as well as semantics and word order. However, pronunciation, particularly of the vowel phonemes, has changed at least as much as in the other North Germanic languages.
Faroese retains many similarities but is influenced by Danish, Norwegian, and Gaelic (Scottish and/or Irish). Although Swedish, Danish and the Norwegian languages have diverged the most, they still retain asymmetric mutual intelligibility. Speakers of modern Swedish, Norwegian and Danish can mostly understand each other without studying their neighboring languages, particularly if speaking slowly. The languages are also sufficiently similar in writing that they can mostly be understood across borders. This could be because these languages have been mutually affected by each other, as well as having a similar development influenced by Middle Low German.
Phonology.
Vowels.
The vowel phonemes mostly come in pairs of long and short. The standardized orthography marks the long vowels with an acute accent. In medieval manuscripts, it is often unmarked but sometimes marked with an accent or through gemination. All phonemes have, more or less, the expected phonetic realization.
Old Norse had nasalized versions of all nine vowel places. These occurred as allophones of the vowels before nasal consonants and in places where a nasal had followed it in an older form of the word, before it was absorbed into a neighboring sound. If the nasal was absorbed by a stressed vowel, it would also lengthen the vowel. These nasalizations also occurred in the other Germanic languages, but were not retained long. They were noted in the First Grammatical Treatise, and otherwise might have remained unknown. The First Grammarian marked these with a dot above the letter. This notation did not catch on, and would soon be obsolete. Nasal and oral vowels probably merged around the 11th century in most of Old East Norse.:3 However, the distinction still holds in Dalecarlian dialects.:4 The dots in the following vowel table separate the oral from nasal phonemes.
Note: The low/low-mid vowels may be indicated differently:
Sometime around the 13th century, Ǫ (/ɔ/) merged with Ø or O in all dialects except Old Danish. In Icelandic, all Ǫ merged with Ø. This can be determined by their distinction within the 12th-century First Grammatical Treatise but not within the early 13th-century Prose Edda. The nasals, also noted in the First Grammatical Treatise, are assumed to have been lost by this time. See Old Icelandic for the Œ > Æ and Ę > E mergers.
Consonants.
Old Norse has six plosive phonemes. Of these /p/ is rare word-initially and /d/ and /b/ are realized as voiced fricative allophones between vowels, except in compound words (e.g. veðrabati), already in the Proto-Germanic language (e.g. "*b" *[β] > [v] between vowels). The /ɡ/ phoneme is realized as [ɡ] after an "n" or another "g" and as [k] before /s/ and /t/. It is realized as a voiced velar fricative [ɣ], by some accounts inside words, and by others between vowels (and otherwise as [ɡ]). The Old East Norse /ʀ/ was an apical consonant whose position isn't precisely known, being reconstructed as a palatal sibilant:2. It descended from Proto-Germanic /z/ and eventually developed into /r/, as it already had done in Old West Norse.
The consonant digraphs "hl", "hr", "hn" occurred word-initially. It is unclear whether they were sequences of two consonants (with the first element realised as /h/ or perhaps /x/), or as single voiceless sonorants /l̥/, /r̥/ and /n̥/ respectively. In Old Norwegian, Old Danish and later Old Swedish the groups "hl", "hr", "hn" were reduced to plain "l", "r", "n", suggesting that they were most likely realised as voiceless sonorants by Old Norse times.
The pronunciation of "hv" is unclear, and may have been /xʷ/ (the Proto-Germanic pronunciation), /hʷ/ or /ʍ/. Unlike the other three groups above, it was retained much longer in all dialects, and never developed into a voiceless sonorant in Icelandic, but instead "hardened" to a plosive /kv/. This suggests that it was not a voiceless sonorant, but retained stronger frication.
Orthography.
Unlike Proto-Norse, which was written with the Elder Futhark, runic Old Norse was originally written with the Younger Futhark, which only had 16 letters. Because of the limited number of runes, the rune for the vowel "u" was also used for the vowels "o", "ø" and "y", and the rune for "i" was used for "e". Medieval runes came into use some time later.
As for the Latin alphabet, there was no standardized orthography in use in the Middle Ages. A modified version of the letter wynn called vend was used briefly for the sounds /u/, /v/, and /w/. Long vowels were sometimes marked with acutes, but also sometimes left unmarked or geminated. The standardized Old Norse spelling was created in the 19th century, and is for the most part phonemic. The most notable deviation is that the non-phonemic difference between the voiced and the voiceless dental fricative is marked — the oldest texts as well as runic inscriptions use "þ" exclusively. Long vowels are denoted with acutes. Most other letters are written with the same glyph as the IPA phoneme, except as shown in the table below.
Accent.
Primary stress in Old Norse falls on the word stem, so that "hyrjar" would be pronounced /ˈhyr.jar/. In compound words, secondary stress falls on the second stem (e.g. "lærisveinn", /ˈlɛːɾ.iˌswɛinː/).:1
Modern Swedish, Danish, and Norwegian have two registers reflected in differing pronunciation of the stressed syllable of words. In Swedish and Norwegian, the registers are reflected in different tones (i.e. through tonal word accent), while in Danish the difference is the presence or absence of "stød", a glottal gesture considered a kind of creaky voice that seems to have been documented by Swedish sources as early as the 16th century. What is here called "class 1" is reflected as tone 1 in Norwegian, acute accent in Swedish, and presence of "stød" in Danish, whereas "class 2" words have tone 2 in Norwegian, grave accent in Swedish, and no "stød" in Danish. No sign of any tonal system is found in Icelandic or Faroese.
Not all cognates occur in the same register classes in all three languages, partly due to language-specific restrictions on the contexts in which the two classes can occur. For example, "stød" can only occur in stressed words that have long vowels and end in a voiced consonant, whereas in Swedish and Norwegian, monosyllables can only take tone 1/acute accent. In general, however, class 1 words are those that are monosyllabic in Old Norse, while class 2 words are those that are polysyllabic. Exceptions, including minimal pairs, have arisen for various reasons:
Phonological processes.
Ablaut.
Ablaut patterns are groups of vowels which are swapped, or ablauted, in the nucleus of a word. Strong verbs ablaut the lemma's nucleus to derive the past forms of the verb. This parallels English conjugation, where, e.g., the nucleus of "sing" becomes "sang" in the past tense and "sung" in the past participle. Some verbs are derived by ablaut, as the present-in-past verbs do by consequence of being derived from the past tense forms of strong verbs.
Umlaut.
Umlaut or mutation is an assimilatory process acting on vowels preceding a vowel or semivowel of a different vowel backness. In the case of i-umlaut and ʀ-umlaut, this entails a fronting of back vowels, with retention of lip rounding. In the case of u-umlaut, this entails labialization of unrounded vowels. Umlaut is phonemic and in many situations grammatically significant as a side effect of losing the Proto-Germanic morphological suffixes whose vowels created the umlaut allophones.
Some /y/, /yː/, /ø/, /øː/, /ɛ/, /ɛː/, /øy/, and /ɛi/ were obtained by i-umlaut from /u/, /uː/, /o/, /oː/, /a/, /aː/, /au/, and /ai/ respectively. Others were formed via ʀ-umlaut from /u/, /uː/, /a/, /aː/, and /au/.
Some /y/, /yː/, /ø/, /øː/, and all /ɔ/, /ɔː/ were obtained by u-umlaut from /i/, /iː/, /e/, /eː/, and /a/, /aː/ respectively. See Old Icelandic for information on /ɔː/.
/œ/ was obtained through a simultaneous u- and i-umlaut of /a/. It appears in words like gøra (gjǫra, geyra), from Proto-Germanic *garwijaną, and commonly in verbs with a velar consonant before the suffix like søkkva < *sankwijaną.
OEN often preserves the original value of the vowel directly preceding runic "ʀ" while OWN receives ʀ-umlaut. Compare runic OEN "glaʀ, haʀi, hrauʀ" with OWN "gler, heri" (later "héri"), "hrøyrr/hreyrr" ("glass", "hare", "pile of rocks").
U-umlaut.
U-umlaut is more common in Old West Norse in both phonemic and allophonic positions, while it only occurs sparsely in post-runic Old East Norse and even in runic Old East Norse. Compare West Old Norse "fǫður" (accusative of "faðir", father), "vǫrðr" (guardian/caretaker), "ǫrn" (eagle), "jǫrð" (in Modern Icelandic: "jörð", earth), "mjǫlk" (in Modern Icelandic: "mjólk") with Old Swedish "faður", "varðer", "örn", "jorð" and Modern Swedish "örn", "jord", "mjölk" with the latter two demonstrating the u-umlaut found in Swedish.
This is still a major difference between Swedish and Faroese and Icelandic today. Plurals of neuters do not have u-umlaut at all in Swedish (in Danish they do in "barn", cf. Swedish "barn"), but in Faroese and Icelandic they do, for example the Faroese and Icelandic plurals of the word "land": "lond" and "lönd" in contrast to the Swedish plural "land" and other numerous examples. That also applies to almost all feminine nouns, for example the largest feminine noun group, the o-stem nouns (except the Swedish noun "jord" mentioned above), and even i-stem nouns and rootnomina, such as Old West Norse "mǫrk" ("" in Icelandic) in comparison with Modern and Old Swedish "mark".
Breaking.
Vowel breaking, or fracture, caused a front vowel to be split into a semivowel-vowel sequence before a back vowel in the following syllable. While West Norse only broke "e", East Norse also broke "i". The change was blocked by a "v", "l", or "r" preceding the potentially-broken vowel.:1
Some /ja/ or /jɔ/ and /jaː/ or /jɔː/ result from breaking of /e/ and /eː/ respectively.
Assimilation or elision of inflectional ʀ.
When a noun, pronoun, adjective, or verb has a long vowel or diphthong in the accented syllable and its stem ends in a single -l, -n, or -s, the -r (or the elder r- or z-variant ʀ) in an ending is assimilated. When the accented vowel is short, the ending is dropped.
The nominative of the strong masculine declension and some i-stem feminine nouns uses one such -r (ʀ). "Óðin"-"r" ("Óðin"-"ʀ") becomes "Óðinn" instead of "*Óðinr" ("*Óðinʀ"), but "karl"-r ("karl"-"ʀ") remains "karl".
"Blása", to blow, has "blæss" for "you blow" instead of "*blæsr" ("*blæsʀ").
The rule is not hard and fast, with counter-examples such as "vinr", which has the synonym "vin", yet retains the unabsorbed version, and "jǫtunn", where assimilation takes place even though the root vowel, Ǫ, is short.
Words with a final r in the word stem, such as "vetr", do not add another -r, as the sounds are already the same. The effect of the dropping usually results in the lack of distinction between some forms of the noun. In the case of "vetr" the dropping renders the nominative and accusative singular and plural identical; the nominative singular and nominative and accusative plural would otherwise have been "*vetrr" ("*vintrʀ"), while the accusative singular would still have been "vetr". This is because the 3rd strong masculine declension, to which it belongs, marks the nominative singular and nominative and accusative plural, but not the accusative singular, with inflectional Rs.
Phonotactics.
Blocking of ii, uu.
"I/j" adjacent to "i", "e", their u-umlauts, and "æ" was not possible, nor "u/v" adjacent to "u", "o", their i-umlauts, and ǫ. At the beginning of words, this manifested as a dropping of the initial "i/j" or "u/v". Compare ON "orð, úlfr" with English "word, wolf". In inflections, this manifested as the dropping of the inflectional vowels. Thus, "klæði" + ᴅᴀᴛ "-i" remains "klæði", and "sjáum" in Icelandic progressed to "sjǫ́um" > "sjǫ́m" > sjám. The "jj" and "vv" of Proto-Germanic became "ggj" and "ggw" respectively in Old Norse, a change known as Holtzmann's law.
Epenthesis.
An epenthetic vowel became popular by 1200 in Old Danish, 1250 in Old Swedish and Norwegian, and 1300 in Old Icelandic. An unstressed vowel was used which varied by dialect. Old Norwegian exhibited all three: /u/ was used in West Norwegian south of Bergen, as in "aftur", "aftor" (older aptr); North of Bergen, /i/ appeared in "aftir", "after"; and East Norwegian used /a/, "after", "aftær".
Syntax.
Old Norse had a freer word order than English. Old Norse used different listing structures than the English, "a, b and c," and, "a, b or c." In those two cases, Old Norse would have, "a and b and c," or, "a and b or c."
Grammar.
Old Norse was a moderately inflected language with high levels of nominal and verbal inflection. Most of the fused morphemes are retained in modern Icelandic, especially in regard to noun case declensions, whereas modern Norwegian in comparison has moved towards more analytical word structures.
Gender.
Old Norse had three grammatical genders – masculine, feminine or neuter. Adjectives or pronouns referring to a noun must mirror the gender of that noun, so that one says, "heill maðr!" but, "heilt barn!" Like in other languages, the grammatical gender of an impersonal noun is generally unrelated to an expected natural gender of that noun. While indeed "karl", "man" is masculine, "kona", "woman", is feminine, and "hús", house, is neuter, so also are "hrafn" and "kráka", for "raven" and "crow", masculine and feminine respectively, even in reference to a female raven or a male crow.
All neuter words have identical nominative and accusative forms, and all feminine words have identical nominative and accusative plurals.
The gender of some words' plurals does not agree with that of their singulars, such as "lim" and "mund". Some words, such as "hungr", have multiple genders, evidenced by their determiners being declined in different genders within a given sentence.
Hierarchy.
Old Norse inherited the Proto-Germanic feature of having neuter as the default gender. This means that when the gender of a noun is unknown, adjectives and pronouns referencing it use the neuter gender forms, rather than the masculine or feminine. Thus, if speaking or writing to a general audience, one would say "velkomit", "well is it come," rather than "velkominn" or "velkomin", "well is [he or she] come," as one does not know whether the person hearing it is going to be male or female.
One generally sees adjectives in their neuter form when used pronominally for this reason. For words more commonly used in this way (rather than to describe a noun) one sees their neuter forms more often than their masculine or feminine. Normally the masculine form would be the most beneficial form of an adjective to learn first, given that the majority of nouns are masculine. In these cases, however, the most practical form to learn first would be the neuter.
Morphology.
Nouns, adjectives and pronouns were declined in four grammatical cases — nominative, accusative, genitive and dative, in singular and plural numbers. Adjectives and pronouns were additionally declined in three grammatical genders. Some pronouns (first and second person) could have dual number in addition to singular and plural. The genitive is used partitively, and quite often in compounds and kennings (e.g.: "Urðarbrunnr", the well of Urðr; "Lokasenna", the gibing of Loki).
There were several classes of nouns within each gender, the following is an example of the "strong" inflectional paradigms:
In addition to these examples there were the numerous "weak" noun paradigms, which had a much higher degree of syncretism between the different cases in its paradigms, i.e. they didn't have as many forms as the "strong" nouns.
A definite article was realised as a suffix, that retained an independent declension e.g. troll ("a troll") – trollit ("the troll"), hǫll (" a hall") – hǫllin ("the hall"), armr ("an arm") – armrinn ("the arm"). This definite article, however, was a separate word, and did not become attached to the noun before later stages of the Old Norse period.
Texts.
The earliest inscriptions in Old Norse are runic, from the 8th century. Runes continued to be commonly used until the 15th century and have been recorded to be in use in some form as late as the 19th century in some parts of Sweden. With the conversion to Christianity in the 11th century came the Latin alphabet. The oldest preserved texts in Old Norse in the Latin alphabet date from the middle of the 12th century. Subsequently, Old Norse became the vehicle of a large and varied body of vernacular literature, unique in medieval Europe. Most of the surviving literature was written in Iceland. Best known are the Norse sagas, the Icelanders' sagas and the mythological literature, but there also survives a large body of religious literature, translations into Old Norse of courtly romances, classical mythology, and the Old Testament, as well as instructional material, grammatical treatises and a large body of letters and official documents.
Dialects.
Most of the innovations that appeared in Old Norse spread evenly through the Old Norse area. As a result, the dialects were very similar and considered to be the same language, a language that they sometimes called the Danish tongue ("Dǫnsk tunga"), sometimes Norse language ("Norrœnt mál"), as evidenced in the following two quotes from Heimskringla by Snorri Sturluson:
"Móðir Dyggva var Drótt, dóttir Danps konungs, sonar Rígs er fyrstr var konungr kallaðr á danska tungu".
Dyggvi's mother was Drott, the daughter of king Danp, Ríg's son, who was the first to be called king in the Danish tongue.
"...stirt var honum norrœnt mál, ok kylfdi mᴊǫk til orðanna, ok hǫfðu margir menn þat mᴊǫk at spotti".
...the Norse language was hard for him, and he often fumbled for words, which amused people greatly.
However, some changes were geographically limited and so created a dialectal difference between Old West Norse and Old East Norse.
As Proto-Norse evolved into Old Norse, in the 8th century, the effects of the umlauts seem to have been very much the same over the whole Old Norse area. But in later dialects of the language a split occurred mainly between west and east as the use of umlauts began to vary. The typical umlauts (for example "fylla" from *"fullijan") were better preserved in the West due to later generalizations in the east where many instances of umlaut were removed (many archaic Eastern texts as well as eastern runic inscriptions however portray the same extent of umlauts as in later Western Old Norse).
All the while, the changes resulting in breaking (for example "hiarta" from *"hertō") were more influential in the East probably once again due to generalizations within the inflectional system. This difference was one of the greatest reasons behind the dialectalization that took place in the 9th and 10th centuries, shaping an Old West Norse dialect in Norway and the Atlantic settlements and an Old East Norse dialect in Denmark and Sweden.
Old West Norse and Old Gutnish did not take part in the monophthongization which changed "æi" ("ei") into "ē", "øy" ("ey") and "au" into "ø̄", nor did certain peripheral dialects of Swedish, as seen in modern Ostrobothnian. Another difference was that Old West Norse lost certain combinations of consonants. The combinations -"mp"-, -"nt"-, and -"nk"- were assimilated into -"pp"-, -"tt"- and -"kk"- in Old West Norse, but this phenomenon was limited in Old East Norse.
Here is a comparison between the two dialects as well as Old Gutnish. It is a transcription from one of the Funbo Runestones (U 990) meaning : "Veðr and Thane and Gunnar raised this stone after Haursi, their father. God help his spirit":
The OEN original text above is transliterated according to traditional scholarly methods, wherein u-umlaut is not regarded in runic Old East Norse. Modern studies have shown that the positions where it applies are the same as for runic Old West Norse. An alternative and probably more accurate transliteration would therefore render the text in OEN as such:
Some past participles and other words underwent i-umlaut in Old West Norse but not in Old East Norse dialects. Examples of that are Icalandic slegið/sleginn and tekið/tekinn, which in Swedish are slagit/slagen and tagit/tagen. This can also be seen in the Icelandic and Norwegian words sterkur and sterk ("strong"), which in Swedish is stark as in Old Swedish. These differences can also be seen in comparison between Norwegian and Swedish.
Old West Norse.
The combinations -mp-, -nt-, and -nk- mostly merged to -pp-, -tt- and -kk- in Old West Norse at around the 7th century, marking the first distinction between the Eastern and Western dialects.:3 The following table illustrates this (Note the influence of East-West Norse on each other) :
An early difference between Old West Norse and the other dialects was that Old West Norse had the forms "bú" ‘dwelling’, "kú" ‘cow’ (accusative) and "trú" ‘faith’ whereas Old East Norse had "bó", "kó" and "tró". Old West Norse was also characterized by the preservation of "u"-umlaut, which meant that for example Proto-Norse *"tanþu" ‘tooth’ was pronounced "tǫnn" and not "tann" as in post-runic Old East Norse; OWN "gǫ́s" and runic OEN "gǫ́s", while post-runic OEN "gás" ‘goose’.
The earliest body of text appears in runic inscriptions and in poems composed ca 900 by Þjóðólfr of Hvinir. The earliest manuscripts are from the period 1150–1200 and concern both legal, religious and historical matters. During the 12th and 13th centuries, Trøndelag and Western Norway were the most important areas of the Norwegian kingdom and they shaped Old West Norse as an archaic language with a rich set of declensions. In the body of text that has come down to us from until ca 1300, Old West Norse had little dialect variation, and Old Icelandic does not diverge much more than the Old Norwegian dialects do from each other.
Old Norwegian differentiated early from Old Icelandic by the loss of the consonant "h" in initial position before "l", "n" and "r", thus whereas Old Icelandic manuscripts might use the form "hnefi" "fist", Old Norwegian manuscripts might use "nefi".
From the late 13th century, Old Icelandic and Old Norwegian started to diverge more. After c. 1350, the Black Death and following social upheavals seem to have accelerated language changes in Norway. From the late 14th century, the language used in Norway is generally referred to as Middle Norwegian.
Old West Norse underwent a lengthening of initial vowels at some point, especially in Norwegian, so that OWN "eta" became "éta," ONW "akr" > "ákr", OIC "ek" > "ék".
Old Icelandic.
In Iceland, initial /w/ before /ɾ/ was lost. Compare Icelandic "rangur" with Norwegian "vrangr", OEN "vrangʀ". This change is shared with Old Gutnish.
A specifically Icelandic sound, the long, u-umlauted A, spelled Ǫ́ and pronounced /ɔː/, developed circa the early 11th century. It was short-lived, being marked in the Grammatical Treatises and remaining until the end of the 12th century.
/w/ merged with /v/ during the 12th century. This caused /v/ to become an independent phoneme from /f/, and the written distinction of ⟨v⟩ for /v/ from medial and final ⟨f⟩ to become merely etymological.
Around the 13th century, Œ/Ǿ (/øː/) merged to Æ (/ɛː/). Thus, pre-13th-century "grœnn" ‘green’ became modern Icelandic "grænn". The 12th-century Grágás manuscripts distinguish the vowels, and so the Codex Regius copy does as well. However, the 13th-century Codex Regius copy of the Poetic Edda probably relied on newer and/or poorer quality sources — Demonstrating either difficulty with or total lack of natural distinction, the manuscripts show separation of the two phonemes in some places, but frequently mix up the letters chosen to distinguish them in others.
Towards the end of the 13th century, Ę (/ɛ/) merged to E (/e/).
Old Norwegian.
Around the 11th century, Old Norwegian ⟨hl⟩, ⟨hn⟩, and ⟨hr⟩ became ⟨l⟩, ⟨n⟩, and ⟨r⟩. It is debatable whether the ⟨hC⟩ sequences represented a consonant cluster, /hC/, or a devoicing, /C̥/.
Orthographic evidence suggests that, in a confined dialect of Old Norwegian, /ɔ/ may have been unrounded before /u/, so that u-umlaut was reversed where the "u" had not been eliminated. e.g. "ǫll", "ǫllum" > "ǫll", "allum".
Greenlandic Norse.
This dialect of Old West Norse was spoken by Icelandic colonies in Greenland. When the colonies died out around the 15th century, the dialect went with it. /θ/, and some /ð/ merged to /t/, so that Old Icelandic Þórðr becomes Tortr.
Text example.
The following text is from "Alexanders saga", an Alexander romance. The manuscript, AM 519 a 4to, is dated c. 1280. The facsimile demonstrates the sigla used by scribes to write Old Norse. Many of these were borrowed from Latin. Without familiarity with these abbreviations, the facsimile will be unreadable to many. In addition, reading the manuscript itself requires familiarity with the letterforms of the native script. The abbreviations are expanded in a version with normalized spelling like the standard normalization system's. Comparing this to the spelling of the same text in Modern Icelandic shows that, while pronunciation has changed greatly, spelling has changed little.
Old East Norse.
Old East Norse, between 800 and 1100, is in Sweden called "Runic Swedish" and in Denmark "Runic Danish". The use of "Swedish" and "Danish" is not for linguistic reasons as the differences between them are minute at best during the more ancient stages of this dialect group. Changes had a tendency to occur earlier in the Danish region and until this day many Old Danish changes have still not taken place in modern Swedish rendering Swedish as the more archaic out of the two concerning both the ancient and the modern languages, sometimes by a profound margin but in all differences are still minute. They are called "runic" because the body of text appears in runes.
Runic Old East Norse is characteristically archaic in form, especially Swedish (which is still true for modern Swedish compared to Danish). In essence it matches or surpasses the archaicness of post-runic Old West Norse which in its turn is generally more archaic than post-runic Old East Norse. While typically "Eastern" in structure, many later post-runic changes and trademarks of EON had yet to happen.
The phoneme "ʀ", which evolved during the Proto-Norse period from "z", was still clearly separated from "r" in most positions, even when being geminated, while in OWN it had already merged with "r".
Monophthongization of "æi > ē" and "øy, au > ø̄" started in mid-10th-century Denmark. Compare runic OEN: "fæigʀ", "gæiʀʀ", "haugʀ", "møydōmʀ", "diūʀ"; with Post-runic OEN: "fēgher", "gēr", "hø̄gher", "mø̄dōmber", "diūr"; OWN: "feigr", "geirr", "haugr", "meydómr", "dýr"; from PN *faigiaz, *gaizaz, *haugaz, *mawi- + dōmaz (maidendom; virginity), *diuza ((wild) animal).
Feminine o-stems often preserve the plural ending -aʀ while in OWN they more often merge with the feminine i-stems: (runic OEN) "*sōlaʀ", "*hafnaʀ"/"*hamnaʀ", "*vāgaʀ" while OWN "sólir", "hafnir" and "vágir" (modern Swedish "solar", "hamnar", "vågar"; suns, havens, scales; Danish has mainly lost the distinction between the two stems with both endings now being rendered as -er or -e alternatively for the o-stems).
Vice versa, masculine i-stems with the root ending in either "g" or "k" tended to shift the plural ending to that of the ja-stems while OWN kept the original: "drængiaʀ", "*ælgiaʀ" and "*bænkiaʀ" while OWN "drengir", "elgir" (elks) and "bekkir" (modern Swedish "drängar", "älgar", "bänkar").
The plural ending of ja-stems were mostly preserved while those of OWN often acquired that of the i-stems: "*bæðiaʀ", "*bækkiaʀ", "*væfiaʀ" while OWN "beðir" (beds), "bekkir", "vefir" (modern Swedish "bäddar", "bäckar", "vävar").
Old Danish.
Until the early 12th century, Old East Norse was very much a uniform dialect. It was in Denmark that the first innovations appeared that would differentiate Old Danish from Old Swedish:3 as these innovations spread north unevenly (unlike the earlier changes that spread more evenly over the East Norse area) creating a series of isoglosses going from Zealand to Svealand.
In Old Danish, /hɾ/ merged with /ɾ/ during the 9th century. From the 11th to 14th centuries, the unstressed vowels -"a", -"o" and -"e" (standard normalization -"a", -"u" and -"i") started to merge into -"ə", represented with the letter "e". This vowel came to be epenthetic, particularly before "-ʀ" endings. At the same time, the voiceless stop consonants "p", "t" and "k" became voiced plosives and even fricative consonants. Resulting from these innovations, Danish has "kage" (cake), "tunger" (tongues) and "gæster" (guests) whereas (Standard) Swedish has retained older forms, "kaka", "tungor" and "gäster" (OEN "kaka", "tungur", "gæstir").
Moreover, the Danish pitch accent shared with Norwegian and Swedish changed into "stød" around this time.
Old Swedish.
At the end of the 10th and early 11th century initial "h-" before "l", "n" and "r" was still preserved in the middle and northern parts of Sweden, and is sporadically still preserved in some northern dialects as "g-", e.g. "gly" (lukewarm), from "hlýʀ". The Dalecarlian dialects developed as Old Swedish dialects and as such can be considered separate languages from Swedish.
Text example.
This is an extract from "Västgötalagen", the Westrogothic law. It is the oldest text written as a manuscript found in Sweden and from the 13th century. It is contemporaneous with most of the Icelandic literature. The text marks the beginning of Old Swedish as a distinct dialect.
Dræpær maþar svænskan man eller smalenskæn, innan konongsrikis man, eigh væstgøskan, bøte firi atta ørtogher ok þrettan markær ok ænga ætar bot. […] Dræpar maþær danskan man allæ noræn man, bøte niv markum. Dræpær maþær vtlænskan man, eigh ma frid flyia or landi sinu oc j æth hans. Dræpær maþær vtlænskæn prest, bøte sva mykit firi sum hærlænskan man. Præstær skal i bondalaghum væræ. Varþær suþærman dræpin ællær ænskær maþær, ta skal bøta firi marchum fiurum þem sakinæ søkir, ok tvar marchar konongi.
If someone slays a Swede or a Smålander, a man from the kingdom, but not a West Geat, he will pay eight örtugar (20-pence coins) and thirteen marks, but no weregild. [...] If someone slays a Dane or a Norwegian, he will pay nine marks. If someone slays a foreigner, he shall not be banished and have to flee to his clan. If someone slays a foreign priest, he will pay as much as for a fellow countryman. A priest counts as a freeman. If a Southerner is slain or an Englishman, he shall pay four marks to the plaintiff and two marks to the king.
Old Gutnish.
Due to Gotland's early isolation from the mainland, many features of Old Norse did not spread from or to the island, and Old Gutnish developed as an entirely separate branch from Old East and West Norse. For example, the diphthong "ai" in "aigu", "þair" and "waita" was not retroactively umlauted to "ei" as in e.g. Old Icelandic "eigu", "þeir" and "veita". Breaking was especially active in Old Gutnish, leading to forms such as "bjera" and "bjauþa", mainland "bera" and "bjúþa". Dropping of /w/ in initial /wɾ/ is shared only with Old Icelandic.
Text example.
The Gutasaga is the longest text surviving from Old Gutnish. It was written in the 13th century and dealt with the early history of the Gotlanders. This part relates to the agreement that the Gotlanders had with the Swedish king sometime before the 9th century:
So gingu gutar sielfs wiliandi vndir suia kunung þy at þair mattin frir Oc frelsir sykia suiariki j huerium staþ. vtan tull oc allar utgiftir. So aigu oc suiar sykia gutland firir vtan cornband ellar annur forbuþ. hegnan oc hielp sculdi kunungur gutum at waita. En þair wiþr þorftin. oc kallaþin. sendimen al oc kunungr oc ierl samulaiþ a gutnal þing senda. Oc latta þar taka scatt sinn. þair sendibuþar aighu friþ lysa gutum alla steþi til sykia yfir haf sum upsala kunungi til hoyrir. Oc so þair sum þan wegin aigu hinget sykia.
So, by their own will, the Gotlanders became the subjects of the Swedish king, so that they could travel freely and without risk to any location in the Swedish kingdom without toll and other fees. Likewise, the Swedes had the right to go to Gotland without corn restrictions or other prohibitions. The king was to provide protection and help, when they needed it and asked for it. The king and the jarl shall send emissaries to the Gutnish thing to receive the taxes. These emissaries shall declare free passage for the Gotlanders to all locations in the sea of the king at Uppsala (that is the Baltic Sea was under Swedish control) and likewise for everyone who wanted to travel to Gotland.
Relationship to other languages.
Relationship to English.
Old English and Old Norse were closely related languages. It is therefore not surprising that many words in Old Norse look familiar to English speakers (e.g., "armr" (arm), "fótr" (foot), "land" (land), "fullr" (full), "hanga" (to hang), "standa" (to stand)). This is because both English and Old Norse stem from a Proto-Germanic mother language. In addition, numerous common, everyday Old Norse words mainly of East Norse origin were adopted into the Old English language during the Viking age. A few examples of Old Norse loanwords in modern English are (English/Viking age Old East Norse):
In a simple sentence like "They are both weak" the extent of the Old Norse loanwords becomes quite clear (Old East Norse with archaic pronunciation: "Þæiʀ eʀu báðiʀ wæikiʀ" while Old English "híe syndon bégen (þá) wáce"). The words "they" and "weak" are both borrowed from Old Norse, and the word "both" might also be a borrowing, though this is disputed. While the number of loanwords adopted from the Norse was not as numerous as that of Norman French or Latin, their depth and every day nature make them a substantial and very important part of every day English speech as they are part of the very core of the modern English vocabulary.
Words like "bull" and "Thursday" are more difficult when it comes to their origins. "Bull" may be from either Old English "bula" or Old Norse "buli", while "Thursday" may be a borrowing, or it could simply be from the Old English "Þunresdæg", which could have been influenced by the Old Norse cognate. The word "are" is from Old English "earun"/"aron", which stems back to Proto-Germanic as well as the Old Norse cognates.
Notes.
Cleasby-Vigfússon:
References.
</dl>

</doc>
<doc id="22667" url="http://en.wikipedia.org/wiki?curid=22667" title="Old English">
Old English

Old English ("Ænglisc, Anglisc, Englisc") or Anglo-Saxon is the earliest historical form of the English language, spoken in England and southern and eastern Scotland in the early Middle Ages. It was brought to Great Britain by Anglo-Saxon settlers probably in the mid-5th century, and the first Old English literary works date from the mid-7th century. After the Norman conquest of England in 1066, Old English developed into the next historical form of English, known as Middle English.
Old English developed from a set of Anglo-Frisian or North Sea Germanic dialects originally spoken along the coasts of Frisia, Lower Saxony, Jutland and Southern Sweden by Germanic tribes traditionally known as the Angles, Saxons, and Jutes. As the Anglo-Saxons became dominant in England, their language replaced the languages of Roman Britain: Common Brittonic, a Celtic language, and Latin, brought to Britain by Roman invasion. Old English had four main dialects (Mercian, Northumbrian, Kentish, and West Saxon), each with distinct differences from the others. After the 9th century, Old English was influenced by Old Norse. The Old English period is arbitrarily considered as ending in 1066, when William the Conqueror conquered England, and Anglo-Norman, a relative of French, replaced English as the language of the upper classes.
Old English is one of the West Germanic languages, and its closest relatives are Old Frisian and Old Saxon. Like other old Germanic languages, it is very different from Modern English and difficult for Modern English speakers to understand without study. Grammatically it is close to Modern Standard German: nouns, adjectives, pronouns, and verbs have many inflectional endings and forms, and word order is much freer. Some Old English inscriptions were written in runes, but literature is written in the Latin alphabet.
History.
Old English was not static, and its usage covered a period of 700 years, from the Anglo-Saxon settlement of Britain in the 5th century to the late 11th century, some time after the Norman invasion.
Old English is a West Germanic language, developing out of Ingvaeonic (also known as North Sea Germanic) dialects from the 5th century.
Anglo-Saxon literacy developed after Christianisation in the late 7th century. The oldest surviving text of Old English literature is "Cædmon's Hymn", composed between 658 and 680. There is a limited corpus of runic inscriptions from the 5th to 7th centuries, but the oldest coherent runic texts (notably Franks Casket) date to the 8th century.
The history of Old English can be subdivided into:
The Old English period is followed by Middle English (12th to 15th century), Early Modern English (c. 1480 to 1650) and finally Modern English (after 1650).
Dialects.
Old English should not be regarded as a single monolithic entity just as Modern English is also not monolithic. It emerged over time out of the many dialects and languages of the colonising tribes, and it was not until the later Anglo-Saxon period that they fused together into Old English. Even then, it continued to exhibit local language variation, remnants of which remain in Modern English dialects.
Thus it is misleading, for example, to consider Old English as having a single sound system. Rather, there were multiple Old English sound systems. Old English has variation along regional lines as well as variation across different times.
For example, the language attested in Wessex during the time of Æthelwold of Winchester, which is named Late West Saxon (or Æthelwoldian Saxon), is considerably different from the language attested in Wessex during the time of Alfred the Great's court, which is named Early West Saxon (or Classical West Saxon or Alfredian Saxon). Furthermore, the difference between Early West Saxon and Late West Saxon is of such a nature that Late West Saxon is not directly descended from Early West Saxon (despite what the similarity in name implies).
The four main dialectal forms of Old English were Mercian, Northumbrian, Kentish, and West Saxon. Each of those dialects was associated with an independent kingdom on the island. Of these, Northumbria south of the Tyne and most of Mercia were overrun by the Vikings during the 9th century. The portion of Mercia that was successfully defended and all of Kent were then integrated into Wessex.
After the process of unification of the diverse Anglo-Saxon kingdoms in 878 by Alfred the Great, there is a marked decline in the importance of regional dialects. This is not because they stopped existing, as evidenced both by the existence of Middle and later Modern English dialects.
However, the bulk of the surviving documents from the Anglo-Saxon period are written in the dialect of Wessex, Alfred's kingdom. It seems likely that with consolidation of power, it became necessary to standardise the language of government to reduce the difficulty of administering the more remote areas of the kingdom. As a result, documents were written in the West Saxon dialect. Not only this, but Alfred was passionate about the spread of the vernacular, and brought many scribes to his region from Mercia to record previously unwritten texts.
The Church was affected likewise, especially since Alfred initiated an ambitious programme to translate religious materials into English. To retain his patronage and ensure the widest circulation of the translated materials, the monks and priests engaged in the programme worked in his dialect. Alfred himself seems to have translated books out of Latin and into English, notably Pope Gregory I's treatise on administration, "Pastoral Care".
Because of the centralisation of power and the Viking invasions, there is little or no written evidence for the development of non-Wessex dialects after Alfred's unification.
Thomas Spencer Baynes claimed in 1856 that, owing to its position at the heart of the Kingdom of Wessex, the relics of Anglo-Saxon accent, idiom and vocabulary were best preserved in the Somerset dialect.
Even after the maximum Anglo-Saxon expansion, Old English was never spoken all over the Kingdom of England; not only was Medieval Cornish spoken all over Cornwall, it was also spoken in adjacent parts of Devon into the age of the Plantagenets, long after the Norman Conquest. Cumbric may have survived into the 12th century in parts of Cumbria and Welsh may have been spoken on the English side of the Anglo-Welsh border. In addition to the Celtic languages, Norse was spoken in some areas under Danish law.
Phonology.
The inventory of classical Old English (i.e. Late West Saxon) surface phones, as usually reconstructed, is as follows.
The sounds marked in parentheses in the chart above are allophones:
The front mid rounded vowels /ø(ː)/ occur in some dialects of Old English, but not in the best attested Late West Saxon dialect.
Vowels were not the only letters and sounds different from Modern English. In Old English, c always sounded like the modern k, never that of s. G sounded like the y in yes when it was before or after a palatal vowel or any diphthong, but it sounded approximately like the g in go when it was before or after a guttural vowel or a mixed vowel.
Letters that are present in Modern English but are completely absent from Old English include j, q, v, and z. The letter k was used, but only rarely.
Sound changes.
The following table shows a possible sequence of changes for some basic vocabulary items, leading from Proto-Indo-European (PIE) to Modern English. The notation ">!" indicates an unexpected change (the simple notation ">" indicates an expected change). An empty cell means no change at the given stage for the given item. Only sound changes that had an effect on one or more of the vocabulary items are shown.
NOTE: Some of the changes listed above as "unexpected" are more predictable than others. For example:
The sound change in "one" is, however, somewhat reminiscent of other cases of "smearing" or breaking of short o, as in Spanish "fuerte", "puerto", (originally "forte", "porto", as in Italian), as well as in Kashubian, where the letter ò also represents /wɛ/.
Grammar.
Morphology.
Unlike Modern English, Old English is a language rich with morphological diversity. It maintains several distinct cases: the nominative, accusative, genitive, dative and (vestigially) instrumental. The only remnants of this system in Modern English are in a few pronouns (the meanings of "I" (nominative) "my" (genitive) and "me" (accusative/dative) in the first person provide an example) and in the possessive ending "-'s", which derives from the genitive ending "-es".
Old English nouns had grammatical gender which is a feature absent in modern English which uses natural gender. For example, "sēo sunne" (the Sun) was feminine, "se mōna" (the Moon) was masculine, and "þæt wīf" "the woman/wife" was neuter. Pronominal usage could reflect either natural or grammatical gender, when those conflicted.
The verb identifies person, number, tense, and mood. Verbs have three moods (Indicative, Subjunctive, and Imperative). They have two numbers (Singular and Plural), three genders (Masculine, Feminine, and Neuter), and only two synthetic tenses (simple present and simple past). Old English grammar also does not contain a synthetic passive. However, Old English does occasionally use compound constructions to express other verbal aspects, the future and the passive voice; in these we see the beginnings of the compound tenses of Modern English.
Old English verbs are separated into two categories according to how they form tenses. Strong verbs change tense by altering the root vowel (like irregular verbs in Modern English) and weak verbs change tense by adding a suffix to the end of the verb (like the –ed or -s in regular verbs in Modern English). Throughout time, however, most of the strong verbs of Old English had either shifted into regular verbs in Modern English or disappeared from the English language altogether. According to linguist Edward Finegan, the number of strong verbs in English has dropped from 333, including "burn" and "help", to 68 irregular verbs today, though conversely, there are also a few weak verbs that have shifted into irregular form, such as "dive" and "wear", and there are also some verbs which have debatable regularity status, such as "sneaked" and "snuck" for "sneak". In comparison to Modern English, Old English had far more irregularity in verb conjugation.
Syntax.
Old English syntax was similar in many ways to that of modern English. However, there were some important differences. Some were simply consequences of the greater level of nominal and verbal inflection – e.g., word order was generally freer. In addition:
Orthography.
Old English was first written in runes ("futhorc") but shifted to a (minuscule) half-uncial script of the Latin alphabet introduced by Irish Christian missionaries from around the 9th century. This was replaced by insular script, a cursive and pointed version of the half-uncial script. This was used until the end of the 12th century when continental Carolingian minuscule (also known as "Caroline") replaced the insular.
The letter ðæt ⟨ð⟩ (called "eth" or "edh" in modern English) was an alteration of Latin ⟨d⟩, and the runic letters thorn ⟨þ⟩ and wynn ⟨ƿ⟩ are borrowings from futhorc. Also used was a symbol for the conjunction "and", a character similar to the number seven (⟨⁊⟩, called a Tironian note), and a symbol for the relative pronoun "þæt", a thorn with a crossbar through the ascender (⟨ꝥ⟩). Macrons ⟨¯⟩ over vowels were rarely used to indicate long vowels. Also used occasionally were abbreviations for a following "m" or "n". All of the sound descriptions below are given using symbols.
Conventions of modern editions.
A number of changes are traditionally made in published modern editions of the original Old English manuscripts. Some of these conventions include the introduction of punctuation and the substitutions of symbols. The symbols ⟨e⟩, ⟨f⟩, ⟨g⟩, ⟨r⟩, ⟨s⟩ are used in modern editions, although their shapes in the insular script are considerably different. The long s ⟨ſ⟩ is substituted by its modern counterpart ⟨s⟩. Insular ⟨ᵹ⟩ is usually substituted with its modern counterpart ⟨g⟩ (which is ultimately a Carolingian symbol).
Additionally, modern editions often distinguish between a velar and palatal ⟨c⟩ and ⟨g⟩ with diacritic dots above the putative palatals: ⟨ċ⟩, ⟨ġ⟩. The "wynn" symbol ⟨ƿ⟩ is usually replaced with ⟨w⟩. Macrons are usually found in modern editions to indicate putative long vowels, while they are usually lacking in the originals. In older printed editions of Old English works, an acute accent mark was used to maintain cohesion between Old English and Old Norse printing.
The alphabetical symbols found in Old English writings and their substitute symbols found in modern editions are listed below:
Doubled consonants are geminated; the geminate fricatives ⟨ðð⟩/⟨þþ⟩, ⟨ff⟩ and ⟨ss⟩ cannot be voiced.
Influence of other languages.
In the course of the Early Middle Ages, Old English assimilated some aspects of a few languages with which it came in contact, such as the two dialects of Old Norse from the contact with the Norsemen or "Danes" who by the late 9th century controlled large tracts of land in northern and eastern England, which came to be known as the Danelaw.
Latin influence.
A large percentage of the educated and literate population of the time were competent in Latin, which was the scholarly and diplomatic "lingua franca" of Western Europe. It is sometimes possible to give approximate dates for the entry of individual Latin words into Old English based on which patterns of linguistic change they have undergone. There were at least three notable periods of Latin influence. The first occurred before the ancestral Angles and Saxons left continental Europe for Britain. The second began when the Anglo-Saxons were converted to Christianity and Latin-speaking priests became widespread. See Latin influence in English: Early Middle Ages for details.
The third and largest single transfer of Latin-based words happened after the Norman Conquest of 1066, when an enormous number of Norman (Old French) words began to influence the language. Most of these Oïl language words were themselves derived from Old French and ultimately from classical Latin, although a notable stock of Norse words were introduced or re-introduced in Norman form. The Norman Conquest approximately marks the end of Old English and the advent of Middle English.
One of the ways the influence of Latin can be seen is that many Latin words for activities also came to be used to refer to the people engaged in those activities, an idiom carried over from Anglo-Saxon but using Latin words. This can be seen in words like "militia", "assembly", "movement", and "service".
The language was further altered by the transition away from the runic alphabet (also known as "futhorc" or fuþorc) to the Latin alphabet, which was also a significant factor in the developmental pressures brought to bear on the language. Old English words were spelled, more or less, as they were pronounced. Often, the Latin alphabet fell short of being able to adequately represent Anglo-Saxon phonetics. Spellings, therefore, can be thought of as best-attempt approximations of how the language actually sounded.
The "silent" letters in many Modern English words were pronounced in Old English: for example, the "c" and "h" in "cniht", the Old English ancestor of the modern "knight", were pronounced. Another side-effect of spelling Old English words phonetically using the Latin alphabet was that spelling was extremely variable. A word's spelling could also reflect differences in the phonetics of the writer's regional dialect. Words also endured idiosyncratic spelling choices of individual authors, some of whom varied spellings between works. Thus, for example, the word "and" could be spelt either "and" or "ond".
Norse influence.
The second major source of loanwords to Old English were the Scandinavian words introduced during the Viking invasions of the 9th and 10th centuries. In addition to a great many place names, these consist mainly of items of basic vocabulary, and words concerned with particular administrative aspects of the Danelaw (that is, the area of land under Viking control, which included extensive holdings all along the eastern coast of England and Scotland).
The Vikings spoke Old Norse, a language related to Old English in that both derived from the same ancestral Proto-Germanic language. It is very common for the intermixing of speakers of different dialects, such as those that occur during times of political unrest, to result in a mixed language, and one theory holds that exactly such a mixture of Old Norse and Old English helped accelerate the decline of case endings in Old English.
Apparent confirmation of this is the fact that simplification of the case endings occurred earliest in the north and latest in the south-west, the area farthest away from Viking influence. Regardless of the truth of this theory, the influence of Old Norse on the lexicon of the English language has been profound: responsible for such basic vocabulary items as "sky", "leg", the pronoun "they", the verb form "are", and hundreds of other words.
Celtic influence.
Traditionally, and following the Anglo-Saxon preference prevalent in the 19th century, many maintain that the influence of Brythonic Celtic on English has been small, citing the small number of Celtic loanwords taken into the language. The number of Celtic loanwords is of a lower order than either Latin or Scandinavian. However, a more recent and still minority view is that distinctive Celtic traits can be discerned in syntax from the post-Old English period, such as the regular progressive construction and analytic word order in opposition to the Germanic languages.
Literature.
Old English literature, though more abundant than literature of the continent before AD 1000 is nonetheless scant. In his supplementary article to the 1935 posthumous edition of Bright's "Anglo-Saxon Reader", Dr. James Hulbert writes:
In such historical conditions, an incalculable amount of the writings of the Anglo-Saxon period perished. What they contained, how important they were for an understanding of literature before the Conquest, we have no means of knowing: the scant catalogues of monastic libraries do not help us, and there are no references in extant works to other compositions...How incomplete our materials are can be illustrated by the well-known fact that, with few and relatively unimportant exceptions, all extant Anglo-Saxon poetry is preserved in four manuscripts.
Some of the most important surviving works of Old English literature are "Beowulf", an epic poem; the "Anglo-Saxon Chronicle", a record of early English history; the Franks Casket, an inscribed early whalebone artefact; and Cædmon's Hymn, a Christian religious poem. There are also a number of extant prose works, such as sermons and saints' lives, biblical translations, and translated Latin works of the early Church Fathers, legal documents, such as laws and wills, and practical works on grammar, medicine, and geography. Still, poetry is considered the heart of Old English literature. Nearly all Anglo-Saxon authors are anonymous, with a few exceptions, such as Bede and Cædmon.
"Beowulf".
The first example is taken from the opening lines of the epic poem "Beowulf". This passage describes how Hrothgar's legendary ancestor Scyld was found as a baby, washed ashore, and adopted by a noble family. The translation is literal and represents the original poetic word order. As such, it is not typical of Old English prose. The modern cognates of original words have been used whenever practical to give a close approximation of the feel of the original poem.
The words in brackets are implied in the Old English by noun case and the bold words in brackets are explanations of words that have slightly different meanings in a modern context. Notice how "what" is used by the poet where a word like "lo" or "behold" would be expected. This usage is similar to "what-ho!", both an expression of surprise and a call to attention.
English poetry is based on stress and alliteration. In alliteration, the first consonant in a word alliterates with the same consonant at the beginning of another word, as with Gār-Dena" and ġeār-dagum". Vowels alliterate with any other vowel, as with æþelingas" and ellen". In the text below, the letters that alliterate are bolded.
A semi-fluent translation in Modern English would be:
Lo! We have heard of majesty of the Spear-Danes, of those nation-kings in the days of yore, and how those noblemen promoted zeal. Scyld Scefing took away mead-benches from bands of enemies, from many tribes; he terrified earls. Since he was first found destitute (he gained consolation for that) he grew under the heavens, prospered in honours, until each of those who lived around him over the sea had to obey him, give him tribute. That was a good king!
The Lord's Prayer.
This text of the Lord's Prayer is presented in the standardised West Saxon literary dialect, with added macrons for vowel length, markings for probable palatalised consonants, modern punctuation, and the replacement of the letter wynn with w.
Charter of Cnut.
This is a proclamation from King Cnut the Great to his earl Thorkell the Tall and the English people written in AD 1020. Unlike the previous two examples, this text is prose rather than poetry. For ease of reading, the passage has been divided into sentences while the pilcrows represent the original division.
Old English as a living language.
Like other historical languages, Old English has been used by scholars and enthusiasts of later periods to create texts either imitating Anglo-Saxon literature or deliberately transferring it to a different cultural context. Examples include Alistair Campbell and J. R. R. Tolkien. A number of websites devoted to Neo-Paganism and Historical Re-enactment offer reference material and forums promoting the active use of Old English. By far the most ambitious project is the , but most of the Neo-Old English texts published online bear little resemblance to the historical model and are riddled with very basic grammatical mistakes.
Bibliography.
Lexicons.
</dl>

</doc>
<doc id="22669" url="http://en.wikipedia.org/wiki?curid=22669" title="Open cluster">
Open cluster

An open cluster, also known as galactic cluster, is a group of up to a few thousand stars that were formed from the same giant molecular cloud and have roughly the same age. More than 1,100 open clusters have been discovered within the Milky Way Galaxy, and many more are thought to exist. They are loosely bound to each other by mutual gravitational attraction and become disrupted by close encounters with other clusters and clouds of gas as they orbit the galactic center, resulting in a migration to the main body of the galaxy as well as a loss of cluster members through internal close encounters. Open clusters generally survive for a few hundred million years, with the most massive ones surviving for a few billion years. In contrast, the more massive globular clusters of stars exert a stronger gravitational attraction on their members, and can survive for longer. Open clusters have been found only in spiral and irregular galaxies, in which active star formation is occurring.
Young open clusters may still be contained within the molecular cloud from which they formed, illuminating it to create an H II region. Over time, radiation pressure from the cluster will disperse the molecular cloud. Typically, about 10% of the mass of a gas cloud will coalesce into stars before radiation pressure drives the rest of the gas away.
Open clusters are key objects in the study of stellar evolution. Because the cluster members are of similar age and chemical composition, their properties (such as distance, age, metallicity and extinction) are more easily determined than they are for isolated stars. A number of open clusters, such as the Pleiades, Hyades or the Alpha Persei Cluster are visible with the naked eye. Some others, such as the Double Cluster, are barely perceptible without instruments, while many more can be seen using binoculars or telescopes. The Wild Duck Cluster, M11, is an example.
Historical observations.
The prominent open cluster Pleiades has been recognized as a group of stars since antiquity, while the Hyades forms part of Taurus, one of the oldest constellations. Other open clusters were noted by early astronomers as unresolved fuzzy patches of light. The Roman astronomer Ptolemy mentions the Praesepe, the Double Cluster in Perseus, and the Ptolemy Cluster, while the Persian astronomer Al-Sufi wrote of the Omicron Velorum cluster. However, it would require the invention of the telescope to resolve these nebulae into their constituent stars. Indeed, in 1603 Johann Bayer gave three of these clusters designations as if they were single stars.
The first person to use a telescope to observe the night sky and record his observations was the Italian scientist Galileo Galilei in 1609. When he turned the telescope toward some of the nebulous patches recorded by Ptolemy, he found they were not a single star, but groupings of many stars. For the Praesepe, he found more than 40 stars. Where previously observers had noted only 6-7 stars in the Pleiades, he found almost 50. In his 1610 treatise "Sidereus Nuncius", Galileo Galilei wrote, "the galaxy is nothing else but a mass of innumerable stars planted together in clusters." Influenced by Galileo's work, the Sicilian astronomer Giovanni Hodierna became possibly the first astronomer to use a telescope to find previously undiscovered open clusters. In 1654, he identified the objects now designated Messier 41, Messier 47, NGC 2362 and NGC 2451.
It was realised as early as 1767 that the stars in a clusters were physically related, when the English naturalist Reverend John Michell calculated that the probability of even just one group of stars like the Pleiades being the result of a chance alignment as seen from Earth was just 1 in 496,000. Between 1774–1781, French astronomer Charles Messier published a catalogue of celestial objects that had a nebulous appearance similar to comets. This catalogue included 26 open clusters. In the 1790s, English astronomer William Herschel began an extensive study of nebulous celestial objects. He discovered that many of these features could be resolved into groupings of individual stars. Herschel conceived the idea that stars were initially scattered across space, but later became clustered together as star systems because of gravitational attraction. He divided the nebulae into eight classes, with classes VI through VIII being used to classify clusters of stars.
The number of clusters known continued to increase under the efforts of astronomers. Hundreds of open clusters were listed in the New General Catalogue, first published in 1888 by the Danish-Irish astronomer J. L. E. Dreyer, and the two supplemental Index Catalogues, published in 1896 and 1905. Telescopic observations revealed two distinct types of clusters, one of which contained thousands of stars in a regular spherical distribution and was found all across the sky but preferentially towards the centre of the Milky Way. The other type consisted of a generally sparser population of stars in a more irregular shape. These were generally found in or near the galactic plane of the Milky Way. Astronomers dubbed the former globular clusters, and the latter open clusters. Because of their location, open clusters are occasionally referred to as "galactic clusters", a term that was introduced in 1925 by the Swiss-American astronomer Robert Julius Trumpler.
Micrometer measurements of the positions of stars in clusters were made as early as 1877 by the German astronomer E. Schönfeld and further pursued by the American astronomer E. E. Barnard prior to his death in 1923. No indication of stellar motion was detected by these efforts. However, in 1918 the Dutch-American astronomer Adriaan van Maanen was able to measure the proper motion of stars in part of the Pleiades cluster by comparing photographic plates taken at different times. As astrometry became more accurate, cluster stars were found to share a common proper motion through space. By comparing the photographic plates of the Pleiades cluster taken in 1918 with images taken in 1943, van Maanen was able to identify those stars that had a proper motion similar to the mean motion of the cluster, and were therefore more likely to be members. Spectroscopic measurements revealed common radial velocities, thus showing that the clusters consist of stars bound together as a group.
The first color-magnitude diagrams of open clusters were published by Ejnar Hertzsprung in 1911, giving the plot for the Pleiades and Hyades star clusters. He continued this work on open clusters for the next twenty years. From spectroscopic data, he was able to determine the upper limit of internal motions for open clusters, and could estimate that the total mass of these objects did not exceed several hundred times the mass of the Sun. He demonstrated a relationship between the star colors and their magnitudes, and in 1929 noticed that the Hyades and Praesepe clusters had different stellar populations than the Pleiades. This would subsequently be interpreted as a difference in ages of the three clusters.
Formation.
The formation of an open cluster begins with the collapse of part of a giant molecular cloud, a cold dense cloud of gas and dust containing up to many thousands of times the mass of the Sun. These clouds have densities that vary from 102 to 106 molecules of neutral hydrogen per cm3, with star formation occurring in regions with densities above 104 molecules per cm3. Typically, only 1–10% of the cloud by volume is above the latter density. Prior to collapse, these clouds maintain their mechanical equilibrium through magnetic fields, turbulence, and rotation.
Many factors may disrupt the equilibrium of a giant molecular cloud, triggering a collapse and initiating the burst of star formation that can result in an open cluster. These include shock waves from a nearby supernova, collisions with other clouds, or gravitational interactions. Even without external triggers, regions of the cloud can reach conditions where they become unstable against collapse. The collapsing cloud region will undergo hierarchical fragmentation into ever smaller clumps, including a particularly dense form known as infrared dark clouds, eventually leading to the formation of up to several thousand stars. This star formation begins enshrouded in the collapsing cloud, blocking the protostars from sight but allowing infrared observation. In the Milky Way galaxy, the formation rate of open clusters is estimated to be one every few thousand years.
The hottest and most massive of the newly formed stars (known as OB stars) will emit intense ultraviolet radiation, which steadily ionizes the surrounding gas of the giant molecular cloud, forming an H II region. Stellar winds and radiation pressure from the massive stars begins to drive away the hot ionized gas at a velocity matching the speed of sound in the gas. After a few million years the cluster will experience its first core-collapse supernovae, which will also expel gas from the vicinity. In most cases these processes will strip the cluster of gas within ten million years and no further star formation will take place. Still, about half of the resulting protostellar objects will be left surrounded by circumstellar disks, many of which form accretion disks.
As only 30 to 40 per cent of the gas in the cloud core forms stars, the process of residual gas expulsion is highly damaging to the star formation process. All clusters thus suffer significant infant weight loss, while a large fraction undergo infant mortality. At this point, the formation of an open cluster will depend on whether the newly formed stars are gravitationally bound to each other; otherwise an unbound stellar association will result. Even when a cluster such as the Pleiades does form, it may only hold on to a third of the original stars, with the remainder becoming unbound once the gas is expelled. The young stars so released from their natal cluster become part of the Galactic field population.
Because most if not all stars form clustered, star clusters are to be viewed the fundamental building blocks of galaxies. The violent gas-expulsion events that shape and destroy many star clusters at birth leave their imprint in the morphological and kinematical structures of galaxies. Most open clusters form with at least 100 stars and a mass of 50 or more solar masses. The largest clusters can have 104 solar masses, with the massive cluster Westerlund 1 being estimated at 5 × 104 solar masses; close to that of a globular cluster. While open clusters and globular clusters form two fairly distinct groups, there may not be a great deal of difference in appearance between a very sparse globular cluster and a very rich open cluster. Some astronomers believe the two types of star clusters form via the same basic mechanism, with the difference being that the conditions that allowed the formation of the very rich globular clusters containing hundreds of thousands of stars no longer prevail in the Milky Way.
It is common for two or more separate open clusters to form out of the same molecular cloud. In the Large Magellanic Cloud, both Hodge 301 and R136 are forming from the gases of the Tarantula Nebula, while in our own galaxy, tracing back the motion through space of the Hyades and Praesepe, two prominent nearby open clusters, suggests that they formed in the same cloud about 600 million years ago. Sometimes, two clusters born at the same time will form a binary cluster. The best known example in the Milky Way is the Double Cluster of NGC 869 and NGC 884 (sometimes mistakenly called h and χ Persei; h refers to a neighboring star and χ to "both" clusters), but at least 10 more double clusters are known to exist. Many more are known in the Small and Large Magellanic Clouds—they are easier to detect in external systems than in our own galaxy because projection effects can cause unrelated clusters within the Milky Way to appear close to each other.
Morphology and classification.
Open clusters range from very sparse clusters with only a few members to large agglomerations containing thousands of stars. They usually consist of quite a distinct dense core, surrounded by a more diffuse 'corona' of cluster members. The core is typically about 3–4 light years across, with the corona extending to about 20 light years from the cluster centre. Typical star densities in the centre of a cluster are about 1.5 stars per cubic light year; the stellar density near the Sun is about 0.003 stars per cubic light year.
Open clusters are often classified according to a scheme developed by Robert Trumpler in 1930. The Trumpler scheme gives a cluster a three part designation, with a Roman numeral from I-IV indicating its concentration and detachment from the surrounding star field (from strongly to weakly concentrated), an Arabic numeral from 1 to 3 indicating the range in brightness of members (from small to large range), and "p", "m" or "r" to indication whether the cluster is poor, medium or rich in stars. An 'n' is appended if the cluster lies within nebulosity.
Under the Trumpler scheme, the Pleiades are classified as I3rn (strongly concentrated and richly populated with nebulosity present), while the nearby Hyades are classified as II3m (more dispersed, and with fewer members).
Numbers and distribution.
There are over 1,000 known open clusters in our galaxy, but the true total may be up to ten times higher than that. In spiral galaxies, open clusters are largely found in the spiral arms where gas densities are highest and so most star formation occurs, and clusters usually disperse before they have had time to travel beyond their spiral arm. Open clusters are strongly concentrated close to the galactic plane, with a scale height in our galaxy of about 180 light years, compared to a galactic radius of approximately 50,000 light years.
In irregular galaxies, open clusters may be found throughout the galaxy, although their concentration is highest where the gas density is highest. Open clusters are not seen in elliptical galaxies: star formation ceased many millions of years ago in ellipticals, and so the open clusters which were originally present have long since dispersed.
In our galaxy, the distribution of clusters depends on age, with older clusters being preferentially found at greater distances from the galactic centre, generally at substantial distances above or below the galactic plane. Tidal forces are stronger nearer the centre of the galaxy, increasing the rate of disruption of clusters, and also the giant molecular clouds which cause the disruption of clusters are concentrated towards the inner regions of the galaxy, so clusters in the inner regions of the galaxy tend to get dispersed at a younger age than their counterparts in the outer regions.
Stellar composition.
Because open clusters tend to be dispersed before most of their stars reach the end of their lives, the light from them tends to be dominated by the young, hot blue stars. These stars are the most massive, and have the shortest lives of a few tens of millions of years. The older open clusters tend to contain more yellow stars.
Some open clusters contain hot blue stars which seem to be much younger than the rest of the cluster. These blue stragglers are also observed in globular clusters, and in the very dense cores of globulars they are believed to arise when stars collide, forming a much hotter, more massive star. However, the stellar density in open clusters is much lower than that in globular clusters, and stellar collisions cannot explain the numbers of blue stragglers observed. Instead, it is thought that most of them probably originate when dynamical interactions with other stars cause a binary system to coalesce into one star.
Once they have exhausted their supply of hydrogen through nuclear fusion, medium- to low-mass stars shed their outer layers to form a planetary nebula and evolve into white dwarfs. While most clusters become dispersed before a large proportion of their members have reached the white dwarf stage, the number of white dwarfs in open clusters is still generally much lower than would be expected, given the age of the cluster and the expected initial mass distribution of the stars. One possible explanation for the lack of white dwarfs is that when a red giant expels its outer layers to become a planetary nebula, a slight asymmetry in the loss of material could give the star a 'kick' of a few kilometres per second, enough to eject it from the cluster.
Because of their high density, close encounters between stars in an open cluster are common. For a typical cluster with 1,000 stars with a 0.5 parsec half-mass radius, on average a star will have an encounter with another member every 10 million years. The rate is even higher in denser clusters. These encounters can have a significant impact on the extended circumstellar disks of material that surround many young stars. Tidal perturbations of large disks may result in the formation of massive planets and brown dwarfs, producing companions at distances of 100 AU or more from the host star.
Eventual fate.
Many open clusters are inherently unstable, with a small enough mass that the escape velocity of the system is lower than the average velocity of the constituent stars. These clusters will rapidly disperse within a few million years. In many cases, the stripping away of the gas from which the cluster formed by the radiation pressure of the hot young stars reduces the cluster mass enough to allow rapid dispersal.
Clusters that have enough mass to be gravitationally bound once the surrounding nebula has evaporated can remain distinct for many tens of millions of years, but over time internal and external processes tend also to disperse them. Internally, close encounters between stars can increase the velocity of a member beyond the escape velocity of the cluster. This results in the gradual 'evaporation' of cluster members.
Externally, about every half-billion years or so an open cluster tends to be disturbed by external factors such as passing close to or through a molecular cloud. The gravitational tidal forces generated by such an encounter tend to disrupt the cluster. Eventually, the cluster becomes a stream of stars, not close enough to be a cluster but all related and moving in similar directions at similar speeds. The timescale over which a cluster disrupts depends on its initial stellar density, with more tightly packed clusters persisting for longer. Estimated cluster half lives, after which half the original cluster members will have been lost, range from 150–800 million years, depending on the original density.
After a cluster has become gravitationally unbound, many of its constituent stars will still be moving through space on similar trajectories, in what is known as a stellar association, moving cluster, or moving group. Several of the brightest stars in the 'Plough' of Ursa Major are former members of an open cluster which now form such an association, in this case, the Ursa Major Moving Group. Eventually their slightly different relative velocities will see them scattered throughout the galaxy. A larger cluster is then known as a stream, if we discover the similar velocities and ages of otherwise unrelated stars.
Studying stellar evolution.
When a Hertzsprung-Russell diagram is plotted for an open cluster, most stars lie on the main sequence. The most massive stars have begun to evolve away from the main sequence and are becoming red giants; the position of the turn-off from the main sequence can be used to estimate the age of the cluster.
Because the stars in an open cluster are all at roughly the same distance from Earth, and were born at roughly the same time from the same raw material, the differences in apparent brightness among cluster members is due only to their mass. This makes open clusters very useful in the study of stellar evolution, because when comparing one star to another, many of the variable parameters are fixed.
The study of the abundances of lithium and beryllium in open cluster stars can give important clues about the evolution of stars and their interior structures. While hydrogen nuclei cannot fuse to form helium until the temperature reaches about 10 million K, lithium and beryllium are destroyed at temperatures of 2.5 million K and 3.5 million K respectively. This means that their abundances depend strongly on how much mixing occurs in stellar interiors. By studying their abundances in open cluster stars, variables such as age and chemical composition are fixed.
Studies have shown that the abundances of these light elements are much lower than models of stellar evolution predict. While the reason for this underabundance is not yet fully understood, one possibility is that convection in stellar interiors can 'overshoot' into regions where radiation is normally the dominant mode of energy transport.
Astronomical distance scale.
Determining the distances to astronomical objects is crucial to understanding them, but the vast majority of objects are too far away for their distances to be directly determined. Calibration of the astronomical distance scale relies on a sequence of indirect and sometimes uncertain measurements relating the closest objects, for which distances can be directly measured, to increasingly distant objects. Open clusters are a crucial step in this sequence.
The closest open clusters can have their distance measured directly by one of two methods. First, the parallax (the small change in apparent position over the course of a year caused by the Earth moving from one side of its orbit around the Sun to the other) of stars in close open clusters can be measured, like other individual stars. Clusters such as the Pleiades, Hyades and a few others within about 500 light years are close enough for this method to be viable, and results from the Hipparcos position-measuring satellite yielded accurate distances for several clusters.
The other direct method is the so-called moving cluster method. This relies on the fact that the stars of a cluster share a common motion through space. Measuring the proper motions of cluster members and plotting their apparent motions across the sky will reveal that they converge on a vanishing point. The radial velocity of cluster members can be determined from Doppler shift measurements of their spectra, and once the radial velocity, proper motion and angular distance from the cluster to its vanishing point are known, simple trigonometry will reveal the distance to the cluster. The Hyades are the best known application of this method, which reveals their distance to be 46.3 parsecs.
Once the distances to nearby clusters have been established, further techniques can extend the distance scale to more distant clusters. By matching the main sequence on the Hertzsprung-Russell diagram for a cluster at a known distance with that of a more distant cluster, the distance to the more distant cluster can be estimated. The nearest open cluster is the Hyades: the stellar association consisting of most of the Plough stars is at about half the distance of the Hyades, but is a stellar association rather than an open cluster as the stars are not gravitationally bound to each other. The most distant known open cluster in our galaxy is Berkeley 29, at a distance of about 15,000 parsecs. Open clusters are also easily detected in many of the galaxies of the Local Group.
Accurate knowledge of open cluster distances is vital for calibrating the period-luminosity relationship shown by variable stars such as cepheid stars, which allows them to be used as standard candles. These luminous stars can be detected at great distances, and are then used to extend the distance scale to nearby galaxies in the Local Group. Indeed, the open cluster designated NGC 7790 hosts three classical Cepheids. RR Lyrae variables are too old to be associated with open clusters, and are instead found in globular clusters.
Planets.
The open cluster NGC 6811 contains two known planetary systems Kepler 66 and Kepler 67.
External links.
Listen to this article ()
This audio file was created from a revision of the "Open cluster" article dated 2006-07-16, and does not reflect subsequent edits to the article. ()
More spoken articles

</doc>
<doc id="22673" url="http://en.wikipedia.org/wiki?curid=22673" title="Orimulsion">
Orimulsion

Orimulsion is a registered trademark name for a bitumen-based fuel that was developed for industrial use by Intevep, the Research and Development Affiliate of Petroleos de Venezuela SA (PDVSA), following earlier collaboration on oil emulsions with BP.
Source of the bitumen.
Like coal and oil, bitumen occurs naturally and is obtained from the world's largest deposit in the Orinoco Belt in Venezuela. The deposit is estimated to be more than 1,200 billion barrels (190 billion m3) of bitumen, an amount approximately equivalent to the world's estimated proven oil reserves.
Preparation.
Raw bitumen has an extremely high viscosity and specific gravity between 8 to 10 API gravity, at ambient temperatures and is unsuitable for direct use in conventional power stations. Orimulsion is made by mixing the bitumen with about 30% fresh water and a small amount of surfactant. The result behaves similarly to fuel oil. An alcohol-based surfactant recently replaced the original phenol-based version; improving the transport properties of the fuel and eliminating the health concerns associated with the phenol group of surfactants.
Advantages.
As a fuel for electricity generation, Orimulsion has a number of attractive characteristics:
Disadvantages.
If there is a spill while shipping over water the mixture de-emulsifies and the bitumen drops out of suspension.
It is a non-Newtonian fluid, and if it is allowed to cool below 30 °C, it will 'set'. Pumping becomes impossible, and there is no way of restarting operations or the flow through the pipeline again.
Decreasing usage.
Orimulsion is currently used as a commercial boiler fuel in power plants worldwide ("e.g.", Canada, Japan, Lithuania, Italy and China). Use of fuel used to be much wider and demand was increasing. However, many of PDVSA's engineers were fired following the Venezuelan general strike of 2002–03.:128 Orimulsion had been the pride of the PDVSA engineers, so Orimulsion fell out of favor with the key political leaders. As a result, the government is trying to "Wind Down" the Orimulsion program. The one exception is the sales of Orimulsion to China. The Venezuelan government has close ties to China, as it has with Cuba. The result is that China is still supplied with Orimulsion, while the rest of the world has either had their supplies terminated, or are still experiencing the "Wind Down" phase. Orimulsion still has excellent potential for domestic consumption.
Another reason given by current PDVSA management is that with rising crude oil prices, it has been found that mixing or diluting Orinoco bitumen (extra-heavy oil) with a lighter crude oil can make this blend more profitable as a crude oil on the world market than by selling it as Orimulsion. An example of this is the popular Merey blend (Orinoco bitumen and Mesa crude oil). ConocoPhillips along with PDVSA operate the Merey Sweeny 58000 oilbbl/d (bpd) delayed coker, vacuum tower and related facilities at ConocoPhillips' refinery in Sweeny, Texas, U.S.A. for processing and upgrading heavy sour Merey crude oil. 
Air pollutant control technology that is commonly available can limit emissions from Orimulsion to levels considered "Best Available Control Technology", as defined by the United States Environmental Protection Agency.

</doc>
<doc id="22676" url="http://en.wikipedia.org/wiki?curid=22676" title="Oxfordian theory of Shakespeare authorship">
Oxfordian theory of Shakespeare authorship

The Oxfordian theory of Shakespeare authorship holds that Edward de Vere, 17th Earl of Oxford, wrote the plays and poems traditionally attributed to William Shakespeare. Though most literary scholars reject all alternative authorship candidates, including Oxford, popular interest in the Oxfordian theory continues. Since the 1920s, the Oxfordian theory has been the most popular alternative Shakespeare authorship theory.
The convergence of documentary evidence of the type used by academics for authorial attribution—title pages, testimony by other contemporary poets and historians, and official records—sufficiently establishes Shakespeare's authorship for the overwhelming majority of Shakespeare scholars and literary historians, and no evidence links Oxford to Shakespeare's works. Oxfordians, however, reject the historical record and often propose the conspiracy theory that the record was falsified to protect the identity of the real author, invoking the dearth of evidence for any conspiracy as evidence of its success. Scholars also note that interpreting the plays and poems as autobiographical, and then using them to construct a hypothetical author, is a method most literary specialists consider unreliable as far as attributive value.
Oxfordian arguments rely heavily on biographical allusions; adherents find correspondences between incidents and circumstances in Oxford's life and events in Shakespeare's plays, sonnets and longer poems. The case also relies on perceived parallels of language, idiom, and thought between Shakespeare's works and Oxford's own poetry and letters. Marked passages in Oxford's Bible have also been linked to biblical allusions in Shakespeare's plays. That no plays survive under Oxford's name is also important to the Oxfordian theory. Oxfordians interpret certain 16th- and 17th-century literary allusions as indicating that Oxford was one of the more prominent suppressed anonymous and/or pseudonymous writers of the day. Under this scenario, Shakespeare was either a "front man" or "play-broker" who published the plays under his own name or was merely an actor with a similar name, misidentified as the playwright since the first Shakespeare biographies of the early 1700s.
The most compelling evidence against the Oxfordian Theory is de Vere's death in 1604, since the generally accepted chronology of Shakespeare's plays places the composition of approximately twelve of the plays after that date. Oxfordian researchers respond that the annual publication of "new" or "corrected" Shakespeare plays stopped in 1604, and that the dedication to Shakespeare's Sonnets implies that the author was dead prior to their publication in 1609. Oxfordians believe the reason so many of the "late plays" show evidence of revision and collaboration is because they were completed by other playwrights after Oxford's death.
History of the Oxfordian theory.
The theory that the works of Shakespeare were in fact written by someone other than William Shakespeare dates back to the mid-nineteenth century. In 1857, the first published book on the topic, "The Philosophy of the Plays of Shakspere Unfolded", by Delia Bacon, was printed. Bacon proposed the first "group theory" of Shakespearian authorship, attributing the works to a committee headed by Francis Bacon and including Walter Raleigh. De Vere is mentioned once in the book, in a list of "high-born wits and poets", who were associated with Raleigh. Some commentators have interpreted this to imply that he was part of the group of authors. Throughout the 19th century Bacon was the preferred hidden author. Oxford is not known to have been mentioned again in this context.
By the beginning of the twentieth century other candidates, typically aristocrats, were put forward, most notably Roger Manners, 5th Earl of Rutland, and William Stanley, 6th Earl of Derby. Oxford's candidacy as sole author was first proposed by J. Thomas Looney in his 1920 book "Shakespeare Identified in Edward de Vere, 17th Earl of Oxford". Following earlier anti-Stratfordians, Looney argued that the known facts of Shakespeare's life did not fit the personality he ascribed to the author of the plays. Like other anti-Stratfordians before him, Looney referred to the absence of records concerning Shakespeare's education, his limited experience of the world, his allegedly poor handwriting skills (evidenced in his signatures), and the "dirt and ignorance" of Stratford at the time. Shakespeare had a petty "acquisitive disposition", he said, while the plays made heroes of free-spending figures. They also portrayed middle and lower-class people negatively, while Shakespearian heroes were typically aristocratic. Looney referred to scholars who found in the plays evidence that their author was an expert in law, widely read in ancient Latin literature, and could speak French and Italian. Looney believed that even very early works such as "Love's Labour's Lost" implied that he was already a person of "matured powers", in his forties or fifties, with wide experience of the world. Looney considered that Oxford's personality fitted that he deduced from the plays, and also identified characters in the plays as detailed portraits of Oxford's family and personal contacts. Several characters, including Hamlet and Bertram (in "All's Well that Ends Well"), were, he believed, self-portraits. Adapting arguments earlier used for Rutland and Derby, Looney fitted events in the plays to episodes in Oxford's life, including his travels to France and Italy, the settings for many plays. Oxford's death in 1604 was linked to a drop-off in the publication of Shakespeare plays. Looney declared that the late play "The Tempest" was not written by Oxford, and that others performed or published after Oxford's death were most probably left incomplete and finished by other writers, thus explaining the apparent idiosyncrasies of style found in the late Shakespeare plays. Looney also introduced the argument that the reference to the "ever-living poet" in the 1609 dedication to Shakespeare's sonnets implied that the author was dead at the time of publication.
Sigmund Freud, the novelist Marjorie Bowen, and several 20th-century celebrities found the thesis persuasive, and Oxford soon overtook Bacon as the favoured alternative candidate to Shakespeare, though academic Shakespearians mostly ignored the subject. Looney's theory attracted a number of activist followers who published books supplementing his own and added new arguments, most notably Percy Allen, Bernard M. Ward, Louis P. Bénézet and Charles Wisner Barrell. Mainstream scholar Stephen May has noted that Oxfordians of this period made genuine contributions to knowledge of Elizabethan history, citing "Ward's quite competent biography of the Earl" and "Charles Wisner Barrell's identification of Edward Vere, Oxford's illegitimate son by Anne Vavasour" as examples. In 1921, Sir George Greenwood, Looney, and others founded The Shakespeare Fellowship, an organization originally dedicated to the discussion and promotion of ecumenical anti-Stratfordian views, but which later became devoted to promoting Oxford as the true Shakespeare.
Decline and revival.
After a period of decline of the Oxfordian theory beginning with World War II, in 1952 Dorothy and Charlton Ogburn published the 1,300-page "This Star of England", which briefly revived Oxfordism. A series of critical academic books and articles, however, held in check any appreciable growth of anti-Stratfordism and Oxfordism, most notably "The Shakespeare Ciphers Examined" (1957), by William and Elizebeth Friedman, "The Poacher from Stratford" (1958), by Frank Wadsworth, "Shakespeare and His Betters" (1958), by Reginald Churchill, "The Shakespeare Claimants" (1962), by H. N. Gibson, and "Shakespeare and His Rivals: A Casebook on the Authorship Controversy" (1962), by George L. McMichael and Edgar M. Glenn. By 1968 the newsletter of The Shakespeare Oxford Society reported that "the missionary or evangelical spirit of most of our members seems to be at a low ebb, dormant, or non-existent". In 1974, membership in the society stood at 80. In 1979, the publication of an analysis of The Ashbourne portrait dealt a further blow to the movement. The painting, long claimed to be one of the portraits of Shakespeare, but considered by Barrell to be an overpaint of a portrait of the Earl of Oxford, turned out to represent neither, but rather depicted Hugh Hamersley.
Charlton Ogburn, Jr., was elected president of The Shakespeare Oxford Society in 1976 and kick-started the modern revival of the Oxfordian movement by seeking publicity through moot court trials, media debates, television, and later the Internet, including Wikipedia, methods which became standard for Oxfordian and anti-Stratfordian promoters because of their success in recruiting members of the lay public. He portrayed academic scholars as self-interested members of an "entrenched authority" that aimed to "outlaw and silence dissent in a supposedly free society", and proposed to counter their influence by portraying Oxford as a candidate on equal footing with Shakespeare. In 1985 he published his 900-page "The Mysterious William Shakespeare: the Myth and the Reality", and by framing the issue as one of fairness in the atmosphere of conspiracy that permeated America after Watergate, he used the media to circumnavigate academia and appeal directly to the public. Ogburn's efforts secured Oxford the place as the most popular alternative candidate.
Although Shakespearian experts disparaged Ogburn's methodology and his conclusions, one reviewer, Richmond Crinkley, the Folger Shakespeare Library's former director of educational programs, acknowledged the appeal of Ogburn's approach, writing that the doubts over Shakespeare, "arising early and growing rapidly", have a "simple, direct plausibility", and the dismissive attitude of established scholars only worked to encourage such doubts. Though Crinkley rejected Ogburn's thesis, calling it "less satisfactory than the unsatisfactory orthodoxy it challenges", he believed that one merit of the book lay in how it forces orthodox scholars to reexamine their concept of Shakespeare as author. Spurred by Ogburn's book, "[i]n the last decade of the twentieth century members of the Oxfordian camp gathered strength and made a fresh assault on the Shakespearean citadel, hoping finally to unseat the man from Stratford and install de Vere in his place."
The Oxfordian theory returned to wide public attention in anticipation of the late October 2011 release of Roland Emmerich's film "Anonymous". Its distributor, Sony Pictures, advertised that the film "presents a compelling portrait of Edward de Vere as the true author of Shakespeare's plays", and commissioned high school and college-level lesson plans to promote the authorship question to history and literature teachers across the United States. According to Sony Pictures, "The objective for our Anonymous program, as stated in the classroom literature, is 'to encourage critical thinking by challenging students to examine the theories about the authorship of Shakespeare's works and to formulate their own opinions.' The study guide does not state that Edward de Vere is the writer of Shakespeare's work, but it does pose the authorship question which has been debated by scholars for decades".
Variant Oxfordian theories.
Although most Oxfordians agree on the main arguments for Oxford, the theory has spawned schismatic variants that have not met with wide acceptance by all Oxfordians, although they have gained much attention.
Prince Tudor theory.
In a letter written by Looney in 1933, he mentions that Allen and Ward were "advancing certain views respecting Oxford and Queen Eliz. which appear to me extravagant & improbable, in no way strengthen Oxford’s Shakespeare claims, and are likely to bring the whole cause into ridicule." Allen and Ward believed that they had discovered that Elizabeth and Oxford were lovers and had conceived a child. Allen developed the theory in his 1934 book "Anne Cecil, Elizabeth & Oxford". He argued that the child was given the name William Hughes, who became an actor under the stage-name "William Shakespeare". He adopted the name because his father, Oxford, was already using it as a pen-name for his plays. Oxford had borrowed the name from a third Shakespeare, the man of that name from Stratford-upon-Avon, who was a law student at the time, but who was never an actor "or" a writer. Allen later changed his mind about Hughes and decided that the concealed child was the Earl of Southampton, the dedicatee of Shakespeare's narrative poems. This secret drama, which has become known as the Prince Tudor theory, was covertly represented in Oxford's plays and poems and remained hidden until Allen and Ward's discoveries. The narrative poems and sonnets had been written by Oxford for his son. "This Star of England" (1952) by Charlton and Dorothy Ogburn included arguments in support of this version of the theory. Their son, Charlton Ogburn, Jr, agreed with Looney that the theory was an impediment to the Oxfordian movement and omitted all discussion about it in his own Oxfordian works.
However, the theory was revived and expanded by Elisabeth Sears in "Shakespeare and the Tudor Rose" (2002), and Hank Whittemore in "The Monument" (2005), an analysis of Shakespeare's Sonnets which interprets the poems as a poetic history of Queen Elizabeth, Oxford, and Southampton. Paul Streitz's "Oxford: Son of Queen Elizabeth I" (2001) advances a variation on the theory: that Oxford himself was the illegitimate son of Queen Elizabeth by her stepfather, Thomas Seymour. Oxford was thus the half-brother of his own son by the queen. Streitz also believes that the queen had children by the Earl of Leicester. These were Robert Cecil, 1st Earl of Salisbury, Robert Devereux, 2nd Earl of Essex, Mary Sidney and Elizabeth Leighton.
Attribution of other works to Oxford.
As with other candidates for authorship of Shakespeare's works, Oxford's supporters have attributed numerous non-Shakespearian works to him. Looney began the process in his 1921 edition of de Vere's poetry. He suggested that de Vere was also responsible for some of the literary works credited to Arthur Golding, Anthony Munday and John Lyly. Streitz credits Oxford with the Authorized King James Version of the Bible. Two professors of linguistics have claimed that de Vere wrote not only the works of Shakespeare, but most of what is memorable in English literature during his lifetime, with such names as Edmund Spenser, Christopher Marlowe, Philip Sidney, John Lyly, George Peele, George Gascoigne, Raphael Holinshed, Robert Greene, Thomas Phaer, and Arthur Golding being among dozens of further pseudonyms of de Vere. Ramon Jiménez has credited Oxford with such plays as"The True Tragedy of Richard III" and "Edmund Ironside".
Group theories.
Group theories in which Oxford played the principal role as writer, but collaborated with others to create the Shakespeare canon, were adopted by a number of early Oxfordians. Looney himself was willing to concede that Oxford may have been assisted by his son-in-law William Stanley, 6th Earl of Derby, who perhaps wrote "The Tempest". B.M. Ward also suggested that Oxford and Derby worked together. In his later writings Percy Allen argued that Oxford led a group of writers, among whom was William Shakespeare. Group theories with Oxford as the principal author or creative "master mind" were also proposed by Gilbert Standen in "Shakespeare Authorship" (1930), Gilbert Slater in "Seven Shakespeares" (1931) and Montagu William Douglas in "Lord Oxford and the Shakespeare Group" (1952).
Case against Oxfordian theory.
Methodology of Oxfordian argument.
Specialists in Elizabethan literary history object to the methodology of Oxfordian arguments. In lieu of any evidence of the type commonly used for authorship attribution, Oxfordians discard the methods used by historians and employ other types of arguments to make their case, the most common being supposed parallels between Oxford's life and Shakespeare's works.
Another is finding cryptic allusions to Oxford's supposed play writing in other literary works of the era that to them suggest that his authorship was obvious to those "in the know". David Kathman writes that their methods are subjective and devoid of any evidential value, because they use a "double standard". Their arguments are "not taken seriously by Shakespeare scholars because they consistently distort and misrepresent the historical record", "neglect to provide necessary context" and calling some of their arguments "outright fabrication". One major evidential objection to the Oxfordian theory is Edward de Vere's 1604 death, after which a number of Shakespeare's plays are generally believed to have been written. In "The Shakespeare Claimants", a 1962 examination of the authorship question, H. N. Gibson concluded that "... on analysis the Oxfordian case appears to me a very weak one".
Mainstream objections.
Mainstream academics have often argued that the Oxford theory is based on snobbery: that anti-Stratfordians reject the idea that the son of a mere tradesman could write the plays and poems of Shakespeare. The Shakespeare Oxford Society has responded that this claim is "a substitute for reasoned responses to Oxfordian evidence and logic" and is merely an "ad hominem" attack, a charge echoed by journalists on both sides of the issue, including Michael Prescott and Joseph Sobran.
Mainstream critics further say that if William Shakespeare were a fraud instead of the true author, the number of people involved in suppressing this information would have made it highly unlikely to succeed. And citing the "testimony of contemporary writers, court records and much else" supporting Shakespeare's authorship, Columbia University professor James S. Shapiro points out the logically fatal tautology of any theory claiming that "there must have been a conspiracy to suppress the truth of de Vere's authorship" based on the idea that "the very absence of surviving evidence proves the case."
Circumstantial evidence.
While no documentary evidence connects Oxford (or any authorial candidate) to the plays of Shakespeare, Oxfordian writers, including Mark Anderson and Charlton Ogburn, say that connection is made by considerable circumstantial evidence inferred from Oxford's connections to the Elizabethan theatre and poetry scene; the participation of his family in the printing and publication of the First Folio; his relationship with the Earl of Southampton (believed by most Shakespeare scholars to have been Shakespeare's patron); as well as a number of specific incidents and circumstances of Oxford's life that Oxfordians say are depicted in the plays themselves.
Theatre connections.
Oxford was noted for his literary and theatrical patronage, garnering dedications from a wide range of authors. For much of his adult life, Oxford patronised both adult and boy acting companies, as well as performances by musicians, acrobats and performing animals, and in 1583, he was a leaseholder of the first Blackfriars Theatre in London.
Family connections.
Oxford was related to several noted literary figures. His mother, Margory Golding, was the sister of the Ovid translator Arthur Golding, and his uncle, Henry Howard, Earl of Surrey, was the inventor of the English or Shakespearian sonnet form.
The three dedicatees of Shakespeare's works (the earls of Southampton, Montgomery and Pembroke) were each proposed as husbands for the three daughters of Edward de Vere. "Venus and Adonis" and "The Rape of Lucrece" were dedicated to Southampton (whom many scholars have argued was the Fair Youth of the "Sonnets"), and the "First Folio" of Shakespeare's plays was dedicated to Montgomery (who married Susan de Vere) and Pembroke (who was once engaged to Bridget de Vere).
Oxford's Bible.
In the late 1990s, Roger A. Stritmatter conducted a study of the marked passages found in Edward de Vere's Geneva Bible, which is now owned by the Folger Shakespeare Library. The Bible contains 1,028 instances of underlined words or passages and a few hand-written annotations, most of which consist of a single word or fragment. Stritmatter believes about a quarter of the marked passages appear in Shakespeare's works as either a theme, allusion, or quotation. Stritmatter grouped the marked passages into eight themes. Arguing that the themes fitted de Vere's known interests, he proceeded to link specific themes to passages in Shakespeare. Critics have doubted that any of the underlinings or annotations in the Bible can be reliably attributed to de Vere and not the book's other owners prior to its acquisition by the Folger Shakespeare Library in 1925, as well as challenging the looseness of Stritmatter's standards for a Biblical allusion in Shakespeare's works and arguing that there is no statistical significance to the overlap.
Stratford connections.
Shakespeare's native Avon and Stratford are referred to in two prefatory poems in the 1623 First Folio, one of which refers to Shakespeare as "Swan of Avon" and another to the author's "Stratford monument". Oxfordians say the first of these phrases could refer to one of Edward de Vere's manors, Bilton Hall, near the Forest of Arden, in Rugby, on the River Avon. This view was first expressed by Charles Wisner Barrell, who argued that De Vere "kept the place as a literary hideaway where he could carry on his creative work without the interference of his father-in-law, Burghley, and other distractions of Court and city life." Oxfordians also consider it significant that the nearest town to the parish of Hackney, where de Vere later lived and was buried, was also named Stratford. Mainstream scholar Irvin Matus demonstrated that Oxford sold the Bilton house in 1580, having previously rented it out, making it unlikely that Ben Jonson's 1623 poem would identify Oxford by referring to a property he once owned, but never lived in, and sold 43 years earlier. Nor is there any evidence of a monument to Oxford in Stratford, London, or anywhere else; his widow provided for the creation of one at Hackney in her 1613 will, but there is no evidence that it was ever erected.
Oxford's annuity.
Oxfordians also believe that Rev. Dr. John Ward's 1662 diary entry stating that Shakespeare wrote two plays a year "and for that had an allowance so large that he spent at the rate of £1,000 a year" as a critical piece of evidence, since Queen Elizabeth I gave Oxford an annuity of exactly £1,000 beginning in 1586 that was continued until his death. Ogburn wrote that the annuity was granted "under mysterious circumstances", and Anderson suggests it was granted because of Oxford's writing patriotic plays for government propaganda. However, the documentary evidence indicates that the allowance was meant to relieve Oxford's embarrassed financial situation caused by the ruination of his estate.
Oxford's travels and the settings of Shakespeare's plays.
Almost half of Shakespeare's plays are set in Italy, many of them containing details of Italian laws, customs, and culture which Oxfordians believe could only have been obtained by personal experiences in Italy, and especially in Venice. The author of "The Merchant of Venice", Looney believed, "knew Italy first hand and was touched with the life and spirit of the country". This argument had earlier been used by supporters of the Earl of Rutland and the Earl of Derby as authorship candidates, both of whom had also travelled on the continent of Europe. Oxfordian William Farina refers to Shakespeare's apparent knowledge of the Jewish ghetto, Venetian architecture and laws in "The Merchant of Venice", especially the city's "notorious Alien Statute". Historical documents confirm that Oxford lived in Venice, and travelled for over a year through Italy. He disliked the country, writing in a letter to Lord Burghley dated 24 September 1575, "I am glad I have seen it, and I care not ever to see it any more". Still, he remained in Italy for another six months, leaving Venice in March 1576. According to Anderson, Oxford definitely visited Venice, Padua, Milan, Genoa, Palermo, Florence, Siena and Naples, and probably passed through Messina, Mantua and Verona, all cities used as settings by Shakespeare. In testimony before the Venetian Inquisition, Edward de Vere was said to be fluent in Italian.
However, some Shakespeare scholars say that Shakespeare gets many details of Italian life wrong, including the laws and urban geography of Venice. Kenneth Gross writes that "the play itself knows nothing about the Venetian ghetto; we get no sense of a legally separate region of Venice where Shylock must dwell." Scott McCrea describes the setting as "a nonrealistic Venice" and the laws invoked by Portia as part of the "imaginary world of the play", inconsistent with actual legal practice. Charles Ross points out that Shakespeare's Alien Statute bears little resemblance to any Italian law. For later plays such as "Othello", Shakespeare probably used Lewes Lewknor's 1599 English translation of Gasparo Contarini's "The Commonwealth and Government of Venice" for some details about Venice's laws and customs.
Shakespeare derived much of this material from John Florio, an Italian scholar living in England who was later thanked by Ben Jonson for helping him get Italian details right for his play "Volpone". Kier Elam has traced Shakespeare's Italian idioms in "Shrew" and some of the dialogue to Florio's "Second Fruits", a bilingual introduction to Italian language and culture published in 1591. Jason Lawrence believes that Shakespeare’s Italian dialogue in the play derives "almost entirely" from Florio’s "First Fruits"(1578). He also believes that Shakespeare became more proficient in reading the language as set out in Florio’s manuals, as evidenced by his increasing use of Florio and other Italian sources for writing the plays.
Oxford's education and knowledge of court life.
In 1567 Oxford was admitted to Gray's Inn, one of the Inns of Court which Justice Shallow reminisces about in "Henry IV, Part 2". Sobran observes that the Sonnets "abound not only in legal terms—more than 200—but also in elaborate legal conceits." These terms include: "allege, auditor, defects, exchequer, forfeit, heirs, impeach, lease, moiety, recompense, render, sureties," and "usage". Shakespeare also uses the legal term, "quietus" (final settlement), in Sonnet 134, the last Fair Youth sonnet.
Regarding Oxford's knowledge of court life, which Oxfordians believe is reflected throughout the plays, mainstream scholars say that any special knowledge of the aristocracy appearing in the plays can be more easily explained by Shakespeare's life-time of performances before nobility and royalty, and possibly, as Gibson theorises, "by visits to his patron's house, as Marlowe visited Walsingham."
Oxford's literary reputation.
Oxford's lyric poetry.
Some of Oxford's lyric works have survived. Stephen May, a leading authority on Oxford's poetry, attributes sixteen poems definitely and four possibly to Oxford, noting that these are probably "only a good sampling" as "both Webbe (1586) and Puttenham (1589) rank him first among the courtier poets, an eminence he probably would not have been granted, despite his reputation as a patron, by virtue of a mere handful of lyrics".
May describes Oxford as a "competent, fairly experimental poet working in the established modes of mid-century lyric verse" and his poetry as "examples of the standard varieties of mid-Elizabethan amorous lyric". In 2004, May wrote that Oxford's poetry was "one man's contribution to the rhetorical mainstream of an evolving Elizabethan poetic" and challenged readers to distinguish any of it from "the output of his mediocre mid-century contemporaries". C. S. Lewis wrote that de Vere's poetry shows "a faint talent", but is "for the most part undistinguished and verbose."
Comparisons to Shakespeare's work.
In the opinion of J. Thomas Looney, as "far as forms of versification are concerned De Vere presents just that rich variety which is so noticeable in Shakespeare; and almost all the forms he employs we find reproduced in the Shakespeare work." Oxfordian Louis P. Bénézet created the "Bénézet test", a collage of lines from Shakespeare and lines he thought were representative of Oxford, challenging non-specialists to tell the difference between the two authors. May notes that Looney compared various motifs, rhetorical devices and phrases with certain Shakespeare works to find similarities he said were "the most crucial in the piecing together of the case", but that Looney used six poems mistakenly attributed to Oxford that were actually written by Greene, Campion, and Greville for some of those "crucial" examples. Bénézet also used two lines from Greene that he thought were Oxford's, while succeeding Oxfordians, including Charles Wisner Barrell, have also misattributed poems to Oxford. "This on-going confusion of Oxford's genuine verse with that of at least three other poets," writes May, "illustrates the wholesale failure of the basic Oxfordian methodology."
According to a computerised textual comparison developed by the Claremont Shakespeare Clinic, the styles of Shakespeare and Oxford were found to be "light years apart", and the odds of Oxford having written Shakespeare were reported as "lower than the odds of getting hit by lightning". Furthermore, while the First Folio shows traces of a dialect identical to Shakespeare's, the Earl of Oxford, raised in Essex, spoke an East Anglian dialect. John Shahan and Richard Whalen, writing in "The Oxfordian" (volume IX, 2006), condemned the Claremont study, calling it "apples to oranges", and noting that the study did not compare Oxford's songs to Shakespeare's songs, did not compare a clean unconfounded sample of Oxford's poems with Shakespeare's poems, and charged that the students under Elliott and Valenza's supervision incorrectly assumed that Oxford's youthful verse was representative of his mature poetry.
Joseph Sobran's book, "Alias Shakespeare", includes Oxford's known poetry in an appendix with what he considers extensive verbal parallels with the work of Shakespeare, and he argues that Oxford's poetry is comparable in quality to some of Shakespeare's early work, such as "Titus Andronicus". Other Oxfordians say that de Vere's extant work is that of a young man and should be considered juvenilia, while May believes that all the evidence dates his surviving work to his early 20s and later.
Contemporary reception.
Four contemporary critics praise Oxford as a poet and a playwright, three of them within his lifetime:
Mainstream scholarship characterises the extravagant praise for de Vere's poetry more as a convention of flattery than honest appreciation of literary merit. Alan Nelson, de Vere's documentary biographer, writes that "[c]ontemporary observers such as Harvey, Webbe, Puttenham and Meres clearly exaggerated Oxford's talent in deference to his rank."
Perceived allusions to Oxford as a concealed writer.
Before the advent of copyright, anonymous and pseudonymous publication was a common practice in the sixteenth century publishing world, and a passage in the "Arte of English Poesie" (1589), an anonymously published work itself, mentions in passing that literary figures in the court who wrote "commendably well" circulated their poetry only among their friends, "as if it were a discredit for a gentleman to seem learned" (Book 1, Chapter 8). In another passage 23 chapters later, the author (probably George Puttenham) speaks of aristocratic writers who, if their writings were made public, would appear to be excellent. It is in this passage that Oxford appears on a list of poets.
According to Daniel Wright, these combined passages confirm that Oxford was one of the concealed writers in the Elizabethan court. Critics of this view argue that Oxford nor any other writer is not here identified as a concealed writer, but as the first in a list of "known" modern writers whose works have already been "made public", "of which number is first" Oxford, adding to the publicly acknowledged literary tradition dating back to Geoffrey Chaucer. Other critics interpret the passage to mean that the courtly writers and their works are known within courtly circles, but not to the general public. In either case, neither Oxford nor anyone else is identified as a hidden writer or one that used a pseudonym.
Oxfordians argue that at the time of the passage's composition (pre-1589), the writers referenced were not in print, and interpret Puttenham's passage (that the noblemen preferred to 'suppress' their work to avoid the discredit of appearing learned) to mean that they were 'concealed'. They cite Sir Philip Sidney, none of whose poetry was published until after his premature death, as an example. Similarly, by 1589 nothing by Greville was in print, and only one of Walter Raleigh's works had been published.
Critics point out that six of the nine poets listed had appeared in print under their own names long before 1589, including a number of Oxford's poems in printed miscellanies, and the first poem published under Oxford's name was printed in 1572, 17 years before Puttenham's book was published. Several other contemporary authors name Oxford as a poet, and Puttenham himself quotes one of Oxford's verses elsewhere in the book, referring to him by name as the author, so Oxfordians misread Puttenham.
Oxfordians also believe other texts refer to the Edward de Vere as a concealed writer. They argue that satirist John Marston's "Scourge of Villanie" (1598) contains further cryptic allusions to Oxford, named as "Mutius". Marston expert Arnold Davenport believes that Mutius is the bishop-poet Joseph Hall and that Marston is criticising Hall's satires.
There is a description of the figure of Oxford in "The Revenge of Bussy D'Ambois", a 1613 play by George Chapman, who has been suggested as the Rival Poet of Shakespeare's Sonnets. Chapman describes Oxford as "Rare and most absolute" in form and says he was "of spirit passing great / Valiant and learn’d, and liberal as the sun". He adds that he "spoke and writ sweetly" of both learned subjects and matters of state ("public weal").
Chronology of the plays and Oxford's 1604 death.
For mainstream Shakespearian scholars, the most compelling evidence against Oxford (besides the historical evidence for William Shakespeare) is his death in 1604, since the generally accepted chronology of Shakespeare's plays places the composition of approximately twelve of the plays after that date. Critics often cite "The Tempest" and "Macbeth", for example, as having been written after 1604.
The exact dates of the composition of most of Shakespeare's plays are uncertain, although David Bevington says it is a 'virtually unanimous' opinion among teachers and scholars of Shakespeare that the canon of late plays depicts an artistic journey that extends well beyond 1604. Evidence for this includes allusions to historical events and literary sources which postdate 1604, as well as Shakespeare's adaptation of his style to accommodate Jacobean literary tastes and the changing membership of the King's Men and their different venues.
Oxfordians say that the conventional composition dates for the plays were developed by mainstream scholars to fit within Shakespeare's lifetime and that no evidence exists that any plays were written after 1604. Anderson argues that all of the Jacobean plays were written before 1604, selectively citing non-Oxfordian scholars like Alfred Harbage, Karl Elze, and Andrew Cairncross to bolster his case. Anderson notes that from 1593 through 1603, the publication of new plays appeared at the rate of two per year, and whenever an inferior or pirated text was published, it was typically followed by a genuine text described on the title page as "newly augmented" or "corrected". After the publication of the Q1 and Q2 "Hamlet" in 1603, no new plays were published until 1608. Anderson observes that, "After 1604, the 'newly correct[ing]' and 'augment[ing]' stops. Once again, the Shake-speare ["sic"] enterprise appears to have shut down".
Notable silences.
Because Shakespeare lived until 1616, Oxfordians question why, if he were the author, did he not eulogise Queen Elizabeth at her death in 1603 or Henry, Prince of Wales, at his in 1612. They believe Oxford's 1604 death provides the explanation. In an age when such actions were expected, Shakespeare also failed to memorialise the coronation of James I in 1604, the marriage of Princess Elizabeth in 1612, and the investiture of Prince Charles as the new Prince of Wales in 1613.
Anderson contends that Shakespeare refers to the latest scientific discoveries and events through the end of the 16th century, but "is mute about science after de Vere’s [Oxford’s] death in 1604". He believes that the absence of any mention of the spectacular supernova of October 1604 or Kepler’s revolutionary 1609 study of planetary orbits are especially noteworthy.
The move to the Blackfriars.
Professor Jonathan Bate writes that Oxfordians cannot "provide any explanation for ... technical changes attendant on the King's Men's move to the Blackfriars theatre four years after their candidate's death ... Unlike the Globe, the Blackfriars was an indoor playhouse" and so required plays with frequent breaks in order to replace the candles it used for lighting. "The plays written after Shakespeare's company began using the Blackfriars in 1608, "Cymbeline" and "The Winter's Tale" for instance, have what most ... of the earlier plays do not have: a carefully planned five-act structure". If new Shakespearian plays were being written especially for presentation at the Blackfriars' theatre after 1608, they could not have been written by Edward de Vere.
Oxfordians argue that Oxford was well acquainted with the Blackfriars Theatre, having been a leaseholder of the venue, and note that the "assumption" that Shakespeare wrote plays for the Blackfriars is not universally accepted, citing Shakespearian scholars such as A. Nicoll who said that "all available evidence is either completely negative or else runs directly counter to such a supposition" and Harley Granville-Barker, who stated "Shakespeare did not write (except for Henry V) five-act plays at any stage of his career. The five-act structure was formalized in the First Folio, and is inauthentic".
Shakespeare's late collaborations.
Further, attribution studies have shown that certain plays in the canon were written by two or three hands, which Oxfordians believe is explained by these plays being either drafted earlier than conventionally believed, or simply revised/completed by others after Oxford's death. Shapiro calls this a 'nightmare' for Oxfordians, implying a 'jumble sale scenario' for his literary remains long after his death.
Identification of earlier works with Shakespeare plays.
Some Oxfordians have identified titles or descriptions of lost works from Oxford's lifetime that suggest a thematic similarity to a particular Shakespearian play and asserted that they were earlier versions. For example, in 1732, the antiquarian Francis Peck published in "Desiderata Curiosa" a list of documents in his possession that he intended to print someday. They included "a pleasant conceit of Vere, earl of Oxford, discontented at the rising of a mean gentleman in the English court, circa 1580." Peck never published his archives, which are now lost. To Anderson, Peck's description suggests that this conceit is "arguably an early draft of "Twelfth Night"."
Contemporary references to Shakespeare as alive or dead.
Oxfordian writers say some literary allusions imply that the playwright and poet died prior to 1609, when "Shake-Speares Sonnets" appeared with the epithet "our ever-living poet" in its dedication. They claim that the phrase "ever-living" rarely, if ever, referred to a living person, but instead was used to refer to the eternal soul of the deceased. Bacon, Derby, Neville, and William Shakespeare all lived well past the 1609 publication of the Sonnets.
However, Don Foster, in his study of Early Modern uses of the phrase "ever-living", argues that the phrase most frequently refers to God or other supernatural beings, suggesting that the dedication calls upon God to bless the living begetter (writer) of the sonnets. He states that the initials "W. H." were a misprint for "W. S." or "W. SH". Bate thinks it a misprint as well, but he thinks it "improbable" that the phrase refers to God. and suggests that the "ever-living poet" might be "a great dead English poet who had written on the great theme of poetic immortality", such as Sir Philip Sidney or Edmund Spenser.
Joseph Sobran, in "Alias Shakespeare," argued that in 1607 William Barksted, a minor poet and playwright, implies in his poem "Mirrha the Mother of Adonis" that Shakespeare was already deceased. Shakespeare scholars explain that Sobran has simply misread Barkstead’s poem, the last stanza of which is a comparison of Barkstead’s poem to Shakespeare’s "Venus and Adonis", and has mistaken the grammar also, which makes it clear that Barkstead is referring to Shakespeare’s "song" in the past tense, not Shakespeare himself. This context is obvious when the rest of the stanza is included.
Against the Oxford theory are several references to Shakespeare, later than 1604, which imply that the author was then still alive. Scholars point to a poem written circa 1620 by a student at Oxford, William Basse, that mentioned the author Shakespeare died in 1616, which is the year Shakespeare deceased and not Edward de Vere.
Dates of composition.
"The Two Gentlemen of Verona".
Tom Veal has noted that the early play "The Two Gentlemen of Verona" reveals no familiarity on the playwright's part with Italy other than "a few place names and the scarcely recondite fact that the inhabitants were Roman Catholics." For example, the play's Verona is situated on a tidal river and has a duke, and none of the characters have distinctly Italian names like in the later plays. Therefore, if the play was written by Oxford, it must have been before he visited Italy in 1575. However, the play's principal source, the Spanish "Diana Enamorada", would not be translated into French or English until 1578, meaning that someone basing a play on it that early could only have read it in the original Spanish, and there is no evidence that Oxford spoke this language. Furthermore, Veal argues, the only explanation for the verbal parallels with the English translation of 1582 would be that the translator saw the play performed and echoed it in his translation, which he describes as "not an impossible theory but far from a plausible one."
"Hamlet".
The composition date of "Hamlet" has been frequently disputed. Several surviving references indicate that a Hamlet-like play was well-known throughout the 1590s, well before the traditional period of composition (1599–1601). Most scholars refer to this lost early play as the Ur-Hamlet; the earliest reference is in 1589. A 1594 performance record of "Hamlet" appears in Philip Henslowe's diary, and Thomas Lodge wrote of it in 1596.
Oxfordian researchers believe that the play is an early version of Shakespeare's own play, and point to the fact that Shakespeare's version survives in three quite different early texts, Q1 (1603), Q2 (1604) and F (1623), suggesting the possibility that it was revised by the author over a period of many years.
"Macbeth".
Scholars contend that the composition date of "Macbeth" is one of the most overwhelming pieces of evidence against the Oxfordian position; the vast majority of critics believe the play was written in the aftermath of the Gunpowder Plot. This plot was brought to light on 5 November 1605, a year after Oxford died. In particular, scholars identify the porter's lines about "equivocation" and treason as an allusion to the trial of Henry Garnet in 1606. Oxfordians respond that the concept of "equivocation" was the subject of a 1583 tract by Queen Elizabeth's chief councillor (and Oxford's father-in-law) Lord Burghley, as well as of the 1584 "Doctrine of Equivocation" by the Spanish prelate Martín de Azpilcueta, which was disseminated across Europe and into England in the 1590s.
"Coriolanus".
Shakespearian scholar David Haley asserts that if Edward de Vere had written "Coriolanus", he "must have foreseen the Midland Revolt grain riots [of 1607] reported in Coriolanus", possible topical allusions in the play that most Shakespearians accept.
"The Tempest".
The play that can be dated within a fourteen-month period is The Tempest. This play has long been believed to have been inspired by the 1609 wreck at Bermuda, then feared by mariners as the "Isle of the Devils", of the flagship of the Virginia Company, the Sea Venture, while leading the Third Supply to relieve Jamestown in the Colony of Virginia. The Sea Venture was captained by Christopher Newport, and carried the Admiral of the company's fleet, Sir George Somers (for whom the archipelago would subsequently be named "The Somers Isles"). The survivors spent nine months in Bermuda before most completed the journey to Jamestown on 23 May 1610 aboard two new ships built from scratch. One of the survivors was the newly-appointed Governor, Sir Thomas Gates. Jamestown, then little more than a rudimentary fort, was found in such a poor condition, with the majority of the previous settlers dead or dying, that Gates and Somers decided to abandon the settlement and the continent, returning everyone to England. However, with the company believing all aboard the Sea Venture dead, a new governor, Baron De La Warr, had been sent with the Fourth Supply fleet, which arrived on 10 June 1610 as Jamestown was being abandoned.
De la Warr remained in Jamestown as Governor, while Gates returned to England (and Somers to Bermuda), arriving in September, 1610. The news of the survival of the Sea Venture's passengers and crew caused a great sensation in England. Two accounts were published: Sylvester Jordain's "A Discovery of the Barmvdas, Otherwise Called the Ile of Divels", in October, 1610, and "A True Declaration of the Estate of the Colonie in Virginia" a month later. The "True Reportory of the Wrack, and Redemption of Sir Thomas Gates Knight", an account by William Strachey dated 15 July 1610, returned to England with Gates in the form of a letter which was circulated privately until its eventual publication in 1625. Shakespeare had multiple contacts to the circle of people amongst whom the letter circled, including to Strachey. "The Tempest" shows clear evidence that he had read and relied on Jordain and especially Stratchey. The play shares premise, basic plot, and many details of the Sea Venture's wrecking and the adventures of the survivors, as well as specific details and linguistics. A detailed comparative analysis shows the "Declaration" to have been the primary source from which the play was drawn. This firmly dates the writing of the play to the months between Gates' return to England and the 1st of November, 1611.
Oxfordians have dealt with this problem in several ways. Looney expelled the play from the canon, arguing that its style and the "dreary negativism" it promoted were inconsistent with Shakespeare's "essentially positivist" soul, and so could not have been written by Oxford. Later Oxfordians have generally abandoned this argument; this has made severing the connection of the play with the wreck of the Sea Venture a priority amongst Oxfordians. A variety of attacks have been directed on the links. These include attempting to cast doubt on whether the "Declaration" travelled back to England with Gates, whether Gates travelled back to England early enough, whether the lowly Shakespeare would have had access to the lofty circles in which the "Declaration" was circulated, to understating the points of similarity between the Sea Venture wreck and the accounts of it, on the one hand, and the play on the other. Oxfordians have even claimed that the writers of the first-hand accounts of the real wreck based them on "The Tempest", or, at least, the same antiquated sources that Shakespeare, or rather Oxford, is imagined to have used exclusively, including Richard Eden's "The Decades of the New Worlde Or West India" (1555) and Desiderius Erasmus's "Naufragium"/"The Shipwreck" (1523). Alden Vaughan commented in 2008 that "[t]he argument that Shakespeare could have gotten every thematic thread, every detail of the storm, and every similarity of word and phrase from other sources stretches credulity to the limits."
"Henry VIII".
Oxfordians note that while the conventional dating for "Henry VIII" is 1610-13, the majority of 18th and 19th century scholars, including notables such as Samuel Johnson, Lewis Theobald, George Steevens, Edmond Malone, and James Halliwell-Phillipps, placed the composition of "Henry VIII" prior to 1604, as they believed Elizabeth's execution of Mary, Queen of Scots (the then king James I's mother) made any vigorous defence of the Tudors politically inappropriate in the England of James I. Though it is described as a new play by two witnesses in 1613, Oxfordians argue that this refers to the fact it was new on stage, having its first production in that year.
Oxfordian cryptology.
Although searching Shakespeare's works for encrypted clues supposedly left by the true author is associated mainly with the Baconian theory, such arguments are often made by Oxfordians as well. Early Oxfordians found many references to Oxford's family name "Vere" in the plays and poems, in supposed puns on words such as "ever" (E. Vere). "The De Vere Code", a book by English actor Jonathan Bond, the author believes that Thomas Thorpe´s 30-word dedication to the original publication of Shakespeare's Sonnets contains six simple encryptions which conclusively establish de Vere as the author of the poems. He also writes that the alleged encryptions settle the question of the identity of "the Fair Youth" as Henry Wriothesley and contain striking references to the sonnets themselves and de Vere's relationship to Sir Philip Sidney and Ben Jonson.
Similarly, a 2009 article in the Oxfordian journal "Brief Chronicles" noted that Francis Meres, in "Palladis Tamia" compares 17 named English poets to 16 named classical poets. Writing that Meres was obsessed with numerology, the authors propose that the numbers should be symmetrical, and that careful readers are meant to infer that Meres knew two of the English poets (viz., Oxford and Shakespeare) to actually be one and the same.
Parallels with the plays.
Literary scholars say that the idea that an author's work must reflect his or her life is a Modernist assumption not held by Elizabethan writers, and that biographical interpretations of literature are unreliable in attributing authorship. Further, such lists of similarities between incidents in the plays and the life of an aristocrat are flawed arguments because similar lists have been drawn up for many competing candidates, such as Francis Bacon and William Stanley, 6th Earl of Derby. Harold Love writes that "The very fact that their application has produced so many rival claimants demonstrates their unreliability," and Jonathan Bate writes that the Oxfordian biographical method "is in essence no different from the cryptogram, since Shakespeare's range of characters and plots, both familial and political, is so vast that it would be possible to find in the plays 'self-portraits' of ... anybody one cares to think of."
Despite this, Oxfordians list numerous incidents in Oxford's life that they say parallel those in many of the Shakespeare plays. Most notable among these, they say, are certain similar incidents found in Oxford's biography and "Hamlet", and "Henry IV, Part 1", which includes a well-known robbery scene with uncanny parallels to a real-life incident involving Oxford.
"Hamlet".
Most Oxfordians consider Hamlet the play most easily seen as portraying Oxford's life story, though mainstream scholars say that incidents from the lives of other contemporary figures such as King James or the Earl of Essex, fit the play just as closely, if not more so.
Hamlet's father was murdered and his mother made an "o'er-hasty marriage" less than two months later. Oxfordians see a parallel with Oxford's life, as Oxford's father died at the age of 46 on 3 August 1562, although not before making a will six days earlier, and his stepmother remarried within 15 months, although exactly when is unknown.
Another frequently-cited parallel involves Hamlet's revelation in Act IV that he was earlier taken captive by pirates. On Oxford's return from Europe in 1576, he encountered a cavalry division outside of Paris that was being led by a German duke, and his ship was hijacked by pirates who robbed him and left him stripped to his shirt, and who might have murdered him had not one of them recognised him. Anderson notes that "[n]either the encounter with Fortinbras' army nor Hamlet's brush with buccaneers appears in any of the play's sources – to the puzzlement of numerous literary critics."
Polonius.
Such speculation often identifies the character of Polonius as a caricature of Lord Burghley, Oxford's guardian from the age of 12.
In the First Quarto the character was not named Polonius, but Corambis. Ogburn writes that "Cor ambis" can be interpreted as "two-hearted" (a view not independently supported by Latinists). He says the name is a swipe "at Burghley's motto, "Cor unum, via una", or 'one heart, one way.'" Scholars suggest that it derives from the Latin phrase "crambe repetita" meaning "reheated cabbage", which was expanded in Elizabethan usage to ""Crambe bis" posita mors est" ("twice served cabbage is deadly"), which implies "a boring old man" who spouts trite rehashed ideas. Similar variants such as "Crambo" and "Corabme" appear in Latin-English dictionaries at the time.
Bed trick.
In his "Memoires" (1658), Francis Osborne writes of "the last great "Earle of Oxford", whose "Lady" was brought to his bed under the notion of his "Mistris", and from such a virtuous deceit she (Oxford's youngest daughter) is said to proceed" (p. 79).
Such a bed trick has been a dramatic convention since antiquity and was used more than 40 times by every major playwright in the Early Modern theatre era except for Ben Jonson. Thomas Middleton used it five times and Shakespeare and James Shirley used it four times. Shakespeare's use of it in "All's Well That Ends Well" and "Measure for Measure" followed his sources for the plays (stories by Boccaccio and Cinthio); nevertheless Oxfordians say that de Vere was drawn to these stories because they "paralleled his own", based on Osborne's anecdote.
Earls of Oxford in the histories.
Oxfordians claim that flattering treatment of Oxford's ancestors in Shakespeare's history plays is evidence of his authorship. Shakespeare omitted the character of the traitorous Robert de Vere, 3rd Earl of Oxford in "The Life and Death of King John", and the character of the 12th Earl of Oxford is given a much more prominent role in "Henry V" than his limited involvement in the actual history of the times would allow. The 12th Earl is given an even more prominent role in the non-Shakespearian play "The Famous Victories of Henry the fifth". Some Oxfordians argue that this was another play written by Oxford, based on the exaggerated role it gave to the 11th Earl of Oxford.
J. Thomas Looney found John de Vere, 13th Earl of Oxford is "hardly mentioned except to be praised" in "Henry VI, Part Three"; the play ahistorically depicts him participating in the Battle of Tewkesbury and being captured. Oxfordians, such as Dorothy and Charlton Ogburn, believe Shakespeare created such a role for the 13th Earl because it was the easiest way Edward de Vere could have "advertised his loyalty to the Tudor Queen" and remind her of "the historic part borne by the Earls of Oxford in defeating the usurpers and restoring the Lancastrians to power". Looney also notes that in "Richard III", when the future Henry VII appears, the same Earl of Oxford is "by his side; and it is Oxford who, as premier nobleman, replies first to the king's address to his followers".
Non-Oxfordian writers do not see any evidence of partiality for the de Vere family in the plays. Richard de Vere, 11th Earl of Oxford, who plays a prominent role in the anonymous "The Famous Victories of Henry V", does not appear in Shakespeare's "Henry V", nor is he even mentioned. In "Richard III", Oxford's reply to the king noted by Looney is a mere two lines, the only lines he speaks in the play. He has a much more prominent role in the non-Shakespearian play "The True Tragedy of Richard III". On these grounds the scholar Benjamin Griffin argues that the non-Shakespearian plays, the "Famous Victories" and "True Tragedy", are the ones connected to Oxford, possibly written for Oxford's Men. Oxfordian Charlton Ogburn Jr. argues that the role of the Earls of Oxford was played down in "Henry V" and "Richard III" to maintain Oxford's nominal anonymity. This is because "It would not do to have a performance of one of his plays at Court greeted with ill-suppressed knowing chuckles."
Oxford's finances.
In 1577 the Company of Cathay was formed to support Martin Frobisher’s hunt for the Northwest Passage, although Frobisher and his investors quickly became distracted by reports of gold at Hall’s Island. With thoughts of an impending Canadian gold-rush and trusting in the financial advice of Michael Lok, the treasurer of the company, de Vere signed a bond for £3,000 in order to invest £1,000 and to assume £2,000 worth—about half—of Lok's personal investment in the enterprise. Oxfordians say this is similar to Antonio in "The Merchant of Venice", who was indebted to Shylock for 3,000 ducats against the successful return of his vessels.
Oxfordians also note that when de Vere travelled through Venice, he borrowed 500 crowns from a Baptista Nigrone. In Padua, he borrowed from a man named Pasquino Spinola. In "The Taming of the Shrew", Kate's father is described as a man "rich in crowns." He, too, is from Padua, and his name is Baptista Minola, which Oxfordians take to be a conflation of Baptista Nigrone and Pasquino Spinola.
When the character of Antipholus of Ephesus in "The Comedy of Errors" tells his servant to go out and buy some rope, the servant (Dromio) replies, "I buy a thousand pounds a year! I buy a rope!" (Act 4, scene 1). The meaning of Dromio’s line has not been satisfactorily explained by critics, but Oxfordians say the line is somehow connected to the fact that de Vere was given a £1,000 annuity by the Queen, later continued by King James.
Marriage and affairs.
Oxfordians see Oxford's marriage to Anne Cecil, Lord Burghley's daughter, paralleled in such plays as "Hamlet", "Othello", "Cymbeline", "The Merry Wives of Windsor", "All's Well That Ends Well", "Measure for Measure", "Much Ado About Nothing", and "The Winter's Tale".
Oxford's illicit congress with Anne Vavasour resulted in an intermittent series of street battles between the Knyvet clan, led by Anne's uncle, Sir Thomas Knyvet, and Oxford’s men. As in "Romeo and Juliet", this imbroglio produced three deaths and several other injuries. The feud was finally put to an end only by the intervention of the Queen.
Oxford's criminal associations.
In May 1573, in a letter to Lord Burghley, two of Oxford's former employees accused three of Oxford's friends of attacking them on "the highway from Gravesend to Rochester." In Shakespeare's "Henry IV, Part 1", Falstaff and three roguish friends of Prince Hal also waylay unwary travellers at Gad's Hill, which is on the highway from Gravesend to Rochester. Scott McCrea says that there is little similarity between the two events, since the crime described in the letter is unlikely to have occurred near Gad's Hill and was not a robbery, but rather an attempted shooting. Mainstream writers also say that this episode derives from an earlier anonymous play, "The Famous Victories of Henry V", which was Shakespeare's source. Some Oxfordians argue that "The Famous Victories" was written by Oxford, based on the exaggerated role it gave to the 11th Earl of Oxford.
Parallels with the sonnets and poems.
In 1609, a volume of 154 linked poems was published under the title "SHAKE-SPEARES SONNETS". Oxfordians believe the title ("Shake-Speares Sonnets") suggests a finality indicating that it was a completed body of work with no further sonnets expected, and consider the differences of opinion among Shakespearian scholars as to whether the Sonnets are fictional or autobiographical to be a serious problem facing orthodox scholars. Joseph Sobran questions why Shakespeare (who lived until 1616) failed to publish a corrected and authorised edition if they are fiction, as well as why they fail to match Shakespeare's life story if they are autobiographic. According to Sobran and other researchers, the themes and personal circumstances expounded by the author of the Sonnets are remarkably similar to Oxford's biography.
The Fair Youth, the Dark Lady, and the Rival Poet.
The focus of the 154 sonnet series appears to narrate the author's relationships with three characters: the Fair Youth, the Dark Lady or Mistress, and the Rival Poet. Beginning with Looney, most Oxfordians (exceptions are Percy Allen and Louis Bénézet) believe that the "Fair Youth" referred to in the early sonnets refers to Henry Wriothesley, 3rd Earl of Southampton, Oxford's peer and prospective son-in-law. The Dark Lady is believed by some Oxfordians to be Anne Vavasour, Oxford's mistress who bore him a son out of wedlock. A case was made by the Oxfordian Peter R. Moore that the Rival Poet was Robert Devereux, Earl of Essex.
Sobran suggests that the so-called procreation sonnets were part of a campaign by Burghley to persuade Southampton to marry his granddaughter, Oxford's daughter Elizabeth de Vere, and says that it was more likely that Oxford would have participated in such a campaign than that Shakespeare would know the parties involved or presume to give advice to the nobility.
Oxfordians also assert that the tone of the poems is that of a nobleman addressing an equal rather than that of a poet addressing his patron. According to them, Sonnet 91 (which compares the Fair Youth's love to such treasures as high birth, wealth, and horses) implies that the author is in a position to make such comparisons, and the 'high birth' he refers to is his own.
Age and lameness.
Oxford was born in 1550, and was between 40 and 53 years old when he presumably would have written the sonnets. Shakespeare was born in 1564. Even though the average life expectancy of Elizabethans was short, being between 26 and 39 was not considered old. In spite of this, age and growing older are recurring themes in the Sonnets, for example, in Sonnets 138 and 37. In his later years, Oxford described himself as "lame". On several occasions, the author of the sonnets also described himself as lame, such as in Sonnets 37 and 89.
Public disgrace.
Sobran also believes "scholars have largely ignored one of the chief themes of the Sonnets: the poet's sense of disgrace ... [T]here can be no doubt that the poet is referring to something real that he expects his friends to know about; in fact, he makes clear that a wide public knows about it ... Once again the poet's situation matches Oxford's ... He has been a topic of scandal on several occasions. And his contemporaries saw the course of his life as one of decline from great wealth, honor, and promise to disgrace and ruin. This perception was underlined by enemies who accused him of every imaginable offense and perversion, charges he was apparently unable to rebut." Examples include Sonnets 29 and 112.
As early as 1576, Edward de Vere was writing about this subject in his poem "Loss of Good Name", which Steven W. May described as "a defiant lyric without precedent in English Renaissance verse."
Lost fame.
The poems "Venus and Adonis" and "Lucrece", first published in 1593 and 1594 under the name "William Shakespeare", proved highly popular for several decades – with "Venus and Adonis" published six more times before 1616, while "Lucrece" required four additional printings during this same period. By 1598, they were so famous, London poet and sonneteer Richard Barnefield wrote:
<poem>Shakespeare...
Whose "Venus" and whose "Lucrece" (sweet and chaste)
Thy name in fame's immortal Book have plac't
Live ever you, at least in Fame live ever:
Well may the Body die, but Fame dies never.</poem>
Despite such publicity, Sobran observed, "[t]he author of the Sonnets expects and hopes to be forgotten. While he is confident that his poetry will outlast marble and monument, it will immortalize his young friend, not himself. He says that his style is so distinctive and unchanging that 'every word doth almost tell my name,' implying that his name is otherwise concealed – at a time when he is publishing long poems under the name William Shakespeare. This seems to mean that he is not writing these Sonnets under that (hidden) name." Oxfordians have interpreted the phrase "every word" as a pun on the word "every", standing for "e vere" - thus telling his name. Mainstream writers respond that several sonnets literally do tell his name, containing numerous puns on the name Will[iam]; in sonnet 136 the poet directly says "thou lov'st me for my name is Will."
Based on Sonnets 81, 72, and others, Oxfordians assert that if the author expected his "name" to be "forgotten" and "buried", it would not have been the name that permanently adorned the published works themselves.
Notes.
Footnotes.
The UK and US editions of differ significantly in pagination. The citations to the book used in this article list the UK page numbers first, followed by the page numbers of the US edition in parentheses.
References.
</dl>

</doc>
<doc id="22677" url="http://en.wikipedia.org/wiki?curid=22677" title="Oxymoron">
Oxymoron

Types.
The most common form of oxymoron involves an adjective–noun combination of two words. For example, the following line from Tennyson's "Idylls of the King" contains two oxymora: 
And faith unfaithful kept him falsely true.
Other examples of oxymora of this kind include:
Less often seen are noun–verb combinations of two words, such as the line "The silence whistles" from Nathan Alterman's "Summer Night", or in a song title like Simon & Garfunkel's "The Sound of Silence".
Oxymora are not always a pair of words; they can also be devised in the meaning of sentences or phrases.
Etymology.
Oxymoron is derived from the 5th century Latin "oxymoron", which is derived from the Ancient Greek: ὀξύς "oxus" "sharp, keen" and μωρός "mōros" "dull, stupid", making the word itself an oxymoron. However, the combined Greek form ὀξύμωρον ("oxumōron") does not in fact appear in the extant Greek sources.
Taxonomy.
Richard Lederer assembled a taxonomy of oxymora in an article in "Word Ways" in 1990, running from single-word oxymora such as "pianoforte" (literally, "soft-loud") through "doublespeak oxymora" (deliberately intended to confuse) and "opinion oxymora" (editorial opinions designed to provoke a laugh). In general, oxymora can be divided into expressions that were deliberately crafted to be contradictory and those phrases that inadvertently or incidentally contain a contradiction, often as a result of a punning use of one or both words.
Apparent oxymora.
Many oxymora have been popularised in vernacular speech. Examples include "controlled chaos","an honourable death", "open secret", "organized mess", "alone in a crowd", and "accidentally on purpose".
There are also examples in which terms that are superficially contradictory are juxtaposed in such a way that there is no contradiction. Examples include "same difference", "jumbo shrimp", and "hot ice" (where "hot" means "stolen" and "ice" means "diamonds", in criminal argot).
Oxymora as paradoxes.
Writers often use an oxymoron to call attention to an apparent contradiction. For example, Wilfred Owen's poem "The Send-off" refers to soldiers leaving for the front line, who "lined the train with faces grimly gay." The oxymoron "grimly gay" highlights the contradiction between how the soldiers feel and how they act: though they put on a brave face and act cheerfully, they feel grim.
Similarly, in Henry James' novella "The Lesson of the Master", a character is described as dressed in a manner "conventionally unconventional, suggesting a tortuous spontaneity." In this way James highlights the contradiction between the character's desire to appear spontaneous, and the efforts she makes to appear so.
One case where many oxymora are strung together can be found in Shakespeare's "Romeo and Juliet", where Romeo declares: 
O heavy lightness! Serious vanity!Mis-shapen chaos of well-seeming forms!Feather of lead, bright smoke, cold fire, sick health!
Some paradoxical oxymora become clichés:
Terms falsely called oxymora for rhetorical effect.
Although a true oxymoron is "something that is surprisingly true, a paradox", Garry Wills has argued that modern usage has brought a common misunderstanding that "oxymoron" is nearly synonymous with "contradiction". The introduction of this misuse, the opposite of its true meaning, has been credited to William F. Buckley.
Sometimes a pair of terms is claimed to be an oxymoron by those who hold the opinion that the two are mutually exclusive. That is, although there is no "inherent" contradiction between the terms, the speaker expresses the opinion that the two terms imply properties or characteristics that cannot occur together. Such claims may be made purely for humorous effect. Comedian George Carlin popularized many examples, such as "military intelligence", "freedom fighters", and "business ethics". Another example is the term "civil war", which is not an oxymoron, but can be claimed to be so for humorous effect, if "civil" is construed as meaning "polite" rather than "between citizens of the same state". Alternatively, such claims may reflect a genuinely held opinion or ideological position. Well-known examples include claims made against "government worker", "honest broker", "educational television", "Microsoft Works", and "working from home".
Visual and physical oxymora.
In his book "More on Oxymoron", the artist Patrick Hughes discusses and gives examples of visual oxymorons. He writes:
In the visual version of oxymoron, the material of which a thing is made (or appears to be made) takes the place of the adjective, and the thing itself (or thing represented) takes the place of the noun.
Examples include waves in the sand, a fossil tree, and topiary representing something solid like an ocean liner. Hughes lists further examples of oxymoronic objects, including:
Other languages.
Oxymora, in the sense of "single-word oxymora" such as "pianoforte", are very common in Chinese and neighboring languages such as Japanese, and consist of two opposing Chinese characters. Archetypal examples include 男女 (man and woman, male and female, gender), 陰陽 (yin and yang), 善悪 (good and evil, morality), and are used to indicate couples, ranges, or the trait that these are extremes of.

</doc>
<doc id="22678" url="http://en.wikipedia.org/wiki?curid=22678" title="OSS">
OSS

OSS may refer to:

</doc>
<doc id="22679" url="http://en.wikipedia.org/wiki?curid=22679" title="Office of Strategic Services">
Office of Strategic Services

The Office of Strategic Services (OSS) was a United States intelligence agency formed during World War II. It was the wartime intelligence agency, and a predecessor of the Central Intelligence Agency (CIA). The OSS was formed in order to coordinate espionage activities behind enemy lines for the branches of the United States Armed Forces. Other functions of the OSS included the use of propaganda, subversion, and post-war planning.
Origin.
Prior to the formation of the OSS, American intelligence had been conducted on an ad-hoc basis by the various departments of the executive branch, including the State, Treasury, Navy, and War Departments. It had no overall direction, coordination, or control. The US Army and US Navy had separate code-breaking departments: Signals Intelligence Service and OP-20-G. (A previous code-breaking operation of the State Department, MI-8, run by Herbert Yardley, had been shut down in 1929 by Secretary of State Henry Stimson, deeming it an inappropriate function for the diplomatic arm, because "gentlemen don't read each other's mail".) The FBI was responsible for domestic security and anti-espionage operations.
President Franklin D. Roosevelt was concerned about American intelligence deficiencies. On the suggestion of William Stephenson, the senior British intelligence officer in the western hemisphere, Roosevelt requested that William J. Donovan draft a plan for an intelligence service based on the British Secret Intelligence Service (MI6) and Special Operations Executive. Colonel Donovan was employed to evaluate the global military position in order to offer suggestions concerning American intelligence requirements because the U.S. did not have a central intelligence agency. After submitting his work, "Memorandum of Establishment of Service of Strategic Information," Colonel Donovan was appointed as the "Co-ordinator of Information" on July 11, 1941 heading the new organization known as the office of the Coordinator of Information (COI). Thereafter the organization was developed with the assistance of the British; Donovan had responsibilities but no actual powers and the existing US agencies were skeptical if not hostile. Until some months after Pearl Harbor, the bulk of OSS intelligence came from the UK. The first OSS agents were trained by British Security Coordination (BSC) in Canada, until training stations were set up in the US with guidance from BSC instructors, who also provided information on how the SOE was arranged and managed. The British immediately made available their short-wave broadcasting capabilities to Europe, Africa and the Far East and provided equipment for agents until American production was established.
The Office of Strategic Services was established by a Presidential military order issued by President Roosevelt on June 13, 1942, to collect and analyze strategic information required by the Joint Chiefs of Staff and to conduct special operations not assigned to other agencies. During the War, the OSS supplied policy makers with facts and estimates, but the OSS never had jurisdiction over all foreign intelligence activities. The FBI was left responsible for intelligence work in Latin America, and the Army and Navy continued to develop and rely on their own sources of intelligence.
Activities.
For the duration of the World War II, the Office of Strategic Services was conducting multiple activities and missions, including collecting intelligence by spying, performing acts of sabotage, waging propaganda war, organizing and coordinating anti-Nazi resistance groups in Europe, providing military training for anti-Japanese guerrilla movement in Asia, among other things. At the height of its influence during WWII, the OSS employed almost 24,000 people.
From 1943–1945, the OSS played a major role in training Kuomintang troops in China and Burma, and recruited Kachin, and other indigenous irregular forces for sabotage as well as guides for Allied forces in Burma fighting the Japanese Army. Among other activities, the OSS helped arm, train and supply resistance movements, including Mao Zedong's Red Army in China and the Viet Minh in French Indochina, in areas occupied by the Axis powers during World War II. OSS officer Archimedes Patti played a central role in OSS operations in French Indochina and met frequently with Ho Chi Minh in 1945.
In the "40th Bomb Group Association Memories Issue # 14 March 1987 Date of event: Summer of 1944 to early Spring, 1945 Date written: September, 1986 Written by: Louis Jones":
The Dixie Mission in China was composed of approximately 20 people, including two OSS officers.
One of the greatest accomplishments of the OSS during World War II was its penetration of Nazi Germany by OSS operatives. The OSS was responsible for training German and Austrian individuals for missions inside Germany. Some of these agents included exiled communists and Socialist party members, labor activists, anti-Nazi prisoners-of-war, and German and Jewish refugees. The OSS also recruited and ran one of the war's most important spies, the German diplomat Fritz Kolbe.
In 1943, the Office of Strategic Services set up operations in Istanbul. Turkey, as a neutral country during the Second World War, was a place where both the Axis and Allied powers had spy networks. The railroads connecting central Asia with Europe as well as Turkey's close proximity to the Balkan states placed it at a crossroads of intelligence gathering. The goal of the OSS Istanbul operation called Project Net-1 was to infiltrate and extenuate subversive action in the old Ottoman and Austro-Hungarian Empires.
Head of operations at OSS Istanbul was a banker from Chicago named Lanning "Packy" Macfarland who maintained the cover story as a banker for the American lend-lease program. Macfarland hired Alfred Schwarz, a Czechoslovakian engineer and businessman who came to be known as "Dogwood" and ended up establishing the Dogwood information chain. Dogwood in turn hired a personal assistant named Walter Arndt and established himself as an employee of the Istanbul Western Electrik Kompani. Through Schwartz and Arndt the OSS was able to infiltrate anti-fascist groups in Austria, Hungary and Germany. Schwartz was able to convince Romanian, Bulgarian, Hungarian and Swiss diplomatic couriers to smuggle American intelligence information into these territories and establish contact with elements antagonistic to the Nazis and their collaborators. Couriers and agents memorized information and produced analytical reports; when they were not able to memorize effectively they recorded information on microfilm and hid it in their shoes or hollowed pencils. Through this process information about the Nazi regime made its way to Macfarland and the OSS in Istanbul and eventually to Washington.
While the OSS "Dogwood-chain" produced a lot of information, its reliability was increasingly questioned by British intelligence. Eventually by May 1944 through collaboration between the OSS, British intelligence, Cairo and Washington the entire Dogwood-chain was found to be unreliable and dangerous. Planting phony information into the OSS was intended to misdirect the resources of the Allies. Schwartz's Dogwood-chain, which was the largest American intelligence gathering tool in occupied territory, was shortly thereafter shut down.
The OSS purchased Soviet code and cipher material (or Finnish information on them) from émigré Finnish army officers in late 1944. Secretary of State Edward Stettinius, Jr., protested that this violated an agreement President Roosevelt made with the Soviet Union not to interfere with Soviet cipher traffic from the United States. General Donovan might have copied the papers before returning them the following January, but there is no record of Arlington Hall's receiving them, and CIA and NSA archives have no surviving copies. This codebook was in fact used as part of the Venona decryption effort, which helped uncover large-scale Soviet espionage in North America.
Weapons and gadgets.
The OSS espionage and sabotage operations produced a steady demand for highly specialized equipment. After realizing that, General Donovan invited experts, organized workshops and funded labs that formed a core of the later established Research & Development Branch. Boston chemist Stanley P. Lovell became its first head, and Donovan humorously called him - "his Professor Moriarty".:101 Throughout the war years, the OSS Research & Development was successfully adapting Allied weapons and espionage equipment, and producing its own line of novel spy tools and gadgets, including: silenced pistols, lightweight sub-machine guns, "Beano" grenades that exploded upon impact, explosives disguised as lumps of coal ("Black Joe") or bags of Chinese flour ("Aunt Jemima"), acetone time delay fuses for limpet mines, compasses hidden in uniform buttons, playing cards that concealed maps, a 16mm Kodak camera in the shape of a matchbox, tasteless poison tablets ("K" and "L" pills), and cigarettes laced with tetrahydrocannabinol acetate (an extract of Indian hemp) to induce uncontrollable chattiness, among others. In addition, innovative communication equipment was developed, such as wiretap gadgets, electronic beacons for locating agents, and the "Joan-Eleanor" portable radio system that made possible for operatives on the ground to establish secure contact with a plane that was preparing to land or drop cargo. The OSS Research & Development also printed fake German and Japanese-issued identification cards, various passes, ration cards and counterfeit money.
On August 28, 1943, Stanley Lovell was asked to make a presentation in front of a not very friendly audience of the Joint Chiefs of Staff, since the U.S. top brass were largely skeptical of all OSS plans beyond collecting military intelligence and were ready to split the OSS between the Army and the Navy.:5–7 While explaining the purpose and mission of his department and introducing various gadgets and tools, he reportedly casually dropped into a waste basket the Hedy, a panic-inducing type of a device in a shape of a firecracker, which shortly produced a loud shrieking sound followed by a deafening boom. The presentation was interrupted and did not resume since everyone in the room fled. In reality, the Hedy, jokingly named after a Hollywood star Hedy Lamarr for her ability to distract men, saved lives of some trapped OSS operatives.:184–185
Not all projects worked. Some ideas were outright goofy, such as producing pathogenic synthetic goat dung in PROJECT Capricious (1942) to spread anthrax by using flies among German troops in Spanish Morocco to prevent Spain from joining the Axis powers. Donovan was not informed about PROJECT Capricious due to its uttermost secrecy, the Germans eventually evacuated and Operation Capricious was aborted.:150–151 There were also ideas to introduce estrogen into Hitler's food to deprive him of his trademark mustache and — recognizable by all Germans — baritone voice. A more deadly plot included hiding a capsule with mustard gas in flowers to cause blindness among Nazi generals inside the German High Command Headquarters.:149 All in all, Stanley Lovell worked hard to level the playing field for the OSS in the WWII arena of espionage, and was later quoted saying, "It was my policy to consider any method whatever that might aid the war, however unorthodox or untried".
In 1939, a young physician named Christian J. Lambertsen developed an oxygen rebreather set (the Lambertsen Amphibious Respiratory Unit) and demonstrated it to the OSS–after already being rejected by the U.S. Navy– in a pool at a hotel in Washington D.C. in 1942 The OSS not only bought into the concept, they hired Lambertsen to lead the program and build up the dive element for the organization. His responsibilities included training and developing methods of combining self-contained diving and swimmer delivery including the Lambertsen Amphibious Respiratory Unit for the OSS "Operational Swimmer Group". Growing involvement of the OSS with coastal infiltration and water-based sabotage eventually led to creation of the OSS Maritime Unit.
Dissolution into other agencies.
After victory in Europe in May 1945, the OSS was better able to concentrate on operations in Japan. One month after the war was won in the Pacific Theater of Operations, on September 20, 1945, President Truman signed Executive Order 9621, which came into effect as of October 1, 1945. Thus in the following days from September 20, 1945, the functions of the OSS were split between the Department of State and the Department of War. The State Department received the Research and Analysis Branch of OSS which was renamed the Interim Research and Intelligence Service or (IRIS) and headed by U.S. Army Colonel Alfred McCormack. This was later renamed the Bureau of Intelligence and Research.
The War Department took over the Secret Intelligence (SI) and Counter-Espionage (X-2) Branches, which were then housed in a new office created for just this purpose—the Strategic Services Unit (SSU). The Secretary of War appointed Brigadier General John Magruder (formerly Donovan's Deputy Director for Intelligence in OSS) as the director to oversee the liquidation of the OSS, and more importantly, the preservation of the clandestine intelligence capability of the OSS.
In January 1946, President Truman created the Central Intelligence Group (CIG) which was the direct precursor to the CIA. The assets of the SSU, which now constituted a streamlined "nucleus" of clandestine intelligence, were transferred to the CIG in mid-1946 and reconstituted as the Office of Special Operations (OSO). Next, the National Security Act of 1947 established the United States's first permanent peacetime intelligence agency, the Central Intelligence Agency, which then took up the functions of the OSS. The direct descendant of the paramilitary component of the OSS is the Special Activities Division of the CIA.
Facilities.
Prince William Forest Park (then known as Chopawamsic Recreational Demonstration Area) was the site of an OSS training camp that operated from 1942 to 1945. Area "C", consisting of approximately 6,000 acre, was used extensively for communications training, whereas Area "A" was used for training some of the OGs. Catoctin Mountain Park, now the location of Camp David, was the site of OSS training Area "B." Congressional Country Club (Area F) in Bethesda, MD was the primary OSS training facility.
The London branch of the OSS, its first overseas facility, was at 70 Grosvenor Street, W1. 
The Facilities of the Catalina Island Marine Institute at Toyon Bay on Santa Catalina Island, Calif., are composed (in part) of a former OSS survival training camp.
The National Park Service commissioned a study of OSS National Park training facilities by Professor John Chambers of Rutgers University.
At Camp X, at Ajax, near Oshawa, Ontario, Canada, an "assassination and elimination" training program was operated by the British Special Operations Executive such as William E. Fairbairn and Eric A. Sykes. Many members of the US Office of Strategic Services also were trained there. It was dubbed "the school of mayhem and murder" by George Hunter White who trained at the facility in the 1950s.
Personnel.
The names of all OSS personnel and documents of their OSS service, previously a closely guarded secret, were released by the US National Archives on August 14, 2008. Among the 24,000 names were those of Julia Child, Ralph Bunche, Arthur Goldberg, Saul K. Padover, Arthur Schlesinger, Jr., Bruce Sundlun, and John Ford. The 750,000 pages in the 35,000 personnel files include applications of people who were not recruited or hired, as well as the service records of those who were.
Major League Baseball player Moe Berg was recruited by the OSS in 1943 because of his language skills, assigned to the Secret Intelligence branch, and took part in missions in the Caribbean, South America, France, England, Norway, Italy, and the Balkans. Later, Berg was briefed in nuclear physics, and sent to Zürich, Switzerland posing as a Swiss physics student, with the mission of attending a lecture at the Technische Hochschule by Germany's top nuclear scientist, Werner Heisenberg. His orders were to kill the scientist if he determined that the Germans were far along in their efforts to build an atomic weapon; he found that the scientist was not a threat. Berg was awarded the Presidential Medal of Freedom, but declined to accept it as he was forbidden from saying what he had done to receive the award. He is the only former Major League Baseball player whose baseball card is displayed at CIA headquarters.
One of the forefathers of today's commandos was Navy Lieutenant Jack Taylor. He was sequestered by the OSS early in the war and had a long career behind enemy lines.
Taro and Mitsu Yashima, both Japanese political dissidents who were imprisoned in Japan for protesting its regime, worked for the OSS in psychological warfare against the Japanese Empire.
In popular culture.
Films
Television
Literature
Comics
Video games
References.
Notes
Bibliography

</doc>
<doc id="22680" url="http://en.wikipedia.org/wiki?curid=22680" title="Oda Nobunaga">
Oda Nobunaga

Oda Nobunaga (織田 信長,   , June 23, 1534 – June 21, 1582) was a powerful samurai daimyo warlord of Japan in the late 16th century who initiated the unification of Japan near the end of the Warring States period. He lived a life of continuous military conquest, eventually conquering a third of Japan before his death in a 1582 coup. His successors were Toyotomi Hideyoshi, a loyal Oda supporter who was the first to unify all of Japan and was thus the first ruler of the whole country since the Ōnin War, and later Tokugawa Ieyasu, who was to consolidate his rule under a shogunate, which ruled Japan until the Meiji Restoration in 1868.
Nobunaga is remembered in Japan as one of the most brutal figures of the Warring States period and was recognized as one of Japan's greatest rulers. Nobunaga was the first of three unifiers during the Warring States period, followed by Toyotomi Hideyoshi and Tokugawa Ieyasu. Oda Nobunaga was well on his way to the complete conquest and unification of Japan when Akechi Mitsuhide, one of his generals, forced Nobunaga to commit suicide in Honnō-ji in Kyoto. Akechi declared himself master over Nobunaga's domains, but was quickly defeated by Hideyoshi.
Early years.
Oda Nobunaga was born on June 23, 1534, in the Owari domain, and was given the childhood name of Kippōshi (吉法師). He was the second son of Oda Nobuhide, a deputy "shugo" (military governor) with land holdings in Owari Province. He is said to have been born in Nagoya Castle, although this is subject to debate. Through his childhood and early teenage years, he was well known for his bizarre behavior and received the name of Owari no Ōutsuke (尾張の大うつけ, "The Fool of Owari"). He was known to run around with other youths from the area, without any regard to his own rank in society. With the introduction of firearms into Japan, though, he became known for his fondness of tanegashima firearms.
Unification of Owari Province.
In 1551, Oda Nobuhide died unexpectedly. Nobunaga was said to have acted outrageously during his funeral, throwing ceremonial incense at the altar. This convinced many Oda retainers of Nobunaga's mediocrity and lack of discipline. Alienated, they then began to side with his soft-spoken and well-mannered brother, Nobuyuki. Hirate Masahide, a valuable mentor and retainer to Nobunaga, was ashamed by Nobunaga's behavior and performed "seppuku". This had a huge effect on Nobunaga, who later built a temple to honor Masahide.
Though Nobunaga was Nobuhide's legitimate successor, the Oda clan was divided into many factions, and the clan was technically under the control of Owari's "shugo", Shiba Yoshimune. Oda Nobutomo, the deceased Nobuhide's brother and deputy to the "shugo", used the weak Yoshimune as his puppet and challenged Nobunaga's place as Owari's new ruler. Nobutomo murdered Yoshimune when it was discovered that he supported and attempted to aid Nobunaga.
Nobunaga persuaded Oda Nobumitsu, a younger brother of Nobuhide, to join his side and, with Nobumitsu's help, slew Nobutomo in Kiyosu Castle, which later became Nobunaga's place of residence for over ten years. Taking advantage of the position of Shiba Yoshikane, Yoshimune's son, as the rightful "shugo", Nobunaga forged an alliance with the Imagawa clan of Suruga Province and the Kira clan of Mikawa Province, as both clans had the same "shugo" and would have no excuse to decline. This also ensured that the Imagawa clan would have to stop attacking Owari's borders.
Though Nobuyuki and his supporters were still at large, Nobunaga brought an army to Mino Province to aid Saitō Dōsan after Dōsan's son, Saitō Yoshitatsu, turned against him. The campaign failed, as Dōsan was killed, and Yoshitatsu became the new master of Mino in 1556.
A few months later Nobuyuki, with support from Shibata Katsuie and Hayashi Hidesada, rebelled against Nobunaga. The conspirators were defeated at the Battle of Inō, but were pardoned after the intervention of Tsuchida Gozen, the birth mother of Nobunaga and Nobuyuki. The next year, Nobuyuki again planned to rebel. Nobunaga was informed of this by Shibata Katsuie, then faked illness to get close to Nobuyuki and assassinated him in Kiyosu Castle.
By 1559, Nobunaga had eliminated all opposition within the clan and Owari Province. He continued to use Shiba Yoshikane as a pretext to make peace with other daimyo, though it was later discovered that Yoshikane had secretly corresponded with the Kira and Imagawa clans, attempting to oust Nobunaga and restore the Shiba clan's place. Nobunaga eventually cast him out, voiding alliances created in the Shiba clan's name.
Battle of Okehazama.
In 1560, Imagawa Yoshimoto gathered an army of 40,000 men and started his march toward Kyoto, with the pretext of aiding the frail Ashikaga shogunate. The Matsudaira clan of Mikawa Province also joined Yoshimoto's forces. Against this, the Oda clan could rally an army of only 3,000, and the forces needed to be split up to defend various border forts. Under such circumstances, Nobunaga was said to have performed his favorite Atsumori dance at Kiyosu Castle, before riding off with only a few attendants to pray. Due to the sheer imbalance in the forces available to the two clans the night before, Shibata Katsuie had tried in vain to change Oda Nobunaga's mind about a frontal attack; he kept reminding Nobunaga of the joint army's lack of manpower compared to Imagawa's numerous soldiers. Hayashi Sado no Kami Hidesada, the remaining advisor from Nobuhide's days, even argued for surrender without fighting, using the same reasoning as Katsuie.
Nobunaga's scouts reported that Yoshimoto was resting at the narrow gorge of Dengaku-hazama, ideal for a surprise attack, and that the Imagawa army were celebrating their victories while Yoshimoto viewed the heads. Nobunaga moved towards Imagawa's camp, and set up a position some distance away. An array of flags and dummy troops made of straw and spare helmets gave the impression of a large host, while the real Oda army hurried round in a rapid march to get behind Yoshimoto's camp. The heat gave way to a terrific thunderstorm. As the Imagawa samurai sheltered from the rain Nobunaga deployed his troops, and when the storm ceased they charged down upon the enemy in the gorge, so suddenly that Yoshimoto thought a brawl had broken out among his men, only realizing it was an attack when two samurai charged up. One aimed a spear at him, which Yoshimoto deflected with his sword, but the second swung his blade and cut off Imagawa's head.
Rapidly weakening in the wake of this battle, the Imagawa clan no longer exerted control over the Matsudaira clan. In 1561, an alliance was forged between Oda Nobunaga and Matsudaira Motoyasu (who would become Tokugawa Ieyasu), despite the decades-old hostility between the two clans. Tradition dates this battle as the first time that Nobunaga noticed the talents of the sandal-bearer who would eventually become Toyotomi Hideyoshi.
"Tenka Fubu".
In Mino, Saitō Yoshitatsu died suddenly of illness in 1561, and was succeeded by his son, Saitō Tatsuoki. Tatsuoki, however, was young and much less effective as a ruler and military strategist compared to his father and grandfather. Taking advantage of this situation, Nobunaga moved his base to Komaki Castle and started his campaign in Mino. By convincing Saitō retainers to abandon their incompetent and foolish master, Nobunaga weakened the Saitō clan significantly, eventually mounting a final attack in 1567. Nobunaga captured Inabayama Castle and sent Tatsuoki into exile.
After taking possession of the castle, Nobunaga changed the name of both the castle and the surrounding town to Gifu. Remains of Nobunaga's residence in Gifu can be found today in Gifu Park. Naming it after the legendary Mount Qi (岐山 "Qi" in Standard Chinese) in China, on which the Zhou dynasty started, Nobunaga revealed his ambition to conquer the whole of Japan. He also started using a new personal seal that read "Tenka Fubu" (天下布武), which means "All the world by force of arms". In 1564, Nobunaga had his sister, Oichi, marry Azai Nagamasa, a daimyo in northern Ōmi Province. This would later help pave the way to Kyoto.
In 1568, Ashikaga Yoshiaki went to Gifu to ask Nobunaga to start a campaign toward Kyoto. Yoshiaki was the brother of the murdered thirteenth shogun of the Ashikaga shogunate, Yoshiteru, and wanted revenge against the killers who had already set up a puppet shogun, Ashikaga Yoshihide. Nobunaga agreed to install Yoshiaki as the new shogun and, grasping the opportunity to enter Kyoto, started his campaign. An obstacle in southern Ōmi Province, however, was the Rokkaku clan. Led by Rokkaku Yoshikata, the clan refused to recognize Yoshiaki as shogun and was ready to go to war. In response, Nobunaga launched a rapid attack, driving the Rokkaku clan out of their castles.
Within a short amount of time, Nobunaga had reached Kyoto and driven the Miyoshi clan out of the city. Yoshiaki was made the 15th shogun of the Ashikaga shogunate. Nobunaga refused the post of Kanrei and eventually began to restrict the powers of the shogun, making it clear that he intended to use him as a facade to justify his future conquests. Yoshiaki, however, was not pleased about being a puppet and secretly corresponded with various daimyo, forging an anti-Nobunaga alliance.
The Asakura clan was particularly disdainful of the Oda clan's increasing power because, historically, the Oda clan had been subordinate to the Asakura clan. Furthermore, Asakura Yoshikage had also protected Ashikaga Yoshiaki, but had not been willing to march toward Kyoto. Thus, the Asakura clan also despised Nobunaga the most for his success.
When Nobunaga launched a campaign into the Asakura clan's domain, Azai Nagamasa, to whom Oichi was married, broke the alliance with Oda to honor the Azai-Asakura alliance which had lasted for generations. With the help of Ikko rebels, the anti-Nobunaga alliance sprang into full force, taking a heavy toll on the Oda clan. At the Battle of Anegawa, Tokugawa Ieyasu joined forces with Nobunaga and defeated the combined forces of the Asakura and Azai clans.
Nobunaga waged war against Buddhists. The Enryaku-ji monastery on Mt. Hiei, with its "sōhei" (warrior monks) of the Tendai school who aided the anti-Nobunaga group by helping Azai-Asakura alliance, was an issue for Nobunaga since the monastery was so close to his residency. Nobunaga attacked Enryaku-ji and burnt it to the ground in 1571, even though it had been admired as a significant cultural symbol at the time, and killed between 3,000 and 4,000 men, women and children in the process.
During the siege of Nagashima, Nobunaga suffered tremendous losses, including the death of a couple of his brothers, to the Ikkō-ikki resistance, a coalition of peasant farmers, monks, Shinto priests and local nobles that opposed samurai rule. The siege finally ended when Nobunaga surrounded the enemy complex and set fire to it, killing tens of thousands of non-combatants, including women and children. He later succeeded in taking their main stronghold at Ishiyama Hongan-ji after an 11-year siege that ended with its surrender.
One of the strongest rulers in the anti-Nobunaga alliance was Takeda Shingen, in spite of his generally peaceful relationship and a nominal alliance with the Oda clan. In 1572, at the urgings of the shogun, Shingen decided to make a drive for the capital starting with invading Tokugawa's territory. Tied down on the Western front, Nobunaga sent lackluster aid to Ieyasu, who suffered defeat at the Battle of Mikatagahara in 1573. However, after the battle, Tokugawa's forces launched night raids and convinced Takeda of an imminent counter-attack, thus saving the vulnerable Tokugawa with the bluff. This would play a pivotal role in Tokugawa's philosophy of strategic patience in his campaigns with Oda Nobunaga. Shortly thereafter, the Takeda forces retreated after Shingen died of illness in 1573. This was a relief for Nobunaga because he could now focus on Yoshiaki, who had openly declared hostility more than once, despite the imperial court's intervention. Nobunaga was able to defeat Yoshiaki's forces and send him into exile, bringing the Ashikaga shogunate to an end in the same year.
Also in 1573, Nobunaga successfully destroyed the Asakura and Azai clans, leading Azai Nagamasa to send Oichi back to Nobunaga and commit suicide. With Nagashima's destruction in 1574, the only threat to Nobunaga was the Takeda clan, now led by Takeda Katsuyori.
At the decisive Battle of Nagashino, the combined forces of Nobunaga and Tokugawa Ieyasu devastated the Takeda clan with the strategic use of arquebuses. Nobunaga compensated for the arquebus' slow reloading time by arranging the arquebusiers in three lines. After each line fired, it would duck and reload as the next line fired. The bullets were able to pierce the Takeda cavalry armor, who were pushed back and killed by incoming fire. From there, Nobunaga continued his expansion, sending Shibata Katsuie and Maeda Toshiie to the north and Akechi Mitsuhide to Tamba Province.
In 1574 Nobunaga accepted the title of "kuge" (court noble), then in 1577 he was given the title of "udaijin" (or Minister of the Right), the third highest position in the Imperial court.
The Oda clan's siege of Ishiyama Hongan-ji in Osaka made some progress, but the Mori clan of the Chūgoku region broke the naval blockade and started sending supplies into the strongly fortified complex by sea. As a result, in 1577, Hashiba Hideyoshi was ordered to expand west to confront the Mori clan.
However, Uesugi Kenshin, said to be the greatest general of his time since the demise of Takeda Shingen, took part in the second anti-Nobunaga alliance. Following his conquest of neighboring forces, the two sides clashed during the Battle of Tedorigawa which resulted in a decisive Uesugi victory. It was around this time that Uesugi forces began preparations to march on Kyoto.
Due to his defeat, Nobunaga's expansion in Noto, Kaga, and Etchū Province area stagnated. But Kenshin, who prepared to move his armies again after the battle, died from a possible cerebral hemorrhage before moving them. After Kenshin's death and much confusion among his successors, Nobunaga started his campaign again on this area.
Nobunaga forced the Ishiyama Hongan-ji to surrender in 1580 and destroyed the Takeda clan in 1582. Nobunaga's administration was at its height of power and he was about to launch invasions into Echigo Province and Shikoku.
Incident at Honnō-ji and death.
In 1582, Nobunaga's former sandal bearer Hashiba Hideyoshi invaded Bitchu Province, laying siege to Takamatsu Castle. The castle was vital to the Mori clan, and losing it would leave the Mori home domain vulnerable. Led by Mōri Terumoto, reinforcements arrived outside Takamatsu Castle, and the two sides came to a standstill. Hashiba asked for reinforcements from Nobunaga.
It has often been argued that Hideyoshi had no need for reinforcements, but asked Nobunaga anyway for various reasons. Most believe that Hideyoshi, envied and hated by fellow generals for his swift rise from a lowly footman to a top general under Oda Nobunaga, wanted to give the credit for taking Takamatsu to Nobunaga so as to humble himself in front of other Oda vassals.
In any case, Nobunaga ordered Niwa Nagahide to prepare for an invasion of Shikoku, and Akechi Mitsuhide to assist Hideyoshi. En route to Chūgoku region, Nobunaga stayed at Honnō-ji, a temple in Kyoto. Since Nobunaga would not expect an attack in the middle of his firmly controlled territories, he was guarded by only a few dozen personal servants and bodyguards. His son Nobutada stayed at Myōkaku-ji, a temple on the grounds of Nijō Palace, the forerunner to Nijō Castle.
Mitsuhide chose that time to attack. On June 21, 1582 (Tenshō (Momoyama period)|]]-10 year, 6-month 2-day), Mitsuhide took a unit of his men and surrounded the Honnō-ji while sending another unit of Akechi troops to assault Myōkaku-ji, initiating a full coup d'état. At Honnō-ji, Nobunaga's small entourage was soon overwhelmed and as the Akechi troops closed in on the burning temple where Nobunaga had been residing, he decided to commit seppuku in one of the inner rooms. Unknown to Nobunaga, his son Nobutada died in the fighting before the temple where he was staying. At Honnō-ji, only his young page, Mori Ranmaru, remained at his master's side; he was still in his teens. Ranmaru's loyalty and devotion to his lord were widely known and praised during the Edo period. He attended to Nobunaga as he sought a moment of peace to carry out his last act, then Ranmaru likewise killed himself in the same way.
The cause of Mitsuhide's "betrayal" is controversial. It has been proposed that Mitsuhide may have heard a rumor that Nobunaga would transfer Mitsuhide's fief to the page, Mori Ranmaru, with whom Nobunaga is alleged to have been in a ritualized homosexual relationship, a form of patronage, known as "shudō". Other motives include revenge for Nobunaga's numerous insults and derisive treatment of Mitsuhide, or Mitsuhide's jealousy as Nobunaga had shown greater favor toward another vassal, Hashiba Hideyoshi. Another possible motive is for revenge as Akechi Mitsuhide's mother (or perhaps aunt) was killed because Nobunaga had gone against a peace treaty that he had previously agreed to.
In 1579, Nobunaga captured Yakami Castle from Hatano Hideharu by promising Hideharu peace terms. This accomplished Mitsuhide's goal, although Nobunaga betrayed the peace agreement and had Hideharu executed. According to several stories, this displeased the Hatano family, and a short while later several of Hideharu's retainers murdered Akechi Mitsuhide's mother (or aunt). The situation was fueled through several public insults Nobunaga had directed at Mitsuhide that even drew the attention of some Western observers. However, Mitsuhide's actual motive for attacking Nobunaga at Honnō-ji is not known.
Just eleven days after the coup at Honnō-ji, Mitsuhide was killed at the Battle of Yamazaki and his army was defeated by Hashiba Hideyoshi, who eventually became heir to Nobunaga's legacy. He is more widely known as Toyotomi Hideyoshi. At the time of Nobunaga's death, he was in control of more than half of the provinces in Japan, the majority of which were in the Kyoto region.
Nobunaga, Hideyoshi and Ieyasu.
Toyotomi Hideyoshi, who unified Japan in 1590, and Tokugawa Ieyasu, who founded the Tokugawa Shogunate in 1603, were loyal followers of Nobunaga. These two were able to build a unified Japan on the basis of Nobunaga's previous achievements. There was a saying: "Nobunaga pounds the national rice cake, Hideyoshi kneads it, and in the end Ieyasu sits down and eats it."
Hideyoshi was brought up from a nameless peasant to be one of Nobunaga's top generals. When he became a grand minister in 1586, he created a law that the samurai caste became codified as permanent and heritable, and that non-samurai were forbidden to carry weapons, thereby ending the social mobility of Japan from which he himself had benefited. He was even said to divert rivers to flood enemy villages and clans. These restrictions lasted until the dissolution of the Edo Shogunate by the Meiji Restoration revolutionaries. Hideyoshi secured his claim as the rightful successor of Nobunaga by defeating Akechi Mitsuhide within a month of Nobunaga's death.
It is important to note that the distinction between samurai and non-samurai was so obscure that during the 16th century, most male adults in any social class (even small farmers) belonged to at least one military organization of their own and served in wars before and during Hideyoshi's rule. It can be said that an "all against all" situation continued for a century. The authorized samurai families after the 17th century were those that chose to follow Nobunaga, Hideyoshi and Ieyasu. Large battles occurred during the change between regimes and a number of defeated samurai were destroyed, became ronin or were absorbed into the general populace.
Ieyasu had shared his childhood with Nobunaga as a hostage of the Oda clan. Though there were a number of battles between Ieyasu and the Oda clan, Ieyasu eventually switched sides and became one of Nobunaga's strongest allies.
Policies.
Militarily, Nobunaga changed the way war was fought in Japan. He developed, implemented, and expanded the use of long pikes, firearms and castle fortifications in accordance with the expanded mass battles of the period. The firearms that were introduced by the Portuguese had allowed the establishment of firearm brigades in the army. Once the two important musket factories in Sakai City and Omi province were conquered, it gave Nobunaga superior firepower over his enemies. Nobunaga also instituted a specialized warrior class system and appointed his retainers and subjects to positions based on ability, not wholly based on name, rank, or family relationship as in prior periods. Retainers were also given land on the basis of rice output, not land size. Nobunaga's organizational system in particular was later used and extensively developed by his ally Tokugawa Ieyasu in the forming of the Tokugawa shogunate in Edo.
Nobunaga's dominance and brilliance was not restricted to the battlefield, for he also was a keen businessman and understood the principles of microeconomics and macroeconomics. First, in order to modernize the economy from an agricultural base to a manufacture and service base, castle towns were developed as the center and basis of local economies. Roads were also made within his domain between castle towns to not only facilitate trade, but also to move armies great distances in short timespans. International trade was also expanded beyond China and the Korean peninsula, while "nanban" (southern barbarian) trade with Europe, the Philippines, Siam and Indonesia was also started.
Nobunaga also instituted "rakuichi rakuza" (楽市楽座) policies as a way to stimulate business and the overall economy through the use of a free market system. These policies abolished and prohibited monopolies and opened once closed and privileged unions, associations and guilds, which he saw as impediments to commerce. Even though these policies provided a major boost to the economy, it was still heavily dependent on daimyos' support. Copies of his original proclamations can be found in Entoku-ji in the city of Gifu. He also developed tax exemptions and established laws to regulate and ease the borrowing of debt.
Culture.
As Nobunaga conquered Japan and amassed a great amount of wealth, he progressively supported the arts for which he always had an interest, but which he later and gradually more importantly used as a display of his power and prestige. He built extensive gardens and castles which were themselves great works of art. Azuchi Castle on the shores of Lake Biwa is said to have been the greatest castle in the history of Japan, covered with gold and statues on the outside and decorated with standing screen, sliding door, wall, and ceiling paintings made by his subject Kanō Eitoku on the inside. During this time, Nobunaga's subject and tea master Sen no Rikyū established the Japanese tea ceremony which Nobunaga popularized and used originally as a way to talk politics and business. The beginnings of modern kabuki were started and later fully developed in the early Edo period.
Additionally, Nobunaga was very interested in European culture which was still very new to Japan. He collected pieces of Western art as well as arms and armor, and he is considered to be among the first Japanese people in recorded history to wear European clothes. He also became the patron of the Jesuit missionaries in Japan and supported the establishment of the first Christian church in Kyoto in 1576, although he remained an adamant atheist and never converted to Christianity. During a visit by the Jesuits in March 1581, Nobunaga's interest was piqued by a slave in the service of a Jesuit inspector of missions, and it was requested that he be left in Nobunaga's service. This slave, later called by the Japanese name Yasuke, was highly favored by Nobunaga and fought in the final battle at Honnō-ji. During that time, the persecution of Buddhists was motivated mostly by separating politics from religion. Though it was not fully realized under Nobunaga's rule, he attempted to create a public, rational political authority. The concepts brought up during this change had the potential to radically change society in Japan. The new ideas that came forth were either incorporated into common discourses without changing it fundamentally, built upon at a later time, or opened up new options in the later Tokugawa era that were expanded on.
Family.
Depending upon the source, Oda Nobunaga and the entire Oda clan are descendents of either the Fujiwara clan or the Taira clan (specifically, Taira no Shigemori's branch). His lineage can be directly traced to his great-great-grandfather, Oda Hisanaga, who was followed by Oda Toshisada, Oda Nobusada, Oda Nobuhide and Nobunaga himself.
Immediate family.
Nobunaga was the eldest legitimate son of Nobuhide, a minor warlord from Owari Province, and Tsuchida Gozen, who was also the mother to three of his brothers (Nobuyuki, Nobukane and Hidetaka) and two of his sisters (Oinu and Oichi).
Descendants.
Nobunaga married Nōhime, the daughter of Saitō Dōsan, as a matter of political strategy; however, she bore him no children and was considered to be barren. It was his concubines Kitsuno and Lady Saka who bore him his children. It was Kitsuno who gave birth to Nobunaga's eldest son, Nobutada. Nobutada's son, Oda Hidenobu, became ruler of the Oda clan after the deaths of Nobunaga and Nobutada. His son Oda Nobuhide was a Christian, and took the baptismal name Peter; he was adopted by Toyotomi Hideyoshi and commissioned chamberlain.
Other relatives.
One of Nobunaga's younger sisters, Oichi, gave birth to three daughters. These three nieces of Nobunaga became involved with important historical figures. Chacha (also known as Lady Yodo), the eldest, became the mistress of Toyotomi Hideyoshi. O-Hatsu married Kyōgoku Takatsugu. The youngest, O-go, married the son of Tokugawa Ieyasu, Tokugawa Hidetada (the second shogun of the Tokugawa shogunate). O-go's daughter Senhime married her cousin Toyotomi Hideyori, Lady Yodo's son.
Nobunaga's nephew was Tsuda Nobusumi, the son of Nobuyuki. Nobusumi married Akechi Mitsuhide's daughter, and was killed after the Incident at Honnō-ji by Nobunaga's third son, Nobutaka, who suspected him of being involved in the plot.
Later descendants.
Nobunari Oda, a retired figure skater, claims the 17th direct descendant of Nobunaga. The ex-monk celebrity Mudō Oda also claims descent from the Sengoku period warlord, but his claims have not been verified.
In popular culture.
Nobunaga appears frequently within fiction and continues to be portrayed in many other anime, manga, video games, and cinematic films. Many depictions show him as villainous or even demonic in nature, though some portray him in a more positive light. The latter type of works include Akira Kurosawa's film "Kagemusha", which portrays Nobunaga as energetic, athletic and respectful towards his enemies. The film "Goemon" portrays him as a saintly mentor of Ishikawa Goemon. Nobunaga is a central character in Eiji Yoshikawa's historical novel "Taiko Ki", where he is a firm but benevolent lord. Nobunaga is also portrayed in a heroic light in some video games such as "Kessen III", "Ninja Gaiden II" and the "Warriors Orochi" series.
By contrast, the novel and anime series "Yōtōden" portrays Nobunaga as a literal demon in addition to a power-mad warlord. In the novel "The Samurai's Tale" by Erik Christian Haugaard, he is portrayed as an antagonist "known for his merciless cruelty". He is portrayed as evil or megalomaniacal in some anime and manga series including "Samurai Deeper Kyo" and "Flame of Recca". Nobunaga is portrayed as evil, villainous, bloodthirsty, and/or demonic in many video games such as "Ninja Master's", "Sengoku", "Maplestory", "" and "Atlantica Online", and the video game series "Onimusha", "Samurai Warriors", "Sengoku Basara" (and its anime adaptation) and "Soulcalibur".
There are also numerous examples of his portrayal in a more neutral or historic framework, especially in the Taiga dramas shown on television in Japan. Oda Nobunaga appears in the manga series "Tail of the Moon", "Kacchu no Senshi Gamu", and Tsuji Kunio's historical fiction "The Signore: Shogun of the Warring States". Historical representations in video games (mostly Western-made strategy titles) include ', ', "Throne of Darkness", the eponymous "Nobunaga's Ambition" series, as well as "Civilization V" and "". Kamenashi Kazuya of the Japanese pop group KAT-TUN wrote and performed a song titled "1582" which is written from the perspective of Mori Ranmaru at the Incident at Honnouji.
There are also more fictive portrayals, in which the figure of Nobunaga influences a story or inspires a characterization. In James Clavell's novel "Shōgun", the character Goroda is a pastiche of Nobunaga. In the film "Sengoku Jieitai 1549" Nobunaga is killed by time-travellers. Nobunaga also appears as a major character in the eroge "Sengoku Rance" and is a playable character in "Pokémon Conquest". In the anime "", in "Sengoku Collection", and the light novel and anime series "The Ambition of Oda Nobuna", he is depicted as a female character. He is the main character of the stage action and anime adaptation of "Nobunaga the Fool".

</doc>
<doc id="22684" url="http://en.wikipedia.org/wiki?curid=22684" title="Otto Wilhelm Hermann von Abich">
Otto Wilhelm Hermann von Abich

Otto Wilhelm Hermann von Abich (December 11, 1806 – July 1, 1886) was a German mineralogist and geologist. Full member of St Petersburg Academy of Sciences (hon. member since 1866).
Biography.
He was born at Berlin and educated at the local university. His earliest scientific work is related to spinels and other minerals. Later he made special studies of fumaroles, of the mineral deposits around volcanic vents, and of the structure of volcanoes. In 1842 he was appointed professor of mineralogy in the university of Dorpat (Tartu), and henceforth gave attention to the geology and mineralogy of the Russian Empire. Residing for some time at Tiflis, he investigated the geology of the Armenian Highland (this term was introduced by Abich) and Caucasus. In 1844 and 1845 he ascended Ararat volcano several times, studied the geological event of 1840 that was centered on Ararat (Akori village). In 1877 he retired to Vienna, where he died. The mineral Abichite was named after him.
Publications.
The following are listed in Chisholm, 1, p. 62:

</doc>
<doc id="22685" url="http://en.wikipedia.org/wiki?curid=22685" title="Organization of the Communist Party of the Soviet Union">
Organization of the Communist Party of the Soviet Union

The organization of the Communist Party of the Soviet Union was based on the principles of democratic centralism.
The governing body of the Communist Party of the Soviet Union (CPSU) was the Party Congress which initially met annually but whose meetings became less frequent, particularly under Joseph Stalin. Party Congresses would elect a Central Committee which, in turn, would elect a Politburo. Under Stalin the most powerful position in the party became the General Secretary who was elected by the Politburo. In 1952 the title of "General Secretary" became "First Secretary" and the "Politburo" became the "Presidium" before reverting to their former names under Leonid Brezhnev in 1966.
In theory, supreme power in the party was invested in the Party Congress. However, in practice the power structure became reversed and, particularly after the death of Lenin, supreme power became the domain of the General Secretary.
Higher levels.
In the late Soviet Union the CPSU incorporated the communist parties of the 15 constituent republics (the communist branch of the Russian SFSR was established in 1990). Before 1990 the communist party organization in Russian oblasts, autonomous republics and some other major administrative units were subordinated directly to the CPSU Central Committee.
Lower levels.
At lower levels, the organizational hierarchy was managed by Party Committees, or partkoms (партком). A partkom was headed by the elected "partkom bureau secretary" ("partkom secretary", секретарь парткома). At enterprises, institutions, kolkhozes, etc., they were called as such, i.e., "partkoms". At higher levels the Committees were abbreviated accordingly: obkoms (обком) at oblast (zone) levels (known earlier as gubkoms (губком) for guberniyas), "raikoms" (райком) at raion (district) levels (known earlier as ukoms (уком) for uyezds), gorkom (горком) at city levels, etc.
The same terminology ("raikom", etc.) was used in the organizational structure of Komsomol.
The bottom level of the Party was the primary party organization (первичная партийная организация) or party cell (партийная ячейка). It was created within any organizational entity of any kind where there were at least three communists. The management of a cell was called party bureau/partbureau (партийное бюро, партбюро). A partbureau was headed by the elected bureau secretary (секретарь партбюро).
At smaller party cells, secretaries were regular employees of the corresponding plant/hospital/school/etc. Sufficiently large party organizations were usually headed by an exempt secretary, who drew his salary from the Party money.

</doc>
<doc id="22686" url="http://en.wikipedia.org/wiki?curid=22686" title="Oromo people">
Oromo people

The Oromo (Oromo: "Oromoo"; Ge'ez: ኦሮሞ, "’Oromo"), are an ethnic group inhabiting Ethiopia, northern Kenya, and parts of Somalia. With around 25 million members, they constitute the single largest ethnicity in Ethiopia and the wider Horn of Africa, at approximately 35% of Ethiopia's population according to the 2007 census. Oromos speak the Oromo language as a mother tongue (also called "Afaan Oromoo" and "Oromiffa"), which is part of the Cushitic branch of the Afro-Asiatic family. The name was given as "Ilm’ Orma" ("Sons of Men" or an eponymous 'Orma') in the 19th century; the present form is probably an obsolete plural of the same word "orma" ("person, stranger").
Origins.
Oromos are the largest Cushitic-speaking group of people living in Northeast Africa. Available information suggests that they have existed as a community in the Horn of Africa for several millennia (Prouty et al., 1981). Bates (1979) contends that the Oromo "were a very ancient race, the indigenous stock, perhaps, on which most other peoples in this part of eastern Africa have been grafted".
While further research is needed to precisely comprehend their origins, the Oromo are believed to have originally adhered to a pastoralist/nomadic and/or semi-agriculturalist lifestyle. Many historians agree that some Oromo clans (Bale) have lived in the southern tip of present-day Ethiopia for over a millennium. They suggest that a Great trade-influenced Oromo migration brought most Oromos to present-day central and western Ethiopia in the 16th and 17th centuries. Historical maps of the ancient Aksum/Abyssinian Empire and Adal/Somali empires indicate that Oromo people are newcomers to most of modern-day central Ethiopia.
Recent history.
Historically, Afaan Oromo-speaking people used their own "Gadaa" system of governance. Oromos also had a number of independent kingdoms, which they shared with the Sidama. Among these were the Gibe region kingdoms of Gera, Gomma, Garo, Gumma, Jimma and Limmu-Ennarea, as well as the kingdom of Jiren.
Historically, both peaceful and violent competition and integration between Oromos and other neighboring ethnicities such as the Amhara, Sidama and the Somali had an impact on politics within the Oromo community. The northern expansion of the Oromos such as the Yejju and, in particular the Arsi, to ethnic Somali and Sidama territories mirrored the southern expansion of Amharas, and helped influence contemporary ethnic politics in Ethiopia. Also the great Somali expansion from the Ogaden plains west towards the Juba river led to conflicts with the Oromo.
In some cases, Oromos and Somalis were in competition for good lands and water resources historically. In addition, Eastern Oromos who were converted to Islam ruled over most of Ethiopia together with Afars and Somalis when Horn of African Muslims who were united and led by Imam Ahmad ibn Ibrihim al-Ghazi conquered a majority of Christian Ethiopian highlands.
Historian Richard Pankhurst stated that before the coming of European powers and the creation of centralized Ethiopia, the area presently known as Ethiopia, Eritrea and Somalia:
Constituted a galaxy of states and polities, each moving in its own orbit, but significantly affecting, and affected by, the other entities in the constellation. Each ruler kept a watchful eye on his neighbors but would often exchange gifts and courtesies with them unless actually at war. Dynastic marriages were made whenever practicable, though these only occasionally crossed barriers of religion. Commerce, on the other hand, made little distinction between faith, and trade routes linked traditionalist, Christian and Muslim localities. Ethnic and linguistic communities remained largely distinct, but there was much cross-fertilization of cultures. This was true not only off the Ethiopian highlands and the Red Sea coastlands, but also further south along the Somali-Oromo frontier where later nineteenth century travelers reported the existence of bilingual trading communities.
In the first decades of the 19th century, three Oromo monarchies, Enarya, Goma and Guma, rose to prominence. The collective area was known as Galla-land and comprised most of central and southern Ethiopia, including lands now held by other ethnic regions. In the general view of Oromo people's role in Ethiopia, Ras Gobana Dacche is a famous Oromo figure who led the development of modern Ethiopia and the political and miliatary incorporation of more territories into Ethiopian borders. Gobana under the authority of Menelik II incorporated several Oromo territories into a centralized Ethiopian state. Some contemporary ethno-nationalist Oromo political groups refer to Gobana in a negative light. Though, before military integration; present day Ethiopia, Eritrea, and parts of Somalia were previously and extensively linked commercially by local, long-distance and trans-frontier trade routes. These commercial routes connected Bonga, Jimma, Seqa, Assandabo, Gojjam, Begemder, Maramma, Massawa, Soddo, Shewa, Harar, Zeila and Berbera. Some Oromo writers believe that the Oromo Ras Gobena and the Amhara Menelik II were the first two people in Ethiopia with the concept of national boundary that brought various different ethno-linguistic communities under a politically and militarily centralized rule.
"The two most important historical figures who signify the introduction of the concepts of national boundary and sovereignty in Ethiopia are Emperor Menelik II and Ras Gobana Dachi, who used guns manufactured in Europe to bring a large swath of Biyas (regions/nations) under a centralized rule."
Ethnically mixed Ethiopians with Oromo background made up a little percentage of Ethiopian generals and leaders. The Wollo Oromo (particularly the Raya Oromo and Yejju Oromo) were early Oromo holders of power among the increasingly mixed Ethiopian state. The later north-to-south movement of central power in Ethiopia led to Oromos in Shewa holding power in Ethiopia together with the Shewan Amhara.
"In terms of descent, the group that became politically dominant in Shewa – and Subsequently in Ethiopia – was a mixture of Amhara and Oromo; in terms of language, religion and cultural practices, it was Amhara."
Nonetheless, in many cases Oromo became part of the Ethiopian nobility without losing their identity. Both ethnically mixed Oromos and those with full Oromo descent held high leadership positions in Ethiopia. Notably Iyasu V was the designated but uncrowned Emperor of Ethiopia (1913–1916), while Haile Selassie I was the crowned and generally acknowledged Emperor of Ethiopia from 1930 to 1974. Both these Ethiopian Emperors are ethnically mixed, with Oromo parents and lineages. Haile Selassie's mother was paternally of Oromo descent and maternally of Gurage heritage, while his father was paternally Oromo and maternally Amhara. He consequently would have been considered Oromo in a patrilineal society, and would have been viewed as Gurage in a matrilineal one. However, in the main, Haile Selassie was regarded as Amhara: his paternal grandmother's royal lineage, through which he was able to ascend to the Imperial throne.
By the 1880s, Sahle Selassie, king of Shewa (the later Emperor Menelik II) allied with Ras Gobena's Shewan Oromo militia to expand his kingdom to the South and East, expanding into areas that hadn't been held together since the invasion of Ahmed Gragn. Another famous leader of Ethiopia with Oromo descent was Ras Makonnen Woldemikael Gudessa, the governor of Harar who served as the top general in the First Italo–Ethiopian War, playing a key role at the Battle of Adwa. He is the father of Ethiopian Emperor Haile Selassie I.
In 1973, Oromo discontent with their position led to the formation of the Oromo Liberation Front (OLF), which began political agitation in the Oromo areas. Also in 1973 there was a catastrophic famine in which over one quarter of a million people died from starvation before the government recognised the disaster and permitted relief measures. The majority who died were Oromos and Amharas from Wollo, Afars and Tigrayans. There were strikes and demonstrations in Addis Ababa in 1974; and in February of that year, Haile Selassie’s government was replaced by the Derg, a military junta led by Mengistu Haile Mariam; but the Council was still Amhara-dominated, with only 25 non-Amhara members out of 125. In 1975 the government declared all rural land State-owned, and announced the end of the tenancy system. However, much of the benefit of this reform was counteracted by compulsive collectivization, State farms and forced resettlement programmes.
In December 2009, a 96-page report titled "Human Rights in Ethiopia: Through the Eyes of the Oromo Diaspora", compiled by the Advocates for Human Rights, documented human rights violations against the Oromo in Ethiopia under three successive regimes: the Abyssinian Empire under Haile Selassie, the Marxist Derg and the current Ethiopian government of the Ethiopian People’s Revolutionary Democratic Front (EPRDF), dominated by members of the Tigray People’s Liberation Front (TPLF) and which was accused to have arrested approximately 20,000 suspected OLF members, to have driven most OLF leadership into exile, and to have effectively neutralized the OLF as a political force in Ethiopia.
According to the Office of the United Nations High Commissioner for Human Rights, the Oromia Support Group (OSG) recorded 594 extra-judicial killings of Oromos by Ethiopian government security forces and 43 disappearances in custody between 2005 and August 2008.
Demographics.
The Oromo people are the largest ethnic grouping in Ethiopia, which has a total of 74 ethnically diverse language groups. About 95% are settled agriculturalists and nomadic pastoralists, practising archaic farming methods and living at subsistence level. A few live in the urban centres.
Oromos today are mainly concentrated in the Oromia region in central Ethiopia, which is the largest region in the country in terms of both population and size. Group members also have a notable presence in northern Kenya.
Language.
The Oromo speak the Oromo language as a mother tongue (also known as "Afaan Oromoo" and "Oromiffa"). It belongs to the Cushitic branch of the Afro-Asiatic family.
According to "Ethnologue", there are around 40,467,900 Oromo speakers worldwide.
The Oromo language is divided into four main linguistic varieties: Borana-Arsi-Guji Oromo, Eastern Oromo, Orma and West Central Oromo.
Modern writing systems used to transcribe Oromo include the Latin script. The Ethiopic script had previously been used by Oromo communities in west-central Ethiopia up until the 1990s. Additionally, the Sapalo script was historically used to write Oromo. It was invented by the Oromo scholar Sheikh Bakri Sapalo (also known by his birth name, Abubaker Usman Odaa) during the 1950s. The Arabic script has also traditionally been used in areas with Muslim populations.
Subgroups.
The Oromo are divided into two major branches that break down into an assortment of clan families. From west to east. The Borana Oromo, also called the Boran, are a pastoralist group living in southern Ethiopia (Oromia) and northern Kenya. The Boran inhabit the former provinces of Shewa, Welega, Illubabor, Kafa, Jimma, Sidamo, northern and northeastern Kenya, and some parts of Somalia.
Barentu/Barentoo or (older) Baraytuma is the other moiety of the Oromo people. The Barentu Oromo inhabit the eastern parts of the Oromia Region in the Zones of Mirab Hararghe or West Hararghe, Arsi Zone, Bale Zone, Debub Mirab Shewa Zone or South West Shewa, Dire Dawa region, the Jijiga Zone of the Somali Region, Administrative Zone 3 of the Afar Region, Oromia Zone of the Amhara Region, and are also found in the Raya Azebo woreda in the Tigray Region.
Society and culture.
Gadaa.
Oromo society was traditionally structured in accordance with "Gadaa", a social stratification system partially based on an eight-year cycle of age sets. However, over the centuries, the age sets grew out-of-alignment with the actual ages of their members, and some time in the 19th century, another age set system was instituted. Under gadaa, every eight years, the Oromo would hold a popular assembly called the "Gumi Gayo", where laws were established for the following eight years. A democratically elected leader, the "Abba Gada", presided over the system for an eight-year term. Gadaa is no longer in wide practice but remains influential.
In a short article, Geoffrey W. Arnott described an Oromo rite of passage in which young men run over the backs of bulls surrounded by the village community.
Religion.
Waaq (also Waq or Waaqa) is the name of God in the traditional Oromo religion, which only about 3% of the population of Oromia follows today, those who do usually living in the Borena Zone.
In the 2007 Ethiopian census in the 88% Oromo region of Oromia, 47.5% were Muslims, 30.5% Orthodox Christians, 17.7% Protestant Christian, 3.3% Traditional. Protestant Christianity is the fastest growing religion inside the Oromo community. In urban areas of Oromia, Orthodox Christianity constitute 51.2% of the population, followed by Islam 29.9% and Protestants 17.5%. But adherence to traditional practices and rituals is still common among many Oromo people regardless of religious background.
Calendar.
It is believed that the Oromo developed their own calendar around 300 BCE. The Oromo calendar is a lunar-stellar calendrical system, relying on astronomical observations of the moon in conjunction with seven particular stars or constellations. Borana Months (Stars/Lunar Phases) are Bittottessa (iangulum), Camsa (Pleiades), Bufa (Aldebarran), Waxabajjii (Belletrix), Obora Gudda (Central Orion-Saiph), Obora Dikka (Sirius), Birra (full moon), Cikawa (gibbous moon), Sadasaa (quarter moon), Abrasa (large crescent), Ammaji (medium crescent), and Gurrandhala (small crescent).
Current.
Most Oromos do not have political unity today due to their historical roles in the Ethiopian state and the region, the spread out movement of different Oromo clans, and the differing religions inside the Oromo nation. Accordingly, Oromos played major roles in all three main political movements in Ethiopia (centralist, federalist and secessionist) during the 19th and 20th century. In addition to holding high powers during the centralist government and the monarchy, the Raya Oromos in Tigray played a major role in the revolt inside the Tigray regional state, known as "Weyane" revolt, challenging Emperor Haile Selassie I's rule in the 1940s. Simultaneously, both federalist and secessionist political forces developed inside the Oromo community.
Presently, a number of ethnic based political organizations have been formed to promote the interests of the Oromo. The first was the Mecha and Tulama Self-Help Association founded in January 1963, but was disbanded by the government after several increasingly tense confrontations in November, 1966. Later groups include the Oromo Liberation Front (OLF), Oromo Federalist Democratic Movement (OFDM), the United Liberation Forces of Oromia (ULFO), the Islamic Front for the Liberation of Oromia (IFLO), the Oromia Liberation Council (OLC), the Oromo National Congress (ONC, recently changed to OPC) and others. Another group, the Oromo People's Democratic Organization (OPDO), is one of the four parties that form the ruling Ethiopian People's Revolutionary Democratic Front (EPRDF) coalition. However, these Oromo groups do not act in unity: the ONC, for example, was part of the United Ethiopian Democratic Forces coalition that challenged the EPRDF in the Ethiopian general elections of 2005.
A number of these groups seek to create an independent Oromo nation, some using armed force. Meanwhile, the ruling OPDO and several opposition political parties in the Ethiopian parliament believe in the unity of the country which has 80 different ethnicities. But most Oromo opposition parties in Ethiopia condemn the economic and political inequalities in the country. Progress has been very slow with the Oromia International Bank just recently established in 2008 though Oromo owned Awash International Bank started early in the 1990s and with the first private Afaan Oromoo newspaper in Ethiopia, Jimma Times, also known as Yeroo, recently established. Though the "Jimma Times" – Yeroo newspaper has faced a lot of harassment and persecution from the Ethiopian government since its beginning. Abuse of Oromo media is widespread in Ethiopia and reflective of the general oppression Oromos face in the country. University departments in Ethiopia did not establish curriculum in Afaan Oromo until the late 1990s.
Various human rights organizations have publicized the government persecution of Oromos in Ethiopia for decades. In 2008, OFDM opposition party condemned the government's indirect role in the death of hundreds of Oromos in western Ethiopia. "Between 2011 and 2014, at least 5000 Oromos have been arrested based on their actual or suspected peaceful opposition to the government. These include thousands of peaceful protestors and hundreds of opposition political party members. The government anticipates a high level of opposition in Oromia, and signs of dissent are sought out and regularly, sometimes pre-emptively, suppressed. In numerous cases, actual or suspected dissenters have been detained without charge or trial, killed by security services during protests, arrests and in detention," See Amnesty International's report titled "Ethiopia: ‘Because I am Oromo’: Sweeping repression in the Oromia region of Ethiopia," http://www.amnesty.org/en/library/info/AFR25/006/2014/en

</doc>
<doc id="22687" url="http://en.wikipedia.org/wiki?curid=22687" title="Oral history">
Oral history

Oral history is the collection and study of historical information about individuals, families, important events, or everyday life using audiotapes, videotapes, or transcriptions of planned interviews. These interviews are conducted with people who participated in or observed past events and whose memories and perceptions of these are to be preserved as an aural record for future generations. Oral history strives to obtain information from different perspectives and most of these cannot be found in written sources. "Oral history" also refers to information gathered in this manner and to a written work (published or unpublished) based on such data, often preserved in archives and large libraries.
The term is sometimes used in a more general sense to refer to any information about past events that people who experienced them tell anybody else, but professional historians usually consider this to be oral tradition. However, as the Columbia Encyclopedia explains: 
Primitive societies have long relied on oral tradition to preserve a record of the past in the absence of written histories. In Western society, the use of oral material goes back to the early Greek historians Herodotus and Thucydides, both of whom made extensive use of oral reports from witnesses. The modern concept of oral history was developed in the 1940s by Allan Nevins and his associates at Columbia University.
In modern times.
Oral history has become an international movement in historical research. Oral historians in different countries have approached the collection, analysis, and dissemination of oral history in different modes. However, it should also be noted that there are many ways of creating oral histories and carrying out the study of oral history even within individual national contexts.
In the words of the "Columbia Encyclopedia": 
The discipline came into its own in the 1960s and early 70s when inexpensive tape recorders were available to document such rising social movements as civil rights, feminism, and anti–Vietnam War protest. Authors such as Studs Terkel, Alex Haley, and Oscar Lewis have employed oral history in their books, many of which are largely based on interviews. In another important example of the genre, a massive archive covering the oral history of American music has been compiled at the Yale School of Music. By the end of the 20th cent. oral history had become a respected discipline in many colleges and universities. At that time the Italian historian Alessandro Portelli and his associates began to study the role that memory itself, whether accurate or faulty, plays in the themes and structures of oral history. Their published work has since become standard material in the field, and many oral historians now include in their research the study of the subjective memory of the persons they interview.
In Britain and Northern Ireland.
Since the early 1970s, oral history in Britain has grown from being a method in folklore studies (see for example the work of the School of Scottish Studies in the 1950s) to becoming a key component in community histories. Oral history continues to be an important means by which non-academics can actively participate in the compilation and study of history. However, practitioners across a wide range of academic disciplines have also developed the method into a way of recording, understanding, and archiving narrated memories. Influences have included women's history and labour history.
In Britain the Oral History Society has played a key role in facilitating and developing the use of oral history. A more complete account of the history of oral history in Britain and Northern Ireland can be found at "Making Oral History" on the Institute of Historical Research's website.
During 1998 and 1999, forty BBC local radio stations recorded personal oral histories from a broad cross-section of the population for the series The Century Speaks. The result was 640 half-hour radio documentaries, broadcast in the final weeks of the millennium, and one of the largest single oral history collections in Europe, the Millennium Memory Bank (MMB). The interview based recordings are held by the British Library Sound Archive in the oral history collection.
In one of the largest memory project anywhere, The BBC in 2003-6 invited its audiences to send in recollections of the homefront in the Second World War. It put 47,000 of the recollections online, along with 15,000 photographs.
In the United States.
Elite studies.
In 1948, Allan Nevins, a Columbia University historian, established the Columbia Oral History Research Office, with a mission of recording, transcribing, and preserving oral history interviews. The Regional Oral History Office was founded in 1954 as a division of the University of California, Berkeley's Bancroft Library. In 1967, American oral historians founded the Oral History Association, and British oral historians founded the Oral History Society in 1969. There are now numerous national organizations and an International Oral History Association, which hold workshops and conferences and publish newsletters and journals devoted to oral history theory and practices.
Oral history began with a focus on national leaders in the United States, but has expanded to include groups representing the entire population. In Britain, the influence of 'history from below' and interviewing people who had been 'hidden from history' was more influential. However, in both countries elite oral history has emerged as an important strand. Scientists, for example, have been covered in numerous oral history projects. Doel (2003) discusses the use of oral interviews by scholars as primary sources, He lists major oral history projects in the history of science begun after 1950. Oral histories, he concludes, can augment the biographies of scientists and help spotlight how their social origins influenced their research. Doel acknowledges the common concerns historians have regarding the validity of oral history accounts. He identifies studies that used oral histories successfully to provide critical and unique insight into otherwise obscure subjects, such as the role scientists played in shaping US policy after World War II. Interviews furthermore can provide road maps for researching archives, and can even serve as a fail-safe resource when written documents have been lost or destroyed. Launius (2003) shows the huge size and complexity of The National Aeronautics and Space Administration (NASA) oral history program since 1959. NASA systematically documented its operations through oral histories. They can help to explore broader issues regarding the evolution of a major federal agency. The collection consists primarily of oral histories conducted by scholars working on books about the agency. Since 1996, however, the collection has also included oral histories of senior NASA administrators and officials, astronauts, and project managers, part of a broader project to document the lives of key agency individuals. Launius emphasizes efforts to include such less-well-known groups within the agency as the Astrobiology Program, and to collect the oral histories of women in NASA.
Folklore roots and ordinary people.
Contemporary oral history involves recording or transcribing eyewitness accounts of historical events. Some anthropologists started collecting recordings (at first especially of Native American folklore) on phonograph cylinders in the late 19th century. In the 1930s, the Federal Writers' Project—part of the Works Progress Administration (WPA)—sent out interviewers to collect accounts from various groups, including surviving witnesses of the Civil War, slavery, and other major historical events. The Library of Congress also began recording traditional American music and folklore onto acetate discs. With the development of audio tape recordings after World War II, the task of oral historians became easier.
In 1946, David P. Boder, a professor of psychology at the Illinois Institute of Technology in Chicago, traveled to Europe to record long interviews with "displaced persons"—most of them Holocaust survivors. Using the first device capable of capturing hours of audio—the wire recorder—Boder came back with the first recorded Holocaust testimonials and in all likelihood the first recorded oral histories of significant length.
Many state and local historical societies have oral history programs. Sinclair Kopp (2002) report on the Oregon Historical Society's program. It began in 1976 with the hiring of Charles Digregorio, who had studied at Columbia with Nevins. Thousands of sound recordings, reel-to-reel tapes, transcriptions, and radio broadcasts have made it one of the largest collections of oral history on the Pacific Coast. In addition to political figures and prominent businessmen, the Oregon Historical Society has done interviews with minorities, women, farmers, and other ordinary citizens, who have contributed extraordinary stories reflecting the state's cultural and social heritage. Hill (2004) encourages oral history projects in high school courses. She demonstrates a lesson plan that encourages the study of local community history through interviews. By studying grassroots activism and the lived experiences of its participants, her high school students came to appreciate how African Americans worked to end Jim Crow laws in the 1950s.
Naison (2005) describes the Bronx African I AM BLACK MAN American History Project, an oral community history project developed by the Bronx County Historical Society. Its goal was to document the histories of black working- and middle-class residents of the South Bronx neighborhood of Morrisania in New York City since the 1940s.
In post-dictatorships.
Czech oral history.
Czech oral history (likewise the oral history applied in others so called post communist countries) did not experience that building period in 1960s and 1970s, partly at the beginning in 1980s, where in the world is spoken about social movement more than a method. With knowledge of the thing I can say that this development was in its beginning probably necessary and well- founded. Understandable (in its beginning) was also some political activism. In 1970s and 1980s in Czech Republic (similarly in other countries of so-called socialist block) was OH absolutely unknown. History and historians did not know about it. Isolate attempts to invite witnesses for scientific project ended without accomplishment (ideological task, guiltlessness of method, imperfect technique, etc.). Hypothetically, if the OH had been discovered earlier for Czech historians, it could have acted positive and surely combative activist role (as A. Freund. P. Thomson and many others speak about it) like in other authoritative regimes. It could have aimed at enquiry of proscribe groups: dissent or prisoners of conscience. To cognate research or any other allusion about just mentioned groups of fellow – citizen was until 1989 totally avoided by communist historiography. Oral History was for the first time used in the mid 1990s but we can speak about some kind of progress for past six years, as Sean Field speaks about it, when it has transformed from disregard and criticized to possibly respect. In the first years of 21st century one can even speak about boom of Oral History in the Czech republic. In 2000, The Oral History Center (COH) at the Institute of Contemporary History, Academy of Sciences, Czech Republic (AV ČR) was established. Next year, in 2001, was created association Post Bellum.
Projects.
"Students in the Period of the Fall of Communism - Life Stories“", published as the book One Hundred Student Revolutions by M. Vaněk and M. Otáhal(1999), was funded by the Grant Agency AV ČR.
The project "„Political Elites and Dissidents during the Period of So-called Normalization - Historical Interviews“" was funded by the GA ČR and resulted in two publications: Victors? Vanquished(2005), a two-volume collection of 50 exemplary interviews; and a compilation of original interpretive essays entitled The Powerful?! or Helpless?! These publications demonstrate that oral history can contribute greatly to our understanding of many interesting fields in human lives and history itself, such as the motives behind the dissidents' activities, the formation of opposition groups, communication between dissidents and state representatives and the emergence of ex-communist elites and their decision-making processes. 
"„An Investigation into Czech Society during the „Normalization“ Era: Biographic Narratives of Workers and the Intelligentsia“" (funded by the Grant Agency AV ČR). The book of interpretations (called "Ordinary People...?!")(2009). 
All oral history centers in the Czech Republic emphasize educational activities (seminars, lectures, conferences), archiving and maintaining interview collections, and providing consultations to those interested in the method.
Post Bellum is a non-profit organization founded in 2001 by a group of historians and journalists interested in increasing the knowledge of people regarding events that occurred in the 20th Century within the Czech Republic and surrounding European countries. Post Bellum has collected thousands of witness accounts by conducting interviews with people who lived through significant periods in history. Their documentation project created in 2008, Memory of Nation, is the biggest oral history project in the Czech Republic. They are working together with Czech Radio and Institute for the Study of Totalitarian Regimes.
In Italy.
Alessandro Portelli is an Italian oral historian. He is known for his work which compared workers' experiences in Harlan County, Kentucky and Terni, Italy. Other oral historians have drawn on Portelli's analysis of memory, identity, and the construction of history.
In Spain.
Because of repression during the Franco dictatorship (1939–75), the development of oral history in Spain was quite limited until the 1970s. It became well-developed in the early 1980s, and often had a focus on the Civil War years (1936–39), especially regarding the losers whose stories had been suppressed. The field was based at the University of Barcelona. Professor Mercedes Vilanova was a leading exponent, and combined it with her interest in quantification and social history. The Barcelona group sought to integrate oral sources with traditional written sources to create mainstream, not ghettoized, historical interpretations. They sought to give a public voice to neglected groups, such as women, illiterates, political leftists, and ethnic minorities.
Methods.
Historians, folklorists, anthropologists, sociologists, journalists, linguists, and many others employ some form of interviewing in their research. Although multi-disciplinary, oral historians have promoted common ethics and standards of practice, most importantly the attaining of the "informed consent" of those being interviewed. Usually this is achieved through a deed of gift, which also establishes copyright ownership that is critical for publication and archival preservation.
Oral historians generally prefer to ask open-ended questions and avoid leading questions that encourage people to say what they think the interviewer wants them to say. Some interviews are "life reviews," conducted with people at the end of their careers. Other interviews focus on a specific period or a specific event in people's lives, such as in the case of war veterans or survivors of a hurricane.
Feldstein (2004) considers oral history to be akin to journalism, Both are committed to uncovering truths and compiling narratives about people, places, and events. Felstein says each could benefit from adopting techniques from the other. Journalism could benefit by emulating the exhaustive and nuanced research methodologies used by oral historians. The practice of oral historians could be enhanced by utilizing the more sophisticated interviewing techniques employed by journalists, in particular, the use of adversarial encounters as a tactic for obtaining information from a respondent.
The first oral history archives focused on interviews with prominent politicians, diplomats, military officers, and business leaders. By the 1960s and '70s, influenced by the rise of new social history, interviewing began to be employed more often when historians investigated history from below. Whatever the field or focus of a project, oral historians attempt to record the memories of many different people when researching a given event. Interviewing a single person provides a single perspective. Individuals may misremember events or distort their account for personal reasons. By interviewing widely, oral historians seek points of agreement among many different sources, and also record the complexity of the issues. The nature of memory—both individual and community—is as much a part of the practice of oral history as are the stories collected.
Legal interpretation and relationship to historical truth.
In 1997 the Supreme Court of Canada, in the "Delgamuukw v. British Columbia" trial, ruled that oral histories were just as important as written testimony. Of oral histories, it said "that they are tangential to the ultimate purpose of the fact-finding process at trial – the determination of the historical truth."
Writers who use oral history have often discussed its relationship to historical truth. Gilda O'Neill writes in "Lost Voices", an oral history of East End hop-pickers: "I began to worry. Were the women's, and my, memories true or were they just stories? I realised that I had no 'innocent' sources of evidence - facts. I had, instead, the stories and their tellers' reasons for remembering in their own particular ways.' Duncan Barrett, one of the co-authors of "The Sugar Girls" describes some of the perils of relying on oral history accounts: "On two occasions, it became clear that a subject was trying to mislead us about what happened – telling a self-deprecating story in one interview, and then presenting a different, and more flattering, version of events when we tried to follow it up. [...] often our interviewees were keen to persuade us of a certain interpretation of the past, supporting broad, sweeping comments about historical change with specific stories from their lives." Alessandro Portelli argues that oral history is valuable nevertheless: "it tells us less about events as such than about their meaning [...] the unique and precious element which oral sources force upon the historian [...] is the speaker's subjectivity."
Regarding the accuracy of oral history, Jean-Loup Gassend concludes in the book "Autopsy of a Battle" "I found that each witness account can be broken down into two parts: 1) descriptions of events that the witness participated in directly, and 2) descriptions of events that the witness did not actually participate in, but that he heard about from other sources. The distinction between these two parts of a witness account is of the highest importance. I noted that concerning events that the witnesses participated in, the information provided was surprisingly reliable, as was confirmed by comparison with other sources. The imprecision or mistakes usually concerned numbers, ranks, and dates, the first two tending to become inflated with time. Concerning events that the witness had not participated in personally, the information was only as reliable as whatever the source of information had been (various rumors); that is to say, it was often very unreliable and I usually discarded such information."
Organization.
National and international organizations promote scholarship in the field. The "Oral History Review" is a scholarly journal begun in 1974. The "Oral History Journal" in Britain was established two years before the "Review". H-ORALHIST is an H-Net Discussion Network established in 1996, based on an earlier listserv, OHA-L, developed by Terry Birdwhistell of the University of Kentucky. It works by email and knits together an international network of researchers interested in creating and using oral history. Its daily email reach 3400 subscribers with discussions of current projects, teaching methods, and the state of historiography in the field. H-ORALHIST is especially interested in methods of teaching oral history to graduate and undergraduate students in diverse settings. H-ORALHIST publishes syllabi, outlines, handouts, bibliographies, tables of contents of journals, guides to term papers, listings of new sources, library catalogs and archives, and reports on new software, datasets, and other materials. H-ORALHIST posts announcements of conferences, fellowships, and jobs. It also carries information about new books and commissions book reviews.
Bangladesh Heritage & Culture in Canada.
Bangladesh Heritage is our legacy from the past, what we live with today, and what we pass on to future generations. Our cultural and natural heritage are both irreplaceable sources of life and inspiration(BHESA).
Find links to our Bangladesh community website, social media presences, and other related projects that could be source of Bangladeshi culture in abroad. 
Here're selected some interesting links to organizations in our local community in Edmonton and greater surroundings.
^http://www.diverseedmonton.ca/community/32-columns/community/56-bhesa-celebrates-bangladesh-culture
BHESA celebrates Bangladesh culture
^http://bhesa.ca/index.php/links/links-bangladesh-heritage
^http://www.pressclubofalberta.com/index.php/en/
^http://www.mjmf.org/

</doc>
<doc id="22689" url="http://en.wikipedia.org/wiki?curid=22689" title="Oncogene">
Oncogene

An oncogene is a gene that has the potential to cause cancer. In tumor cells, they are often mutated or expressed at high levels.
Most of the normal cells will undergo a programmed form of rapid cell death (apoptosis) when critical functions are altered. Activated oncogenes can cause those cells designated for apoptosis to survive and proliferate instead. Most oncogenes require an additional step, such as mutations in another gene, or environmental factors, such as viral infection, to cause cancer. Since the 1970s, dozens of oncogenes have been identified in human cancer. Many cancer drugs target the proteins encoded by oncogenes.
History.
The term "oncogene" was coined in 1969 by National Cancer Institute scientists, George Todaro and Robert Heubner.
The first confirmed oncogene was discovered in 1970 and was termed src (pronounced "sarc" as in "sarcoma"). Src was in fact first discovered as an oncogene in a chicken retrovirus. Experiments performed by Dr. G. Steve Martin of the University of California, Berkeley demonstrated that the Src was indeed the oncogene of the virus. The first nucleotide sequence of v-src was sequenced in 1980 by A.P. Czernilofsky et al.
In 1976 Drs. Dominique Stehelin, J. Michael Bishop and Harold E. Varmus of the University of California, San Francisco demonstrated that oncogenes were activated proto-oncogenes, found in many organisms including humans. For this discovery, proving Todaro and Heubner's "oncogene theory", Bishop and Varmus were awarded the Nobel Prize in Physiology or Medicine in 1989.
Oncoproteins are any proteins coded by an oncogene and they play an important role in the regulation or synthesis of proteins linked to tumorigenic cell growth. Some oncoproteins are accepted and used as tumor markers
Proto-oncogene.
A proto-oncogene is a normal gene that can become an oncogene due to mutations or increased expression. The resultant protein encoded by an oncogene is termed oncoprotein. Proto-oncogenes code for proteins that help to regulate cell growth and differentiation. Proto-oncogenes are often involved in signal transduction and execution of mitogenic signals, usually through their protein products. Upon "activation", a proto-oncogene (or its product) becomes a tumor-inducing agent, an oncogene. Examples of proto-oncogenes include RAS, WNT, MYC, ERK, and TRK. The MYC gene is implicated in Burkitt's Lymphoma, which starts when a chromosomal translocation moves an enhancer sequence within the vicinity of the MYC gene. The MYC gene codes for widely used transcription factors. When the enhancer sequence is wrongly placed, these transcription factors are produced at much higher rates. Another example of an oncogene is the Bcr-Abl gene found on the Philadelphia Chromosome, a piece of genetic material seen in Chronic Myelogenous Leukemia caused by the translocation of pieces from chromosomes 9 and 22. Bcr-Abl codes for a receptor tyrosine kinase, which is constitutively active, leading to uncontrolled cell proliferation. (More information about the Philadelphia Chromosome below)
Activation.
The proto-oncogene can become an oncogene by a relatively small modification of its original function. There are three basic methods of activation:
The expression of oncogenes can be regulated by microRNAs (miRNAs), small RNAs 21-25 nucleotides in length that control gene expression by downregulating them. Mutations in such microRNAs (known as oncomirs) can lead to activation of oncogenes. Antisense messenger RNAs could theoretically be used to block the effects of oncogenes.
Classification.
There are several systems for classifying oncogenes, but there is not yet a widely accepted standard. They are sometimes grouped both spatially (moving from outside the cell inwards) and chronologically (parallelling the "normal" process of signal transduction). There are several categories that are commonly used:
More detailed information for the above Table:

</doc>
<doc id="22691" url="http://en.wikipedia.org/wiki?curid=22691" title="Orthogonal frequency-division multiplexing">
Orthogonal frequency-division multiplexing

Orthogonal frequency-division multiplexing (OFDM) is a method of encoding digital data on multiple carrier frequencies. OFDM has developed into a popular scheme for wideband digital communication, used in applications such as digital television and audio broadcasting, DSL Internet access, wireless networks, powerline networks, and 4G mobile communications.
OFDM is a frequency-division multiplexing (FDM) scheme used as a digital multi-carrier modulation method. A large number of closely spaced orthogonal sub-carrier signals are used to carry data on several parallel data streams or channels. Each sub-carrier is modulated with a conventional modulation scheme (such as quadrature amplitude modulation or phase-shift keying) at a low symbol rate, maintaining total data rates similar to conventional "single-carrier" modulation schemes in the same bandwidth.
The primary advantage of OFDM over single-carrier schemes is its ability to cope with severe channel conditions (for example, attenuation of high frequencies in a long copper wire, narrowband interference and frequency-selective fading due to multipath) without complex equalization filters. Channel equalization is simplified because OFDM may be viewed as using many slowly modulated narrowband signals rather than one rapidly modulated wideband signal. The low symbol rate makes the use of a guard interval between symbols affordable, making it possible to eliminate intersymbol interference (ISI) and utilize echoes and time-spreading (on analogue TV these are visible as ghosting and blurring, respectively) to achieve a diversity gain, i.e. a signal-to-noise ratio improvement. This mechanism also facilitates the design of single frequency networks (SFNs), where several adjacent transmitters send the same signal simultaneously at the same frequency, as the signals from multiple distant transmitters may be combined constructively, rather than interfering as would typically occur in a traditional single-carrier system.
Example of applications.
The following list is a summary of existing OFDM based standards and products. For further details, see the Usage section at the end of the article.
Wireless.
The OFDM based multiple access technology OFDMA is also used in several 4G and pre-4G cellular networks and mobile broadband standards:
Key features.
The advantages and disadvantages listed below are further discussed in the Characteristics and principles of operation section below.
Characteristics and principles of operation.
Orthogonality.
Conceptually, OFDM is a specialized FDM, the additional constraint being: all the carrier signals are orthogonal to each other.
In OFDM, the sub-carrier frequencies are chosen so that the sub-carriers are orthogonal to each other, meaning that cross-talk between the sub-channels is eliminated and inter-carrier guard bands are not required. This greatly simplifies the design of both the transmitter and the receiver; unlike conventional FDM, a separate filter for each sub-channel is not required.
The orthogonality requires that the sub-carrier spacing is formula_1 Hertz, where "T"U seconds is the useful symbol duration (the receiver side window size), and "k" is a positive integer, typically equal to 1. Therefore, with "N" sub-carriers, the total passband bandwidth will be "B" ≈ "N"·Δ"f" (Hz).
The orthogonality also allows high spectral efficiency, with a total symbol rate near the Nyquist rate for the equivalent baseband signal (i.e. near half the Nyquist rate for the double-side band physical passband signal). Almost the whole available frequency band can be utilized. OFDM generally has a nearly 'white' spectrum, giving it benign electromagnetic interference properties with respect to other co-channel users.
OFDM requires very accurate frequency synchronization between the receiver and the transmitter; with frequency deviation the sub-carriers will no longer be orthogonal, causing "inter-carrier interference" (ICI) (i.e., cross-talk between the sub-carriers). Frequency offsets are typically caused by mismatched transmitter and receiver oscillators, or by Doppler shift due to movement. While Doppler shift alone may be compensated for by the receiver, the situation is worsened when combined with multipath, as reflections will appear at various frequency offsets, which is much harder to correct. This effect typically worsens as speed increases, and is an important factor limiting the use of OFDM in high-speed vehicles. In order to mitigate ICI in such scenarios, one can shape each sub-carrier in order to minimize the interference resulting in a non-orthogonal subcarriers overlapping. For example, a low-complexity scheme referred to as WCP-OFDM ("Weighted Cyclic Prefix Orthogonal Frequency-Division Multiplexing") consists in using short filters at the transmitter output in order to perform a potentially non-rectangular pulse shaping and a near perfect reconstruction using a single-tap per subcarrier equalization. Other ICI suppression techniques usually increase drastically the receiver complexity.
Implementation using the FFT algorithm.
The orthogonality allows for efficient modulator and demodulator implementation using the FFT algorithm on the receiver side, and inverse FFT on the sender side. Although the principles and some of the benefits have been known since the 1960s, OFDM is popular for wideband communications today by way of low-cost digital signal processing components that can efficiently calculate the FFT.
The time to compute the inverse-FFT or FFT transform has to take less than the time for each symbol. Which for example for DVB-T (FFT 8k) means the computation has to be done in 896 µs or less.
For an -point FFT this may be approximated to:
The computational demand approximately scales linearly with FFT size so a double size FFT needs double the amount of time and vice versa.
As a comparison an Intel Pentium III CPU at 1.266 GHz is able to calculate a 8 192 point FFT in 576 µs using FFTW. Intel Pentium M at 1.6 GHz does it in 387 µs. Intel Core Duo at 3.0 GHz does it in 96.8 µs.
Guard interval for elimination of intersymbol interference.
One key principle of OFDM is that since low symbol rate modulation schemes (i.e., where the symbols are relatively long compared to the channel time characteristics) suffer less from intersymbol interference caused by multipath propagation, it is advantageous to transmit a number of low-rate streams in parallel instead of a single high-rate stream. Since the duration of each symbol is long, it is feasible to insert a guard interval between the OFDM symbols, thus eliminating the intersymbol interference.
The guard interval also eliminates the need for a pulse-shaping filter, and it reduces the sensitivity to time synchronization problems.
The cyclic prefix, which is transmitted during the guard interval, consists of the end of the OFDM symbol copied into the guard interval, and the guard interval is transmitted followed by the OFDM symbol. The reason that the guard interval consists of a copy of the end of the OFDM symbol is so that the receiver will integrate over an integer number of sinusoid cycles for each of the multipaths when it performs OFDM demodulation with the FFT. In some standards such as Ultrawideband, in the interest of transmitted power, cyclic prefix is skipped and nothing is sent during the guard interval. The receiver will then have to mimic the cyclic prefix functionality by copying the end part of the OFDM symbol and adding it to the beginning portion.
Simplified equalization.
The effects of frequency-selective channel conditions, for example fading caused by multipath propagation, can be considered as constant (flat) over an OFDM sub-channel if the sub-channel is sufficiently narrow-banded (i.e., if the number of sub-channels is sufficiently large). This makes frequency domain equalization possible at the receiver, which is far simpler than the time-domain equalization used in conventional single-carrier modulation. In OFDM, the equalizer only has to multiply each detected sub-carrier (each Fourier coefficient) in each OFDM symbol by a constant complex number, or a rarely changed value.
If differential modulation such as DPSK or DQPSK is applied to each sub-carrier, equalization can be completely omitted, since these non-coherent schemes are insensitive to slowly changing amplitude and phase distortion.
In a sense, improvements in FIR equalization using FFTs or partial FFTs leads mathematically closer to OFDM, but the OFDM technique is easier to understand and implement, and the sub-channels can be independently adapted in other ways than varying equalization coefficients, such as switching between different QAM constellation patterns and error-correction schemes to match individual sub-channel noise and interference characteristics.
Some of the sub-carriers in some of the OFDM symbols may carry pilot signals for measurement of the channel conditions (i.e., the equalizer gain and phase shift for each sub-carrier). Pilot signals and training symbols (preambles) may also be used for time synchronization (to avoid intersymbol interference, ISI) and frequency synchronization (to avoid inter-carrier interference, ICI, caused by Doppler shift).
OFDM was initially used for wired and stationary wireless communications. However, with an increasing number of applications operating in highly mobile environments, the effect of dispersive fading caused by a combination of multi-path propagation and doppler shift is more significant. Over the last decade, research has been done on how to equalize OFDM transmission over doubly selective channels.
Channel coding and interleaving.
OFDM is invariably used in conjunction with channel coding (forward error correction), and almost always uses frequency and/or time interleaving.
Frequency (subcarrier) interleaving increases resistance to frequency-selective channel conditions such as fading. For example, when a part of the channel bandwidth fades, frequency interleaving ensures that the bit errors that would result from those subcarriers in the faded part of the bandwidth are spread out in the bit-stream rather than being concentrated. Similarly, time interleaving ensures that bits that are originally close together in the bit-stream are transmitted far apart in time, thus mitigating against severe fading as would happen when travelling at high speed.
However, time interleaving is of little benefit in slowly fading channels, such as for stationary reception, and frequency interleaving offers little to no benefit for narrowband channels that suffer from flat-fading (where the whole channel bandwidth fades at the same time).
The reason why interleaving is used on OFDM is to attempt to spread the errors out in the bit-stream that is presented to the error correction decoder, because when such decoders are presented with a high concentration of errors the decoder is unable to correct all the bit errors, and a burst of uncorrected errors occurs. A similar design of audio data encoding makes compact disc (CD) playback robust.
A classical type of error correction coding used with OFDM-based systems is convolutional coding, often concatenated with Reed-Solomon coding. Usually, additional interleaving (on top of the time and frequency interleaving mentioned above) in between the two layers of coding is implemented. The choice for Reed-Solomon coding as the outer error correction code is based on the observation that the Viterbi decoder used for inner convolutional decoding produces short error bursts when there is a high concentration of errors, and Reed-Solomon codes are inherently well-suited to correcting bursts of errors.
Newer systems, however, usually now adopt near-optimal types of error correction codes that use the turbo decoding principle, where the decoder iterates towards the desired solution. Examples of such error correction coding types include turbo codes and LDPC codes, which perform close to the Shannon limit for the Additive White Gaussian Noise (AWGN) channel. Some systems that have implemented these codes have concatenated them with either Reed-Solomon (for example on the MediaFLO system) or BCH codes (on the DVB-S2 system) to improve upon an error floor inherent to these codes at high signal-to-noise ratios.
Adaptive transmission.
The resilience to severe channel conditions can be further enhanced if information about the channel is sent over a return-channel. Based on this feedback information, adaptive modulation, channel coding and power allocation may be applied across all sub-carriers, or individually to each sub-carrier. In the latter case, if a particular range of frequencies suffers from interference or attenuation, the carriers within that range can be disabled or made to run slower by applying more robust modulation or error coding to those sub-carriers.
The term "discrete multitone modulation" ("DMT") denotes OFDM based communication systems that adapt the transmission to the channel conditions individually for each sub-carrier, by means of so-called "bit-loading". Examples are ADSL and VDSL.
The upstream and downstream speeds can be varied by allocating either more or fewer carriers for each purpose. Some forms of rate-adaptive DSL use this feature in real time, so that the bitrate is adapted to the co-channel interference and bandwidth is allocated to whichever subscriber needs it most.
OFDM extended with multiple access.
OFDM in its primary form is considered as a digital modulation technique, and not a multi-user channel access method, since it is utilized for transferring one bit stream over one communication channel using one sequence of OFDM symbols. However, OFDM can be combined with multiple access using time, frequency or coding separation of the users.
In orthogonal frequency-division multiple access (OFDMA), frequency-division multiple access is achieved by assigning different OFDM sub-channels to different users. OFDMA supports differentiated quality of service by assigning different number of sub-carriers to different users in a similar fashion as in CDMA, and thus complex packet scheduling or Media Access Control schemes can be avoided. OFDMA is used in:
OFDMA is also a candidate access method for the IEEE 802.22 "Wireless Regional Area Networks" (WRAN). The project aims at designing the first cognitive radio based standard operating in the VHF-low UHF spectrum (TV spectrum).
In Multi-carrier code division multiple access (MC-CDMA), also known as OFDM-CDMA, OFDM is combined with CDMA spread spectrum communication for coding separation of the users. Co-channel interference can be mitigated, meaning that manual fixed channel allocation (FCA) frequency planning is simplified, or complex dynamic channel allocation (DCA) schemes are avoided.
Space diversity.
In OFDM based wide area broadcasting, receivers can benefit from receiving signals from several spatially dispersed transmitters simultaneously, since transmitters will only destructively interfere with each other on a limited number of sub-carriers, whereas in general they will actually reinforce coverage over a wide area. This is very beneficial in many countries, as it permits the operation of national single-frequency networks (SFN), where many transmitters send the same signal simultaneously over the same channel frequency. SFNs utilise the available spectrum more effectively than conventional multi-frequency broadcast networks (MFN), where program content is replicated on different carrier frequencies. SFNs also result in a diversity gain in receivers situated midway between the transmitters. The coverage area is increased and the outage probability decreased in comparison to an MFN, due to increased received signal strength averaged over all sub-carriers.
Although the guard interval only contains redundant data, which means that it reduces the capacity, some OFDM-based systems, such as some of the broadcasting systems, deliberately use a long guard interval in order to allow the transmitters to be spaced farther apart in an SFN, and longer guard intervals allow larger SFN cell-sizes. A rule of thumb for the maximum distance between transmitters in an SFN is equal to the distance a signal travels during the guard interval — for instance, a guard interval of 200 microseconds would allow transmitters to be spaced 60 km apart.
A "single frequency network" is a form of transmitter macrodiversity. The concept can be further utilized in "dynamic single-frequency networks" (DSFN), where the SFN grouping is changed from timeslot to timeslot.
OFDM may be combined with other forms of space diversity, for example antenna arrays and MIMO channels. This is done in the IEEE802.11 Wireless LAN standard.
Linear transmitter power amplifier.
An OFDM signal exhibits a high peak-to-average power ratio (PAPR) because the independent phases of the sub-carriers mean that they will often combine constructively. Handling this high PAPR requires:
Any non-linearity in the signal chain will cause intermodulation distortion that
The linearity requirement is demanding, especially for transmitter RF output circuitry where amplifiers are often designed to be non-linear in order to minimise power consumption. In practical OFDM systems a small amount of peak clipping is allowed to limit the PAPR in a judicious trade-off against the above consequences. However, the transmitter output filter which is required to reduce out-of-band spurs to legal levels has the effect of restoring peak levels that were clipped, so clipping is not an effective way to reduce PAPR.
Although the spectral efficiency of OFDM is attractive for both terrestrial and space communications, the high PAPR requirements have so far limited OFDM applications to terrestrial systems.
The crest factor CF (in dB) for an OFDM system with n uncorrelated sub-carriers is
 CF = 10 log ( n ) + CFc ...
where CFc is the crest factor (in dB) for each sub-carrier.
(CFc is 3.01 dB for the sine waves used for BPSK and QPSK modulation).
For example, the DVB-T signal in 2K mode is composed of 1705 sub-carriers that are each QPSK-modulated, giving a crest factor of 35.32 dB.
Many crest factor reduction techniques have been developed.
The dynamic range required for an FM receiver is 120 dB while DAB only require
about 90 dB. As a comparison, each extra bit per sample increases the dynamic range with 6 dB.
Efficiency comparison between single carrier and multicarrier.
The performance of any communication system can be measured in terms of its power efficiency and bandwidth efficiency.
The power efficiency describes the ability of communication system to preserve bit error rate (BER) of the transmitted signal at low power levels.
Bandwidth efficiency reflects how efficiently the allocated bandwidth is utilized and is defined as the throughput data rate per Hertz in a given bandwidth.
If the large number of subcarriers are used, the bandwidth efficiency of multicarrier system such as OFDM with using optical fiber channel is defined as
Factor 2 is because of two polarization states in the fiber.
where formula_7 is the symbol rate in giga symbol per second (Gsps), and formula_8 is the bandwidth of OFDM signal.
There is saving of bandwidth by using Multicarrier modulation with orthogonal frequency division multiplexing . So the bandwidth for multicarrier system is less in comparison with single carrier system and hence bandwidth efficiency of multicarrier system is larger than single carrier system.
There is only 1 dBm increase in receiver power, but we get 76.7% improvement in bandwidth efficiency with using multicarrier transmission technique.
Idealized system model.
This section describes a simple idealized OFDM system model suitable for a time-invariant AWGN channel.
Transmitter.
An OFDM carrier signal is the sum of a number of orthogonal sub-carriers, with baseband data on each sub-carrier being independently modulated commonly using some type of quadrature amplitude modulation (QAM) or phase-shift keying (PSK). This composite baseband signal is typically used to modulate a main RF carrier.
formula_9 is a serial stream of binary digits. By inverse multiplexing, these are first demultiplexed into formula_10 parallel streams, and each one mapped to a (possibly complex) symbol stream using some modulation constellation (QAM, PSK, etc.). Note that the constellations may be different, so some streams may carry a higher bit-rate than others.
An inverse FFT is computed on each set of symbols, giving a set of complex time-domain samples. These samples are then quadrature-mixed to passband in the standard way. The real and imaginary components are first converted to the analogue domain using digital-to-analogue converters (DACs); the analogue signals are then used to modulate cosine and sine waves at the carrier frequency, formula_11, respectively. These signals are then summed to give the transmission signal, formula_12.
Receiver.
The receiver picks up the signal formula_13, which is then quadrature-mixed down to baseband using cosine and sine waves at the carrier frequency. This also creates signals centered on formula_14, so low-pass filters are used to reject these. The baseband signals are then sampled and digitised using analog-to-digital converters (ADCs), and a forward FFT is used to convert back to the frequency domain.
This returns formula_10 parallel streams, each of which is converted to a binary stream using an appropriate symbol detector. These streams are then re-combined into a serial stream, formula_16, which is an estimate of the original binary stream at the transmitter.
Mathematical description.
If formula_10 sub-carriers are used, and each sub-carrier is modulated using formula_18 alternative symbols, the OFDM symbol alphabet consists of formula_19 combined symbols.
The low-pass equivalent OFDM signal is expressed as:
where formula_21 are the data symbols, formula_10 is the number of sub-carriers, and formula_23 is the OFDM symbol time. The sub-carrier spacing of formula_24 makes them orthogonal over each symbol period; this property is expressed as:
where formula_26 denotes the complex conjugate operator and formula_27 is the Kronecker delta.
To avoid intersymbol interference in multipath fading channels, a guard interval of length formula_28 is inserted prior to the OFDM block. During this interval, a "cyclic prefix" is transmitted such that the signal in the interval formula_29 equals the signal in the interval formula_30. The OFDM signal with cyclic prefix is thus:
The low-pass signal above can be either real or complex-valued. Real-valued low-pass equivalent signals are typically transmitted at baseband—wireline applications such as DSL use this approach. For wireless applications, the low-pass signal is typically complex-valued; in which case, the transmitted signal is up-converted to a carrier frequency formula_11. In general, the transmitted signal can be represented as:
Usage.
OFDM is used in:
OFDM system comparison table.
Key features of some common OFDM based systems are presented in the following table.
ADSL.
OFDM is used in ADSL connections that follow the ANSI T1.413 and G.dmt (ITU G.992.1) standards, where it is called "discrete multitone modulation" (DMT). DSL achieves high-speed data connections on existing copper wires. OFDM is also used in the successor standards ADSL2, ADSL2+, VDSL, VDSL2, and G.fast. ADSL2 uses variable sub-carrier modulation, ranging from BPSK to 32768QAM (in ADSL terminology this is referred to as bit-loading, or bit per tone, 1 to 15 bits per sub-carrier).
Long copper wires suffer from attenuation at high frequencies. The fact that OFDM can cope with this frequency selective attenuation and with narrow-band interference are the main reasons it is frequently used in applications such as ADSL modems. However, DSL cannot be used on every copper pair; interference may become significant if more than 25% of phone lines coming into a central office are used for DSL.
Powerline Technology.
OFDM is used by many powerline devices to extend digital connections through power wiring. Adaptive modulation is particularly important with such a noisy channel as electrical wiring.
Some medium speed smart metering modems, "Prime" and "G3" use OFDM at modest frequencies (30–100 kHz)with modest numbers of channels (several hundred) in order to overcome the intersymbol interference in the power line environment.
The IEEE 1901 standards include two incompatible physical layers that both use OFDM.
The ITU-T G.hn standard, which provides high-speed local area networking over existing home wiring (power lines, phone lines and coaxial cables) is based on a PHY layer that specifies OFDM with adaptive modulation and a Low-Density Parity-Check (LDPC) FEC code.
Wireless local area networks (LAN) and metropolitan area networks (MAN).
OFDM is extensively used in wireless LAN and MAN applications, including IEEE 802.11a/g/n and WiMAX.
IEEE 802.11a/g/n operating in the 2.4 and 5 GHz bands, specifies a per-stream airside data rates ranging from 6 to 54 Mbit/s. If both devices can utilize "HT mode" added with 802.11n then the top 20 MHz per-stream rate is increased to 72.2 Mbit/s with the option of data rates between 13.5 and 150 Mbit/s using a 40 MHz channel. Four different modulation schemes are used: BPSK, QPSK, 16-QAM, and 64-QAM, along with a set of error correcting rates (1/2–5/6). The multitude of choices allows the system to adapt the optimum data rate for the current signal conditions.
Wireless personal area networks (PAN).
OFDM is also now being used in the for high-speed wireless personal area networks in the 3.1–10.6 GHz ultrawideband spectrum (see MultiBand-OFDM).
Terrestrial digital radio and television broadcasting.
Much of Europe and Asia has adopted OFDM for terrestrial broadcasting of digital television (DVB-T, DVB-H and T-DMB) and radio (EUREKA 147 DAB, Digital Radio Mondiale, HD Radio and T-DMB).
DVB-T.
By Directive of the European Commission, all television services transmitted to viewers in the European Community must use a transmission system that has been standardized by a recognized European standardization body, and such a standard has been developed and codified by the DVB Project, "Digital Video Broadcasting (DVB); Framing structure, channel coding and modulation for digital terrestrial television". Customarily referred to as DVB-T, the standard calls for the exclusive use of COFDM for modulation. DVB-T is now widely used in Europe and elsewhere for terrestrial digital TV.
SDARS.
The ground segments of the Digital Audio Radio Service (SDARS) systems used by XM Satellite Radio and Sirius Satellite Radio are transmitted using Coded OFDM (COFDM). The word "coded" comes from the use of forward error correction (FEC).
COFDM vs VSB.
The question of the relative technical merits of COFDM versus 8VSB for terrestrial digital television has been a subject of some controversy, especially between European and North American technologists and regulators. The United States has rejected several proposals to adopt the COFDM based DVB-T system for its digital television services, and has instead opted for 8VSB (vestigial sideband modulation) operation.
One of the major benefits provided by COFDM is in rendering radio broadcasts relatively immune to multipath distortion and signal fading due to atmospheric conditions or passing aircraft. Proponents of COFDM argue it resists multipath far better than 8VSB. Early 8VSB DTV (digital television) receivers often had difficulty receiving a signal. Also, COFDM allows single-frequency networks, which is not possible with 8VSB.
However, newer 8VSB receivers are far better at dealing with multipath, hence the difference in performance may diminish with advances in equalizer design. Moreover, 8VSB is nearly a single sideband transmission scheme, while OFDM can be described as a double sideband modulation scheme. This implies that 8VSB (with 3 bit/symbol) modulation offers similar bit rate and require similar bandwidth as 64QAM OFDM (with 6 bit per symbol and sub-carrier), i.e. similar spectral efficiency in (bit/s)/Hz. However, the small 8VSB alphabet of 8 symbols makes it less prone to noise than the 64QAM alphabet of 64 symbols, resulting in lower bit-error rate for the same carrier-to-noise ratio in case of multipath propagation. 8VSB requires less power than 64QAM to transmit a signal the same distance (i.e., the received carrier-to-noise threshold is lower for the same bit error rate).
Digital radio.
COFDM is also used for other radio standards, for Digital Audio Broadcasting (DAB), the standard for digital audio broadcasting at VHF frequencies, for Digital Radio Mondiale (DRM), the standard for digital broadcasting at shortwave and medium wave frequencies (below 30 MHz) and for DRM+ a more recently introduced standard for digital audio broadcasting at VHF frequencies. (30 to 174 MHz)
The USA again uses an alternate standard, a proprietary system developed by iBiquity dubbed "HD Radio". However, it uses COFDM as the underlying broadcast technology to add digital audio to AM (medium wave) and FM broadcasts.
Both Digital Radio Mondiale and HD Radio are classified as in-band on-channel systems, unlike Eureka 147 (DAB: Digital Audio Broadcasting) which uses separate VHF or UHF frequency bands instead.
BST-OFDM used in ISDB.
The "band-segmented transmission orthogonal frequency division multiplexing" ("BST-OFDM") system proposed for Japan (in the ISDB-T, ISDB-TSB, and ISDB-C broadcasting systems) improves upon COFDM by exploiting the fact that some OFDM carriers may be modulated differently from others within the same multiplex. Some forms of COFDM already offer this kind of hierarchical modulation, though BST-OFDM is intended to make it more flexible. The 6 MHz television channel may therefore be "segmented", with different segments being modulated differently and used for different services.
It is possible, for example, to send an audio service on a segment that includes a segment composed of a number of carriers, a data service on another segment and a television service on yet another segment—all within the same 6 MHz television channel. Furthermore, these may be modulated with different parameters so that, for example, the audio and data services could be optimized for mobile reception, while the television service is optimized for stationary reception in a high-multipath environment.
Ultra-wideband.
Ultra-wideband (UWB) wireless personal area network technology may also utilise OFDM, such as in Multiband OFDM (MB-OFDM). This UWB specification is advocated by the WiMedia Alliance (formerly by both the Multiband OFDM Alliance [MBOA] and the WiMedia Alliance, but the two have now merged), and is one of the competing UWB radio interfaces.
FLASH-OFDM.
"Fast low-latency access with seamless handoff orthogonal frequency division multiplexing" (Flash-OFDM), also referred to as F-OFDM, was based on OFDM and also specified higher protocol layers. It was developed by Flarion, and purchased by Qualcomm in January 2006. Flash-OFDM was marketed as a packet-switched cellular bearer, to compete with GSM and 3G networks. As an example, 450 MHz frequency bands previously used by NMT-450 and C-Net C450 (both 1G analogue networks, now mostly decommissioned) in Europe are being licensed to Flash-OFDM operators.
In Finland, the license holder Digita began deployment of a nationwide "@450" wireless network in parts of the country since April 2007. It was purchased by Datame in 2011. In February 2012 Datame announced they would upgrade the 450 MHz network to competing CDMA2000 technology.
Slovak Telekom in Slovakia offers Flash-OFDM connections with a maximum downstream speed of 5.3 Mbit/s, and a maximum upstream speed of 1.8 Mbit/s, with a coverage of over 70 percent of Slovak population.
T-Mobile Germany uses Flash-OFDM to backhaul Wi-Fi HotSpots on the Deutsche Bahn's ICE high speed trains.
American wireless carrier Nextel Communications field tested wireless broadband network technologies including Flash-OFDM in 2005. Sprint purchased the carrier in 2006 and decided to deploy the mobile version of WiMAX, which is based on Scalable Orthogonal Frequency Division Multiple Access (SOFDMA) technology.
Citizens Telephone Cooperative launched a mobile broadband service based on Flash-OFDM technology to subscribers in parts of Virginia in March 2006. The maximum speed available was 1.5 Mbit/s. The service was discontinued on April 30, 2009.
Digiweb Ltd. launched a mobile broadband network using Flash-OFDM technology at 872 MHz in July 2007 in Ireland and Digiweb also owns a national 872 MHz license in Norway. Voice handsets are not yet available as of November 2007. The deployment is live in a small area north of Dublin only.
Butler Networks operates a Flash-OFDM network in Denmark at 872 MHz.
In Netherlands, KPN-telecom will start a pilot around July 2007.

</doc>
<doc id="22693" url="http://en.wikipedia.org/wiki?curid=22693" title="Operator overloading">
Operator overloading

In programming, operator overloading—less commonly known as operator ad hoc polymorphism—is a specific case of polymorphism, where different operators have different implementations depending on their arguments. Operator overloading is generally defined by the language, the programmer, or both.
Motivation.
Operator overloading is syntactic sugar, and is used because it allows the developer to program using notation closer to the target domain and allows user-defined types a similar level of syntactic support as types built into the language. It is common, for example, in scientific computing, where it allows computational representations of mathematical objects to be manipulated with the same syntax as on paper.
Operator overloading does not change the expressive power of a language (with functions), as it can be emulated using function calls; for example, consider variables codice_1 of some user-defined type, such as matrices: 
 a + b * c
In a language that supports operator overloading, and with the usual assumption that the '*' operator has higher precedence than '+' operator, this is a concise way of writing:
 add (a, multiply (b,c))
However, the former syntax reflects common mathematical usage.
Examples.
In this case, the addition operator is overloaded to allow addition on a user-defined type "Time" (in C++):
Addition is a binary operation, which means it has two operands. In C++, the arguments being passed are the operands, and the codice_2 object is the returned value.
The operation could also be defined as a class method, replacing codice_3 by the hidden codice_4 argument; however this forces the left operand to be of type codice_5:
Note that a unary operator defined as a class method would receive no apparent argument (it only works from codice_4):
Less than(<) operator is often overloaded to sort a structure or class. 
Note that in the last example, operator overloading is done within the class which is the same as the previous examples. In C++ after overloading less than operator(<), standard sorting functions can be used to sort some classes.
Criticisms.
Operator overloading has often been criticized because it allows programmers to give operators completely different semantics depending on the types of their operands. For example, the use of the codice_7 in C++'s:
shifts the bits in the variable a left by 1 bit if a is of an integer type, but if a is an output stream then the above code will attempt to write a "1" to the stream. Because operator overloading allows the original programmer to change the usual semantics of an operator and to catch any subsequent programmers by surprise, it is considered good practice to use operator overloading with care (the creators of Java decided not to use this feature, although not necessarily for this reason).
Another, more subtle, issue with operators is that certain rules from mathematics can be wrongly expected or unintentionally assumed. For example, the commutativity of + (i.e. that codice_8) does not always apply; an example of this occurs when the operands are strings, since + is commonly overloaded to perform a concatenation of strings (i.e. codice_9 yields codice_10, which is different from codice_11 yields codice_12). A typical counter to this argument comes directly from mathematics: While + is commutative on integers (and most generally any complex numbers), it is not commutative for other "types" of variable. It can be further noted that + is, in practice, not associative even with floating-point values, due to rounding errors. Another example: In mathematics, multiplication is commutative for real and complex numbers but not commutative in matrix multiplication.
Catalog.
A classification of some common programming languages is made according to whether their operators are overloadable by the programmer and whether the operators are limited to a predefined set.
Timeline of operator overloading.
1960s.
The ALGOL 68 specification allowed operator overloading.
Extract from the ALGOL 68 language specification (page 177) where the overloaded operators ¬, =, ≠ and abs are defined:
 10.2.2. Operations on Boolean Operands
 a) op ∨ = (bool a, b) bool:( a | true | b );
 b) op ∧ = (bool a, b) bool: ( a | b | false );
 c) op ¬ = (bool a) bool: ( a | false | true );
 d) op = = (bool a, b) bool:( a∧b ) ∨ ( ¬b∧¬a );
 e) op ≠ = (bool a, b) bool: ¬(a=b);
 f) op abs = (bool a)int: ( a | 1 | 0 );
Note that no special declaration is required to "overload" an operator, and the programmer is free to create new operators.
1980s.
Ada supports overloading of operators from its inception, with the publication of the Ada 83 language standard. However, the designers of the language chose not to permit the definition of new operators: only the existing operators in the language may be overloaded (by defining new functions with identifiers such as "+", "*", "and" etc.). Subsequent revisions of the language (in 1995 and 2005) maintain the restriction to overloading of existing operators.
C++'s operator overloading is further refined from that of ALGOL 68's.
1990s.
Sun chooses not to include operator overloading in the Java
language.
Ruby allows operator overloading as syntactic sugar for simple method calls.
Lua allows operator overloading as syntactic sugar for method calls with the added feature that if the first operand doesn't define that operator, the method for the second operand will be used.
2000s.
Microsoft includes operator overloading for C# in 2001.
Scala treats all operators as methods and thus allows operator overloading by proxy.
In Perl 6, the definition of all operators is delegated to lexical functions, and so, using function definitions, operators can be overloaded or new operators added. For example, the function defined in the Rakudo source for incrementing a Date object with "+" is:
Since "multi" was used, the function gets added to the list of multidispatch candidates, and "+" is only overloaded for the case where the type constraints in the function signature are met.
While the capacity for overloading includes +, *, >=, the postfix and term i, and so on, it also allows for overloading various brace operators: "[x, y]", "x[ y ]", "x{ y }", and "x( y )".

</doc>
<doc id="22700" url="http://en.wikipedia.org/wiki?curid=22700" title="Omphalos hypothesis">
Omphalos hypothesis

The Omphalos hypothesis is the argument that God created the world recently (in the last ten thousand years, in keeping with Flood geology), but complete with signs of great age. It was named after the title of an 1857 book, "Omphalos" by Philip Henry Gosse, in which Gosse argued that in order for the world to be "functional", God must have created the Earth with mountains and canyons, trees with growth rings, Adam and Eve with hair, fingernails, and navels ("omphalos" is Greek for "navel"), and that therefore "no" evidence that we can see of the presumed age of the earth and universe can be taken as reliable. The idea saw some revival in the 20th century by some creationists, who extended the argument to light that appears to originate in far-off stars and galaxies (although other creationists reject this explanation). Many creationists believe that Adam and Eve had no navels, and that the trees in the Garden of Eden had no growth rings.
Support.
Although the grasses were only a moment old at their creation, they appeared as if they were months old. Likewise, the trees, although only a day old when they sprouted forth, were nevertheless like ... years old as they were fully grown and fruits were already budding on their branches.
Chateaubriand wrote in his 1802 book, "Génie du christianisme" (Part I Book IV Chapter V): "God might have created, and doubtless did create, the world with all the marks of antiquity and completeness which it now exhibits." Rabbi Dovid Gottlieb supports a similar position, arguing further that the evidence for an old universe is strong: "The bones, artifacts, partially decayed radium, potassium-argon, uranium, the red-shifted light from space, etc.– all of it points to a greater age which nevertheless is not true."
Creationists still argue the same way. For instance, John D. Morris, president of the Institute for Creation Research talks about the "appearance of age":
When Adam was created, he no doubt looked like a mature adult, fully able to walk, talk, care for the garden, etc. When God created fruit trees, they were already bearing fruit. In each case, what He created was functionally complete right from the start—able to fulfill the purpose for which it was created. Stars, created on Day Four, had to be seen to perform their purpose of usefulness in telling time; therefore, their light had to be visible on Earth right from the start.
He does not extend this idea to the geological record, preferring to believe that it was all created in the Flood, but others such as Gerald E. Aardsma go further, with his idea of "virtual history". This appears to suggest that events after the creation have changed the "virtual history" we now see, including the fossils:
This raises one more major point of difference, the handling of the Fall. Briefly, Creation with Appearance of Age runs into a theological snag with things like fossils of fish with other smaller fish in their stomachs: "Do you mean that God chose to paint, of all things, a facade of SUFFERING and DEATH onto the creation when He gave it this arbitrary appearance of age at the time of creation?" The virtual history paradigm recognizes simply that all creation type miracles entail a virtual history, so the Fall, with its creation type miracles (by which the nature of the creation was changed --- "subjected to futility") carried with it its own (fallen) virtual history, which is the virtual history we now see. We do not see the original utopian pre-Fall creation with its (presumably utopian) virtual history.
The past president of the Missouri Association for Creation has said:
The appearance of age in the things which God created is a much-debated issue in contemporary Christian scientific circles. Can God -- or more accurately -- would God create something which at the very moment of its creation has the appearance of age? The short answer to this question may be: How Else? How, indeed, could God create anything that did not appear to us to be aged (like a fine wine) at the moment of its creation... Maybe you thought of a visible star -- depending on its distance from the earth, its light might appear to have been traveling for over a billion years to reach your eyes. All of these things would have the appearance of age and an ongoing process at the very moment of their creation.
Criticisms.
When did false history begin?
Though Gosse's original Omphalos hypothesis specifies a popular creation story, others have proposed that the idea does not preclude creation as recently as five minutes ago, including memories of times before this created "in situ". This idea is sometimes called "Last Thursdayism" by its opponents, as in "the world might as well have been created last Thursday."
The concept is both unverifiable and unfalsifiable through any conceivable scientific method—in other words, it is impossible even "in principle" to subject it to any form of test by reference to any empirical data because the empirical data themselves are considered to have been arbitrarily created to look the way they do at every observable level of detail.
A deceptive creator.
From a religious viewpoint, it can be interpreted as God having 'created a fake,' such as illusions of light in space of stellar explosions (supernovae) that never really happened, or volcanic mountains that were never really volcanoes in the first place and that never actually experienced erosion.
This conception has therefore drawn harsh rebuke from some theologians. Reverend Canon Brian Hebblethwaite, for example, preached against Bertrand Russell's Five minute hypothesis:
 Bertrand Russell wrote, in The Analysis of Mind: 'there is no logical impossibility in the hypothesis that the world sprang into being five minutes ago, exactly as it then was, with a population that "remembered" a wholly unreal past'. 'Human beings', posited in being five minutes ago with built-in 'memory' traces, would not be human beings. The suggestion is logically incoherent.
The basis for Hebblethwaite's objection, however, is the presumption of a God that would not deceive us about our very humanity - an unprovable presumption that the Omphalos hypothesis rejects at the outset. Hebblethwaite also suggests that God necessarily had to create certain elements of the Universe in combination with the creation of man:
 to be an adult human being, we have to have gone through a real process of growth and nurture and a real history of interpersonal relation in a real and specific culture. One can even suggest that it is necessary for the Creator to have fashioned us in and through a whole evolving physical universe. As, again, Austin Farrer put it, 'if God wished to make no more than any single one of us, he would need to make half a universe. And why? Because no one of us would be the creature he is, if a thousand thousand lines of converging history, both physical and personal, had not met in him. Your life or mine is but a half-sentence in the book of the world. Tear it from its place, and it cannot be read; or if it can be read, it signifies nothing'.
In a rebuttal of the claim that God might have implanted a false history of the age of the Universe in order to test our faith in the truth of the Torah, Rabbi Natan Slifkin, an author whose works have been banned by several Haredi rabbis for going against the tenets of the Talmud, writes:
 God essentially created two conflicting accounts of Creation: one in nature, and one in the Torah. How can it be determined which is the real story, and which is the fake designed to mislead us? One could equally propose that it is nature which presents the real story, and that the Torah was devised by God to test us with a fake history!
One has to be able to rely on God's truthfulness if religion is to function. Or, to put it another way—if God went to enormous lengths to convince us that the world is billions of years old, who are we to disagree?
Gosse, however, did not assert that God deceived us, only that any act of creation of human, animal or plant would "at the instant of its creation present indubitable evidences of a previous history" in far more subtle, microscopic and unavoidable ways than the presence or absence of hair or navels. He presented it not as an hypothesis but as a law or logical necessity: any created organism must be "from the first marked with the records of a previous being". The alternative, he argued, would be a created earth in which trees (larger than saplings) would exhibit no seasonal growth rings.
A consistent creator.
Some Jewish commentaries on the age of the Universe delve into the Omphalos hypothesis. In particular, rabbi Natan Slifkin writes:
 Gosse took it as a given that each animal species was created "ex nihilo" rather than having evolved. Based on that premise, he pointed out that there is no such thing as creating something at the "first stage" in an animal's existence. A cow begins life as a calf; but before that, it is a fetus, and earlier than being a fetus, it was an ovum, part of its mother. Every species is an endless cycle of life.
"However, careful consideration shows that the false history was most certainly "not" complete." Would Adam have had "memories" of his non-existent childhood? Would he have possessed mementos from his non-existent childhood? Likewise, surely not. Would he have scars from non-existent childhood mishaps? Well, since he knew that he never experienced any such mishaps, then he surely would not have possessed scars either. But, by the same token, there is no reason why he should have had a scar from the umbilical cord not being removed ... Since it must necessarily have been incomplete, it is difficult to argue that God should have created any false history at all.
Other formulations.
Five-minute hypothesis.
The five-minute hypothesis is a skeptical hypothesis put forth by the philosopher Bertrand Russell that proposes that the universe sprang into existence five minutes ago from nothing, with human memory and all other signs of history included. It is a commonly used example of how one may maintain extreme philosophical skepticism with regards to memory.
Borges's "Tlön, Uqbar, Orbis Tertius".
Jorge Luis Borges, in his 1940 work, "Tlön, Uqbar, Orbis Tertius", describes a fictional world in which some essentially follow as a religious belief a philosophy much like Russell's discussion on the logical extreme of Gosse's theory:
 One of the schools of Tlön goes so far as to negate time: it reasons that the present is indefinite, that the future has no reality other than as a present hope, the past none other than present memory.
Borges had earlier written a short essay, "The Creation and P. H. Gosse" that explored the rejection of Gosse's "Omphalos". Borges argued that its unpopularity stemmed from Gosse's explicit (if inadvertent) outlining of what Borges characterized as absurdities in the Genesis story.
Last Thursdayism.
Last Thursdayism is a similar response to omphalism which posits that, by the same logic, the world might have been created last Thursday (or by implication, on any other given date and time), but with the appearance of age: people's memories, history books, fossils, light already on the way from distant stars, and so forth. It is aimed at the logic point that when this logic is permitted, it can be used to prove any "fixed date creation" schema. The first known reference is on November 2, 1992, in a Usenet post titled "Last Thursdayism proven!", responding to an apocalyptic prediction:
 As everyone knows, it was predicted that the world would end last Wednesday at 10:00 PST. Since there appears to be a world in existence now, the entire universe must therefore have been recreated, complete with an apparent "history", last *Thursday*. QED.
It developed on talk.origins into a satiric parody religion with a catechism; other postings started the "heretical" splinter groups Last Wednesdayism and Last Fridayism. Another version, claiming not to be a parody, incorporates ideas from solipsism.

</doc>
<doc id="22702" url="http://en.wikipedia.org/wiki?curid=22702" title="Origen">
Origen

Origen (; Greek: Ὠριγένης, "Ōrigénēs"), or Origen Adamantius (Ὠριγένης Ἀδαμάντιος, "Ōrigénēs Adamántios"; 184/185 – 253/254), was a scholar and early Christian theologian who was born and spent the first half of his career in Alexandria. He was a prolific writer in multiple branches of theology, including textual criticism, biblical exegesis and hermeneutics, philosophical theology, preaching, and spirituality.
Unlike many church fathers, he was never canonized as a saint because some of his teachings directly contradicted the teachings attributed to the apostles, notably the Apostles Paul and John. His teachings on the pre-existence of souls, the final reconciliation of all creatures, including perhaps even the devil (the apokatastasis), and the subordination of the Son of God to God the Father, were extremely controversial.
Etymology.
Origen's Greek name "Ōrigénēs" (Ὠριγένης) probably means "child of Horus" (from Ὧρος, "Horus", and γένος, "born"). His nickname or cognomen "Adamantios" (Ἀδαμάντιος) derives from Greek "adámas" (ἀδάμας), which means "adamant", "unalterable", "unbreakable", "unconquerable", "diamond". He acquired it because of his severe ascetical practices.
Life.
Early years.
Origen was born in Alexandria to Christian parents. He was educated by his father, Leonides of Alexandria, who gave him a standard Hellenistic education, but also had him study the Christian scriptures. The name of his mother is unknown.
In 202, Origen's father was martyred in the outbreak of the persecution during the reign of Septimius Severus. A story reported by Eusebius has it that Origen wished to follow him in martyrdom, but was prevented only by his mother hiding his clothes. The death of Leonides left the family of nine impoverished when their property was confiscated. Origen, however, was taken under the protection of a woman of wealth and standing; but as her household already included a heretic named Paul, the strictly orthodox Origen seems to have remained with her only a short time.
Eusebius, our chief witness to Origen's life, says that in 203 Origen revived the Catechetical School of Alexandria where Clement of Alexandria had once taught but had apparently been driven out during the persecution under Severus. Many modern scholars, however, doubt that Clement's school had been an official ecclesiastical institution as Origen's was and thus deny continuity between the two. But the persecution still raged, and the young teacher visited imprisoned Christians, attended the courts, and comforted the condemned, himself preserved from persecution because the persecution was probably limited only to converts to Christianity. His fame and the number of his pupils increased rapidly, so that Bishop Demetrius of Alexandria, made him restrict himself to instruction in Christian doctrine alone.
Asceticism and castration.
Origen, to be entirely independent, sold his library for a sum which netted him a daily income of 4 obols, on which he lived by exercising the utmost frugality. Teaching throughout the day, he devoted the greater part of the night to the study of the Bible and lived a life of rigid asceticism.
Eusebius reported that Origen, following literally, castrated himself. This story was accepted during the Middle Ages and was cited by Peter Abelard in his letters to Heloise. Edward Gibbon, in his work "The History of the Decline and Fall of the Roman Empire", also accepts this story as true. During the past century, scholars have often questioned this, surmising that this may have been a rumor circulated by his detractors. Henry Chadwick points out that, while the story may be true, it seems unlikely, given that Origen's exposition of Matthew 19:12 "strongly deplored any literal interpretation of the words". However, many noted historians, such as Peter Brown and William Placher, continue to find no reason to deny the truth of Eusebius' claims.
Travels.
During the reign of emperor Caracalla, about 211–212, Origen paid a brief visit to Rome, but the relative laxity during the pontificate of Zephyrinus seems to have disillusioned him, and on his return to Alexandria he resumed his teaching with zeal increased by the contrast. But the school had far outgrown the strength of a single man; the catechumens pressed eagerly for elementary instruction, and the baptized sought for interpretation of the Bible. Under these circumstances, Origen entrusted the teaching of the catechumens to Heraclas, the brother of the martyr Plutarch, his first pupil.
His own interests became more and more centered in exegesis, and he accordingly studied Hebrew, though there is no certain knowledge concerning his instructor in that language. From about this period (212–213) dates Origen's acquaintance with Ambrose of Alexandria, whom he was instrumental in converting from Valentinianism to orthodoxy. Later (about 218) Ambrose, a man of wealth, made a formal agreement with Origen to promulgate his writings, and all the subsequent works of Origen (except his sermons, which were not expressly prepared for publication) were dedicated to Ambrose.
In 213 or 214, Origen visited Arabia at the request of the prefect, who wished to have an interview with him; and Origen accordingly spent a brief time in Petra, after which he returned to Alexandria. In the following year, a popular uprising at Alexandria caused Caracalla to let his soldiers plunder the city, shut the schools, and expel all foreigners. The latter measure caused Ambrose to take refuge in Caesarea, where he seems to have made his permanent home; and Origen left Egypt, apparently going with Ambrose to Caesarea, where he spent some time. Here, in conformity with local usage based on Jewish custom, Origen, though not ordained, preached and interpreted the scriptures at the request of the bishops Alexander of Jerusalem and Theoctistus of Caesarea. When, however, the confusion in Alexandria subsided, Demetrius recalled Origen, probably in 216.
Of Origen's activity during the next decade little is known, but it was probably devoted to teaching and writing. The latter was rendered the more easy for him by Ambrose, who provided him with more than seven stenographers to take dictation in relays, as many scribes to prepare long-hand copies, and a number of girls to multiply the copies. At the request of Ambrose, he now began a huge commentary on the "Bible", beginning with John, and continuing with Genesis, Psalms 1–25, and Lamentations, besides brief exegeses of selected texts (forming the ten books of his "Stromateis"), two books on the resurrection, and the work "On First Principles".
Conflict with Demetrius and removal to Caesarea.
Demetrius, the bishop of Alexandria, at first supported Origen but later opposed him, disputing his ordination in another diocese (Caesarea Maritima in Palestine). This ecclesiastical turmoil eventually caused Origen to move to Caesarea, a move which he characterized as divine deliverance from Egypt akin to that the ancient Hebrews received. About 230, Origen entered on the fateful journey which was to compel him to give up his work at Alexandria and embittered the next years of his life. Sent to Greece on some ecclesiastical mission, he paid a visit to Caesarea, where he was heartily welcomed and was ordained a priest, that no further cause for criticism might be given Demetrius, who had strongly disapproved his preaching before ordination while at Caesarea. But Demetrius, taking this well-meant act as an infringement of his rights, was furious, for not only was Origen under his jurisdiction as bishop of Alexandria, but, if Eastern sources may be believed, Demetrius had been the first to introduce episcopal ordination in Egypt. The metropolitan accordingly convened a synod of bishops and presbyters which banished Origen from Alexandria, while a second synod declared his ordination invalid.
Origen accordingly fled from Alexandria in 231–2, and made his permanent home in Caesarea in Palestine, where his friend Theoctistus was bishop. A series of attacks on him seems to have emanated from Alexandria, whether for his self-castration (a capital crime in Roman law) or for alleged heterodoxy is unknown; but at all events these fulminations were heeded only at Rome, while Palestine, Phoenicia, Arabia, and Achaia paid no attention to them. At Alexandria, Heraclas became head of Origen's school, and shortly afterward, on the death of Demetrius, was consecrated bishop.
During this time at Caesarea in Palestine (232–5), he resumed work on the "Commentary on John", composing at least books 6-10, wrote the treatise "On Prayer", and, some time in the first half of the year 235, composed his "Exhortation to Martyrdom". Approximately three years after his arrival in Caesarea in Palestine, Origen's life as a scholar was again interrupted by the persecution of Maximinus Thrax (AD235-8). He took refuge at Caesarea in Cappadocia. At Caesarea, Origen was joyfully received, was the guest of Firmilian, bishop of Caesarea in Cappadocia, and perhaps also of the empress-dowager Julia Avita Mamaea.
After the death of Maximinus, Origen resumed his life in Caesarea of Palestine. Little is known of the last twenty years of Origen's life. He founded a school where Gregory Thaumaturgus, later bishop of Pontus, was one of the pupils. He preached regularly on Wednesdays and Fridays, and later daily. He taught dialectics, physics, ethics, and metaphysics. He evidently, however, developed an extraordinary literary productivity, broken by occasional journeys; one of which, to Athens during some unknown year, was of sufficient length to allow him time for research.
After his return from Athens, he succeeded in converting Beryllus, bishop of Bostra, from his adoptionistic (i.e., belief that Jesus was born human and only became divine after his baptism) views to the orthodox faith; yet in these very years (about 240) probably occurred the attacks on Origen's own orthodoxy which compelled him to defend himself in writing to Pope Fabian and many bishops. Neither the source nor the object of these attacks is known, though the latter may have been connected with Novatianism (a strict refusal to accept Christians who had denied their faith under persecution).
After his conversion of Beryllus, however, his aid was frequently invoked against heresies. Thus, when the doctrine was promulgated in Arabia that the soul died and decayed with the body, being restored to life only at the resurrection (see soul sleep), appeal was made to Origen, who journeyed to Arabia, and successfully battled this doctrine.
There was second outbreak of the Antonine Plague, which at its height in 251 to 266 took the lives of 5,000 a day in Rome. This time it was called the Plague of Cyprian. Emperor Decius, believing the plague to be a product of magic, caused by the failure of Christians to recognize him as Divine, began Christian persecutions. This time Origen did not escape the Decian persecution. Eusebius recounted how Origen suffered "bodily tortures and torments under the iron collar and in the dungeon; and how for many days with his feet stretched four spaces in the stocks" Though he did not die while being tortured, he died three years later due to injuries sustained at the age of 69. A later legend, recounted by Jerome and numerous itineraries, places his death and burial at Tyre, but to this little value can be attached.
Works.
Origen excelled in multiple branches of theological scholarship. For instance, he was the greatest textual critic of the early Church, directing the production of the massive "Hexapla" ("Sixfold"), an Old Testament in six columns: Hebrew, Hebrew in Greek characters, the Septuagint, and the Greek versions of Theodotion, Aquila of Sinope, and Symmachus. He was one of the greatest biblical scholars of the early Church, having written commentaries on most of the books of the Bible, though few are extant. He interpreted scripture both literally and allegorically. Origen was largely responsible for the collection of usage information regarding the texts which became the New Testament. The information used to create the late-fourth-century Easter Letter, which declared accepted Christian writings, was probably based on the "Ecclesiastical History" [HE] of Eusebius of Caesarea, wherein he uses the information passed on to him by Origen to create both his list at HE 3:25 and Origen’s list at HE 6:25. Eusebius got his information about what texts were accepted by the third-century churches throughout the known world, a great deal of which Origen knew of firsthand from his extensive travels, from the library and writings of Origen. In fact, Origen would have possibly included in his list of "inspired writings" other texts which were kept out by the likes of Eusebius, including the Epistle of Barnabas, Shepherd of Hermas, and 1 Clement. "Origen is not the originator of the idea of biblical canon, but he certainly gives the philosophical and literary-interpretative underpinnings for the whole notion." As a theologian, in "De principiis" ("On First Principles"), he articulated one of the first philosophical expositions of Christian doctrine. Having been educated in classical and philosophical studies, some of his teachings were influenced by and engaged with aspects of Neo-Pythagorean, Neo-Platonist, and other strains of contemporary philosophical thought. An ordained priest in Palestine, he has left posterity numerous homilies on various books of the Bible. Finally, he has also been regarded as a spiritual master for such works as "An Exhortation to Martyrdom" and "On Prayer".
In 2012, 29 unpublished homilies by Origen were discovered in the Bavarian State Library. This text can be found online.
Exegetical writings.
According to Epiphanius, Origen wrote about 6,000 works ("i.e.", rolls or chapters). A list was given by Eusebius in his lost "Life of Pamphilus", which was apparently known to Jerome. These fall into four classes: textual criticism; exegesis; systematic, practical, and apologetic theology; and letters; besides certain spurious works.
By far the most important work of Origen on textual criticism was the "Hexapla", a comparative study of various translations of the Old Testament.
The full text of the "Hexapla" is no longer extant. Some portions were discovered in Milan indicating that at least some individual parts existed much longer than was previously thought. The "Hexapla" has been referred to by later manuscripts and authors, and represented the precursor to the parallel bible.
The "Tetrapla" was an abbreviation of the "Hexapla" in which Origen placed only the translations (Aquila, Symmachus, Theodotion, and the Septuagint) in parallels.
He was likewise keenly conscious of the textual difficulties in the manuscripts of the New Testament, although he never wrote definitely on this subject. In his exegetical writings he frequently alludes to the variant readings, but his habit of making rough citations in his dictation, the verification being left to the scribes, renders it impossible to deduce his text from his commentaries.
The exegetical writings of Origen fall into three classes:
Jerome states that there were scholia on Leviticus, Psalms i.-xv., Ecclesiastes, Isaiah, and part of John. The "Stromateis" were of a similar character, and the margin of "Codex Athous Laura", 184, contains citations from this work on Rom. 9:23; I Cor. 6:14, 7:31, 34, 9:20-21, 10:9, besides a few other fragments.
Homilies on almost the entire Bible were prepared by Origen. There are 205, and possibly 279, homilies of Origen that are extant either in Greek or in Latin translations. The homilies preserved are on Genesis (16), Exodus (13), Leviticus (16), Numbers (28), Joshua (26), Judges (9), I Sam. (2), Psalms 36-38 (9), Canticles (2), Isaiah (9), Jeremiah (7 Greek, 2 Latin, 12 Greek and Latin), Ezekiel (14), and Luke (39). The homilies were preached in the church at Caesarea, with the exception of the two on 1 Samuel which were delivered in Jerusalem. Nautin has argued that they were all preached in a three-year liturgical cycle some time between 238 and 244, preceding the "Commentary on the Song of Songs", where Origen refers to homilies on Judges, Exodus, Numbers, and a work on Leviticus.
It is not improbable that Origen gave no attention to supervising the publication of his homilies, for only by such a hypothesis can the numerous evidences of carelessness in diction be explained. The exegesis of the homilies was simpler than that of the scientific commentaries, but nevertheless demanded no mean degree of intelligence from the auditor. Origen's chief aim was the practical exposition of the text, verse by verse; and while in such books as Leviticus and Numbers he sought to allegorize, the wealth of material in the prophets seldom rendered it necessary for him to seek meanings deeper than the surface afforded.
On June 11, 2012, the Bavarian National Library announced the discovery by philologist Marina Molin Pradel of unknown original texts of homilies by Origenes in a twelfth-century Greek manuscript. The attribution to Origen has been confirmed by experts like Prof. Lorenzo Perrone of the Bologna University.
Extant commentaries of Origen.
The object of Origen's commentaries was to give an exegesis that discriminated strictly against historical significance, in favour of a "hidden" spiritual truth. At the same time, he neglected neither philological nor geographical, historical nor antiquarian material, to all of which he devoted numerous excursus.
In his commentary on John he constantly considered the exegesis of the Valentinian Heracleon (probably at the insistence of Ambrose), and in many other places he implied or expressly cited Gnostic views and refuted them.
Unfortunately, only meagre fragments of the commentaries have survived. Three commentaries on New Testament books survive in large measure. Of the 32 books in the "Commentary on John", only nine have been preserved. The "Commentary on Romans" is extant only in the abbreviated Latin translation of Rufinus, though some Greek fragments also exist. The eight books preserved of the "Commentary on Matthew" (Books 10-17) cover Matthew 13.36-22.33. There also exists a Latin translation of the commentary by an unknown translator which covers Matthew 16.13-27.66 One commentary on a book of the Old Testament, the "Commentary on the Song of Songs", has also been preserved in part, in a Latin translation of Rufinus.
Fragments of some other commentaries survive. Citations in Origen's Philocalia include fragments of the third book of the commentary on Genesis. There is also Ps. i, iv.1, the small commentary on Canticles, and the second book of the large commentary on the same, the twentieth book of the commentary on Ezekiel, and the commentary on Hosea. Of the non-extant commentaries, there is limited evidence of their arrangement.
Dogmatic, practical, and apologetic writings.
Study of "On First Principles" has occupied centre stage in studies of Origen since the fourth century. It is perhaps written for his more advanced pupils at Alexandria and probably composed between 212 and 215. It is extant only in the free translation of Rufinus of 397, except for fragments (books 3.1 and 4.1-3) preserved in "Origen's Philocalia", and smaller citations in Justinian's letter to Mennas.
In the first book the author considers God, the Logos, the Holy Ghost, reason, and the angels; in the second the world and man (including the incarnation of the Logos, the soul, free will, and eschatology); in the third, the doctrine of sin and redemption; and in the fourth, the scriptures; the whole being concluded with a résumé of the entire system. The work is noteworthy as the first endeavor to present Christianity as a complete theory of the universe, and was designed to remove the difficulties felt by many Christians concerning the essential basis of their faith.
Between 232-235, while in Caesarea in Palestine, Origen wrote "On Prayer". This is preserved entire in Greek. After an introduction on the object, necessity, and advantage of prayer, ends with an exegesis of the Lord's Prayer, concluding with remarks on the position, place, and attitude to be assumed during prayer, as well as on the classes of prayer.
"On Martyrdom", or the "Exhortation to Martyrdom", also preserved entire in Greek, was written some time after the beginning of the persecution of Maximinus in the first half of 235. In it, Origen warns against any trifling with idolatry and emphasizes the duty of suffering martyrdom manfully; while in the second part he explains the meaning of martyrdom.
"Against Celsus" (Greek: Κατὰ Κέλσου; Latin: "Contra Celsum"), preserved entire in Greek, was Origen's last treatise, written about 248. Ambrose had requested that Origen provide an answer to a book entitled "The True Doctrine" which attacked Christianity, and had been written some time in the second century by an unknown Middle Platonic philosopher named Celsus. In "Against Celsus", Origen drew freely on the Greek philosophers and poets as well as the Bible to provide a rational basis for holding the Christian faith.
The papyri discovered at Tura in 1941 contained the Greek text of two previously unknown works of Origen. Neither work can be dated precisely, though both were probably written after the persecution of Maximinus in 235. One is "On the Pascha". The other is "Dialogue of Origen with Heraclides and the Bishops with him concerning the Father and the Son and the soul".
Lost works include two books on the resurrection, written before "On First Principles", and also two dialogues on the same theme dedicated to Ambrose.
Eusebius had a collection of more than one hundred letters of Origen, and the list of Jerome speaks of several books of his epistles. Except for a few fragments, only three letters have been preserved. The first, partly preserved in the Latin translation of Rufinus, is addressed to friends in Alexandria. The second is a short letter to Gregory Thaumaturgus, preserved in the "Philocalia". The third is an epistle to Sextus Julius Africanus, extant in Greek, replying to a letter from Africanus (also extant), and defending the authenticity of the Greek additions to the book of Daniel.
Forgeries of the writings of Origen made in his lifetime are discussed by Rufinus in "De adulteratione librorum Origenis". The "Dialogus de recta in Deum fide", the "Philosophumena" of Hippolytus of Rome, and the "Commentary on Job" by Julian of Halicarnassus have also been ascribed to him.
Views.
Philosophical and religious.
Origen, reportedly trained in the school of Clement and by his father, has long been considered essentially a Platonist with occasional traces of Stoic philosophy. Patristic scholar Mark J Edwards has argued that many of Origen's positions are more properly Aristotelian than strictly Platonic (for instance, his philosophical anthropology). Nonetheless, he was thus a pronounced idealist, as one regarding all things temporal and material as insignificant and indifferent, the only real and eternal things being comprised in the idea. He therefore regards as the purely ideal center of this spiritual and eternal world, God, the pure reason, whose creative powers call into being the world with matter as the necessary substratum.
Origen's cosmology is complicated and controverted, but he seems to have held to a hypothesis of the preexistence of souls. Before the known world was created by God, he created a great number of spiritual intelligences. At first devoted to the contemplation and love of their creator, almost all of these intelligences eventually grew bored of contemplating God, and their love for him cooled off. Those whose love for God diminished the most became demons. Those whose love diminished moderately became human souls, eventually to be incarnated in fleshly bodies. Those whose love diminished the least became angels. One, however, who remained perfectly devoted to God became, through love, one with the Word (Logos) of God. The Logos eventually took flesh and was born of the Virgin Mary, becoming the God-man Jesus Christ. The diverse conditions in which human beings are born is actually dependent upon what their souls did in this pre-existent state. Thus what seems unfair, some being born poor and others wealthy, some sick and others healthy, and so forth, is, Origen insists, actually in a by-product of the free-will of souls. Thus, material creation is at least implicitly of a lesser ontological category than the immaterial, or spiritual, and the heavy material bodies that man assumes after the fall will eventually be cast off. Origen, however, still insisted on a bodily resurrection, but in contrast to Athenagoras, who believed that earthly bodies would be precisely reconstituted in the hereafter, Origen argued that Paul's notion of a flourishing spiritual body is more appropriate.
He was a rigid adherent of scripture, making no statement without adducing some scriptural basis. To him the scriptures were divinely inspired, as was proved both by the fulfillment of prophecy and by the immediate impression which the scriptures made on those who read them. Since the divine Logos spoke in the scriptures, they were an organic whole and on every occasion he combatted the Gnostic tenet of the inferiority of the Old Testament.
In his exegesis, Origen sought to discover the deeper meaning implied in the scriptures. One of his chief methods was the translation of proper names, which enabled him, like Philo, to find a deep meaning even in every event of history (see hermeneutics), but at the same time he insisted on an exact grammatical interpretation of the text as the basis of all exegesis.
A strict adherent of the Church, Origen yet distinguished sharply between the ideal and the empirical Church, representing "a double church of men and angels", or, in Platonic phraseology, the lower church and its celestial ideal. The ideal Church alone was the Church of Christ, scattered over all the earth; the other provided also a shelter for sinners. Holding that the Church, as being in possession of the mysteries, affords the only means of salvation, he was indifferent to her external organization, although he spoke sometimes of the office-bearers as the pillars of the Church, and of their heavy duties and responsibilities.
More important to him was the idea borrowed from Plato of the grand division between the great human multitude, capable of sensual vision only, and those who know how to comprehend the hidden meaning of scripture and the diverse mysteries, church organization being for the former only.
It is doubtful whether Origen possessed an obligatory creed; at any rate, such a confession of faith was not a norm like the inspired word of scripture. The reason, illumined by the divine Logos, which is able to search the secret depths of the divine nature, remains as the only source of knowledge.
Theological and dogmatic.
Origen's conception of God the Father is apophatic—a perfect unity, invisible and incorporeal, transcending all things material, and therefore inconceivable and incomprehensible. He is likewise unchangeable, and transcends space and time. But his power is limited by his goodness, justice, and wisdom; and, though entirely free from necessity, his goodness and omnipotence constrained him to reveal himself.
This revelation, the external self-emanation of God, is expressed by Origen in various ways, the Logos being only one of many. Revelation was the first creation of God (cf. Prov. viii. 22), in order to afford creative mediation between God and the world, such mediation being necessary, because God, as changeless unity, could not be the source of a multitudinous creation.
The Logos is the rational creative principle that permeates the universe. Since God eternally manifests himself, the Logos is likewise eternal. He forms a bridge between the created and uncreated, and only through him, as the visible representative of divine wisdom, can the inconceivable and incorporeal God be known. Creation came into existence only through the Logos, and God's nearest approach to the world is the command to create. While the Logos is substantially a unity, he comprehends a multiplicity of concepts, so that Origen terms him, in Platonic fashion, "essence of essences" and "idea of ideas".
The defense of the unity of God against the Gnostics led Origen to maintain the subordination of the Logos to God, and the doctrine of the eternal generation is later. Origen distinctly emphasized the independence of the Logos as well as the distinction from the being and substance of God. The term "of the same substance with the Father" was not employed. The Logos (and the Holy Spirit also) however, does share in the divinity of God. He is an image, a reflex of God, in which God communicates his divinity, as light radiating from the sun.
The Logos doctrine and cosmology.
The activity of the Logos was conceived by Origen in Platonic fashion, as the world soul, wherein God manifested his omnipotence. His first creative act was the divine spirit, as an independent existence; and partial reflexes of the Logos were the created rational beings, who, as they had to revert to the perfect God as their background, must likewise be perfect; yet their perfection, unlike in kind with that of God, the Logos, and the divine spirit, had to be attained. The freedom of the will is an essential fact of the reason, notwithstanding the foreknowledge of God. The Logos, eternally creative, forms an endless series of finite, comprehensible worlds, which are mutually alternative. Combining the Stoic doctrine of a universe without beginning with the biblical doctrine of the beginning and the end of the world, he conceived of the visible world as the stages of an eternal cosmic process, affording also an explanation of the diversity of human fortunes, rewards, and punishments. The material world, which at first had no place in this eternal spiritual progression, was due to the fall of the spirits from God, the first being the serpent, who was imprisoned in matter and body. The ultimate aim of God in the creation of matter out of nothing was not punishment, but the upraising of the fallen spirits. Man's accidental being is rooted in transitory matter, but his higher nature is formed in the image of the Creator. The soul is divided into the rational and the irrational, the latter being material and transitory, while the former, incorporeal and immaterial, possesses freedom of the will and the power to reascend to purer life. The strong ethical import of this cosmic process can not remain unnoticed. The return to original being through divine reason is the object of the entire cosmic process. Through the worlds which follow each other in eternal succession, the spirits are able to return to Paradise. God so ordered the universe that all individual acts work together toward one cosmic end which culminates in himself. Likewise as to Origen's anthropology, man conceived in the image of God is able by imitating God in good works to become like God, if he first recognizes his own weakness and trusts all to the divine goodness. He is aided by guardian angels, but more especially by the Logos who operates through saints and prophets in proportion to the constitution of these and man's capacity.
Christology.
The culmination of this gradual revelation is the universal revelation of Christ. In Christ, God, hitherto manifest only as the Lord, appeared as the Father. The incarnation of the Logos, moreover, was necessary since otherwise he would not be intelligible to sensual man; but the indwelling of the Logos remained a mystery, which could be represented only by the analogy of his indwelling in the saints; nor could Origen fully explain it. He speaks of a "remarkable body", and in his opinion that the mortal body of Jesus was transformed by God into an ethereal and divine body, Origen approximated the Docetism that he otherwise abhorred. His concept of the soul of Jesus is likewise uncertain and wavering. He proposes the question whether it was not originally perfect with God but, emanating from him, at his command assumed a material body. As he conceived matter as merely the universal limit of created spirits, so would it be impossible to state in what form the two were combined. He dismissed the solution by referring it to the mystery of the divine governance of the universe. More logically did he declare the material nature of the world to be merely an episode in the spiritual process of development, whose end should be the annihilation of all matter and return to God, who should again be all in all. The doctrine of the resurrection of the body he upholds by the explanation that the Logos maintains the unity of man's existence by ever changing his body into new forms, thus preserving the unity and identity of personality in harmony with the tenet of an endless cosmic process. Origen's concept of the Logos allowed him to make no definite statement on the redemptive work of Jesus. Since sin was ultimately only negative as a lack of pure knowledge, the activity of Jesus was essentially example and instruction, and his human life was only incidental as contrasted with the immanent cosmic activity of the Logos. Origen regarded the death of Jesus as a sacrifice, paralleling it with other cases of self-sacrifice for the general good. On this, Origen's accord with the teachings of the Church was merely superficial.
Eschatology.
His idealizing tendency to consider the spiritual alone as real, fundamental to his entire system, led him to combat the "rude" or "crude" Chiliasm (see Christian eschatology) of a sensual beyond. His position on the literal resurrection of physical bodies is difficult, but in both the "Contra Celsum" and "On First Principles", Origen affirms some form of bodily resurrection, but eschews the notion that earthly bodies will be raised, on account of their gross materiality. Origen believes that all spirits will be finally rescued and glorified, each in the form of its individual life, in order to serve a new epoch of the world when sensuous matter disappears of itself. Yet he constrained himself from breaking entirely with the distinct celestial hopes and representations of Paradise prevalent in the Church. He represents a progressive purification of souls, until, cleansed of all clouds of evil, they should know the truth and God as the Son knew him, see God face to face, and attain a full possession of the Holy Spirit and union with God. The means of attainment of this end were described by Origen in different ways, the most important of which was his concept of a purifying fire which should cleanse the world of evil and thus lead to cosmic renovation. By a further spiritualization Origen could call God himself this consuming fire. In proportion as the souls were freed from sin and ignorance, the material world was to pass away, until, after endless eons, at the final end, God should be all in all, and the worlds and spirits should return to a knowledge of God; in Greek this is called Apokatastasis.
Character.
In Origen the Christian Church had its first theologian. His teaching was not merely theoretical, but was also imbued with an intense ethical power. To the multitude to whom his instruction was beyond grasp, he left mediating images and symbols, as well as the final goal of attainment. In Origen Christianity blended with the pagan philosophy in which lived the desire for truth and the longing after God. Origen had many admirers and followers, one in particular, Dionysius of Alexandria, who caused controversy throughout Libya in 259 due to his theology in regards to the unity of the trinity. Three centuries later his very name was stricken from the books of the Church; yet in the monasteries of the Greeks his influence still lived on, as the spiritual father of Greek monasticism.
Origen's influence on the later church.
Anathemas (544, 553).
While Patriarch Mennas of Constantinople condemned Origen and a form of apocatastasis at the Synod of Constantinople (543); experts are divided whether the Second Council of Constantinople (the Fifth Ecumenical Council) in 553 ratified the condemnation authentically as "It is [only] certain that the council opened on 5 May, 553, in spite of the protestations of Pope Vigilius, who though at Constantinople refused to attend it, and that in the eight conciliary sessions (from 5 May to 2 June), the Acts of which we possess, only the question of the Three Chapters is treated." Many heteroclite views became associated with Origen, and the 15 anathemas attributed to the council condemn a form of apocatastasis along with the pre-existence of the soul, animism (a heterodox Christology), and a denial of real and lasting resurrection of the body. Some authorities believe these anathemas belong to an earlier local synod. The anathema against Origen in his person, declaring him (among others) a heretic, reads as follows:
If anyone does not anathematize Arius, Eunomius, Macedonius, Apollinaris, Nestorius, Eutyches and Origen, as well as their impious writings, as also all other heretics already condemned and anathematized by the Holy Catholic and Apostolic Church, and by the aforesaid four Holy Synods and [if anyone does not equally anathematize] all those who have held and hold or who in their impiety persist in holding to the end the same opinion as those heretics just mentioned: let him be anathema.
As a result of this condemnation, the writings of Origen supporting his teachings in these areas were destroyed. They were either destroyed outright, or translated with the appropriate adjustments to eliminate conflict with orthodox Christian doctrine. Therefore, little direct evidence remains to fully confirm or disprove Origen's support of the nine points of anathema against him.
The Fifth Ecumenical Council addressed what was called "The Three Chapters" and opposed a form of Origenism which truly had nothing to do with Origen and Origenist views. In fact, Popes Vigilius (537–555), Pelagius I (556–61), Pelagius II (579–90), and Gregory the Great (590–604) were only aware that the Fifth Council specifically dealt with the Three Chapters and make no mention of Origenism or Universalism, nor spoke as if they knew of its condemnation - even though Gregory the Great opposed the belief of universalism.
The Emperor Justinian denied apocatastasis, making it the ninth of the ten doctrines in his edict against Origen in 545, and later that year, the doctrine was the fourteenth of the fifteen at the council in Constantinople that condemned Origen.
Origen in the 1970s.
In "Reincarnation in Christianity" (1978), theosophist Geddes MacGregor asserts that Origen believed in reincarnation and taught about it, but that his texts written about the subject have been destroyed.
Origen wrote about the Greeks' transmigration of the soul, with which he may or may not have agreed. Many theologians share the notion that Origen's extant works from Latin translations (not from the original Greek) confirm he did not believe in reincarnation. He was cognizant of the concept of transmigration ("metensomatosis" transformation, and loses what it once was, the human soul will not be what it was) from Greek philosophy, but it is repeatedly stated that this concept is not a part of the Christian teaching or scripture. A translation of his "Commentary on the Gospel of Matthew", which stems from a 6th-century Latin translation, reads: "In this place [when Jesus said Elijah was come and referred to John the Baptist] it does not appear to me that by Elijah the soul is spoken of, lest I fall into the doctrine of transmigration, which is foreign to the Church of God, and not handed down by the apostles, nor anywhere set forth in the scriptures" (ibid., 13:1:46–53). Conversely in Origen's "Against Celsus", he argues that the teaching of the resurrection does not come from the doctrine of reincarnation, yet contradictorily claims to know that the soul transmigrates from body to body:
Our teaching on the subject of the resurrection is not, as Celsus imagines, derived from anything that we have heard on the doctrine of metempsychosis; but we know that the soul, which is immaterial and invisible in its nature, exists in no material place, without having a body suited to the nature of that place. Accordingly, it at one time puts off one body which was necessary before, but which is no longer adequate in its changed state, and it exchanges it for a second; and at another time it assumes another in addition to the former, which is needed as a better covering, suited to the purer ethereal regions of heaven. When it comes into the world at birth, it casts off the integuments which it needed in the womb; and before doing this, it puts on another body suited for its life upon earth.
There is evidence that Origen's writing was mistranslated from Greek into Latin due to religious bias, and that he taught reincarnation in his lifetime. One of the epistles written by St. Jerome, "To Avitus" (Letter 124; "Ad Avitum", Epistula CXXIV), asserts that Origen's "On First Principles" (Greek: Περὶ Ἀρχῶν; Latin: "De Principiis") was mistranscribed from Greek into Latin:
 About ten years ago that saintly man Pammachius sent me a copy of a certain person's [ Rufinus's ] rendering, or rather misrendering, of Origen's "First Principles"; with a request that in a Latin version I should give the true sense of the Greek and should set down the writer's words for good or for evil without bias in either direction. When I did as he wished and sent him the book, he was shocked to read it and locked it up in his desk lest being circulated it might wound the souls of many.
St. Jerome writes about Origen in "To Avitus", conveying the impression that Origen was a heretic like Arius. Concerning Origen's "On First Principles", St. Jerome warns Avitus "that there are countless things in the book to be abhorred, and that, as the Lord says, you will have to walk among scorpions and serpents". Further, in "To Avitus" (Letter 124), St. Jerome writes about "convincing proof" that Origen teaches reincarnation in the original version of the book:
The following passage is a convincing proof that he [Origen] holds the transmigration of the souls and annihilation of bodies. "If it can be shown that an incorporeal and reasonable being has life in itself independently of the body and that it is worse off in the body than out of it; then beyond a doubt bodies are only of secondary importance and arise from time to time to meet the varying conditions of reasonable creatures. Those who require bodies are clothed with them, and contrariwise, when fallen souls have lifted themselves up to better things, their bodies are once more annihilated. They are thus ever vanishing and ever reappearing."
St. Jerome further elaborates Origen's ideas in "To Avitus":
Moreover, [Origen writes that] to avoid the agony of punishment and the burning flame the more sensitive may choose to become low organisms, to dwell in water, to assume the shape of this or that animal; so that we have reason to fear a metamorphosis not only into four-footed things but even into fishes. Then, lest he [Origen] should be held guilty of maintaining with Pythagoras the transmigration of souls, he winds up the wicked reasoning with which he has wounded his reader by saying: "I must not be taken to make dogmas of these things; they are only thrown out as conjectures to show that they are not altogether overlooked."
St. Jerome adds to this:
Hellfire, moreover, and the torments with which holy scripture threatens sinners he [Origen] explains not as external punishments but as the pangs of guilty consciences when by God's power the memory of our transgressions is set before our eyes. "The whole crop of our sins grows up afresh from seeds which remain in the soul, and all our dishonourable and undutiful acts are again pictured before our gaze. Thus it is the fire of conscience and the stings of remorse which torture the mind as it looks back on former self-indulgence." And again: "but perhaps this coarse and earthly body ought to be described as mist and darkness; for at the end of this world and when it becomes necessary to pass into another, the like darkness will lead to the like physical birth." In speaking thus he [Origen] clearly pleads for the transmigration of souls as taught by Pythagoras and Plato.
The original text of Origen's "On First Principles" (Greek: Περὶ Ἀρχῶν) has almost completely disappeared. It remains extant as "De Principiis" in fragments translated into Latin by St. Jerome reportedly in good faith, and in the more complete, though "not very reliable Latin translation of Rufinus".
Today.
Origen is regarded by the Roman Catholic Church as a Church Father, but not a Saint.
His thought on the Old Testament was an important link in the development of the medieval system of typology. 

</doc>
<doc id="22703" url="http://en.wikipedia.org/wiki?curid=22703" title="Oliver Hazard Perry-class frigate">
Oliver Hazard Perry-class frigate

The "Oliver Hazard Perry" class is a class of frigates named after the American Commodore Oliver Hazard Perry, the hero of the naval Battle of Lake Erie. Also known as the Perry or FFG-7 class, the warships were designed in the United States in the mid-1970s as general-purpose escort vessels inexpensive enough to be bought in large quantities to replace World War II-era destroyers and complement 1960s-era Knox class frigates. The FFG-7s were the low capability ships to provide numbers with the Spruance destroyers the high capability ships for 1970s construction, in Admiral Zumwalt's, high low fleet plan. Intended to protect amphibious landing forces, supply and replenishment groups, and merchant convoys from aircraft and submarines, they also later were part of battleship-centric surface action groups and aircraft carrier battle groups/strike groups. Fifty-five ships were built in the United States: 51 for the United States Navy and four for the Royal Australian Navy (RAN). In addition, eight were built in Taiwan, six in Spain, and two in Australia for their navies. Former U.S. Navy warships of this class have been sold or donated to the navies of Bahrain, Egypt, Poland, Pakistan, and Turkey.
The Navy built 51 of the Oliver Hazard Perry frigates, with the first going into service in 1977, and the last to be finally moth-balled, or transferred to other navies for continued service, in 2015. Some of the U.S. Navy's frigates, such as USS "Duncan" (14.6 years in service) had fairly short careers, while a few lasted as long as 30+ years in active U.S. service, and some lasting even longer after being sold or donated to other navies.
Design and construction.
The ships were designed by the Bath Iron Works shipyard in Maine in partnership with the New York-based naval architects Gibbs & Cox.
The "Oliver Hazard Perry"-class ships were produced in 445-foot (136 meter) long "short-hull" (Flight I) and 453-foot (138 meter) long "long-hull" (Flight III) variants. The long-hull ships (FFG 8, 28, 29, 32, 33, and 36-61) carry the larger SH-60 "Seahawk" LAMPS III helicopters, while the short-hulled warships carry the smaller and less-capable SH-2 "Seasprite" LAMPS I. Aside from the lengths of their hulls, the principal difference between the versions is the location of the aft capstan: on long-hull ships, it sits a step below the level of the flight deck in order to provide clearance for the tail rotor of the longer "Seahawk" helicopters. The long-hull ships also carry the RAST (Recovery Assist Securing and Traversing) system for the "Seahawk", a hook, cable, and winch system that can reel in a "Seahawk" from a hovering flight, expanding the ship's pitch-and-roll range in which flight operations are permitted. The FFG 8, 29, 32, and 33 were built as "short-hull" warships but were later modified into "long-hull" warships. Oliver Hazard Perry-class Frigates were the second class of surface ship (after the Spruance-class destroyers) in the US Navy to be built with gas turbine propulsion. The gas turbine propulsion plant was more automated than other Navy propulsion plants at the time and could be centrally monitored and controlled from a remote engineering control center away from the engines. The gas turbine propulsion plants also allowed the ship's speed to be controlled directly from the bridge via a throttle control, a first for the US Navy.
American shipyards constructed "Oliver Hazard Perry"-class ships for the U.S. Navy and the Royal Australian Navy (RAN). Early American-built Australian ships were originally built as the "short-hull" version, but they were modified during the 1980s to the "long-hull" design. Shipyards in Australia, Spain, and Taiwan have produced several warships of the "long-hull" design for their navies.
Although the per-ship costs rose greatly over the period of production, all 51 ships planned for the U.S. Navy were built. As of 2015, all of these ships have been either scrapped or transferred to the navies of other countries, including Bahrain, Egypt, Poland, Pakistan, and Turkey. Several of these have replaced old Second World War-built American destroyers that had been given to those countries.
During the design phase of the "Oliver Hazard Perry" class, head of the Royal Corps of Naval Constructors, R.J. Daniels, was invited by an old friend, US Chief of the Bureau of Ships, Adm Robert C Gooding, to advise upon the use of variable-pitch propellers in the class. During the course of this conversation, Daniels warned Gooding against the use of aluminium in the superstructure of the FFG-7 class as he believed it would lead to structural weaknesses. A number of ships subsequently developed structural cracks, including a 40 ft fissure in USS "Duncan", before the problems were remedied.
The "Oliver Hazard Perry"-class frigates were designed primarily as anti-aircraft and anti-submarine warfare guided-missile warships intended to provide open-ocean escort of amphibious warfare ships and merchant ship convoys in moderate threat environments in a potential war with the Soviet Union and the Warsaw Pact countries. They could also provide air defense against 1970s- and 1980s-era aircraft and anti-ship missiles. These warships are equipped to escort and protect aircraft carrier battle groups, amphibious landing groups, underway replenishment groups, and merchant ship convoys. They can conduct independent operations to perform such tasks as surveillance of illegal drug smugglers, maritime interception operations, and exercises with other nations.
The addition of the Naval Tactical Data System, LAMPS helicopters, and the Tactical Towed Array System (TACTAS) gave these warships a combat capability far beyond the original expectations. They are well-suited for the littoral regions and most war-at-sea scenarios.
Notable combat actions.
"Oliver Hazard Perry"-class frigates made worldwide news twice during the 1980s. Despite being small, these frigates were shown to be extremely durable. During the Iran–Iraq War, on 17 May 1987, the USS "Stark" was attacked by an Iraqi warplane. Struck by two Exocet anti-ship missiles, thirty-seven American sailors died in the deadly prelude to the American Operation Earnest Will, the reflagging and escorting of oil tankers through the Persian Gulf and the Straits of Hormuz. Less than a year later, on 14 April 1988, the "Samuel B. Roberts" was nearly sunk by an Iranian mine. No lives were lost, but 10 sailors were evacuated from the warship for medical treatment. The Roberts crew battled fire and flooding for 2 days, ultimately managing to save the ship. The U.S. Navy retaliated four days later with Operation Praying Mantis, a one-day attack on Iranian oil platforms being used as bases for raids on merchant shipping. Those had included bases for the minelaying operations that damaged the "Samuel B. Roberts". Both frigates were repaired in American shipyards and returned to full service. The USS "Stark" was decommissioned in 1999, and scrapped in 2006.
Modifications.
United States.
The U.S. Navy and Royal Australian Navy have modified their remaining "Perrys" to reduce their operating costs, replacing Detroit Diesel Company 16V149TI electrical generators with Caterpillar, Inc.- 3512B diesel engines.
In mid-2000, the U.S.Navy removed the frigates' Mk 13 single-arm missile launchers and magazines because the primary missile, the Standard SM-1MR, became outmoded.
The "zone-defense" anti-aircraft warfare (AAW) capability has vanished, and all that remains is a "point-defense" type of AAW armament. It would supposedly have been too costly to refit the Standard Missile SM-1MR missiles, which had little ability to bring down sea-skimming missiles. Another reason is to allow more SM-1MRs to go to American allies that operate "Perrys", such as Poland, Spain, Australia, Turkey, and Taiwan.
The loss of the launchers also strips the frigates of their Harpoon anti-ship missiles. However, their "Seahawk" helicopters can carry the much shorter-range Penguin and Hellfire anti-ship missiles.
The last nine ships of the class have new remotely operated 25-mm Mk 38 Mod 2 Naval Gun Systems installed on platforms over the old MK 13 launcher magazine.
As of 2002, the U.S. Navy had updated the remaining active "Oliver Hazard Perry"-class warships' Phalanx CIWS to the "Block 1B" capability, which allowed the Mk 15 20 mm Phalanx gun to shoot at fast-moving surface craft and helicopters. They were also to be fitted with the Mk 53 DLS "Nulka" missile decoy system, which will be better than the presently-equipped chaff (SRBOC, Super Rapid Blooming Offboard Chaff) and flares at guarding against anti-ship missiles. It had been planned to outfit the remaining ships with one 32-cell RIM-116 Rolling Airframe Missile launcher at the location of the former Mk-13, but this did not occur.
On June 16, 2009, Vice Admiral Barry McCullough turned down the suggestion of then-U.S. Senator Mel Martinez (R-FL) to keep the "Perrys" in service, citing their worn-out and maxed-out condition. However, U.S. Representative Ander Crenshaw (R-FL) and former U.S. Representative Gene Taylor (D-MS) took up the cause to retain the vessels.
The Perry-class frigates were to eventually be replaced by Littoral Combat Ships by 2019. However, the worn out frigates are being retired faster than the LCSs are being built, which may lead to a gap in United States Southern Command mission coverage. According to Navy deactivation plans, all "Oliver Hazard Perry"-class frigates will be retired by October 2015, leaving the U.S. Navy without a frigate class of ships in over 70 years. The "Kauffman" will be the last to be retired, scheduled for 21 September 2015, which will leave the Navy devoid of frigates for the first time since 1943. The ships will either be made available for sale to foreign navies or dismantled. Perry-class frigate retirement was accelerated by budget pressures, which will lead to the remaining 11 ships being replaced by only eight LCS hulls. With the timeline LCS mission packages will come online unknown, there is uncertainty if they will be able to perform the frigates' counter-narcotics and anti-submarine roles when they are gone. The Navy is looking into Military Sealift Command to see if the Joint High Speed Vessel, Mobile Landing Platform, and other auxiliary ships could handle low-end missions that the frigates performed.
The U.S. Coast Guard is harvesting weapons systems components from decommissioned Navy Perry-class frigates to save money. Harvesting components from four decommissioned frigates results in more than $24 million in cost savings, which increases with parts from more decommissioned frigates. Equipment including Mk 75, 76 mm/62 caliber gun mounts, gun control panels, barrels, launchers, junction boxes, and other components will be returned to service aboard Famous-class cutters to extend their service lives into the 2030s.
Australia.
Australia is spending A$1.46bn to upgrade Royal Australian Navy (RAN) "Adelaide"-class guided-missile frigates, including equipping them to fire the SM-2 version of the Standard missile, adding an eight-cell vertical launch system for Evolved Sea Sparrow missiles, and installing better air-search radars and long-range sonar.
The first of the upgraded frigates, HMAS "Sydney", returned to the RAN fleet in 2005. Each of the four frigates to be upgraded have the work at the Garden Island shipyard in Sydney, Australia, with the modernizations lasting between 18 months and two years. These frigates are planned to be replaced starting in 2013 by three new "Hobart"-class air warfare destroyers equipped with the AEGIS combat system. However, the third of those destroyers will not be commissioned until 2017, at the earliest.
The cost will be partly offset, in the short run, by the decommissioning and disposal of the two older frigates. HMAS "Canberra" was decommissioned on 12 November 2005 at naval base in Western Australia and HMAS "Adelaide" was decommissioned at that same naval base on 20 January 2008.
Turkey.
The Turkish Navy had commenced the modernization of its G class frigates with the GENESIS (Gemi Entegre Savaş İdare Sistemi) combat management system in 2007. The first GENESIS upgraded ship was delivered in 2007, and the last delivery is scheduled for 2011. The "short-hull" "Oliver Hazard Perry"-class frigates that are currently part of the Turkish Navy were modified with the ASIST landing platform system at the Gölcük Naval Shipyard, so that they can accommodate the S-70B "Seahawk" helicopters. Turkey is planning to add one eight-cell Mk 41 Vertical Launching Systems (VLS) for the Evolved Sea Sparrow missile, to be installed forward of the present Mk 13 missile launchers, similar to the case in the modernization program of the Australian Adelaide class frigates. F-495 TCG "Gediz" was the first ship in the class to receive the Mk 41 VLS installation.
There are also plans for new components to be installed that are being developed for the Milgem class warships ("Ada class" corvettes and "F-100 class" frigates) of the Turkish Navy. These include modern Three-dimensional and X-band radars developed by Aselsan and Turkish-made hull-mounted sonars. One of the G class frigates will also be used as a test-bed for Turkey's 6,000+ ton TF-2000 class anti-aircraft warfare (AAW) frigates that are currently being designed by the Turkish Naval Institute.
Former operator.
On May 11, 2009, the first International Frigate Working Group met in Mayport Naval Station to discuss maintenance, obsolescence and logistics issues regarding Oliver Hazard Perry-class ships of the U.S. and foreign navies.
Related legislation.
On April 7, 2014, the United States House of Representatives voted to pass the Taiwan Relations Act Affirmation and Naval Vessel Transfer Act of 2014 (H.R. 3470; 113th Congress), a bill that would allow eight more "Perry" frigates to be transferred to foreign countries. The bill would authorize the President to transfer "Curts" and "McClusky" to Mexico, and "Rentz" and "Vandegrift" to Thailand. The bill would also authorize the President to sell four units ("Taylor", "Gary", "Carr", and "Elrod") to the Taipei Economic and Cultural Representative Office of the United States (which is the Taiwan instrumentality designated pursuant to the Taiwan Relations Act) for about $10 million each.

</doc>
<doc id="22705" url="http://en.wikipedia.org/wiki?curid=22705" title="Ottawa Senators">
Ottawa Senators

The Ottawa Senators (French: "Sénateurs d'Ottawa") are a professional ice hockey team based in Ottawa, Ontario, Canada. They are members of the Atlantic Division of the Eastern Conference of the National Hockey League (NHL). The Senators play their home games at the 19,153 seat (20,500 capacity) Canadian Tire Centre which opened in 1996.
Founded and established by Ottawa real estate developer Bruce Firestone, the team is the second NHL franchise to use the Ottawa Senators name. The original Ottawa Senators, founded in 1883, had a famed history, winning 11 Stanley Cups and playing in the NHL from 1917 until 1934. On December 6, 1990, after a two-year public campaign by Firestone, the NHL awarded a new franchise, which began play in the 1992–93 season. The current team owner is Eugene Melnyk, and in 2012, the club was valued by "Forbes" magazine at $220 million.
The team has had success, qualifying for the Stanley Cup playoffs in 15 of the past 18 seasons, winning four division titles, the Presidents' Trophy in 2003 and appearing in the 2007 Stanley Cup Finals. The success has been reflected in attendance and has been in the top half in attendance in the NHL.
History.
Ottawa had been home to the original Senators, a founding NHL franchise and 11-time Stanley Cup champions. After the NHL expanded to the United States in the late 1920s, the original Senators' eventual financial losses forced the franchise to move to St. Louis in 1934 operating as the Eagles while a Senators senior amateur team took over the Senators' place in Ottawa. The NHL team was unsuccessful in St. Louis, and planned to return to Ottawa, but the NHL decided instead to suspend the franchise and transfer the players to other NHL teams.
Fifty-four years later, after the NHL announced plans to expand, Ottawa real estate developer Bruce Firestone decided along with colleagues Cyril Leeder and Randy Sexton that Ottawa was now able to support an NHL franchise, and the group proceeded to put a bid together. His firm, Terrace Investments, did not have the liquid assets to finance the expansion fee and the team, but the group conceived a strategy to leverage a land development. In 1989, after finding a suitable site on farmland just west of Ottawa in Kanata on which to construct a new arena, Terrace announced its intention to win a franchise and launched a successful "Bring Back the Senators" campaign to both woo the public and persuade the NHL that the city could support an NHL franchise. Public support was high and the group would secure over 11,000 season ticket pledges. On December 12, 1990, the NHL approved a new franchise for Firestone's group, to start play in the 1992–93 season.
1992–96: First seasons.
The new team hired former NHL player Mel Bridgman, who had no previous NHL management experience, as its first general manager in 1992. The team was initially interested in hiring former Jack Adams Award winner Brian Sutter as its first head coach, but Sutter came with a high price tag and was reluctant to be a part of an expansion team. When Sutter was eventually signed to coach the Boston Bruins, Ottawa signed Rick Bowness, the man Sutter replaced in Boston. The new Senators played their first game on October 8, 1992, in the Ottawa Civic Centre against the Montreal Canadiens with lots of pre-game spectacle. The Senators defeated the Canadiens 5–3 in one of the few highlights that season. Following the initial excitement of the opening night victory, the club floundered badly and eventually tied the San Jose Sharks for the worst record in the league, winning only 10 games with 70 losses and four ties for 24 points, three points better than the NHL record for futility. The Senators had aimed low and considered the 1992–93 season a small success, as Firestone had set a goal for the season of not setting a new NHL record for fewest points in a season. The long term plan was to finish low in the standings for its first few years in order to secure high draft picks and eventually contend for the Stanley Cup.
Bridgman was fired after one season and Team President Randy Sexton took over the general manager duties. Firestone himself soon left the team and Rod Bryden emerged as the new owner. The strategy of aiming low and securing a high draft position did not change. The Senators finished last overall for the next three seasons. Although 1993 first overall draft choice Alexandre Daigle wound up being one of the greatest draft busts in NHL history, they chose Radek Bonk in 1994, Bryan Berard (traded for Wade Redden) in 1995, Chris Phillips in 1996 and Marian Hossa in 1997, all of whom would become solid NHL players and formed a strong core of players in years to come. Alexei Yashin, the team's first-ever draft selection from 1992, emerged as one of the NHL's brightest young stars. The team traded many of their better veteran players of the era, including 1992–93 leading scorer Norm Maciver and fan favourites Mike Peluso and Bob Kudelski in an effort to stockpile prospects and draft picks.
As the 1995–96 season began, star centre Alexei Yashin refused to honour his contract and did not play. In December, after three straight last-place finishes and a team which was ridiculed throughout the league, fans began to grow restless waiting for the team's long term plan to yield results, and arena attendance began to decline. Rick Bowness was fired in late 1995 and was replaced by the Prince Edward Island Senators' head coach Dave Allison. Allison would fare no better than his predecessor, and the team would stumble to a 2–22–3 record under him. Sexton himself was fired and replaced by Pierre Gauthier, the former assistant GM of Anaheim. Before the end of January 1996, Gauthier had resolved the team's most pressing issues by settling star player Alexei Yashin's contract dispute, and hiring the highly regarded Jacques Martin as head coach. While Ottawa finished last overall once again, the 1995–96 season ended with renewed optimism, due in part to the upgraded management and coaching, and also to the emergence of an unheralded rookie from Sweden named Daniel Alfredsson, who would win the Calder Memorial Trophy as NHL Rookie of the Year in 1996.
1996–2004: Jacques Martin era.
Martin would impose a "strong defence first" philosophy that led to the team qualifying for the playoffs every season that he coached, but he was criticized for the team's lack of success in the playoffs, notably losing four straight series against the provincial rival Toronto Maple Leafs. Martin outlasted several general managers and a change in ownership.
In 1996–97, his first season, the club qualified for the playoffs in the last game of the season, and nearly defeated the Buffalo Sabres in the first round. In 1997–98, the club finished with their first winning record and upset the heavily favoured New Jersey Devils to win their first playoff series. In 1998–99, the Senators jumped from fourteenth overall in the previous season to third, with 103 points—the first 100-point season in club history, only to be swept in the first round. In 1999–2000 despite the holdout of team captain Alexei Yashin, Martin guided the team to the playoffs, only to lose to the Maple Leafs in the first Battle of Ontario series. Yashin returned for 2000–01 and the team improved to win their division and place second in the Eastern Conference. Yashin played poorly in another first round playoff loss and on the day of the 2001 NHL Entry Draft, he was traded to the New York Islanders in exchange for Zdeno Chara, Bill Muckalt and the second overall selection in the draft, which Ottawa used to select centre Jason Spezza.
The 2001–02 Senators regular season points total dropped, but in the playoffs, they upset the Philadelphia Flyers for the franchise's second playoff series win. Yet the Sens would lose in game seven of the second round of the playoffs. Despite speculation that Martin would be fired, it was GM Marshall Johnston who left, retiring from the team, replaced by John Muckler, the Senators' first with previous GM experience.
In 2002–03 off-ice problems dominated the headlines, as the Senators filed for bankruptcy in mid-season, but continued play after getting emergency financing. Despite the off-ice problems, Ottawa had an outstanding season, placing first overall in the NHL to win the Presidents' Trophy. In the playoffs, they came within one game of making it into the finals. Prior to the 2003–04 season, pharmaceutical billionaire Eugene Melnyk would purchase the club to bring financial stability. Martin would guide the team to another good regular season but again would lose in the first round of the playoffs, leading to Martin's dismissal as management felt that a new coach was required for playoff success.
2004–present: Bryan Murray era.
After the playoff loss, owner Melnyk promised that changes were coming and they came quickly. In June 2004, Anaheim Ducks GM Bryan Murray of nearby Shawville, became head coach. That summer, the team also made substantial personnel changes, trading long-time players Patrick Lalime and Radek Bonk, and signing free agent goaltender Dominik Hasek. The team would not be able to show its new lineup for a year, as the 2004–05 NHL lockout intervened and most players played in Europe or in the minors. In a final change, just before the 2005–06 season, the team traded long-time player Marian Hossa for Dany Heatley.
The media predicted the Senators to be Stanley Cup contenders in 2005–06, as they had a strong core of players returning, played in an up-tempo style fitting the new rule changes and Hasek was expected to provide top-notch goaltending. The team rushed out of the gate, winning 19 of the first 22 games, in the end winning 52 games and 113 points, placing first in the conference, and second overall. The newly formed 'CASH' line of Alfredsson, Spezza and newly acquired Dany Heatley established itself as one of the league's top offensive lines. Hasek played well until he was injured during the 2006 Winter Olympics, forcing the team to enter the playoffs with rookie netminder Ray Emery as their starter. Without Hasek, the club bowed out in a second round loss to the Buffalo Sabres.
2006–07: Trip to the Stanley Cup finals.
In 2006–07, the Senators reached the Stanley Cup Finals after qualifying for the playoffs in nine consecutive seasons. The Senators had a high turn-over of personnel and the disappointment of 2006 to overcome and started the season poorly. Trade rumours swirled around Daniel Alfredsson for most of the last months of 2006. The team lifted itself out of last place in the division to nearly catch the Buffalo Sabres by season's end, placing fourth in the Eastern Conference. The team finished with 105 points, their fourth straight 100-point season and sixth in the last eight. In the playoffs, Ottawa continued its good play. Led by the 'CASH' line, goaltender Ray Emery, and the strong defence of Chris Phillips and Anton Volchenkov, the club defeated the Pittsburgh Penguins, the second-ranked New Jersey Devils and the top-ranked Buffalo Sabres to advance to the Stanley Cup Finals.
The 2006–07 Senators thus became the first Ottawa team to be in the Stanley Cup final since 1927 and the city was swept up in the excitement. Businesses along all of the main streets posted large hand-drawn "Go Sens Go" signs, residents put up large displays in front of the their homes or decorated their cars. A large Ottawa Senators flag was draped on the City Hall, along with a large video screen showing the games. A six-storey likeness of Daniel Alfredsson was hung on the Corel building. Rallies were held outside of City Hall, car rallies of decorated cars paraded through town and a section of downtown, dubbed the "Sens Mile," was closed off to traffic during and after games for fans to congregate.
In the Final, the Senators now faced the Anaheim Ducks, considered a favourite since the start of the season, a team the Senators had last played in 2006, and a team known for its strong defence. The Ducks won the first two games in Anaheim 3–2 and 1–0. Returning home, the Senators won game three 5–3, but lost game four 3–2. The Ducks won game five 6–2 in Anaheim to clinch the series. The Ducks had played outstanding defence, shutting down the 'CASH' line, forcing Murray to split up the line. The Ducks scored timely goals and Ducks' goaltender Jean-Sebastien Giguere out-played Emery.
2007–11: A team in decline.
In the off-season after the Stanley Cup Final, Bryan Murray's contract was expiring, while GM John Muckler had one season remaining, at which he was expected to retire. Murray, who had previously been at GM for other NHL clubs, was expected to take over the GM position, although no public timetable was given. Owner Melnyk decided to offer Muckler another position in the organization and give the GM position to Murray. Muckler declined the offer and was relieved from his position. Melnyk publicly justified the move, saying that he expected to lose Murray if his contract ran out. Murray then elevated John Paddock, the assistant coach, to head coach of the Senators. Under Paddock, the team came out to a record start to the 2007–08 season. However, team play declined to a .500 level and the team looked to be falling out of the playoffs. Paddock was fired by Murray, who took over coaching on an interim basis. The club managed to qualify for the playoffs by a tie-breaker, but was swept in the first round of the playoffs to the Pittsburgh Penguins. In June, the club bought-out goaltender Ray Emery, who had become notorious for off-ice events in Ottawa and lateness to several team practices.
For 2008–09, Murray hired Craig Hartsburg to coach the Senators. Under Hartsburg's style, the Senators struggled and played under .500. Uneven goaltending with Martin Gerber and Alex Auld meant the team played cautiously to protect the goaltender. Murray's patience ran out in February 2009 with the team well out of playoff contention and Hartsburg was fired, although he had two years left on his contract, and the team also had Paddock under contract. Cory Clouston was elevated from the Binghamton coaching position. The team played above .500 under Clouston and rookie goaltender Brian Elliott, who had been promoted from Binghamton. Gerber was waived from the team at the trading deadline and the team traded for goaltender Pascal Leclaire, although he would not play due to injury. The team failed to make the playoffs for the first time in 12 seasons. Auld would be traded in the off-season to make room. Clouston's coaching had caused a rift with top player Dany Heatley (although unspecified "personal issues" were also noted by Heatley) and after Clouston was given a contract to continue coaching, Heatley made a trade demand and was traded just before the start of the 2009–10 season.
In 2009–10, the Senators were a .500 team until January, when the team went on a team-record 11-game winning streak. The streak propelled the team to the top of the Northeast Division standings and a top-three placing for the playoffs. The team was unable to hold off the Sabres for the division lead, but qualified for the playoffs in the fifth position. For the third season in four, the Senators played off against the Pittsburgh Penguins in the first round. A highlight for the Senators was winning a triple-overtime fifth game in Pittsburgh, but the team was unable to win a playoff game on home ice, losing the series in six games.
2011–present: Rebuilding.
The Senators had a much poorer than expected 2010–2011 campaign, resulting in constant rumours of a shakeup right through until December. The rumours were heightened in January after the team went on a lengthy losing streak. January was a dismal month for the Senators, winning only one game all month. Media speculated on the imminent firing of Clouston, Murray or both. Owner Melynk cleared the air in an article in the January 22, 2011 edition of the "Ottawa Sun." Melnyk stated that he would not fire either Clouston or Murray, but that he had given up on this season and was in the process of developing a plan for the future. On Monday, January 24, the "Globe and Mail" reported that the plan included hiring a new general manager before the June entry draft and that Murray would be retained as an advisor to the team. A decision on whether to retain Clouston would be made by the new general manager. The article by Roy MacGregor, a long-time reporter of the Ottawa Senators, stated that former assistant coach Pierre McGuire had already been interviewed. Murray, in a press conference that day, stated that he wished to stay on as the team's general manager. He also stated that Melnyk was allowing him to continue as general manager without restraint. Murray said that the players were now to be judged by their play until the February 28 trade deadline. Murray would attempt to move "a couple, at least" of the players for draft picks or prospects at that time if the Senators remained out of playoff contention. At the time of Murray's comments the team was eight games under .500 and 14 points out of a playoff position after 49 games.
Murray started with the trading of Mike Fisher to the Nashville Predators in exchange for a first round pick in the 2011 draft. Fisher already had a home in Nashville with new wife Carrie Underwood. The trading of Fisher, a fan favourite in Ottawa, lead to a small anti-Underwood backlash in the city with the banning of her songs from the play lists of some local radio stations. Murray next traded Chris Kelly, another veteran, to the Boston Bruins for a second round pick in the 2011 draft. A few days later, pending unrestricted free agent Jarkko Ruutu was sent to the Anaheim Ducks in exchange for a sixth round pick in 2011. A swap of goaltenders was made with the Colorado Avalanche which brought Craig Anderson to Ottawa in exchange for Brian Elliott. Both goalies were having sub-par seasons prior to the trade. Under-achieving forward Alex Kovalev was traded to the Pittsburgh Penguins for a seventh round draft pick. On trade deadline day, Ottawa picked up goaltender Curtis McElhinney on waivers and traded Chris Campoli with a seventh round pick to the Chicago Blackhawks for a second round pick and Ryan Potulny. Goaltender Anderson played very well down the stretch for Ottawa, and the team quickly signed the soon-to-be unrestricted free agent to a four-year contract. After media speculation on the future of Murray within the organization, Murray was re-signed as general manager on April 8 to a three-year extension. On April 9, Head Coach Cory Clouston and assistants Greg Carvel and Brad Lauer were dismissed from their positions. Murray said that the decision was made based on the fact that the team entered the season believing it was a contender, but finished with a 32–40–10 record. Former Detroit Red Wings' assistant coach Paul MacLean was hired as Clouston's replacement on June 14, 2011.
As the 2011–12 season began, many hockey writers and commentators were convinced that the Senators would finish at or near the bottom of the NHL standings. In the midst of rebuilding, the Ottawa lineup contained many rookies and inexperienced players. The team struggled out of the gate, losing five of their first six games before a reversal of fortunes saw them win six games in a row. In December 2011, the team acquired forward Kyle Turris from the Phoenix Coyotes in exchange for David Rundblad and a draft pick. The team improved its play afterwards and moved into a playoff position before the All-Star Game. For the first time in Senators' history, the All-Star Game was held in Ottawa, and it was considered a great success. Five Senators were voted in or named to the event, including Daniel Alfredsson, who was named captain of one team. The team continued its playoff push after the break. After starting goalie Craig Anderson injured his hand in a kitchen accident at home, the Senators called up Robin Lehner from Binghamton and acquired highly regarded goaltender Ben Bishop from the St. Louis Blues. While Anderson recovered, the team continued its solid play. On April 1, 2012, the Senators defeated the New York Islanders 5–1, officially ensuring a playoff position. The team finished as the eighth seed in the Eastern Conference, drawing a first round playoff matchup against the Conference champion New York Rangers. Ultimately, Ottawa lost the series in seven games.
The next season, Ottawa would be challenged to repeat the success they had in 2011–12, due to long-term injuries to key players such as Erik Karlsson, Jason Spezza, Milan Michalek and Craig Anderson. Despite these injuries, the Senators would finish seventh in the Eastern Conference and head coach Paul MacLean would go on to win the Jack Adams Award as the NHL's coach of the year. Ottawa would play the second-seeded Montreal Canadiens in the first round of the playoffs, eventually winning in five games, blowing out Montreal 6–1 in games three and five. The Senators would advance to play the top-seeded Pittsburgh Penguins in the second round, this time losing in five games. During the off-season, the Senators traded veteran defenceman Sergei Gonchar to the Dallas Stars for a sixth round pick in the 2013 draft. July 5, 2013, would be a day of mixed emotions for the city and fans, as long-time captain Daniel Alfredsson signed a one-year contract with the Detroit Red Wings, leaving Ottawa after 17 seasons with the Senators and 14 as captain. The signing shocked numerous fans across the city and many within the Senators organization. The day finished optimistically however, as Murray acquired star forward Bobby Ryan from the Anaheim Ducks in exchange for forwards Jakob Silfverberg, Stefan Noesen and a first round pick in the 2014 draft. The hope was that Ryan would be the guy to play on the top line with Jason Spezza after Alfredsson's departure. Murray would also sign free agent forward Clarke MacArthur to a two-year contract that same day and would sign free agent defenceman Joe Corvo to a one-year contract three days later on July 8, 2013.
For the 2013–14 NHL season, the league realigned and Ottawa was assigned to the new Atlantic Division along with the rest of the old Northeast Division, with the additions of the Columbus Blue Jackets and Detroit Red Wings, formerly of the Western Conference. The re-alignment brought increased competition to qualify for the playoffs, as there were now 16 teams in the Eastern Conference fighting for eight playoff spots. The season began with a changing of leadership, as on September 14, 2013, the Ottawa Senators named Jason Spezza their eighth captain in franchise history. While new addition Clarke MacArthur had a career year, Ryan and Spezza struggled to find chemistry, and Ryan was moved to a line with MacArthur and Kyle Turris, where he fared much better. Bobby Ryan also ran into injury problems during the season, and while there were times where Joe Corvo played solidly, he eventually lost his place in the lineup. The club struggled on defence, as shots and goals against numbers increased from the previous season. The club was a sub .500 team much of the season, or only a few games above and never was in a playoff position all season. At the trade deadline, Murray traded for flashy right winger Ales Hemsky from the Edmonton Oilers, quickly finding success on a line with Spezza and Michalek. The club, however, was eliminated from playoff contention in the last week of the season. At the end of the season, the club failed to come to terms on a new contract with Ales Hemsky and captain Jason Spezza requested a trade out of Ottawa. At the 2014 NHL Entry Draft, a potential trade to the Nashville Predators was negotiated by Murray but rejected by Spezza, as the Predators were one of the teams on his limited no-trade list. A deal with the Dallas Stars was eventually reached, and Spezza was sent, along with Ludwig Karlsson, in exchange for Alex Chiasson, Nick Paul, Alex Guptill and a 2015 second round pick. During the off-season, the club signed forward David Legwand to a two-year, $6 million contract.
At the beginning of the 2014–15 season, defenceman Erik Karlsson was named the franchise's ninth captain, with the club also re-signing Bobby Ryan to a seven-year extension. The Senators became the first team in modern NHL history to overcome a 14-point deficit at any junction of the season to qualify for the playoffs.
Home rinks.
Ottawa Civic Centre.
The new Senators' first home arena was the Ottawa Civic Centre, located on Bank Street, where they played from the 1992-93 season to January of the 1995-96 season. They played their first home game on October 8, 1992 against the Montreal Canadiens with lots of pre-game spectacle. The Senators would defeat the Canadiens 5–3 in one of few highlights that season. Montreal would eventually finish the season as Stanley Cup champions. Following the initial excitement of the opening night victory, the club floundered badly and would eventually tie with the San Jose Sharks for the worst record in the league, finishing with only 10 wins, 70 losses and 4 ties for 24 points, three points better than the NHL record for futility.
Canadian Tire Centre.
As part of its bid to land a NHL franchise for Ottawa, Terrace Corporation unveiled the original proposal for the arena development at a press conference in September 1989. The proposal included a hotel and 20,500 seat arena, named The Palladium on 100 acre, surrounded by a 500 acre mini-city, named "West Terrace." The site itself, 600 acre of farmland, on the western border of Kanata, had been acquired in May 1989 by Terrace. Rezoning approval was granted by the Board on August 28, 1991, with conditions. The conditions imposed by the board included a scaling down of the arena to 18,500 seats, a moratorium on development outside the initial 100 acre arena site, and that the cost of the highway interchange with highway 417 be paid by Terrace. A two-year period was used seeking financing for the site and interchange by Terrace Corporation. The corporation received a $6 million grant from the federal government, but needed to borrow to pay for the rest of the costs of construction. A ground-breaking ceremony was held in June 1992 but actual construction did not start until July 7, 1994. Actual construction took 18 months, finishing in January 1996.
The newly built Palladium opened on January 15, 1996 with a concert by Canadian rocker Bryan Adams. The Senators played their first game in their new arena two days later, falling 3-0 to the Montreal Canadiens. On February 17, 1996, the name 'Palladium' was changed to the 'Corel Centre' when Corel Corporation, an Ottawa software company, signed a 10-year deal for the naming rights.
When mortgage holder Covanta Energy (the former Ogden Entertainment) went into receivership in 2001, Terrace was expected to pay off the entire debt. The ownership was not able to refinance the arena, eventually leading Terrace itself to declare bankruptcy in 2003. However, on August 26, 2003, billionaire businessman Eugene Melnyk finalized the purchase of the Senators and the arena. The arena and club became solely owned by Melnyk through a new company, Capital Sports Properties.
In 2004, the ownership applied to expand its seating. In December 2004, the City of Ottawa amended its by-laws and in 2005, the venue was allowed to increase its seating capacity to 19,153 and total attendance capacity to 20,500 when including standing room.
On January 19, 2006, the arena became known as 'Scotiabank Place' after reaching a new 15-year naming agreement with Canadian bank Scotiabank on January 11, 2006. Scotiabank had been an advertising partner with the club for several years and took over the naming after Corel declined to renew its naming agreement with the Senators, but continued as an advertising sponsor.
On June 18, 2013, the Ottawa Senators announced a new marketing agreement with Canadian Tire, and as a result, the arena was renamed the Canadian Tire Centre on July 1, 2013.
Team identity.
Logo and jersey design.
The team colours are red, black and white, with added trim of gold. The team's away jersey is mostly white with red and black trim, while the home jersey is red, with white and black trim. The club logo is officially the head of a Roman general, a member of the Senate of the Roman Republic, projecting from a gold circle. The original, unveiled on May 23, 1991, described the general as a "centurion figure, strong and prominent" according to its designer, Tony Milchard.
The current jersey design was unveiled on August 22, 2007, in conjunction with the league-wide adoption of the "Rbk EDGE" jerseys by Reebok for the 2007–08 season. The jersey incorporates the original Senators' 'O' logo as a shoulder patch. At the same time, the team updated its logos, and switched their usage. The primary logo, which according to team owner Eugene Melnyk, "represents strength and determination" is an update of the old secondary logo. The old primary logo has become the team's secondary logo and only appears on Senators' merchandise.
In 2011, the Senators introduced their current third jersey design. Mostly black, the jersey incorporated horizontal striping intended to be reminiscent of the original Senators' 'barber-pole' designs. Shield-type patches were added to the shoulders. The design of the shield-type patches was intended to be similar to the shield patches that the original Senators added to their jerseys after each Stanley Cup championship win. The patches spell the team name, one in English, and one in French. The design was a collaborative effort between the Senators and a fan in Gatineau, Quebec who had been circulating a version of it on the internet since 2009.
Attendance and revenues.
On April 18, 2008, the club announced its final attendance figures for 2007–08. The club had 40 sell-outs out of 41 home dates, a total attendance of 812,665 during the regular season, placing the club third in attendance in the NHL. The number of sell-outs and the total attendance were both club records. The previous attendance records were set during the 2005–06 with a season total of 798,453 and 33 sell-outs. In 2006–07 regular season attendance was 794,271, with 31 sell-outs out of 41 home dates or an average attendance of 19,372. In the 2007 playoffs, the Senators played 9 games with 9 sell-outs and an attendance of 181,272 for an average of 20,141, the highest in team history.
On November 29, 2011, a "Forbes" magazine report valued the Ottawa Senators Hockey Club at $201 million, (17th highest in NHL). The valuation was based on $27 million for the sport, $70 million for the arena, $80 million for the market and $25 million for the brand. For 2010–11, the club had an operating income of $2.8 million on revenues of $100 million. The gate receipts for the 2010–11 season were $46 million and player expenses were $57 million. The operating income followed two years where the team posted a loss. Forbes estimates that the organization has a debt/value ratio of 65%, including arena debt. Eugene Melnyk bought the team for $92 million in 2003. A November 2014 report by Forbes valued the Senators at $400 million, 16th highest in the NHL.
Arena entertainment.
At many home games the fans are entertained both outside and inside Canadian Tire Centre with a myriad of talent – live music, rock bands, giveaways and promotions. The live music includes the traditional Scottish music of the 'Sons of Scotland Pipe Band' of Ottawa along with highland dancers. Before and during games, entertainment is provided by Spartacat, the official mascot of the Senators, an anthropomorphic lion. He made his debut on the Senators' opening night: October 8, 1992. Anthems are usually sung by former Ontario Provincial Police Constable Lyndon Slewidge. Slewidge sings the "bilingual" version of "O Canada" containing both English and French words. The Senators have their own theme song "Ottawa Senators Theme Song" which is played as the team comes on the ice and is also used in Sens TV web videos. It was composed locally in Ottawa.
Sens Army.
The fans of the Senators are known as the "Sens Army". Like most hockey fanatics, they are known to dress up for games; some in Roman legionary clothing. For the 2006–2007 playoff run, more fans than ever before would wear red, and fan activities included 'Red Rallies' of decorated cars, fan rallies at Ottawa City Hall Plaza and the 'Sens Mile' along Elgin Street where fans would congregate.
Sens Mile.
Much like the Red Mile in Calgary during the Flames' 2004 cup run and the Copper Kilometer in Edmonton during the Oilers' 2006 cup run, Ottawa Senators fans took to the streets to celebrate their team's success during the 2006–07 playoffs. The idea to have a 'Sens Mile' on the downtown Elgin Street, a street with numerous restaurants and pubs, began as a grassroots campaign on Facebook by Ottawa residents before Game 4 of the Ottawa-Buffalo Eastern Conference Final series. After the Game 5 win, Ottawa residents closed the street to traffic for a spontaneous celebration. The City of Ottawa then closed Elgin Street for each game of the Final.
Broadcasting and media.
On television, Senators games not broadcast by the league's national broadcast partners are televised by TSN5 within the Ottawa River valley and Eastern Ontario (portions are shared with the Toronto Maple Leafs, along with Quebec, the Maritime provinces and Newfoundland and Labrador. Senators games were previously broadcast by Sportsnet East. On January 29, 2014, the team announced a new, 12-year regional broadcasting deal with Bell Media to take effect in the 2014-15 season, which will see CFGO maintain radio coverage, and see TSN (English) and RDS (French) gain regional television rights to Senators games not broadcast nationally by Sportsnet (who will take over national NHL rights beginning in the same season), TVA Sports, or "Hockey Night in Canada". The deal will also expand Bell Canada's role as a team sponsor.
In April 2014, Dean Brown, who had called play-by-play for Senators games since 1992, stated that it was "extremely unlikely" that he would move to TSN and continue his role. He noted that the network already had four commentators among its personalities—including Chris Cuthbert, Gord Miller, Rod Black, and Paul Romanuk (who was, however, picked up by Rogers for its national NHL coverage in June 2014), who were likely candidates to serve as the new voices of the Senators.
On radio, all home and away games are broadcast on a network of local stations in eastern Ontario. The flagship radio station is the Ottawa station CFGO "TSN Radio 1200", which produces the broadcasts and provides the play-by-play announcers. Radio broadcasts on CFGO began in 1997–98; the contract has since been extended through the 2025-2026 season through an extensive rights deal with the station's current owner, Bell Media.
During the 2006–07 and 2007–08 seasons, several games were only available in video on pay-per-view or at local movie theatres in the Ottawa area. The "Sens TV" service was suspended indefinitely as of September 24, 2008.
The Senators' organization operates predominantly in English, but provides French services. The Senators' web site is in both languages. Arena announcements and press releases are in both languages. The Senators' ticket agency "CapitalTickets.ca" operates in English and French. The French-language cable television channels TVA Sports and RDS broadcast a selection of Senators games. On the RDS network, Félix Séguin and former Senators goaltender Patrick Lalime are the announcers, starting in the 2011–12 season. The TVA Sports broadcast team consists of Michel Langevin, Yvon Pedneault and Enrico Ciccone. The Senators are broadcast on radio in French through Intersport Production and CJFO Unique FM in Ottawa. Play-by-play is done by Nicolas St. Pierre and the colour commentary of Alain Sanscartier.
Players and personnel.
Current roster.
Jack Adams Award
James Norris Memorial Trophy
King Clancy Memorial Trophy
Mark Messier Leadership Award
NHL All-Rookie Team
NHL First All-Star Team
NHL Second All-Star Team
Team records.
Source: Ottawa Senators.

</doc>
<doc id="22706" url="http://en.wikipedia.org/wiki?curid=22706" title="Orchestra">
Orchestra

An orchestra is a large instrumental ensemble that contains sections of string, brass, woodwind, and percussion instruments. Other instruments such as the piano and celesta may sometimes be grouped into a fifth section such as a keyboard section or may stand alone, as may the concert harp and electric and electronic instruments. The term "orchestra" derives from the Greek ὀρχήστρα, the name for the area in front of an ancient Greek stage reserved for the Greek chorus. The orchestra grew by accretion throughout the 18th and 19th centuries, but changed very little in composition during the course of the 20th century.
A smaller-sized orchestra for this time period (of about fifty musicians or fewer) is called a chamber orchestra. A full-size orchestra (about 100 musicians) may sometimes be called a symphony orchestra or philharmonic orchestra; these modifiers do not necessarily indicate any strict difference in either the instrumental constitution or role of the orchestra, but can be useful to distinguish different ensembles based in the same city (for instance, the London Symphony Orchestra and the London Philharmonic Orchestra). A symphony orchestra will usually have over eighty musicians on its roster, in some cases over a hundred, but the actual number of musicians employed in a particular performance may vary according to the work being played and the size of the venue. A leading chamber orchestra might employ as many as fifty musicians; some are much smaller than that. Orchestras can also be found in schools. The term concert orchestra may sometimes be used (e.g., BBC Concert Orchestra; RTÉ Concert Orchestra)—no distinction is made on size of orchestra by use of this term, although their use is generally distinguished as for live concert. As such they are commonly chamber orchestras.
Instrumentation.
The typical symphony orchestra consists of 4 groups of similar musical instruments called the woodwinds, brass, percussion, and strings. Other instruments such as the piano and celesta may sometimes be grouped into a fifth section such as a keyboard section or may stand alone, as may the concert harp and electric and electronic instruments. The orchestra, depending on the size, contains almost all of the standard instruments in each group. In the history of the orchestra, its instrumentation has been expanded over time, often agreed to have been standardized by the classical period and Ludwig van Beethoven's influence on the classical model. In the 20th century, new repertory demands expanded the instrumentation of the orchestra, resulting in a flexible use of the classical model instruments in various combinations.
Beethoven's influence.
The so-called "standard complement" of double winds and brass in the orchestra from the first half of the 19th century is generally attributed to the forces called for by Beethoven. The exceptions to this are his Symphony No. 4, Violin Concerto, and Piano Concerto No. 4, which each specify a single flute. The composer's instrumentation almost always included paired flutes, oboes, clarinets, bassoons, horns and trumpets. Beethoven carefully calculated the expansion of this particular timbral "palette" in Symphonies 3, 5, 6, and 9 for an innovative effect. The third horn in the "Eroica" Symphony arrives to provide not only some harmonic flexibility, but also the effect of "choral" brass in the Trio. Piccolo, contrabassoon, and trombones add to the triumphal finale of his Symphony No. 5. A piccolo and a pair of trombones help deliver storm and sunshine in the Sixth. The Ninth asks for a second pair of horns, for reasons similar to the "Eroica" (four horns has since become standard); Beethoven's use of piccolo, contrabassoon, trombones, and untuned percussion—plus chorus and vocal soloists—in his finale, are his earliest suggestion that the timbral boundaries of symphony might be expanded for good. For several decades after his departure, symphonic instrumentation was faithful to Beethoven's well-established model, with few exceptions.
Expanded instrumentation.
Apart from the core orchestral complement, various other instruments are called for occasionally. These include the classical guitar, heckelphone, flugelhorn, cornet, harpsichord, and organ. Saxophones, for example, appear in some 19th- through 21st-century scores. While appearing only as featured solo instruments in some works, for example Maurice Ravel's orchestration of Modest Mussorgsky's "Pictures at an Exhibition" and Sergei Rachmaninoff's "Symphonic Dances", the saxophone is included in other works, such as Ravel's "Boléro", Sergei Prokofiev's Romeo and Juliet Suites 1 and 2, Vaughan Williams' Symphonies No.6 and 9 and William Walton's "Belshazzar's Feast", and many other works as a member of the orchestral ensemble. The euphonium is featured in a few late Romantic and 20th-century works, usually playing parts marked "tenor tuba", including Gustav Holst's "The Planets", and Richard Strauss's "Ein Heldenleben". The Wagner tuba, a modified member of the horn family, appears in Richard Wagner's cycle "Der Ring des Nibelungen" and several other works by Strauss, Béla Bartók, and others; it has a prominent role in Anton Bruckner's "Symphony No. 7 in E Major". Cornets appear in Pyotr Ilyich Tchaikovsky's ballet "Swan Lake", Claude Debussy's "La Mer", and several orchestral works by Hector Berlioz. Unless these instruments are played by members doubling on another instrument (for example, a trombone player changing to euphonium for a certain passage), orchestras will use freelance musicians to augment their regular rosters.
The 20th-century orchestra was far more flexible than its predecessors. In Beethoven's and Felix Mendelssohn's time, the orchestra was composed of a fairly standard core of instruments which was very rarely modified. As time progressed, and as the Romantic period saw changes in accepted modification with composers such as Berlioz and Mahler, the 20th century saw that instrumentation could practically be hand-picked by the composer. Today, however, the modern orchestra has generally been considered standardized with the modern instrumentation listed below.
With this history in mind, the orchestra can be seen to have a general evolution as outlined below. The first is a Baroque music orchestra, the second is a typical classical orchestra (i.e. Beethoven/Joseph Haydn), the third is typical of an early/mid-romantic (i.e. Johannes Brahms/Antonín Dvořák/Tchaikovsky), late romantic/early 20th century (i.e. Wagner/Mahler/Igor Stravinsky), to the common complement of a present day modern orchestras (i.e. John Adams/Samuel Barber/Aaron Copland/Philip Glass/Krzysztof Penderecki).
Organization.
Among the instrument groups and within each group of instruments, there is a generally accepted hierarchy. Every instrumental group (or section) has a principal who is generally responsible for leading the group and playing orchestral solos. The violins are divided into two groups, first violin and second violin, with the second violins playing with lower registers than the first violins.
The principal first violin is called the concertmaster (or "leader" in the UK) and is not only considered the leader of the string section, but the second-in-command of the entire orchestra, behind only the conductor. The concertmaster leads the pre-concert tuning and handles musical aspects of orchestra management, such as determining the bowings for the violins or for all of the string section. The concertmaster usually sits to the conductor's left, closest to the audience. In some U.S. and British orchestras, the concertmaster comes on stage after the rest of the orchestra is seated, takes a bow, and receives applause before the conductor (and the soloists, if there are any) appear on stage.
The principal trombone is considered the leader of the low brass section, while the principal trumpet is generally considered the leader of the entire brass section. While the oboe often provides the tuning note for the orchestra (due to 300-year-old convention), no principal is the leader of the woodwind section though in woodwind ensembles, often the flute is leader. Instead, each principal confers with the others as equals in the case of musical differences of opinion. The horn, while technically a brass instrument, often acts in the role of both woodwind and brass. Most sections also have an assistant principal (or co-principal or associate principal), or in the case of the first violins, an assistant concertmaster, who often plays a tutti part in addition to replacing the principal in his or her absence.
A section string player plays in unison with the rest of the section, except in the case of divided ("divisi") parts, where upper and lower parts in the music are often assigned to "outside" (nearer the audience) and "inside" seated players. Where a solo part is called for in a string section, the section leader invariably plays that part. The section leader (or principal) of a string section is also responsible for determining the bowings, often based on the bowings set out by the concertmaster. In some cases, the principal of a string section may use a slightly different bowing than the Concertmaster, to accommodate the requirements of playing their instrument (e.g., the double bass section). Principals of a string section will also lead entrances for their section, typically by lifting the bow before the entrance, to ensure the section plays together. Tutti wind and brass players generally play a unique but non-solo part. Section percussionists play parts assigned to them by the principal percussionist.
In modern times, the musicians are usually directed by a conductor, although early orchestras did not have one, giving this role instead to the concertmaster or the harpsichordist playing the continuo. Some modern orchestras also do without conductors, particularly smaller orchestras and those specializing in historically accurate (so-called "period") performances of baroque and earlier music.
The most frequently performed repertoire for a symphony orchestra is Western classical music or opera. However, orchestras are used sometimes in popular music, extensively in film music, and increasingly often in video game music. Orchestras are also used in the symphonic metal genre. The term "orchestra" can also be applied to a jazz ensemble, for example in performance of big band music.
History.
Early history.
The first orchestras were made up of small groups of musicians that gathered for festivals, holidays, or funerals. It was not until the 11th century that families of instruments started to appear with differences in tones and octaves. True modern orchestras started in the late 16th century when composers started writing music for instrumental groups. In the 15th and 16th centuries in Italy the households of nobles had musicians to provide music for dancing and the court, however with the emergence of the theatre, particularly opera, in the early 17th century, music was increasingly written for groups of players in combination, which is the origin of orchestral playing. Opera originated in Italy, and Germany eagerly followed. Dresden, Munich and Hamburg successively built opera houses. At the end of the 17th century opera flourished in England under Henry Purcell, and in France under Lully, who with the collaboration of Molière also greatly raised the status of the entertainments known as ballets, interspersed with instrumental and vocal music.
In the 17th century and early 18th century, instrumental groups were taken from all of the available talent. A composer such as Johann Sebastian Bach had control over almost all of the musical resources of a town, whereas Handel would hire the best musicians available. This placed a premium on being able to rewrite music for whichever singers or musicians were best suited for a performance — Handel produced different versions of the "Messiah" oratorio almost every year.
As nobility began to build retreats away from towns, they began to hire musicians to form permanent ensembles. Composers such as the young Joseph Haydn would then have a fixed body of instrumentalists to work with. At the same time, traveling virtuoso performers such as the young Wolfgang Amadeus Mozart would write concerti that showed off their skills, and they would travel from town to town, arranging concerts along the way. The aristocratic orchestras worked together over long periods, making it possible for ensemble playing to improve with practice.
Mannheim school.
This change, from civic music making where the composer had some degree of time or control, to smaller court music making and one-off performance, placed a premium on music that was easy to learn, often with little or no rehearsal. The results were changes in musical style and emphasis on new techniques. Mannheim had one of the most famous orchestras of that time, where notated dynamics and phrasing, previously quite rare, became standard (see Mannheim school). It also attended a change in musical style from the complex counterpoint of the baroque period, to an emphasis on clear melody, homophonic textures, short phrases, and frequent cadences: a style that would later be defined as classical.
Throughout the late 18th century composers would continue to have to assemble musicians for a performance, often called an "Academy", which would, naturally, feature their own compositions. In 1781, however, the Leipzig Gewandhaus Orchestra was organized from the merchants concert society, and it began a trend towards the formation of civic orchestras that would accelerate into the 19th century. In 1815, Boston's Handel and Haydn Society was founded, in 1842 the New York Philharmonic and the Vienna Philharmonic were formed, and in 1858, the Hallé Orchestra was formed in Manchester. There had long been standing bodies of musicians around operas, but not for concert music: this situation changed in the early 19th century as part of the increasing emphasis in the composition of symphonies and other purely instrumental forms. This was encouraged by composer critics such as E. T. A. Hoffmann who declared that instrumental music was the "purest form" of music. The creation of standing orchestras also resulted in a professional framework where musicians could rehearse and perform the same works repeatedly, leading to the concept of a repertoire in instrumental music.
Performance standards.
In the 1830s, conductor François Antoine Habeneck, began rehearsing a selected group of musicians in order to perform the symphonies of Beethoven, which had not been heard in their entirety in Paris. He developed techniques of rehearsing the strings separately, notating specifics of performance, and other techniques of cuing entrances that were spread across Europe. His rival and friend Hector Berlioz would adopt many of these innovations in his touring of Europe.
Instrumental craftsmanship.
The invention of the piston and rotary valve by Heinrich Stölzel and Friedrich Blühmel, both Silesians, in 1815, was the first in a series of innovations, including the development of modern keywork for the flute by Theobald Boehm and the innovations of Adolphe Sax in the woodwinds. These advances would lead Hector Berlioz to write a landmark book on instrumentation, which was the first systematic treatise on the use of instrumental sound as an expressive element of music.
The effect of the invention of valves for the brass was felt almost immediately: instrument-makers throughout Europe strove together to foster the use of these newly refined instruments and continuing their perfection; and the orchestra was before long enriched by a new family of valved instruments, variously known as tubas, or euphoniums and bombardons, having a chromatic scale and a full sonorous tone of great beauty and immense volume, forming a magnificent bass. This also made possible a more uniform playing of notes or intonation, which would lead to a more and more "smooth" orchestral sound that would peak in the 1950s with Eugene Ormandy and the Philadelphia Orchestra and the conducting of Herbert von Karajan with the Berlin Philharmonic.
During this transition period, which gradually eased the performance of more demanding "natural" brass writing, many composers (notably Wagner and Berlioz) still "notated" brass parts for the older "natural" instruments. This practice made it possible for players still using natural horns, for instance, to perform from the same parts as those now playing valved instruments. However, over time, use of the valved instruments became standard, indeed universal, until the revival of older instruments in the contemporary movement towards authentic performance (sometimes known as "historically informed performance").
At the time of the invention of the valved brass, the pit orchestra of most operetta composers seems to have been modest. An example is Sullivan's use of two flutes, one oboe, two clarinets, one bassoon, two horns, two cornets (a piston), two trombones, drums and strings.
During this time of invention, winds and brass were expanded, and had an increasingly easy time playing in tune with each other: particularly the ability for composers to score for large masses of wind and brass that previously had been impractical. Works such as the "Requiem" of Hector Berlioz would have been impossible to perform just a few decades earlier, with its demanding writing for twenty woodwinds, as well as four gigantic brass ensembles each including around four trumpets, four trombones, and two tubas.
Wagner's influence.
The next major expansion of symphonic practice came from Richard Wagner's Bayreuth orchestra, founded to accompany his musical dramas. Wagner's works for the stage were scored with unprecedented scope and complexity: indeed, his score to "Das Rheingold" calls for six harps. Thus, Wagner envisioned an ever-more-demanding role for the conductor of the theater orchestra, as he elaborated in his influential work "On Conducting". This brought about a revolution in orchestral composition, and set the style for orchestral performance for the next eighty years. Wagner's theories re-examined the importance of tempo, dynamics, bowing of string instruments and the role of principals in the orchestra. Conductors who studied his methods would go on to be influential themselves.
20th century orchestra.
As the early 20th century dawned, symphony orchestras were larger, better funded, and better trained than ever before; consequently, composers could compose larger and more ambitious works. The influence of Gustav Mahler was particularly innovational; in his later symphonies, such as the mammoth Symphony No. 8, Mahler pushes the furthest boundaries of orchestral size, employing huge forces. By the peak years of Shostakovich, orchestras could support the most enormous forms of symphonic expression. With the recording era beginning, the standard of performance reached a pinnacle. In recordings, small errors in a performance could be "fixed", but many older conductors and composers could remember a time when simply "getting through" the music as best as possible was the standard. Combined with the wider audience made possible by recording, this led to a renewed focus on particular conductors and on a high standard of orchestral execution. As sound was added to silent film, the virtuoso orchestra became a key component of the establishment of motion pictures as mass-market entertainment.
Counter-revolution.
In the 1920s and 1930s, economic as well as artistic considerations led to the formation of smaller concert societies, particularly those dedicated to the performance of music of the avant-garde, including Igor Stravinsky and Arnold Schoenberg. This tendency to start festival orchestras or dedicated groups would also be pursued in the creation of summer musical festivals, and orchestras for the performance of smaller works. Among the most influential of these was the Academy of St Martin in the Fields under the baton of Sir Neville Marriner.
With the advent of the early music movement, smaller orchestras where players worked on execution of works in styles derived from the study of older treatises on playing became common. These include the Orchestra of the Age of Enlightenment, the London Classical Players under the direction of Sir Roger Norrington and the Academy of Ancient Music under Christopher Hogwood, among others.
Recent trends in the United States.
In the United States, the late 20th century saw a crisis of funding and support for orchestras. The size and cost of a symphony orchestra, compared to the size of the base of supporters, became an issue that struck at the core of the institution. Few orchestras could fill auditoriums, and the time-honored season-subscription system became increasingly anachronistic, as more and more listeners would buy tickets on an ad hoc basis for individual events. Orchestral endowments and—more centrally to the daily operation of American orchestras—orchestral donors have seen investment portfolios shrink or produce lower yields, reducing the ability of donors to contribute; further, there has been a trend toward donors finding other social causes more compelling. Also, while government funding is less central to American than European orchestras, cuts in such funding are still significant for American ensembles. Finally, the drastic falling-off of revenues from recording, tied to no small extent to changes in the recording industry itself, began a period of change that has yet to reach its conclusion.
U.S. orchestras that have gone into Chapter 11 bankruptcy include the Philadelphia Orchestra (in April 2011), and the Louisville Orchestra, in December 2010; orchestras that have gone into Chapter 7 bankruptcy and have ceased operations include the Northwest Chamber Orchestra in 2006, the Honolulu Orchestra in March 2011, the New Mexico Symphony Orchestra in April 2011, and the Syracuse Symphony in June 2011. The Festival of Orchestras in Orlando, Florida ceased operations at the end of March, 2011.
Critics such as Norman Lebrecht were vocal in their diagnosis of the problem as the "jet set conductor" (whose salaries were presumably bleeding the orchestras dry); and several high-profile conductors have taken pay cuts in recent years; but the amounts of revenue involved are too small to account for the crisis. Music administrators such as Michael Tilson Thomas and Esa-Pekka Salonen argued that new music, new means of presenting it, and a renewed relationship with the community could revitalize the symphony orchestra. The influential critic Greg Sandow has argued in detail that orchestras must revise their approach to music, performance, the concert experience, marketing, public relations, community involvement, and presentation to bring them in line with the expectations of 21st-century audiences immersed in popular culture.
It is not uncommon for contemporary composers to use unconventional instruments, including various synthesizers, to achieve desired effects. Many, however, find more conventional orchestral configuration to provide better possibilities for color and depth. Composers like John Adams often employ Romantic-size orchestras, as in Adams' opera "Nixon in China"; Philip Glass and others may be more free, yet still identify size-boundaries. Glass in particular has recently turned to conventional orchestras in works like the "Concerto for Cello and Orchestra" and the Violin Concerto No. 2.
Along with a decrease in funding, some U.S. orchestras have reduced their overall personnel, as well as the number of players appearing in performances. The reduced numbers in performance are usually confined to the string section, since the numbers here have traditionally been flexible (as multiple players typically play from the same part).
Conductorless orchestras.
The post-revolutionary symphony orchestra Persimfans was formed in the Soviet Union in 1922. The unusual aspect of the orchestra was that, believing that in the ideal Marxist state all people are equal, its members felt that there was no need to be led by the dictatorial baton of a conductor; instead they were led by a committee. Although it was a partial success, the principal difficulty with the concept was in changing tempo. The orchestra survived for ten years before Stalin's cultural politics effectively forced it into disbandment by draining away its funding.
Some ensembles, such as the Orpheus Chamber Orchestra, based in New York City, have had more success, although decisions are likely to be deferred to some sense of leadership within the ensemble (for example, the principal wind and string players).
Others have returned to the tradition of a principal player, usually a violinist, being the artistic director and running rehearsals (such as the Australian Chamber Orchestra, Amsterdam Sinfonietta & Candida Thompson and the New Century Chamber Orchestra).
Multiple conductors.
The techniques of polystylism and polytempo music have recently led a few composers to write music where multiple orchestras perform simultaneously. These trends have brought about the phenomenon of polyconductor music, wherein separate sub-conductors conduct each group of musicians. Usually, one principal conductor conducts the sub-conductors, thereby shaping the overall performance. Some pieces are enormously complex in this regard, such as Evgeni Kostitsyn's Third Symphony, which calls for nine conductors.
Charles Ives often used two conductors, one for example to simulate a marching band coming through his piece. "Realizations for Symphonic Band" includes one example from Ives. Benjamin Britten's War Requiem is also an important example of the repertoire for more than one conductor.
One of the best examples in the late century orchestral music is Karlheinz Stockhausen's "Gruppen", for three orchestras placed around the audience. This way, the sound masses could be spacialized, as in an electroacoustic work. "Gruppen" was premiered in Cologne, in 1958, conducted by Stockhausen, Bruno Maderna and Pierre Boulez. Recently, it was performed by Simon Rattle, John Carewe and Daniel Harding.
Other meanings of "orchestra".
In Ancient Greece, the orchestra was the space between the auditorium and the proscenium (or stage), in which were stationed the chorus and the instrumentalists. The word "orchestra" literally means "a dancing place".
In some theaters, the orchestra is the area of seats directly in front of the stage (called "primafila" or "platea"); the term more properly applies to the place in a theatre, or concert hall reserved for the musicians.

</doc>
<doc id="22707" url="http://en.wikipedia.org/wiki?curid=22707" title="Oolong">
Oolong

Oolong RP: /uːlɒŋ/, GA: /ulɑŋ/ () is a traditional Chinese tea ("Camellia sinensis)" produced through a unique process including withering the plant under the strong sun and oxidation before curling and twisting. Most oolong teas, especially those of fine quality, involve unique tea plant cultivars that are exclusively used for particular varieties. The degree of oxidation can range from 8 to 85%, depending on the variety and production style. Oolong is especially popular with tea connoisseurs of south China and Chinese expatriates in Southeast Asia, as is the Fujian preparation process known as the Gongfu tea ceremony.
In Chinese tea culture, semi-oxidised oolong teas are collectively grouped as "qīngchá" (). The taste of oolong varies widely among different subvarieties. It can be sweet and fruity with honey aromas, or woody and thick with roasted aromas, or green and fresh with bouquet aromas, all depending on the horticulture and style of production. Several subvarieties of oolong, including those produced in the Wuyi Mountains of northern Fujian, such as Da Hong Pao, are among the most famous Chinese teas.
Different varieties of oolong are processed differently, but the leaves are formed into one of two distinct styles. Some are rolled into long curly leaves, while others are 'wrap-curled' into small beads, each with a tail. The former style is the more traditional of the two in China.
The name "oolong tea" came into the English language from the Chinese name (), meaning "black dragon".
Possible origins.
There are three widely accepted explanations of the origin of the Chinese name. According to the "tribute tea" theory, oolong tea came directly from Dragon-Phoenix Tea Cake tribute tea. The term oolong tea replaced the old term when loose tea came into fashion. Since it was dark, long, and curly, it was called Black Dragon tea.
According to the "Wuyi" theory, oolong tea first existed in the Wuyi Mountains region. This is evidenced by Qing dynasty poems such as Wuyi Tea Song (Wuyi Chage) and Tea Tale (Chashuo). It was said that oolong tea was named after the part of the Wuyi Mountain where it was originally produced.
According to the "Anxi" theory, oolong tea had its origin in the Anxi oolong tea plant, which was discovered by a man named Sulong, Wulong, or Wuliang.
Another tale tells of a man named Wu Liang (later corrupted to Wu Long, or Oolong) who discovered oolong tea by accident when he was distracted by a deer after a hard day's tea-picking, and by the time he remembered to return to the tea it had already started to oxidize.
Varieties.
Wuyi rock (cliff) tea (武夷岩茶 Wǔyí yán chá) from Fujian province.
The most famous and expensive oolong teas are made here, and the production is still usually accredited as being organic. Much Shuǐ Xiān is grown elsewhere in Fujian.
Some of the better known cliff teas are:
Fújiàn province.
Golden Cassia "Huángjīn Guì" (黄金桂）
There is a story regarding the origin of the "Tiě Guānyīn" variety: There was once a poor farmer who was devout and dedicated to maintaining the temple of Kuan Yin, the goddess of mercy. One day, to reward him for his loyalty and commitment to her, she told him that the key to his future was outside the temple. Outside he found a scrungy old bush, which he nursed to a flourishing bloom of greenish leaves.
Guangdong province.
The name "dan cong" originally meant phoenix teas all picked from one tree. In recent times though it has become a generic term for all Phoenix Mountain oolongs. True dan congs are still being produced, but they are extremely high quality and almost impossible to get in western markets. 
Taiwan.
Tea cultivation began in Taiwan in the 18th century. Since then, many of the teas which are grown in Fujian province have also been grown in Taiwan. Since the 1970s, the tea industry in Taiwan has expanded at a rapid rate, in line with the rest of Taiwan's economy. Due to high domestic demand and a strong tea culture, most Taiwanese tea is bought and consumed by the Taiwanese.
As the weather in Taiwan is highly variable, tea quality may differ from season to season. Although the island is not particularly large, it is geographically varied, with high, steep mountains rising abruptly from low-lying coastal plains. The different weather patterns, temperatures, altitudes, and soil ultimately result in differences in appearance, aroma, and flavour of the tea grown in Taiwan. In some mountainous areas, teas have been cultivated at ever higher elevations to produce a unique sweet taste that fetches a premium price.
New Zealand.
In the early 1990s a Taiwanese migrant to New Zealand was intrigued by the similarities between his native Taiwan's high mountains and New Zealand north Island's climate. He imported camellia sinensis cuttings into New Zealand and the plants thrived. Two oolong cultivars (qin xin and jinxuan) now spread across just under 40 hectares and have developed their own unique terroir character. The leaves are processed into oolong and black tea and exported worldwide under the trade name Zealong.
Steeping.
Generally, 3 grams of tea per 200 ml of water, or about two teaspoons of oolong tea per cup, should be used. Oolong teas should be prepared with 200 to 205°F (93 to 96°C) water (not boiling) and steeped 3–10 minutes. High quality oolong can be steeped several times from the same leaves and, unlike other teas, it improves with rebrewing: it is common to steep the same leaves three to five times, the third or fourth steeping usually being considered the best.
A widely used ceremonial method of steeping oolongs in Taiwan and China is called gongfucha. This method uses a small steeping vessel, such as a gaiwan or Yixing clay teapot, with more tea than usual for the amount of water used. Multiple short steeps of 20 seconds to 1 minute are performed; the tea is often served in one- to two-ounce tasting cups.
Caffeine.
Oolong in general contains caffeine. Though the caffeine content in tea will vary based on terroir, when the leaf is plucked, and the production processes.
Health benefits.
A study conducted in Japan in 2001 by the Archives of Dermatology found that consuming oolong tea may help eczema and other inflammatory skin conditions including psoriasis.

</doc>
<doc id="22709" url="http://en.wikipedia.org/wiki?curid=22709" title="Okapi">
Okapi

The okapi ("Okapia johnstoni"), is a giraffid artiodactyl mammal native to the northeast of the Democratic Republic of the Congo in Central Africa. Although the okapi bears striped markings reminiscent of zebras, it is most closely related to the giraffe. The okapi and the giraffe are the only living members of the family Giraffidae. The okapi stands 1.5 m tall at the shoulder and has an average body length of about 2.5 m. Its weight ranges from 200 to. It has a long neck, and large and flexible ears. Its coat is a chocolate to reddish brown, much in contrast with the white horizontal stripes and rings on the legs and white ankles. Male okapis have short, hair-covered horns called ossicones, less than 15 cm in length. Females possess hair whorls,and ossicones are absent.
Okapis are primarily diurnal but may be active for a few hours in darkness. They are essentially solitary, coming together only to breed. Okapis are herbivores, feeding on tree leaves and buds, grasses, ferns, fruits, and fungi. Rut in males and estrus in females does not depend on the season. In captivity, estrous cycles recur every 15 days. The gestational period is around 440 to 450 days long, following which usually a single calf is born. The juveniles are kept in hiding, and nursing takes place infrequently. Juveniles start taking solid food from three months, and weaning takes place at six months.
Okapis inhabit canopy forests at altitudes of 500 -. They are endemic to the tropical forests of the Democratic Republic of the Congo, where they occur across the central, northern and eastern regions. The International Union for the Conservation of Nature and Natural Resources (IUCN) classifies the okapi as Endangered. Major threats include habitat loss due to logging and human settlement. Extensive hunting for bushmeat and skin and illegal mining have also led to a decline in populations. The Okapi Conservation Project was established in 1987 to protect okapi populations.
Etymology and taxonomy.
The scientific name of the okapi is "Okapia johnstoni". It was first described by British zoologist Ray Lankester in 1901. The generic name "Okapia" derives from the Lese Karo name "o'api", while the specific name ("johnstoni") is in recognition of the British Governor of Uganda, Sir Harry Johnston, who first acquired an okapi specimen for science from the Ituri Forest while repatriating a group of Pygmies to the Belgian Congo. The animal was brought to prominent European attention by speculation on its existence found in press reports covering Henry Morton Stanley's journeys in 1887. Remains of a carcass were later sent to London by the English adventurer and colonial administrator Harry Johnston and became a media event in 1901. 
In 1901, zoologist Philip Sclater presented a painting of the okapi before the Zoological Society of London that depicted its physical features with some clarity. There was much confusion regarding the taxonomical status of this newly discovered animal. Sir Harry Johnston himself called it a "Helladotherium", or a relative of other extinct giraffids. Based on the description of the okapi by Pygmies, who referred to it as a "horse", Sclater named the species "Equus johnstoni". Subsequently, Lankester declared that the okapi represented an unknown genus of Giraffidae, which he placed in its own genus "Okapia", and assigned the name "Okapia johnstoni" to the species.
In 1902, Swiss zoologist Charles Immanuel Forsyth Major suggested the inclusion of "O. johnstoni" in the extinct giraffid subfamily Palaeotraginae. However, the species was placed in its own subfamily Okapiinae, by Swedish palaeontologist Birger Bohlin in 1926, mainly due to the lack of a cingulum, a major feature of the palaeotragids. In 1986, "Okapia" was finally established as a sister genus of "Giraffa" on the basis of cladistic analysis. The two genera together with "Palaeotragus" constitute the tribe Giraffini.
Evolution.
The earliest members of Giraffidae first appeared in the Early Miocene in Africa, having diverged from the superficially deer-like climacoceratids. Giraffids spread into Europe and Asia by the middle Miocene in a first radiation. Another radiation began in the Pliocene but was terminated by a decline in diversity in the Pleistocene. Several important primitive giraffids existed more or less contemporaneously in the Miocene (23-10 million years ago), including "Canthumeryx", "Giraffokeryx", "Palaeotragus" and "Samotherium". According to palaeontologist and author Kathleen Hunt, "Samotherium" split into "Okapia" (18 million years ago) and "Giraffa" (12 million years ago). However, another author J. D. Skinner argued that "Canthumeryx" gave rise to the okapi and giraffe through the latter three genera and that the okapi is the extant form of "Palaeotragus". The okapi is sometimes referred to as an example of a living fossil, as it has existed as a species over a long geological time period, and morphologically resembles more primitive forms (e.g. "Samotherium").
Characteristics.
The okapi is a medium-sized giraffid, standing 1.5 m tall at the shoulder. Its average body length is about 2.5 m and its weight ranges from 200 to. It has a long neck, and large and flexible ears. The coat is a chocolate to reddish brown, much in contrast with the white horizontal stripes and rings on the legs and white ankles. The striking stripes make it resemble a zebra. These features serve as an effective camouflage amidst dense vegetation. The face, throat and chest are greyish white. Interdigital glands are present on all four feet, and are slightly larger on the front feet. Male okapis have short, hair-covered horns called ossicones, less than 15 cm in length. The okapi exhibits sexual dimorphism, with females 4.2 cm taller on average, slightly redder and lacking prominent horns, instead possessing hair whorls.
The okapi shows several adaptations to its tropical habitat. The large number of rod cells in the retina facilitate night vision, and there is an efficient olfactory system. The large auditory bullae lead to a strong sense of hearing. The dental formula of the okapi is 0.0.3.33.1.3.3. Teeth are low-crowned, fine-cusped and efficiently cut tender foliage. The large caecum and colon help in microbial digestion, and a quick rate of food passage allows for lower cell wall digestion than in other ruminants.
The okapi can be easily distinguished from its nearest extant relative, the giraffe. It is much smaller and shares more external similarities with the deer and bovids than with the giraffe. While both sexes possess horns in the giraffe, only males bear horns in the okapi. The okapi has large palatine sinuses, unique among the giraffids. Morphological similarities shared between the giraffe and the okapi include a similar gait - both use a pacing gait, stepping simultaneously with the front and the hind leg on the same side of the body, unlike other ungulates that walk by moving alternate legs on either side of the body - and a long black tongue (longer in the okapi) useful in plucking buds and leaves as well as for grooming.
Ecology and behaviour.
Okapis are primarily diurnal but may be active for a few hours in darkness. They are essentially solitary, coming together only to breed. They have overlapping home ranges and typically occur at densities of about 0.6 animals per square kilometre. Male home ranges average 13 km2 while female home ranges average 3 -. Males migrate continuously, while females are sedentary. Males often mark territories and bushes with their urine, while females use common defecation sites. Grooming is a common practice, focused at the earlobes and the neck. Okapis often rub their neck against trees, leaving a brown exudate. 
The male is protective of his territory, but allows females to pass through the domain to forage. Males visit female home ranges at the time of breeding. Although generally tranquil, the okapi can kick and butt with its head to show aggression. As the vocal cords are poorly developed, vocal communication is mainly restricted to three sounds - "chuff" (contact calls used by both sexes), "moan" (by females during courtship) and "bleat" (by infants under stress). Individuals may engage in Flehmen response, a visual expression in which the animals curls back its upper lips, displays the teeth and inhales through the mouth for a few seconds. The leopard is the main predator of the okapi.
Diet.
Okapis are herbivores, feeding on tree leaves and buds, grasses, ferns, fruits, and fungi. They prefer to feed in treefall gaps. The staple food comprises shrubs and lianas. The main constituents of the diet are woody, dicotyledonous species; monocotyledonous plants are not eaten regularly. In the Ituri forest, the okapi feeds mainly upon the plant families Acanthaceae, Ebenaceae, Euphorbiaceae, Flacourtiaceae, Loganiaceae, Rubiaceae and Violaceae.
Reproduction.
Female okapis become sexually mature when about one-and-a-half year old, while males reach maturity after two years. Rut in males and estrus in females does not depend on the season. In captivity, estrus cycles recur every 15 days. The male and the female begin courtship by circling, smelling and licking each other. The male shows his dominance by extending his neck, tossing his head and protruding one leg forward. This is followed by mounting and copulation.
The gestational period is around 440 to 450 days long, following which usually a single calf is born, weighing 14 -. The udder of the pregnant female starts swelling two months before parturition, and vulval discharges may occur. Parturition takes 3–4 hours, and the female stands throughout this period, though she may rest during brief intervals. The mother consumes the afterbirth, and extensively grooms the infant. The milk of the female is very rich in proteins and has low fat content. As in other ruminants, the infant can stand within 30 minutes of birth. Although generally similar to adults, newborn calves have false eyelashes, a long dorsal mane and long white hairs in the stripes. These features gradually disappear and give way to the general appearance within a year. The juveniles are kept in hiding, and nursing takes place infrequently. The growth rate of calves is appreciably high in the first few months of birth, after which it gradually declines. Juveniles start taking solid food from three months, and weaning takes place at six months. Horn development in males takes one year after birth. The okapi's average lifespan is 20 to 30 years.
Habitat and distribution.
Okapis inhabit canopy forests at altitudes of 500 -. They are endemic to the tropical forests of the Democratic Republic of the Congo. They do not occur in gallery forests, habitats disturbed by human settlement and swamp forests, but may occasionally use seasonally inundated areas. In the wet season, they visit rocky inselbergs that offer forage uncommon elsewhere. A study found that the population density of the okapi averaged 0.53 animals per square kilometre in mixed "Cynometera" forests.
The okapi occurs across central, northern and eastern Democratic Republic of the Congo, and north and east of the Congo river. The species ranges from the Maiko forest northward to the Ituri forest, then through the river basins of the Rubi, Lake Tele and Ebola to the west and the Ubangi river further north. Smaller populations exist west and south of the Congo river. They are also common in the Wamba and Epulu areas. The okapi is extinct in Uganda.
Threats and conservation.
The International Union for the Conservation of Nature and Natural Resources (IUCN) classifies the okapi as Endangered. It is fully protected under Congolese law. The Okapi Wildlife Reserve and Maiko National Park support significant populations of the okapi, though there has been a steady decline in numbers due to several threats. Other areas of occurrence are the Rubi Tele Hunting Reserve and the Abumombanzi Reserve. Major threats include habitat loss due to logging and human settlement. Extensive hunting for bushmeat and skin and illegal mining have also led to population declines. A threat that has emerged quite recently is the presence of illegal armed groups around protected areas, inhibiting conservation and monitoring actions. A small population occurs north of the Virunga National Park, but is bereft of protection due to the presence of armed groups in the vicinity. In June 2012, a gang of poachers attacked the headquarters of the Okapi Wildlife Reserve, killing six guards and other staff as well as 13 of the captive okapi.
The Okapi Conservation Project, established in 1987, works towards the conservation of the okapi as well as the growth of the indigenous Mbuti people. In November 2011, the White Oak Conservation center and Jacksonville Zoo and Gardens hosted an international meeting of the Okapi Species Survival Plan (SSP) and the Okapi European Endangered Species Programme (EEP) at Jacksonville, which was attended by representatives from zoos from the USA, Europe and Japan. The aim was to discuss the management of captive okapis and arrange support for okapi conservation. Many zoos in North America and Europe currently have okapis in captivity.

</doc>
<doc id="22710" url="http://en.wikipedia.org/wiki?curid=22710" title="Ovary">
Ovary

The ovary (From Latin: "ovarium", literally "egg" or "nut") is an ovum-producing reproductive organ, often found in pairs as part of the vertebrate female reproductive system. Ovaries in female individuals are analogous to testes in male individuals, in that they are both gonads and endocrine glands. Although ovaries occur in a wide variety of animals, both vertebrate and invertebrate, this article is primarily about ovaries in humans.
Structure.
In the case of human ovaries, each one is whitish in color and located alongside the lateral wall of the uterus in a region called the ovarian fossa. The fossa usually lies beneath the external iliac artery and in front of the ureter and the internal iliac artery. It is about 4 cm x 3 cm x 2 cm in size.
Usually each ovary takes turns releasing an egg each month; however, if there was a case where one ovary was absent or dysfunctional then the other ovary would continue providing eggs to be released.
Ligaments.
In humans the paired ovaries lie within the pelvic cavity, on either side of the uterus, to which they are attached via a fibrous cord called the ovarian ligament. The ovaries are uncovered in the peritoneal cavity but are tethered to the body wall via the suspensory ligament of the ovary. The part of the broad ligament of the uterus that covers the ovary is known as the mesovarium. The ovary is thus considered an intraperitoneal organ.
Extremities.
There are two extremities to the ovary:
Histology.
The ovary also contains blood vessels and lymphatics.
Function.
Gamete production.
The ovaries are the site of production and periodical release of egg cells, the female gametes. In the ovaries, the developing egg cell (or oocyte) grows within the environment provided by follicles. Follicles are composed of different types and number of cells according to the stage of their maturation, and their size is indicative of the stage of oocyte development.:833
When the oocyte finishes its maturation in the ovary, a surge of luteinizing hormone secreted by the pituitary gland stimulates the release of the oocyte through the rupture of the follicle, a process called ovulation. The follicle remains functional and reorganizes into a corpus luteum, which secretes progesterone in order to prepare the uterus for an eventual implantation of the embryo.:839
Endocrine function.
Ovaries secrete estrogen, testosterone and progesterone. In women, fifty percent of testosterone is produced by the ovaries and adrenal glands and released directly into the blood stream. Estrogen is responsible for the appearance of secondary sex characteristics for females at puberty and for the maturation and maintenance of the reproductive organs in their mature functional state. Progesterone prepares the uterus for pregnancy, and the mammary glands for lactation. Progesterone functions with estrogen by promoting menstrual cycle changes in the endometrium.
Ovarian aging.
As women age, they experience a decline in reproductive performance leading to menopause. This decline is tied to a decline in the number of ovarian follicles. Although about 1 million oocytes are present at birth in the human ovary, only about 500 (about 0.05%) of these ovulate, and the rest are wasted. The decline in ovarian reserve appears to occur at a constantly increasing rate with age, and leads to nearly complete exhaustion of the reserve by about age 52. As ovarian reserve and fertility decline with age, there is also a parallel increase in pregnancy failure and meiotic errors resulting in chromosomally abnormal conceptions.
Women with an inherited mutation in the DNA repair gene BRCA1 undergo menopause prematurely, suggesting that naturally occurring DNA damages in oocytes are repaired less efficiently in these women, and this inefficiency leads to early reproductive failure. The BRCA1 protein plays a key role in a type of DNA repair termed homologous recombinational repair that is the only known cellular process that can accurately repair DNA double-strand breaks. Titus et al. showed that DNA double-strand breaks accumulate with age in humans and mice in primordial follicles. Primodial follicles contain oocytes that are at an intermediate (prophase I) stage of meiosis. Meiosis is the general process in eukaryotic organisms by which germ cells are formed, and it is likely an adaptation for removing DNA damages, especially double-strand breaks, from germ line DNA. (see Meiosis and Origin and function of meiosis). Homologous recombinational repair is especially promoted during meiosis. Titus et al. also found that expression of 4 key genes necessary for homologous recombinational repair of DNA double-strand breaks (BRCA1, MRE11, RAD51 and ATM) decline with age in the oocytes of humans and mice. They hypothesized that DNA double-strand break repair is vital for the maintenance of oocyte reserve and that a decline in efficiency of repair with age plays a key role in ovarian aging.
Clinical significance.
Ovarian diseases can be classified as endocrine disorders or as a disorders of the reproductive system.
If the egg fails to release from the follicle in the ovary an ovarian cyst may form. Small ovarian cysts are common in healthy women. Some women have more follicles than usual (polycystic ovary syndrome), which inhibits the follicles to grow normally and this will cause cycle irregularities.
Other conditions include:
Society and culture.
Cryopreservation.
Cryopreservation of ovarian tissue, often called "ovarian tissue cryopreservation", is of interest to women who want to preserve their reproductive function beyond the natural limit, or whose reproductive potential is threatened by cancer therapy, for example in hematologic malignancies or breast cancer. The procedure is to take a part of the ovary and carry out slow freezing before storing it in liquid nitrogen whilst therapy is undertaken. Tissue can then be thawed and implanted near the fallopian, either orthotopic (on the natural location) or heterotopic (on the abdominal wall), where it starts to produce new eggs, allowing normal conception to take place. A study of 60 procedures concluded that ovarian tissue harvesting appears to be safe. The ovarian tissue may also be transplanted into mice that are immunocompromised (SCID mice) to avoid graft rejection, and tissue can be harvested later when mature follicles have developed.
Other animals.
Ovaries of some kind are found in the female reproductive system of many animals that employ sexual reproduction, including invertebrates. However, they develop in a very different way in most invertebrates than they do in vertebrates, and are not truly homologous.
Many of the features found in human ovaries are common to all vertebrates, including the presence of follicular cells, tunica albuginea, and so on. However, many species produce a far greater number of eggs during their lifetime than do humans, so that, in fish and amphibians, there may be hundreds, or even millions of fertile eggs present in the ovary at any given time. In these species, fresh eggs may be developing from the germinal epithelium throughout life. Corpora lutea are found only in mammals, and in some elasmobranch fish; in other species, the remnants of the follicle are quickly resorbed by the ovary. In birds, reptiles, and monotremes, the egg is relatively large, filling the follicle, and distorting the shape of the ovary at maturity.
Amphibians and reptiles have no ovarian medulla; the central part of the ovary is a hollow, lymph-filled space.
The ovary of teleosts is also often hollow, but in this case, the eggs are shed into the cavity, which opens into the oviduct. Certain nematodes of the genus "Philometra" are parasitic in the ovary of marine fishes and can be spectacular, with females as long as 40 cm, coiled in the ovary of a fish half this length. These nematodes never parasitize humans.
Although most normal female vertebrates have two ovaries, this is not the case in all species. In most birds and in platypuses, the right ovary never matures, so that only the left is functional. (Exceptions include the Kiwi and some, but not all raptors, in which both ovaries persist.) In some elasmobranchs, only the right ovary develops fully. In the primitive jawless fish, and some teleosts, there is only one ovary, formed by the fusion of the paired organs in the embryo.

</doc>
<doc id="22713" url="http://en.wikipedia.org/wiki?curid=22713" title="Opium">
Opium

Opium (poppy tears, "lachryma papaveris") is the dried latex obtained from the opium poppy ("Papaver somniferum"). Opium latex contains approximately 12% of the analgesic alkaloid morphine, which is processed chemically to produce heroin and other synthetic opioids for medicinal use and for the illegal drug trade. The latex also contains the closely related opiates codeine and thebaine and non-analgesic alkaloids such as papaverine and noscapine. The traditional, labor-intensive method of obtaining the latex is to scratch ("score") the immature seed pods (fruits) by hand; the latex leaks out and dries to a sticky yellowish residue that is later scraped off, and dehydrated. The word "meconium" (derived from the Greek for "opium-like", but now used to refer to infant stools) historically referred to related, weaker preparations made from other parts of the opium poppy or different species of poppies.
The production of opium itself has not changed since ancient times. Through selective breeding of the "Papaver somniferum" plant, the content of the phenanthrene alkaloids morphine, codeine, and to a lesser extent thebaine, has been greatly increased. In modern times, much of the thebaine, which often serves as the raw material for the synthesis for hydrocodone, hydromorphone, and other semisynthetic opiates, originates from extracting "Papaver orientale" or "Papaver bracteatum".
Opium for illegal use is often converted into heroin, which is less bulky, making it easier to smuggle, and which multiplies its potency to approximately twice that of morphine.
History.
Cultivation of opium poppies for food, anaesthesia, and ritual purposes dates back to at least the Neolithic Age (new stone age). The Sumerian, Assyrian, Egyptian, Indian, Minoan, Greek, Roman, Persian and Arab Empires all made widespread use of opium, which was the most potent form of pain relief then available, allowing ancient surgeons to perform prolonged surgical procedures. Opium is mentioned in the most important medical texts of the ancient world, including the Ebers Papyrus and the writings of Dioscorides, Galen, and Avicenna. Widespread medical use of unprocessed opium continued through the American Civil War before giving way to morphine and its successors, which could be injected at a precisely controlled dosage.
In China, recreational use began in the 15th century, but was limited by its rarity and expense. Opium trade became more regular by the 17th century, when it was mixed with tobacco for smoking, and addiction was first recognized. Opium prohibition in China began in 1729, yet was followed by nearly two centuries of increasing opium use. China had a positive balance sheet in trading with the British, which led to a decrease of the British silver stocks. Therefore, the British tried to encourage Chinese opium use to enhance their balance, and they delivered it from Indian provinces under British control. In India, its cultivation, as well as the manufacture and traffic to China, were subject to the East India Company (EIC), as a strict monopoly of the British government. There was an extensive and complicated system of EIC agencies involved in the supervision and management of opium production and distribution in India. A massive destruction of opium by an emissary of the Chinese Daoguang Emperor in an attempt to stop opium imports, led to the First Opium War (1839–1842), in which Britain defeated China. After 1860, opium use continued to increase with widespread domestic production in China. By 1905, an estimated 25% of the male population were regular consumers of the drug. Recreational use of opium elsewhere in the world remained rare into late in the 19th century, as indicated by ambivalent reports of opium usage.
Global regulation of opium began with the stigmatization of Chinese immigrants and opium dens in San Francisco, California, leading rapidly from town ordinances in the 1870s to the formation of the International Opium Commission in 1909. During this period, the portrayal of opium in literature became squalid and violent, British opium trade was largely supplanted by domestic Chinese production, purified morphine and heroin became widely available for injection, and patent medicines containing opiates reached a peak of popularity. Opium was prohibited in many countries during the early 20th century, leading to the modern pattern of opium production as a precursor for illegal recreational drugs or tightly regulated legal prescription drugs. Illicit opium production, now dominated by Afghanistan, was decimated in 2000, when production was banned by the Taliban, but has increased steadily since the fall of the Taliban in 2001 and over the course of the war in Afghanistan. Worldwide production in 2006 was 6610 metric tons—about one-fifth the level of production in 1906.
Ancient use.
Opium has been actively collected since prehistoric times, and may be the soma plant ubiquitously mentioned in the Rig Veda. Though western scholars typically date the text at 1500 BCE, Indian scholars maintain that the verses and the history contained in them have been orally transmitted thousands of years before. "Soma" is Vedic Sanskrit for moon, describing both the shape of the bulb and its nocturnal juice emission, which in ancient times would have been visible by moonlight only. A common name for males in Afghanistan is "Redey", which in Pashto means "poppy". This term may be derived from the Sanskrit words "rddhi" and "hrdya", which mean "magical", "a type of medicinal plant", and "heart-pleasing", respectively. The upper South Asian belt of Afghanistan, Pakistan, northern India, and Burma still account for the world's largest supply of opium.
At least 17 finds of "Papaver somniferum" from Neolithic settlements have been reported throughout Switzerland, Germany, and Spain, including the placement of large numbers of poppy seed capsules at a burial site (the "Cueva de los Murciélagos", or "Bat Cave", in Spain), which have been carbon-14 dated to 4200 BCE. Numerous finds of "P. somniferum" or "P. setigerum" from Bronze Age and Iron Age settlements have also been reported.
The first known cultivation of opium poppies was in Mesopotamia, approximately 3400 BCE, by Sumerians, who called the plant "hul gil", the "joy plant". Tablets found at Nippur, a Sumerian spiritual center south of Baghdad, described the collection of poppy juice in the morning and its use in production of opium. Cultivation continued in the Middle East by the Assyrians, who also collected poppy juice in the morning after scoring the pods with an iron scoop; they called the juice "aratpa-pal", possibly the root of "Papaver". Opium production continued under the Babylonians and Egyptians.
Opium was used with poison hemlock to put people quickly and painlessly to death, but it was also used in medicine. The Ebers Papyrus, "circa" 1500 BCE, describes a way to "stop a crying child" using grains of the poppy plant strained to a pulp. "Spongia somnifera", sponges soaked in opium, were used during surgery. The Egyptians cultivated "opium thebaicum" in famous poppy fields around 1300 BCE. Opium was traded from Egypt by the Phoenicians and Minoans to destinations around the Mediterranean Sea, including Greece, Carthage, and Europe. By 1100 BCE, opium was cultivated on Cyprus, where surgical-quality knives were used to score the poppy pods, and opium was cultivated, traded, and smoked. Opium was also mentioned after the Persian conquest of Assyria and Babylonian lands in the 6th century BCE.
From the earliest finds, opium has appeared to have ritual significance, and anthropologists have speculated ancient priests may have used the drug as a proof of healing power. In Egypt, the use of opium was generally restricted to priests, magicians, and warriors, its invention is credited to Thoth, and it was said to have been given by Isis to Ra as treatment for a headache. A figure of the Minoan "goddess of the narcotics", wearing a crown of three opium poppies, "circa" 1300 BCE, was recovered from the Sanctuary of Gazi, Crete, together with a simple smoking apparatus. The Greek gods Hypnos (Sleep), Nyx (Night), and Thanatos (Death) were depicted wreathed in poppies or holding them. Poppies also frequently adorned statues of Apollo, Asklepios, Pluto, Demeter, Aphrodite, Kybele and Isis, symbolizing nocturnal oblivion.
Islamic societies (500–1500 AD).
As the power of the Roman Empire declined, the lands to the south, and east of the Mediterranean Sea became incorporated into the Islamic Empires. Some Muslims believe "hadiths", such as in "Sahih Bukhari", prohibits every intoxicating substance, though the use of intoxicants in medicine has been widely permitted by scholars. Dioscorides' five-volume "De Materia Medica", the precursor of pharmacopoeias, remained in use (with some improvements in Arabic versions) from the 1st to 16th centuries, and described opium and the wide range of its uses prevalent in the ancient world.
Between 400 and 1200 AD, Arab traders introduced opium to China. The Persian physician Muhammad ibn Zakariya al-Razi ("Rhazes", 845–930 AD) maintained a laboratory and school in Baghdad, and was a student and critic of Galen; he made use of opium in anesthesia and recommended its use for the treatment of melancholy in "Fi ma-la-yahdara al-tabib", "In the Absence of a Physician", a home medical manual directed toward ordinary citizens for self-treatment if a doctor was not available.
The renowned Andalusian ophthalmologic surgeon Abu al-Qasim al-Zahrawi ("Abulcasis", 936–1013 AD) relied on opium and mandrake as surgical anaesthetics and wrote a treatise, "al-Tasrif", that influenced medical thought well into the 16th century.
The Persian physician Abū ‘Alī al-Husayn ibn Sina ("Avicenna") described opium as the most powerful of the stupefacients, in comparison to mandrake and other highly effective herbs, in "The Canon of Medicine". The text lists medicinal effects of opium, such as analgesia, hypnosis, antitussive effects, gastrointestinal effects, cognitive effects, respiratory depression, neuromuscular disturbances, and sexual dysfunction. It also refers to opium's potential as a poison. Avicenna describes several methods of delivery and recommendations for doses of the drug. This classic text was translated into Latin in 1175 and later into many other languages and remained authoritative into the 17th century. Şerafeddin Sabuncuoğlu used opium in the 14th-century Ottoman Empire to treat migraine headaches, sciatica, and other painful ailments.
Reintroduction to Western medicine.
Manuscripts of Pseudo-Apuleius's 5th-century work from the 10th and 11th centuries refer to the use of wild poppy "Papaver agreste" or "Papaver rhoeas" (identified as "P. silvaticum") instead of "P. somniferum" for inducing sleep and relieving pain.
The use of Paracelsus' laudanum was introduced to Western medicine in 1527, when Philippus Aureolus Theophrastus Bombastus von Hohenheim, better known by the name Paracelsus, returned from his wanderings in Arabia with a famous sword, within the pommel of which he kept "Stones of Immortality" compounded from opium thebaicum, citrus juice, and "quintessence of gold." The name "Paracelsus" was a pseudonym signifying him the equal or better of Aulus Cornelius Celsus, whose text, which described the use of opium or a similar preparation, had recently been translated and reintroduced to medieval Europe. "The Canon of Medicine", the standard medical textbook Paracelsus burned in a public bonfire three weeks after being appointed professor at the University of Basel, also described the use of opium, though many Latin translations were of poor quality. "Laudanum" was originally the 16th-century term for a medicine associated with a particular physician that was widely well-regarded, but became standardized as "tincture of opium", a solution of opium in ethanol, which Paracelsus has been credited with developing. During his lifetime, Paracelsus was viewed as an adventurer who challenged the theories and mercenary motives of contemporary medicine with dangerous chemical therapies, but his therapies marked a turning point in Western medicine. In the 17th century, laudanum was recommended for pain, sleeplessness, and diarrhea by Thomas Sydenham, the renowned "father of English medicine" or "English Hippocrates", to whom is attributed the quote, "Among the remedies which it has pleased Almighty God to give to man to relieve his sufferings, none is so universal and so efficacious as opium." 
Use of opium as a cure-all was reflected in the formulation of mithridatium described in the 1728 "Chambers Cyclopedia", which included true opium in the mixture. Subsequently, laudanum became the basis of many popular patent medicines of the 19th century.
During the 18th century, opium was found to be a good remedy for nervous disorders. Due to its sedative and tranquilizing properties, it was used to quiet the minds of those with psychosis, help with people who were considered insane, and also to help treat patients with insomnia. However, despite its medicinal values in these cases, it was noted that in cases of psychosis, it could cause anger or depression, and due to the drug's euphoric effects, it could cause depressed patients to become more depressed after the effects wore off because they would get used to being high.
The standard medical use of opium persisted well into the 19th century. US president William Henry Harrison was treated with opium in 1841, and in the American Civil War, the Union Army used 2.8 million ounces of opium tincture and powder and about 500,000 opium pills. During this time of popularity, users called opium "God's Own Medicine."
Recreational use in Europe, the Middle East and the US (15th to 19th centuries).
Opium is said to have been used for recreational purposes from the 14th century onwards in Muslim societies. Testimonies of historians, diplomats, religious scholars, intellectuals and travellers, Ottoman and European, confirm, from the 16th to the 19th centuries, Anatolian opium was eaten in Constantinople as much as it was exported to Europe. In 1573, for instance, a Venetian visitor to the Ottoman Empire observed many of the Turkish natives of Constantinople regularly drank a "certain black water made with opium" that makes them feel good, but to which they become so addicted, if they try to go without, they will "quickly die". From eating it, dervishes were said to draw ecstasy, soldiers courage, and others bliss and voluptuousness. Indeed, Turkey supplied the West with opium long before China. In his "Confessions of an English Opium-Eater" (1821, p. 188), it is Ottoman, not Chinese, addicts about whom Thomas de Quincey writes: "I question whether any Turk, of all that ever entered the paradise of opium-eaters, can have had half the pleasure I had."
Extensive textual and pictorial sources also show that poppy cultivation and opium consumption were widespread in Safavid Iran and Mughal India.
The most important reason for the increase in opiate consumption in the United States during the 19th century was the prescribing and dispensing of legal opiates by physicians and pharmacists to women with "female problems" (mostly to relieve menstrual pain). Between 150,000 and 200,000 opiate addicts lived in the United States in the late 19th century and between two-thirds and three-quarters of these addicts were women.
Recreational use in China.
The earliest clear description of the use of opium as a recreational drug in China came from Xu Boling, who wrote in 1483 that opium was "mainly used to aid masculinity, strengthen sperm and regain vigor", and that it "enhances the art of alchemists, sex and court ladies". He also described an expedition sent by the Ming dynasty Chenghua Emperor in 1483 to procure opium for a price "equal to that of gold" in Hainan, Fujian, Zhejiang, Sichuan and Shaanxi, where it is close to the western lands of Xiyu. A century later, Li Shizhen listed standard medical uses of opium in his renowned "Compendium of Materia Medica" (1578), but also wrote that "lay people use it for the art of sex", in particular the ability to "arrest seminal emission". This association of opium with sex continued in China until the end of the 19th century.
Opium smoking began as a privilege of the elite and remained a great luxury into the early 19th century. However, by 1861, Wang Tao wrote that opium was used even by rich peasants, and even a small village without a rice store would have a shop where opium was sold.
Smoking of opium came on the heels of tobacco smoking and may have been encouraged by a brief ban on the smoking of tobacco by the Ming emperor. The prohibition ended in 1644 with the coming of the Qing dynasty, which encouraged smokers to mix in increasing amounts of opium. In 1705, Wang Shizhen wrote, "nowadays, from nobility and gentlemen down to slaves and women, all are addicted to tobacco." Tobacco in that time was frequently mixed with other herbs (this continues with clove cigarettes to the modern day), and opium was one component in the mixture. Tobacco mixed with opium was called "madak" (or "madat") and became popular throughout China and its seafaring trade partners (such as Taiwan, Java, and the Philippines) in the 17th century. In 1712, Engelbert Kaempfer described addiction to "madak": "No commodity throughout the Indies is retailed with greater profit by the Batavians than opium, which [its] users cannot do without, nor can they come by it except it be brought by the ships of the Batavians from Bengal and Coromandel."
Fueled in part by the 1729 ban on "madak", which at first effectively exempted pure opium as a potentially medicinal product, the smoking of pure opium became more popular in the 18th century. In 1736, the smoking of pure opium was described by Huang Shujing, involving a pipe made from bamboo rimmed with silver, stuffed with palm slices and hair, fed by a clay bowl in which a globule of molten opium was held over the flame of an oil lamp. This elaborate procedure, requiring the maintenance of pots of opium at just the right temperature for a globule to be scooped up with a needle-like skewer for smoking, formed the basis of a craft of "paste-scooping" by which servant girls could become prostitutes as the opportunity arose.
Chinese diaspora.
Beginning in 19th-century China, famine and political upheaval, as well as rumors of wealth to be had in nearby Southeast Asia, led to the Chinese Diaspora. Chinese emigrants to cities such as San Francisco, London, and New York brought with them the Chinese manner of opium smoking and the social traditions of the opium den. The Indian Diaspora distributed opium-eaters in the same way, and both social groups survived as "lascars" (seamen) and "coolies" (manual laborers). French sailors provided another major group of opium smokers, having contracted the habit in French Indochina, where the drug was promoted by the colonial government as a monopoly and source of revenue. Among white Europeans, opium was more frequently consumed as laudanum or in patent medicines. Britain's All-India Opium Act of 1878 formalized social distinctions, limiting recreational opium sales to registered Indian opium-eaters and Chinese opium-smokers and prohibiting its sale to workers from Burma. Likewise, American law sought to contain addiction to immigrants by prohibiting Chinese from smoking opium in the presence of a white man.
Because of the low social status of immigrant workers, contemporary writers and media had little trouble portraying opium dens as seats of vice, white slavery, gambling, knife- and revolver-fights, a source for drugs causing deadly overdoses, with the potential to addict and corrupt the white population. By 1919, anti-Chinese riots attacked Limehouse, the Chinatown of London. Chinese men were deported for playing keno and sentenced to hard labor for opium possession. Both the immigrant population and the social use of opium fell into decline. Yet despite lurid literary accounts to the contrary, 19th-century London was not a hotbed of opium smoking. The total lack of photographic evidence of opium smoking in Britain, as opposed to the relative abundance of historical photos depicting opium smoking in North America and France, indicates the infamous Limehouse opium-smoking scene was little more than fantasy on the part of British writers of the day, who were intent on scandalizing their readers while drumming up the threat of the "yellow peril".
Prohibition and conflict in China.
Opium prohibition began in 1729, when Emperor Yongzheng of the Qing Dynasty, disturbed by "madak" smoking at court and carrying out the government's role of upholding Confucian virtue, officially prohibited the sale of opium, except for a small amount for medicinal purposes. The ban punished sellers and opium den keepers, but not users of the drug. Opium was banned completely in 1799, and this prohibition continued until 1860.
Under the Qing Dynasty, China opened itself to foreign trade under the Canton System through the port of Guangzhou (Canton), and traders from the East India Company began visiting the port by the 1690s. Due to the growing British demand for Indian tea and the Chinese Emperor's lack of interest in British commodities other than silver, British traders resorted to trade in opium as a high-value commodity for which China was not self-sufficient. The English traders had been purchasing small amounts of opium from India for trade since Ralph Fitch first visited in the mid-16th century. Trade in opium was standardized, with production of balls of raw opium, 1.1 to 1.6 kilograms, 30% water content, wrapped in poppy leaves and petals, and shipped in chests of 60–65 kilograms (one picul).
Chests of opium were sold in auctions in Calcutta with the understanding that the independent purchasers would then smuggle it into China.
After the 1757 Battle of Plassey and 1764 Battle of Buxar, the British East India Company gained the power to act as "diwan" of Bengal, Bihar, and Odisha "(See company rule in India)". This allowed the company to exercise a monopoly over opium production and export in India, to encourage ryots to cultivate the cash crops of indigo and opium with cash advances, and to prohibit the "hoarding" of rice. This strategy led to the increase of the land tax to 50% of the value of crops and to the doubling of East India Company profits by 1777. It is also claimed to have contributed to the starvation of 10 million people in the Bengal famine of 1770. Beginning in 1773, the British government began enacting oversight of the company's operations, and in response to the Indian Rebellion of 1857, this policy culminated in the establishment of direct rule over the presidencies and provinces of British India. Bengal opium was highly prized, commanding twice the price of the domestic Chinese product, which was regarded as inferior in quality.
Some competition came from the newly independent United States, which began to compete in Guangzhou, selling Turkish opium in the 1820s. Portuguese traders also brought opium from the independent Malwa states of western India, although by 1820, the British were able to restrict this trade by charging "pass duty" on the opium when it was forced to pass through Bombay to reach an "entrepot".
Despite drastic penalties and continued prohibition of opium until 1860, opium importation rose steadily from 200 chests per year under Yongzheng to 1,000 under Qianlong, 4,000 under Jiaqing, and 30,000 under Daoguang. The illegal sale of opium became one of the world's most valuable single commodity trades and has been called "the most long continued and systematic international crime of modern times". Opium smuggling provided 15 to 20% of the British Empire's revenue and simultaneously caused scarcity of silver in China.
In response to the ever-growing number of Chinese people becoming addicted to opium, Daoguang of the Qing Dynasty took strong action to halt the import of opium, including the seizure of cargo. In 1838, the Chinese Commissioner Lin Zexu destroyed 20,000 chests of opium in Guangzhou. Given that a chest of opium was worth nearly $1,000 in 1800, this was a substantial economic loss. The British queen Victoria, not willing to replace the cheap opium with costly silver, began the First Opium War in 1840, the British winning Hong Kong and trade concessions in the first of a series of Unequal Treaties.
Following China's defeat in the Second Opium War in 1858, China was forced to legalize opium and began massive domestic production. Importation of opium peaked in 1879 at 6,700 tons, and by 1906, China was producing 85% of the world's opium, some 35,000 tons, and 27% of its adult male population regularly used opium —13.5 million people consuming 39,000 tons of opium yearly. From 1880 to the beginning of the Communist era, the British attempted to discourage the use of opium in China, but this effectively promoted the use of morphine, heroin, and cocaine, further exacerbating the problem of addiction.
Scientific evidence of the pernicious nature of opium use was largely undocumented in the 1890s, when Protestant missionaries in China decided to strengthen their opposition to the trade by compiling data which would demonstrate the harm the drug did. Faced with the problem that many Chinese associated Christianity with opium, partly due to the arrival of early Protestant missionaries on opium clippers, at the 1890 Shanghai Missionary Conference, they agreed to establish the Permanent Committee for the Promotion of Anti-Opium Societies in an attempt to overcome this problem and to arouse public opinion against the opium trade. The members of the committee were John Glasgow Kerr, MD, American Presbyterian Mission in Canton; B.C. Atterbury, MD, American Presbyterian Mission in Peking; Archdeacon Arthur E. Moule, Church Missionary Society in Shanghai; Henry Whitney, MD, American Board of Commissioners for foreign Missions in Foochow; the Rev. Samuel Clarke, China Inland Mission in Kweiyang; the Rev. Arthur Gostick Shorrock, English Baptist Mission in Taiyuan; and the Rev. Griffith John, London Mission Society in Hankow. These missionaries were generally outraged over the British government's Royal Commission on Opium visiting India but not China. Accordingly, the missionaries first organized the Anti-Opium League in China among their colleagues in every mission station in China. American missionary Hampden Coit DuBose acted as first president. This organization, which had elected national officers and held an annual national meeting, was instrumental in gathering data from every Western-trained medical doctor in China, which was then published as William Hector Park compiled "Opinions of Over 100 Physicians on the Use of Opium in China" (Shanghai: American Presbyterian Mission Press, 1899). The vast majority of these medical doctors were missionaries; the survey also included doctors who were in private practices, particularly in Shanghai and Hong Kong, as well as Chinese who had been trained in medical schools in Western countries. In England, the home director of the China Inland Mission, Benjamin Broomhall, was an active opponent of the opium trade, writing two books to promote the banning of opium smoking: "The Truth about Opium Smoking" and "The Chinese Opium Smoker". In 1888, Broomhall formed and became secretary of the Christian Union for the Severance of the British Empire with the Opium Traffic and editor of its periodical, "National Righteousness". He lobbied the British Parliament to stop the opium trade. He and James Laidlaw Maxwell appealed to the London Missionary Conference of 1888 and the Edinburgh Missionary Conference of 1910 to condemn the continuation of the trade. When Broomhall was dying, his son Marshall read to him from "The Times" the welcome news that an agreement had been signed ensuring the end of the opium trade within two years.
Official Chinese resistance to opium was renewed on September 20, 1906, with an antiopium initiative intended to eliminate the drug problem within 10 years. The program relied on the turning of public sentiment against opium, with mass meetings at which opium paraphernalia were publicly burned, as well as coercive legal action and the granting of police powers to organizations such as the Fujian Anti-Opium Society. Smokers were required to register for licenses for gradually reducing rations of the drug. Action against opium farmers centred upon a highly repressive incarnation of law enforcement in which rural populations had their property destroyed, their land confiscated and/or were publically tortured, humiliated and executed. Addicts sometimes turned to missionaries for treatment for their addiction, though many associated these foreigners with the drug trade. The program was counted as a substantial success, with a cessation of direct British opium exports to China (but not Hong Kong) and most provinces declared free of opium production. Nonetheless, the success of the program was only temporary, with opium use rapidly increasing during the disorder following the death of Yuan Shikai in 1916. Opium farming also increased after the death of Yuan Shikai, peaking in 1930 when the League of Nations singled China out as the primary source of illicit opium in East and Southeast Asia. Many local powerholders facilitated the trade during this period to finance conflicts over territory and political campaigns. In some areas food crops were eradicated to make way for opium, contributing to famines in Kweichow and Shensi Provinces between 1921 and 1923, and food deficits in other provinces .
Beginning in 1915, Chinese nationalist groups came to describe the period of military losses and Unequal Treaties as the "Century of National Humiliation", later defined to end with the conclusion of the Chinese Civil War in 1949.
In the northern provinces of Ningxia and Suiyuan in China, Chinese Muslim General Ma Fuxiang both prohibited and engaged in the opium trade. It was hoped that Ma Fuxiang would have improved the situation, since Chinese Muslims were well known for opposition to smoking opium. Ma Fuxiang officially prohibited opium and made it illegal in Ningxia, but the Guominjun reversed his policy; by 1933, people from every level of society were abusing the drug, and Ningxia was left in destitution. In 1923, an officer of the Bank of China from Baotou found out that Ma Fuxiang was assisting the drug trade in opium which helped finance his military expenses. He earned $2 million from taxing those sales in 1923. General Ma had been using the bank, a branch of the Government of China's exchequer, to arrange for silver currency to be transported to Baotou to use it to sponsor the trade.
Opium trade under the Chinese Communist Party was important to its finances in the 1940s. Peter Vladimirov's diary provided a first hand account. Chen Yung-Fa provided a detailed historical account of how the opium trade was essential to the economy of Yan'an during this period. Mitsubishi and Mitsui were involved in the opium trade during the Japanese occupation of China.
The Mao Zedong government is generally credited with eradicating both consumption and production of opium during the 1950s using unrestrained repression and social reform. Ten million addicts were forced into compulsory treatment, dealers were executed, and opium-producing regions were planted with new crops. Remaining opium production shifted south of the Chinese border into the Golden Triangle region, at times with the involvement of Western intelligence agencies. The remnant opium trade primarily served Southeast Asia, but spread to American soldiers during the Vietnam War, with 20% of soldiers regarding themselves as addicted during the peak of the epidemic in 1971. In 2003, China was estimated to have four million regular drug users and one million registered drug addicts.
Prohibition outside China.
There were no legal restrictions on the importation or use of opium in the United States until the San Francisco Opium Den Ordinance, which banned dens for public smoking of opium in 1875, a measure fueled by anti-Chinese sentiment and the perception that whites were starting to frequent the dens. This was followed by an 1891 California law requiring that narcotics carry warning labels and that their sales be recorded in a registry; amendments to the California Pharmacy and Poison Act in 1907 made it a crime to sell opiates without a prescription, and bans on possession of opium or opium pipes in 1909 were enacted.
At the US federal level, the legal actions taken reflected constitutional restrictions under the enumerated powers doctrine prior to reinterpretation of the commerce clause, which did not allow the federal government to enact arbitrary prohibitions, but did permit arbitrary taxation. Beginning in 1883, opium importation was taxed at $6 to $300 per pound, until the Opium Exclusion Act of 1909 prohibited the importation of opium altogether. In a similar manner, the Harrison Narcotics Tax Act of 1914, passed in fulfillment of the International Opium Convention of 1912, nominally placed a tax on the distribution of opiates, but served as a "de facto" prohibition of the drugs. Today, opium is regulated by the Drug Enforcement Administration under the Controlled Substances Act.
Following passage of a Colonial Australian law in 1895, Queensland's Aboriginals Protection and Restriction of the Sale of Opium Act 1897 addressed opium addiction among Aboriginal people, though it soon became a general vehicle for depriving them of basic rights by administrative regulation. By 1905 all Australian states and territories had passed similar laws making prohibitions to Opium sale. Smoking and possession was prohibited in 1908.
Hardening of Canadian attitudes toward Chinese opium users and fear of a spread of the drug into the white population led to the effective criminalization of opium for nonmedical use in Canada between 1908 and the mid-1920s.
In 1909, the International Opium Commission was founded, and by 1914, 34 nations had agreed that the production and importation of opium should be diminished. In 1924, 62 nations participated in a meeting of the Commission. Subsequently, this role passed to the League of Nations, and all signatory nations agreed to prohibit the import, sale, distribution, export, and use of all narcotic drugs, except for medical and scientific purposes. This role was later taken up by the International Narcotics Control Board of the United Nations under of the Single Convention on Narcotic Drugs, and subsequently under the Convention on Psychotropic Substances. Opium-producing nations are required to designate a government agency to take physical possession of licit opium crops as soon as possible after harvest and conduct all wholesaling and exporting through that agency.
Regulation in Britain and the United States.
Before the 1920s, regulation in Britain was controlled by the pharmacists. Pharmacists that were found to have prescribed opium for illegitimate causes and anyone found to have sold opium without proper qualifications would be prosecuted. Due to the passing of the Rolleston Act in Britain in 1926, doctors could prescribe opiates such as morphine and heroin on their own accord based on if they felt that their patients needed it. This Act came about due to the fact that Britain didn’t see people’s addiction as an indulgence, but rather as a medical problem that needed weaning off the drug rather than cutting the patient off altogether. The passing of this act put the control of opium use in the hands of medical doctors instead of pharmacists. However, as the 20th century continued, the addiction to opiates, especially heroin in young people, continued to rise and so the sale and prescription of opiates was limited to doctors in treatment centers and if these doctors were found to be prescribing opiates without just cause, then they could lose their license to practice or prescribe drugs.
The abuse of opium in the United States began in the late 19th century and was largely stigmatized with Chinese immigrants. During this time the use of opium had little negative connotation and was used freely until 1882 when a law was passed to confine opium smoking to specific dens. Until the full ban on opium based products came into effect just after the turn of the century, physicians in the US considered opium a miracle drug that could help with many ailments. Therefore, the ban on said products was more a result of negative connotations towards its use and distribution by Chinese immigrants who were heavily persecuted during this particular period in history. As the 19th century progressed however, there was a doctor by the name of Hamilton Wright that worked to decrease the use of opium in the US by submitting the Harrison Act to congress. This act put taxes and restrictions on the sale and prescription of opium, as well as trying to stigmatize the opium poppy and its derivatives as "demon drugs," to try and scare people away from them. This act and the stigma of a demon drug on opium, led to the criminalization of people that used opium-based products.
20th century historical use.
During the Communist era in Eastern Europe, poppy stalks sold in bundles by farmers were processed by users with household chemicals to make "kompot" ("Polish heroin"), and poppy seeds were used to produce "koknar", an opiate.
Obsolescence.
Globally, opium has gradually been superseded by a variety of purified, semi-synthetic, and synthetic opioids with progressively stronger effects, and by other general anesthetics. This process began in 1804, when Friedrich Wilhelm Adam Sertürner first isolated morphine from the opium poppy. The process continued until 1817, when Sertürner published the isolation of pure morphine from opium after at least thirteen years of research and a nearly disastrous trial on himself and three boys. The great advantage of purified morphine was that a patient could be treated with a known dose—whereas with raw plant material, as Gabriel Fallopius once lamented, "if soporifics are weak they do not help; if they are strong they are exceedingly dangerous." Morphine was the first pharmaceutical isolated from a natural product, and this success encouraged the isolation of other alkaloids: by 1820, isolations of noscapine, strychnine, veratrine, colchicine, caffeine, and quinine were reported. Morphine sales began in 1827, by Heinrich Emanuel Merck of Darmstadt, and helped him expand his family pharmacy into the Merck KGaA pharmaceutical company.
Codeine was isolated in 1832 by Pierre Jean Robiquet.
The use of diethyl ether and chloroform for general anesthesia began in 1846–1847, and rapidly displaced the use of opiates and tropane alkaloids from Solanaceae due to their relative safety.
Heroin, the first semi-synthetic opioid, was first synthesized in 1874, but was not pursued until its rediscovery in 1897 by Felix Hoffmann at the Bayer pharmaceutical company in Elberfeld, Germany. From 1898 to 1910 heroin was marketed as a non-addictive morphine substitute and cough medicine for children. By 1902, sales made up 5% of the company's profits, and "heroinism" had attracted media attention. Oxycodone, a thebaine derivative similar to codeine, was introduced by Bayer in 1916 and promoted as a less-addictive analgesic. Preparations of the drug such as oxycodone with paracetamol and extended release oxycodone remain popular to this day.
A range of synthetic opioids such as methadone (1937), pethidine (1939), fentanyl (late 1950s), and derivatives thereof have been introduced, and each is preferred for certain specialized applications. Nonetheless, morphine remains the drug of choice for American combat medics, who carry packs of syrettes containing 16 milligrams each for use on severely wounded soldiers. No drug has been found that can match the painkilling effect of opioids without also duplicating much of their addictive potential.
Modern production and usage.
"Papaver somniferum".
Opium poppies ("Papaver somniferum") are popular and attractive garden plants, whose flowers vary greatly in color, size and form. A modest amount of domestic cultivation in private gardens is not usually subject to legal controls. In part, this tolerance reflects variation in addictive potency. A cultivar for opium production, "Papaver somniferum L. elite", contains 91.2% morphine, codeine, and thebaine in its latex alkaloids, whereas in the latex of the condiment cultivar "Marianne", these three alkaloids total only 14.0 %. The remaining alkaloids in the latter cultivar are primarily narcotoline and noscapine.
Seed capsules can be dried and used for decorations, but they also contain morphine, codeine, and other alkaloids. These pods can be boiled in water to produce a bitter tea that induces a long-lasting intoxication "(See Poppy tea)". If allowed to mature, poppy pods (poppy straw) can be crushed and used to produce lower quantities of morphinans. In poppies subjected to mutagenesis and selection on a mass scale, researchers have been able to use poppy straw to obtain large quantities of oripavine, a precursor to opioids and antagonists such as naltrexone. Although millennia older, the production of poppy head decoctions can be seen as a quick and dirty variant of the Kábáy poppy straw process, which since its publication in 1930 has become the major method of obtaining licit opium alkaloids worldwide, as discussed under the Wikipedia Morphine article.
Poppy seeds are a common and flavorsome topping for breads and cakes. One gram of poppy seeds contains up to 33 micrograms of morphine and 14 micrograms of codeine, and the Substance Abuse and Mental Health Services Administration in the United States formerly mandated that all drug screening laboratories use a standard cutoff of 300 nanograms per milliliter in urine samples. A single poppy seed roll (0.76 grams of seeds) usually did not produce a positive drug test, but a positive result was observed from eating two rolls. A slice of poppy seed cake containing nearly five grams of seeds per slice produced positive results for 24 hours. Such results are viewed as false positive indications of drug use and were the basis of a legal defense. On November 30, 1998, the standard cutoff was increased to 2000 nanograms (two micrograms) per milliliter. Confirmation by gas chromatograpy-mass spectrometry will distinguish amongst opium and variants including poppy seeds, heroin, and morphine and codeine pharmaceuticals by measuring the morphine:codeine ratio and looking for the presence of noscapine and acetylcodeine, the latter of which is only found in illicitly produced heroin, and heroin metabolites such as 6-monoacetylmorphine.
Harvesting and processing.
When grown for opium production, the skin of the ripening pods of these poppies is scored by a sharp blade at a time carefully chosen so that rain, wind, and dew cannot spoil the exudation of white, milky latex, usually in the afternoon. Incisions are made while the pods are still raw, with no more than a slight yellow tint, and must be shallow to avoid penetrating hollow inner chambers or "loculi" while cutting into the lactiferous vessels. In Indian Subcontinent, Afghanistan, Central Asia and Iran, the special tool used to make the incisions is called a "nushtar" or "nishtar" (from Persian, meaning a lancet) and carries three or four blades three millimeters apart, which are scored upward along the pod. Incisions are made three or four times at intervals of two to three days, and each time the "poppy tears," which dry to a sticky brown resin, are collected the following morning. One acre harvested in this way can produce three to five kilograms of raw opium. In the Soviet Union, pods were typically scored horizontally, and opium was collected three times, or else one or two collections were followed by isolation of opiates from the ripe capsules. Oil poppies, an alternative strain of "P. somniferum", were also used for production of opiates from their capsules and stems. A traditional Chinese method of harvesting opium latex involved cutting off the heads and piercing them with a coarse needle then collecting the dried opium 24 to 48 hours later.
Raw opium may be sold to a merchant or broker on the black market, but it usually does not travel far from the field before it is refined into morphine base, because pungent, jelly-like raw opium is bulkier and harder to smuggle. Crude laboratories in the field are capable of refining opium into morphine base by a simple acid-base extraction. A sticky, brown paste, morphine base is pressed into bricks and sun-dried, and can either be smoked, prepared into other forms or processed into heroin.
The production of wheat in Deh Dehi has decreased dramatically since farmers had invested in the opium trade. Over some years, the opium trade has become the key economic activity in the village. A farmer reported that he can earn between 1000–2000 lakhs annual profit from poppy cultivation instead of the 20 he would make cultivating wheat. Now, all the irrigated land is given over to the poppy cultivation, and most of the men and women who worked in the livestock trade are either involved in the opium trade or work overseas.
Other methods of preparation (besides smoking), include processing into regular opium tincture ("tinctura opii"), laudanum, paregoric ("tinctura opii camphorata"), herbal wine (e.g. "vinum opii"), opium powder ("pulvis opii"), opium sirup ("sirupus opii") and opium extract ("extractum opii"). Vinum opii is made by combining sugar, white wine, cinnamon, and cloves. Opium syrup is made by combining 997.5 part sugar syrup with 2.5 parts opium extract. Opium extract ("extractum opii") finally can be made by macerating raw opium with water. To make opium extract, 20 parts water are combined with 1 part raw opium which has been boiled for 5 minutes (the latter to ease mixing).
Heroin is widely preferred because of increased potency. One study in postaddicts found heroin to be approximately 2.2 times more potent than morphine by weight with a similar duration; at these relative quantities, they could distinguish the drugs subjectively but had no preference. Heroin was also found to be twice as potent as morphine in surgical anesthesia. Morphine is converted into heroin by a simple chemical reaction with acetic anhydride, followed by a varying degree of purification. Especially in Mexican production, opium may be converted directly to "black tar heroin" in a simplified procedure. This form predominates in the U.S. west of the Mississippi. Relative to other preparations of heroin, it has been associated with a dramatically decreased rate of HIV transmission among intravenous drug users (4% in Los Angeles vs. 40% in New York) due to technical requirements of injection, although it is also associated with greater risk of venous sclerosis and necrotizing fasciitis.
Illegal production.
Opium production has fallen since 1906, when 41,000 tons were produced, but because 39,000 tons of that year's opium were consumed in China, overall usage in the rest of the world was much lower. These figures from 1906 have been criticized as overestimates. In 1980, 2,000 tons of opium supplied all legal and illegal uses. Recently, opium production has increased considerably, surpassing 5,000 tons in 2002 and reaching 8,600 tons in Afghanistan and 840 tons in the Golden Triangle in 2014. Production is expected to increase in 2015 as new, improved seeds have been brought into Afghanistan. The World Health Organization has estimated that current production of opium would need to increase fivefold to account for total global medical need. 
In 2002, the price for one kilogram of opium was $300 for the farmer, $800 for purchasers in Afghanistan, and $16,000 on the streets of Europe before conversion into heroin.
Afghanistan is currently the primary producer of the drug. After regularly producing 70% of the world's opium, Afghanistan decreased production to 74 tons per year under a ban by the Taliban in 2000, a move which cut production by 94 percent. A year later, after American and British troops invaded Afghanistan, removed the Taliban and installed the interim government, the land under cultivation leapt back to 285 sqmi, with Afghanistan supplanting Burma to become the world's largest opium producer once more. Opium production in that country has increased rapidly since, reaching an all-time high in 2006. According to DEA statistics, Afghanistan's production of oven-dried opium increased to 1,278 tons in 2002, more than doubled by 2003, and nearly doubled again during 2004. In late 2004, the U.S. government estimated that 206,000 hectares were under poppy cultivation, 4.5% of the country's total cropland, and produced 4,200 metric tons of opium, 76% of the world's supply, yielding 60% of Afghanistan's gross domestic product. In 2006, the UN Office on Drugs and Crime estimated production to have risen 59% to 407000 acre in cultivation, yielding 6,100 tons of opium, 82% of the world's supply. The value of the resulting heroin was estimated at $3.5 billion, of which Afghan farmers were estimated to have received $700 million in revenue. For farmers, the crop can be up to ten times more profitable than wheat. The price of opium is around $138 per kilo. Opium production has led to rising tensions in Afghan villages. Though direct conflict has yet to occur, the opinions of the new class of young, rich men involved in the opium trade are at odds with those of the traditional village leaders.
An increasingly large fraction of opium is processed into morphine base and heroin in drug labs in Afghanistan. Despite an international set of chemical controls designed to restrict availability of acetic anhydride, it enters the country, perhaps through its Central Asian neighbors which do not participate. A counternarcotics law passed in December 2005 requires Afghanistan to develop registries or regulations for tracking, storing, and owning acetic anhydride.
Besides Afghanistan, smaller quantities of opium are produced in Pakistan, the Golden Triangle region of Southeast Asia (particularly Burma), Colombia, Guatemala, and Mexico.
Chinese production mainly trades with and profits from North America. In 2002, they were seeking to expand through eastern United States. In the post 9/11 era, trading between borders became difficult and because new international laws were set into place, the opium trade became more diffused. Power shifted from remote to high-end smugglers and opium traders. Outsourcing became a huge factor for survival for many smugglers and opium farmers.
In South American countries, opium poppies are technically illegal, but nonetheless appear in some nurseries as ornamentals.
Legal production.
Legal opium production is allowed under the United Nations Single Convention on Narcotic Drugs and other international drug treaties, subject to strict supervision by the law enforcement agencies of individual countries. The leading legal production method is the Gregory process, whereby the entire poppy, excluding roots and leaves, is mashed and stewed in dilute acid solutions. The alkaloids are then recovered via acid-base extraction and purified. This process was developed in the UK during World War II, when wartime shortages of many essential drugs encouraged innovation in pharmaceutical processing.
Legal opium production in India is much more traditional. As of 2008, opium was collected by farmers who were licensed to grow 0.1 ha of opium poppies, who to maintain their licenses needed to sell 56 kilograms of unadulterated raw opium paste. The price of opium paste is fixed by the government according to the quality and quantity tendered. The average is around 1500 rupees ($29 US) per kilogram. Some additional money is made by drying the poppy heads and collecting poppy seeds, and a small fraction of opium beyond the quota may be consumed locally or diverted to the black market. The opium paste is dried and processed into government opium and alkaloid factories before it is packed into cases of 60 kilograms for export. Purification of chemical constituents is done in India for domestic production, but typically done abroad by foreign importers.
Legal opium importation from India and Turkey is conducted by Mallinckrodt, Noramco, Abbott Laboratories, Purdue Pharma, and Cody Laboratories Inc. in the United States, and legal opium production is conducted by GlaxoSmithKline, Johnson and Johnson, Johnson Matthey, and Mayne in Tasmania, Australia; Sanofi Aventis in France; Shionogi Pharmaceutical in Japan; and MacFarlan Smith in the United Kingdom. The UN treaty requires that every country submit annual reports to the International Narcotics Control Board, stating that year's actual consumption of many classes of controlled drugs as well as opioids and projecting required quantities for the next year. This is to allow trends in consumption to be monitored and production quotas allotted.
A recent proposal from the European Senlis Council hopes to solve the problems caused by the large quantity of opium produced illegally in Afghanistan, most of which is converted to heroin and smuggled for sale in Europe and the USA. This proposal is to license Afghan farmers to produce opium for the world pharmaceutical market, and thereby solve another problem, that of chronic underuse of potent analgesics where required within developing nations. Part of the proposal is to overcome the "80–20 rule" that requires the U.S. to purchase 80% of its legal opium from India and Turkey to include Afghanistan, by establishing a second-tier system of supply control that complements the current INCB regulated supply and demand system by providing poppy-based medicines to countries who cannot meet their demand under the current regulations. Senlis arranged a conference in Kabul that brought drug policy experts from around the world to meet with Afghan government officials to discuss internal security, corruption issues, and legal issues within Afghanistan.
In June 2007, the Council launched a "Poppy for Medicines" project that provides a technical blueprint for the implementation of an integrated control system within Afghan village-based poppy for medicine projects: the idea promotes the economic diversification by redirecting proceeds from the legal cultivation of poppy and production of poppy-based medicines (See Senlis Council). There has been criticism of the Senlis report findings by Macfarlan Smith, who argue that though they produce morphine in Europe, they were never asked to contribute to the report.
Cultivation in the UK.
In late 2006, the British government permitted the pharmaceutical company MacFarlan Smith (a Johnson Matthey company) to cultivate opium poppies in England for medicinal reasons, after Macfarlan Smith's primary source, India, decided to increase the price of export opium latex. This move is well received by British farmers, with a major opium poppy field located in Didcot, England. The British government has contradicted the Home Office's suggestion that opium cultivation can be legalized in Afghanistan for exports to the United Kingdom, helping lower poverty and internal fighting whilst helping the NHS to meet the high demand for morphine and heroin. Opium poppy cultivation in the United Kingdom does not need a license, but a license is required for those wishing to extract opium for medicinal products.
Consumption.
In the industrialized world, the United States is the world's biggest consumer of prescription opioids, with Italy one of the lowest because of tighter regulations on prescribing narcotics for pain relief. Most opium imported into the United States is broken down into its alkaloid constituents, and whether legal or illegal, most current drug use occurs with processed derivatives such as heroin rather than with unrefined opium.
Intravenous injection of opiates is most used: by comparison with injection, "dragon chasing" (heating of heroin with barbital on a piece of foil), and madak and "ack ack" (smoking of cigarettes containing tobacco mixed with heroin powder) are only 40% and 20% efficient, respectively. One study of British heroin addicts found a 12-fold excess mortality ratio (1.8% of the group dying per year). Most heroin deaths result not from overdose "per se", but combination with other depressant drugs such as alcohol or benzodiazepines.
The smoking of opium does not involve the burning of the material as might be imagined. Rather, the prepared opium is indirectly heated to temperatures at which the active alkaloids, chiefly morphine, are vaporized. In the past, smokers would use a specially designed opium pipe which had a removable knob-like pipe-bowl of fired earthenware attached by a metal fitting to a long, cylindrical stem. A small "pill" of opium about the size of a pea would be placed on the pipe-bowl, which was then heated by holding it over an opium lamp, a special oil lamp with a distinct funnel-like chimney to channel heat into a small area. The smoker would lie on his or her side in order to guide the pipe-bowl and the tiny pill of opium over the stream of heat rising from the chimney of the oil lamp and inhale the vaporized opium fumes as needed. Several pills of opium were smoked at a single session depending on the smoker's tolerance to the drug. The effects could last up to twelve hours.
In Eastern culture, opium is more commonly used in the form of paregoric to treat diarrhea. This is a weaker solution than laudanum, an alcoholic tincture which was prevalently used as a pain medication and sleeping aid. Tincture of opium has been prescribed for, among other things, severe diarrhea. Taken thirty minutes prior to meals, it significantly slows intestinal motility, giving the intestines greater time to absorb fluid in the stool.
Despite the historically negative view of opium as a cause of addiction, the use of morphine and other derivatives isolated from opium in the treatment of chronic pain has been reestablished. If given in controlled doses, modern opiates can be an effective treatment for neuropathic pain and other forms of chronic pain.
Chemical and physiological properties.
Opium contains two main groups of alkaloids. Phenanthrenes such as morphine, codeine, and thebaine are the main psychoactive constituents. Isoquinolines such as papaverine and noscapine have no significant central nervous system effects, and are not regulated under the Controlled Substances Act. Morphine is the most prevalent and important alkaloid in opium, consisting of 10%–16% of the total, and is responsible for most of its harmful effects such as lung edema, respiratory difficulties, coma, or cardiac or respiratory collapse. Morphine binds to and activates mu opioid receptor in the brain, spinal cord, stomach and intestine. Regular use can lead to drug tolerance or physical dependence. Chronic opium addicts in 1906 China or modern-day Iran consume an average of eight grams of opium daily.
Both analgesia and drug addiction are functions of the mu opioid receptor, the class of opioid receptor first identified as responsive to morphine. Tolerance is associated with the superactivation of the receptor, which may be affected by the degree of endocytosis caused by the opioid administered, and leads to a superactivation of cyclic AMP signaling. Long-term use of morphine in palliative care and management of chronic pain cannot be managed without the possible development of drug tolerance or physical dependence. Many techniques of drug treatment exist, including pharmacologically based treatments with naltrexone, methadone, or ibogaine.
Slang terms.
Some slang terms for opium include "O.P.", "hop", "midnight oil", "tar", "dope", and "Big O". ("Tar" and "dope" can also refer to heroin.) The traditional opium pipe is known as a "dream stick".
Cultural references.
There is a longstanding literary history by and about opium users. 
Towards the end of the 19th century, references to opium and opium addiction, in the contexts of crime and the foreign underclass, abound within English literature.
Opium likewise underwent a transformation in Chinese literature, becoming associated with indolence and vice by the early 20th century. 
In the 20th century, as the use of opium was eclipsed by morphine and heroin, its role in literature became more limited and often focused on issues related to its prohibition.

</doc>
<doc id="22716" url="http://en.wikipedia.org/wiki?curid=22716" title="Online algorithm">
Online algorithm

In computer science, an online algorithm is one that can process its input piece-by-piece in a serial fashion, i.e., in the order that the input is fed to the algorithm, without having the entire input available from the start. 
In contrast, an offline algorithm is given the whole problem data from the beginning and is required to output an answer which solves the problem at hand. 
Some "offline "vs" online" algorithms:
Not every "online algorithm" has an "offline" counterpart.
Explaining.
Because it does not know the whole input, an online algorithm is forced to make decisions that may later turn out not to be optimal, and the study of online algorithms has focused on the quality of decision-making that is possible in this setting. Competitive analysis formalizes this idea by comparing the relative performance of an online and offline algorithm for the same problem instance. Specifically, the competitive ratio of an algorithm, is defined as the worst-case ratio of its cost divided by the optimal cost, over all possible inputs. The competitive ratio of an online problem is the best competitive ratio achieved by an online algorithm. Intuitively, the competitive ratio of an algorithm gives a measure on the quality of solutions produced by this algorithm, while the competitive ratio of a problem shows the importance of knowing the future for this problem.
Other interpretations.
For other points of view on "online inputs to algorithms", see 
Examples.
Some "online algorithms":
Online problems redirects here.
A problem exemplifying the concepts of online algorithms is the Canadian Traveller Problem. The goal of this problem is to minimize the cost of reaching a target in a weighted graph where some of the edges are unreliable and may have been removed from the graph. However, that an edge has been removed ("failed") is only revealed to "the traveller" when she/he reaches one of the edge's endpoints. The worst case for this problem is simply that all of the unreliable edges fail and the problem reduces to the usual Shortest Path Problem. An alternative analysis of the problem can be made with the help of competitive analysis. For this method of analysis, the offline algorithm knows in advance which edges will fail and the goal is to minimize the ratio between the online and offline algorithms' performance. This problem is PSPACE-complete.
There are many formal problems that offers more than one "online algorithm" as solution:

</doc>
<doc id="22717" url="http://en.wikipedia.org/wiki?curid=22717" title="Origin">
Origin

Origin, origins, or original may refer to:

</doc>
<doc id="22718" url="http://en.wikipedia.org/wiki?curid=22718" title="Ozone">
Ozone

Ozone (systematically named 1λ1,3λ1-trioxidane and "catena"-trioxygen), or trioxygen, is an inorganic molecule with the chemical formula OO2 (also written [O3]). It is a pale blue gas with a distinctively pungent smell. It is an allotrope of oxygen that is much less stable than the diatomic allotrope O2, breaking down in the lower atmosphere to normal dioxygen. Ozone is formed from dioxygen by the action of ultraviolet light and also atmospheric electrical discharges, and is present in low concentrations throughout the Earth's atmosphere(stratosphere). In total, ozone makes up only of the atmosphere.
Ozone's odour is sharp, reminiscent of chlorine, and detectable by many people at concentrations of as little as in air. Ozone's O3 formula was determined in 1865. The molecule was later proven to have a bent structure and to be diamagnetic. In standard conditions, ozone is a pale blue gas that condenses at progressively cryogenic temperatures to a dark blue liquid and finally a violet-black solid. Ozone's instability with regard to more common dioxygen is such that both concentrated gas and liquid ozone may decompose explosively.
It is therefore used commercially only in low concentrations.
Ozone is a powerful oxidant (far more so than dioxygen) and has many industrial and consumer applications related to oxidation. This same high oxidising potential, however, causes ozone to damage mucous and respiratory tissues in animals, and also tissues in plants, above concentrations of about . This makes ozone a potent respiratory hazard and pollutant near ground level. However, the ozone layer (a portion of the stratosphere with a higher concentration of ozone, from two to eight ppm) is beneficial, preventing damaging ultraviolet light from reaching the Earth's surface, to the benefit of both plants and animals.
Nomenclature.
The trivial name "ozone" is the most commonly used and preferred IUPAC name. The systematic names "1λ1,3λ1-trioxidane" and "catena-trioxygen", valid IUPAC names, are constructed according to the substitutive and additive nomenclatures, respectively. The name "ozone" derives from "ozein" (ὄζειν), the Greek word for smell (verb), referring to ozone's distinctive smell.
In appropriate contexts, ozone can be viewed as trioxidane with two hydrogen atoms removed, and as such, "trioxidanylidene" may be used as a context-specific systematic name, according to substitutive nomenclature. By default, these names pay no regard to the radicality of the ozone molecule. In even more specific context, this can also name the non-radical singlet ground state, whereas the diradical state is named "trioxidanediyl".
"Trioxidanediyl" (or "ozonide") is used, non-systematically, to refer to the substituent group (-OOO-). Care should be taken to avoid confusing the name of the group for the context-specific name for ozone given above.
History.
In 1785, Dutch chemist Martinus van Marum was conducting experiments involving electrical sparking above water when he noticed an unusual smell, which he attributed to the electrical reactions, failing to realize he had in fact created ozone. A half century later, Christian Friedrich Schönbein noticed the same pungent odour and recognized it as the smell often following a bolt of lightning. In 1839 he succeeded in isolating the gaseous chemical and named it "ozone", from the Greek word "ozein" (ὄζειν) meaning "to smell". For this reason, Schönbein is generally credited with the discovery of ozone. The formula for ozone, O3, was not determined until 1865 by Jacques-Louis Soret and confirmed by Schönbein in 1867.
For much of the second half of the nineteenth century and well into the twentieth, ozone was considered a healthy component of the environment by naturalists and health-seekers. The City of Beaumont in California had as its official slogan "Beaumont: Zone of Ozone," as evidenced on postcards and Chamber of Commerce letterhead. Naturalists working outdoors often considered the higher elevations beneficial because of their ozone content. "There is quite a different atmosphere [at higher elevation] with enough ozone to sustain the necessary energy [to work]," wrote naturalist Henry Henshaw, working in Hawaii. Seaside air was considered to be healthy because of its "ozone" content but the smell giving rise to this belief is in fact that of halogenated seaweed metabolites.
Physical properties.
Ozone is colourless or slightly bluish gas (blue when liquefied), slightly soluble in water and much more soluble in inert non-polar solvents such as carbon tetrachloride or fluorocarbons, where it forms a blue solution. At 161 K, it condenses to form a dark blue liquid. It is dangerous to allow this liquid to warm to its boiling point, because both concentrated gaseous ozone and liquid ozone can detonate. At temperatures below 80 K, it forms a violet-black solid.
Most people can detect about 0.01 μmol/mol of ozone in air where it has a very specific sharp odour somewhat resembling chlorine bleach. Exposure of 0.1 to 1 μmol/mol produces headaches, burning eyes and irritation to the respiratory passages.
Even low concentrations of ozone in air are very destructive to organic materials such as latex, plastics and animal lung tissue.
Ozone is diamagnetic, which means that its electrons are all paired. In contrast, O2 is paramagnetic, containing two unpaired electrons.
Structure.
According to experimental evidence from microwave spectroscopy, ozone is a bent molecule, with C2v symmetry (similar to the water molecule). The O – O distances are 127.2 pm. The O – O – O angle is 116.78°. The central atom is "sp"² hybridized with one lone pair. Ozone is a polar molecule with a dipole moment of 0.53 D. The bonding can be expressed as a resonance hybrid with a single bond on one side and double bond on the other producing an overall bond order of 1.5 for each side.
Reactions.
Ozone is a powerful oxidizing agent, far stronger than O2. It is also unstable at high concentrations, decaying to ordinary diatomic oxygen. It has a varying half-life length, depending upon atmospheric conditions (temperature, humidity, and air movement). In a sealed chamber with a fan that moves the gas, ozone has a half-life of approximately a day at room temperature. Some unverified claims imply that ozone can have a half life as short as a half an hour under atmospheric conditions.
This reaction proceeds more rapidly with increasing temperature and increased pressure. Deflagration of ozone can be triggered by a spark, and can occur in ozone concentrations of 10 wt% or higher.
With metals.
Ozone will oxidise most metals (except gold, platinum, and iridium) to oxides of the metals in their highest oxidation state. For example:
With nitrogen and carbon compounds.
Ozone also oxidises nitric oxide to nitrogen dioxide:
This reaction is accompanied by chemiluminescence. The NO2 can be further oxidized:
The NO3 formed can react with NO2 to form N2O5.
Solid nitronium perchlorate can be made from NO2, ClO2, and O3 gases:
Ozone does not react with ammonium salts, but it oxidizes ammonia to ammonium nitrate:
Ozone reacts with carbon to form carbon dioxide, even at room temperature:
With sulfur compounds.
Ozone oxidises sulfides to sulfates. For example, lead(II) sulfide is oxidised to lead(II) sulfate:
Sulfuric acid can be produced from ozone, water and either elemental sulfur or sulfur dioxide:
In the gas phase, ozone reacts with hydrogen sulfide to form sulfur dioxide:
In an aqueous solution, however, two competing simultaneous reactions occur, one to produce elemental sulfur, and one to produce sulfuric acid:
With alkenes and alkynes.
Alkenes can be oxidatively cloven by ozone, in a process called ozonolysis, giving alcohols, aldehydes, ketones, and carboxylic acids, depending on the second step of the workup.
Usually ozonolysis is carried out in a solution of dichloromethane, at a temperature of −78oC. After a sequence of cleavage and rearrangement, an organic ozonide is formed. With reductive workup (e.g. zinc in acetic acid or dimethyl sulfide), ketones and aldehydes will be formed, with oxidative workup (e.g. aqueous or alcoholic hydrogen peroxide), carboxylic acids will be formed.
Other substrates.
All three atoms of ozone may also react, as in the reaction of tin(II) chloride with hydrochloric acid and ozone:
Iodine perchlorate can be made by treating iodine dissolved in cold anhydrous perchloric acid with ozone:
Combustion.
Ozone can be used for combustion reactions and combustible gases; ozone provides higher temperatures than burning in dioxygen (O2). The following is a reaction for the combustion of carbon subnitride which can also cause higher temperatures:
Ozone can react at cryogenic temperatures. At 77 K, atomic hydrogen reacts with liquid ozone to form a hydrogen superoxide radical, which dimerizes:
Reduction to ozonides.
Reduction of ozone gives the ozonide anion, O. Derivatives of this anion are explosive and must be stored at cryogenic temperatures. Ozonides for all the alkali metals are known. KO3, RbO3, and CsO3 can be prepared from their respective superoxides:
Although KO3 can be formed as above, it can also be formed from potassium hydroxide and ozone:
NaO3 and LiO3 must be prepared by action of CsO3 in liquid NH3 on an ion exchange resin containing Na+ or Li+ ions:
A solution of calcium in ammonia reacts with ozone to give to ammonium ozonide and not calcium ozonide:
Applications.
Ozone can be used to remove manganese from water, forming a precipitate which can be filtered:
Ozone will also detoxify cyanides by converting them to cyanates, which are a thousand times less toxic.
Ozone will also completely decompose urea:
Ozone in Earth's atmosphere.
The standard way to express total ozone levels (the amount of ozone in a vertical column) in the atmosphere is by using Dobson units. Point measurements are reported as mole fractions in nmol/mol (parts per billion, ppb) or as concentrations in μg/m3. The study of ozone concentration in the atmosphere started in the 1920s.
Ozone layer.
Location and production.
The highest levels of ozone in the atmosphere are in the stratosphere, in a region also known as the ozone layer between about 10 km and 50 km above the surface (or between about 6 and 31 miles). However, even in this "layer" the ozone concentrations are only two to eight parts per million, so most of the oxygen there remains of the dioxygen type.
Ozone in the stratosphere is mostly produced from short-wave ultraviolet rays (in the UVC band) but it can be also produced from x-rays reacting with oxygen:
where "M" denotes the third body that carries off the excess energy of the reaction. The thus produced ozone is destroyed by the reaction with atomic oxygen:
The latter reaction is catalysed by the presence of certain free radicals, of which the most important are hydroxyl (OH), nitric oxide (NO) and atomic chlorine (Cl) and bromine (Br). In recent decades the amount of ozone in the stratosphere has been declining mostly because of emissions of chlorofluorocarbons (CFC) and similar chlorinated and brominated organic molecules, which have increased the concentration of ozone-depleting catalysts above the natural background.
Importance to surface-dwelling life on Earth.
Ozone in the ozone layer filters out sunlight wavelengths from about 200 nm UV rays to 315 nm, with ozone peak absorption at about 250 nm. This ozone UV absorption is important to life, since it extends the absorption of UV by ordinary oxygen and nitrogen in air (which absorb all wavelengths < 200 nm) through the lower UV-C (200–280 nm) and the entire UV-B band (280–315 nm). The small unabsorbed part that remains of UV-B after passage through ozone causes sunburn in humans, and direct DNA damage in living tissues in both plants and animals. Ozone's effect on mid-range UV-B rays is illustrated by its effect on UV-B at 290 nm, which has a radiation intensity 350 million times as powerful at the top of the atmosphere as at the surface. Nevertheless, enough of UV-B radiation at similar frequency reaches the ground to cause some sunburn, and these same wavelengths are also among those responsible for the production of vitamin D in humans.
The ozone layer has little effect on the longer UV wavelengths called UV-A (315–400 nm), but this radiation does not cause sunburn or direct DNA damage, and while it probably does cause long-term skin damage in certain humans, it is not as dangerous to plants and to the health of surface-dwelling organisms on Earth in general (see ultraviolet for more information on near ultraviolet).
Low level ozone.
Low level ozone (or tropospheric ozone) is an atmospheric pollutant. It is not emitted directly by car engines or by industrial operations, but formed by the reaction of sunlight on air containing hydrocarbons and nitrogen oxides that react to form ozone directly at the source of the pollution or many kilometers down wind.
Ozone reacts directly with some hydrocarbons such as aldehydes and thus begins their removal from the air, but the products are themselves key components of smog. Ozone photolysis by UV light leads to production of the hydroxyl radical HO• and this plays a part in the removal of hydrocarbons from the air, but is also the first step in the creation of components of smog such as peroxyacyl nitrates, which can be powerful eye irritants. The atmospheric lifetime of tropospheric ozone is about 22 days; its main removal mechanisms are being deposited to the ground, the above-mentioned reaction giving HO•, and by reactions with OH and the peroxy radical HO2•.
There is evidence of significant reduction in agricultural yields because of increased ground-level ozone and pollution which interferes with photosynthesis and stunts overall growth of some plant species. The United States Environmental Protection Agency is proposing a secondary regulation to reduce crop damage, in addition to the primary regulation designed for the protection of human health.
Certain examples of cities with elevated ozone readings are Houston, Texas, and Mexico City, Mexico. Houston has a reading of around 41 nmol/mol, while Mexico City is far more hazardous, with a reading of about 125 nmol/mol.
Ozone cracking.
Ozone gas attacks any polymer possessing olefinic or double bonds within its chain structure, such as natural rubber, nitrile rubber, and styrene-butadiene rubber. Products made using these polymers are especially susceptible to attack, which causes cracks to grow longer and deeper with time, the rate of crack growth depending on the load carried by the rubber component and the concentration of ozone in the atmosphere. Such materials can be protected by adding antiozonants, such as waxes, which bond to the surface to create a protective film or blend with the material and provide long term protection. Ozone cracking used to be a serious problem in car tires for example, but the problem is now seen only in very old tires. On the other hand, many critical products like gaskets and O-rings may be attacked by ozone produced within compressed air systems. Fuel lines made of reinforced rubber are also susceptible to attack, especially within the engine compartment, where some ozone is produced by electrical components. Storing rubber products in close proximity to a DC electric motor can accelerate ozone cracking. The commutator of the motor generates sparks which in turn produce ozone.
Ozone as a greenhouse gas.
Although ozone was present at ground level before the Industrial Revolution, peak concentrations are now far higher than the pre-industrial levels, and even background concentrations well away from sources of pollution are substantially higher. Ozone acts as a greenhouse gas, absorbing some of the infrared energy emitted by the earth. Quantifying the greenhouse gas potency of ozone is difficult because it is not present in uniform concentrations across the globe. However, the most widely accepted scientific assessments relating to climate change (e.g. the Intergovernmental Panel on Climate Change Third Assessment Report) suggest that the radiative forcing of tropospheric ozone is about 25% that of carbon dioxide.
The annual global warming potential of tropospheric ozone is between 918–1022 tons carbon dioxide equivalent/tons tropospheric ozone. This means on a per-molecule basis, ozone in the troposphere has a radiative forcing effect roughly 1,000 times as strong as carbon dioxide. However, tropospheric ozone is a short-lived greenhouse gas, which decays in the atmosphere much more quickly than carbon dioxide. This means that over a 20-year span, the global warming potential of tropospheric ozone is much less, roughly 62 to 69 tons carbon dioxide equivalent / ton tropospheric ozone.
Because of its short-lived nature, tropospheric ozone does not have strong global effects, but has very strong radiative forcing effects on regional scales. In fact, there are regions of the world where tropospheric ozone has a radiative forcing up to 150% of carbon dioxide.
Health effects.
Ozone air pollution.
Ozone precursors are a group of pollutants, predominantly those emitted during the combustion of fossil fuels. Ground-level ozone pollution (tropospheric ozone) is created near the Earth's surface by the action of daylight UV rays on these precursors. The ozone at ground level is primarily from fossil fuel precursors, but methane is a natural precursor, and the very low natural background level of ozone at ground level is considered safe. This section examines health impacts of fossil fuel burning, which raises ground level ozone far above background levels.
There is a great deal of evidence to show that ground level ozone can harm lung function and irritate the respiratory system. Exposure to ozone and the pollutants that produce it is linked to premature death, asthma, bronchitis, heart attack, and other cardiopulmonary problems.
Long-term exposure to ozone has been shown to increase risk of death from respiratory illness. A study of 450,000 people living in United States cities showed a significant correlation between ozone levels and respiratory illness over the 18-year follow-up period. The study revealed that people living in cities with high ozone levels such as Houston or Los Angeles had an over 30% increased risk of dying from lung disease.
Air quality guidelines such as those from the World Health Organization, the United States Environmental Protection Agency (EPA) and the European Union are based on detailed studies designed to identify the levels that can cause measurable ill health effects.
According to scientists with the US EPA, susceptible people can be adversely affected by ozone levels as low as 40 nmol/mol. In the EU, the current target value for ozone concentrations is 120 µg/m³ which is about 60 nmol/mol. This target applies to all member states in accordance with Directive 2008/50/EC. Ozone concentration is measured as a maximum daily mean of 8 hour averages and the target should not be exceeded on more than 25 calendar days per year, starting from January 2010. Whilst the directive requires in the future a strict compliance with 120 µg/m³ limit (i.e. mean ozone concentration not to be exceeded on any day of the year), there is no date set for this requirement and this is treated as a long-term objective. 
In the USA, the Clean Air Act directs the EPA to set National Ambient Air Quality Standards for several pollutants, including ground-level ozone, and counties out of compliance with these standards are required to take steps to reduce their levels. In May 2008, under a court order, the EPA lowered its ozone standard from 80 nmol/mol to 75 nmol/mol. The move proved controversial, since the Agency's own scientists and advisory board had recommended lowering the standard to 60 nmol/mol. Many public health and environmental groups also supported the 60 nmol/mol standard, and the World Health Organization recommends 51 nmol/mol.
On January 7, 2010, the U.S. Environmental Protection Agency (EPA) announced proposed revisions to the National Ambient Air Quality Standard (NAAQS) for the pollutant ozone, the principal component of smog:
The EPA has developed an Air Quality Index (AQI) to help explain air pollution levels to the general public. Under the current standards, eight-hour average ozone mole fractions of 85 to 104 nmol/mol are described as "unhealthy for sensitive groups," 105 nmol/mol to 124 nmol/mol as "unhealthy," and 125 nmol/mol to 404 nmol/mol as "very unhealthy."
Ozone can also be present in indoor air pollution, partly as a result of electronic equipment such as photocopiers. A connection has also been known to exist between the increased pollen, fungal spores, and ozone caused by thunderstorms and hospital admissions of asthma sufferers.
In the Victorian era, one British folk myth held that the smell of the sea was caused by ozone. In fact, the characteristic "smell of the sea" is caused by dimethyl sulfide a chemical generated by phytoplankton. Victorian British folk considered the resulting smell "bracing".
Heat waves.
Ozone production rises during heat waves, because plants absorb less ozone. It is estimated that curtailed ozone absorption by plants is responsible for the loss of 460 lives in the UK in the hot summer of 2006. A similar investigation to assess the joint effects of ozone and heat during the European heat waves in 2003, concluded that these appear to be additive.
Physiology.
Ozone, along with reactive forms of oxygen such as superoxide, singlet oxygen, hydrogen peroxide, and hypochlorite ions, is naturally produced by white blood cells and other biological systems (such as the roots of marigolds) as a means of destroying foreign bodies. Ozone reacts directly with organic double bonds. Also, when ozone breaks down to dioxygen it gives rise to oxygen free radicals, which are highly reactive and capable of damaging many organic molecules. Moreover, it is believed that the powerful oxidizing properties of ozone may be a contributing factor of inflammation. The cause-and-effect relationship of how the ozone is created in the body and what it does is still under consideration and still subject to various interpretations, since other body chemical processes can trigger some of the same reactions. A team headed by Dr. Paul Wentworth Jr. of the Department of Chemistry at the Scripps Research Institute has shown evidence linking the antibody-catalyzed water-oxidation pathway of the human immune response to the production of ozone. In this system, ozone is produced by antibody-catalyzed production of trioxidane from water and neutrophil-produced singlet oxygen.
When inhaled, ozone reacts with compounds lining the lungs to form specific, cholesterol-derived metabolites that are thought to facilitate the build-up and pathogenesis of atherosclerotic plaques (a form of heart disease). These metabolites have been confirmed as naturally occurring in human atherosclerotic arteries and are categorized into a class of secosterols termed "atheronals", generated by ozonolysis of cholesterol's double bond to form a 5,6 secosterol as well as a secondary condensation product via aldolization.
Ozone has been implicated to have an adverse effect on plant growth: "... ozone reduced total chlorophylls, carotenoid and carbohydrate concentration, and increased 1-aminocyclopropane-1-carboxylic acid (ACC) content and ethylene production. In treated plants, the ascorbate leaf pool was decreased, while lipid peroxidation and solute leakage were significantly higher than in ozone-free controls. The data indicated that ozone triggered protective mechanisms against oxidative stress in citrus."
Safety regulations.
Due to the strongly oxidizing properties of ozone, ozone is a primary irritant, affecting especially the eyes and respiratory systems and can be hazardous at even low concentrations. The Canadian Center for Occupation Safety and Health reports that: "Even very low concentrations of ozone can be harmful to the upper respiratory tract and the lungs. The severity of injury depends on both by the concentration of ozone and the duration of exposure. Severe and permanent lung injury or death could result from even a very short-term exposure to relatively low concentrations." To protect workers potentially exposed to ozone, U.S. Occupational Safety and Health Administration has established a permissible exposure limit (PEL) of 0.1 μmol/mol (29 CFR 1910.1000 table Z-1), calculated as an 8-hour time weighted average. Higher concentrations are especially hazardous and NIOSH has established an Immediately Dangerous to Life and Health Limit (IDLH) of 5 μmol/mol. Work environments where ozone is used or where it is likely to be produced should have adequate ventilation and it is prudent to have a monitor for ozone that will alarm if the concentration exceeds the OSHA PEL. Continuous monitors for ozone are available from several suppliers.
Elevated ozone exposure can occur on passenger aircraft, with levels depending on altitude and atmospheric turbulence. United States Federal Aviation Authority regulations set a limit of 250 nmol/mol with a maximum four-hour average of 100 nmol/mol. Some planes are equipped with ozone converters in the ventilation system to reduce passenger exposure.
Production.
Ozone generators are used to produce ozone for cleaning air or remove smoke odors in unoccupied rooms. These ozone generators can produce over 3 g of ozone per hour. Ozone often forms in nature under conditions where O2 will not react. Ozone used in industry is measured in μmol/mol (ppm, parts per million), nmol/mol (ppb, parts per billion), μg/m3, mg/h (milligrams per hour) or weight percent. The regime of applied concentrations ranges from 1 to 5% in air and from 6 to 14% in oxygen for older generation methods. New electrolytic methods can achieve up 20 to 30% dissolved ozone concentrations in output water.
Temperature and humidity plays a large role in how much ozone is being produced using traditional generation methods such as corona discharge and ultraviolet light. Old generation methods will produce less than 50% its nominal capacity if operated with humid ambient air than when it operates in very dry air. New generators using electrolytic methods can achieve higher purity and dissolution through using water molecules as the source of ozone production.
Corona discharge method.
This is the most common type of ozone generator for most industrial and personal uses. While variations of the "hot spark" coronal discharge method of ozone production exist, including medical grade and industrial grade ozone generators, these units usually work by means of a corona discharge tube. They are typically cost-effective and do not require an oxygen source other than the ambient air to produce ozone concentrations of 3–6%. Fluctuations in ambient air, due to weather or other environmental conditions, cause variability in ozone production. However, they also produce nitrogen oxides as a by-product. Use of an air dryer can reduce or eliminate nitric acid formation by removing water vapor and increase ozone production. Use of an oxygen concentrator can further increase the ozone production and further reduce the risk of nitric acid formation by removing not only the water vapor, but also the bulk of the nitrogen.
Ultraviolet light.
UV ozone generators, or vacuum-ultraviolet (VUV) ozone generators, employ a light source that generates a narrow-band ultraviolet light, a subset of that produced by the Sun. The Sun's UV sustains the ozone layer in the stratosphere of Earth.
While standard UV ozone generators tend to be less expensive, they usually produce ozone with a concentration of about 0.5% or lower. Another disadvantage of this method is that it requires the air (oxygen) to be exposed to the UV source for a longer amount of time, and any gas that is not exposed to the UV source will not be treated. This makes UV generators impractical for use in situations that deal with rapidly moving air or water streams (in-duct air sterilization, for example). Production of ozone is one of the potential dangers of ultraviolet germicidal irradiation. VUV ozone generators are used in swimming pool and spa applications ranging to millions of gallons of water. VUV ozone generators, unlike corona discharge generators, do not produce harmful nitrogen by-products and also unlike corona discharge systems, VUV ozone generators work extremely well in humid air environments. There is also not normally a need for expensive off-gas mechanisms, and no need for air driers or oxygen concentrators which require extra costs and maintenance.
Cold plasma.
In the cold plasma method, pure oxygen gas is exposed to a plasma created by dielectric barrier discharge. The diatomic oxygen is split into single atoms, which then recombine in triplets to form ozone.
Cold plasma machines utilize pure oxygen as the input source and produce a maximum concentration of about 5% ozone. They produce far greater quantities of ozone in a given space of time compared to ultraviolet production. However, because cold plasma ozone generators are very expensive, they are found less frequently than the previous two types.
The discharges manifest as filamentary transfer of electrons (micro discharges) in a gap between two electrodes. In order to evenly distribute the micro discharges, a dielectric insulator must be used to separate the metallic electrodes and to prevent arcing.
Some cold plasma units also have the capability of producing short-lived allotropes of oxygen which include O4, O5, O6, O7, etc. These species are even more reactive than ordinary O3.
Electrolytic.
Electrolytic ozone generation (EOG) splits water molecules into H2, O2, and O3.
In most EOG methods, the hydrogen gas will be removed to leave oxygen and ozone as the only reaction products. Therefore, EOG can achieve higher dissolution in water without other competing gases found in corona discharge method, such as nitrogen gases present in ambient air.
This method of generation can achieve concentrations of 20–30% and is independent of air quality because water is used as the source material. Production of ozone electrolytically is typically unfavorable because of the high overpotential required to produce ozone as compared to oxygen. This is why ozone is not produced during typical water electrolysis. However, it is possible to increase the overpotential of oxygen by careful catalyst selection such that ozone is preferentially produced under electrolysis. Catalysts typically chosen for this approach are lead dioxide or boron-doped diamond.
Special considerations.
Ozone cannot be stored and transported like other industrial gases (because it quickly decays into diatomic oxygen) and must therefore be produced on site. Available ozone generators vary in the arrangement and design of the high-voltage electrodes. At production capacities higher than 20 kg per hour, a gas/water tube heat-exchanger may be utilized as ground electrode and assembled with tubular high-voltage electrodes on the gas-side. The regime of typical gas pressures is around 2 bar absolute in oxygen and 3 bar absolute in air. Several megawatts of electrical power may be installed in large facilities, applied as one phase AC current at 50 to 8000 Hz and peak voltages between 3,000 and 20,000 volts. Applied voltage is usually inversely related to the applied frequency.
The dominating parameter influencing ozone generation efficiency is the gas temperature, which is controlled by cooling water temperature and/or gas velocity. The cooler the water, the better the ozone synthesis. The lower the gas velocity, the higher the concentration (but the lower the net ozone produced). At typical industrial conditions, almost 90% of the effective power is dissipated as heat and needs to be removed by a sufficient cooling water flow.
Because of the high reactivity of ozone, only a few materials may be used like stainless steel (quality 316L), titanium, aluminium (as long as no moisture is present), glass, polytetrafluorethylene, or polyvinylidene fluoride. Viton may be used with the restriction of constant mechanical forces and absence of humidity (humidity limitations apply depending on the formulation). Hypalon may be used with the restriction that no water come in contact with it, except for normal atmospheric levels. Embrittlement or shrinkage is the common mode of failure of elastomers with exposure to ozone. Ozone cracking is the common mode of failure of elastomer seals like O-rings.
Silicone rubbers are usually adequate for use as gaskets in ozone concentrations below 1 wt%, such as in equipment for accelerated aging of rubber samples.
Incidental production.
Ozone may be formed from O2 by electrical discharges and by action of high energy electromagnetic radiation. Unsuppressed arcing breaks down the chemical bonds of the atmospheric oxygen surrounding the contacts [O2 → 2O]. Free radicals of oxygen in and around the arc recombine to create ozone [O3]. Certain electrical equipment generate significant levels of ozone. This is especially true of devices using high voltages, such as ionic air purifiers, laser printers, photocopiers, tasers and arc welders. Electric motors using brushes can generate ozone from repeated sparking inside the unit. Large motors that use brushes, such as those used by elevators or hydraulic pumps, will generate more ozone than smaller motors.
Ozone is similarly formed in the Catatumbo lightning storms phenomenon on the Catatumbo River in Venezuela, which helps to replenish ozone in the upper troposphere. It is the world's largest single natural generator of ozone, lending calls for it to be designated a UNESCO World Heritage Site.
Laboratory production.
In the laboratory, ozone can be produced by electrolysis using a 9 volt battery, a pencil graphite rod cathode, a platinum wire anode and a 3 molar sulfuric acid electrolyte. The half cell reactions taking place are:
In the net reaction, three equivalents of water are converted into one equivalent of ozone and three equivalents of hydrogen. Oxygen formation is a competing reaction.
It can also be "prepared" by high voltage arc. This can be done with an apparatus consisting of two concentric glass tubes sealed together at the top, with in and out spigots at the top and bottom of the outer tube. The inner core should have a length of metal foil inserted into it connected to one side of the power source. The other side of the power source should be connected to another piece of foil wrapped around the outer tube. Dry O2 should be run through the tube in one spigot. As the O2 is run through one spigot into the apparatus and high voltage is applied to the foil leads, electricity will discharge between the dry dioxygen in the middle and form O3 and O2 out the other spigot. The reaction can be summarized as follows:
Applications.
Industry.
The largest use of ozone is in the preparation of pharmaceuticals, synthetic lubricants, and many other commercially useful organic compounds, where it is used to sever carbon-carbon bonds. It can also be used for bleaching substances and for killing microorganisms in air and water sources. Many municipal drinking water systems kill bacteria with ozone instead of the more common chlorine. Ozone has a very high oxidation potential. Ozone does not form organochlorine compounds, nor does it remain in the water after treatment. Ozone can form the suspected carcinogen bromate in source water with high bromide concentrations. The Safe Drinking Water Act mandates that these systems introduce an amount of chlorine to maintain a minimum of 0.2 μmol/mol residual free chlorine in the pipes, based on results of regular testing. Where electrical power is abundant, ozone is a cost-effective method of treating water, since it is produced on demand and does not require transportation and storage of hazardous chemicals. Once it has decayed, it leaves no taste or odour in drinking water.
Although low levels of ozone have been advertised to be of some disinfectant use in residential homes, the concentration of ozone in dry air required to have a rapid, substantial effect on airborne pathogens exceeds safe levels recommended by the U.S. Occupational Safety and Health Administration and Environmental Protection Agency. Humidity control can vastly improve both the killing power of the ozone and the rate at which it decays back to oxygen (more humidity allows more effectiveness). Spore forms of most pathogens are very tolerant of atmospheric ozone in concentrations where asthma patients start to have issues.
Industrially, ozone is used to:
Ozone is a reagent in many organic reactions in the laboratory and in industry. Ozonolysis is the cleavage of an alkene to carbonyl compounds.
Many hospitals around the world use large ozone generators to decontaminate operating rooms between surgeries. The rooms are cleaned and then sealed airtight before being filled with ozone which effectively kills or neutralizes all remaining bacteria.
Ozone is used as an alternative to chlorine or chlorine dioxide in the bleaching of wood pulp. It is often used in conjunction with oxygen and hydrogen peroxide to eliminate the need for chlorine-containing compounds in the manufacture of high-quality, white paper.
Ozone can be used to detoxify cyanide wastes (for example from gold and silver mining) by oxidising cyanide to cyanate and eventually to carbon dioxide.
Consumers.
Devices generating high levels of ozone, some of which use ionization, are used to sanitize and deodorize uninhabited buildings, rooms, ductwork, woodsheds, and boats and other vehicles.
One company has been successfully selling a CPAP sanitizer for the CPAP gear used by sleep apnea patients. This sanitizer works by pumping high concentration levels of electrically-generated ozone into the unit's humidification water tank (with or without water in it) and out through the hose into the mask, which is enclosed and sealed in an ozone-capturing receptacle (that also contains the ozone generator and pump that pushes it into the water tank), which completes a closed-loop system. This closed-loop system prevents the high levels of ozone from escaping while effectively sanitizing the CPAP equipment, as the CPAP equipment is prone to developing bacterial infestations and harboring viruses and other pathogens because of the constant moisture generated by the CPAP system's humidifier. The sanitizing unit has a two-hour cycle, it pumps the ozone for 6–10 minutes (user-designated) and then resting for two hours while maintaining the sealed closed-circuit loop as the ozone decays back into oxygen and finishes the sanitizing effect.
In the U.S., air purifiers emitting low levels of ozone have been sold. This kind of air purifier is sometimes claimed to imitate nature's way of purifying the air without filters and to sanitize both it and household surfaces. The United States Environmental Protection Agency (EPA) has declared that there is "evidence to show that at concentrations that do not exceed public health standards, ozone is not effective at removing many odor-causing chemicals" or "viruses, bacteria, mold, or other biological pollutants." Furthermore, its report states that "results of some controlled studies show that concentrations of ozone considerably higher than these [human safety] standards are possible even when a user follows the manufacturer’s operating instructions." A couple kept repeating health claims for the generator they sold, without supporting scientific studies. In 1998 a federal jury convicted them, among others things, of illegally distributing an ozone generator and of wire fraud.
Ozonated water is used to launder clothes and to sanitize food, drinking water, and surfaces in the home. According to the U.S. Food and Drug Administration (FDA), it is "amending the food additive regulations to provide for the safe use of ozone in gaseous and aqueous phases as an antimicrobial agent on food, including meat and poultry." Studies at California Polytechnic University demonstrated that 0.3 μmol/mol levels of ozone dissolved in filtered tapwater can produce a reduction of more than 99.99% in such food-borne microorganisms as salmonella, "E. coli" 0157:H7 and "Campylobacter". This quantity is 20,000 times the WHO-recommended limits stated above.
Ozone can be used to remove pesticide residues from fruits and vegetables.
Ozone is used in homes and hot tubs to kill bacteria in the water and to reduce the amount of chlorine or bromine required by reactivating them to their free state. Since ozone does not remain in the water long enough, ozone by itself is ineffective at preventing cross-contamination among bathers and must be used in conjunction with halogens. Gaseous ozone created by ultraviolet light or by corona discharge is injected into the water.
Ozone is also widely used in treatment of water in aquariums and fish ponds. Its use can minimize bacterial growth, control parasites, eliminate transmission of some diseases, and reduce or eliminate "yellowing" of the water. Ozone must not come in contact with fish's gill structures. Natural salt water (with life forms) provides enough "instantaneous demand" that controlled amounts of ozone activate bromide ion to hypobromous acid, and the ozone entirely decays in a few seconds to minutes. If oxygen fed ozone is used, the water will be higher in dissolved oxygen, fish's gill structures will atrophy and they will become dependent on higher dissolved oxygen levels.
Aquaculture.
Ozonation - a process of infusing water with ozone - can be used in aquaculture to facilitate organic breakdown. Ozone is also added to recirculating systems to reduce nitrite levels through conversion into nitrate. If nitrite levels in the water are high, nitrites will also accumulate in the blood and tissues of fish, where it interferes with oxygen transport (it causes oxidation of the heme-group of haemoglobin from ferrous (Fe2+) to ferric (Fe3+), making haemoglobin unable to bind O2). Despite these apparent positive effects, ozone use in recirculation systems has been linked to reducing the level of bioavailable iodine in salt water systems, resulting in iodine deficiency symptoms such as goitre and decreased growth in Senegalese sole (Solea senegalensis) larvae.
Ozonate seawater is used for surface disinfection of haddock and Atlantic halibut eggs against nodavirus. Nodavirus is a lethal and vertically transmitted virus which causes severe mortality in fish. Haddock eggs should not be treated with high ozone level as eggs so treated did not hatch and died after 3–4 days.
Agriculture.
Ozone application on freshly cut pineapple and banana shows increase in flavonoids and total phenol contents when exposure is up to 20 minutes. Decrease in ascorbic acid (one form of vitamin C) content is observed but the positive effect on total phenol content and flavonoids can overcome the negative effect. Tomatoes upon treatment with ozone shows an increase in β-carotene, lutein and lycopene. However, ozone application on strawberries in pre-harvest period shows decrease in ascorbic acid content.
Ozone facilitates the extraction of some heavy metals from soil using EDTA. EDTA forms strong, water-soluble coordination compounds with some heavy metals (Pb, Zn) thereby making it possible to dissolve them out from contaminated soil. If contaminated soil is pre-treated with ozone, the extraction efficacy of Pb, Am and Pu increases by 11.0–28.9%, 43.5% and 50.7% respectively.

</doc>
<doc id="22719" url="http://en.wikipedia.org/wiki?curid=22719" title="Orchidaceae">
Orchidaceae

Orchidaceae is a diverse and widespread family of flowering plants, with blooms that are often colourful and often fragrant, commonly known as the orchid family. Along with the Asteraceae, they are one of the two largest families of flowering plants, with between 21,950 and 26,049 currently accepted species, found in 880 genera. The determination of which family is larger is still under debate, because verified data on the members of such enormous families are continually in flux. Regardless, the number of orchid species nearly equals the number of bony fishes and more than twice the number of bird species, and about four times the number of mammal species. The family also encompasses about 6–11% of all seed plants. The largest genera are "Bulbophyllum" (2,000 species), "Epidendrum" (1,500 species), "Dendrobium" (1,400 species) and "Pleurothallis" (1,000 species).
The family also includes "Vanilla" (the genus of the vanilla plant), "Orchis" (type genus), and many commonly cultivated plants such as "Phalaenopsis" and "Cattleya". Moreover, since the introduction of tropical species into cultivation in the 19th century, horticulturists have produced more than 100,000 hybrids and cultivars.
Etymology.
The type genus (i.e. the genus after which the family is named) is "Orchis". The genus name comes from the Ancient Greek ὄρχις ("órkhis"), literally meaning "testicle", because of the shape of the twin tubers in some species of "Orchis". The term "orchid" was introduced in 1845 by John Lindley in "School Botany", as a shortened form of "Orchidaceae".
Description.
Orchids are easily distinguished from other plants, as they share some very evident shared derived characteristics, or "apomorphies". Among these are: bilateral symmetry of the flower (zygomorphism), many resupinate flowers, a nearly always highly modified petal ("labellum"), fused stamens and carpels, and extremely small seeds.
Stem and roots.
All orchids are perennial herbs that lack any permanent woody structure. They can grow according to two patterns:
Terrestrial orchids may be rhizomatous or form corms or tubers. The root caps of terrestrial orchids are smooth and white.
Some sympodial terrestrial orchids, such as "Orchis" and "Ophrys", have two subterranean tuberous roots. One is used as a food reserve for wintry periods, and provides for the development of the other one, from which visible growth develops.
In warm and constantly humid climates, many terrestrial orchids do not need pseudobulbs.
Epiphytic orchids, those that grow upon a support, have modified aerial roots that can sometimes be a few meters long. In the older parts of the roots, a modified spongy epidermis, called velamen, has the function to absorb humidity. It is made of dead cells and can have a silvery-grey, white or brown appearance. In some orchids, the velamen includes spongy and fibrous bodies near the passage cells, called tilosomes.
The cells of the root epidermis grow at a right angle to the axis of the root to allow them to get a firm grasp on their support. Nutrients mainly come from animal droppings and other organic detritus collecting among on their supporting surfaces.
The base of the stem of sympodial epiphytes, or in some species essentially the entire stem, may be thickened to form a pseudobulb that contains nutrients and water for drier periods.
The pseudobulb has a smooth surface with lengthwise grooves, and can have different shapes, often conical or oblong. Its size is very variable; in some small species of "Bulbophyllum", it is no longer than two millimeters, while in the largest orchid in the world, "Grammatophyllum speciosum" (giant orchid), it can reach three meters. Some "Dendrobium" species have long, canelike pseudobulbs with short, rounded leaves over the whole length; some other orchids have hidden or extremely small pseudobulbs, completely included inside the leaves.
With ageing, the pseudobulb sheds its leaves and becomes dormant. At this stage it is often called a backbulb. Backbulbs still hold nutrition for the plant, but then a pseudobulb usually takes over, exploiting the last reserves accumulated in the backbulb, which eventually dies off, too. A pseudobulb typically lives for about five years. Orchids without noticeable pseudobulbs are also said to have growths, an individual component of a sympodial plant.
Leaves.
Like most monocots, orchids generally have simple leaves with parallel veins, although some Vanilloideae have a reticulate venation. Leaves may be ovate, lanceolate, or orbiculate, and very variable in size on the individual plant. Their characteristics are often diagnostic. They are normally alternate on the stem, often folded lengthwise along the centre ("plicate"), and have no stipules. Orchid leaves often have siliceous bodies called stegmata in the vascular bundle sheaths (not present in the Orchidoideae) and are fibrous.
The structure of the leaves corresponds to the specific habitat of the plant. Species that typically bask in sunlight, or grow on sites which can be occasionally very dry, have thick, leathery leaves and the laminae are covered by a waxy cuticle to retain their necessary water supply. Shade-loving species, on the other hand, have long, thin leaves.
The leaves of most orchids are perennial, that is, they live for several years, while others, especially those with plicate leaves as in "Catasetum", shed them annually and develop new leaves together with new pseudobulbs.
The leaves of some orchids are considered ornamental. The leaves of the "Macodes sanderiana", a semiterrestrial or rock-hugging ("lithophyte") orchid, show a sparkling silver and gold veining on a light green background. The cordate leaves of "Psychopsis limminghei" are light brownish-green with maroon-puce markings, created by flower pigments. The attractive mottle of the leaves of lady's slippers from tropical and subtropical Asia ("Paphiopedilum"), is caused by uneven distribution of chlorophyll. Also, "Phalaenopsis schilleriana" is a pastel pink orchid with leaves spotted dark green and light green. The jewel orchid ("Ludisia discolor") is grown more for its colorful leaves than its white flowers.
Some orchids, as "Dendrophylax lindenii" (ghost orchid), "Aphyllorchis" and "Taeniophyllum" depend on their green roots for photosynthesis and lack normally developed leaves, as do all of the heterotrophic species.
Orchids of the genus "Corallorhiza" (coralroot orchids) lack leaves altogether and instead wrap their roots around the roots of mature trees and use specialized fungi to harvest sugars.
Flowers.
Orchidaceae are well known for the many structural variations in their flowers.
Some orchids have single flowers, but most have a racemose inflorescence, sometimes with a large number of flowers. The flowering stem can be basal, that is, produced from the base of the tuber, like in "Cymbidium", apical, meaning it grows from the apex of the main stem, like in "Cattleya", or axillary, from the leaf axil, as in "Vanda".
As an apomorphy of the clade, orchid flowers are primitively zygomorphic (bilaterally symmetrical), although in some genera like "Mormodes", "Ludisia" and "Macodes", this kind of symmetry may be difficult to notice.
The orchid flower, like most flowers of monocots, has two whorls of sterile elements. The outer whorl has three sepals and the inner whorl has three petals. The sepals are usually very similar to the petals (and thus called "tepals", 1), but may be completely distinct.
The medial petal, called the "labellum" or lip (6), which is always modified and enlarged, is actually the "upper" medial petal; however, as the flower develops, the inferior ovary (7) or the pedicel usually rotates 180 degrees, so that the labellum arrives at the lower part of the flower, thus becoming suitable to form a platform for pollinators. This characteristic, called resupination, occurs primitively in the family and is considered apomorphic, a derived characteristic all Orchidaceae share. The torsion of the ovary is very evident from the longitudinal section shown ("below right"). Some orchids have secondarily lost this resupination, e.g. "Zygopetalum" and "Epidendrum secundum".
The normal form of the sepals can be found in "Cattleya", where they form a triangle. In "Paphiopedilum" (Venus slippers), the lower two sepals are fused into a synsepal, while the lip has taken the form of a slipper. In "Masdevallia", all the sepals are fused.
Orchid flowers with abnormal numbers of petals or lips are called peloric. Peloria is a genetic trait, but its expression is environmentally influenced and may appear random.
Orchid flowers primitively had three stamens, but this situation is now limited to the genus "Neuwiedia". "Apostasia" and the Cypripedioideae have two stamens, the central one being sterile and reduced to a staminode. All of the other orchids, the clade called "Monandria", retain only the central stamen, the others being reduced to staminodes (4). The filaments of the stamens are always adnate (fused) to the style to form cylindrical structure called the gynostemium or column (2). In the primitive Apostasioideae, this fusion is only partial; in the Vanilloideae, it is more deep; in Orchidoideae and Epidendroideae, it is total. The stigma (9) is very asymmetrical, as all of its lobes are bent towards the centre of the flower and lie on the bottom of the column.
Pollen is released as single grains, like in most other plants, in the Apostasioideae, Cypripedioideae and Vanilloideae. In the other subfamilies, that comprise the great majority of orchids, the anther (3), carries and two pollinia.
A pollinium is a waxy mass of pollen grains held together by the glue-like alkaloid viscin, containing both cellulosic strands and mucopolysaccharides. Each pollinium is connected to a filament which can take the form of a caudicle, as in "Dactylorhiza" or "Habenaria", or a "stipe", as in "Vanda". Caudicles or stipes hold the pollinia to the viscidium, a sticky pad which sticks the pollinia to the body of pollinators.
At the upper edge of the stigma of single-anthered orchids, in front of the anther cap, there is the rostellum (5), a slender extension involved in the complex pollination mechanism.
As mentioned, the ovary is always inferior (located behind the flower). It is three-carpelate and one or, more rarely, three-partitioned, with parietal placentation (axile in the Apostasioideae).
In 2011, a member of the genus "Bulbophyllum", "Bulbophyllum nocturnum", was discovered to flower nocturnally.
Fruits and seeds.
The ovary typically develops into a capsule that is dehiscent by three or six longitudinal slits, while remaining closed at both ends.
The seeds are generally almost microscopic and very numerous, in some species over a million per capsule. After ripening, they blow off like dust particles or spores. They lack endosperm and must enter symbiotic relationships with various mycorrhizal basidiomyceteous fungi that provide them the necessary nutrients to germinate, so that all orchid species are mycoheterotrophic during germination and reliant upon fungi to complete their lifecycles.
As the chance for a seed to meet a suitable fungus is very small, only a minute fraction of all the seeds released grow into adult plants. In cultivation, germination typically takes weeks.
Horticultural techniques have been devised for germinating orchid seeds on an artificial nutrient medium, eliminating the requirement of the fungus for germination and greatly aiding the propagation of ornamental orchids. The usual medium for the sowing of orchids in artificial conditions is agar agar gel combined with a carbohydrate energy source. The carbohydrate source can be combinations of discrete sugars or can be derived from other sources such as banana, pineapple, peach or even tomato puree or coconut water. After the preparation of the agar agar medium it is poured into test tubes or jars which are then autoclaved (or cooked in a pressure cooker) to sterilize the medium. After cooking, the medium begins to gel as it cools.
Pollination.
The complex mechanisms which orchids have evolved to achieve cross-pollination were investigated by Charles Darwin and described in "Fertilisation of Orchids" (1862). Orchids have developed highly specialized pollination systems, thus the chances of being pollinated are often scarce, so orchid flowers usually remain receptive for very long periods, rendering unpollinated flowers long-lasting in cultivation. Most orchids deliver pollen in a single mass. Each time pollination succeeds, thousands of ovules can be fertilized.
Pollinators are often visually attracted by the shape and colours of the labellum. However, some "Bulbophyllum" species attract male fruit flies ("Bactrocera" spp.) solely via a floral chemical which simultaneously acts as a floral reward (e.g. methyl eugenol, raspberry ketone or zingerone) to perform pollination. The flowers may produce attractive odours. Although absent in most species, nectar may be produced in a spur of the labellum (8 in the illustration above), or on the point of the sepals, or in the septa of the ovary, the most typical position amongst the Asparagales.
In orchids that produce pollinia, pollination happens as some variant of the following sequence: when the pollinator enters into the flower, it touches a viscidium, which promptly sticks to its body, generally on the head or abdomen. While leaving the flower, it pulls the pollinium out of the anther, as it is connected to the viscidium by the caudicle or stipe. The caudicle then bends and the pollinium is moved forwards and downwards. When the pollinator enters another flower of the same species, the pollinium has taken such position that it will stick to the stigma of the second flower, just below the rostellum, pollinating it. The possessors of orchids may be able to reproduce the process with a pencil, small paintbrush, or other similar device.
Some orchids mainly or totally rely on self-pollination, especially in colder regions where pollinators are particularly rare. The caudicles may dry up if the flower has not been visited by any pollinator, and the pollinia then fall directly on the stigma. Otherwise, the anther may rotate and then enter the stigma cavity of the flower (as in "Holcoglossum amesianum").
The slipper orchid "Paphiopedilum parishii" reproduces by self-fertilization. This occurs when the anther changes from a solid to a liquid state and directly contacts the stigma surface without the aid of any pollinating agent or floral assembly.
The labellum of the Cypripedioideae is poke-bonnet-shaped, and has the function of trapping visiting insects. The only exit leads to the anthers that deposit pollen on the visitor.
In some extremely specialized orchids, such as the Eurasian genus "Ophrys", the labellum is adapted to have a colour, shape and odour which attracts male insects via mimicry of a receptive female. Pollination happens as the insect attempts to mate with flowers.
Many neotropical orchids are pollinated by male orchid bees, which visit the flowers to gather volatile chemicals they require to synthesize pheromonal attractants. Each type of orchid places the pollinia on a different body part of a different species of bee, so as to enforce proper cross-pollination.
A rare achlorophyllous saprophytic orchid growing entirely underground in Australia, "Rhizanthella slateri", is never exposed to light, and depends on ants and other terrestrial insects to pollinate it.
"Catasetum", a genus discussed briefly by Darwin, actually launches its viscid pollinia with explosive force when an insect touches a seta, knocking the pollinator off the flower.
After pollination, the sepals and petals fade and wilt, but they usually remain attached to the ovary.
Asexual reproduction.
Some species, such as "Phalaenopsis", "Dendrobium" and "Vanda", produce offshoots or plantlets formed from one of the nodes along the stem, through the accumulation of growth hormones at that point. These shoots are known as "keiki".
Taxonomy.
The taxonomy of this family is in constant flux, as new studies continue to identify more classificatory elements. The Orchidaceae is currently placed in the order Asparagales by the APG III system of 2009.
Five subfamilies are recognised. The cladogram has been made according to the APG system:
Evolution.
A study in the scientific journal "Nature" has hypothesized that the origin of orchids goes back much longer than originally expected. An extinct species of stingless bee, "Proplebeia dominicana", was found trapped in Miocene amber from about 15-20 million years ago. The bee was carrying pollen of a previously unknown orchid taxon, "Meliorchis caribea", on its wings. This find is the first evidence of fossilised orchids to date and shows insects were active pollinators of orchids then. This extinct orchid, "M. caribea", has been placed within the extant tribe Cranichideae, subtribe Goodyerinae (subfamily Orchidoideae).
Genetic sequencing indicates orchids may have arisen earlier, 76 to 84 million years ago during the Late Cretaceous. In other words, they may have coexisted with dinosaurs. According to Mark W. Chase "et al." (2001), the overall biogeography and phylogenetic patterns of Orchidaceae show they are even older and may go back roughly 100 million years.
Using the molecular clock method, it was possible to determine the age of the major branches of the orchid family. This also confirmed that the subfamily Vanilloideae is a branch at the basal dichotomy of the monandrous orchids, and must have evolved very early in the evolution of the family. Since this subfamily occurs worldwide in tropical and subtropical regions, from tropical America to tropical Asia, New Guinea and West Africa, and the continents began to split about 100 million years ago, significant biotic exchange must have occurred after this split (since the age of "Vanilla" is estimated at 60 to 70 million years).
Genera.
The following are amongst the most notable genera of the orchid family:
Distribution.
Orchidaceae are cosmopolitan, occurring in almost every habitat apart from glaciers. The world's richest diversity of orchid genera and species is found in the tropics, but they are also found above the Arctic Circle, in southern Patagonia, and two species of "Nematoceras" on Macquarie Island at 54° south.
The following list gives a rough overview of their distribution:
Ecology.
A majority of orchids are perennial epiphytes, which grow anchored to trees or shrubs in the tropics and subtropics. Species such as "Angraecum sororium" are lithophytes, growing on rocks or very rocky soil. Other orchids (including the majority of temperate Orchidaceae) are terrestrial and can be found in habitat areas such as grasslands or forest.
Some orchids, such as "Neottia" and "Corallorhiza", lack chlorophyll, so are unable to photosynthesize. Instead, these species obtain energy and nutrients by parasitising soil fungi through the formation of orchid mycorrhizas. The fungi involved include those that form ectomycorrhizas with trees and other woody plants, parasites such as "Armillaria", and saprotrophs. These orchids are known as myco-heterotrophs, but were formerly (incorrectly) described as saprophytes as it was believed they gained their nutrition by breaking down organic matter. While only a few species are achlorophyllous holoparasites, all orchids are myco-heterotrophic during germination and seedling growth, and even photosynthetic adult plants may continue to obtain carbon from their mycorrhizal fungi.
Uses.
Perfumery.
The scent of orchids is frequently analysed by perfumers (using headspace technology and gas-liquid chromatography) to identify potential fragrance chemicals.
Horticulture.
The other important use of orchids is their cultivation for the enjoyment of the flowers. Most cultivated orchids are tropical or subtropical, but quite a few which grow in colder climates can be found on the market. Temperate species available at nurseries include "Ophrys apifera" (bee orchid), "Gymnadenia conopsea" (fragrant orchid), "Anacamptis pyramidalis" (pyramidal orchid) and "Dactylorhiza fuchsii" (common spotted orchid).
Orchids of all types have also often been sought by collectors of both species and hybrids. Many hundreds of societies and clubs worldwide have been established. These can be small, local clubs such as the , or larger, national organisations such as the . Both serve to encourage cultivation and collection of orchids, but some go further by concentrating on conservation or research.
The term "botanical orchid" loosely denotes those small-flowered, tropical orchids belonging to several genera that do not fit into the "florist" orchid category. A few of these genera contain enormous numbers of species. Some, such as "Pleurothallis" and "Bulbophyllum", contain approximately 1700 and 2000 species, respectively, and are often extremely vegetatively diverse. The primary use of the term is among orchid hobbyists wishing to describe unusual species they grow, though it is also used to distinguish naturally occurring orchid species from horticulturally created hybrids.
Use as food.
The dried seed pods of one orchid genus, "Vanilla" (especially "Vanilla planifolia"), are commercially important as flavoring in baking, for perfume manufacture and aromatherapy.
The underground tubers of terrestrial orchids [mainly "Orchis mascula" (early purple orchid)] are ground to a powder and used for cooking, such as in the hot beverage "salep" or in the Turkish frozen treat "dondurma". The name "salep" has been claimed to come from the Arabic expression "ḥasyu al-tha`lab", "fox testicles", but it appears more likely the name comes directly from the Arabic name "saḥlab". The similarity in appearance to testes naturally accounts for "salep" being considered an aphrodisiac.
The dried leaves of "Jumellea fragrans" are used to flavor rum on Reunion Island.
Some saprophytic orchid species of the group "Gastrodia" produce potato-like tubers and were consumed as food by native peoples in Australia and can be successfully cultivated, notably "Gastrodia sesamoides". Wild stands of these plants can still be found in the same areas as early aboriginal settlements, such as Ku-ring-gai Chase National Park in Australia. Aboriginal peoples located the plants in habitat by observing where bandicoots had scratched in search of the tubers after detecting the plants underground by scent.
Traditional medicinal uses.
Orchids have been used in traditional medicine in an effort to treat many diseases and ailments. They have been used as a source of herbal remedies in China since 2800 BC. "Gastrodia elata" is one of the three orchids listed in the earliest known Chinese Materia Medica ("Shennon bencaojing") (c. 100 AD). Theophrastus mentions orchids in his "Enquiry into Plants" (372–286 BC).
Cultural symbolism.
Orchids have many associations with symbolic values. For example, the orchid is the City Flower of Shaoxing, China. "Cattleya mossiae" is the national Venezuelan flower, while "Cattleya trianae" is the national flower of Colombia. "Vanda" 'Miss Joaquim' is the national flower of Singapore. "Guarianthe skinneri" is the national flower of Costa Rica. Orchids native to the Mediterranean are depicted on the "Ara Pacis" in Rome, until now the only known instance of orchids in ancient art, and the earliest in European art.

</doc>
<doc id="22721" url="http://en.wikipedia.org/wiki?curid=22721" title="Obsidian">
Obsidian

Obsidian is a naturally occurring volcanic glass formed as an extrusive igneous rock.
It is produced when felsic lava extruded from a volcano cools rapidly with minimum crystal growth. Obsidian is commonly found within the margins of rhyolitic lava flows known as obsidian flows, where the chemical composition (high silica content) induces a high viscosity and polymerization degree of the lava. The inhibition of atomic diffusion through this highly viscous and polymerized lava explains the lack of crystal growth. Obsidian is hard and brittle; it therefore fractures with very sharp edges, which were used in the past in cutting and piercing tools, and has been used experimentally as surgical scalpel blades.
Origin and properties.
... among the various forms of glass we may reckon Obsian glass, a substance very similar to the stone found by Obsius in Ethiopia.
The translation into English of "Natural History" written by the elder Pliny of Rome shows a few sentences on the subject of a volcanic glass called Obsian, so named from its resemblance to a stone ("obsiānus lapis") found in Ethiopia by Obsius, a Roman explorer.
Obsidian is the rock formed as a result of quickly cooled lava, which is the parent material. Having a low water content when newly formed typically less than 1% water by weight, obsidian becomes progressively hydrated when exposed to groundwater, forming perlite. Tektites were once thought by many to be obsidian produced by lunar volcanic eruptions, though few scientists now adhere to this hypothesis.
Obsidian is mineral-like, but not a true mineral because as a glass it is not crystalline; in addition, its composition is too complex to comprise a single mineral. It is sometimes classified as a mineraloid. Though obsidian is usually dark in color similar to mafic rocks such as basalt, obsidian's composition is extremely felsic. Obsidian consists mainly of SiO2 (silicon dioxide), usually 70% or more. Crystalline rocks with obsidian's composition include granite and rhyolite. Because obsidian is metastable at the Earth's surface (over time the glass becomes fine-grained mineral crystals), no obsidian has been found that is older than Cretaceous age. This breakdown of obsidian is accelerated by the presence of water.
Pure obsidian is usually dark in appearance, though the color varies depending on the presence of impurities. Iron and magnesium typically give the obsidian a dark brown to black color. Very few samples are nearly colorless. In some stones, the inclusion of small, white, radially clustered crystals of cristobalite in the black glass produce a blotchy or snowflake pattern ("snowflake obsidian"). It may contain patterns of gas bubbles remaining from the lava flow, aligned along layers created as the molten rock was flowing before being cooled. These bubbles can produce interesting effects such as a golden sheen ("sheen obsidian"). An iridescent, rainbow-like sheen ("rainbow obsidian") is caused by inclusions of magnetite nanoparticles (Nadin, 2007).
Occurrence.
Obsidian can be found in locations which have experienced rhyolitic eruptions. It can be found in Argentina, Armenia, Azerbaijan, Australia, Canada, Chile, Georgia, Greece, El Salvador, Guatemala, Iceland, Italy, Japan, Kenya, Mexico, New Zealand, Papua New Guinea, Peru, Scotland, Turkey and the United States. Obsidian flows which may be hiked on are found within the calderas of Newberry Volcano and Medicine Lake Volcano in the Cascade Range of western North America, and at Inyo Craters east of the Sierra Nevada in California. Yellowstone National Park has a mountainside containing obsidian located between Mammoth Hot Springs and the Norris Geyser Basin, and deposits can be found in many other western U.S. states including Arizona, Colorado, New Mexico, Texas, Utah, Washington, Oregon and Idaho. Obsidian can also be found in the eastern U.S. states of Virginia, as well as Pennsylvania and North Carolina.
There are only four major deposit areas in the central Mediterranean: Lipari, Pantelleria, Palmarola and Monte Arci.
Ancient sources in the Aegean were Melos and Giali.
Acigöl town and the Göllü Dağ volcano were the most important sources in central Anatolia, one of the more important source areas in prehistoric Near East.
Historical use.
The first archaeological evidence known of usage were made from within Kariandusi and other sites of the Acheulian age (beginning 1.5 million years previously) dated 700,000 BC, although the number of objects found at these sites were very low relative to the Neolithic. Use of obsidian in pottery of the Neolithic in the area around Lipari was found to be significantly less at a distance representing two weeks journeying. Anatolian sources of obsidian are known to have been the material used in the Levant and modern-day Iraqi Kurdistan from a time beginning sometime about 12,500 BC. The first attested civilized use is from excavations at Tell Brak dated the late fifth millennia. Obsidian was valued in Stone Age cultures because, like flint, it could be fractured to produce sharp blades or arrowheads. Like all glass and some other types of naturally occurring rocks, obsidian breaks with a characteristic conchoidal fracture. It was also polished to create early mirrors. Modern archaeologists have developed a relative dating system, obsidian hydration dating, to calculate the age of obsidian artifacts.
Middle East.
In the Ubaid in the 5th millennium BC, blades were manufactured from obsidian mined in what is now Turkey. Ancient Egyptians used obsidian imported from the eastern Mediterranean and southern Red Sea regions. Obsidian was also used in ritual circumcisions because of its deftness and sharpness. In the eastern Mediterranean area the material was used to make tools, mirrors and decorative objects.
Obsidian has also been found in Gilat, a site in the western Negev in Israel. Eight obsidian artifacts dating to the Chalcolithic Age found at this site were traced to obsidian sources in Anatolia. Neutron activation analysis (NAA) on the obsidian found at this site helped to reveal trade routes and exchange networks previously unknown.
Americas.
Lithic analysis can be instrumental in understanding prehispanic groups in Mesoamerica. A careful analysis of obsidian in a culture or place can be of considerable use to reconstruct commerce, production, distribution and thereby understand economic, social and political aspects of a civilization. This is the case in Yaxchilán, a Maya city where even warfare implications have been studied linked with obsidian use and its debris. Another example is the archeological recovery at coastal Chumash sites in California indicating considerable trade with the distant site of Casa Diablo, California in the Sierra Nevada Mountains.
Pre-Columbian Mesoamericans' use of obsidian was extensive and sophisticated; including carved and worked obsidian for tools and decorative objects. Mesoamericans also made a type of sword with obsidian blades mounted in a wooden body. Called a "macuahuitl", the weapon was capable of inflicting terrible injuries, combining the sharp cutting edge of an obsidian blade with the ragged cut of a serrated weapon.
Native American people traded obsidian throughout the Americas. Each volcano and in some cases each volcanic eruption produces a distinguishable type of obsidian, making it possible for archaeologists to trace the origins of a particular artifact. Similar tracing techniques have allowed obsidian to be identified in Greece also as coming from Melos, Nisyros or Yiali, islands in the Aegean Sea. Obsidian cores and blades were traded great distances inland from the coast.
In Chile obsidian tools from Chaitén Volcano have been found as far away as in Chan-Chan 400 km north of the volcano and also in sites 400 km south of it.
Easter Island.
Obsidian was also used on Rapa Nui (Easter Island) for edged tools such as "Mataia" and the pupils of the eyes of their Moai (statues).
Current use.
Though not approved by the US Food and Drug Administration (FDA) for use on humans, obsidian is used by some surgeons for scalpel blades, as well-crafted obsidian blades have a cutting edge many times sharper than high-quality steel surgical scalpels, the cutting edge of the blade being only about 3 nanometers thick. Even the sharpest metal knife has a jagged, irregular blade when viewed under a strong enough microscope; when examined even under an electron microscope an obsidian blade is still smooth and even. One study found that obsidian incisions produced fewer inflammatory cells and less granulation tissue at 7 days, in a group of rats. Don Crabtree produced obsidian blades for surgery and other purposes, and has written articles on the subject. Obsidian scalpels may currently be purchased for surgical use on research animals.
Obsidian is also used for ornamental purposes and as a gemstone. It presents a different appearance depending on how it is cut: in one direction it is jet black, while in another it is glistening gray. "Apache tears" are small rounded obsidian nuggets embedded within a grayish-white perlite matrix.
Plinths for audio turntables have been made of obsidian since the 1970s; e.g. the grayish-black SH-10B3 plinth by Technics.

</doc>
<doc id="22722" url="http://en.wikipedia.org/wiki?curid=22722" title="Otaku">
Otaku

Otaku (おたく/オタク) is a Japanese term for people with obsessive interests, commonly the anime and manga fandom. Its contemporary usage originated with Akio Nakamori's 1983 essay in "Manga Burikko". "Otaku" may be used as a pejorative; its negativity stems from the stereotypical view of otaku and the media's reporting on Tsutomu Miyazaki, "The Otaku Murderer", in 1989. According to studies published in 2013, the term has become less negative, and an increasing number of people now self-identify as otaku.
Otaku subculture is a central theme of various anime and manga works, documentaries and academic research. The subculture began in the 1980s as changing social mentalities and the nurturing of otaku traits by Japanese schools combined with the resignation of such individuals to become social outcasts. The subculture's birth coincided with the anime boom, after the release of works like Mobile Suit Gundam before branched into Comic Market. The definition of otaku subsequently became more complex, and numerous classifications of otaku emerged. In 2005, the Nomura Research Institute divided otaku into twelve groups and estimated the size and market impact of each of these groups. Other institutions have split it further or focus on a single otaku interest. These publications classify distinct groups including anime, manga, camera, automobile, idol and electronics otaku. The economic impact of otaku has been estimated to be as high as ¥2 trillion ($18 billion).
Etymology.
"Otaku" is derived from a Japanese term for another person's house or family (お宅, "otaku"). This word is often used metaphorically, as an honorific second-person pronoun. In this usage, its literal translation is "you". For example, in the anime Macross, first aired in 1982, Lynn Minmay uses the term this way. The modern slang form, which is distinguished from the older usage by being written only in hiragana (おたく), katakana (オタク or, less frequently, ヲタク) or rarely in rōmaji, first appeared in public discourse in the 1980s, through the work of humorist and essayist Akio Nakamori. His 1983 series "An Investigation of "Otaku"" (『おたく』の研究, "Otaku" no Kenkyū), printed in the lolicon magazine "Manga Burikko", applied the term to unpleasant fans in caricature. Animators Haruhiko Mikimoto and Shōji Kawamori had used the term among themselves as an honorific second-person pronoun since the late 1970s. Supposedly, some fans used it past the point in their relationships where others would have moved on to a less formal style. Because this misuse indicated social awkwardness, Nakamori chose the word itself to label the fans. Morikawa Kaichirō identified this as the origin of its contemporary usage.
Another claim for the origin of the term comes from the works of science fiction author Motoko Arai, who used the word in her novels as a second-person pronoun and the readers adopted the term for themselves. However, a different claim points to a 1981 "Variety" magazine essay.
In 1989, the case of Tsutomu Miyazaki, "The Otaku Murderer", brought the fandom, very negatively, to national attention. Miyazaki, who randomly chose and murdered four girls, had a collection of 5,763 videotapes, some containing anime and slasher films that were found interspersed with videos and pictures of his victims. Later that year, the contemporary knowledge magazine Bessatsu Takarajima dedicated its 104th issue to the topic of otaku. It was called "Otaku no Hon" (おたくの本, lit. The Book of Otaku) and delved into the subculture of otaku with 19 articles by otaku insiders, among them Akio Nakamori. This publication has been claimed by scholar Rudyard Pesimo to have popularized the term.
Usage.
In modern Japanese slang, the term "otaku" is mostly equivalent to "geek" or "nerd", but in a more derogatory manner than used in the West. However, it can relate to any fan of any particular theme, topic, hobby or form of entertainment. "When these people are referred to as otaku, they are judged for their behaviors - and people suddenly see an “otaku” as a person unable to relate to reality". The word entered English as a loanword from the Japanese language. It is typically used to refer to a fan of anime/manga but can also refer to Japanese video games or Japanese culture in general. The American magazine "Otaku USA" popularizes and covers these aspects. The usage of the word is a source of contention among some fans, owing to its negative connotations and stereotyping of the fandom. Widespread English exposure to the term came in 1988 with the release of Gunbuster, which referred to anime fans as otaku. Gunbuster was released officially in English in March 1990. The term's usage spread throughout rec.arts.anime with discussions about Otaku no Video's portrayal of otaku before its 1994 English release. Positive and negative aspects, including the pejorative usage, were intermixed. The term was also popularized by William Gibson's 1996 novel "Idoru", which references otaku.
Subculture.
Morikawa Kaichirō identifies the subculture as distinctly Japanese, a product of the school system and society. Japanese schools have a class structure which functions as a caste system, but clubs are an exception to the social hierarchy. In these clubs, a student's interests will be recognized and nurtured, catering to the interests of otaku. Secondly, the vertical structure of Japanese society identifies the value of individuals by their success. Until the late 1980s, unatheletic and unattractive males focused on academics, hoping to secure a good job and marry to raise their social standing. Those unable to succeed socially focused instead on their interests, often into adulthood, with their lifestyle centering around those interests, furthering the creation of the otaku subculture.
Even prior to the coinage of the term, the stereotypical traits of the subculture were identified in a 1981 issue of "Fan Rōdo" (Fan road) about "culture clubs". These individuals were drawn to anime, a counter-culture, with the release of hard science fiction works like Mobile Suit Gundam. These works allowed a congregation and development of obsessive interests that turned anime into a medium for unpopular students, catering to obsessed fans. After these fans discovered Comic Market, the term was used as a self-confirming and self-mocking collective identity.
The 1989 "Otaku Murderer" case gave a negative connotation to the fandom from which it has not fully recovered. The usage of "(interest) otaku", however, is used for teasing or self-deprecation, but the unqualified term remains negative. The identification of otaku turned negative in late 2004 when Kaoru Kobayashi kidnapped, sexually assaulted, and murdered a seven-year-old first-grade student. Japanese journalist Akihiro Ōtani suspected that Kobayashi's crime was committed by a member of the figure moe zoku even before his arrest. Although Kobayashi was not an otaku, the degree of social hostility against otaku increased. Otaku were seen by law enforcement as possible suspects for sex crimes, and local governments called for stricter laws controlling the depiction of eroticism in otaku materials.
Not all attention has been negative. In his book, "Otaku", Hiroki Azuma observed: "Between 2001 and 2007, the otaku forms and markets quite rapidly won social recognition in Japan", citing the fact that "[i]n 2003, Miyazaki Hayao won the Academy Award for his "Spirited Away"; around the same time Murakami Takashi achieved recognition for otaku-like designs; in 2004, the Japanese pavilion in the 2004 International Architecture exhibition of the Venice Biennale (Biennale Architecture) featured “otaku”. In 2005, the word "moe" - one of the keywords of the present volume - was chosen as one of the top ten “buzzwords of the year." The former Prime Minister of Japan Taro Aso has also claimed to be an otaku, using this subculture to promote Japan in foreign affairs. In 2013, a Japanese study of 137,734 people found that 42.2% self-identify as a type of otaku. This study suggests that the stigma of the word has vanished, and the term has been embraced by many.
Places.
The district of Akihabara in Tokyo, where there are maid cafes featuring waitresses who dress up and act like maids or anime characters, is a notable attraction center for otaku. Akihabara also has dozens of stores specializing in anime, manga, retro video games, figurines, card games and other collectibles. Another popular location is Otome Road in Ikebukuro, Tokyo. In Nagoya, students from Nagoya City University started a project on ways to help promote hidden tourist attractions related to the otaku culture to attract more otaku to the city.
Subtypes.
There are specific terms for different types of otaku, including Fujoshi (腐女子, lit. "rotten girl"), a self-mockingly pejorative Japanese term for female fans of yaoi, which focuses on homosexual male relationships. "Reki-jo" are female otaku who are interested in Japanese history. Some terms refer to a location, like "Akiba-kei", a slang term meaning "Akihabara-style" which applies to those familiar with Akihabara's culture. Another is Wotagei or otagei (ヲタ芸 or オタ芸), a type of cheering that is part of Akiba-kei. Other terms, such as Itasha (痛車), literally "painful car", describe vehicles who are decorated with fictional characters, especially bishōjo game or eroge characters.
Media.
Otaku often participate in self-mocking through the production or interest in humor directed at their subculture. Anime and manga otaku are the subject of numerous self-critical works, like Otaku no Video, which contains a live-interview mockumentary that pokes fun at the otaku subculture and includes Gainax's own staff as the interviewees. Other works depict otaku subculture less critically, like Genshiken and Comic Party. A well-known novel-cum-manga-cum-anime is Welcome to the N.H.K., which focuses on the popular subcultures popular with otaku and highlights other social outcasts like the hikikomori and NEETs. Works that focus on an otaku character include "WataMote - No Matter How I Look at It, It’s You Guys' Fault I’m Not Popular!", the story of an unattractive and unsociable otome game otaku who exhibits delusions about her social status. Watamote is a self-mocking insight that follows the heroine's delusion and attempts to reform herself only by facing reality with comedic results on the path to popularity. An American documentary, "Otaku Unite!", focuses on the American side of the otaku culture.
Types and classification of Japanese otaku.
The Nomura Research Institute (NRI) has made two major studies into otaku, the first in 2004 and a revised study with a more specific definition in 2005. The 2005 study defines twelve major fields of otaku interests. Of these groups, manga (Japanese comics) was the largest, with 350,000 individuals and ¥83 billion market scale. Idol otaku were the next largest group, with 280,000 individuals and ¥61 billion. Travel otaku with 250,000 individuals and ¥81 billion. PC otaku with 190,000 individuals and ¥36 billion. Video game otaku with 160,000 individuals and ¥21 billion. Automobile otaku with 140,000 individuals and ¥54 billion. Animation (anime) otaku with 110,000 individuals and ¥20 billion. The remaining five categories include Mobile IT equipment otaku, with 70,000 individuals and ¥8 billion; Audio-visual equipment otaku, with 60,000 individuals and ¥12 billion; camera otaku, with 50,000 individuals and ¥18 billion; fashion otaku, with 40,000 individuals and ¥13 billion; and railway otaku, with 20,000 individuals and ¥4 billion. These values were partially released with a much higher estimation in 2004, but this definition focused on the consumerism and not the "unique psychological characteristics" of otaku used in the 2005 study.
NRI's 2005 study also put forth five archetypes of otaku. The first is the family-oriented otaku, who has broad interests and is more mature than other otaku; their object of interest is secretive and they are "closet otaku". The second is the serious "leaving my own mark on the world" otaku, with interests in mechanical or business personality fields. The third type is the "media-sensitive multiple interest" otaku, whose diverse interests are shared with others. The fourth type is the "outgoing and assertive otaku", who gain recognition by promoting their hobby. The last is the "fan magazine-obsessed otaku", which is predominately female with the a small group of males being the "moe type"; the secret hobby is focused on the production or interest in fan works. The Hamagin Research Institute found that moe-related content was worth ¥88.8 billion ($807 million) in 2005, and one analyst estimated the market could be as much as ¥2 trillion ($18 billion). Japan based "Tokyo Otaku Mode" a place for news relating to Otaku has been liked on Facebook almost 10 million times.
Other classifications of otaku interests include vocaloid, cosplay, figures and professional wrestling as categorized by the Yano Research Institute. Yano Research reports and the tracks market growth and trends in sectors heavily influenced by otaku consumerism. In 2012, it noted around 30% growth in dating sim and online gaming otaku, while vocaloid, cosplay, idols and maid services grew by 10%, confirming its 2011 predictions.

</doc>
<doc id="22723" url="http://en.wikipedia.org/wiki?curid=22723" title="Object modeling language">
Object modeling language

An Object Modeling Language is a standardized set of symbols used to model a software system using an object-oriented framework. The symbols can be either informal or formal ranging from predefined graphical templates to formal object models defined by grammars and specifications.
A modeling language is usually associated with a methodology for object-oriented development. The modeling language defines the elements of the model. E.g., that a model has classes, methods, object properties, etc. The methodology defines the steps developers and users need to take to develop and maintain a software system. Steps such as "Define requirements", "Develop code", and "Test system". 
It is common to equate the modeling language and the modeling methodology. For example the Booch method may refer to Grady Booch's standard for diagramming, his methodology, or both. Or the Rumbaugh Object Modeling Technique is both a set of diagrams and a process model for developing object-oriented systems.
In the early years of the object-oriented community there were several competing modeling and methodology standards. Booch and Rumbaugh were two of the most popular. Ivar Jacobson's Objectory, Shlaer-Mellor,and Yourdon-Coad were also popular.
However, the object-oriented community values re-use and standardization. As shown in the graphic there were efforts starting in the mid '90's to reconcile the leading models and focus on one unified specification. The graphic shows the evolution of one of the most important object modeling language standards: the Unified Modeling Language (UML).
The UML began as an attempt by some of the major thought leaders in the community to define a standard language at the OOPSLA '95 Conference. Originally, Grady Booch and James Rumbaugh merged their models into a unified model. This was followed by Booch's company Rational Software purchasing Ivar Jacobson's Objectory company and merging their model into the UML. At the time Rational and Objectory were two of the dominant players in the small world of independent vendors of Object-Oriented tools and methods.
The Object Management Group then picked up and took over ownership of the UML. The OMG is one of the most influential standards organizations in the object-oriented world. The UML is both a formal metamodel and a collection of graphical templates. The meta-model defines the elements in an object-oriented model such as classes and properties. It is essentially the same thing as the meta-model in object-oriented languages such as Smalltalk or CLOS. However, in those cases the meta-model is meant primarily to be used by developers at run time to dynamically inspect and modify an application object model. The UML meta-model provides a mathematical formal foundation for the various graphic views used by the modeling language to describe an emerging system.
The following diagram illustrates the class hierarchy of the various graphic templates defined by the UML. "Structure diagrams" define the static structure of an object: its place in the class hierarchy, its relation to other objects, etc. "Behavior diagrams" specify the dynamic aspects of the model, business process logic, coordination and timing of distributed objects, etc. 

</doc>
<doc id="22725" url="http://en.wikipedia.org/wiki?curid=22725" title="On Fairy-Stories">
On Fairy-Stories

"On Fairy-Stories" is an essay by J. R. R. Tolkien which discusses the fairy-story as a literary form. It was initially written (and entitled simply "Fairy Stories") for presentation by Tolkien as the Andrew Lang lecture at the University of St Andrews, Scotland, in 1939. It first appeared in print, with some enhancement, in 1947, in a festschrift volume, "Essays Presented to Charles Williams", compiled by C. S. Lewis. Charles Williams, a friend of Lewis's, had been relocated with the Oxford University Press staff from London to Oxford during the London blitz in World War II. This allowed him to participate in gatherings of the Inklings with Lewis and Tolkien. The volume of essays was intended to be presented to Williams upon the return of the OUP staff to London with the ending of the war. However, Williams died suddenly on 15 May 1945, and the book was published as a memorial volume.
"On Fairy-Stories" was subsequently published with "Leaf by Niggle" in "Tree and Leaf", as well as in "The Tolkien Reader", published in 1966. The length of the essay, as it appears in "Tree and Leaf", is 60 pages, including about ten pages of notes.
The essay is significant because it contains Tolkien's explanation of his philosophy on fantasy and thoughts on mythopoiesis. Moreover, the essay is an early analysis of speculative fiction by one of the most important authors in the genre.
Literary context.
Tolkien was among the pioneers of the genre that we would now call fantasy writing. In particular, his stories – together with those of C. S. Lewis — were among the first to establish the convention of an alternative world or universe as the setting for speculative fiction. Most earlier works with styles similar to Tolkien's, such as the science fiction of H.G. Wells or the Gothic romances of Mary Shelley, were set in a world that is recognisably that of the author and introduced only a single fantastic element—or at most a fantastic milieu within the author's world, as with Lovecraft or Howard. Tolkien departed from this; his work was nominally part of the history of our own world, but did not have the close linkage to history or contemporary times that his precursors had.
The essay "On Fairy-Stories" is an attempt to explain and defend the genre of fairy tales or "Märchen". It distinguishes "Märchen" from "traveller's tales" (such as "Gulliver's Travels"), science fiction (such as H.G. Wells's "The Time Machine"), beast tales (such as Aesop's Fables and "Peter Rabbit"), and dream stories (such as "Alice in Wonderland"). One touchstone of the authentic fairy tale is that it is presented as wholly credible. "It is at any rate essential to a genuine fairy-story, as distinct from the employment of this form for lesser or debased purposes, that it should be presented as 'true.' ...But since the fairy-story deals with 'marvels,' it cannot tolerate any frame or machinery suggesting that the whole framework in which they occur is a figment or illusion."
Tolkien emphasises that through the use of fantasy, which he equates with fancy and imagination, the author can bring the reader to experience a world which is consistent and rational, under rules other than those of the normal world. He calls this "a rare achievement of Art," and notes that it was important to him as a reader: "It was in fairy-stories that I first divined the potency of the words, and the wonder of things, such as stone, and wood, and iron; tree and grass; house and fire; bread and wine."
Tolkien suggests that fairy stories allow the reader to review his own world from the "perspective" of a different world. This concept, which shares much in common with phenomenology, Tolkien calls "recovery," in the sense that one's unquestioned assumptions might be recovered and changed by an outside perspective. Second, he defends fairy stories as offering escapist pleasure to the reader, justifying this analogy: a prisoner is not obliged to think of nothing but cells and wardens. And third, Tolkien suggests that fairy stories can provide moral or emotional consolation, through their happy ending, which he terms a "eucatastrophe".
In conclusion and as expanded upon in an epilogue, Tolkien asserts that a truly good and representative fairy story is marked by joy: "Far more powerful and poignant is the effect [of joy] in a serious tale of Faerie. In such stories, when the sudden turn comes, we get a piercing glimpse of joy, and heart's desire, that for a moment passes outside the frame, rends indeed the very web of story, and lets a gleam come through." Tolkien sees Christianity as partaking in and fulfilling the overarching mythological nature of the cosmos: "I would venture to say that approaching the Christian story from this perspective, it has long been my feeling (a joyous feeling) that God redeemed the corrupt making-creatures, men, in a way fitting to this aspect, as to others, of their strange nature. The Gospels contain a fairy-story, or a story of a larger kind which embraces all the essence of fairy-stories. ...and among its marvels is the greatest and most complete conceivable eucatastrophe. The Birth of Christ is the eucatastrophe of Man's history. The Resurrection is the eucatastrophe of the story of the Incarnation."

</doc>
<doc id="22727" url="http://en.wikipedia.org/wiki?curid=22727" title="Otaku no Video">
Otaku no Video

Otaku no Video (おたくのビデオ, Otaku no Bideo, lit. "Geeks' Video") is a 1991 comedy anime spoofing the life and culture of otaku, individuals with obsessive interests in media, particularly anime and manga, as well as the history of Gainax, its creators. It is noted for its mix of conventional documentary film styles (with actual film, no less), with a more traditional anime storytelling fashion. It is licensed in the United States by AnimEigo. The "DAICON III and IV Opening Animations" from the early eighties are also featured in this OVA.
Plot summary.
The story begins in "Otaku No Video 1982", where the main character is a normal Japanese male, Ken Kubo, living quite happily in Japan during the year 1982 with his girlfriend Yoshiko and as a member of his college's tennis team, until he meets one of his former friends from high school, Tanaka. After Tanaka brings him into his circle of friends (all of them being otaku, too: a female illustrator, an information geek, a martial artist, and a weapons collector), Kubo soon makes the wish to become the "Otaking", the King of all the otaku.
Kubo's quest continues in "More Otaku No Video 1985", set 3 years later. He manages to create his own model kits, open shops, and even build a factory in China. Later, he loses it all when one of his rivals (who's also married to Yoshiko, who never forgave Kubo for abandoning her) takes control of his enterprise with Tanaka's unwitting aid. But after Kubo and Tanaka make peace, teaming up with hard-working artist Misuzu, Kubo and friends successfully take over the anime industry with a magical girl show, "Misty May", during the nineties. Once they have reached the peak of their ambitions, Ken and Tanaka create Otakuland in 1999, the equivalent of Disneyland for otaku (the story suggests Otakuland to be located in the same city of Urayasu, Chiba Prefecture, as the original Tokyo Disneyland.)
Many years later, Ken and Tanaka return to Otakuland in a post-apocalyptic submerged Japan and find its central structure, a giant robot, converted into a functional spaceship piloted by their old otaku friends. Miraculously rejuvenated, they fly off to space in search of the planet of Otaku.
"A Portrait of an Otaku".
A controversial and humorous part of "Otaku no Video" was the inclusion of live-action documentary excerpts, titled "A Portrait of an Otaku". In these segments, the documentary crew would interview an anonymous otaku, typically ashamed at being a fan and whose face are censored with a mosaic and have their voices digitally masked. The mock documentary segments serve as a counterpoint to the anime: while the anime emphasizes the camaradrie, creativity, and dreams of mainstream acceptance of otaku, the mock interviews exaggerate its negative qualities. The subjects run the gamut of the otaku subculture: the interviews cover a cosplayer who now works as a computer programmer and outright denies his cosplay days, even when presented with photographic evidence, but keeps his Char Aznable helmet in his desk drawer, an airsoft otaku, a garage kit otaku, and a shut-in who videorecords television programs for trade, but has not actually watched anything he's recorded. The interviews also contain fans who engage in a range of illicit or unsavory activities, such as cel thieves, a pornography fan attempting to manufacture glasses to defeat the mosaic censorship common in Japanese porno videos and who is shown masturbating during the interview, and a computer gamer -famous Gainax member Hideaki Anno- obsessed with a character in a hentai computer game (Noriko from "Gunbuster" -one of Anno's works- who makes a cameo in Gainax's own hentai game: "Cybernetic High School").
It is believed that all the subjects in the Portrait of an Otaku segments were Gainax employees or connected to Gainax at the time of filming. The first otaku interviewed bore a remarkable resemblance to Toshio Okada, a principal founder in Gainax, in both background and physical appearance. The gaijin otaku, Shon Hernandez, has been confirmed to have been Craig York, who with Shon Howell and Lea Hernandez, whose names were borrowed for the character", were the main staff of General Products USA, an early western branch of Gainax's merchandising in the early 1990s. The interview with "Shon Hernandez" has been a point of contention with Lea Hernandez, who, in an interview with "PULP magazine", noted that the interview was unscripted and that Craig York had been fairly sincere in his thoughts and had felt that Gainax insulted their American members. In the interview, the words spoken by Shon Hernandez in the background are noticeably different from what is shown on screen via subtitle (which is based on the Japanese voiceover "translation").
At FanimeCon 2003, Hiroshi Sato, an animator and another Gainax member, mentioned that he had been in one of the interviews in "Otaku no Video". In "Otaku no Video", the garage kit otaku was given the pseudonym "Sato Hiroshi" for the interview.
Production and release.
Since "Otaku no Video" was partially based in the personal life of the original creators of Gainax, who started their careers as otaku during the late seventies and the beginning of the eighties, many anime titles from that period are shown as footage or referenced in the OVA (in costumes, cosplay or other related material). Among them are "Gatchaman", "Uchuu Senkan Yamato", "Urusei Yatsura", "Captain Harlock", "Mobile Suit Gundam", "Space Adventure Cobra", "Phoenix 2772", "Magical Princess Minky Momo", "The Super Dimension Fortress Macross", "", "The Wings of Honneamise", "Top wo Nerae!" and the "Daicon III and IV Opening Animations".
"Otaku no Video" was released with subtitles in North America by AnimEigo on March 17, 1993.

</doc>
<doc id="22735" url="http://en.wikipedia.org/wiki?curid=22735" title="Original sin">
Original sin

Original sin, also called ancestral sin, is the Christian doctrine of humanity's state of sin resulting from the fall of man, stemming from Adam's rebellion in Eden. This condition has been characterized in many ways, ranging from something as insignificant as a slight deficiency, or a tendency toward sin yet without collective guilt, referred to as a "sin nature", to something as drastic as total depravity or automatic guilt of all humans through collective guilt.
The concept of original sin was first alluded to in the 2nd century by Irenaeus, Bishop of Lyons in his controversy with certain dualist Gnostics. Other church fathers such as Augustine also developed the doctrine, seeing it as based on the New Testament teaching of Paul the Apostle ( and ) and the Old Testament verse of . Tertullian, Cyprian, Ambrose and Ambrosiaster considered that humanity shares in Adam's sin, transmitted by human generation. Augustine's formulation of original sin was popular among Protestant reformers, such as Martin Luther and John Calvin, who equated original sin with concupiscence, affirming that it persisted even after baptism and completely destroyed freedom. The Jansenist movement, which Catholic Church then declared heretical, also maintained that original sin destroyed freedom of will.
Jewish theologians are divided in regard to the cause of what is called "original sin". Some teach that it was due to Adam's yielding to temptation in eating of the forbidden fruit and has been inherited by his descendants; the majority, however, do not hold Adam responsible for the sins of humanity, teaching that, in Genesis 8:21 and 6:5-8, God recognized that Adam's sins are his alone. However, Adam is recognized by some as having brought death into the world by his disobedience. Because of his sin, his descendants will live a mortal life, which will end in death of their bodies. The doctrine of "inherited sin" is not found in most of mainstream Judaism. Although some in Orthodox Judaism place blame on Adam for overall corruption of the world, and though there were some Jewish teachers in Talmudic times who believed that death was a punishment brought upon humanity on account of Adam's sin, that is not the dominant view in most of Judaism today. Modern Judaism generally teaches that humans are born sin-free and untainted, and choose to sin later and bring suffering to themselves. The concept of inherited sin is also not found in any real form in Islam. Some interpretations of original sin are rejected by other Christian theologies.
History of the doctrine.
The formalized doctrine of original sin was first developed in the 2nd-century by Irenaeus, the Bishop of Lyons, in his struggle against Gnosticism. Irenaeus contrasted their doctrine with the view that the Fall was a step in the wrong direction by Adam, with whom, Irenaeus believed, his descendants had some solidarity or identity. Irenaeus believed that Adam's sin had grave consequences for humanity, that it is the source of human sinfulness, mortality and enslavement to sin, and that all human beings participate in his sin and share his guilt.
The Greek Fathers emphasized the cosmic dimension of the Fall, namely that since Adam human beings are born into a fallen world, but held fast to belief that man, though fallen, is free. They thus did not teach that human beings are deprived of free will and involved in total depravity, which is one understanding of original sin. During this period the doctrines of human depravity and the inherently sinful nature of human flesh were taught by Gnostics, and orthodox Christian writers took great pains to counter them. Christian Apologists insisted that God's future judgment of humanity implied humanity must have the ability to live righteously.
Augustine.
Augustine of Hippo (354–430) taught that Adam's sin is transmitted by concupiscence, or "hurtful desire", resulting in humanity becoming a "massa damnata" (mass of perdition, condemned crowd), with much enfeebled, though not destroyed, freedom of will. When Adam sinned, human nature was thenceforth transformed. Adam and Eve, via sexual reproduction, recreated human nature. Their descendants now live in sin, in the form of concupiscence, a term Augustine used in a metaphysical, not a psychological sense. Augustine insisted that concupiscence was not "a being" but a "bad quality", the privation of good or a wound. He admitted that sexual concupiscence ("libido") might have been present in the perfect human nature in paradise, and that only later it became disobedient to human will as a result of the first couple's disobedience to God's will in the original sin. In Augustine's view (termed "Realism"), all of humanity was really present in Adam when he sinned, and therefore all have sinned. Original sin, according to Augustine, consists of the guilt of Adam which all humans inherit. As sinners, humans are utterly depraved in nature, lack the freedom to do good, and cannot respond to the will of God without divine grace. Grace is irresistible, results in conversion, and leads to perseverance.
Augustine articulated his explanation in reaction to Pelagianism, which insisted that humans have of themselves, without the necessary help of God's grace, the ability to lead a morally good life, and thus denied both the importance of baptism and the teaching that God is the giver of all that is good. Pelagius claimed that the influence of Adam on other humans was merely that of bad example. Augustine held that the effects of Adam's sin are transmitted to his descendants not by example but by the very fact of generation from that ancestor. A wounded nature comes to the soul and body of the new person from his/her parents, who experience "libido" (or "concupiscence"). Augustine's view was that human procreation was the way the transmission was being effected. He did not blame, however, the sexual passion itself, but the spiritual "concupiscence" present in human nature, soul and body, even after baptismal regeneration. Christian parents transmit their wounded nature to children, because they give them birth, not the "re-birth". Augustine used Ciceronian Stoic concept of passions, to interpret St. Paul's doctrine of universal sin and redemption. In that view, also sexual desire itself as well as other bodily passions were consequence of the original sin, in which pure affections were wounded by vice and became disobedient to human reason and will. As long as they carry a threat to the dominion of reason over the soul they constitute moral evil, but since they do not presuppose consent, one cannot call them sins. Humanity will be liberated from passions, and pure affections will be restored only when all sin has been washed away and ended, that is in the resurrection of the dead.
Augustine believed that the only definitive destinations of souls are heaven and hell. He concluded that unbaptized infants go to hell as a consequence of original sin. The Latin Church Fathers who followed Augustine adopted his position, which became a point of reference for Latin theologians in the Middle Ages. In the later medieval period, some theologians continued to hold Augustine's view, others held that unbaptized infants suffered no pain at all: unaware of being deprived of the beatific vision, they enjoyed a state of natural, not supernatural happiness. Starting around 1300, unbaptized infants were often said to inhabit the "limbo of infants". The declares: "As regards children who have died without Baptism, the Church can only entrust them to the mercy of God, as she does in her funeral rites for them. Indeed, the great mercy of God who desires that all men should be saved, and Jesus' tenderness toward children which caused him to say: 'Let the children come to me, do not hinder them,' allow us to hope that there is a way of salvation for children who have died without Baptism. All the more urgent is the Church's call not to prevent little children coming to Christ through the gift of holy Baptism." But the theory of Limbo, while it "never entered into the dogmatic definitions of the Magisterium ... remains ... a possible theological hypothesis".
Cassian.
In the works of John Cassian (ca. 360 – 435), "Conference" XIII recounts how the wise monk Chaeremon, of whom he is writing, responded to puzzlement caused by his own statement that "man even though he strive with all his might for a good result, yet cannot become master of what is good unless he has acquired it simply by the gift of Divine bounty and not by the efforts of his own toil" (chapter 1). In chapter 11, Cassian presents Chaeremon as speaking of the cases of Paul the persecutor and Matthew the publican as difficulties for those who say "the beginning of free will is in our own power", and the cases of Zaccheus and the good thief on the cross as difficulties for those who say "the beginning of our free will is always due to the inspiration of the grace of God", and as concluding: "These two then; viz., the grace of God and free will seem opposed to each other, but really are in harmony, and we gather from the system of goodness that we ought to have both alike, lest if we withdraw one of them from man, we may seem to have broken the rule of the Church's faith: for when God sees us inclined to will what is good, He meets, guides, and strengthens us: for 'At the voice of thy cry, as soon as He shall hear, He will answer thee'; and: 'Call upon Me', He says, 'in the day of tribulation and I will deliver thee, and thou shalt glorify Me'. And again, if He finds that we are unwilling or have grown cold, He stirs our hearts with salutary exhortations, by which a good will is either renewed or formed in us."
Cassian did not accept the idea of total depravity, on which Martin Luther was to insist. He taught that human nature is fallen or depraved, but not totally. Augustine Casiday states that, at the same time, Cassian "baldly asserts that God's grace, not human free will, is responsible for 'everything which pertains to salvation' – even faith." Cassian pointed out that people still have moral freedom and one has the option to choose to follow God. Colm Luibhéid says that, according to Cassian, there are cases where the soul makes the first little turn, but in Cassian's view, according to Casiday, any sparks of goodwill that may exist, not "directly" caused by God, are totally inadequate and only "direct" divine intervention ensures spiritual progress. and Lauren Pristas says that "for Cassian, salvation is, from beginning to end, the effect of God's grace."
Church reaction.
Opposition to Augustine's ideas about original sin, which he had developed in reaction to Pelagianism, arose rapidly. After a long and bitter struggle the general principles of Augustine's teaching were confirmed within Western Christianity by many councils, especially the Second Council of Orange in 529. However, while the Church condemned Pelagius, it did not endorse Augustine entirely and, while Augustine's authority was accepted, he was interpreted in the light of writers such as Cassian. Some of the followers of Augustine identified original sin with concupiscence in the psychological sense, but this identification was challenged by the 11th-century Saint Anselm of Canterbury, who defined original sin as "privation of the righteousness that every man ought to possess", thus separating it from concupiscence. In the 12th century the identification of original sin with concupiscence was supported by Peter Lombard and others, but was rejected by the leading theologians in the next century, chief of whom was Thomas Aquinas. He distinguished the supernatural gifts of Adam before the Fall from what was merely natural, and said that it was the former that were lost, privileges that enabled man to keep his inferior powers in submission to reason and directed to his supernatural end. Even after the fall, man thus kept his natural abilities of reason, will and passions. Rigorous Augustine-inspired views persisted among the Franciscans, though the most prominent Franciscan theologians, such as Duns Scotus and William of Ockham, eliminated the element of concupiscence.
Protestant reformation.
Martin Luther (1483–1546) asserted that humans inherit Adamic guilt and are in a state of sin from the moment of conception. The second article in Lutheranism's Augsburg Confession presents its doctrine of original sin in summary form:
It is also taught among us that since the fall of Adam all men who are born according to the course of nature are conceived and born in sin. That is, all men are full of evil lust and inclinations from their mothers' wombs and are unable by nature to have true fear of God and true faith in God. Moreover, this inborn sickness and hereditary sin is truly sin and condemns to the eternal wrath of God all those who are not born again through Baptism and the Holy Spirit. Rejected in this connection are the Pelagians and others who deny that original sin is sin, for they hold that natural man is made righteous by his own powers, thus disparaging the sufferings and merit of Christ.
Luther, however, also agreed with the Roman Catholic doctrine of the Immaculate Conception (that Mary was conceived free from original sin) by saying:
[Mary] is full of grace, proclaimed to be entirely without sin. God's grace fills her with everything good and makes her devoid of all evil. God is with her, meaning that all she did or left undone is divine and the action of God in her. Moreover, God guarded and protected her from all that might be hurtful to her.
Protestant Reformer John Calvin (1509–1564) developed a systematic theology of Augustinian Protestantism by interpretation of Augustine of Hippo's notion of original sin. Calvin believed that humans inherit Adamic guilt and are in a state of sin from the moment of conception. This inherently sinful nature (the basis for the Calvinistic doctrine of "total depravity") results in a complete alienation from God and the total inability of humans to achieve reconciliation with God based on their own abilities. Not only do individuals inherit a sinful nature due to Adam's fall, but since he was the federal head and representative of the human race, all whom he represented inherit the guilt of his sin by imputation. Redemption by Jesus Christ is the only remedy.
John Calvin defined original sin in his "Institutes of the Christian Religion" as follows: Original sin, therefore, seems to be a hereditary depravity and corruption of our nature, diffused into all parts of the soul, which first makes us liable to God's wrath, then also brings forth in us those works which Scripture calls "works of the flesh" (Gal 5:19). And that is properly what Paul often calls sin. The works that come forth from it – such as adulteries, fornications, thefts, hatreds, murders, carousings – he accordingly calls "fruits of sin" (Gal 5:19–21), although they are also commonly called "sins" in Scripture, and even by Paul himself.
Council of Trent.
The Council of Trent (1545–1563), while not pronouncing on points disputed among Catholic theologians, condemned the teaching that in baptism the whole of what belongs to the essence of sin is not taken away, but is only cancelled or not imputed, and declared the concupiscence that remains after baptism not truly and properly "sin" in the baptized, but only to be called sin in the sense that it is of sin and inclines to sin.
In 1567, soon after the close of the Council of Trent, Pope Pius V went beyond Trent by sanctioning Aquinas's distinction between nature and supernature in Adam's state before the Fall, condemned the identification of original sin with concupiscence, and approved the view that the unbaptized could have right use of will.
Denominational views.
Roman Catholicism.
The "Catechism of the Catholic Church" says:
By his sin Adam, as the first man, lost the original holiness and justice he had received from God, not only for himself but for all humans.
Adam and Eve transmitted to their descendants human nature wounded by their own first sin and hence deprived of original holiness and justice; this deprivation is called "original sin".
As a result of original sin, human nature is weakened in its powers, subject to ignorance, suffering and the domination of death, and inclined to sin (this inclination is called "concupiscence").
The Catholic Church teaches that every human person born on this earth is made in the image of God. Within man "is both the powerful surge toward the good because we are made in the image of God, and the darker impulses toward evil because of the effects of Original Sin." Furthermore, it explicitly denies that we inherit "guilt" from anyone, maintaining that instead we inherit our fallen nature. In this it differs from the Calvinism/Protestant position that each person actually inherits Adam's guilt, and teaches instead that "original sin does not have the character of a personal fault in any of Adam's descendants ... but the consequences for nature, weakened and inclined to evil, persist in man". "In other words, human beings do not bear any 'original guilt' from Adam and Eve's particular sin."
The Church has always held baptism to be "for the remission of sins", and, as mentioned in , infants too have traditionally been baptized, though not guilty of any actual personal sin. The sin that through baptism was remitted for them could only be original sin, with which they were connected by the very fact of being a human. The first comprehensive theological explanation of this practice of baptizing infants, guilty of no actual personal sin, was given by Saint Augustine of Hippo, not all of whose ideas on original sin have been adopted by the Catholic Church. Indeed the Church has condemned the interpretation of some of his ideas by certain leaders of the Protestant Reformation.
The "Catechism of the Catholic Church" explains that in "yielding to the tempter, Adam and Eve committed a "personal sin", but this sin affected "the human nature" that they would then transmit in a "fallen state" ... original sin is called "sin" only in an analogical sense: it is a sin "contracted" and not "committed"—a state and not an act" ( This "state of deprivation of the original holiness and justice ... transmitted to the descendants of Adam along with human nature" ( involves no personal responsibility or personal guilt on their part (cf. "Catechism of the Catholic Church", 405). Personal responsibility and guilt were Adam's, who because of his sin, was unable to pass on to his descendants a human nature with the holiness with which it would otherwise have been endowed, in this way implicating them in his sin. The doctrine of original sin thus does not impute the sin of the father to his children, but merely states that they inherit from him a "human nature deprived of original holiness and justice", which is "transmitted by propagation to all mankind".
In the theology of the Catholic Church, original sin is regarded as the general condition of sinfulness, that is (the absence of holiness and perfect charity) into which humans are born, distinct from the actual sins that a person commits. This teaching explicitly states that "original sin does not have the character of a personal fault in any of Adam's descendants". In other words, human beings do not bear any "original guilt" from Adam's particular sin, which is his alone. The prevailing view, also held in Eastern Orthodoxy, is that human beings bear no guilt for the sin of Adam. The Catholic Church teaches: "By our first parents' sin, the devil has acquired a certain domination over man, even though "man remains free"."
The Catholic doctrine of the Immaculate Conception of Mary is that Mary was conceived free from original sin: "the most Blessed Virgin Mary was, from the first moment of her conception, by a singular grace and privilege of almighty God and by virtue of the merits of Jesus Christ, Savior of the human race, preserved immune from all stain of original sin." The doctrine sees her as an exception to the general rule that human beings are not immune from the reality of original sin.
Eastern Orthodoxy.
The Eastern Orthodox's version of "original sin" is the view that sin originates with the Devil, "for the devil sinneth from the beginning. (1 John iii. 8)". They acknowledge that the introduction of ancestral sin into the human race affected the subsequent environment for humanity (see also traducianism). However, they never accepted Augustine of Hippo's notions of original sin and hereditary guilt.
Orthodox Churches accept the teachings of John Cassian, as do Catholic Churches eastern and western, in rejecting the doctrine of Total Depravity, by teaching that human nature is "fallen", that is, depraved, but not totally. Augustine Casiday states that Cassian "baldly asserts that God's grace, not human free will, is responsible for 'everything which pertains to salvation' – even faith." Cassian points out that people still have moral freedom and one has the option to choose to follow God. Colm Luibhéid says that, according to Cassian, there are cases where the soul makes the first little turn, while Augustine Casiday says that, in Cassian's view, any sparks of goodwill that may exist, not "directly" caused by God, are totally inadequate and only "direct" divine intervention ensures spiritual progress. and Lauren Pristas says that "for Cassian, salvation is, from beginning to end, the effect of God's grace."
Eastern Orthodoxy accepts the doctrine of ancestral sin: "Original sin is hereditary. It did not remain only Adam and Eve's. As life passes from them to all of their descendants, so does original sin." "As from an infected source there naturally flows an infected stream, so from a father infected with sin, and consequently mortal, there naturally proceeds a posterity infected like him with sin, and like him mortal."
The Orthodox Church in America makes clear the distinction between "fallen nature" and "fallen man" and this is affirmed in the early teaching of the Church whose role it is to act as the catalyst that leads to true or inner redemption. Every human person born on this earth bears the image of God undistorted within themselves. In the Orthodox Christian understanding, they explicitly deny that humanity inherited "guilt" from anyone. Rather, they maintain that we inherit our fallen nature. While humanity does bear the consequences of the original, or first, sin, humanity does not bear the personal guilt associated with this sin. Adam and Eve are guilty of their willful action; we bear the consequences, chief of which is death."
On whether Mary actually ever sinned, or was stained by original sin, the view of the Eastern Orthodox Church varies, though there is general agreement that she was cleansed from sin at the Annunciation.
Classical Anglicanism.
The original formularies of the Church of England also continue in the Reformation understanding of Original Sin. In the Thirty-Nine Articles, Article IX "Of Original or Birth-sin" states:
Original Sin standeth not in the following of Adam, (as the Pelagians do vainly talk;) but it is the fault and corruption of the Nature of every man, that naturally is ingendered of the offspring of Adam; whereby man is very far gone from original righteousness, and is of his own nature inclined to evil, so that the flesh lusteth always contrary to the spirit; and therefore in every person born into this world, it deserveth God's wrath and damnation. And this infection of nature doth remain, yea in them that are regenerated; whereby the lust of the flesh, called in the Greek, Φρονεμα σαρκος, which some do expound the wisdom, some sensuality, some the affection, some the desire, of the flesh, is not subject to the Law of God. And although there is no condemnation for them that believe and are baptized, yet the Apostle doth confess, that concupiscence and lust hath of itself the nature of sin.
However, more recent doctrinal statements (e.g. the 1938 report "Doctrine in the Church of England") permit a greater variety of understandings of this doctrine. The 1938 report summarizes:
Man is by nature capable of communion with God, and only through such communion can he become what he was created to be. "Original sin" stands for the fact that from a time apparently prior to any responsible act of choice man is lacking in this communion, and if left to his own resources and to the influence of his natural environment cannot attain to his destiny as a child of God.
Methodism.
The Methodist Church upholds Article VII in the Articles of Religion in the "Book of Discipline of the United Methodist Church": Original sin standeth not in the following of Adam (as the Pelagians do vainly talk), but it is the corruption of the nature of every man, that naturally is engendered of the offspring of Adam, whereby man is very far gone from original righteousness, and of his own nature inclined to evil, and that continually.
Seventh-day Adventism.
Seventh-day Adventists believe that humans are inherently sinful due to the fall of Adam, but they do not totally accept the Augustinian/Calvinistic understanding of original sin, taught in terms of original guilt, but hold more to what could be termed the "total depravity" tradition. Seventh-day Adventists have historically preached a doctrine of inherited weakness, but not a doctrine of inherited guilt. According to Augustine and Calvin, humanity inherits not only Adam's depraved nature but also the actual guilt of his transgression, and Adventists look more toward the Wesleyan model.
In part, the Adventist position on original sin reads:
The nature of the penalty for original sin, i.e., Adam's sin, is to be seen as literal, physical, temporal, or actual death – the opposite of life, i.e., the cessation of being. By no stretch of the scriptural facts can death be spiritualised as depravity. God did not punish Adam by making him a sinner. That was Adam’s own doing. All die the first death because of Adam’s sin regardless of their moral character – children included.
Early Adventists Pioneers (such as George Storrs and Uriah Smith) tended to de-emphasise the morally corrupt nature inherited from Adam, while stressing the importance of actual, personal sins committed by the individual. They thought of the "sinful nature" in terms of physical mortality rather than moral depravity. Traditionally, Adventists look at sin in terms of willful transgressions, and that Christ triumphed over sin. Adventism believes that Christ is both our Substitute and our Example. They base their belief on texts such as "Whosoever committeth sin transgresseth also the law: for sin is the transgression of the law." (1 John 3:4)
Though believing in the concept of inherited sin from Adam, there is no dogmatic Adventist position on original sin. Related articles dealing with the subject are publicly available on the General Conference of the Seventh-day Adventist Church’s official website on theological doctrine, the Biblical Research Institute.
Jehovah's Witnesses.
According to Jehovah's Witnesses, all humans are born sinners and inherit sin, corruption, and death from Adam. They believe Adam was originally created perfect and sinless, but with free will; the Devil, who was originally a perfect angel, but later developed feelings of pride and self-importance, seduced Eve, and then through her, persuaded Adam to disobey God, and to obey the Devil instead, rebelling against God's sovereignty, making themselves sinners and transmitting a sinful nature to their offspring. Instead of destroying the Devil right away, as well as destroying the disobedient couple, God decided to test the loyalty of the rest of humankind, and to prove to that man cannot be independent of God successfully, that man is lost without God's laws and standards, and can never bring peace to the earth, and that Satan was a deceiver, murderer, and liar.
Witnesses believe that all men possess "inherited sin" from the "one man" Adam, and that man is born corrupt, and dies because of inherited sin and imperfection, that inherited sin is the reason and cause for sickness and suffering, made worse by the Devil's wicked influence. They believe Jesus is the "second Adam", being the sinless Son of God and the Messiah, and that he came to undo Adamic sin; and that salvation and everlasting life can only be obtained through faith and obedience to the second Adam. They believe that "sin" is "missing the mark" of God's standard of perfection, and that everyone is born a sinner, due to being the offspring of sinner Adam.
Mormonism.
The Book of Mormon, a text sacred to Mormonism, contains an original sin doctrine in which humanity inherited a fallen and depraved nature from Adam. Young children, however, are thought to be held innocent until an age of accountability. As Mormon doctrines developed, founder Joseph Smith ultimately taught that humans had an essentially godlike nature, and were not only holy in a premortal state, but could progress eternally to become like God. He wrote as an Article of Faith, "We believe that men will be punished for their own sins, and not for Adam’s transgression." Later Mormons took this creed as a rejection of the doctrine of original sin and any notion of inherited sinfulness. Thus, while modern Mormons will agree that the fall of Adam brought consequences to the world, including the possibility of sin, they generally reject the idea that any culpability is automatically transmitted to Adam and Eve's offspring.
Swedenborgianism.
In Swedenborgianism, exegesis of the first 11 chapters of Genesis from "The First Church", has a view that Adam is not an individual person. Rather, he is a symbolic representation of the "Most Ancient Church", having a more direct contact with heaven than all other successive churches. Swedenborg's view of original sin is referred to as "hereditary evil", which passes from generation to generation. It cannot be completely abolished by an individual man, but can be tempered when someone reforms their own life, and are thus held accountable only for their own sins.
Islam.
The concept of original sin is not recognized in Islam. Muslims believe that Adam and Eve were forgiven by God, and use the following Koranic "suras" to support this belief:
"O Adam, dwell with your wife in the Garden and enjoy as you wish but approach not this tree or you run into harm and transgression. Then Satan whispered to them in order to reveal to them their shame that was hidden from them and he said: 'Your Lord only forbade you this tree lest you become angels or such beings as live forever.' And he swore to them both that he was their sincere adviser. So by deceit he brought them to their fall: when they tasted the tree their shame became manifest to them and they began to sew together the leaves of the Garden over their bodies. And their Lord called unto them: 'Did I not forbid you that tree and tell you that Satan was your avowed enemy?'" Sūrat al-Aʻrāf:19–22.
"They said: 
'Our Lord, we have wronged ourselves souls. If You forgive us not and bestow not upon us Your mercy, we shall certainly be of the losers' " Surat al-Aʻraf :23
".. Thus did Adam disobey his Lord, so he went astray. Then his Lord chose him, and turned to him with forgiveness, and gave him guidance." Surat Ṭā Hāʼ:121–122
"(God) said: 
'Get down (from the Garden), one of you an enemy to the other [i.e. Adam, Eve, and Satan]. On earth will be a dwelling-place for you and an enjoyment – for a short time'. He (God) said: 'Therein you shall live, and therein you shall die, and from it you shall be brought out [i.e. resurrected].' " 
Surat al-Aʻraf:24–25.
"That no burdened person (with sins) shall bear the burden (sins) of another. And that man can have nothing but what he does (of good and bad). And that his deeds will be seen, Then he will be recompensed with a full and the best [fair] recompense." Surat an-Najm:38–41
Criticism.
Historian Robin Lane Fox argues that the foundation of the doctrine of "original sin", that was accepted by the Church, was based on a "mis-translation" of Paul the Apostle's Epistle to the Romans () by Augustine, in his "On the Grace of Christ, and on Original Sin".
In an 8-page contribution, I.J.J. Spangenberg has stated:
Darwin, did not set out to undermine the grand narrative of Christianity, but his theory of evolution through natural selection led to conclusions that were diametrically opposite to those that Christians traditionally believed and proclaimed. The research carried out under the paradigm of evolution brought to light that Augustine's convictions on "original sin" and death could no longer be held. However, conservative theologians and church members are reluctant to acknowledge this (Bowler 2007:225). Nevertheless, a change in traditional theology is a prerequisite for any meaningful dialogue between religion and science.
That what Spangenberg calls "traditional theology" is not the only accepted contemporary theology is evident from the writings of Reinhold Niebuhr and others reviewed in Jerry D. Korsmeyer's "Evolution and Eden" and Tatha Wiley's "Original Sin: Origins, Developments, Contemporary Meanings", and from the fact that, with regard to official Catholic Church doctrine on original sin, the authoritative "Catechism of the Catholic Church" "explicitly acknowledges that the account of the fall in Genesis 2 and 3 uses figurative language". Difficulty for what Spangenberg calls the dialogue between religion and science arises, in the view of Korsmeyer, from a confrontation between a few popularizers of scientific knowledge and "religious fundamentalists who consider that their religious knowledge includes scientific conclusions drawn from the Bible".

</doc>
<doc id="22738" url="http://en.wikipedia.org/wiki?curid=22738" title="Operation Enduring Freedom">
Operation Enduring Freedom

"Operation Enduring Freedom" (OEF) is the official name used by the government of the United States of America to describe the Global War on Terrorism.
The Operation comprises several subordinate operations:
Etymology.
The U.S. government used the term "Operation Enduring Freedom - Afghanistan" to officially describe the War in Afghanistan, from the period between October 2001 and December 2014. Continued operations in Afghanistan by the United States' military forces, both non-combat and combat, now occur under the name Operation Freedom's Sentinel.
The operation was originally called "Operation Infinite Justice", but as similar phrases have been used by adherents of several religions as an exclusive description of God, it is believed to have been changed to avoid offense to Muslims, who are the majority religion in Afghanistan. In September 2001, U.S. President George W. Bush's remark that "this crusade, this war on terrorism, is going to take a while", which prompted widespread criticism from the Islamic world, may also have contributed to the renaming of the operation.
The term "OEF-A" typically refers to the phase of the War in Afghanistan from 2001 to 2014. Other operations, such as the Georgia Train and Equip Program, are only loosely or nominally connected, such as through government funding vehicles. All the operations, however, have a focus on counterterrorism activities.
Operation Enduring Freedom – Afghanistan, which was a joint U.S., U.K., and Afghan operation, was separate from the International Security Assistance Force (ISAF), which was an operation of North Atlantic Treaty Organization nations including the U.S. and the U.K. The two operations ran in parallel, and although it had been suggested that they merge.
Overview.
In response to the attacks of 11 September, the early combat operations that took place on 7 October 2001 to include a mix of strikes from land-based B-1 Lancer, B-2 Spirit and B-52 Stratofortress bombers, carrier-based F-14 Tomcat and F/A-18 Hornet fighters, and Tomahawk cruise missiles launched from both U.S. and British ships and submarines signaled the start of Operation Enduring Freedom – Afghanistan (OEF-A).
The initial military objectives of OEF-A, as articulated by President George W. Bush in his 20 September Address to a Joint Session of Congress and his 7 October address to the country, included the destruction of terrorist training camps and infrastructure within Afghanistan, the capture of al-Qaeda leaders, and the cessation of terrorist activities in Afghanistan."
In January 2002, over 1,200 soldiers from the United States Special Operations Command Pacific (SOCPAC) deployed to the Philippines to support the Armed Forces of the Philippines (AFP) in their push to uproot terrorist forces on the island of Basilan. Of those groups included are Abu Sayyaf Group (ASG), al-Qaeda and Jemaah Islamiyah. The operation consisted of training the AFP in counter-terrorist operations as well as supporting the local people with humanitarian aid in Operation Smiles.
In October 2002, the Combined Task Force 150 and United States military Special Forces established themselves in Djibouti at Camp Lemonnier. The stated goals of the operation were to provide humanitarian aid and patrol the Horn of Africa to reduce the abilities of terrorist organizations in the region. Similar to OEF-P, the goal of humanitarian aid was emphasised, ostensibly to prevent militant organizations from being able to take hold amongst the population as well as reemerge after being removed.
The military aspect involves coalition forces searching and boarding ships entering the region for illegal cargo as well as providing training and equipment to the armed forces in the region. The humanitarian aspect involves building schools, clinics and water wells to enforce the confidence of the local people.
Since 2001, the cumulative expenditure by the U.S. government on Operation Enduring Freedom has exceeded $150 billion.
The operation continues, with military direction mostly coming from United States Central Command.
Operation Enduring Freedom – Afghanistan (OEF-A).
The Taliban.
Seizing upon a power vacuum after the Soviets withdrew from Afghanistan after their invasion, the Taliban assumed the role of government from 1996–2001. Their extreme interpretation of Islamic law prompted them to ban music, television, sports, and dancing, and enforce harsh judicial penalties (See Human rights in Afghanistan). Amputation was an accepted form of punishment for stealing, and public executions could often be seen at the Kabul football stadium. Women's rights groups around the world were frequently critical as the Taliban banned women from appearing in public or holding many jobs outside the home. They drew further criticism when they destroyed the Buddhas of Bamyan, historical statues nearly 1500 years old, because the Buddhas were considered idols.
In 1996, Saudi dissident Osama bin Laden moved to Afghanistan upon the invitation of the Northern Alliance leader Abdur Rabb ur Rasool Sayyaf. When the Taliban came to power, bin Laden was able to forge an alliance between the Taliban and his al-Qaeda organization. It is understood that al-Qaeda-trained fighters known as the 055 Brigade were integrated with the Taliban army between 1997 and 2001. It has been suggested that the Taliban and bin Laden had very close connections.
US-led coalition action.
On 20 September 2001, the U.S. stated that Osama bin Laden was behind the 11 September attacks in 2001. The US made a five-point ultimatum to the Taliban:
On 21 September 2001, the Taliban rejected this ultimatum, stating there was no evidence in their possession linking bin Laden to the 11 September attacks.
On 22 September 2001 the United Arab Emirates and later Saudi Arabia withdrew their recognition of the Taliban as the legal government of Afghanistan, leaving neighboring Pakistan as the only remaining country with diplomatic ties.
On 4 October 2001, it is believed that the Taliban covertly offered to turn bin Laden over to Pakistan for trial in an international tribunal that operated according to Islamic shar'ia law.
On 7 October 2001, the Taliban proposed to try bin Laden in Afghanistan in an Islamic court. This proposition was immediately rejected by the US. Later on the same day, United States and British forces initiated military action against the Taliban, bombing Taliban forces and al-Qaeda terrorist training camps.
On 14 October 2001, the Taliban proposed to hand bin Laden over to a third country for trial, but only if they were given evidence of bin Laden's involvement in the events of 11 September 2001. The US rejected this proposal and military operations ensued.
The UN Security Council, on 16 January 2002, unanimously established an arms embargo and the freezing of identifiable assets belonging to bin Laden, al-Qaeda, and the remaining Taliban.
Combat operations start.
On Sunday 7 October 2001, American and British forces began an aerial bombing campaign targeting Taliban forces and al-Qaeda.
The Northern Alliance, aided by Joint Special Operations teams consisting of Green Berets from the 5th Special Forces Group, aircrew members from the 160th Special Operations Aviation Regiment (SOAR), and Air Force Combat Controllers, fought against the Taliban. Aided by U.S. bombing and massive defections, they captured Mazari Sharif on 9 November. They then rapidly gained control of most of northern Afghanistan, and took control of Kabul on 13 November after the Taliban unexpectedly fled the city. The Taliban were restricted to a smaller and smaller region, with Kunduz, the last Taliban-held city in the north, captured on 26 November. Most of the Taliban fled to Pakistan.
The war continued in the south of the country, where the Taliban retreated to Kandahar. After Kandahar fell in December, remnants of the Taliban and al-Qaeda continued to mount resistance. Meanwhile, in November 2001 the U.S. military and its allied forces established their first ground base in Afghanistan to the south west of Kandahar, known as FOB Rhino.
The Battle of Tora Bora, involving U.S., British and Northern Alliance forces took place in December 2001 to further destroy the Taliban and suspected al-Qaeda in Afghanistan. In early March 2002 the United States military, along with allied Afghan military forces, conducted a large operation to destroy al-Qaeda in an operation code-named Operation Anaconda.
The operation was carried out by elements of the United States 10th Mountain Division, 101st Airborne Division, the U.S. special forces groups TF 11, TF Bowie, TF Dagger, TF K-Bar, British Royal Marines, the Norwegian Forsvarets Spesialkommando (FSK), Hærens Jegerkommando and Marinejegerkommandoen, Canada's 3rd Battalion Princess Patricia's Canadian Light Infantry, Canada's Joint Task Force 2, the German KSK, and elements of the Australian Special Air Service Regiment and of the New Zealand Special Air Service and the Afghan National Army.
After managing to evade U.S. forces throughout the summer of 2002, the remnants of the Taliban gradually began to regain their confidence. A U.S. and Canadian led operation (supported by British and Dutch forces), Operation Mountain Thrust was launched in May 2006 to counter renewed Taliban insurgency.
Since January 2006, the NATO International Security Assistance Force undertook combat duties from Operation Enduring Freedom in southern Afghanistan, the NATO force chiefly made up of British, Canadian and Dutch forces (and some smaller contributions from Denmark, Romania and Estonia and air support from Norway as well as air and artillery support from the U.S.) ("see the article Coalition combat operations in Afghanistan in 2006"). The United States military also conducts military operations separate from NATO as part of Operation Enduring Freedom in other parts of Afghanistan, in areas such as Kandahar, Bagram, and Kabul (including Camp Eggers and Camp Phoenix.)
International support.
The United States was supported by during Operation Enduring Freedom (OEF) in Afghanistan in 2001–2003 and in subsequent coalition operations directly or indirectly in support of OEF. See the article Afghanistan War order of battle for the current disposition of coalition forces in Afghanistan.
Result.
The U.S.-led coalition initially removed the Taliban from power and seriously crippled al-Qaeda and associated militants in Afghanistan. However, success in quelling the Taliban insurgency since the 2001 invasion has been mixed. Many believe the Taliban cannot be defeated as long as it has sanctuary in neighboring Pakistan and that Operation Enduring Freedom has transformed into a continuing full-fledged war with no end in sight.
On 9 October 2004, Afghanistan elected Hamid Karzai president in its first direct elections. The following year, Afghans conducted the Afghan parliamentary election, 2005 on 18 September. Since the invasion, hundreds of schools and mosques have been constructed, millions of dollars in aid have been distributed, and the occurrence of violence has been reduced.
While military forces interdict insurgents and assure security, Provincial reconstruction teams are tasked with infrastructure building, such as constructing roads and bridges, assisting during floods, and providing food and water to refugees. Many warlords have participated in an allegiance program, recognizing the legitimacy of the government of Afghanistan, and surrendering their soldiers and weapons; however, subsequent actions have led to questions about their true loyalties.
The Afghan National Army, Afghan National Police, and Afghan Border Police are being trained to assume the task of securing their nation.
On 31 December 2014, Operation Enduring Freedom - Afghanistan concluded, and was succeeded by Operation Freedom's Sentinel on 1 January 2015.
Criticism.
AFP, reporting on a news story in the Sunday, 3 April 2004, issue of "The New Yorker", wrote that retired Army Colonel Hy Rothstein, "who served in the Army Special Forces for more than 20 years, ...commissioned by The Pentagon to examine the war in Afghanistan concluded the conflict created conditions that have given 'warlordism, banditry and opium production a new lease on life'..."
The conduct of U.S. forces was criticised in a report entitled Enduring Freedom – Abuses by U.S. Forces in Afghanistan by U.S.-based human rights group Human Rights Watch in 2004. Some Pakistani scholars, such as Masood Ashraf Raja, editor of , have also provided a more specific form of criticism that relates to the consequences of the Global War on Terrorism on the region.
Operation Enduring Freedom – Philippines (OEF-P).
Abu Sayyaf Group.
The Abu Sayyaf Group (ASG) Al Harakat Al Islamiyya, is deemed a "foreign terrorist organization" by the United States government. Specifically, it is an Islamist separatist group based in and around the southern islands of the Republic of the Philippines, primarily Jolo, Basilan, and Mindanao.
Since inception in the early 1990s, the group has carried out bombings, assassinations, kidnappings, and extortion in their fight for an independent Islamic state in western Mindanao and the Sulu Archipelago. Its claimed overarching goal is to create a Pan-Islamic superstate across the "Malay" portions of Southeast Asia, spanning, from east to west, the large island of Mindanao, the Sulu Archipelago (Basilan and Jolo islands), the large island of Borneo (Malaysia and Indonesia), the South China Sea, and the Malay Peninsula (Peninsular Malaysia, Thailand and Myanmar).
Jemaah Islamiyah.
Jemaah Islamiyah is a militant Islamic terrorist organization dedicated to the establishment of a fundamentalist Islamic theocracy in Southeast Asia, in particular Indonesia, Singapore, Brunei, Malaysia, the south of Thailand and the Philippines.
Financial links between Jemaah Islamiyah and other terrorist groups, such as Abu Sayyaf and al-Qaeda, have been found to exist. Jemaah Islamiyah means "Islamic Group" or "Islamic Community" and is often abbreviated JI.
Jemaah Islamiyah is thought to have killed hundreds of civilians. Also, it is suspected of carrying out the Bali car bombing on 12 October 2002, in which suicide bombers attacked a nightclub killing 202 people and wounding many more. Most of the casualties were Australian tourists. After this attack, the U.S. State Department designated Jemaah Islamiyah as a Foreign Terrorist Organization. Jemaah Islamiyah is also suspected of carrying out the Zamboanga bombings, the Metro Manila bombings, the 2004 Australian embassy bombing and the 2005 Bali terrorist bombing.
U.S. actions.
In January 2002, 1,200 members of United States Special Operations Command, Pacific (SOCPAC) were deployed to the Philippines to assist the Armed Forces of the Philippines (AFP) in uprooting al-Qaeda, Jemaah Islamiyah and Abu Sayyaf. The members of SOCPAC were assigned to assist in military operations against the terrorist forces as well as humanitarian operations for the island of Basilan, where most of the conflict was expected to take place.
The United States Special Forces (SF) unit trained and equipped special forces and scout rangers of the AFP, creating the Light Reaction Company (LRC). The LRC and elements of SOCPAC deployed to Basilan on completion of their training. The stated goals of the deployment were denying the ASG sanctuary, surveiling, controlling, and denying ASG routes, surveiling supporting villages and key personnel, conducting local training to overcome AFP weaknesses and sustain AFP strengths, supporting operations by the AFP "strike force" (LRC) in the area of responsibility (AOR), conducting and supporting civil affairs operations in the AOR.
Result.
The desired result was for the AFP to gain sufficient capability to locate and destroy the ASG, to recover hostages and to enhance the legitimacy of the Philippine government. Much of the operation was a success: the ASG was driven from Basilan and one U.S. hostage was recovered. The Abu Sayyaf Group's ranks, which once counted more than 800 members, was reduced to less than 100. The humanitarian portion of the operation, Operation Smiles, created 14 schools, 7 clinics, 3 hospitals and provided medical care to over 18,000 residents of Basilan. Humanitarian groups were able to continue their work without fear of further kidnappings and terrorists attacks by the Abu Sayyaf Group.
Operation Enduring Freedom – Horn of Africa (OEF-HOA).
Unlike other operations contained in Operation Enduring Freedom, OEF-HOA does not have a specific terrorist organization as a target. OEF-HOA instead focuses its efforts to disrupt and detect terrorist activities in the region and to work with host nations to deny the reemergence of terrorist cells and activities. Operations began in mid-2002 at Camp Lemonier by a Combined Joint Special Operations Task Force (CJSOTF) augmented by support forces from Fort Stewart, Fort Hood, and Fort Story. In October 2002, the Combined Joint Task Force, Horn of Africa (CJTF-HOA) was established at Djibouti at Camp Lemonier, taking over responsibilities from the CJSOTF. CJTF-HOA comprised approximately 2,000 personnel including U.S. military and Special Operations Forces (SOF), and coalition force members, Combined Task Force 150 (CTF-150). The coalition force consists of ships from Australia, Canada, France, Germany, Netherlands, Italy, Pakistan, New Zealand, Spain, Turkey and the United Kingdom. The primary goal of the coalition forces is to monitor, inspect, board and stop suspected shipments from entering the Horn of Africa region.
CJTF-HOA has devoted the majority of its efforts to train selected armed forces units of the countries of Djibouti, Kenya and Ethiopia in counterterrorism and counterinsurgency tactics. Humanitarian efforts conducted by CJTF-HOA include the rebuilding of schools and medical clinics, as well as providing medical services to those countries whose forces are being trained. The program expands as part of the Trans-Saharan Counter Terrorism Initiative as CJTF personnel also assist in training the forces of Chad, Niger, Mauritania and Mali.
US action.
Anti-piracy operations were undertaken by the coalition throughout 2006 with a battle fought in March when US vessels were attacked by pirates. In January 2007, during the war in Somalia, an AC-130 airstrike was conducted against al-Qaeda members embedded with forces of the Islamic Courts Union (ICU) operating in southern Somalia near Ras Kamboni. US naval forces, including the aircraft carrier USS "Dwight D. Eisenhower", were positioned off the coast of Somalia to provide support and to prevent any al-Qaeda forces escaping by sea. Actions against pirates also occurred in June and October 2007 with varying amounts of success.
Military decorations.
Since 2002, the United States military has created military awards and decorations related to Operation Enduring Freedom:
NATO also created a military decoration related to Operation Enduring Freedom:
References.
http://www.politifact.com/truth-o-meter/promises/obameter/promise/1096/end-war-afghanistan-2014/

</doc>
<doc id="22739" url="http://en.wikipedia.org/wiki?curid=22739" title="Obfuscation (software)">
Obfuscation (software)

In software development, obfuscation is the deliberate act of creating obfuscated code, i.e. source or machine code that is difficult for humans to understand. Like obfuscation in natural language, it may use needlessly roundabout expressions to compose statements.
Programmers may deliberately obfuscate code to conceal its purpose (security through obscurity) or its logic, in order to prevent tampering, deter reverse engineering, or as a puzzle or recreational challenge for someone reading the source code.
Programs known as "obfuscators" transform readable code into obfuscated code using various techniques.
Overview.
The architecture and characteristics of some languages may make them easier to obfuscate than others. C, C++, and the Perl programming language are some examples of languages easy to obfuscate.
Recreational obfuscation.
Writing and reading obfuscated source code can be a brain teaser for programmers. A number of programming contests reward the most creatively obfuscated code: the International Obfuscated C Code Contest, Obfuscated Perl Contest, and .
Types of obfuscations include simple keyword substitution, use or non-use of whitespace to create artistic effects, and self-generating or heavily compressed programs.
Short obfuscated Perl programs may be used in signatures of Perl programmers. These are JAPHs ("Just another Perl hacker").
Examples.
This is a winning entry from the International Obfuscated C Code Contest written by Ian Phillipps in 1988 and subsequently reverse engineered by Thomas Ball.
It is a C program that when compiled and run will generate the 12 verses of "The 12 Days of Christmas". It contains all the strings required for the poem in an encoded form within the code.
A non-winning entry from the same year, this next example illustrates creative use of whitespace; it generates mazes of arbitrary length:
Modern C compilers don't allow constant strings to be overwritten, which can be avoided by changing "*M" to "M[3]" and omitting "M=".
The following example by Óscar Toledo Gutiérrez, Best of Show entry in the 19th IOCCC, implements a 8080 emulator complete with terminal and disk controller, capable of booting CP/M-80 and running CP/M applications,
An example of a JAPH:
This slowly displays the text "Just another Perl / Unix hacker", multiple characters at a time, with delays. An explanation can be found here.
Some Python examples can be found in the .
Disadvantages of obfuscation.
Obfuscation can make reading, writing and reverse-engineering a program difficult and time-consuming, but not necessarily impossible. In Java it also limits the use of the Reflection application programming interface on the obfuscated code. Some anti-virus software, such as AVG, will also alert their users when they land on a site with code obfuscated, as one of the purposes of obfuscation can be to hide malicious code. However, some developers may employ code obfuscation for the purpose of reducing file size or increasing security. The average user may not expect their antivirus software to provide alerts about an otherwise harmless piece of code, especially from trusted corporations, so such a feature may actually serve as a deterrent.
Obfuscating software.
A variety of tools exists to perform or assist with code obfuscation.
These include experimental research tools created by academics, hobbyist tools,
commercial products written by professionals, and open-source software.
There also exist deobfuscation tools that attempt to perform the reverse
transformation.
Although the majority of commercial obfuscation solutions work by transforming
either program source
code, or platform-independent bytecode as used by
Java and
.NET, there are also some that work with C and
C++ - languages that are typically compiled to native code, or work directly on compiled binaries.
Obfuscation and copyleft licenses.
There has been debate on whether it is illegal to skirt copyleft software licenses by releasing source code in obfuscated form, such as in cases in which the author is less willing to make the source code available. The issue is addressed in the GNU General Public License by defining source code as the "preferred" version of the source code be made available. The GNU website states "Obfuscated 'source code' is not real source code and does not count as source code." 
References.
</dl>

</doc>
<doc id="22742" url="http://en.wikipedia.org/wiki?curid=22742" title="Ötzi">
Ötzi

Ötzi (]; also called Ötzi the Iceman, the Similaun Man, the Man from Hauslabjoch, Homo tyrolensis, and the Hauslabjoch mummy) is a well-preserved natural mummy of a man who lived around 3,300 BCE, more precisely between 3359 and 3105 BCE, with a 66% chance that he died between 3239 and 3105 BCE. The mummy was found in September 1991 in the Ötztal Alps, hence the nickname "Ötzi", near the Similaun mountain and Hauslabjoch on the border between Austria and Italy. He is Europe's oldest known natural human mummy, and has offered an unprecedented view of Chalcolithic Europeans. His body and belongings are displayed in the South Tyrol Museum of Archaeology in Bolzano, South Tyrol, Italy.
Discovery.
Ötzi was found on 19 September 1991 by two German tourists, at an elevation of 3210 m on the east ridge of the Fineilspitze in the Ötztal Alps on the Austrian–Italian border. The tourists, Helmut and Erika Simon, were walking off the path between the mountain passes Hauslabjoch and Tisenjoch. They believed that the body was of a recently deceased mountaineer. The next day, a mountain gendarme and the keeper of the nearby Similaunhütte first attempted to remove the body, which was frozen in ice below the torso, using a pneumatic drill and ice-axes, but had to give up due to bad weather. The next day, eight groups visited the site, amongst whom happened to be the famous mountaineers Hans Kammerlander and Reinhold Messner. The body was semi-officially extracted on 22 September and officially salvaged the following day. It was transported to the University of Innsbruck, where it was recognized to be primeval the same day.
At the Treaty of Saint-Germain-en-Laye (1919), the border between North and South Tyrol was defined as the watershed of the rivers Inn and Etsch. However, near Tisenjoch the (now withdrawn) glacier complicated establishing the watershed at the time and the border was established too far north. Therefore, although Ötzi's find site drains to the Austrian side, surveys in October 1991 showed that the body had been located 92.56 m inside Italian territory as delineated in 1919. The province of South Tyrol therefore claimed property rights, but agreed to let Innsbruck University finish its scientific examinations. Since 1998, it has been on display at the South Tyrol Museum of Archaeology in Bolzano, the capital of South Tyrol.
Scientific analyses.
The corpse has been extensively examined, measured, X-rayed, and dated. Tissues and intestinal contents have been examined microscopically, as have the items found with the body. In August 2004, frozen bodies of three Austro-Hungarian soldiers killed during the Battle of San Matteo (1918) were found on the mountain Punta San Matteo in Trentino. One body was sent to a museum in the hope that research on how the environment affected its preservation would help unravel Ötzi's past.
Body.
By current estimates, at the time of his death Ötzi was approximately 1.65 m tall, weighed about 50 kg and was about 45 years of age. When his body was found, it weighed 13.750 kg (30.25 lb). Because the body was covered in ice shortly after his death, it had only partially deteriorated. Analysis of pollen, dust grains and the isotopic composition of his tooth enamel indicates that he spent his childhood near the present village of Feldthurns, north of Bolzano, but later went to live in valleys about 50 kilometres farther north. Analysis by Franco Rollo's group at the University of Camerino has shown that Ötzi's mitochondrial DNA belongs to the K1 subcluster of the mitochondrial haplogroup K, but that it cannot be categorized into any of the three modern branches of that subcluster. Rollo's group published Ötzi's complete mtDNA sequence in 2008.
Analysis of Ötzi's intestinal contents showed two meals (the last one consumed about eight hours before his death), one of chamois meat, the other of red deer and herb bread. Both were eaten with grain as well as roots and fruits. The grain from both meals was a highly processed einkorn wheat bran, quite possibly eaten in the form of bread. In the proximity of the body, and thus possibly originating from the Iceman's provisions, chaff and grains of einkorn and barley, and seeds of flax and poppy were discovered, as well as kernels of sloes (small plumlike fruits of the blackthorn tree) and various seeds of berries growing in the wild. Hair analysis was used to examine his diet from several months before.
Pollen in the first meal showed that it had been consumed in a mid-altitude conifer forest, and other pollens indicated the presence of wheat and legumes, which may have been domesticated crops. Pollen grains of hop-hornbeam were also discovered. The pollen was very well preserved, with the cells inside remaining intact, indicating that it had been fresh (a few hours old) at the time of Ötzi's death, which places the event in the spring. Einkorn wheat is harvested in the late summer, and sloes in the autumn; these must have been stored from the previous year.
In 2009, a CAT scan revealed that the stomach had shifted upward to where his lower lung area would normally be. Analysis of the contents revealed the partly digested remains of ibex meat, confirmed by DNA analysis, suggesting he had a meal less than two hours before his death. Wheat grains were also found.
High levels of both copper particles and arsenic were found in Ötzi's hair. This, along with Ötzi's copper axe blade, which is 99.7% pure copper, has led scientists to speculate that Ötzi was involved in copper smelting.
By examining the proportions of Ötzi's tibia, femur and pelvis, Christopher Ruff has determined that Ötzi's lifestyle included long walks over hilly terrain. This degree of mobility is not characteristic of other Copper Age Europeans. Ruff proposes that this may indicate that Ötzi was a high-altitude shepherd.
Using modern 3-D technology, a facial reconstruction has been created for the South Tyrol Museum of Archaeology in Bolzano, Italy. It shows Ötzi looking old for his 45 years, with deep-set brown eyes, a beard, a furrowed face, and sunken cheeks. He is depicted looking tired and ungroomed.
Health.
Ötzi apparently had whipworm ("Trichuris trichiura"), an intestinal parasite. During CT scans, it was observed that three or four of his right ribs had been cracked when he had been lying face down after death, or where the ice had crushed his body. One of his fingernails (of the two found) shows three Beau's lines indicating he was sick three times in the six months before he died. The last incident, two months before he died, lasted about two weeks. Also, it was found that his epidermis, the outer skin layer, was missing, a natural process from his mummification in ice. Ötzi's teeth showed considerable internal deterioration from cavities. These oral pathologies may have been brought about by his grain-heavy, high carbohydrate diet. DNA analysis in February 2012 revealed that Ötzi was lactose intolerant, supporting the theory that lactose intolerance was still common at that time, despite the increasing spread of agriculture and dairying.
Skeletal details and tattooing.
Ötzi had several carbon tattoos including groups of short, parallel, vertical lines to both sides of the lumbar spine, a cruciform mark behind the right knee, and various marks around both ankles. Radiological examination of his bones showed "age-conditioned or strain-induced degeneration" in these areas, including osteochondrosis and slight spondylosis in the lumbar spine and wear-and-tear degeneration in the knee and especially in the ankle joints. It has been speculated that these tattoos may have been related to pain relief treatments similar to acupressure or acupuncture.
If so, this is at least 2000 years before their previously known earliest use in China (c. 1000 BCE).
Clothes and shoes.
Ötzi's clothes were sophisticated. He wore a cloak made of woven grass and a coat, a belt, a pair of leggings, a loincloth and shoes, all made of leather of different skins. He also wore a bearskin cap with a leather chin strap. The shoes were waterproof and wide, seemingly designed for walking across the snow; they were constructed using bearskin for the soles, deer hide for the top panels, and a netting made of tree bark. Soft grass went around the foot and in the shoe and functioned like modern socks. The coat, belt, leggings and loincloth were constructed of vertical strips of leather sewn together with sinew. His belt had a pouch sewn to it that contained a cache of useful items: a scraper, drill, flint flake, bone awl and a dried fungus.
The shoes have since been reproduced by a Czech academic, who said that "because the shoes are actually quite complex, I'm convinced that even 5,300 years ago, people had the equivalent of a cobbler who made shoes for other people". The reproductions were found to constitute such excellent footwear that it was reported that a Czech company offered to purchase the rights to sell them. However, a more recent hypothesis by British archaeologist Jacqui Wood says that Ötzi's "shoes" were actually the upper part of snowshoes. According to this theory, the item currently interpreted as part of a "backpack" is actually the wood frame and netting of one snowshoe and animal hide to cover the face.
Tools and equipment.
Other items found with the Iceman were a copper axe with a yew handle, a flint-bladed knife with an ash handle and a quiver of 14 arrows with viburnum and dogwood shafts. Two of the arrows, which were broken, were tipped with flint and had fletching (stabilizing fins), while the other 12 were unfinished and untipped. The arrows were found in a quiver with what is presumed to be a bow string, an unidentified tool, and an antler tool which might have been used for sharpening arrow points. There was also an unfinished yew longbow that was 1.82 m long.
In addition, among Ötzi's possessions were berries, two birch bark baskets, and two species of polypore mushrooms with leather strings through them. One of these, the birch fungus, is known to have antibacterial properties, and was probably used for medicinal purposes. The other was a type of tinder fungus, included with part of what appeared to be a complex firestarting kit. The kit featured pieces of over a dozen different plants, in addition to flint and pyrite for creating sparks.
Ötzi's copper axe was of particular interest. The axe's haft is 60 cm long and made from carefully worked yew with a right-angled crook at the shoulder, leading to the blade. The 9.5 cm long axe head is made of almost pure copper, produced by a combination of casting, cold forging, polishing, and sharpening. It was let into the forked end of the crook and fixed there using birch-tar and tight leather lashing. The blade part of the head extends out of the lashing and shows clear signs of having been used to chop and cut. At the time, such an axe would have been a valuable possession, important both as a tool and as a status symbol for the bearer.
Genetic analysis.
A group of scientists have sequenced Ötzi's full genome and the report was published on 28 February 2012. The Y-DNA of Ötzi belongs to a subclade of G defined by the SNPs M201, P287, P15, L223 and L91 (G-L91, ISOGG G2a2b, former "G2a4"). He was not typed for any of the subclades downstreaming from G-L91. G-L91 is now mostly found in South Corsica.
Analysis of his mitochondrial DNA has shown that Ötzi belongs to the K1 subclade, but cannot be categorized into any of the three modern branches of that subclade (K1a, K1b or K1c). The new subclade has provisionally been named "K1ö" for "Ötzi". Multiplex assay study was able to confirm that the Iceman's mtDNA belongs to a previously unknown European mtDNA clade with a very limited distribution amongst modern data sets.
By autosomal DNA he is most closely related to southern Europeans, especially to the geographically isolated populations of the two Mediterranean islands of Sardinia and Corsica.
DNA analysis also showed him at high risk of atherosclerosis, lactose intolerance. The presence of the DNA sequence of "Borrelia burgdorferi", making him the earliest known human with Lyme disease. The authenticity of this claim has been questioned in recent bioinformatics research.
A 2012 paper by paleoanthropologist John Hawks suggests that Ötzi had a higher degree of Neanderthal ancestry than modern Europeans.
In October 2013, it was reported that 19 modern Tyrolean men were related to Ötzi. Scientists from the Institute of Legal Medicine at Innsbruck Medical University had analysed the DNA of over 3,700 Tyrolean male blood donors and found 19 who shared a particular genetic mutation with the 5,300 year old man, which led them to identify the link.
Blood.
In May 2012, scientists announced the discovery that Ötzi still had intact blood cells. These are the oldest complete human blood cells ever identified. In most bodies this old, the blood cells are either shrunken or mere remnants, but Ötzi's have the same dimensions as living red blood cells and resembled a modern-day sample.
Cause of death.
Initial speculation.
It was initially believed that Ötzi died from exposure during a winter storm. Later it was speculated that Ötzi may have been a victim of a ritual sacrifice, perhaps for being a chieftain. This explanation was inspired by theories previously advanced for the first millennium BCE bodies recovered from peat bogs such as the Tollund Man and the Lindow Man.
Theories involving struggle followed by cold death.
In 2001 X-rays and a CT scan revealed that Ötzi had an arrowhead lodged in his left shoulder when he died, and a matching small tear on his coat. The discovery of the arrowhead prompted researchers to theorize Ötzi died of blood loss from the wound, which would probably have been fatal even if modern medical techniques had been available. Further research found that the arrow's shaft had been removed before death, and close examination of the body found bruises and cuts to the hands, wrists and chest and cerebral trauma indicative of a blow to the head. One of the cuts was to the base of his thumb that reached down to the bone but had no time to heal before his death. Currently, it is believed that the cause of death was a blow to the head, however researchers are unsure of what inflicted the fatal injury. Unpublished and thus unconfirmed DNA analyses claim they revealed traces of blood from four other people on his gear: one from his knife, two from the same arrowhead, and a fourth from his coat. Interpretations of these findings were that Ötzi killed two people with the same arrow, and was able to retrieve it on both occasions, and the blood on his coat was from a wounded comrade he may have carried over his back. Ötzi's unnatural posture in death (frozen body, face down, left arm bent across the chest) suggests that the theory of a solitary death from blood loss, hunger, cold and weakness is untenable. Rather, before death occurred and rigor mortis set in, the Iceman was turned on to his stomach in the effort to remove the arrow shaft.
In May 2012, researchers using Raman spectroscopy and atomic force microscopy concluded that Ötzi did not die immediately from his shoulder wound. They detected dried blood cells and possibly fibrin in a state of degradation from maturity, suggesting an established blood clot of more than a few days' age.
The DNA evidence suggests that he was assisted by companions who were also wounded; pollen and food analysis suggests that he was out of his home territory. The copper axe could not have been made by him alone. It would have required a group tribal effort to mine, smelt and cast the copper axe head. This may indicate that Ötzi was part of an armed raiding party involved in a skirmish, perhaps with a neighboring tribe, and this skirmish had gone badly.
When the Iceman's mitochondrial DNA was analyzed by Franco Rollo and his colleagues, it was discovered that he had genetic markers associated with reduced fertility. It has been speculated that this may have affected his social acceptance, or at least that his infertility could have had social implications within his tribal group, which could have played a role in the chain of events that led to the confrontation.
Burial theory.
In 2010, it was proposed that Ötzi died at a much lower altitude and was buried higher in the mountains, as posited by archaeologist Alessandro Vanzetti of the Sapienza University of Rome and his colleagues. According to their study of the items found near Ötzi and their locations, it is possible that the iceman may have been placed above what has been interpreted as a stone burial mound but was subsequently moved with each thaw cycle that created a flowing watery mix driven by gravity before being re-frozen.
While archaeobotanist Klaus Oeggl of the University of Innsbruck agrees that the natural process described probably caused the body to move from the ridge that includes the stone formation, he pointed out that the paper provided no compelling evidence to demonstrate that the scattered stones constituted a burial platform. Moreover, biological anthropologist Albert Zink argues that the iceman's bones display no dislocations that would have resulted from a downhill slide and that the intact blood clots in his arrow wound would show damage were the body carted up the mountain.
In either case, the burial theory does not contradict the possibility of a violent cause of death as stated in the preceding theories.
Legal dispute.
Italian law entitled the Simons to a finders' fee from the South Tyrolean provincial government of 25% of the value of Ötzi. In 1994 the authorities offered a "symbolic" reward of 10 million lire (€5,200), which the Simons turned down. In 2003, the Simons filed a lawsuit which asked a court in Bolzano to recognize their role in Ötzi's discovery and declare them his "official discoverers". The court decided in the Simons' favor in November 2003, and at the end of December that year the Simons announced that they were seeking US$300,000 as their fee. The provincial government decided to appeal.
In addition, two people came forward to claim that they were part of the same mountaineering party that came across Ötzi and discovered the body first:
According to The Telegraph report in 2005 the rival claims were heard by a Bolzano court. The legal case angered Mrs. Simon, who alleged that neither woman was present on the mountain that day. In 2005, Mrs. Simon's lawyer said: "Mrs. Simon is very upset by all this and by the fact that these two new claimants have decided to appear 14 years after Ötzi was found." In 2008, however, Jarc stated for a Slovene newspaper that she wrote two times to the Bolzano court in regard to her claim but received no reply whatsoever.
In 2004, Helmut Simon died. Two years later, in June 2006, an appeals court affirmed that the Simons had indeed discovered the Iceman and were therefore entitled to a finder's fee. It also ruled that the provincial government had to pay the Simons' legal costs. After this ruling, Mrs. Erika Simon reduced her claim to €150,000. The provincial government's response was that the expenses it had incurred to establish a museum and the costs of preserving the Iceman should be considered in determining the finder's fee. It insisted it would pay no more than €50,000. In September 2006, the authorities appealed the case to Italy's highest court, the Court of Cassation.
On 29 September 2008 it was announced that the provincial government and Mrs. Simon had reached a settlement of the dispute, under which she would receive €150,000 in recognition of Ötzi's discovery by her and her late husband and the tourist income that it attracts.
"Ötzi's curse".
Influenced by the "Curse of the pharaohs" and the media theme of cursed mummies, claims have been made that Ötzi is cursed. The allegation revolves around the deaths of several people connected to the discovery, recovery and subsequent examination of Ötzi. It is alleged that they have died under mysterious circumstances. These persons include co-discoverer Helmut Simon, and Konrad Spindler, the first examiner of the mummy in Austria at a local morgue in 1991. To date, the deaths of seven people, of which four were the result of some violence in the form of accidents, have been attributed to the alleged curse. In reality hundreds of people were involved in the recovery of Ötzi and are still involved in studying the body and the artifacts found with it. The fact that a small percentage of them have died over the years has not been shown to be statistically significant.

</doc>
<doc id="22743" url="http://en.wikipedia.org/wiki?curid=22743" title="Operation Deadlight">
Operation Deadlight

Operation "Deadlight" was the code name for the Royal Navy operation to scuttle German U-boats surrendered to the Allies after the defeat of Germany near the end of World War II.
Of the 156 U-boats that surrendered to the allies at the end of the war, 116 were scuttled as part of Operation "Deadlight". The operation was carried out by the Royal Navy and it was planned to tow the submarines to three areas about 100 miles north-west of Ireland and sink them. The areas were codenamed XX, YY and ZZ. The intention was to use XX as the main area for scuttling while 36 boats would be towed to ZZ for use as targets for aerial attack. YY was to be a reserve position where if the weather was good enough, submarines could be diverted from XX to be sunk by naval forces. In the case of those submarines not being used as targets the plan was to sink them via explosive charges with naval gunfire as a fall-back option if that failed.
When Operation "Deadlight" was activated, it was found that many of the U-boats were in an extremely poor condition as a result of being moored in exposed harbours while awaiting disposal. Combined with poor weather, this meant that 56 of the boats sank before reaching the designated scuttling areas and those which did were generally sunk by gunfire rather than explosive charges. The first sinking took place on 17 November 1945 and the last on 11 February 1946.
U-boats excluded from Operation "Deadlight".
Several U-boats escaped Operation "Deadlight". Some were claimed as prizes by Britain, France, Norway and the Soviet Union. Four were in the far east when Germany surrendered and were commandeered by Japan ("U-181" was renamed "I-501", "U-195" - "I-506", "U-219" - "I-505", "U-862" - "I-502", and a fifth boat, "U-511," had been sold to Japan in 1943 and renamed "RO-500"). Two U-boats that survived Operation "Deadlight" are today museum ships. "U-505" was earmarked for scuttling but Rear Admiral Daniel V. Gallery argued successfully that she did not fall under Operation "Deadlight". United States Navy Task Group 22.3, under then-Captain Gallery, had captured "U-505" in battle on 4 June 1944. Having been captured, not surrendered at the end of the war, she survived to become a war memorial at the Museum of Science and Industry in Chicago. "U-995" was transferred to Norway by Britain in October 1948 and became the Norwegian "Kaura". She was returned to Germany in 1965 to become a museum ship in 1971.
"Deadlight" U-boats discovered.
In 2001 to 2003 nautical archaeologist Innes McCartney discovered and surveyed fourteen of the U-boat wrecks, including the rare Type XXI U-boat "U2506", once under the command of Horst Von Schroeter and the successful Type IXC U-boat, "U155" commanded by Adolf Piening.
In the late nineties an approach was made to the British Ministry of Defence for salvage rights on the Operation Deadlight U-boats by a firm who planned to raise up to a hundred of them. Because the wrecks were constructed in the pre-atomic age, they contain metals which are not radioactively tainted and which are therefore valuable for certain research purposes. No salvage award was made due to objections from Russia and the USA, and it is now probable that the U-boats will remain under the sea.

</doc>
<doc id="22746" url="http://en.wikipedia.org/wiki?curid=22746" title="Order of the Eastern Star">
Order of the Eastern Star

The Order of the Eastern Star is a Freemasonry-related fraternal organization open to both men and women. It was established in 1850 by lawyer and educator Rob Morris, a noted Freemason. The order is based on teachings from the Bible, but is open to people of all religious beliefs. It has approximately 10,000 chapters in twenty countries and approximately 500,000 members under its General Grand Chapter.
Members of the Order are aged 18 and older; men must be Master Masons and women must have specific relationships with Masons. Originally, a woman would have to be the daughter, widow, wife, sister, or mother of a master Mason, but the Order now allows other relatives as well as allowing Job's Daughters, Rainbow Girls, Members of the Organization of Triangle (NY only) and members of the Constellation of Junior Stars (NY only) to become members when of age.
History.
The Order was created by Rob Morris in 1850 when he was teaching at the Eureka Masonic College in Richland, Mississippi. While confined by illness, he set down the principles of the order in his "Rosary of the Eastern Star". By 1855, he had organized a "Supreme Constellation" in New York, which chartered chapters throughout the United States.
In 1866, Dr. Morris started working with Robert Macoy, and handed the Order over to him while Morris was traveling in the Holy Land. Macoy organized the current system of Chapters, and modified Dr. Morris' "Rosary" into a "Ritual".
On December 1, 1874, Queen Esther Chapter No. 1 became the first Prince Hall Affiliate chapter of the Order of the Eastern Star when it was established in Washington, D.C. by Thornton Andrew Jackson.
The "General Grand Chapter" was formed in Indianapolis, Indiana on November 6, 1876. Committees formed at that time created the "Ritual of the Order of the Eastern Star" in more or less its current form.
Emblem and heroines.
The emblem of the Order is a five-pointed star with the white ray of the star pointing downwards towards the manger. In the Chapter room, the downward-pointing white ray points to the West. The character-building lessons taught in the Order are stories inspired by Biblical figures:
Officers.
There are 18 main officers in a full chapter:
Traditionally, a woman who is elected Associate Conductress will be elected to Conductress the following year, then the next year Associate Matron, and then next year as Worthy Matron. A man elected Associate Patron will usually be elected Worthy Patron the following year. Usually the woman who is elected to become Associate Matron will let it be known who she wishes to be her Associate Patron, so the next year they will both go to the East together as Worthy Matron and Worthy Patron. There is no male counterpart to the Conductress and Associate Conductress. Only women are allowed to be Matrons, Conductresses, and the Star Points (Adah, Ruth, etc.) and only men can be Patrons.
Headquarters.
The General Grand Chapter headquarters, the International Temple, is located in the Dupont Circle neighborhood of Washington, D.C., in the former Perry Belmont Mansion. The mansion was built in 1909 for the purpose of entertaining the guests of Perry Belmont. This included Britain's Prince of Wales in 1919. General Grand Chapter purchased the building in 1935. The secretary of General Grand Chapter lives there while serving his or her term of office. The mansion features works of art from around the world, most of which were given as gifts from various international Eastern Star chapters.
Charities.
The Order has a charitable foundation and from 1986-2001 contributed $513,147 to Alzheimer's disease research, juvenile diabetes research, and juvenile asthma research. It also provides bursaries to students of theology and religious music, as well as other scholarships that differ by jurisdiction. In 2000 over $83,000 was donated. Many jurisdictions support a Masonic and/or Eastern Star retirement center or nursing home for older members; some homes are also open to the public. The Elizabeth Bentley OES Scholarship Fund was started in 1947.

</doc>
<doc id="22747" url="http://en.wikipedia.org/wiki?curid=22747" title="OSI model">
OSI model

The Open Systems Interconnection model (OSI Model) is a conceptual model that characterizes and standardizes the internal functions of a communication system by partitioning it into abstraction layers. The model is a product of the Open Systems Interconnection project at the International Organization for Standardization (ISO), maintained by the identification ISO/IEC 7498-1.
An open system is a set of protocols that allow any two different systems to communicate regardless of their underlying structure. The purpose of OSI model is to show how to facilitate communication between different systems without requiring changes to the logic of the underlying hardware and software.The OSI model isn't a protocol; it is a model for understanding and designing a network architecture that is flexible, robust and interoperable.
The model groups communication functions into seven logical layers. A layer serves the layer above it and is served by the layer below it. For example, a layer that provides error-free communications across a network provides the path needed by applications above it, while it calls the next lower layer to send and receive packets that make up the contents of that path. Two instances at one layer are connected by a horizontal connection on that layer.
History.
In the late 1970s, two projects began independently, with the same goal: to define a unifying standard for the architecture of networking systems. One was administered by the International Organization for Standardization (ISO), while the other was undertaken by the International Telegraph and Telephone Consultative Committee, or CCITT (the abbreviation is from the French version of the name). These two international standards bodies each developed a document that defined similar networking models.
In 1983, these two documents were merged to form a standard called The Basic Reference Model for Open Systems Interconnection. The standard is usually referred to as the Open Systems Interconnection Reference Model, the OSI Reference Model, or simply the OSI model. It was published in 1984 by both the ISO, as standard ISO 7498, and the renamed CCITT (now called the Telecommunications Standardization Sector of the International Telecommunication Union or ITU-T) as standard X.200.
OSI had two major components, an "abstract model" of networking, called the Basic Reference Model or seven-layer model, and a set of specific protocols.
The concept of a seven-layer model was provided by the work of Charles Bachman at Honeywell Information Services. Various aspects of OSI design evolved from experiences with the ARPANET, NPLNET, EIN, CYCLADES network and the work in IFIP WG6.1. The new design was documented in ISO 7498 and its various addenda. In this model, a networking system was divided into layers. Within each layer, one or more entities implement its functionality. Each entity interacted directly only with the layer immediately beneath it, and provided facilities for use by the layer above it.
Protocols enable an entity in one host to interact with a corresponding entity at the same layer in another host. Service definitions abstractly described the functionality provided to an (N)-layer by an (N-1) layer, where N was one of the seven layers of protocols operating in the local host.
The OSI standards documents are available from the ITU-T as the X.200-series of recommendations. Some of the protocol specifications were also available as part of the ITU-T X series. The equivalent ISO and ISO/IEC standards for the OSI model were available from ISO, but only some of them without fees.
Description of OSI layers.
The recommendation X.200 describes seven layers, labeled 1 to 7. Layer 1 is the lowest layer in this model.
At each level "N" two entities at the communicating devices (layer N "peers") exchange protocol data units (PDUs) by means of a layer N "protocol". Each PDU contains a payload, called the service data unit (SDU), along with protocol-related headers and/or footers.
Data processing by two communicating OSI-compatible devices is done as such:
Some orthogonal aspects, such as management and security, involve all of the layers (See ITU-T X.800 Recommendation). These services are aimed at improving the CIA triad - confidentiality, integrity, and availability - of the transmitted data. In practice, the availability of a communication service is determined by the interaction between network design and network management protocols. Appropriate choices for both of these are needed to protect against denial of service.
Layer 1: Physical Layer.
The physical layer has the following major functions:
The physical layer of Parallel SCSI operates in this layer, as do the physical layers of Ethernet and other local-area networks, such as Token Ring, FDDI, ITU-T G.hn, and IEEE 802.11 (Wi-Fi), And Wifi Hotspot as well as personal area networks such as Bluetooth and IEEE 802.15.4.
Layer 2: Data Link Layer.
The data link layer provides node-to-node data transfer -- a reliable link between two directly connected nodes, by detecting and possibly correcting errors that may occur in the physical layer.
The data link layer is divided into two sublayers:
The Point-to-Point Protocol (PPP) is an example of a data link layer in the TCP/IP protocol stack.
The ITU-T G.hn standard, which provides high-speed local area networking over existing wires (power lines, phone lines and coaxial cables), includes a complete data link layer that provides both error correction and flow control by means of a selective-repeat sliding-window protocol.
Layer 3: Network Layer.
The network layer provides the functional and procedural means of transferring variable length data sequences (called datagrams) from one node to another connected to the same "network." It translates logical network address into physical machine address. A network is a medium to which many nodes can be connected, on which every node has an "address" and which permits nodes connected to it to transfer messages to other nodes connected to it by merely providing the content of a message and the address of the destination node and letting the network find the way to deliver ("route") the message to the destination node. In addition to message routing, the network may (or may not) implement message delivery by splitting the message into several fragments, delivering each fragment by a separate route and reassembling the fragments, report delivery errors, etc.
Datagram delivery at the network layer is "not" guaranteed to be "reliable".
A number of layer-management protocols, a function defined in the "management annex", ISO 7498/4, belong to the network layer. These include routing protocols, multicast group management, network-layer information and error, and network-layer address assignment. It is the function of the payload that makes these belong to the network layer, not the protocol that carries them.
Layer 4: Transport Layer.
The transport layer provides the functional and procedural means of transferring variable-length data sequences from a source to a destination host via one or more networks, while maintaining the quality of service functions.
An example of a transport-layer protocol in the standard Internet stack is Transmission Control Protocol (TCP), usually built on top of the Internet Protocol (IP).
The transport layer controls the reliability of a given link through flow control, segmentation/desegmentation, and error control. Some protocols are state- and connection-oriented. This means that the transport layer can keep track of the segments and retransmit those that fail. The transport layer also provides the acknowledgement of the successful data transmission and sends the next data if no errors occurred. The transport layer creates packets out of the message received from the application layer. Packetizing is a process of dividing the long message into smaller messages.
OSI defines five classes of connection-mode transport protocols ranging from class 0 (which is also known as TP0 and provides the fewest features) to class 4 (TP4, designed for less reliable networks, similar to the Internet). Class 0 contains no error recovery, and was designed for use on network layers that provide error-free connections. Class 4 is closest to TCP, although TCP contains functions, such as the graceful close, which OSI assigns to the session layer. Also, all OSI TP connection-mode protocol classes provide expedited data and preservation of record boundaries. Detailed characteristics of TP0-4 classes are shown in the following table:
An easy way to visualize the transport layer is to compare it with a post office, which deals with the dispatch and classification of mail and parcels sent. Do remember, however, that a post office manages the outer envelope of mail. Higher layers may have the equivalent of double envelopes, such as cryptographic presentation services that can be read by the addressee only. Roughly speaking, tunneling protocols operate at the transport layer, such as carrying non-IP protocols such as IBM's SNA or Novell's IPX over an IP network, or end-to-end encryption with IPsec. While Generic Routing Encapsulation (GRE) might seem to be a network-layer protocol, if the encapsulation of the payload takes place only at endpoint, GRE becomes closer to a transport protocol that uses IP headers but contains complete frames or packets to deliver to an endpoint. L2TP carries PPP frames inside transport packet.
Although not developed under the OSI Reference Model and not strictly conforming to the OSI definition of the transport layer, the Transmission Control Protocol (TCP) and the User Datagram Protocol (UDP) of the Internet Protocol Suite are commonly categorized as layer-4 protocols within OSI.
Layer 5: Session Layer.
The session layer controls the dialogues (connections) between computers. It establishes, manages and terminates the connections between the local and remote application. It provides for full-duplex, half-duplex, or simplex operation, and establishes checkpointing, adjournment, termination, and restart procedures. The OSI model made this layer responsible for graceful close of sessions, which is a property of the Transmission Control Protocol, and also for session checkpointing and recovery, which is not usually used in the Internet Protocol Suite. The session layer is commonly implemented explicitly in application environments that use remote procedure calls.
Layer 6: Presentation Layer.
The presentation layer establishes context between application-layer entities, in which the application-layer entities may use different syntax and semantics if the presentation service provides a big mapping between them. If a mapping is available, presentation service data units are encapsulated into session protocol data units, and passed down the protocol stack.
This layer provides independence from data representation (e.g., encryption) by translating between application and network formats. The presentation layer transforms data into the form that the application accepts. This layer formats and encrypts data to be sent across a network. It is sometimes called the syntax layer.
The original presentation structure used the Basic Encoding Rules of Abstract Syntax Notation One (ASN.1), with capabilities such as converting an EBCDIC-coded text file to an ASCII-coded file, or serialization of objects and other data structures from and to XML.
Layer 7: Application Layer.
The application layer is the OSI layer closest to the end user, which means both the OSI application layer and the user interact directly with the software application. This layer interacts with software applications that implement a communicating component. Such application programs fall outside the scope of the OSI model. Application-layer functions typically include identifying communication partners, determining resource availability, and synchronizing communication. When identifying communication partners, the application layer determines the identity and availability of communication partners for an application with data to transmit. When determining resource availability, the application layer must decide whether sufficient network or the requested communication exists. In synchronizing communication, all communication between applications requires cooperation that is managed by the application layer. Some examples of application-layer implementations include:
Cross-layer functions.
There are some functions or services that are not tied to a given layer, but they can affect more than one layer. Examples include the following:
Interfaces.
Neither the OSI Reference Model nor OSI protocols specify any programming interfaces, other than as deliberately abstract service specifications. Protocol specifications precisely define the interfaces between different computers, but the software interfaces inside computers, known as network sockets are implementation-specific.
For example Microsoft Windows' Winsock, and Unix's Berkeley sockets and System V Transport Layer Interface, are interfaces between applications (layer 5 and above) and the transport (layer 4). NDIS and ODI are interfaces between the media (layer 2) and the network protocol (layer 3).
Interface standards, except for the physical layer to media, are approximate implementations of OSI service specifications.
Comparison with TCP/IP model.
In the TCP/IP model of the Internet, protocols are deliberately not as rigidly designed into strict layers as in the OSI model. RFC 3439 contains a section entitled "Layering considered harmful". However, TCP/IP does recognize four broad layers of functionality which are derived from the operating scope of their contained protocols: the scope of the software application; the end-to-end transport connection; the internetworking range; and the scope of the direct links to other nodes on the local network.
Even though the concept is different from the OSI model, these layers are nevertheless often compared with the OSI layering scheme in the following way:
These comparisons are based on the original seven-layer protocol model as defined in ISO 7498, rather than refinements in such things as the internal organization of the network layer document.
The presumably strict peer layering of the OSI model as it is usually described does not present contradictions in TCP/IP, as it is permissible that protocol usage does not follow the hierarchy implied in a layered model. Such examples exist in some routing protocols (e.g., OSPF), or in the description of tunneling protocols, which provide a link layer for an application, although the tunnel host protocol might well be a transport or even an application-layer protocol in its own right.

</doc>
<doc id="22751" url="http://en.wikipedia.org/wiki?curid=22751" title="Original Sin (2001 film)">
Original Sin (2001 film)

 
Original Sin is a 2001 erotic thriller film starring Antonio Banderas and Angelina Jolie. It is based on the novel "Waltz into Darkness" by Cornell Woolrich, and is a remake of the 1969 François Truffaut film "Mississippi Mermaid". Jolie was nominated for a Golden Raspberry Award in 2001 for Worst Actress for her work in "Original Sin" and "".
Plot.
"Original Sin" is set in the late 19th century Cuba during the Spanish rule, and flashes back and forth from the scene of a woman awaiting her execution by garrote while telling her story to a priest, to the actual events of that story. 
Luis Vargas (Antonio Banderas), a wealthy Hispanic-Cuban businessman, sends for American Julia Russell (Angelina Jolie) to sail to his country to be his bride. Julia departs from the ship, looking nothing like the photos she's sent prior to her voyage. Julia explains she wants more than a man who is interested in a pretty face, and that's why she's been deceptive - substituting a plain-looking woman in place of her own picture. Luis also admits to deception; he's been misleading her into believing he's a poor working man, instead of the rich owner of a coffee company.
Luis and Julia wed within hours of her setting foot in Cuba. Luis falls passionately in love with his new wife.
Meanwhile, Julia's sister Emily has been trying to contact her, worried about her after such a long trip to a strange land. Luis forces Julia to write back, fearing that if Julia continues to ignore Emily's letters, Emily will assume something terrible has befallen her sister and might send the authorities to check on her welfare. Holding off as long as possible, Julia finally pens a letter to her sister.
In order to assure that his wife has everything she wants, Luis adds Julia to his business and personal bank accounts, giving her free rein to spend as she pleases. Luis discovers Julia has run off with nearly all of his fortune, and then teams up with a detective, Walter Downs (Thomas Jane), hired by Emily to find her real sister Julia. Walter reveals to Luis he believes Julia to be an impostor and the intended wife to be dead by her hand, and that she may be working with someone. The two set out together looking for her.
Luis finds Julia and discovers she is actually working with Walter and that he & Luis are staying at the same hotel. Luis believes she loves him and lies to Walter, but, when confronted, a fight breaks out and Luis shoots Walter. Julia coldly tells Luis to go and buy them tickets home, but the minute he leaves, Walter gets to his feet; he had loaded the gun with blanks. Julia appears to love Luis, but, Walter has too much control over her, so, she continues to work for him as she and Luis run off to live in secret with the supposedly dead Walter in pursuit. 
Luis throws away his promising future and opens himself to living a lie with Julia. One night, Luis follows Julia and discovers Walter is alive and that the two are still working together; she is apparently going to poison her husband that very night. He returns home and waits for her, and when she arrives, reveals he knows of the plan, confesses his love for her once more and swallows the poisoned drink. Julia flees with the dying Luis, with Walter close behind. They run into him at a train station; Walter is furious that Julia has betrayed him. As Walter holds a knife to her throat, Luis shoots and wounds him, with Julia finishing him off.
Back in the "mise en scene", Julia finishes her story and asks the priest to pray with her. The next morning the guards come to her cell to take her to her execution, only to find the priest in her clothing.
In Morocco, Julia is watching a card game. She walks around the table occupied by gamblers — including Luis — and thanks them for allowing her to watch. As Julia signals Luis about the other players' cards, he begins telling them the story of how they got there.

</doc>
<doc id="22753" url="http://en.wikipedia.org/wiki?curid=22753" title="Oscar Hammerstein II">
Oscar Hammerstein II

Oscar Greeley Clendenning Hammerstein II (; July 12, 1895 – August 23, 1960) was an American librettist, theatrical producer, and (usually uncredited) theatre director of musicals for almost forty years. Hammerstein won eight Tony Awards and two Academy Awards for Best Original Song. Many of his songs are standard repertoire for singers and jazz musicians. He co-wrote 850 songs. Hammerstein was the lyricist and playwright in his partnerships; his collaborators wrote the music. Hammerstein collaborated with composers Jerome Kern, Vincent Youmans, Rudolf Friml, Richard A. Whiting and Sigmund Romberg; but his most famous collaboration, by far, was with Richard Rodgers, which included "The Sound of Music".
Early life.
Oscar Greeley Clendenning Hammerstein II was born in New York City, the son of Alice (née Nimmo) and William Hammerstein. His grandfather was German-born theatre impresario Oscar Hammerstein I. His father was from a Jewish family, and his mother was the daughter of Scottish and English parents. He was raised Episcopalian.
Although Hammerstein's father managed the Victoria Theatre for his father and was a producer of vaudeville shows, he was opposed to his son's desire to participate in the arts. Hammerstein attended Columbia University (1912–1916) and studied at Columbia Law School until 1917. As a student, he maintained high grades and engaged in numerous extracurricular activities, including playing first base on the baseball team, and becoming an active member of Pi Lambda Phi, a mostly Jewish fraternity.
When he was 19, and still a student at Columbia, his father died of Bright's disease, June 10, 1914, symptoms of which doctors originally attributed to scarlet fever. On the train trip to the funeral with his brother, he read the headlines in the "New York Herald": "Hammerstein's Death a Shock to the Theater Circle." The "New York Times" wrote, "Hammerstein, the Barnum of Vaudeville, Dead at Forty." When he and his brother arrived home, they attended their father's funeral with their grandfather, and more than a thousand others, at Temple Israel in Harlem, and took part in the ceremonies held in the Jewish tradition. Two hours later, "taps was sounded over Broadway," writes biographer Hugh Fordin.
After his father's death, he participated in his first play with the Varsity Show, entitled "On Your Way". Throughout the rest of his college career, Hammerstein wrote and performed in several Varsity Shows.
Early career.
After quitting law school to pursue theatre, Hammerstein began his first professional collaboration, with Herbert Stothart, Otto Harbach and Frank Mandel. He began as an apprentice and went on to form a 20-year collaboration with Harbach. Out of this collaboration came his first musical, "Always You", for which he wrote the book and lyrics. It opened on Broadway in 1920.
Throughout the next forty years, Hammerstein teamed with many other composers, including Jerome Kern, with whom Hammerstein enjoyed a highly successful collaboration. In 1927, Kern and Hammerstein had their biggest hit, "Show Boat", which is often revived and is still considered one of the masterpieces of the American musical theatre. "Here we come to a completely new genre — the musical play as distinguished from musical comedy. Now ... the play was the thing, and everything else was subservient to that play. Now ... came complete integration of song, humor and production numbers into a single and inextricable artistic entity." Many years later, Hammerstein's wife Dorothy bristled when she heard a remark that Jerome Kern had written "Ol' Man River." "Indeed not," she retorted. "Jerome Kern wrote "dum, dum, dum-dum. My husband wrote 'Ol' Man River'."
Other Kern-Hammerstein musicals include "Sweet Adeline", "Music in the Air", "Three Sisters", and "Very Warm for May". Hammerstein also collaborated with Vincent Youmans ("Wildflower"), Rudolf Friml ("Rose-Marie"), and Sigmund Romberg ("The Desert Song" and "The New Moon").
Rodgers and Hammerstein.
Hammerstein's most successful and sustained collaboration began when he teamed up with Richard Rodgers to write a musical adaptation of the play "Green Grow the Lilacs". Rodgers' first partner, Lorenz Hart, originally planned to collaborate with Rodgers on this piece, but his alcoholism had become out of control, and he was unable to write. Hart was also not certain that the idea had much merit, and the two therefore separated. The adaptation became the first Rodgers and Hammerstein collaboration, entitled "Oklahoma!", which opened on Broadway in 1943. It furthered the revolution begun by "Show Boat", by thoroughly integrating all the aspects of musical theatre, with the songs and dances arising out of and further developing the plot and characters. William A. Everett and Paul R. Laird wrote that this was a "show, that, like 'Show Boat', became a milestone, so that later historians writing about important moments in twentieth-century theatre would begin to identify eras according to their relationship to 'Oklahoma.'" After "Oklahoma!", Rodgers and Hammerstein were the most important contributors to the musical-play form – with such masterworks as "Carousel", "The King and I" and "South Pacific". The examples they set in creating vital plays, often rich with social thought, provided the necessary encouragement for other gifted writers to create musical plays of their own".
The partnership went on to produce these and other Broadway musicals such as "Allegro", "Me and Juliet", "Pipe Dream", "Flower Drum Song", and "The Sound of Music", as well as the musical film "State Fair" (and its stage adaptation of the same name), and the television musical "Cinderella", all featured in the revue "A Grand Night for Singing". Hammerstein also wrote the book and lyrics for "Carmen Jones", an adaptation of Georges Bizet's opera "Carmen" with an all-black cast that became a 1943 Broadway musical and a 1954 film.
Death.
Hammerstein died of stomach cancer on August 23, 1960, at his home Highland Farm in Doylestown, Pennsylvania, at 65, shortly after the opening of "The Sound of Music" on Broadway. The final song he wrote was "Edelweiss", which was added near the end of the second act during rehearsal. This was not an Austrian folk song, but had been written specifically for the musical. After his death, "The Sound of Music" was made into the hit 1965 film adaptation, which won the Academy Award for Best Picture.
The lights of Times Square were turned off for one minute, and London's West End lights were dimmed in recognition of his contribution to the musical. He was cremated, and his ashes were buried at the Ferncliff Cemetery in Hartsdale, New York. A memorial plaque was unveiled at Southwark Cathedral, England, on May 24, 1961. He was survived by his second wife, Dorothy, his three children and two stepchildren.
Personal life.
Hammerstein married his second wife, the Australian-born Dorothy (Blanchard) Jacobson (1899-1987), on May 13, 1929. He had three children: William Hammerstein (1918–2001) and Alice Hammerstein Mathias by his first wife, Myra Finn, and James Hammerstein by Blanchard. By Dorothy he also had a stepdaughter, Susan Blanchard (whose four husbands included Henry Fonda and Richard Widmark), and a stepson, Henry Jacobson.
Reputation.
Hammerstein was one of the most important "book writers" in Broadway history – he made the story, not the songs or the stars, central to the musical and brought musical theater to full maturity as an art form. According to Stephen Sondheim, "What few people understand is that Oscar's big contribution to the theater was as a theoretician, as a Peter Brook, as an innovator. People don't understand how experimental "Show Boat" and "Oklahoma!" felt at the time they were done. Oscar is not about the 'lark that is learning to pray' – that's easy to make fun of. He's about "Allegro"."
His reputation for being sentimental is based largely on the movie versions of the musicals, especially "The Sound of Music", in which a song sung by those in favor of reaching an accommodation with the Nazis, "No Way to Stop It", was cut. As recent revivals of "Show Boat", "Oklahoma!", "Carousel", and "The King and I" in London and New York show, Hammerstein was one of the more tough-minded and socially conscious American musical theater artists. According to Richard Kislan, "The shows of Rodgers and Hammerstein were the product of sincerity. In the light of criticism directed against them and their universe of sweetness and light, it is important to understand that they believed sincerely in what they wrote." According to Marc Bauch, "The Rodgers and Hammerstein musicals are romantic musical plays. Love is important."
According to "The Rodgers and Hammerstein Story" by Stanley Green, "For three minutes, on the night of September first, the entire Times Square area in New York City was blacked out in honor of the man who had done so much to light up that particular part of the world. From 8:57 to 9:00 p.m., every neon sign and every light bulb was turned off and all traffic was halted between 42nd Street and 53rd Street, and between 8th Ave and the Avenue of the Americas. A crowd of 5,000 people, many with heads bowed, assembled at the base of the statue of Father Duffy on Times Square where two trumpeters blew taps. It was the most complete blackout on Broadway since World War II, and the greatest tribute of its kind ever paid to one man."
Songs.
Hammerstein contributed the lyrics to 850 songs, according to "The Complete Lyrics of Oscar Hammerstein II", edited by Amy Asch. Some well-known songs are "Ol' Man River", "Can't Help Lovin' That Man" and "Make Believe" from "Show Boat"; "Indian Love Call" from "Rose-Marie"; "People Will Say We're in Love" and "Oklahoma" (which has been the official state song of Oklahoma since 1953) from "Oklahoma!"; "Some Enchanted Evening", from "South Pacific"; "Getting to Know You" and "Shall We Dance" from "The King and I"; and the title song as well as "Climb Ev'ry Mountain" from "The Sound of Music".
Several albums of Hammerstein's musicals were named to the "Songs of the Century" list as compiled by the Recording Industry Association of America (RIAA), the National Endowment for the Arts, and Scholastic Corporation:
Awards and legacy.
Hammerstein won two Oscars for best original song—in 1941 for "The Last Time I Saw Paris" in the film "Lady Be Good", and in 1945 for "It Might as Well Be Spring" in "State Fair." In 1950, the team of Rodgers and Hammerstein received The Hundred Year Association of New York's Gold Medal Award "in recognition of outstanding contributions to the City of New York."
Hammerstein won eight Tony Awards, six for lyrics or book, and two as producer of the Best Musical ("South Pacific" and "The Sound of Music"). Rodgers and Hammerstein began writing together before the era of the Tonys: "Oklahoma!" opened in 1943 and "Carousel" in 1945, and the Tony Awards were not awarded until 1947. They won a special Pulitzer Prize in 1944 for "Oklahoma!" and, with Joshua Logan, the annual Pulitzer Prize for Drama in 1950 for "South Pacific". The Oscar Hammerstein II Center for Theater Studies at Columbia University was established in 1981 with a $1-million gift from his family.
His advice and work influenced Stephen Sondheim, a friend of the Hammerstein family from childhood. Sondheim has attributed his success in theater directly to Hammerstein's influence and guidance.
The Oscar Hammerstein Award for Lifetime Achievement in Musical Theatre is presented annually. The York Theatre Company in New York City is the Administrator of the award. The 2009 winners were Jerry Bock and Sheldon Harnick. Past awardees are composers such as Stephen Sondheim and performers such as Carol Channing. The 2010 award went to Thomas Meehan.
Oscar Hammerstein was a member of the American Theater Hall of Fame.

</doc>
<doc id="22756" url="http://en.wikipedia.org/wiki?curid=22756" title="Otto Jespersen">
Otto Jespersen

Jens Otto Harry Jespersen or Otto Jespersen (]; 16 July 1860 – 30 April 1943) was a Danish linguist who specialized in the grammar of the English language.
Early life.
Otto Jespersen was born in Randers in Jutland. He was inspired by the work of Danish philologist Rasmus Rask as a boy, and with the help of Rask's grammars taught himself some Icelandic, Italian, and Spanish. He entered the University of Copenhagen in 1877 when he was 17, initially studying law but not forgetting his language studies. In 1881 he shifted his focus completely to languages, and in 1887 earned his master's degree in French, with English and Latin as his secondary languages. He supported himself during his studies through part-time work as a schoolteacher and as a shorthand reporter in the Danish parliament. In 1887–1888, he traveled to England, Germany and France, meeting linguists like Henry Sweet and Paul Passy and attending lectures at institutions like Oxford University. Following the advice of his mentor Vilhelm Thomsen, he returned to Copenhagen in August 1888 and began work on his doctoral dissertation on the English case system. He successfully defended his dissertation in 1891.
Academic life and work.
Jespersen was a professor of English at the University of Copenhagen from 1893 to 1925, and served as Rector of the university in 1920–21. His early work focused primarily on language teaching reform and on phonetics, but he is best known for his later work on syntax and on language development.
He advanced the theories of "Rank" and "Nexus" in Danish in two papers: "Sprogets logik" (1913) and "De to hovedarter af grammatiske forbindelser" (1921). Jespersen in this theory of ranks removes the parts of speech from the syntax, and differentiates between primaries, secondaries, and tertiaries; e.g. in ""well honed phrase"," "phrase" is a primary, this being defined by a secondary, "honed", which again is defined by a tertiary "well". The term "Nexus" is applied to sentences, structures similar to sentences and sentences in formation, in which two concepts are expressed in one unit; e.g., "it rained, he ran indoors". This term is qualified by a further concept called a "junction" which represents one idea, expressed by means of two or more elements, whereas a nexus combines two ideas. Junction and nexus proved valuable in bringing the concept of context to the forefront of the attention of the world of linguistics.
He was most widely recognized for some of his books. "Language: Its Nature, Development and Origin" (1922) is considered by many to be his masterpiece. "Modern English Grammar on Historical Principles" (1909–1949), concentrated on morphology and syntax, and "Growth and Structure of the English Language" (1905) is a comprehensive view of English by someone with another native language, and still in print, over 70 years after his death and more than 100 years after publication. Late in his life he published "Analytic Syntax" (1937), in which he presents his views on syntactic structure using an idiosyncratic shorthand notation. In "The Philosophy of Grammar" (1924) he challenged the accepted views of common concepts in Grammar and proposed corrections to the basic definitions of grammatical case, pronoun, object, voice etc., and developed further his notions of "Rank" and "Nexus". In the 21st century this book is still used as one of the basic texts in modern Structural linguistics. "Mankind, Nation and Individual: from a linguistic point of view" (1925) is one of the pioneering works on Sociolinguistics.
Jespersen visited the United States twice: he lectured at the Congress of Arts and Sciences in St. Louis in 1904, and in 1909–1910 he visited both the University of California and Columbia University. While in the U.S., he took occasion to study the country's educational system. His autobiography (see below) was published in English translation as recently as 1995.
Jespersen was a proponent of phonosemanticism and wrote: “Is there really much more logic in the opposite extreme which denies any kind of sound symbolism (apart from the small class of evident echoisms and ‘onomatopoeia’) and sees in our words only a collection of accidental and irrational associations of sound and meaning? ...There is no denying that there are words which we feel instinctively to be adequate to express the ideas they stand for.”
After his retirement in 1925, Jespersen remained active in the international linguistic community. In addition to continuing to write, he convened and chaired the first International Meeting on Linguistic Research in Geneva in 1930, and acted as president of the Fourth International Congress of Linguists in Copenhagen in 1936.
Jespersen was an important figure in the international language movement. He was an early supporter of the Esperanto offshoot Ido and in 1927 published his own project Novial. He also worked with the International Auxiliary Language Association.
Jespersen received honorary degrees from Columbia University in New York (1910), St. Andrews University in Scotland (1925), and the Sorbonne in Paris (1927). He was one of the first six international scholars to be elected as honorary members of the Linguistic Society of America.
Trivia.
He appears as a character in Joseph Skibell's 2010 novel "A Curable Romantic".
In C.S.Lewis' science fiction novel "Out of the Silent Planet", he is said to be comparable in philology to Einstein and Schroedinger in physics.

</doc>
<doc id="22758" url="http://en.wikipedia.org/wiki?curid=22758" title="List of object-oriented programming languages">
List of object-oriented programming languages

This is a list of notable object-oriented programming languages, which are also listed in .

</doc>
<doc id="22759" url="http://en.wikipedia.org/wiki?curid=22759" title="OOP">
OOP

OOP, Oop, or oop may refer to:

</doc>
<doc id="22760" url="http://en.wikipedia.org/wiki?curid=22760" title="Occidental">
Occidental

"Occidental" is derived from a Latin word for the direction west, "occidens", and is a term sometimes used to refer to the European continent. The corresponding term Oriental ("of the Orient") is of similar derivation: it is taken from the Latin for east, "oriens".
Other Usages.
It may also refer to:

</doc>
<doc id="22761" url="http://en.wikipedia.org/wiki?curid=22761" title="Occidental language">
Occidental language

The language Occidental, later Interlingue, is a planned international auxiliary language created by the Balto-German naval officer and teacher Edgar de Wahl, and published in 1922. The vocabulary is based on already existing international words. The language is thereby naturalistic, at the same time as it is constructed to be regular. Occidental was quite popular in the years before the Second World War, but declined in the years thereafter.
Occidental is devised so that many of its derived word forms reflect the similar forms common to a number of Western European languages, primarily those in the Romance family. This was done through application of de Wahl's rule which is a set of rules for converting verb infinitives into derived nouns and adjectives. The result is a language easy to understand at first sight for individuals acquainted with several Western European languages. Coupled with a simplified grammar, this made Occidental exceptionally popular in Europe during the 15 years before World War II.
In "The Esperanto Book", Don Harlow says that Occidental had an intentional emphasis on European forms, and that some of its leading followers espoused a Eurocentric philosophy, which may have hindered its spread. Still, Occidental gained adherents in many nations including Asian nations. Before World War II it had grown to become the second largest international auxiliary language in numbers of adherents, after Esperanto. According to the Occidental magazine "Cosmoglotta" in 1928, a majority of Ido adherents took up Occidental in place of Ido.
Occidental survived World War II, undergoing a name change to "Interlingue", but faded into insignificance following the appearance in the early 1950s of a competing naturalistic project, Interlingua, which attracted among others the notable Occidentalist Ric Berger.
Alphabet and pronunciation.
Occidental is written with 26 Latin letters: a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p, q, r, s, t, u, v, w, x, y, z. The letters of the alphabet are pronounced as "a, be, ce, de, e, ef, ge, ha, i, jot, ka, el, em, en, o, pe, qu, er, es, te, u, ve, duplic ve, ix, ypsilon", and "zet".
Pronunciation.
The vowels "a, e, i, o", and "u" have a continental pronunciation and are all sounded. The "y" (initial and medial) are pronounced as in "yes", "ey" (final) as in "they", and "eu" as éh-oo.
The consonants are pronounced as in English, with the following exceptions:
Grammar.
Like English, Interlingue has a definite article and an indefinite article. The definite article (the) is "li", and the indefinite (a, an) is "un". Plural of a noun is made by adding "-s" after a vowel, or "-es" after a consonant.
Personal pronouns.
Interlingue has two forms for the personal pronouns: one for the subject form (nominative), and one for the object form (accusative or dative). In short, the personal pronouns in the subject form are:
The variants "illa" and "ella" both exist for third person singular feminine. The pronoun expressing politeness is "vu", which behaves like second person plural. The indefinite personal pronoun "one" is "on" in Occidental. If necessary, one can specify the gender of third person plural by using "illos" (masculine) or "illas" (feminine).
In the object form the pronouns are: "me, te, le, la, it, nos, vos", and "les" (with "los" and "las" as specific masculine and feminine forms, respectively). The possessive pronouns are "mi, tui, su" (his/her/its), "nor, vor" and "lor".
Example texts.
 Li material civilisation, li scientie, e mem li arte unifica se plu e plu. Li cultivat europano senti se quasi in hem in omni landes queles have europan civilisation, it es, plu e plu, in li tot munde. Hodie presc omni states guerrea per li sam armes. Sin cessa li medies de intercommunication ameliora se, e in consecuentie de to li terra sembla diminuer se. Un Parisano es nu plu proxim a un angleso o a un germano quam il esset ante cent annus a un paisano frances.
Translation: "Material civilization, science, and even art unify themselves more and more. The educated European feels himself almost at home in all lands that have European civilization, that is, more and more, in the entire world. Today almost all states war with the same armaments. Without pause the modes of intercommunication improve, and in consequence from that the world seems to decrease. A Parisian is now closer to an Englishman or a German than he was a hundred years before to a French peasant."

</doc>
<doc id="22763" url="http://en.wikipedia.org/wiki?curid=22763" title="Osiris">
Osiris

Osiris (, or Usir;or Asiri, also Ausar), was an Egyptian god, usually identified as the god of the afterlife, the underworld and the dead. He was classically depicted as a green-skinned man with a pharaoh's beard, partially mummy-wrapped at the legs, wearing a distinctive crown with two large ostrich feathers at either side, and holding a symbolic crook and flail.
Osiris was at times considered the oldest son of the earth god Geb, and the sky goddess Nut, as well as being brother and husband of Isis, with Horus being considered his posthumously begotten son. He was also associated with the epithet Khenti-Amentiu, which means "Foremost of the Westerners" — a reference to his kingship in the land of the dead. As ruler of the dead, Osiris was also sometimes called ""king of the living", since the Ancient Egyptians considered the blessed dead "the living ones"".
Osiris was considered the brother of Isis, Set, Nephthys, Horus the Elder and father of Horus the younger.
Osiris is first attested in the middle of the Fifth dynasty of Egypt, although it is likely that he was worshipped much earlier; the term Khenti-Amentiu dates to at least the first dynasty, also as a pharaonic title. Most information available on the myths of Osiris is derived from allusions contained in the Pyramid Texts at the end of the Fifth Dynasty, later New Kingdom source documents such as the Shabaka Stone and the "Contending of Horus and Seth", and much later, in narrative style from the writings of Greek authors including Plutarch and Diodorus Siculus.
Osiris was considered not only a merciful judge of the dead in the afterlife, but also the underworld agency that granted all life, including sprouting vegetation and the fertile flooding of the Nile River. He was described as the "Lord of love", "He Who is Permanently Benign and Youthful" and the "Lord of Silence". The Kings of Egypt were associated with Osiris in death — as Osiris rose from the dead they would, in union with him, inherit eternal life through a process of imitative magic. By the New Kingdom all people, not just pharaohs, were believed to be associated with Osiris at death, if they incurred the costs of the assimilation rituals.
Through the hope of new life after death, Osiris began to be associated with the cycles observed in nature, in particular vegetation and the annual flooding of the Nile, through his links with the heliacal rising of Orion and Sirius at the start of the new year. Osiris was widely worshipped as Lord of the Dead until the suppression of the Egyptian religion during the rise of Christianity in the Roman Empire.
Etymology of the name.
"Osiris" is a Latin transliteration of the Ancient Greek Ὄσιρις ], which in turn is the Greek adaptation of the original theonym in the Egyptian language. In Egyptian hieroglyphs the name is written "Wsjr", as the hieroglyphic writing does not restitute all the vowels, and Egyptologists transliterate the name variously as Asar, Asari, Aser, Ausar, Ausir, Wesir, Usir, Usire or Ausare.
Several proposals have been made for the etymology and meaning of the original name "Wsjr". John Gwyn Griffiths (1980) proposed a derivation from "wser" signifying "the powerful". Moreover, one of the oldest attestations of the god Osiris appears in the mastaba of the deceased Netjer-wser (God Almighty).
David Lorton (1985) proposed that "Wsjr" is composed by the morphemes "set-jret" signifying "ritual activity", Osiris being the one who receives it. Wolfhart Westendorf (1987) proposed an etymology from "Waset-jret" "she who bears the eye".
Appearance.
Osiris is represented in his most developed form of iconography wearing the "Atef" crown, which is similar to the White crown of Upper Egypt, but with the addition of two curling ostrich feathers at each side (see also Atef crown (hieroglyph)). He also carries the crook and flail. The crook is thought to represent Osiris as a shepherd god. The symbolism of the flail is more uncertain with shepherds whip, fly-whisk, or association with the god Andjety of the ninth nome of Lower Egypt proposed.
He was commonly depicted as a pharaoh with a complexion of either green (the color of rebirth) or black (alluding to the fertility of the Nile floodplain) in mummiform (wearing the trappings of mummification from chest downward).
More rarely, he was depicted as a lunar god with a crown encompassing the moon.
Early mythology.
The Pyramid Texts describe early conceptions of an afterlife in terms of eternal travelling with the sun god amongst the stars. Amongst these mortuary texts, at the beginning of the 4th dynasty, is found: "An offering the king gives and Anubis". By the end of the 5th dynasty, the formula in all tombs becomes "An offering the king gives and Osiris".
Father of Horus.
Osiris is the mythological father of the god Horus, whose conception is described in the Osiris myth, a central myth in ancient Egyptian belief. The myth described Osiris as having been killed by his brother Set, who wanted Osiris' throne. Isis joined the fragmented pieces of Osiris, but the only body part missing was the phallus. Isis fashioned a golden phallus, and briefly brought Osiris back to life by use of a spell that she learned from her father. This spell gave her time to become pregnant by Osiris before he again died. Isis later gave birth to Horus. As such, since Horus was born after Osiris' resurrection, Horus became thought of as a representation of new beginnings and the vanquisher of the evil Set.
"Ptah-Seker" (who resulted from the identification of Creator god Ptah with Seker), god of reincarnation, thus gradually became identified with Osiris, the two becoming Ptah-Seker-Osiris. As the sun was thought to spend the night in the underworld, and was subsequently "reincarnated" every morning, Ptah-Seker-Osiris was identified as both Creator god, king of the underworld, god of the afterlife, reincarnation, life, death, and resurrection. 
Ram god.
Osiris' soul, or rather his "Ba", was occasionally worshipped in its own right, almost as if it were a distinct god, especially in the Delta city of Mendes. This aspect of Osiris was referred to as "Banebdjedet", which is grammatically feminine (also spelt ""Banebded" or "Banebdjed""), literally "the "ba" of the lord of the "djed", which roughly means "The soul of the lord of the pillar of continuity". The "djed", a type of pillar, was usually understood as the backbone of Osiris, and, at the same time, as the Nile, the backbone of Egypt.
The Nile, supplying water, and Osiris (strongly connected to the vegetable regeneration) who died only to be resurrected, represented continuity and stability. As "Banebdjed", Osiris was given epithets such as "Lord of the Sky" and "Life of the (sun god) Ra", since Ra, when he had become identified with Atum, was considered Osiris' ancestor, from whom his regal authority is inherited. "Ba" does not mean "soul" in the western sense, and has to do with power, reputation, force of character, especially in the case of a god.
Since the "ba" was associated with power, and also happened to be a word for ram in Egyptian, Banebdjed was depicted as a ram, or as Ram-headed. A living, sacred ram was kept at Mendes and worshipped as the incarnation of the god, and upon death, the rams were mummified and buried in a ram-specific necropolis. Banebdjed was consequently said to be Horus' father, as Banebdjed was an aspect of Osiris.
Regarding the association of Osiris with the ram, the god's traditional crook and flail are the instruments of the shepherd, which has suggested to some scholars also an origin for Osiris in herding tribes of the upper Nile. The crook and flail were originally symbols of the minor agricultural deity Andjety, and passed to Osiris later. From Osiris, they eventually passed to Egyptian kings in general as symbols of divine authority.
Mythology.
The cult of Osiris (who was a god chiefly of regeneration and rebirth) had a particularly strong interest in the concept of immortality. Plutarch recounts one version of the myth in which Set (Osiris' brother), along with the Queen of Ethiopia, conspired with 72 accomplices to plot the assassination of Osiris.
Set fooled Osiris into getting into a box, which Set then shut, sealed with lead, and threw into the Nile (sarcophagi were based on the box in this myth). Osiris' wife, Isis, searched for his remains until she finally found him embedded in a tamarind tree trunk, which was holding up the roof of a palace in Byblos on the Phoenician coast. She managed to remove the coffin and open it, but Osiris was already dead.
In one version of the myth, she used a spell learned from her father and brought him back to life so he could impregnate her. Afterwards he died again and she hid his body in the desert. Months later, she gave birth to Horus. While she raised Horus, Set was hunting one night and came across the body of Osiris.
Enraged, he tore the body into fourteen pieces and scattered them throughout the land. Isis gathered up all the parts of the body, except the penis (which had been eaten by a fish, the "medjed") and bandaged them together for a proper burial. The gods were impressed by the devotion of Isis and resurrected Osiris as the god of the underworld. Because of his death and resurrection, Osiris was associated with the flooding and retreating of the Nile and thus with the crops along the Nile valley.
Diodorus Siculus gives another version of the myth in which Osiris was described as an ancient king who taught the Egyptians the arts of civilization, including agriculture, then travelled the world with his sister Isis, the satyrs, and the nine muses, before finally returning to Egypt. Osiris was then murdered by his evil brother Typhon, who was identified with Set. Typhon divided the body into twenty-six pieces, which he distributed amongst his fellow conspirators in order to implicate them in the murder. Isis and Hercules (Horus) avenged the death of Osiris and slew Typhon. Isis recovered all the parts of Osiris' body, except the phallus, and secretly buried them. She made replicas of them and distributed them to several locations, which then became centres of Osiris worship.
Death and institution as god of the dead.
Plutarch and others have noted that the sacrifices to Osiris were "gloomy, solemn, and mournful..." (Isis and Osiris, 69) and that the great mystery festival, celebrated in two phases, began at Abydos commemorating the death of the god, on the same day that grain was planted in the ground (Isis and Osiris, 13). "The death of the grain and the death of the god were one and the same: the cereal was identified with the god who came from heaven; he was the bread by which man lives. The resurrection of the god symbolized the rebirth of the grain." (Larson 17) The annual festival involved the construction of "Osiris Beds" formed in shape of Osiris, filled with soil and sown with seed.
The germinating seed symbolized Osiris rising from the dead. An almost pristine example was found in the tomb of Tutankhamun by Howard Carter.
The first phase of the festival was a public drama depicting the murder and dismemberment of Osiris, the search of his body by Isis, his triumphal return as the resurrected god, and the battle in which Horus defeated Set. This was all presented by skilled actors as a literary history, and was the main method of recruiting cult membership.
According to Julius Firmicus Maternus of the fourth century, this play was re-enacted each year by worshippers who
"beat their breasts and gashed their shoulders... When they pretend that the mutilated remains of the god have been found and rejoined...they turn from mourning to rejoicing." ("De Errore Profanorum").
The passion of Osiris was reflected in his name 'Wenennefer" ("the one who continues to be perfect"), which also alludes to his post mortem power.
Ikhernofret Stela.
Much of the extant information about the Passion of Osiris can be found on the Ikhernofret Stela at Abydos erected in the 12th Dynasty by Ikhernofret (also I-Kher-Nefert), possibly a priest of Osiris or other official (the titles of Ikhernofret are described in his stela from Abydos) during the reign of Senwosret III (Pharaoh Sesostris, about 1875 BC). The Passion Plays were held in the last month of the inundation (the annual Nile flood, coinciding with Spring, and held at Abydos/Abedjou which was the traditional place where the body of Osiris/Wesir drifted ashore after having been drowned in the Nile.
The part of the myth recounting the chopping up of the body into 14 pieces by Set is not recounted in this particular stela. Although it is attested to be a part of the rituals by a version of the Papyrus Jumilhac, in which it took Isis 12 days to reassemble the pieces, coinciding with the festival of ploughing. Some elements of the ceremony were held in the temple, while others involved public participation in a form of theatre. The Stela of I-Kher-Nefert recounts the programme of events of the public elements over the five days of the Festival:
Wheat and clay rituals.
Contrasting with the public "theatrical" ceremonies sourced from the I-Kher-Nefert stele (from the Middle Kingdom), more esoteric ceremonies were performed inside the temples by priests witnessed only by chosen initiates. Plutarch mentions that (for much later period) two days after the beginning of the festival "the priests bring forth a sacred chest containing a small golden coffer, into which they pour some potable water...and a great shout arises from the company for joy that Osiris is found (or resurrected). Then they knead some fertile soil with the water...and fashion therefrom a crescent-shaped figure, which they cloth and adorn, this indicating that they regard these gods as the substance of Earth and Water." ("Isis and Osiris," 39). Yet his accounts were still obscure, for he also wrote, "I pass over the cutting of the wood" - opting not to describe it, since he considered it as a most sacred ritual ("Ibid." 21).
In the Osirian temple at Denderah, an inscription (translated by Budge, Chapter XV, Osiris and the Egyptian Resurrection) describes in detail the making of wheat paste models of each dismembered piece of Osiris to be sent out to the town where each piece is discovered by Isis. At the temple of Mendes, figures of Osiris were made from wheat and paste placed in a trough on the day of the murder, then water was added for several days, until finally the mixture was kneaded into a mold of Osiris and taken to the temple to be buried (the sacred grain for these cakes were grown only in the temple fields). Molds were made from the wood of a red tree in the forms of the sixteen dismembered parts of Osiris, the cakes of 'divine' bread were made from each mold, placed in a silver chest and set near the head of the god with "the inward parts of Osiris" as described in the Book of the Dead (XVII).
On the first day of the Festival of Ploughing, where the goddess Isis appeared in her shrine where she was stripped naked, paste made from the grain were placed in her bed and moistened with water, representing the fecund earth. All of these sacred rituals were "climaxed by the eating of sacramental god, the eucharist by which the celebrants were transformed, in their persuasion, into replicas of their god-man" (Larson 20).
Judgement.
The idea of divine justice being exercised after death for wrongdoing during life is first encountered during the Old Kingdom, in a 6th dynasty tomb containing fragments of what would be described later as the Negative Confessions.
With the rise of the cult of Osiris during the Middle Kingdom the “"democratization of religion"” offered to even his humblest followers the prospect of eternal life, with moral fitness becoming the dominant factor in determining a person's suitability.
At death a person faced judgment by a tribunal of forty-two divine judges. If they led a life in conformance with the precepts of the goddess Ma'at, who represented truth and right living, the person was welcomed into the kingdom of Osiris. If found guilty, the person was thrown to a ""devourer" and didn't share in eternal life.
The person who is taken by the devourer is subject first to terrifying punishment and then annihilated. These depictions of punishment may have influenced medieval perceptions of the inferno in hell via early Christian and Coptic texts.
Purification for those who are considered justified may be found in the descriptions of ""Flame Island", where they experience the triumph over evil and rebirth. For the damned, complete destruction into a state of non-being awaits, but there is no suggestion of eternal torture.
Divine pardon at judgement was always a central concern for the Ancient Egyptians.
During the reign of Seti I, Osiris was also invoked in royal decrees to pursue the living when wrongdoing was observed, but kept secret and not reported.
Greco-Roman era.
Hellenization.
Eventually, in Egypt, the Hellenic pharaohs decided to produce a deity that would be acceptable to both the local Egyptian population, and the influx of Hellenic visitors, to bring the two groups together, rather than allow a source of rebellion to grow. Thus Osiris was identified explicitly with Apis, while really an aspect of Ptah, who had already been identified as Osiris by this point, and a syncretism of the two was created, known as Serapis, and depicted as a standard Greek god. 
Destruction of cult.
The cult of Osiris continued until the 6th century AD on the island of Philae in Upper Nile. The Theodosian decrees of the 390s, to destroy all pagan temples, were not enforced there. The worship of Isis and Osiris was allowed to continue at Philae until the time of Justinian, by treaty between the Blemmyes-Nobadae and Diocletian. Every year they visited Elephantine, and at certain intervals took the image of Isis up river to the land of the Blemmyes for oracular purposes. The practices ended when Justinian I sent Narses to destroy sanctuaries, arrest priests, and seize divine images, which were taken to Constantinople.

</doc>
<doc id="22764" url="http://en.wikipedia.org/wiki?curid=22764" title="Orthodox Bahá'í Faith">
Orthodox Bahá'í Faith

The Orthodox Bahá'í Faith is a small Bahá'í sect that formed in 1960 by Mason Remey, and subsequently was the name used by Joel Marangella after he claimed to be Remey's successor. The basis of the dispute is over the identity of the Bahá'í "Guardian", a term referring to the appointed head of the religion, an executive hereditary office held by Shoghi Effendi from 1921 to 1957.
Other than on the matter of leadership and organization, there are few differences between the orthodox and mainstream Bahá'ís in matters of doctrine. As a group who believe that Mason Remey was the second Guardian of the Bahá'í Faith, they are considered heretical Covenant-breakers by the majority of Bahá'ís who follow the leadership of the Universal House of Justice. 
Membership data of the Orthodox Bahá'ís is scarce. One source estimated them at no more than 100 members as of 1988. Memorandums from an Illinois court case in 2007 state their membership in the United States at 40. Websites claiming to represent the Orthodox community indicate followers in the United States and India. Joel Marangella died in San Diego, California on Sept 1, 2013.
Background.
Following the unexpected death of the Bahá'í Faith's first Guardian Shoghi Effendi in 1957, the 27 living Hands of the Cause, having the responsibility to acknowledge any appointment of a successor, gathered and decided that he had died "without having appointed his successor," and that the Universal House of Justice would decide on the situation after its first election. Charles Mason Remey, one of the Hands, declared himself the successor to Shoghi Effendi in 1960. His claim was rejected by the 26 remaining Hands, on the basis that he was not a descendant of Bahá'u'lláh, nor was he appointed to the position by Shoghi Effendi. Remey based his claim on his being the president of the International Bahá'í Council appointed by Shoghi Effendi in 1951. The result was that Remey was unanimously expelled from the Bahá'í community by the Hands of the Cause.
In 1962 Remey asked his supporters in the United States to organize themselves and elect a "National Spiritual Assembly Under the Hereditary Guardianship" (NSAUHG), first elected in 1963. The Assembly of 9 members was incorporated in New Mexico in 1964.
In 1964 the NSAUHG filed a lawsuit against the National Spiritual Assembly (NSA) of the Bahá'ís of the United States to receive the legal title to the Bahá'í House of Worship in Illinois, and all other property owned by the NSA. The NSA counter-sued, and in August 1966 Remey instructed the NSAUHG to withdraw from any action in the matter "regardless of the consequences." Later that year, Remey asked the NSAUHG to dissolve, as well as the International Bahá'í Council that he had appointed with Joel Marangella as president, residing in France. Marangella previously served on the National Spiritual Assembly of France in 1961, and was declared a Covenant-breaker when he accepted Mason Remey as the next Guardian.
Over the years following 1966 the followers of Mason Remey were not organized; with some of his followers concluding that Remey was suffering from dementia, until several of the individuals involved began forming their own groups based on different understandings of succession.
In 1962 Remey gave Marangella a sealed envelope, with instructions to open it when the time was right. In 1965 Mason Remey called for the International Bahá'í Council, of which Marangella was president, to become active. Marangella then opened the sealed letter, which was a hand-written note by Remey appointing Marangella as his successor. Marangella looks upon that time as the time of his official appointment. Remey then changed his mind, deactivated the International Bahá'í Council in 1966, and in 1969 Marangella announced that he was the third Guardian. All of the members of the 1966 NSAUHG accepted Marangella's claim. 
In 1970 Marangella appointed members to a "National Bureau of the Orthodox Bahá'ís in New York", which two years later was moved to New Mexico, and subsequently changed its name to "Mother Bahá'í Council of the United States" (1978) and "Provisional National Bahá'í Council" (2000), with all members appointed by Joel Marangella.. Marangella died in San Diego, CA on Sept 1, 2013.

</doc>
<doc id="22770" url="http://en.wikipedia.org/wiki?curid=22770" title="1 (number)">
1 (number)

1 (one; or , also called "unit", "unity", and "(multiplicative) identity") is a number, a numeral, and the name of the glyph representing that number. It represents a single entity, the unit of counting or measurement. For example, a line segment of "unit length" is a line segment of length 1.
As a number.
One, sometimes referred to as unity, is the integer before two and after zero. One is the first non-zero number in the natural numbers as well as the first odd number in the natural numbers.
Any number multiplied by one is that number, as one is the identity for multiplication. As a result, one is its own factorial, its own square, its own cube, and so on. One is also the result of the empty product, as any number multiplied by one is itself. It is also the only natural number that is neither composite nor prime with respect to division, but instead considered a unit.
As a digit.
The glyph used today in the Western world to represent the number 1, a vertical line, often with a serif at the top and sometimes a short horizontal line at the bottom, traces its roots back to the Indians, who wrote 1 as a horizontal line, much like the Chinese character 一. The Gupta wrote it as a curved line, and the Nagari sometimes added a small circle on the left (rotated a quarter turn to the right, this 9-look-alike became the present day numeral 1 in the Gujarati and Punjabi scripts). The Nepali also rotated it to the right but kept the circle small. This eventually became the top serif in the modern numeral, but the occasional short horizontal line at the bottom probably originates from similarity with the Roman numeral formula_1. In some countries, the little serif at the top is sometimes extended into a long upstroke, sometimes as long as the vertical line, which can lead to confusion with the glyph for seven in other countries. Where the 1 is written with a long upstroke, the number 7 has a horizontal stroke through the vertical line.
While the shape of the 1 character has an ascender in most modern typefaces, in typefaces with text figures, the character usually is of x-height, as, for example, in .
Many older typewriters do not have a separate symbol for "1" and use the lowercase "l" instead. It is possible to find cases when the uppercase "J" is used, while it may be for decorative purposes.
Mathematics.
Mathematically, 1 is:
One cannot be used as the base of a positional numeral system. (Sometimes tallying is referred to as "base 1", since only one mark — the tally itself — is needed, but this is not a positional notation.)
Since the base 1 exponential function (1"x") always equals 1, its inverse does not exist (which would be called the logarithm base 1 if it did exist).
There are two ways to write the real number 1 as a recurring decimal: as 1.000..., and as 0.999... ("q.v."). There is only one way to represent the real number 1 as a Dedekind cut: formula_2.
Formalizations of the natural numbers have their own representations of 1:
In a multiplicative group or monoid, the identity element is sometimes denoted "1", especially in abelian groups, but "e" (from the German "Einheit", "unity") is more traditional. However, "1" is especially common for the multiplicative identity of a ring, i.e., when an addition and "0" are also present. When such a ring has characteristic "n" not equal to 0, the element called 1 has the property that "n"1 = 1"n" = 0 (where this 0 is the additive identity of the ring). Important examples are general fields.
One is the first figurate number of every kind, such as triangular number, pentagonal number and centered hexagonal number, to name just a few.
In many mathematical and engineering equations, numeric values are typically "normalized" to fall within the unit interval from 0 to 1, where 1 usually represents the maximum possible value in the range of parameters.
Because of the multiplicative identity, if "f"("x") is a multiplicative function, then "f"(1) must equal 1.
It is also the first and second number in the Fibonacci sequence (0 is the zeroth) and is the first number in many other mathematical sequences. As a matter of convention, Sloane's early "Handbook of Integer Sequences" added an initial 1 to any sequence that did not already have it and considered these initial 1's in its lexicographic ordering. Sloane's later "Encyclopedia of Integer Sequences" and its Web counterpart, the "On-Line Encyclopedia of Integer Sequences", ignore initial ones in their lexicographic ordering of sequences, because such initial ones often correspond to trivial cases.
One is neither a prime number nor a composite number, but a unit, like −1 and, in the Gaussian integers, "i" and −"i". The fundamental theorem of arithmetic guarantees unique factorization over the integers only up to units. (For example, 4 = 22, but if units are included, is also equal to, say, (−1)6×123×22, among infinitely many similar "factorizations".)
The definition of a field requires that 1 must not be equal to 0. Thus, there are no fields of characteristic 1. Nevertheless, abstract algebra can consider the field with one element, which is not a singleton and is not a set at all.
One is the only positive integer divisible by exactly one positive integer (whereas prime numbers are divisible by exactly two positive integers, composite numbers are divisible by more than two positive integers, and zero is divisible by all positive integers). One was formerly considered prime by some mathematicians, using the definition that a prime is divisible only by one and itself. However, this complicates the fundamental theorem of arithmetic, so modern definitions exclude units.
One is one of three possible values of the Möbius function: it takes the value one for square-free integers with an even number of distinct prime factors.
One is the only odd number in the range of Euler's totient function φ("x"), in the cases "x" = 1 and "x" = 2.
One is the only 1-perfect number (see multiply perfect number).
By definition, 1 is the magnitude, absolute value, or norm of a unit complex number, unit vector, and a unit matrix (more usually called an identity matrix). Note that the term "unit matrix" is sometimes used to mean something quite different.
By definition, 1 is the probability of an event that is almost certain to occur.
One is the most common leading digit in many sets of data, a consequence of Benford's law.
The ancient Egyptians represented all fractions (with the exception of 2/3) in terms of sums of fractions with numerator 1 and distinct denominators. For example, formula_3. Such representations are popularly known as Egyptian Fractions or Unit Fractions. 
The Generating Function that has all coefficients 1 is given by
formula_4.
This power series converges and has finite value if and only if, formula_5. 
In philosophy.
In the philosophy of Plotinus and a number of other neoplatonists, The One is the ultimate reality and source of all existence.
Philo of Alexandria (20 BC – AD 50) regarded the number one as God's number, and the basis for all numbers ("De Allegoriis Legum," ii.12 [i.66]).
Etymology.
The word one can be used as a noun, an adjective and a pronoun.
It comes from the Old English word an, which comes from the Proto-Germanic root *ainaz. The Proto-Germanic root *ainaz comes from the Proto-Indo-European root *oi-no-.
Compare the Proto-Germanic root *ainaz to Old Frisian an, Gothic ains, Danish een, Dutch een, German eins and Old Norse einn.
Compare the Proto-Indo-European root *oi-no- (which means one, single) to Greek oinos (which means "ace" on dice), Latin unus (one), Old Persian aivam, Old Church Slavonic -inu and ino-, Lithuanian vienas, Old Irish oin and Breton un (one).

</doc>
<doc id="22773" url="http://en.wikipedia.org/wiki?curid=22773" title="Oxidative phosphorylation">
Oxidative phosphorylation

Oxidative phosphorylation (or OXPHOS in short) is the metabolic pathway in which the mitochondria in cells use their structure, enzymes, and energy released by the oxidation of nutrients to reform ATP. Although the many forms of life on earth use a range of different nutrients, ATP is the molecule that supplies energy to metabolism. Almost all aerobic organisms carry out oxidative phosphorylation. This pathway is probably so pervasive because it is a highly efficient way of releasing energy, compared to alternative fermentation processes such as anaerobic glycolysis.
During oxidative phosphorylation, electrons are transferred from electron donors to electron acceptors such as oxygen, in redox reactions. These redox reactions release energy, which is used to form ATP. In eukaryotes, these redox reactions are carried out by a series of protein complexes within the cell's intermembrane wall mitochondria, whereas, in prokaryotes, these proteins are located in the cells' intermembrane space. These linked sets of proteins are called electron transport chains. In eukaryotes, five main protein complexes are involved, whereas in prokaryotes many different enzymes are present, using a variety of electron donors and acceptors.
The energy released by electrons flowing through this electron transport chain is used to transport protons across the inner mitochondrial membrane, in a process called "electron transport". This generates potential energy in the form of a pH gradient and an electrical potential across this membrane. This store of energy is tapped by allowing protons to flow back across the membrane and down this gradient, through a large enzyme called ATP synthase; this process is known as chemiosmosis. This enzyme uses this energy to generate ATP from adenosine diphosphate (ADP), in a phosphorylation reaction. This reaction is driven by the proton flow, which forces the rotation of a part of the enzyme; the ATP synthase is a rotary mechanical motor.
Although oxidative phosphorylation is a vital part of metabolism, it produces reactive oxygen species such as superoxide and hydrogen peroxide, which lead to propagation of free radicals, damaging cells and contributing to disease and, possibly, aging (senescence). The enzymes carrying out this metabolic pathway are also the target of many drugs and poisons that inhibit their activities.
Overview of energy transfer by chemiosmosis.
Oxidative phosphorylation works by using energy-releasing chemical reactions to drive energy-requiring reactions: The two sets of reactions are said to be "coupled". This means one cannot occur without the other. The flow of electrons through the electron transport chain, from electron donors such as NADH to electron acceptors such as oxygen, is an exergonic process – it releases energy, whereas the synthesis of ATP is an endergonic process, which requires an input of energy. Both the electron transport chain and the ATP synthase are embedded in a membrane, and energy is transferred from electron transport chain to the ATP synthase by movements of protons across this membrane, in a process called "chemiosmosis". In practice, this is like a simple electric circuit, with a current of protons being driven from the negative N-side of the membrane to the positive P-side by the proton-pumping enzymes of the electron transport chain. These enzymes are like a battery, as they perform work to drive current through the circuit. The movement of protons creates an electrochemical gradient across the membrane, which is often called the "proton-motive force". It has two components: a difference in proton concentration (a H+ gradient, ΔpH) and a difference in electric potential, with the N-side having a negative charge.
ATP synthase releases this stored energy by completing the circuit and allowing protons to flow down the electrochemical gradient, back to the N-side of the membrane. This kinetic energy drives the rotation of part of the enzymes structure and couples this motion to the synthesis of ATP.
The two components of the proton-motive force are thermodynamically equivalent: In mitochondria, the largest part of energy is provided by the potential; in alkaliphile bacteria the electrical energy even has to compensate for a counteracting inverse pH difference. Inversely, chloroplasts operate mainly on ΔpH. However, they also require a small membrane potential for the kinetics of ATP synthesis. At least in the case of the fusobacterium "P. modestum" it drives the counter-rotation of subunits a and c of the FO motor of ATP synthase.
The amount of energy released by oxidative phosphorylation is high, compared with the amount produced by anaerobic fermentation. Glycolysis produces only 2 ATP molecules, but somewhere between 30 and 36 ATPs are produced by the oxidative phosphorylation of the 10 NADH and 2 succinate molecules made by converting one molecule of glucose to carbon dioxide and water, while each cycle of beta oxidation of a fatty acid yields about 14 ATPs. These ATP yields are theoretical maximum values; in practice, some protons leak across the membrane, lowering the yield of ATP.
Electron and proton transfer molecules.
The electron transport chain carries both protons and electrons, passing electrons from donors to acceptors, and transporting protons across a membrane. These processes use both soluble and protein-bound transfer molecules. In mitochondria, electrons are transferred within the intermembrane space by the water-soluble electron transfer protein cytochrome c. This carries only electrons, and these are transferred by the reduction and oxidation of an iron atom that the protein holds within a heme group in its structure. Cytochrome c is also found in some bacteria, where it is located within the periplasmic space.
Within the inner mitochondrial membrane, the lipid-soluble electron carrier coenzyme Q10 (Q) carries both electrons and protons by a redox cycle. This small benzoquinone molecule is very hydrophobic, so it diffuses freely within the membrane. When Q accepts two electrons and two protons, it becomes reduced to the "ubiquinol" form (QH2); when QH2 releases two electrons and two protons, it becomes oxidized back to the "ubiquinone" (Q) form. As a result, if two enzymes are arranged so that Q is reduced on one side of the membrane and QH2 oxidized on the other, ubiquinone will couple these reactions and shuttle protons across the membrane. Some bacterial electron transport chains use different quinones, such as menaquinone, in addition to ubiquinone.
Within proteins, electrons are transferred between flavin cofactors, iron–sulfur clusters, and cytochromes. There are several types of iron–sulfur cluster. The simplest kind found in the electron transfer chain consists of two iron atoms joined by two atoms of inorganic sulfur; these are called [2Fe–2S] clusters. The second kind, called [4Fe–4S], contains a cube of four iron atoms and four sulfur atoms. Each iron atom in these clusters is coordinated by an additional amino acid, usually by the sulfur atom of cysteine. Metal ion cofactors undergo redox reactions without binding or releasing protons, so in the electron transport chain they serve solely to transport electrons through proteins. Electrons move quite long distances through proteins by hopping along chains of these cofactors. This occurs by quantum tunnelling, which is rapid over distances of less than 1.4×10−9 m.
Eukaryotic electron transport chains.
Many catabolic biochemical processes, such as glycolysis, the citric acid cycle, and beta oxidation, produce the reduced coenzyme NADH. This coenzyme contains electrons that have a high transfer potential; in other words, they will release a large amount of energy upon oxidation. However, the cell does not release this energy all at once, as this would be an uncontrollable reaction. Instead, the electrons are removed from NADH and passed to oxygen through a series of enzymes that each release a small amount of the energy. This set of enzymes, consisting of complexes I through IV, is called the electron transport chain and is found in the inner membrane of the mitochondrion. Succinate is also oxidized by the electron transport chain, but feeds into the pathway at a different point.
In eukaryotes, the enzymes in this electron transport system use the energy released from the oxidation of NADH to pump protons across the inner membrane of the mitochondrion. This causes protons to build up in the intermembrane space, and generates an electrochemical gradient across the membrane. The energy stored in this potential is then used by ATP synthase to produce ATP. Oxidative phosphorylation in the eukaryotic mitochondrion is the best-understood example of this process. The mitochondrion is present in almost all eukaryotes, with the exception of anaerobic protozoa such as "Trichomonas vaginalis" that instead reduce protons to hydrogen in a remnant mitochondrion called a hydrogenosome.
NADH-coenzyme Q oxidoreductase (complex I).
NADH-coenzyme Q oxidoreductase, also known as "NADH dehydrogenase" or "complex I", is the first protein in the electron transport chain. Complex I is a giant enzyme with the mammalian complex I having 46 subunits and a molecular mass of about 1,000 kilodaltons (kDa). The structure is known in detail only from a bacterium; in most organisms the complex resembles a boot with a large "ball" poking out from the membrane into the mitochondrion. The genes that encode the individual proteins are contained in both the cell nucleus and the mitochondrial genome, as is the case for many enzymes present in the mitochondrion.
The reaction that is catalyzed by this enzyme is the two electron oxidation of NADH by coenzyme Q10 or "ubiquinone" (represented as Q in the equation below), a lipid-soluble quinone that is found in the mitochondrion membrane:
formula_1
The start of the reaction, and indeed of the entire electron chain, is the binding of a NADH molecule to complex I and the donation of two electrons. The electrons enter complex I via a prosthetic group attached to the complex, flavin mononucleotide (FMN). The addition of electrons to FMN converts it to its reduced form, FMNH2. The electrons are then transferred through a series of iron–sulfur clusters: the second kind of prosthetic group present in the complex. There are both [2Fe–2S] and [4Fe–4S] iron–sulfur clusters in complex I.
As the electrons pass through this complex, four protons are pumped from the matrix into the intermembrane space. Exactly how this occurs is unclear, but it seems to involve conformational changes in complex I that cause the protein to bind protons on the N-side of the membrane and release them on the P-side of the membrane. Finally, the electrons are transferred from the chain of iron–sulfur clusters to a ubiquinone molecule in the membrane. Reduction of ubiquinone also contributes to the generation of a proton gradient, as two protons are taken up from the matrix as it is reduced to ubiquinol (QH2).
Succinate-Q oxidoreductase (complex II).
Succinate-Q oxidoreductase, also known as "complex II" or "succinate dehydrogenase", is a second entry point to the electron transport chain. It is unusual because it is the only enzyme that is part of both the citric acid cycle and the electron transport chain. Complex II consists of four protein subunits and contains a bound flavin adenine dinucleotide (FAD) cofactor, iron–sulfur clusters, and a heme group that does not participate in electron transfer to coenzyme Q, but is believed to be important in decreasing production of reactive oxygen species. It oxidizes succinate to fumarate and reduces ubiquinone. As this reaction releases less energy than the oxidation of NADH, complex II does not transport protons across the membrane and does not contribute to the proton gradient.
In some eukaryotes, such as the parasitic worm "Ascaris suum", an enzyme similar to complex II, fumarate reductase (menaquinol:fumarate
oxidoreductase, or QFR), operates in reverse to oxidize ubiquinol and reduce fumarate. This allows the worm to survive in the anaerobic environment of the large intestine, carrying out anaerobic oxidative phosphorylation with fumarate as the electron acceptor. Another unconventional function of complex II is seen in the malaria parasite "Plasmodium falciparum". Here, the reversed action of complex II as an oxidase is important in regenerating ubiquinol, which the parasite uses in an unusual form of pyrimidine biosynthesis.
Electron transfer flavoprotein-Q oxidoreductase.
Electron transfer flavoprotein-ubiquinone oxidoreductase (ETF-Q oxidoreductase), also known as "electron transferring-flavoprotein dehydrogenase", is a third entry point to the electron transport chain. It is an enzyme that accepts electrons from electron-transferring flavoprotein in the mitochondrial matrix, and uses these electrons to reduce ubiquinone. This enzyme contains a flavin and a [4Fe–4S] cluster, but, unlike the other respiratory complexes, it attaches to the surface of the membrane and does not cross the lipid bilayer.
In mammals, this metabolic pathway is important in beta oxidation of fatty acids and catabolism of amino acids and choline, as it accepts electrons from multiple acetyl-CoA dehydrogenases. In plants, ETF-Q oxidoreductase is also important in the metabolic responses that allow survival in extended periods of darkness.
Q-cytochrome c oxidoreductase (complex III).
Q-cytochrome c oxidoreductase is also known as "cytochrome c reductase", "cytochrome bc1 complex", or simply "complex III". In mammals, this enzyme is a dimer, with each subunit complex containing 11 protein subunits, an [2Fe-2S] iron–sulfur cluster and three cytochromes: one cytochrome c1 and two b cytochromes. A cytochrome is a kind of electron-transferring protein that contains at least one heme group. The iron atoms inside complex III’s heme groups alternate between a reduced ferrous (+2) and oxidized ferric (+3) state as the electrons are transferred through the protein.
The reaction catalyzed by complex III is the oxidation of one molecule of ubiquinol and the reduction of two molecules of cytochrome c, a heme protein loosely associated with the mitochondrion. Unlike coenzyme Q, which carries two electrons, cytochrome c carries only one electron.
As only one of the electrons can be transferred from the QH2 donor to a cytochrome c acceptor at a time, the reaction mechanism of complex III is more elaborate than those of the other respiratory complexes, and occurs in two steps called the Q cycle. In the first step, the enzyme binds three substrates, first, QH2, which is then oxidized, with one electron being passed to the second substrate, cytochrome c. The two protons released from QH2 pass into the intermembrane space. The third substrate is Q, which accepts the second electron from the QH2 and is reduced to Q.−, which is the ubisemiquinone free radical. The first two substrates are released, but this ubisemiquinone intermediate remains bound. In the second step, a second molecule of QH2 is bound and again passes its first electron to a cytochrome c acceptor. The second electron is passed to the bound ubisemiquinone, reducing it to QH2 as it gains two protons from the mitochondrial matrix. This QH2 is then released from the enzyme.
As coenzyme Q is reduced to ubiquinol on the inner side of the membrane and oxidized to ubiquinone on the other, a net transfer of protons across the membrane occurs, adding to the proton gradient. The rather complex two-step mechanism by which this occurs is important, as it increases the efficiency of proton transfer. If, instead of the Q cycle, one molecule of QH2 were used to directly reduce two molecules of cytochrome c, the efficiency would be halved, with only one proton transferred per cytochrome c reduced.
Cytochrome c oxidase (complex IV).
Cytochrome c oxidase, also known as "complex IV", is the final protein complex in the electron transport chain. The mammalian enzyme has an extremely complicated structure and contains 13 subunits, two heme groups, as well as multiple metal ion cofactors – in all, three atoms of copper, one of magnesium and one of zinc.
This enzyme mediates the final reaction in the electron transport chain and transfers electrons to oxygen, while pumping protons across the membrane. The final electron acceptor oxygen, which is also called the "terminal electron acceptor", is reduced to water in this step. Both the direct pumping of protons and the consumption of matrix protons in the reduction of oxygen contribute to the proton gradient. The reaction catalyzed is the oxidation of cytochrome c and the reduction of oxygen:
formula_5
Alternative reductases and oxidases.
Many eukaryotic organisms have electron transport chains that differ from the much-studied mammalian enzymes described above. For example, plants have alternative NADH oxidases, which oxidize NADH in the cytosol rather than in the mitochondrial matrix, and pass these electrons to the ubiquinone pool. These enzymes do not transport protons, and, therefore, reduce ubiquinone without altering the electrochemical gradient across the inner membrane.
Another example of a divergent electron transport chain is the "alternative oxidase", which is found in plants, as well as some fungi, protists, and possibly some animals. This enzyme transfers electrons directly from ubiquinol to oxygen.
The electron transport pathways produced by these alternative NADH and ubiquinone oxidases have lower ATP yields than the full pathway. The advantages produced by a shortened pathway are not entirely clear. However, the alternative oxidase is produced in response to stresses such as cold, reactive oxygen species, and infection by pathogens, as well as other factors that inhibit the full electron transport chain. Alternative pathways might, therefore, enhance an organisms' resistance to injury, by reducing oxidative stress.
Organization of complexes.
The original model for how the respiratory chain complexes are organized was that they diffuse freely and independently in the mitochondrial membrane. However, recent data suggest that the complexes might form higher-order structures called supercomplexes or "respirasomes." In this model, the various complexes exist as organized sets of interacting enzymes. These associations might allow channeling of substrates between the various enzyme complexes, increasing the rate and efficiency of electron transfer. Within such mammalian supercomplexes, some components would be present in higher amounts than others, with some data suggesting a ratio between complexes I/II/III/IV and the ATP synthase of approximately 1:1:3:7:4. However, the debate over this supercomplex hypothesis is not completely resolved, as some data do not appear to fit with this model.
Prokaryotic electron transport chains.
In contrast to the general similarity in structure and function of the electron transport chains in eukaryotes, bacteria and archaea possess a large variety of electron-transfer enzymes. These use an equally wide set of chemicals as substrates. In common with eukaryotes, prokaryotic electron transport uses the energy released from the oxidation of a substrate to pump ions across a membrane and generate an electrochemical gradient. In the bacteria, oxidative phosphorylation in "Escherichia coli" is understood in most detail, while archaeal systems are at present poorly understood.
The main difference between eukaryotic and prokaryotic oxidative phosphorylation is that bacteria and archaea use many different substances to donate or accept electrons. This allows prokaryotes to grow under a wide variety of environmental conditions. In "E. coli", for example, oxidative phosphorylation can be driven by a large number of pairs of reducing agents and oxidizing agents, which are listed below. The midpoint potential of a chemical measures how much energy is released when it is oxidized or reduced, with reducing agents having negative potentials and oxidizing agents positive potentials.
As shown above, "E. coli" can grow with reducing agents such as formate, hydrogen, or lactate as electron donors, and nitrate, DMSO, or oxygen as acceptors. The larger the difference in midpoint potential between an oxidizing and reducing agent, the more energy is released when they react. Out of these compounds, the succinate/fumarate pair is unusual, as its midpoint potential is close to zero. Succinate can therefore be oxidized to fumarate if a strong oxidizing agent such as oxygen is available, or fumarate can be reduced to succinate using a strong reducing agent such as formate. These alternative reactions are catalyzed by succinate dehydrogenase and fumarate reductase, respectively.
Some prokaryotes use redox pairs that have only a small difference in midpoint potential. For example, nitrifying bacteria such as "Nitrobacter" oxidize nitrite to nitrate, donating the electrons to oxygen. The small amount of energy released in this reaction is enough to pump protons and generate ATP, but not enough to produce NADH or NADPH directly for use in anabolism. This problem is solved by using a nitrite oxidoreductase to produce enough proton-motive force to run part of the electron transport chain in reverse, causing complex I to generate NADH.
Prokaryotes control their use of these electron donors and acceptors by varying which enzymes are produced, in response to environmental conditions. This flexibility is possible because different oxidases and reductases use the same ubiquinone pool. This allows many combinations of enzymes to function together, linked by the common ubiquinol intermediate. These respiratory chains therefore have a modular design, with easily interchangeable sets of enzyme systems.
In addition to this metabolic diversity, prokaryotes also possess a range of isozymes – different enzymes that catalyze the same reaction. For example, in "E. coli", there are two different types of ubiquinol oxidase using oxygen as an electron acceptor. Under highly aerobic conditions, the cell uses an oxidase with a low affinity for oxygen that can transport two protons per electron. However, if levels of oxygen fall, they switch to an oxidase that transfers only one proton per electron, but has a high affinity for oxygen.
ATP synthase (complex V).
ATP synthase, also called "complex V", is the final enzyme in the oxidative phosphorylation pathway. This enzyme is found in all forms of life and functions in the same way in both prokaryotes and eukaryotes. The enzyme uses the energy stored in a proton gradient across a membrane to drive the synthesis of ATP from ADP and phosphate (Pi). Estimates of the number of protons required to synthesize one ATP have ranged from three to four, with some suggesting cells can vary this ratio, to suit different conditions.
This phosphorylation reaction is an equilibrium, which can be shifted by altering the proton-motive force. In the absence of a proton-motive force, the ATP synthase reaction will run from right to left, hydrolyzing ATP and pumping protons out of the matrix across the membrane. However, when the proton-motive force is high, the reaction is forced to run in the opposite direction; it proceeds from left to right, allowing protons to flow down their concentration gradient and turning ADP into ATP. Indeed, in the closely related vacuolar type H+-ATPases, the hydrolysis reaction is used to acidify cellular compartments, by pumping protons and hydrolysing ATP.
ATP synthase is a massive protein complex with a mushroom-like shape. The mammalian enzyme complex contains 16 subunits and has a mass of approximately 600 kilodaltons. The portion embedded within the membrane is called FO and contains a ring of c subunits and the proton channel. The stalk and the ball-shaped headpiece is called F1 and is the site of ATP synthesis. The ball-shaped complex at the end of the F1 portion contains six proteins of two different kinds (three α subunits and three β subunits), whereas the "stalk" consists of one protein: the γ subunit, with the tip of the stalk extending into the ball of α and β subunits. Both the α and β subunits bind nucleotides, but only the β subunits catalyze the ATP synthesis reaction. Reaching along the side of the F1 portion and back into the membrane is a long rod-like subunit that anchors the α and β subunits into the base of the enzyme.
As protons cross the membrane through the channel in the base of ATP synthase, the FO proton-driven motor rotates. Rotation might be caused by changes in the ionization of amino acids in the ring of c subunits causing electrostatic interactions that propel the ring of c subunits past the proton channel. This rotating ring in turn drives the rotation of the central axle (the γ subunit stalk) within the α and β subunits. The α and β subunits are prevented from rotating themselves by the side-arm, which acts as a stator. This movement of the tip of the γ subunit within the ball of α and β subunits provides the energy for the active sites in the β subunits to undergo a cycle of movements that produces and then releases ATP.
This ATP synthesis reaction is called the "binding change mechanism" and involves the active site of a β subunit cycling between three states. In the "open" state, ADP and phosphate enter the active site (shown in brown in the diagram). The protein then closes up around the molecules and binds them loosely – the "loose" state (shown in red). The enzyme then changes shape again and forces these molecules together, with the active site in the resulting "tight" state (shown in pink) binding the newly produced ATP molecule with very high affinity. Finally, the active site cycles back to the open state, releasing ATP and binding more ADP and phosphate, ready for the next cycle.
In some bacteria and archaea, ATP synthesis is driven by the movement of sodium ions through the cell membrane, rather than the movement of protons. Archaea such as "Methanococcus" also contain the A1Ao synthase, a form of the enzyme that contains additional proteins with little similarity in sequence to other bacterial and eukaryotic ATP synthase subunits. It is possible that, in some species, the A1Ao form of the enzyme is a specialized sodium-driven ATP synthase, but this might not be true in all cases.
Reactive oxygen species.
Molecular oxygen is an ideal terminal electron acceptor because it is a strong oxidizing agent. The reduction of oxygen does involve potentially harmful intermediates. Although the transfer of four electrons and four protons reduces oxygen to water, which is harmless, transfer of one or two electrons produces superoxide or peroxide anions, which are dangerously reactive.
These reactive oxygen species and their reaction products, such as the hydroxyl radical, are very harmful to cells, as they oxidize proteins and cause mutations in DNA. This cellular damage might contribute to disease and is proposed as one cause of aging.
The cytochrome c oxidase complex is highly efficient at reducing oxygen to water, and it releases very few partly reduced intermediates; however small amounts of superoxide anion and peroxide are produced by the electron transport chain. Particularly important is the reduction of coenzyme Q in complex III, as a highly reactive ubisemiquinone free radical is formed as an intermediate in the Q cycle. This unstable species can lead to electron "leakage" when electrons transfer directly to oxygen, forming superoxide. As the production of reactive oxygen species by these proton-pumping complexes is greatest at high membrane potentials, it has been proposed that mitochondria regulate their activity to maintain the membrane potential within a narrow range that balances ATP production against oxidant generation. For instance, oxidants can activate uncoupling proteins that reduce membrane potential.
To counteract these reactive oxygen species, cells contain numerous antioxidant systems, including antioxidant vitamins such as vitamin C and vitamin E, and antioxidant enzymes such as superoxide dismutase, catalase, and peroxidases, which detoxify the reactive species, limiting damage to the cell.
Inhibitors.
There are several well-known drugs and toxins that inhibit oxidative phosphorylation. Although any one of these toxins inhibits only one enzyme in the electron transport chain, inhibition of any step in this process will halt the rest of the process. For example, if oligomycin inhibits ATP synthase, protons cannot pass back into the mitochondrion. As a result, the proton pumps are unable to operate, as the gradient becomes too strong for them to overcome. NADH is then no longer oxidized and the citric acid cycle ceases to operate because the concentration of NAD+ falls below the concentration that these enzymes can use.
Not all inhibitors of oxidative phosphorylation are toxins. In brown adipose tissue, regulated proton channels called uncoupling proteins can uncouple respiration from ATP synthesis. This rapid respiration produces heat, and is particularly important as a way of maintaining body temperature for hibernating animals, although these proteins may also have a more general function in cells' responses to stress.
History.
The field of oxidative phosphorylation began with the report in 1906 by Arthur Harden of a vital role for phosphate in cellular fermentation, but initially only sugar phosphates were known to be involved. However, in the early 1940s, the link between the oxidation of sugars and the generation of ATP was firmly established by Herman Kalckar, confirming the central role of ATP in energy transfer that had been proposed by Fritz Albert Lipmann in 1941. Later, in 1949, Morris Friedkin and Albert L. Lehninger proved that the coenzyme NADH linked metabolic pathways such as the citric acid cycle and the synthesis of ATP. The term "oxidative phosphorylation" was coined by Volodymyr Belitser in 1939.
For another twenty years, the mechanism by which ATP is generated remained mysterious, with scientists searching for an elusive "high-energy intermediate" that would link oxidation and phosphorylation reactions. This puzzle was solved by Peter D. Mitchell with the publication of the chemiosmotic theory in 1961. At first, this proposal was highly controversial, but it was slowly accepted and Mitchell was awarded a Nobel prize in 1978. Subsequent research concentrated on purifying and characterizing the enzymes involved, with major contributions being made by David E. Green on the complexes of the electron-transport chain, as well as Efraim Racker on the ATP synthase. A critical step towards solving the mechanism of the ATP synthase was provided by Paul D. Boyer, by his development in 1973 of the "binding change" mechanism, followed by his radical proposal of rotational catalysis in 1982. More recent work has included structural studies on the enzymes involved in oxidative phosphorylation by John E. Walker, with Walker and Boyer being awarded a Nobel Prize in 1997.

</doc>
<doc id="22775" url="http://en.wikipedia.org/wiki?curid=22775" title="Old Fashioned">
Old Fashioned

The Old Fashioned is a cocktail made by muddling sugar with bitters then adding alcohol, such as whiskey or brandy, and a twist of citrus rind. It is traditionally served in a short, round, 8 - tumbler-like glass, which is called an "Old Fashioned glass", named after the drink.
The Old Fashioned, developed during the 19th century and given its name in the 1880s, is an IBA Official Cocktail. It is also one of six basic drinks listed in David A. Embury's "The Fine Art of Mixing Drinks".
History.
The first documented definition of the word "cocktail" was in response to a reader's letter asking to define the word in the May 6, 1806, issue of "The Balance and Columbian Repository" in Hudson, New York. In the May 13, 1806, issue, the paper's editor wrote that it was a potent concoction of spirits, bitters, water, and sugar; it was also referred to at the time as a bittered sling.
J.E. Alexander describes the cocktail similarly in 1833, as he encountered it in New York City, as being rum, gin, or brandy, significant water, bitters, and sugar, though he includes a nutmeg garnish as well.
By the 1860s, it was common for orange curaçao, absinthe, and other liqueurs to be added to the cocktail. The original concoction, albeit in different proportions, came back into vogue, and was referred to as "old-fashioned". The most popular of the in-vogue "old-fashioned" cocktails were made with whiskey, according to a Chicago barman, quoted in The Chicago Daily Tribune in 1882, with rye being more popular than Bourbon. The recipe he describes is a similar combination of spirits, bitters, water and sugar of seventy-six years earlier.
Traditionally, the first use of the name "Old Fashioned" for a Bourbon whiskey cocktail was said to have been, anachronistically, at the Pendennis Club, a gentlemen's club founded in 1881 in Louisville, Kentucky. The recipe was said to have been invented by a bartender at that club in honor of Colonel James E. Pepper, a prominent bourbon distiller, who brought it to the Waldorf-Astoria Hotel bar in New York City.
Recipe.
George Kappeler provides some of the earliest published recipes for Old Fashioned cocktails in his 1895 book. Recipes are given for Whiskey, Brandy, Holland gin, and Old Tom gin. The Whiskey Old Fashioned recipe specifies the following (with a jigger being 2 USfloz):
By the 1860s, as illustrated by Jerry Thomas' 1862 book, basic cocktail recipes included Curaçao, or other liqueurs, not mentioned in the early 19th century descriptions, nor the Chicago Daily Tribune descriptions of the "Old Fashioned" cocktails of the early 1880s; it is absent from Kappeler's Old Fashioned recipes, as well. The differences of the Old Fashioned cocktail recipes from the cocktail recipes of the late 19th Century are mainly preparation method, the use of sugar and water in lieu of simple or gomme syrup, and the absence of additional liqueurs. These Old Fashioned cocktail recipes are literally for cocktails done the old-fashioned way.
A book by David Embury published in 1948 provides a slight variation, specifying 12 parts American whiskey, 1 part simple syrup, 1-3 dashes Angostura bitters, a twist of lemon peel over the top, and serve garnished with the lemon peel.
Two additional recipes from the 1900s vary in the precise ingredients, but omit the cherry which was introduced after 1930 as well as the soda water which the occasional recipe calls for. Orange bitters were a popular ingredient in the late 19th century,
Modifications.
The original Old Fashioned recipe would have showcased the whiskey available in America in the 19th century, either Irish, Bourbon or rye whiskey. But in some regions, especially Wisconsin, brandy is substituted for whiskey (sometimes called a Brandy Old Fashioned). Eventually the use of other spirits became common, such as a gin recipe becoming popularized in the late 1940s. Another common modification is to add soda water.
Common garnishes for an Old Fashioned include an orange slice or a maraschino cherry, although these modifications came around 1930, some time after the original recipe was invented. While some recipes began making sparse use of the orange zest for flavor, the practice of muddling orange and other fruit gained prevalence as late as the 1990s.
In popular culture.
In John Updike's novel "Rabbit, Run", the title character resents the job he works at to "earn a living to buy sugar for [his wife Janice] to put into her rotten old Old-Fashioneds".
The drunkard played by Jim Backus in Stanley Kramer's film "It's a Mad, Mad, Mad, Mad World" steps away from the controls of the airplane he is flying to mix himself an Old Fashioned.
The Old Fashioned is the cocktail of choice of Don Draper, the lead character on the "Mad Men" television series, set in the 1960s. The drink was well known in the 1960s, but was nearly forgotten at the time of the series' premiere in 2007. The use of the drink in the series coincides with a renewed interest in this and other classic cocktails in the 2000s.
In the film "Crazy, Stupid, Love" Jacob Palmer portrayed by Ryan Gosling enjoys this drink as his beverage of choice.

</doc>
<doc id="22776" url="http://en.wikipedia.org/wiki?curid=22776" title="Omnipotence">
Omnipotence

Omnipotence is the quality of having unlimited power. Monotheistic religions generally attribute omnipotence to only the deity of their faith. In the monotheistic philosophies of Abrahamic religions, omnipotence is often listed as one of a deity's characteristics among many, including omniscience, omnipresence, and omnibenevolence. The presence of all these properties in a single entity has given rise to considerable theological debate, prominently including the problem of theodicy, the question of why such a deity would permit the manifestation of evil.
Meanings.
The term omnipotent has been used to connote a number of different positions. These positions include, but are not limited to, the following:
Under many philosophical definitions of the term "deity", senses 2, 3 and 4 can be shown to be equivalent. However, on all understandings of omnipotence, it is generally held that a deity is able to intervene in the world by superseding the laws of physics, since they are not part of its nature, but the principles on which it has created the physical world. However many modern scholars (such as John Polkinghorne) hold that it is part of a deity's nature to be consistent and that it would be inconsistent for a deity to go against its own laws unless there were an overwhelming reason to do so.
The word "Omnipotence" derives from the Latin term "Omni Potens", meaning "All-Powerful" instead of "Infinite Power" implied by its English counterpart. The term could be applied to both deities and Roman Emperors. Being the one with "All the power", it was not uncommon for nobles to attempt to prove their Emperor's "Omni Potens" to the people, by demonstrating his effectiveness at leading the Empire.
Scholastic definition.
St. Thomas Aquinas, OP acknowledged difficulty in comprehending the Deity's power: "All confess that God is omnipotent; but it seems difficult to explain in what His omnipotence precisely consists: for there may be doubt as to the precise meaning of the word 'all' when we say that God can do all things. If, however, we consider the matter aright, since power is said in reference to possible things, this phrase, 'God can do all things,' is rightly understood to mean that God can do all things that are possible; and for this reason He is said to be omnipotent." In the scholastic understanding, omnipotence is generally understood to be compatible with certain limitations or restrictions. A proposition that is necessarily true is one whose negation is self-contradictory.
St. Thomas explains that:
Omnipotence is all-sufficient power. The adaptation of means to ends in the universe does not argue, as J. S. Mill would have it, that the power of the designer is limited, but only that God has willed to manifest His glory by a world so constituted rather than by another. Indeed the production of secondary causes, capable of accomplishing certain effects, requires greater power than the direct accomplishment of these same effects. On the other hand even though no creature existed, God's power would not be barren, for "creatures are not an end to God." Regarding the Deity's power, medieval theologians contended that there are certain things that even an omnipotent deity cannot do. The statement "a deity can do anything" is only sensible with an assumed suppressed clause, "that implies the perfection of true power". This standard scholastic answer allows that acts of creatures such as walking can be performed by humans but not by a deity. Rather than an advantage in power, human acts such as walking, sitting, or giving birth were possible only because of a "defect" in human power. The capacity to sin, for example, is not a power but a defect or infirmity. In response to questions of a deity performing impossibilities, e.g. making square circles, St. Thomas says that "everything that does not imply a contradiction in terms, is numbered amongst those possible things, in respect of which God is called omnipotent: whereas whatever implies contradiction does not come within the scope of divine omnipotence, because it cannot have the aspect of possibility. Hence it is better to say that such things cannot be done, than that God cannot do them. Nor is this contrary to the word of the angel, saying: 'No word shall be impossible with God.' For whatever implies a contradiction cannot be a word, because no intellect can possibly conceive such a thing."
In recent times, C. S. Lewis has adopted a scholastic position in the course of his work The Problem of Pain. Lewis follows Aquinas' view on contradiction:
 His Omnipotence means power to do all that is intrinsically possible, not to do the intrinsically impossible. You may attribute miracles to him, but not nonsense. This is no limit to his power. If you choose to say 'God can give a creature free will and at the same time withhold free will from it,' you have not succeeded in saying "anything" about God: meaningless combinations of words do not suddenly acquire meaning simply because we prefix to them the two other words 'God can.'... It is no more possible for God than for the weakest of his creatures to carry out both of two mutually exclusive alternatives; not because his power meets an obstacle, but because nonsense remains nonsense even when we talk it about God.
 — Lewis, 18
In psychology.
Early Freudianism saw a feeling of omnipotence as intrinsic to early childhood. 'As Freud and Ferenczi have shown, the child lives in a sort of megalomania for a long period...the "fiction of omnipotence"'. At birth. 'the baby "is" everything "as far as he knows" - "all powerful"...every step he takes towards establishing his own limits and boundaries will be painful because he'll have to lose this original God-like feeling of omnipotence'.
Freud considered that in a neurotic 'the "omnipotence" which he ascribed to his thoughts and feelings...is a frank acknowledgement of a relic of the old megalomania of infancy'. In some narcissists, the 'period of primary narcissism which subjectively did not need any objects and was entirely independent...may be retained or regressively regained..."omnipotent" behavior'.
D. W. Winnicott took a more positive view of a belief in early omnipotence, seeing it as essential to the child's well-being; and "good-enough" mothering as essential to enable the child to 'cope with the immense shock of loss of omnipotence' - as opposed to whatever 'prematurely forces it out of its narcissistic universe'.
Rejection or limitation.
Some monotheists reject the view that a deity is or could be omnipotent, or take the view that, by choosing to create creatures with freewill, a deity has chosen to limit divine omnipotence. In Conservative and Reform Judaism, and some movements within Protestant Christianity, including open theism, deities are said to act in the world through persuasion, and not by coercion (this is a matter of choice—a deity could act miraculously, and perhaps on occasion does so—while for process theism it is a matter of necessity—creatures have inherent powers that a deity cannot, even in principle, override). Deities are manifested in the world through inspiration and the creation of possibility, not necessarily by miracles or violations of the laws of nature.
The rejection of omnipotence often follows from either philosophical or scriptural considerations, discussed below.
Philosophical grounds.
Process theology rejects unlimited omnipotence on a philosophical basis, arguing that omnipotence as classically understood would be less than perfect, and is therefore incompatible with the idea of a perfect deity. The idea is grounded in Plato's oft-overlooked statement that "being is power."
 My notion would be, that anything which possesses any sort of power to affect another, or to be affected by another, if only for a single moment, however trifling the cause and however slight the
effect, has real existence; and I hold that the definition of being is simply power.
 — Plato, 247E
From this premise, Charles Hartshorne argues further that:
 Power is influence, and perfect power is perfect influence ... power must be exercised upon something, at least if by power we mean influence, control; but the something controlled cannot be absolutely inert, since the merely passive, that which has no active tendency of its own, is nothing; yet if the something acted upon is itself partly active, then there must be some resistance, however slight, to the "absolute" power, and how can power which is resisted be absolute?
 — Hartshorne, 89
The argument can be stated as follows:
For example, though someone might control a lump of jelly-pudding almost completely, the inability of that pudding to stage any resistance renders that person's power rather unimpressive. Power can only be said to be great if it is over something that has defenses and its own agenda. If a deity's power is to be great, it must therefore be over beings that have at least some of their own defenses and agenda. Thus, if a deity does not have absolute power, it must therefore embody some of the characteristics of power, and some of the characteristics of persuasion. This view is known as dipolar theism.
The most popular works espousing this point are from Harold Kushner (in Judaism). The need for a modified view of omnipotence was also articulated by Alfred North Whitehead in the early 20th century and expanded upon by the aforementioned philosopher Charles Hartshorne. Hartshorne proceeded within the context of the theological system known as process theology.
Scriptural grounds.
In the Authorized King James Version of the Bible, as well as several other versions, in Revelation 19:6 it is stated "...the Lord God omnipotent reigneth" (the original Greek word is παντοκράτωρ, "all-mighty"). Although much of the narrative of the Old Testament describes the Judeo-Christian God as interacting with creation primarily through persuasion, and only occasionally through force. However, it could further be argued that the ability to conflict with truth is not an appropriate representation of accepted definitions of power, which negates the assertion that a deity does not have infinite powers.
Many other verses in the Christian Bible do assert omnipotence of its deity without actually using the word itself. There are several mentions of the Christian deity being referred to as simply "Almighty", showing that the Christian Bible supports the belief of an omnipotent deity. Some such verses are listed below:
Psalms 33:8-9: Let all the earth fear the LORD: let all the inhabitants of the world stand in awe of him. For he spoke, and it was done; he commanded, and it stood fast.
Genesis 17:1: And when Abram was ninety years old and nine, the LORD appeared to Abram, and said unto him, I am the Almighty God; walk before me, and be thou perfect. (The Hebrew word used here is "shadday")
Jeremiah 32:27: Behold, I am the LORD, the God of all flesh: is there any thing too hard for me?
At his command a storm arose and covered the sea. (Psalm 107:25)
Several parts of the New Testament claim Jesus to be one with the Father, who is omnipotent, and others show Jesus to have some separation from the Father and even self-imposed limitations on his power. (Gospel of John)
Paradoxes.
A classical example goes as follows:
Augustine, in his City of God, argued, instead, that God could not do anything that would make God non-omnipotent:
For He is called omnipotent on account of His doing what He wills, not on account of His suffering what He wills not; for if that should befall Him, He would by no means be omnipotent. Wherefore, He cannot do some things for the very reason that He is omnipotent.
Uncertainty and other views.
All the above stated claims of power are each based on scriptual grounds and upon empirical human perception. This perception is limited to our senses. The power of a deity is related to its existence.There are however other ways of perception like: reason, intuition, revelation, divine inspiration, religious experience, mystical states, and historical testimony.
According to the Hindu philosophy the essence of God or Brahman can never be understood or known since Brahman is beyond both existence and non-existence, transcending and including time, causation and space, and thus can never be known in the same material sense as one traditionally 'understands' a given concept or object.
So presuming there is a god-like entity consciently taking actions, we cannot comprehend the limits of a deity's powers.
Since the current laws of physics are only known to be valid in this universe, it is possible that the laws of physics are different in parallel universes, giving a God-like entity more power. If the number of universes is unlimited, then the power of a certain God-like entity is also unlimited, since the laws of physics may be different in other universes, and accordingly making this entity omnipotent. Unfortunately concerning a multiverse there is a lack of empirical correlation. To the extreme there are theories about realms beyond this multiverse (Nirvana, Chaos, Nothingness).
Also trying to develop a theory to explain, assign or reject omnipotence on grounds of logic has little merit, since being omnipotent, in a Cartesian sense, would mean the omnipotent being is above logic. A view supported by René Descartes He issues this idea in his Meditations on First Philosophy. This view is called universal possibilism.
Allowing assumption that a deity exists, further debate may be provoked that said deity is consciously taking actions. It could be concluded from an emanationism point of view, that all actions and creations by a deity are simply flows of divine energy (the flowing Tao in conjunction with qi is often seen as a river; Dharma (Buddhism) the law of nature discovered by Buddha has no beginning or end.)
Pantheism and pandeism see the universe/multiverse itself as God (or, at least, the current state of God), while panentheism sees the universe/multiverse as 'the body of God', making 'God' everybody and everything. So if one does something, actually 'God' is doing it. We are 'God's' means according to this view.
In the Taoist religious or philosophical tradition, the Tao is in some ways equivalent to a deity or the logos. The Tao is understood to have inexhaustible power, yet that power is simply another aspect of its weakness.

</doc>
<doc id="22780" url="http://en.wikipedia.org/wiki?curid=22780" title="Octopus">
Octopus

An octopus ( or ; plural: octopuses, octopi, or octopodes; see below) is a cephalopod mollusc of the order Octopoda. It has two eyes and four pairs of arms and, like other cephalopods, it is bilaterally symmetric. An octopus has a hard beak, with its mouth at the center point of the arms. An octopus has no internal or external skeleton (although some species have a vestigial remnant of a shell inside their mantles), allowing it to squeeze through tight places. Octopuses are among the most intelligent and behaviorally flexible of all invertebrates.
Octopuses inhabit many diverse regions of the ocean, including coral reefs, pelagic waters, and the ocean floor. They have numerous strategies for defending themselves against predators, including the expulsion of ink, the use of camouflage and deimatic displays, their ability to jet quickly through the water, and their ability to hide. An octopus trails its eight arms behind it as it swims. All octopuses are venomous, but only one group, the blue-ringed octopus, is known to be deadly to humans.
Around 300 species are recognized, which is over one-third of the total number of known cephalopod species. The term 'octopus' may also be used to refer specifically to the genus "Octopus".
Biology.
Octopuses are characterized by their eight arms, usually bearing suction cups. The arms of octopuses are often distinguished from the pair of feeding tentacles found in squid and cuttlefish. Both types of limb are muscular hydrostats. Unlike most other cephalopods, the majority of octopuses – those in the suborder most commonly known, Incirrina – have almost entirely soft bodies with no internal skeleton. They have neither a protective outer shell like the nautilus, nor any vestige of an internal shell or bones, like cuttlefish or squid. The beak, similar in shape to a parrot's beak, and made of chitin, is the only hard part of their bodies. This enables them to squeeze through very narrow slits between underwater rocks, which is very helpful when they are fleeing from moray eels or other predatory fish. The octopuses in the less-familiar Cirrina suborder have two fins and an internal shell, generally reducing their ability to squeeze into small spaces. These cirrate species are often free-swimming and live in deep-water habitats, while incirrate octopus species are found in reefs and other shallower seafloor habitats.
Octopuses have a relatively short life expectancy, with some species living for as little as six months. Larger species, such as the giant pacific octopus, may live for up to five years under suitable circumstances. However, reproduction is a cause of death: males can live for only a few months after mating, and females die shortly after their eggs hatch. They neglect to eat during the (roughly) one-month period spent taking care of their unhatched eggs, eventually dying of starvation. In a scientific experiment, the removal of both optic glands after spawning was found to result in the cessation of broodiness, the resumption of feeding, increased growth, and greatly extended lifespans.
Octopuses have three hearts. Two branchial hearts pump blood through each of the two gills, while the third is a systemic heart that pumps blood through the body. Octopus blood contains the copper-rich protein hemocyanin for transporting oxygen. Although less efficient under normal conditions than the iron-rich hemoglobin of vertebrates, in cold conditions with low oxygen pressure, hemocyanin oxygen transportation is more efficient than hemoglobin oxygen transportation. The hemocyanin is dissolved in the plasma instead of being carried within red blood cells, and gives the blood a bluish color. The octopus draws water into its mantle cavity, where it passes through its gills. As molluscs, their gills are finely divided and vascularized outgrowths of either the outer or the inner body surface.
Intelligence.
Octopuses are highly intelligent, possibly more so than any other order of invertebrates. The exact extent of their intelligence and learning capability is much debated among biologists, but maze and problem-solving experiments have shown evidence of a memory system that can store both short- and long-term memory. It is not known precisely what contribution learning makes to adult octopus behavior. Young octopuses learn almost no behaviors from their parents, with whom they have very little contact.
An octopus has a highly complex nervous system, only part of which is localized in its brain. Two-thirds of an octopus's neurons are found in the nerve cords of its arms, which have limited functional autonomy. Octopus arms show a variety of complex reflex actions that persist even when they have no input from the brain. Unlike vertebrates, the complex motor skills of octopuses are not organized in their brain using an internal somatotopic map of its body, instead using a nonsomatotopic system unique to large-brained invertebrates. Despite this delegation of control, octopus arms do not become tangled or stuck to each other because the suction cups have chemical sensors that recognize octopus skin and prevent self-attachment. Some octopuses, such as the mimic octopus, will move their arms in ways that emulate the shape and movements of other sea creatures.
In laboratory experiments, octopuses can be readily trained to distinguish between different shapes and patterns. They have been reported to practice observational learning, although the validity of these findings is widely contested on a number of grounds. Octopuses have also been observed in what some have described as play: repeatedly releasing bottles or toys into a circular current in their aquariums and then catching them. Octopuses often break out of their aquariums and sometimes into others in search of food. They have even boarded fishing boats and opened holds to eat crabs.
Tool use.
The octopus has been shown to use tools. At least four specimens of the veined octopus ("Amphioctopus marginatus") have been witnessed retrieving discarded coconut shells, manipulating them, and then reassembling them to use as shelter.
Protective legislation.
Due to their intelligence, octopuses in some countries are on the list of experimental animals on which surgery may not be performed without anesthesia, a protection usually extended only to vertebrates. In the UK from 1993 to 2012, the common octopus ("Octopus vulgaris") was the only invertebrate protected under the Animals (Scientific Procedures) Act 1986. In 2012, this legislation was extended to include all cephalopods in accordance with a general EU directive.
Defense.
An octopus's primary defense is to hide or to disguise itself through camouflage and mimicry. Octopuses have several secondary defenses (defenses they use once they have been seen by a predator). The most common secondary defense is fast escape. Other defenses include distraction with the use of ink sacs and autotomising limbs.
Most octopuses can eject a thick, blackish ink in a large cloud to aid in escaping from predators. The main coloring agent of the ink is melanin, which is the same chemical that gives humans their hair and skin color. This ink cloud is thought to reduce the efficiency of olfactory organs, which would aid an octopus's evasion from predators that employ smell for hunting, such as sharks. Ink clouds of some species might serve as pseudomorphs, or decoys that the predator attacks instead.
An octopus's camouflage is aided by certain specialized skin cells which can change the apparent color, opacity, and reflectivity of the epidermis. Chromatophores contain yellow, orange, red, brown, or black pigments; most species have three of these colors, while some have two or four. Other color-changing cells are reflective iridophores, and leucophores (white). This color-changing ability can also be used to communicate with or warn other octopuses. The highly venomous blue-ringed octopus becomes bright yellow with blue rings when it is provoked. Octopuses can use muscles in the skin to change the texture of their mantle to achieve a greater camouflage. In some species, the mantle can take on the spiky appearance of seaweed, or the scraggly, bumpy texture of a rock, among other disguises. However, in some species, skin anatomy is limited to relatively patternless shades of one color, and limited skin texture. It is thought that octopuses that are day-active and/or live in complex habitats such as coral reefs have evolved more complex skin than their nocturnal and/or sand-dwelling relatives.
When under attack, some octopuses can perform arm autotomy, in a manner similar to the way skinks and other lizards detach their tails. The crawling arm serves as a distraction to would-be predators. Such severed arms remain sensitive to stimuli and move away from unpleasant sensations.
A few species, such as the mimic octopus, have a fourth defense mechanism. They can combine their highly flexible bodies with their color-changing ability to accurately mimic other, more dangerous animals, such as lionfish, sea snakes, and eels.
Reproduction.
When octopuses reproduce, the male uses a specialized arm called a hectocotylus to transfer spermatophores (packets of sperm) from the terminal organ of the reproductive tract (the cephalopod "penis") into the female's mantle cavity. The hectocotylus in benthic octopuses is usually the third right arm. Males die within a few months of mating. In some species, the female octopus can keep the sperm alive inside her for weeks until her eggs are mature. After they have been fertilized, the female lays about 200,000 eggs (this figure dramatically varies between families, genera, species and also individuals).
Senses.
Octopuses have keen eyesight. Like other cephalopods, they can distinguish the polarization of light. Color vision appears to vary from species to species, being present in "O. aegina" but absent in "O. vulgaris". Attached to the brain are two special organs, called statocysts, that allow the octopus to sense the orientation of its body relative to horizontal. An autonomic response keeps the octopus's eyes oriented so the pupil slit is always horizontal.
Octopuses also have an excellent sense of touch. An octopus's suction cups are equipped with chemoreceptors so the octopus can taste what it is touching. The arms contain tension sensors so the octopus knows whether its arms are stretched out. However, it has a very poor proprioceptive sense. The tension receptors are not sufficient for the brain to determine the position of the octopus's body or arms. (It is not clear whether the octopus brain would be capable of processing the large amount of information that this would require; the flexibility of an octopus's arms is much greater than that of the limbs of vertebrates, which devote large areas of cerebral cortex to the processing of proprioceptive inputs.) As a result, the octopus does not possess stereognosis; that is, it does not form a mental image of the overall shape of the object it is handling. It can detect local texture variations, but cannot integrate the information into a larger picture.
The neurological autonomy of the arms means the octopus has great difficulty learning about the detailed effects of its motions. The brain may issue a high-level command to the arms, but the nerve cords in the arms execute the details. There is no neurological path for the brain to receive proprioceptive feedback about just how its command was executed by the arms; the only way it knows just what motions were made is by observing the arms visually, i.e. exteroception.
Octopuses might use the statocyst (a sac-like structure containing a mineralised mass and sensitive hairs) to register sound. The common octopus can hear sounds between 400 Hz and 1000 Hz, and hears best at a frequency of 600 Hz.
Locomotion.
Octopuses move about by crawling or swimming. Their main means of slow travel is crawling, with some swimming. Jet propulsion is their fastest means of locomotion, followed by swimming and walking.
They crawl by walking on their arms, usually on many at once, on both solid and soft surfaces, while supported in water. In 2005, some octopuses ("Adopus aculeatus" and "Amphioctopus marginatus" under current taxonomy) were found to walk on two arms, while at the same time resembling plant matter. This form of locomotion allows these octopuses to move quickly away from a potential predator while possibly not triggering that predator's search image for octopus (food). A study of this behavior conducted by the Weymouth Sea Life Centre led to the suggestion that the two rearmost appendages may be more accurately termed 'legs' rather than 'arms'. Some species of octopus can crawl out of the water for a short period, which they may do between tide pools while hunting crustaceans or gastropods or to escape predators.
Octopuses swim by expelling a jet of water from a contractile mantle, and aiming it via a muscular siphon.
Diet.
Bottom-dwelling octopuses eat mainly crabs, polychaete worms, and other molluscs such as whelks and clams. Open-ocean octopuses eat mainly prawns, fish and other cephalopods. They usually inject their prey with a paralysing saliva before dismembering it into small pieces with their beaks. Octopuses feed on shelled molluscs either by using force, or by drilling a hole in the shell, injecting a secretion into the hole, and then extracting the soft body of the mollusc.
Large octopuses have also been known to catch and kill some species of sharks. Seabirds have also been documented as prey.
Size.
The giant Pacific octopus, "Enteroctopus dofleini", is often cited as the largest known octopus species. Adults usually weigh around 15 kg (33 lb), with an arm span of up to 4.3 m (14 ft). The largest specimen of this species to be scientifically documented was an animal with a live mass of 71 kg (156.5 lb). The alternative contender is the seven-arm octopus, "Haliphron atlanticus", based on a 61 kg (134 lb) carcass estimated to have a live mass of 75 kg (165 lb). However, a number of questionable size records would suggest "E. dofleini" is the largest of all known octopus species by a considerable margin; one such record is of a specimen weighing 272 kg (600 lb) and having an arm span of 9 m (30 ft).
Etymology and pluralization.
The term "octopus" is derived, through scientific Latin, from ancient Greek ὀκτώπους ("eight-footed") < ὀκτώ ("eight") and πούς ("foot"). (Ancient Greek also had the form ὀκτάπους, which would give "octapus" in English; cf. Modern Greek χταπόδι < οκταπόδι < οκταπόδιον < ὀκτάπους.)
The usual plural in English is "octopuses" (pronounced /ˈɒktəpʊsɪz/), but the Greek plural form "octopodes" (pronounced /ɒkˈtɒpədiːz/) is sometimes used, though less frequently than in the past. The form "octopi", as if the word were a Latin second-declension noun, is generally considered incorrect, but is in fact used, so that it is registered by the descriptivist "Merriam-Webster 11th Collegiate Dictionary", which lists "octopuses" and "octopi", in that order, and "Webster's New World College Dictionary", which lists plurals in the order: "octopuses", "octopi", and "octopodes". The "Oxford English Dictionary" (2008 Draft Revision) also lists "octopuses", "octopi", and "octopodes", in that order, labelling "octopodes" as rare and noting that "octopi" derives from the misapprehension that "octōpus" is a second-declension Latin noun and stating that, if the word were native to Latin, it would be third declension "octōpēs" (plural: "octōpedes") after the pattern of "pēs" ("foot", plural "pedēs"). The "New Oxford American Dictionary" (3rd Edition 2010) lists only "octopuses" as being the acceptable pluralization, with a usage note indicating "octopodes" as being "still occasionally used", and "octopi" as being "incorrect".
Related to the word "octopus" are the term "Octopoda" (the taxonomic order of cephalopod molluscs that comprises the octopuses) and the adjective "octopoid".
Relationship to humans.
Ancient peoples of the Mediterranean were aware of the octopus, as evidenced by certain artworks and designs of prehistory. For example, a stone carving found in the archaeological recovery from Bronze Age Minoan Crete at Knossos (1900 – 1100 BC) has a depiction of a fisherman carrying an octopus.
In classical Greece, Aristotle (384 BC – 322 BC) commented on the colour-changing abilities of the octopus, both for camouflage and for signalling, in his "Historia animalium":
The octopus ... seeks its prey by so changing its colour as to render it like the colour of the stones adjacent to it; it does so also when alarmed.—Aristotle
Octopuses were often depicted in the art of the Moche people of ancient Peru, who worshipped the sea and its animals.
In mythology.
The Gorgon of Greek mythology has been thought to have been inspired by the octopus or squid, the octopus itself representing the severed head of Medusa, the beak as the protruding tongue and fangs, and its tentacles as the snakes.
The Kraken are legendary sea monsters of giant proportions said to dwell off the coasts of Norway and Greenland, usually portrayed in art as a giant octopus attacking ships.
The Hawaiian creation myth relates that the present cosmos is only the last of a series, having arisen in stages from the wreck of the previous universe. In this account, the octopus is the lone survivor of the previous, alien universe.
Akkorokamui is a gigantic octopus-like monster from Ainu folklore, which supposedly lurks in Funka Bay in Hokkaidō and has been sighted in several locations including Taiwan and Korea since the 19th century.
In Japanese mythology and folklore there is a yokai called tako no nana ashi which is a octopus with seven tentacles.
In literature.
The octopus has a significant role in Victor Hugo's book "Travailleurs de la mer" ("Toilers of the Sea").
Ian Fleming's 1966 short story collection "Octopussy and The Living Daylights", and the 1983 "James Bond" film partly inspired by Hugo's book.
In John Steinbeck's novella "Sweet Thursday", the marine biologist "Doc" is studying what the denizens of Cannery Row call "devilfish". Doc's study of octopuses to ascertain whether their behavior displays emotional responses similar to humans, such as apoplexy, is a major plot device in the novella.
Ed Ricketts, the marine biologist who was Steinbeck's friend and inspiration for the character Doc, had an octopus as a trademark for products sold by his Pacific Biological Laboratories.
Ringo Starr wrote a 2014 children's book based on his 1969 song "Octopus's Garden". The book is illustrated by Ben Court.
As a metaphor.
Due to having numerous arms that emanate from a common center, the octopus is often used as a metaphor for a group or organization that is perceived as being powerful, manipulative or bent on domination. Use of this terminology is invariably negative and employed by the opponents of the groups or institutions so described.
As food.
Octopus is eaten in many cultures. The arms and sometimes other body parts are prepared in various ways, often varying by species or geography.
As pets.
Though octopuses can be difficult to keep in captivity, some people keep them as pets. They often escape even from supposedly secure tanks, due to their problem-solving skills, mobility and lack of rigid structure.
The variation in size and lifespan among octopus species makes it difficult to know how long a new specimen can naturally be expected to live. That is, a small octopus may be just born or may be an adult, depending on its species. By selecting a well-known species, such as the California two-spot octopus, one can choose a small octopus (around the size of a tennis ball) and be confident it is young with a full life ahead of it.

</doc>
<doc id="22781" url="http://en.wikipedia.org/wiki?curid=22781" title="Omniscience">
Omniscience

Omniscience , mainly in religion, is the capacity to know everything that there is to know. In particular, Hinduism and the Abrahamic religions (Judaism, Christianity, and Islam) believe that there is a divine being who is omniscient. An omniscient point-of-view, in writing, is to know everything that can be known about a character, including past history, thoughts, feelings, etc. In Latin, "omnis" means "all" and "sciens" means "knowing". 
Definitions.
There is a distinction between:
Some modern Christian theologians argue that God's omniscience is inherent rather than total, and that God chooses to limit his omniscience in order to preserve the freewill and dignity of his creatures. John Calvin, among other theologians of the 16th century, comfortable with the definition of God as being omniscient in the total sense, in order for worthy beings' abilities to choose freely, embraced the doctrine of predestination.
Jain view.
Jainism view infinite knowledge as an inherent capability of every soul. "Arihanta" is the word used by Jains to refer to those human beings who have conquered all inner passions, like attachment, greed, pride, anger and possess Kevala Jnana (infinite knowledge). They are said to be of two kinds-
Controversies.
Omnipotence (unlimited power) is sometimes understood to also imply the capacity to know everything that will be. 
Nontheism often claims that the very concept of omniscience is inherently contradictory.
Whether omniscience, particularly regarding the choices that a human will make, is compatible with free will has been debated by theists and philosophers. The argument that divine foreknowledge is not compatible with free will is known as theological fatalism. Generally, if humans are truly free to choose between different alternatives, it is very difficult to understand how God could know what this choice will be.
God created knowledge.
Some theists argue that God created all knowledge and has ready access thereto. This statement invokes a circular time contradiction: presupposing the existence of God, before knowledge existed, there was no knowledge at all, which means that God was unable to possess knowledge prior to its creation. Alternately if knowledge was not a "creation" but merely existed in God's mind for all time there would be no contradiction. In Thomistic thought, which holds God to exist outside of time due to his ability to perceive everything at once, everything which God knows in his mind already exists. Hence, God would know of nothing that "was not" in existence (or else it would exist), and God would also know everything that "was" in existence (or else it would not exist), and God would possess this knowledge of what did exist and what did not exist at any point in the history of time.
The circular time contradiction can suppose anything concerning God, such as the creation of life, meaning before God created life, he wasn't alive. Moreover to assume any more attributes, to then say God is merciful, but before the creation of mercy, he wouldn't have been merciful, and before the creation of the concept of negation (meaning to assume something as not), no one would have any concept of what is not. These apparent contradictions, however, presuppose that such attributes are separately defined and detached from God, which is not necessarily so. It is not a given that attributes which can be assigned to or used to describe mankind, can be equally (or even similarly) ascribed to God. Take good and evil for example: goodness is biblically defined as that which is of God; it is intrinsic to his being and is revealed most prominently through his provision of Old Testament Law, the keeping of which is the very definition of goodness and the neglecting of which (on even the slightest of grounds), is the epitome of evil. A similar argument could be laid down concerning God's omniscience (i.e. knowledge). It even eludes the idea a lot more even to assume the concept of "nothing" or negation was created, therefore it is seemingly impossible to conceive such a notion where it draws down to a paradox. Assuming that the creator and creation is separate, and not the same one thing, or process. That it is a "this or that" notion, instead of a "this and that" idea.
To assume that knowledge in Plato's sense as described to be a belief that's true, it then means that before everything came into being, it was all to be conceived as total imagination by God until the set of truth.
One verse "God created man in his own Image" states that God imagined the form of humans, taking image as a root word for imagine, mistakenly understood as man to look like God. [this verse from Genesis 1 is in the Hebrew Scriptures. The word 'Image' is translated from two Hebrew words 'demuth' - likeness or similitude and 'tselem'- an obscure word which translates as image or idol. It is difficult, therefore to make a case for the author's reading of this verse to mean 'God imagined the form of humans'.
The above definitions of omniscience cover what is called "propositional knowledge" ("knowing that"), as opposed to "experiential knowledge" ("knowing how").
That some entity is omniscient in the sense of possessing all possible propositional knowledge does not imply that it also possesses all possible experiential knowledge.
Opinions differ as to whether the propositionally omniscient God of the theists is able to possess all experiential knowledge as well. But it seems at least obvious that a divine infinite being conceived of as necessary infinitely knowledgeable would also know "how", for example, a finite person (man) dying feels like as He (God) would have access to all knowledge including the obvious experiences of the dying human. There is a third type of knowledge: "practical" or "procedural knowledge" ("knowing how to do"). If omniscience is taken to be "all" knowledge then all knowledge of all types would be fully known and comprehended.
Omniscience vs free will.
A question arises : an omniscient entity knows everything even about his/her/its own decisions in the future, does it therefore forbid any free will to that entity? William Lane Craig states that the question subdivides into two: (1) If God foreknows the occurrence of some event E, does E happen necessarily?, and (2) If some event E is contingent, how can God foreknow E’s occurrence? 
"See : Determinism, Freewill and argument from free will"
Non-theological uses.
The field of literary analysis and criticism can discuss omniscience in the point of view of a narrator. An omniscient narrator, almost always a third-person narrator, can reveal insights into characters and settings that would not be otherwise apparent from the events of the story and which no single character could be aware of.
A collection of surveillance techniques which together contribute to much disparate knowledge about the movements, actions, conversation, appearance, etc. of an individual (or organisation) is sometimes called omniscient technology.
The word "omniscient" characterizes a fictional character in the Devin Townsend album "Ziltoid the Omniscient".
Omniscience in Buddhist India.
The topic of omniscience has been much debated in various Indian traditions, but no more so than by the Buddhists. After Dharmakirti's excursions into the subject of what constitutes a valid cognition, Śāntarakṣita and his student Kamalaśīla thoroughly investigated the subject in the Tattvasamgraha and its commentary the Panjika. The arguments in the text can be broadly grouped into four sections:
See also.
</dl>

</doc>
<doc id="22784" url="http://en.wikipedia.org/wiki?curid=22784" title="Original Chip Set">
Original Chip Set

The Original Chip Set (OCS) was a chipset used in the earliest Commodore Amiga computers and defined the Amiga's graphics and sound capabilities. It was succeeded by the slightly improved Enhanced Chip Set (ECS) and greatly improved Advanced Graphics Architecture (AGA).
The original chipset appeared in Amiga models built between 1985 and 1990: the Amiga 1000, Amiga 2000, Amiga CDTV, and Amiga 500.
Overview of chips.
The chipset which gave the Amiga its unique graphics features consists of three main "custom" chips; "Agnus", "Denise", and "Paula". Both the original chipset and the enhanced chipset were manufactured using NMOS logic technology by Commodore's chip manufacturing subsidiary, MOS Technology. According to Jay Miner, OCS chipset was fabricated in 5 µm manufacturing process while AGA Lisa was implemented in 1.5 µm process. All three custom chips were originally packaged in 48-pin DIPs; later versions of Agnus, known as Fat Agnus, were packaged in an 84-pin PLCC.
Agnus is the central chip in the design. It controls all access to chip RAM from both the central 68000 processor and the other custom chips, using a complicated priority system. Agnus includes sub-components known as the "blitter" (fast transfer of data in memory without the intervention of the processor) and the "copper" (video-synchronized co-processor). The original Agnus can address 512 KB of chip RAM. Later revisions, dubbed 'Fat Agnus', added 512 KB pseudo-fast RAM, which for ECS was changed to 1 MB (sometimes called 'Fatter Agnus') and subsequently to 2 MB chip RAM.
Denise is the main video processor. Without using overscan, the Amiga's graphics display is 320 or 640 pixels wide by 200 (NTSC) or 256 (PAL) pixels tall. Denise also supports interlacing, which doubles the vertical resolution, at the cost of pretty bad flickering on most monitors produced during the same timeframe as the Amiga computers. Planar bitmap graphics are used, which splits the individual bits per pixel into separate areas of memory, called bitplanes. In normal operation, Denise allows between 1 and 5 bitplanes, giving 2 to 32 unique colours. These colours are selected from a palette of 4096 colours (4 bits per RGB component). A 6th bitplane is available for two special video modes: Halfbrite mode and Hold And Modify mode. Denise also supports eight sprites, single pixel scrolling, and a "dual playfield" mode. Denise also handles mouse and digital joystick input.
Paula is primarily the audio chip, with 4 independent hardware-mixed 8-bit PCM sound channels, each of which supports 65 volume levels (no sound to maximum volume) and waveform output rates from roughly 20 samples per second to almost 29,000 samples per second. Paula also handles interrupts and various I/O functions including the floppy disk drive, the serial port, and analog joysticks.
There are many similarities - both in overall functionality and in the division of functionality into the three component chips - between the OCS chipset and the much earlier and simpler chipset of the Atari 8-bit family of home computers, consisting of the ANTIC, GTIA and POKEY chips; both chipsets were conceptually designed by Jay Miner, which explains the similarity.
Agnus.
The Agnus chip is in overall control of the entire chipset's operation. All operations are synchronised to the position of the video beam. This includes access to the built-in RAM, known as chip RAM because the chipset has access to it. Both the central 68000 processor and other members of the chipset have to arbitrate for access to chip RAM via "Agnus". In computing architecture terms, this is Direct Memory Access (DMA), where Agnus is the DMA Controller (DMAC).
Agnus has a complex and priority-based memory access policy that attempts to best coordinate requests for memory access among competing resources. For example, bitplane data fetches are prioritized over blitter transfers as the immediate display of frame buffer data is considered more important than the processing of memory by the blitter. Agnus also attempts to order accesses in such a way so as to overlap CPU bus cycles with DMA cycles. As the original 68000 processor in Amigas tended only to access memory on every second available memory cycle, Agnus operates a system where "odd" memory access cycles are allocated first and as needed to time-critical custom chip DMA while any remaining cycles are available to the CPU, thus the CPU does not generally get locked out of memory access and does not appear to slow down. However, non-time-critical custom chip access, such as "blitter" transfers, can use up any spare odd or even cycles and, if the "BLITHOG" (blitter hog) flag is set, Agnus can lock out the even cycles from the CPU in deference to the "blitter".
Agnus's timings are measured in "colour clocks" of 280 ns. This is equivalent to two low resolution (140 ns) pixels or four high resolution (70 ns) pixels. Like Denise, these timings were designed for display on household TVs, and can be synchronised to an external clock source.
Blitter.
The "blitter" is a sub-component of Agnus. "Blit" is shorthand for "block image transfer" or bit blit. The blitter is a highly parallel memory transfer and logic operation unit. It has three modes of operation: copying blocks of memory, filling blocks (e.g. polygon filling) and line drawing.
The blitter allows the rapid copying of video memory, meaning that the CPU can be freed for other tasks. The blitter was primarily used for drawing and redrawing graphics images on the screen, called "bobs", short for "blitter objects".
The blitter's block copying mode takes zero to three data sources in memory, called A, B and C, performs a programmable boolean function on the data sources and writes the result to a destination area, D. Any of these four areas can overlap. The blitter runs either from the start of the block to the end, known as "ascending" mode, or in reverse, "descending" mode.
Blocks are "rectangular"; they have a "width" in multiples of 16 bits, a height measured in "lines", and a "stride" distance to move from the end of one line to the next. This allows the blitter to operate on any conceivable video resolution. The copy automatically performs a per-pixel logical operation. These operations are described generically using minterms. This is most commonly used to do direct copies (D = A), or apply a pixel mask around blitted objects (D = (C AND B) OR A). The copy can also barrel shift each line by 0 to 15 pixels. This allows the blitter to draw at pixel offsets that are not exactly multiples of 16.
These functions allow the Amiga to move GUI windows around the screen rapidly as each is represented in graphical memory space as a rectangular block of memory which may be shifted to any required screen memory location at will.
The blitter's line mode draws single-pixel thick lines using the Bresenham's line algorithm. It can also apply a 16-bit repeating pattern to the line. The line mode can also be used to draw rotated bobs: each line of bob data is used as line pattern while the line mode draws the tilted bob line by line.
The blitter's filling mode is used to fill per-line horizontal spans. On each span, it reads each pixel in turn from right to left. Whenever it reads a set pixel, it toggles filling mode on or off. When filling mode is on, it sets every pixel until filling mode is turned off or the line ends. Together, these modes allow the blitter to draw individual flat-shaded polygons. Later Amigas tended to use a combination of a faster CPU and blitter for many operations.
Copper.
The "copper" is another sub-component of Agnus; The name is short for "co-processor". The copper is a programmable finite state machine that executes a programmed instruction stream, synchronized with the video hardware.
When it is turned on, the copper has three states; either reading an instruction, executing it, or waiting for a specific video beam position. The copper runs a program called the "copper list" in parallel with the main CPU. The copper runs in sync with the video beam, and it can be used to perform various operations which require video synchronization. Most commonly it is used to control video output, but it can write to most of the chipset registers and thus can be used to initiate blits, set audio registers, or interrupt the CPU.
The copper list has three kinds of instructions, each one being a pair of two bytes, four bytes in total:
The length of the copper list program is limited by execution time. The copper restarts executing the copper list at the start of each new video frame. There is no explicit "end" instruction; instead, the WAIT instruction is used to wait for a location which is never reached.
External video timing.
Under normal circumstances, the Amiga generates its own video timings, but Agnus also supports synchronising the system to an external signal so as to achieve genlocking with external video hardware. There is also an 1 bit output on this connector that indicates whether the Amiga is outputting background colour or not, permitting easy overlaying of Amiga video onto external video. This made the Amiga particularly attractive as a character generator for titling videos and broadcast work, as it avoided the use and expense of AB roll and chromakey units that would be required without the genlock support. The support of overscan, interlacing and genlocking capabilities, and the fact that the display timing was very close to broadcast standards (NTSC or PAL), made the Amiga the first ideal computer for video purposes, and indeed, it was used in many studios for digitizing video data (sometimes called frame-grabbing), subtitling and interactive video news.
Denise.
Denise is programmed to fetch planar video data from 1 to 5 bitplanes and translate that into a colour lookup. The number of bitplanes is arbitrary, thus if 32 colours are not needed, 2, 4, 8 or 16 can be used instead. The number of bitplanes (and resolution) can be changed on the fly, usually by the copper. This allows for very economical use of RAM. There can also be a sixth bitplane, which can be used in three special graphics modes:
In Extra-HalfBrite (EHB), if a pixel is set on the sixth bitplane, the brightness of the regular 32 colour pixel is halved. Early versions of the Amiga 1000 sold in the United States did not have the Extra-HalfBrite mode.
In Hold-and-Modify mode (HAM), each 6-bit pixel is interpreted as 2 control bits and 4 data bits. The 4 possible permutations of control bits are "set", "modify red", "modify green" and "modify blue". With "set", the 4 data bits act like a regular 16-colour display look up. With one of the "modify"s, the red, green or blue component of the previous pixel is modified to the data value, and the other two components are held from the previous pixel. This allows all 4096 colours on screen at once and is an example of lossy image compression in hardware.
In Dual Playfield mode, instead of acting as a single screen, two "playfields" of 8 colours each (3 bitplanes each) are drawn on top of each other. They are independently scrollable and the background colour of the top playfield "shines through" to the underlying playfield.
There are two horizontal graphics resolutions, "lowres" with 140 ns pixels and "hires" with 70 ns pixels. This makes the display 320 or 640 pixels wide without overscan. Denise supports very wide overscan; there is no need for a border around the graphics as other computers suffered from. Vertical resolution, without overscan, is 200 pixels for an 60 Hz NTSC Amiga or 256 for a 50 Hz PAL Amiga. This can be doubled using an interlaced display.
Denise can also lay up to eight 16 pixel wide sprites per scan line (in automatic mode) on top, underneath, or between playfields, and detect collisions between sprites and the playfields or between sprites. These sprites have 3 visible colours and one transparent colour. Optionally, adjacent pairs of sprites can be "attached" to make a single 15 colour sprite. Using Copper or CPU register manipulations, each sprite 'channel' can be reused multiple times in a single frame to increase the total sprites per frame. Sprite position registers may also be changed during a scanline, increasing the total sprites on a single scanline.
Finally, Denise is responsible for handling mouse/joystick x/y inputs.
Paula.
The Paula chip includes logic for audio playback, floppy disk drive control, serial port input/output and mouse/joystick buttons 2 and 3 signals. The logic remained functionally identical across all Amiga models from Commodore.
Audio.
Paula has four DMA-driven 8-bit PCM sample sound channels. Two sound channels are mixed into the left audio output, and the other two are mixed into the right output, producing stereo audio output. The only supported hardware sample format is signed linear 8-bit two's complement. Each sound channel has an independent frequency and a 6-bit volume control (64 levels). Internally, the audio hardware is implemented by four state machines, each having eight different states.
Additionally the hardware allows one channel in a channel pair to modulate the other channel's period or amplitude. It is rarely used on the Amiga due to both frequency and volume being controllable in better ways, but could be used to achieve different kinds of tremolo and vibrato, and even rudimentary FM synthesis effects.
Audio may be output using two methods. Most often, DMA-driven audio is used. As explained in the discussion of Agnus, memory access is prioritized and one DMA slot per scan line is available for each of the four sound channels. On a regular NTSC or PAL display, DMA audio playback is limited to a maximum output rate of 28867 values per channel (PAL: 28837) per second totaling 57674 (PAL: 57734) values per second on each stereo output. This rate can be increased with the ECS and AGA chipsets by using a video mode with higher horizontal scan rate. 
Alternately, Paula may signal the CPU to load a new sample into any of the four audio output buffers by generating an interrupt when a new sample is needed. This allows for output rates that exceed 57 kHz per channel and increases the number of possible voices (simultaneous sounds) through software mixing. 
The Amiga contains an analog low-pass filter (reconstruction filter) which is external to Paula. The filter is a 12 dB/oct Butterworth low-pass filter at approximately 3.3 kHz. The filter can only be applied globally to all four channels. In models after the Amiga 1000 (excluding the very first revision of the Amiga 500), the brightness of the power LED is used to indicate the status of the filter. The filter is active when the LED is at normal brightness, and deactivated when dimmed (on early Amiga 500 models the LED went completely off). Models released before Amiga 1200 also have a static "tone knob" type low-pass filter that is enabled regardless of the optional "LED filter". This filter is a 6 dB/oct low-pass filter with cutoff frequency at 4.5 or 5 kHz.
A software technique was later developed which can play back 14-bit audio by combining two channels set at different volumes. This results in two 14-bit channels instead of four 8-bit channels. This is achieved by playing the high byte of a 16-bit sample at maximum volume, and the low byte at minimum volume (both ranges overlap, so the low byte needs to be shifted right two bits). The bit shift operation requires a small amount of CPU or blitter overhead, whereas conventional 8-bit playback is almost entirely DMA driven. This technique was incorporated into the retargetable audio subsystem AHI, allowing compatible applications to use this mode transparently.
Floppy disk controller.
The floppy controller is unusually flexible. It can read and write raw bit sequences directly from and to the disk via DMA or programmed I/O at 500 (double density) or 250 kbit/s (single density or GCR). MFM or GCR were the two most commonly used formats though in theory any run-length limited code could be used. It also provides a number of convenient features, such as sync-on-word (in MFM coding, $4489 is usually used as the sync word). MFM encoding/decoding is usually done with the blitter — one pass for decode, three passes for encode. Normally the entire track is read or written in one shot, rather than sector-by-sector; this made it possible to get rid of most of the inter-sector gaps that most floppy disk formats need to safely prevent the "bleeding" of a written sector into the previously-existing header of the next sector due to speed variations of the drive. If all sectors and their headers are always written in one go, such bleeding is only an issue at the end of the track (which still must not bleed back into its beginning), so that only one gap per track is needed. This way, for the native Amiga disk format, the raw storage capacity of 3.5 inch DD disks was increased from the typical 720 KB to 880 KB, although the less-than-ideal file system of the earlier Amiga models reduced this again to ca. 830 KB of actual payload data.
In addition to the native 880 KB 3.5-inch disk format, the controller can handle many foreign formats, such as:
The Amiga 3000 introduced a special, dual-speed floppy drive that also allowed to use high density disks with double capacity without any change to Paula's floppy controller.
Serial port.
The serial port is rudimentary, using programmed input/output only and lacking a FIFO buffer. However, virtually any bit rate can be selected, including all standard rates, MIDI rate, as well as extremely high custom rates.

</doc>
<doc id="22786" url="http://en.wikipedia.org/wiki?curid=22786" title="Optic neuritis">
Optic neuritis

Optic neuritis is inflammation of the optic nerve. It is also called papillitis (when the head of the optic nerve is involved) and retrobulbar neuritis (when the posterior of the nerve is involved). It is caused by many different conditions, and it may lead to complete or partial loss of vision. The most common cause is multiple sclerosis.
Causes.
The optic nerve comprises axons that emerge from the retina of the eye and carry visual information to the primary visual nuclei, most of which is relayed to the occipital cortex of the brain to be processed into vision. Inflammation of the optic nerve causes loss of vision, usually because of the swelling and destruction of the myelin sheath covering the optic nerve.
The most common etiology is multiple sclerosis. Up to 50% of patients with MS will develop an episode of optic neuritis, and 20-30% of the time optic neuritis is the presenting sign of MS. The presence of demyelinating white matter lesions on brain MRI at the time of presentation of optic neuritis is the strongest predictor for developing clinically definite MS. Almost half of the patients with optic neuritis have white matter lesions consistent with multiple sclerosis.
At five years follow-up, the overall risk of developing MS is 30%, with or without MRI lesions. Patients with a normal MRI still develop MS (16%), but at a lower rate compared to those patients with three or more MRI lesions (51%). From the other perspective, however, almost half (44%) of patients with any demyelinating lesions on MRI at presentation will not have developed MS ten years later.
Some other causes of optic neuritis include infection (e.g. syphilis, Lyme disease, herpes zoster), autoimmune disorders (e.g. lupus, neurosarcoidosis, neuromyelitis optica), inflammatory bowel disease, drug induced (e.g. chloramphenicol, ethambutol), vasculitis, B12 deficiency and diabetes.
Symptoms.
Major symptoms are sudden loss of vision (partial or complete), sudden blurred or "foggy" vision, and pain on movement of the affected eye. The vision might also be described as "disturbed/blackened" rather than blurry, as when feeling dizzy. Many patients with optic neuritis may lose some of their color vision in the affected eye (especially red), with colors appearing subtly washed out compared to the other eye. A study found that 92.2% of patients experienced pain, which actually preceded the visual loss in 39.5% of cases. However, several case studies in children have demonstrated the absence of pain in more than half of cases (approximately 60%) in their pediatric study population, with the most common symptom reported simply as "blurriness." Other remarkable differences between the presentation of adult optic neuritis as compared to pediatric cases include more often unilateral optic neuritis in adults, while children much predominantly present with bilateral involvement. Symptoms peak several days to weeks after onset, while symptoms failing to improve after 8 weeks should suggest a diagnosis other than optic neuritis.
On medical examination the head of the optic nerve can easily be visualised by a slit lamp with high plus or by using direct ophthalmoscopy; however, frequently there is no abnormal appearance of the nerve head in optic neuritis (in cases of retrobulbar optic neuritis), though it may be swollen in some patients (anterior papillitis or more extensive optic neuritis). In many cases, only one eye is affected and patients may not be aware of the loss of color vision until they are asked to close or cover the healthy eye.
Epidemiology.
Optic neuritis typically affects young adults ranging from 18–45 years of age, with a mean age of 30–35 years. There is a strong female predominance. The annual incidence is approximately 5/100,000, with a prevalence estimated to be 115/100,000.
Treatment and prognosis.
In the vast majority of MS associated optic neuritis, visual function spontaneously improves over the first 2–3 months, and there is evidence that corticosteroid treatment does not affect the long term outcome. However, for optic neuritis that is not MS associated (or atypical optic neuritis) the evidence is less clear and therefore the threshold for treatment with intravenous corticosteroids is lower. Intravenous corticosteroids have also been found to reduce the risk of developing MS in the following two years in those patients who have MRI lesions; but this effect disappears by the third year of follow up.
Paradoxically it has been demonstrated that oral administration of corticosteroids in this situation may lead to more recurrent attacks than in non-treated patients (though oral steroids are generally prescribed after the intravenous course, to wean the patient off the medication). This effect of corticosteroids seems to be limited to optic neuritis and has not been observed in other diseases treated with corticosteroids.
A Cochrane Systematic Review studied the effect of corticosteroids for treating participants suffering from optic neuritis. Treatments reviewed included intravenous methylprednisone, oral methylprednisone, and oral prednisone. All treatments reviewed did not show any benefit in terms of recovery to visual acuity, contrast sensitivity, or visual field.
In the longer term, there is evidence that patients with MS who first present with optic neuritis have a relatively more benign MS course.
Recurrent optic neuritis.
The repetition of an idiopatic optic neuritis is considered a distinct clinical condition, and it has been found to be associated with AQP- neuromyelitis optica
In popular culture.
In the season five episode of Dr. Quinn, Medicine Woman, "Season of Miracles", Reverend Timothy Johnson is struck blind by Optic neuritis on Christmas Day, 1872. He remains blind for the duration of the series.
In Charles Dickens "Bleak House" the main character, Esther Summerville suffers from a transient episode of visual loss with symptoms also observed during the course of optic neuritis. Sir William Searle Holdsworth suggested "Bleak House" to have taken place in 1827.

</doc>
<doc id="22787" url="http://en.wikipedia.org/wiki?curid=22787" title="List of organizations with .int domain names">
List of organizations with .int domain names

This is a list of organizations with INT domain names, in alphabetical order of the second-level domain name. The list is not comprehensive. As of June 2012, the INT domain consists of 166 subdomain delegations.
These organizations are generally international organizations established by treaty. Some however (such as YMCA) do not meet current restrictions and were grandfathered in from prior acceptance.

</doc>
<doc id="22788" url="http://en.wikipedia.org/wiki?curid=22788" title="Organization of American States">
Organization of American States

The Organization of American States (Spanish: "Organización de los Estados Americanos", Portuguese: "Organização dos Estados Americanos", French: "Organisation des États Américains"), or the OAS or OEA, is an inter-continental organization founded on 30 April 1948, for the purposes of regional solidarity and cooperation among its member states. Headquartered in Washington, D.C., United States, the OAS's members are the 35 independent states of the Americas.
As of 26 May 2015, the Secretary General of OAS is Luis Almagro.
History.
The notion of an international union in the New World was first put forward by Simón Bolívar who, at the 1826 Congress of Panama (still being part of Colombia), proposed creating a league of American republics, with a common military, a mutual defense pact, and a supranational parliamentary assembly. This meeting was attended by representatives of Gran Colombia (comprising the modern-day nations of Colombia, Ecuador, Panama, Venezuela, Peru, and Bolivia), The United Provinces of Central America, and Mexico but the grandly titled "Treaty of Union, League, and Perpetual Confederation" was ultimately ratified only by Gran Colombia. Bolívar's dream soon floundered with civil war in Gran Colombia, the disintegration of Central America, and the emergence of national rather than New World outlooks in the newly independent American republics. Bolívar's dream of American unity was meant to unify Latin American nations against imperial domination by external power.
The pursuit of regional solidarity and cooperation again came to the forefront in 1889–1890, at the First International Conference of American States. Gathered together in Washington, D.C., 18 nations resolved to found the International Union of American Republics, served by a permanent secretariat called the Commercial Bureau of the American Republics (renamed the "International Commercial Bureau" at the Second International Conference in 1901–1902). These two bodies, in existence as of 14 April 1890, represent the point of inception to which today's OAS and its General Secretariat trace their origins.
At the Fourth International Conference of American States (Buenos Aires, 1910), the name of the organization was changed to the "Union of American Republics" and the Bureau became the "Pan American Union." The Pan American Union Building was constructed in 1910, on Constitution Avenue, Northwest, Washington, D.C.
In the mid-1930s, U.S. President Franklin Delano Roosevelt organized an inter-American conference in Buenos Aires. One of the items at the conference was a "League of Nations of the Americas", an idea proposed by Colombia, Guatemala, and the Dominican Republic. At the subsequent Inter-American Conference for the Maintenance of Peace, 21 nations pledged to remain neutral in the event of a conflict between any two members. The experience of World War II convinced hemispheric governments that unilateral action could not ensure the territorial integrity of the American nations in the event of external aggression. To meet the challenges of global conflict in the postwar world and to contain conflicts within the hemisphere, they adopted a system of collective security, the Inter-American Treaty of Reciprocal Assistance (Rio Treaty) signed in 1947 in Rio de Janeiro.
The Ninth International Conference of American States was held in Bogotá between March and May 1948 and led by United States Secretary of State George Marshall, a meeting which led to a pledge by members to fight communism in the western hemisphere. This was the event that saw the birth of the OAS as it stands today, with the signature by 21 American countries of the Charter of the Organization of American States on 30 April 1948 (in effect since December 1951). The meeting also adopted the American Declaration of the Rights and Duties of Man, the world's first general human rights instrument, Bogotá considered the first defensive state in the event of war, of the Organization of American States.
The transition from the Pan American Union to OAS would have been smooth if it had not been for the assassination of Colombian leader Jorge Eliécer Gaitán and all the commotion that follows. The Director General of the former, Alberto Lleras Camargo, became the Organization's first Secretary General. The current Secretary General is former Uruguayan minister of foreign affairs Luis Almagro.
Significant milestones in the history of the OAS since the signing of the Charter have included the following:
Goals and purpose.
In the words of Article 1 of the Charter, the goal of the member nations in creating the OAS was "to achieve an order of peace and justice, to promote their solidarity, to strengthen their collaboration, and to defend their sovereignty, their territorial integrity, and their independence." Article 2 then defines eight essential purposes:
Over the course of the 1990s, with the end of the Cold War, the return to democracy in Latin America, and the thrust toward globalization, the OAS made major efforts to reinvent itself to fit the new context. Its stated priorities now include the following:
Organizational structure.
The Organization of American States is composed of an Organization of American States General Secretariat, the Permanent Council, the Inter-American Council for Integral Development, and a number of committees.
The General Secretariat of the Organization of American States consists of six secretariats.
The various committees of the Organization of American States include:
General Assembly.
The General Assembly is the supreme decision-making body of OAS. It convenes once every year in a regular session. In special circumstances, and with the approval of two-thirds of the member states, the Permanent Council can convene special sessions.
The Organization's member states take turns hosting the General Assembly on a rotating basis. The states are represented at its sessions by their chosen delegates: generally, their ministers of foreign affairs, or their appointed deputies. Each state has one vote, and most matters—except for those for which the Charter or the General Assembly's own rules of procedure specifically require a two-thirds majority—are settled by a simple majority vote.
The General Assembly's powers include setting the OAS's general course and policies by means of resolutions and declarations; approving its budget and determining the contributions payable by the member states; approving the reports and previous year's actions of the OAS's specialized agencies; and electing members to serve on those agencies.
Membership and adhesions.
All 35 independent nations of the Americas are members of the OAS. Upon foundation on 5 May 1948, there were 21 members:
The later expansion of the OAS included Canada and the newly independent nations of the Caribbean. Members with later admission dates (sorted chronologically):
Canada and the OAS.
Although Canada obtained independence in its foreign policy from the United Kingdom in 1931, it chose not to join the OAS when it was first formed, despite its close relations with the United States. Canada became a Permanent Observer in the OAS on 2 February 1972. Canada signed the Charter of the Organization of American States on 13 November 1989 and this decision was ratified on 8 January 1990.
In 2004–2005, Canada was the second largest contributor to the OAS, with an annual assessed contribution representing 12.36 percent of the OAS Regular Budget (US$9.2 million) and an additional C$9 million in voluntary contributions to specific projects. Shortly after joining as a full member, Canada was instrumental in the creation of the Unit for the Promotion of Democracy, which provides support for the strengthening and consolidation of democratic processes and institutions in OAS member states.
Status of Cuba.
The current government of Cuba was excluded from participation in the Organization under a decision adopted by the Eighth Meeting of Consultation in Punta del Este, Uruguay, on 31 January 1962. The vote was passed by 14 in favor, with one against (Cuba) and six abstentions (Argentina, Bolivia, Brazil, Chile, Ecuador, and Mexico). The operative part of the resolution reads as follows:
This meant that the Cuban nation was still technically a member state, but that the current government was denied the right of representation and attendance at meetings and of participation in activities. The OAS's position was that although Cuba's participation was suspended, its obligations under the Charter, the American Declaration of the Rights and Duties of Man, etc. still hold: for instance, the Inter-American Commission on Human Rights continued to publish reports on Cuba's human rights situation and to hear individual cases involving Cuban nationals. However, this stance was occasionally questioned by other individual member states.
Cuba's position was stated in an official note sent to the Organization "merely as a courtesy" by Minister of Foreign Affairs Dr. Raúl Roa on 4 November 1964: "Cuba was arbitrarily excluded... The Organization of American States has no juridical, factual, or moral jurisdiction, nor competence, over a state which it has illegally deprived of its rights."
The reincorporation of Cuba as an active member regularly arose as a topic within the inter-American system – for instance, it was intimated by the outgoing ambassador of Mexico in 1998 – but most observers did not see it as a serious possibility while the present government remained in power. Since 1960, the Cuban administration had repeatedly characterized the OAS as the "Ministry of Colonies" of the United States of America. On 6 May 2005, President Fidel Castro reiterated that the island nation would not "be part of a disgraceful institution that has only humiliated the honor of Latin American nations". After Fidel Castro's recent retirement and the ascent of his brother Raúl to power, this official position was reasserted. Venezuelan President Hugo Chávez promised to veto any final declaration of the 2009 Summit of the Americas due to Cuba's exclusion.
On 17 April 2009, after a "trading of warm words" between the administrations of U.S. President Barack Obama and Cuban leader Raúl Castro, OAS Secretary General José Miguel Insulza said he would ask the 2009 General Assembly to annul the 1962 resolution excluding Cuba.
On 3 June 2009, foreign ministers assembled in San Pedro Sula, Honduras, for the OAS's 39th General Assembly, passed a vote to lift Cuba's suspension from the OAS. The United States had been pressuring the OAS for weeks to condition Cuba's readmission to the group on democratic principles and commitment to human rights. Ecuador's Foreign Minister Fander Falconí said there will be no such conditions. "This is a new proposal, it has no conditions—of any kind," Falconí said. "That suspension was made in the Cold War, in the language of the Cold War. What we have done here is fix a historic error." The suspension was lifted at the end of the General Assembly, but, to be readmitted to the Organization, Cuba will need to comply with all the treaties signed by the Member States, including the Inter-American Democratic Charter of 2001. A Declaration by Cuba's Revolutionary Government dated 8 June 2009 stated that while Cuba welcomed the Assembly's gesture, in light of the Organization's historical record "Cuba will not return to the OAS."
Suspension of Honduras.
Following the expulsion of its President Manuel Zelaya, Honduras' membership of the Organization was suspended unanimously at midnight on 5 July 2009. The "de facto" government had already announced it was leaving the OAS hours earlier; this was not, however, taken into account by the OAS, which does not recognize that government as legitimate. An extraordinary meeting had been conducted by the OAS in Washington, D.C., with Zelaya in attendance. The suspension of Honduras was approved unanimously with 33 votes (Honduras did not vote). This was the first suspension carried out by the OAS since that of Cuba in 1962.
After Zelaya's return to Honduras in 2011, the country was re-admitted to the Organization on 1 June 2011 with 32 votes in favor and 1 (Ecuador) against. Venezuela expressed some reservations.
Permanent Observers.
As of 31 January 2014, there are 69 permanent observer countries, as well as the European Union.
Official languages.
The Organization's official languages are Spanish, English, Portuguese, and French; the national languages of the majority of its member nations. The Charter, the basic instrument governing OAS, makes no reference to the use of official languages. These references are to be found in the Rules of Procedure governing the various OAS bodies. Article 51 of the Rules of Procedure of the General Assembly, the supreme body of the OAS, which meets once a year, states that English, French, Portuguese and Spanish are the four official languages. Article 28 stipulates that a Style Committee shall be set up with representatives of the four official languages to review the General Assembly resolutions and declarations. Article 53 states that proposals shall be presented in the four official languages. The Rules of Procedure and Statutes of other bodies, such as the Inter-American Council for Integral Development (CIDI), the Permanent Executive Committee of the Inter-American Council for Integral Development (CEPCIDI), the Inter-American Commission of Women (CIM), the Inter-American Drug Abuse Control Commission (CICAD), the Inter-American Commission on Human Rights (IACHR) and the Inter-American Juridical Committee (CJI), technical bodies of the OAS, also mention the four official languages in which their meetings are to be conducted. Policy is therefore dictated through these instruments that require use of the four official languages at meetings.
Although a number of other languages have official status in one or more member states of OAS (Dutch in Suriname; Haitian Creole alongside French in Haiti; Quechua and Aymara in Peru, Ecuador and Bolivia; Guaraní in Paraguay), they are not official languages of the Organization.

</doc>
<doc id="22789" url="http://en.wikipedia.org/wiki?curid=22789" title="World Organisation for Animal Health">
World Organisation for Animal Health

The World Organization for Animal Health (OIE) is the intergovernmental organization responsible for improving animal health worldwide.
The need to fight animal diseases at global level led to the creation of the Office International des Epizooties through the international Agreement signed on January 25, 1924. In May 2003 the Office became the World Organisation for Animal Health but kept its historical acronym OIE.
It is recognized as a reference organisation by the World Trade Organization (WTO) and in 2014 had a total of 180 member states. The OIE maintains permanent relations with 45 other international and regional organisations and has Regional and sub-regional Offices on every continent.
The main objective of the Office is to control epizootic diseases and thus to prevent their spread.
The OIE does not depend on the UN system; its autonomy is both institutional and financial and its activities are governed by its own constitutional texts.
Since its first General Session, held in Paris, The Office carries on its work under the authority of a Committee consisting of delegates of the contracting Governments.
Membership.
OIE has a total of 180 members.
World Animal Health Information Database (WAHID) Interface.
Timely dissemination of information is crucial to containing outbreaks. The WAHID Interface provides access to all data held within OIE's new World Animal Health Information System (WAHIS). It replaces and significantly extends the former web interface named Handistatus II System.
A comprehensive range of information is available from:

</doc>
