<doc id="25268" url="http://en.wikipedia.org/wiki?curid=25268" title="Quantum electrodynamics">
Quantum electrodynamics

In particle physics, quantum electrodynamics (QED) is the relativistic quantum field theory of electrodynamics. In essence, it describes how light and matter interact and is the first theory where full agreement between quantum mechanics and special relativity is achieved. QED mathematically describes all phenomena involving electrically charged particles interacting by means of exchange of photons and represents the quantum counterpart of classical electromagnetism giving a complete account of matter and light interaction.
In technical terms, QED can be described as a perturbation theory of the electromagnetic quantum vacuum. Richard Feynman called it "the jewel of physics" for its extremely accurate predictions of quantities like the anomalous magnetic moment of the electron and the Lamb shift of the energy levels of hydrogen.:Ch1
History.
The first formulation of a quantum theory describing radiation and matter interaction is attributed to British scientist Paul Dirac, who (during the 1920s) was first able to compute the coefficient of spontaneous emission of an atom.
Dirac described the quantization of the electromagnetic field as an ensemble of harmonic oscillators with the introduction of the concept of creation and annihilation operators of particles. In the following years, with contributions from Wolfgang Pauli, Eugene Wigner, Pascual Jordan, Werner Heisenberg and an elegant formulation of quantum electrodynamics due to Enrico Fermi, physicists came to believe that, in principle, it would be possible to perform any computation for any physical process involving photons and charged particles. However, further studies by Felix Bloch with Arnold Nordsieck, and Victor Weisskopf, in 1937 and 1939, revealed that such computations were reliable only at a first order of perturbation theory, a problem already pointed out by Robert Oppenheimer. At higher orders in the series infinities emerged, making such computations meaningless and casting serious doubts on the internal consistency of the theory itself. With no solution for this problem known at the time, it appeared that a fundamental incompatibility existed between special relativity and quantum mechanics.
Difficulties with the theory increased through the end of 1940. Improvements in microwave technology made it possible to take more precise measurements of the shift of the levels of a hydrogen atom, now known as the Lamb shift and magnetic moment of the electron. These experiments unequivocally exposed discrepancies which the theory was unable to explain.
A first indication of a possible way out was given by Hans Bethe. In 1947, while he was traveling by train to reach Schenectady from New York, after giving a talk at the conference at Shelter Island on the subject, Bethe completed the first non-relativistic computation of the shift of the lines of the hydrogen atom as measured by Lamb and Retherford. Despite the limitations of the computation, agreement was excellent. The idea was simply to attach infinities to corrections of mass and charge that were actually fixed to a finite value by experiments. In this way, the infinities get absorbed in those constants and yield a finite result in good agreement with experiments. This procedure was named renormalization.
Based on Bethe's intuition and fundamental papers on the subject by Sin-Itiro Tomonaga, Julian Schwinger, Richard Feynman and Freeman Dyson, it was finally possible to get fully covariant formulations that were finite at any order in a perturbation series of quantum electrodynamics. Sin-Itiro Tomonaga, Julian Schwinger and Richard Feynman were jointly awarded with a Nobel prize in physics in 1965 for their work in this area. Their contributions, and those of Freeman Dyson, were about covariant and gauge invariant formulations of quantum electrodynamics that allow computations of observables at any order of perturbation theory. Feynman's mathematical technique, based on his diagrams, initially seemed very different from the field-theoretic, operator-based approach of Schwinger and Tomonaga, but Freeman Dyson later showed that the two approaches were equivalent. Renormalization, the need to attach a physical meaning at certain divergences appearing in the theory through integrals, has subsequently become one of the fundamental aspects of quantum field theory and has come to be seen as a criterion for a theory's general acceptability. Even though renormalization works very well in practice, Feynman was never entirely comfortable with its mathematical validity, even referring to renormalization as a "shell game" and "hocus pocus".:128
QED has served as the model and template for all subsequent quantum field theories. One such subsequent theory is quantum chromodynamics, which began in the early 1960s and attained its present form in the 1975 work by H. David Politzer, Sidney Coleman, David Gross and Frank Wilczek. Building on the pioneering work of Schwinger, Gerald Guralnik, Dick Hagen, and Tom Kibble, Peter Higgs, Jeffrey Goldstone, and others, Sheldon Glashow, Steven Weinberg and Abdus Salam independently showed how the weak nuclear force and quantum electrodynamics could be merged into a single electroweak force.
Feynman's view of quantum electrodynamics.
Introduction.
Near the end of his life, Richard P. Feynman gave a series of lectures on QED intended for the lay public. These lectures were transcribed and published as Feynman (1985), "QED: The strange theory of light and matter", a classic non-mathematical exposition of QED from the point of view articulated below.
The key components of Feynman's presentation of QED are three basic actions.:85
These actions are represented in a form of visual shorthand by the three basic elements of Feynman diagrams: a wavy line for the photon, a straight line for the electron and a junction of two straight lines and a wavy one for a vertex representing emission or absorption of a photon by an electron. These can all be seen in the adjacent diagram.
It is important not to over-interpret these diagrams. Nothing is implied about "how" a particle gets from one point to another. The diagrams do "not" imply that the particles are moving in straight or curved lines. They do "not" imply that the particles are moving with fixed speeds. The fact that the photon is often represented, by convention, by a wavy line and not a straight one does "not" imply that it is thought that it is more wavelike than is an electron. The images are just symbols to represent the actions above: photons and electrons do, somehow, move from point to point and electrons, somehow, emit and absorb photons. We do not know how these things happen, but the theory tells us about the probabilities of these things happening.
As well as the visual shorthand for the actions Feynman introduces another kind of shorthand for the numerical quantities called probability amplitudes. The probability is the square of the total probability amplitude. If a photon moves from one place and time—in shorthand, A—to another place and time—in shorthand, B—the associated quantity is written in Feynman's shorthand as P(A to B). The similar quantity for an electron moving from C to D is written E(C to D). The quantity which tells us about the probability amplitude for the emission or absorption of a photon he calls 'j'. This is related to, but not the same as, the measured electron charge 'e'.:91
QED is based on the assumption that complex interactions of many electrons and photons can be represented by fitting together a suitable collection of the above three building blocks, and then using the probability amplitudes to calculate the probability of any such complex interaction. It turns out that the basic idea of QED can be communicated while making the assumption that the square of the total of the probability amplitudes mentioned above (P(A to B), E(A to B) and 'j') acts just like our everyday probability. (A simplification made in Feynman's book.) Later on, this will be corrected to include specifically quantum-style mathematics, following Feynman.
The basic rules of probability amplitudes that will be used are that a) if an event can happen in a variety of different ways then its probability amplitude is the sum of the probability amplitudes of the possible ways and b) if a process involves a number of independent sub-processes then its probability amplitude is the product of the component probability amplitudes.:93
Basic constructions.
Suppose we start with one electron at a certain place and time (this place and time being given the arbitrary label A) and a photon at another place and time (given the label B). A typical question from a physical standpoint is: 'What is the probability of finding an electron at C (another place and a later time) and a photon at D (yet another place and time)?'. The simplest process to achieve this end is for the electron to move from A to C (an elementary action) and for the photon to move from B to D (another elementary action). From a knowledge of the probability amplitudes of each of these sub-processes – E(A to C) and P(B to D) – then we would expect to calculate the probability amplitude of both happening together by multiplying them, using rule b) above. This gives a simple estimated overall probability amplitude, which is squared to give an estimated probability. But there are other ways in which the end result could come about. The electron might move to a place and time E where it absorbs the photon; then move on before emitting another photon at F; then move on to C where it is detected, while the new photon moves on to D. The probability of this complex process can again be calculated by knowing the probability amplitudes of each of the individual actions: three electron actions, two photon actions and two vertexes – one emission and one absorption. We would expect to find the total probability amplitude by multiplying the probability amplitudes of each of the actions, for any chosen positions of E and F. We then, using rule a) above, have to add up all these probability amplitudes for all the alternatives for E and F. (This is not elementary in practice, and involves integration.) But there is another possibility, which is that the electron first moves to G where it emits a photon which goes on to D, while the electron moves on to H, where it absorbs the first photon, before moving on to C. Again we can calculate the probability amplitude of these possibilities (for all points G and H). We then have a better estimation for the total probability amplitude by adding the probability amplitudes of these two possibilities to our original simple estimate. Incidentally the name given to this process of a photon interacting with an electron in this way is Compton scattering.
There are an "infinite number" of other intermediate processes in which more and more photons are absorbed and/or emitted. For each of these possibilities there is a Feynman diagram describing it. This implies a complex computation for the resulting probability amplitudes, but provided it is the case that the more complicated the diagram the less it contributes to the result, it is only a matter of time and effort to find as accurate an answer as one wants to the original question. This is the basic approach of QED. To calculate the probability of "any" interactive process between electrons and photons it is a matter of first noting, with Feynman diagrams, all the possible ways in which the process can be constructed from the three basic elements. Each diagram involves some calculation involving definite rules to find the associated probability amplitude.
That basic scaffolding remains when one moves to a quantum description but some conceptual changes are needed. One is that whereas we might expect in our everyday life that there would be some constraints on the points to which a particle can move, that is "not" true in full quantum electrodynamics. There is a possibility of an electron at A, or a photon at B, moving as a basic action to "any other place and time in the universe". That includes places that could only be reached at speeds greater than that of light and also "earlier times". (An electron moving backwards in time can be viewed as a positron moving forward in time.):89, 98–99
Probability amplitudes.
Quantum mechanics introduces an important change in the way probabilities are computed. Probabilities are still represented by the usual real numbers we use for probabilities in our everyday world, but probabilities are computed as the square of probability amplitudes. Probability amplitudes are complex numbers.
Feynman avoids exposing the reader to the mathematics of complex numbers by using a simple but accurate representation of them as arrows on a piece of paper or screen. (These must not be confused with the arrows of Feynman diagrams which are actually simplified representations in two dimensions of a relationship between points in three dimensions of space and one of time.) The amplitude arrows are fundamental to the description of the world given by quantum theory. No satisfactory reason has been given for "why" they are needed. But pragmatically we have to accept that they are an essential part of our description of all quantum phenomena. They are related to our everyday ideas of probability by the simple rule that the probability of an event is the square of the length of the corresponding amplitude arrow. So, for a given process, if two probability amplitudes, v and w, are involved, the probability of the process will be given either by
or
The rules as regards adding or multiplying, however, are the same as above. But where you would expect to add or multiply probabilities, instead you add or multiply probability amplitudes that now are complex numbers.
Addition and multiplication are familiar operations in the theory of complex numbers and are given in the figures. The sum is found as follows. Let the start of the second arrow be at the end of the first. The sum is then a third arrow that goes directly from the start of the first to the end of the second. The product of two arrows is an arrow whose length is the product of the two lengths. The direction of the product is found by adding the angles that each of the two have been turned through relative to a reference direction: that gives the angle that the product is turned relative to the reference direction.
That change, from probabilities to probability amplitudes, complicates the mathematics without changing the basic approach. But that change is still not quite enough because it fails to take into account the fact that both photons and electrons can be polarized, which is to say that their orientations in space and time have to be taken into account. Therefore P(A to B) actually consists of 16 complex numbers, or probability amplitude arrows.:120–121 There are also some minor changes to do with the quantity "j", which may have to be rotated by a multiple of 90° for some polarizations, which is only of interest for the detailed bookkeeping.
Associated with the fact that the electron can be polarized is another small necessary detail which is connected with the fact that an electron is a fermion and obeys Fermi–Dirac statistics. The basic rule is that if we have the probability amplitude for a given complex process involving more than one electron, then when we include (as we always must) the complementary Feynman diagram in which we just exchange two electron events, the resulting amplitude is the reverse – the negative – of the first. The simplest case would be two electrons starting at A and B ending at C and D. The amplitude would be calculated as the "difference", E(A to D) × E(B to C) − E(A to C) × E(B to D), where we would expect, from our everyday idea of probabilities, that it would be a sum.:112–113
Propagators.
Finally, one has to compute P (A to B) and E (C to D) corresponding to the probability amplitudes for the photon and the electron respectively. These are essentially the solutions of the Dirac Equation which describes the behavior of the electron's probability amplitude and the Klein–Gordon equation which describes the behavior of the photon's probability amplitude. These are called Feynman propagators. The translation to a notation commonly used in the standard literature is as follows:
where a shorthand symbol such as formula_4 stands for the four real numbers which give the time and position in three dimensions of the point labeled A.
Mass renormalization.
A problem arose historically which held up progress for twenty years: although we start with the assumption of three basic "simple" actions, the rules of the game say that if we want to calculate the probability amplitude for an electron to get from A to B we must take into account all the possible ways: all possible Feynman diagrams with those end points. Thus there will be a way in which the electron travels to C, emits a photon there and then absorbs it again at D before moving on to B. Or it could do this kind of thing twice, or more. In short we have a fractal-like situation in which if we look closely at a line it breaks up into a collection of "simple" lines, each of which, if looked at closely, are in turn composed of "simple" lines, and so on "ad infinitum". This is a very difficult situation to handle. If adding that detail only altered things slightly then it would not have been too bad, but disaster struck when it was found that the simple correction mentioned above led to "infinite" probability amplitudes. In time this problem was "fixed" by the technique of renormalization. However, Feynman himself remained unhappy about it, calling it a "dippy process".:128
Conclusions.
Within the above framework physicists were then able to calculate to a high degree of accuracy some of the properties of electrons, such as the anomalous magnetic dipole moment. However, as Feynman points out, it fails totally to explain why particles such as the electron have the masses they do. "There is no theory that adequately explains these numbers. We use the numbers in all our theories, but we don't understand them – what they are, or where they come from. I believe that from a fundamental point of view, this is a very interesting and serious problem.":152
Mathematics.
Mathematically, QED is an abelian gauge theory with the symmetry group U(1). The gauge field, which mediates the interaction between the charged spin-1/2 fields, is the electromagnetic field.
The QED Lagrangian for a spin-1/2 field interacting with the electromagnetic field is given by the real part of:78
where
Equations of motion.
To begin, substituting the definition of "D" into the Lagrangian gives us
Next, we can substitute this Lagrangian into the Euler–Lagrange equation of motion for a field:
to find the field equations for QED.
The two terms from this Lagrangian are then
Substituting these two back into the Euler–Lagrange equation (2) results in
with complex conjugate
Bringing the middle term to the right-hand side transforms this second equation into
The left-hand side is like the original Dirac equation and the right-hand side is the interaction with the electromagnetic field.
One further important equation can be found by substituting the above Lagrangian into another Euler–Lagrange equation, this time for the field, "A"μ:
The two terms this time are
and these two terms, when substituted back into (3) give us
Now, if we impose the Lorenz gauge condition, that the divergence of the four potential vanishes
then we get
which is a wave equation for the four potential, the QED version of the classical Maxwell equations in the Lorenz gauge. (In the above equation, the square represents the D'Alembert operator.)
Interaction picture.
This theory can be straightforwardly quantized by treating bosonic and fermionic sectors as free. This permits us to build a set of asymptotic states which can be used to start a computation of the probability amplitudes for different processes. In order to do so, we have to compute an evolution operator that, for a given initial state formula_19, will give a final state formula_20 in such a way to have:5
This technique is also known as the S-matrix. The evolution operator is obtained in the interaction picture where time evolution is given by the interaction Hamiltonian, which is the integral over space of the second term in the Lagrangian density given above::123
and so, one has:86
where "T" is the time ordering operator. This evolution operator only has meaning as a series, and what we get here is a perturbation series with the fine structure constant as the development parameter. This series is called the Dyson series.
Feynman diagrams.
Despite the conceptual clarity of this Feynman approach to QED, almost no early textbooks follow him in their presentation. When performing calculations it is much easier to work with the Fourier transforms of the propagators. Quantum physics considers particle's momenta rather than their positions, and it is convenient to think of particles as being created or annihilated when they interact. Feynman diagrams then "look" the same, but the lines have different interpretations. The electron line represents an electron with a given energy and momentum, with a similar interpretation of the photon line. A vertex diagram represents the annihilation of one electron and the creation of another together with the absorption or creation of a photon, each having specified energies and momenta.
Using Wick theorem on the terms of the Dyson series, all the terms of the S-matrix for quantum electrodynamics can be computed through the technique of Feynman diagrams. In this case rules for drawing are the following:801–802
To these rules we must add a further one for closed loops that implies an integration on momenta formula_24, since these internal ("virtual") particles are not constrained to any specific energy–momentum – even that usually required by special relativity (see this article for details).
From them, computations of probability amplitudes are straightforwardly given. An example is Compton scattering, with an electron and a photon undergoing elastic scattering. Feynman diagrams are in this case:158–159
and so we are able to get the corresponding amplitude at the first order of a perturbation series for the S-matrix:
from which we are able to compute the cross section for this scattering.
Renormalizability.
Higher order terms can be straightforwardly computed for the evolution operator but these terms display diagrams containing the following simpler ones:ch 10
that, being closed loops, imply the presence of diverging integrals having no mathematical meaning. To overcome this difficulty, a technique called renormalization has been devised, producing finite results in very close agreement with experiments. It is important to note that a criterion for theory being meaningful after renormalization is that the number of diverging diagrams is finite. In this case the theory is said to be renormalizable. The reason for this is that to get observables renormalized one needs a finite number of constants to maintain the predictive value of the theory untouched. This is exactly the case of quantum electrodynamics displaying just three diverging diagrams. This procedure gives observables in very close agreement with experiment as seen e.g. for electron gyromagnetic ratio.
Renormalizability has become an essential criterion for a quantum field theory to be considered as a viable one. All the theories describing fundamental interactions, except gravitation whose quantum counterpart is presently under very active research, are renormalizable theories.
Nonconvergence of series.
An argument by Freeman Dyson shows that the radius of convergence of the perturbation series in QED is zero. The basic argument goes as follows: if the coupling constant were negative, this would be equivalent to the Coulomb force constant being negative. This would "reverse" the electromagnetic interaction so that "like" charges would "attract" and "unlike" charges would "repel". This would render the vacuum unstable against decay into a cluster of electrons on one side of the universe and a cluster of positrons on the other side of the universe. Because the theory is 'sick' for any negative value of the coupling constant, the series do not converge, but are an asymptotic series.
From a modern perspective, we say that QED is not well defined as a quantum field theory to arbitrarily high energy. The coupling constant runs to infinity at finite energy, signalling a Landau pole. The problem is essentially that QED is not asymptotically free. This is one of the motivations for embedding QED within a Grand Unified Theory.

</doc>
<doc id="25270" url="http://en.wikipedia.org/wiki?curid=25270" title="Quine (computing)">
Quine (computing)

A quine is a non-empty computer program which takes no input and produces a copy of its own source code as its only output. The standard terms for these programs in the computability theory and computer science literature are "self-replicating programs", "self-reproducing programs", and "self-copying programs".
A quine is a fixed point of an execution environment, when the execution environment is viewed as a function. Quines are possible in any Turing complete programming language, as a direct consequence of Kleene's recursion theorem. For amusement, programmers sometimes attempt to develop the shortest possible quine in any given programming language.
The name "quine" was coined by Douglas Hofstadter, in his popular science book "", in the honor of philosopher Willard Van Orman Quine (1908–2000), who made an extensive study of indirect self-reference, and in particular for the following paradox-producing expression, known as Quine's paradox:
"Yields falsehood when preceded by its quotation" yields falsehood when preceded by its quotation.
In some languages, particularly scripting languages, an empty source file is a fixed point of the language, being a valid program that produces no output. Such an empty program, submitted as "the world's smallest self reproducing program", once won the "worst abuse of the rules" prize in the International Obfuscated C Code Contest.
History.
The idea of self-reproducing automata came from the dawn of computing, if not before. John Von Neumann himself theorized about them. Later they were written about in Paul Bratley and Jean Millo's article "Computer Recreations: Self-Reproducing Automata" in 1972.
Bratley first became interested in self-reproducing programs after seeing the first known such program written in Atlas Autocode at Edinburgh in the 1960s by the University of Edinburgh lecturer and researcher Hamish Dewar. This program appears below:
 %BEGIN
 !THIS IS A SELF-REPRODUCING PROGRAM
 %ROUTINESPEC R
 R
 PRINT SYMBOL(39)
 R
 PRINT SYMBOL(39)
 NEWLINE
 %CAPTION %END~
 %CAPTION %ENDOFPROGRAM~
 %ROUTINE R
 %PRINTTEXT '
 %BEGIN
 !THIS IS A SELF-REPRODUCING PROGRAM
 %ROUTINESPEC R
 R
 PRINT SYMBOL(39)
 R
 PRINT SYMBOL(39)
 NEWLINE
 %CAPTION %END~
 %CAPTION %ENDOFPROGRAM~
 %ROUTINE R
 %PRINTTEXT '
 %END
 %ENDOFPROGRAM
Examples.
The following Java code demonstrates the basic structure of a quine.
The source code contains a string array of itself, which is output twice, once inside quotation marks.
The following short Java quine can be compiled at the command line - but it depends on the java VM version, it doesn't work with current JVMs. it makes use of multiple tricks of the Java language, and thus is much harder to read. However, it relies on the same principle of code repetition within string literals.
The following example is in Javascool.
The same idea is used in SQL quine:
A very concise quine with the same basic structure can be written in Lua:
And in Python:
A JavaScript example:
And, less concisely, in R:
And in Go: http://play.golang.org/p/pVBds0oHrO
Quines can take advantage of codice_1. For example, this Ruby quine:
"Cheating" quines.
Quines, per definition, cannot receive "any" form of input, including reading a file, which means a quine is considered to be "cheating" if it looks at its own source code. The following shell script is not a quine:
The above also applies to this JavaScript code:
Ouroboros programs.
The quine concept can be extended to multiple levels or recursion, originating what has been called "ouroboros programs", or quine-relays. This should not be confused with Multiquines.
Example.
This Java program outputs the source for a C++ program that outputs the original Java code.
Such programs have been produced with various cycle lengths:
Multiquines.
David Madore, creator of Unlambda, describes multiquines as follows:
"A multiquine is a set of r different programs (in r different languages — without this condition we could take them all equal to a single quine), each of which is able to print any of the r programs (including itself) according to the command line argument it is passed. (Note that cheating is not allowed: the command line arguments must not be too long — passing the full text of a program is considered cheating)."
A multiquine consisting of 2 languages (or biquine) would be a program which:
A biquine could then be seen as a set of two programs, both of which are able to print either of the two, depending on the command line argument supplied.
A 5-part multiquine (or pentaquine) has been produced with Python, Perl, C, NewLISP, and F#
Radiation-hardened.
A radiation-hardened quine is a quine that can have any single character removed and still produce the original program with no missing character. Of necessity, such quines are much more convoluted than ordinary quines, as is seen by the following example in Ruby:

</doc>
<doc id="25271" url="http://en.wikipedia.org/wiki?curid=25271" title="Field of fractions">
Field of fractions

In abstract algebra, the field of fractions of an integral domain is the smallest field in which it can be embedded. The elements of the field of fractions of the integral domain formula_1 are equivalence classes (see the construction below) written as formula_2 with formula_3 and formula_4 in formula_1 and formula_6. The field of fractions of formula_1 is sometimes denoted by formula_8 or formula_9.
Mathematicians refer to this construction as the field of fractions, fraction field, field of quotients, or quotient field. All four are in common usage. The expression "quotient field" may sometimes run the risk of confusion with the quotient of a ring by an ideal, which is a quite different concept.
Construction.
Let formula_1 be any integral domain. For formula_17 with formula_18, the fraction formula_19 denotes the equivalence class of pairs formula_20, where formula_20 is equivalent to formula_22 if and only if formula_23.
The "field of fractions" formula_8 is defined as the set of all such fractions formula_19.
The sum of formula_19 and formula_29 is defined as formula_30, and the product of formula_19 and formula_29 is defined as formula_33 (one checks that these are well defined).
The embedding of formula_1 in formula_8 maps each formula_36 in formula_1 to the fraction formula_38 for any nonzero formula_39 (the equivalence class is independent of the choice formula_40). This is modelled on the identity formula_41. If additionally, formula_1 contains a multiplicative identity (that is, formula_1 is an integral domain), then formula_44.
The field of fractions of formula_1 is characterised by the following universal property: if formula_46 is an injective ring homomorphism from formula_1 into a field formula_48, then there exists a unique ring homomorphism formula_49 which extends formula_50.
There is a categorical interpretation of this construction. Let formula_51 be the category of integral domains and injective ring maps. The functor from formula_51 to the category of fields which takes every integral domain to its fraction field and every homomorphism to the induced map on fields (which exists by the universal property) is the left adjoint of the forgetful functor from the category of fields to formula_51.
A multiplicative identity is not required for the role of the integral domain; this construction can be applied to any nonzero commutative rng with no nonzero zero divisors.
Generalisation.
For any commutative ring formula_1 and any multiplicative set formula_55 in formula_1, the localization formula_55formula_58formula_1 is the commutative ring consisting of fractions formula_60 with formula_61 and formula_62,
where now formula_63 is equivalent to formula_64 if and only if there exists formula_65 such that formula_66.
Two special cases of this are notable:

</doc>
<doc id="25272" url="http://en.wikipedia.org/wiki?curid=25272" title="Quadratic reciprocity">
Quadratic reciprocity

In number theory, the law of quadratic reciprocity is a theorem about modular arithmetic that gives conditions for the solvability of quadratic equations modulo prime numbers. There are a number of equivalent statements of the theorem. One version of the law states that
for "p" and "q" odd prime numbers, and formula_2 denoting the Legendre symbol.
This law, combined with the properties of the Legendre symbol, means that any Legendre symbol formula_3 can be calculated. This makes possible to determine for any quadratic equation formula_4, where "p" an odd prime, if it has a solution. However, it does not provide any help at all for actually "finding" the solution. (The article on quadratic residues discusses algorithms for this.)
The theorem was conjectured by Euler and Legendre and first proven by Gauss. He refers to it as the "fundamental theorem" in the "Disquisitiones Arithmeticae" and his papers, writing
Privately he referred to it as the "golden theorem." He published six proofs, and two more were found in his posthumous papers. There are now over 200 published proofs.
The first section of this article gives a special case of quadratic reciprocity that is representative of the general case. The second section gives the formulations of quadratic reciprocity found by Legendre and Gauss.
Motivating example.
Consider the polynomial "f"("n") = "n"2 − 5 and its values for "n" = 1, 2, 3, 4, ... The prime factorizations of these values are given as follows:
A striking feature of the data is that with the exceptions of 2 and 5, "the prime numbers that appear as factors are precisely those with final digit 1 or 9."
Another way of phrasing this is that the primes "p" for which there exists an "n" such that "n"2 ≡ 5 (mod "p") are precisely 2, 5, and those primes "p" that are ≡ 1 or 4 (mod 5).
The law of quadratic reciprocity gives a similar characterization of prime divisors of "f"("n") = "n"2 − "c" for any integer "c".
Terminology, data, and two statements of the theorem.
A quadratic residue (mod "n") is any number congruent to a square (mod "n"). A quadratic nonresidue (mod "n") is any number that is not congruent to a square (mod "n"). The adjective "quadratic" can be dropped if the context makes it clear that it is implied. When working modulo primes (as in this article), it is usual to treat zero as a special case. By doing so, the following statements become true:
Table of quadratic residues.
This table is complete for odd primes less than 50. To check whether a number "m" is a quadratic residue mod one of these primes "p", find "a" ≡ "m" (mod "p") and 0 ≤ "a" < "p". If "a" is in row "p", then "m" is a residue (mod "p"); if "a" is not in row "p" of the table, then "m" is a nonresidue (mod "p").
The quadratic reciprocity law is the statement that certain patterns found in the table are true in general.
In this article, "p" and "q" always refer to distinct positive odd prime numbers.
−1 and the first supplement.
First of all, for which prime numbers is −1 a quadratic residue? Examining the table, we find −1 in rows 5, 13, 17, 29, 37, and 41 but not in rows 3, 7, 11, 19, 23, 31, 43 or 47.
The former primes are all ≡ 1 (mod 4), and the latter are all ≡ 3 (mod 4). This leads to
The first supplement to quadratic reciprocity:
±2 and the second supplement.
For which prime numbers is 2 a quadratic residue? Examining the table, we find 2 in rows 7, 17, 23, 31, 41, and 47, but not in rows 3, 5, 11, 13, 19, 29, 37, or 43.
The former primes are all ≡ ±1 (mod 8), and the latter are all ≡ ±3 (mod 8). This leads to
The second supplement to quadratic reciprocity:
−2 is in rows 3, 11, 17, 19, 41, 43, but not in rows 5, 7, 13, 23, 29, 31, 37, or 47. The former are ≡ 1 or ≡ 3 (mod 8), and the latter are ≡ 5 or ≡ 7 (mod 8).
±3.
3 is in rows 11, 13, 23, 37, and 47, but not in rows 5, 7, 17, 19, 29, 31, 41, or 43.
The former are ≡ ±1 (mod 12) and the latter are all ≡ ±5 (mod 12).
−3 is in rows 7, 13, 19, 31, 37, and 43 but not in rows 5, 11, 17, 23, 29, 41, or 47. The former are ≡ 1 (mod 3) and the latter ≡ 2 (mod 3).
Since the only residue (mod 3) is 1, we see that −3 is a quadratic residue modulo every prime which is a residue (mod 3).
±5.
5 is in rows 11, 19, 29, 31, and 41 but not in rows 3, 7, 13, 17, 23, 37, 43, or 47.
The former are ≡ ±1 (mod 5) and the latter are ≡ ±2 (mod 5).
Since the only residues (mod 5) are ±1, we see that 5 is a quadratic residue modulo every prime which is a residue (mod 5).
−5 is in rows 3, 7, 23, 29, 41, 43, and 47 but not in rows 11, 13, 17, 19, 31, or 37. The former are ≡ 1, 3, 7, 9 (mod 20) and the latter are ≡ 11, 13, 17, 19 (mod 20).
Gauss's version.
The observations about −3 and +5 continue to hold: −7 is a residue (mod "p") if and only if "p" is a residue (mod 7), −11 is a residue (mod "p") if and only if "p" is a residue (mod 11), +13 is a residue (mod "p") if and only if "p" is a residue (mod 13), ...
The more complicated-looking rules for the quadratic characters of +3 and −5, which depend upon congruences (mod 12) and (mod 20) respectively, are simply the ones for −3 and +5 working with the first supplement. 
For example, for −5 to be a residue (mod "p"), either both 5 and −1 have to be residues (mod "p") or they both have to be nonresidues:
i.e., "p" has to be ≡ ±1 (mod 5) "and" ≡ 1 (mod 4), which is the same thing as "p" ≡ 1 or 9 (mod 20), or "p" has to be ≡ ±2 mod 5 "and" ≡ 3 mod 4, which is the same as "p" ≡ 3 or 7 (mod 20). See Chinese remainder theorem.
The generalization of the rules for −3 and +5 is Gauss's statement of quadratic reciprocity:
These statements may be combined:
Legendre's version.
Another way to organize the data is to see which primes are residues mod which other primes, as illustrated in the above table. The entry in row "p" column "q" is R if "q" is a quadratic residue (mod "p"); if it is a nonresidue the entry is N.
If the row, or the column, or both, are ≡ 1 (mod 4) the entry is blue or green; if both row and column are ≡ 3 (mod 4), it is yellow or orange.
The blue and green entries are symmetric around the diagonal: The entry for row "p", column "q" is R (resp N) if and only if the entry at row "q", column "p", is R (resp N).
The yellow and orange ones, on the other hand, are antisymmetric: The entry for row "p", column "q" is R (resp N) if and only if the entry at row "q", column "p", is N (resp R).
This observation is Legendre's statement of quadratic reciprocity:
It is a simple exercise to prove that Legendre's and Gauss's statements are equivalent – it requires no more than the first supplement and the facts about multiplying residues and nonresidues.
Connection with cyclotomy.
The early proofs of quadratic reciprocity are relatively unilluminating. The situation changed when Gauss used Gauss sums to show that quadratic fields are subfields of cyclotomic fields, and implicitly deduced quadratic reciprocity from a reciprocity theorem for cyclotomic fields. His proof was cast in modern form by later algebraic number theorists. This proof served as a template for class field theory, which can be viewed as a vast generalization of quadratic reciprocity
Robert Langlands formulated the Langlands program, which gives a conjectural vast generalization of class field theory. He wrote:
History and alternative statements.
There are a number of ways to state the theorem. Keep in mind that Euler and Legendre did not have Gauss's congruence notation, nor did Gauss have the Legendre symbol.
In this article "p" and "q" always refer to distinct positive odd primes.
Fermat.
Fermat proved (or claimed to have proved) a number of theorems about expressing a prime by a quadratic form:
He did not state the law of quadratic reciprocity, although the cases −1, ±2, and ±3 are easy deductions from these and other of his theorems.
He also claimed to have a proof that if the prime number "p" ends with 7, (in base 10) and the prime number "q" ends in 3, and "p" ≡ "q" ≡ 3 (mod 4), then
Euler conjectured, and Lagrange proved, that 
Proving these and other statements of Fermat was one of the things that led mathematicians to the reciprocity theorem.
Euler.
Translated into modern notation, Euler stated:
This is equivalent to quadratic reciprocity.
He could not prove it, but he did prove the second supplement.
Legendre and his symbol.
Fermat proved that if "p" is a prime number and "a" is an integer, 
Thus, if "p" does not divide "a", 
Legendre lets "a" and "A" represent positive primes ≡ 1 (mod 4) and "b" and "B" positive primes ≡ 3 (mod 4), and sets out a table of eight theorems that together are equivalent to quadratic reciprocity:
<br>
He says that since expressions of the form 
This is now known as the Legendre symbol, and an equivalent definition is used today: for all integers "a" and all odd primes "p"
Legendre's version of quadratic reciprocity.
He notes that these can be combined:
A number of proofs, especially those based on Gauss's Lemma, explicitly calculate this formula.
The supplementary laws using Legendre symbols.
Legendre's attempt to prove reciprocity is based on a theorem of his:
formula_34
E.g., Theorem I is handled by letting "a" ≡ 1 and "b" ≡ 3 (mod 4) be primes and assuming that formula_35 and, contrary the theorem, that formula_36 Then formula_37 has a solution, and taking congruences (mod 4) leads to a contradiction.
This technique doesn't work for Theorem VIII. Let "b" ≡ "B" ≡ 3 (mod 4), and assume formula_38 Then if there is another prime "p" ≡ 1 (mod 4) such that formula_39 the solvability of formula_40 leads to a contradiction (mod 4). But Legendre was unable to prove there has to be such a prime p; he was later able to show that all that is required is "Legendre's lemma":
but he couldn't prove that either. Hilbert symbol (below) discusses how techniques based on the existence of solutions to formula_42 can be made to work.
Gauss.
Gauss first proves the supplementary laws. He sets the basis for induction by proving the theorem for ±3 and ±5. Noting that it is easier to state for −3 and +5 than it is for +3 or −5, he states the general theorem in the form:
In the next sentence, he christens it the "fundamental theorem" (Gauss never used the word "reciprocity").
Introducing the notation "a" R "b" (resp. "a" N "b") to mean "a" is a quadratic residue (resp. nonresidue) (mod "b"), and letting "a", "a"′, etc. represent positive primes ≡ 1 (mod 4) and "b", "b"′, etc. positive primes ≡ 3 (mod 4), he breaks it out into the same 8 cases as Legendre:
In the next Article he generalizes this to what are basically the rules for the Jacobi symbol (below). Letting "A", "A"′, etc. represent any (prime or composite) positive numbers ≡ 1 (mod 4) and "B", "B"′, etc. positive numbers ≡ 3 (mod 4):
All of these cases take the form "if a prime is a residue (mod a composite), then the composite is a residue or nonresidue (mod the prime), depending on the congruences (mod 4)". He proves that these follow from cases 1) - 8).
Gauss needed, and was able to prove, a lemma similar to the one Legendre needed:
The proof of quadratic reciprocity is by complete induction (i.e. assuming it is true for all numbers less than "n" allows the deduction it is true for "n") for each of the cases 1) to 8).
Gauss's version in Legendre symbols.
These can be combined:
A number of proofs of the theorem, especially those based on Gauss sums, or the splitting of primes in algebraic number fields, derive this formula.
Other statements.
Note that the statements in this section are equivalent to quadratic reciprocity: if, for example, Euler's version is assumed, the Legendre-Gauss version can be deduced from it, and vice versa.
Euler.
This form of quadratic reciprocity is derived from Euler's work:
Euler's statement can be proved by using Gauss's lemma.
Gauss.
Gauss's fourth proof consists of proving this theorem (by comparing two formulas for the value of Gauss sums) and then restricting it to two primes:
Let "a", "b", "c", ... be unequal positive odd primes, whose product is "n", and let "m" be the number of them that are ≡ 3 (mod 4); check whether "n"/"a" is a residue of "a", whether "n"/"b" is a residue of "b", ... The number of nonresidues found will be even when "m" ≡ 0, 1 (mod 4), and it will be odd if "m" ≡ 2, 3 (mod 4).
 He gives the example. Let "a" = 3, "b" = 5, "c" = 7, and "d" = 11. Three of these, 3, 7, and 11 ≡ 3 (mod 4), so "m" ≡ 3 (mod 4).
<br>
5×7×11 R 3;  3×7×11 R 5;  3×5×11 R 7;  and  3×5×7 N 11, so there are an odd number of nonresidues.
Eisenstein.
Eisenstein formulates this:
Mordell.
Mordell proved the following to be equivalent to quadratic reciprocity:
Jacobi symbol.
The Jacobi symbol is a generalization of the Legendre symbol; the main difference is that the bottom number has to be positive and odd, but does not have to be prime. If it is prime, the two symbols agree. It obeys the same rules of manipulation as the Legendre symbol. In particular
and if both numbers are positive and odd (this is sometimes called "Jacobi's reciprocity law"):
<br>
However, if the Jacobi symbol is +1 and the bottom number is composite, it does not necessarily mean that the top number is a quadratic residue of the bottom one. Gauss's cases 9) - 14) above can be expressed in terms of Jacobi symbols:
and since "p" is prime the left hand side is a Legendre symbol, and we know whether "M" is a residue (mod "p") or not.
The formulas listed in the preceding section are true for Jacobi symbols as long as the symbols are defined. Euler's formula may be written
For example, 
formula_57
and 2 is a residue mod the primes 7, 23 and 31: 32 ≡ 2 (mod 7), 52 ≡ 2 (mod 23), and 82 ≡ 2 (mod 31), but 2 is not a quadratic residue (mod 5), so it can't be one (mod 15). This is related to the problem Legendre had: if we know that formula_58, we know that "a" is a nonresidue modulo every prime in the arithmetic series "m" + 4"a", "m" + 8"a", ..., if there "are" any primes in this series, but that wasn't proved until decades after Legendre.
Eisenstein's formula requires relative primality conditions (which are true if the numbers are prime)
Hilbert symbol.
The quadratic reciprocity law can be formulated in terms of the Hilbert symbol formula_62 where "a" and "b" are any 
two nonzero rational numbers and "v" runs over all the non-trivial absolute values of the rationals (the archimedean one and 
the "p"-adic absolute values for primes "p"). The Hilbert symbol formula_62 is 1 or −1. It is defined to be 1 if and only if the equation formula_64 has a solution in the completion of the rationals at "v" other than formula_65. The Hilbert reciprocity law states that formula_62, for fixed "a" and "b" and varying "v", is 1 for 
all but finitely many "v" and the product of formula_62 over all "v" is 1. (This formally 
resembles the residue theorem from complex analysis.)
The proof of Hilbert reciprocity reduces to checking a few special cases, and the non-trivial cases 
turn out to be equivalent to the main law and the two supplementary laws of quadratic reciprocity 
for the Legendre symbol. There is no kind of reciprocity in the Hilbert reciprocity law; its name 
simply indicates the historical source of the result in quadratic reciprocity. Unlike quadratic reciprocity, 
which requires sign conditions (namely positivity of the primes involved) and a special treatment of the prime 2, 
the Hilbert reciprocity law treats all absolute values of the rationals on an equal footing. Therefore 
it is a more natural way of expressing quadratic reciprocity with a view towards generalization: the 
Hilbert reciprocity law extends with very few changes to all global fields and this extension can 
rightly be considered a generalization of quadratic reciprocity to all global fields.
Other rings.
There are also quadratic reciprocity laws in rings other than the integers.
Gaussian integers.
In his second monograph on quartic reciprocity Gauss stated quadratic reciprocity for the ring Z["i"] of Gaussian integers, saying that it is a corollary of the biquadratic law in Z["i"], but did not provide a proof of either theorem. Peter Gustav Lejeune Dirichlet showed that the law in Z["i"] can be deduced from the law for Z without using biquadratic reciprocity.
For an odd Gaussian prime π and a Gaussian integer α, gcd(α, π) = 1, define the quadratic character for Z["i"] by the formula
Let λ = "a" + "b i" and μ = "c" + "d i" be distinct Gaussian primes where "a" and "c" are odd and "b" and "d" are even. Then
where formula_70 is the Jacobi symbol for Z.
Eisenstein integers.
The ring of Eisenstein integers is Z[ω], where formula_71 is a cube root of 1. (See the articles on Eisenstein integer and cubic reciprocity for definitions and notations).
For an Eisenstein prime π, Nπ ≠ 3 and an Eisenstein integer α, gcd(α, π) = 1, define the quadratic character for Z[ω] by the formula
Let λ = "a" + "b" ω and μ = "c" + "d" ω be distinct Eisenstein primes where "a" and "c" are not divisible by 3 and "b" and "d" are divisible by 3. Eisenstein proved 
where formula_70 is the Jacobi symbol for Z.
Imaginary quadratic fields.
The laws in Z["i"] and Z[ω] are special cases of more general laws that hold for the ring of integers in any imaginary quadratic number field.
Let "k" be an imaginary quadratic number field with ring of integers formula_75 
For a prime ideal formula_76 with odd norm formula_77   and formula_78  define the quadratic character for formula_79 by the formula
for an arbitrary ideal formula_81 factored into prime ideals formula_82 define
and for formula_84 define
Let formula_86 be an integral basis of formula_87
For formula_88 with odd norm Nν, define (ordinary) integers "a", "b", "c", "d" by the equations, 
and define a function χ(ν) where ν has odd norm by
If "m" = "Nμ" and "n" = "Nν" are both odd, Herglotz proved
Also, if formula_92
Polynomials over a finite field.
Let F be a finite field with "q" = "p""n" elements, where "p" is an odd prime number and "n" is positive, and let F["x"] be the ring of polynomials in one variable with coefficients in F. If formula_94 and "f" is irreducible, monic, and has positive degree, define the quadratic character formula_95 for F["x"] in the usual manner:
If formula_97 is a product of monic irreducibles let
Dedekind proved that if formula_94 are monic and have positive degrees,
Higher powers.
The attempt to generalize quadratic reciprocity for powers higher than the second was one of the main goals that led 19th century mathematicians, including Carl Friedrich Gauss, Peter Gustav Lejeune Dirichlet, Carl Gustav Jakob Jacobi, Gotthold Eisenstein, Richard Dedekind, Ernst Kummer, and David Hilbert to the study of general algebraic number fields and their rings of integers; specifically Kummer invented ideals in order to state and prove higher reciprocity laws.
The ninth in the list of 23 unsolved problems which David Hilbert proposed to the Congress of Mathematicians in 1900 asked for the 
"Proof of the most general reciprocity law [f]or an arbitrary number field". In 1923 Artin, building upon work by Furtwängler, Takagi, Hasse and others, discovered a general theorem for which all known reciprocity laws are special cases; he proved it in 1927.
The links below provide more detailed discussions of these theorems.
References.
The "Disquisitiones Arithmeticae" has been translated (from Latin) into English and German. The German edition includes all of Gauss's papers on number theory: all the proofs of quadratic reciprocity, the determination of the sign of the Gauss sum, the investigations into biquadratic reciprocity, and unpublished notes. Footnotes referencing the "Disquisitiones Arithmeticae" are of the form "Gauss, DA, Art. "n"".
The two monographs Gauss published on biquadratic reciprocity have consecutively numbered sections: the first contains §§ 1–23 and the second §§ 24–76. Footnotes referencing these are of the form "Gauss, BQ, § "n"". 
These are in Gauss's "Werke", Vol II, pp. 65–92 and 93–148. German translations are in pp. 511–533 and 534–586 of "Untersuchungen über höhere Arithmetik."
Every textbook on elementary number theory (and quite a few on algebraic number theory) has a proof of quadratic reciprocity. Two are especially noteworthy:
Franz Lemmermeyer's "Reciprocity Laws: From Euler to Eisenstein" has "many" proofs (some in exercises) of both quadratic and higher-power reciprocity laws and a discussion of their history. Its immense bibliography includes literature citations for 196 different published proofs for the quadratic reciprocity law.
Kenneth Ireland and Michael Rosen's "A Classical Introduction to Modern Number Theory" also has many proofs of quadratic reciprocity (and many exercises), and covers the cubic and biquadratic cases as well. Exercise 13.26 (p.202) says it all

</doc>
<doc id="25274" url="http://en.wikipedia.org/wiki?curid=25274" title="Quantum information">
Quantum information

In physics and computer science, quantum information is information that is held in the state of a quantum system. Quantum information is the basic entity that is studied in the growing field of quantum information theory, and manipulated using the engineering techniques of quantum information processing. Much like classical information can be processed with digital computers, transmitted from place to place, manipulated with algorithms, and analyzed with the mathematics of computer science, so also analogous concepts apply to quantum information.
Quantum information.
Quantum information differs strongly from classical information, epitomized by the bit, in many striking and unfamiliar ways. Among these are the following: 
The study of all of the above topics and differences comprises quantum information theory.
Quantum information theory.
The theory of quantum information is a result of the effort to generalize classical information theory to the quantum world. Quantum information theory aims to investigate the following question:
How is information stored in a state of a quantum system?
As mentioned in the introduction, an arbitrary quantum state cannot be precisely converted in classical bits; this is the content of the no-teleportation theorem.
The information content of a message "M" can be measured in terms of the minimum number "n" of qubits needed to encode the message. Such a message "M" is encoded with "n" qubits and "n"2 classical bits that describe the relative arrangement of the "n" qubits. The qubit is the smallest possible unit of quantum information.
Quantum information can be transmitted through quantum channels, which do have a finite capacity. This is analogous to the classical case, where the noisy-channel coding theorem defines the maximum channel capacity of a classical communications channel. An important breakthrough for the theory of quantum information occurred when quantum error correction codes and fault-tolerant quantum computation schemes were discovered.
Quantum information can be manipulated and processed using quantum logic gates, in rough analog to the processing of classical information with digital circuits.
Journals.
Many journals publish research in quantum information science, although only a few are dedicated to this area. Among these are 
See also.
</dl>

</doc>
<doc id="25275" url="http://en.wikipedia.org/wiki?curid=25275" title="Quinolone">
Quinolone

The quinolones are a family of synthetic broad-spectrum antibacterial drugs.
The first generation of quinolones began with the introduction of nalidixic acid in 1962 for treatment of urinary tract infections in humans. Nalidixic acid was discovered by George Lesher and coworkers in a distillate during an attempt at chloroquine synthesis. Quinolones exert their antibacterial effect by preventing bacterial DNA from unwinding and duplicating. The majority of quinolones in clinical use belong to the subset fluoroquinolones, which have a fluorine atom attached to the central ring system, typically at the 6-position or C-7 position.
Medical uses.
Fluoroquinolones are broad-spectrum antibiotics (effective for both Gram-negative and Gram-positive bacteria) that play an important role in treatment of serious bacterial infections, especially hospital-acquired infections and others in which resistance to older antibacterial classes is suspected. Because the use of broad-spectrum antibiotics encourages the spread of multidrug-resistant strains and the development of "Clostridium difficile" infections, treatment guidelines from the Infectious Disease Society of America, the American Thoracic Society, and other professional organizations recommend minimizing the use of fluoroquinolones and other broad-spectrum antibiotics in less severe infections and in those in which risk factors for multidrug resistance are not present.
Fluoroquinolones are featured prominently in The American Thoracic Society guidelines for the treatment of hospital-acquired pneumonia. The Society recommends fluoroquinolones not be used as a first-line agent for community-acquired pneumonia, instead recommending macrolide or doxycycline as first-line agents. The Drug-Resistant "Streptococcus pneumoniae" Working Group recommends fluoroquinolones be used for the ambulatory treatment of community-acquired pneumonia only after other antibiotic classes have been tried and failed, or in those with demonstrated drug-resistant "Streptococcus pneumoniae".
Fluoroquinolones are often used for genitourinary infections, and are widely used in the treatment of hospital-acquired infections associated with urinary catheters. In community-acquired infections, they are recommended only when risk factors for multidrug resistance are present or after other antibiotic regimens have failed. However, for serious acute cases of pyelonephritis or bacterial prostatitis where the patient may need to be hospitalised, fluoroquinolones are recommended as first-line therapy.
Due to sickle-cell disease patients' being at increased risk for developing osteomyelitis from the "Salmonella "genus, fluoroquinolones are the "drugs of choice" due to their ability to enter bone tissue without chelating it, as tetracyclines are known to do.
Specific populations.
Children.
The use of fluoroquinolones to treat infections in children is controversial.
In most countries, fluoroquinolones are approved for use in children only under narrow circumstances, owing in part to the observation of high rates of musculoskeletal adverse events in fluoroquinolone treated juvenile animals. In the UK, the prescribing indications for fluoroquinolones for children is severely restricted. Only inhalant anthrax and pseudomonal infections in cystic fibrosis infections are licensed indications in the UK due to ongoing safety concerns. In a study comparing the safety and efficacy of levofloxacin to that of azithromycin or the ceftriaxone in 712 children with community-acquired pneumonia, serious adverse events were experienced by 6% of those treated with levofloxacin and 4% of those treated with comparator antibiotics. Most of these were considered by the treating physician to be unrelated or doubtfully related to the study drug. Two deaths were observed in the levofloxacin group, neither of which was thought to be treatment-related. Spontaneous reports to the FDA Adverse Effects Reporting System at the time of the 20 September 2011 FDA Pediatric Drugs Advisory Committee include musculoskeletal events (39, including 5 cases of tendon rupture) and central nervous system events (19, including 5 cases of seizures) as the most common spontaneous reports between April 2005 and March 2008. An estimated 130,000 pediatric prescriptions for levofloxacin were filled on behalf of 112,000 pediatric patients during that period.
A number of recent meta analyses have concluded that fluoroquinolones pose little or no additional risk to children compared to other antibiotic classes.
Current recommendations by the American Academy of Pediatrics state that the use of fluoroquinolines in children may be appropriate when the infection is caused by multidrug-resistant bacteria, or when alternative treatment options require parenteral administration and oral therapy is preferred.
Adverse effects.
In general, fluoroquinolones are well tolerated, with most side effects being mild to moderate. On occasion, serious adverse effects occur. Common side effects include gastrointestinal effects such as nausea, vomiting, and diarrhea, as well as headache and insomnia.
The overall rate of adverse events in patients treated with fluoroquinolones is roughly similar to that seen in patients treated with other antibiotic classes. A U.S. Centers for Disease Control study found patients treated with fluoroquinolones experienced adverse events severe enough to lead to an emergency department visit more frequently than those treated with cephalosporins or macrolides, but less frequently than those treated with penicillins, clindamycin, sulfonamides, or vancomycin.
Postmarketing surveillance has revealed a variety of relatively rare but serious adverse effects that are associated with all members of the fluoroquinolone antibacterial class. Among these, tendon problems and exacerbation of the symptoms of the neurological disorder myasthenia gravis are the subject of "black box" warnings in the United States. Quinolones are associated with an increased risk of tendinitis and tendon rupture in all age groups. This side effect is most common but not limited to the Achilles tendon. Fluoroquinolone-associated tendinopathy symptoms have occurred as early as 2 hours after the initial fluoroquinolone exposure and as late as 6 months after the medication was discontinued. The most severe form of tendonopathy associated with fluoroquinolone administration is tendon rupture, which in the great majority of cases involves the Achilles tendon. Younger people typically experience good recovery, but permanent disability is possible, and is more likely in older patients. The overall frequency of fluoroquinolone-associated Achilles tendon rupture in patients treated with ciprofloxacin or levofloxacin has been estimated at 17 per 100,000 treatments (three times the rate in people without fluoroquinolone exposure). Risk is substantially elevated in the elderly and in those with recent exposure to topical or systemic corticosteroid therapy. Simultaneous use of corticosteroids is present in almost one-third of quinolone-associated tendon rupture. Other risk factors include patients with kidney, heart and lung transplants,strenuous physical activity during or immediately after treatment, renal failure or previous tendon disorders like rheumatoid arthritis. Some experts have advised avoidance of fluoroquinolones in athletes.
Fluoroquinolones prolong the heart's QT interval by blocking voltage-gated potassium channels. Prolongation of the QT interval can lead to torsades de pointes, a life-threatening arrhythmia, but in practice this appears relatively uncommon in part because the most widely prescribed fluoroquinolones (ciprofloxacin and levofloxacin) only minimally prolong the QT interval.
"Clostridium difficile"-associated diarrhea may occur in connection with the use of any antibacterial drug, especially those with a broad spectrum of activity such as clindamycin, cephalosporins, and fluoroquinolones. Fluoroquinoline treatment is associated with risk that is similar to or less than that associated with broad spectrum cephalosporins. Fluoroquinoline administration may be associated with the acquisition and outgrowth of a particularly virulent "Clostridium" strain.
The U.S. prescribing information contains a warning regarding uncommon cases of peripheral neuropathy, which can be permanent. Other nervous system effects include insomnia, restlessness, and rarely, seizure, convulsions, and psychosis Other rare and serious adverse events have been observed with varying degrees of evidence for causation.
Events that may occur in acute overdose are rare, and include renal failure and seizure. Susceptible groups of patients, such as children and the elderly, are at greater risk of adverse reactions during therapeutic use.
Contraindications.
Quinolones are contraindicated if a patient has epilepsy, QT prolongation, pre-existing CNS lesions, or CNS inflammation, or the patient has suffered a stroke. They are best avoided in the athlete population. Safety concerns exist for fluoroquinolone use during pregnancy, so they are contraindicated except for when no other safe alternative antibiotic exists. However, one meta-analysis looking at the outcome of pregnancies involving quinolone use in the first trimester found no increased risk of malformations. They are also contraindicated in children due to the risks of damage to the musculoskeletal system. Their use in children is not absolutely contraindicated, however. For certain severe infections where other antibiotics are not an option, their use can be justified. Quinolones should also not be given to people with a known hypersensitivity to the drug.
Pharmacology.
The basic pharmacophore, or active structure, of the fluoroquinolone class is based upon the quinoline ring system. The addition of the fluorine atom at C6 distinguishes the successive-generation fluoroquinolones from the first-generation of quinolones. The addition of the C6 fluorine atom has since been demonstrated to not be required for the antibacterial activity of this class ("circa" 1997).
Mechanism of action.
First and second generation fluoroquinolones selectively inhibit the topoisomerase II ligase domain, leaving the two nuclease domains intact. This modification, coupled with the constant action of the topoisomerase II in the bacterial cell, leads to DNA fragmentation via the nucleasic activity of the intact enzyme domains. Third and fourth generation fluoroquinolones are more selective for topoisomerase IV ligase domain, and thus have enhanced gram positive coverage.
Fluoroquinolones can enter cells easily via porins and, therefore, are often used to treat intracellular pathogens such as "Legionella pneumophila" and "Mycoplasma pneumoniae". For many gram-negative bacteria, DNA gyrase is the target, whereas topoisomerase IV is the target for many gram-positive bacteria. Some compounds in this class have been shown to inhibit the synthesis of mitochondrial DNA.
Mechanism of toxicity.
The mechanisms of the toxicity of fluoroquinolones has been attributed to their interactions with different receptor complexes, such as blockade of the GABAa receptor complex within the central nervous system, leading to excitotoxic type effects and oxidative stress.
Interactions.
Products containing multivalent cations, such as aluminium- or magnesium-containing antacids and products containing calcium, iron, or zinc, invariably result in marked reduction of oral absorption of fluoroquinolones. Other drugs that interact with fluoroquinolones include sucralfate, probenecid, cimetidine, theophylline, warfarin, antiviral agents, phenytoin, cyclosporine, rifampin, pyrazinamide, and cycloserine.
Fluoroquinolones have varying specificity for Cytochrome P450, and so may have interactions with drugs cleared by those enzymes; the order from most P450-inhibitory to least, is: enoxacin > ciprofloxacin > norfloxacin > ofloxacin, levofloxacin, trovafloxacin, gatifloxacin, moxifloxacin.
Antibiotic misuse and bacterial resistances.
Resistance to quinolones can evolve rapidly, even during a course of treatment. Numerous pathogens, including Escherichia coli commonly exhibit resistance. Widespread veterinary usage of quinolones, in particular in Europe, has been implicated.
Fluoroquinolones had become the most commonly prescribed class of antibiotics to adults in 2002. Nearly half (42%) of these prescriptions were for conditions not approved by the FDA, such as acute bronchitis, otitis media, and acute upper respiratory tract infection, according to a study supported in part by the Agency for Healthcare Research and Quality. In addition, they are commonly prescribed for medical conditions, such as acute respiratory illness, that are usually caused by viral infections.
Three mechanisms of resistance are known. Some types of efflux pumps can act to decrease intracellular quinolone concentration. In Gram-negative bacteria, plasmid-mediated resistance genes produce proteins that can bind to DNA gyrase, protecting it from the action of quinolones. Finally, mutations at key sites in DNA gyrase or topoisomerase IV can decrease their binding affinity to quinolones, decreasing the drugs' effectiveness.
History.
Nalidixic acid is considered to be the predecessor of all members of the quinolone family, including the second, third and fourth generations commonly known as fluoroquinolones. This first generation also included other quinolone drugs, such as pipemidic acid, oxolinic acid, and cinoxacin, which were introduced in the 1970s. They proved to be only marginal improvements over nalidixic acid.
Since the introduction of nalidixic acid in 1962, more than 10,000 analogs have been synthesized, but only a handful have found their way into clinical practice.
Boxed warnings.
In the US, the package insert for fluoroquinolone antibiotics includes a boxed warning of increased risk of developing tendonitis and tendon rupture in patients of all ages taking fluoroquinolones for systemic use. This risk is further increased in individuals over 60 years of age, taking corticosteroid drugs, and have received kidney, heart, or lung transplants. Another boxed warning says fluoroquinolones, due to their neuromuscular blocking activity, may exacerbate muscle weakness in persons with myasthenia gravis. Serious adverse events, including deaths and requirement for ventilatory support, have been reported in this group of patients. Avoidance of fluoroquinolones in patients with known history of myasthenia gravis is advised.
Partly as a result of the efforts of Public Citizen, the FDA ordered boxed warnings on all fluoroquinolones, advising consumers of an enhanced risk of tendon damage.
Generations.
Researchers divide the quinolones into generations based on their antibacterial spectrum. The earlier-generation agents are, in general, more narrow-spectrum than the later ones, but no standard is employed to determine which drug belongs to which generation. The only universal standard applied is the grouping of the nonfluorinated drugs found within this class (quinolones) within the 'first-generation' heading. As such, a wide variation exists within the literature dependent upon the methods employed by the authors.
The first generation is rarely used today. Nalidixic acid was added to the OEHHA Prop 65 list as a carcinogen on 15 May 1998. A number of the second-, third-, and fourth-generation drugs have been removed from clinical practice due to severe toxicity issues or discontinued by their manufacturers. The drugs most frequently prescribed today consist of Avelox (moxifloxacin), Cipro (ciprofloxacin), Levaquin (levofloxacin), and, to some extent, their generic equivalents.
Second-generation.
The second-generation class is sometimes subdivided into "Class 1" and "Class 2".
Third-generation.
Unlike the first- and second-generations, the third-generation is active against streptococci.
Fourth-generation.
Fourth-generation fluoroquinolones act at DNA gyrase and topoisomerase IV. This dual action slows development of resistance.
Veterinary use.
The quinolones have been widely used in agriculture, and several agents have veterinary, but not human, applications.
However, the agricultural use of fluoroquinolones in the US has been restricted since 1997, due to concerns over the development of antibiotic resistance.

</doc>
<doc id="25277" url="http://en.wikipedia.org/wiki?curid=25277" title="Quarterback">
Quarterback

Quarterback (commonly abbreviated to QB) is a position in American and Canadian football. Quarterbacks are members of the offensive team and line up directly behind the offensive line. Quarterbacks are the leaders of the offensive team, responsible for calling the play in the huddle.
Overview.
In modern football, the quarterback is the leader of the offense. The quarterback touches the ball on almost every offensive play, and his successes and failures can have a significant impact on the fortunes of his team. Accordingly, the quarterback is among the most glorified and scrutinized positions in team sports. Prior to each play, the quarterback tells the rest of his team which play the team will run; after the team is lined up, the center will pass the ball back between his legs to the quarterback (a process called the snap). On a running play, the quarterback will then hand or pitch the ball backwards to a running back. On a passing play, the quarterback will try to throw the ball downfield to a wide receiver, tight end, or running back. Additionally, the quarterback can run with the ball himself. This could be part of a designed play like the option run or quarterback sneak, or it could be an impromptu effort to avoid being sacked by the defense.
Depending on the offensive scheme by his team, the quarterback's role can vary. In systems like the triple option the quarterback will only pass the ball a few times per a game, while the spread offense as run by schools like Texas Tech requires quarterbacks to throw the ball in most plays. The passing game is emphasized heavily in the Canadian Football League (CFL), where there are only three downs as opposed to the four downs used in American football. Different skillsets are required of the quarterback in each system - quarterbacks that perform well in a spread offensive system, a popular offensive scheme in the NCAA and NFHS, rarely perform well in the National Football League (NFL), as the fundamentals of the pro-style offense used in the NFL are very different from those in the spread system. while quarterbacks in Canadian football need to be able to throw the ball often and accurately. In general, quarterbacks need to have physical skills such as arm strength, mobility, and quick throwing motion, in addition to intangibles such as competitiveness, leadership, intelligence, and downfield vision. The absence of a star quarterback can by itself greatly damage his team's play. For example, the Indianapolis Colts, among the most successful franchises in any sport during the 2000s with quarterback Peyton Manning, had a 2-14 record in 2011 because of his injuries. By contrast, a non-star quarterback on a winning team may be called a "game manager" if he avoids making mistakes that prevent his team's defense and rushing offenses from succeeding.
In the NFL, quarterbacks are required to wear a uniform number between 1 and 19. In the National Collegiate Athletic Association (NCAA) and National Federation of State High School Associations (NFHS), quarterbacks are required to wear a uniform number between 1 and 49; in the NFHS, the quarterback can also wear a number between 80 and 89. In the CFL, the quarterback can wear any number from 1 to 49 and 70 to 100. Because of their numbering, quarterbacks are eligible receivers in the NCAA, NFHS, and CFL; in the NFL, quarterbacks are eligible receivers if they are not lined up directly under center.
History.
The quarterback position dates to the late 1800s, when American Ivy League schools playing a form of rugby union imported from England began to put their own spin on the game. Walter Camp, a prominent athlete and rugby player at Yale University, pushed through a change in rules at a meeting in 1880 that established a line of scrimmage and allowed for the football to be snapped to a quarterback. The change was meant to allow for teams to strategize their play more thoroughly and retain possession more easily than was possible in the chaos of a scrum in rugby. In Camp's formulation, the "quarter-back" was the person who received a ball snapped back with another player's foot. Originally he was not allowed to run forward of the line of scrimmage:
A scrimmage takes place when the holder of the ball puts it on the ground before him and puts it in play while on-side either by kicking the ball or by snapping it back with his foot. The man who first receives the ball from the snap-back shall be called the quarter-back and shall not rush forward with the ball under penalty of foul.—Walter Camp, rule adopted at Springfield, Massachusetts Intercollegiate Football Association convention, 1880 
The exchange between the person snapping the ball (typically the center) and the quarterback was initially an awkward one because it involved a kick. At first, centers gave the ball a small boot, and then picked it up and handed it to the quarterback. By 1889, Yale center Bert Hanson was bouncing the ball on the ground to the quarterback between his legs. The following year, a rule change officially made snapping the ball using the hands between the legs legal. Several years later, Amos Alonzo Stagg at the University of Chicago invented the lift-up snap: the center passed the ball off the ground and between his legs to a standing quarterback. A similar set of changes were later adopted in Canadian football as part of the Burnside rules, a set of rules proposed by John Meldrum "Thrift" Burnside, the captain of the University of Toronto's football team.
The change from a scrum to a line of scrimmage made it possible for teams to decide what plays they would run before the snap. At first, the captains of college teams were put in charge of play-calling, indicating with shouted codes which players would run with the ball and how the men on the line were supposed to block. Yale later used visual signals, including adjustments of the captain's knit hat, to call plays. Centers could also signal plays based on the alignment of the ball before the snap. In 1888, however, Princeton University began to have its quarterback call plays using number signals. That system caught on, and quarterbacks began to act as directors and organizers of offensive play.
Early on, quarterbacks were used in a variety of formations. Harvard's team put seven men on the line of scrimmage, with three halfbacks who alternated at quarterback and a lone fullback. Princeton put six men on the line and had one designated quarterback, while Yale used seven linemen, one quarterback and two halfbacks who lined up on either side of the fullback. This was the origin of the T-formation, an offensive set that remained in use for many decades afterward and gained popularity in professional football starting in the 1930s.
In 1906, the forward pass was legalized in American football; Canadian football did not adopt the forward pass until 1929. Despite the legalization of the forward pass, the most popular formations of the early 20th century focused mostly on the rushing game. The single-wing formation, a run-oriented offensive set, was invented by football coach Glenn "Pop" Warner around the year 1908. In the single-wing, the quarterback was positioned behind the line of scrimmage and was flanked by a tailback, fullback and wingback. He served largely as a blocking back; the tailback typically took the snap, either running forward with the ball or making a lateral pass to one of the other players in the backfield. The quarterback's job was usually to make blocks upfield to help the tailback or fullback gain yards. Passing plays were rare in the single-wing, an unbalanced power formation where four linemen lined up to one side of the center and two lined up to the other. The tailback was the focus of the offense, and was often a triple-threat man who would either pass, run or kick the ball.
Offensive play-calling continued to focus on rushing up through the 1920s, when professional leagues began to challenge the popularity of college football. In the early days of the professional National Football League (NFL), which was founded in 1920, games were largely low-scoring affairs. Two-thirds of all games in the 1920s were shutouts, and quarterbacks usually passed only out of desperation. In addition to a reluctance to risk turnovers by passing, various rules existed that limited the effectiveness of the forward pass: passers were required to drop back five yards behind the line of scrimmage before they could attempt a pass, and incomplete passes in the end zone resulted in a change of possession and a touchback Additionally, the rules requires the ball to be snapped from the location on the field where it was ruled dead; if a play ended with a player going out of bounds, the center had to snap the ball from the sideline, an awkward place to start a play.
Despite these constraints, player-coach Curly Lambeau of the Green Bay Packers, along with several other NFL figures of his era, was a consistent proponent of the forward pass. The Packers found success in the 1920s and 1930s using variations on the single-wing that emphasized the passing game. Packers quarterback Red Dunn and New York Giants and Brooklyn Dodgers quarterback Benny Friedman were the leading passers of their era, but passing remained a relative rarity among other teams; between 1920 and 1932, there were three times as many running plays as there were passing plays.
Early NFL quarterbacks typically were responsible for calling the team's offensive plays with signals before the snap. The use of the huddle to call plays originated with Stagg in 1896, but only began to be used regularly in college games in 1921. In the NFL, players were typically assigned numbers, as were the gaps between offensive linemen. One player, usually the quarterback, would call signals indicating which player was to run the ball and which gap he would run toward. Play-calling or any other kind of coaching from the sidelines was not permitted during this period, leaving the quarterback to devise the offensive strategy. Substitutions were limited, and quarterbacks often played on both offense and defense.
The period between 1933 and 1945 was marked by numerous changes for the quarterback position. The rule requiring a quarterback to be five yards behind the line of scrimmage to pass was abolished. Hash marks were added to the field that established a limited zone between which the ball was placed before snaps, making offensive formations more flexible. Additionally, incomplete passes in the end zone were no longer counted as turnovers and touchbacks.
The single-wing continued to be in wide use throughout this, and a number of forward-passing tailbacks became stars, including Sammy Baugh of the Washington Redskins. In 1939, University of Chicago head football coach Clark Shaughnessy made modifications to the T-formation, a formation that put the quarterback behind the center and had him receive the snap directly. Shaughnessy altered the formation by having the linemen be spaced further apart, and he began having players go in motion behind the line of scrimmage before the snap to confuse defenses. These changes were picked up by Chicago Bears coach George Halas, a close friend of Shaughnessy, and they quickly caught on in the professional ranks. Utilizing the T-formation and led by quarterback Sid Luckman, the Bears reached the NFL championship game in 1940 and beat the Redskins by a score of 73–0. The blowout led other teams across the league to adopt variations on the T-formation, including the Philadelphia Eagles, Cleveland Rams and Detroit Lions. Baugh and the Redskins converted to the T-formation and continued to succeed.
Thanks in part to the emergence of the T-formation and changes in the rulebooks to liberalize the passing game, passing from the quarterback position became more common in the 1940s. Over the course of the decade, passing yards began to exceed rushing yards for the first time in the history of football. The Cleveland Browns of the late 1940s in the All-America Football Conference (AAFC), a professional league created to challenge the NFL, were one of the teams of that era that relied most on passing. Quarterback Otto Graham helped the Browns win four AAFC championships in the late 1940s in head coach Paul Brown's T-formation offense, which emphasized precision timing passes. Cleveland, along with several other AAFC teams, was absorbed by the NFL in 1950 after the dissolution of the AAFC that same year. By the end of the 1940s, all NFL teams aside from the Pittsburgh Steelers used the T-formation as their primary offensive formation.
As late as the 1960s, running plays occurred more frequently than passes. NFL quarterback Milt Plum later stated that during his career (1957-1969) passes typically only occurred on third downs and sometimes on first downs. Quarterbacks only increased in importance as rules changed to favor passing and higher scoring and as football gained popularity on television after the 1958 NFL Championship Game, often referred to as "The Greatest Game Ever Played". Early modern offenses evolved around the quarterback as a passing threat, boosted by rules changes in 1978 and 1979 that made it a penalty for defensive backs to interfere with receivers downfield and allowed offensive linemen to pass-block using their arms and open hands; the rules had limited them to blocking with their hands held to their chests. Average passing yards per game rose from 283.3 in 1977 to 408.7 in 1979.
The NFL has continued to be a pass-heavy league to the present day, in part due to further rule changes that prescribed harsher penalties for hitting the quarterback and for hitting defenseless receivers as they awaited passes. Passing in wide-open offenses has also been an emphasis at the high school and college levels, and professional coaches have devised schemes to fit the talents of new generations of quarterbacks.
While quarterbacks and team captains usually called plays in football's early years, today coaches often decide which plays the offense will run. Some teams use an offensive coordinator, an assistant coach whose duties include offensive game-planning and often play-calling. In the NFL, coaches are allowed to communicate with quarterbacks and call plays using audio equipment built into the player's helmet. Quarterbacks are allowed to hear, but not talk to, their coaches until there are fifteen seconds left on the play clock. Once the quarterback receives the call, he may relay it to other players via signals or in a huddle.
Dallas Cowboys head coach Tom Landry was an early advocate of taking play calling out of the quarterback's hands. Although this remained a common practice in the NFL through the 1970s, fewer QBs were doing it by the 1980s and even Hall-of-Famers like Joe Montana did not call their own plays. Buffalo Bills QB Jim Kelly was one of the last to regularly call plays. Among current NFL QBs, Peyton Manning of the Denver Broncos has been known to call all, or nearly all, of his team's plays using a no-huddle offense—although late in his tenure with the Indianapolis Colts, his center Jeff Saturday had equal say in making adjustments and calling audibles. Similarly, Baltimore Ravens quarterback Joe Flacco retains a high degree of control over the offense, particularly when running a no-huddle scheme.
Trends and other roles.
In addition to their main role, quarterbacks are occasionally used in other roles. Some teams utilize a backup quarterback as their holder on placekicks. A benefit of using quarterbacks as holders is that it would be easier to pull off a fake field goal attempt, but many coaches prefer to use punters as holders because a punter will have far more time in practice sessions to work with the kicker than any quarterback would. In the Wildcat, a formation where a halfback lines up behind the center and the quarterback lines up out wide, the quarterback can be used as a receiving target or a blocker. A more rare use for a quarterback is to punt the ball himself, a play known as a quick kick. Denver Broncos quarterback John Elway was known to perform quick kicks occasionally, typically when the Broncos were facing a third-and-long situation. Philadelphia Eagles quarterback Randall Cunningham, an All-America punter in college, was also known to punt the ball occasionally, and was assigned as the team's default punter for certain situations, such as when the team was backed up inside their own five-yard line.
As Roger Staubach's back-up, Dallas Cowboys quarterback Danny White was also the team's punter, opening strategic possibilities for coach Tom Landry. Ascending the starting role upon Staubach's retirement, White held his position as the team's punter for several seasons—a double duty he performed to All-American standard at Arizona State University. White also had two touchdown receptions as a Dallas Cowboy, both from the halfback option.
Special tactics.
If quarterbacks are uncomfortable with the formation the defense is using, they may call an audible change to their play. For example, if a quarterback receives the call to execute a running play, but he notices that the defense is ready to blitz—that is, to send additional defensive backs across the line of scrimmage in an attempt to tackle the quarterback or hurt his ability to pass—the quarterback may want to change the play. To do this, the quarterback yells a special code, like "Blue 42," or "Texas 29," which tells the offense to switch to a specific play or formation, but it all depends on the quarterbacks' judgment of the defenses' alignment.
Also, quarterbacks can "spike" or throw the football at the ground to stop the official game clock. For example, if a team is down by a field goal with only seconds remaining, a quarterback may spike the ball to prevent the game clock from running out. This usually allows the field goal unit to come onto the field, or attempt a final "Hail Mary pass". However, if a team is winning, a quarterback can keep the clock running by kneeling after the snap. This is normally done when the opposing team has no timeouts and there is little time left in the game, as it allows a team to burn up the remaining time on the clock without risking a turnover or injury.
Dual-threat quarterbacks.
A dual-threat quarterback possesses the skills and physique to run with the ball if necessary. With the rise of several blitz heavy defensive schemes and increasingly faster defensive players, the importance of a mobile quarterback has been redefined. While arm power, accuracy, and pocket presence – the ability to successfully operate from within the "pocket" formed by his blockers – are still the most important quarterback virtues, the ability to elude or run past defenders creates an additional threat that allows greater flexibility in the team's passing and running game.
Dual-threat quarterbacks have historically been more prolific at the college level. Typically, a quarterback with exceptional quickness is used in an option offense, which allows the quarterback to either hand the ball off, run it himself, or pitch it to the running back following him at a distance of three yards outside and one yard behind. This type of offense forces defenders to commit to either the running back up the middle, the quarterback around the end, or the running back trailing the quarterback. It is then that the quarterback has the "option" to identify which match up is most favorable to the offense as the play unfolds and exploit that defensive weakness. In the college game, many schools employ several plays that are designed for the quarterback to run with the ball. This is much less common in professional football, except for a quarterback sneak, but there is still an emphasis on being mobile enough to escape a heavy pass rush. Historically, high profile dual threat quarterbacks in the NFL were uncommon, Steve Young and John Elway being among the notable exceptions, leading their teams to 3 and 5 Super Bowl appearances respectively and Michael Vick, who's rushing ability was a rarity in the early 2000s, although he never lead his team to a Super Bowl. In recent years, quarterbacks with dual-threat capabilities have become more popular. Examples of dual-threat quarterbacks currently playing in the NFL include Robert Griffin III, Andrew Luck, Cam Newton, Ryan Tannehill, Colin Kaepernick and Russell Wilson.
Two-quarterback system.
Some teams employ a strategy which involves the use of more than one quarterback during the course of a game. This is more common at lower levels of football, such as high school or small college, but rare in major college or professional football.
There are four circumstances in which a two-quarterback system may be used.
The first is when a team is in the process of determining which quarterback will eventually be the starter, and may choose to use each quarterback for part of the game in order to compare the performances.
The second, still occasionally seen in major-college football, is the use of different quarterbacks in different game or down/distance situations. Generally this involves a running quarterback and a passing quarterback in an option or wishbone offense. In Canadian football, quarterback sneaks or other runs in short-yardage situations tend to be successful as a result of the distance between the offensive and defensive lines being one yard. Drew Tate, a quarterback for the Calgary Stampeders, was primarily used in short-yardage situations and led the CFL in rushing touchdowns during the 2014 season with ten scores as the backup to Bo Levi Mitchell. This strategy had all but disappeared from professional American football, but returned to some extent with the advent of the "wildcat" offense. There is a great debate within football circles as to the effectiveness of the so-called "two-quarterback system". Many coaches and media personnel remain skeptical of the model. 
Teams such as USC (Southern California), OSU (Oklahoma State), Northwestern, and smaller West Georgia have utilized the two-quarterback system; West Georgia, for example, uses the system due to the skill sets of its quarterbacks. Teams like these use this situation because of the advantages it gives them against defenses of the other team, so that the defense is unable to adjust to their game plan.
The third is a starter–reliever system, in which the starting quarterback may be replaced later in the game if ineffective. This is distinct from a situation in which a starter is benched in favor of the back-up because the switch is part of the game plan, and the expectation is that the two players will assume the same roles game after game. This strategy is rare, and was last seen in the NFL in the "WoodStrock" combination of Don Strock and David Woodley, which took the Miami Dolphins to the Epic in Miami in 1982 and Super Bowl XVII the following year.
The fourth is if a coach decides that the team has two quarterbacks who are equally effective and proceeds to rotate the quarterbacks at predetermined intervals, such as after each quarter or after each series. Southern California high school football team Corona Centennial operated this model during the 2014 football season, rotating quarterbacks after every series.
Racial issues.
During the 2013 season, 67 percent of NFL players were African American but only 17 percent of quarterbacks were; 82 percent of quarterbacks were white. Samuel G. Freedman, writing in "The New Yorker", asserted that black quarterbacks have faced discrimination, "often denied the starting positions they deserved."
Since the inception of the game, only two quarterbacks of African American descent have led their team to a Super Bowl victory, Doug Williams in 1988 and Russell Wilson in 2014.
References.
Bibliography.
</dl>

</doc>
<doc id="25278" url="http://en.wikipedia.org/wiki?curid=25278" title="Quadrilateral">
Quadrilateral

In Euclidean plane geometry, a quadrilateral is a polygon with four sides (or edges) and four vertices or corners. Sometimes, the term quadrangle is used, by analogy with triangle, and sometimes tetragon for consistency with pentagon (5-sided), hexagon (6-sided) and so on.
The origin of the word "quadrilateral" is the two Latin words "quadri", a variant of four, and "latus", meaning "side".
Quadrilaterals are simple (not self-intersecting) or complex (self-intersecting), also called crossed. Simple quadrilaterals are either convex or concave.
The interior angles of a simple (and planar) quadrilateral "ABCD" add up to 360 degrees of arc, that is
This is a special case of the "n"-gon interior angle sum formula ("n" − 2) × 180°. In a crossed quadrilateral, the four interior angles on either side of the crossing add up to 720°.
All convex quadrilaterals tile the plane by repeated rotation around the midpoints of their edges.
Convex quadrilaterals – parallelograms.
A parallelogram is a quadrilateral with two pairs of parallel sides. Equivalent conditions are that opposite sides are of equal length; that opposite angles are equal; or that the diagonals bisect each other. Parallelograms also include the square, rectangle, rhombus and rhomboid.
Special line segments.
The two "diagonals" of a convex quadrilateral are the line segments that connect opposite vertices.
The two "bimedians" of a convex quadrilateral are the line segments that connect the midpoints of opposite sides. They intersect at the "vertex centroid" of the quadrilateral (see Remarkable points below).
The four "maltitudes" of a convex quadrilateral are the perpendiculars to a side through the midpoint of the opposite side.
Area of a convex quadrilateral.
There are various general formulas for the area "K" of a convex quadrilateral.
Trigonometric formulas.
The area can be expressed in trigonometric terms as
where the lengths of the diagonals are "p" and "q" and the angle between them is "θ". In the case of an orthodiagonal quadrilateral (e.g. rhombus, square, and kite), this formula reduces to formula_3 since "θ" is 90°.
The area can be also expressed in terms of bimedians as 
where the lengths of the bimedians are "m" and "n" and the angle between them is "φ".
Bretschneider's formula expresses the area in terms of the sides and two opposite angles:
where the sides in sequence are "a", "b", "c", "d", where "s" is the semiperimeter, and "A" and "C" are two (in fact, any two) opposite angles. This reduces to Brahmagupta's formula for the area of a cyclic quadrilateral when "A"+"C" = 180°.
Another area formula in terms of the sides and angles, with angle "C" being between sides "b" and "c", and "A" being between sides "a" and "d", is
In the case of a cyclic quadrilateral, the latter formula becomes formula_7
In a parallelogram, where both pairs of opposite sides and angles are equal, this formula reduces to formula_8
Alternatively, we can write the area in terms of the sides and the intersection angle "θ" of the diagonals, so long as this angle is not 90°:
In the case of a parallelogram, the latter formula becomes formula_10
Another area formula including the sides "a", "b", "c", "d" is
where "x" is the distance between the midpoints of the diagonals and "φ" is the angle between the bimedians.
The last trigonometric area formula including the sides "a", "b", "c", "d" and the angle "α" between "a" and "b" is: 
which can also be used for the area of a concave quadrilateral (having the concave part opposite to angle "α") just changing the first sign + to - .
Non-trigonometric formulas.
The following two formulas express the area in terms of the sides "a", "b", "c", "d", the semiperimeter "s", and the diagonals "p", "q":
The first reduces to Brahmagupta's formula in the cyclic quadrilateral case, since then "pq" = "ac" + "bd".
The area can also be expressed in terms of the bimedians "m", "n" and the diagonals "p", "q":
In fact, any three of the four values "m", "n", "p", and "q" suffice for determination of the area, since in any quadrilateral the four values are related by formula_17:p. 126 The corresponding expressions are:
if the lengths of two bimedians and one diagonal are given, and
if the lengths of two diagonals and one bimedian are given.
Vector formulas.
The area of a quadrilateral "ABCD" can be calculated using vectors. Let vectors AC and BD form the diagonals from "A" to "C" and from "B" to "D". The area of the quadrilateral is then
which is half the magnitude of the cross product of vectors AC and BD. In two-dimensional Euclidean space, expressing vector AC as a free vector in Cartesian space equal to (x"1,"y"1) and BD as (x"2,"y"2), this can be rewritten as:
Diagonals.
Properties of the diagonals in some quadrilaterals.
In the following table it is listed if the diagonals in some of the most basic quadrilaterals bisect each other, if their diagonals are perpendicular, and if their diagonals have equal length. The list applies to the most general cases, and excludes named subsets.
"Note 1: The most general trapezoids and isosceles trapezoids do not have perpendicular diagonals, but there are infinite numbers of (non-similar) trapezoids and isosceles trapezoids that do have perpendicular diagonals and are not any other named quadrilateral."
"Note 2: In a kite, one diagonal bisects the other. The most general kite has unequal diagonals, but there is an infinite number of (non-similar) kites in which the diagonals are equal in length (and the kites are not any other named quadrilateral)."
Length of the diagonals.
The length of the diagonals in a convex quadrilateral "ABCD" can be calculated using the law of cosines. Thus
and
Other, more symmetric formulas for the length of the diagonals, are
and
Generalizations of the parallelogram law and Ptolemy's theorem.
In any convex quadrilateral "ABCD", the sum of the squares of the four sides is equal to the sum of the squares of the two diagonals plus four times the square of the line segment connecting the midpoints of the diagonals. Thus
where "x" is the distance between the midpoints of the diagonals.:p.126 This is sometimes known as "Euler's quadrilateral theorem" and is a generalization of the parallelogram law.
The German mathematician Carl Anton Bretschneider derived in 1842 the following generalization of Ptolemy's theorem, regarding the product of the diagonals in a convex quadrilateral
This relation can be considered to be a law of cosines for a quadrilateral. In a cyclic quadrilateral, where "A" + "C" = 180°, it reduces to "pq = ac + bd". Since cos ("A" + "C") ≥ −1, it also gives a proof of Ptolemy's inequality.
Other metric relations.
If "X" and "Y" are the feet of the normals from "B" and "D" to the diagonal "AC" = "p" in a convex quadrilateral "ABCD" with sides "a" = "AB", "b" = "BC", "c" = "CD", "d" = "DA", then:p.14
In a convex quadrilateral "ABCD" with sides "a" = "AB", "b" = "BC", "c" = "CD", "d" = "DA", and where the diagonals intersect at "E",
where "e" = "AE", "f" = "BE", "g" = "CE", and "h" = "DE".
The shape of a convex quadrilateral is fully determined by the lengths of its sides in sequence and of one diagonal between two specified vertices. The two diagonals "p, q" and the four side lengths "a, b, c, d" of a quadrilateral are related by the Cayley-Menger determinant, as follows:
Bimedians.
The bimedians of a quadrilateral are the line segments connecting the midpoints of the opposite sides.
The midpoints of the sides of any quadrilateral (convex, concave or crossed) are the vertices of a parallelogram called the Varignon parallelogram. It has the following properties:
The diagonals of the Varignon parallelogram are the bimedians of the original quadrilateral.
The two bimedians in a quadrilateral and the line segment joining the midpoints of the diagonals in that quadrilateral are concurrent and are all bisected by their point of intersection.:p.125
In a convex quadrilateral with sides "a", "b", "c" and "d", the length of the bimedian that connects the midpoints of the sides "a" and "c" is
where "p" and "q" are the length of the diagonals. The length of the bimedian that connects the midpoints of the sides "b" and "d" is
Hence:p.126
This is also a corollary to the parallelogram law applied in the Varignon parallelogram.
The lengths of the bimedians can also be expressed in terms of two opposite sides and the distance "x" between the midpoints of the diagonals. This is possible when using Euler's quadrilateral theorem in the above formulas. Whence
and
Note that the two opposite sides in these formulas are not the two that the bimedian connects.
In a convex quadrilateral, there is the following dual connection between the bimedians and the diagonals:
Trigonometric identities.
The four angles of a simple quadrilateral "ABCD" satisfy the following identities:
and
Also,
In the last two formulas, no angle is allowed to be a right angle, since tan 90° is not defined.
Inequalities.
Area.
If a convex quadrilateral has the consecutive sides "a", "b", "c", "d" and the diagonals "p", "q", then its area "K" satisfies
From Bretschneider's formula it directly follows that the area of a quadrilateral satisfies
with equality if and only if the quadrilateral is cyclic or degenerate such that one side is equal to the sum of the other three (it has collapsed into a line segment, so the area is zero).
The area of any quadrilateral also satisfies the inequality
Denoting the perimeter as "L", we have:p.114
with equality only in the case of a square.
The area of a convex quadrilateral also satisfies
for diagonal lengths "p" and "q", with equality if and only if the diagonals are perpendicular.
Diagonals and bimedians.
A corollary to Euler's quadrilateral theorem is the inequality
where equality holds if and only if the quadrilateral is a parallelogram.
Euler also generalized Ptolemy's theorem, which is an equality in a cyclic quadrilateral, into an inequality for a convex quadrilateral. It states that
where there is equality if and only if the quadrilateral is cyclic.:p.128–129 This is often called Ptolemy's inequality.
In any convex quadrilateral the bimedians "m, n" and the diagonals "p, q" are related by the inequality
with equality holding if and only if the diagonals are equal.:Prop.1 This follows directly from the quadrilateral identity formula_50
Sides.
The sides "a", "b", "c", and "d" of any quadrilateral satisfy:p.228,#275
and:p.234,#466
Maximum and minimum properties.
Among all quadrilaterals with a given perimeter, the one with the largest area is the square. This is called the "isoperimetric theorem for quadrilaterals". It is a direct consequence of the area inequality:p.114
where "K" is the area of a convex quadrilateral with perimeter "L". Equality holds if and only if the quadrilateral is a square. The dual theorem states that of all quadrilaterals with a given area, the square has the shortest perimeter.
The quadrilateral with given side lengths that has the maximum area is the cyclic quadrilateral.
Of all convex quadrilaterals with given diagonals, the orthodiagonal quadrilateral has the largest area.:p.119 This is a direct consequence of the fact that the area of a convex quadrilateral satisfies
where "θ" is the angle between the diagonals "p" and "q". Equality holds if and only if "θ" = 90°.
If "P" is an interior point in a convex quadrilateral "ABCD", then
From this inequality it follows that the point inside a quadrilateral that minimizes the sum of distances to the vertices is the intersection of the diagonals. Hence that point is the Fermat point of a convex quadrilateral.:p.120
Remarkable points and lines in a convex quadrilateral.
The centre of a quadrilateral can be defined in several different ways. The "vertex centroid" comes from considering the quadrilateral as being empty but having equal masses at its vertices. The "side centroid" comes from considering the sides to have constant mass per unit length. The usual centre, called just centroid (centre of area) comes from considering the surface of the quadrilateral as having constant density. These three points are in general not all the same point. 
The "vertex centroid" is the intersection of the two bimedians. As with any polygon, the "x" and "y" coordinates of the vertex centroid are the arithmetic means of the "x" and "y" coordinates of the vertices.
The "area centroid" of quadrilateral "ABCD" can be constructed in the following way. Let "Ga", "Gb", "Gc", "Gd" be the centroids of triangles "BCD", "ACD", "ABD", "ABC" respectively. Then the "area centroid" is the intersection of the lines "GaGc" and "GbGd". 
In a general convex quadrilateral "ABCD", there are no natural analogies to the circumcenter and orthocenter of a triangle. But two such points can be constructed in the following way. Let "Oa", "Ob", "Oc", "Od" be the circumcenters of triangles "BCD", "ACD", "ABD", "ABC" respectively; and denote by "Ha", "Hb", "Hc", "Hd" the orthocenters in the same triangles. Then the intersection of the lines "OaOc" and "ObOd" is called the "quasicircumcenter"; and the intersection of the lines "HaHc" and "HbHd" is called the "quasiorthocenter" of the convex quadrilateral. These points can be used to define an Euler line of a quadrilateral. In a convex quadrilateral, the quasiorthocenter "H", the "area centroid" "G", and the quasicircumcenter "O" are collinear in this order, and "HG" = 2"GO".
There can also be defined a "quasinine-point center" "E" as the intersection of the lines "EaEc" and "EbEd", where "Ea", "Eb", "Ec", "Ed" are the nine-point centers of triangles "BCD", "ACD", "ABD", "ABC" respectively. Then "E" is the midpoint of "OH".
Another remarkable line in a convex quadrilateral is the Newton line.
Taxonomy.
A taxonomy of quadrilaterals is illustrated by the following graph. Lower forms are special cases of higher forms. Note that "trapezoid" here is referring to the North American definition (the British equivalent is a trapezium), and "kite" excludes the "concave kite" ("arrowhead" or "dart"). Inclusive definitions are used throughout.

</doc>
<doc id="25280" url="http://en.wikipedia.org/wiki?curid=25280" title="Quantum teleportation">
Quantum teleportation

Quantum teleportation is a process by which quantum information (e.g. the exact state of an atom or photon) can be transmitted (exactly, in principle) from one location to another, with the help of classical communication and previously shared quantum entanglement between the sending and receiving location. Because it depends on classical communication, which can proceed no faster than the speed of light, it cannot be used for superluminal transport or communication of classical bits. It also cannot be used to make copies of a system, as this violates the no-cloning theorem. While it has proven possible to teleport one or more qubits of information between two (entangled) atoms, this has not yet been achieved, if it is even possible, between molecules or anything larger, due to the no-teleportation theorem. 
Although the name is inspired by the teleportation commonly used in fiction, there is no relationship outside the name, because quantum teleportation concerns only the transfer of information. Quantum teleportation is not a form of transportation, but of communication; it provides a way of transporting a qubit from one location to another, without having to move a physical particle along with it.
The seminal paper first expounding the idea was published by C. H. Bennett, G. Brassard, C. Crépeau, R. Jozsa, A. Peres and W. K. Wootters in 1993. Since then, quantum teleportation has been realized in various physical systems. Presently, the record distance for quantum teleportation is 143 km with photons,
and 21m with material systems. In August 2013, the achievement of "fully deterministic" quantum teleportation, using a hybrid technique, was reported. On 29 May 2014, scientists announced a reliable way of transferring data by quantum teleportation. Quantum teleportation of data had been done before but with highly unreliable methods.
Non-technical summary.
In matters relating to quantum or classical information theory, it is convenient to work with the simplest possible unit of information, the two-state system. In classical information this is a bit, commonly represented using one or zero (or true or false). The quantum analog of a bit is a quantum bit, or qubit. Qubits encode a type of information, called quantum information, which differs sharply from "classical" information. For example, quantum information can be neither copied (the no-cloning theorem) nor destroyed (the no-deleting theorem), and classical bits cannot be used to encode quantum bits.
Quantum teleportation provides a mechanism of moving a qubit from one location to another, without having to physically transport the underlying particle that a qubit is normally attached to. Much like the invention of the telegraph allowed classical bits to be transported at high speed across continents, quantum teleportation holds the promise that one day, qubits could be moved likewise. However, as of 2013, only photons and single atoms have been employed as information bearers; molecules have not, nor does this even seem likely in the upcoming years, as the technology remains daunting. Specific distance and quantity records are stated below.
The movement of qubits does require the movement of "things"; in particular, the actual teleportation protocol requires that an entangled quantum state or Bell state be created, and its two parts shared between two locations (the source and destination, or Alice and Bob). In essence, a certain kind of "quantum channel" between two sites must be established first, before a qubit can be moved. Teleportation also requires a classical information link to be established, as two classical bits must be transmitted to accompany each qubit. The need for such links may, at first, seem disappointing; however, this is not unlike ordinary communications, which requires wires, radios or lasers. What's more, Bell states are most easily shared using photons from lasers, and so teleportation could be done, in principle, through open space.
The quantum states of single atoms have been teleported. An atom consists of several parts: the qubits in the electronic state or electron shells surrounding the atomic nucleus, the qubits in the nucleus itself, and, finally, the electrons, protons and neutrons making up the atom. Physicists have teleported the qubits encoded in the electronic state of atoms; they have not teleported the nuclear state, nor the nucleus itself. It is therefore false to say "an atom has been teleported". It has not. The quantum state of an atom has. Thus, performing this kind of teleportation requires a stock of atoms at the receiving site, available for having qubits imprinted on them. The importance of teleporting nuclear state is unclear: nuclear state does affect the atom, e.g. in hyperfine splitting, but whether such state would need to be teleported in some futuristic "practical" application is debatable.
An important aspect of quantum information theory is entanglement, which imposes statistical correlations between otherwise distinct physical systems. These correlations hold even when measurements are chosen and performed independently, out of causal contact from one another, as verified in Bell test experiments. Thus, an observation resulting from a measurement choice made at one point in spacetime seems to instantaneously affect outcomes in another region, even though light hasn't yet had time to travel the distance; a conclusion seemingly at odds with Special relativity (EPR paradox). However such correlations can never be used to transmit any information faster than the speed of light, a statement encapsulated in the no-communication theorem. Thus, teleportation, as a whole, can never be superluminal, as a qubit cannot be reconstructed until the accompanying classical information arrives.
The proper description of quantum teleportation requires a basic mathematical toolset, which, although complex, is not out of reach of advanced high-school students, and indeed becomes accessible to college students with a good grounding in finite-dimensional linear algebra. In particular, the theory of Hilbert spaces and projection matrixes is heavily used. A qubit is described using a two-dimensional complex number-valued vector space (a Hilbert space); the formal manipulations given below do not make use of anything much more than that. Strictly speaking, a working knowledge of quantum mechanics is not required to understand the mathematics of quantum teleportation, although without such acquaintance, the deeper meaning of the equations may remain quite mysterious.
Protocol.
The prerequisites for quantum teleportation are a qubit that is to be teleported, a conventional communication channel capable of transmitting two classical bits (i.e., one of four states), and means of generating an entangled EPR pair of qubits, transporting each of these to two different locations, A and B, performing a Bell measurement on one of the EPR pair qubits, and manipulating the quantum state of the other of the pair. The protocol is then as follows:
Experimental results and records.
Work in 1998 verified the initial predictions, and the distance of teleportation was increased in August 2004 to 600 meters, using optical fiber. The longest distance yet claimed to be achieved for quantum teleportation is 143 km, performed in May 2012, between the two Canary Islands of La Palma and Tenerife off the Atlantic coast of north Africa. In April 2011, experimenters reported that they had demonstrated teleportation of wave packets of light up to a bandwidth of 10 MHz while preserving strongly nonclassical superposition states.
Researchers at the Niels Bohr Institute successfully used quantum teleportation to transmit information between clouds of gas atoms, notable because the clouds of gas are macroscopic atomic ensembles.
Formal presentation.
There are a variety of ways in which the teleportation protocol can be written mathematically. Some are very compact but abstract, and some are verbose but straightforward and concrete. The presentation below is of the latter form: verbose, but has the benefit of showing each quantum state simply and directly. Later sections review more compact notations.
The teleportation protocol begins with a quantum state or qubit formula_4, in Alice's possession, that she wants to convey to Bob. This qubit can be written generally, in bra–ket notation, as:
The subscript "C" above is used only to distinguish this state from "A" and "B", below. The protocol requires that Alice and Bob share a maximally entangled state. This state is fixed in advance, by mutual agreement between Alice and Bob, and can be any one of the four Bell states shown. It does not matter which one.
In the following, assume that Alice and Bob share the state formula_10
Alice obtains one of the particles in the pair, with the other going to Bob. (This is implemented by preparing the particles together and shooting them to Alice and Bob from a common source.) The subscripts "A" and "B" in the entangled state refer to Alice's or Bob's particle.
At this point, Alice has two particles ("C", the one she wants to teleport, and "A", one of the entangled pair), and Bob has one particle, "B". In the total system, the state of these three particles is given by
Alice will then make a local measurement in the Bell basis (i.e. the four Bell states) on the two particles in her possession. To make the result of her measurement clear, it is best to write the state of Alice's two qubits as superpositions of the Bell basis. This is done by using the following general identities, which are easily verified:
and
One applies these identities with "A" and "C" subscripts. The total three particle state, of "A", "B" and "C" together, thus becomes the following four-term superposition:
The above is just a change of basis on Alice's part of the system. No operation has been performed and the three particles are still in the same total state. The actual teleportation occurs when Alice measures her two qubits A,C, in the Bell basis 
Experimentally, this measurement may be achieved via a series of laser pulses directed at the two particles. Given the above expression, evidently the result of Alice's (local) measurement is that the three-particle state would collapse to one of the following four states (with equal probability of obtaining each):
Alice's two particles are now entangled to each other, in one of the four Bell states, and the entanglement originally shared between Alice's and Bob's particles is now broken. Bob's particle takes on one of the four superposition states shown above. Note how Bob's qubit is now in a state that resembles the state to be teleported. The four possible states for Bob's qubit are unitary images of the state to be teleported.
The result of Alice's Bell measurement tells her which of the above four states the system is in. She can now send her result to Bob through a classical channel. Two classical bits can communicate which of the four results she obtained.
After Bob receives the message from Alice, he will know which of the four states his particle is in. Using this information, he performs a unitary operation on his particle to transform it to the desired state formula_22:
to recover the state.
to his qubit.
Teleportation is thus achieved. The above-mentioned three gates correspond to rotations of π radians (180°) about appropriate axes (X, Y and Z).
Some remarks:
Alternative notations.
 Quantum teleportation, as computed in a dagger compact category. Such diagrams are employed in categorical quantum mechanics, and trace back to Penrose graphical notation, developed in the early 1970s.
There are a variety of different notations in use that describe the teleportation protocol. One common one is by using the notation of quantum gates. In the above derivation, the unitary transformation that is the change of basis (from the standard product basis into the Bell basis) can be written using quantum gates. Direct calculation shows that this gate is given by
where "H" is the one qubit Walsh-Hadamard gate and formula_31 is the Controlled NOT gate.
Entanglement swapping.
Teleportation can be applied not just to pure states, but also mixed states, that can be regarded as the state of a single subsystem of an entangled pair. The so-called entanglement swapping is a simple and illustrative example.
If Alice has a particle which is entangled with a particle owned by Bob, and Bob teleports it to Carol, then afterwards, Alice's particle is entangled with Carol's.
A more symmetric way to describe the situation is the following: Alice has one particle, Bob two, and Carol one. Alice's particle and Bob's first particle are entangled, and so are Bob's second and Carol's particle:
 ___
 Alice-:-:-:-:-:-Bob1 -:- Bob2-:-:-:-:-:-Carol
 \___/
Now, if Bob performs a projective measurement on his two particles in the Bell state basis and communicates the results to Carol, as per the teleportation scheme described above, the state of Bob's first particle can be teleported to Carol's. Although Alice and Carol never interacted with each other, their particles are now entangled.
A detailed diagrammatic derivation of entanglement swapping has been given by Bob Coecke, presented in terms of categorical quantum mechanics.
N-state particles.
One can imagine how the teleportation scheme given above might be extended to "N"-state particles, i.e. particles whose states lie in the "N" dimensional Hilbert space. The combined system of the three particles now has an formula_32 dimensional state space. To teleport, Alice makes a partial measurement on the two particles in her possession in some entangled basis on the formula_33 dimensional subsystem. This measurement has formula_33 equally probable outcomes, which are then communicated to Bob classically. Bob recovers the desired state by sending his particle through an appropriate unitary gate.
Logic gate teleportation.
In general, mixed states ρ may be transported, and a linear transformation ω applied during teleportation, thus allowing data processing of quantum information. This is one of the foundational building blocks of quantum information processing. This is demonstrated below.
General description.
A general teleportation scheme can be described as follows. Three quantum systems are involved. System 1 is the (unknown) state "ρ" to be teleported by Alice. Systems 2 and 3 are in a maximally entangled state "ω" that are distributed to Alice and Bob, respectively. The total system is then in the state
A successful teleportation process is a LOCC quantum channel Φ that satisfies
where Tr12 is the partial trace operation with respect systems 1 and 2, and formula_37 denotes the composition of maps. This describes the channel in the Schrödinger picture.
Taking adjoint maps in the Heisenberg picture, the success condition becomes
for all observable "O" on Bob's system. The tensor factor in formula_39 is formula_40 while that of formula_41 is formula_42.
Further details.
The proposed channel Φ can be described more explicitly. To begin teleportation, Alice performs a local measurement on the two subsystems (1 and 2) in her possession. Assume the local measurement have "effects"
If the measurement registers the "i"-th outcome, the overall state collapses to
The tensor factor in formula_45 is formula_40 while that of formula_41 is formula_42. Bob then applies a corresponding local operation Ψ"i" on system 3. On the combined system, this is described by
where "Id" is the identity map on the composite system formula_50.
Therefore the channel Φ is defined by
Notice Φ satisfies the definition of LOCC. As stated above, the teleportation is said to be successful if, for all observable "O" on Bob's system, the equality
holds. The left hand side of the equation is:
where Ψ"i*" is the adjoint of Ψ"i" in the Heisenberg picture. Assuming all objects are finite dimensional, this becomes
The success criterion for teleportation has the expression
Local explanation of the phenomenon.
A local explanation of quantum teleportation is put forward by David Deutsch and Patrick Hayden, with respect to the many-worlds interpretation of Quantum mechanics. Their paper asserts that the two bits that Alice sends Bob contain "locally inaccessible information" resulting in the teleportation of the quantum state. "The ability of quantum information to flow through a classical channel ..., surviving decoherence, is ... the
basis of quantum teleportation."

</doc>
<doc id="25284" url="http://en.wikipedia.org/wiki?curid=25284" title="Qubit">
Qubit

In quantum computing, a qubit () or quantum bit is a unit of quantum information—the quantum analogue of the classical bit. A qubit is a two-state quantum-mechanical system, such as the polarization of a single photon: here the two states are vertical polarization and horizontal polarization.  In a classical system, a bit would have to be in one state or the other. However quantum mechanics allows the qubit to be in a superposition of both states at the same time, a property which is fundamental to quantum computing.
Origin of the concept and name.
The concept of the qubit was unknowingly introduced by Stephen Wiesner in 1983, in his proposal for unforgeable quantum money, which he had tried to publish for over a decade.
The coining of the term "qubit" is attributed to Benjamin Schumacher. In the acknowledgments of his paper, Schumacher states that the term "qubit" was invented in jest due to its phonological resemblance with an ancient unit of length called cubit, during a conversation with William Wootters. The paper describes a way of compressing states emitted by a quantum source of information so that they require fewer physical resources to store. This procedure is now known as Schumacher compression.
Bit versus qubit.
The bit is the basic unit of information. It is used to represent information by computers. Regardless of its physical realization, a bit has two possible states typically thought of as 0 and 1, but more generally—and according to applications—interpretable as true and false, night and day, or any other dichotomous choice. An analogy to this is a light switch—its off position can be thought of as 0 and its on position as 1.
A qubit has a few similarities to a classical bit, but is overall very different. There are two possible outcomes for the measurement of a qubit—usually 0 and 1, like a bit. The difference is that whereas the state of a bit is either 0 or 1, the state of a qubit can also be a superposition of both. It is possible to fully encode one bit in one qubit. However, a qubit can hold even more information, e.g. up to two bits using Superdense coding.
Representation.
The two states in which a qubit may be measured are known as basis states (or basis vectors). As is the tradition with any sort of quantum states, they are represented by Dirac—or "bra–ket"—notation. This means that the two computational basis states are conventionally written as formula_1 and formula_2 (pronounced "ket 0" and "ket 1").
Qubit states.
A pure qubit state is a linear superposition of the basis states. This means that the qubit can be represented as a linear combination of formula_3 and formula_4 :
where α and β are probability amplitudes and can in general both be complex numbers.
When we measure this qubit in the standard basis, the probability of outcome formula_3 is formula_7 and the probability of outcome formula_4 is formula_9. Because the absolute squares of the amplitudes equate to probabilities, it follows that α and β must be constrained by the equation
simply because this ensures you must measure either one state or the other (the total probability of all possible outcomes must be 1).
Bloch sphere.
The possible states for a single qubit can be visualised using a Bloch sphere (see diagram). Represented on such a sphere, a classical bit could only be at the "North Pole" or the "South Pole", in the locations where formula_3 and formula_4 are respectively. The rest of the surface of the sphere is inaccessible to a classical bit, but a pure qubit state can be represented by any point on the surface. For example, the pure qubit state <math>
Qubit storage.
In a paper entitled: "Solid-state quantum memory using the 31P nuclear spin," published in the October 23, 2008 issue of the journal "Nature", a team of scientists from the U.K. and U.S. reported the first relatively long (1.75 seconds) and coherent transfer of a superposition state in an electron spin "processing" qubit to a nuclear spin "memory" qubit. This event can be considered the first relatively consistent quantum data storage, a vital step towards the development of quantum computing. Recently, a modification of similar systems (using charged rather than neutral donors) has dramatically extended this time, to 3 hours at very low temperatures and 39 minutes at room temperature.

</doc>
<doc id="25286" url="http://en.wikipedia.org/wiki?curid=25286" title="Quechuan languages">
Quechuan languages

Quechuan , also known as runa simi ("people's language"), is a Native American language family spoken primarily in the Andes region of South America, derived from a common ancestral language. It is the most widely spoken language family of the indigenous peoples of the Americas, with a total of probably some 8 million to 10 million speakers.
History: origins and divergence.
Quechua had already expanded across wide ranges of the central Andes long before the expansion of the Inca Empire. The Inca were just one among many peoples in present-day Peru who already spoke forms of Quechua. In the Cuzco region, Quechua was influenced by local languages such as Aymara. The Cuzco variety of Quechua developed as quite distinct. In similar way, a diverse group of dialects developed in different areas related to existing local languages during the period when the Inca Empire ruled and imposed Quechua as the official language.
After the Spanish conquest in the 16th century, Quechua continued to be used widely as the "general language" and main means of communication between the Spaniards and the indigenous population. The Roman Catholic Church adopted Quechua to use as the language of evangelisation. Given use by the missionaries, the range of Quechua continued to expand in some areas.
But the administrative and religious use of Quechua was terminated in the late 18th century when it was banned from public use in Peru in response to the Túpac Amaru II rebellion. The Crown banned even "loyal" pro-Catholic texts in Quechua, such as Garcilaso de la Vega's "Comentarios Reales." Despite a brief revival of the language immediately after independence in the 19th century, the prestige of Quechua had decreased sharply. Its use gradually was restricted to more isolated and conservative rural areas.
The oldest written records of the language are by missionary Fray Domingo de Santo Tomás, who arrived in Peru in 1538 and learned the language from 1540. He published his "Grammatica o arte de la lengua general de los indios de los reynos del Perú" in 1560.
Current status.
Today, Quechua has the status of an official language in Bolivia, Ecuador and Peru, along with Spanish.
Currently, the major obstacle to the diffusion of the usage and teaching of Quechua is the lack of written material in the Quechua language, namely books, newspapers, software, magazines, etc. Thus, Quechua, along with Aymara and the minor indigenous languages, remains essentially a spoken language.
In recent years, Quechua has been introduced in Intercultural bilingual education (IBE) in Bolivia, Ecuador and Peru, which is, however reaching only a part of the Quechua-speaking population. There is an ongoing process of Quechua-speaking populations shifting to Spanish for the purposes of social advancement.
Quechua and Spanish are now heavily intermixed, with many hundreds of Spanish loanwords in Quechua. Conversely, Quechua phrases and words are commonly used by Spanish speakers. In southern rural Bolivia, for instance, many Quechua words such as "wawa" (infant), "misi" (cat), "waska" (strap, or thrashing) are as commonly used as their Spanish counterparts, even in entirely Spanish-speaking areas. Quechua has also had a profound impact on other native languages of the Americas, for example Mapudungun.
Number of speakers.
The number of speakers given varies widely according to the sources. The total in "Ethnologue" 16 is 10 million, mostly based on figures published 1987–2002, but with a few dating from the 1960s. The figure for Imbabura Quechua in "Ethnologue", for example, is 300,000, an estimate from 1977. The missionary organization FEDEPI, on the other hand, estimated one million Imbabura speakers (published 2006). Census figures are also problematic, due to under-reporting. The 2001 Ecuador census reports only 500,000 Quechua speakers, where most sources estimate over 2 million. The censuses of Peru (2007) and Bolivia (2001) are thought to be more reliable.
Additionally, there are an unknown number of speakers in emigrant communities, including Queens, New York and Paterson, New Jersey in the United States.
Classification.
There are significant differences between the varieties of Quechua spoken the central Peruvian highlands and the peripheral varieties of Ecuador on the one hand and southern Peru and Bolivia on the other. These can be labeled Quechua I (or Quechua B, central) and Quechua II (or Quechua A, peripheral). Within these two groups, there are few sharp boundaries, making them dialect continua. However, there is a secondary division in Quechua II between the grammatically simplified northern varieties of Ecuador, Quechua II-B, known there as "Kichwa", and the generally more conservative varieties of the southern highlands, Quechua II-C, which include the old Inca capital of Cuzco. The closeness is at least in part due to the influence of Cuzco Quechua on the Ecuadorean varieties during the Inca Empire, as northern nobles were required to educate their children in Cuzco, maintaining Cuzco as the prestige dialect in the north.
Speakers from different points within any one of these three regions can generally understand each other reasonably well. There are nonetheless significant local-level differences across each. (Wanka Quechua, in particular, has several very distinctive characteristics that make this variety distinctly difficult to understand, even for other Central Quechua speakers.) Speakers from "different" major regions, meanwhile, particularly Central vs Southern Quechua, are not able to communicate effectively.
The lack of mutual intelligibility is the basic criterion that defines Quechua not as a single language, but as a language family. The complex and progressive nature of how speech varies across the dialect continua makes it nearly impossible to differentiate discrete varieties; "Ethnologue" lists 44 that they judge require separate literature. As a reference point, the overall degree of diversity across the family is a little less than that of the Romance or Germanic families, and more of the order of Slavic or Arabic. The greatest diversity is within Central Quechua, AKA Quechua I, which is believed to lie close to the homeland of the ancestral Proto-Quechua language.
Family tree.
Alfredo Torero devised the traditional classification, the three divisions above plus a fourth, northern Peruvian, branch. The latter cause complications in the classification, however, as they (Cajamarca-Lambayeque, Pacaraos, and Yauyos) have features of both Quechua I and Quechua II, and so are difficult to assign to either. Torero's classification is,
Willem Adelaar adheres to the Quechua I / Quechua II (central/peripheral) bifurcation, but partially following later modifications by Torero, reassigns part of Quechua II-A to Quechua I:
Landerman (1991) does not believe a truly genetic classification is possible, and breaks up Quechua II, so that the family has four geographical–typological branches: Northern, North Peruvian, Central, and Southern. He includes Chachapoyas and Lamas in North Peruvian Quechua, so that Ecuadorian is synonymous with Northern Quechua.
Geographical distribution.
Quechua I (Central Quechua, "Waywash") is spoken in Peru's central highlands, from Ancash to Huancayo. It is the most diverse branch of Quechua, to the extent that its divisions are commonly considered different languages.
Quechua II (Peripheral Quechua, "Wamp'una" 'Traveler')
Cognates.
A sampling of words in several Quechuan languages:[]
Quechua and Aymara.
Quechua shares a large amount of vocabulary, and some striking structural parallels, with Aymara, and these two families have sometimes been grouped together as a 'Quechumaran' family. This hypothesis is generally rejected by specialists, however; the parallels are better explained by mutual influence and borrowing through intensive and long-term contact. Many Quechua–Aymara cognates are close, often closer than intra-Quechua cognates, and there is little relationship in the affixal system.
Vocabulary.
A number of Quechua loanwords have entered English via Spanish, including "coca", "condor", "guano", "jerky", "llama", "puma", "quinine", "quinoa", "vicuña" and possibly "gaucho". The word "lagniappe" comes from the Quechuan word "yapay" ("to increase; to add") with the Spanish article "la" in front of it, "la yapa" or "la ñapa" in Spanish.
The influence on Latin American Spanish includes such borrowings as "papa" for "potato", "chuchaqui" for "hangover" in Ecuador, and diverse borrowings for "altitude sickness", in Bolivia from Quechuan "suruqch'i" to Bolivian "sorojchi", in Colombia, Ecuador, and Peru "soroche". 
In Bolivia particularly, Quechua words are used extensively even by non-Quechua speakers. These include wawa (baby, infant), ch'aki (hangover), misi (cat), juk'ucho (mouse), q'omer uchu (green pepper), jacu ("lets go"), chhiri and chhurco (curly haired), among many others. Quechua grammar also enters Bolivian Spanish, such as the use of the suffix -ri. In Bolivian quechua, -ri is added to verbs to signify an action is performed with affection, or, in the imperative, as a rough equivalent to please. In Bolivia -ri is often included in the Spanish imperative to imply "please" or to soften commands. For example, the standard "pásame" (pass me), becomes pasarime.
Quechua has borrowed a large number of Spanish words, such as "piru" (from "pero", but), "bwenu" (from "bueno", good), iskwila (from "escuela," school), waka (from "vaca," cow) and "burru" (from "burro", donkey).
Etymology of Quechua.
At first, Spaniards referred to the language of the Inca empire as the "lengua general", the "general tongue". The name "quichua" is first used in 1560 by Domingo de Santo Tomás in his "Grammatica o arte de la lengua general de los indios de los reynos del Perú". It is not known what name the native speakers gave to their language before colonial times, and whether it was Spaniards who called it "quechua".
There are two possible etymologies of Quechua as the name of the language. There is a possibility that the name Quechua was derived from "*qiĉ.wa", the native word which originally meant the "temperate valley" altitude ecological zone in the Andes (suitable for maize cultivation) and to its inhabitants.
Alternatively, Pedro Cieza de León and Garcilaso de la Vega, the early Spanish chroniclers, inform about the existence of the people called Quichua in the present-day Apurímac Region, and it could be inferred that their name was given to the entire language.
The Hispanicised spellings "Quechua" and "Quichua" have been used in Peru and Bolivia since the 17th century, especially after the III Lima Council. Today the various local pronunciations of "Quechua Simi" include ], ], ], ].
Another name that native speakers give to their own language is "runa simi", "language of man/people"; it also seems to have emerged during the colonial period.
Phonology.
The description below applies to Cusco dialect; there are significant differences in other varieties of Quechua.
Vowels.
Quechua uses only three vowel phonemes: /a/ /i/ and /u/, as in Aymara (including Jaqaru). Monolingual speakers pronounce these as [æ] [ɪ] and [ʊ] respectively, though the Spanish vowels /a/ /i/ and /u/ may also be used. When the vowels appear adjacent to the uvular consonants /q/, /qʼ/, and /qʰ/, they are rendered more like [ɑ], [ɛ] and [ɔ] respectively.
Consonants.
None of the plosives or fricatives are voiced; voicing is not phonemic in the Quechua native vocabulary of the modern Cusco variety.
About 30% of the modern Quechua vocabulary is borrowed from Spanish, and some Spanish sounds (e.g. f, b, d, g) may have become phonemic, even among monolingual Quechua speakers.
Aspirated and ejective renderings of consonants are only phonemic in some varieties of Quechua. Others only use plain /p/, /t/, /t͡ʃ/, and /k/.
Stress.
Stress is penultimate in most dialects of Quechua. In some varieties the apocope of word-final vowels or other factors may cause exceptional final stress.
Writing system.
Quechua has been written using the Roman alphabet since the Spanish conquest of Peru. However, written Quechua is not used by the Quechua-speaking people at large due to the lack of printed referential material in Quechua.
Until the 20th century, Quechua was written with a Spanish-based orthography. Examples: "Inca, Huayna Cápac, Collasuyo, Mama Ocllo, Viracocha, quipu, tambo, condor". This orthography is the most familiar to Spanish speakers, and as a corollary, has been used for most borrowings into English.
In 1975, the Peruvian government of Juan Velasco adopted a new orthography for Quechua. This is the writing system preferred by the "Academia Mayor de la Lengua Quechua". Examples: "Inka, Wayna Qhapaq, Qollasuyu, Mama Oqllo, Wiraqocha, khipu, tampu, kuntur". This orthography:
In 1985, a variation of this system was adopted by the Peruvian government; it uses the Quechuan three-vowel system. Examples: "Inka, Wayna Qhapaq, Qullasuyu, Mama Uqllu, Wiraqucha, khipu, tampu, kuntur".
The different orthographies are still highly controversial in Peru. Advocates of the traditional system believe that the new orthographies look too foreign, and suggest that it makes Quechua harder to learn for people who have first been exposed to written Spanish. Those who prefer the new system maintain that it better matches the phonology of Quechua, and point to studies showing that teaching the five-vowel system to children causes reading difficulties in Spanish later on.
For more on this, see Quechuan and Aymaran spelling shift.
Writers differ in the treatment of Spanish loanwords. Sometimes these are adapted to the modern orthography, and sometimes they are left in Spanish. For instance, "I am Roberto" could be written "Robertom kani" or "Ruwirtum kani". (The "-m" is not part of the name; it is an evidential suffix.)
The Peruvian linguist Rodolfo Cerrón-Palomino has proposed an orthographic norm for all Southern Quechua. This norm, "el Quechua estándar" or "Hanan Runasimi", which is accepted by many institutions in Peru, has been made by combining conservative features of two widespread dialects, Ayacucho Quechua and Cusco Quechua. For instance:
Grammar.
Morphological type.
All varieties of Quechua are very regular agglutinative languages, as opposed to isolating or fusional ones. Their normal sentence order is SOV (subject–object–verb). Their large number of suffixes changes both the overall significance of words and their subtle shades of meaning. Notable grammatical features include bipersonal conjugation (verbs agree with both subject and object), evidentiality (indication of the source and veracity of knowledge), a set of topic particles, and suffixes indicating who benefits from an action and the speaker's attitude toward it, although some languages and varieties may lack some of these characteristics.
Pronouns.
In Quechua, there are seven pronouns. Quechua has two first person plural pronouns ("we", in English). One is called the inclusive, which is used when the speaker wishes to include in "we" the person to whom he or she is speaking ("us and you"). The other form is called the exclusive, which is used when the addressee is excluded. ("us without you"). Quechua also adds the suffix "-kuna" to the second and third person singular pronouns "qam" and "pay" to create the plural forms "qam-kuna" and "pay-kuna".
Adjectives.
Adjectives in Quechua are always placed before nouns. They lack gender and number, and are not declined to agree with substantives.
Nouns.
Noun roots accept suffixes which indicate person (defining of possession, not identity), number, and case. In general, the personal suffix precedes that of number – in the Santiago del Estero variety, however, the order is reversed. From variety to variety, suffixes may change.
Adverbs.
Adverbs can be formed by adding "-ta" or, in some cases, "-lla" to an adjective: "allin – allinta" ("good – well"), "utqay – utqaylla" ("quick – quickly"). They are also formed by adding suffixes to demonstratives: "chay" ("that") – "chaypi" ("there"), "kay" ("this") – "kayman" ("hither").
There are several original adverbs. For Europeans, it is striking that the adverb "qhipa" means both "behind" and "future", whereas "ñawpa" means "ahead, in front" and "past". This means that local and temporal concepts of adverbs in Quechua (as well as in Aymara) are associated to each other reversely compared to European languages. For the speakers of Quechua, we are moving backwards into the future (we cannot see it – i.e. it is unknown), facing the past (we can see it – i.e. we remember it).
Verbs.
The infinitive forms (unconjugated) have the suffix "-y" ("much'a"= "kiss"; "much'a-y" = "to kiss"). The endings for the indicative are:
The suffixes shown in the table above usually indicate the subject; the person of the object is also indicated by a suffix ("-a-" for first person and "-su-" for second person), which precedes the suffixes in the table. In such cases, the plural suffixes from the table ("-chik" and "-ku") can be used to express the number of the object rather than the subject.
Various suffixes are added to the stem to change the meaning. For example, "-chi" is a causative and "-ku" is a reflexive (example: "wañuy" = "to die"; "wañuchiy" = to kill "wañuchikuy" = "to commit suicide"); "-naku" is used for mutual action (example: "marq'ay"= "to hug"; "marq'anakuy"= "to hug each other"), and "-chka" is a progressive, used for an ongoing action (e.g., "mikhuy" = "to eat"; "mikhuchkay" = "to be eating").
Grammatical particles.
Particles are indeclinable, that is, they do not accept suffixes. They are relatively rare. The most common are "arí" ("yes") and "mana" ("no"), although "mana" can take some suffixes, such as "-n"/"-m" ("manan"/"manam"), "-raq" ("manaraq", not yet) and "-chu" ("manachu?", or not?), to intensify the meaning. Also used are "yaw" ("hey", "hi"), and certain loan words from Spanish, such as "piru" (from Spanish "pero" "but") and "sinuqa" (from "sino" "rather").
Evidentiality.
The Quechua languages have three different morphemes that mark evidentiality. Evidentiality refers to a morpheme whose primary purpose is to indicate the source of information. In the Quechua languages, evidentiality is a three-term system. This means that there are three evidential morphemes that mark varying levels of source information. These markers can apply to first, second, and third person. The chart below depicts an example of these morphemes from the Wanka Quechua language.
Wanka Quechua 
The parentheses around the vowels indicate that the vowel can be dropped in when following an open vowel. For the sake of cohesiveness, the above forms will be used to broadly discuss the evidential morphemes. However, it should be noted that there are dialectal variations to the forms. The variations will be presented in the following descriptions.
The following sentences provide examples of the three evidentials and further discuss the meaning behind each of them.
"-m(i)" : Direct Evidence and Commitment
Regional variations: In the Cuzco dialect, the direct evidential presents itself as "–mi" and "–n".
The evidential "–mi" indicates that the speaker has a “strong personal conviction the veracity of the circumstance expressed.” It has the basis of direct personal experience.
Wanka Quechua 
I saw them with my own eyes.
"-chr(a)" : Inference and Attenuation
Regional variations: In Quechua languages, not specified by the source, the inference morpheme appears as "–ch(i), -ch(a), -chr(a)".
The "–chr(a)" evidential indicates that the utterance is an inference or form of conjecture. This inference relays the speaker’s non-commitment to the truth-value of the statement. It also appears in cases such as acquiescence, irony, interrogative constructions, and first person inferences. These uses constitute non-prototypical use and will be later discussed in the Changes in Meaning and Other Uses section.
Wanka Quechua
I think they will probably come back.
"-sh(i)" : Hearsay
Regional variations: It can appear as "–sh(i)" or "–s(i)" depending on the dialect.
With the use of this morpheme, the speaker “serves as a conduit through which information from another source passes”. The information being related is hearsay or revelatory in nature. It also works to express the uncertainty of the speaker regarding the situation. However, it also appears in other constructions that are discussed in the Changes in Meaning section.
Wanka Quechua
(I was told) Shani borrowed it.
Hintz discusses an interesting case of evidential behavior found in Sihaus Quechua. The author postulates that instead of three single evidential markers, this Quechua language contains three pairs of evidential markers.
Affix or Clitic
It may have been noted the evidential morphemes have been referred to as ‘markers’ or ‘morphemes’. The literature seems to differ on whether or not the evidential morphemes are acting as affixes or clitics, in come cases, such as Wanka Quechua, enclitics. Lefebvre and Muysken (1998) discuss this issue in terms of case but remark as to how the line between affix and clitic is not a clear one. Both terms will be used interchangeably throughout these sections.
Position in the Sentence
The evidentials in the Quechua languages are “second position enclitics” that attach to the first constituent in the sentence as shown in the examples below.
Once there were an old man and an old woman.
They can also occur on a focused constituent.
It is now that Pedro is building the house.
Sometimes the affix is described as attaching to the focus, especially when in reference to Tarma Quechua, but this does not hold true for all varieties of Quechua. In Huanuco Quechua. The evidentials follow any number of topics, marked by the topic marker "–qa", and the element with the evidential must precede the main verb or be the main verb.
However, there are exceptions to this rule as well. The more topics there are in a sentence, the more likely to deviate from the usual form.
When she (the witch) reached the peak, God had already taken the child up into heaven.
Changes in Meaning and Other Uses
Evidentials can be used to relay different meanings depending on the context and perform other functions. The following examples are restricted to Wanka Quechua.
The direct evidential, -mi
The direct evidential appears in Wh-Questions and Yes/No Questions. Considering the direct evidential in terms of prototypical semantics, it seems somewhat counterintuitive to have a direct evidential, basically an evidential that confirms the speaker’s certainty about a topic, in a question. However, if one focuses less on the structure and more on the situation, some sense can be made. The speaker is asking the addressee for information. Therefore, the speaker assumes the speaker knows the answer, or else why would they bother asking. This assumption is where the direct evidential comes into play. The speaker holds a certain amount of certainty that the addressee will know the answer. The speaker interprets the addressee as being in “direct relation” to the proposed content; this situation is the same as when, in regular sentences, the speaker assumes direct relation to the proposed information.
When did he come back from Huancayo?
The direct evidential affix is also seen in Yes/No Questions. This is similar to the situation with the Wh-Questions. Floyd describes the Yes/No questions as being “characterized as instructions to the addressee to assert one of the propositions of a disjunction”. Once again, the burden of direct evidence is being placed on the addressee, not on the speaker. The question marker in Wanka Quechua, "-chun", is derived from the negative –chu marker and the direct evidential (realized as –n in some dialects).
Is he going to Tarma?
The inferential evidential, -chr(a)
While "–chr(a)" is usually used in an inferential context, it has some non-prototypical uses.
"Mild Exhortation"
In these constructions the evidential works to reaffirm and encourage the addressee’s actions or thoughts.
Yes, tell them, "I've gone farther."
This example comes from a conversation between husband and wife discussing the reactions of their family and friends after they have been gone for a while. The husband says he plans to stretch the truth and tell them about far places he has gone, and his wife (in the example above) echoes and encourages his thoughts.
"Acquiescence"
With these, the evidential is used to highlight the speaker’s assessment of inevitability of an event and acceptance of it. There is a sense of resistance, diminished enthusiasm, and disinclination in these constructions.
I suppose I'll pay you then.
This example comes from a discourse where a woman demands compensation from the man (the speaker in the example) whose pigs ruined her potatoes. He denies the pigs as being his, but finally realizes he may be responsible and produces the above example.
"Interrogative"
Somewhat similar to the "–mi" evidential, the inferential evidential can be found in content questions. However, the salient difference between the uses of the evidentials in questions is that in the "–m(i)" marked questions, an answer is expected. This is not the case with "–chr(a)" marked questions.
I wonder what we will give our families when we arrive.
"Irony"
Irony in language can be a somewhat complicated topic due to how it functions differently in languages and, by its semantic nature, is already somewhat vague. For these purposes, it is suffice to say that when irony takes place in Wanka Quechua, the "–chr(a)" marker is used.
(I suppose) That's how you learn [i.e., that is the way in which you will learn].
This example comes from discourse between a father and daughter about her refusal to attend school. It can be interpreted as a genuine statement, i.e., perhaps one can learn by resisting school, or as an ironic statement, i.e., that's an absurd idea.
The hearsay evidential, -sh(i)
Aside from being used to express hearsay and revelation, this affix also has other uses.
"Folktales, Myths, and Legends"
Because folktales, myths, and legends are, in essence, reported speech, it follows that the hearsay marker would be used with them. Many of these types of stories are passed down through generations, furthering this aspect of reported speech. A difference between simple hearsay and folktales can be seen in the frequency of the "–sh(i)" marker. In normal conversation using reported speech, the marker is used less to eliminate redundancy.
"Riddles"
Riddles are somewhat similar to myths and folktales due to their nature to be passed by word of mouth.
Omission and Overuse of Evidential Affixes
In certain grammatical structures, the evidential marker does not appear at all. In all the Quechuan languages the evidential will not appear in a dependent clause. Sadly, no example was given to depict this omission.
Omissions can and do occur in Quechua. The sentence is understood to have the same evidentiality as the other sentences in the context. It varies among Quechuan speakers as to how much they omit evidentials, though these occur only in connected speech.
An interesting contrast to omission of evidentials is overuse of evidentials. If a speaker uses evidentials too much with no reason, their competence is brought into question. For example, the overuse of –m(i) could lead others to believe that the speaker is not a native speaker of the language or, in some extreme cases, that one is mentally ill.
Cultural Aspect
By using evidentials, the Quechua culture has certain assumptions about the information being relayed. Those who do not abide by the cultural customs should not be trusted. A passage from Weber (1986) summarizes them nicely below:
Evidentials also show that being precise and stating the source of one’s information is extremely important in the language and the culture. Failure to use them correctly can lead to diminished standing in the community. Speakers are aware of the evidentials and even use proverbs to teach children the importance of being precise and truthful. Precision and information source are of the utmost importance. They are a powerful and resourceful method of human communication.
Literature.
Although the body of literature in Quechua is not as sizable as its historical and present-day prominence would suggest, it is nevertheless not negligible.
As in the case of the Mesoamerican civilizations, there are a number of surviving Andean documents in the local language that were written down in Latin characters after the European conquest, but which express to a great extent the culture of pre-conquest times. The Quechua literature of this type is somewhat scantier, but nevertheless significant. It includes the so-called Huarochiri manuscript (1598), describing the mythology and religion of the valley of Huarochirí, as well as Quechua poems quoted within the Spanish-language texts of some chronicles dealing with the pre-conquest period. There are a number of anonymous or signed Quechua dramas dating from the post-conquest period (starting from the 17th century), some of which deal with the Inca era, while most are on religious topics and of European inspiration. The most famous of these dramas are "Ollantay" and the plays describing the death of Atahualpa. For example, Juan de Espinosa Medrano wrote several dramas in the language. Poems in Quechua were also composed during the colonial period.
Dramas and poems continued to be written in the 19th and especially in 20th centuries as well; in addition, in the 20th century and more recently, more prose has been published. While some of that literature consists of original compositions (poems and dramas), the bulk of 20th century Quechua literature consists of traditional folk stories and oral narratives. Johnny Payne has translated two sets of Quechua oral short stories, one into Spanish and the other into English.
Many Andean musicians write and sing in their native languages, including Quechua and Aymara. Notable musical groups are Los Kjarkas, Kala Marka, J'acha Mallku, Savia Andina, Wayna Picchu, Wara and many others.
References.
</dl>
Further reading.
</dl>

</doc>
<doc id="25291" url="http://en.wikipedia.org/wiki?curid=25291" title="Protein quaternary structure">
Protein quaternary structure

In biochemistry, quaternary structure is the arrangement of multiple folded protein or coiling protein molecules in a multi-subunit complex.
Description and examples.
Many proteins are actually assemblies of more than one polypeptide chain, which in the context of the larger assemblage are known as protein subunits. In addition to the tertiary structure of the subunits, multiple-subunit proteins possess a quaternary structure, which is the arrangement into which the subunits assemble. Enzymes composed of subunits with diverse functions are sometimes called holoenzymes, in which some parts may be known as regulatory subunits and the functional core is known as the catalytic subunit. Examples of proteins with quaternary structure include hemoglobin, DNA polymerase, and ion channels. Other assemblies referred to instead as multiprotein complexes also possess quaternary structure. Examples include nucleosomes and microtubules. Changes in quaternary structure can occur through conformational changes within individual subunits or through reorientation of the subunits relative to each other. It is through such changes, which underlie cooperativity and allostery in "multimeric" enzymes, that many proteins undergo regulation and perform their physiological function.
The above definition follows a classical approach to biochemistry, established at times when the distinction between a protein and a functional, proteinaceous unit was difficult to elucidate. More recently, people refer to protein-protein interaction when discussing quaternary structure of proteins and consider all assemblies of proteins as protein complexes.
Nomenclature of quaternary structures.
The number of subunits in an oligomeric complex is described using names that end in -mer (Greek for "part, subunit"). Formal and Greco-Latinate names are generally used for the first ten types and can be used for up to twenty subunits, whereas higher order complexes are usually described by the number of subunits, followed by -meric.
Although complexes higher than octamers are rarely observed for most proteins, there are some important exceptions. Viral capsids are often composed of multiples of 60 proteins. Several molecular machines are also found in the cell, such as the proteasome (four heptameric rings = 28 subunits), the transcription complex and the spliceosome. The ribosome is probably the largest molecular machine, and is composed of many RNA and protein molecules.
In some cases, proteins form complexes that then assemble into even larger complexes. In such cases, one uses the nomenclature, e.g., "dimer of dimers" or "trimer of dimers", to suggest that the complex might dissociate into smaller sub-complexes before dissociating into monomers.
Determination of quaternary structure.
Protein quaternary structure can be determined using a variety of experimental techniques that require a sample of protein in a variety of experimental conditions. The experiments often provide an estimate of the mass of the native protein and, together with knowledge of the masses and/or stoichiometry of the subunits, allow the quaternary structure to be predicted with a given accuracy. It is not always possible to obtain a precise determination of the subunit composition for a variety of reasons.
The number of subunits in a protein complex can often be determined by measuring the hydrodynamic molecular volume or mass of the intact complex, which requires native solution conditions. For "folded" proteins, the mass can be inferred from its volume using the partial specific volume of 0.73 ml/g. However, volume measurements are less certain than mass measurements, since "unfolded" proteins appear to have a much larger volume than folded proteins; additional experiments are required to determined whether a protein is unfolded or has formed an oligomer.
Prediction of quaternary structure attribute.
Some bioinformatics methods were developed for predicting the quaternary structural attributes of proteins based on their sequence information by using various modes of pseudo amino acid composition (see, e.g., refs.
).
Methods that measure the size of the intact complex indirectly.
Methods that measure the mass or volume under unfolding conditions (such as 
MALDI-TOF mass spectrometry and SDS-PAGE) are generally not useful, since non-native conditions usually cause the complex to dissociate into monomers. However, these may sometimes be applicable; for example, the experimenter may apply SDS-PAGE after first treating the intact complex with chemical cross-link reagents.
Protein-protein interactions.
Proteins are capable of forming very tight complexes. For example, ribonuclease inhibitor binds to ribonuclease A with a roughly 20 fM dissociation constant. Other proteins have evolved to bind specifically to unusual moieties on another protein, e.g., biotin groups (avidin), phosphorylated tyrosines (SH2 domains) or proline-rich segments (SH3 domains).

</doc>
<doc id="25292" url="http://en.wikipedia.org/wiki?curid=25292" title="Quest for Glory">
Quest for Glory

Quest for Glory is a series of hybrid adventure/role-playing video games (and later Action/RPG for game 5) designed by Corey and Lori Ann Cole. The series combined humor, puzzle elements, themes and characters borrowed from various legends, puns, and memorable characters, creating a 5-part series of the Sierra stable.
Although the series was originally titled Hero's Quest, Sierra failed to trademark the name. The Milton Bradley Company successfully trademarked an electronic version of their unrelated joint Games Workshop board game, "HeroQuest", which forced Sierra to change the series' title to "Quest for Glory". This decision caused all future games in the series (as well as newer releases of "Hero's Quest I") to switch over to the new name.
Series.
The series consisted of five games, each of which followed directly upon the events of the last. New games frequently referred to previous entries in the series, often in the form of cameos from recurring characters. The objective of the series is to transform the player character from an average adventurer to a Hero by completing non-linear quests.
The game also was revolutionary in its character import system, which allowed you to import your individual character, including the skills and wealth he had acquired, from one game to the next.
Hybrids by their gameplay and themes, the games feature serious stories leavened by humor throughout. There are real dangers to face, and true heroic feats to perform, but silly details and overtones creep in (when the drama of adventuring does not force them out). Cheap word play is particularly frequent, to the point that the second game's ending refers to itself as the hero's "latest set of adventures and miserable puns."
The games also have some memorable easter eggs, including a number of allusions to other Sierra games. For example if one types "pick nose" in the first game, (or click the lockpick icon on the player in the new version), if his lock-picking skill was high enough, the game would respond "Success! You now have an open nose"; If the skill was too low, the player would insert the lock pick too far, killing himself. Another example is Dr. Cranium, an allusion to "The Castle of Dr. Brain", in the fourth game.
Each game drew its inspiration from a different culture and mythology (in order, Germanic/fairy tale; Middle Eastern/Arabian Nights; Egyptian/African; Slavic folklore/Eastern European folklore; and finally Greco-Mediterranean) with the hero facing increasingly powerful opponents with help from characters who become increasingly familiar from game to game.
Each game varied somewhat from the tradition it is derived from; for example, Baba Yaga, a character borrowed from Slavic folklore, first appeared in the first game. The second game introduced several Arab and African-themed characters who reappeared in the third game, and characters from every game and genre in the series reappeared in the fourth and fifth games. In addition to deviating from the player's expectations of the culture represented in each game, the series also included a number of intentional anachronisms, such as the pizza-loving, mad scientists in the later games.
There was some criticism concerning the games as time-consuming. For example, while adding to realism, in order to build a certain skill or reach a certain point of time, the player has to repeat for countless times some certain action (such as 'climb tree', 'get rock'-'throw rock'), or walk aimlessly until the time passes.
Gameplay.
The first four games are hybrid Adventure/Role playing video games, while the fifth game switched to the genre of Action/RPG.
The gameplay standards established in earlier Sierra adventure games were enhanced by the player's ability to choose his character's career path from among the three traditional role-playing game backgrounds: fighter, magic-user/wizard and thief. Further variation was added by the ability to customize the Hero's abilities, including the option of selecting skills normally reserved for another character class, leading to unique combinations often referred to as "hybrid characters". During the second or third games, a character could be initiated as a Paladin by performing honorable actions, changing his class and abilities and receiving a unique sword. This would apply when the character is exported into later games. Any character that finished any game in the series (except "Dragon Fire", the last in the series) could be exported to a more recent game ("Shadows of Darkness" has a glitch which allows one to import characters from the same game), keeping the stats and parts of the inventory. If the character received the paladin sword, he would keep the magic sword (Soulforge or Piotyr's sword) and special paladin magic abilities. A character imported into a later game in the series from any other game could be assigned any character class, including Paladin.
Each career path had its own strengths and weaknesses, scenarios unique to those that possess the skills associated with it. Each class also had its own distinct way to solve various in-game puzzles, which encouraged replay: some puzzles had up to four different solutions. For instance, if a door is closed, instead of lockpicking or casting an open spell, the fighter can simply knock down the door. The magic user and the thief are both non-confrontational characters, as they lack the close range ability of the fighter, but are better able to attack from a distance, using daggers or spells. An example of these separate paths can be seen early in the first game. A gold ring belonging to the healer rests in a nest on top of a tree; fighters might make it fall by hurling rocks, thieves may want to climb the tree, while a magic user can simply cast the fetch spell to retrieve the nest, and then, while the fighter and magic user return the ring for a reward, the thief can choose between returning or selling the same ring in the thieves' guild (which is not available for those not possessing the "thieving" skills). It is also possible to build (over the course of several games) a character that has points in every skill in the game and can therefore perform nearly every task.
Each character class featured special abilities unique to that class, as well as a shared set of attributes which could be developed by performing tasks and completing quests. In general, for a particular game the maximum value which can be reached for an ability is 100*[the number of that game]. "Quest for Glory V" allows stat bonuses which can push an attribute over the maximum and lets certain classes raise certain attributes beyond the normal limits. "Quest for Glory V" also features special kinds of equipment which lower some stats while raising others. At the beginning of each game, the player may assign points to certain attributes, and certain classes only have specific attributes enabled, although skills can be added for an extra cost.
General attributes influence all characters classes and how they interact with objects and other people in the game; high values in strength allows to move heavier objects and communication helps with bargaining goods with sellers. These attributes are changed by performing actions related to the skill; climbing a tree eventually increases the skill value in climb, running increases vitality, and so on. There are also complementing skills which are only of associated with some classes; parry (the ability to block a blow with the sword), for instance, is mainly used by fighters and paladins, lock picking and sneaking thief's hobby, and the ability to cast magic spells is usually associated with magic user.
Vital statistics are depleted by performing some actions. Health (determined by strength and vitality) determines the hit points of the character, which decreases when the player is attacked or harms himself. Stamina (based on agility and vitality) limits the number of actions (exercise, fighting, running, etc.) the character is able to perform before needing rest or risking injury. Mana is only required by characters with skill in magic, and is calculated according to the character's intelligence and magic attributes.
Puzzle and Experience points only show the development of the player and his progress in the game, though in the first game also affected the kind of random encounters a player faces, as some monsters only appear after a certain level of experience is reached.
Games.
"Quest for Glory I: So You Want to Be a Hero".
In the valley barony of Spielburg, the evil ogress Baba Yaga has cursed the land and the baron who tried to drive her off. His children have disappeared, while the land is ravaged by monsters and brigands. The Valley of Spielburg is in need of a Hero able to solve these problems.
The original game was released in 1989 while a VGA remake was released in 1992.
"Quest for Glory II: Trial by Fire".
Quest for Glory II: Trial by Fire takes place in the land of Shapeir, in the world of Gloriana. Directly following from the events of the first game, the newly proclaimed Hero of Spielburg travels by flying carpet with his friends Abdulla Doo, Shameen and Shema to the desert city of Shapeir. The city is threatened by magical elementals, while the Emir Arus al-Din of Shapeir's sister city Raseir is missing and his city fallen under tyranny.
"Quest for Glory II" is the only game in the series to not have originated or have been remade beyond the EGA graphics engine by Sierra, but AGD Interactive released a VGA remake of the game using the Adventure Game Studio engine on August 24, 2008.
"Quest for Glory III: Wages of War".
Rakeesh the Paladin brings the Hero (and Prince of Shapeir) along with Uhura and her son Simba to his homeland, the town of Tarna in a jungle and savannah country called Fricana that mimics the central African ecosystems.
Tarna is on the brink of war; the Simbani, the tribe of Uhura, are ready to do battle with the Leopardmen. Each enemy has stolen a sacred relic from the other tribe and refused to return it before the other does. The Hero must prevent the war and then thwart a demon who may be loosed upon the world.
"Quest for Glory: Shadows of Darkness".
Drawn without warning from victory in Fricana, the Hero arrives without equipment or explanation in the middle of the hazardous Dark One Caves in the distant land of Mordavia.
"Quest for Glory V: Dragon Fire".
Erasmus introduces the player character, the Hero, to the Greece-like kingdom of Silmaria, whose king was recently assassinated. Thus, the traditional Rites of Rulership are due to commence, and the victor will be crowned king. The Hero enters the contest with the assistance of Erasmus, Rakeesh, and many old friends from previous entries in the series. The Hero competes against competitors, including the Silmarian guard Kokeeno Pookameeso, the warlord Magnum Opus, the hulking Gort, and the warrior Elsa Von Spielburg.
World.
The gameworld of the series is called Gloriana and is basically a fairy tale mirror version of Earth. Countries and continents explored in the Games are Spielburg (Game 1; German folklore), Shapeir (Game 2; Arabia of "One Thousand and One Nights"), Tarna (Game 3; African mythology, esp. Egypt), Mordavia (Game 4; Slavic mythology) and Silmaria (Game 5; Greek mythology). Adventures, Monsters and Story of the games are usually drawn from legends of the respective mirrored region, although there are several cross-over exceptions, like the eastern European Baba Yaga that also appears in the first game.
Characters.
Along with the Hero, several memorable characters appear and re-appear throughout the series including Rakeesh Sah Tarna, Abdullah Doo, Elsa von Spielburg, the evil Ad Avis and many others.
Original concept.
Originally, the series was to be a tetralogy, consisting of 4 games, with the following themes and cycles:
the 4 cardinal directions, the 4 classical elements, the 4 seasons and 4 different mythologies.
This is what the creators originally had in mind:
However, when ' was designed, it was thought that it would be too difficult for the hero to go straight from Shapeir to Mordavia and defeat the Dark One. To solve the problem, a new game, ', was inserted into the canon, and caused a renumbering of the series. Evidence for this can be found in the end of ': the player is told that the next game will be ' and a fanged vampiric moon is shown, to hint at the next game's theme.
They talked about it in the Fall 1992 issue of Sierra's InterAction magazine, and an online chat room:
 "When we developed the concept for the series," explained Corey, "we wanted some unifying themes for the story. We worked with the four seasons, the four basic elements – Earth, Air, Fire, and Water – and the four cardinal points of the compass. We planned to create four games to follow these elements.
"The first game – "So You Want to be a Hero" – is springtime and Earth and set in medieval Germany in the North. The second game – "Trial by Fire" – was the element of Fire, in the summer, and set in the South, in Arabia."
"The original third chapter," added Lori, "was to be "Shadows of Darkness", set in Transylvania – the East – and in the Fall, using Air as the central element."
Somewhere between finishing "Trial by Fire" and cranking up the design process for "Shadows of Darkness", the husband-and-wife team realized a fifth chapter would have to be added to bridge the games. That chapter became "Wages of War".
The concept of seasons in the games represents the maturation of the Hero as he moves from story to story. It's a critical component in a series that – from the very beginning – was designed to be a defined quartet of stories, representing an overall saga with a distinct beginning, middle, and end.
"One of the unifying themes," explained Corey, "is the growth of your character, going from being an adolescent Hero in the first game to being a young man in the second. You're strong and confident..."
"The third game," continued Lori, "was to show you as a master of your profession, with the fourth depicting you at the mature peek of your powers."
In the first episode, the player is a new graduate of the "Famous Adventurer's Correspondence School", ready to venture out into the springtime of his career and build a rep. It's a light-hearted, exhilarating journey into the unknown that can be replayed three times with three distinct outlooks at puzzle-solving.
In the second chapter – "Trial by Fire" – the Hero enters the summer of his experience, facing more difficult challenges with more highly-developed skills. While the episode is more serious and dangerous than its predecessor, it retains the enchanting mixture of fantasy, challenge, and humor that made the first game a hit with so many fans.
Of all the reasons Lori and Corey found for creating a bridge between "Trial by Fire" and "Shadows of Darkenss", the most compelling was the feeling that the Hero character simply hadn't matured enough to face the very grim challenges awaiting him in Transylvania.
"In terms of role-playing aspects," said Corey, ""Shadows of Darkness" is going to be a very difficult game. You'll have very tough opposition from the very beginning of the game."
"Also," said Lori, "you'll be very much alone. In "Trial by Fire" you had a lot of friends to help you. You always had a place to go back to rest. You always had a place of safety until the very end of the game. Once you get into "Shadows of Darkness", you're not going to have any sanctuary. You won't be able to trust anyone, because nobody will trust you.
""Wages of War" is the bridge," she continues. "You start with people you know to help you along in the beginning. But when push comes to shove, you're the one who's on his own, who has to solve the ultimate mystery. As you go along, just when you think you're all alone, your allies come back to you, but you have to face the final challenge by yourself."
 — Lori and Corey Cole

</doc>
<doc id="25293" url="http://en.wikipedia.org/wiki?curid=25293" title="Quango">
Quango

In both the United Kingdom and Ireland, a quasi-autonomous non-governmental organisation (quango or QuANGO, less often QANGO or qango) is an organisation to which a government has devolved power. In the United Kingdom this term covers different "arm's-length" government bodies, including "non-departmental public bodies", non-ministerial departments, and executive agencies.
The Forestry Commission, which is a non-ministerial government department responsible for forestry in England and Scotland, is an example of a quango.
History.
The term "quasi-autonomous non-governmental organisation" was created in 1967 by the Carnegie Foundation's Alan Pifer in an essay on independence and accountability in public-funded bodies incorporated in the private sector. This term was shortened to "quango" by Anthony Barker, a British participant during a follow-up conference on the subject. 
It describes an ostensibly non-governmental organisation performing governmental functions, often in receipt of funding or other support from government, while mainstream NGOs mostly get their donations or funds from the public and other organisations that support their cause. Numerous quangos were created from the 1980s onwards. Examples in the United Kingdom include those engaged in the regulation of various commercial and service sectors, such as the Water Services Regulation Authority.
An essential feature of a quango in the original definition was that it should not be a formal part of the state structure. The term was then extended to apply to a range of organisations, such as executive agencies providing (from 1988) health, education and other services. Particularly in the UK, this occurred in a polemical atmosphere in which it was alleged that proliferation of such bodies was undesirable and should be reversed (see below). This spawned the related acronym "qualgo", a 'quasi-autonomous "local" government organisation'.
The less contentious term non-departmental public body (NDPB) is often employed to identify numerous organisations with devolved governmental responsibilities. The UK government's definition in 1997 of a non-departmental public body or quango was:
A body which has a role in the processes of national government, but is not a government department or part of one, and which accordingly operates to a greater or lesser extent at arm's length from Ministers.
Use.
United Kingdom.
The Cabinet Office 2009 report on non-departmental public bodies found that there are 766 NDPBs sponsored by the UK government.
The number has been falling: there were 790 in 2008 and 827 in 2007. The number of NDPBs has fallen by over 10% since 1997. Staffing and expenditure of NDPBs have increased. They employed 111,000 people in 2009 and spent £46.5 billion, of which £38.4 billion was directly funded by the Government. 
Since the coalition government of Conservatives and Liberal Democrats was formed in May 2010, numerous NDPBs have been abolished under Conservative plans to reduce the overall budget deficit by reducing the size of the public sector. As of the end of July 2010, the government had abolished at least 80 NDPBs and warned many others that they faced mergers or deep cuts. In September 2010, "The Telegraph" published a leaked Cabinet Office list suggesting that a further 94 could be abolished, while four would be privatised and 129 merged. In August 2012, Cabinet Office minister Francis Maude said the government was on course to abolish 204 public bodies by 2015, and said this would create a net saving of at least £2.6 billion.
Ireland.
In 2006 there were more than 800 quangos in Ireland, 482 at national and 350 at local level, with a total of 5,784 individual appointees and a combined annual budget of €13 billion.
Criticisms.
"The Times" has accused quangos of bureaucratic waste and excess. In 2005, Dan Lewis, author of "The Essential Guide to Quangos", claimed that the UK had 529 quangos, many of which were useless and duplicated the work of others.
In popular culture.
Quangos were mentioned in several episodes of the popular British sitcom "Yes, Minister!". In particular, the chairmanship of a quango played a central role in the episode "Jobs for the Boys" from the first series of the sitcom.
"Mr. Robinson's Quango" is a song on the Blur album "The Great Escape" which satirises the life of a chairman.
A February 2015 at the satiric website "" claims that the Irish-language preservation agency Údarás na Gaeltachta has changed its name to "Údarás na Quangó" in recognition of the trend. 

</doc>
<doc id="25295" url="http://en.wikipedia.org/wiki?curid=25295" title="Quiver">
Quiver

A quiver is a container for arrows, bolts, or darts. Quivers can be attached in various positions on an archer's body, the bow, or the ground, depending on the type of shooting and the archer's personal preference. Quivers were traditionally made of leather, wood, furs, and other natural materials, but are now often made of metal or plastic.
Types.
Norman archers depicted in the Bayeux Tapestry. The top left archer was caught unprepared and has hastily thrown his belt quiver about his shoulders, as well as forgotten his helmet.
Belt quiver.
The most common style of quiver is a flat or cylindrical container suspended from the belt. They are found across many cultures from North America to China. Many variations of this type exist, such as being canted forwards or backwards, and being carried on the dominant hand side, off-hand side, or the small of the back. Some variants enclose almost the entire arrow, while minimalist "pocket quivers" consist of little more than a small stiff pouch that only covers the first few inches.
Back quiver.
Back quivers are secured to the archer's back via straps, with the nock ends protruding above the dominant hand's shoulder. Arrows can drawn over the shoulder rapidly by the nock. This style of quiver was used by Native American tribes of North America and tribes in Africa. The Japanese Samurai also used quivers on their backs, called Yebira, while both on foot and horseback. While popular in cinema and 20th century art for depictions of medieval European characters (such as Robin Hood), this style of quiver was rarely used in medieval Europe. The Bayeux Tapestry shows that most bowmen in medieval Europe used belt quivers.
Ground quiver.
A ground quiver is used for both target shooting or warfare when the archer is shooting from a fixed location. They can be simply stakes in the ground with a ring at the top to hold the arrows, or more elaborate designs that hold the arrows within reach without the archer having to lean down to draw.
Bow quiver.
A modern invention, the bow quiver attaches directly to the bow's limbs and holds the arrows steady with a clip of some kind. They are popular with compound bow hunters as it allows one piece of equipment to be carried in the field without encumbering the hunter's body.
Arrow bag.
A style used by medieval English Longbowmen and several other cultures, an arrow bag is a simple drawstring cloth sack with a leather spacer at the top to keep the arrows divided. When not in use, the drawstring could be closed, completely covering the arrows so as to protect them from rain and dirt. Some had straps or rope sewn to them for carrying, but many either were tucked into the belt or set on the ground before battle to allow easier access.
Japanese quivers.
Yebira refers to a variety of quiver designs. The Yazutsu is a different type, used in Kyudo. Arrows are removed from it before shooting, and held in the hand, so it is mainly used to transport and protect arrows.

</doc>
<doc id="25296" url="http://en.wikipedia.org/wiki?curid=25296" title="Quid">
Quid

Quid may refer to:

</doc>
<doc id="25297" url="http://en.wikipedia.org/wiki?curid=25297" title="Quinine">
Quinine

Quinine (, or ) is a white crystalline alkaloid having antipyretic (fever-reducing), antimalarial, analgesic (painkilling), and anti-inflammatory properties and a bitter taste. It is a stereoisomer of quinidine, which, unlike quinine, is an antiarrhythmic. Quinine contains two major fused-ring systems: the aromatic quinoline and the bicyclic quinuclidine.
Quinine occurs naturally in the bark of the cinchona tree, though it has also been synthesized in the laboratory. The medicinal properties of the cinchona tree were originally discovered by the Quechua, who are indigenous to Peru and Bolivia; later, the Jesuits were the first to bring cinchona to Europe.
Quinine was the first effective Western treatment for malaria caused by "Plasmodium falciparum", appearing in therapeutics in the 17th century. It remained the antimalarial drug of choice until the 1940s, when other drugs such as chloroquine that have fewer unpleasant side effects replaced it. Since then, many effective antimalarials have been introduced, although quinine is still used to treat the disease in certain critical circumstances, such as severe malaria, and in impoverished regions due to its low cost. Quinine is available with a prescription in the United States and "over-the-counter" (in minute quantities) in tonic water. Quinine is also used to treat lupus and arthritis. Quinine was also frequently prescribed in the US as an off-label treatment for nocturnal leg cramps, but this has become less prevalent due to a Food and Drug Administration statement warning against the practice.
Quinine is highly fluorescent (quantum yield ~0.58) in 0.1 M sulfuric acid solution and it is widely used as a standard for fluorescence quantum yield measurement. 
It is on the WHO Model List of Essential Medicines, a list of the most important medications needed in a basic health system.
Medical uses.
As of 2006, quinine is no longer recommended by the WHO (World Health Organization) as first-line treatment for malaria, and it should be used only when artemisinins are not available.
Quinine is a basic amine and is usually presented as a salt. Various existing preparations include the hydrochloride, dihydrochloride, sulfate, bisulfate and gluconate. This makes quinine dosing complicated, since each of the salts has a different weight.
The following amounts of each salt form contain equal amounts of quinine:
All quinine salts may be given orally or intravenously (IV); quinine gluconate may also be given intramuscularly (IM) or rectally (PR). The main problem with the rectal route is that the dose can be expelled before it is completely absorbed; in practice, this is corrected by giving a further half dose.
In the United States, quinine sulfate is commercially available in 324-mg tablets under the brand name Qualaquin; the adult dose is two tablets every eight hours. No injectable preparation of quinine is licensed in the US; quinidine is used instead.
Adverse effects.
Quinine can, in therapeutic doses, cause cinchonism; in rare cases, it may even cause death (usually by pulmonary edema). The development of mild cinchonism is not a reason for stopping or interrupting quinine therapy, and the patient should be reassured. Blood glucose levels and electrolyte concentrations must be monitored when quinine is given by injection. The patient should ideally be in cardiac monitoring when the first quinine injection is given (these precautions are often unavailable in developing countries where malaria is endemic).
Cinchonism is much less common when quinine is given by mouth, but oral quinine is not well tolerated (quinine is exceedingly bitter and many patients will vomit after ingesting quinine tablets): Other drugs such as Fansidar (sulfadoxine with pyrimethamine) or Malarone (proguanil with atovaquone) are often used when oral therapy is required. Quinine ethyl carbonate is tasteless and odourless, but is available commercially only in Japan. Blood glucose, electrolyte and cardiac monitoring are not necessary when quinine is given by mouth.
Quinine can cause paralysis if accidentally injected into a nerve. It is extremely toxic in overdose, and the advice of a poisons specialist should be sought immediately.
Quinine in some cases can lead to constipation, erectile dysfunction, or diarrhea.
"The New York Times Magazine" described a case presenting with fever, hypotension, and blood abnormalities mimicking septic shock, which was judged to be an adverse reaction to quinine.
Non-abortifacient.
Despite popular belief, quinine is not an effective abortifacient (a substance that may induce abortion) (in the US, quinine is listed as pregnancy category D). Pregnant women who take toxic doses of quinine will suffer from renal failure before experiencing any kind of quinine-induced abortion. Indeed, quinine is the only drug recommended by the WHO as first-line treatment for uncomplicated malaria in pregnancy.
Disease interactions.
Quinine can cause hemolysis in G6PD deficiency (an inherited deficiency), but this risk is small and the physician should not hesitate to use quinine in patients with G6PD deficiency when there is no alternative. Quinine can also cause drug-induced immune thrombocytopenic purpura. Symptoms can be severe enough to require hospitalization and platelet transfusion, with several cases known to have resulted in death.
Quinine can cause abnormal heart rhythms, and should be avoided if possible in patients with atrial fibrillation, conduction defects or heart block.
Hearing impairment.
Some studies have related the use of quinine and hearing impairment, particularly high-frequency loss. Although some studies suggest that this high-frequency hearing impairment is reversible, it has not been conclusively established whether such impairment is temporary or permanent.
Mechanism of action.
As with other quinoline antimalarial drugs, the mechanism of action of quinine has not been fully resolved. The most widely accepted hypothesis of its action is based on the well-studied and closely related quinoline drug, chloroquine. This model involves the inhibition of hemozoin biocrystallization in Heme Detoxification pathway, which facilitates the aggregation of cytotoxic heme. Free cytotoxic heme accumulates in the parasites, causing their deaths.
Regulation.
United States.
From 1969 to 1992, the US Food and Drug Administration (FDA) received 157 reports of health problems related to quinine use, including 23 which had resulted in death. In 1994, the FDA banned the marketing of over-the-counter quinine as a treatment for nocturnal leg cramps. Pfizer Pharmaceuticals had been selling the brand name Legatrin for this purpose. Also sold as a Softgel [tm](by SmithKlineBeecham?)as Q-vel [tm].Doctors may still prescribe quinine, but the FDA has ordered firms to stop marketing unapproved drug products containing quinine. The FDA is also cautioning consumers about off-label use of quinine to treat leg cramps. Quinine is approved for treatment of malaria, but is also commonly prescribed to treat leg cramps and similar conditions. Because malaria is life-threatening, the risks associated with quinine use are considered acceptable when used to treat that affliction.
Though Legatrin was banned by the FDA for the treatment of leg cramps, the drug manufacturer URL Mutual has branded a quinine-containing drug named Qualaquin. It is marketed as a treatment for malaria and is sold in the United States only by prescription. In 2004, the CDC reported only 1,347 confirmed cases of malaria in the United States.
Nonmedical uses.
In some areas, nonmedical use of quinine is regulated. For example, in the United States and Germany, quinine is limited to between 83 and 85 parts per million.
Beverages.
Quinine is a flavour component of tonic water and bitter lemon. On the soda gun behind many bars, tonic water is designated by the letter "Q" representing quinine. According to tradition, the bitter taste of antimalarial quinine tonic led British colonials in India to mix it with gin, thus creating the gin and tonic cocktail, which is still popular today in many parts of the world, especially the UK, United States, Canada, Australia, and New Zealand. In France, quinine is an ingredient of an "apéritif" known as "quinquina" or "Cap Corse". In Spain, quinine ("Peruvian bark") is sometimes blended into sweet Malaga wine, which is then called "Malaga Quina". In Italy, the traditional flavoured wine Barolo Chinato is infused with quinine and local herbs and is served as a "digestif". In Canada and Italy, quinine is an ingredient in the carbonated chinotto beverages Brio and San Pellegrino chinotto. In Scotland, the company A.G. Barr uses quinine as an ingredient in the carbonated and caffeinated beverage Barr's Irn-Bru. In the United Kingdom, Australia, New Zealand, South Africa and Egypt, quinine is an ingredient in Schweppes and other brands of Indian Tonic Water mixer drink called 'Dry Lemon'. Schweppes and a few other drinks makers also produce Bitter Lemon, a pale green mixer drink containing quinine. In Uruguay and Argentina, quinine is an ingredient of a Pepsico Inc. tonic water named Paso de los Toros. In Denmark, it is used as an ingredient in the carbonated sports drink Faxe Kondi made by Royal Unibrew. In the US, quinine is listed as an ingredient in some Diet Snapple flavors, including Cranberry Raspberry.
Scientific.
Because of its relatively constant and well-known fluorescence quantum yield, quinine is used in photochemistry as a common fluorescence standard.
The UV absorption peaks around 350 nm (in UVA). Fluorescent emission peaks at around 460 nm (bright blue/cyan hue).
Quinine (and quinidine) are used as the chiral moiety for the ligands used in Sharpless asymmetric dihydroxylation as well as for numerous other chiral catalyst backbones.
The bark of "Remijia" contains 0.5–2% of quinine. The bark is cheaper than bark of "Cinchona", and as it has an intense taste it is used for making tonic water.
Other.
Quinine is sometimes used as a cutting agent in street drugs such as cocaine and heroin.
Quinine is used as a treatment for "Cryptocaryon irritans" (commonly referred to as white spot, crypto or marine ich) infection of marine aquarium fish.
History.
Quinine is an effective muscle relaxant, long used by the Quechua, who are indigenous to Peru, to halt shivering due to low temperatures. The Peruvians would mix the ground bark of cinchona trees with sweetened water to offset the bark's bitter taste, thus producing tonic water.
Quinine has been used in unextracted form by Europeans since at least the early 17th century. It was first used to treat malaria in Rome in 1631. During the 17th century, malaria was endemic to the swamps and marshes surrounding the city of Rome. Malaria was responsible for the deaths of several popes, many cardinals and countless common Roman citizens. Most of the priests trained in Rome had seen malaria victims and were familiar with the shivering brought on by the febrile phase of the disease. The Jesuit brother Agostino Salumbrino (1561–1642), an apothecary by training who lived in Lima, observed the Quechua using the bark of the cinchona tree for that purpose. While its effect in treating malaria (and hence malaria-induced shivering) was unrelated to its effect in controlling shivering from rigors, it was still a successful medicine for malaria. At the first opportunity, Salumbrino sent a small quantity to Rome to test as a malaria treatment. In the years that followed, cinchona bark, known as Jesuit's bark or Peruvian bark, became one of the most valuable commodities shipped from Peru to Europe. When King Charles II was cured of malaria at the end of the 17th Century with quinine, it became popular in London. It remained the antimalarial drug of choice until the 1940s, when other drugs took over.
The form of quinine most effective in treating malaria was found by Charles Marie de La Condamine in 1737. Quinine was isolated and named in 1820 by French researchers Pierre Joseph Pelletier and Joseph Bienaimé Caventou. The name was derived from the original Quechua (Inca) word for the cinchona tree bark, "quina" or "quina-quina", which means "bark of bark" or "holy bark". Prior to 1820, the bark was first dried, ground to a fine powder, and then mixed into a liquid (commonly wine) which was then drunk. Large-scale use of quinine as a prophylaxis started around 1850.
Quinine also played a significant role in the colonization of Africa by Europeans. Quinine had been said to be the prime reason Africa ceased to be known as the "white man's grave". A historian has stated, "it was quinine's efficacy that gave colonists fresh opportunities to swarm into the Gold Coast, Nigeria and other parts of west Africa".
To maintain their monopoly on cinchona bark, Peru and surrounding countries began outlawing the export of cinchona seeds and saplings beginning in the early 19th century. The Dutch government persisted in its attempt to smuggle the seeds, and by the 1930s Dutch plantations in Java were producing 22 million pounds of cinchona bark, or 97% of the world's quinine production. During World War II, Allied powers were cut off from their supply of quinine when the Germans conquered the Netherlands and the Japanese controlled the Philippines and Indonesia. The United States had managed to obtain four million cinchona seeds from the Philippines and began operating cinchona plantations in Costa Rica. Nonetheless, such supplies came too late; tens of thousands of US troops in Africa and the South Pacific died due to the lack of quinine. Despite controlling the supply, the Japanese did not make effective use of quinine, and thousands of Japanese troops in the southwest Pacific died as a result.
Synthetic quinine.
Cinchona trees remain the only economically practical source of quinine. However, under wartime pressure, research towards its synthetic production was undertaken. A formal chemical synthesis was accomplished in 1944 by American chemists R.B. Woodward and W.E. Doering. Since then, several more efficient quinine total syntheses have been achieved, but none of them can compete in economic terms with isolation of the alkaloid from natural sources. The first synthetic organic dye, mauveine, was discovered by William Henry Perkin in 1856 while he was attempting to synthesize quinine.

</doc>
<doc id="25298" url="http://en.wikipedia.org/wiki?curid=25298" title="Quincy">
Quincy

Quincy may refer to:

</doc>
<doc id="25301" url="http://en.wikipedia.org/wiki?curid=25301" title="Quimby">
Quimby

Quimby may refer to:

</doc>
<doc id="25302" url="http://en.wikipedia.org/wiki?curid=25302" title="Quail">
Quail

Quail is a collective name for several genera of mid-sized birds generally placed in the order Galliformes. 
Old World quail are found in the family Phasianidae, and New World quail are found in the family Odontophoridae. The buttonquail are named more for their superficial resemblance to quail, and are members of the Turnicidae family in the Charadriiformes order. The king quail, one of the Old World quail, often is sold in the pet trade, and within this trade is commonly, though mistakenly, referred to as a "button quail". Many of the common larger species are farm-raised for table food or egg consumption, and are hunted on game farms or in the wild, where they may be released to supplement the wild population, or extend into areas outside their natural range. In 2007, 40 million quail were produced in the U.S. 
The collective noun for a group of quail is a flock, covey or bevy.

</doc>
<doc id="25303" url="http://en.wikipedia.org/wiki?curid=25303" title="Quagmire (disambiguation)">
Quagmire (disambiguation)

Quagmire may refer to:

</doc>
<doc id="25305" url="http://en.wikipedia.org/wiki?curid=25305" title="Crossbow bolt">
Crossbow bolt

A quarrel or bolt is the arrow used in a crossbow. The name "quarrel" is derived from the French "carré", "square", referring to the fact that they typically have square heads. Although their length varies, they are typically shorter than traditional arrows.
Lighted ends.
A recent advancement in quarrels is the "lighted end" which can be attached to the nock of the quarrel, and upon release, will shine a light back to the archer, showing the path and destination of the quarrel. This is used to both improve quarrel recovery, and to show flight and target patterns in shooting and hunting. "Lighted bolt ends are great for detecting errant flight and diagnosing tuning problems when sighting in. In addition, they are pivotal in animal recovery. With proper follow-through, hunters often see their bolt's impact on animals and can recover it. Noting where a bolt entered, then inspecting it after the shot, lets you know how long to wait before taking up the blood trail."

</doc>
<doc id="25308" url="http://en.wikipedia.org/wiki?curid=25308" title="Quasispecies model">
Quasispecies model

The quasispecies model is a description of the process of the Darwinian evolution of certain self-replicating entities within the framework of physical chemistry. Put simply, a quasispecies is a large group or cloud of related genotypes that exist in an environment of high mutation rate, where a large fraction of offspring are expected to contain one or more mutations relative to the parent. This is in contrast to a species, which from an evolutionary perspective is a more-or-less stable single genotype, most of the offspring of which will be genetically accurate copies.
It is useful mainly in providing a qualitative understanding of the evolutionary processes of self-replicating macromolecules such as RNA or DNA or simple asexual organisms such as bacteria or viruses (see also viral quasispecies), and is helpful in explaining something of the early stages of the origin of life. Quantitative predictions based on this model are difficult because the parameters that serve as its input are impossible to obtain from actual biological systems. The quasispecies model was put forward by Manfred Eigen and Peter Schuster based on initial work done by Eigen.
Simplified explanation.
When evolutionary biologists describe competition between species, they generally assume that each species is a single genotype whose descendants are mostly accurate copies. (Such genotypes are said to have a high reproductive "fidelity".) Evolutionarily, we are interested in the behavior and fitness of that one species or genotype over time.
Some organisms or genotypes, however, may exist in circumstances of low fidelity, where most descendants contain one or more mutations. A group of such genotypes is constantly changing, so discussions of which single genotype is the most fit become meaningless. Importantly, if many closely related genotypes are only one mutation away from each other, then genotypes in the group can mutate back and forth into each other. For example, with one mutation per generation, a child of the sequence AGGT could be AGTT, and a grandchild could be AGGT again. Thus we can envision a cloud of related genotypes that is rapidly mutating, with sequences going back and forth among different points in the cloud. Though the proper definition is mathematical, that cloud, roughly speaking, is a quasispecies.
Quasispecies behavior exists for large numbers of individuals existing at a certain (high) range of mutation rates.
Quasispecies, fitness, and evolutionary selection.
In a species, though reproduction may be mostly accurate, periodic mutations will give rise to one or more competing genotypes. If a mutation results in greater replication and survival, the mutant genotype may out-compete the parent genotype and come to dominate the species. Thus, the individual genotypes (or species) may be seen as the units on which selection acts and biologists will often speak of a single genotype's fitness.
In a quasispecies, however, mutations are ubiquitous and so the fitness of an individual genotype becomes meaningless: if one particular mutation generates a boost in reproductive success, it can't amount to much because that genotype's offspring are unlikely to be accurate copies with the same properties. Instead, what matters is the "connectedness" of the cloud. For example, the sequence AGGT has 12 (3+3+3+3) possible single point mutants AGGA, AGGG, and so on. If 10 of those mutants are viable genotypes that may reproduce (and some of whose offspring or grandchildren may mutate back into AGGT again), we would consider that sequence a well-connected node in the cloud. If instead only two of those mutants are viable, the rest being lethal mutations, then that sequence is poorly connected and most of its descendants will not reproduce. The analog of fitness for a quasispecies is the tendency of nearby relatives within the cloud to be well-connected, meaning that more of the mutant descendants will be viable and give rise to further descendants within the cloud.
When the fitness of a single genotype becomes meaningless because of the high rate of mutations, the cloud as a whole or quasispecies becomes the natural unit of selection.
Application to biological research.
Quasispecies represents the evolution of high-mutation-rate viruses such as HIV and sometimes single genes or molecules within the genomes of other organisms. Quasispecies models have also been proposed by Jose Fontanari and Emmanuel David Tannenbaum to model the evolution of sexual reproduction. Quasispecies was also shown in compositional replicators (based on the Gard model for abiogenesis) and was also suggested to be applicable to describe cell's replication, which amongst other things requires the maintenance and evolution of the internal composition of the parent and bud.
Formal background.
The model rests on four assumptions:
In the quasispecies model, mutations occur through errors made in the process of copying already existing sequences. Further, selection arises because different types of sequences tend to replicate at different rates, which leads to the suppression of sequences that replicate more slowly in favor of sequences that replicate faster. However, the quasispecies model does not predict the ultimate extinction of all but the fastest replicating sequence. Although the sequences that replicate more slowly cannot sustain their abundance level by themselves, they are constantly replenished as sequences that replicate faster mutate into them. At equilibrium, removal of slowly replicating sequences due to decay or outflow is balanced by replenishing, so that even relatively slowly replicating sequences can remain present in finite abundance.
Due to the ongoing production of mutant sequences, selection does not act on single sequences, but on mutational "clouds" of closely related sequences, referred to as "quasispecies". In other words, the evolutionary success of a particular sequence depends not only on its own replication rate, but also on the replication rates of the mutant sequences it produces, and on the replication rates of the sequences of which it is a mutant. As a consequence, the sequence that replicates fastest may even disappear completely in selection-mutation equilibrium, in favor of more slowly replicating sequences that are part of a quasispecies with a higher average growth rate. Mutational clouds as predicted by the quasispecies model have been observed in RNA viruses and in "in vitro" RNA replication.
The mutation rate and the general fitness of the molecular sequences and their neighbors is crucial to the formation of a quasispecies. If the mutation rate is zero, there is no exchange by mutation, and each sequence is its own species. If the mutation rate is too high, exceeding what is known as the error threshold, the quasispecies will break down and be dispersed over the entire range of available sequences.
Mathematical description.
A simple mathematical model for a quasispecies is as follows: let there be formula_1 possible sequences and let there be formula_2 organisms with sequence "i". Let's say that each of these organisms asexually gives rise to formula_3 offspring. Some are duplicates of their parent, having sequence "i", but some are mutant and have some other sequence. Let the mutation rate formula_4 correspond to the probability that a "j" type parent will produce an "i" type organism. Then the expected number of "i" type organisms produced by any "j" type parent is formula_5,
where formula_6.
Then the total number of "i"-type organisms after the first round of reproduction, given as formula_7, is
Sometimes a death rate term formula_9 is included so that:
where formula_11 is equal to 1 when i=j and is zero otherwise. Note that the "n-th" generation can be found by just taking the "n-th" power of W substituting it in place of W in the above formula.
This is just a system of linear equations. The usual way to solve such a system is to first diagonalize the W matrix. Its diagonal entries will be eigenvalues corresponding to certain linear combinations of certain subsets of sequences which will be eigenvectors of the W matrix. These subsets of sequences are the quasispecies. Assuming that the matrix W is irreducible, then after very many generations only the eigenvector with the largest eigenvalue will prevail, and it is this quasispecies that will eventually dominate. The components of this eigenvector give the relative abundance of each sequence at equilibrium.
Note about irreducibility.
W being irreducible means that for some integer formula_12, that the formula_13 power of W is > 0, i.e. all the entries are positive. If W is irreducible then each type can, through a sequence of mutations (i.e. powers of W) mutate into all the other types. If W isn't irreducible, then the dominant species (or quasispecies) that develops can depend on the initial population, as is the case in the simple example given below.
Alternative formulations.
The quasispecies formulae may be expressed as a set of linear differential equations. If we consider the difference between the new state formula_7 and the old state formula_2 to be the state change over one moment of time, then we can state that the time derivative of formula_2 is given by this difference, formula_17 we can write:
The quasispecies equations are usually expressed in terms of concentrations formula_19 where
The above equations for the quasispecies then become for the discrete version:
or, for the continuum version:
Simple example.
The quasispecies concept can be illustrated by a simple system consisting of 4 sequences. Sequences [0,0], [0,1], [1,0], and [1,1] are numbered 1, 2, 3, and 4, respectively. Let's say the [0,0] sequence never mutates and always produces a single offspring. Let's say the other 3 sequences all produce, on average, formula_24 replicas of themselves, and formula_25 of each of the other two types, where formula_26. The W matrix is then:
The diagonalized matrix is:
And the eigenvectors corresponding to these eigenvalues are:
Only the eigenvalue formula_29 is more than unity. For the n-th generation, the corresponding eigenvalue will be formula_30 and so will increase without bound as time goes by. This eigenvalue corresponds to the eigenvector [0,1,1,1], which represents the quasispecies consisting of sequences 2, 3, and 4, which will be present in equal numbers after a very long time. Since all population numbers must be positive, the first two quasispecies are not legitimate. The third quasispecies consists of only the non-mutating sequence 1. It's seen that even though sequence 1 is the most fit in the sense that it reproduces more of itself than any other sequence, the quasispecies consisting of the other three sequences will eventually dominate (assuming that the initial population was not homogeneous of the sequence 1 type).

</doc>
<doc id="25310" url="http://en.wikipedia.org/wiki?curid=25310" title="Qing dynasty">
Qing dynasty

The Qing dynasty (; ]), also called Empire of the Great Qing, Great Qing, or Manchu dynasty, was the last imperial dynasty of China, ruling from 1644 to 1912 with a brief, abortive restoration in 1917. It was preceded by the Ming dynasty and succeeded by the Republic of China. The Qing multi-cultural empire lasted almost three centuries and formed the territorial base for the modern Chinese state.
The dynasty was founded by the Jurchen Aisin Gioro clan in Manchuria. In the late sixteenth century, Nurhaci, originally a Ming vassal, began organizing Jurchen clans into "Banners", military-social units. Nurhaci formed these clans into a unified entity, the subjects of which became known collectively as the Manchu people. By 1636, his son Hong Taiji began driving Ming forces out of Liaodong and declared a new dynasty, the Qing. In 1644, peasant rebels led by Li Zicheng conquered the Ming capital Beijing. Rather than serve them, Ming general Wu Sangui made an alliance with the Manchus and opened the Shanhai Pass to the Banner Armies led by Prince Dorgon, who defeated the rebels and seized Beijing. The conquest of China proper was not completed until 1683 under the Kangxi Emperor (r. 1661–1722). The Ten Great Campaigns of the Qianlong Emperor from the 1750s to the 1790s extended Qing control into Central Asia. While the early rulers maintained their Manchu ways (such as they were simultaneously emperors to the Han Chinese, khans to the Mongols and patrons of Tibetan Buddhism), they governed using Confucian styles and institutions of bureaucratic government. They retained the imperial examinations to recruit Han Chinese to work under or in parallel with Manchus. They also adapted the ideals of the tributary system in international relations, and in places such as Taiwan, the Qing so-called internal foreign policy closely resembled colonial policy and control.
The reign of the Qianlong Emperor (1735–1796) saw the apogee and initial decline in prosperity and imperial control. The population rose to some 400 million, but taxes and government revenues were fixed at a low rate, virtually guaranteeing eventual fiscal crisis. Corruption set in, rebels tested government legitimacy, and ruling elites did not change their mindsets in the face of changes in the world system. Following the Opium War, European powers imposed unequal treaties, free trade, extraterritoriality and treaty ports under foreign control. The Taiping Rebellion (1849–60) and Dungan Revolt (1862–77) in Central Asia led to the deaths of some 20 million people. In spite of these disasters, in the Tongzhi Restoration of the 1860s, Han Chinese elites rallied to the defense of the Confucian order and the Qing rulers. The initial gains in the Self-Strengthening Movement were destroyed in the First Sino-Japanese War of 1895, in which the Qing lost its influence over Korea and the possession of Taiwan. New Armies were organized, but the ambitious Hundred Days' Reform of 1898 was turned back by Empress Dowager Cixi, a ruthless but capable leader. When, in response to the violently anti-foreign Yihetuan ("Boxers"), foreign powers invaded China, the Empress Dowager declared war on them, leading to defeat and the flight of the Imperial Court to Xi'an.
After agreeing to sign the Boxer Protocol the government then initiated unprecedented fiscal and administrative reforms, including elections, a new legal code, and abolition of the examination system. Sun Yat-sen and other revolutionaries competed with reformers such as Liang Qichao and monarchists such as Kang Youwei to transform the Qing empire into a modern nation. After the death of the Empress Dowager and the Emperor in 1908, the hardline Manchu court alienated reformers and local elites alike. Local uprisings starting on October 11, 1911 led to the 1911 Revolution. The last emperor abdicated on February 12, 1912.
Names.
Nurhaci originally named his state the "Great Jin" (lit. "gold") dynasty in honor both of the 12–13th century Jurchen Jin dynasty and of his Aisin Gioro clan ("Aisin" being Manchu for the Chinese 金 ("jīn", "gold")), and afterwards called the "Later Jin dynasty" by historians. His son Hong Taiji renamed the dynasty "Great Qing" in 1636. There are competing explanations on the meaning of "Qīng" (lit. "clear" or "pure"). The name may have been selected in reaction to the name of the Ming dynasty (明), which consists of the Chinese characters for "sun" (日) and "moon" (月), both associated with the fire element of the Chinese zodiacal system. The character "Qīng" (清) is composed of "water" (氵) and "azure" (青), both associated with the water element. This association would justify the Qing conquest as defeat of fire by water. The water imagery of the new name may also have had Buddhist overtones of perspicacity and enlightenment and connections with the Bodhisattva Manjusri.
After conquering "China proper", the Manchus identified their state as "China" (中國, "Zhōngguó"; "Middle Kingdom"), and referred to it as "Dulimbai Gurun" in Manchu ("Dulimbai" means "central" or "middle," "gurun" means "nation" or "state"). The emperors equated the lands of the Qing state (including present day Northeast China, Xinjiang, Mongolia, Tibet and other areas) as "China" in both the Chinese and Manchu languages, defining China as a multi-ethnic state, and rejecting the idea that "China" only meant Han areas. The Qing emperors proclaimed that both Han and non-Han peoples were part of "China." They used both "China" and "Qing" to refer to their state in official documents, international treaties (as the Qing was known internationally as "China" or the "Chinese Empire") and foreign affairs, and "Chinese language" ("Dulimbai gurun i bithe") included Chinese, Manchu, and Mongol languages, and "Chinese people" (中國之人 "Zhōngguó zhī rén"; Manchu: "Dulimbai gurun i niyalma") referred to all subjects of the empire.
In the Chinese-language versions of its treaties and its maps of the world, the Qing government used "Qing" and "China" interchangeably.
The Manchu name "daicing", which sounds like a phonetic rendering of "Dà Qīng" or "Dai Ching", may in fact have been derived from a Mongolian word that means "warrior". "Daicing gurun" may therefore have meant "warrior state", a pun that was only intelligible to Manchu and Mongol people. In the later part of the dynasty, however, even the Manchus themselves had forgotten this possible meaning.
When the Qing conquered Dzungaria in 1759, they proclaimed that the new land was absorbed into "China" ("Dulimbai Gurun") in a Manchu language memorial. The Manchu language version of the Convention of Kyakhta (1768), a treaty with the Russian Empire concerning criminal jurisdiction over bandits, referred to people from the Qing as "people from the Central Kingdom ("Dulimbai Gurun")".
History.
Formation of the Manchu state.
The Qing dynasty was founded not by Han Chinese, who form the majority of the Chinese population, but by a sedentary farming people known as the Jurchen, a Tungusic people who lived around the region now comprising the Chinese provinces of Jilin and Heilongjiang. What was to become the Manchu state was founded by Nurhaci, the chieftain of a minor Jurchen tribe – the Aisin Gioro – in Jianzhou in the early 17th century. Originally a vassal of the Ming emperors, Nurhachi embarked on an intertribal feud in 1582 that escalated into a campaign to unify the nearby tribes. By 1616, he had sufficiently consolidated Jianzhou so as to be able to proclaim himself Khan of the Great Jin in reference to the previous Jurchen dynasty.
Two years later, Nurhachi announced the "Seven Grievances" and openly renounced the sovereignty of Ming overlordship in order to complete the unification of those Jurchen tribes still allied with the Ming emperor. After a series of successful battles, he relocated his capital from Hetu Ala to successively bigger captured Ming cities in Liaodong Peninsula: first Liaoyang in 1621, then Shenyang (Mukden) in 1625.
Relocating his court from Jianzhou to Liaodong provided Nurhachi access to more resources; it also brought him in close contact with the Mongol domains on the plains of Mongolia. Although by this time the once-united Mongol nation had long since fragmented into individual and hostile tribes, these tribes still presented a serious security threat to the Ming borders. Nurhachi's policy towards the Mongols was to seek their friendship and cooperation against the Ming, securing his western border from a powerful potential enemy.
Furthermore, the Mongols proved a useful ally in the war, lending the Jurchens their expertise as cavalry archers. To cement this new alliance, Nurhachi initiated a policy of inter-marriages between the Jurchen and Mongol nobilities, while those who resisted were met with military action. This is a typical example of Nurhachi's initiatives that eventually became official Qing government policy. During most of the Qing period, the Mongols gave military assistance to the Manchus.
Some of Nurhaci's other important contributions include ordering the creation of a written Manchu script based on the Mongolian after the earlier Jurchen script was forgotten which had been derived from Khitan and Chinese and the creation of the civil and military administrative system which eventually evolved into the Eight Banners, the defining element of Manchu identity and the foundation for transforming the loosely knitted Jurchen tribes into a nation.
Han defectors played a massive role in the Qing conquest of China. Han Chinese Generals who defected to the Manchu were often given women from the Imperial Aisin Gioro family in marriage while the ordinary soldiers who defected were often given non-royal Manchu women as wives. Nurhaci married one of his granddaughters to the Ming General Li Yongfang after he surrendered Fushun in Liaoning to the Manchu in 1618 and a mass marriage of Han Chinese officers and officials to Manchu women numbering 1,000 couples was arranged by Prince Yoto and Hongtaiji in 1632 to promote harmony between the two ethnic groups. Jurchen (Manchu) women married Han Chinese defectors in Liaodong. Aisin Gioro women were married to the sons of the Han Chinese Generals Sun Sike (Sun Ssu-k'o), Geng Jimao (Keng Chi-mao), Shang Kexi (Shang K'o-hsi), and Wu Sangui (Wu San-kuei). Geng Zhongming, a Han bannerman, was awarded the title of Prince Jingnan, and his son Geng Jingmao managed to have both his sons Geng Jingzhong and Geng Zhaozhong become court attendants under Shunzhi and get married to Aisin Gioro women, with Haoge's (a son of Hong Taiji) daughter marrying Geng Jingzhong and Prince Abatai's granddaughter marrying Geng Zhaozhong.
Nurhachi's unbroken series of military successes came to an end in January 1626 when he was defeated by Yuan Chonghuan while laying siege to Ningyuan. He died a few months later and was succeeded by his eighth son, Hong Taiji, who emerged after a short political struggle amongst other potential contenders as the new Khan.
Although Hong Taiji was an experienced leader and the commander of two Banners at the time of his succession, his reign did not start well on the military front. The Jurchens suffered yet another defeat in 1627 at the hands of Yuan Chonghuan. As before, this defeat was, in part, due to Ming's newly acquired Portuguese cannons.
To redress the technological and numerical disparity, Hong Taiji in 1634 created his own artillery corps, the "ujen chooha", Chinese: 重軍 from among his existing Han troops who cast their own cannons in the European design with the help of defector Chinese metallurgists. In 1635, the Manchus' Mongol allies were fully incorporated into a separate Banner hierarchy under direct Manchu command. Hong Taiji then proceeded in 1636 to invade Korea again.
This was followed by the creation of the first two Han Banners in 1637 (increasing to eight in 1642). Together these military reforms enabled Hong Taiji to resoundingly defeat Ming forces in a series of battles from 1640 to 1642 for the territories of Songshan and Jinzhou. This final victory resulted in the surrender of many of the Ming dynasty's most battle-hardened troops, the death of Yuan Chonghuan at the hands of the Chongzhen Emperor (who thought Yuan had betrayed him), and the complete and permanent withdrawal of the remaining Ming forces north of the Great Wall.
Meanwhile, Hong Taiji set up a rudimentary bureaucratic system based on the Ming model. He established six boards or executive level ministries in 1631 to oversee finance, personnel, rites, military, punishments, and public works. However, these administrative organs had very little role initially, and it was not until the eve of completing the conquest some ten years later that they filled out their government roles.
Hong Taiji's bureaucracy was staffed with many Han Chinese, including many newly surrendered Ming officials. The Manchus' continued dominance was ensured by an ethnic quota for top bureaucratic appointments. Hong Taiji's reign also saw a fundamental change of policy towards his Han Chinese subjects. Nurhaci had treated Han in Liaodong differently according to how much grain they had, those with less than 5 to 7 sin were treated like chattel while those with more than that amount were rewarded with property. Due to a revolt by Han in Liaodong in 1623, Nurhachi, who previously gave concessions to conquered Han subjects in Liaodong, turned against them and ordered that they no longer be trusted and enacted discriminatory policies and killings against them, while ordering that Han who assimilated to the Jurchen (in Jilin) before 1619 be treated equally as Jurchens were and not like the conquered Han in Liaodong. Hong Taiji instead incorporated them into the Jurchen "nation" as full (if not first-class) citizens, obligated to provide military service. By 1648, less than one-sixth of the bannermen were of Manchu ancestry. This change of policy not only increased Hong Taiji's manpower and reduced his military dependence on banners not under his personal control, it also greatly encouraged other Han Chinese subjects of the Ming dynasty to surrender and accept Jurchen rule when they were defeated militarily. Through these and other measures Hong Taiji was able to centralize power unto the office of the Khan, which in the long run prevented the Jurchen federation from fragmenting after his death.
One of the defining events of Hong Taiji's reign was the official adoption of the name "Manchu" for the united Jurchen people in November, 1635. The next year, when he is said to be presented with the imperial seal of the Yuan dynasty after the defeat of the last Khagan of the Mongols, Hong Taiji renamed his state from "Great Jin" to "Great Qing" and elevated his position from Khan to Emperor, suggesting imperial ambitions beyond unifying the Manchu territories.
Claiming the Mandate of Heaven.
Hong Taiji died suddenly in September 1643 without a designated heir. As the Jurchens had traditionally "elected" their leader through a council of nobles, the Qing state did not have in place a clear succession system until the reign of the Kangxi Emperor. The leading contenders for power at this time were Hong Taiji's oldest son Hooge and Hong Taiji' half brother Dorgon. A compromise candidate in the person of Hong Taiji's five-year-old son, Fulin, was installed as the Shunzhi Emperor, with Dorgon as regent and de facto leader of the Manchu nation.
Ming government officials fought against each other, against fiscal collapse, and against a series of peasant rebellions. They were unable to capitalise on the Manchu succession dispute and installation of a minor as emperor. In April 1644, the capital at Beijing was sacked by a coalition of rebel forces led by Li Zicheng, a former minor Ming official, who established a short-lived Shun dynasty. The last Ming ruler, the Chongzhen Emperor, committed suicide when the city fell, marking the official end of the dynasty.
Li Zicheng then led a coalition of rebel forces numbering 200,000 to confront Wu Sangui, the general commanding the Ming garrison at Shanhai Pass. Shanhai Pass is a pivotal pass of the Great Wall, located fifty miles northeast of Beijing, and for years its defenses kept the Manchus from directly raiding the Ming capital. Wu Sangui, caught between a rebel army twice his size and a foreign enemy he had fought for years, decided to cast his lot with the Manchus, with whom he was familiar. Wu Sangui may have been influenced by Li Zicheng's mistreatment of his family and other wealthy and cultured officials; it was said that Li also took Wu's concubine Chen Yuanyuan for himself. Wu and Dorgon allied in the name of avenging the death of the Chongzhen Emperor. Together, the two former enemies met and defeated Li Zicheng's rebel forces in battle on May 27, 1644.
The newly allied armies captured Beijing on June 6. The Shunzhi Emperor was invested as the "Son of Heaven" on October 30. The Manchus, who had positioned themselves as political heir to the Ming emperor by defeating the rebel Li Zicheng, completed the symbolic transition by holding a formal funeral for the Chongzhen Emperor. However the process of conquering the rest of China took another seventeen years of battling Ming loyalists, pretenders and rebels. The last Ming pretender, Prince Gui, sought refuge with the King of Burma, but was turned over to a Qing expeditionary army commanded by Wu Sangui, who had him brought back to Yunnan province and executed in early 1662.
Han Chinese Banners were made up of Han Chinese who defected to the Qing up to 1644 and joined the Eight Banners, giving them social and legal privileges in addition to being acculturated to Manchu culture. So many Han defected to the Qing and swelled the ranks of the Eight Banners that ethnic Manchus became a minority, making up only 16% in 1648, with Han Bannermen dominating at 75%. This multi-ethnic force in which Manchus were only a minority conquered China for the Qing.
Han Chinese Bannermen were responsible for the successful Qing conquest of China, as they made up the majority of governors in the early Qing, and they governed and administered China after the conquest, stabilizing Qing rule. Han Bannermen dominated the post of governor-general in the time of the Shunzhi and Kangxi Emperors, and also the post of governor, largely excluding ordinary Han civilians from these posts.
The Qing showed that the Manchus valued military skills in propaganda targeted towards the Ming military to get them to defect to the Qing, since the Ming civilian political system discriminated against the military. The three Liaodong Han Bannermen officers who played a massive role in the conquest of southern China from the Ming were Shang Kexi, Geng Zhongming, and Kong Youde and they governed southern China autonomously as viceroys for the Qing after their conquests. Normally the Manchu Bannermen acted only as reserve forces or in the rear and were used predominantly for quick strikes with maximum impact, so as to minimize ethnic Manchu losses; instead, the Qing used defected Han Chinese troops to fight as the vanguard during the entire conquest of China.
Among the Banners, gunpowder weapons like muskets and artillery were specifically wielded by the Chinese Banners.
To promote ethnic harmony, a 1648 decree from Shunzhi allowed Han Chinese civilian men to marry Manchu women from the Banners with the permission of the Board of Revenue if they were registered daughters of officials or commoners or the permission of their banner company captain if they were unregistered commoners, it was only later in the dynasty that these policies allowing intermarriage were done away with.
The first seven years of the Shunzhi Emperor's reign were dominated by the regent prince Dorgon. Because of his own political insecurity, Dorgon followed Hong Taiji's example by ruling in the name of the emperor at the expense of rival Manchu princes, many of whom he demoted or imprisoned under one pretext or another. Although the period of his regency was relatively short, Dorgon cast a long shadow over the Qing dynasty.
First, the Manchus had entered "China proper" because Dorgon responded decisively to Wu Sangui's appeal. Then, after capturing Beijing, instead of sacking the city as the rebels had done, Dorgon insisted, over the protests of other Manchu princes, on making it the dynastic capital and reappointing most Ming officials. Choosing Beijing as the capital had not been a straightforward decision, since no major Chinese dynasty had directly taken over its immediate predecessor's capital. Keeping the Ming capital and bureaucracy intact helped quickly stabilize the regime and sped up the conquest of the rest of the country. However, not all of Dorgon's policies were equally popular nor easily implemented.
Dorgon's controversial July 1645 edict (the "haircutting order") forced adult Han Chinese men to shave the front of their heads and comb the remaining hair into the queue hairstyle which was worn by Manchu men, on pain of death. The popular description of the order was: "To keep the hair, you lose the head; To keep your head, you cut the hair." To the Manchus, this policy was a test of loyalty and an aid in distinguishing friend from foe. For the Han Chinese, however, it was a humiliating reminder of Qing authority that challenged traditional Confucian values. The "Classic of Filial Piety" ("Xiaojing") held that "a person's body and hair, being gifts from one's parents, are not to be damaged." Under the Ming dynasty, adult men did not cut their hair but instead wore it in the form of a top-knot. The order triggered strong resistance to Qing rule in Jiangnan and massive killing of ethnic Han Chinese. Li Chengdong, a Han Chinese general who had served the Ming but surrendered to the Qing, ordered troops to carry out three separate massacres in the city of Jiading within a month, resulting in tens of thousands of deaths. At the end of the third massacre, there was hardly any living person left in this city. Jiangyin also held out against about 10,000 Qing troops for 83 days. When the city wall was finally breached on 9 October 1645, the Qing army led by the Han Chinese Ming defector Liu Liangzuo (劉良佐), who had been ordered to "fill the city with corpses before you sheathe your swords," massacred the entire population, killing between 74,000 and 100,000 people. The queue was the only aspect of Manchu culture which the Qing forced on the common Han population. The Qing required people serving as officials to wear Manchu clothing, but allowed non-official Han civilians to continue wearing Hanfu (Han clothing).
On December 31, 1650, Dorgon suddenly died during a hunting expedition, marking the official start of the Shunzhi Emperor's personal rule. Because the emperor was only 12 years old at that time, most decisions were made on his behalf by his mother, Empress Dowager Xiaozhuang, who turned out to be a skilled political operator.
Although Dorgon's support had been essential to Shunzhi's ascent, Dorgon had through the years centralised so much power in his hands as to become a direct threat to the throne. So much so that upon his death he was extraordinarily bestowed the posthumous title of Emperor Yi (), the only instance in Qing history in which a Manchu "prince of the blood" () was so honored. Two months into Shunzhi's personal rule, Dorgon was not only stripped of his titles, but his corpse was disinterred and mutilated. to atone for multiple "crimes", one of which was persecuting to death Shunzhi’s agnate eldest brother, Hooge. More importantly, Dorgon's symbolic fall from grace also signalled a political purge of his family and associates at court, thus reverting power back to the person of the emperor. After a promising start, Shunzhi's reign was cut short by his early death in 1661 at the age of twenty-four from smallpox. He was succeeded by his third son Xuanye, who reigned as the Kangxi Emperor.
The Kangxi Emperor's reign and consolidation.
The sixty-one year reign of the Kangxi Emperor was the longest of any Chinese emperor. Kangxi's reign is also celebrated as the beginning of an era known as the "High Qing", during which the dynasty reached the zenith of its social, economic and military power. Kangxi's long reign started when he was eight years old upon the untimely demise of his father. To prevent a repeat of Dorgon's dictatorial monopolizing of power during the regency, the Shunzhi Emperor, on his deathbed, hastily appointed four senior cabinet ministers to govern on behalf of his young son. The four ministers — Sonin, Ebilun, Suksaha, and Oboi — were chosen for their long service, but also to counteract each other's influences. Most important, the four were not closely related to the imperial family and laid no claim to the throne. However as time passed, through chance and machination, Oboi, the most junior of the four, achieved such political dominance as to be a potential threat. Even though Oboi's loyalty was never an issue, his personal arrogance and political conservatism led him into an escalating conflict with the young emperor. In 1669 Kangxi, through trickery, disarmed and imprisoned Oboi — a significant victory for a fifteen-year-old emperor over a wily politician and experienced commander.
The early Manchu rulers also established two foundations of legitimacy which help to explain the stability of their dynasty. The first was the bureaucratic institutions and the neo-Confucian culture which they adopted from earlier dynasties. Manchu rulers and Han Chinese scholar-official elites gradually came to terms with each other. The examination system offered a path for ethnic Han to become officials. Imperial patronage of Kangxi Dictionary demonstrated respect for Confucian learning, while the Sacred Edict of 1670 effectively extolled Confucian family values. The second major source of stability was the Central Asian aspect of their Manchu identity which allowed them to appeal to Mongol, Tibetan and Uighur constituents. The Qing rulers were simultaneously emperors to the Han Chinese, khans to the Mongols, and presented themselves as Buddhist sage rulers, patrons of Tibetan Buddhism, for the newly conquered areas of Central Asia. The Kangxi Emperor also welcomed to his court Jesuit missionaries, who had first come to China under the Ming. Missionaries including Tomás Pereira, Martino Martini, Johann Adam Schall von Bell, Ferdinand Verbiest and Antoine Thomas held significant positions as military weapons experts, mathematicians, cartographers, astronomers and advisers to the emperor. The relationship of trust was however lost in the later Chinese Rites controversy.
Yet controlling the "Mandate of Heaven" was a daunting task. The vastness of China's territory meant that there were only enough banner troops to garrison key cities forming the backbone of a defense network that relied heavily on surrendered Ming soldiers. In addition, three surrendered Ming generals were singled out for their contributions to the establishment of the Qing dynasty, ennobled as feudal princes (藩王), and given governorships over vast territories in Southern China. The chief of these was Wu Sangui, who was given the provinces of Yunnan and Guizhou, while generals Shang Kexi and Geng Jingzhong were given Guangdong and Fujian provinces respectively.
As the years went by, the three feudal lords and their extensive territories became increasingly autonomous. Finally, in 1673, Shang Kexi petitioned Kangxi for permission to retire to his hometown in Liaodong province and nominated his son as his successor. The young emperor granted his retirement, but denied the heredity of his fief. In reaction, the two other generals decided to petition for their own retirements to test Kangxi's resolve, thinking that he would not risk offending them. The move backfired as the young emperor called their bluff by accepting their requests and ordering that all three fiefdoms to be reverted to the crown.
Faced with the stripping of their powers, Wu Sangui, later joined by Geng Zhongming and by Shang Kexi's son Shang Zhixin, felt they had no choice but to revolt. The ensuing Revolt of the Three Feudatories lasted for eight years. Wu attempted, ultimately in vain, to fire the embers of south China Ming loyalty by restoring Ming customs, ordering that the resented queues be cut, and declaring himself emperor of a new dynasty. At the peak of the rebels' fortunes, they extended their control as far north as the Yangtze River, nearly establishing a divided China. Wu then hesitated to go further north, not being able to coordinate strategy with his allies, and Kangxi was able to unify his forces for a counterattack led by a new generation of Manchu generals. By 1681, the Qing government had established control over a ravaged southern China which took several decades to recover. Manchu Generals and Bannermen were initially put to shame by the better performance of the Han Chinese Green Standard Army, who fought better than them against the rebels and this was noted by Kangxi, leading him to task Generals Sun Sike, Wang Jinbao, and Zhao Liangdong to lead Green Standard Soldiers to crush the rebels. The Qing thought that Han Chinese were superior at battling other Han people and so used the Green Standard Army as the dominant and majority army in crushing the rebels instead of Bannermen. Similarly, in northwestern China against Wang Fuchen, the Qing used Han Chinese Green Standard Army soldiers and Han Chinese Generals such as Zhang Liangdong, Wang Jinbao, and Zhang Yong as the primary military forces. This choice was due to the rocky terrain, which favoured infantry troops over cavalry, to the desire to keep Bannermen in the reserves, and, again, to the belief that Han troops were better at fighting other Han people. These Han generals achieved victory over the rebels. Also due to the mountainous terrain, Sichuan and southern Shaanxi were also retaken by the Han Chinese Green Standard Army under Wang Jinbao and Zhao Liangdong in 1680, with Manchus only participating in dealing with logistics and provisions. 400,000 Green Standard Army soldiers and 150,000 Bannermen served on the Qing side during the war. 213 Han Chinese Banner companies, and 527 companies of Mongol and Manchu Banners were mobilized by the Qing during the revolt.
To extend and consolidate the dynasty's control in Central Asia, the Kangxi Emperor personally led a series of military campaigns against the Dzungars in Outer Mongolia. The Kangxi Emperor was able to successfully expel Galdan's invading forces from these regions, which were then incorporated into the empire. Galdan was eventually killed in the First Oirat-Manchu War. In 1683, Qing forces took Taiwan from Zheng Keshuang, grandson of Koxinga, who had conquered Taiwan from the Dutch colonists as a base against the Qing. Winning Taiwan freed Kangxi's forces for series of battles over Albazin, the far eastern outpost of Russian Empire. The 1689 Treaty of Nerchinsk was China's first formal treaty with a European power and kept the border peaceful for the better part of two centuries. After Galdan's death, his followers, as adherents to Tibetan Buddhism, attempted to control the choice of the next Dalai Lama. Kangxi dispatched two armies to Lhasa, the capital of Tibet, and installed a Dalai Lama sympathetic to the Qing.
By the end of the 17th century, China was at its greatest height of confidence and political control since the Ming dynasty.
Reigns of the Yongzheng and Qianlong emperors.
The reigns of the Yongzheng Emperor (r. 1723–1735) and his son, the Qianlong Emperor (r. 1735–1796), marked the height of Qing power. During this period, the Qing Empire ruled over 13 million square kilometres of territory.
After the Kangxi Emperor's death in the winter of 1722, his fourth son, Prince Yong (雍親王), became the Yongzheng Emperor. In the later years of Kangxi's reign, Yongzheng and his brothers had fought, and there were rumours that he had usurped the throne, a charge for which there is little evidence. In fact, his father had trusted him with delicate political issues and discussed state policy with him. When Yongzheng came to power at the age of 45, he felt a sense of urgency about the problems which had accumulated in his father's later years and did not need instruction in how to exercise power. In the words of one recent historian, he was "severe, suspicious, and jealous, but extremely capable and resourceful," and in the words of another, turned out to be an "early modern state-maker of the first order."
He moved rapidly. First, he promoted Confucian orthodoxy and reversed what he saw as his father's laxness by cracking down on unorthodox sects and by decapitating an anti-Manchu writer his father had pardoned. In 1723 he outlawed Christianity and expelled Christian missionaries, though some were allowed to remain in the capital. Next, he moved to control the government. He expanded his father's system of Palace Memorials which brought frank and detailed reports on local conditions directly to the throne without being intercepted by the bureaucracy, and created a small Grand Council of personal advisors which eventually grew into the emperor's "de facto" cabinet for the rest of the dynasty. He shrewdly filled key positions with Manchu and Han Chinese officials who depended on his patronage. When he began to realize that the financial crisis was even greater than he had thought, Yongzheng rejected his father's lenient approach to local landowning elites and mounted a campaign to enforce collection of the land tax. The increased revenues were to be used for "money to nourish honesty" among local officials and for local irrigation, schools, roads, and charity. Although these reforms were effective in the north, in the south and lower Yangzi valley, where Kangxi had wooed the elites, there were long established networks of officials and landowners. Yongzheng dispatched experienced Manchu commissioners to penetrate the thickets of falsified land registers and coded account books, but they were met with tricks, passivity, and even violence. The fiscal crisis persisted.
In 1725 Yongzheng bestowed the hereditary title of Marquis on a descendant of the Ming dynasty Imperial family, Zhu Zhiliang, who received a salary from the Qing government and whose duty was to perform rituals at the Ming tombs, and was also inducted the Chinese Plain White Banner in the Eight Banners. Later the Qianlong Emperor bestowed the title Marquis of Extended Grace posthumously on Zhu Zhuliang in 1750, and the title passed on through twelve generations of Ming descendants until the end of the Qing dynasty.
Yongzheng also inherited diplomatic and strategic problems. A team made up entirely of Manchus drew up the Treaty of Kyakhta (1727) to solidify the diplomatic understanding with Russia. In exchange for territory and trading rights, the Qing would have a free hand dealing with the situation in Mongolia. Yongzheng then turned to that situation, where the Zunghars threatened to re-emerge, and to the southwest, where local Miao chieftains resisted Qing expansion. These campaigns drained the treasury but established the emperor's control of the military and military finance.
The Yongzheng Emperor died in 1735. His 24-year-old son, Prince Bao (寶親王), then became the Qianlong Emperor. Qianlong personally led military campaigns near Xinjiang and Mongolia, putting down revolts and uprisings in Sichuan and parts of southern China while expanding control over Tibet.
Qianlong's reign saw the launch of several ambitious cultural projects, including the compilation of the "Siku Quanshu", or "Complete Repository of the Four Branches of Literature". With a total of over 3,400 books, 79,000 chapters, and 36,304 volumes, the "Siku Quanshu" is the largest collection of books in Chinese history. Nevertheless, Qianlong used Literary Inquisition to silence opposition. The accusation of individuals began with the emperor's own interpretation of the true meaning of the corresponding words. If the emperor decided these were derogatory or cynical towards the dynasty, persecution would begin. Literary inquisition began with isolated cases at the time of Shunzhi and Kangxi, but became a pattern under Qianlong's rule, during which there were 53 cases of literary persecution.
Beneath outward prosperity and imperial confidence, the later years of Qianlong's reign saw rampant corruption and neglect. Heshen, the emperor's handsome young favorite, took advantage of the emperor's indulgence to become one of the most corrupt officials in the history of the dynasty. Qianlong's son, the Jiaqing Emperor (r. 1796–1820), eventually forced Heshen to commit suicide.
China also began suffering from mounting overpopulation during this period. Population growth was stagnant for the first half of the 17th century due to civil wars and epidemics, but prosperity and internal stability gradually reversed this trend. The introduction of new crops from the Americas such as the potato and peanut allowed an improved food supply as well, so that the total population of China during the 18th century ballooned from 100 million to 300 million people. Soon all available farmland was used up, forcing peasants to work ever-smaller and more intensely worked plots. Emperor Qianlong once bemoaned the country's situation by remarking "The population continues to grow, but the land does not." The only remaining part of the empire that had arable farmland was Manchuria, where the provinces of Jilin and Heilongjiang had been walled off as a Manchu homeland. The emperor decreed for the first time that Han Chinese civilians were forbidden to settle.
In 1796, open rebellion by the White Lotus Society against the Qing government broke out. The White Lotus Rebellion continued for eight years, until 1804, and marked a turning point in the history of the Qing dynasty.
Rebellion, unrest and external pressure.
At the start of the dynasty, the Chinese empire continued to be the hegemonic power in East Asia. Although there was no formal ministry of foreign relations, the Lifan Yuan was responsible for relations with the Mongol and Tibetans in Central Asia, while the tributary system, a loose set of institutions and customs taken over from the Ming, in theory governed relations with East and Southeast Asian countries. The Treaty of Nerchinsk (1689) stabilized relations with Czarist Russia.
However, the 18th century saw the European empires gradually expand across the world, as European states developed economies built on maritime trade. The dynasty was confronted with newly developing concepts of the international system and state to state relations. European trading posts expanded into territorial control in nearby India and on the islands that are now Indonesia. The Qing response, successful for a time, was in 1756 to establish the Canton System, which restricted maritime trade to that city and gave monopoly trading rights to private Chinese merchants. The British East India Company and the Dutch East India Company had long before been granted similar monopoly rights by their governments.
In 1793, the British East India Company, with the support of the British government, sent a delegation to China under Lord George Macartney in order to open free trade and put relations on a basis of equality. The imperial court viewed trade as unimportant, whereas the British saw maritime trade as the key to their economy. The Qianlong Emperor told Macartney "the kings of the myriad nations come by land and sea with all sorts of precious things," and "consequently there is nothing we lack..."
Demand in Europe for Chinese goods such as silk, tea, and ceramics could only be met if European companies funneled their limited supplies of silver into China. In the late 1700s, the governments of Great Britain and France were deeply concerned about the imbalance of trade and the drain of silver. To meet the growing Chinese demand for opium, the British East India Company greatly expanded its production in Bengal. Since China's economy was essentially self-sufficient, the country had little need to import goods or raw materials from the Europeans, so the usual way of payment was through silver. The Daoguang emperor, concerned both over the outflow of silver and the damage that opium smoking was causing to his subjects, ordered Lin Zexu to end the opium trade. Lin confiscated the stocks of opium without compensation in 1839, leading Great Britain to declare war on China in the following year.
The First Opium War revealed the outdated state of the Chinese military. The Qing navy, composed entirely of wooden sailing junks, was severely outclassed by the modern tactics and firepower of the British Royal Navy. British soldiers, using advanced muskets and artillery, easily outmaneuvered and outgunned Qing forces in ground battles. The Qing surrender in 1842 marked a decisive, humiliating blow to China. The Treaty of Nanjing, the first of the unequal treaties, demanded war reparations, forced China to open up the five ports of Canton, Amoy, Fuchow, Ningpo and Shanghai to western trade and missionaries, and to cede Hong Kong Island to Great Britain. It revealed many inadequacies in the Qing government and provoked widespread rebellions against the already hugely unpopular regime.
The Taiping Rebellion in the mid-19th century was the first major instance of anti-Manchu sentiment threatening the stability of the dynasty. Hong Xiuquan, a failed civil service candidate, led the Taiping Rebellion, amid widespread social unrest and worsening famine. In 1851 Hong Xiuquan and others launched an uprising in Guizhou province, established the Taiping Heavenly Kingdom with Hong himself as king, claiming he often had visions of God and that he was the brother of Jesus Christ. Slavery, concubinage, arranged marriage, opium smoking, footbinding, judicial torture, and the worship of idols were all banned. However, success and subsequent authority and power led to internal feuds, defections and corruption. In addition, British and French troops, equipped with modern weapons, had come to the assistance of the Qing imperial army. It was not until 1864 that Qing armies under Zeng Guofan succeeded in crushing the revolt. The rebellion not only posed the most serious threat towards Qing rulers; it was also "bloodiest civil war of all time." Between 20 and 30 million people died during its fourteen-year course from 1850 to 1864. After the outbreak of this rebellion, there were also revolts by the Muslims and Miao people of China against the Qing dynasty, most notably in the Dungan Revolt (1862–77) in the northwest and the Panthay Rebellion (1856–1873) in Yunnan.
The Western powers, largely unsatisfied with the Treaty of Nanjing, gave grudging support to the Qing government during the Taiping and Nian Rebellions. China's income fell sharply during the wars as vast areas of farmland were destroyed, millions of lives were lost, and countless armies were raised and equipped to fight the rebels. In 1854, Great Britain tried to re-negotiate the Treaty of Nanjing, inserting clauses allowing British commercial access to Chinese rivers and the creation of a permanent British embassy at Beijing.
In 1856, Qing authorities, in searching for a pirate, boarded a ship, the "Arrow", which the British claimed had been flying the British flag, an incident which led to the Second Opium War. In 1858, facing no other options, the Xianfeng Emperor agreed to the Treaty of Tientsin, which contained clauses deeply insulting to the Chinese, such as a demand that all official Chinese documents be written in English and a proviso granting British warships unlimited access to all navigable Chinese rivers.
Ratification of the treaty the following year led to resumption of hostilities and in 1860, with Anglo-French forces marching on Beijing, the emperor and his court fled the capital for the imperial hunting lodge at Rehe. Once in Beijing, the Anglo-French forces looted the Old Summer Palace, and in an act of revenge for the arrest of several Englishmen, burnt it to the ground. Prince Gong, a younger half-brother of the emperor, who had been left as his brother's proxy in the capital, was forced to sign the Convention of Beijing. Meanwhile, the humiliated emperor died the following year at Rehe.
Self-strengthening and the frustration of reforms.
Yet the dynasty rallied. Chinese generals and officials such as Zuo Zongtang led the suppression of rebellions and stood behind the Manchus. When the Tongzhi Emperor came to the throne at the age of five in 1861, these officials rallied around him in what was called the Tongzhi Restoration. Their aim was to adopt western military technology in order to preserve Confucian values. Zeng Guofan, in alliance with Prince Gong, sponsored the rise of younger officials such as Li Hongzhang, who put the dynasty back on its feet financially and instituted the Self-Strengthening Movement. The reformers then proceeded with institutional reforms, including China's first unified ministry of foreign affairs, the Zongli Yamen; allowing foreign diplomats to reside in the capital; establishment of the Imperial Maritime Customs Service; the formation of modernized armies, such as the Beiyang Army, as well as a navy; and the purchase from Europeans of armament factories. 
The dynasty lost control of peripheral territories bit by bit. In return for promises of support against the British and the French, Czarist Russia took large chunks of territory in the Northeast in 1860. The period of cooperation between the reformers and the European powers ended with the Tientsin Massacre of 1870, which was incited by the murder of French nuns set off by the belligerence of local French diplomats. Starting with the Cochinchina Campaign in 1858, France expanded control of Indochina. By 1883, France was in full control of the region and had reached the Chinese border. The Sino-French War over Tonkin, once a Qing tributary state, ended in 1885 with French victory and Chinese recognition of all the French claims to it.
In 1884, pro-Japanese Koreans in Seoul led the Gapsin Coup. Tensions between China and Japan rose after China intervened to suppress the uprising. Japanese Prime Minister Itō Hirobumi and Li Hongzhang signed the Convention of Tientsin, an agreement to withdraw troops simultaneously, but the First Sino-Japanese War of 1895 was a military humiliation. The Treaty of Shimonoseki recognized Korean independence and ceded Taiwan and the Pescadores to Japan. The terms might have been harsher, but when Japanese citizen attacked and wounded Li Hongzhang, an international outcry shamed the Japanese into revising them. The original agreement stipulated the cession of Liaodong Peninsula to Japan, but Russia, with its own designs on the territory, along with Germany and France, in what was known as the Triple Intervention, successfully put pressure on the Japanese to abandon the peninsula.
These years saw an evolution in the participation of Empress Dowager Cixi (Wade–Giles: Tz'u-Hsi) in state affairs. She entered the imperial palace in the 1850s as a concubine to the Xianfeng Emperor (r. 1850–1861) and came to power in 1861 after her five-year-old son, the Tongzhi Emperor ascended the throne. She, the Empress Dowager Ci'an (who had been Xianfeng's empress), and Prince Gong (a son of the Daoguang Emperor), staged a coup that ousted several regents for the boy emperor. Between 1861 and 1873, she and Ci'an served as regents, choosing the reign title "Tongzhi" (ruling together). Following the emperor's death in 1875, Cixi's nephew, the Guangxu Emperor, took the throne, in violation of the dynastic custom that the new emperor be of the next generation, and another regency began. In the spring of 1881, Ci'an suddenly died, aged only forty-three, leaving Cixi as sole regent. 
From 1889, when Guangxu began to rule in his own right, to 1898, the Empress Dowager lived in semi-retirement, spending the majority of the year at the Summer Palace. On November 1, 1897, two German Roman Catholic missionaries were murdered in the southern part of Shandong Province (the Juye Incident). In response, Germany used the murders as a pretext for a naval occupation of Jiaozhou Bay. The occupation prompted a "scramble for concessions" in 1898, which included the German lease of Jiazhou Bay, the Russian acquisition of Liaodong, and the British lease of the New Territories of Hong Kong.
In the wake of these external defeats, Emperor Guangxu initiated the Hundred Days' Reform of 1898. Newer, more radical advisers such as Kang Youwei were given positions of influence. The emperor issued a series of edicts and plans were made to reorganize the bureaucracy, restructure the school system, and appoint new officials. Opposition from the bureaucracy was immediate and intense. Although she had been involved in the initial reforms, the empress dowager stepped in to call them off, arrested and executed several reformers, and took over day-to-day control of policy. Yet many of the plans stayed in place, and the goals of reform were implanted.
Widespread drought in North China, combined with the imperialist designs of European powers and the instability of the Qing government, created conditions that led to the emergence of the Righteous and Harmonious Fists, or "Boxers." In 1900, local groups of Boxers proclaiming support for the Qing dynasty murdered foreign missionaries and large numbers of Chinese Christians, then converged on Beijing to besiege the Foreign Legation Quarter. A coalition of European, Japanese, and Russian armies (the Eight-Nation Alliance) then entered China without diplomatic notice, much less permission. Cixi declared war on all of these nations, only to lose control of Beijing after a short, but hard-fought campaign. She fled to Xi'an. The victorious allies drew up scores of demands on the Qing government, including compensation for their expenses in invading China and execution of complicit officials.
Reform, revolution, collapse.
By the early 20th century, mass civil disorder had begun in China, and it was growing continuously. To overcome such problems, Empress Dowager Cixi issued an imperial edict in 1901 calling for reform proposals from the governors-general and governors and initiated the era of the dynasty's "New Policies", also known as the "Late Qing Reform". The edict paved the way for the most far-reaching reforms in terms of their social consequences, including the creation of a national education system and the abolition of the imperial examinations in 1905.
The Guangxu Emperor died on November 14, 1908, and on November 15, 1908, Cixi also passed away. Rumors held that she or Yuan Shikai ordered trusted eunuchs to poison the Guangxu Emperor, and an autopsy conducted nearly a century later confirmed lethal levels of arsenic in his corpse. Puyi, the oldest son of Zaifeng, Prince Chun, and nephew to the childless Guangxu emperor, was appointed successor at the age of two, leaving Zaifeng with the regency. This was followed by the dismissal of General Yuan Shikai from his former positions of power. In April 1911 Zaifeng created a cabinet in which there were two vice-premiers. Nonetheless, this cabinet was also known by contemporaries as "The Royal Cabinet" because among the thirteen cabinet members, five were members of the imperial family or Aisin Gioro relatives. This brought a wide range of negative opinions from senior officials like Zhang Zhidong. 
The Wuchang Uprising of October 10, 1911, led to the creation of a new central government, the Republic of China, in Nanjing with Sun Yat-sen as its provisional head. Many provinces soon began "separating" from Qing control. Seeing a desperate situation unfold, the Qing government brought Yuan Shikai back to military power. He took control of his Beiyang Army to crush the revolution in Wuhan at the Battle of Yangxia. After taking the position of Prime Minister and creating his own cabinet, Yuan Shikai went as far as to ask for the removal of Zaifeng from the regency. This removal later proceeded with directions from Empress Dowager Longyu.
With Zaifeng gone, Yuan Shikai and his Beiyang commanders effectively dominated Qing politics. He reasoned that going to war would be unreasonable and costly, especially when noting that the Qing government had a goal for constitutional monarchy. Similarly, Sun Yat-sen's government wanted a republican constitutional reform, both aiming for the benefit of China's economy and populace. With permission from Empress Dowager Longyu, Yuan Shikai began negotiating with Sun Yat-sen, who decided that his goal had been achieved in forming a republic, and that therefore he could allow Yuan to step into the position of President of the Republic of China.
On 12 February 1912, after rounds of negotiations, Longyu issued an imperial edict bringing about the abdication of the child emperor Puyi. This brought an end to over 2,000 years of imperial China and began an extended period of instability of warlord factionalism. The unorganized political and economic systems combined with a widespread criticism of Chinese culture led to questioning and doubt about the future. In the 1930s, the Empire of Japan invaded Northeast China and founded Manchukuo in 1932, with Puyi, as the emperor. After the invasion by the Soviet Union, Manchukuo collapsed in 1945.
Government.
The early Qing emperors adopted the bureaucratic structures and institutions from the preceding Ming dynasty but split rule between Han Chinese and Manchus, with some positions also given to Mongols. Like previous dynasties, the Qing recruited officials via the imperial examination system, until the system was abolished in 1905. The Qing divided the positions into civil and military positions, each having nine grades or ranks, each subdivided into a and b categories. Civil appointments ranged from attendant to the emperor or a Grand Secretary in the Forbidden City (highest) to being a prefectural tax collector, deputy jail warden, deputy police commissioner or tax examiner. Military appointments ranged from being a field marshal or chamberlain of the imperial bodyguard to a third class sergeant, corporal or a first or second class private.
Central government agencies.
The formal structure of the Qing government centered on the Emperor as the absolute ruler, who presided over six Boards (Ministries), each headed by two presidents and assisted by four vice presidents. In contrast to the Ming system, however, Qing ethnic policy dictated that appointments were split between Manchu noblemen and Han officials who had passed the highest levels of the state examinations. The Grand Secretariat, which had been an important policy-making body under the Ming, lost its importance during the Qing and evolved into an imperial chancery. The institutions which had been inherited from the Ming formed the core of the Qing "Outer Court," which handled routine matters and was located in the southern part of the Forbidden City.
In order not to let the routine administration take over the running of the empire, the Qing emperors made sure that all important matters were decided in the "Inner Court," which was dominated by the imperial family and Manchu nobility and which was located in the northern part of the Forbidden City. The core institution of the inner court was the Grand Council. It emerged in the 1720s under the reign of the Yongzheng Emperor as a body charged with handling Qing military campaigns against the Mongols, but it soon took over other military and administrative duties and served to centralize authority under the crown. The Grand Councillors served as a sort of privy council to the emperor.
The Six Ministries and their respective areas of responsibilities were as follows:
From the early Qing, the central government was characterized by a system of dual appointments by which each position in the central government had a Manchu and a Han Chinese assigned to it. The Han Chinese appointee was required to do the substantive work and the Manchu to ensure Han loyalty to Qing rule. The distinction between Han Chinese and Manchus extended to their court costumes. During the Qianlong Emperor's reign, for example, members of his family were distinguished by garments with a small circular emblem on the back, whereas Han officials wore clothing with a square emblem.
In addition to the six boards, there was a Lifan Yuan unique to the Qing government. This institution was established to supervise the administration of Tibet and the Mongol lands. As the empire expanded, it took over administrative responsibility of all minority ethnic groups living in and around the empire, including early contacts with Russia — then seen as a tribute nation. The office had the status of a full ministry and was headed by officials of equal rank. However, appointees were at first restricted only to candidates of Manchu and Mongol ethnicity, until later open to Han Chinese as well.
Even though the Board of Rites and Lifan Yuan performed some duties of a foreign office, they fell short of developing into a professional foreign service. It was not until 1861 — a year after losing the Second Opium War to the Anglo-French coalition — that the Qing government bowed to foreign pressure and created a proper foreign affairs office known as the Zongli Yamen. The office was originally intended to be temporary and was staffed by officials seconded from the Grand Council. However, as dealings with foreigners became increasingly complicated and frequent, the office grew in size and importance, aided by revenue from customs duties which came under its direct jurisdiction.
There was also another government institution called Imperial Household Department which was unique to the Qing dynasty. It was established before the fall of the Ming, but it became mature only after 1661, following the death of the Shunzhi Emperor and the accession of his son, the Kangxi Emperor. The department's original purpose was to manage the internal affairs of the imperial family and the activities of the inner palace (in which tasks it largely replaced eunuchs), but it also played an important role in Qing relations with Tibet and Mongolia, engaged in trading activities (jade, ginseng, salt, furs, etc.), managed textile factories in the Jiangnan region, and even published books. Relations with the Salt Superintendents and salt merchants, such as those at Yangzhou, were particularly lucrative, especially since they were direct, and did not go through absorptive layers of bureaucracy. The department was manned by "booi", or "bondservants," from the Upper Three Banners. By the 19th century, it managed the activities of at least 56 subagencies.
Administrative divisions.
Qing China reached its largest extent during the 18th century, when it ruled China proper (eighteen provinces) as well as the areas of present-day Northeast China, Inner Mongolia, Outer Mongolia, Xinjiang and Tibet, at approximately 13 million km2 in size. There were originally 18 provinces, all of which in China proper, but later this number was increased to 22, with Manchuria and Xinjiang being divided or turned into provinces. Taiwan, originally part of Fujian province, became a province of its own in the 19th century, but was ceded to the Empire of Japan following the First Sino-Japanese War by the end of the century. In addition, many surrounding countries, such as Korea (Joseon dynasty), Vietnam were tributary states of China during much of this period. The Katoor dynasty of Afghanistan also paid tribute to the Qing dynasty of China until the mid-19th century. During the Qing dynasty the Chinese claimed suzerainty over the Taghdumbash Pamir in the south west of Tashkurgan Tajik Autonomous County but permitted the Mir of Hunza to administer the region in return for a tribute. Until 1937 the inhabitants paid tribute to the Mir of Hunza, who exercised control over the pastures. The Hunzas of northern Pakistan were tributaries and allies to China, acknowledging China as suzerain since 1761. Khanate of Kokand were forced to submit as protectorate and pay tribute to the Qing dynasty in China between 1774 and 1798.
Territorial administration.
The Qing organization of provinces was based on the fifteen administrative units set up by the Ming dynasty, later made into eighteen provinces by splitting for example, Huguang into Hubei and Hunan provinces. The provincial bureaucracy continued the Yuan and Ming practice of three parallel lines, civil, military, and censorate, or surveillance. Each province was administered by a governor (巡撫, "xunfu") and a provincial military commander (提督, "tidu"). Below the province were prefectures (府, "fu") operating under a prefect (知府, "zhīfǔ"), followed by subprefectures under a subprefect. The lowest unit was the county, overseen by a county magistrate. The eighteen provinces are also known as "China proper". The position of viceroy or governor-general (總督, "zongdu") was the highest rank in the provincial administration. There were eight regional viceroys in China proper, each usually took charge of two or three provinces. The Viceroy of Zhili, who was responsible for the area surrounding the capital Beijing, is usually considered as the most honorable and powerful viceroy among the eight.
By the mid-18th century, the Qing had successfully put outer regions such as Inner and Outer Mongolia, Tibet and Xinjiang under its control. Imperial commissioners and garrisons were sent to Mongolia and Tibet to oversee their affairs. These territories were also under supervision of a central government institution called Lifan Yuan. Qinghai was also put under direct control of the Qing court. Xinjiang, also known as Chinese Turkestan, was subdivided into the regions north and south of the Tian Shan mountains, also known today as Dzungaria and Tarim Basin respectively, but the post of Ili General was established in 1762 to exercise unified military and administrative jurisdiction over both regions. Dzungaria was fully opened to Han migration by the Qianlong Emperor. Likewise, Manchuria was also governed by military generals until its division into provinces, though some areas of Xinjiang and Northeast China were lost to the Russian Empire in the mid-19th century. Manchuria was originally separated from China proper by the Inner Willow Palisade, a ditch and embankment planted with willows intended to restrict the movement of the Han Chinese, as the area was off-limits to civilian Han Chinese until the government started colonizing the area, especially since the 1860s.
With respect to these outer regions, the Qing maintained imperial control, with the emperor acting as Mongol khan, patron of Tibetan Buddhism and protector of Muslims. However, Qing policy changed with the establishment of Xinjiang province in 1884. During The Great Game era, taking advantage of the Dungan revolt in northwest China, Yaqub Beg invaded Xinjiang from Central Asia with support from the British Empire, and made himself the ruler of the kingdom of Kashgaria. The Qing court sent forces to defeat Yaqub Beg and Xinjiang was reconquered, and then the political system of China proper was formally applied onto Xinjiang. The Kumul Khanate, which was incorporated into the Qing empire as a vassal after helping Qing defeat the Zunghars in 1757, maintained its status after Xinjiang turned into a province through the end of the dynasty in the Xinhai Revolution up until 1930. In early 20th century, Great Britain sent an expedition force to Tibet and forced Tibetans to sign a treaty. The Qing court responded by asserting Chinese sovereignty over Tibet, resulting in the 1906 Anglo-Chinese Convention signed between Britain and China. The British agreed not to annex Tibetan territory or to interfere in the administration of Tibet, while China engaged not to permit any other foreign state to interfere with the territory or internal administration of Tibet. Furthermore, similar to Xinjiang which was converted into a province earlier, the Qing government also turned Manchuria into three provinces in the early 20th century, officially known as the "Three Northeast Provinces", and established the post of Viceroy of Three Northeast Provinces to oversee these provinces, making the total number of regional viceroys to nine.
Military.
Beginnings and early development.
The early Qing military was rooted in the Eight Banners first developed by Nurhaci to organize Jurchen society beyond petty clan affiliations. There were eight banners in all, differentiated by color. The yellow, bordered yellow, and white banners were known as the "Upper Three Banners" and were under the direct command of the emperor. Only Manchus belonging to the Upper Three Banners, and selected Han Chinese who had passed the highest level of martial exams could serve as the emperor's personal bodyguards. The remaining Banners were known as the "Lower Five Banners." They were commanded by hereditary Manchu princes descended from Nurhachi's immediate family, known informally as the "Iron cap princes". Together they formed the ruling council of the Manchu nation as well as high command of the army. Nurhachi's son Hong Taiji expanded the system to include mirrored Mongol and Han Banners. After capturing Beijing in 1644, the relatively small Banner armies were further augmented by the Green Standard Army, made up of those Ming troops who had surrendered to the Qing, which eventually outnumbered Banner troops three to one. They maintained their Ming era organization and were led by a mix of Banner and Green Standard officers. 
Banner Armies were organized along ethnic lines, namely Manchu and Mongol, but included non-Manchu bondservants registered under the household of their Manchu masters. The years leading up to the conquest increased the number of Han Chinese under Manchu rule, leading Hong Taiji to create the Eight Han Banners, and around the time of the Qing takeover of Beijing, their numbers rapidly swelled. Han Bannermen held high status and power in the early Qing period, especially immediately after the conquest during Shunzhi and Kangxi's reign where they dominated Governor-Generalships and Governorships across China at the expense of both Manchu Bannermen and Han civilians. Han also numerically dominated the Banners up until the mid 18th century. European visitors in Beijing called them "Tartarized Chinese" or "Tartarified Chinese". It was in Qianlong's reign that the Qianlong Emperor, concerned about maintaining Manchu identity, re-emphasized Manchu ethnicity, ancestry, language, and culture in the Eight Banners and started a mass discharge of Han Bannermen from the Eight Banners, either asking them to voluntarily resign from the Banner rolls or striking their names off. This led to a change from Han majority to a Manchu majority within the Banner system, and previous Han Bannermen garrisons in southern China such as at Fuzhou, Zhenjiang, Guangzhou, were replaced by Manchu Bannermen in the purge, which started in 1754. The turnover by Qianlong most heavily impacted Han banner garrisons stationed in the provinces while it less impacted Han Bannermen in Beijing, leaving a larger proportion of remaining Han Bannermen in Beijing than the provinces. Han Bannermen's status was decreased from that point on with Manchu Banners gaining higher status. Han Bannermen numbered 75% in 1648 Shunzhi's reign, 72% in 1723 Yongzheng's reign, but decreased to 43% in 1796 during the first year of Jiaqing's reign, which was after Qianlong's purge. The mass discharge was known as the Disbandment of the Han Banners. Qianlong directed most of his ire at those Han Bannermen descended from defectors who joined the Qing after the Qing passed through the Great Wall at Shanhai Pass in 1644, deeming their ancestors as traitors to the Ming and therefore untrustworthy, while retaining Han Bannermen who were descended from defectors who joined the Qing before 1644 in Liaodong and marched through Shanhai pass, also known as those who "followed the Dragon through the pass" ().
After a century of peace the Manchu Banner troops lost their fighting edge. Before the conquest, the Manchu banner had been a "citizen" army whose members were farmers and herders obligated to provide military service in times of war. The decision to turn the banner troops into a professional force whose every need was met by the state brought wealth, corruption, and decline as a fighting force. The Green Standard Army declined in a similar way.
Rebellion and modernization.
 Early during the Taiping Rebellion, Qing forces suffered a series of disastrous defeats culminating in the loss of the regional capital city of Nanjing in 1853. Shortly thereafter, a Taiping expeditionary force penetrated as far north as the suburbs of Tianjin, the imperial heartlands. In desperation the Qing court ordered a Chinese official, Zeng Guofan, to organize regional and village militias into an emergency army called tuanlian. Zeng Guofan's strategy was to rely on local gentry to raise a new type of military organization from those provinces that the Taiping rebels directly threatened. This new force became known as the Xiang Army, named after the Hunan region where it was raised. The Xiang Army was a hybrid of local militia and a standing army. It was given professional training, but was paid for out of regional coffers and funds its commanders — mostly members of the Chinese gentry — could muster. The Xiang Army and its successor, the Huai Army, created by Zeng Guofan's colleague and student Li Hongzhang, were collectively called the "Yong Ying" (Brave Camp).
Zeng Guofan had no military experience. Being a classically educated official, he took his blueprint for the Xiang Army from the Ming general Qi Jiguang, who, because of the weakness of regular Ming troops, had decided to form his own "private" army to repel raiding Japanese pirates in the mid-16th century. Qi Jiguang's doctrine was based on Neo-Confucian ideas of binding troops' loyalty to their immediate superiors and also to the regions in which they were raised. Zeng Guofan's original intention for the Xiang Army was simply to eradicate the Taiping rebels. However, the success of the Yongying system led to its becoming a permanent regional force within the Qing military, which in the long run created problems for the beleaguered central government.
First, the Yongying system signaled the end of Manchu dominance in Qing military establishment. Although the Banners and Green Standard armies lingered on as a drain on resources, henceforth the Yongying corps became the Qing government's de facto first-line troops. Second, the Yongying corps were financed through provincial coffers and were led by regional commanders, weakening central government's grip on the whole country. Finally, the nature of Yongying command structure fostered nepotism and cronyism amongst its commanders, who laid the seeds of regional warlordism in the first half of the 20th century.
 By the late 19th century, the most conservative elements within the Qing court could no longer ignore China's military weakness. In 1860, during the Second Opium War, the capital Beijing was captured and the Summer Palace sacked by a relatively small Anglo-French coalition force numbering 25,000. The advent of modern weaponry resulting from the European Industrial Revolution had rendered China's traditionally trained and equipped army and navy obsolete. The government attempts to modernize during the Self-Strengthening Movement were initially successful, but yielded few lasting results because of the central government's lack of funds, lack of political will, and unwillingness to depart from tradition.
Losing the First Sino-Japanese War of 1894–1895 was a watershed. Japan, a country long regarded by the Chinese as little more than an upstart nation of pirates, annihilated the Qing government's modernized Beiyang Fleet, then deemed to be the strongest naval force in Asia. The Japanese victory occurred a mere three decades after the Meiji Restoration set a feudal Japan on course to emulate the Western nations in their economic and technological achievements. Finally, in December 1894, the Qing government took concrete steps to reform military institutions and to re-train selected units in westernized drills, tactics and weaponry. These units were collectively called the New Army. The most successful of these was the Beiyang Army under the overall supervision and control of a former Huai Army commander, General Yuan Shikai, who used his position to build networks of loyal officers and eventually become President of the Republic of China.
Society.
The most significant fact of early and mid-Qing social history was population growth. The population doubled during the 18th century. People in this period were also remarkably on the move. There is evidence suggesting that the empire's rapidly expanding population was geographically mobile on a scale, which, in term of its volume and its protracted and routinized nature, was unprecedented in Chinese history. Indeed, the Qing government did far more to encourage mobility than to discourage it. Migration took several different forms, though might be divided in two varieties: permanent migration for resettlement, and relocation conceived by the party (in theory at least) as a temporary sojourn. Parties to the latter would include the empire's increasingly large and mobile manual workforce, as well as its densely overlapping internal diaspora of local-origin-based merchant groups. It would also included the patterned movement of Qing subjects overseas, largely to Southeastern Asia, in search of trade and other economic opportunities.
According to statute, Qing society was divided into relatively closed estates, of which in most general terms there were five. Apart from the estates of the officials, the comparatively minuscule aristocracy, and the degree-holding literati, there also existed a major division among ordinary Chinese between commoners and people with inferior status. They were divided into two categories: one of them, the good "commoner" people, the other "mean" people. The majority of the population belonged to the first category and were described as "liangmin", a legal term meaning good people, as opposed to "jianmin" meaning the mean (or ignoble) people. Qing law explicitly stated that the traditional four occupational groups of scholars, farmers, artisans and merchants were "good", or having a status of commoners. On the other hand, slaves or bondservants, entertainers (including prostitutes and actors), and those low-level employees of government officials were the "mean people". Mean people were considered legally inferior to commoners and suffered unequal treatments, forbidden to take the imperial examination.
Economy.
By the end of the 17th century, the Chinese economy had recovered from the devastation caused by the wars in which the Ming dynasty were overthrown, and the resulting breakdown of order. In the following century, markets continued to expand as in the late Ming period, but with more trade between regions, a greater dependence on overseas markets and a greatly increased population. After the re-opening of the southeast coast, which had been closed in the late 17th century, foreign trade was quickly re-established, and was expanding at 4% per annum throughout the latter part of the 18th century. China continued to export tea, silk and manufactures, creating a large, favorable trade balance with the West. The resulting inflow of silver expanded the money supply, facilitating the growth of competitive and stable markets.
The government broadened land ownership by returning land that had been sold to large landowners in the late Ming period by families unable to pay the land tax. To give people more incentives to participate in the market, they reduced the tax burden in comparison with the late Ming, and replaced the corvée system with a head tax used to hire laborers. The administration of the Grand Canal was made more efficient, and transport opened to private merchants. A system of monitoring grain prices eliminated severe shortages, and enabled the price of rice to rise slowly and smoothly through the 18th century. Wary of the power of wealthy merchants, Qing rulers limited their trading licenses and usually refused them permission to open new mines, except in poor areas. These restrictions on domestic resource exploration, as well as on foreign trade, are held by some scholars as a cause of the Great Divergence, by which the Western world overtook China economically.
By the end of the 18th century the population had risen to 300 million from approximately 150 million during the late Ming dynasty. The dramatic rise in population was due to several reasons, including the long period of peace and stability in the 18th century and the import of new crops China received from the Americas, including peanuts, sweet potatoes and maize. New species of rice from Southeast Asia led to a huge increase in production. Merchant guilds proliferated in all of the growing Chinese cities and often acquired great social and even political influence. Rich merchants with official connections built up huge fortunes and patronized literature, theater and the arts. Textile and handicraft production boomed.
Arts and culture.
Under the Qing, traditional forms of art flourished and innovations occurred at many levels and in many types. High levels of literacy, a successful publishing industry, prosperous cities, and the Confucian emphasis on cultivation all fed a lively and creative set of cultural fields.
The Manchu emperors were generally adept at poetry and often skilled in painting, and offered their patronage to Confucian culture. The Kangxi and Qianlong Emperors, for instance, embraced Chinese traditions both to control them and to proclaim their own legitimacy. The Kangxi Emperor sponsored the "Peiwen Yunfu", a rhyme dictionary published in 1711, and the "Kangxi Dictionary" published in 1716, which remains to this day an authoritative reference. The Qianlong Emperor sponsored the largest collection of writings in Chinese history, the "Siku Quanshu," completed in 1782. Court painters made new versions of the Song masterpiece, Zhang Zeduan's "Along the River During the Qingming Festival" whose depiction of a prosperous and happy realm demonstrated the beneficence of the emperor. The emperors undertook tours of the south and commissioned monumental scrolls to depict the grandeur of the occasion. Imperial patronage also encouraged the industrial production of ceramics and Chinese export porcelain.
Yet the most impressive aesthetic works were done among the scholars and urban elite. Calligraphy and painting remained a central interest to both court painters and scholar-gentry who considered the Four Arts part of their cultural identity and social standing. The painting of the early years of the dynasty included such painters as the orthodox Four Wangs and the individualists Bada Shanren (1626–1705) and Shitao (1641–1707). The nineteenth century saw such innovations as the Shanghai School and the Lingnan School which used the technical skills of tradition to set the stage for modern painting.
Traditional learning flourished, especially among Ming loyalists such as Dai Zhen and Gu Yanwu, but scholars in the school of evidential learning made innovations in skeptical textual scholarship. Scholar-bureaucrats, including Lin Zexu and Wei Yuan, developed a school of practical statecraft which rooted bureaucratic reform and restructuring in classical philosophy.
Literature grew to new heights in the Qing period. Poetry continued as a mark of the cultivated gentleman, but women wrote in larger and larger numbers and came from all walks of life. The poetry of the Qing dynasty is a lively field of research, being studied (along with the poetry of the Ming dynasty) for its association with Chinese opera, developmental trends of Classical Chinese poetry, the transition to a greater role for vernacular language, and for poetry by women in Chinese culture. The Qing dynasty was a period of much literary collection and criticism, and many of the modern popular versions of Classical Chinese poems were transmitted through Qing dynasty anthologies, such as the "Quantangshi" and the "Three Hundred Tang Poems". Pu Songling brought the short story form to a new level in his "Strange Stories from a Chinese Studio", published in the mid-18th century, and Shen Fu demonstrated the charm of the informal memoir in "Six Chapters of a Floating Life", written in the early 19th century but published only in 1877. The art of the novel reached a pinnacle in Cao Xueqin's "Dream of the Red Chamber", but its combination of social commentary and psychological insight were echoed in highly skilled novels such as Wu Jingzi's "The Scholars" (1750) and Li Ruzhen's "Flowers in the Mirror" (1827).
In drama, Kong Shangren's Kunqu opera "The Peach Blossom Fan", completed in 1699, portrayed the tragic downfall of the Ming dynasty in romantic terms. The most prestigious form became the so-called Peking opera, though local and folk opera were also widely popular.
Cuisine aroused a cultural pride in the accumulated richness of a long and varied past. The gentleman gourmet, such as Yuan Mei, applied aesthetic standards to the art of cooking, eating, and appreciation of tea at a time when New World crops and products entered everyday life. The Manchu Han Imperial Feast originated at the court. Although this banquet was probably never common, it reflected an appreciation by Han Chinese for Manchu culinary customs.
By the end of the nineteenth century, all elements of national artistic and cultural life had recognized and begun to come to terms with world culture as found in the West and Japan. Whether to stay within old forms or welcome Western models was now a conscious choice rather than an unchallenged acceptance of tradition. Classically trained Confucian scholars such as Liang Qichao and Wang Guowei broke ground later cultivated in the New Culture Movement.

</doc>
<doc id="25312" url="http://en.wikipedia.org/wiki?curid=25312" title="Quantum gravity">
Quantum gravity

Quantum gravity (QG) is a field of theoretical physics that seeks to describe the force of gravity according to the principles of quantum mechanics.
The current understanding of gravity is based on Albert Einstein's general theory of relativity, which is formulated within the framework of classical physics. On the other hand, the nongravitational forces are described within the framework of quantum mechanics, a radically different formalism for describing physical phenomena based on probability. The necessity of a quantum mechanical description of gravity follows from the fact that one cannot consistently couple a classical system to a quantum one.
Although a quantum theory of gravity is needed in order to reconcile general relativity with the principles of quantum mechanics, difficulties arise when one attempts to apply the usual prescriptions of quantum field theory to the force of gravity. From a technical point of view, the problem is that the theory one gets in this way is not renormalizable and therefore cannot be used to make meaningful physical predictions. As a result, theorists have taken up more radical approaches to the problem of quantum gravity, the most popular approaches being string theory and loop quantum gravity. A recent development is the theory of causal fermion systems which gives quantum mechanics, general relativity and quantum field theory as limiting cases.
Strictly speaking, the aim of quantum gravity is only to describe the quantum behavior of the gravitational field and should not be confused with the objective of unifying all fundamental interactions into a single mathematical framework. Although some quantum gravity theories such as string theory try to unify gravity with the other fundamental forces, others such as loop quantum gravity make no such attempt; instead, they make an effort to quantize the gravitational field while it is kept separate from the other forces. A theory of quantum gravity that is also a grand unification of all known interactions is sometimes referred to as a theory of everything (TOE).
One of the difficulties of quantum gravity is that quantum gravitational effects are only expected to become apparent near the Planck scale, a scale far smaller in distance (equivalently, far larger in energy) than what is currently accessible at high energy particle accelerators. As a result, quantum gravity is a mainly theoretical enterprise, although there are speculations about how quantum gravity effects might be observed in existing experiments.
Overview.
Much of the difficulty in meshing these theories at all energy scales comes from the different assumptions that these theories make on how the universe works. Quantum field theory depends on particle fields embedded in the flat space-time of special relativity. General relativity models gravity as a curvature within space-time that changes as a gravitational mass moves. Historically, the most obvious way of combining the two (such as treating gravity as simply another particle field) ran quickly into what is known as the renormalization problem. In the old-fashioned understanding of renormalization, gravity particles would attract each other and adding together all of the interactions results in many infinite values which cannot easily be cancelled out mathematically to yield sensible, finite results. This is in contrast with quantum electrodynamics where, given that the series still do not converge, the interactions sometimes evaluate to infinite results, but those are few enough in number to be removable via renormalization.
Effective field theories.
Quantum gravity can be treated as an effective field theory. Effective quantum field theories come with some high-energy cutoff, beyond which we do not expect that the theory provides a good description of nature. The "infinities" then become large but finite quantities depending on this finite cutoff scale, and correspond to processes that involve very high energies near the fundamental cutoff. These quantities can then be absorbed into an infinite collection of coupling constants, and at energies well below the fundamental cutoff of the theory, to any desired precision; only a finite number of these coupling constants need to be measured in order to make legitimate quantum-mechanical predictions. This same logic works just as well for the highly successful theory of low-energy pions as for quantum gravity. Indeed, the first quantum-mechanical corrections to graviton-scattering and Newton's law of gravitation have been explicitly computed (although they are so astronomically small that we may never be able to measure them). In fact, gravity is in many ways a much better quantum field theory than the Standard Model, since it appears to be valid all the way up to its cutoff at the Planck scale.
While confirming that quantum mechanics and gravity are indeed consistent at reasonable energies, it is clear that near or above the fundamental cutoff of our effective quantum theory of gravity (the cutoff is generally assumed to be of the order of the Planck scale), a new model of nature will be needed. Specifically, the problem of combining quantum mechanics and gravity becomes an issue only at very high energies, and may well require a totally new kind of model.
Quantum gravity theory for the highest energy scales.
The general approach to deriving a quantum gravity theory that is valid at even the highest energy scales is to assume that such a theory will be simple and elegant and, accordingly, to study symmetries and other clues offered by current theories that might suggest ways to combine them into a comprehensive, unified theory. One problem with this approach is that it is unknown whether quantum gravity will actually conform to a simple and elegant theory, as it should resolve the dual conundrums of special relativity with regard to the uniformity of acceleration and gravity, and general relativity with regard to spacetime curvature.
Such a theory is required in order to understand problems involving the combination of very high energy and very small dimensions of space, such as the behavior of black holes, and the origin of the universe.
Quantum mechanics and general relativity.
The graviton.
At present, one of the deepest problems in theoretical physics is harmonizing the theory of general relativity, which describes gravitation, and applications to large-scale structures (stars, planets, galaxies), with quantum mechanics, which describes the other three fundamental forces acting on the atomic scale. This problem must be put in the proper context, however. In particular, contrary to the popular claim that quantum mechanics and general relativity are fundamentally incompatible, one can demonstrate that the structure of general relativity essentially follows inevitably from the quantum mechanics of interacting theoretical spin-2 massless particles 
(called gravitons).
While there is no concrete proof of the existence of gravitons, quantized theories of matter may necessitate their existence. Supporting this theory is the observation that all fundamental forces except gravity have one or more known messenger particles, leading researchers to believe that at least one most likely does exist; they have dubbed this hypothetical particle the "graviton". The predicted find would result in the classification of the graviton as a "force particle" similar to the photon of the electromagnetic field. Many of the accepted notions of a unified theory of physics since the 1970s assume, and to some degree depend upon, the existence of the graviton. These include string theory, superstring theory, M-theory, and loop quantum gravity. Detection of gravitons is thus vital to the validation of various lines of research to unify quantum mechanics and relativity theory. 
The dilaton.
The dilaton made its first appearance in Kaluza–Klein theory, a five-dimensional theory that combined gravitation and electromagnetism. Generally, it appears in string theory. More recently, it has appeared in the lower-dimensional many-bodied gravity problem based on the field theoretic approach of Roman Jackiw. The impetus arose from the fact that complete analytical solutions for the metric of a covariant "N"-body system have proven elusive in general relativity. To simplify the problem, the number of dimensions was lowered to "(1+1)", i.e. one spatial dimension and one temporal dimension. This model problem, known as "R=T" theory (as opposed to the general "G=T" theory) was amenable to exact solutions in terms of a generalization of the Lambert W function. It was also found that the field equation governing the dilaton (derived from differential geometry) was the Schrödinger equation and consequently amenable to quantization.
Thus, one had a theory which combined gravity, quantization and even the electromagnetic interaction, promising ingredients of a fundamental physical theory. It is worth noting that the outcome revealed a previously unknown and already existing "natural link" between general relativity and quantum mechanics. However, this theory needs to be generalized in "(2+1)" or "(3+1)" dimensions although, in principle, the field equations are amenable to such generalization as shown with the inclusion of a one-graviton process and yielding the correct Newtonian limit in "d" dimensions if a dilaton is included. However, it is not yet clear what the fully generalized field equation governing the dilaton in (3+1) dimensions should be. This is further complicated by the fact that gravitons can propagate in "(3+1)" dimensions and consequently that would imply gravitons and dilatons exist in the real world. Moreover, detection of the dilaton is expected to be even more elusive than the graviton. However, since this approach allows for the combination of gravitational, electromagnetic and quantum effects, their coupling could potentially lead to a means of vindicating the theory, through cosmology and perhaps even "experimentally".
Nonrenormalizability of gravity.
General relativity, like electromagnetism, is a classical field theory. One might expect that, as with electromagnetism, there should be a corresponding quantum field theory.
However, gravity is perturbatively nonrenormalizable. For a quantum field theory to be well-defined according to this understanding of the subject, it must be asymptotically free or asymptotically safe. The theory must be characterized by a choice of "finitely many" parameters, which could, in principle, be set by experiment. For example, in quantum electrodynamics, these parameters are the charge and mass of the electron, as measured at a particular energy scale.
On the other hand, in quantizing gravity, there are "infinitely many independent parameters" (counterterm coefficients) needed to define the theory. For a given choice of those parameters, one could make sense of the theory, but since we can never do infinitely many experiments to fix the values of every parameter, we do not have a meaningful physical theory:
As explained below, there is a way around this problem by treating QG as an effective field theory.
Any meaningful theory of quantum gravity that makes sense and is predictive at all energy scales must have some deep principle that reduces the infinitely many unknown parameters to a finite number that can then be measured.
QG as an effective field theory.
In an effective field theory, all but the first few of the infinite set of parameters in a non-renormalizable theory are suppressed by huge energy scales and hence can be neglected when computing low-energy effects. Thus, at least in the low-energy regime, the model is indeed a predictive quantum field theory. (A very similar situation occurs for the very similar effective field theory of low-energy pions.) Furthermore, many theorists agree that even the Standard Model should really be regarded as an effective field theory as well, with "nonrenormalizable" interactions suppressed by large energy scales and whose effects have consequently not been observed experimentally.
Recent work has shown that by treating general relativity as an effective field theory, one can actually make legitimate predictions for quantum gravity, at least for low-energy phenomena. An example is the well-known calculation of the tiny first-order quantum-mechanical correction to the classical Newtonian gravitational potential between two masses.
Spacetime background dependence.
A fundamental lesson of general relativity is that there is no fixed spacetime background, as found in Newtonian mechanics and special relativity; the spacetime geometry is dynamic. While easy to grasp in principle, this is the hardest idea to understand about general relativity, and its consequences are profound and not fully explored, even at the classical level. To a certain extent, general relativity can be seen to be a relational theory, in which the only physically relevant information is the relationship between different events in space-time.
On the other hand, quantum mechanics has depended since its inception on a fixed background (non-dynamic) structure. In the case of quantum mechanics, it is time that is given and not dynamic, just as in Newtonian classical mechanics. In relativistic quantum field theory, just as in classical field theory, Minkowski spacetime is the fixed background of the theory.
String theory.
String theory can be seen as a generalization of quantum field theory where instead of point particles, string-like objects propagate in a fixed spacetime background, although the interactions among closed strings give rise to space-time in a dynamical way.
Although string theory had its origins in the study of quark confinement and not of quantum gravity, it was soon discovered that the string spectrum contains the graviton, and that "condensation" of certain vibration modes of strings is equivalent to a modification of the original background. In this sense, string perturbation theory exhibits exactly the features one would expect of a perturbation theory that may exhibit a strong dependence on asymptotics (as seen, for example, in the AdS/CFT correspondence) which is a weak form of background dependence.
Background independent theories.
Loop quantum gravity is the fruit of an effort to formulate a background-independent quantum theory.
Topological quantum field theory provided an example of background-independent quantum theory, but with no local degrees of freedom, and only finitely many degrees of freedom globally. This is inadequate to describe gravity in 3+1 dimensions, which has local degrees of freedom according to general relativity. In 2+1 dimensions, however, gravity is a topological field theory, and it has been successfully quantized in several different ways, including spin networks.
Semi-classical quantum gravity.
Quantum field theory on curved (non-Minkowskian) backgrounds, while not a full quantum theory of gravity, has shown many promising early results. In an analogous way to the development of quantum electrodynamics in the early part of the 20th century (when physicists considered quantum mechanics in classical electromagnetic fields), the consideration of quantum field theory on a curved background has led to predictions such as black hole radiation.
Phenomena such as the Unruh effect, in which particles exist in certain accelerating frames but not in stationary ones, do not pose any difficulty when considered on a curved background (the Unruh effect occurs even in flat Minkowskian backgrounds). The vacuum state is the state with the least energy (and may or may not contain particles).
See Quantum field theory in curved spacetime for a more complete discussion.
Points of tension.
There are other points of tension between quantum mechanics and general relativity.
Candidate theories.
There are a number of proposed quantum gravity theories. Currently, there is still no complete and consistent quantum theory of gravity, and the candidate models still need to overcome major formal and conceptual problems. They also face the common problem that, as yet, there is no way to put quantum gravity predictions to experimental tests, although there is hope for this to change as future data from cosmological observations and particle physics experiments becomes available.
String theory.
One suggested starting point is ordinary quantum field theories which, after all, are successful in describing the other three basic fundamental forces in the context of the standard model of elementary particle physics. However, while this leads to an acceptable effective (quantum) field theory of gravity at low energies, gravity turns out to be much more problematic at higher energies. Where, for ordinary field theories such as quantum electrodynamics, a technique known as renormalization is an integral part of deriving predictions which take into account higher-energy contributions, gravity turns out to be nonrenormalizable: at high energies, applying the recipes of ordinary quantum field theory yields models that are devoid of all predictive power.
One attempt to overcome these limitations is to replace ordinary quantum field theory, which is based on the classical concept of a point particle, with a quantum theory of one-dimensional extended objects: string theory. At the energies reached in current experiments, these strings are indistinguishable from point-like particles, but, crucially, different modes of oscillation of one and the same type of fundamental string appear as particles with different (electric and other) charges. In this way, string theory promises to be a unified description of all particles and interactions. The theory is successful in that one mode will always correspond to a graviton, the messenger particle of gravity; however, the price to pay are unusual features such as six extra dimensions of space in addition to the usual three for space and one for time.
In what is called the , it was conjectured that both string theory and a unification of general relativity and supersymmetry known as supergravity form part of a hypothesized eleven-dimensional model known as M-theory, which would constitute a uniquely defined and consistent theory of quantum gravity. As presently understood, however, string theory admits a very large number (10500 by some estimates) of consistent vacua, comprising the so-called "string landscape". Sorting through this large family of solutions remains a major challenge.
Loop quantum gravity.
Loop quantum gravity is based first of all on the idea to take seriously the insight of general relativity that spacetime is a dynamical field and therefore is a quantum object. The second idea is that the quantum discreteness that determines the particle-like behavior of other field theories (for instance, the photons of the electromagnetic field) also affects the structure of space.
The main result of loop quantum gravity is the derivation of a granular structure of space at the Planck length. This is derived as follows. In the case of electromagnetism, the quantum operator representing the energy of each frequency of the field has discrete spectrum. Therefore the energy of each frequency is quantized, and the quanta are the photons. In the case of gravity, the operators representing the area and the volume of each surface or space region have discrete spectrum. Therefore area and volume of any portion of space are quantized, and the quanta are elementary quanta of space. It follows that spacetime has an elementary quantum granular structure at the Planck scale, which cuts-off the ultraviolet infinities of quantum field theory.
The quantum state of spacetime is described in the theory by means of a mathematical structure called spin networks. Spin networks were initially introduced by Roger Penrose in abstract form, and later shown by Carlo Rovelli and Lee Smolin to derive naturally from a non perturbative quantization of general relativity. Spin networks do not represent quantum states of a field in spacetime: they represent directly quantum states of spacetime.
The theory is based on the reformulation of general relativity known as Ashtekar variables, which represent geometric gravity using mathematical analogues of electric and magnetic fields. 
In the quantum theory space is represented by a network structure called a spin network, evolving over time in discrete steps.
The dynamics of the theory is today constructed in several versions. One version starts with the canonical quantization of general relativity. The analogue of the Schrödinger equation is a Wheeler–DeWitt equation, which can be defined in the theory. 
In the covariant, or spinfoam formulation of the theory, the quantum dynamics is obtained via a sum over discrete versions of spacetime, called spinfoams. These represent histories of spin networks.
Other approaches.
There are a number of other approaches to quantum gravity. The approaches differ depending on which features of general relativity and quantum theory are accepted unchanged, and which features are modified. Examples include:
Weinberg–Witten theorem.
In quantum field theory, the Weinberg–Witten theorem places some constraints on theories of composite gravity/emergent gravity. However, recent developments attempt to show that if locality is only approximate and the holographic principle is correct, the Weinberg–Witten theorem would not be valid.
Experimental tests.
As was emphasized above, quantum gravitational effects are extremely weak and therefore difficult to test. For this reason, the possibility of experimentally testing quantum gravity had not received much attention prior to the late 1990s. However, in the past decade, physicists have realized that evidence for quantum gravitational effects can guide the development of the theory. Since theoretical development has been slow, the field of phenomenological quantum gravity, which studies the possibility of experimental tests, has obtained increased attention.
The most widely pursued possibilities for quantum gravity phenomenology include violations of Lorentz invariance, imprints of quantum gravitational effects in the cosmic microwave background (in particular its polarization), and decoherence induced by fluctuations in the space-time foam.
The BICEP2 experiment detected what was initially thought to be primordial B-mode polarization caused by gravitational waves in the early universe. If truly primordial, these waves were born as quantum fluctuations in gravity itself. Cosmologist Ken Olum (Tufts University) stated: "I think this is the only observational evidence that we have that actually shows that gravity is quantized...It's probably the only evidence of this that we will ever have."

</doc>
<doc id="25315" url="http://en.wikipedia.org/wiki?curid=25315" title="Quality of service">
Quality of service

Quality of service (QoS) is the overall performance of a telephony or computer network, particularly the performance seen by the users of the network.
To quantitatively measure quality of service, several related aspects of the network service are often considered, such as error rates, bandwidth, throughput, transmission delay, availability, jitter, etc.
Quality of service is particularly important for the transport of traffic with special requirements. In particular, much technology has been developed to allow computer networks to become as useful as telephone networks for audio conversations, as well as supporting new applications with even stricter service demands.
Definitions.
In the field of telephony, quality of service was defined by the ITU in 1994. Quality of service comprises requirements on all the aspects of a connection, such as service response time, loss, signal-to-noise ratio, crosstalk, echo, interrupts, frequency response, loudness levels, and so on. A subset of telephony QoS is grade of service (GoS) requirements, which comprises aspects of a connection relating to capacity and coverage of a network, for example guaranteed maximum blocking probability and outage probability.
In the field of computer networking and other packet-switched telecommunication networks, the traffic engineering term refers to resource reservation control mechanisms rather than the achieved service quality. Quality of service is the ability to provide different priority to different applications, users, or data flows, or to guarantee a certain level of performance to a data flow. For example, a required bit rate, delay, jitter, packet dropping probability and/or bit error rate may be guaranteed. Quality of service guarantees are important if the network capacity is insufficient, especially for real-time streaming multimedia applications such as voice over IP, online games and IP-TV, since these often require fixed bit rate and are delay sensitive, and in networks where the capacity is a limited resource, for example in cellular data communication.
A network or protocol that supports QoS may agree on a traffic contract with the application software and reserve capacity in the network nodes, for example during a session establishment phase. During the session it may monitor the achieved level of performance, for example the data rate and delay, and dynamically control scheduling priorities in the network nodes. It may release the reserved capacity during a tear down phase.
A best-effort network or service does not support quality of service. An alternative to complex QoS control mechanisms is to provide high quality communication over a best-effort network by over-provisioning the capacity so that it is sufficient for the expected peak traffic load. The resulting absence of network congestion eliminates the need for QoS mechanisms.
QoS is sometimes used as a quality measure, with many alternative definitions, rather than referring to the ability to reserve resources. Quality of service sometimes refers to the level of quality of service, i.e. the guaranteed service quality. High QoS is often confused with a high level of performance or achieved service quality, for example high bit rate, low latency and low bit error probability.
An alternative and disputable definition of QoS, used especially in application layer services such as telephony and streaming video, is requirements on a metric that reflects or predicts the subjectively experienced quality. In this context, QoS is the acceptable cumulative effect on subscriber satisfaction of all imperfections affecting the service. Other terms with similar meaning are the quality of experience (QoE) subjective business concept, the required “user perceived performance”, the required “degree of satisfaction of the user” or the targeted “number of happy customers”. Examples of measures and measurement methods are mean opinion score (MOS), perceptual speech quality measure (PSQM) and perceptual evaluation of video quality (PEVQ). See also Subjective video quality.
History.
Conventional Internet routers and LAN switches operate on a best effort basis. This equipment is less expensive, less complex and faster and thus more popular than competing more complex technologies that provided QoS mechanisms. There were four “Type of service” bits and three “Precedence” bits provided in each IP packet header, but they were not generally respected. These bits were later re-defined as Differentiated services code points (DSCP) and are sometimes honored in peered links on the modern Internet.
With the advent of IPTV and IP telephony, QoS mechanisms are increasingly available to the end user.
A number of attempts for layer 2 technologies that add QoS tags to the data have gained popularity in the past. Examples are frame relay, asynchronous transfer mode (ATM) and multiprotocol label switching (MPLS) (a technique between layer 2 and 3). Despite these network technologies remaining in use today, this kind of network lost attention after the advent of Ethernet networks. Today Ethernet is, by far, the most popular layer 2 technology. Ethernet may offer QoS through its 802.1p.
In Ethernet, virtual local area networks (VLAN) may be used to separate different QoS levels. For example fibre-to-the-home switches typically offer several Ethernet ports connected to different VLANs. One VLAN may be used for Internet access (low priority), one for IPTV (higher priority) and one for IP telephony (highest priority). Different Internet service providers may use different VLANs.
Qualities of traffic.
In packet-switched networks, quality of service is affected by various factors, which can be divided into “human” and “technical” factors. Human factors include: stability of service, availability of service, delays, user information. Technical factors include: reliability, scalability, effectiveness, maintainability, grade of service, etc.
Many things can happen to packets as they travel from origin to destination, resulting in the following problems as seen from the point of view of the sender and receiver:
Applications.
A defined quality of service may be desired or required for certain types of network traffic, for example:
These types of service are called "inelastic", meaning that they require a certain minimum level of bandwidth and a certain maximum latency to function. By contrast, "elastic" applications can take advantage of however much or little bandwidth is available. Bulk file transfer applications that rely on TCP are generally elastic.
Mechanisms.
Circuit switched networks, especially those intended for voice transmission, such as Asynchronous Transfer Mode (ATM) or GSM, have QoS in the core protocol and do not need additional procedures to achieve it. Shorter data units and built-in QoS were some of the unique selling points of ATM for applications such as video on demand.
When the expense of mechanisms to provide QoS is justified, network customers and providers can enter into a contractual agreement termed a service level agreement (SLA) which specifies guarantees for the ability of a network/protocol to give guaranteed performance/throughput/latency bounds based on mutually agreed measures, usually by prioritizing traffic.
In other approaches, resources are reserved at each step on the network for the call as it is set up.
Over-provisioning.
An alternative to complex QoS control mechanisms is to provide high quality communication by generously over-provisioning a network so that capacity is based on peak traffic load estimates. This approach is simple for networks with predictable peak loads. The performance is reasonable for many applications. This might include demanding applications that can compensate for variations in bandwidth and delay with large receive buffers, which is often possible for example in video streaming. Over-provisioning can be of limited use, however, in the face of transport protocols (such as TCP) that over time exponentially increase the amount of data placed on the network until all available bandwidth is consumed and packets are dropped. Such greedy protocols tend to increase latency and packet loss for all users.
Commercial VoIP services are often competitive with traditional telephone service in terms of call quality even though QoS mechanisms are usually not in use on the user's connection to their ISP and the VoIP provider's connection to a different ISP. Under high load conditions, however, VoIP may degrade to cell-phone quality or worse. The mathematics of packet traffic indicate that network requires just 60% more raw capacity under conservative assumptions.
The amount of over-provisioning in interior links required to replace QoS depends on the number of users and their traffic demands. This limits usability of over-provisioning. Newer more bandwidth intensive applications and the addition of more users results in the loss of over-provisioned networks. This then requires a physical update of the relevant network links which is an expensive process. Thus over-provisioning cannot be blindly assumed on the Internet.
IP and Ethernet efforts.
Unlike single-owner networks, the Internet is a series of exchange points interconnecting private networks. Hence the Internet's core is owned and managed by a number of different network service providers, not a single entity. Its behavior is much more stochastic or unpredictable. Therefore, research continues on QoS procedures that are deployable in large, diverse networks.
There are two principal approaches to QoS in modern packet-switched IP networks, a parameterized system based on an exchange of application requirements with the network, and a prioritized system where each packet identifies a desired service level to the network.
Early work used the integrated services (IntServ) philosophy of reserving network resources. In this model, applications used the Resource reservation protocol (RSVP) to request and reserve resources through a network. While IntServ mechanisms do work, it was realized that in a broadband network typical of a larger service provider, Core routers would be required to accept, maintain, and tear down thousands or possibly tens of thousands of reservations. It was believed that this approach would not scale with the growth of the Internet, and in any event was antithetical to the notion of designing networks so that Core routers do little more than simply switch packets at the highest possible rates.
In response to these markings, routers and switches use various queuing strategies to tailor performance to requirements. At the IP layer, DSCP markings use the 6 bits in the IP packet header. At the MAC layer, VLAN IEEE 802.1Q and IEEE 802.1p can be used to carry essentially the same information.
Routers supporting DiffServ configure their network scheduler to use multiple queues for packets awaiting transmission from bandwidth constrained (e.g., wide area) interfaces. Router vendors provide different capabilities for configuring this behavior, to include the number of queues supported, the relative priorities of queues, and bandwidth reserved for each queue.
In practice, when a packet must be forwarded from an interface with queuing, packets requiring low jitter (e.g., VoIP or videoconferencing) are given priority over packets in other queues. Typically, some bandwidth is allocated by default to network control packets (such as Internet Control Message Protocol and routing protocols), while best effort traffic might simply be given whatever bandwidth is left over.
At the Media Access Control (MAC) layer, VLAN IEEE 802.1Q and IEEE 802.1p can be used to distinguish between Ethernet frames and classify them. Queueing theory models have been developed on performance analysis and QoS for MAC layer protocols.
Cisco IOS NetFlow and the Cisco Class Based QoS (CBQoS) Management Information Base (MIB) are marketed by Cisco Systems.
One compelling example of the need for QoS on the Internet relates to congestion collapse. The Internet relies on congestion avoidance protocols, as built into Transmission Control Protocol (TCP), to reduce traffic under conditions that would otherwise lead to "meltdown". QoS applications such as VoIP and IPTV, because they require largely constant bitrates and low latency cannot use TCP and cannot otherwise reduce their traffic rate to help prevent congestion. QoS contracts limit traffic that can be offered to the Internet and thereby enforce traffic shaping that can prevent it from becoming overloaded, and are hence an indispensable part of the Internet's ability to handle a mix of real-time and non-real-time traffic without meltdown.
End-to-end quality of service.
End-to-end quality of service can require a method of coordinating resource allocation between one autonomous system and another.
The Internet Engineering Task Force (IETF) defined the Resource Reservation Protocol (RSVP) for bandwidth reservation, as a proposed standard in 1997.
RSVP is an end-to-end bandwidth reservation protocol. The traffic engineering version, RSVP-TE, is used in many networks to establish traffic-engineered Multiprotocol Label Switching (MPLS) label-switched paths.
The IETF also defined Next Steps in Signaling (NSIS) with QoS signalling as a target. NSIS is a development and simplification of RSVP.
Research consortia such as "end-to-end quality of service support over heterogeneous networks" (EuQoS, from 2004 through 2007) and fora such as the IPsphere Forum developed more mechanisms for handshaking QoS invocation from one domain to the next. IPsphere defined the Service Structuring Stratum (SSS) signaling bus in order to establish, invoke and (attempt to) assure network services.
EuQoS conducted experiments to integrate Session Initiation Protocol, Next Steps in Signaling and IPsphere's SSS with an estimated cost of about 15.6 million Euro and published a book.
A research project Multi Service Access Everywhere (MUSE) defined another QoS concept in a first phase from January 2004 through February 2006, and a second phase from January 2006 through 2007.
Another research project named PlaNetS was proposed for European funding circa 2005.
A broader European project called "Architecture and design for the future Internet" known as 4WARD had a budgest estimated at 23.4 million Euro and was funded from January 2008 through June 2010.
It included a "Quality of Service Theme" and published a book.
Another European project, called WIDENS (Wireless Deployable Network System) proposed a bandwidth reservation approach for mobile wireless multirate adhoc networks.<br>
In the services domain, end-to-end Quality of Service has also been discussed in the case of composite services (consisting of atomic services) or applications (consisting of application components). Moreover, in cloud computing end-to-end QoS has been the focus of various research efforts aiming at the provision of QoS guarantees across the cloud service models.
Circumvention.
Strong cryptography network protocols such as Secure Sockets Layer, I2P, and virtual private networks obscure the data transferred using them. As all electronic commerce on the Internet requires the use of such strong cryptography protocols, unilaterally downgrading the performance of encrypted traffic creates an unacceptable hazard for customers. Yet, encrypted traffic is otherwise unable to undergo deep packet inspection for QoS.
Doubts about quality of service over IP.
The Internet2 project found, in 2001, that the QoS protocols were probably not deployable inside its Abilene Network with equipment available at that time.
Equipment available at the time relied on software to implement QoS. The group also predicted that “logistical, financial, and organizational barriers will block the way toward any bandwidth guarantees” by protocol modifications aimed at QoS.
They believed that the economics would encourage network providers to deliberately erode the quality of best effort traffic as a way to push customers to higher priced QoS services. Instead they proposed over-provisioning of capacity as more cost-effective at the time.
The Abilene network study was the basis for the testimony of Gary Bachula to the US Senate Commerce Committee's hearing on Network Neutrality in early 2006. He expressed the opinion that adding more bandwidth was more effective than any of the various schemes for accomplishing QoS they examined.
Bachula's testimony has been cited by proponents of a law banning quality of service as proof that no legitimate purpose is served by such an offering. This argument is dependent on the assumption that over-provisioning isn't a form of QoS and that it is always possible. Cost and other factors affect the ability of carriers to build and maintain permanently over-provisioned networks.
Mobile (cellular) QoS.
Mobile cellular service providers may offer mobile QoS to customers just as the fixed line PSTN services providers and Internet Service Providers (ISP) may offer QoS. QoS mechanisms are always provided for circuit switched services, and are essential for non-elastic services, for example streaming multimedia.
Mobility adds complication to the QoS mechanisms, for several reasons:
Standards.
Quality of service in the field of telephony, was first defined in 1994 in the ITU-T Recommendation E.800. This definition is very broad, listing 6 primary components: Support, Operability, Accessibility, Retainability, Integrity and Security.
A 1995 recommendation X.902 included a definition is the OSI reference model.
In 1998 the ITU published a document discussing QoS in the field of data networking. X.641 offers a means of developing or enhancing standards related to QoS and provide concepts and terminology that will assist in maintaining the consistency of related standards.
Some QoS-related IETF Request For Comments (RFC)s are (RFC 2474), and (RFC 2205); both these are discussed above. The IETF has also published two RFCs giving background on QoS: RFC 2990: , and RFC 3714: .
The IETF has also published RFC 4594 as an informative or "best practices" document about the practical aspects of designing a QoS solution for a DiffServ network. They try to identify which types of applications are commonly run over an IP network to group them into traffic classes, study what treatment do each of these classes need from the network, and suggest which of the QoS mechanisms commonly available in routers can be used to implement those treatments.
External links.
Listen to this article ()
This audio file was created from a revision of the "Quality of service" article dated 2008-07-18, and does not reflect subsequent edits to the article. ()
More spoken articles

</doc>
<doc id="25316" url="http://en.wikipedia.org/wiki?curid=25316" title="Quadrature amplitude modulation">
Quadrature amplitude modulation

Quadrature amplitude modulation (QAM) is both an analog and a digital modulation scheme. It conveys two analog message signals, or two digital bit streams, by changing ("modulating") the amplitudes of two carrier waves, using the amplitude-shift keying (ASK) digital modulation scheme or amplitude modulation (AM) analog modulation scheme. The two carrier waves, usually sinusoids, are out of phase with each other by 90° and are thus called quadrature carriers or quadrature components — hence the name of the scheme. The modulated waves are summed, and the final waveform is a combination of both phase-shift keying (PSK) and amplitude-shift keying (ASK), or (in the analog case) of phase modulation (PM) and amplitude modulation. In the digital QAM case, a finite number of at least two phases and at least two amplitudes are used. PSK modulators are often designed using the QAM principle, but are not considered as QAM since the amplitude of the modulated carrier signal is constant. QAM is used extensively as a modulation scheme for digital telecommunication systems. Arbitrarily high spectral efficiencies can be achieved with QAM by setting a suitable constellation size, limited only by the noise level and linearity of the communications channel.
QAM is being used in optical fiber systems as bit rates increase; QAM16 and QAM64 can be optically emulated with a 3-path interferometer.
Digital QAM.
Like all modulation schemes, QAM conveys data by changing some aspect of a carrier signal, or the carrier wave, (usually a sinusoid) in response to a data signal. In the case of QAM, the amplitude of two waves, 90° out-of-phase with each other (in quadrature) are changed ("modulated" or "keyed") to represent the data signal. Amplitude modulating two carriers in quadrature can be equivalently viewed as both amplitude modulating and phase modulating a single carrier.
Phase modulation (analog PM) and phase-shift keying (digital PSK) can be regarded as a special case of QAM, where the magnitude of the modulating signal is a constant, with only the phase varying. This can also be extended to frequency modulation (FM) and frequency-shift keying (FSK), for these can be regarded as a special case of phase modulation.
Analog QAM.
When transmitting two signals by modulating them with QAM, the transmitted signal will be of the form:
where formula_2, formula_3, and formula_4 are the modulating signals, formula_5 is the carrier frequency and formula_6 is the real part.
At the receiver, these two modulating signals can be demodulated using a coherent demodulator. Such a receiver multiplies the received signal separately with both a cosine and sine signal to produce the received estimates of formula_3 and formula_4 respectively. Because of the orthogonality property of the carrier signals, it is possible to detect the modulating signals independently.
In the ideal case formula_3 is demodulated by multiplying the transmitted signal with a cosine signal:
Using standard trigonometric identities, we can write it as:
Low-pass filtering formula_12 removes the high frequency terms (containing formula_13), leaving only the formula_3 term. This filtered signal is unaffected by formula_4, showing that the in-phase component can be received independently of the quadrature component. Similarly, we may multiply formula_16 by a sine wave and then low-pass filter to extract formula_4.
The phase of the received signal is assumed to be known accurately at the receiver. If the demodulating phase is even a little off, it results in crosstalk between the modulated signals. This issue of carrier synchronization at the receiver must be handled somehow in QAM systems. The coherent demodulator needs to be exactly in phase with the received signal, or otherwise the modulated signals cannot be independently received. For example analog television systems transmit a burst of the transmitting colour subcarrier after each horizontal synchronization pulse for reference.
Analog QAM is used in NTSC and PAL television systems, where the I- and Q-signals carry the components of chroma (colour) information. "Compatible QAM" or C-QUAM is used in AM stereo radio to carry the stereo difference information.
Fourier analysis of QAM.
In the frequency domain, QAM has a similar spectral pattern to DSB-SC modulation. Using the properties of the Fourier transform, we find that:
where "S"("f"), "M""I"("f") and "M""Q"("f") are the Fourier transforms (frequency-domain representations) of "s"("t"), "I"("t") and "Q"("t"), respectively.
Quantized QAM.
As in many digital modulation schemes, the constellation diagram is useful for QAM. In QAM, the constellation points are usually arranged in a square grid with equal vertical and horizontal spacing, although other configurations are possible (e.g. Cross-QAM). Since in digital telecommunications the data are usually binary, the number of points in the grid is usually a power of 2 (2, 4, 8, …). Since QAM is usually square, some of these are rare—the most common forms are 16-QAM, 64-QAM and 256-QAM. By moving to a higher-order constellation, it is possible to transmit more bits per symbol. However, if the mean energy of the constellation is to remain the same (by way of making a fair comparison), the points must be closer together and are thus more susceptible to noise and other corruption; this results in a higher bit error rate and so higher-order QAM can deliver more data less reliably than lower-order QAM, for constant mean constellation energy. Using higher-order QAM without increasing the bit error rate requires a higher signal-to-noise ratio (SNR) by increasing signal energy, reducing noise, or both.
If data-rates beyond those offered by 8-PSK are required, it is more usual to move to QAM since it achieves a greater distance between adjacent points in the I-Q plane by distributing the points more evenly. The complicating factor is that the points are no longer all the same amplitude and so the demodulator must now correctly detect both phase and amplitude, rather than just phase.
64-QAM and 256-QAM are often used in digital cable television and cable modem applications. In the United States, 64-QAM and 256-QAM are the mandated modulation schemes for digital cable (see QAM tuner) as standardised by the SCTE in the standard . Note that many marketing people will refer to these as QAM-64 and QAM-256. In the UK, 64-QAM is used for digital terrestrial television (Freeview) whilst 256-QAM is used for Freeview-HD.
Communication systems designed to achieve very high levels of spectral efficiency usually employ very dense QAM constellations. For example current Homeplug AV2 500-Mbit powerline Ethernet devices use 1024-QAM and 4096-QAM, as well as future devices using ITU-T G.hn standard for networking over existing home wiring (coaxial cable, phone lines and power lines); 4096-QAM provides 12 bits/symbol. Another example is VDSL2 technology for copper twisted pairs, whose constellation size goes up to 32768 points.
Ultra-high capacity Microwave Backhaul Systems also use 1024-QAM. With 1024-QAM, Adaptive Coding and Modulation (ACM), and XPIC, Vendors can obtain Gigabit capacity in a single 56 MHz channel.
Ideal structure.
Transmitter.
The following picture shows the ideal structure of a QAM transmitter, with a carrier frequency formula_5 and the frequency response of the transmitter's filter formula_20:
First the flow of bits to be transmitted is split into two equal parts: this process generates two independent signals to be transmitted. They are encoded separately just like they were in an amplitude-shift keying (ASK) modulator. Then one channel (the one "in phase") is multiplied by a cosine, while the other channel (in "quadrature") is multiplied by a sine. This way there is a phase of 90° between them. They are simply added one to the other and sent through the real channel.
The sent signal can be expressed in the form:
where formula_22 and formula_23 are the voltages applied in response to the formula_24th symbol to the cosine and sine waves respectively.
Receiver.
The receiver simply performs the inverse operation of the transmitter. Its ideal structure is shown in the picture below with formula_25 the receive filter's frequency response :
Multiplying by a cosine (or a sine) and by a low-pass filter it is possible to extract the component in phase (or in quadrature). Then there is only an ASK demodulator and the two flows of data are merged back.
In practice, there is an unknown phase delay between the transmitter and receiver that must be compensated by "synchronization" of the receivers local oscillator; i.e., the sine and cosine functions in the above figure. In mobile applications, there will often be an offset in the relative "frequency" as well, due to the possible presence of a Doppler shift proportional to the relative velocity of the transmitter and receiver. Both the phase and frequency variations introduced by the channel must be compensated by properly tuning the sine and cosine components, which requires a "phase reference", and is typically accomplished using a Phase-Locked Loop (PLL).
In any application, the low-pass filter and the receive formula_25 filter will be implemented as a single combined filter. Here they are shown as separate just to be clearer.
Quantized QAM performance.
The following definitions are needed in determining error rates:
formula_37 is related to the complementary Gaussian error function by:
formula_38, which is the probability that "x" will be under the tail of the Gaussian PDF towards positive infinity.
The error rates quoted here are those in additive white Gaussian noise (AWGN).
Where coordinates for constellation points are given in this article, note that they represent a "non-normalised" constellation. That is, if a particular mean average energy were required (e.g. unit average energy), the constellation would need to be linearly scaled.
Rectangular QAM.
Rectangular QAM constellations are, in general, sub-optimal in the sense that they do not maximally space the constellation points for a given energy. However, they have the considerable advantage that they may be easily transmitted as two pulse amplitude modulation (PAM) signals on quadrature carriers, and can be easily demodulated. The non-square constellations, dealt with below, achieve marginally better bit-error rate (BER) but are harder to modulate and demodulate.
The first rectangular QAM constellation usually encountered is 16-QAM, the constellation diagram for which is shown here. A Gray coded bit-assignment is also given. The reason that 16-QAM is usually the first is that a brief consideration reveals that 2-QAM and 4-QAM are in fact binary phase-shift keying (BPSK) and quadrature phase-shift keying (QPSK), respectively. Also, the error-rate performance of 8-QAM is close to that of 16-QAM (only about 0.5 dB better), but its data rate is only three-quarters that of 16-QAM.
Expressions for the symbol-error rate of rectangular QAM are not hard to derive but yield rather unpleasant expressions. For an even number of bits per symbol, formula_39, exact expressions are available. They are most easily expressed in a "per carrier" sense:
so
The bit-error rate depends on the bit to symbol mapping, but for formula_42 and a Gray-coded assignment—so that we can assume each symbol error causes only one bit error—the bit-error rate is approximately
Since the carriers are independent, the overall bit error rate is the same as the per-carrier error rate, just like BPSK and QPSK.
Odd-"k" QAM.
For odd formula_39, such as 8-QAM (formula_46) it is harder to obtain symbol-error rates, but a tight upper bound is:
Two rectangular 8-QAM constellations are shown below without bit assignments. These both have the same minimum distance between symbol points, and thus the same symbol-error rate (to a first approximation).
The exact bit-error rate, formula_32 will depend on the bit-assignment.
Note that both of these constellations are seldom used in practice, as the non-rectangular version of 8-QAM is optimal.
Non-rectangular QAM.
It is the nature of QAM that most orders of constellations can be constructed in many different ways and it is neither possible nor instructive to cover them all here. This article instead presents two, lower-order constellations.
Two diagrams of circular QAM constellation are shown, for 8-QAM and 16-QAM. The circular 8-QAM constellation is known to be the optimal 8-QAM constellation in the sense of requiring the least mean power for a given minimum Euclidean distance. The 16-QAM constellation is suboptimal although the optimal one may be constructed along the same lines as the 8-QAM constellation. The circular constellation highlights the relationship between QAM and PSK. Other orders of constellation may be constructed along similar (or very different) lines. It is consequently hard to establish expressions for the error rates of non-rectangular QAM since it necessarily depends on the constellation. Nevertheless, an obvious upper bound to the rate is related to the minimum Euclidean distance of the constellation (the shortest straight-line distance between two points):
Again, the bit-error rate will depend on the assignment of bits to symbols.
Although, in general, there is a non-rectangular constellation that is optimal for a particular formula_27, they are not often used since the rectangular QAMs are much easier to modulate and demodulate.
Interference and noise.
In moving to a higher order QAM constellation (higher data rate and mode) in hostile RF/microwave QAM application environments, such as in broadcasting or telecommunications, multipath interference typically increases. There is a spreading of the spots in the constellation, decreasing the separation between adjacent states, making it difficult for the receiver to decode the signal appropriately. In other words, there is reduced noise immunity. There are several test parameter measurements which help determine an optimal QAM mode for a specific operating environment. The following three are most significant:
References.
The notation used here has mainly (but not exclusively) been taken from

</doc>
<doc id="25317" url="http://en.wikipedia.org/wiki?curid=25317" title="QAM (disambiguation)">
QAM (disambiguation)

QAM may refer to:

</doc>
<doc id="25319" url="http://en.wikipedia.org/wiki?curid=25319" title="Quetzalcoatlus">
Quetzalcoatlus

Quetzalcoatlus was a pterodactyloid pterosaur known from the Late Cretaceous of North America (Maastrichtian stage) and one of the largest known flying animals of all time. It was a member of the Azhdarchidae, a family of advanced toothless pterosaurs with unusually long, stiffened necks. Its name comes from the Mesoamerican feathered serpent god Quetzalcoatl.
Description.
Size.
When it was first discovered, scientists estimated that the largest "Quetzalcoatlus" fossils came from an individual with a wingspan as large as 15.9 m, choosing the middle of three extrapolations from the proportions of other pterosaurs that gave an estimate of 11, 15.5 and 21 meters respectively (36 feet, 50.85 feet, 68.9 feet). In 1981, further study lowered these estimates to 11 –. More recent estimates based on greater knowledge of azhdarchid proportions place its wingspan at 10 –.
Mass estimates for giant azhdarchids are extremely problematic because no existing species share a similar size or body plan, and in consequence published results vary widely. While some studies have historically found extremely low weight estimates for "Quetzalcoatlus", as low as 70 kg for a 10 m individual, a majority of estimates published since the 2000s have been higher, around 200 -.
Skull.
Skull material (from smaller specimens, possibly a related species) shows that "Quetzalcoatlus" had a very sharp and pointed beak. That is contrary to some earlier reconstructions that showed a blunter snout, based on the inadvertent inclusion of jaw material from another pterosaur species, possibly a tapejarid or a form related to "Tupuxuara". A skull crest was also present but its exact form and size are still unknown.
Discovery and species.
The first "Quetzalcoatlus" fossils were discovered in Texas, United States, from the Maastrichtian Javelina Formation at Big Bend National Park (dated to around 68 million years ago) in 1971 by a geology graduate student from the University of Texas at Austin's Jackson School of Geosciences, Douglas A. Lawson. The specimen consisted of a partial wing (in pterosaurs composed of the forearms and elongated fourth finger), from an individual later estimated at over 10 m in wingspan. Lawson discovered a second site of the same age, about forty kilometers from the first, where between 1972 and 1974 he and Professor Wann Langston Jr. of the Texas Memorial Museum unearthed three fragmentary skeletons of much smaller individuals. Lawson in 1975 announced the find in an article in "Science". That same year, in a subsequent letter to the same journal, he made the original large specimen, TMM 41450-3, the holotype of a new genus and species, "Quetzalcoatlus northropi". The genus name refers to the Aztec feathered serpent god Quetzalcoatl. The specific name honors John Knudsen Northrop, the founder of Northrop, who was interested in large tailless flying wing aircraft designs resembling "Quetzalcoatlus". At first it was assumed that the smaller specimens were juvenile or subadult forms of the larger type. Later, when more remains were found, it was realized they could have been a separate species. This possible second species from Texas was provisionally referred to as a "Quetzalcoatlus" sp. by Alexander Kellner and Langston in 1996, indicating that its status was too uncertain to give it a full new species name. The smaller specimens are more complete than the "Q. northropi" holotype, and include four partial skulls, though they are much less massive, with an estimated wingspan of 5.5 m.
The holotype specimen of "Q. northropi" has yet to be properly described and diagnosed. Where the known remains overlap, it has been considered by Mark Witton and colleagues (2010) to be indistinguishable from its Romanian contemporary "Hatzegopteryx". If "Q. northropi" is complete enough to be distinguished from other pterosaurs (i.e., if it is not a "nomen dubium"), "Hatzegopteryx" may represent the same animal. It is likely that huge pterosaurs such as "Q. northropi" would have had very large, transcontinental ranges, making its presence in both North America and Europe unsurprising. Mark Witton "et al." argued that the skull material of "Hatzegopteryx" and "Q." sp. differ enough that they cannot be regarded as the same animal, making it likely that "Q." sp., if not identical to "Quetzalcoatlus northropi", represents a distinct genus.
An azhdarchid neck vertebra, discovered in 2002 from the Maastrichtian age Hell Creek Formation, may also belong to "Quetzalcoatlus". The specimen (BMR P2002.2) was recovered accidentally when it was included in a field jacket prepared to transport part of a tyrannosaur specimen. Despite this association with the remains of a large carnivorous dinosaur, the vertebra shows no evidence that it was chewed on by the dinosaur. The bone came from an individual azhdarchid pterosaur estimated to have had a wingspan of 5 -.
Classification.
Below is a cladogram showing the phylogenetic placement of "Quetzalcoatlus" within Neoazhdarchia from Andres and Myers (2013).
Paleobiology.
"Quetzalcoatlus" was abundant in Texas during the Lancian in a fauna dominated by "Alamosaurus". The "Alamosaurus"-"Quetzalcoatlus" association probably represents semi-arid inland plains. "Quetzalcoatlus" had precursors in North America and its apparent rise to widespreadness may represent the expansion of its preferred habitat rather than an immigration event, as some experts have suggested.
Feeding.
There have been a number of different ideas proposed about the lifestyle of "Quetzalcoatlus". Because the area of the fossil site was four hundred kilometers removed from the coastline and there were no indications of large rivers or deep lakes nearby at the end of the Cretaceous, Lawson in 1975 rejected a fish-eating lifestyle, instead suggesting that "Quetzalcoatlus" scavenged like the Marabou Stork, but then on the carcasses of titanosaur sauropods such as "Alamosaurus". Lawson had found the remains of the giant pterosaur while searching for the bones of this dinosaur, which formed an important part of its ecosystem.
In 1996, Thomas Lehman and Langston rejected the scavenging hypothesis, pointing out that the lower jaw bent so strongly downwards that even when it closed completely a gap of over five centimeters remained between it and the upper jaw, very different from the hooked beaks of specialized scavenging birds. They suggested that with its long neck vertebrae and long toothless jaws "Quetzalcoatlus" fed like modern-day skimmers, catching fish during flight while cleaving the waves with its beak. While this skim-feeding view became widely accepted, it was not subjected to scientific research until 2007 when a study showed that for such large pterosaurs it was not a viable method because the energy costs would be too high due to excessive drag. In 2008 pterosaur workers Mark Paul Witton and Darren Naish published an examination of possible feeding habits and ecology of azhdarchids. Witton and Naish noted that most azhdarchid remains are found in inland deposits far from seas or other large bodies of water required for skimming. Additionally, the beak, jaw, and neck anatomy are unlike those of any known skimming animal. Rather, they concluded that azhdarchids were more likely terrestrial stalkers, similar to modern storks, and probably hunted small vertebrates on land or in small streams. Though "Quetzalcoatlus", like other pterosaurs, was a quadruped when on the ground, "Quetzalcoatlus" and other azhdarchids have fore and hind limb proportions more similar to modern running ungulate mammals than to their smaller cousins, implying that they were uniquely suited to a terrestrial lifestyle.
Flight.
The nature of flight in "Quetzalcoatlus" and other giant azhdarchids was poorly understood until serious biomechanical studies were conducted in the 21st century. One early (1984) experiment by Paul MacCready used practical aerodynamics to test the flight of "Quetzalcoatlus". MacCready constructed a model flying machine or ornithopter with a simple computer functioning as an autopilot. The model successfully flew with a combination of soaring and wing flapping; however, the model was half scale based on a then-current weight estimate of around 80 kg, far lower than more modern estimates of over 200 kg. The method of flight in these pterosaurs depends largely on weight, which has been controversial, and widely differing masses have been favored by different scientists. Some researchers have suggested that these animals employed slow, soaring flight, while others have concluded that their flight was fast and dynamic. In 2010, Donald Henderson argued that the mass of "Q. northropi" had been underestimated, even the highest estimates, and that it was too massive to have achieved powered flight. He estimated it in his 2010 paper as 540 kg. Henderson argued that it may have been flightless.
However, most other flight capability estimates have disagreed with Henderson's research, suggesting instead an animal superbly adapted to long-range, extended flight. In 2010, Mike Habib, a professor of biomechanics at Chatham University, and Mark Witton, a British paleontologist, undertook a further investigation into the claims of flightlessness in large pterosaurs. After factoring wingspan, body weight, and aerodynamics, a sophisticated computer program led the two researchers to conclude that "Q. northropi" was capable of flight "up to 80 miles an hour for 7 to 10 days at altitudes of 15,000 feet". Mike Habib further suggested a maximum flight range of 8,000 to 12,000 miles for "Q. northropi". Henderson's work was further criticized by Habib, who pointed out that although Henderson used excellent mass estimations, they were based on outdated pterosaur models, and that anatomical study of "Q. northropi" and other large pterosaur forelimbs show a higher degree of robustness than would be expected if they were purely quadrupedal. Habib believes that large pterosaurs most likely utilized a short burst of powered flight in order to then transition to thermal soaring.
Cultural significance.
"Quetzalcoatlus" has been featured in documentaries, both in cinemas and on television, since the 1980s. The Smithsonian project to build a working model of "Q. northropi" was the subject of the 1986 IMAX documentary "On the Wing", shown at the National Air and space museum in Washington, D.C.. It has also been featured in television programs such as the BBC's "Walking with Dinosaurs" in 1999 and Dangerous, Ltd.'s "Clash of the Dinosaurs" in 2009. The later program featured traits invented by the producers to heighten entertainment value, including a depiction of "Quetzalcoatlus" with the ability to use ultraviolet vision to locate dinosaur urine when hunting in the air. It was also depicted in the 2011 documentary "March of the Dinosaurs", where it was erroneously depicted as a clawless, bipedal scavenger, and in the 2009 series "Animal Armageddon", where it was correctly portrayed with pycnofibres. In the "Return to Jurassic Park" bonus feature of the 2011 Blu-ray release of the "Jurassic Park" film series, John R. Horner describes "Quetzalcoatlus" as the pterosaur that most accurately represented and matched the size of the pterosaurs that are featured in the films.
In June 2010, several life-sized models of "Q. northropi" were put on display on London's South Bank as the centerpiece exhibit for the Royal Society’s 350th anniversary exhibition. The models, which included both flying and standing individuals with wingspans of 9 m, were intended to help build interest in science among the public. The models were created by scientists from the University of Portsmouth, including David Martill, Bob Loveridge and Mark Witton, and engineers Bob and Jack Rushton from Griffon Hoverwork. The display presented to the public the most accurate pterosaur models constructed at the time, taking into account anatomical and footprint evidence based on skeletal and trace fossils from related pterosaurs.
In 1985, the U.S. Defense Advanced Research Projects Agency (DARPA) and AeroVironment used "Quetzalcoatlus northropi" as the basis for an experimental ornithopter UAV. They produced a half-scale model weighing 40 lb, with a wingspan of 18 ft. Coincidentally, Douglas A. Lawson, who discovered "Q. northropi" in Texas in 1971, named it for John "Jack" Northrop, a famous developer of tailless flying wing aircraft in the 1940s. The replica of "Q. northropi" incorporates a "flight control system/autopilot which processes pilot commands and sensor inputs, implements several feedback loops, and delivers command signals to its various servo-actuators." It is on exhibit at the National Air and Space Museum.

</doc>
<doc id="25320" url="http://en.wikipedia.org/wiki?curid=25320" title="Quedlinburg">
Quedlinburg

Quedlinburg (]) is a medieval German town situated just north of the Harz mountains, in the district of Harz in the west of Saxony-Anhalt, Germany. In 1994, both the medieval court and the old town were added to the prestigious UNESCO world heritage list.
The town was the capital of the district of Quedlinburg until 2007, when the district was disbanded. Several locations in the town are designated stops along the scenic holiday route, the Romanesque Road.
History.
The town of Quedlinburg is known since at least the early 9th century, when a settlement known as Gross Orden existed at the eastern bank of the river Bode. As such, the city was first mentioned in 922 as part of a donation by King Henry the Fowler. The records of this donation were collected at the abbey of Corvey.
After Henry's death in 936, his widow Saint Matilda founded a religious community for women ("Frauenstift") on the castle hill, where daughters of the higher nobility were educated. The main task of this collegiate foundation, Quedlinburg Abbey, was to pray for the memory of King Henry and the rulers who came after him. The "Annals of Quedlinburg" were also compiled there. The first abbess was Matilda, a granddaughter of King Henry and St. Matilda.
The Quedlinburg castle complex, founded by King Henry and built up by Emperor Otto I in 936, was an imperial palatinate of the Saxon emperors. The palatinate, including the male convent, was in the valley, where today the Roman Catholic Church of St. Wiperti is situated, while the women's convent was located on the castle hill.
In 961 and 963, a canon's monastery was established in St. Wiperti, south of the castle hill. It was abandoned in the 16th century, and at one time the church, which boasts a magnificent crypt from the 10th century, was even used as a barn and a pigsty before being restored in the 1950s.
In 973, shortly before the death of Emperor Otto I, a "Reichstag" (Imperial Convention) was held at the imperial court in which Mieszko, duke of Poland, and Boleslav, duke of Bohemia, as well as numerous other nobles from as far away as Byzantium and Bulgaria, gathered to pay homage to the emperor. On the occasion, Otto the Great introduced his new daughter-in-law Theophanu, a Byzantine princess whose marriage to Otto II brought hope for recognition and continued peace between the rulers of the Eastern and Western empires.
In 994, Otto III granted the right of market, tax, and coining, and established the first market place to the north of the castle hill.
The town became a member of the Hanseatic League in 1426. Quedlinburg Abbey frequently disputed the independence of Quedlinburg, which sought the aid of the Bishopric of Halberstadt. In 1477, Abbess Hedwig, aided by her brothers Ernest and Albert, broke the resistance of the town and expelled the bishop's forces. Quedlinburg was forced to leave the Hanseatic League and was subsequently protected by the Electorate of Saxony. Both town and abbey converted to Lutheranism in 1539 during the Protestant Reformation.
In 1697, Elector Frederick Augustus I of Saxony sold his rights to Quedlinburg to Elector Frederick III of Brandenburg for 240,000 thalers. Quedlinburg Abbey contested Brandenburg-Prussia's claims throughout the 18th century, however. The abbey was secularized in 1802 during the German Mediatisation, and Quedlinburg passed to the Kingdom of Prussia as part of the Principality of Quedlinburg Part of the Napoleonic Kingdom of Westphalia from 1807–13, it was included within the new Prussian Province of Saxony in 1815. In all this time, great ladies ruled Quedlinburg as abbesses without "taking the veil"; they were free to marry. The last of these great ladies was a Swedish princess, an early fighter for women's rights, Sofia Albertina.
During the Nazi regime, the memory of Henry I became a sort of cult, as Heinrich Himmler saw himself as the reincarnation of the "most German of all German" rulers. The collegiate church and castle were to be turned into a shrine for Nazi Germany. The Nazi Party tried to create a new religion. The cathedral was closed from 1938 and during the war. The local crematory was kept busy burning the victims of the Langenstein-Zwieberge concentration camp. Liberation in 1945 brought back the Protestant bishop and the church bells, and the Nazi-style eagle was taken down from the tower. Georg Ay was local party chief from 1931 until the end of the war.
Quedlinburg was administered within Bezirk Halle while part of the Communist East Germany from 1949 to 1990. It became part of the state of Saxony-Anhalt upon German reunification in 1990.
During Quedlinburg's Communist era as part of the GDR (1949–1990), restoration specialists from Poland were called in during the 1980s to carry out repairs on the old architecture. As in all German cities, the "Altstadt" (old city) medieval sections are the most popular attractions of any town. Now Quedlinburg is a center of restoration of "Fachwerk" houses.
During the last months of World War II, the United States military occupied Quedlinburg. In the 1980s, upon the death of one of the US military men, the theft of medieval art from Quedlinburg came to light.
Main sights.
In the innermost parts of the town, a wide selection of half-timbered buildings from at least five different centuries are to be found (including a 14th-century structure, one of Germany's oldest), while around the outer fringes of the old town are wonderful examples of "Jugendstil" buildings, dating from the late 19th and early 20th centuries.
Since December 1994, the old town of Quedlinburg and the castle mount with the collegiate church are listed as one of UNESCO's World Heritage Sites. Quedlinburg is one of the best-preserved medieval and renaissance towns in Europe, having escaped major damage in World War II.
In 2006, the Harzer Schmalspurbahnen Selketal branch was extended into Quedlinburg from Gernrode, giving access to the historic steam narrow gauge railway, Alexisbad and high Harz plateau.
The castle and the cathedral still tower above the city the way they dominated the town in early Middle Ages. The cathedral is a prime example of German Romanesque style. The Domschatz, the cathedral treasure containing ancient Christian religious artefacts and books, was stolen by an American soldier and finally brought back to Quedlinburg in 1993 and is again on display here.
Geography.
The town is located north of the Harz mountains, about 123 m above sea level. The nearest mountains reach 181 m above sea level. The biggest part of the town is located in the western part of the Bode river bed. This river comes from the Harz mountains and flows into the river Saale and further into the river Elbe. The municipal area of Quedlinburg is 120.42 km²; before the incorporation of the two (previously independent) municipalities of Gernrode and Bad Suderode in January 2014 it was only 78.14 km².
Climate.
Quedlinburg has a humid continental climate (Köppen climate classification) resulting from prevailing westerlies, blowing from the high-pressure area in the central Atlantic towards Scandinavia. Snowfall occurs almost every winter. January and February are the coldest months of the year, with an average temperature of 0.1 °C and 0.4 °C. July and August are the hottest months, with an average temperature of 17.8 °C (63 °F) and 17.2 °C. The average annual precipitation is close to 438 mm with rain occurring usually from May to September. This precipitation is one of the lowest in Germany, which has an annual average close to 700 mm. In August 2010, Quedlinburg was the driest place in Germany, with only 72,4 l/m2.
Transport.
Air.
The nearest airports to Quedlinburg are Hannover, 120 km north-west, and Leipzig/Halle Airport, 90 km south-east. Much closer, but only served by a few airlines, is Magdeburg-Cochstedt. An airfield is located at Ballenstedt-Assmussstedt for general aviation.
Train.
Regional trains run on the standard-gauge Magdeburg–Thale line by Deutsche Bahn and the private company Connex connect Quedlinburg with Magdeburg, Thale, and Halberstadt.
In 2006, the Selke Valley branch of the Harz Narrow Gauge Railways was extended into Quedlinburg from Gernrode, giving access to the historic steam narrow-gauge railway, Alexisbad, and high Harz plateau.
Bus.
Quedlinburg is connected by regional buses to the surrounding villages and small towns. Additionally, buses to Berlin are run by the company .
Notable people.
Jordanus of Quedlinburg, a 14th-century preacher and monk, wrote texts about contemporary devoutness.
In the 18th century, Dorothea Erxleben was the first female medical doctor in Germany. Born in 1715, she was the first women to receive a full M.D. from a German university (University of Halle), with the help of Frederick the Great. Trained originally by her father, the town's physician, she had been practicing as a physician, but without the Masters degree, until she was accused of witchcraft. She demanded a chance to defend her knowledge. Officials debated for a year over whether a woman so often pregnant could practice medicine. They finally allowed her to take the exams – after the birth of her fourth child – and she passed with flying colors.
Friedrich Gottlieb Klopstock was a German poet and contemporary of Johann Wolfgang von Goethe.
Sister cities.
Quedlinburg is twinned with:

</doc>
<doc id="25321" url="http://en.wikipedia.org/wiki?curid=25321" title="Quantization">
Quantization

Quantization is the procedure of constraining something from a continuous set of values (such as the real numbers) to a relatively small discrete set (such as the integers).

</doc>
<doc id="25322" url="http://en.wikipedia.org/wiki?curid=25322" title="Quantum theory">
Quantum theory

Quantum theory may mean:
In science:
In popular culture:

</doc>
<doc id="25323" url="http://en.wikipedia.org/wiki?curid=25323" title="QRP operation">
QRP operation

In amateur radio, QRP operation refers to transmitting at reduced power while attempting to maximize one's effective range. The term QRP derives from the standard Q code used in radio communications, where "QRP" and "QRP?" are used to request, "Reduce power", and ask "Should I reduce power?" respectively. The opposite of QRP is QRO, or high-power operation.
Philosophy.
Most amateurs use approximately 100 watts on HF and 50 watts on VHF/UHF , but in some parts of the world, like the US, they can use up to 1500 watts. QRP enthusiasts contend that this is not always necessary, and doing so wastes power, increases the likelihood of causing interference to nearby televisions, radios, and telephones and, for United States' amateurs, is incompatible with FCC Part 97 rule, which states that one must use "the minimum power necessary to carry out the desired communications".
The current record for a QRP connection is 1 µW for 1,650 miles on 10m.
Practice.
There is not complete agreement on what constitutes QRP power. While most QRP enthusiasts agree that for CW, AM, FM, and data modes, the transmitter output power should be 5 watts (or less), the maximum output power for SSB (single sideband) is not always agreed upon. Some believe that the power should be no more than 10 watts peak envelope power (PEP), while others strongly hold that the power limit should be 5 watts. QRPers are known to use even less than five watts, sometimes operating with as little as 100 milliwatts or even less. Extremely low power—1 watt and below—is often referred to by hobbyists as QRPp.
Communicating using QRP can be difficult since the QRPer must face the same challenges of radio propagation faced by amateurs using higher power levels, but with the inherent disadvantages associated with having a weaker signal on the receiving end, all other things being equal. QRP aficionados try to make up for this through more efficient antenna systems and enhanced operating skills.
QRP is especially popular with CW operators and those using the newer digital modes. PSK31 is a highly efficient, narrow-band mode that is very suitable to QRP operation.
QRSS.
Some extreme QRP enthusiasts use QRSS — transmitting extremely slowly — to compensate for the decreased signal-to-noise ratio involved in QRP operation.
QRSS derives from the standard Q code used in radio communications, where "QRS?" asks "Shall I send more slowly?" and "QRS" requests "Send more slowly".
Rather than directly listening to such slow transmissions, many QRSS enthusiasts record the transmission for later analysis, later decoding "by ear" while playing it back at much faster rates (time compression), or decoding "by eye" on the waterfall display of a spectrum analyzer.
QRSS enthusiasts typically use some form of Morse code, except much slower — rather than a typical 1/10 second "dit" time, QRSS transmissions may use a full second for the "dit" time, or in extreme cases, a full minute for a single "dit" time.
A few people apply QRSS techniques to other narrow-band communication codes or protocols, such as the "Slowfeld" variant of Hellschreiber, slow-scan television, MT63, etc.
Equipment.
Many of the larger, more powerful commercial transceivers permit the operator to lower their output level to QRP levels. Commercial transceivers specially designed to operate at or near QRP power levels have been commercially available since the late 1960s. In 1969, American manufacturer, Ten-Tec, produced the Powermite-1. This radio was one of Ten-Tec's first assembled transceivers. (The was available, and it was essentially the same radio, albeit in kit form.) This radio featured modular construction (all stages of the transceiver were on individual circuit boards): the transmitter was capable of about one or two watts of RF, and the receiver was a direct-conversion unit, similar to that found in the Heathkit HW-7 and HW-8 lines. Many amateurs became quite adept at QRP'ing through their use of these early, trend-setting radios . As QRP has become more popular in recent years , radio manufacturers have introduced radios specifically intended for the QRP enthusiast. Popular US models include Elecraft KX3, K2 and K1, the Yaesu Yaesu FT-817, the Icom IC-703, and the 516 Argonaut V and the new 539 Argonaut VI from TenTec. Another popular source is , which offers a variety of popular kits. Enthusiasts operate QRP radios on the HF bands in portable modes, usually carrying the radios in backpacks, with whip antennas. Some QRPers prefer to construct their equipment from kits or homebrew it from scratch. Many popular designs are based on the NE612 mixer IC, i.e. the K1, K2, ATS series and the Softrock SDR.
Contests and awards.
There are specific operating awards, contests, clubs, and conventions devoted to QRP enthusiasts.
In the USA, the November Sweepstakes, June and September VHF QSO Parties, January VHF Sweepstakes, and the ARRL International DX Contest, as well as many major international contests have designated special QRP categories. For example, during the annual ARRL's Field Day contest, making a QSO (ham-to-ham contact) using "QRP battery power" is worth five times as many points as a contact made by conventional means.
The QRP ARCI club sponsors 12 contests during the year specifically for QRP operators. 
Typical awards include the QRP ARCI club's "thousand-miles-per-watt" award, available to anyone presenting evidence of a qualifying contact. QRP ARCI also offers special awards for achieving the ARRL's Worked All States, Worked All Continents, and DX Century Club awards under QRP conditions. Other QRP clubs also offer similar versions of these awards, as well as general QRP operating achievement awards.

</doc>
<doc id="25327" url="http://en.wikipedia.org/wiki?curid=25327" title="QCD">
QCD

The initialism QCD may refer to:

</doc>
<doc id="25328" url="http://en.wikipedia.org/wiki?curid=25328" title="Quicksilver">
Quicksilver

Quicksilver is the chemical element mercury.
Quicksilver also may refer to

</doc>
<doc id="25330" url="http://en.wikipedia.org/wiki?curid=25330" title="Quartet">
Quartet

In music, a quartet or quartette (French: "quatuor", German: "Quartett", Italian: "quartetto", Spanish: "cuarteto", Polish: "kwartet") is an ensemble of four singers or instrumental performers; or a musical composition for four voices or instruments.
Classical.
String quartet.
In Classical music, the most important combination of four instruments in chamber music is the string quartet. String quartets most often consist of two violins, a viola, and a cello. The particular choice and number of instruments derives from the registers of the human voice: soprano, alto, tenor and bass. In the string quartet, two violins play the soprano and alto vocal registers, the viola plays the tenor register and the cello plays the bass register. 
Composers of notable string quartets include Joseph Haydn (68 compositions), Wolfgang Amadeus Mozart (23), Ludwig van Beethoven (17), Felix Mendelssohn (6), Franz Schubert (15), Johannes Brahms (3), Antonín Dvořák (14), Alexander Borodin (2), Béla Bartók (6), and Dmitri Shostakovich (15). The Italian composer Luigi Boccherini (1743–1805), wrote more than 100 string quartets. 
Less often, string quartets are written for other combinations of the standard string ensemble. These include quartets for one violin, two violas, and one cello, notably by Carl Stamitz (6 compositions) and others; and for one violin, one viola, and two cellos, by Johann Georg Albrechtsberger and others.
Piano quartet.
Another common standard classical quartet is the piano quartet, consisting of violin, viola, cello, and piano. Romantic composers Beethoven, Brahms, and Mendelssohn each wrote three important compositions in this form, and Mozart, Dvořák, and Gabriel Fauré each wrote two.
Other instrumental quartets.
Wind quartets are scored either the same as a string quartet with the wind instrument replacing the first violin (i.e. scored for wind, violin, viola and cello) or are groups of four wind instruments. Among the latter, the SATB format woodwind quartet of flute, oboe, clarinet, and bassoon is relatively common.
An example of a wind quartet featuring four of the same types of wind instruments is the saxophone quartet, consisting of soprano saxophone, alto saxophone, tenor saxophone and baritone saxophone or (SATB). Often a second alto may be substituted for the soprano part (AATB) or a bass saxophone may be substituted for the baritone.
Vocal quartet.
Compositions for four singers have been written for quartets a cappella; accompanied by instruments, such as a piano; and accompanied by larger vocal forces, such as a choir. Brahms and Schubert wrote numerous pieces for four voices that were once popular in private salons, although they are seldom performed today. Vocal quartets also feature within larger classical compositions, such as opera, choral works, and symphonic compositions. The final movement of Beethoven's Ninth Symphony and the Verdi Requiem are two examples of renowned concert works that include vocal quartets.
Typically, a vocal quartet is composed of:
Baroque quartet.
The baroque quartet is a form of music composition similar to the trio sonata, but with four music parts performed by three solo melodic instruments and basso continuo. The solo instruments could be strings or wind instruments.
Examples of baroque quartets are Telemann's Paris quartets.
Jazz.
Quartets are popular in jazz and jazz fusion music. Jazz quartet ensembles are often composed of a horn (e.g., saxophone, trumpet, etc.), a chordal instrument (e.g., electric guitar, piano, Hammond organ, etc.), a bass instrument (e.g., double bass or bass guitar) and a drum kit. This configuration is sometimes modified by using a second horn replacing the chordal instrument, such as a trumpet and saxophone with string bass and drum kit, popularized by Miles Davis, or by using two chordal instruments (e.g., piano and electric guitar).
Popular music.
In 20th century Western popular music, the term "vocal quartet" usually refers to ensembles of four singers of the same gender. This is particularly common for barbershop quartets and Gospel quartets. 
Some well-known female US vocal quartets include The Carter Sisters; The Forester Sisters; The Chiffons; The Chordettes; The Lennon Sisters; and En Vogue. Some well-known male US vocal quartets include The Statler Brothers; The Ames Brothers; The Chi-Lites; Crosby Stills Nash & Young; The Dixie Hummingbirds; The Four Aces; Four Freshmen; The Four Seasons; The Four Tops; The Cathedral Quartet; Ernie Haase and Signature Sound; The Golden Gate Quartet; The Hilltoppers; The Jordanaires; Mills Brothers; The Rascals; and The Skylarks. The only known U.S. drag quartet is The Kinsey Sicks. Some mixed-gender vocal quartets include The Pied Pipers; The Mamas & the Papas; The Merry Macs; and The Weavers.
The quartet lineup also is very common in pop and rock music. A standard quartet formation in pop and rock music is an ensemble consisting of two electric guitars, a bass guitar, and a drum kit. This configuration is sometimes modified by using a keyboard instrument (e.g., organ, piano, synthesizer) or a soloing instrument (e.g., saxophone) in place of the second electric guitar.

</doc>
<doc id="25336" url="http://en.wikipedia.org/wiki?curid=25336" title="Quantum entanglement">
Quantum entanglement

Quantum entanglement is a physical phenomenon that occurs when pairs or groups of particles are generated or interact in ways such that the quantum state of each particle cannot be described independently—instead, a quantum state may be given for the system as a whole.
Measurements of physical properties such as position, momentum, spin, polarization, etc. performed on entangled particles are found to be appropriately correlated. For example, if a pair of particles is generated in such a way that their total spin is known to be zero, and one particle is found to have clockwise spin on a certain axis, then the spin of the other particle, measured on the same axis, will be found to be counterclockwise. Because of the nature of quantum measurement, however, this behavior gives rise to effects that can appear paradoxical: any measurement of a property of a particle can be seen as acting on that particle (e.g. by collapsing a number of superposed states); and in the case of entangled particles, such action must be on the entangled system as a whole. It thus appears that one particle of an entangled pair "knows" what measurement has been performed on the other, and with what outcome, even though there is no known means for such information to be communicated between the particles, which at the time of measurement may be separated by arbitrarily large distances.
Such phenomena were the subject of a 1935 paper by Albert Einstein, Boris Podolsky and Nathan Rosen, and several papers by Erwin Schrödinger shortly thereafter, describing what came to be known as the EPR paradox. Einstein and others considered such behavior to be impossible, as it violated the local realist view of causality (Einstein referred to it as "spooky action at a distance"), and argued that the accepted formulation of quantum mechanics must therefore be incomplete. Later, however, the counterintuitive predictions of quantum mechanics were verified experimentally. Experiments have been performed involving measuring the polarization or spin of entangled particles in different directions, which—by producing violations of Bell's inequality—demonstrate statistically that the local realist view cannot be correct. This has been shown to occur even when the measurements are performed more quickly than light could travel between the sites of measurement: there is no lightspeed or slower influence that can pass between the entangled particles. Recent experiments have measured entangled particles within less than one one-hundredth of a percent of the light travel time between them. According to the formalism of quantum theory, the effect of measurement happens instantly. It is not possible, however, to use this effect to transmit classical information at faster-than-light speeds (see Faster-than-light → Quantum mechanics).
Quantum entanglement is an area of extremely active research by the physics community, and its effects have been demonstrated experimentally with photons, electrons, molecules the size of buckyballs, and even small diamonds. Research is also focused on the utilization of entanglement effects in communication and computation.
History.
The counterintuitive predictions of quantum mechanics about strongly correlated systems were first discussed by Albert Einstein in 1935, in a joint paper with Boris Podolsky and Nathan Rosen. In this study, they formulated the EPR paradox (Einstein, Podolsky, Rosen paradox), a thought experiment that attempted to show that quantum mechanical theory was incomplete. They wrote: "We are thus forced to conclude that the quantum-mechanical description of physical reality given by wave functions is not complete."
However, they did not coin the word "entanglement", nor did they generalize the special properties of the state they considered. Following the EPR paper, Erwin Schrödinger wrote a letter (in German) to Einstein in which he used the word "Verschränkung" (translated by himself as "entanglement") "to describe the correlations between two particles that interact and then separate, as in the EPR experiment." He shortly thereafter published a seminal paper defining and discussing the notion, and terming it "entanglement." In the paper he recognized the importance of the concept, and stated: "I would not call [entanglement] "one" but rather "the" characteristic trait of quantum mechanics, the one that enforces its entire departure from classical lines of thought."
Like Einstein, Schrödinger was dissatisfied with the concept of entanglement, because it seemed to violate the speed limit on the transmission of information implicit in the theory of relativity. Einstein later famously derided entanglement as "spukhafte Fernwirkung" or "spooky action at a distance."
The EPR paper generated significant interest among physicists and inspired much discussion about the foundations of quantum mechanics (perhaps most famously Bohm's interpretation of quantum mechanics), but produced relatively little other published work. So, despite the interest, the weak point in EPR's argument was not discovered until 1964, when John Stewart Bell proved that one of their key assumptions, the principle of locality, which underlies the kind of hidden variables interpretation hoped for by EPR, was mathematically inconsistent with the predictions of quantum theory. Specifically, he demonstrated an upper limit, seen in Bell's inequality, regarding the strength of correlations that can be produced in any theory obeying local realism, and he showed that quantum theory predicts violations of this limit for certain entangled systems. His inequality is experimentally testable, and there have been numerous relevant experiments, starting with the pioneering work of Freedman and Clauser in 1972 and Aspect's experiments in 1982. They have all shown agreement with quantum mechanics rather than the principle of local realism. However, the issue is not finally settled, as each of these experimental tests has left open at least one loophole by which it is possible to question the validity of the results.
The work of Bell raised the possibility of using these super strong correlations as a resource for communication. It led to the discovery of quantum key distribution protocols, most famously BB84 by Bennet and Brassard and E91 by Artur Ekert. Although BB84 does not use entanglement, Ekert's protocol uses the violation of a Bell's inequality as a proof of security.
Concept.
Meaning of entanglement.
An entangled system is defined to be one whose quantum state cannot be factored as a product of states of its local constituents (e.g. individual particles). If entangled, one constituent cannot be fully described without considering the other(s). Note that the state of a composite system is always expressible as a "sum", or superposition, of products of states of local constituents; it is entangled if this sum necessarily has more than one term.
Quantum systems can become entangled through various types of interactions. For some ways in which entanglement may be achieved for experimental purposes, see the section below on methods. Entanglement is broken when the entangled particles decohere through interaction with the environment; for example, when a measurement is made.
As an example of entanglement: a subatomic particle decays into an entangled pair of other particles. The decay events obey the various conservation laws, and as a result, the measurement outcomes of one daughter particle must be highly correlated with the measurement outcomes of the other daughter particle (so that the total momenta, angular momenta, energy, and so forth remains roughly the same before and after this process). For instance, a spin-zero particle could decay into a pair of spin-1/2 particles. Since the total spin before and after this decay must be zero (conservation of angular momentum), whenever the first particle is measured to be spin up on some axis, the other (when measured on the same axis) is always found to be spin down. (This is called the "spin anti-correlated" case; and if the prior probabilities for measuring each spin are equal, the pair is said to be in the singlet state.)
Apparent paradox.
The seeming paradox here is that a measurement made on either of the particles apparently collapses the state of the entire entangled system—and does so instantaneously, before any information about the measurement could have reached the other particle (assuming that information cannot travel faster than light). In the quantum formalism, the result of a spin measurement on one of the particles is a collapse into a state in which each particle has a definite spin (either up or down) along the axis of measurement. The outcome is taken to be random, with each possibility having a probability of 50%. However, if both spins are measured along the same axis, they are found to be anti-correlated. This means that the random outcome of the measurement made on one particle seems to have been transmitted to the other, so that it can make the "right choice" when it is measured. The distance and timing of the measurements can be chosen so as to make the interval between the two measurements spacelike, i.e. from any of the two measuring events to the other a message would have to travel faster than light. Then, according to the principles of special relativity, it is not in fact possible for any information to travel between two such measuring events—it is not even possible to say which of the measurements came first, as this would depend on the inertial system of the observer. Therefore the correlation between the two measurements cannot appropriately be explained as one measurement determining the other: different observers would disagree about the role of cause and effect.
The hidden variables theory.
A possible resolution to the apparent paradox might be to assume that the state of the particles contains some hidden variables, whose values effectively determine, right from the moment of separation, what the outcomes of the spin measurements are going to be. This would mean that each particle carries all the required information with it, and nothing needs to be transmitted from one particle to the other at the time of measurement. It was originally believed by Einstein and others (see the previous section) that this was the only way out, and therefore that the accepted quantum mechanical description (with a random measurement outcome) must be incomplete. (In fact similar paradoxes can arise even without entanglement: the position of a single particle is spread out over space, and two widely separated detectors attempting to detect the particle in two different places must instantaneously attain appropriate correlation, so that they do not "both" detect the particle.)
Violations of Bell's inequality.
The hidden variables theory fails, however, when we consider measurements of the spin of entangled particles along different axes (for example, along any of three axes which make angles of 120 degrees). If a large number of pairs of such measurements are made (on a large number of pairs of entangled particles), then statistically, if the local realist or hidden variables view were correct, the results would always satisfy Bell's inequality. A number of experiments have shown in practice, however, that Bell's inequality is not satisfied. This tends to confirm that the original formulation of quantum mechanics is indeed correct, in spite of its apparently paradoxical nature. Even when measurements of the entangled particles are made in moving relativistic reference frames, in which each measurement (in its own relativistic time frame) occurs before the other, the measurement results remain correlated.
The fundamental issue about measuring spin along different axes is that these measurements cannot have definite values at the same time―they are incompatible in the sense that these measurements' maximum simultaneous precision is constrained by the uncertainty principle. This is contrary to what is found in classical physics, where any number of properties can be measured simultaneously with arbitrary accuracy. It has been proven mathematically that compatible measurements cannot show Bell-inequality-violating correlations, and thus entanglement is a fundamentally non-classical phenomenon.
Other types of experiments.
In a 2012 experiment, "delayed-choice entanglement swapping" was used to decide whether two particles were entangled or not after they had already been measured.
In a 2013 experiment, entanglement swapping has been used to create entanglement between photons that never coexisted in time, thus demonstrating that "the nonlocality of quantum mechanics, as manifested by entanglement, does not apply only to particles with spacelike separation, but also to particles with timelike [i.e., temporal] separation".
In three independent experiments it was shown that classically-communicated separable quantum states can be used to carry entangled states.
In August 2014, researcher Gabriela Barreto Lemos and team were able to "take pictures" of objects using photons that have not interacted with the subjects, but were entangled with photons that did interact with such objects. Lemos, from the University of Vienna, is confident that this new quantum imaging technique could find application where low light imaging is imperative, in fields like biological or medical imaging.
Special Theory of Relativity.
Another theory explains quantum entanglement using special relativity. According to this theory, faster-than-light communication between entangled systems can be achieved because the time dilation of special relativity allows time to stand still in light's point of view. For example, in the case of two entangled photons, a measurement made on one photon at present time would determine the state of the photon for both the present and past at the same moment. This leads to the instantaneous determination of the state of the other photon. Corresponding logic is applied to explain entangled systems, i.e. electron and positron, that travel below the speed of light.
The Mystery of Time.
There exist physicists who say that time is an emergent phenomenon that is a side effect of quantum entanglement. The
Wheeler–DeWitt equation that combines general relativity and quantum mechanics – by leaving out time altogether – was introduced in 1960s and it was taken up again in 1983, when the theorists Don Page and William Wootters made a solution based on the quantum phenomenon of entanglement. Page and Wootters argued that entanglement can be used to measure time.
In 2013, at the Istituto Nazionale di Ricerca Metrologica (INRIM) in Turin, Italy, Ekaterina Moreva, together with Giorgio Brida, Marco Gramegna, Vittorio Giovannetti, Lorenzo Maccone, and Marco Genovese performed the first experimental test of Page and Wootters' ideas. Their result has been interpreted to confirm that time is an emergent phenomenon for internal observers but absent for external observers of the universe.
Source for the arrow of time.
Physicist Seth Lloyd says that quantum uncertainty gives rise to "entanglement", the putative source of the arrow of time. According to Lloyd; "The arrow of time is an arrow of increasing correlations."
Non-locality and hidden variables.
There is much confusion about the meaning of entanglement, non-locality and hidden variables and how they relate to each other. As described above, entanglement is an experimentally verified and accepted property of nature, which has critical implications for the interpretations of quantum mechanics. The question becomes, "How can one account for something that was at one point indefinite with regard to its spin (or whatever is in this case the subject of investigation) suddenly becoming definite in that regard even though no physical interaction with the second object occurred, and, if the two objects are sufficiently far separated, could not even have had the time needed for such an interaction to proceed from the first to the second object?" The latter question involves the issue of locality, i.e., whether for a change to occur in something the agent of change has to be in physical contact (at least via some intermediary such as a field force) with the thing that changes. Study of entanglement brings into sharp focus the dilemma between locality and the completeness or lack of completeness of quantum mechanics.
Bell's theorem and related results rule out a local realistic explanation for quantum mechanics (one which obeys the principle of locality while also ascribing definite values to quantum observables). However, in other interpretations, the experiments that demonstrate the apparent non-locality can also be described in local terms: If each distant observer regards the other as a quantum system, communication between the two must then be treated as a measurement process, and this communication is strictly local. In particular, in the many worlds interpretation, the underlying description is fully local. More generally, the question of locality in quantum physics is extraordinarily subtle and sometimes hinges on precisely how it is defined.
In the media and popular science, quantum non-locality is often portrayed as being equivalent to entanglement. While it is true that a bipartite quantum state must be entangled in order for it to produce non-local correlations, there exist entangled states that do not produce such correlations. A well-known example of this is the Werner state that is entangled for certain values of formula_1, but can always be described using local hidden variables. In short, entanglement of a two-party state is necessary but not sufficient for that state to be non-local. It is important to recognise that entanglement is more commonly viewed as an algebraic concept, noted for being a precedent to non-locality as well as to quantum teleportation and to superdense coding, whereas non-locality is defined according to experimental statistics and is much more involved with the foundations and interpretations of quantum mechanics.
Quantum mechanical framework.
The following subsections are for those with a good working knowledge of the formal, mathematical description of quantum mechanics, including familiarity with the formalism and theoretical framework developed in the articles: bra–ket notation and mathematical formulation of quantum mechanics.
Pure states.
Consider two noninteracting systems A and B, with respective Hilbert spaces HA and HB. The Hilbert space of the composite system is the tensor product
If the first system is in state formula_3 and the second in state formula_4, the state of the composite system is
States of the composite system which can be represented in this form are called "separable states", or (in the simplest case) "product states".
Not all states are separable states (and thus product states). Fix a basis formula_6 for HA and a basis formula_7 for HB. The most general state in "HA" ⊗ "HB" is of the form
This state is separable if there exist formula_9 so that formula_10 yielding formula_11 and formula_12 It is inseparable if for all formula_9 we have formula_14 If a state is inseparable, it is called an "entangled state".
For example, given two basis vectors formula_15 of HA and two basis vectors formula_16 of HB, the following is an entangled state:
If the composite system is in this state, it is impossible to attribute to either system A or system B a definite pure state. Another way to say this is that while the von Neumann entropy of the whole state is zero (as it is for any pure state), the entropy of the subsystems is greater than zero. In this sense, the systems are "entangled". This has specific empirical ramifications for interferometry. It is worthwhile to note that the above example is one of four Bell states, which are (maximally) entangled pure states (pure states of the "HA" ⊗ "HB" space, but which cannot be separated into pure states of each HA and HB).
Now suppose Alice is an observer for system A, and Bob is an observer for system B. If in the entangled state given above Alice makes a measurement in the formula_18 eigenbasis of A, there are two possible outcomes, occurring with equal probability:
If the former occurs, then any subsequent measurement performed by Bob, in the same basis, will always return 1. If the latter occurs, (Alice measures 1) then Bob's measurement will return 0 with certainty. Thus, system B has been altered by Alice performing a local measurement on system A. This remains true even if the systems A and B are spatially separated. This is the foundation of the EPR paradox.
The outcome of Alice's measurement is random. Alice cannot decide which state to collapse the composite system into, and therefore cannot transmit information to Bob by acting on her system. Causality is thus preserved, in this particular scheme. For the general argument, see no-communication theorem.
Ensembles.
As mentioned above, a state of a quantum system is given by a unit vector in a Hilbert space. More generally, if one has a large number of copies of the same system, then the state of this "ensemble" is described by a density matrix, which is a positive-semidefinite matrix, or a trace class when the state space is infinite-dimensional, and has trace 1. Again, by the spectral theorem, such a matrix takes the general form:
where the the "w"i are positive-valued probabilities (they sum up to 1), the vectors αi are unit vectors, and in the infinite-dimensional case, we would take the closure of such states in the trace norm. We can interpret ρ as representing an ensemble where wi is the proportion of the ensemble whose states are formula_22. When a mixed state has rank 1, it therefore describes a "pure ensemble". When there is less than total information about the state of a quantum system we need density matrices to represent the state.
Experimentally, a mixed ensemble might be realized as follows. Consider a "black-box" apparatus that spits electrons towards an observer. The electrons' Hilbert spaces are identical. The apparatus might produce electrons that are all in the same state; in this case, the electrons received by the observer are then a pure ensemble. However, the apparatus could produce electrons in different states. For example, it could produce two populations of electrons: one with state formula_23 with spins aligned in the positive z direction, and the other with state formula_24 with spins aligned in the negative y direction. Generally, this is a mixed ensemble, as there can be any number of populations, each corresponding to a different state.
Following the definition above, for a bipartite composite system, mixed states are just density matrices on "HA" ⊗ "HB". That is, it has the general form
where the "w"i are positive-valued probabilities, formula_26, and the vectors are unit vectors. This is self-adjoint and positive and has trace 1.
Extending the definition of separability from the pure case, we say that a mixed state is separable if it can be written as:131–132
where the wi are positive-valued probabilities and the formula_28's and formula_29's are themselves mixed states (density operators) on the subsystems A and B respectively. In other words, a state is separable if it is a probability distribution over uncorrelated states, or product states. By writing the density matrices as sums of pure ensembles and expanding, we may assume without loss of generality that formula_28 and formula_29 are themselves pure ensembles. A state is then said to be "entangled" if it is not separable. 
In general, finding out whether or not a mixed state is entangled is considered difficult. The general bipartite case has been shown to be NP-hard. For the 2 × 2 and 2 × 3 cases, a necessary and sufficient criterion for separability is given by the famous Positive Partial Transpose (PPT) condition.
Reduced density matrices.
The idea of a reduced density matrix was introduced by Paul Dirac in 1930. Consider as above systems A and B each with a Hilbert space HA, HB. Let the state of the composite system be
As indicated above, in general there is no way to associate a pure state to the component system A. However, it still is possible to associate a density matrix. Let
which is the projection operator onto this state. The state of A is the partial trace of ρT over the basis of system B:
ρA is sometimes called the reduced density matrix of ρ on subsystem A. Colloquially, we "trace out" system B to obtain the reduced density matrix on A.
For example, the reduced density matrix of A for the entangled state
discussed above is
This demonstrates that, as expected, the reduced density matrix for an entangled pure ensemble is a mixed ensemble. Also not surprisingly, the density matrix of A for the pure product state formula_37 discussed above is
In general, a bipartite pure state ρ is entangled if and only if its reduced states are mixed rather than pure. 
Two applications that use them.
Reduced density matrices were explicitly calculated in different spin chains with unique ground state. An example is the one-dimensional AKLT spin chain: the ground state can be divided into a block and an environment. The reduced density matrix of the block is proportional to a projector to a degenerate ground state of another Hamiltonian.
The reduced density matrix also was evaluated for XY spin chains, where it has full rank. It was proved that in the thermodynamic limit, the spectrum of the reduced density matrix of a large block of spins is an exact geometric sequence in this case.
Entropy.
In this section, the entropy of a mixed state is discussed as well as how it can be viewed as a measure of quantum entanglement.
Definition.
In classical information theory, the Shannon entropy, H is associated to a probability distribution,formula_39, in the following way:
Since a mixed state ρ is a probability distribution over an ensemble, this leads naturally to the definition of the von Neumann entropy:
In general, one uses the Borel functional calculus to calculate a non-polynomial function such as log2("ρ"). If the nonnegative operator ρ acts on a finite-dimensional Hilbert space and has eigenvalues formula_42, log2("ρ") turns out to be nothing more than the operator with the same eigenvectors, but the eigenvalues formula_43. The Shannon entropy is then:
Since an event of probability 0 should not contribute to the entropy, and given that
the convention 0 log(0) = 0 is adopted. This extends to the infinite-dimensional case as well: if ρ has spectral resolution
assume the same convention when calculating
As in statistical mechanics, the more uncertainty (number of microstates) the system should possess, the larger the entropy. For example, the entropy of any pure state is zero, which is unsurprising since there is no uncertainty about a system in a pure state. The entropy of any of the two subsystems of the entangled state discussed above is log(2) (which can be shown to be the maximum entropy for 2 × 2 mixed states).
As a measure of entanglement.
Entropy provides one tool which can be used to quantify entanglement, although other entanglement measures exist. If the overall system is pure, the entropy of one subsystem can be used to measure its degree of entanglement with the other subsystems.
For bipartite pure states, the von Neumann entropy of reduced states is the unique measure of entanglement in the sense that it is the only function on the family of states that satisfies certain axioms required of an entanglement measure.
It is a classical result that the Shannon entropy achieves its maximum at, and only at, the uniform probability distribution {1/"n"...,1/"n"}. Therefore, a bipartite pure state "ρ" ∈ "H"A ⊗ "H"B is said to be a maximally entangled state if the reduced state of ρ is the diagonal matrix
For mixed states, the reduced von Neumann entropy is not the only reasonable entanglement measure.
As an aside, the information-theoretic definition is closely related to entropy in the sense of statistical mechanics (comparing the two definitions, we note that, in the present context, it is customary to set the Boltzmann constant ). For example, by properties of the Borel functional calculus, we see that for any unitary operator U,
Indeed, without this property, the von Neumann entropy would not be well-defined. 
In particular, U could be the time evolution operator of the system, i.e.
where H is the Hamiltonian of the system. Here the entropy is unchanged.
The reversibility of a process is associated with the resulting entropy change, i.e., a process is reversible if, and only if, it leaves the entropy of the system invariant. Therefore, the march of the arrow of time towards thermodynamic equilibrium is simply the growing spread of quantum entanglement.
This provides a connection between quantum information theory and thermodynamics. 
Rényi entropy also can be used as a measure of entanglement.
Entanglement measures.
Entanglement measures quantify the amount of entanglement in a (often viewed as a bipartite) quantum state. As aforementioned, entanglement entropy is the standard measure of entanglement for pure states (but no longer a measure of entanglement for mixed states). For mixed states, there are some entanglement measures in the literature and no single one is standard.
Most (but not all) of these entanglement measures reduce for pure states to entanglement entropy, and are difficult (NP-hard) to compute.
Quantum field theory.
The Reeh-Schlieder theorem of quantum field theory is sometimes seen as an analogue of quantum entanglement.
Applications.
Entanglement has many applications in quantum information theory. With the aid of entanglement, otherwise impossible tasks may be achieved.
Among the best-known applications of entanglement are superdense coding and quantum teleportation.
Most researchers believe that entanglement is necessary to realize quantum computing (although this is disputed by some).
Entanglement is used in some protocols of quantum cryptography. This is because the "shared noise" of entanglement makes for an excellent one-time pad. Moreover, since measurement of either member of an entangled pair destroys the entanglement they share, entanglement-based quantum cryptography allows the sender and receiver to more easily detect the presence of an interceptor.
In interferometry, entanglement is necessary for surpassing the standard quantum limit and achieving the Heisenberg limit.
Entangled states.
There are several canonical entangled states that appear often in theory and experiments.
For two qubits, the Bell states are
These four pure states are all maximally entangled (according to the entropy of entanglement) and form an orthonormal basis (linear algebra) of the Hilbert space of the two qubits. They play a fundamental role in Bell's theorem.
For M>2 qubits, the GHZ state is
which reduces to the Bell state formula_54 for formula_55. The traditional GHZ state was defined for formula_56. GHZ states are occasionally extended to "qudits", i.e. systems of "d" rather than 2 dimensions.
Also for M>2 qubits, there are spin squeezed states. Spin squeezed states are a class of states satisfying certain restrictions on the uncertainty of spin measurements, and are necessarily entangled.
For two bosonic modes, a NOON state is
This is like a Bell state formula_54 except the basis kets 0 and 1 have been replaced with "the "N" photons are in one mode" and "the "N" photons are in the other mode".
Finally, there also exist twin Fock states for bosonic modes, which can be created by feeding a Fock state into two arms leading to a beam-splitter. They are the sum of multiple of NOON states, and can used to achieve the Heisenberg limit.
For the appropriately chosen measure of entanglement, Bell, GHZ, and NOON states are maximally entangled while spin squeezed and twin Fock states are only partially entangled. The partially entangled states are generally easier to prepare experimentally.
Methods of creating entanglement.
Entanglement is usually created by direct interactions between subatomic particles. These interactions can take numerous forms. One of the most commonly used methods is spontaneous parametric down-conversion to generate a pair of photons entangled in polarisation. Other methods include the use of a fiber coupler to confine and mix photons, the use of quantum dots to trap electrons until decay occurs, the use of the Hong-Ou-Mandel effect, etc. In the earliest tests of Bell's theorem, the entangled particles were generated using atomic cascades.
It is also possible to create entanglement between quantum systems that never directly interacted, through the use of entanglement swapping.
Testing a system for entanglement.
Systems which contain no entanglement are said to be separable. For 2-Qubit and Qubit-Qutrit systems (2 x 2 and 2 x 3 respectively) the simple Peres-Horodecki criterion provides both a necessary and a sufficient criterion for separability, and thus for detecting entanglement. However, for the general case, the criterion is merely a sufficient one for separability, as the problem becomes NP-hard. A numerical approach to the problem is suggested by Jon Magne Leinaas, Jan Myrheim and Eirik Ovrum in their paper "Geometrical aspects of entanglement". Leinaas et al. offer a numerical approach, iteratively refining an estimated separable state towards the target state to be tested, and checking if the target state can indeed be reached. An implementation of the algorithm (including a built in Peres-Horodecki criterion testing) is brought in the 
Further reading.
</dl>

</doc>
<doc id="25343" url="http://en.wikipedia.org/wiki?curid=25343" title="Quasi-War">
Quasi-War

The Quasi-War (French: "Quasi-guerre") was an undeclared war fought almost entirely at sea between the United States of America against the French Republic from 1798 to 1800. In the United States, the conflict was sometimes also referred to as the "Undeclared War with France", the "Pirate Wars", and the "Half-War".
Background.
The Kingdom of France had been a crucial ally of the United States in the American Revolutionary War since the spring of 1776, and had signed in 1778 a treaty of alliance with the United States of America. But in 1794, after the French Revolution toppled that country's monarchy, the American government came to an agreement with the Kingdom of Great Britain, the Jay Treaty, that resolved several points of contention between the United States and Great Britain that had lingered after the end of the American Revolutionary War. It also contained economic clauses.
The United States had already declared neutrality in the conflict between Great Britain and revolutionary France, and American legislation was being passed for a trade deal with Britain. With the U.S. refusal to continue repaying its debt to France on the grounds that the debt had been owed to the French Crown, not to Republican France, French outrage at the U.S. led to a series of responses. French privateers began seizing American ships trading with Britain, and the French government refused to receive the new U.S. minister, Charles Cotesworth Pinckney, when he arrived in Paris in December 1796. In his annual message to Congress at the close of 1797, President John Adams reported on France's refusal to negotiate and spoke of the need "to place our country in a suitable posture of defense." In April 1798, President Adams informed Congress of the "XYZ Affair", in which French agents had demanded a large bribe for the restoration of diplomatic relations with the United States.
The French Navy inflicted substantial losses on American shipping. On 21 February 1795, Secretary of State Timothy Pickering reported to Congress that France had seized 316 American merchant ships during the previous eleven months. Furthermore, French marauders cruised the length of the Atlantic seaboard virtually unopposed. The administration had no warships to combat them, the Navy having been abolished and its last vessel sold in 1785. The U.S. possessed only a flotilla of small revenue cutters and some neglected coastal forts.
Increased depredations by French privateers led to the rebirth of the United States Navy and the United States Marine Corps to protect the expanding American merchant fleet. Congress authorized the president to acquire, arm, and man not more than 12 ships of up to 22 guns each. Several merchantmen were immediately purchased and converted into ships of war, and construction of the frigate "Congress" resumed.
7 July 1798, the date on which Congress rescinded treaties with France, is considered to be the beginning of the Quasi-War. This was followed two days later with the passage of the Congressional authorization to attack French warships.
Naval engagements.
The U.S. Navy operated with a battle fleet of about 25 vessels. These patrolled the southern coast of the United States and throughout the Caribbean, seeking French privateers. Captain Thomas Truxtun's insistence on the highest standards of crew training paid dividends as the frigate "Constellation" captured "L'Insurgente" and severely damaged "La Vengeance". French privateers usually resisted, as did "La Croyable", which was captured on 7 July 1798, by "Delaware" outside of Egg Harbor, New Jersey. "Enterprise" captured eight privateers and freed 11 American merchant ships from captivity. "Experiment" captured the French privateers "Deux Amis" and "Diane". Numerous American merchantmen were recaptured by "Experiment". "Boston" forced "Le Berceau" into submission. Silas Talbot engineered an expedition to Puerto Plata harbor in the Colony of Santo Domingo, a possession of France's ally Spain, on 11 May 1800; sailors and Marines from "Constitution" under Lieutenant Isaac Hull captured the French privateer "Sandwich" in the harbor and spiked the guns of the Spanish fort.
Only one U.S Navy vessel was captured by French forces, "Retaliation", which was later re-captured. She was the commandeered privateer "La Croyable", recently purchased by the U.S. Navy. "Retaliation" departed Norfolk on 28 October 1798, with "Montezuma" and "Norfolk", and cruised in the West Indies protecting American commerce. On 20 November 1798, the French frigates "L’Insurgente" and "Volontaire" overtook "Retaliation" while her consorts were away and forced commanding officer Lieutenant William Bainbridge to surrender the out-gunned schooner. "Montezuma" and "Norfolk" escaped after Bainbridge convinced the senior French commander that those American warships were too powerful for his frigates and persuaded him to abandon the chase. Renamed "Magicienne" by the French, the schooner again came into American hands on 28 June, when a broadside from "Merrimack" forced her to haul down her colors.
Revenue cutters in the service of the United States Revenue-Marine, the predecessor to the United States Coast Guard, also took part in the conflict. The cutter USRC "Pickering", commanded by Edward Preble, made two cruises to the West Indies and captured 10 prizes. Preble turned command of "Pickering" over to Benjamin Hillar, and he captured the much larger and more heavily armed French privateer "l‍ '​Egypte Conquise" after a nine-hour battle. In September 1800, Hillar, "Pickering", and her entire crew were lost at sea in a storm. Preble commanded the frigate "Essex", which he sailed around Cape Horn into the Pacific to protect American merchantmen in the East Indies; he recaptured several ships that had been seized by French privateers.
American naval losses may have been light, but the French successfully seized many American merchant ships by the war's end in 1800—over 2,000, according to one source.
Although they were fighting the same enemy, the Royal Navy and the United States Navy did not cooperate operationally, nor did they share operational plans or come to mutual understandings about deployment of their forces. The British did sell the American government naval stores and munitions. In addition, the two navies shared a system of signals by which each could recognize the other's warships at sea, and allowed merchantmen of their respective nations to join each other's convoys.
Conclusion of hostilities.
By the autumn of 1800, the United States Navy and the Royal Navy, combined with a more conciliatory diplomatic stance by the government of First Consul Napoleon Bonaparte, had reduced the activity of the French privateers and warships. The Convention of 1800, signed on 30 September, ended the Franco-American War. Unfortunately for President Adams, the news did not arrive in time to help him secure a second term in the 1800 presidential election.

</doc>
<doc id="25345" url="http://en.wikipedia.org/wiki?curid=25345" title="Quality management system">
Quality management system

A quality management system (QMS) is a collection of business processes focused on achieving quality policy and quality objectives to meet customer requirements. It is expressed as the organizational structure, policies, procedures, processes and resources needed to implement quality management. Early systems emphasized predictable outcomes of an industrial product production line, using simple statistics and random sampling. By the 20th century, labour inputs were typically the most costly inputs in most industrialized societies, so focus shifted to team cooperation and dynamics, especially the early signalling of problems via a continuous improvement cycle. In the 21st century, QMS has tended to converge with sustainability and transparency initiatives, as both investor and customer satisfaction and perceived quality is increasingly tied to these factors. Of all QMS regimes, the ISO 9000 family of standards is probably the most widely implemented worldwide - the ISO 19011 audit regime applies to both, and deals with quality and sustainability and their integration.
Other QMS, e.g. Natural Step, focus on sustainability issues and assume that other quality problems will be reduced as result of the systematic thinking, transparency, documentation and diagnostic discipline.
Concept of quality - historical background.
The concept of quality as we think of it now first emerged from the Industrial Revolution. Previously goods had been made from start to finish by the same person or team of people, with handcrafting and tweaking the product to meet 'quality criteria'. Mass production brought huge teams of people together to work on specific stages of production where one person would not necessarily complete a product from start to finish. In the late 19th century pioneers such as Frederick Winslow Taylor and Henry Ford recognized the limitations of the methods being used in mass production at the time and the subsequent varying quality of output. Birland established Quality Departments to oversee the quality of production and rectifying of errors, and Ford emphasized standardization of design and component standards to ensure a standard product was produced. Management of quality was the responsibility of the Quality department and was implemented by Inspection of product output to 'catch' defects.
Application of statistical control came later as a result of World War production methods, and were advanced by the work done of W. Edwards Deming, a statistician, after whom the Deming Prize for quality is named. Joseph M. Juran focused more on managing for quality. The first edition of Juran's Quality Control Handbook was published in 1951. He also developed the "Juran's trilogy," an approach to cross-functional management that is composed of three managerial processes: quality planning, quality control and quality improvement. These functions all play a vital role when evaluating quality.
Quality, as a profession and the managerial process associated with the quality function, was introduced during the second-half of the 20th century, and has evolved since then. Over this period, few other disciplines have seen as many changes as the quality profession.
The quality profession grew from simple control, to engineering, to systems engineering. Quality control activities were predominant in the 1940s, 1950s, and 1960s. The 1970s were an era of quality engineering and the 1990s saw quality systems as an emerging field. Like medicine, accounting, and engineering, quality has achieved status as a recognized profession Reference American Society for Quality (ASQ) Certified Quality Engineer (CQE) http://prdweb.asq.org/certification/control/quality-engineer/index
As Lee and Dale (1998) state, there are many organisations that are striving to assess the methods and ways in which their overall productivity, the quality of their products and services and the required operations to achieve them are done.
Quality system for medical devices.
ISO 13485 is considered state of the art for medical device manufacturers QMS and related services. The standard is harmonised in the EU to the medical devices directive (93/42/EEC) as well as the IVD and AIMD directives; the standard is also used in other jurisdictions such as Japan (JPAL) and Canada (via the CMDCAS scheme). 
Quality System requirements for medical devices have been internationally recognized as a way to assure product safety and efficacy and customer satisfaction since at least 1983, and were instituted as requirements in a . The U.S. Food and Drug Administration (FDA) had documented design defects in medical devices that contributed to recalls from 1983 to 1989 that would have been prevented if Quality Systems had been in place. The rule is promulgated at .
According to current Good Manufacturing Practice (GMP), medical device manufacturers have the responsibility to use good judgment when developing their quality system and apply those sections of the FDA Quality System (QS) Regulation that are applicable to their specific products and operations, in of the QS regulation. As with GMP, operating within this flexibility, it is the responsibility of each manufacturer to establish requirements for each type or family of devices that will result in devices that are safe and effective, and to establish methods and procedures to design, produce, and distribute devices that meet the quality system requirements.
The FDA has identified in the QS regulation the essential elements that a quality system shall embody for design, production and distribution, without prescribing specific ways to establish these elements. These elements include:
all overseen by management and quality audits.
Because the QS regulation covers a broad spectrum of devices and production processes, it allows some leeway in the details of quality system elements. It is left to manufacturers to determine the necessity for, or extent of, some quality elements and to develop and implement procedures tailored to their particular processes and devices. For example, if it is impossible to mix up labels at a manufacturer because there is only one label to each product, then there is no necessity for the manufacturer to comply with all of the GMP requirements under device labeling.
Drug manufactures are regulated under a different section of the Code of Federal Regulations:
Quality management organizations and awards.
The International Organization for Standardization's ISO 9001:2008 series describes standards for a QMS addressing the principles and processes surrounding the design, development and delivery of a general product or service. Organizations can participate in a continuing certification process to ISO 9001:2008 to demonstrate their compliance with the standard, which includes a requirement for continual (i.e. planned) improvement of the QMS, as well as more foundational QMS components such as failure mode and effects analysis (FMEA). 
(ISO 9000:2005 provides information on the fundamentals and vocabulary used in quality management systems. ISO 9004:2009 provides guidance on quality management approach for the sustained success of an organization. Neither of these standards can be used for certification purposes as they provide guidance, not requirements).
The educates organizations in improving their performance and administers the Malcolm Baldrige National Quality Award. The Baldrige Award recognizes U.S. organizations for performance excellence based on the . The Criteria address critical aspects of management that contribute to performance excellence: leadership; strategy; customers; measurement, analysis, and knowledge management; workforce; operations; and results.
The European Foundation for Quality Management's EFQM Excellence Model supports an award scheme similar to the Baldrige Award for European companies.
In Canada, the presents the " on an annual basis to organisations that have displayed outstanding performance in the areas of Quality and Workplace Wellness, and have met the Institute's criteria with documented overall achievements and results.
EQUASS is a sector-specific quality system designed for the social services sector, and addresses quality principles that are specific to service delivery to vulnerable groups, such as empowerment, rights and person-centredness. 
The is a network of state and local organizations that use the at the grassroots level to improve the performance of local organizations and economies. browsers can find Alliance members in their state and get the latest news and events from the Baldrige community.
Quality Management System process.
A QMS process is an element of an organizational QMS. The ISO9001:2000 standard requires organizations seeking compliance or certification to define the processes which form the QMS and the sequence and interaction of these processes. Butterworth-Heinemann and other publishers have offered several books which provide step-by-step guides to whom seeking the quality certifications of their products , , , , .
Examples of such processes include:
ISO9001 requires that the performance of these processes be measured, analysed and continually improved, and the results of this form an input into the management review process.
References.
Business School Press
21. Lee, R., and Dale, B. (1998) Business process management: a review and evaluation, Business Process Re-engineering & Management Journal, 4 (3), 214–225

</doc>
<doc id="25346" url="http://en.wikipedia.org/wiki?curid=25346" title="Québécois (word)">
Québécois (word)

Québécois (pronounced ]; feminine: Québécoise (pronounced ]), Quebecois (fem.: Quebecoise), or Québecois (fem.: Québecoise) is a word used primarily to refer to a French-speaking native or inhabitant of the Canadian province of Quebec. It can refer to French spoken in Quebec. It may also be used, with an upper or lower case initial, as an adjective relating to Quebec, or to the French culture of Quebec. A resident or native of Quebec is usually referred to in English as a Quebecer or Quebecker. In French, Québécois or Québécoise usually refers to any native or resident of Quebec. Its use became more prominent in the 1960s as French Canadians from Quebec increasingly self-identified as Québécois.
Etymology.
The name "Quebec" comes from a Mi'kmaq word "k'webeq" meaning "where the waters get narrow" and originally referred to the area around Quebec City, where the Saint Lawrence River narrows to a cliff-lined gap. French explorer Samuel de Champlain chose this name in 1608 for the colonial outpost he would use as the administrative seat for the French colony of Canada and New France. The Province of Quebec was first founded as a British colony in the Royal Proclamation of 1763 after the Treaty of Paris formally transferred the French colony of New France to Britain after the Seven Years' War. Quebec City remained the capital. In 1774, Guy Carleton obtained from the British Government the Quebec Act, which gave Canadiens most of the territory they held before 1763; the right of religion; and their right of language and culture. The British Government did this to in order to keep their loyalty, in the face of a growing menace of independence from the 13 original British colonies.
Québécois identity.
The term became more common in English as "Québécois" largely replacing "French Canadian" as an expression of cultural and national identity among French Canadians living in Quebec during the Quiet Revolution of the 1960s. The predominant French Canadian nationalism and identity of previous generations was based on the protection of the French language, the Roman Catholic Church, and Church-run institutions across Canada and in parts of the United States. In contrast, the modern Québécois identity is secular and based on a social democratic ideal of an active Quebec government promoting the French language and French-speaking culture in the arts, education, and business within the Province of Quebec. Politically, this resulted in a push towards more autonomy for Quebec and an internal debate on Quebec independence and identity that continues to this day. The emphasis on the French language and Quebec autonomy means that French-speakers across Canada now self-identify more specifically with provincial or regional identity-tags, such as "acadienne", or "franco-canadienne", "franco-manitobaine", "franco-ontarienne" or "fransaskoise". As a result, francophone and anglophones now borrow the French terms when discussing issues of francophone linguistic and cultural identity in English, though outside of Quebec terms such as Franco-Ontarian, acadian and Franco-Manitoban are still predominant.
Québécois nation.
The political shift towards a new Quebec nationalism in the 1960s led to Québécois increasingly referring to provincial institutions as being "national". This was reflected in the change of the provincial "Legislative Assembly" to "National Assembly" in 1968. Nationalism reached an apex the 1970s and 1990s, with contentious constitutional debates resulting in close to half of all of French-speaking Québécois seeking recognition of nation status through tight referendums on Quebec sovereignty in 1980 and 1995. Having lost both referendums, the sovereigntist Parti Québécois government renewed the push for recognition as a nation through symbolic motions that gained the support of all parties in the National Assembly. They affirmed the right to determine the independent status of Quebec. They also renamed the area around Quebec City the "Capitale-Nationale" (national capital) region and renamed provincial parks "Parcs Nationaux" (national parks). In opposition in October 2003, the Parti Québécois tabled a motion that was unanimously adopted in the National Assembly affirming that the Quebec people formed a nation. Bloc Québécois leader Gilles Duceppe scheduled a similar motion in the House of Commons for November 23, 2006, that would have recognized "Quebecers as a nation". Conservative Prime Minister Stephen Harper tabled the "Québécois nation motion" the day before the Bloc Québécois resolution came to a vote. The English version changed the word "Quebecer" to "Québécois" and added "within a united Canada" at the end of the Bloc motion.
The "Québécois nation" was recognized by the Canadian House of Commons on November 27, 2006. The Prime Minister specified that the motion used the "cultural" and "sociological" as opposed to the "legal" sense of the word "nation". According to Harper, the motion was of a symbolic political nature, representing no constitutional change, no recognition of Quebec sovereignty, and no legal change in its political relations within the federation. The Prime Minister has further elaborated, stating that the motion's definition of Québécois relies on personal decisions to self-identify as Québécois, and therefore is a personal choice.
Despite near-universal support in the House of Commons, several important dissenters criticized the motion. Intergovernmental Affairs minister Michael Chong resigned from his position and abstained from voting, arguing that this motion was too ambiguous and had the potential of recognizing a destructive ethnic nationalism in Canada. Liberals were the most divided on the issue and represented 15 of the 16 votes against the motion. Liberal MP Ken Dryden summarized the view of many of these dissenters, maintaining that it was a game of semantics that cheapened issues of national identity. A survey by Leger Marketing in November 2006 showed that Canadians were deeply divided on this issue. When asked if Québécois are a nation, only 53 per cent of Canadians agreed, 47 per cent disagreed, with 33 per cent strongly disagreeing; 78 per cent of French-speaking Canadians agreed that Québécois are a nation, next to 38 per cent of English-speakers. As well, 78 per cent of 1,000 Québécois polled thought that Québécois should be recognized as a nation.
Québécois in census and ethnographic studies.
The Québécois self-identify as an ethnic group in both the English and French versions of the Canadian census and in demographic studies of ethnicity in Canada. In the 2001 Census of Canada, 98,670 Canadians, or just over 1% of the population of Quebec identified "Québécois" as their ethnicity, ranking "Québécois" as the 37th most common response. These results were based on a question on residents in each household in Canada: "To which ethnic or cultural group(s) did this person's ancestors belong?", along with a list of sample choices ("Québécois" did not appear among the various sample choices). The most common ethnicity,"Canadien" or Canadian, did appear as an example on the questionnaire, and was selected by 4.9 million people or 68.2% of the Quebec population.
In the more detailed "Ethnic Diversity Survey",
Québécois was the most common ethnic identity in Quebec, reported by 37% of
Quebec’s population aged 15 years and older, either as their only identity or alongside
other identities. The survey, based on interviews, asked the following questions: ""1) I would now like to ask you about your ethnic ancestry, heritage or background. What were the ethnic or cultural origins of your ancestors? 2) In addition to "Canadian", what were the other ethnic or cultural origins of your ancestors on first coming to North America?"" This survey did not list possible choices of ancestry and permitted multiple answers.
In census ethnic surveys, French-speaking Canadians identify their ethnicity most often as French, "Canadien", "Québécois", or French Canadian, with the latter three referred to by Jantzen (2005) as "French New World" ancestries because they originate in Canada. Jantzen (2005) distinguishes the English "Canadian", meaning "someone whose family has been in Canada for multiple generations", and the French "Canadien", used to refer to descendants of the original settlers of New France in the 17th and 18th centuries.
Those reporting "French New World" ancestries overwhelmingly had ancestors that went back at least 4 generations in Canada: specifically, 90% of "Québécois" traced their ancestry back this far. Fourth generation Canadiens and Québécois showed considerable attachment to their ethno-cultural group, with 70% and 61% respectively reporting a strong sense of belonging.
The generational profile and strength of identity of French New World ancestries contrast with those of British or Canadian ancestries, which represent the largest ethnic identities in Canada. Although deeply rooted Canadians express a deep attachment to their ethnic identity, most English-speaking Canadians of British ancestry generally cannot trace their ancestry as far back in Canada as French-speakers. As a result, their identification with their ethnicity is weaker tending to have a more broad based cultural identification: for example, only 50% of third generation "Canadians" strongly identify as such, bringing down the overall average. The survey report notes that 80% of Canadians whose families had been in Canada for three or more generations reported "Canadian and provincial or regional ethnic identities". These identities include "Québécois" (37% of Quebec population), "Acadian" (6% of Atlantic provinces) and "Newfoundlander" (38% of Newfoundland and Labrador).
English usage.
English expressions employing the term may imply specific reference to francophones; such as "Québécois literature"
French usage.
Most French usage employs references to people and things of Quebec origin.
Possible use as an ethnic designation in French.
Dictionaries.
The dictionary "Le Petit Robert", published in France, states that the adjective "québécois", in addition to its territorial meaning, may refer specifically to francophone or French Canadian culture in Quebec. The dictionary gives as examples "cinéma québécois" and "littérature québécoise".
However, an ethnic or linguistic sense is absent from "Le Petit Larousse", also published in France, as well as from French dictionaries published in Canada such as "Le Dictionnaire québécois d'aujourd'hui" and "Le Dictionnaire du français Plus", which indicate instead "Québécois francophone" "francophone Quebecer" in the linguistic sense. These dictionaries also include phrases like "cinéma québécois" "Quebec cinema", but do not classify them as relating to language or ethnicity.
The online dictionary "Grand dictionnaire terminologique" of the Office québécois de la langue française mentions only a territorial meaning for "Québécois".
Other opinion.
Newspaper editor Lysiane Gagnon has referred to an ethnic sense of the word "Québécois" in both English and French.
Special terms using 'Québécois'.
French expressions employing "Québécois" often appear in both French and English.
Further reading.
Teboul, Victor (2007), L'identité québécoise est-elle inclusive ? http://www.tolerance.ca/Article.aspx?ID=3621&L=fr
</dl>

</doc>
<doc id="25348" url="http://en.wikipedia.org/wiki?curid=25348" title="Quantico, Virginia">
Quantico, Virginia

Quantico (formerly Potomac) is a town in Prince William County, Virginia. As of the 2010 United States Census, Quantico had a population of 480.
Quantico is bordered by the U.S. military installation of Marine Corps Base Quantico on three sides and the Potomac River on the fourth. Quantico is located south of the mouth of Quantico Creek on the Potomac. The word Quantico is a derivation of the name a Doeg village recorded by English colonists as "Pamacocack".
Quantico is the site of one of the largest U.S. Marine Corps bases in the world, MCB Quantico. The base is the site of the Marine Corps Combat Development Command and HMX-1 (the presidential helicopter squadron), Officer Candidate School and The Basic School. The United States Drug Enforcement Administration's training academy, the FBI Academy, the FBI Laboratory, the Naval Criminal Investigative Service and the Air Force Office of Special Investigations headquarters are on the base. A replica of the USMC War Memorial stands in the entrance to the base (the original is at the north end of Arlington National Cemetery).
s of 2013[ [update]], the mayor is Kevin P. Brown.
Geography.
Quantico is at 38°31'19" North, 77°17'23" West (38.521871, −77.289757). According to the United States Census Bureau, the town has a total area of 0.1 sqmi, of which, 0.1 sqmi of it is land and none of the area is covered with water.
Climate.
Quantico has a humid subtropical climate (Köppen climate classification "Cfa").
Demographics.
As of the census of 2000, there are 561 people, 295 households, and 107 families living in the town. The population density is 7811.2 PD/sqmi. There are 359 housing units at an average density of 4998.6 /sqmi.
Racial composition.
The racial makeup is 51.32% White, 20.32% African American, 10.16% Asian, 5.53% Hispanic or Latino, 0.36% Native American, 2.32% from other races, and 5.53% from two or more races.
Households.
There are 295 households out of which 19.7% have children under the age of 18 living with them, 21.4% are married couples living together, 11.2% have a female householder with no husband present, and 63.4% are non-families. Of all households, 53.2% are made up of individuals and 9.2% have someone living alone who is 65 years of age or older. The average household size is 1.90 and the average family size is 3.02.
Ages.
The population is spread out, with 20.9% under the age of 18, 11.6% from 18 to 24, 39.8% from 25 to 44, 19.4% from 45 to 64, and 8.4% who are 65 years of age or older. The median age is 35 years. For every 100 females there are 122.6 males. For every 100 females age 18 and over, there are 130.1 males.
Income.
The median income for a male is $29,615 versus $23,125 for females. The per capita income for the town is $19,087. 21.4% of the population and 22.4% of families are below the poverty line. Out of the total population, 39.4% of those under the age of 18 and none of those 65 and older are living below the poverty line.
In popular culture.
The FBI Academy in Quantico was the setting of fifteen episodes of "The X-Files" and several scenes from Silence of the Lambs. "Criminal Minds" is based out of Quantico. The CBS drama "" is also set in Quantico.

</doc>
<doc id="25349" url="http://en.wikipedia.org/wiki?curid=25349" title="QSIG">
QSIG

QSIG is an ISDN based signaling protocol for signaling between private branch exchanges (PBXs) in a private integrated services network (PISN). It makes use of the connection-level Q.931 protocol and the application-level ROSE protocol. ISDN "proper" functions as the physical link layer.
QSIG was originally developed by Ecma International, adopted by ETSI and is defined by a set of ISO standard documents, so is not owned by any company. This allows interoperability between communications platforms provided by disparate vendors. 
QSIG has two layers, called BC (basic call) and GF (generic function). QSIG BC describes how to set up calls between PBXs. QSIG GF provides supplementary services for large-scale corporate, educational, and government networks, such as line identification, call intrusion and call forwarding. Thus for a large or very distributed company that requires multiple PBXs, users can receive the same services across the network and be unaware of the switch that their telephone is connected to. This greatly eases the problems of management of large networks.
QSIG will likely never rival each vendor's private network protocols, but it does provide an option for a higher level of integration than that of the traditional choices.
List of QSIG standards.
Note: This list is not complete. See the "source" after the list for more information.
Source : (search the list for PISN to find all QSIG related standards at ECMA)
QSIG basically uses ROSE to invoke specific supplementary service at the remote PINX. These ROSE operations are coded in a Q.931 FACILITY info element. Here a list of QSIG opcodes:
List of ISDN standards.
Source : (ETSI)
Source : (ITU)

</doc>
<doc id="25350" url="http://en.wikipedia.org/wiki?curid=25350" title="Quasicrystal">
Quasicrystal

A quasiperiodic crystal, or quasicrystal, is a structure that is ordered but not periodic. A quasicrystalline pattern can continuously fill all available space, but it lacks translational symmetry. While crystals, according to the classical crystallographic restriction theorem, can possess only two, three, four, and six-fold rotational symmetries, the Bragg diffraction pattern of quasicrystals shows sharp peaks with other symmetry orders, for instance five-fold.
Aperiodic tilings were discovered by mathematicians in the early 1960s, and, some twenty years later, they were found to apply to the study of quasicrystals. The discovery of these aperiodic forms in nature has produced a paradigm shift in the fields of crystallography. Quasicrystals had been investigated and observed earlier, but, until the 1980s, they were disregarded in favor of the prevailing views about the atomic structure of matter. In 2009, after a dedicated search, a mineralogical finding, icosahedrite, offered evidence for the existence of natural quasicrystals.
Roughly, an ordering is non-periodic if it lacks translational symmetry, which means that a shifted copy will never match exactly with its original. The more precise mathematical definition is that there is never translational symmetry in more than "n" – 1 linearly independent directions, where "n" is the dimension of the space filled, e.g., the three-dimensional tiling displayed in a quasicrystal may have translational symmetry in two dimensions. The ability to diffract comes from the existence of an indefinitely large number of elements with a regular spacing, a property loosely described as long-range order. Experimentally, the aperiodicity is revealed in the unusual symmetry of the diffraction pattern, that is, symmetry of orders other than two, three, four, or six. 
In 1982 materials scientist Dan Shechtman observed that certain aluminium-manganese alloys produced the unusual diffractograms which today are seen as revelatory of quasicrystal structures. Due to fear of the scientific community's reaction, it took him two years to publish the results for which he was awarded the Nobel Prize in Chemistry in 2011.
History.
In 1961, Hao Wang asked whether determining if a set of tiles admits a tiling of the plane is an algorithmically unsolvable problem or not. He conjectured that it is solvable, relying on the hypothesis that any set of tiles, which can tile the plane can do it "periodically" (hence, it would suffice to try to tile bigger and bigger patterns until obtaining one that tiles periodically). Nevertheless, two years later, his student, Robert Berger, constructed a set of some 20,000 square tiles (now called Wang tiles), which can tile the plane but not in a periodic fashion. As the number of known aperiodic sets of tiles grew, each set seemed to contain even fewer tiles than the previous one. In particular, in 1976, Roger Penrose proposed a set of just two tiles, up to rotation, (referred to as Penrose tiles) that produced only non-periodic tilings of the plane. These tilings displayed instances of fivefold symmetry. One year later, Alan Mackay showed experimentally that the diffraction pattern from the Penrose tiling had a two-dimensional Fourier transform consisting of sharp 'delta' peaks arranged in a fivefold symmetric pattern. Around the same time, Robert Ammann had created a set of aperiodic tiles that produced eightfold symmetry.
Mathematically, quasicrystals have been shown to be derivable from a general method, which treats them as projections of a higher-dimensional lattice. Just as circles, ellipses, and hyperbolic curves in the plane can be obtained as sections from a three-dimensional double cone, so too various (aperiodic or periodic) arrangements in two and three dimensions can be obtained from postulated hyperlattices with four or more dimensions. Icosahedral quasicrystals in three dimensions were projected from a six-dimensional hypercubic lattice by Peter Kramer and Roberto Neri in 1984. The tiling is formed by two tiles with rhombohedral shape.
Shechtman first observed ten-fold electron diffraction patterns in 1982, as described in his . The observation was made during a routine investigation, by electron microscopy, of a rapidly cooled alloy of aluminium and manganese prepared at the National Bureau of Standards (now NIST).
In the summer of the same year, Shechtman visited Ilan Blech and related his observation to him. Blech responded that such diffractions were seen before. Around that time, Shechtman also related his finding to John Cahn of NIST who did not offer any explanation and challenged him to solve the observation. Shechtman quoted Cahn as saying: "Danny, this material is telling us something and I challenge you to find out what it is".
The observation of the ten-fold diffraction pattern lay unexplained by Shechtman and others for two years until the spring of 1984, when Blech asked Shechtman to show him his results again. A quick study of Shechtman’s results showed that the common explanation for a ten-fold symmetrical diffraction pattern, namely the existence of twins, was ruled out by his experiments.
Since periodicity as well as twins were ruled out, Blech, unaware of the two-dimensional tiling work, was looking for another possibility: a completely new structure containing cells, which are connected to each other by defined angles and distances but without translational periodicity. Blech decided to use a computer simulation to calculate the diffraction intensity from a cluster of such a material without long-range translational order but still not random. He termed this new structure multiple polyhedral.
The idea of a new structure was the necessary paradigm shift to break the impasse. The “Eureka moment” came when the computer simulation showed sharp ten-fold diffraction patterns, similar to the observed ones, emanating from the three-dimensional structure devoid of periodicity. The multiple polyhedral structure was termed later by many researchers as icosahedral glass but in effect it embraces "any arrangement of polyhedra connected with definite angles and distances" (this general definition includes tiling, for example).
Shechtman accepted Blech’s discovery of a new type of material and it gave him the courage to publish his experimental observation. Shechtman and Blech jointly wrote a paper entitled “The Microstructure of Rapidly Solidified Al6Mn” and sent it for publication around June 1984 to the Journal of Applied Physics (JAP). The JAP editor promptly rejected the paper as being better fit for a metallurgical readership. As a result, the same paper was re-submitted for publication to the Metallurgical Transactions A, where it was accepted. Although not noted in the body of the published text, the published paper was slightly revised prior to publication.
Meanwhile, on seeing the draft of the Shechtman-Blech paper in the summer of 1984, John Cahn suggested that Shechtman’s experimental results merit a fast publication in a more appropriate scientific journal. Shechtman agreed and, in hindsight, called this fast publication - "a winning move”. This paper, published in the Physical Review Letters”, repeated Shechtman’s observation and used the same illustrations as the original Shechtman-Blech paper in the Metallurgical Transactions A. Naturally, being the first paper to appear in print, the Physical Review Letters paper caused considerable excitement in the scientific community.
Next year, Ishimasa "et al." reported twelvefold symmetry in Ni-Cr particles. Soon, eightfold diffraction patterns were recorded in V-Ni-Si and Cr-Ni-Si alloys. Over the years, hundreds of quasicrystals with various compositions and different symmetries have been discovered. The first quasicrystalline materials were thermodynamically unstable—when heated, they formed regular crystals. However, in 1987, the first of many stable quasicrystals were discovered, making it possible to produce large samples for study and opening the door to potential applications. In 2009, following a 10-year systematic search, scientists reported the first natural quasicrystal, a mineral found in the Khatyrka River in eastern Russia. This natural quasicrystal exhibits high crystalline quality, equalling the best artificial examples. The natural quasicrystal phase, with a composition of Al63Cu24Fe13, was named icosahedrite and it was approved by the International Mineralogical Association in 2010. Furthermore, analysis indicates it may be meteoritic in origin, possibly delivered from a carbonaceous chondrite asteroid.
In 1972, de Wolf and van Aalst reported that the diffraction pattern produced by a crystal of sodium carbonate cannot be labeled with three indices but needed one more, which implied that the underlying structure had four dimensions in reciprocal space. Other puzzling cases have been reported, but until the concept of quasicrystal came to be established, they were explained away or denied. However, at the end of the 1980s, the idea became acceptable, and in 1992 the International Union of Crystallography altered its definition of a crystal, broadening it as a result of Shechtman’s findings, reducing it to the ability to produce a clear-cut diffraction pattern and acknowledging the possibility of the ordering to be either periodic or aperiodic. Now, the symmetries compatible with translations are defined as "crystallographic", leaving room for other "non-crystallographic" symmetries. Therefore, aperiodic or quasiperiodic structures can be divided into two main classes: those with crystallographic point-group symmetry, to which the incommensurately modulated structures and composite structures belong, and those with non-crystallographic point-group symmetry, to which quasicrystal structures belong.
Originally, the new form of matter was dubbed "Shechtmanite". The term "quasicrystal" was first used in print by Steinhardt and Levine shortly after Shechtman's paper was published.
The adjective "quasicrystalline" has been already in use but now it came to be applied to any pattern with unusual symmetry. 'Quasiperiodical' structures were claimed to be observed in some decorative tilings devised by medieval Islamic architects. For example, Girih tiles in a medieval Islamic mosque in Isfahan, Iran, are arranged in a two-dimensional quasicrystalline pattern. These claims have, however, been under some debate.
Shechtman was awarded the Nobel Prize in Chemistry in 2011 for his work on quasicrystals. “His discovery of quasicrystals revealed a new principle for packing of atoms and molecules,” stated the Nobel Committee and pointed that “this led to a paradigm shift within chemistry.” 
Mathematics.
There are several ways to mathematically define quasicrystalline patterns. One definition, the "cut and project" construction, is based on the work of Harald Bohr. The concept of an almost periodic function (also called a quasiperiodic function) was studied by Bohr, including work of Bohl and Escanglon.
He introduced the notion of a superspace. Bohr showed that quasiperiodic functions arise as restrictions of high-dimensional periodic functions to an irrational slice (an intersection with one or more hyperplanes), and discussed their Fourier point spectrum. These functions are not exactly periodic, but they are arbitrarily close in some sense, as well as being a projection of an exactly periodic function.
In order that the quasicrystal itself be aperiodic, this slice must avoid any lattice plane of the higher-dimensional lattice. De Bruijn showed that Penrose tilings can be viewed as two-dimensional slices of five-dimensional hypercubic structures. Equivalently, the Fourier transform of such a quasicrystal is nonzero only at a dense set of points spanned by integer multiples of a finite set of basis vectors (the projections of the primitive reciprocal lattice vectors of the higher-dimensional lattice).
The intuitive considerations obtained from simple model aperiodic tilings are formally expressed in the concepts of Meyer and Delone sets. The mathematical counterpart of physical diffraction is the Fourier transform and the qualitative description of a diffraction picture as 'clear cut' or 'sharp' means that singularities are present in the Fourier spectrum. There are different methods to construct model quasicrystals. These are the same methods that produce aperiodic tilings with the additional constraint for the diffractive property. Thus, for a substitution tiling the eigenvalues of the substitution matrix should be Pisot numbers. The aperiodic structures obtained by the cut-and-project method are made diffractive by choosing a suitable orientation for the construction; this is a geometric approach that has also a great appeal for physicists.
Classical theory of crystals reduces crystals to point lattices where each point is the center of mass of one of the identical units of the crystal. The structure of crystals can be analyzed by defining an associated group. Quasicrystals, on the other hand, are composed of more than one type of unit, so, instead of lattices, quasilattices must be used. Instead of groups, groupoids, the mathematical generalization of groups in category theory, is the appropriate tool for studying quasicrystals.
Using mathematics for construction and analysis of quasicrystal structures is a difficult task for most experimentalists. Computer modeling, based on the existing theories of quasicrystals, however, greatly facilitated this task. Advanced programs have been developed allowing one to construct, visualize and analyze quasicrystal structures and their diffraction patterns.
Interacting spins were also analyzed in quasicrystals: AKLT Model and 8 vertex model were solved in quasicrystals analytically 
Materials science of quasicrystals.
Since the original discovery by Dan Shechtman, hundreds of quasicrystals have been reported and confirmed. Undoubtedly, the quasicrystals are no longer a unique form of solid; they exist
universally in many metallic alloys and some polymers. Quasicrystals are found most often in aluminium alloys (Al-Li-Cu, Al-Mn-Si, Al-Ni-Co, Al-Pd-Mn, Al-Cu-Fe, Al-Cu-V, etc.), but numerous other compositions are also known (Cd-Yb, Ti-Zr-Ni, Zn-Mg-Ho, Zn-Mg-Sc, In-Ag-Yb, Pd-U-Si, etc.).
There are two types of known quasicrystals. The first type, polygonal (dihedral) quasicrystals, have an axis of eight, ten, or 12-fold local symmetry (octagonal, decagonal, or dodecagonal quasicrystals, respectively). They are periodic along this axis and quasiperiodic in planes normal to it. The second type, icosahedral quasicrystals, are aperiodic in all directions.
Regarding thermal stability, three types of quasicrystals are distinguished:
Except for the Al–Li–Cu system, all the stable quasicrystals are almost free of defects and disorder, as evidenced by x-ray and electron diffraction revealing peak widths as sharp as those of perfect crystals such as Si. Diffraction patterns exhibit fivefold, threefold, and twofold symmetries, and reflections are arranged quasiperiodically in three dimensions.
The origin of the stabilization mechanism is different for the stable and metastable quasicrystals. Nevertheless, there is a common feature observed in most quasicrystal-forming liquid alloys or their undercooled liquids: a local icosahedral order. The icosahedral order is in equilibrium in the "liquid state" for the stable quasicrystals, whereas the icosahedral order prevails in the "undercooled liquid state" for the metastable quasicrystals.
A nanoscale icosahedral phase was formed in Zr-, Cu- and Hf-based bulk metallic glasses alloyed with noble metals.

</doc>
<doc id="25381" url="http://en.wikipedia.org/wiki?curid=25381" title="Recreation">
Recreation

Recreation is an activity of leisure, leisure being discretionary time. The "need to do something for recreation" is an essential element of human biology and psychology. Recreational activities are often done for enjoyment, amusement, or pleasure and are considered to be "fun".
Etymology.
The term "recreation" appears to have been used in English first in the late 14th century, first in the sense of "refreshment or curing of a sick person", and derived turn from Latin ("re": "again", "creare": "to create, bring forth, beget.)
Prerequisites to leisure.
Humans spend their time in activities of daily living, work, sleep, social duties, and leisure, the latter time being free from prior commitments to physiologic or social needs, a prerequisite of recreation. Leisure has increased with increased longevity and, for many, with decreased hours spent for physical and economic survival, yet others argue that time pressure has increased for modern people, as they are committed to too many tasks. Other factors that account for an increased role of recreation are affluence, population trends, and increased commercialization of recreational offerings. While one perception is that leisure is just "spare time", time not consumed by the necessities of living, another holds that leisure is a force that allows individuals to consider and reflect on the values and realities that are missed in the activities of daily life, thus being an essential element of personal development and civilization. This direction of thought has even been extended to the view that leisure is the purpose of work, and a reward in itself, and "leisure life" reflects the values and character of a nation. Leisure is considered a human right under the Universal Declaration of Human Rights.
Play, recreation and work.
Recreation is difficult to separate from the general concept of play, which is usually the term for children's recreational activity. Children may playfully imitate activities that reflect the realities of adult life. It has been proposed that play or recreational activities are outlets of or expression of excess energy, channeling it into socially acceptable activities that fulfill individual as well as societal needs, without need for compulsion, and providing satisfaction and pleasure for the participant. A traditional view holds that work is supported by recreation, recreation being useful to "recharge the battery" so that work performance is improved. Work, an activity generally performed out of economic necessity and useful for society and organized within the economic framework, however can also be pleasurable and may be self-imposed thus blurring the distinction to recreation. Many activities may be work for one person and recreation for another, or, at an individual level, over time recreational activity may become work, and vice versa. Thus, for a musician, playing an instrument may be at one time a profession, and at another a recreation. Similarly, it maybe difficult to separate education from recreation as in the case of recreational mathematics.
Recreational activities.
Recreation is an essential part of human life and finds many different forms which are shaped naturally by individual interests but also by the surrounding social construction. Recreational activities can be communal or solitary, active or passive, outdoors or indoors, healthy or harmful, and useful for society or detrimental. A list of typical activities could be almost endless including most human activities, a few examples being reading, playing or listening to music, watching movies or TV, gardening, hunting, hobbies, sports, studies, and travel. Not all recreational activities can be considered wise, healthy, or socially acceptable or useful—examples are gambling, drinking, or delinquent activities. Recreational drugs are being used to enhance the recreational experience, a wide-ranging and controversial subject as some drugs are accepted or tolerated by society within limits, others not and declared illegal.
Public space such as parks and beaches are essential venues for many recreational activities. Tourism has recognized that many visitors are specifically attracted by recreational offerings. In support of recreational activities government has taken an important role in their creation, maintenance, and organization, and whole industries have developed merchandise or services. Recreation-related business is an important factor in the economy; it has been estimated that the outdoor recreation sector alone contributes $730 billion annually to the U.S. economy and generates 6.5 million jobs.
Organized recreation.
Many recreational activities are organized, typically by public institutions, voluntary group-work agencies, private groups supported by membership fees, and commercial enterprises. Examples of each of these are the National Park Service, the YMCA, the Kiwanis, and Disney World.
Health and recreation.
Recreation has many health benefits, and, accordingly, Therapeutic Recreation has been developed to take advantage of this effect. The National Council for Therapeutic Recreation Certification (NCTRC) is the nationally recognized credentialing organization for the profession of Therapeutic Recreation. Professionals in the field of Therapeutic Recreation who are certified by the NCTRC are called "Certified Therapeutic Recreation Specialists". The job title "Recreation Therapist" is identified in the U.S. Dept of Labor's Occupation Outlook. Such therapy is applied in rehabilitation, psychiatric facilities for youth and adults, and in the care of the elderly, the disabled, or people with chronic diseases. Recreational physical activity is important to reduce obesity, and the risk of osteoporosis and of cancer, most significantly in men that of colon and prostate, and in women that of the breast; however, not all malignancies are reduced as outdoor recreation has been linked to a higher risk of melanoma. Extreme adventure recreation naturally carries its own hazards.
Recreation as a career.
A recreation specialist would be expected to meet the recreational needs of a community or assigned interest group. Educational institutions offer courses that lead to a degree as a Bachelor of Arts in recreation management. People with such degrees often work in parks and recreation centers in towns, on community projects and activities. Networking with instructors, budgeting, and evaluation of continuing programs are common job duties.
In the United States, most states have a professional organization for continuing education and certification in recreation management. The National Recreation and Park Association administers a certification program called the CPRP (Certified Park and Recreation Professional) that is considered a national standard for professional recreation specialist practices.

</doc>
<doc id="25382" url="http://en.wikipedia.org/wiki?curid=25382" title="Recession">
Recession

In economics, a recession is a business cycle contraction. It is a general slowdown in economic activity. Macroeconomic indicators such as GDP (gross domestic product), investment spending, capacity utilization, household income, business profits, and inflation fall, while bankruptcies and the unemployment rate rise.
Recessions generally occur when there is a widespread drop in spending (an adverse demand shock). This may be triggered by various events, such as a financial crisis, an external trade shock, an adverse supply shock or the bursting of an economic bubble. Governments usually respond to recessions by adopting expansionary macroeconomic policies, such as increasing money supply, increasing government spending and decreasing taxation.
Definition.
In a 1975 "New York Times" article, economic statistician Julius Shiskin suggested several rules of thumb for defining a recession, one of which was two down consecutive quarters of GDP. In time, the other rules of thumb were forgotten. Some economists prefer a definition of a 1.5-2 percentage points rise in unemployment within 12 months.
In the United States, the Business Cycle Dating Committee of the National Bureau of Economic Research (NBER) is generally seen as the authority for dating US recessions. The NBER defines an economic recession as: "a significant decline in economic activity spread across the economy, lasting more than a few months, normally visible in real GDP, real income, employment, industrial production, and wholesale-retail sales." Almost universally, academics, economists, policy makers, and businesses defer to the determination by the NBER for the precise dating of a recession's onset and end.
In the United Kingdom, recessions are generally defined as two consecutive quarters of negative economic growth, as measured by the seasonal adjusted quarter-on-quarter figures for real GDP. The exact same recession definition applies for all member states of the European Union.
Attributes.
A recession has many attributes that can occur simultaneously and includes declines in component measures of economic activity (GDP) such as consumption, investment, government spending, and net export activity. These summary measures reflect underlying drivers such as employment levels and skills, household savings rates, corporate investment decisions, interest rates, demographics, and government policies.
Economist Richard C. Koo wrote that under ideal conditions, a country's economy should have the household sector as net savers and the corporate sector as net borrowers, with the government budget nearly balanced and net exports near zero. When these relationships become imbalanced, recession can develop within the country or create pressure for recession in another country. Policy responses are often designed to drive the economy back towards this ideal state of balance.
A severe (GDP down by 10%) or prolonged (three or four years) recession is referred to as an economic depression, although some argue that their causes and cures can be different. As an informal shorthand, economists sometimes refer to different recession shapes, such as V-shaped, U-shaped, L-shaped and W-shaped recessions.
Type of recession or shape.
The type and shape of recessions are distinctive. In the US, V-shaped, or short-and-sharp contractions followed by rapid and sustained recovery, occurred in 1954 and 1990–91; U-shaped (prolonged slump) in 1974–75, and W-shaped, or double-dip recessions in 1949 and 1980–82. Japan’s 1993–94 recession was U-shaped and its 8-out-of-9 quarters of contraction in 1997–99 can be described as L-shaped. Korea, Hong Kong and South-east Asia experienced U-shaped recessions in 1997–98, although Thailand’s eight consecutive quarters of decline should be termed L-shaped.
Psychological aspects.
Recessions have psychological and confidence aspects. For example, if companies expect economic activity to slow, they may reduce employment levels and save money rather than invest. Such expectations can create a self-reinforcing downward cycle, bringing about or worsening a recession. Consumer confidence is one measure used to evaluate economic sentiment. The term animal spirits has been used to describe the psychological factors underlying economic activity. Economist Robert J. Shiller wrote that the term "...refers also to the sense of trust we have in each other, our sense of fairness in economic dealings, and our sense of the extent of corruption and bad faith. When animal spirits are on ebb, consumers do not want to spend and businesses do not want to make capital expenditures or hire people."
Balance sheet recession.
High levels of indebtedness or the bursting of a real estate or financial asset price bubble can cause what is called a "balance sheet recession." This is when large numbers of consumers or corporations pay down debt (i.e., save) rather than spend or invest, which slows the economy. The term balance sheet derives from an accounting identity that holds that assets must always equal the sum of liabilities plus equity. If asset prices fall below the value of the debt incurred to purchase them, then the equity must be negative, meaning the consumer or corporation is insolvent. Economist Paul Krugman wrote in 2014 that "the best working hypothesis seems to be that the financial crisis was only one manifestation of a broader problem of excessive debt--that it was a so-called "balance sheet recession." In Krugman's view, such crises require debt reduction strategies combined with higher government spending to offset declines from the private sector as it pays down its debt.
For example, economist Richard Koo wrote that Japan's "Great Recession" that began in 1990 was a "balance sheet recession." It was triggered by a collapse in land and stock prices, which caused Japanese firms to have negative equity, meaning their assets were worth less than their liabilities. Despite zero interest rates and expansion of the money supply to encourage borrowing, Japanese corporations in aggregate opted to pay down their debts from their own business earnings rather than borrow to invest as firms typically do. Corporate investment, a key demand component of GDP, fell enormously (22% of GDP) between 1990 and its peak decline in 2003. Japanese firms overall became net savers after 1998, as opposed to borrowers. Koo argues that it was massive fiscal stimulus (borrowing and spending by the government) that offset this decline and enabled Japan to maintain its level of GDP. In his view, this avoided a U.S. type Great Depression, in which U.S. GDP fell by 46%. He argued that monetary policy was ineffective because there was limited demand for funds while firms paid down their liabilities. In a balance sheet recession, GDP declines by the amount of debt repayment and un-borrowed individual savings, leaving government stimulus spending as the primary remedy.
Krugman discussed the balance sheet recession concept during 2010, agreeing with Koo's situation assessment and view that sustained deficit spending when faced with a balance sheet recession would be appropriate. However, Krugman argued that monetary policy could also affect savings behavior, as inflation or credible promises of future inflation (generating negative real interest rates) would encourage less savings. In other words, people would tend to spend more rather than save if they believe inflation is on the horizon. In more technical terms, Krugman argues that the private sector savings curve is elastic even during a balance sheet recession (responsive to changes in real interest rates) disagreeing with Koo's view that it is inelastic (non-responsive to changes in real interest rates).
A July 2012 survey of balance sheet recession research reported that consumer demand and employment are affected by household leverage levels. Both durable and non-durable goods consumption declined as households moved from low to high leverage with the decline in property values experienced during the subprime mortgage crisis. Further, reduced consumption due to higher household leverage can account for a significant decline in employment levels. Policies that help reduce mortgage debt or household leverage could therefore have stimulative effects.
Liquidity trap.
A liquidity trap is a Keynesian theory that a situation can develop in which interest rates reach near zero (zero interest-rate policy) yet do not effectively stimulate the economy. In theory, near-zero interest rates should encourage firms and consumers to borrow and spend. However, if too many individuals or corporations focus on saving or paying down debt rather than spending, lower interest rates have less effect on investment and consumption behavior; the lower interest rates are like "pushing on a string." Economist Paul Krugman described the U.S. 2009 recession and Japan's lost decade as liquidity traps. One remedy to a liquidity trap is expanding the money supply via quantitative easing or other techniques in which money is effectively printed to purchase assets, thereby creating inflationary expectations that cause savers to begin spending again. Government stimulus spending and mercantilist policies to stimulate exports and reduce imports are other techniques to stimulate demand. He estimated in March 2010 that developed countries representing 70% of the world's GDP were caught in a liquidity trap.
Paradoxes of thrift and deleveraging.
Behavior that may be optimal for an individual (e.g., saving more during adverse economic conditions) can be detrimental if too many individuals pursue the same behavior, as ultimately one person's consumption is another person's income. Too many consumers attempting to save (or pay down debt) simultaneously is called the paradox of thrift and can cause or deepen a recession. Economist Hyman Minsky also described a "paradox of deleveraging" as financial institutions that have too much leverage (debt relative to equity) cannot all de-leverage simultaneously without significant declines in the value of their assets.
During April 2009, U.S. Federal Reserve Vice Chair Janet Yellen discussed these paradoxes: "Once this massive credit crunch hit, it didn’t take long before we were in a recession. The recession, in turn, deepened the credit crunch as demand and employment fell, and credit losses of financial institutions surged. Indeed, we have been in the grips of precisely this adverse feedback loop for more than a year. A process of balance sheet deleveraging has spread to nearly every corner of the economy. Consumers are pulling back on purchases, especially on durable goods, to build their savings. Businesses are cancelling planned investments and laying off workers to preserve cash. And, financial institutions are shrinking assets to bolster capital and improve their chances of weathering the current storm. Once again, Minsky understood this dynamic. He spoke of the paradox of deleveraging, in which precautions that may be smart for individuals and firms—and indeed essential to return the economy to a normal state—nevertheless magnify the distress of the economy as a whole."
Predictors.
There are no known completely reliable predictors, but the following are considered possible predictors.
Government responses.
Most mainstream economists believe that recessions are caused by inadequate aggregate demand in the economy, and favor the use of expansionary macroeconomic policy during recessions. Strategies favored for moving an economy out of a recession vary depending on which economic school the policymakers follow. Monetarists would favor the use of expansionary monetary policy, while Keynesian economists may advocate increased government spending to spark economic growth. Supply-side economists may suggest tax cuts to promote business capital investment. When interest rates reach the boundary of an interest rate of zero percent (zero interest-rate policy) conventional monetary policy can no longer be used and government must use other measures to stimulate recovery. Keynesians argue that fiscal policy—tax cuts or increased government spending—works when monetary policy fails. Spending is more effective because of its larger multiplier but tax cuts take effect faster.
For example, Paul Krugman wrote in December 2010 that significant, sustained government spending was necessary because indebted households were paying down debts and unable to carry the U.S. economy as they had previously: "The root of our current troubles lies in the debt American families ran up during the Bush-era housing bubble...highly indebted Americans not only can’t spend the way they used to, they’re having to pay down the debts they ran up in the bubble years. This would be fine if someone else were taking up the slack. But what’s actually happening is that some people are spending much less while nobody is spending more — and this translates into a depressed economy and high unemployment. What the government should be doing in this situation is spending more while the private sector is spending less, supporting employment while those debts are paid down. And this government spending needs to be sustained..."
Stock market.
Some recessions have been anticipated by stock market declines. In "Stocks for the Long Run", Siegel mentions that since 1948, ten recessions were preceded by a stock market decline, by a lead time of 0 to 13 months (average 5.7 months), while ten stock market declines of greater than 10% in the Dow Jones Industrial Average were not followed by a recession.
The real-estate market also usually weakens before a recession. However real-estate declines can last much longer than recessions.
Since the business cycle is very hard to predict, Siegel argues that it is not possible to take advantage of economic cycles for timing investments. Even the National Bureau of Economic Research (NBER) takes a few months to determine if a peak or trough has occurred in the US.
During an economic decline, high yield stocks such as fast moving consumer goods, pharmaceuticals, and tobacco tend to hold up better. However when the economy starts to recover and the bottom of the market has passed (sometimes identified on charts as a MACD), growth stocks tend to recover faster. There is significant disagreement about how health care and utilities tend to recover. Diversifying one's portfolio into international stocks may provide some safety; however, economies that are closely correlated with that of the U.S. may also be affected by a recession in the U.S.
There is a view termed the "halfway rule" according to which investors start discounting an economic recovery about halfway through a recession. In the 16 U.S. recessions since 1919, the average length has been 13 months, although the recent recessions have been shorter. Thus if the 2008 recession followed the average, the downturn in the stock market would have bottomed around November 2008. The actual US stock market bottom of the 2008 recession was in March 2009.
Politics.
Generally an administration gets credit or blame for the state of economy during its time. This has caused disagreements about when a recession actually started. In an economic cycle, a downturn can be considered a consequence of an expansion reaching an unsustainable state, and is corrected by a brief decline. Thus it is not easy to isolate the causes of specific phases of the cycle.
The 1981 recession is thought to have been caused by the tight-money policy adopted by Paul Volcker, chairman of the Federal Reserve Board, before Ronald Reagan took office. Reagan supported that policy. Economist Walter Heller, chairman of the Council of Economic Advisers in the 1960s, said that "I call it a Reagan-Volcker-Carter recession. The resulting taming of inflation did, however, set the stage for a robust growth period during Reagan's administration.
Economists usually teach that to some degree recession is unavoidable, and its causes are not well understood. Consequently, modern government administrations attempt to take steps, also not agreed upon, to soften a recession.
Consequences.
Unemployment.
Unemployment is particularly high during a recession. Many economists working within the neoclassical paradigm argue that there is a natural rate of unemployment which, when subtracted from the actual rate of unemployment, can be used to calculate the negative GDP gap during a recession. In other words, unemployment never reaches 0 percent, and thus is not a negative indicator of the health of an economy unless above the "natural rate," in which case it corresponds directly to a loss in gross domestic product, or GDP.
The full impact of a recession on employment may not be felt for several quarters. Research in Britain shows that low-skilled, low-educated workers and the young are most vulnerable to unemployment in a downturn. After recessions in Britain in the 1980s and 1990s, it took five years for unemployment to fall back to its original levels. Many companies often expect employment discrimination claims to rise during a recession.
Business.
Productivity tends to fall in the early stages of a recession, then rises again as weaker firms close. The variation in profitability between firms rises sharply. Recessions have also provided opportunities for anti-competitive mergers, with a negative impact on the wider economy: the suspension of competition policy in the United States in the 1930s may have extended the Great Depression.
Social effects.
The living standards of people dependent on wages and salaries are more affected by recessions than those who rely on fixed incomes or welfare benefits. The loss of a job is known to have a negative impact on the stability of families, and individuals' health and well-being.
History.
Global.
According to the International Monetary Fund (IMF), "Global recessions seem to occur over a cycle lasting between eight and 10 years." The IMF takes many factors into account when defining a global recession. Until April 2009, IMF several times communicated to the press, that a global annual real GDP growth of 3.0 percent or less in their view was "...equivalent to a global recession."
By this measure, six periods since 1970 qualify: 1974–1975, 1980–1983, 1990–1993, 1998, 2001–2002, and 2008–2009. During what IMF in April 2002 termed the past three global recessions of the last three decades, global per capita output growth was zero or negative, and IMF argued—at that time—that because of the opposite being found for 2001, the economic state in this year by itself did not qualify as a "global recession".
In April 2009, IMF changed their Global recession definition to: 
By this new definition, a total of four global recessions took place since World War II: 1975, 1982, 1991 and 2009. All of them only lasted one year, although the third would have lasted three years (1991–93) if IMF as criteria had used the normal exchange rate weighted per‑capita real World GDP rather than the purchase power parity weighted per‑capita real World GDP.
United Kingdom.
The most recent recession to affect the United Kingdom was the late-2000s recession.
United States.
According to economists, since 1854, the U.S. has encountered 32 cycles of expansions and contractions, with an average of 17 months of contraction and 38 months of expansion. However, since 1980 there have been only eight periods of negative economic growth over one fiscal quarter or more, and four periods considered recessions:
For the past three recessions, the NBER decision has approximately conformed with the definition involving two consecutive quarters of decline. While the 2001 recession did not involve two consecutive quarters of decline, it was preceded by two quarters of alternating decline and weak growth.
Late 2000s.
Official economic data shows that a substantial number of nations were in recession as of early 2009. The US entered a recession at the end of 2007, and 2008 saw many other nations follow suit. The US recession of 2007 ended in June 2009 as the nation entered the current economic recovery.
United States.
The United States housing market correction (a possible consequence of United States housing bubble) and subprime mortgage crisis significantly contributed to a recession.
The 2007–2009 recession saw private consumption fall for the first time in nearly 20 years. This indicates the depth and severity of the current recession. With consumer confidence so low, recovery takes a long time. Consumers in the U.S. have been hard hit by the current recession, with the value of their houses dropping and their pension savings decimated on the stock market. Not only have consumers watched their wealth being eroded – they are now fearing for their jobs as unemployment rises.
U.S. employers shed 63,000 jobs in February 2008, the most in five years. Former Federal Reserve chairman Alan Greenspan said on 6 April 2008 that "There is more than a 50 percent chance the United States could go into recession." On 1 October, the Bureau of Economic Analysis reported that an additional 156,000 jobs had been lost in September. On 29 April 2008, Moody's declared that nine US states were in a recession. In November 2008, employers eliminated 533,000 jobs, the largest single month loss in 34 years. For 2008, an estimated 2.6 million U.S. jobs were eliminated.
The unemployment rate in the US grew to 8.5 percent in March 2009, and there were 5.1 million job losses until March 2009 since the recession began in December 2007. That was about five million more people unemployed compared to just a year prior, which was the largest annual jump in the number of unemployed persons since the 1940s.
Although the US Economy grew in the first quarter by 1%, by June 2008 some analysts stated that due to a protracted credit crisis and "...rampant inflation in commodities such as oil, food, and steel," the country was nonetheless in a recession. The third quarter of 2008 brought on a GDP retraction of 0.5% the biggest decline since 2001. The 6.4% decline in spending during Q3 on non-durable goods, like clothing and food, was the largest since 1950.
A 17 November 2008 report from the Federal Reserve Bank of Philadelphia based on the survey of 51 forecasters, suggested that the recession started in April 2008 and would last 14 months. They project real GDP declining at an annual rate of 2.9% in the fourth quarter and 1.1% in the first quarter of 2009. These forecasts represent significant downward revisions from the forecasts of three months ago.
A 1 December 2008, report from the National Bureau of Economic Research stated that the U.S. has been in a recession since December 2007 (when economic activity peaked), based on a number of measures including job losses, declines in personal income, and declines in real GDP. By July 2009 a growing number of economists believed that the recession may have ended. The National Bureau of Economic Research announced on 20 September 2010 that the 2008/2009 recession ended in June 2009, making it the longest recession since World War II.
Other countries.
Many other countries, particularly in Europe, have undergone decreasing rates of GDP growth. Some countries have been able to avoid a recession but have still experienced slower economic activity, such as China. India and Australia were able to maintain positive growth throughout the late-2000s recession.

</doc>
<doc id="25385" url="http://en.wikipedia.org/wiki?curid=25385" title="RSA (cryptosystem)">
RSA (cryptosystem)

RSA is one of the first practical public-key cryptosystems and is widely used for secure data transmission. In such a cryptosystem, the encryption key is public and differs from the decryption key which is kept secret. In RSA, this asymmetry is based on the practical difficulty of factoring the product of two large prime numbers, the factoring problem. RSA is made of the initial letters of the surnames of Ron Rivest, Adi Shamir and Leonard Adleman, who first publicly described the algorithm in 1977. Clifford Cocks, an English mathematician, had developed an equivalent system in 1973, but it was not declassified until 1997.
A user of RSA creates and then publishes a public key based on the two large prime numbers, along with an auxiliary value. The prime numbers must be kept secret. Anyone can use the public key to encrypt a message, but with currently published methods, if the public key is large enough, only someone with knowledge of the prime numbers can feasibly decode the message.
Breaking RSA encryption is known as the RSA problem; whether it is as hard as the factoring problem remains an open question.
History.
The RSA algorithm was publicly described in 1977 by Ron Rivest, Adi Shamir, and Leonard Adleman at MIT; the letters RSA are the initials of their surnames, listed in the same order as on the paper.
MIT was granted U.S. Patent for a "Cryptographic communications system and method" that used the algorithm, on September 20, 1983. Though the patent was going to expire on September 21, 2000 (the term of patent was 17 years at the time), the algorithm was released to the public domain by RSA Security on September 6, 2000, two weeks earlier. Since a paper describing the algorithm had been published in August 1977, prior to the December 1977 filing date of the patent application, regulations in much of the rest of the world precluded patents elsewhere and only the US patent was granted. Had Cocks' work been publicly known, a patent in the US would not have been possible either.
From the DWPI's abstract of the patent,
The system includes a communications channel coupled to at least one terminal having an encoding device and to at least one terminal having a decoding device. A message-to-be-transferred is enciphered to ciphertext at the encoding terminal by encoding the message as a number M in a predetermined set. That number is then raised to a first predetermined power (associated with the intended receiver) and finally computed. The remainder or residue, C, is... computed when the exponentiated number is divided by the product of two predetermined prime numbers (associated with the intended receiver).
Clifford Cocks, an English mathematician working for the UK intelligence agency GCHQ, described an equivalent system in an internal document in 1973, but given the relatively expensive computers needed to implement it at the time, it was mostly considered a curiosity and, as far as is publicly known, was never deployed. His discovery, however, was not revealed until 1998 due to its top-secret classification, and Rivest, Shamir, and Adleman devised RSA independently of Cocks' work.
Operation.
The RSA algorithm involves three steps: key generation, encryption and decryption.
Key generation.
RSA involves a "public key" and a "private key." The public key can be known by everyone and is used for encrypting messages. Messages encrypted with the public key can only be decrypted in a reasonable amount of time using the private key. The keys for the RSA algorithm are generated the following way:
The "public key" consists of the modulus "n" and the public (or encryption) exponent "e". The "private key" consists of the modulus "n" and the private (or decryption) exponent "d", which must be kept secret. "p", "q", and φ("n") must also be kept secret because they can be used to calculate "d".
Encryption.
Alice transmits her public key ("n", "e") to Bob and keeps the private key d secret. Bob then wishes to send message M to Alice.
He first turns M into an integer m, such that 0 ≤ "m" < "n" and gcd("m", "n") = 1 by using an agreed-upon reversible protocol known as a padding scheme. He then computes the ciphertext c corresponding to
This can be done efficiently, even for 500-bit numbers, using Modular exponentiation. Bob then transmits c to Alice.
Note that at least nine values of m will yield a ciphertext c equal to m,
Decryption.
Alice can recover m from c by using her private key exponent d via computing
Given m, she can recover the original message M by reversing the padding scheme.
A worked example.
Here is an example of RSA encryption and decryption. The parameters used here are artificially small, but one can also .
The public key is ("n" = 3233, "e" = 17). For a padded plaintext message "m", the encryption function is
The private key is ("d" = 2753). For an encrypted ciphertext "c", the decryption function is
For instance, in order to encrypt "m" = 65, we calculate
To decrypt "c" = 2790, we calculate
Both of these calculations can be computed efficiently using the square-and-multiply algorithm for modular exponentiation. In real-life situations the primes selected would be much larger; in our example it would be trivial to factor "n", 3233 (obtained from the freely available public key) back to the primes "p" and "q". Given "e", also from the public key, we could then compute "d" and so acquire the private key.
Practical implementations use the Chinese remainder theorem to speed up the calculation using modulus of factors (mod "pq" using mod "p" and mod "q").
The values "d""p", "d""q" and "q"inv, which are part of the private key are computed as follows:
Here is how "d""p", "d""q" and "q"inv are used for efficient decryption. (Encryption is efficient by choice of public exponent "e")
Signing messages.
Suppose Alice uses Bob's public key to send him an encrypted message. In the message, she can claim to be Alice but Bob has no way of verifying that the message was actually from Alice since anyone can use Bob's public key to send him encrypted messages. In order to verify the origin of a message, RSA can also be used to sign a message.
Suppose Alice wishes to send a signed message to Bob. She can use her own private key to do so. She produces a hash value of the message, raises it to the power of "d" (modulo "n") (as she does when decrypting a message), and attaches it as a "signature" to the message. When Bob receives the signed message, he uses the same hash algorithm in conjunction with Alice's public key. He raises the signature to the power of "e" (modulo "n") (as he does when encrypting a message), and compares the resulting hash value with the message's actual hash value. If the two agree, he knows that the author of the message was in possession of Alice's private key, and that the message has not been tampered with since.
Proofs of correctness.
Proof using Fermat's little theorem.
The proof of the correctness of RSA is based on Fermat's little theorem. This theorem states that if "p" is prime and "p" does not divide an integer "a" then
We want to show that "med" ≡ "m" (mod "pq") for every integer "m" when "p" and "q" are distinct prime numbers and "e" and "d" are positive integers satisfying
Since formula_19, we can write
for some nonnegative integer "h".
To check whether two numbers, like "med" and "m", are congruent mod "pq" it suffices (and in fact is equivalent) to check they are congruent mod "p" and mod "q" separately. (This is part of the Chinese remainder theorem, although it is not the significant part of that theorem.) To show "med" ≡ "m" (mod "p"), we consider two cases: "m" ≡ 0 (mod "p") and "m" formula_21 0 (mod "p").
In the first case "med" is a multiple of "p", so "med" ≡ 0 ≡ "m" (mod "p"). In the second case
where we used Fermat's little theorem to replace "m""p"−1 mod "p" with 1.
The verification that "med" ≡ "m" (mod "q") proceeds in a similar way, treating separately the cases "m" ≡ 0 (mod "q") and "m" formula_21 0 (mod "q"), using Fermat's little theorem for modulus "q" in the second case.
This completes the proof that, for any integer "m", and integers "e", "d" such that formula_24,
Proof using Euler's theorem.
Although the original paper of Rivest, Shamir, and Adleman used Fermat's little theorem to explain why RSA works, it is common to find proofs that rely instead on Euler's theorem.
We want to show that "med" ≡ "m" (mod "n"), where "n" = "pq" is a product of two different prime numbers and "e" and "d" are positive integers satisfying "ed" ≡ 1 (mod φ("n")). Since "e" and "d" are positive, we can write "ed" = 1 + "h"φ("n") for some non-negative integer "h". "Assuming" that "m" is relatively prime to "n", we have
where the second-last congruence follows from the Euler's theorem.
When "m" is not relatively prime to "n", the argument just given is invalid. This is highly improbable (only a proportion of 1/"p" + 1/"q" − 1/("pq") numbers have this property), but even in this case the desired congruence is still true. Either "m" ≡ 0 (mod "p") or "m" ≡ 0 (mod "q"), and these cases can be treated using the previous proof.
Padding.
Attacks against plain RSA.
There are a number of attacks against plain RSA as described below.
Padding schemes.
To avoid these problems, practical RSA implementations typically embed some form of structured, randomized padding into the value "m" before encrypting it. This padding ensures that "m" does not fall into the range of insecure plaintexts, and that a given message, once padded, will encrypt to one of a large number of different possible ciphertexts.
Standards such as PKCS#1 have been carefully designed to securely pad messages prior to RSA encryption. Because these schemes pad the plaintext "m" with some number of additional bits, the size of the un-padded message "M" must be somewhat smaller. RSA padding schemes must be carefully designed so as to prevent sophisticated attacks which may be facilitated by a predictable message structure. Early versions of the PKCS#1 standard (up to version 1.5) used a construction that appears to make RSA semantically secure. However, at Eurocrypt 2000, Coron et al. showed that for some types of messages, this padding does not provide a high enough level of security. Furthermore, at Crypto 1998, Bleichenbacher showed that this version is vulnerable to a practical adaptive chosen ciphertext attack. Later versions of the standard include Optimal Asymmetric Encryption Padding (OAEP), which prevents these attacks. As such, OAEP should be used in any new application, and PKCS#1 v1.5 padding should be replaced wherever possible. The PKCS#1 standard also incorporates processing schemes designed to provide additional security for RSA signatures (e.g., the Probabilistic Signature Scheme for RSA/RSA-PSS).
Secure padding schemes such as RSA-PSS are as essential for the security of message signing as they are for message encryption. Two US patents on PSS were granted (USPTO 6266771 and USPTO 70360140); however, these patents expired on 24 July 2009 and 25 April 2010, respectively. Use of PSS no longer seems to be encumbered by patents. Note that using different RSA key-pairs for encryption and signing is potentially more secure.
Security and practical considerations.
Using the Chinese remainder algorithm.
For efficiency many popular crypto libraries (like OpenSSL, Java and .NET) use the following optimization for decryption and signing based on the Chinese remainder theorem. The following values are precomputed and stored as part of the private key:
These values allow the recipient to compute the exponentiation "m" = "c""d" (mod "pq") more efficiently as follows:
This is more efficient than computing "m" ≡ "c""d" (mod "pq") even though two modular exponentiations have to be computed. The reason is that these two modular exponentiations both use a smaller exponent and a smaller modulus.
Integer factorization and RSA problem.
The security of the RSA cryptosystem is based on two mathematical problems: the problem of factoring large numbers and the RSA problem. Full decryption of an RSA ciphertext is thought to be infeasible on the assumption that both of these problems are hard, i.e., no efficient algorithm exists for solving them. Providing security against "partial" decryption may require the addition of a secure padding scheme.
The RSA problem is defined as the task of taking "e"th roots modulo a composite "n": recovering a value "m" such that "c" ≡ "m""e" (mod "n"), where ("n", "e") is an RSA public key and "c" is an RSA ciphertext. Currently the most promising approach to solving the RSA problem is to factor the modulus "n". With the ability to recover prime factors, an attacker can compute the secret exponent "d" from a public key ("n", "e"), then decrypt "c" using the standard procedure. To accomplish this, an attacker factors "n" into "p" and "q", and computes ("p" − 1)("q" − 1) which allows the determination of "d" from "e". No polynomial-time method for factoring large integers on a classical computer has yet been found, but it has not been proven that none exists. "See integer factorization for a discussion of this problem".
Multiple polynomial quadratic sieve (MPQS) can be used to factor the public modulus "n". The time taken to factor 128-bit and 256-bit "n" on a desktop computer (Processor: Intel Dual-Core i7-4500U 1.80GHz) are respectively 2 seconds and 35 minutes.
A tool called yafu can be used to optimize this process.The automation within YAFU is state-of-the-art, combining factorization algorithms in an intelligent and adaptive methodology that minimizes the time to find the factors of arbitrary input integers. Most algorithm implementations are multi-threaded, allowing YAFU to fully utilize multi- or many-core processors (including SNFS, GNFS, SIQS, and ECM). YAFU is primarily a command-line driven tool. The time taken to factor "n" using yafu on the same computer was reduced to 103.1746 seconds. Yafu requires the GGNFS binaries to factor N that are 320 bits or larger. This is a very complicated software that requires a certain amount of technical skill to install and configure. It took about 5720s to factor "320bit-N" on the same computer.
In 2009, Benjamin Moody has factored an RSA-512 bit key in 73 days using only public software (GGNFS) and his desktop computer (dual-core Athlon64 at 1,900 MHz). Just under 5 gigabytes of disk was required and about 2.5 gigabytes of RAM for the sieving process. The first RSA-512 factorization in 1999 required the equivalent of 8,400 MIPS years over an elapsed time of about 7 months.
Rivest, Shamir and Adleman note that Miller has shown that – assuming the Extended Riemann Hypothesis – finding "d" from "n" and "e" is as hard as factoring "n" into "p" and "q" (up to a polynomial time difference). However, Rivest, Shamir and Adleman note (in section IX / D of their paper) that they have not found a proof that inverting RSA is equally hard as factoring.
s of 2010[ [update]], the largest factored RSA number was 768 bits long (232 decimal digits, see RSA-768). Its factorization, by a state-of-the-art distributed implementation, took around fifteen hundred CPU years (two years of real time, on many hundreds of computers). This means that, at this date, no larger RSA key has been factored. In practice, RSA keys are typically 1024 to 2048 bits long. Some experts believe that 1024-bit keys may become breakable in the near future (though this is disputed); few see any way that 4096-bit keys could be broken in the foreseeable future. Therefore, it is generally presumed that RSA is secure if "n" is sufficiently large. If "n" is 300 bits or shorter, it can be factored in a few hours on a personal computer, using software already freely available. Keys of 512 bits have been shown to be practically breakable in 1999 when RSA-155 was factored by using several hundred computers and are now factored in a few weeks using common hardware. Exploits using 512-bit code-signing certificates that may have been factored were reported in 2011. A theoretical hardware device named TWIRL and described by Shamir and Tromer in 2003 called into question the security of 1024 bit keys. It is currently recommended that "n" be at least 2048 bits long.
In 1994, Peter Shor showed that a quantum computer (if one could ever be practically created for the purpose) would be able to factor in polynomial time, breaking RSA; see Shor's algorithm.
Faulty key generation.
Finding the large primes "p" and "q" is usually done by testing random numbers of the right size with probabilistic primality tests which quickly eliminate virtually all non-primes.
Numbers "p" and "q" should not be 'too close', lest the Fermat factorization for "n" be successful, if "p" − "q", for instance is less than 2"n"1/4 (which for even small 1024-bit values of "n" is ) solving for "p" and "q" is trivial. Furthermore, if either "p" − 1 or "q" − 1 has only small prime factors, "n" can be factored quickly by Pollard's "p" − 1 algorithm, and these values of "p" or "q" should therefore be discarded as well.
It is important that the private key "d" be large enough. Michael J. Wiener showed that if "p" is between "q" and 2"q" (which is quite typical) and "d" < "n"1/4/3, then "d" can be computed efficiently from "n" and "e".
There is no known attack against small public exponents such as "e" = 3, provided that proper padding is used. Coppersmith's Attack has many applications in attacking RSA specifically if the public exponent "e" is small and if the encrypted message is short and not padded. 65537 is a commonly used value for "e"; this value can be regarded as a compromise between avoiding potential small exponent attacks and still allowing efficient encryptions (or signature verification). The NIST Special Publication on Computer Security (SP 800-78 Rev 1 of August 2007) does not allow public exponents "e" smaller than 65537, but does not state a reason for this restriction.
Importance of strong random number generation.
A cryptographically strong random number generator, which has been properly seeded with adequate entropy, must be used to generate the primes "p" and "q". An analysis comparing millions of public keys gathered from the Internet was carried out in early 2012 by Arjen K. Lenstra, James P. Hughes, Maxime Augier, Joppe W. Bos, Thorsten Kleinjung and Christophe Wachter. They were able to factor 0.2% of the keys using only Euclid's algorithm.
They exploited a weakness unique to cryptosystems based on integer factorization. If "n" = "pq" is one public key and "n"′ = "p"′"q"′ is another, then if by chance "p" = "p"′ (but q is not equal to q'), then a simple computation of gcd("n","n"′) = "p" factors both "n" and "n"′, totally compromising both keys. Lenstra et al. note that this problem can be minimized by using a strong random seed of bit-length twice the intended security level, or by employing a deterministic function to choose "q" given "p", instead of choosing "p" and "q" independently.
Nadia Heninger was part of a group that did a similar experiment. They used an idea of Daniel J. Bernstein to compute the GCD of each RSA key "n" against the product of all the other keys "n"′ they had found (a 729 million digit number), instead of computing each gcd("n","n"′) separately, thereby achieving a very significant speedup since after one large division the GCD problem is of normal size.
Heninger says in her blog that the bad keys occurred almost entirely in embedded applications, including "firewalls, routers, VPN devices, remote server administration devices, printers, projectors, and VOIP phones" from over 30 manufacturers. Heninger explains that the one-shared-prime problem uncovered by the two groups results from situations where the pseudorandom number generator is poorly seeded initially and then reseeded between the generation of the first and second primes. Using seeds of sufficiently high entropy obtained from key stroke timings or electronic diode noise or atmospheric noise from a radio receiver tuned between stations should solve the problem.
Strong random number generation is important throughout every phase of public key cryptography. For instance, if a weak generator is used for the symmetric keys that are being distributed by RSA, then an eavesdropper could bypass the RSA and guess the symmetric keys directly.
Timing attacks.
Kocher described a new attack on RSA in 1995: if the attacker Eve knows Alice's hardware in sufficient detail and is able to measure the decryption times for several known ciphertexts, she can deduce the decryption key "d" quickly. This attack can also be applied against the RSA signature scheme. In 2003, Boneh and Brumley demonstrated a more practical attack capable of recovering RSA factorizations over a network connection (e.g., from a Secure Socket Layer (SSL)-enabled webserver) This attack takes advantage of information leaked by the Chinese remainder theorem optimization used by many RSA implementations.
One way to thwart these attacks is to ensure that the decryption operation takes a constant amount of time for every ciphertext. However, this approach can significantly reduce performance. Instead, most RSA implementations use an alternate technique known as cryptographic blinding. RSA blinding makes use of the multiplicative property of RSA. Instead of computing "c""d" (mod "n"), Alice first chooses a secret random value "r" and computes ("r""e""c")"d" (mod "n"). The result of this computation after applying Euler's Theorem is "rc""d" (mod "n") and so the effect of "r" can be removed by multiplying by its inverse. A new value of "r" is chosen for each ciphertext. With blinding applied, the decryption time is no longer correlated to the value of the input ciphertext and so the timing attack fails.
Adaptive chosen ciphertext attacks.
In 1998, Daniel Bleichenbacher described the first practical adaptive chosen ciphertext attack, against RSA-encrypted messages using the PKCS #1 v1 padding scheme (a padding scheme randomizes and adds structure to an RSA-encrypted message, so it is possible to determine whether a decrypted message is valid). Due to flaws with the PKCS #1 scheme, Bleichenbacher was able to mount a practical attack against RSA implementations of the Secure Socket Layer protocol, and to recover session keys. As a result of this work, cryptographers now recommend the use of provably secure padding schemes such as Optimal Asymmetric Encryption Padding, and RSA Laboratories has released new versions of PKCS #1 that are not vulnerable to these attacks.
Side-channel analysis attacks.
A side-channel attack using branch prediction analysis (BPA) has been described. Many processors use a branch predictor to determine whether a conditional branch in the instruction flow of a program is likely to be taken or not. Often these processors also implement simultaneous multithreading (SMT). Branch prediction analysis attacks use a spy process to discover (statistically) the private key when processed with these processors.
Simple Branch Prediction Analysis (SBPA) claims to improve BPA in a non-statistical way. In their paper, "On the Power of Simple Branch Prediction Analysis", the authors of SBPA (Onur Aciicmez and Cetin Kaya Koc) claim to have discovered 508 out of 512 bits of an RSA key in 10 iterations.
A power fault attack on RSA implementations has been described in 2010. The authors recovered the key by varying the CPU power voltage outside limits; this caused multiple power faults on the server.

</doc>
<doc id="25389" url="http://en.wikipedia.org/wiki?curid=25389" title="Robert A. Heinlein">
Robert A. Heinlein

Robert Anson Heinlein (; July 7, 1907 – May 8, 1988) was an American science fiction writer. Often called the "dean of science fiction writers", he was an influential and controversial author of the genre in his time. 
He was one of the first science fiction writers to break into mainstream magazines such as "The Saturday Evening Post" in the late 1940s. He was one of the best-selling science fiction novelists for many decades, and he, Isaac Asimov, and Arthur C. Clarke are often considered to be the "Big Three" of science fiction authors.
A notable writer of science fiction short stories, Heinlein was one of a group of writers who came to prominence under the editorship of John W. Campbell, Jr. in his "Astounding Science Fiction" magazine—though Heinlein denied that Campbell influenced his writing to any great degree.
Within the framework of his science fiction stories, Heinlein repeatedly addressed certain social themes: the importance of individual liberty and self-reliance, the obligation individuals owe to their societies, the influence of organized religion on culture and government, and the tendency of society to repress nonconformist thought. He also speculated on the influence of space travel on human cultural practices.
Heinlein was named the first Science Fiction Writers Grand Master in 1974. He won Hugo Awards for four of his novels; in addition, fifty years after publication, three of his works were awarded "Retro Hugos"—awards given retrospectively for works that were published before the Hugo Awards came into existence. In his fiction, Heinlein coined terms that have become part of the English language, including "grok" and "waldo", and speculative fiction, as well as popularizing the terms like "TANSTAAFL", "pay it forward", and space marine. He also described a modern version of a waterbed in his novel "The Door Into Summer", though he never patented or built one. In the first chapter of the novel "Space Cadet" he anticipated the cell phone, 35 years before the technology was invented by Motorola. Several of Heinlein's works have been adapted for film and television.
Life.
Birth and childhood.
Heinlein was born on July 7, 1907 to Rex Ivar Heinlein (an accountant) and Bam Lyle Heinlein, in Butler, Missouri. He was a 6th-generation German-American: a family tradition had it that Heinleins fought in every American war starting with the War of Independence.
His childhood was spent in Kansas City, Missouri. The outlook and values of this time and place (in his own words, "The Bible Belt") had a definite influence on his fiction, especially his later works, as he drew heavily upon his childhood in establishing the setting and cultural atmosphere in works like "Time Enough for Love" and "To Sail Beyond the Sunset". He often broke with many of the Bible Belt's values and mores—especially in regard to religion and sexual morality—both in his writing and in his personal life.
Navy.
Heinlein's experience in the U.S. Navy exerted a strong influence on his character and writing. Heinlein graduated from the U.S. Naval Academy in Annapolis, Maryland, in 1929 with a B.S. degree in naval engineering, and he served as an officer in the Navy. He was assigned to the new aircraft carrier USS "Lexington" in 1931, where he worked in radio communications, then in its earlier phases, with the carrier's aircraft. The captain of this carrier was Ernest J. King, who later served as the Chief of Naval Operations and Commander-in-Chief, U.S. Fleet during World War II. Heinlein was frequently interviewed during his later years by military historians who asked him about Captain King and his service as the commander of the U.S. Navy's first modern aircraft carrier.
Heinlein also served aboard the destroyer USS "Roper" in 1933 and 1934, reaching the rank of lieutenant. His brother, Lawrence Heinlein, served in the U.S. Army, the U.S. Air Force, and the Missouri National Guard, and he rose to the rank of major general in the National Guard.
In 1929, Heinlein married Elinor Curry of Kansas City in Los Angeles, but their marriage lasted for only about a year. His second marriage in 1932 to Leslyn MacDonald (1904–1981) lasted for 15 years. MacDonald was a political radical, and Isaac Asimov later recalled that Heinlein was, as was she, "a flaming liberal".
California.
In 1934, Heinlein was discharged from the Navy due to pulmonary tuberculosis. During a lengthy hospitalization, he developed a design for a waterbed.
After his discharge, Heinlein attended a few weeks of graduate classes in mathematics and physics at the University of California at Los Angeles (UCLA), but he soon quit either because of his health or from a desire to enter politics.
Heinlein supported himself at several occupations, including real estate sales and silver mining, but for some years found money in short supply. Heinlein was active in Upton Sinclair's socialist End Poverty in California movement in the early 1930s. When Sinclair gained the Democratic nomination for Governor of California in 1934, Heinlein worked actively in the campaign. Heinlein himself ran for the California State Assembly in 1938, but he was unsuccessful.
Author.
While not destitute after the campaign—he had a small disability pension from the Navy—Heinlein turned to writing in order to pay off his mortgage. His first published story, "Life-Line", was printed in the August 1939 issue of "Astounding Science-Fiction". Originally written for a contest, it was instead sold to "Astounding" for significantly more than the contest's first-prize payoff. Another Future History story, "Misfit", followed in November. Heinlein was quickly acknowledged as a leader of the new movement toward "social" science fiction. He was the guest of honor at Denvention, the 1941 Worldcon, held in Denver. During World War II, he did aeronautical engineering for the U.S. Navy, also recruiting Isaac Asimov and L. Sprague de Camp to work at the Philadelphia Naval Shipyard in Pennsylvania.
As the war wound down in 1945, Heinlein began re-evaluating his career. The atomic bombings of Hiroshima and Nagasaki, along with the outbreak of the Cold War, galvanized him to write nonfiction on political topics. In addition, he wanted to break into better-paying markets. He published four influential short stories for "The Saturday Evening Post" magazine, leading off, in February 1947, with "The Green Hills of Earth". That made him the first science fiction writer to break out of the "pulp ghetto". In 1950, the movie "Destination Moon"—the documentary-like film for which he had written the story and scenario, co-written the script, and invented many of the effects—won an Academy Award for special effects. Also, he embarked on a series of juvenile S.F. novels for the Charles Scribner's Sons publishing company that went from 1947 through 1959, at the rate of one book each autumn, in time for Christmas presents to teenagers. He also wrote for "Boys' Life" in 1952.
At the Philadelphia Naval Shipyard he had met and befriended a chemical engineer named Virginia "Ginny" Gerstenfeld. After the war, her engagement having fallen through, she moved to UCLA for doctoral studies in chemistry, and made contact again.
As his second wife's alcoholism gradually spun out of control, Heinlein moved out and the couple filed for divorce. Heinlein's friendship with Virginia turned into a relationship and on October 21, 1948 — shortly after the decree nisi came through — they married in the town of Raton, New Mexico shortly after having set up house in Colorado. They would remain married until Heinlein's death.
As Heinlein's increasing success as a writer resolved their initial financial woes, they had a house custom built with various innovative features, later described in an article in "Popular Mechanics". In 1965, after various chronic health problems of Virginia's were traced back to altitude sickness, they moved to Santa Cruz, California, at sea level, while they were building a new residence in the adjacent village of Bonny Doon, California. Their unique circular California house—which like their Colorado house, he designed along with Virginia and then built himself—is on Bonny Doon Road .
Ginny undoubtedly served as a model for many of his intelligent, fiercely independent female characters. She was a chemist, rocket test engineer, and held a higher rank in the Navy than Heinlein himself. She was also an accomplished college athlete, earning four letters. In 1953–1954, the Heinleins voyaged around the world (mostly via ocean liners and cargo liners, as Ginny detested flying), which Heinlein described in "Tramp Royale", and which also provided background material for science fiction novels set aboard spaceships on long voyages, such as "Podkayne of Mars" and "Friday". Ginny acted as the first reader of his manuscripts. Isaac Asimov believed that Heinlein made a swing to the right politically at the same time he married Ginny.
The Heinleins formed the small "Patrick Henry League" in 1958, and they worked in the 1964 Barry Goldwater Presidential campaign.
When Robert A. Heinlein opened his Colorado Springs newspaper on April 5, 1958, he read a full-page ad demanding that the Eisenhower Administration stop testing nuclear weapons. The science-fiction author was flabbergasted. He called for the formation of the Patrick Henry League and spent the next several weeks writing and publishing his own polemic that lambasted "Communist-line goals concealed in idealistic-sounding nonsense" and urged Americans not to become "soft-headed."
Heinlein had used topical materials throughout his juvenile series beginning in 1947, but in 1959, his novel "Starship Troopers" was considered by the editors and owners of Scribner's to be too controversial for one of its prestige lines, and it was rejected.
Heinlein found another publisher (Putnam), feeling himself released from the constraints of writing novels for children, and he began to write "my own stuff, my own way", and he wrote a series of challenging books that redrew the boundaries of science fiction, including his best-known work, "Stranger in a Strange Land" (1961), and "The Moon Is a Harsh Mistress" (1966).
Later life and death.
Beginning in 1970, Heinlein had a series of health crises, broken by strenuous periods of activity in his hobby of stonemasonry. (In a private correspondence, he referred to that as his "usual and favorite occupation between books.") The decade began with a life-threatening attack of peritonitis, recovery from which required more than two years. As soon as he was well enough to write again, he began work on "Time Enough for Love" (1973), which introduced many of the themes found in his later fiction.
In the mid-1970s, Heinlein wrote two articles for the "Britannica Compton Yearbook". He and Ginny crisscrossed the country helping to reorganize blood donation in the United States, and he was the guest of honor at the Worldcon for the third time at MidAmeriCon in Kansas City, Missouri, in 1976. While vacationing in Tahiti in early 1978, he suffered a transient ischemic attack. Over the next few months, he became more and more exhausted, and his health again began to decline. The problem was determined to be a blocked carotid artery, and he had one of the earliest known carotid bypass operations to correct it. Heinlein and Virginia had been smokers, and smoking appears often in his fiction, as do fictitious strikable self-lighting cigarettes.
In 1980 Robert Heinlein was a member of the Citizens Advisory Council on National Space Policy, chaired by Jerry Pournelle, which met at the home of SF writer Larry Niven to write space policy papers for the incoming Reagan Administration. Members included Buzz Aldrin, General Daniel Graham, rocket engineer Max Hunter, North American VP and Space Shuttle manager George Merrick, and other aerospace industry leaders. Policy recommendations from the Council included ballistic missile defense concepts which were later transformed into what was called the Strategic Defense Initiative by those who favored it, and "Star Wars" as a term of derision coined by Senator Ted Kennedy. Heinlein contributed to the Council contribution to the Reagan "Star Wars" speech of Spring 1983.
Asked to appear before a Joint Committee of the U.S. House and Senate that year, he testified on his belief that spin-offs from space technology were benefiting the infirm and the elderly. Heinlein's surgical treatment re-energized him, and he wrote five novels from 1980 until he died in his sleep from emphysema and heart failure on May 8, 1988.
At that time, he had been putting together the early notes for another "World as Myth" novel. Several of his other works have been published posthumously.
After his death, his wife Virginia Heinlein issued a compilation of Heinlein's correspondence and notes into a somewhat autobiographical examination of his career, published in 1989 under the title "Grumbles from the Grave". Heinlein's archive is housed by the Special Collections department of McHenry Library at the University of California at Santa Cruz. The collection includes manuscript drafts, correspondence, photographs and artifacts. A substantial portion of the archive has been digitized and it is available online through the Robert A. and Virginia Heinlein Archives.
Works.
Heinlein published 32 novels, 59 short stories, and 16 collections during his life. Four films, two television series, several episodes of a radio series, and a board game have been derived more or less directly from his work. He wrote a screenplay for one of the films. Heinlein edited an anthology of other writers' SF short stories.
Three nonfiction books and two poems have been published posthumously. "For Us, The Living: A Comedy of Customs" was published posthumously in 2003; "Variable Star", written by Spider Robinson based on a sketchy outline by Heinlein, was published in September 2006. Four collections have been published posthumously.
Series.
Over the course of his career Heinlein wrote three somewhat overlapping series.
Early work, 1939–1958.
Heinlein began his career as a writer of stories for Astounding Science Fiction, a highly respected science fiction magazine, which was edited by John Campbell. The science fiction writer Frederik Pohl has described Heinlein as "that greatest of Campbell-era sf writers". Isaac Asimov said that, from the time of his first story, it was accepted that Heinlein was the best science fiction writer in existence, adding that he would hold this title through his lifetime.
Alexei and Cory Panshin noted that Heinlein's impact was immediately felt. In 1940, the year after selling 'Life-Line' to Campbell, he wrote three short novels, four novelettes, and seven short stories. They went on to say that "No one ever dominated the science fiction field as Bob did in the first few years of his career." Alexei expresses awe in Heinlein's ability to show readers a world so drastically different from the one we live in now, yet have so many similarities. He says that "We find ourselves not only in a world other than our own, but identifying with a living, breathing individual who is operating within its context, and thinking and acting according to its terms."
The first novel that Heinlein wrote, "" (1939), did not see print during his lifetime, but Robert James tracked down the manuscript and it was published in 2003. Though some regard it as a failure as a novel, considering it little more than a disguised lecture on Heinlein's social theories, some readers took a very different view. In a review of it, John Clute wrote: "I'm not about to suggest that if Heinlein had been able to publish [such works] openly in the pages of Astounding in 1939, SF would have gotten the future right; I would suggest, however, that if Heinlein, and his colleagues, had been able to publish adult SF in Astounding and its fellow journals, then SF might not have done such a grotesquely poor job of prefiguring something of the flavor of actually living here at the onset of 2004."
"For Us, the Living" was intriguing as a window into the development of Heinlein's radical ideas about man as a social animal, including his interest in free love. The root of many themes found in his later stories can be found in this book. It also contained much material that could be considered background for his other novels, including a detailed description of the protagonist's treatment to avoid being banned to Coventry (a lawless land in the Heinlein mythos where unrepentant law-breakers are exiled).
It appears that Heinlein at least attempted to live in a manner consistent with these ideals, even in the 1930s, and had an open relationship in his marriage to his second wife, Leslyn. He was also a nudist; nudism and body taboos are frequently discussed in his work. At the height of the Cold War, he built a bomb shelter under his house, like the one featured in "Farnham's Freehold."
After "For Us, The Living", Heinlein began selling (to magazines) first short stories, then novels, set in a Future History, complete with a time line of significant political, cultural, and technological changes. A chart of the future history was published in the May 1941 issue of "Astounding". Over time, Heinlein wrote many novels and short stories that deviated freely from the Future History on some points, while maintaining consistency in some other areas. The Future History was eventually overtaken by actual events. These discrepancies were explained, after a fashion, in his later World as Myth stories.
Heinlein's first novel published as a book, "Rocket Ship Galileo", was initially rejected because going to the moon was considered too far out, but he soon found a publisher, Scribner's, that began publishing a Heinlein juvenile once a year for the Christmas season. Eight of these books were illustrated by Clifford Geary in a distinctive white-on-black scratchboard style. Some representative novels of this type are "Have Space Suit—Will Travel", "Farmer in the Sky", and "Starman Jones". Many of these were first published in serial form under other titles, e.g., "Farmer in the Sky" was published as "Satellite Scout" in the Boy Scout magazine "Boys' Life". There has been speculation that Heinlein's intense obsession with his privacy was due at least in part to the apparent contradiction between his unconventional private life and his career as an author of books for children, but "For Us, The Living" also explicitly discusses the political importance Heinlein attached to privacy as a matter of principle.
The novels that Heinlein wrote for a young audience are commonly called "the Heinlein juveniles", and they feature a mixture of adolescent and adult themes. Many of the issues that he takes on in these books have to do with the kinds of problems that adolescents experience. His protagonists are usually very intelligent teenagers who have to make their way in the adult society they see around them. On the surface, they are simple tales of adventure, achievement, and dealing with stupid teachers and jealous peers. Heinlein was a vocal proponent of the notion that juvenile readers were far more sophisticated and able to handle more complex or difficult themes than most people realized. His juvenile stories often had a maturity to them that made them readable for adults. "Red Planet", for example, portrays some very subversive themes, including a revolution in which young students are involved; his editor demanded substantial changes in this book's discussion of topics such as the use of weapons by children and the misidentified sex of the Martian character. Heinlein was always aware of the editorial limitations put in place by the editors of his novels and stories, and while he observed those restrictions on the surface, was often successful in introducing ideas not often seen in other authors' juvenile SF.
In 1957, James Blish wrote that one reason for Heinlein's success "has been the high grade of machinery which goes, today as always, into his story-telling. Heinlein seems to have known from the beginning, as if instinctively, technical lessons about fiction which other writers must learn the hard way (or often enough, never learn). He does not always operate the machinery to the best advantage, but he always seems to be aware of it."
1959–1960.
Heinlein decisively ended his juvenile novels with "Starship Troopers" (1959), a controversial work and his personal riposte to leftists calling for President Dwight D. Eisenhower to stop nuclear testing in 1958.
"The "Patrick Henry" ad shocked 'em," he wrote many years later. ""Starship Troopers" outraged 'em."
"Starship Troopers" is a coming-of-age story about duty, citizenship, and the role of the military in society. The book portrays a society in which suffrage is earned by demonstrated willingness to place society's interests before one's own, at least for a short time and often under onerous circumstances, in government service; in the case of the protagonist, this was military service.
Later, in "Expanded Universe", Heinlein said that it was his intention in the novel that service could include positions outside strictly military functions such as teachers, police officers, and other government positions. This is presented in the novel as an outgrowth of the failure of unearned suffrage government and as a very successful arrangement. In addition, the franchise was only awarded "after" leaving the assigned service, thus those serving their terms—in the military, or any other service—were excluded from exercising any franchise. Career military were completely disenfranchised until retirement.
The name "Starship Troopers" was licensed for an unrelated, B movie script called Bug Hunt at Outpost Nine, which was then retitled to benefit from the book's credibility. The resulting 1997 film, written by Ed Neumeier and directed by Paul Verhoeven, had little relationship to the book, beyond the inclusion of names and other superficial traits. Fans of Heinlein were critical of the movie, which they considered a betrayal of Heinlein's philosophy, presenting the society in which the story takes place as fascist. Christopher Weuve, an admirer of Heinlein, has said that the society depicted in the film showed only a superficial resemblance to the society that Heinlein describes in his book. Weuve summed up his critique of the film as follows. First, "while the Terran Federation in "Starship Troopers" is specifically stated to be a representative democracy, Ed Neumeier decided to make the government into a fascist state ... Second, the book was multiracial, but not so the movie: all the non-Anglo characters from the book have been replaced by characters who look like they stepped out of the Aryan edition of "GQ"... Third, there is real element of sadism present in the movie which simply isn't present in the book."
Likewise, the powered armor technology that is not only central to the book, but became a standard subgenre of science fiction thereafter, is completely absent in the movie, where the characters use World War II-technology weapons and wear light combat gear little more advanced than that. According to Verhoeven, this, and the fascist tone of the book, reflected his own experience in the Nazi-occupied Netherlands during WWII.
In fact, Verhoeven had not even read the book, attempting to after he bought the rights to add to his existing movie, and disliking it: "I stopped after two chapters because it was so boring...It is really quite a bad book. I asked Ed Neumeier to tell me the story because I just couldn't read the thing".
Middle period work, 1961–1973.
From about 1961 ("Stranger in a Strange Land") to 1973 ("Time Enough for Love"), Heinlein explored some of his most important themes, such as individualism, libertarianism, and free expression of physical and emotional love. Three novels from this period, "Stranger in a Strange Land", "The Moon Is a Harsh Mistress", and "Time Enough for Love", won the Libertarian Futurist Society's Prometheus Hall of Fame Award, designed to honor classic libertarian fiction. Jeff Riggenbach described "The Moon is a Harsh Mistress" as "unquestionably one of the three or four most influential libertarian novels of the last century".
Heinlein did not publish "Stranger in a Strange Land" until some time after it was written, and the themes of free love and radical individualism are prominently featured in his long-unpublished first novel, "For Us, The Living: A Comedy of Customs".
"The Moon Is a Harsh Mistress" tells of a war of independence waged by the Lunar penal colonies, with significant comments from a major character, Professor La Paz, regarding the threat posed by government to individual freedom.
Although Heinlein had previously written a few short stories in the fantasy genre, during this period he wrote his first fantasy novel, "Glory Road", and in "Stranger in a Strange Land" and "I Will Fear No Evil", he began to mix hard science with fantasy, mysticism, and satire of organized religion. Critics William H. Patterson, Jr., and Andrew Thornton believe that this is simply an expression of Heinlein's longstanding philosophical opposition to positivism. Heinlein stated that he was influenced by James Branch Cabell in taking this new literary direction. The penultimate novel of this period, "I Will Fear No Evil", is according to critic James Gifford "almost universally regarded as a literary failure" and he attributes its shortcomings to Heinlein's near-death from peritonitis.
Later work, 1980–1987.
After a seven-year hiatus brought on by poor health, Heinlein produced five new novels in the period from 1980 ("The Number of the Beast") to 1987 ("To Sail Beyond the Sunset"). These books have a thread of common characters and time and place. They most explicitly communicated Heinlein's philosophies and beliefs, and many long, didactic passages of dialog and exposition deal with government, sex, and religion. These novels are controversial among his readers and one critic, Dave Langford, has written about them very negatively. Heinlein's four Hugo awards were all for books written before this period.
Some of these books, such as "The Number of the Beast" and "The Cat Who Walks Through Walls", start out as tightly constructed adventure stories, but transform into philosophical fantasias at the end. It is a matter of opinion whether this demonstrates a lack of attention to craftsmanship or a conscious effort to expand the boundaries of science fiction, either into a kind of magical realism, continuing the process of literary exploration that he had begun with "Stranger in a Strange Land", or into a kind of literary metaphor of quantum science ("The Number of the Beast" dealing with the Observer problem, and "The Cat Who Walks Through Walls" being a direct reference to the Schrödinger's cat thought experiment).
Most of the novels from this period are recognized by critics as forming an offshoot from the Future History series, and referred to by the term World as Myth.
The tendency toward authorial self-reference begun in "Stranger in a Strange Land" and "Time Enough for Love" becomes even more evident in novels such as "The Cat Who Walks Through Walls", whose first-person protagonist is a disabled military veteran who becomes a writer, and finds love with a female character.
The 1982 novel "Friday", a more conventional adventure story (borrowing a character and backstory from the earlier short story "Gulf", also containing suggestions of connection to "The Puppet Masters") continued a Heinlein theme of expecting what he saw as the continued disintegration of Earth's society, to the point where the title character is strongly encouraged to seek a new life off-planet. It concludes with a traditional Heinlein note, as in "The Moon is a Harsh Mistress" or "Time Enough for Love", that freedom is to be found on the frontiers.
The 1984 novel " is a sharp satire of organized religion. Heinlein himself was agnostic.
Posthumous publications.
Several Heinlein works have been published since his death, including the aforementioned " as well as 1989's "Grumbles from the Grave", a collection of letters between Heinlein and his editors and agent; 1992's "Tramp Royale", a travelogue of a southern hemisphere tour the Heinleins took in the 1950s; "Take Back Your Government", a how-to book about participatory democracy written in 1946; and a tribute volume called "Requiem: Collected Works and Tributes to the Grand Master", containing some additional short works previously unpublished in book form. "Off the Main Sequence", published in 2005, includes three short stories never before collected in any Heinlein book (Heinlein called them "stinkeroos").
Spider Robinson, a colleague, friend, and admirer of Heinlein, wrote "Variable Star", based on an outline and notes for a juvenile novel that Heinlein prepared in 1955. The novel was published as a collaboration, with Heinlein's name above Robinson's on the cover, in 2006.
A complete collection of Heinlein's published work, conformed and copy-edited by several Heinlein scholars including biographer William H. Patterson has been published by the Heinlein Trust as the "Virginia Edition", after his wife.
Views.
Heinlein's books probe a range of ideas about a range of topics such as sex, race, politics, and the military. Many were seen as radical or as ahead of their time in their social criticism. His books have inspired considerable debate about the specifics, and the evolution, of Heinlein's own opinions, and have earned him both lavish praise and a degree of criticism. He has also been accused of contradicting himself on various philosophical questions.
As Ted Gioia notes:
[Heinlein] has been accused of many things—of being a libertine or a libertarian, a fascist or a fetishist, pre-Oedipal or just plain preposterous. Heinlein's critics cut across all ends of the political spectrum, as do his fans. His admirers have ranged from Madalyn Murray O'Hair, the founder of American Atheists, to members of the Church of All Worlds, who hail Heinlein as a prophet. Apparently both true believers and non-believers, and perhaps some agnostics, have found sustenance in Heinlein's prodigious output.
Brian Doherty cites William Patterson, saying that the best way to gain an understanding of Heinlein is as a "full-service iconoclast, the unique individual who decides that things do not have to be, and won't continue, as they are." He says this vision is "at the heart of Heinlein, science fiction, libertarianism, and America. Heinlein imagined how everything about the human world, from our sexual mores to our religion to our automobiles to our government to our plans for cultural survival, might be flawed, even fatally so."
The critic Elizabeth Anne Hull, for her part, has praised Heinlein for his interest in exploring fundamental life questions, especially questions about "political power—our responsibilities to one another" and about "personal freedom, particularly sexual freedom."
Politics.
Heinlein's political positions evolved throughout his life, though he was always strongly patriotic and firmly supported the United States military. Heinlein's early political leanings were liberal. In 1934 he worked actively for the Democratic campaign of Upton Sinclair for Governor of California. After Sinclair's loss, Heinlein became an anti-Communist Democratic activist. He made an unsuccessful bid for a California State Assembly seat in 1938. Heinlein's first novel, "For Us, The Living" (written 1939), consists largely of speeches advocating the Social Credit system, and the early story "Misfit" (1939) deals with an organization that seems to be Franklin D. Roosevelt's Civilian Conservation Corps translated into outer space.
Heinlein's juvenile fiction of the 1940s and 1950s, however, began to espouse conservative views. After 1945, he came to believe that a strong world government was the only way to avoid mutual nuclear annihilation. His 1949 novel "Space Cadet" describes a future scenario where a military-controlled global government enforces world peace. Heinlein ceased considering himself a Democrat in 1954.
Heinlein considered himself a libertarian, but in a letter to Judith Merril in 1967 (never sent) he also described himself as a philosophical anarchist or an "autarchist" 
"Stranger in a Strange Land" was embraced by the hippie counterculture, and libertarians have found inspiration in "The Moon Is a Harsh Mistress". Both groups found resonance with his themes of personal freedom in both thought and action.
Race.
Heinlein grew up in the era of racial segregation in the United States and wrote some of his most influential fiction at the height of the US civil rights movement. His early juveniles were very much ahead of their time both in their explicit rejection of racism and in their inclusion of non-white protagonists—in the context of science fiction before the 1960s, the mere existence of non-white characters was a remarkable novelty, with green occurring more often than brown. For example, his second juvenile, the 1948 "Space Cadet", explicitly uses aliens as a metaphor for minorities. In his juvenile, "Star Beast", the "de facto" foreign minister of the Terran government is an undersecretary, a Mr. Kiku, who is from Africa. Heinlein explicitly states his skin is "ebony black", and that Kiku is in an arranged marriage that is happy.
In a number of his stories, Heinlein challenges his readers' possible racial preconceptions by introducing a strong, sympathetic character, only to reveal much later that he or she is of African or other ancestry; in several cases, the covers of the books show characters as being light-skinned, when in fact the text states, or at least implies, that they are dark-skinned or of African ancestry. Heinlein repeatedly denounced racism in his non-fiction works, including numerous examples in "Expanded Universe".
Heinlein reveals near the end of "Starship Troopers" that the novel's protagonist and narrator, Johnny Rico, the formerly disaffected scion of a wealthy family, is Filipino, actually named "Juan Rico" and speaks Tagalog in addition to English.
Race was a central theme in some of Heinlein's fiction. The most prominent and controversial example is "Farnham's Freehold", which casts a white family into a future in which white people are the slaves of cannibalistic black rulers. In the 1941 novel "Sixth Column" (also known as "The Day After Tomorrow"), a white resistance movement in the United States defends itself against an invasion by an Asian fascist state (the "Pan-Asians") using a "super-science" technology that allows ray weapons to be tuned to specific races. The book is sprinkled with racist slurs against Asian people, and blacks and Hispanics are not mentioned at all. The idea for the story was pushed on Heinlein by editor John W. Campbell, and Heinlein wrote later that he had "had to re-slant it to remove racist aspects of the original story line" and that he did not "consider it to be an artistic success." (However, the novel prompted a heated debate in the scientific community regarding the plausibility of developing ethnic bioweapons.)
Some of the alien species in Heinlein's fiction can be interpreted in terms of an allegorical representation of human ethnic groups. It has been suggested that the strongly hierarchical and anti-individualistic "Bugs" in "Starship Troopers" were meant to represent the Chinese or Japanese, but Heinlein claimed to have written the book in response to "calls for the unilateral ending of nuclear testing by the United States." Heinlein suggests in the book that the Bugs are a good example of Communism being something that humans cannot successfully adhere to, since humans are strongly defined individuals, whereas the Bugs, being a collective, can all contribute to the whole without consideration of individual desire.
Heinlein's biographer William Patterson relates a number of instances in which Heinlein responded to anti-semitic remarks by (falsely) claiming to be half-Jewish himself and breaking off all further contact with the anti-semite. (Heinlein's actual ancestry is German-American on his father's side and Scots-Irish American on his mother's side, both going back to the Colonial era in the USA.)
Individualism and self-determination.
In keeping with his belief in individualism, his work for adults—and sometimes even his work for juveniles—often portrays both the oppressors and the oppressed with considerable ambiguity. Heinlein believed that individualism was incompatible with ignorance. He believed that an appropriate level of adult competence was achieved through a wide-ranging education, whether this occurred in a classroom or not. In his juvenile novels, more than once a character looks with disdain at a student's choice of classwork, saying, "Why didn't you study something useful?" In "Time Enough for Love", Lazarus Long gives a long list of capabilities that anyone should have, concluding, "Specialization is for insects." The ability of the individual to create himself is explored in stories such as "I Will Fear No Evil", "—All You Zombies—", and "By His Bootstraps".
Sexual issues.
For Heinlein, personal liberation included sexual liberation, and free love was a major subject of his writing starting in 1939, with "For Us, The Living". During his early period, Heinlein's writing for younger readers needed to take account of both editorial perceptions of sexuality in his novels, and potential perceptions among the buying public; as critic William H. Patterson has put it, his dilemma was "to sort out what was really objectionable from what was only excessive over-sensitivity to imaginary librarians".
By his middle period, sexual freedom and the elimination of sexual jealousy were a major theme of "Stranger in a Strange Land" (1961), in which the progressively minded but sexually conservative reporter, Ben Caxton, acts as a dramatic foil for the less parochial characters, Jubal Harshaw and Valentine Michael Smith (Mike). Another of the main characters, Jill, is homophobic.
Gary Westfahl points out that "Heinlein is a problematic case for feminists; on the one hand, his works often feature strong female characters and vigorous statements that women are equal to or even superior to men; but these characters and statements often reflect hopelessly stereotypical attitudes about typical female attributes. It is disconcerting, for example, that in "Expanded Universe" Heinlein calls for a society where all lawyers and politicians are women, essentially on the grounds that they possess a mysterious feminine practicality that men cannot duplicate." Also, in Heinlein's "Stranger in a Strange Land", Jill, one of the main characters, says, "nine times out of ten, if a girl gets raped it's partly her fault".
In books written as early as 1956, Heinlein dealt with incest and the sexual nature of children. Many of his books (including "Time for the Stars", "Glory Road", "Time Enough for Love", and "The Number of the Beast") dealt explicitly or implicitly with incest, sexual feelings and relations between adults and children, or both. The treatment of these themes include the romantic relationship and eventual marriage (once the girl becomes an adult via time-travel) of a 30-year-old engineer and an 11-year-old girl in "The Door into Summer" or the more overt intra-familial incest in "To Sail Beyond the Sunset" and "Farnham's Freehold". Peers such as L. Sprague de Camp and Damon Knight have commented critically on Heinlein's portrayal of incest and pedophilia in a lighthearted and even approving manner.
Philosophy.
In "To Sail Beyond the Sunset", Heinlein has the main character, Maureen, state that the purpose of metaphysics is to ask questions: Why are we here? Where are we going after we die? (and so on), and that "you are not allowed to answer the questions". "Asking" the questions is the point of metaphysics, but "answering" them is not, because once you answer this kind of question, you cross the line into religion. Maureen does not state a reason for this; she simply remarks that such questions are "beautiful" but lack answers. Maureen's son/lover Lazarus Long makes a related remark in "Time Enough for Love". In order for us to answer the "big questions" about the universe, Lazarus states at one point, it would be necessary to stand "outside" the universe.
During the 1930s and 1940s, Heinlein was deeply interested in Alfred Korzybski's General Semantics and attended a number of seminars on the subject. His views on epistemology seem to have flowed from that interest, and his fictional characters continue to express Korzybskian views to the very end of his writing career. Many of his stories, such as "Gulf", "If This Goes On—", and "Stranger in a Strange Land", depend strongly on the premise, related to the well-known Sapir–Whorf hypothesis, that by using a correctly designed language, one can change or improve oneself mentally, or even realize untapped potential (as in the case of Joe Green in "Gulf").
When Ayn Rand's novel "The Fountainhead" was published, Heinlein was very favorably impressed, as quoted in "Grumbles..." and mentioned John Galt—the hero in Rand's "Atlas Shrugged"—as a heroic archetype in "The Moon Is a Harsh Mistress". He was also strongly affected by the religious philosopher P. D. Ouspensky. Freudianism and psychoanalysis were at the height of their influence during the peak of Heinlein's career, and stories such as "Time for the Stars" indulged in psychological theorizing.
However, he was skeptical about Freudianism, especially after a struggle with an editor who insisted on reading Freudian sexual symbolism into his juvenile novels. Heinlein was fascinated by the social credit movement in the 1930s. This is shown in "Beyond This Horizon" and in his 1938 novel "", which was finally published in 2003, long after his death. He was strongly committed to cultural relativism, and the sociologist Margaret Mader in his novel "Citizen of the Galaxy" is clearly a reference to Margaret Mead.
Pay it Forward.
The term "pay it forward", though it was already in occasional use as a quotation, was popularized by Robert A. Heinlein in his book "Between Planets", published in 1951:
 The banker reached into the folds of his gown, pulled out a single credit note. "But eat first—a full belly steadies the judgment. Do me the honor of accepting this as our welcome to the newcomer."
His pride said no; his stomach said YES! Don took it and said, "Uh, thanks! That's awfully kind of you. I'll pay it back, first chance."
"Instead, pay it forward to some other brother who needs it."
Heinlein was a mentor to Ray Bradbury, giving him help and quite possibly passing on the concept, made famous by the publication of a letter from him to Heinlein thanking him. In Bradbury's novel "Dandelion Wine", published in 1957, when the main character Douglas Spaulding is reflecting on his life being saved by Mr. Jonas, the Junkman:
 How do I thank Mr. Jonas, he wondered, for what he's done? How do I thank him, how pay him back? No way, no way at all. You just can't pay. What then? What? Pass it on somehow, he thought, pass it on to someone else. Keep the chain moving. Look around, find someone, and pass it on. That was the only way...
Bradbury has also advised that writers he has helped thank him by helping other writers.
Heinlein both preached and practiced this philosophy; now the Heinlein Society, a humanitarian organization founded in his name, does so, attributing the philosophy to its various efforts, including Heinlein for Heroes, the Heinlein Society Scholarship Program, and Heinlein Society blood drives.
Author Spider Robinson made repeated reference to the doctrine, attributing it to his spiritual mentor Heinlein.
Influence and legacy.
The Dean of Science Fiction.
Heinlein is usually identified, along with Isaac Asimov and Arthur C. Clarke, as one of the three masters of science fiction to arise in the so-called Golden Age of science fiction, associated with John W. Campbell and his magazine "Astounding".
In the 1950s he was a leader in bringing science fiction out of the low-paying and less prestigious "pulp ghetto". Most of his works, including short stories, have been continuously in print in many languages since their initial appearance and are still available as new paperbacks decades after his death.
Robert Heinlein was also influenced by the American writer, philosopher and humorist Charles Fort who is credited as a major influence on most of the leading science-fiction writers of the 20th-century. Heinlein was a lifelong member of the International Fortean Organization also known as INFO, the successor to the original Fortean Society. Heinlein's letters were often displayed on the walls of the INFO offices, and his active participation in the organization is mentioned in the INFO Journal.
He was at the top of his form during, and himself helped to initiate, the trend toward social science fiction, which went along with a general maturing of the genre away from space opera to a more literary approach touching on such adult issues as politics and human sexuality. In reaction to this trend, hard science fiction began to be distinguished as a separate subgenre, but paradoxically Heinlein is also considered a seminal figure in hard science fiction, due to his extensive knowledge of engineering, and the careful scientific research demonstrated in his stories. Heinlein himself stated—with obvious pride—that in the days before pocket calculators, he and his wife Virginia once worked for several days on a mathematical equation describing an Earth-Mars rocket orbit, which was then subsumed in a single sentence of the novel "Space Cadet".
Influence among writers.
Heinlein has had a nearly ubiquitous influence on other science fiction writers. In a 1953 poll of leading science fiction authors, he was cited more frequently as an influence than any other modern writer. Critic James Gifford writes that "Although many other writers have exceeded Heinlein's output, few can claim to match his broad and seminal influence. Scores of science fiction writers from the prewar Golden Age through the present day loudly and enthusiastically credit Heinlein for blazing the trails of their own careers, and shaping their styles and stories."
Writer David Gerrold, responsible for creating the tribbles in Star Trek, also credited Heinlein as the inspiration for his Dingilliad series of novels. Gregory Benford refers to his novel Jupiter Project as a Heinlein tribute. Similarly, Charles Stross says to his Hugo Award-nominated novel Saturn's Children is "a space opera and late-period Robert A. Heinlein tribute", referring to Heinlein's "Friday")
Words and phrases coined.
Outside the science fiction community, several words and phrases coined or adopted by Heinlein have passed into common English usage:
Inspiring culture and technology.
In 1962, Oberon Zell-Ravenheart (then still using his birth name, Tim Zell) founded the Church of All Worlds, a Neopagan religious organization modeled in many ways after the treatment of religion in the novel "Stranger in a Strange Land". This spiritual path included several ideas from the book, including non-mainstream family structures, social libertarianism, water-sharing rituals, an acceptance of all religious paths by a single tradition, and the use of several terms such as "grok", "Thou art God", and "Never Thirst". Though Heinlein was neither a member nor a promoter of the Church, it was done with frequent correspondence between Zell and Heinlein, and he was a paid subscriber to their magazine "Green Egg". This Church still exists as a 501(C)(3) religious organization incorporated in California, with membership worldwide, and it remains an active part of the neopagan community today.
He was influential in making space exploration seem to the public more like a practical possibility. His stories in publications such as "The Saturday Evening Post" took a matter-of-fact approach to their outer-space setting, rather than the "gee whiz" tone that had previously been common. The documentary-like film "Destination Moon" advocated a Space Race with the Soviet Union almost a decade before such an idea became commonplace, and was promoted by an unprecedented publicity campaign in print publications. Many of the astronauts and others working in the U.S. space program grew up on a diet of the Heinlein juveniles, best evidenced by the naming of a crater on Mars after him, and a tribute interspersed by the Apollo 15 astronauts into their radio conversations while on the moon.
Heinlein was also a guest commentator for Walter Cronkite during Neil Armstrong and Buzz Aldrin's Apollo 11 moon landing. He remarked to Cronkite during the landing that, "This is the greatest event in human history, up to this time. This is—today is New Year's Day of the Year One." Businessman and entrepreneur Elon Musk says that Heinlein's books have helped inspire his career.
Heinlein Society.
The Heinlein Society was founded by Virginia Heinlein on behalf of her husband, to "pay forward" the legacy of the writer to future generations of "Heinlein's Children." The foundation has programs to:
The Heinlein society also established the Robert A. Heinlein Award in 2003 "for outstanding published works in science fiction and technical writings to inspire the human exploration of space."
In popular culture.
Jimmy Webb, "appropriated" the author's title The Moon is a Harsh Mistress, for his song of the same name:
Robert Heinlein, was a kind of early mentor of mine. I started reading his books when I was eight years old. ... I guess I was really getting more of my education out of science-fiction than out of public school. I was reading Ray Bradbury and Isaac Asimov and learning a great deal about the patois of the language itself and how these words were being used to create emotions. I was learning this from writers without even knowing it. ... "The Moon is a Harsh Mistress" was one of the best titles I've ever heard in my life. I really am guilty of appropriating something from another writer. In this case I had contact with Robert A. Heinlein's attornies. I said, 'I want to write a song with the title, "The Moon is a Harsh Mistress". Can you ask Mr. Heinlein if it's okay with him?' They called me back and he said he had no objection to it.
Honors.
In his lifetime, Heinlein received four Hugo Awards, for "Stranger in a Strange Land", "The Moon is a Harsh Mistress", "Starship Troopers", and "Double Star", and was nominated for four Nebula Awards, for "Stranger in a Strange Land", "Friday", "Time Enough for Love", and "Job: A Comedy of Justice". He was also given two posthumus Hugos, for "Farmer in the Sky" and "The Man Who Sold the Moon".
The Science Fiction Writers of America named Heinlein its first Grand Master in 1974, presented 1975. Officers and past presidents of the Association select a living writer for lifetime achievement (now annually and including fantasy literature).
Main-belt asteroid 6312 Robheinlein (1990 RH4), discovered on September 14, 1990 by H. E. Holt, at Palomar was named after him. Likewise, the Heinlein crater on Mars is named after him.
The Science Fiction and Fantasy Hall of Fame inducted Heinlein in 1998, its third class of two deceased and two living writers and editors.
In 2001 the United States Naval Academy created the Robert A. Heinlein Chair In Aerospace Engineering.
There was an active campaign to persuade the Secretary of the Navy to name the new "Zumwalt"-class destroyer DDG-1001 the USS "Robert A. Heinlein"; however, DDG-1001 will be named USS "Monsoor", after Michael Monsoor, a Navy SEAL who was posthumously awarded the Medal of Honor for his service in Iraq.
In December 2013 Heinlein was announced as an inductee to the Hall of Famous Missourians. His bronze bust, created by Kansas City sculptor, E. Spencer Schubert, will be one of forty-four on permanent display in the Missouri State Capitol in Jefferson City.
References.
Other sources.
</dl>
External links.
Biography and criticism
Bibliography and works

</doc>
<doc id="25391" url="http://en.wikipedia.org/wiki?curid=25391" title="Russia">
Russia

Russia (Russian: Россия, "Rossiya"; ]), also officially known as the Russian Federation (Russian: Российская Федерация, "Rossiyskaya Federatsiya"; ]), is a country in northern Eurasia. It is a federal semi-presidential republic. At 17075400 km2, Russia is the largest country in the world, covering more than one-eighth of the Earth's inhabited land area. Russia is also the world's ninth most populous nation with nearly 144 million people as of 2015.
Extending across the entirety of northern Asia and much of Eastern Europe, Russia spans nine time zones and incorporates a wide range of environments and landforms. From northwest to southeast, Russia shares land borders with Norway, Finland, Estonia, Latvia, Lithuania and Poland (both with Kaliningrad Oblast), Belarus, Ukraine, Georgia, Azerbaijan, Kazakhstan, China, Mongolia, and North Korea. It shares maritime borders with Japan by the Sea of Okhotsk and the U.S. state of Alaska across the Bering Strait.
The nation's history began with that of the East Slavs, who emerged as a recognizable group in Europe between the 3rd and 8th centuries AD. Founded and ruled by a Varangian warrior elite and their descendants, the medieval state of Rus arose in the 9th century. In 988 it adopted Orthodox Christianity from the Byzantine Empire, beginning the synthesis of Byzantine and Slavic cultures that defined Russian culture for the next millennium. Rus' ultimately disintegrated into a number of smaller states; most of the Rus' lands were overrun by the Mongol invasion and became tributaries of the nomadic Golden Horde. The Grand Duchy of Moscow gradually reunified the surrounding Russian principalities, achieved independence from the Golden Horde, and came to dominate the cultural and political legacy of Kievan Rus'. By the 18th century, the nation had greatly expanded through conquest, annexation, and exploration to become the Russian Empire, which was the third largest empire in history, stretching from Poland in Europe to Alaska in North America.
Following the Russian Revolution, the Russian Soviet Federative Socialist Republic became the largest and leading constituent of the Soviet Union, the world's first constitutionally socialist state and a recognized superpower, which played a decisive role in the Allied victory in World War II. The Soviet era saw some of the most significant technological achievements of the 20th century, including the world's first human-made satellite, and the first man in space. Following the dissolution of the Soviet Union in 1991, the Russian SFSR reconstituted itself as the Russian Federation and is recognized as the continuing legal personality (the sole successor state) of the Union state.
The Russian economy ranks as the fifteenth largest by nominal GDP and sixth largest by purchasing power parity in 2015. Russia's extensive mineral and energy resources, the largest reserves in the world, have made it one of the largest producers of oil and natural gas globally. The country is one of the five recognized nuclear weapons states and possesses the largest stockpile of weapons of mass destruction. Russia was the world's second biggest exporter of major arms in 2010-14, according to SIPRI data. Russia is a great power and a permanent member of the United Nations Security Council, a member of the G20, the Council of Europe, the Asia-Pacific Economic Cooperation, the Shanghai Cooperation Organization, the Eurasian Economic Community, the Organization for Security and Cooperation in Europe (OSCE), and the World Trade Organization (WTO), as well as being the leading member of the Commonwealth of Independent States.
Etymology.
The name "Russia" is derived from Rus, a medieval state populated mostly by the East Slavs. However, this proper name became more prominent in the later history, and the country typically was called by its inhabitants "Русская Земля" (russkaya zemlya), which can be translated as "Russian Land" or "Land of Rus'". In order to distinguish this state from other states derived from it, it is denoted as "Kievan Rus"' by modern historiography. The name "Rus" itself comes from Rus people, a group of Varangians (possibly Swedish Vikings) who founded the state of Rus (Русь).
An old Latin version of the name Rus' was Ruthenia, mostly applied to the western and southern regions of Rus' that were adjacent to Catholic Europe. The current name of the country, Россия (Rossiya), comes from the Byzantine Greek designation of the Kievan Rus', Ρωσσία "Rossía"—spelt Ρωσία ("Rosía" ]) in Modern Greek.
The standard way to refer to citizens of Russia is as "Russians" (Rossiyane).
History.
Early periods.
In prehistoric times the vast steppes of Southern Russia were home to tribes of nomadic pastoralists. Remnants of these steppe civilizations were discovered in such places as Ipatovo, Sintashta, Arkaim, and Pazyryk, which bear the earliest known traces of mounted warfare, a key feature in the nomadic way of life.
In classical antiquity, the Pontic Steppe was known as Scythia. Since the 8th century BC, Ancient Greek traders brought their civilization to the trade emporiums in Tanais and Phanagoria. The Romans settled on the western part of the Caspian Sea, where their empire stretched towards the east.{CN}} In 3rd – 4th centuries AD a semi-legendary Gothic kingdom of Oium existed in Southern Russia till it was overrun by Huns. Between the 3rd and 6th centuries AD, the Bosporan Kingdom, a Hellenistic polity which succeeded the Greek colonies, was also overwhelmed by nomadic invasions led by warlike tribes, such as the Huns and Eurasian Avars. A Turkic people, the Khazars, ruled the lower Volga basin steppes between the Caspian and Black Seas until the 10th century.
The ancestors of modern Russians are the Slavic tribes, whose original home is thought by some scholars to have been the wooded areas of the Pinsk Marshes. The East Slavs gradually settled Western Russia in two waves: one moving from Kiev toward present-day Suzdal and Murom and another from Polotsk toward Novgorod and Rostov. From the 7th century onwards, the East Slavs constituted the bulk of the population in Western Russia and slowly but peacefully assimilated the native Finno-Ugric peoples, including the Merya, the Muromians, and the Meshchera.
Kievan Rus'.
The establishment of the first East Slavic states in the 9th century coincided with the arrival of "Varangians", the traders, warriors and settlers from the Baltic Sea region. Primarily they were Vikings of Scandinavian origin, who ventured along the waterways extending from the eastern Baltic to the Black and Caspian Seas. According to the Primary Chronicle, a Varangian from Rus' people, named Rurik, was elected ruler of Novgorod in 862. In 882 his successor Oleg ventured south and conquered Kiev, which had been previously paying tribute to the Khazars, founding Kievan Rus'. Oleg, Rurik's son Igor and Igor's son Sviatoslav subsequently subdued all local East Slavic tribes to Kievan rule, destroyed the Khazar khaganate and launched several military expeditions to Byzantium and Persia.
In the 10th to 11th centuries Kievan Rus' became one of the largest and most prosperous states in Europe. The reigns of Vladimir the Great (980–1015) and his son Yaroslav the Wise (1019–1054) constitute the Golden Age of Kiev, which saw the acceptance of Orthodox Christianity from Byzantium and the creation of the first East Slavic written legal code, the "Russkaya Pravda".
In the 11th and 12th centuries, constant incursions by nomadic Turkic tribes, such as the Kipchaks and the Pechenegs, caused a massive migration of Slavic populations to the safer, heavily forested regions of the north, particularly to the area known as Zalesye.
The age of feudalism and decentralization was marked by constant in-fighting between members of the Rurik Dynasty that ruled Kievan Rus' collectively. Kiev's dominance waned, to the benefit of Vladimir-Suzdal in the north-east, Novgorod Republic in the north-west and Galicia-Volhynia in the south-west.
Ultimately Kievan Rus' disintegrated, with the final blow being the Mongol invasion of 1237–40, that resulted in the destruction of Kiev and the death of about half the population of Rus'. The invading Mongol elite, together with their conquered Turkic subjects (Cumans, Kipchaks, Bulgars) became known as Tatars, formed the state of the Golden Horde, which pillaged the Russian principalities; the Mongols ruled the Cuman-Kipchak confederation and Volga Bulgaria (modern-day southern and central expanses of Russia) for over two centuries.
Galicia-Volhynia was eventually assimilated by the Polish-Lithuanian Commonwealth, while the Mongol-dominated Vladimir-Suzdal and Novgorod Republic, two regions on the periphery of Kiev, established the basis for the modern Russian nation. The Novgorod together with Pskov retained some degree of autonomy during the time of the Mongol yoke and were largely spared the atrocities that affected the rest of the country. Led by Prince Alexander Nevsky, Novgorodians repelled the invading Swedes in the Battle of the Neva in 1240, as well as the Germanic crusaders in the Battle of the Ice in 1242, breaking their attempts to colonize the Northern Rus'.
Grand Duchy of Moscow.
The most powerful state to eventually arise after the destruction of Kievan Rus' was the Grand Duchy of Moscow ("Moscovy" in the Western chronicles), initially a part of Vladimir-Suzdal. While still under the domain of the Mongol-Tatars and with their connivance, Moscow began to assert its influence in the Central Rus' in the early 14th century, gradually becoming the main leading force in the process of the Rus' lands' reunification and expansion of Russia.
Those were hard times, with frequent Mongol-Tatar raids and agriculture suffering from the beginning of the Little Ice Age. As in the rest of Europe, plague was a frequent occurrence between 1350 and 1490. However, because of the lower population density and better hygiene (widespread practicing of banya, the wet steam bath), the death rate from plague was not as severe as in Western Europe, and population numbers recovered by 1500.
Led by Prince Dmitry Donskoy of Moscow and helped by the Russian Orthodox Church, the united army of Russian principalities inflicted a milestone defeat on the Mongol-Tatars in the Battle of Kulikovo in 1380. Moscow gradually absorbed the surrounding principalities, including the formerly strong rivals, such as Tver and Novgorod.
Ivan III ("the Great") finally threw off the control of the Golden Horde, consolidated the whole of Central and Northern Rus' under Moscow's dominion, and was the first to take the title "Grand Duke of all the Russias". After the fall of Constantinople in 1453, Moscow claimed succession to the legacy of the Eastern Roman Empire. Ivan III married Sophia Palaiologina, the niece of the last Byzantine emperor Constantine XI, and made the Byzantine double-headed eagle his own, and eventually Russia's, coat-of-arms.
Tsardom of Russia.
In development of the Third Rome ideas, the Grand Duke Ivan IV (the "Terrible") was officially crowned the first Tsar ("Caesar") of Russia in 1547. The Tsar promulgated a new code of laws (Sudebnik of 1550), established the first Russian feudal representative body (Zemsky Sobor) and introduced local self-management into the rural regions.
During his long reign, Ivan the Terrible nearly doubled the already large Russian territory by annexing the three Tatar khanates (parts of disintegrated Golden Horde): Kazan and Astrakhan along the Volga River, and Sibirean Khanate in Southwestern Siberia. Thus, by the end of the 16th century Russia was transformed into a multiethnic, multidenominational and transcontinental state.
However, the Tsardom was weakened by the long and unsuccessful Livonian War against the coalition of Poland, Lithuania, and Sweden for access to the Baltic coast and sea trade. At the same time the Tatars of the Crimean Khanate, the only remaining successor to the Golden Horde, continued to raid Southern Russia. In an effort to restore the Volga khanates, Crimeans and their Ottoman allies invaded central Russia and were even able to burn down parts of Moscow in 1571. But next year the large invading army was thoroughly defeated by Russians in the Battle of Molodi, forever eliminating the threat of the Ottoman–Crimean expansion into Russia. The slave raids of Crimeans, however, didn't cease until the late 17th century, though the construction of new fortification lines across Southern Russia, such as the Great Abatis Line, constantly narrowed the area accessible to incursions.
The death of Ivan's sons marked the end of the ancient Rurik Dynasty in 1598, and in combination with the famine of 1601–03 led to the civil war, the rule of pretenders and foreign intervention during the Time of Troubles in the early 17th century. Polish-Lithuanian Commonwealth occupied parts of Russia, including Moscow. In 1612, the Poles were forced to retreat by the Russian volunteer corps, led by two national heroes, merchant Kuzma Minin and Prince Dmitry Pozharsky. The Romanov Dynasty acceded the throne in 1613 by the decision of Zemsky Sobor, and the country started its gradual recovery from the crisis.
Russia continued its territorial growth through the 17th century, which was the age of Cossacks. Cossacks were warriors organized into military communities, resembling pirates and pioneers of the New World. In 1648, the peasants of Ukraine joined the Zaporozhian Cossacks in rebellion against Poland-Lithuania during the Khmelnytsky Uprising, because of the social and religious oppression they suffered under Polish rule. In 1654, the Ukrainian leader, Bohdan Khmelnytsky, offered to place Ukraine under the protection of the Russian Tsar, Aleksey I. Aleksey's acceptance of this offer led to another Russo-Polish War. Finally, Ukraine was split along the Dnieper River, leaving the western part, right-bank Ukraine, under Polish rule and eastern part (Left-bank Ukraine and Kiev) under Russian. Later, in 1670–71 the Don Cossacks led by Stenka Razin initiated a major uprising in the Volga Region, but the Tsar's troops were successful in defeating the rebels.
In the east, the rapid Russian exploration and colonisation of the huge territories of Siberia was led mostly by Cossacks hunting for valuable furs and ivory. Russian explorers pushed eastward primarily along the Siberian River Routes, and by the mid-17th century there were Russian settlements in Eastern Siberia, on the Chukchi Peninsula, along the Amur River, and on the Pacific coast. In 1648, the Bering Strait between Asia and North America was passed for the first time by Fedot Popov and Semyon Dezhnyov.
Imperial Russia.
Under Peter the Great, Russia was proclaimed an Empire in 1721 and became recognized as a world power. Ruling from 1682 to 1725, Peter defeated Sweden in the Great Northern War, forcing it to cede West Karelia and Ingria (two regions lost by Russia in the Time of Troubles), as well as Estland and Livland, securing Russia's access to the sea and sea trade. On the Baltic Sea Peter founded a new capital called Saint Petersburg, later known as Russia's "Window to Europe". Peter the Great's reforms brought considerable Western European cultural influences to Russia.
The reign of Peter I's daughter Elizabeth in 1741–62 saw Russia's participation in the Seven Years' War (1756–63). During this conflict Russia annexed East Prussia for a while and even took Berlin. However, upon Elisabeth's death, all these conquests were returned to Kingdom of Prussia by pro-Prussian Peter III of Russia.
Catherine II ("the Great"), who ruled in 1762–96, presided over the Age of Russian Enlightenment. She extended Russian political control over the Polish-Lithuanian Commonwealth and incorporated most of its territories into Russia during the Partitions of Poland, pushing the Russian frontier westward into Central Europe. In the south, after successful Russo-Turkish Wars against the Ottoman Empire, Catherine advanced Russia's boundary to the Black Sea, defeating the Crimean Khanate. As a result of victories over the Qajar Persian Empire, by the first half of the 19th century Russia also made significant territorial gains in Transcaucasia and the North Caucasus. This continued with Alexander I's (1801–25) wresting of Finland from the weakened kingdom of Sweden in 1809 and of Bessarabia from the Ottomans in 1812. At the same time Russians colonized Alaska and even founded settlements in California, like Fort Ross.
In 1803–1806, the first Russian circumnavigation was made, later followed by other notable Russian sea exploration voyages. In 1820 a Russian expedition discovered the continent of Antarctica.
In alliances with various European countries, Russia fought against Napoleon's France. The French invasion of Russia at the height of Napoleon's power in 1812 failed miserably as the obstinate resistance in combination with the bitterly cold Russian Winter led to a disastrous defeat of invaders, in which more than 95% of the pan-European Grande Armée perished. Led by Mikhail Kutuzov and Barclay de Tolly, the Russian army ousted Napoleon from the country and drove through Europe in the war of the Sixth Coalition, finally entering Paris. Alexander I headed Russia's delegation at the Congress of Vienna that defined the map of post-Napoleonic Europe.
The officers of the Napoleonic Wars brought ideas of liberalism back to Russia with them and attempted to curtail the tsar's powers during the abortive Decembrist revolt of 1825. At the end of the conservative reign of Nicolas I (1825–55), a zenith period of Russia's power and influence in Europe was disrupted by defeat in the Crimean War. Between 1847 and 1851, about one million people died of Asiatic cholera.
Nicholas's successor Alexander II (1855–81) enacted significant changes in the country, including the emancipation reform of 1861. These "Great Reforms" spurred industrialization and modernized the Russian army, which had successfully liberated Bulgaria from Ottoman rule in 1877–78 Russo-Turkish War.
The late 19th century saw the rise of various socialist movements in Russia. Alexander II was killed in 1881 by revolutionary terrorists, and the reign of his son
Alexander III (1881–94) was less liberal but more peaceful. The last Russian Emperor, Nicholas II (1894–1917), was unable to prevent the events of the Russian Revolution of 1905, triggered by the unsuccessful Russo-Japanese War and the demonstration incident known as Bloody Sunday. The uprising was put down, but the government was forced to concede major reforms, including granting the freedoms of speech and assembly, the legalization of political parties, and the creation of an elected legislative body, the State Duma of the Russian Empire. The Stolypin agrarian reform led to a massive peasant migration and settlement into Siberia. More than four million settlers arrived in that region between 1906 and 1914.
In 1914, Russia entered World War I in response to Austria-Hungary's declaration of war on Russia's ally Serbia, and fought across multiple fronts while isolated from its Triple Entente allies. In 1916, the Brusilov Offensive of the Russian Army almost completely destroyed the military of Austria-Hungary. However, the already-existing public distrust of the regime was deepened by the rising costs of war, high casualties, and rumors of corruption and treason. All this formed the climate for the Russian Revolution of 1917, carried out in two major acts.
Revolution and Russian Republic.
The February Revolution forced Nicholas II to abdicate; he and his family were imprisoned and later executed during the Russian Civil War. The monarchy was replaced by a shaky coalition of political parties that declared itself the Provisional Government. An alternative socialist establishment existed alongside, the Petrograd Soviet, wielding power through the democratically elected councils of workers and peasants, called "Soviets". The rule of the new authorities only aggravated the crisis in the country, instead of resolving it. Eventually, the October Revolution, led by Bolshevik leader Vladimir Lenin, overthrew the Provisional Government and gave full governing power to the Soviets, leading to the creation of the world's first socialist state.
Soviet Russia and civil war.
Following the October Revolution, a civil war broke out between the anti-Communist White movement and the new Soviet regime with its Red Army. Bolshevist Russia lost its Ukrainian, Polish, Baltic, and Finnish territories by signing the Treaty of Brest-Litovsk that concluded hostilities with the Central Powers of World War I. The Allied powers launched an unsuccessful military intervention in support of anti-Communist forces. In the meantime both the Bolsheviks and White movement carried out campaigns of deportations and executions against each other, known respectively as the Red Terror and White Terror. By the end of the civil war, the Russian economy and its infrastructure were heavily damaged. Millions became White émigrés, and the Povolzhye famine of 1921 claimed up to 5 million victims.
Soviet Union.
The Russian Soviet Federative Socialist Republic (called "Russian Socialist Federative Soviet Republic" at the time) together with the Ukrainian, Byelorussian, and Transcaucasion Soviet Socialist Republics, formed the Union of Soviet Socialist Republics (USSR), or Soviet Union, on 30 December 1922. Out of the 15 republics that would make up the USSR, the largest in size and over half of the total USSR population was the Russian SFSR, which came to dominate the union for its entire 69-year history.
Following Lenin's death in 1924, a troika was designated to govern the Soviet Union. However, Joseph Stalin, an elected General Secretary of the Communist Party, managed to suppress all opposition groups within the party and consolidate power in his hands. Leon Trotsky, the main proponent of world revolution, was exiled from the Soviet Union in 1929, and Stalin's idea of Socialism in One Country became the primary line. The continued internal struggle in the Bolshevik party culminated in the Great Purge, a period of mass repressions in 1937–38, during which hundreds of thousands of people were executed, including original party members and military leaders accused of coup d'état plots.
Under Stalin's leadership, the government launched a planned economy, industrialisation of the largely rural country, and collectivization of its agriculture. During this period of rapid economic and social change, millions of people were sent to penal labor camps, including many political convicts for their opposition to Stalin's rule; millions were deported and exiled to remote areas of the Soviet Union. The transitional disorganisation of the country's agriculture, combined with the harsh state policies and a drought, led to the Soviet famine of 1932–1933. The Soviet Union, though with a heavy price, was transformed from a largely agrarian economy to a major industrial powerhouse in a short span of time.
The Appeasement policy of Great Britain and France towards Adolf Hitler's annexation of Austria and Czechoslovakia did not stem an increase in the power of Nazi Germany and put a threat of war to the Soviet Union. Around the same time the Third Reich allied with the Empire of Japan, a rival of the USSR in the Far East and an open enemy of the USSR in the Soviet–Japanese Border Wars in 1938–39.
In August 1939, after another failure of attempts to establish an anti-Nazi alliance with Britain and France, the Soviet government decided to improve relations with Germany by concluding the Molotov-Ribbentrop Pact, pledging non-aggression between the two countries and dividing their spheres of influence in Eastern Europe. While Hitler conquered Poland, France and other countries actied on single front at the start of World War II, the USSR was able to build up its military and claim some of the former territories of the Russian Empire as a result of the Soviet invasion of Poland, Winter War and the occupation of the Baltic states.
On 22 June 1941, Nazi Germany broke the non-aggression treaty and invaded the Soviet Union with the largest and most powerful invasion force in human history, opening the largest theater of World War II. Although the German army had considerable early success, their attack was halted in the Battle of Moscow. Subsequently, the Germans were dealt major defeats first at the Battle of Stalingrad in the winter of 1942–43, and then in the Battle of Kursk in the summer of 1943. Another German failure was the Siege of Leningrad, in which the city was fully blockaded on land between 1941–44 by German and Finnish forces, and suffered starvation and more than a million deaths, but never surrendered. Under Stalin's administration and the leadership of such commanders as Georgy Zhukov and Konstantin Rokossovsky, Soviet forces took Eastern Europe in 1944–45 and captured Berlin in May 1945. In August 1945 the Soviet Army ousted the Japanese from China's Manchukuo and North Korea, contributing to the allied victory over Japan.
The 1941–45 period of World War II is known in Russia as the "Great Patriotic War". During this conflict, which included many of the most lethal battle operations in human history, Soviet military and civilian deaths were 10.6 million and 15.9 million respectively, accounting for about a third of all World War II casualties. The full demographic loss to the Soviet peoples was even greater. The Soviet economy and infrastructure suffered massive devastation, but the Soviet Union emerged as an acknowledged military superpower on the continent.
The Red Army occupied Eastern Europe after the war, including East Germany. Dependent socialist governments were installed in the Eastern Bloc satellite states. Becoming the world's second nuclear weapons power, the USSR established the Warsaw Pact alliance and entered into a struggle for global dominance, known as the Cold War, with the United States and NATO. The Soviet Union supported revolutionary movements across the world, including the newly formed People's Republic of China, the Democratic People's Republic of Korea and, later on, the Republic of Cuba. Significant amounts of the Soviet resources were allocated in aid to the other socialist states.
After Stalin's death and a short period of collective rule, new leader Nikita Khrushchev denounced the cult of personality of Stalin and launched the policy of de-Stalinization. The penal labor system was reformed and many prisoners were released and rehabilitated (many of them posthumously). The general easement of repressive policies became known later as the Khrushchev Thaw. At the same time, tensions with the United States heightened when the two rivals clashed over the deployment of the U.S. Jupiter missiles in Turkey and Soviet missiles in Cuba.
In 1957, the Soviet Union launched the world's first artificial satellite, "Sputnik 1", thus starting the Space Age. Russian cosmonaut Yuri Gagarin became the first human to orbit the Earth aboard "Vostok 1" manned spacecraft on 12 April 1961.
Following the ousting of Khrushchev in 1964, another period of collective rule ensued, until Leonid Brezhnev became the leader. The era of the 1970s and the early 1980s was designated later as the Era of Stagnation, a period when the economic growth slowed and social policies became static. The 1965 Kosygin reform aimed for partial decentralization of the Soviet economy and shifted the emphasis from heavy industry and weapons to light industry and consumer goods but was stifled by the conservative Communist leadership.
In 1979, after a Communist-led revolution in Afghanistan, Soviet forces entered that country at request of the new regime. The occupation drained economic resources and dragged on without achieving meaningful political results. Ultimately the Soviet Army was withdrawn from Afghanistan in 1989 due to international opposition, persistent anti-Soviet guerilla warfare, and a lack of support by Soviet citizens.
From 1985 onwards, the last Soviet leader Mikhail Gorbachev, who sought to enact liberal reforms in the Soviet system, introduced the policies of "glasnost" (openness) and "perestroika" (restructuring) in an attempt to end the period of economic stagnation and to democratise the government. This, however, led to the rise of strong nationalist and separatist movements. Prior to 1991, the Soviet economy was the second largest in the world, but during its last years it was afflicted by shortages of goods in grocery stores, huge budget deficits, and explosive growth in money supply leading to inflation.
By 1991, economic and political turmoil began to boil over, as the Baltic republics chose to secede from the Union. On 17 March, a referendum was held, to which the vast majority of participating citizens voted in favour of preserving the Soviet Union as a renewed federation. In August 1991, a coup d'état attempt by members of Gorbachev's government, directed against Gorbachev and aimed at preserving the Soviet Union, instead led to the end of the Communist Party of the Soviet Union. Despite the will expressed by the people, on 25 December 1991, the USSR was dissolved into 15 post-Soviet states.
Russian Federation.
In June 1991, Boris Yeltsin became the first directly elected President in Russian history when he was elected President of the Russian Soviet Federative Socialist Republic, which became the independent Russian Federation in December of that year. During and after the disintegration of the Soviet Union, wide-ranging reforms including privatization and market and trade liberalization were undertaken, including radical changes along the lines of "shock therapy" as recommended by the United States and the International Monetary Fund. All this resulted in a major economic crisis, characterized by a 50% decline of both GDP and industrial output between 1990–95.
The privatization largely shifted control of enterprises from state agencies to individuals with inside connections in the government. Many of the newly rich moved billions in cash and assets outside of the country in an enormous capital flight. The depression of the economy led to the collapse of social services; the birth rate plummeted while the death rate skyrocketed. Millions plunged into poverty, from 1.5% level of poverty in the late Soviet era, to 39–49% by mid-1993. The 1990s saw extreme corruption and lawlessness, the rise of criminal gangs and violent crime.
The 1990s were plagued by armed conflicts in the North Caucasus, both local ethnic skirmishes and separatist Islamist insurrections. From the time Chechen separatists declared independence in the early 1990s, an intermittent guerrilla war has been fought between the rebel groups and the Russian military. Terrorist attacks against civilians carried out by separatists, most notably the Moscow theater hostage crisis and Beslan school siege, caused hundreds of deaths and drew worldwide attention.
Russia took up the responsibility for settling the USSR's external debts, even though its population made up just half of the population of the USSR at the time of its dissolution. High budget deficits caused the 1998 Russian financial crisis and resulted in a further GDP decline.
On 31 December 1999, President Yeltsin unexpectedly resigned, handing the post to the recently appointed Prime Minister, Vladimir Putin, who then won the 2000 presidential election. Putin suppressed the Chechen insurgency, although sporadic violence still occurs throughout the Northern Caucasus. High oil prices and the initially weak currency followed by increasing domestic demand, consumption, and investments has helped the economy grow for nine straight years, improving the standard of living and increasing Russia's influence on the world stage. While many reforms made during the Putin presidency have been generally criticized by Western nations as un-democratic, Putin's leadership over the return of order, stability, and progress has won him widespread admiration in Russia.
On 2 March 2008, Dmitry Medvedev was elected President of Russia, while Putin became Prime Minister. Putin returned to the presidency following the 2012 presidential elections, and Medvedev was appointed Prime Minister.
In 2014, after President Viktor Yanukovych of Ukraine fled as a result of a revolution, Putin requested and received authorization from the Russian Parliament to deploy Russian troops to Ukraine. Following a Crimean referendum in which separation was favored by a large majority of voters, but which was not accepted internationally, the Russian leadership announced the annexation of Crimea by Russia. On 27 March the United Nations General Assembly voted in favor of a non-binding resolution opposing the Russian annexation of Crimea.
Politics.
Governance.
According to the Constitution of Russia, the country is a federation and semi-presidential republic, wherein the President is the head of state and the Prime Minister is the head of government. The Russian Federation is fundamentally structured as a multi-party representative democracy, with the federal government composed of three branches:
The president is elected by popular vote for a six-year term (eligible for a second term, but not for a third consecutive term). Ministries of the government are composed of the Premier and his deputies, ministers, and selected other individuals; all are appointed by the President on the recommendation of the Prime Minister (whereas the appointment of the latter requires the consent of the State Duma). Leading political parties in Russia include United Russia, the Communist Party, the Liberal Democratic Party, and A Just Russia. In 2013, Russia was ranked as 122nd of 167 countries in the Democracy Index, compiled by The Economist Intelligence Unit, while the World Justice Project currently ranks Russia 80th of 99 countries surveyed in terms of rule of law.
Foreign relations.
The Russian Federation is recognized in international law as a successor state of the former Soviet Union. Russia continues to implement the international commitments of the USSR, and has assumed the USSR's permanent seat in the UN Security Council, membership in other international organisations, the rights and obligations under international treaties, and property and debts. Russia has a multifaceted foreign policy. As of 2009, it maintains diplomatic relations with 191 countries and has 144 embassies. The foreign policy is determined by the President and implemented by the Ministry of Foreign Affairs of Russia.
As the successor to a former superpower, Russia's geopolitical status has often been debated, particularly in relation to unipolar and multipolar views on the global political system. While Russia is commonly accepted to be a great power, in recent years it has been characterized by a number of world leaders, scholars, commentators and politicians as a currently reinstating or potential superpower.
As one of five permanent members of the UN Security Council, Russia plays a major role in maintaining international peace and security. The country participates in the Quartet on the Middle East and the Six-party talks with North Korea. Russia is a member of the G8 industrialized nations, the Council of Europe, OSCE, and APEC. Russia usually takes a leading role in regional organisations such as the CIS, EurAsEC, CSTO, and the SCO. Russia became the 39th member state of the Council of Europe in 1996. In 1998, Russia ratified the European Convention on Human Rights. The legal basis for EU relations with Russia is the Partnership and Cooperation Agreement, which came into force in 1997. The Agreement recalls the parties' shared respect for democracy and human rights, political and economic freedom and commitment to international peace and security. In May 2003, the EU and Russia agreed to reinforce their cooperation on the basis of common values and shared interests. Former President Vladimir Putin had advocated a strategic partnership with close integration in various dimensions including establishment of EU-Russia Common Spaces. Since the dissolution of the Soviet Union, Russia has developed a friendlier relationship with the United States and NATO. The NATO-Russia Council was established in 2002 to allow the United States, Russia and the 27 allies in NATO to work together as equal partners to pursue opportunities for joint collaboration.
Russia maintains strong and positive relations with other BRIC countries. India is the largest customer of Russian military equipment and the two countries share extensive defense and strategic relations. In recent years, the country has strengthened bilateral ties especially with the People's Republic of China by signing the Treaty of Friendship as well as building the Trans-Siberian oil pipeline and gas pipeline from Siberia to China.
An important aspect of Russia's relations with the West is the criticism of Russia's political system and human rights management (including LGBT rights, media freedom, and reports about killed journalists) by the Western governments, the mass media and the leading democracy and human rights watchdogs. In particular, such organisations as the Amnesty International and Human Rights Watch consider Russia to have not enough democratic attributes and to allow few political rights and civil liberties to its citizens. Freedom House, an international organisation funded by the United States, ranks Russia as "not free", citing "carefully engineered elections" and "absence" of debate. Russian authorities dismiss these claims and especially criticise Freedom House. The Russian Ministry of Foreign Affairs has called the 2006 "Freedom in the World" report "prefabricated", stating that the human rights issues have been turned into a political weapon in particular by the United States. The ministry also claims that such organisations as Freedom House and Human Rights Watch use the same scheme of voluntary extrapolation of "isolated facts that of course can be found in any country" into "dominant tendencies".
Military.
The Russian military is divided into the Ground Forces, Navy, and Air Force. There are also three independent arms of service: Strategic Missile Troops, Aerospace Defence Forces, and the Airborne Troops. In 2006, the military had 1.037 million personnel on active duty. It is mandatory for all male citizens aged 18–27 to be drafted for a year of service in Armed Forces.
Russia has the largest stockpile of nuclear weapons in the world. It has the second largest fleet of ballistic missile submarines and is the only country apart from the United States with a modern strategic bomber force. Russia's tank force is the largest in the world, its surface navy and air force are among the largest ones.
The country has a large and fully indigenous arms industry, producing most of its own military equipment with only few types of weapons imported. Russia is one of the world's top supplier of arms, a spot it has held since 2001, accounting for around 30% of worldwide weapons sales and exporting weapons to about 80 countries. The Stockholm International Peace Research Institute, SIPRI, found that Russia was the second biggest exporter of arms in 2010-14, increasing their exports by 37 per cent from the period 2005-2009. In 2010-14, Russia delivered weapons to 56 states and to rebel forces in eastern Ukraine.
The Russian government's published 2014 military budget is about 2.49 trillion rubles (approximately US$69.3 billion), the third largest in the world behind the US and China. The official budget is set to rise to 3.03 trillion rubles (approximately US$83.7 billion) in 2015, and 3.36 trillion rubles (approximately US$93.9 billion) in 2016. However, unofficial estimates put the budget significantly higher, for example the Stockholm International Peace Research Institute (SIPRI) 2013 Military Expenditure Database estimated Russia's military expenditure in 2012 at US$90.749 billion. This estimate is an increase of more than US$18 billion on SIPRI's estimate of the Russian military budget for 2011 (US$71.9 billion). As of 2014, Russia's military budget is higher than any other European nation.
According to 2012 Global Peace Index, Russia is the sixth least peaceful out of 162 countries in the world, principally because of its defense industry. Russia has historically ranked low on the index since its inception in 2007.
Political divisions.
According to the Constitution, the country comprises eighty-five federal subjects, including the Republic of Crimea and the federal city of Sevastopol, whose recent establishment is internationally disputed and criticized as illegal annexation. In 1993, when the Constitution was adopted, there were eighty-nine federal subjects listed, but later some of them were merged. These subjects have equal representation—two delegates each—in the Federation Council. However, they differ in the degree of autonomy they enjoy.
Federal subjects are grouped into nine federal districts, each administered by an envoy appointed by the President of Russia. Unlike the federal subjects, the federal districts are not a subnational level of government, but are a level of administration of the federal government. Federal districts' envoys serve as liaisons between the federal subjects and the federal government and are primarily responsible for overseeing the compliance of the federal subjects with the federal laws.
Geography.
Russia is the largest country in the world; its total area is 17075400 km2. There are 23 UNESCO World Heritage Sites in Russia, 40 UNESCO biosphere reserves, 41 national parks and 101 nature reserves. It lies between latitudes 41° and 82° N, and longitudes 19° E and 169° W.
Russia's territorial expansion was achieved largely in the late 16th century under the Cossack, Yermak Timofeyevich, during the reign of Ivan the Terrible, at a time when competing city-states in the western regions of Russia had banded together to form one country. Yermak mustered an army and pushed eastward, where he conquered nearly all the lands once belonging to the Mongols, defeating their ruler, Khan Kuchum.
Russia has a wide natural resource base, including major deposits of timber, petroleum, natural gas, coal, ores and other mineral resources.
Topography.
The two widest separated points in Russia are about 8000 km apart along a geodesic line. These points are: the boundary with Poland on a 60 km long Vistula Spit separating the Gdańsk Bay from the Vistula Lagoon; and the farthest southeast of the Kuril Islands. The points which are furthest separated in longitude are 6600 km apart along a geodesic line. These points are: in the west, the same spit; in the east, the Big Diomede Island. The Russian Federation spans 9 time zones.
Most of Russia consists of vast stretches of plains that are predominantly steppe to the south and heavily forested to the north, with tundra along the northern coast. Russia possesses 10% of the world's arable land. Mountain ranges are found along the southern borders, such as the Caucasus (containing Mount Elbrus, which at 5642 m is the highest point in both Russia and Europe) and the Altai (containing Mount Belukha, which at the 4506 m is the highest point of Siberia outside of the Russian Far East); and in the eastern parts, such as the Verkhoyansk Range or the volcanoes of Kamchatka Peninsula (containing Klyuchevskaya Sopka, which at the 4750 m is the highest active volcano in Eurasia as well as the highest point of Asian Russia). The Ural Mountains, rich in mineral resources, form a north-south range that divides Europe and Asia.
Russia has an extensive coastline of over 37000 km along the Arctic and Pacific Oceans, as well as along the Baltic Sea, Sea of Azov, Black Sea and Caspian Sea. The Barents Sea, White Sea, Kara Sea, Laptev Sea, East Siberian Sea, Chukchi Sea, Bering Sea, Sea of Okhotsk, and the Sea of Japan are linked to Russia via the Arctic and Pacific. Russia's major islands and archipelagos include Novaya Zemlya, the Franz Josef Land, the Severnaya Zemlya, the New Siberian Islands, Wrangel Island, the Kuril Islands, and Sakhalin. The Diomede Islands (one controlled by Russia, the other by the U.S.) are just 3 km apart, and Kunashir Island is about 20 km from Hokkaido, Japan.
Russia has thousands of rivers and inland bodies of water, providing it with one of the world's largest surface water resources. Its lakes contain approximately one-quarter of the world's liquid fresh water. The largest and most prominent of Russia's bodies of fresh water is Lake Baikal, the world's deepest, purest, oldest and most capacious fresh water lake. Baikal alone contains over one-fifth of the world's fresh surface water. Other major lakes include Ladoga and Onega, two of the largest lakes in Europe. Russia is second only to Brazil in volume of the total renewable water resources. Of the country's 100,000 rivers, the Volga is the most famous, not only because it is the longest river in Europe, but also because of its major role in Russian history. The Siberian rivers Ob, Yenisey, Lena and Amur are among the longest rivers in the world.
Climate.
The enormous size of Russia and the remoteness of many areas from the sea result in the dominance of the humid continental climate, which is prevalent in all parts of the country except for the tundra and the extreme southeast. Mountains in the south obstruct the flow of warm air masses from the Indian Ocean, while the plain of the west and north makes the country open to Arctic and Atlantic influences.
Most of Northern European Russia and Siberia has a subarctic climate, with extremely severe winters in the inner regions of Northeast Siberia (mostly the Sakha Republic, where the Northern Pole of Cold is located with the record low temperature of −71.2 °C), and more moderate elsewhere. The strip of land along the shore of the Arctic Ocean, as well as the Russian Arctic islands, have a polar climate.
The coastal part of Krasnodar Krai on the Black Sea, most notably in Sochi, possesses a humid subtropical climate with mild and wet winters. Winter is dry compared to summer in many regions of East Siberia and the Far East, while other parts of the country experience more even precipitation across seasons. Winter precipitation in most parts of the country usually falls as snow. The region along the Lower Volga and Caspian Sea coast, as well as some areas of southernmost Siberia, possesses a semi-arid climate.
Throughout much of the territory there are only two distinct seasons—winter and summer—as spring and autumn are usually brief periods of change between extremely low temperatures and extremely high. The coldest month is January (February on the coastline), the warmest usually is July. Great ranges of temperature are typical. In winter, temperatures get colder both from south to north and from west to east. Summers can be quite hot, even in Siberia. The continental interiors are the driest areas.
Biodiversity.
From north to south the East European Plain, also known as Russian Plain, is clad sequentially in Arctic tundra, coniferous forest (taiga), mixed and broad-leaf forests, grassland (steppe), and semi-desert (fringing the Caspian Sea), as the changes in vegetation reflect the changes in climate. Siberia supports a similar sequence but is largely taiga. Russia has the world's largest forest reserves, known as "the lungs of Europe", second only to the Amazon Rainforest in the amount of carbon dioxide it absorbs.
There are 266 mammal species and 780 bird species in Russia. A total of 415 animal species have been included in the Red Data Book of the Russian Federation as of 1997 and are now protected.
Economy.
Russia has a developed, high-income market economy with enormous natural resources, particularly oil and natural gas. It has the 15th largest economy in the world by nominal GDP and the 6th largest by purchasing power parity (PPP). Since the turn of the 21st century, higher domestic consumption and greater political stability have bolstered economic growth in Russia. The country ended 2008 with its ninth straight year of growth, but growth has slowed with the decline in the price of oil and gas. Real GDP per capita, PPP (current international) was 19,840 in 2010. Growth was primarily driven by non-traded services and goods for the domestic market, as opposed to oil or mineral extraction and exports. The average nominal salary in Russia was $967 per month in early 2013, up from $80 in 2000. In March 2014 the average nominal monthly wages reached 30,000 RUR (or US$980), while tax on the income of individuals is payable at the rate of 13% on most incomes. Approximately 12.8% of Russians lived below the national poverty line in 2011, significantly down from 40% in 1998 at the worst point of the post-Soviet collapse. Unemployment in Russia was at 5.4% in 2014, down from about 12.4% in 1999. The middle class has grown from just 8 million persons in 2000 to 104 million persons in 2013. Sugar imports reportedly dropped 82% between 2012 and 2013 as a result of the increase in domestic output.
Oil, natural gas, metals, and timber account for more than 80% of Russian exports abroad. Since 2003, the exports of natural resources started decreasing in economic importance as the internal market strengthened considerably. Despite higher energy prices, oil and gas only contribute to 5.7% of Russia's GDP and the government predicts this will be 3.7% by 2011. Oil export earnings allowed Russia to increase its foreign reserves from $12 billion in 1999 to $597.3 billion on 1 August 2008, the third largest foreign exchange reserves in the world. The macroeconomic policy under Finance Minister Alexei Kudrin was prudent and sound, with excess income being stored in the Stabilization Fund of Russia. In 2006, Russia repaid most of its formerly massive debts, leaving it with one of the lowest foreign debts among major economies. The Stabilization Fund helped Russia to come out of the global financial crisis in a much better state than many experts had expected.
A simpler, more streamlined tax code adopted in 2001 reduced the tax burden on people and dramatically increased state revenue. Russia has a flat tax rate of 13%. This ranks it as the country with the second most attractive personal tax system for single managers in the world after the United Arab Emirates. According to Bloomberg, Russia is considered well ahead of most other resource-rich countries in its economic development, with a long tradition of education, science, and industry. The country has a higher proportion of higher education graduates than any other country in Eurasia.
The economic development of the country has been uneven geographically with the Moscow region contributing a very large share of the country's GDP. 
Inequality of household income and wealth has also been noted, with Credit Suisse finding Russian wealth distribution so much more extreme than other countries studied it "deserves to be placed in a separate category."
Another problem is modernisation of infrastructure, ageing and inadequate after years of being neglected in the 1990s; the government has said $1 trillion will be invested in development of infrastructure by 2020. In December 2011, Russia finally joined the World Trade Organisation, allowing it a greater access to overseas markets. Some analysts estimate that WTO membership could bring the Russian economy a bounce of up to 3% annually. Russia ranks as the second-most corrupt country in Europe (after Ukraine), according to the Corruption Perceptions Index. The Norwegian-Russian Chamber of Commerce also states that "[c]orruption is one of the biggest problems both Russian and international companies have to deal with". The high rate of corruption acts as a hidden tax as businesses and individuals often have to pay money that is not part of the official tax rate. It is estimated that corruption is costing the Russian economy an estimated $2 billion (80 billion rubles) per year. In 2014, a book-length study by Professor Karen Dawisha was published concerning corruption in Russian under Putin's government.
The Russian central bank announced plans in 2013 to free float the Russian ruble in 2015. According to a stress test conducted by the central bank Russian financial system would be able to handle a currency decline of 25%–30% without major central bank interference. However, Russian economy began stagnating in late 2013 and in combination with the War in Donbass is in danger of entering stagflation, slow growth and high inflation. The Russian ruble collapsed by 24% from October 2013 to October 2014 entering the level where the central bank may need to intervene to strengthen the currency. Moreover, after bringing inflation down to 3.6% in 2012, the lowest rate since gaining independence from the Soviet Union, inflation in Russia jumped to nearly 7.5% in 2014, causing the central bank to increase its lending rate to 8% from 5.5% in 2013. In an October 2014 article in "Bloomberg Business Week", it was reported that Russia had significantly started shifting its economy towards China in response to increasing financial tensions following its annexation of Crimea and subsequent Western economic sanctions.
Agriculture.
The total area of cultivated land in Russia was estimated as 1,237,294 km2 in 2005, the fourth largest in the world. From 1999 to 2009, Russia's agriculture demonstrated steady growth, and the country turned from a grain importer to the third largest grain exporter after EU and the United States. The production of meat has grown from 6,813,000 tonnes in 1999 to 9,331,000 tonnes in 2008, and continues to grow.
This restoration of agriculture was supported by credit policy of the government, helping both individual farmers and large privatized corporate farms, that once were Soviet kolkhozes and still own the significant share of agricultural land. While large farms concentrate mainly on the production of grain and husbandry products, small private household plots produce most of the country's yield of potatoes, vegetables and fruits.
With access to three of the world's oceans—the Atlantic, Arctic, and Pacific—Russian fishing fleets are a major contributor to the world's fish supply. The total capture of fish was at 3,191,068 tons in 2005. Both exports and imports of fish and sea products grew significantly in the recent years, reaching correspondingly $2,415 and $2,036 millions in 2008.
Sprawling from the Baltic Sea to the Pacific Ocean, Russia has more than a fifth of the world's forests, which makes it the largest forest country in the world. However, according to a 2012 study by the Food and Agriculture Organization of the United Nations and the Government of the Russian Federation, the considerable potential of Russian forests is underutilized and Russia's share of the global trade in forest products is less than four percent.
Energy.
In recent years, Russia has frequently been described in the media as an energy superpower. The country has the world's largest natural gas reserves, the 8th largest oil reserves, and the second largest coal reserves. Russia is the world's leading natural gas exporter and second largest natural gas producer, while also the largest oil exporter and the largest oil producer.
Russia is the 3rd largest electricity producer in the world and the 5th largest renewable energy producer, the latter because of the well-developed hydroelectricity production in the country. Large cascades of hydropower plants are built in European Russia along big rivers like Volga. The Asian part of Russia also features a number of major hydropower stations, however the gigantic hydroelectric potential of Siberia and the Russian Far East largely remains unexploited.
Russia was the first country to develop civilian nuclear power and to construct the world's first nuclear power plant. Currently the country is the 4th largest nuclear energy producer, with all nuclear power in Russia being managed by Rosatom State Corporation. The sector is rapidly developing, with an aim of increasing the total share of nuclear energy from current 16.9% to 23% by 2020. The Russian government plans to allocate 127 billion rubles ($5.42 billion) to a federal program dedicated to the next generation of nuclear energy technology. About 1 trillion rubles ($42.7 billion) is to be allocated from the federal budget to nuclear power and industry development before 2015.
In May 2014 on a two-day trip to Shanghai, President Putin signed a deal on behalf of Gazprom for the Russian energy giant to supply China with 38 billion cubic meters of natural gas per year. Construction of a pipeline to facilitate the deal was agreed whereby Russia would contribute $55bn to the cost, and China $22bn, in what Putin described as "the world's biggest construction project for the next four years." The natural gas would begin to flow sometime between 2018 and 2020 and would continue for 30 years at an ultimate cost to China of $400bn.
Transport.
Railway transport in Russia is mostly under the control of the state-run Russian Railways monopoly. The company accounts for over 3.6% of Russia's GDP and handles 39% of the total freight traffic (including pipelines) and more than 42% of passenger traffic. The total length of common-used railway tracks exceeds 85500 km, second only to the United States. Over 44000 km of tracks are electrified, which is the largest number in the world, and additionally there are more than 30000 km of industrial non-common carrier lines. Railways in Russia, unlike in the most of the world, use broad gauge of , with the exception of 957 km on Sakhalin island using narrow gauge of . The most renown railway in Russia is Trans-Siberian ("Transsib"), spanning a record 7 time zones and serving the longest single continuous services in the world, Moscow-Vladivostok (9259 km), Moscow–Pyongyang (10267 km) and Kiev–Vladivostok (11085 km).
As of 2006 Russia had 933,000 km of roads, of which 755,000 were paved. Some of these make up the Russian federal motorway system. With a large land area the road density is the lowest of all the G8 and BRIC countries.
Much of Russia's inland waterways, which total 102000 km, are made up of natural rivers or lakes. In the European part of the country the network of channels connects the basins of major rivers. Russia's capital, Moscow, is sometimes called "the port of the five seas", because of its waterway connections to the Baltic, White, Caspian, Azov and Black Seas.
Major sea ports of Russia include Rostov-on-Don on the Azov Sea, Novorossiysk on the Black Sea, Astrakhan and Makhachkala on the Caspian, Kaliningrad and St Petersburg on the Baltic, Arkhangelsk on the White Sea, Murmansk on the Barents Sea, Petropavlovsk-Kamchatsky and Vladivostok on the Pacific Ocean. In 2008 the country owned 1,448 merchant marine ships. The world's only fleet of nuclear-powered icebreakers advances the economic exploitation of the Arctic continental shelf of Russia and the development of sea trade through the Northern Sea Route between Europe and East Asia.
By total length of pipelines Russia is second only to the United States. Currently many new pipeline projects are being realized, including Nord Stream and South Stream natural gas pipelines to Europe, and the Eastern Siberia – Pacific Ocean oil pipeline (ESPO) to the Russian Far East and China.
Russia has 1,216 airports, the busiest being Sheremetyevo, Domodedovo, and Vnukovo in Moscow, and Pulkovo in St. Petersburg. The total length of runways in Russia exceeds 600000 km.
Typically, major Russian cities have well-developed systems of public transport, with the most common varieties of exploited vehicles being bus, trolleybus and tram. Seven Russian cities, namely Moscow, Saint Petersburg, Nizhny Novgorod, Novosibirsk, Samara, Yekaterinburg, and Kazan, have underground metros, while Volgograd features a metrotram. The total length of metros in Russia is 465.4 km. Moscow Metro and Saint Petersburg Metro are the oldest in Russia, opened in 1935 and 1955 respectively. These two are among the fastest and busiest metro systems in the world, and are famous for rich decorations and unique designs of their stations, which is a common tradition on Russian metros and railways.
Science and technology.
Science and technology in Russia blossomed since the Age of Enlightenment, when Peter the Great founded the Russian Academy of Sciences and Saint Petersburg State University, and polymath Mikhail Lomonosov established the Moscow State University, paving the way for a strong native tradition in learning and innovation. In the 19th and 20th centuries the country produced a large number of notable scientists and inventors.
The Russian physics school began with Lomonosov who proposed the law of conservation of matter preceding the energy conservation law. Russian discoveries and inventions in physics include the electric arc, electrodynamical Lenz's law, space groups of crystals, photoelectric cell, superfluidity, Cherenkov radiation, electron paramagnetic resonance, heterotransistors and 3D holography. Lasers and masers were co-invented by Nikolai Basov and Alexander Prokhorov, while the idea of tokamak for controlled nuclear fusion was introduced by Igor Tamm, Andrei Sakharov and Lev Artsimovich, leading eventually the modern international ITER project, where Russia is a party.
Since the time of Nikolay Lobachevsky (the "Copernicus of Geometry" who pioneered the non-Euclidean geometry) and a prominent tutor Pafnuty Chebyshev, the Russian mathematical school became one of the most influential in the world. Chebyshev's students included Aleksandr Lyapunov, who founded the modern stability theory, and Andrey Markov who invented the Markov chains. In the 20th century Soviet mathematicians, such as Andrey Kolmogorov, Israel Gelfand, and Sergey Sobolev, made major contributions to various areas of mathematics. Nine Soviet/Russian mathematicians were awarded with Fields Medal, a most prestigious award in mathematics. Recently Grigori Perelman was offered the first ever Clay Millennium Prize Problems Award for his final proof of the Poincaré conjecture in 2002.
Russian chemist Dmitry Mendeleev invented the Periodic table, the main framework of modern chemistry. Aleksandr Butlerov was one of the creators of the theory of chemical structure, playing a central role in organic chemistry. Russian biologists include Dmitry Ivanovsky who discovered viruses, Ivan Pavlov who was the first to experiment with the classical conditioning, and Ilya Mechnikov who was a pioneer researcher of the immune system and probiotics.
Many Russian scientists and inventors were émigrés, like Igor Sikorsky, who built the first airliners and modern-type helicopters; Vladimir Zworykin, often called the father of TV; chemist Ilya Prigogine, noted for his work on dissipative structures and complex systems; Nobel Prize-winning economists Simon Kuznets and Wassily Leontief; physicist Georgiy Gamov (an author of the Big Bang theory) and social scientist Pitirim Sorokin. Many foreigners worked in Russia for a long time, like Leonard Euler and Alfred Nobel.
Russian inventions include arc welding by Nikolay Benardos, further developed by Nikolay Slavyanov, Konstantin Khrenov and other Russian engineers. Gleb Kotelnikov invented the knapsack parachute, while Evgeniy Chertovsky introduced the pressure suit. Alexander Lodygin and Pavel Yablochkov were pioneers of electric lighting, and Mikhail Dolivo-Dobrovolsky introduced the first three-phase electric power systems, widely used today. Sergei Lebedev invented the first commercially viable and mass-produced type of synthetic rubber. The first ternary computer, "Setun", was developed by Nikolay Brusentsov.
In the 20th century a number of prominent Soviet aerospace engineers, inspired by the fundamental works of Nikolai Zhukovsky, Sergei Chaplygin and others, designed many hundreds of models of military and civilian aircraft and founded a number of "KBs" ("Construction Bureaus") that now constitute the bulk of Russian United Aircraft Corporation. Famous Russian aircraft include the civilian Tu-series, Su and MiG fighter aircraft, Ka and Mi-series helicopters; many Russian aircraft models are on the list of most produced aircraft in history.
Famous Russian battle tanks include T34, the most heavily produced tank design of World War II, and further tanks of T-series, including the most produced tank in history, T54/55. The AK47 and AK74 by Mikhail Kalashnikov constitute the most widely used type of assault rifle throughout the world—so much so that more AK-type rifles have been manufactured than all other assault rifles combined.
With all these achievements, however, since the late Soviet era Russia was lagging behind the West in a number of technologies, mostly those related to energy conservation and consumer goods production. The crisis of the 1990s led to the drastic reduction of the state support for science and a brain drain migration from Russia.
In the 2000s, on the wave of a new economic boom, the situation in the Russian science and technology has improved, and the government launched a campaign aimed into modernisation and innovation. Russian President Dmitry Medvedev formulated top priorities for the country's technological development:
Currently Russia has completed the GLONASS satellite navigation system. The country is developing its own fifth-generation jet fighter and constructing the first serial mobile nuclear plant in the world.
Space exploration.
Russian achievements in the field of space technology and space exploration are traced back to Konstantin Tsiolkovsky, the father of theoretical astronautics. His works had inspired leading Soviet rocket engineers, such as Sergey Korolyov, Valentin Glushko, and many others who contributed to the success of the Soviet space program on early stages of the Space Race and beyond.
In 1957 the first Earth-orbiting artificial satellite, "Sputnik 1", was launched; in 1961 the first human trip into space was successfully made by Yury Gagarin. Many other Soviet and Russian space exploration records ensued, including the first spacewalk performed by Alexey Leonov, Luna 9 was the first spacecraft to land on the Moon, Venera 7 was the first to land on another planet (Venus), Mars 3 then the first to land on Mars, the first space exploration rover "Lunokhod 1" and the first space station "Salyut 1" and "Mir".
After the collapse of the Soviet Union, some government-funded space exploration programs, including the Buran space shuttle program, were cancelled or delayed, while participation of the Russian space industry in commercial activities and international cooperation intensified.
Nowadays Russia is the largest satellite launcher. After the U.S. Space Shuttle program ended in 2011, Soyuz rockets became the only provider of transport for astronauts at the International Space Station. 
Demographics.
Ethnic Russians comprise 81% of the country's population. The Russian Federation is also home to several sizeable minorities. In all, 160 different other ethnic groups and indigenous peoples live within its borders. Though Russia's population is comparatively large, its density is low because of the country's enormous size. Population is densest in European Russia, near the Ural Mountains, and in southwest Siberia. 73% of the population lives in urban areas while 27% in rural ones. The results of the 2010 Census show a total population of 142,856,536.
Russia's population peaked at 148,689,000 in 1991, just before the dissolution of the Soviet Union. It began to experience a rapid decline starting in the mid-1990s. The decline has slowed to near stagnation in recent years because of reduced death rates, increased birth rates and increased immigration.
In 2009, Russia recorded annual population growth for the first time in fifteen years, with total growth of 10,500. 279,906 migrants arrived to the Russian Federation the same year, of which 93% came from CIS countries. The number of Russian emigrants steadily declined from 359,000 in 2000 to 32,000 in 2009. There are also an estimated 10 million illegal immigrants from the ex-Soviet states in Russia. Russia is home to approximately 116 million ethnic Russians and about 20 million ethnic Russians live outside Russia in the former republics of the Soviet Union, mostly in Ukraine and Kazakhstan.
The 2010 census recorded 81% of the population as ethnically Russian, and 19% as other ethnicities: 3.7% Tatars; 1.4% Ukrainians; 1.1% Bashkirs; 1% Chuvashes; 11.8% others and unspecified. According to the Census, 84.93% of the Russian population belongs to European ethnic groups (Slavic, Germanic, Finnic other than Ugric, Greek, and others). This is a decline from the 2002, when they constituted for more than 86% of the population.
Russia's birth rate is higher than that of most European countries (12.6 births per 1000 people in 2010 compared to the European Union average of 9.90 per 1000), but its death rate is also substantially higher (in 2010, Russia's death rate was 14.3 per 1000 people compared to the EU average of 10.28 per 1000). The Russian Ministry of Health and Social Affairs predicted that by 2011 the death rate would equal the birth rate because of increase in fertility and decline in mortality. The government is implementing a number of programs designed to increase the birth rate and attract more migrants. Monthly government child-assistance payments were doubled to US$55, and a one-time payment of US$9,200 was offered to women who had a second child since 2007.
In 2006, in a bid to compensate for the country's demographic decline, the Russian government started simplifying immigration laws and launched a state program "for providing assistance to voluntary immigration of ethnic Russians from former Soviet republics". In 2009 Russia experienced its highest birth rate since the dissolution of the Soviet Union. In 2012, the birth rate increased again. Russia recorded 1,896,263 births, the highest number since 1990, and even exceeding annual births during the period 1967–1969, with a TFR of about 1.7, the highest since 1991. (Source: Vital statistics table below)
In August 2012, as the country saw its first demographic growth since the 1990s, President Putin declared that Russia's population could reach 146 million by 2025, mainly as a result of immigration.
Language.
Russia's 160 ethnic groups speak some 100 languages. According to the 2002 Census, 142.6 million people speak Russian, followed by Tatar with 5.3 million and Ukrainian with 1.8 million speakers. Russian is the only official state language, but the Constitution gives the individual republics the right to establish their own state languages in addition to Russian.
Despite its wide distribution, the Russian language is homogeneous throughout the country. Russian is the most geographically widespread language of Eurasia, as well as the most widely spoken Slavic language. It belongs to the Indo-European language family and is one of the living members of the East Slavic languages, the others being Belarusian and Ukrainian (and possibly Rusyn). Written examples of Old East Slavic ("Old Russian") are attested from the 10th century onwards.
Russian is the second-most used language on the Internet after English, one of two official languages aboard the International Space Station and is one of the six official languages of the UN.
Religion.
There is no official census of religion in Russia, and estimates are based on surveys only. In August 2012, ARENA estimated that about 46.8% of Russians are Christians (including Orthodox, Catholic, Protestant, and non-denominational), which is slightly less than an absolute 50%+ majority. However, later that year, the Levada Center estimated that 76% of Russians are Christians, and in June 2013, the Public Opinion Foundation estimated that 65% of Russians are Christians. These findings are in line with Pew Research Center's 2011 survey, which estimated that 73.6% of Russians are Christians, with Russian Public Opinion Research Center (VCIOM)'s 2010 survey (~77% Christian), and with Ipsos MORI's 2011 survey (69%). Orthodox Christianity, Islam, Judaism and Buddhism are Russia's traditional religions, and are all legally a part of Russia's "historical heritage".
Traced back to the Christianization of Kievan Rus' in the 10th century, Russian Orthodoxy is the dominant religion in the country; smaller Christian denominations such as Catholics, Armenian Gregorians and various Protestant churches also exist. The Russian Orthodox Church was the country's state religion prior to the Revolution and remains the largest religious body in the country. An estimated 95% of the registered Orthodox parishes belong to the Russian Orthodox Church while there are a number of smaller Orthodox Churches. However, the vast majority of Orthodox believers do not attend church on a regular basis. Easter is the most popular religious holiday in Russia, celebrated by a large segment of the Russian population, including large numbers of those who are non-religious. More than three-quarters of the Russian population celebrate Easter by making traditional Easter cakes, coloured eggs and paskha.
Islam is the second largest religion in Russia after Russian Orthodoxy. It is the traditional or predominant religion amongst some Caucasian ethnicities (notably the Chechens, the Ingush and the Circassians), and amongst some Turkic peoples (notably the Tatars and the Bashkirs). Altogether, there are 9,400,000 Muslims in Russia or 6.5% of the total population as of 2012 (the share of Muslims is probably much higher because the survey doesn't include detailed data for the traditionally Islamic states of Chechnya and Ingushetia). Notwithstanding, various differences split the Muslim population in different groups. According to the survey, most of the Muslims (precisely 6,700,000 or 4.6% of the total population) are "unaffiliated" to any Islamic schools and branches or Islamic organisation, this is mainly because it is not essential for Muslims to be affiliated with any specific sect or organization. Those who are affiliated are mostly Sunni Muslims, with Shia and Ahmadiyya minorities. Unaffiliated Muslims constitute significant numbers of over 10% in Kabardino-Balkaria (49%), Bashkortostan (38%), Karachay-Cherkessia (34%), Tatarstan (31%), Yamalia (13%), Orenburg Oblast (11%), Adygea (11%) and Astrakhan Oblast (11%). Most of the regions of Siberia have an unaffiliated Muslim population of 1% to 2%.
Buddhism is traditional in three regions of the Russian Federation: Buryatia, Tuva, and Kalmykia. Some residents of the Siberian and Far Eastern regions, such as Yakutia and Chukotka, practice shamanist, pantheistic, and pagan rites, along with the major religions. Induction into religion takes place primarily along ethnic lines. Slavs are significantly Orthodox Christian, Turkic speakers are predominantly Muslim, and Mongolic peoples are generally Buddhists.
Various reports put the number of non-religious in Russia at between 16–48% of the population. The number of atheists has decreased significantly; according to the recent statistic, only seven percent declared themselves atheists, a decrease of 5% in three years.
Health.
The Russian Constitution guarantees free, universal health care for all its citizens. In practice, however, free health care is partially restricted because of mandatory registration. While Russia has more physicians, hospitals, and health care workers than almost any other country in the world on a per capita basis, since the dissolution of the Soviet Union the health of the Russian population has declined considerably as a result of social, economic, and lifestyle changes; the trend has been reversed only in the recent years, with average life expectancy having increased 5.2 years for males and 3.1 years for females between 2006–14.
As of 2014, the average life expectancy in Russia was 65.29 years for males and 76.49 years for females. The biggest factor contributing to the relatively low life expectancy for males is a high mortality rate among working-age males. Deaths mostly occur because of preventable causes (e.g., alcohol poisoning, smoking, traffic accidents, violent crime). As a result of the large gender difference in life expectancy, and also because of the lasting effect of high casualties in World War II, the gender imbalance remains to this day; there are 0.859 males to every female.
Education.
Russia have the most college-level or higher graduates in percentage of population in the world. Russia has a free education system, which is guaranteed for all citizens by the Constitution, however entry to subsidized higher education is highly competitive. As a result of great emphasis on science and technology in education, Russian medical, mathematical, scientific, and aerospace research is generally of a high order.
Since 1990, the 11-year school education has been introduced. Education in state-owned secondary schools is free. University level education is free, with exceptions. A substantial share of students is enrolled for full pay (many state institutions started to open commercial positions in the last years).
In 2004, state spending for education amounted to 3.6% of the GDP, or 13% of the consolidated state budget. The Government allocates funding to pay the tuition fees within an established quota or number of students for each state institution. In higher education institutions, students are paid a small stipend and provided with free housing if they are from out of town.
The oldest and largest Russian universities are Moscow State University and Saint Petersburg State University. In the 2000s, in order to create higher education and research institutions of comparable scale in Russian regions, the government launched a program of establishing "federal universities", mostly by merging existing large regional universities and research institutes and providing them with a special funding. These new institutions include the Southern Federal University, Siberian Federal University, Kazan Volga Federal University, North-Eastern Federal University, and Far Eastern Federal University.
Culture.
Folk culture and cuisine.
There are over 160 different ethnic groups and indigenous peoples in Russia. Ethnic Russians with their Slavic Orthodox traditions, Tatars and Bashkirs with their Turkic Muslim culture, Buddhist nomadic Buryats and Kalmyks, Shamanistic peoples of the Extreme North and Siberia, highlanders of the Northern Caucasus, Finno-Ugric peoples of the Russian North West and Volga Region all contribute to the cultural diversity of the country.
Handicraft, like Dymkovo toy, khokhloma, gzhel and palekh miniature represent an important aspect of Russian folk culture. Ethnic Russian clothes include kaftan, kosovorotka and ushanka for men, sarafan and kokoshnik for women, with lapti and valenki as common shoes. The clothes of Cossacks from Southern Russia include burka and papaha, which they share with the peoples of the Northern Caucasus.
Russian cuisine widely uses fish, poultry, mushrooms, berries, and honey. Crops of rye, wheat, barley, and millet provide the ingredients for various breads, pancakes and cereals, as well as for kvass, beer and vodka drinks. Black bread is rather popular in Russia, compared to the rest of the world. Flavourful soups and stews include shchi, borsch, ukha, solyanka and okroshka. Smetana (a heavy sour cream) is often added to soups and salads. Pirozhki, blini and syrniki are native types of pancakes. Chicken Kiev, pelmeni and shashlyk are popular meat dishes, the last two being of Tatar and Caucasus origin respectively. Other meat dishes include stuffed cabbage rolls "(golubtsy)" usually filled with meat. Salads include Olivier salad, vinegret and dressed herring.
Russia's large number of ethnic groups have distinctive traditions regarding folk music. Typical ethnic Russian musical instruments are gusli, balalaika, zhaleika, and garmoshka. Folk music had a significant influence on Russian classical composers, and in modern times it is a source of inspiration for a number of popular folk bands, like Melnitsa. Russian folk songs, as well as patriotic Soviet songs, constitute the bulk of the repertoire of the world-renowned Red Army choir and other popular ensembles.
Russians have many traditions, including the washing in banya, a hot steam bath somewhat similar to sauna. Old Russian folklore takes its roots in the pagan Slavic religion. Many Russian fairy tales and epic bylinas were adaptated for animation films, or for feature movies by the prominent directors like Aleksandr Ptushko ("Ilya Muromets", "Sadko") and Aleksandr Rou ("Morozko", "Vasilisa the Beautiful"). Russian poets, including Pyotr Yershov and Leonid Filatov, made a number of well-known poetical interpretations of the classical fairy tales, and in some cases, like that of Alexander Pushkin, also created fully original fairy tale poems of great popularity.
Architecture.
Since the Christianization of Kievan Rus' for several ages Russian architecture was influenced predominantly by the Byzantine architecture. Apart from fortifications (kremlins), the main stone buildings of ancient Rus' were Orthodox churches with their many domes, often gilded or brightly painted.
Aristotle Fioravanti and other Italian architects brought Renaissance trends into Russia since the late 15th century, while the 16th century saw the development of unique tent-like churches culminating in Saint Basil's Cathedral. By that time the onion dome design was also fully developed. In the 17th century, the "fiery style" of ornamentation flourished in Moscow and Yaroslavl, gradually paving the way for the Naryshkin baroque of the 1690s. After the reforms of Peter the Great the change of architectural styles in Russia generally followed that in the Western Europe.
The 18th-century taste for rococo architecture led to the ornate works of Bartolomeo Rastrelli and his followers. The reigns of Catherine the Great and her grandson Alexander I saw the flourishing of Neoclassical architecture, most notably in the capital city of Saint Petersburg. The second half of the 19th century was dominated by the Neo-Byzantine and Russian Revival styles. Prevalent styles of the 20th century were the Art Nouveau, Constructivism, and the Stalin Empire style.
In 1955, a new Soviet leader, Nikita Khrushchev, condemned the "excesses" of the former academic architecture, and the late Soviet era was dominated by plain functionalism in architecture. This helped somewhat to resolve the housing problem, but created a large quantity of buildings of low architectural quality, much in contrast with the previous bright styles. The situation improved in the recent two decades. Many temples demolished in Soviet times were rebuilt, and this process continues along with the restoration of various historical buildings destroyed in World War II. A total of 23,000 Orthodox churches have been rebuilt between 1991 and 2010, which effectively quadrapled the number of operating churches in Russia.
Visual arts.
Early Russian painting is represented in icons and vibrant frescos, the two genres inherited from Byzantium. As Moscow rose to power, Theophanes the Greek, Dionisius and Andrei Rublev became vital names associated with a distinctly Russian art.
The Russian Academy of Arts was created in 1757 and gave Russian artists an international role and status. Ivan Argunov, Dmitry Levitzky, Vladimir Borovikovsky and other 18th century academicians mostly focused on portrait painting. In the early 19th century, when neoclassicism and romantism flourished, mythological and Biblical themes inspired many prominent paintings, notably by Karl Briullov and Alexander Ivanov.
In the mid-19th century the "Peredvizhniki" ("Wanderers") group of artists broke with the Academy and initiated a school of art liberated from academic restrictions. These were mostly realist painters who captured Russian identity in landscapes of wide rivers, forests, and birch clearings, as well as vigorous genre scenes and robust portraits of their contemporaries. Some artists focused on depicting dramatic moments in Russian history, while others turned to social criticism, showing the conditions of the poor and caricaturing authority; critical realism flourished under the reign of Alexander II. Leading realists include Ivan Shishkin, Arkhip Kuindzhi, Ivan Kramskoi, Vasily Polenov, Isaac Levitan, Vasily Surikov, Viktor Vasnetsov, Ilya Repin, and Boris Kustodiev.
The turn of the 20th century saw the rise of symbolist painting, represented by Mikhail Vrubel, Kuzma Petrov-Vodkin, and Nicholas Roerich.
The Russian avant-garde was a large, influential wave of modernist art that flourished in Russia from approximately 1890 to 1930. The term covers many separate, but inextricably related art movements that occurred at the time, namely neo-primitivism, suprematism, constructivism, rayonism, and Russian Futurism. Notable artists from this era include El Lissitzky, Kazimir Malevich, Wassily Kandinsky, and Marc Chagall. Since the 1930s the revolutionary ideas of the avant-garde clashed with the newly emerged conservative direction of socialist realism.
Soviet art produced works that were furiously patriotic and anti-fascist during and after the Great Patriotic War. Multiple war memorials, marked by a great restrained solemnity, were built throughout the country. Soviet artists often combined innovation with socialist realism, notably the sculptors Vera Mukhina, Yevgeny Vuchetich and Ernst Neizvestny.
Music and dance.
Music in 19th century Russia was defined by the tension between classical composer Mikhail Glinka along with other members of The Mighty Handful, who embraced Russian national identity and added religious and folk elements to their compositions, and the Russian Musical Society led by composers Anton and Nikolay Rubinsteins, which was musically conservative. The later tradition of Pyotr Ilyich Tchaikovsky, one of the greatest composers of the Romantic era, was continued into the 20th century by Sergei Rachmaninoff. World-renowned composers of the 20th century include Alexander Scriabin, Igor Stravinsky, Sergei Prokofiev, Dmitri Shostakovich and Alfred Schnittke.
Russian conservatories have turned out generations of famous soloists. Among the best known are violinists Jascha Heifetz, David Oistrakh, Leonid Kogan, Gidon Kremer, and Maxim Vengerov; cellists Mstislav Rostropovich, Natalia Gutman; pianists Vladimir Horowitz, Sviatoslav Richter, Emil Gilels, Vladimir Sofronitsky and Evgeny Kissin; and vocalists Fyodor Shalyapin, Mark Reizen, Elena Obraztsova, Tamara Sinyavskaya, Nina Dorliak, Galina Vishnevskaya, Anna Netrebko and Dmitry Hvorostovsky.
During the early 20th century, Russian ballet dancers Anna Pavlova and Vaslav Nijinsky rose to fame, and impresario Sergei Diaghilev and his Ballets Russes' travels abroad profoundly influenced the development of dance worldwide. Soviet ballet preserved the perfected 19th century traditions, and the Soviet Union's choreography schools produced many internationally famous stars, including Galina Ulanova, Maya Plisetskaya, Rudolf Nureyev, and Mikhail Baryshnikov. The Bolshoi Ballet in Moscow and the Mariinsky Ballet in St Petersburg remain famous throughout the world.
Modern Russian rock music takes its roots both in the Western rock and roll and heavy metal, and in traditions of the Russian bards of the Soviet era, such as Vladimir Vysotsky and Bulat Okudzhava. Popular Russian rock groups include Mashina Vremeni, DDT, Aquarium, Alisa, Kino, Kipelov, Nautilus Pompilius, Aria, Grazhdanskaya Oborona, Splean and Korol i Shut. Russian pop music developed from what was known in the Soviet times as "estrada" into full-fledged industry, with some performers gaining wide international recognition, such as t.A.T.u., Nu Virgos and Vitas.
Literature and philosophy.
In the 18th century, during the era of Russian Enlightenment, the development of Russian literature was boosted by the works of Mikhail Lomonosov and Denis Fonvizin. By the early 19th century a modern native tradition had emerged, producing some of the greatest writers in Russian history. This period, known also as the Golden Age of Russian Poetry, began with Alexander Pushkin, who is considered the founder of the modern Russian literary language and often described as the "Russian Shakespeare". It continued into the 19th century with the poetry of Mikhail Lermontov and Nikolay Nekrasov, dramas of Alexander Ostrovsky and Anton Chekhov, and the prose of Nikolai Gogol and Ivan Turgenev. Leo Tolstoy and Fyodor Dostoyevsky have been described by literary critics as the greatest novelists of all time.
By the 1880s, the age of the great novelists was over, and short fiction and poetry became the dominant genres. The next several decades became known as the Silver Age of Russian Poetry, when the previously dominant literary realism was replaced by symbolism. Leading authors of this era include such poets as Valery Bryusov, Vyacheslav Ivanov, Alexander Blok, Nikolay Gumilev and Anna Akhmatova, and novelists Leonid Andreyev, Ivan Bunin, and Maxim Gorky.
Russian philosophy blossomed in the 19th century, when it was defined initially by the opposition of Westernizers, advocating Western political and economical models, and Slavophiles, insisting on developing Russia as a unique civilization. The latter group includes Nikolai Danilevsky and Konstantin Leontiev, the founders of eurasianism. In its further development Russian philosophy was always marked by a deep connection to literature and interest in creativity, society, politics and nationalism; Russian cosmism and religious philosophy were other major areas. Notable philosophers of the late 19th and the early 20th centuries include Vladimir Solovyev, Sergei Bulgakov, and Vladimir Vernadsky.
Following the Russian Revolution of 1917 many prominent writers and philosophers left the country, including Bunin, Vladimir Nabokov and Nikolay Berdyayev, while a new generation of talented authors joined together in an effort to create a distinctive working-class culture appropriate for the new Soviet state. In the 1930s censorship over literature was tightened in line with the policy of socialist realism. In the late 1950s restrictions on literature were eased, and by the 1970s and 1980s, writers were increasingly ignoring official guidelines. Leading authors of the Soviet era include novelists Yevgeny Zamyatin, Ilf and Petrov, Mikhail Bulgakov and Mikhail Sholokhov, and poets Vladimir Mayakovsky, Yevgeny Yevtushenko, and Andrey Voznesensky.
The Soviet Union was also a major producer of science fiction, written by authors like Arkady and Boris Strugatsky, Kir Bulychov, Alexander Belayev and Ivan Yefremov. Traditions of Russian science fiction and fantasy are continued today by numerous writers.
Cinema, animation and media.
Russian and later Soviet cinema was a hotbed of invention in the period immediately following the 1917, resulting in world-renowned films such as "The Battleship Potemkin" by Sergei Eisenstein. Eisenstein was a student of filmmaker and theorist Lev Kuleshov, who developed the Soviet montage theory of film editing at the world's first film school, the All-Union Institute of Cinematography. Dziga Vertov, whose "kino-glaz" ("film-eye") theory—that the camera, like the human eye, is best used to explore real life—had a huge impact on the development of documentary film making and cinema realism. The subsequent state policy of socialist realism somewhat limited creativity, however many Soviet films in this style were artistically successful, like "Chapaev", "The Cranes Are Flying", and "Ballad of a Soldier".
1960s and 1970s saw a greater variety of artistic styles in the Soviet cinema. Eldar Ryazanov's and Leonid Gaidai's comedies of that time were immensely popular, with many of the catch phrases still in use today. In 1961–68 Sergey Bondarchuk directed an Oscar-winning film adaptation of Leo Tolstoy's epic "War and Peace", which was the most expensive film made in the Soviet Union. In 1969, Vladimir Motyl's "White Sun of the Desert" was released, a very popular film in a genre of ostern; the film is traditionally watched by cosmonauts before any trip into space.
Russian animation dates back to the late Russian Empire times. During Soviet era, Soyuzmultfilm studio was the largest animation producer. Soviet animators developed a great variety of pioneering techniques and aesthetic styles, with prominent directors including Ivan Ivanov-Vano, Fyodor Khitruk and Aleksandr Tatarsky. Many Soviet cartoon heroes, such as the Russian-style Winnie-the-Pooh, cute little Cheburashka, Wolf and Hare from "Nu, Pogodi!" are iconic images in Russia and many surrounding countries.
The late 1980s and 1990s were a period of crisis in Russian cinema and animation. Although Russian filmmakers became free to express themselves, state subsidies were drastically reduced, resulting in fewer films produced. The early years of the 21st century have brought increased viewership and subsequent prosperity to the industry on the back of the economic revival. Production levels are already higher than in Britain and Germany. Russia's total box-office revenue in 2007 was $565 million, up 37% from the previous year. In 2002 the "Russian Ark" became the first feature film ever to be shot in a single take. The traditions of Soviet animation were developed recently by such directors as Aleksandr Petrov and studios like Melnitsa Animation.
Russia was among the first countries to introduce radio and television. While there were few channels in the Soviet time, in the past two decades many new state and private-owned radio stations and TV channels appeared. In 2005 a state-run English language Russia Today TV started broadcasting, and its Arabic version Rusiya Al-Yaum was launched in 2007.
Sports.
Combining the total medals of Soviet Union and Russia, the country is second among all nations by number of gold medals both at the Summer Olympics and at the Winter Olympics. Soviet and later Russian athletes have always been in the top three for the number of gold medals collected at the Summer Olympics. Soviet gymnasts, track-and-field athletes, weight lifters, wrestlers, boxers, fencers, shooters, cross country skiers, biathletes, speed skaters and figure skaters were consistently among the best in the world, along with Soviet basketball, handball, volleyball and ice hockey players. The 1980 Summer Olympics were held in Moscow while the 2014 Winter Olympics were hosted in Sochi.
Although ice hockey was only introduced during the Soviet era, the national team managed to win gold at almost all the Olympics and World Championships they contested. Russian players Valery Kharlamov, Sergei Makarov, Vyacheslav Fetisov and Vladislav Tretiak hold four of six positions in the IIHF "Team of the Century". Russia has not won the Olympic ice hockey tournament since the Unified Team won gold in 1992. Recently Russia won the 2008, 2009, 2012 and the 2014 IIHF World Championships. Russia dominated the 2012 tournament, winning all of its ten matches—the first time any team had done so since the Soviet Union in 1989.
The Kontinental Hockey League (KHL) was founded in 2008 as a successor to the Russian Superleague. It is seen as a rival to the National Hockey League (NHL), is ranked the top hockey league in Europe as of 2009, and the second-best in the world. It is an international professional ice hockey league in Eurasia and consists of 28 teams, of which 21 are based in Russia and 7 more are located in Latvia, Kazakhstan, Belarus, Ukraine, Czech Republic, Slovakia, and Croatia.
Bandy, also known as Russian hockey, is another traditionally popular ice sport. The Soviet Union won all the Bandy World Championships for men between 1957–79 and some thereafter too. After the dissolution of the Soviet Union, Russia has continuously been one of the most successful teams, winning many world championships.
Association football is one of the most popular sports in modern Russia. The Soviet national team became the first ever European Champions by winning Euro 1960. Appearing in four FIFA World Cups from 1958 to 1970, Lev Yashin is regarded to be one of the greatest goalkeepers in the history of football, and was chosen on the FIFA World Cup Dream Team. The Soviet national team reached the final of Euro 1988. In 1956 and 1988, the Soviet Union won gold at the Olympic football tournament. Russian clubs CSKA Moscow and Zenit St Petersburg won the UEFA Cup in 2005 and 2008 respectively. The Russian national football team reached the semi-finals of Euro 2008, losing only to the eventual champions Spain. Russia will host the 2018 FIFA World Cup, with 11 host cities located in the European part of the country and in the Ural region.
In 2007, the Russian national basketball team won the European Basketball Championship. Russian basketball club PBC CSKA Moscow is one of the top teams in Europe, winning the Euroleague in 2006 and 2008.
Larisa Latynina, who currently holds the record for the most gold Olympic medals won by a woman (and held the record for most Olympic medals won per person from 1964 until 2012 when swimmer Michael Phelps replaced her record), established the USSR as the dominant force in gymnastics for many years. Today, Russia is the leading nation in rhythmic gymnastics with Yevgeniya Kanayeva. Russian synchronized swimming is the best in the world, with almost all gold medals at Olympics and World Championships having been swept by Russians in recent decades. Figure skating is another popular sport in Russia, especially pair skating and ice dancing. With the exception of 2010 a Soviet or Russian pair has won gold at every Winter Olympics since 1964.
Since the end of the Soviet era, tennis has grown in popularity and Russia has produced a number of famous players, including Maria Sharapova, the world's highest paid female athlete. In martial arts, Russia produced the sport Sambo and renowned fighters, like Fedor Emelianenko. Chess is a widely popular pastime in Russia; from 1927, Russian grandmasters have held the world chess championship almost continuously.
The 2014 Winter Olympics were held in Sochi in the south of Russia. Russia won the largest number of medals among the participating nations with 13 gold, 11 silver, and 9 bronze medals for a total of 33 medals. Commentators evaluated the Games as having been an overall success.
Formula One is also becoming increasingly popular in Russia. In 2010 Vitaly Petrov became the first Russian to drive in Formula One. There had only been two Russian Grands Prix (in 1913 and 1914), but the Russian Grand Prix returned as part of the Formula One season in 2014, as part of a six-year deal.
National holidays and symbols.
There are seven public holidays in Russia, except those always celebrated on Sunday. Russian New Year traditions resemble those of the Western Christmas, with New Year Trees and gifts, and Ded Moroz (Father Frost) playing the same role as Santa Claus. Orthodox Christmas falls on 7 January, because Russian Orthodox Church still follows the Julian calendar and all Orthodox holidays are 13 days after Western ones. Another two major Christian holidays are Easter and Trinity Sunday. Kurban Bayram and Uraza Bayram are celebrated by Russian Muslims.
Further Russian public holidays include Defender of the Fatherland Day (23 February), which honors Russian men, especially those serving in the army; International Women's Day (8 March), which combines the traditions of Mother's Day and Valentine's Day; Spring and Labor Day (1 May); Victory Day; Russia Day (12 June); and Unity Day (4 November), commemorating the popular uprising which expelled the Polish occupation force from Moscow in 1612.
Victory Day is the second most popular holiday in Russia; it commemorates the victory over Nazism in the Great Patriotic War. A huge military parade, hosted by the President of Russia, is annually organised in Moscow on Red Square. Similar parades took place in all major Russian cities and cities with the status "Hero city" or "City of Military Glory".
Popular non-public holidays include Old New Year (New Year according to Julian Calendar on 14 January), Tatiana Day (students holiday on 25 January), Maslenitsa (a pre-Christian spring holiday a week before the Great Lent), Cosmonautics Day (in tribute to the first human trip into space), Ivan Kupala Day (another pre-Christian holiday on 7 July) and Peter and Fevronia Day (taking place on 8 July and being the Russian analogue of Valentine's Day, which focuses, however, on the family love and fidelity).
State symbols of Russia include the Byzantine double-headed eagle, combined with St. George of Moscow in the Russian coat of arms. The Russian flag dates from the late Tsardom of Russia period and has been widely used since the time of the Russian Empire. The Russian anthem shares its music with the Soviet Anthem, though not the lyrics. The imperial motto "God is with us" and the Soviet motto "Proletarians of all countries, unite!" are now obsolete and no new motto has replaced them. The hammer and sickle and the full Soviet coat of arms are still widely seen in Russian cities as a part of old architectural decorations. The Soviet Red Stars are also encountered, often on military equipment and war memorials. The Red Banner continues to be honored, especially the Banner of Victory of 1945.
The Matryoshka doll is a recognizable symbol of Russia, and the towers of Moscow Kremlin and Saint Basil's Cathedral in Moscow are main Russia's architectural icons. Cheburashka is a mascot of the Russian national Olympic team. St. Mary, St. Nicholas, St. Andrew, St. George, St. Alexander Nevsky, St. Sergius of Radonezh and St. Seraphim of Sarov are Russia's patron saints. Chamomile is the national flower, while birch the national tree. The Russian bear is an animal symbol and a national personification of Russia, though this image has a Western origin and Russians themselves have accepted it only fairly recently. The native Russian national personification is Mother Russia.
Tourism.
Tourism in Russia has seen rapid growth since the late Soviet times, first domestic tourism and then international tourism, fueled by the rich cultural heritage and great natural variety of the country. Major tourist routes in Russia include a journey around the Golden Ring of ancient cities, cruises on the big rivers like the Volga, and long journeys on the famous Trans-Siberian Railway. In 2013, Russia was visited by 28.4 million tourists, it is the ninth most visited country in the world and the seventh most visited in Europe.
The most visited destinations in Russia are Moscow and Saint Petersburg, the current and the former capitals of the country. Recognized as World Cities, they feature such world-renowned museums as Tretyakov Gallery and Hermitage, famous theaters like Bolshoi and Mariinsky, ornate churches like Saint Basil's Cathedral, Cathedral of Christ the Saviour, Saint Isaac's Cathedral and Church of the Savior on Blood, impressive fortifications like Moscow Kremlin and Peter and Paul Fortress, beautiful squares and streets like Red Square, Palace Square, Tverskaya Street and Nevsky Prospect. Rich palaces and parks are found in the former imperial residences in suburbs of Moscow (Kolomenskoye, Tsaritsyno) and St Petersburg (Peterhof, Strelna, Oranienbaum, Gatchina, Pavlovsk and Tsarskoye Selo). Moscow displays the Soviet architecture at its best, along with modern skyscrapers, while St Petersburg, nicknamed "Venice of the North", boasts of its classical architecture, many rivers, channels and bridges.
Kazan, the capital of Tatarstan, shows a mix of Christian Russian and Muslim Tatar cultures. The city has registered a brand "The Third Capital of Russia", though a number of other major cities compete for this status, including Novosibirsk, Yekaterinburg and Nizhny Novgorod.
The warm subtropical Black Sea coast of Russia is the site for a number of popular sea resorts, like Sochi, the follow-up host of the 2014 Winter Olympics. Large artificial Federation Island in the sea near the Sochi of Khostinsky City District is shaped like the Russian Federation and host hotels and offices. The mountains of the Northern Caucasus contain popular ski resorts, including Dombay. The most famous natural destination in Russia is Lake Baikal, "the Blue Eye of Siberia". This unique lake, oldest and deepest in the world has crystal-clean waters and is surrounded by taiga-covered mountains. Other popular natural destinations include Kamchatka with its volcanoes and geysers, Karelia with its lakes and granite rocks, the snowy Altai Mountains, and the wild steppes of Tyva.

</doc>
<doc id="25400" url="http://en.wikipedia.org/wiki?curid=25400" title="Rational choice theory">
Rational choice theory

Rational choice theory, also known as choice theory or rational action theory, is a framework for understanding and often formally modeling social and economic behavior. Rationality, interpreted as "wanting more rather than less of a good", is widely used as an assumption of the behavior of individuals in microeconomic models and analysis and appears in almost all economics textbook treatments of human decision-making. It is also central to some of modern political science, sociology, and philosophy. It attaches "wanting more" to instrumental rationality, which involves seeking the most cost-effective means to achieve a specific goal without reflecting on the worthiness of that goal. Gary Becker was an early proponent of applying rational actor models more widely. Becker won the 1992 Nobel Memorial Prize in Economic Sciences for his studies of discrimination, crime, and human capital.
Definition and scope.
The "rationality" described by rational choice theory is different from the colloquial and most philosophical use of the word. Typically, "rationality" means "sane" or "in a thoughtful clear-headed manner." Rational choice theory uses a specific and narrower definition of "rationality" simply to mean that an individual acts "as if" balancing costs against benefits to arrive at action that maximizes personal advantage. In rational choice theory, all decisions, crazy or sane, are postulated as mimicking such a "rational" process. Thus rationality is seen as a property of patterns of choices, rather than of individual choices: there is nothing irrational in preferring fish to meat the first time, but there is something irrational in preferring fish to meat "and" preferring meat to fish, regularly.
Early neoclassical economists writing about rational choice, including William Stanley Jevons, assumed that agents make consumption choices as to maximize their happiness. Twentieth century refinements of rational choice theory have eliminated such presumptions. In essence, the rationality assumed under modern rational choice theory is considerably narrower than its name might suggest—it mandates just a consistent ranking of choice alternatives.:501 Contemporary work done under the rational choice theory paradigm typically does not investigate the origins, nature, or validity of the vast array of human motivations of human desire.
Although models used in rational choice theory are diverse, all assume that individuals choose the best action according to personal identificative functions, and constraints facing them. Most idealistic models have additional assumptions. The proponents of rational choice models associated with the Chicago school of economics do not claim that a model's assumptions are a full description of reality, only that good or bad models can aid reasoning and provide help in formulating falsifiable hypothesis, whether intuitive or not. In this view, the only way to judge the success of a hypothesis is empirical tests. To use an example from Milton Friedman, if a theory that says that the behavior of the leaves of a tree is explained by their rationality passes the empirical test, it is seen as successful. Personal rationality is not seen as an egotistical good, but rather a utilitarianistic one under certain circumstances.
However, it may not be possible to empirically test or falsify the rationality assumption, so that the theory leans heavily toward being a tautology (true by definition) since there is no effort to explain individual goals. Nonetheless, empirical tests can be conducted on some of the results derived from the models. In recent years the theoretical vision of rational choice theory has been subject to more and more doubt by the experimental results of behavioral economics. This criticism has encouraged many social scientists to utilize concepts of bounded rationality to replace the "absolute" rationality of rational choice theory: this points to the difficulties of data-processing and decision-making associated with many choices in economics, political science, and sociology. More economists these days are learning from other fields, such as psychology, in order to get a more accurate view of human decision-making than offered by rational choice theory. For example, the behavioral economist and experimental psychologist Daniel Kahneman won the Nobel Memorial Prize in Economic Sciences in 2002 for his work in this field.
Because of the relative success of economics at understanding markets, rational choice theory has also become increasingly employed in social sciences other than economics, such as sociology and political science in recent decades. It has had far-reaching impacts on the study of political science, especially in fields like the study of interest groups, elections, behaviour in legislatures, coalitions, and bureaucracy. Models that rely on rational choice theory often adopt methodological individualism, the assumption that social situations or collective behaviors are the result of individual actions alone, with no role for larger institutions. The poor fit between this and a sociological conception of social situations partially explains the theory's limited use in sociology. Among other things, sociology's emphasis on the determination of individual tastes and perspectives by social institutions often conflicts with rational choice theory's methodological assumption that tastes and perspectives are given and static.
Actions, assumptions, and individual preferences.
The basic idea of rational choice theory is that patterns of behavior in societies reflect the choices made by individuals as they try to maximize their benefits and minimize their costs. In other words, people make decisions about how they should act by comparing the costs and benefits of different courses of action. As a result, patterns of behavior will develop within the society that result from those choices.
The idea of rational choice, where people compare the costs and benefits of certain actions, is easy to see in economic theory. Since people want to get the most useful products at the lowest price, they will judge the benefits of a certain object (for example, how useful is it or how attractive is it) compared to similar objects. Then they will compare prices (or costs). In general, people will choose the object that provides the greatest reward at the lowest cost.
Rational decision making entails choosing a "rational" action given one's preferences, the actions one could take, and expectations about the outcomes of those actions. Actions are often expressed as a set, for example a set of "j" exhaustive and exclusive actions:
For example, if a person is to vote for either Roger or Sara or to abstain, their set of possible voting actions is:
Individuals can also have similar sets of possible outcomes.
Rational choice theory makes three assumptions about individuals' preferences for actions:
Taken together, these assumptions imply that given a set of exhaustive and exclusive actions to choose from, an individual can rank the elements of this set in terms of his preferences, this preference structure is internally consistent, and the set has at least one maximal element.
An individual's preferences can also take forms:
In more complex models, other assumptions are often incorporated, such as the assumption of independence axiom. Also, with dynamic models that include decision-making over time, time inconsistency may affect an individual's preferences.
Research that took off in the 1980s sought to develop models which drop these assumptions and argue that such behaviour could still be rational, Anand (1993). This work, often conducted by economic theorists and analytical philosophers, suggests ultimately that the assumptions or axioms above are not completely general and might at best be regarded as approximations.
Other assumptions.
At the same time, is often claimed from behavioural or social disciplines that rational choice theory makes some descriptively unrealistic assumptions in order to generate tractable and testable predictions. These can include:
Alternative theories of human action include such components as Amos Tversky and Daniel Kahneman's prospect theory, which reflects the empirical finding as that, contrary to standard preferences assumed under neoclassical economics, individuals attach extra value to items that they already own compared to similar items owned by others. Under standard preferences, the amount that an individual is willing to pay for an item (such as a drinking mug) is assumed to equal the amount he or she is willing to be paid in order to part with it. In experiments, the latter price is sometimes significantly higher than the former (but see Plott and Zeiler 2005, Plott and Zeiler 2007 and Klass and Zeiler, 2013 ). Tversky and Kahneman do not characterize loss aversion as irrational. Behavioral economics includes a large number of other amendments to its picture of human behavior that go against neoclassical assumptions.
Utility maximization.
Often preferences are described by their utility function or "payoff function". This is an ordinal number an individual assigns over the available actions, such as:
The individual's preferences are then expressed as the relation between these ordinal assignments. For example, if an individual prefers the candidate Sara over Roger over abstaining, their preferences would have the relation:
Criticism.
Both the assumptions and the behavioral predictions of rational choice theory have sparked criticism from various camps. As mentioned above, some economists have developed models of bounded rationality, which hope to be more psychologically plausible without completely abandoning the idea that reason underlies decision-making processes. Other economists have developed more theories of human decision-making that allow for the roles of uncertainty, institutions, and determination of individual tastes by their socioeconomic environment (cf. Fernandez-Huerga, 2008).
Martin Hollis and Edward J. Nell's 1975 book offers both a philosophical critique of neo-classical economics and an innovation in the field of economic methodology. Further they outlined an alternative vision to neo-classicism based on a rationalist theory of knowledge. Within neo-classicism, the authors addressed consumer behaviour (in the form of indifference curves and simple versions of revealed preference theory) and marginalist producer behaviour in both product and factor markets. Both are based on rational optimizing behaviour. They consider imperfect as well as perfect markets since neo-classical thinking embraces many market varieties and disposes of a whole system for their classification. However, the authors believe that the issues arising from basic maximizing models have extensive implications for econometric methodology (Hollis and Nell, 1975, p. 2). In particular it is this class of models – rational behavior as maximizing behaviour – which provide support for specification and identification. And this, they argue, is where the flaw is to be found. Hollis and Nell (1975) argued that positivism (broadly conceived) has provided neo-classicism with important support, which they then show to be unfounded. They base their critique of neo-classicism not only on their critique of positivism but also on the alternative they propose, rationalism. Indeed, they argue that rationality is central to neo-classical economics – as rational choice – and that this conception of rationality is misused. Demands are made of it that it cannot fulfill.
In their 1994 work, "Pathologies of Rational Choice Theory", Donald P. Green and Ian Shapiro argue that the empirical outputs of rational choice theory have been limited. They contend that much of the applicable literature, at least in political science, was done with weak statistical methods and that when corrected many of the empirical outcomes no longer hold. When taken in this perspective, rational choice theory has provided very little to the overall understanding of political interaction - and is an amount certainly disproportionately weak relative to its appearance in the literature. Yet, they concede that cutting edge research, by scholars well-versed in the general scholarship of their fields (such as work on the U.S. Congress by Keith Krehbiel, Gary Cox, and Mat McCubbins) has generated valuable scientific progress.
Duncan K. Foley (2003, p. 1) has also provided an important criticism of the concept of "rationality" and its role in economics. He argued that“Rationality” has played a central role in shaping and establishing the hegemony of contemporary mainstream economics. As the specific claims of robust neoclassicism fade into the history of economic thought, an orientation toward situating explanations of economic phenomena in relation to rationality has increasingly become the touchstone by which mainstream economists identify themselves and recognize each other. This is not so much a question of adherence to any particular conception of rationality, but of taking rationality of individual behavior as the unquestioned starting point of economic analysis.
Foley (2003, p. 9) went on to argue thatThe concept of rationality, to use Hegelian language, represents the relations of modern capitalist society one-sidedly. The burden of rational-actor theory is the assertion that ‘naturally’ constituted individuals facing existential conflicts over scarce resources would rationally impose on themselves the institutional structures of modern capitalist society, or something approximating them. But this way of looking at matters systematically neglects the ways in which modern capitalist society and its social relations in fact constitute the ‘rational’, calculating individual. The well-known limitations of rational-actor theory, its static quality, its logical antinomies, its vulnerability to arguments of infinite regress, its failure to develop a progressive concrete research program, can all be traced to this starting-point.
Schram and Caterino (2006) contains a fundamental methodological criticism of rational choice theory for promoting the view that the natural science model is the only appropriate methodology in social science and that political science should follow this model, with its emphasis on quantification and mathematization. Schram and Caterino argue instead for methodological pluralism. The same argument is made by William E. Connolly, who in his work Neuropolitics shows that advances in neuroscience further illuminate some of the problematic practices of rational choice theory.
More recently Edward J. Nell and Karim Errouaki (2011, Ch. 1) argued that:The DNA of neoclassical economics is defective. Neither the induction problem nor the problems of methodological individualism can be solved within the framework of neoclassical assumptions. The neoclassical approach is to call on rational economic man to solve both. Economic relationships that reflect rational choice should be ‘projectible’. But that attributes a deductive power to ‘rational’ that it cannot have consistently with positivist (or even pragmatist) assumptions (which require deductions to be simply analytic). To make rational calculations projectible, the agents may be assumed to have idealized abilities, especially foresight; but then the induction problem is out of reach because the agents of the world do not resemble those of the model. The agents of the model can be abstract, but they cannot be endowed with powers actual agents could not have. This also undermines methodological individualism; if behaviour cannot be reliably predicted on the basis of the ‘rational choices of agents’, a social order cannot reliably follow from the choices of agents.
Furthermore, Pierre Bourdieu fiercely opposed rational choice theory as grounded in a misunderstanding of how social agents operate. Bourdieu argued that social agents do not continuously calculate according to explicit rational and economic criteria. According to Bourdieu, social agents operate according to an implicit practical logic—a practical sense—and bodily dispositions. Social agents act according to their "feel for the game" (the "feel" being, roughly, habitus, and the "game" being the field).
Other social scientists, inspired in part by Bourdieu's thinking have expressed concern about the inappropriate use of economic metaphors in other contexts, suggesting that this may have political implications. The argument they make is that by treating everything as a kind of "economy" they make a particular vision of the way an economy works seem more natural. Thus, they suggest, rational choice is as much ideological as it is scientific, which does not in and of itself negate its scientific utility.
An evolutionary psychology perspective is that many of the seeming contradictions and biases regarding rational choice can be explained as being rational in the context of maximizing biological fitness in the ancestral environment but not necessarily in the current one. Thus, when living at subsistence level where a reduction of resources may have meant death it may have been rational to place a greater value on losses than on gains. It may also explain differences between groups such as males being less risk-averse than females since males have more variable reproductive success than females. While unsuccessful risk-seeking may limit reproductive success for both sexes, males may potentially increase their reproductive success much more than females from successful risk-seeking.
Benefits.
The rational choice approach allows preferences to be represented as real-valued utility functions. Economic decision making then becomes a problem of maximizing this utility function, subject to constraints (e.g. a budget). This has many advantages. It provides a compact theory that makes empirical predictions with a relatively sparse model - just a description of the agent's objectives and constraints. Furthermore, optimization theory is a well-developed field of mathematics. These two factors make rational choice models tractable compared to other approaches to choice. Most importantly, this approach is strikingly general. It has been used to analyze not only personal and household choices about
traditional economic matters like consumption and savings, but also choices about education, marriage, child-bearing, migration, crime and so on, as well as business decisions about output, investment, hiring, entry, exit, etc. with varying degrees of success.
Despite the empirical shortcomings of rational choice theory, the flexibility and tractability of rational choice models (and the lack of equally powerful alternatives) ensure that they will remain an important part of economic analysis in the near future.

</doc>
<doc id="25401" url="http://en.wikipedia.org/wiki?curid=25401" title="Romance languages">
Romance languages

The Romance languages— sometimes called the Latin languages, and occasionally the Romanic or Neo-Latin languages—are the group of modern languages that evolved from spoken Latin between the sixth and ninth centuries A.D. and that thus form a branch of the Italic languages within the Indo-European language family.
Today, more than 800 million people are native speakers worldwide, mainly in Europe and the Americas, but also in many smaller regions scattered throughout the world. Additionally, the major Romance languages have many non-native speakers and enjoy widespread use as lingua francas. This is especially the case for French, which is in widespread use throughout Central and West Africa, Madagascar, Mauritius and the Maghreb region.
The five most widely spoken Romance languages by number of native speakers are Spanish (410 million), Portuguese (216 million), French (75 million), Italian (60 million), and Romanian (25 million).
Because of the difficulty of imposing boundaries on a continuum, various counts of the Romance languages are given; Dalby lists 23 based on mutual intelligibility:
In several of these cases, more than one variety has been standardized, so is considered a distinct language in the popular conception; this is true, for example, with Asturian and Leonese, as well as Neapolitan and Sicilian.
The constructed language Interlingua, developed between 1937 and 1951, is also considered by some to be a Romance language, because it derives most of its vocabulary and grammar from French, Italian, Portuguese and Spanish, but with grammatical features not present in English, German, and Russian removed. Its proponents claim written Interlingua is intelligible to anyone who speaks a Romance language—indeed, this was the goal of the creators.
Origins.
Romance languages are the continuation of Vulgar Latin, the popular and colloquial sociolect of Latin spoken by soldiers, settlers, and merchants of the Roman Empire, as distinguished from the classical form of the language spoken by the Roman upper classes, the form in which the language was generally written. Between 350 BC and AD 150, the expansion of the Empire, together with its administrative and educational policies, made Latin the dominant native language in continental Western Europe. Latin also exerted a strong influence in southeastern Britain, the Roman province of Africa, the Roman province of Asia and the Balkans north of the Jireček Line.
During the Empire's decline, and after its fragmentation and collapse in the fifth century, varieties of Latin began to diverge within each local area at an accelerated rate and eventually evolved into a continuum of recognizably different typologies. The overseas empires established by Portugal, Spain, and France from the fifteenth century onward spread their languages to the other continents to such an extent that about two-thirds of all Romance language speakers today live outside Europe.
Despite other influences (e.g. "substratum" from pre-Roman languages, especially Continental Celtic languages; and "superstratum" from later Germanic or Slavic invasions), the phonology, morphology, and lexicon of all Romance languages consist mainly of evolved forms of Vulgar Latin. However, some notable differences occur between today's Romance languages and their Roman ancestor. With only one or two exceptions, Romance languages have lost the declension system of Latin and, as a result, have SVO sentence structure and make extensive use of prepositions.
Name.
The term "Romance" comes from the Vulgar Latin adverb "romanice", derived from "Romanicus": for instance, in the expression "romanice loqui", "to speak in Roman" (that is, the Latin vernacular), contrasted with "latine loqui", "to speak in Latin" (Medieval Latin, the conservative version of the language used in writing and formal contexts or as a lingua franca), and with "barbarice loqui", "to speak in Barbarian" (the non-Latin languages of the peoples living outside the Roman Empire). From this adverb the noun "romance" originated, which applied initially to anything written "romanice", or "in the Roman vernacular".
The word 'romance' with the modern sense of romance novel or love affair has the same origin. In the medieval literature of Western Europe, serious writing was usually in Latin, while popular tales, often focusing on love, were composed in the vernacular and came to be called "romances".
Samples.
Lexical and grammatical similarities among the Romance languages, and between Latin and each of them, are apparent from the following examples having the same meaning in various Romance lects:
English: She always closes the window before she dines
Some of the divergence comes from semantic change: where the same root word has developed different meanings. For example, the Portuguese word "fresta" is descended from Latin "fenestra" "window" (and is thus cognate to French "fenêtre", Italian "finestra", Romanian "fereastră" and so on), but now means "skylight" and "slit". Cognates may exist but have become rare, such as "finiestra" in Spanish, or dropped out of use entirely. The Spanish and Portuguese terms "defenestrar" meaning "to throw through a window" and "fenestrado" meaning "replete with windows" also have the same root, but are later borrowings from Latin.
Likewise, Portuguese also has the word "cear", a cognate of Italian "cenare" and Spanish "cenar", but uses it in the sense of "to have a late supper" in most varieties, while the preferred word for "to dine" is "jantar" (related to archaic Spanish "yantar" "to eat") because of semantic changes in the 19th century. Galician has both "fiestra" (from medieval "fẽestra", the ancestor of standard Portuguese "fresta") and the less frequently used "ventá" and "xanela".
As an alternative to "lei" (originally the genitive form), Italian has the pronoun "ella", a cognate of the other words for "she", but it is hardly ever used in speaking.
Spanish, Asturian, and Leonese "ventana" and Mirandese and Sardinian "bentana" come from Latin "ventus" "wind" (cf. English "window", etymologically 'wind eye'), and Portuguese "janela", Galician "xanela", Mirandese "jinela" from Latin *"ianuella" "small opening", a derivative of "ianua" "door".
Sardinian "balcone" (alternative for "ventàna"/"bentàna") comes from Old Italian and is similar to other Romance languages such as French "balcon" (from Italian "balcone"), Portuguese "balcão", Romanian "balcon", Spanish "balcón", Catalan "balcó" and Corsican "balconi" (alternative for "purtellu").
History.
Vulgar Latin.
Documentary evidence is limited about Vulgar Latin for the purposes of comprehensive research, and the literature is often hard to interpret or generalize. Many of its speakers were soldiers, slaves, displaced peoples, and forced resettlers, more likely to be natives of conquered lands than natives of Rome.
Vulgar Latin is believed to have already had most of the features shared by all Romance languages, which distinguish them from Classical Latin, such as the almost complete loss of the Latin case system and its replacement by prepositions; the loss of the neuter gender and comparative inflections; replacement of some verb paradigms by innovations (e.g. the synthetic future gave way to an originally analytic strategy now typically formed by infinitive + evolved present indicative forms of 'have'); the use of articles; and the initial stages of the palatalization of the plosives /k/, /g/, and /t/.
To some scholars, this suggests the form of Vulgar Latin that evolved into the Romance languages was around during the time of the Roman Empire (from the end of the first century BC), and was spoken alongside the written Classical Latin which was reserved for official and formal occasions. Other scholars argue that the distinctions are more rightly viewed as indicative of sociolinguistic and register differences normally found within any language.
Fall of the Western Roman Empire.
During the political decline of the Western Roman Empire in the fifth century, there were large-scale migrations into the empire, and the Latin-speaking world was fragmented into several independent states. Central Europe and the Balkans were occupied by the Germanic and Slavic tribes, as well as by the Huns, which isolated the Vlachs from the rest of Latin Europe.
British Romance and African Romance, the forms of Vulgar Latin used in southeastern Britain and the Roman province of Africa, where it had been spoken by much of the urban population, disappeared in the Middle Ages (as did Pannonian Romance in what is now Hungary). But the Germanic tribes that had penetrated Italy, Gaul, and Hispania eventually adopted Latin/Romance and the remnants of Roman culture alongside existing inhabitants of those regions, and so Latin remained the dominant language there.
Early Romance.
Over the course of the 4th–8th centuries AD, Vulgar Latin, by this time highly dialectalized, broke up into discrete languages that were no longer mutually intelligible.:5 Clear evidence of Latin change comes from the Reichenau Glosses, an 8th-century compilation of about 1,200 words from the 4th-century Latin Vulgate Bible (St. Jerome) that were no longer intelligible along with their 8th-century equivalents in proto-Franco-Provençal. The following are some examples with reflexes in several modern, closely related Romance languages for comparison:
In all of the above examples, the words appearing in the fourth century Vulgate are the same words as would have been used in Classical Latin of c. 50 BC. It is likely that some of these words had already disappeared from casual speech; but if so, they must have been still widely understood, as there is no recorded evidence that the common people of the time had difficulty understanding the language.
By the 8th century, the situation was very different. During the late 8th century, Charlemagne, holding that "Latin of his age was by classical standards intolerably corrupt",:6 successfully imposed Classical Latin as an artificial written vernacular for Western Europe. Unfortunately, this meant that parishioners could no longer understand the sermons of their priests, forcing the Council of Tours in 813 to issue an edict that priests needed to translate their speeches into the "rustica romana lingua", an explicit acknowledgement of the reality of the Romance languages as separate languages from Latin.:6 By this time, and possibly as early as the 6th century according to Price (1984),:6 the Romance lects had split apart enough to be able to speak of separate Gallo-Romance, Ibero-Romance, Italo-Romance and Eastern Romance languages. Some researchers have postulated that the major divergences in the spoken dialects began in the 5th century, as the formerly widespread and efficient communication networks of the Western Roman Empire rapidly broke down, leading to the total disappearance of the Western Roman Empire by the end of the century. Unfortunately, the critical period between the 5th–10th centuries AD is poorly documented because little or no writing from the chaotic "Dark Ages" of the 5th–8th centuries has survived, and writing after that time was in consciously classicized Medieval Latin, with vernacular writing only beginning in earnest in the 11th or 12th centuries.
Recognition of the vernaculars.
Between the 10th and 13th centuries, some local vernaculars developed a written form and began to supplant Latin in many of its roles. In some countries, such as Portugal, this transition was expedited by force of law; whereas in others, such as Italy, many prominent poets and writers used the vernacular of their own accord – some of the most famous in Italy being Giacomo da Lentini and Dante Alighieri.
Uniformization and standardization.
The invention of the printing press brought a tendency towards greater uniformity of standard languages within political boundaries, at the expense of other Romance languages and dialects less favored politically. In France, for instance, the dialect spoken in the region of Paris gradually spread to the entire country, and the Occitan of the south lost ground.
Modern status.
The Romance language most widely spoken natively today is Spanish (Castilian), followed by Portuguese, French, Italian, Romanian and Catalan, which together cover a vast territory in Europe and beyond, and work as official and national languages in dozens of countries. Galician, with more than a million native speakers, is official together with Spanish in Galicia, and has legal recognition in neighbouring territories in Castilla y León. A few other languages have official recognition on a regional or otherwise limited level; for instance, Asturian and Aragonese in Spain; Mirandese in Portugal; Friulan, Sardinian and Franco-Provençal in Italy; and Romansh in Switzerland.
French, Italian, Portuguese, Spanish, and Romanian are also official languages of the European Union. Spanish, Portuguese, French, Italian, Romanian, and Catalan are the official languages of the Latin Union; and French and Spanish are two of the six official languages of the United Nations.
Outside of Europe, French, Portuguese and Spanish are spoken and enjoy official status in various countries that emerged from the respective colonial empires. French is one of the official languages of Canada, and it also has official status in many countries of Africa, as well as in some island nations in the Indian and Pacific Oceans.
Spanish is an official language in approximately half of South America (nine countries), in Central America (except Belize), in Mexico, and—in the Caribbean—in Cuba, the Dominican Republic, and Puerto Rico. It is also the official language of Equatorial Guinea in Africa.
Portuguese, in its original homeland, Portugal, is spoken by virtually the entire population of 10 million.
As the official language of Brazil, it is spoken by some 200 million people in that country, as well as by neighboring residents of eastern Paraguay and northern Uruguay, accounting for about half the population of South America. It is the official language of six African countries (Angola, Cape Verde, Guinea-Bissau, Mozambique, Equatorial Guinea, and São Tomé and Príncipe), and is spoken as a first language by perhaps 25 million residents of that continent. In Asia, Portuguese is co-official with other languages in East Timor and Macau, while most Portuguese-speakers in Asia—some 400,000—are in Japan due to return immigration of Japanese Brazilians. In North America 1,000,000 people speak Portuguese as their home language.
In Oceania, Portuguese is the second most spoken Romance language, after French, due mainly to the number of speakers in East Timor. Its closest relative, Galician (and Spanish) possesses official status in the autonomous community of Galicia in Spain, together with Spanish.
Although Italy also had some colonial possessions, its language did not remain official after the end of the colonial domination, resulting in Italian being spoken only as a minority or secondary language by immigrant communities in North and South America, Australia, and some African countries, notably former Italian colonies Libya, Eritrea and Somalia, where it is spoken by a few educated people in commerce and government. Romania did not establish a colonial empire, but beyond its native territory in Southeastern Europe, it also spread to other countries on the Mediterranean (especially the other Romance countries, most notably Italy and Spain), and elsewhere such as Israel, where it is the native language of five percent of the population, and is spoken by many more as a secondary language; this is due to the large numbers of Romanian-born Jews who moved to Israel after World War II. Some 2.6 million people in the former Soviet republic of Moldova speak a variety of Romanian, called variously Moldovan or Romanian by them.
The total native speakers of Romance languages are divided as follows (with their ranking within the languages of the world in brackets):
Catalan is unusual in that it is not the main language of any nation-state, other than Andorra (a microstate between Spain and France), but nonetheless has been able to compete and even gain speakers at the expense of the dominant language of its nation (Spanish); in fact, Catalan is the only minority European language whose long-term survival is probably not under threat. This is because unlike most minority-languages, Catalan has not remained linked to tradition and rural culture.
Catalan was used for high-level culture in the Middle Age and early modern times, and again from the 21st century. Besides it, a rich and lively popular culture (songs, literature, theatre, newspapers) has always existed and evolved in accordance with times. The result is a Catalan national feeling surviving the kingdoms union, and the belief that the Catalan language is a critical component of the separate ethnic identity of the Catalan people. This has allowed them to resist the historic persecutions and high immigration rates as well as the assimilationist urges that are in the process of destroying most of the remaining minority-language communities, even those that have strong government support (e.g. Irish language speakers).
The remaining Romance languages survive mostly as spoken languages for informal contact. National governments have historically viewed linguistic diversity as an economic, administrative or military liability, as well as a potential source of separatist movements; therefore, they have generally fought to eliminate it, by extensively promoting the use of the official language, restricting the use of the "other" languages in the media, characterizing them as mere "dialects", or even persecuting them. As a result, all of these languages are considered endangered to varying degrees according to the UNESCO Red Book of Endangered Languages, ranging from "vulnerable" (e.g. Sicilian and Venetian) to "severely endangered" (Arpitan, most of the Occitan varieties).
Since the late twentieth and early twenty-first centuries, increased sensitivity to the rights of minorities has allowed some of these languages to start recovering their prestige and lost rights. Yet it is unclear whether these political changes will be enough to reverse the decline of minority Romance languages.
Classification and related languages.
The classification of the Romance languages is inherently difficult, since most of the linguistic area can be considered a dialect continuum, and in some cases political biases can come into play. Along with Latin (which is not included among the Romance languages) and a few extinct languages of ancient Italy, they make up the Italic branch of the Indo-European family.
Proposed divisions.
There are various schemes used to subdivide the Romance languages. Three of the most common schemes are as follows:
The main subfamilies that have been proposed by Ethnologue within the various classification schemes for Romance languages are:
The three-way division is made primarily based on the outcome of Vulgar Latin (Proto-Romance) vowels:
Italo-Western is in turn split along the so-called "La Spezia–Rimini Line" in northern Italy, which divides the central and southern Italian languages from the so-called Western Romance languages to the north and west. The primary characteristics dividing the two are:
In fact, the reality is somewhat more complex. All of the "southeast" characteristics apply to all languages southeast of the line, and all of the "northwest" characteristics apply to all languages in France and (most of) Spain. However, the Gallo-Italic languages and the Rhaeto-Romance languages of Switzerland and Italy are somewhere in between. All of these languages do have the "northwest" characteristics of lenition and loss of gemination. However:
On top of this, the ancient Mozarabic language in southern Spain, at the far end of the "northwest" group, had the "southeast" characteristics of lack of lenition and palatalization of /k/ to /tʃ/. Certain languages around the Pyrenees (e.g. some highland Aragonese dialects) also lack lenition, and northern French dialects such as Norman and Picard have palatalization of /k/ to /tʃ/ (although this is possibly an independent, secondary development, since /k/ between vowels, i.e. when subject to lenition, developed to /dz/ rather than /dʒ/, as would be expected for a primary development).
The usual solution to these issues is to create various nested subgroups. Western Romance is split into the Gallo-Iberian languages, in which lenition happens and which include nearly all the Western Romance languages, and the Pyrenean-Mozarabic group, which includes the remaining languages without lenition (and is unlikely to be a valid clade; probably at least two clades, one for Mozarabic and one for Pyrenean). Gallo-Iberian is split in turn into the Iberian languages (e.g. Spanish and Portuguese), and the larger Gallo-Romance languages (stretching from eastern Spain to northeast Italy).
Probably a more accurate description, however, would be to say that there was a focal point of innovation located in central France, from which a series of innovations spread out as areal changes. The La Spezia–Rimini Line represents the farthest point to the southeast that these innovations reached, corresponding to the northern chain of the Apennine Mountains, which cuts straight across northern Italy and forms a major geographic barrier to further language spread.
This would explain why some of the "northwest" features (almost all of which can be characterized as innovations) end at differing points in northern Italy, and why some of the languages in geographically remote parts of Spain (in the south, and high in the Pyrenees) are lacking some of these features. It also explains why the languages in France (especially standard French) seem to have innovated earlier and more completely than other Western Romance languages.
Many of the "southeast" features also apply to the Eastern Romance languages (particularly, Romanian), despite the geographic discontinuity. Examples are lack of lenition, maintenance of intertonic vowels, use of vowel-changing plurals, and palatalization of /k/ to /tʃ/. (Gemination is missing, which may be an independent development, and /kt/ develops into /pt/ rather than either of the normal Italo-Western developments.) This has led some researchers to postulate a basic two-way East-West division, with the "Eastern" languages including Romanian and central and southern Italian.
Sardinian does not fit into this picture at all. It is clear that Sardinian became linguistically independent from the remainder of the Romance languages at an extremely early date, possibly already by the first century BC. Sardinian contains a large number of archaic features, including total lack of palatalization of /k/ and /g/ and a large amount of vocabulary preserved nowhere else, including some items already archaic by the time of Classical Latin (first century BC). Sardinian has plurals in /s/ but no lenition of voiceless consonants (at least in most conservative Nuorese dialects) and a number of innovations unseen elsewhere: most famously, its unique vowel system, but also development of /au/ to /a/, a peculiar sort of lenition that operates as a synchronic feature, and use of "su" < "ipsum" as an article (another archaic feature, also seen in the Catalan of the Balearic Islands and formerly more widespread in Occitano-Romance, known as "article salat" – the "salat" article, or literally the "salted" article).
Gallo-Romance languages.
The Gallo-Romance languages are generally considered the most innovative (least conservative) among the Romance languages. Northern France—the medieval area of the langue d'oïl, out of which modern French developed—was the epicenter. Characteristic Gallo-Romance features generally developed earliest and appear in their most extreme manifestation in the langue d'oïl, gradually spreading out from there along riverways and transalpine roads. It is not coincidental that the earliest vernacular Romance writing occurred in Northern France: Generally, the development of vernacular writing in a given area was forced by the almost total inability of Romance speakers to understand the Classical Latin that still served as the vehicle of writing and culture.
Gallo-Romance languages as a whole are usually characterized by the loss of all unstressed final vowels other than /-a/ (most significantly, final /-o/ and /-e/ were lost). However, when the loss of a final vowel would result in an impossible final cluster (e.g. /tr/), a prop vowel appears in place of the lost vowel, usually /e/. Generally, the same changes also occurred in final syllables closed by a consonant.
Furthermore, loss of /e/ in a final syllable was early enough in Primitive Old French that the Classical Latin third-singular /t/ was often preserved, e.g. "venit" "he comes" > /ˈvɛːnet/ (Romance vowel changes) > /ˈvjɛnet/ (diphthongization) > /ˈvjɛned/ (lenition) > /ˈvjɛnd/ (Gallo-Romance final vowel loss) > /ˈvjɛnt/ (final devoicing). Elsewhere, final vowel loss occurred later or unprotected /t/ was lost earlier (perhaps under Italian influence).
Gallo-Romance can be divided into five subgroups:
Other than southern Occitano-Romance, the Gallo-Romance languages are quite innovatory, with French and some of the Gallo-Italian languages rivaling each other for the most extreme phonological changes compared with conservative languages. For example, French "sain, saint, sein, ceint, ceint" meaning "healthy, holy, breast, (he) girds, (was) girded" (Latin "sānum", "sanctum", "sinum", "cinget", "cinctum") are all pronounced /sɛ̃/; similarly "cent, sent, sans, sang" meaning "hundred, (he) feels, without, blood" (Latin "centum", "sentit", "(ab)sentis", "sanguen") are all pronounced /sɑ̃/.
In some ways, however, the Gallo-Romance languages are conservative. The older stages of many of the languages are famous for preserving a two-case system consisting of nominative and oblique, fully marked on nouns, adjectives and determiners, inherited almost directly from the Latin nominative and accusative cases and preserving a number of different declensional classes and irregular forms.
In the opposite of the normal pattern, the languages closest to the oïl epicenter preserve the case system the best, while languages at the periphery—near to languages that had long before lost the case system except on pronouns—lose it early. For example, the case system is well preserved in Old Occitan up through the thirteenth century or so but is totally lost in Old Catalan at the time, despite otherwise being virtually the same language at the time.
The Occitan group is known for an innovatory /ɡ/ ending on many subjunctive and preterite verbs, and an unusual development of [ð] (Latin intervocalic -d-), which in many varieties merges with [dz] (from intervocalic palatalized -c- and -ty-).
The following tables show two examples of the extensive phonological changes that French has undergone. (Compare modern Italian "saputo", "vita", even more conservative than the reconstructed Western Romance forms.)
Notable characteristics of the Gallo-Romance languages are:
The Gallo-Italian and Italian Rhaeto-Romance languages have a number of features in common with the other Italian languages:
Pidgins, creoles, and mixed languages.
Some Romance languages have developed varieties which seem dramatically restructured as to their grammars or to be mixtures with other languages. It is not always clear whether they should be classified as Romance, pidgins, creole languages, or mixed languages. Some other languages, such as English, are sometimes thought of as creoles of semi-Romance ancestry. There are several dozens of creoles of French, Spanish, and Portuguese origin, some of them spoken as national languages in former European colonies.
Creoles of French:
Creoles of Spanish:
Creoles of Portuguese:
Auxiliary and constructed languages.
Latin and the Romance languages have also served as the inspiration and basis of numerous auxiliary and constructed languages, so-called "neo-romantic languages".
The concept was first developed in 1903 by Italian mathematician Giuseppe Peano, under the title Latino sine flexione. He wanted to create a "naturalistic" international language, as opposed to an autonomous constructed language like Esperanto or Volapuk which were designed for maximal simplicity of lexicon and derivation of words. Peano used Latin as the base of his language, because at the time of his flourishing it was the "de facto" international language of scientific communication.
Other languages developed since include Idiom Neutral, Occidental, Lingua Franca Nova, and most famously and successfully, Interlingua. Each of these languages has attempted to varying degrees to achieve a pseudo-Latin vocabulary as common as possible to living Romance languages.
There are also languages created for artistic purposes only, such as Talossan. Because Latin is a very well attested ancient language, some amateur linguists have even constructed Romance languages that mirror real languages that developed from other ancestral languages. These include Brithenig (which mirrors Welsh), Breathanach (mirrors Irish), Wenedyk (mirrors Polish), Þrjótrunn (mirrors Icelandic), and Helvetian (mirrors German).
Linguistic features.
Basic features.
Romance languages have a number of shared features across all languages:
Changes from Classical Latin.
The most significant changes between Classical Latin and Proto-Romance (and hence all the modern Romance languages) relate to the reduction or loss of the Latin case system, and the corresponding syntactic changes that were triggered.
The case system was drastically reduced from the vigorous six-case system of Latin. Although four cases can be constructed for Proto-Romance nouns (nominative, accusative, combined genitive/dative, and vocative), the vocative is marginal and present only in Romanian (where it may be an outright innovation), and of the remaining cases, no more than two are present in any one language. Romanian is the only modern Romance language with case marking on nouns, with a two-way opposition between nominative/accusative and genitive/dative. Some of the older Gallo-Romance languages (in particular, Old French, Old Occitan, Old Sursilvan and Old Friulian, and in traces Old Catalan and Old Venetan) had an opposition between nominative and general oblique, and in Ibero-Romance languages, such as Spanish and Portuguese, as well as in Italian (see under Case), a couple of examples are found which preserve the old nominative. As in English, case is preserved better on pronouns.
Concomitant with the loss of cases, freedom of word order was greatly reduced. Classical Latin had a generally verb-final (SOV) but overall quite free word order, with a significant amount of word scrambling and mixing of left-branching and right-branching constructions. The Romance languages eliminated word scrambling and nearly all left-branching constructions, with most languages developing a rigid SVO, right-branching syntax. (Old French, however, had a freer word order due to the two-case system still present, as well as a predominantly verb-second word order developed under the influence of the Germanic languages.) Some freedom, however, is allowed in the placement of adjectives relative to their head noun. In addition, some languages (e.g. Spanish, Romanian) have an "accusative preposition" (Romanian "pe", Spanish "personal "a"") along with clitic doubling, which allows for some freedom in ordering the arguments of a verb.
The Romance languages developed grammatical articles where Latin had none. Articles are often introduced around the time a robust case system falls apart in order to disambiguate the remaining case markers (which are usually too ambiguous by themselves) and to serve as parsing clues that signal the presence of a noun (a function formerly served by the case endings themselves).
This was the pattern followed by the Romance languages: In the Romance languages that still preserved a functioning nominal case system (e.g. Romanian and Old French), only the combination of article and case ending serves to uniquely identify number and case (compare the similar situation in modern German). All Romance languages have a definite article (originally developed from "ipse" "self" but replaced in nearly all languages by "ille" "that (over there)") and an indefinite article (developed from "ūnus" "one"). Many also have a partitive article ("dē" "of" + definite article).
Latin had a large number of syntactic constructions expressed through infinitives, participles, and similar nominal constructs. Examples are the ablative absolute, the accusative-plus-infinitive construction used for reported speech, gerundive constructions, and the common use of reduced relative clauses expressed through participles. All of these are replaced in the Romance languages by subordinate clauses expressed with finite verbs, making the Romance languages much more "verbal" and less "nominal" than Latin. Under the influence of the Balkan sprachbund, Romanian has progressed the furthest, largely eliminating the infinitive. (It is currently being revived, however, due to the increasing influence of other Romance languages.)
Phonology.
Vowels.
Every language has a different set of vowels from every other. Common characteristics are as follows:
Consonants.
Most Romance languages have similar sets of consonants. The following is a combined table of the consonants of the five major Romance languages (French, Spanish, Italian, Portuguese, Romanian).
Key:
Notable changes:
Most instances of most of the sounds below that occur (or used to occur, as described above) in all of the languages are cognate. However:
Lexical stress.
Word stress was rigorously predictable in classical Latin except in a very few exceptional cases, either on the penultimate syllable (second from last) or antepenultimate syllable (third from last), according to the syllable weight of the penultimate syllable. Stress in the Romance Languages mostly remains on the same syllable as in Latin, but various sound changes have made it no longer so predictable. Minimal pairs distinguished only by stress exist in some languages, e.g. Italian "Papa" [ˈpa.pa] "Pope" vs. "papà" [pa.ˈpa] "daddy", or Spanish imperfect subjunctive "cantara" [kan.ˈta.ɾa] "[if he] sang" vs. future "cantará" [kan.ta.ˈɾa] "[he] will sing".
Erosion of unstressed syllables following the stress has caused most Spanish and Portuguese words to have either penultimate or ultimate stress: e.g. Latin "trēdecim" "thirteen" > Spanish "trece", Portuguese "treze"; Latin "amāre" "to love" > Spanish/Portuguese "amar". Most words with antepenultimate stress are learned borrowings from Latin, e.g. Spanish/Portuguese "fábrica" "factory" (the corresponding inherited word is Spanish "fragua", Portuguese "frágua" "forge"). This process has gone even farther in French, with deletion of all post-stressed vowels, leading to consistent, predictable stress on the last syllable: e.g. Latin "Stephanum" "Stephen" > Old French "Estievne" > French "Étienne" /e.ˈtjɛn/; Latin "juvenis" "young" > Old French "juevne" > French "jeune" /ʒœn/. This applies even to borrowings: e.g. Latin "fabrica" > French borrowing "fabrique" /fa.ˈbʀik/ (the inherited word in this case being monosyllabic "forge" < Pre-French *"fauriga").
Other than French (with consistent final stress), the position of the stressed syllable generally falls on one of the last three syllables. Exceptions may be caused by clitics or (in Italian) certain verb endings, e.g. Italian "telefonano" [teˈlɛ.fo.na.no] "they telephone"; Spanish "entregándomelo" [en.tɾe.ˈɣan.do.me.lo] "delivering it to me"; Italian "mettiamocene" [meˈtːjaː.mo.tʃe.ne] "let's put some of it in there"; Portuguese "dávamo-vo-lo" [ˈda.vɐ.mu.vu.lu] "we were giving it to you". Stress on verbs is almost completely predictable in Spanish and Portuguese, but less so in Italian.
Nominal morphology.
Nouns, adjectives, and pronouns can be marked for gender, number and case. Adjectives and pronouns must agree in all features with the noun they are bound to.
Number.
The Romance languages inherited from Latin two grammatical numbers, singular and plural; there is no trace of a dual number.
Gender.
Most Romance languages have two grammatical genders, masculine and feminine. The gender of animate nouns is generally natural (i.e. nouns referring to men are generally masculine, and vice versa), but for nonanimate nouns it is arbitrary.
Although Latin had a third gender (neuter), there is little trace of this in most languages. The biggest exception is Romanian, where there is a productive class of "neuter" nouns, which include the descendants of many Latin neuter nouns and which behave like masculines in the singular and feminines in the plural, both in the endings used and in the agreement of adjectives and pronouns (e.g. "un deget" "one finger" vs. "două degete" "two fingers", cf. Latin "digitus", pl. "digiti").
Such nouns arose because of the identity of the Latin neuter singular "-um" with the masculine singular, and the identity of the Latin neuter plural "-a" with the feminine singular. A similar class exists in Italian, although it is no longer productive (e.g. "il dito" "the finger" vs. "le dita" "the fingers", "l'uovo" "the egg" vs. "le uova" "the eggs"). (A few isolated nouns in Latin had different genders in the singular and plural, but this was an unrelated phenomenon; this is similarly the case with a few French nouns, such as "amour", "délice", "orgue".)
Spanish also has vestiges of the neuter in two demonstrative adjectives: "eso", "aquello" (both meaning "that [one]"), the pronoun "ello" (meaning "it") and the article "lo" (used to intensify adjectives). Portuguese also has neuter demonstrative adjectives: "isto", "isso", "aquilo" (meaning "this [near me]", "this/that [near you]", "that [far from the both of us]").
Case.
Latin had an extensive case system, where all nouns were declined in six cases (nominative, vocative, accusative, dative, genitive, and ablative) and two numbers. Adjectives were additionally declined in three genders, leading to potentially 36 (6 * 2 * 3) different endings per adjective. In practice, some category combinations had identical endings to other combinations, but a basic adjective like "bonus" "good" still had 14 distinct endings.
In all Romance languages, this system was drastically reduced. In most modern Romance languages, in fact, case is no longer marked at all on nouns, adjectives and determiners, and most forms are derived from the Latin accusative case. Much like English, however, case has survived somewhat better on pronouns.
Most pronouns have distinct nominative, accusative, genitive and possessive forms (cf. English "I, me, mine, my"). Many also have a separate dative form, a "disjunctive" form used after prepositions, and (in some languages) a special form used with the preposition "con" "with" (a conservative feature inherited from Latin forms such as "mēcum", "tēcum", "nobiscum").
The system of inflectional classes is also drastically reduced. The basic system is most clearly indicated in Spanish, where there are only three classes, corresponding to the first, second and third declensions in Latin: plural in "-as" (feminine), plural in "-os" (masculine), plural in "-es" (either masculine or feminine). The singular endings exactly track the plural, except the singular "-e" is dropped after certain consonants.
The same system underlines many other modern Romance languages, such as Portuguese, French and Catalan. In these languages, however, further sound changes have resulted in various irregularities. In Portuguese, for example, loss of /l/ and /n/ between vowels (with nasalization in the latter case) produces various irregular plurals ("nação – nações" "nation(s)"; "hotel – hotéis" "hotel(s)").
In French and Catalan, loss of /o/ and /e/ in most unstressed final syllables has caused the "-os" and "-es" classes to merge. In French, merger of remaining /e/ with final /a/ into [ə], and its subsequent loss, has completely obscured the original Romance system, and loss of final /s/ has caused most nouns to have identical pronunciation in singular and plural, although they are still marked differently in spelling (e.g. "femme – femmes" "woman – women", both pronounced /fam/).
Noun inflection has survived in Romanian somewhat better than elsewhere.:399 Determiners are still marked for two cases (nominative/accusative and genitive/dative) in both singular and plural, and feminine singular nouns have separate endings for the two cases. In addition, there is a separate vocative case, and the combination of noun with a following clitic definite article produces a separate set of "definite" inflections for nouns.
The inflectional classes of Latin have also survived more in Romanian than elsewhere, e.g. "om – oameni" "man – men" (Latin "homo" – "homines"); "corp – corpuri" "body – bodies" (Latin "corpus" – "corpora"). (Many other exceptional forms, however, are due to later sound changes or analogy, e.g. "casă – case" "house(s)" vs. "lună – luni" "moon(s)"; "frate – fraţi" "brother(s)" vs. "carte – cărţi" "book(s)" vs. "vale – văi" "valley(s)".)
In Italian, the situation is somewhere in between Spanish and Romanian. There are no case endings and relatively few classes, as in Spanish, but noun endings are generally formed with vowels instead of /s/, as in Romanian: "amico – amici" "friend(s) (masc.)", "amica – amiche" "friend(s) (fem.)"; "cane – cani" "dog(s)". The masculine plural "amici" is thought to reflect the Latin nominative plural "-ī" rather than accusative plural "-ōs" (Spanish "-os"); however, the other plurals are thought to stem from special developments of Latin "-ās" and "-ēs".
A different type of noun inflection survived into the medieval period in a number of western Romance languages (Old French, Old Occitan, and the older forms of a number of Rhaeto-Romance languages). This inflection distinguished nominative from oblique, grouping the accusative case with the oblique, rather than with the nominative as in Romanian.
The oblique case in these languages generally inherits from the Latin accusative; as a result, masculine nouns have distinct endings in the two cases while most feminine nouns do not.
A number of different inflectional classes are still represented at this stage. For example, the difference in the nominative case between masculine "li voisins" "the neighbor" and "li pere" "the father", and feminine "la riens" "the thing" vs. "la fame" "the woman", faithfully reflects the corresponding Latin inflectional differences ("vicīnus" vs. "pater", "fēmina" vs. "rēs").
A number of synchronically quite irregular differences between nominative and oblique reflect direct inheritances of Latin third-declension nouns with two different stems (one for the nominative singular, one for all other forms), most with of which had a stress shift between nominative and the other forms: "li ber – le baron" "baron" ("barō" – "barōnem"); "la suer – la seror" "sister" ("soror" – "sorōrem"); "li prestre – le prevoire" "priest" ("presbyter" – "presbyterem"); "li sire – le seigneur" "lord" ("senior" – "seniōrem"); "li enfes – l'enfant" "child" ("infāns" – "infantem").:36–39
A few of these multi-stem nouns derive from Latin forms without stress shift, e.g. "li om – le ome" "man" ("homō" – "hominem"). All of these multi-stem nouns refer to people; other nouns with stress shift in Latin (e.g. "amor" – "amōrem" "love") have not survived. Interestingly, some of the same nouns with multiple stems in Old French or Old Occitan have come down in Italian in the nominative rather than the accusative (e.g. "uomo" "man" < "homō", "moglie" "wife" < "mulier"), suggesting that a similar system existed in pre-literary Italian.
The modern situation in Sursilvan (one of the Rhaeto-Romance languages) is unique in that the original nominative/oblique distinction has been reinterpreted as a predicative/attributive distinction::381
Pronouns, determiners.
As described above, case marking on pronouns is much more extensive than for nouns. Determiners (e.g. words such as "a", "the", "this") are also marked for case in Romanian.
Most Romance languages have the following sets of pronouns and determiners:
Personal pronouns.
Unlike in English, a separate neuter personal pronoun ("it") generally does not exist, but both singular and plural third person distinguish masculine from feminine. Also, as described above, case is marked on pronouns even though it is not usually on nouns, similar to English. As in English, there are forms for nominative case (subject pronouns), oblique case (object pronouns), and genitive case (possessive pronouns); in addition, third-person pronouns distinguish accusative and dative. There is also an additional set of possessive determiners, distinct from the genitive case of the personal pronoun; this corresponds to the English difference between "my, your" and "mine, yours".
Development from Latin.
The Romance languages do not retain the Latin third-person personal pronouns, but have innovated a separate set of third-person pronouns by borrowing the demonstrative "ille" ("that (over there)"), and creating a separate reinforced demonstrative by attaching a variant of "ecce" "behold!" (or "here is ...") to the pronoun.
Similarly, in place of the genitive of the Latin pronouns, the Romance languages adopted the reflexive possessive, which then serves indifferently as both reflexive and non-reflexive possessive. Note that the reflexive, and hence the third-person possessive, is unmarked for the gender of the person being referred to. Hence, although gendered possessive forms do exist—e.g. Portuguese "seu" (masc.) vs. "sua" (fem.)—these refer to the gender of the object possessed, not the possessor.
The gender of the possessor needs to be made clear by a collocation such as French "la voiture à lui/elle", Portuguese "o carro dele/dela", literally "the car of him/her". (In spoken Brazilian Portuguese, these collocations are the usual way of expressing the third-person possessive, since the former possessive "seu carro" now has the meaning "your car".)
The same demonstrative "ille" was borrowed to create the definite article (see below), which explains the similarity in form between personal pronoun and definite article. When the two are different, it is usually because of differing degrees of phonetic reduction. Generally, the personal pronoun is unreduced (beyond normal sound change), while the article has suffered various amounts of reduction, e.g. Spanish "ella" "she" < "illa" vs. "la" "the (fem.)" < "-la" < "illa".
Clitic pronouns.
Object pronouns in Latin were normal words, but in the Romance languages they have become clitic forms, which must stand adjacent to a verb and merge phonologically with it. Originally, object pronouns could come either before or after the verb; sound change would often produce different forms in these two cases, with numerous additional complications and contracted forms when multiple clitic pronouns cooccurred.
Catalan still largely maintains this system with a highly complex clitic pronoun system. Most languages, however, have simplified this system by undoing some of the clitic mergers and requiring clitics to stand in a particular position relative to the verb (usually after imperatives, before other finite forms, and either before or after non-finite forms depending on the language).
When a pronoun cannot serve as a clitic, a separate disjunctive form is used. These result from dative object pronouns pronounced with stress (which causes them to develop differently from the equivalent unstressed pronouns), or from subject pronouns.
Most Romance languages are null subject languages. The subject pronouns are used only for emphasis and take the stress, and as a result are not clitics. In French, however (as in Friulian and in some Gallo-Italian languages of northern Italy), verbal agreement marking has degraded to the point that subject pronouns have become mandatory, and have turned into clitics. These forms cannot be stressed, so for emphasis the disjunctive pronouns must be used in combination with the clitic subject forms. Friulian and the Gallo-Italian languages have actually gone further than this and merged the subject pronouns onto the verb as a new type of verb agreement marking, which must be present even when there is a subject noun phrase. (Some non-standard varieties of French treat disjunctive pronouns as arguments and clitic pronouns as agreement markers.)
Familiar–formal distinction.
In medieval times, most Romance languages developed a distinction between familiar and polite second-person pronouns (a so-called "T-V distinction"), similar to the former English distinction between familiar "thou" and polite "you". As in English, this generally developed by appropriating the plural second-person pronoun to serve in addition as a polite singular. French is still at this stage, with familiar singular "tu" vs. formal or plural "vous". In cases like this, the pronoun requires plural agreement in all cases whenever a single affix marks both person and number (as in verb agreement endings and object and possessive pronouns), but singular agreement elsewhere where appropriate (e.g. "vous-même" "yourself" vs. "vous-mêmes" "yourselves").
Many languages, however, innovated further in developing an even more polite pronoun, generally composed of a noun phrase (e.g. Portuguese "vossa mercê" "your mercy", progressively reduced to "vossemecê", "vosmecê" and finally "você") and taking third-person singular agreement. A plural equivalent was created at the same time or soon after (Portuguese "vossas mercês", reduced to "vocês"), taking third-person plural agreement. Spanish innovated similarly, with "usted(es)" from earlier "vuestra(s) merced(es)".
In Portuguese and Spanish (as in other languages with similar forms), the "extra-polite" forms in time came to be the normal polite forms, and the former polite (or plural) second-person "vos" knocked down to a familiar form, either becoming a familiar plural (as in European Spanish) or a familiar singular (as in many varieties of Latin American Spanish). In the latter case, it either competes with the original familiar singular "tu" (as in Guatemala), displaces it entirely (as in Argentina), or is itself displaced (as in Mexico, except in Chiapas). In American Spanish, the gap created by the loss of familiar plural "vos" was filled by originally polite "ustedes", with the result that there is no familiar/polite distinction in the plural, just as in the original "tu/vos" system.
A similar path was followed by Italian and Romanian. Romanian uses "dumneavoastră" "your lordship", while Italian the former polite phrase "sua eccellenza" "your excellency" has simply been supplanted by the corresponding pronoun "Ella" or "Lei" (literally "she", but capitalized when meaning "you"). As in European Spanish, the original second-person plural "voi" serves as familiar plural. (In Italy, during fascist times leading up to World War II, "voi" was resurrected as a polite singular, and discarded again afterwards, although it remains in some southern dialects.)
Portuguese innovated again in developing a new extra-polite pronoun "o senhor" "the sir", which in turn downgraded "você". Hence, modern European Portuguese has a three-way distinction between "familiar" "tu", "equalizing" "você" and "polite" "o senhor". (The original second-person plural "vós" was discarded centuries ago in speech, and is used today only in translations of the Bible, where "tu" and "vós" serve as universal singular and plural pronouns, respectively.)
Brazilian Portuguese, however, has diverged from this system, and most dialects simply use "você" (and plural "vocês") as a general-purpose second person pronoun, combined with "te" (from "tu") as the clitic object pronoun. The form "o senhor" is sometimes used in speech, but only in situations where an English speaker would say "sir" or "ma'am". The result is that second-person verb forms have disappeared, and the whole pronoun system has been radically realigned. However that is the case only in the spoken language of central and southern Brazil, with the northern areas of the country still largely preserving the second person verb form and the "tu" and "você" distinction.
Articles.
Latin had no articles as such. The closest definite article was the non-specific demonstrative "is, ea, id" meaning approximately "this/that/the". The closest indefinite articles were the indefinite determiners "aliquī, aliqua, aliquod" "some (non-specific)" and "certus" "a certain".
Romance languages have both indefinite and definite articles, but none of the above words form the basis for either of these. Usually the definite article is derived from the Latin demonstrative "ille" ("that"), but some languages (e.g. Sardinian, and some dialects spoken around the Pyrenees) have forms from "ipse" (emphatic, as in "I myself"). The indefinite article everywhere is derived from the number "ūnus" ("one").
Some languages, e.g. French and Italian, have a partitive article that approximately translates as "some". This is used either with mass nouns or with plural nouns—both cases where the indefinite article cannot occur. A partitive article is used (and in French, required) whenever a bare noun refers to specific (but unspecified or unknown) quantity of the noun, but not when a bare noun refers to a class in general. For example, the partitive would be used in both of the following sentences:
But neither of these:
The sentence "Men arrived today", however, (presumably) means "some specific men arrived today" rather than "men, as a general class, arrived today" (which would mean that there were no men before today). On the other hand, "I hate men" does mean "I hate men, as a general class" rather than "I hate some specific men".
As in many other cases, French has developed the farthest from Latin in its use of articles. In French, nearly all nouns, singular and plural, must be accompanied by an article (either indefinite, definite, or partitive) or demonstrative pronoun.
Due to pervasive sound changes, most nouns are pronounced identically in the singular and plural, and there is often heavy homonymy between nouns and identically pronounced words of other classes. For example, all of the following are pronounced /sɛ̃/: "sain" "healthy"; "saint" "saint, holy"; "sein" "breast"; "ceins" "(you) put on, gird"; "ceint" "(he) puts on, girds"; "ceint" "put on, girded"; and the equivalent noun and adjective plural forms "sains, saints, seins, ceints". The article helps identify the noun forms "saint" or "sein", and distinguish singular from plural; likewise, the mandatory subject of verbs helps identify the verb "ceint". In more conservative Romance languages, neither articles nor subject pronouns are necessary, since all of the above words are pronounced differently (In Italian, for example, the equivalents are "sano, santo, seno, cingi, cinge, cinto, sani, santi, seni, cinti", where all vowels and consonants are pronounced as written, and ⟨s⟩ and ⟨c⟩ are clearly distinct from each other).
Latin, at least originally, had a three-way distinction among demonstrative pronouns ("hic" "iste" "ille") corresponding to first, second and third persons. Such a distinction is not reflected in modern English, but formerly existed as "this" vs. "that" vs. "yon(der)". In urban Latin of Rome, "iste" came to have a specifically derogatory meaning, but this innovation apparently did not reach the provinces and is not reflected in the modern Romance languages. A number of these languages still have such a three-way distinction, although "hic" has been lost and the other pronouns have shifted somewhat in meaning. For example, Spanish has "este" "this" vs. "ese" "that (near you)" vs. "aquel" (fem. "aquella") "that (over yonder)". The Spanish pronouns derive, respectively, from Latin "iste" "ipse" "accu"-"ille", where "accu-" is an emphatic prefix derived from "eccum" "behold it!", possibly with influence from "atque" "and".
Reinforced demonstratives such as "accu"-"ille" became necessary once "ille" came to be used as an article as well as a demonstrative. Such forms were often created even when not strictly needed to distinguish otherwise ambiguous forms. Italian, for example, has both "questo" "this" ("eccu"-"istum") and "quello" "that" ("eccu"-"illum"), in addition to dialectal "codesto" "that (near you)" ("eccu-tē-istum"). French generally prefers forms derived from bare "ecce" "behold", as in the pronoun "ce" "this one/that one" (earlier "ço", from "ecce"-"hoc") and the determiner "ce/cet" "this/that" (earlier "cest", from "ecce"-"istum").
Reinforced forms are likewise common in locative adverbs (words such as English "here" and "there"), based on related Latin forms such as "hic" "this" vs. "hīc" "here", "hāc" "this way", and "ille" "that" vs. "illīc" "there", "illāc" "that way". Here again French prefers bare "ecce" while Spanish and Italian prefer "eccum" (French "ici" "here" vs. Spanish "aquí", Italian "qui"). In western languages such as Spanish, Portuguese and Catalan, doublets and triplets arose such as Portuguese "aqui, acá, cá" "(to) here" ("accu"-"hīc", "accu"-"hāc", "eccu"-"hāc"). From these, a prefix "a-" was extracted, from which forms like "aí" "there (near you)" ("a-(i)bi") and "ali" "there (over yonder)" ("a-(i)llīc") were created; compare Catalan neuter pronouns "açò" ("acce"-"hoc") "this", "això" ("a-(i)psum"-"hoc") "that (near you)", "allò" ("a-(i)llum"-"hoc") "that (yonder)".
Subsequent changes often reduced the number of demonstrative distinctions. Standard Italian, for example, has only a two-way distinction "this" vs. "that", as in English, with second-person and third-person demonstratives combined. In Catalan, however, a former three-way distinction "aquest, aqueix, aquell" has recently been reduced differently, with first-person and second-person demonstratives combined. Hence "aquest" means either "this" or "that (near you)"; on the phone, "aquest" is used to refer both to speaker and addressee.
Old French had a similar distinction to Italian ("cist/cest" vs. "cil/cel"), both of which could function as either adjectives or pronouns. Modern French, however, has no distinction between "this" and "that": "ce/cet, cette" < "cest, ceste" is only an adjective, and "celui, celle" < "cel lui, celle" is only a pronoun, and both forms indifferently mean either "this" or "that". (The distinction between "this" and "that" can be made, if necessary, by adding the suffixes "-ci" "here" or "-là" "there", e.g. "cette femme-ci" "this woman" vs. "cette femme-là" "that woman", but this is rarely done except when specifically necessary to distinguish two entities from each other.)
Verbal morphology.
Verbs have many conjugations, including in most languages:
Several tenses and aspects, especially of the indicative mood, have been preserved with little change in most languages, as shown in the following table for the Latin verb "dīcere" (to say), and its descendants.
The main tense and mood distinctions that were made in classical Latin are generally still present in the modern Romance languages, though many are now expressed through compound rather than simple verbs. The passive voice, which was mostly synthetic in classical Latin, has been completely replaced with compound forms.
For a more detailed illustration of how the verbs have changed with respect to classical Latin, see Romance verbs.
Note that in Catalan, the synthetic preterite is predominantly a literary tense, except in Valencian; but an analytic preterite (formed using an auxiliary "vadō", which in other languages signals the future) persists in speech, with the same meaning. In Portuguese, a morphological present perfect does exist but has a different meaning (closer to "I have been doing"), and is rare in practice.
The following are common features of the Romance languages (inherited from Vulgar Latin) that are different from Classical Latin:
Lexicon.
Borrowing.
Romance languages have borrowed heavily, though mostly from other Romance languages. However, some, such as Spanish, Portuguese, Romanian, and French, have borrowed heavily from other language groups. Vulgar Latin borrowed first from indigenous languages of the Roman empire, and during the Germanic folk movements, from Germanic languages, especially Gothic. Notable examples are *"blancus" "white", replacing native "albus" (but Romansh "alv", Dalmatian "jualb", Romanian "alb"); *"guerra" "war", replacing native "bellum"; and the words for the cardinal directions, where cognates of English "north", "south", "east" and "west" replaced the native words "septentriō", "merīdiēs" (also "noon; midday nap"; cf. Romanian "meriză"), "oriens", and "occidens". (See History of French – The Franks.) Some Celtic words were incorporated into the core vocabulary, partly for words with no Latin equivalent ("betulla" "birch", "camisia" "shirt", "cerevisia" "beer"), but in some cases replacing Latin vocabulary ("gladius" "sword", replacing "ensis"; "cambiāre" "to exchange", replacing "mūtāre" except in Romanian and Portuguese; "carrus" "cart", replacing "currus"; "pettia" "piece", largely displacing "pars" (later resurrected) and eliminating "frustum"). Many Greek words also entered the lexicon. e.g. "spatha" "sword" (replacing "gladius" which shifted to "iris", cf. French "épée", Spanish "espada", Italian "spada "and Romanian "spadă"); "cara" "face" (partly replacing "faciēs"); "colpe" "blow" (replacing "ictus", cf. Spanish "golpe", French "coup"); "cata" "each" (replacing "quisque"); common suffixes *"-ijāre/-izāre" (French "oyer/-iser", Spanish "-ear/-izar", Italian "-eggiare/-izzare", etc.), "-ista".
Lexical innovation.
Many basic nouns and verbs, especially those that were short or had irregular morphology, were replaced by longer derived forms with regular morphology. Nouns, and sometimes adjectives, were often replaced by diminutives, e.g. "auris" "ear" > "auricula" (orig. "outer ear") > "oricla" (Sardinian "origra", Italian "orecchia/o", Portuguese "orelha", etc.); "avis" "bird" > "avicellus" (orig. "chick, nestling") > "aucellu" (Occitan "aucèl", Friulian "ucel", French "oiseau", etc.); "caput" "head" > "capitium" (Portuguese "cabeça", Spanish "cabeza", French "chevet" "headboard"; but reflexes of "caput" were retained also, sometimes without change of meaning); "vetus" "old" > "vetulus" > "veclus" (Dalmatian "vieklo", Italian "vecchio", Portuguese "velho", etc.). Sometimes augmentative constructions were used instead: "piscis" "fish" > Old French "peis" > "peisson" (orig. "big fish") > French "poisson". Verbs were often replaced by frequentative constructions: "canere" "to sing" > "cantāre"; "iacere" "to throw" > "iactāre" > *"iectāre" (Italian "gettare", Portuguese "jeitar", Spanish "echar", etc.); "iuvāre" > "adiūtāre" (Italian "aiutare", Spanish "ayudar", French "aider", etc.); "vēnārī" "hunt" > replaced by *"captiāre" "to hunt", frequentative of "capere" "to seize" (Italian "cacciare", Portuguese "caçar", Romansh "catschar", French "chasser", etc.).
Many Classical Latin words became archaic or poetic and were replaced by more colloquial terms: "equus" "horse" > "caballus" (orig. "nag") (but "equa" "mare" remains, cf. Spanish "yegua"); "domus" "house" > "casa" (orig. "hut"); "ignis" "fire" > "focus" (orig. "hearth"); "strāta" "street" > "rūga" (orig. "furrow") or "callis" (orig. "footpath") (but "strāta" is continued in Italian "strada"). In some cases, terms from common occupations became generalized: "invenīre" "to find" > Ibero-Romance "(f)afflāre" (orig. "to sniff out", in hunting, cf. Spanish "hallar", Portuguese "achar"); "advenīre" "to arrive" > Ibero-Romance "plicāre" (orig. "to fold (sails)", cf. Spanish "llegar", Portuguese "chegar"), elsewhere "arripāre" (orig. "to harbor at a riverbank", cf. Italian "arrivare", French "arriver") ("advenīre" is continued with the meaning "to achieve, mangage to do"; cf. Middle French "aveindre") . The same thing sometimes happened to religious terms, due to the pervasive influence of Christianity: "loquī" "to speak" > "parabolāre" (orig. "to tell parables", cf. Occitan "paraular", French "parler") or "fabulārī" (orig. "to tell stories", cf. Spanish "hablar", Portuguese "falar"), based on Jesus' way of speaking in parables.
Many prepositions were used as verbal particles to make new roots and verb stems, e.g. Italian "estrarre" "to extract" from Latin "ex-" "out of" and "trahere" "to pull" (Italian "trarre"), or to augment already existing words, e.g. French "coudre", Italian "cucire", Portuguese "coser" "to sew", from "cōnsuere" "to sew up", from "suere" "to sew", with total loss of the bare stem. Many prepositions weakened and commonly became compounded, e.g. "de ex" > French "dès" "as of", "ab ante" > Italian "avanti" "forward". Some words derived from phrases, e.g. Portuguese "agora", Spanish "ahora" "now" < "hāc hōrā" "at this hour"; French "avec" "with" (prep.) < Old French "avuec" (adv.) < "ab hoc" "away from that"; Spanish "tamaño", Portuguese "tamanho" "size" < "tam magnum" "so big"; Italian "codesto" "this, that" (near you) < Old Italian "cotevesto" < "eccum tibi istum" approx. "here's that thing of yours"; Portuguese "você" "you" < "vosmecê" < "vossemecê" < Old Portuguese "vossa mercee" "your mercy".
A number of common Latin words that have disappeared in many or most Romance languages have survived either in the periphery or in remote corners (especially Sardinia). For example, Latin "caseum" "cheese" in the more outer places (Portuguese "queijo", Spanish "queso", Romansh "caschiel", Sardinian "càsu", Romanian "caş"), but in the central areas has been replaced by "formāticum", originally "moulded (cheese)" (French "fromage", Occitan/Catalan "formatge", Italian "formaggio"); similarly "(com)edere" "to eat (up)", which survives as Spanish/Portuguese "comer" but elsewhere is replaced by "mandūcāre", originally "to chew" (French "manger", Italian "mangiare", Romanian "mâncare"). In some cases, one language happens to preserve a word displaced elsewhere, e.g. Italian "ogni" "everything" < "omnes", displaced elsewhere by "tōtum", originally "whole"; Friulian "vaî" "to cry" < "flere" "to weep"; Vegliote "otijemna" "fishing pole" < "antenna" "yardarm". Sardinian in particular preserves many words entirely lost elsewhere, e.g. "emmo" "yes" < "immo" "rather/yes/no", "mannu" "big" < "magnus", "narare" "to say" < "narrāre" "to tell", and "domo" "house" < (abl.) "domō" "at home". Sardinian even preserves some words that were already archaic in Classical Latin, e.g. "àchina" "grape" < "acinam".
Latinisms.
During the Middle Ages, scores of words were borrowed directly from Classical Latin (so-called latinisms), either in their original form ("learned loans") or in a somewhat nativized form ("semi-learned loans"). These introduced many doublets, e.g. Latin "fragilis" > French "fragile" "fragile" (learned) vs. "frêle" "frail" (inherited); Latin "fabrica" "craft, manufacture" > French "fabrique" "factory" (learned) vs. "forge" "forge" (inherited), Spanish "fábrica" "factory" (learned) vs. "fragua" "forge" (inherited); Latin "ferrum" > Spanish "fierro" (learned) vs. "hierro" (inherited) both mean "iron"; Latin "lēgālis" "legal" > French "légal" "legal" (learned) vs. "loyal" "loyal" (inherited), Spanish "legal" "legal" (learned) vs. "leal" "loyal" (inherited); "advōcātus" "advocate" > French "avocat" "barrister (attorney)" (learned) vs. "avoué" "solicitor (attorney)" (inherited); Latin "polīre" "to polish" > Portuguese "polir" "to polish" (learned) vs. "puir" "to wear thin" (inherited). Sometimes triplets arise: Latin "articulus" "joint" > Portuguese "artículo" "joint, knuckle" (learned), "artigo" "article" (semi-learned), "artelho" "ankle" (inherited; archaic and dialectal). In many cases, the learned word simply displaced the original popular word, e.g. Spanish "crudo" "crude" (Old Spanish "cruo"); French "légume" "vegetable" (Old French "leüm"); Portuguese "flor" "flower" (Old Portuguese "chor"). The learned loan always looks more like the original than the inherited word does, since regular sound change has been bypassed; likewise, it usually has a meaning closer to the original.
Borrowing from Classical Latin has produced a large number of suffix doublets. Examples from Spanish (learned form first): "-ción" vs. "-zon"; "-cia" vs. "-za"; "-ificar" vs. "-iguar"; "-izar" vs. "-ear"; "-mento" vs. "-miento"; "-tud" (< nominative "-tūdō") vs. "-dumbre" (< accusative "-tūdine"); "-ículo" vs. "-ejo"; etc. Similar examples can be found in all the other Romance languages.
This borrowing also introduced large numbers of classical prefixes in their original form ("dis-", "ex-", "post-", "trans"-) and reinforced many others ("re-", popular Spanish/Portuguese "des-" < "dis-", popular French "dé-" < "dis-", popular Italian "s-" < "ex-"). Many Greek prefixes and suffixes (hellenisms) also found their way into the lexicon: "tele-", "poli-/poly-", "meta-", "pseudo-", "-scope/scopo", "-logie/logia/logía", etc.
Sound changes.
Consonants.
Significant sound changes affected the consonants of the Romance languages.
Apocope.
There was a tendency to eliminate final consonants in Vulgar Latin, either by dropping them (apocope) or adding a vowel after them (epenthesis).
Many final consonants were rare, occurring only in certain prepositions (e.g. "ad" "towards", "apud" "at, near (a person)"), conjunctions ("sed" "but"), demonstratives (e.g. "illud" "that (over there)", "hoc" "this"), and nominative singular noun forms, especially of neuter nouns (e.g. "lac" "milk", "mel" "honey", "cor" "heart"). Many of these prepositions and conjunctions were replaced by others, while the nouns were regularized into forms that avoided the final consonants (e.g. *"lacte", *"mele", *"core").
Final "-m" was dropped in Vulgar Latin. Even in Classical Latin, final "-am", "-um" (accusative endings) was often elided in poetic meter, suggesting the "m" was weakly pronounced, probably marking the nasalisation of the vowel before it. This nasal vowel lost its nasalization in the Romance languages except in monosyllables, where it became /n/ (cf. Spanish "quien" < "quem", French "rien" < "rem").
As a result, only the following final consonants occurred in Vulgar Latin:
Final "-t" was eventually dropped in many languages, although this often occurred several centuries after the Vulgar Latin period. For example, the reflex of "-t" was dropped in Old French and Old Spanish only around AD 1100. In Old French, this occurred only when a vowel still preceded the consonant. Hence "venit" "he comes" > Old French "vient", and the /t/ was never dropped. (It survives to this day in liaison forms, e.g. "vient-il?" "is he coming?" /vjɛ̃ti(l)/.)
In Italo-Romance and Eastern Romance, eventually "all" final consonants were either dropped or protected by an epenthetic vowel, except in clitic forms (e.g. prepositions "con", "per"). Modern Italian still has almost no consonant-final words, although Romanian has resurfaced them through later loss of final /u/. For example, "amās" "you love" > "ame" > "ami"; "amant" "they love" > *"aman" > "amano". On the evidence of "sloppily written" Langobardic documents, however, the loss of final /s/ did not occur till the seventh or eighth century AD, after the Vulgar Latin period, and the presence of many former final consonants is betrayed by the syntactic gemination ("raddoppiamento sintattico") that they trigger. It is also thought that /s/ became /j/ rather than simply disappearing: "nōs" > "noi" "we", "s(ed)ēs" > "sei" "you are", "crās" > "crai" "tomorrow" (southern Italian). In unstressed syllables, the resulting diphthongs were simplified: "amīcās" > /aˈmikai/ > "amiche" /aˈmike/ "(female) friends", where nominative "amīcae" should produce "**amice" rather than "amiche" (masculine "amīcī" > "amici" not "**amichi").
Central Western Romance languages eventually regained a large number of final consonants through the general loss of final /e/ and /o/, e.g. Catalan "llet" "milk" < "lactem", "foc" "fire" < "focum", "peix" "fish" < "piscem". In French, most of these secondary final consonants were lost, but tertiary final consonants later arose through the loss of /ə/ < "-a". Hence masculine "frigidum" "cold" > Old French /froit/ > "froid" /fʁwa/, feminine "frigidam" > Old French /froidə/ > "froide" /fʁwad/.
Palatalization.
Palatalization was one of the most important processes affecting consonants in Vulgar Latin. This eventually resulted in a whole series of "palatal" and postalveolar consonants in most Romance languages, e.g. Italian /ʃ/, /ʒ/, /tʃ/, /dʒ/, /ts/, /dz/, /ɲ/, /ʎ/.
The following historical stages occurred:
Note how the environments become progressively less "palatal", and the languages affected become progressively fewer.
The outcomes of palatalization depended on the historical stage, the consonants involved, and the languages involved. The primary division is between the Western Romance languages, with /ts/ resulting from palatalization of /k/, and the remaining languages (Italo-Romance and Eastern Romance) with /tʃ/ resulting. It is often suggested that /tʃ/ was the original result in all languages, with /tʃ/ > /ts/ a later innovation in the Western Romance languages. Evidence of this is the fact that Italian has both /ttʃ/ and /tts/ as outcomes of palatalization in different environments, while Western Romance has only /(t)ts/. Even more suggestive is the fact that Mozarabic, in southern Spain, had /tʃ/ as the outcome despite being in the "Western Romance" area and geographically disconnected from the remaining /tʃ/ areas; this suggests that Mozarabic was an outlying "relic" area where the change /tʃ/ > /ts/ failed to reach. (Northern French dialects, such as Norman and Picard, also had /tʃ/, but this may be a secondary development, i.e. due to a later sound change /ts/ > /tʃ/.) Note that /ts,dz,dʒ/ eventually became /s,z,ʒ/ in most Western Romance languages. Thus Latin "caelum" (sky, heaven), pronounced [ˈkailu(m)] with an initial [k], became Italian "cielo" [ˈtʃɛlo], Romanian "cer" [tʃer], Spanish "cielo" [ˈθjelo]/[ˈsjelo], French "ciel" [sjɛl], Catalan "cel" [ˈsɛɫ], and Portuguese "céu" [ˈsɛw].
The outcome of palatalized /d/ and /g/ is less clear:
This suggests that palatalized /d/ > /dʲ/ > either /j/ or /dz/ depending on location, while palatalized /g/ > /j/; after this, /j/ > /(d)dʒ/ in most areas, but Spanish and Gascon (originating from isolated districts behind the western Pyrenees) were relic areas unaffected by this change.
In French, the outcomes of /k/ palatalized by /e,i,j/ and by /a/ were different: "centum" "hundred" > "cent" /sɑ̃/ but "cantum" "song" > "chant" /ʃɑ̃/.
The original outcomes of palatalization must have continued to be phonetically palatalized even after they had developed into alveolar/postalveolar/etc. consonants. This is clear from French, where all originally palatalized consonants triggered the development of a following glide /j/ in certain circumstances (most visible in the endings "-āre", "-ātum/ātam"). In some cases this /j/ came from a consonant palatalized by an adjoining consonant after the late loss of a separating vowel. For example, "mansiōnātam" > /masʲoˈnata/ > masʲˈnada/ > /masʲˈnʲæðə/ > early Old French "maisnieḍe" /maisˈniɛðə/ "household". Similarly, "mediētātem" > /mejeˈtate/ > /mejˈtade/ > /mejˈtæðe/ > early Old French "meitieḍ" /mejˈtʲɛθ/ > modern French "moitié" /mwaˈtje/ "half". In both cases, phonetic palatalization must have remained in primitive Old French at least through the time when unstressed intertonic vowels were lost (c. eighth century AD?), well after the fragmentation of the Romance languages.
The effect of palatalization is indicated in the writing systems of almost all Romance languages, where the letters ⟨c g⟩ have the "hard" pronunciation [k ɡ] in most situations, but a "soft" pronunciation (e.g. French/Portuguese [s ʒ], Italian/Romanian [tʃ dʒ]) before ⟨e i y⟩. (Because Middle English was originally written by scribes speaking Norman French, the English spelling system has the same peculiarity.) This has the effect of keeping the modern spelling similar to the original Latin spelling, but complicates the relationship between sound and letter. In particular, the hard sounds must be written differently before ⟨e i y⟩ (e.g. Italian ⟨ch gh⟩, Portuguese ⟨qu gu⟩), and likewise for the soft sounds when not before these letters (e.g. Italian ⟨ci gi⟩, Portuguese ⟨ç j⟩). Furthermore, in Spanish, Catalan, Occitan and Brazilian Portuguese, the use of ⟨u⟩ to signal the hard pronunciation before ⟨e i y⟩ means that a different spelling is also needed to signal the sounds /kw ɡw/ before these letters (Spanish ⟨cu gü⟩, Catalan, Occitan and Brazilian Portuguese ⟨qü gü⟩). This produces a number of orthographic alternations in verbs whose pronunciation is entirely regular. The following are examples of corresponding first-person plural indicative and subjunctive in a number of regular Portuguese verbs: "marcamos marquemos" "we mark"; "caçamos cacemos" "we hunt"; "chegamos cheguemos" "we arrive"; "averiguamos averigüemos" "we verify"; "adequamos adeqüemos" "we adapt"; "oferecemos ofereçamos" "we offer"; "dirigimos dirijamos" "we drive" "erguemos ergamos" "we raise"; "delinquimos delincamos" "we commit a crime".
Lenition.
Stop consonants shifted by lenition in Vulgar Latin.
The voiced labial consonants /b/ and /w/ (represented by ⟨b⟩ and ⟨v⟩, respectively) both developed a fricative [β] as an intervocalic allophone. This is clear from the orthography; in medieval times, the spelling of a consonantal ⟨v⟩ is often used for what had been a ⟨b⟩ in Classical Latin, or the two spellings were used interchangeably. In many Romance languages (Italian, French, Portuguese, Romanian, etc.), this fricative later developed into a /v/; but in others (Spanish, Galician, some Catalan and Occitan dialects, etc.) reflexes of /b/ and /w/ simply merged into a single phoneme.
Several other consonants were "softened" in intervocalic position in Western Romance (Spanish, Portuguese, French, Northern Italian), but normally not phonemically in the rest of Italy (except some cases of "elegant" or Ecclesiastical words), nor apparently at all in Romanian. The dividing line between the two sets of dialects is called the La Spezia–Rimini Line and is one of the most important isoglosses of the Romance dialects. The changes (instances of diachronic lenition) are as follows:
Single voiceless plosives became voiced: "-p-, -t-, -c-" > "-b-, -d-, -g-". Subsequently, in some languages they were further weakened, either becoming fricatives or approximants, [β̞], [ð̞], [ɣ˕] (as in Spanish) or disappearing entirely (as /t/ and /k/, but not /p/, in French). The following example shows progressive weakening of original /t/: e.g. "vītam" > Italian "vita" [ˈvita], Portuguese "vida" [ˈvidɐ] (European Portuguese [ˈviðɐ]), Spanish "vida" [ˈbiða], French "vie" [vi]. These sound changes may be due in part to the influence of Continental Celtic languages.
Consonant length is no longer phonemically distinctive in most Romance languages. However some languages of Italy (Italian, Sardinian, Sicilian, and numerous other varieties of central and southern Italy) do have long consonants like /ɡɡ/, /dd/, /bb/, /kk/, /tt/, /pp/, /ll/, /mm/, /nn/, /ss/, and to a lesser extent /rr/, etc., where the doubling indicates a short hold before the consonant is released, in many cases with distinctive lexical value: e.g. "note" /ˈnɔ.te/ (notes) vs. "notte" /ˈnɔt.te/ (night), "cade" /ˈka.de/ (s/he, it falls) vs. "cadde" /ˈkad.de/ (s/he, it fell). They may even occur at the beginning of words in Romanesco, Neapolitan and Sicilian, and are occasionally indicated in writing, e.g. Sicilian "cchiù" (more), and "ccà" (here). In general, the consonants /b/, /ts/, and /dz/ are long at the start of a word, while the archiphoneme is realised as a trill /r/ in the same position.
A few languages have regained secondary geminate consonants. The double consonants of Piedmontese exist only after stressed /ə/, written "ë", and are not etymological: "vëdde" (Latin "vidēre", to see), "sëcca" (Latin "sicca", dry, feminine of "sech"). In standard Catalan and Occitan, there exists a geminate sound /lː/ written "ŀl" (Catalan) or "ll" (Occitan), but it is usually pronounced as a simple sound in colloquial (and even some formal) speech in both languages.
Prosthesis.
In Western Romance, an epenthetic or prosthetic vowel was inserted at the beginning of any word that began with /s/ and another consonant: "spatha" "sword" > Spanish/Portuguese "espada", Catalan "espasa", Old French "espeḍe" > modern "épée"; "Stephanum" "Stephen" > Spanish "Esteban", Catalan "Esteve", Portuguese "Estêvão", Old French "Estievne" > modern "Étienne"; "status" "state" > Spanish/Portuguese "estado", Catalan "estat", Old French "estat" > modern "état"; "spiritus" "spirit" > Spanish "espíritu", Portuguese "espírito", Catalan "esperit", French "esprit". Epenthetic /e/ in Western Romance languages was also probably influenced by Continental Celtic languages. While Western Romance words undergo word-initial epenthesis, cognates in Italian do not: "spatha" > "spada", "Stephanum" > "Stefano", "status" > "stato", "spiritus" > "spirito". In Italian, syllabification rules were preserved instead by vowel-final articles, thus feminine "spada" as "la spada", but instead of rendering the masculine "*il spaghetto", "lo spaghetto" came to be the norm. Though receding at present, Italian once had an epenthetic /i/ if a consonant preceded such clusters, so that 'in Switzerland' was "in" /i/"Svizzera". Some speakers still use the prosthetic /i/, and it is fossilized in a few set phrases as "per iscritto" 'in writing' (although in this case it has probably survived due to the influence of the separate word "iscritto" < Latin "īnscrīptus").
Stressed vowels.
Loss of vowel length, reorientation.
One profound change that affected Vulgar Latin was the reorganisation of its vowel system. Classical Latin had five short vowels, "ă, ĕ, ĭ, ŏ, ŭ", and five long vowels, "ā, ē, ī, ō, ū", each of which was an individual phoneme (see the table in the right, for their likely pronunciation in IPA), and four diphthongs, "ae", "oe", "au" and "eu" (five according to some authors, including "ui"). There were also long and short versions of "y", representing the rounded vowel /y(ː)/ in Greek borrowings, which however probably came to be pronounced /i(ː)/ even before Romance vowel changes started.
There is evidence that in the imperial period all the short vowels except "a" differed by quality as well as by length from their long counterparts. So, for example "ē" was pronounced close-mid /eː/ while "ĕ" was pronounced open-mid /ɛ/, and "ī" was pronounced close /iː/ while "ĭ" was pronounced near-close /ɪ/.
During the Proto-Romance period, phonemic length distinctions were lost. Vowels came to be automatically pronounced long in stressed, open syllables (i.e. when followed by only one consonant), and pronounced short everywhere else. This situation is still maintained in modern Italian: "cade" [ˈkaːde] "he falls" vs. "cadde" [ˈkadde] "he fell".
The Proto-Romance loss of phonemic length originally produced a system with nine different quality distinctions in monophthongs, where only original /ă ā/ had merged. Soon, however, many of these vowels coalesced:
The Proto-Romance allophonic vowel-length system was rephonemicized in the Gallo-Romance languages as a result of the loss of many final vowels. Some northern Italian languages (e.g. Friulan) still maintain this secondary phonemic length, but most languages dropped it by either diphthongizing or shortening the new long vowels.
French phonemicized a third vowel length system around AD 1300 as a result of the sound change /VsC/ > /VhC/ > /VːC/ (where "V" is any vowel and "C" any consonant). This vowel length was eventually lost by around AD 1700, but the former long vowels are still marked with a circumflex. A fourth vowel length system, still non-phonemic, has now arisen: All nasal vowels as well as the oral vowels /ɑ o ø/ (which mostly derive from former long vowels) are pronounced long in all stressed closed syllables, and all vowels are pronounced long in syllables closed by the voiced fricatives /v z ʒ ʁ vʁ/. This system in turn has been phonemicized in some non-standard dialects (e.g. Haitian Creole), as a result of the loss of final /ʁ/.
Latin diphthongs.
The Latin diphthongs "ae" and "oe", pronounced /ai/ and /oi/ in earlier Latin, were early on monophthongized.
"ae" became /ɛː/ by the a.d. 1st century at the latest. Although this sound was still distinct from all existing vowels, the neutralization of Latin vowel length eventually caused its merger with /ɛ/ < short "e": e.g. "caelum" "sky" > French "ciel", Spanish/Italian "cielo", Portuguese "céu" /sɛw/, with the same vowel as in "mele" "honey" > French/Spanish "miel", Italian "miele", Portuguese "mel" /mɛl/. Some words show an early merger of "ae" with /eː/, as in "praeda" "booty" > Gallo-Romance /preːða/ > Old French "preie" (vs. expected **"priée") > French "proie" "prey"; or "faenum" "hay" > "fēnum" [feːnu] > Spanish "heno", French "foin".
"oe" generally merged with /eː/: "poenam" "punishment" > Romance */péna/ > Spanish/Italian "pena", French "peine"; "foedus" "ugly" > Romance */fédo/ > Spanish "feo", Portuguese "feio". There are relatively few such outcomes, since "oe" was rare in Classical Latin (most original instances had become Classical "ū", as in Old Latin "oinos" "one" > Classical "ūnus").
"au" merged with "ō" [o] in the popular speech of Rome already by the 1st century b.c. A number of authors remarked on this explicitly, e.g. Cicero's taunt that the populist politician Publius Clodius Pulcher had changed his name from "Claudius" to ingratiate himself with the masses. This change never penetrated far from Rome, however, and the pronunciation /au/ was maintained for centuries in the vast majority of Latin-speaking areas, although it eventually developed into some variety of "o" in many languages. For example, Italian and French have /ɔ/ as the usual reflex, but this post-dates diphthongization of ɔ and the French-specific palatalization /ka/ > /tʃa/ (hence "causa" > French "chose", Italian "cosa" /kɔza/ not *"cuosa"). Spanish has /o/, but Portuguese spelling maintains ⟨ou⟩, only recently developed to /o/ (and still /ou/ in some dialects). Occitan, Romanian, southern Italian languages, and many other minority Romance languages still have /au/. A few common words, however, show an early merger with "ō" [o], evidently reflecting a generalization of the popular Roman pronunciation: e.g. French "queue", Italian "coda" /koda/, Occitan "co(d)a", Romanian "coadă" (all meaning "tail") must all derive from "cōda" rather than Classical "cauda". Similarly, Portuguese "orelha", French "oreille", Romanian "ureche", and Sardinian "olícra", "orícla" "ear" must derive from "oricla" rather than Classical "auris", and the form "oricla" is in fact reflected in the Appendix Probi (but Occitan "aurelha" reflects "auricla", probably influenced by "ausir" "to hear").
Further developments.
Metaphony.
An early process that operated in all Romance languages to varying degrees was metaphony (vowel mutation), conceptually similar to the umlaut process so characteristic of the Germanic languages. Depending on the language, certain stressed vowels were raised (or sometimes diphthongized) either by a final /i/ or /u/ or by a directly following /j/. Metaphony is most extensive in the Italo-Romance languages, and applies to nearly all languages in Italy; however, it is absent from Tuscan, and hence from standard Italian. In many languages affected by metaphony, a distinction exists between final /u/ (from most cases of Latin "-um") and final /o/ (from Latin "-ō", "-ud" and some cases of "-um", esp. masculine "mass" nouns), and only the former triggers metaphony.
Some examples:
Diphthongization.
A number of languages diphthongized some of the free vowels, especially the low-mid vowels /ɛ ɔ/:
These diphthongizations had the effect of reducing or eliminating the distinctions between low-mid and high-mid vowels in many languages. In Spanish and Romanian, all low-mid vowels were diphthongized, and the distinction disappeared entirely. Portuguese is the most conservative in this respect, keeping the seven-vowel system more or less unchanged (but with changes in particular circumstances, e.g. due to metaphony). Other than before palatalized consonants, Catalan keeps /ɔ o/ intact, but /ɛ e/ split in a complex fashion into /ɛ e ə/ and then coalesced again in the standard dialect (Eastern Catalan) in such a way that most original /ɛ e/ have reversed their quality to become /e ɛ/.
In French and Italian, the distinction between low-mid and high-mid vowels occurred only in closed syllables. Standard Italian more or less maintains this. In French, /e/ and /ɛ/ merged by the twelfth century or so, and the distinction between /ɔ/ and /o/ was eliminated without merging by the sound changes /u/ > /y/, /o/ > /u/. Generally this led to a situation where both [e,o] and [ɛ,ɔ] occur allophonically, with the high-mid vowels in open syllables and the low-mid vowels in closed syllables. This is still the situation in modern Spanish, for example. In French, however, both [e/ɛ] and [o/ɔ] were partly rephonemicized: Both /e/ and /ɛ/ occur in open syllables as a result of /aj/ > /ɛ/, and both /o/ and /ɔ/ occur in closed syllables as a result of /al/ > /au/ > /o/.
Old French also had numerous falling diphthongs resulting from diphthongization before palatal consonants or from a fronted /j/ originally following palatal consonants in Proto-Romance or later: e.g. "pācem" /patsʲe/ "peace" > PWR */padzʲe/ (lenition) > OF "paiz" /pajts/; *"punctum" "point" > Gallo-Romance */ponʲto/ > */pojɲto/ (fronting) > OF "point" /põjnt/. During the Old French period, preconsonantal /l/ [ɫ] vocalized to /w/, producing many new falling diphthongs: e.g. "dulcem" "sweet" > PWR */doltsʲe/ > OF "dolz" /duɫts/ > "douz" /duts/; "fallet" "fails, is deficient" > OF "falt" > "faut" "is needed"; "bellus" "beautiful" > OF "bels" [bɛɫs] > "beaus" [bɛaws]. By the end of the Middle French period, "all" falling diphthongs either monophthongized or switched to rising diphthongs: proto OF /aj ɛj jɛj ej jej wɔj oj uj al ɛl el il ɔl ol ul/ > early OF /aj ɛj i ej yj oj yj aw ɛaw ew i ɔw ow y/ > modern spelling ⟨ai ei i oi ui oi ui au eau eu i ou ou u⟩ > mod. French /ɛ ɛ i wa ɥi wa ɥi o o ø i u u y/.
Nasalization.
In both French and Portuguese, nasal vowels eventually developed from sequences of a vowel followed by a nasal consonant (/m/ or /n/). Originally, all vowels in both languages were nasalized before any nasal consonants, and nasal consonants not immediately followed by a vowel were eventually dropped. In French, nasal vowels before remaining nasal consonants were subsequently denasalized, but not before causing the vowels to lower somewhat, e.g. "dōnat" "he gives" > OF "dune" /dunə/ > "donne" /dɔn/, "fēminam" > "femme" /fam/. Other vowels remained diphthongized, and were dramatically lowered: "fīnem" "end" > "fin" /fɛ̃/ (often pronounced [fæ̃]); "linguam" "tongue" > "langue" /lɑ̃ɡ/; "ūnum" "one" > "un" /œ̃/, /ɛ̃/.
In Portuguese, /n/ between vowels was dropped, and the resulting hiatus eliminated through vowel contraction of various sorts, often producing diphthongs: "manum, *manōs" > PWR *"manu, ˈmanos" "hand(s)" > "mão, mãos" /mɐ̃w̃, mɐ̃w̃s/; "canem, canēs" "dog(s)" > PWR *"kane, ˈkanes" > *"can, ˈcanes" > "cão, cães" /kɐ̃w̃, kɐ̃j̃s/; "ratiōnem, ratiōnēs" "reason(s)" > PWR *"raˈdʲzʲone, raˈdʲzʲones" > *"raˈdzon, raˈdzones" > "razão, razões" /χaˈzɐ̃w̃, χaˈzõj̃s/ (Brazil), /ʁaˈzɐ̃ũ, ʁɐˈzõj̃s/ (Portugal). Sometimes the nasalization was eliminated: "lūna" "moon" > Old Portuguese "lũa" > "lua"; "vēna" "vein" > Old Portuguese "vẽa" > "veia". Nasal vowels that remained actually tend to be raised (rather than lowered, as in French): "fīnem" "end" > "fim" /fĩ/; "centum" "hundred" > PWR "tʲsʲɛnto" > "cento" /ˈsẽtu/; "pontem" "bridge" > PWR "pɔnte" > "ponte" /ˈpõtʃi/ (Brazil), /ˈpõtɨ/ (Portugal). In Portugal, vowels before a nasal consonant have become denasalized, but in Brazil they remain heavily nasalized.
Front-rounded vowels.
Characteristic of the Gallo-Romance languages and Rhaeto-Romance languages are the front rounded vowels /y ø œ/. All of these languages show an unconditional change /u/ > /y/, e.g. "lūnam" > French "lune" /lyn/, Occitan /ˈlyno/. Many of the languages in Switzerland and Italy show the further change /y/ > /i/. Also very common is some variation of the French development /ɔː oː/ (lengthened in open syllables) > /we ew/ > /œ œ/, with mid back vowels diphthongizing in some circumstances and then re-monophthongizing into mid-front rounded vowels. (French has both /ø/ and /œ/, with /ø/ developing from /œ/ in certain circumstances.)
Unstressed vowels.
There was more variability in the result of the unstressed vowels. Originally in Proto-Romance, the same nine vowels developed in unstressed as stressed syllables, and in Sardinian, they coalesced into the same five vowels in the same way.
In Italo-Western Romance, however, vowels in unstressed syllables were significantly different from stressed vowels, with yet a third outcome for final unstressed syllables. In non-final unstressed syllables, the seven-vowel system of stressed syllables developed, but then the low-mid vowels /ɛ ɔ/ merged into the high-mid vowels /e o/. This system is still preserved, largely or completely, in all of the conservative Romance languages (e.g. Italian, Spanish, Portuguese, Catalan).
In final unstressed syllables, results were somewhat complex. One of the more difficult issues is the development of final short "-u", which appears to have been raised to /u/ rather than lowered to /o/, as happened in all other syllables. However, it is possible that in reality, final /u/ comes from "long" *"-ū" < "-um", where original final "-m" caused vowel lengthening as well as nasalization. Evidence of this comes from Rhaeto-Romance, in particular Sursilvan, which preserves reflexes of both final "-us" and "-um", and where the latter, but not the former, triggers metaphony. This suggests the development "-us" > /ʊs/ > /os/, but "-um" > /ũː/ > /u/.
The original five-vowel system in final unstressed syllables was preserved as-is in some of the more conservative central Italian languages, but in most languages there was further coalescence:
Various later changes happened in individual languages, e.g.:
Intertonic vowels.
The so-called "intertonic vowels" are word-internal unstressed vowels, i.e. not in the initial, final, or "tonic" (i.e. stressed) syllable, hence intertonic. Intertonic vowels were the most subject to loss or modification. Already in Vulgar Latin intertonic vowels between a single consonant and a following /r/ or /l/ tended to drop: "vétulum" "old" > "veclum" > Dalmatian "vieklo", Sicilian "vecchiu", Portuguese "velho". But many languages ultimately dropped almost all intertonic vowels.
Generally, those languages south and east of the La Spezia–Rimini Line (Romanian and Central-Southern Italian) maintained intertonic vowels, while those to the north and west (Western Romance) dropped all except /a/. Standard Italian generally maintained intertonic vowels, but typically raised unstressed /e/ > /i/. Examples:
Portuguese is more conservative in maintaining some intertonic vowels other than /a/: e.g. *"offerḗscere" "to offer" > Portuguese "oferecer" vs. Spanish "ofrecer", French "offrir" (< *"offerīre"). French, on the other hand, drops even intertonic /a/ after the stress: "Stéphanum" "Stephen" > Spanish "Esteban" but Old French "Estievne" > French "Étienne". Many cases of /a/ before the stress also ultimately dropped in French: "sacraméntum" "sacrament" > Old French "sairement" > French "serment" "oath".
Writing systems.
The Romance languages for the most part have kept the writing system of Latin, adapting it to their evolution.
One exception was Romanian before the nineteenth century, where, after the Roman retreat, literacy was reintroduced through the Romanian Cyrillic alphabet, a Slavic influence. A Cyrillic alphabet was also used for Romanian (Moldovan) in the USSR. The non-Christian populations of Spain also used the scripts of their religions (Arabic and Hebrew) to write Romance languages such as Ladino and Mozarabic in "aljamiado".
Letters.
The Romance languages are written with the classical Latin alphabet of 23 letters – "A", "B", "C", "D", "E", "F", "G", "H", "I", "K", "L", "M", "N", "O", "P", "Q", "R", "S", "T", "V", "X", "Y", "Z" – subsequently modified and augmented in various ways. In particular, the single Latin letter "V" split into "V" (consonant) and "U" (vowel), and the letter "I" split into "I" and "J". The Latin letter "K" and the new letter "W", which came to be widely used in Germanic languages, are seldom used in most Romance languages – mostly for unassimilated foreign names and words. Indeed in Italian prose "*kilometro" is properly "chilometro." Catalan eschews importation of "foreign" letters more than most languages. Thus Wikipedia becomes "Viquipèdia" in Catalan but remains "Wikipedia" in Spanish.
While most of the 23 basic Latin letters have maintained their phonetic value, for some of them it has diverged considerably; and the new letters added since the Middle Ages have been put to different uses in different scripts. Some letters, notably "H" and "Q", have been variously combined in digraphs or trigraphs (see below) to represent phonetic phenomena that could not be recorded with the basic Latin alphabet, or to get around previously established spelling conventions. Most languages added auxiliary marks (diacritics) to some letters, for these and other purposes.
The spelling rules of most Romance languages are fairly simple, but subject to considerable regional variation. The letters with most conspicuous phonetic variations, between Romance languages or with respect to Latin, are:
Otherwise, letters that are not combined as digraphs generally have the same sounds as in the International Phonetic Alphabet (IPA), whose design was, in fact, greatly influenced by the Romance spelling systems.
Digraphs and trigraphs.
Since most Romance languages have more sounds than can be accommodated in the Roman Latin alphabet they all resort to the use of digraphs and trigraphs – combinations of two or three letters with a single sound value. The concept (but not the actual combinations) is derived from Classical Latin, which used, for example, "TH", "PH", and "CH" when transliterating the Greek letters "θ", "ϕ" (later "φ"), and "χ". These were once aspirated sounds in Greek before changing to corresponding fricatives, and the "H" represented what sounded to the Romans like an /ʰ/ following /t/, /p/, and /k/ respectively. Some of the digraphs used in modern scripts are:
While the digraphs "CH", "PH", "RH" and "TH" were at one time used in many words of Greek origin, most languages have now replaced them with "C/QU", "F", "R" and "T". Only French has kept these etymological spellings, which now represent /k/ or /ʃ/, /f/, /ʀ/ and /t/, respectively.
Double consonants.
Gemination, in the languages where it occurs, is usually indicated by doubling the consonant, except when it does not contrast phonemically with the corresponding short consonant, in which case gemination is not indicated. In Jèrriais, long consonants are marked with an apostrophe: "S'S" is a long /zz/, "SS'S" is a long /ss/, and "T'T" is a long /tt/. Phonemic contrast of geminates vs. single consonants is widespread in Italian, and normally indicated in the traditional orthography: "fatto" /fatto/ 'done' vs. "fato" /fato/ 'fate, destiny'; "cadde" /kadde/ 's/he, it fell' vs. "cade" /kade/ 's/he, it falls'. The double consonants in French orthography, however, are merely etymological. In Catalan, the gemination of the "l" is marked by a "punt volat" = "flying point" – "l·l".
Diacritics.
Romance languages also introduced various marks (diacritics) that may be attached to some letters, for various purposes. In some cases, diacritics are used as an alternative to digraphs and trigraphs; namely to represent a larger number of sounds than would be possible with the basic alphabet, or to distinguish between sounds that were previously written the same. Diacritics are also used to mark word stress, to indicate exceptional pronunciation of letters in certain words, and to distinguish words with same pronunciation (homophones).
Depending on the language, some letter-diacritic combinations may be considered distinct letters, e.g. for the purposes of lexical sorting. This is the case, for example, of Romanian "ș" ([ʃ]) and Spanish "ñ" ([ɲ]).
The following are the most common use of diacritics in Romance languages.
Upper and lower case.
Most languages are written with a mixture of two distinct but phonetically identical variants or "cases" of the alphabet: majuscule ("uppercase" or "capital letters"), derived from Roman stone-carved letter shapes, and minuscule ("lowercase"), derived from Carolingian writing and Medieval quill pen handwriting which were later adapted by printers in the fifteenth and sixteenth centuries.
In particular, all Romance languages presently capitalize (use uppercase for the first letter of) the following words: the first word of each complete sentence, most words in names of people, places, and organizations, and most words in titles of books. The Romance languages do not follow the German practice of capitalizing all nouns including common ones. Unlike English, the names of months, days of the weeks, and derivatives of proper nouns are usually not capitalized: thus, in Italian one capitalizes "Francia" ("France") and "Francesco" ("Francis"), but not "francese" ("French") or "francescano" ("Franciscan"). However, each language has some exceptions to this general rule.
Vocabulary comparison.
The tables below provide a vocabulary comparison that illustrates a number of examples of sound shifts that have occurred between Latin and Romance languages, along with a selection of minority languages. Words are given in their conventional spellings. In addition, for French the actual pronunciation is given, due to the dramatic differences between spelling and pronunciation. (French spelling approximately reflects the pronunciation of Old French, c. 1200 AD.)
References.
Overviews:
Sound Changes:
Lexicon:
French:
Portuguese:
Spanish:
Italian:

</doc>
<doc id="25402" url="http://en.wikipedia.org/wiki?curid=25402" title="Rugby football">
Rugby football

Rugby football is a style of football that developed at Rugby School and was one of many versions of football played at English public schools during the 19th century. The two main types of rugby are rugby league and rugby union. Although these two forms share the same objective of getting the ball over the line to score a try, the specific rules are different.
History.
In 1871, English clubs met to form the Rugby Football Union (RFU). In 1892, after charges of professionalism (compensation of team members) were made against some clubs for paying players for missing work, the Northern Rugby Football Union, usually called the Northern Union (NU), was formed. The existing rugby union authorities responded by issuing sanctions against the clubs, players, and officials involved in the new organization. After the schism, the separate clubs were named "rugby league" and "rugby union".
Global status of rugby codes.
Rugby union is both a professional and amateur game, and is dominated by the first tier unions: Argentina, Australia, England, France, Ireland, Italy, New Zealand, Scotland, South Africa and Wales. Second and third tier unions include Brazil, Canada, Chile, Colombia, Fiji, Georgia, Japan, Mexico, Namibia, Peru, Portugal, Romania, Russia, Samoa, Spain, Tonga, the United States, Uruguay and Venezuela. Rugby Union is administered by the International Rugby Board (IRB), whose headquarters are located in Dublin, Ireland. It is the national sport in New Zealand, Wales, Fiji, Samoa, Tonga and Madagascar, and is the most popular form of rugby globally, with the seven-a-side version of the game, known as Rugby sevens, having been admitted into the programme of the Olympic Games from Rio de Janeiro in 2016 onwards. There was a possibility sevens would be a demonstration sport at the 2012 London Olympics but many sports including sevens were dropped.
In Canada and the United States, rugby union evolved into gridiron football. During the late 1800s (and even the early 1900s), the two forms of the game were very similar (to the point where the United States was able to win the gold medal for rugby union at the 1924 Summer Olympics), but numerous rule changes have differentiated the gridiron-based game from its rugby counterpart. Among unique features of the North American game are the separation of play into downs instead of releasing the ball immediately upon tackling, the requirement that the team with the ball set into a set formation for at least one second before resuming play after a tackle (and the allowance of up to 40 seconds to do so), the allowance for one forward pass from behind the site of the last tackle on each down, the evolution of hard plastic equipment (particularly the football helmet and shoulder pads), a smaller and pointier ball that is favorable to being passed but makes drop kicks impractical, a generally smaller and narrower field measured in customary units instead of metric (in some variants of the American game a field can be as short as 50 yards between end zones), and a distinctive field (shaped like a gridiron, from which the code's nickname is derived) with lines marked in five-yard intervals.
Rugby league is also both a professional and amateur game, administered on a global level by the Rugby League International Federation. In addition to amateur and semi-professional competitions in the United States, Russia, Lebanon, Serbia, Europe and Australasia, there are two major professional competitions—the Australasian National Rugby League and the European Super League. International Rugby League is dominated by Australia, England and New Zealand. Other nations from the South Pacific and Europe also play in the Pacific Cup and European Cup respectively.
Laws.
Distinctive features common to both rugby codes include the oval ball and the throwing the ball forward is not allowed, so that players can gain ground only by running with the ball or by kicking it. As the sport of rugby league moved further away from its union counterpart, rule changes were implemented with the aim of making a faster-paced and more try-orientated game.
The main differences between the two games, besides league having teams of 13 players and union of 15, involve the tackle and its aftermath:
Set pieces of the union code include the "scrum", in which packs of opposing players push against each other for possession, and the "line-out", in which parallel lines of players from each team, arranged perpendicular to the touch-line, attempt to catch the ball thrown from touch. A rule has been added to line-outs which allows the jumper to be pulled down once a players's feet are on the ground.
In the league code, the scrum still exists, but with greatly reduced importance as it involves fewer players and is rarely contested. Set pieces are generally started from the play-the-ball situation. Many of the rugby league positions have similar names and requirements to rugby union positions, but there are no flankers in rugby league.
Culture.
Home countries.
In England, rugby union is widely regarded as an "establishment" sport, played mostly by members of the upper and middle classes. For example, many pupils at public schools and grammar schools play rugby union, although the game (which had a long history of being played at state schools until the 1980s) is becoming increasingly popular in comprehensive schools. Despite this stereotype, the game, particularly in the West Country is popular amongst all classes. In contrast, rugby league has traditionally been seen as a working class pursuit. Another exception to rugby union's upper class stereotype is in Wales, where it has been traditionally associated with small village teams made up of coal miners and other industrial workers who played on their days off. In Ireland, rugby union is a unifying force across the national and sectarian divide, with the Ireland international team representing both political entities.
In Australia, support for both codes is concentrated in New South Wales, Queensland and the Australian Capital Territory. The same perceived class barrier as exists between the two games in England also occurs in these states, fostered by rugby union's prominence and support at private schools.
Exceptions to the above include New Zealand (although rugby league is still considered to be a lower class game by many or a game for 'westies' referring to lower class western suburbs of Auckland and more recently, southern Auckland where the game is also popular), Wales, France (except Paris), Cornwall, Gloucestershire, Somerset, Scottish Borders, County Limerick (see Munster) and the Pacific Islands, where rugby union is popular in working class communities. Nevertheless, rugby league is perceived as the game of the working-class people in northern England and in the Australian states of New South Wales and Queensland.
In the United Kingdom, rugby union fans sometimes used the term "rugger" as an alternative name for the sport, (see Oxford '-er'), although this archaic expression has not had currency since the 1950s or earlier. New Zealanders refer to rugby union simply as either "rugby" or "union", or even simply "football", and to rugby league as "rugby league" or "league". In the U.S., people who play rugby are sometimes called "ruggers", a term little used elsewhere except facetiously.
Those considered to be heavily involved with the rugby union lifestyle—including heavy drinking and striped jumpers—sometimes identify as “rugger buggers”. 
Internationally.
In France, rugby is widely played and has a strong tradition in the Basque, Occitan and Catalan areas along the border regions between Spain and France. The game is very popular in South Africa, having been introduced by English-speaking settlers in the 19th century. British colonists also brought the game with them to Australia and New Zealand, where the game is widely played. It has spread thence to much of Polynesia, having particularly strong followings in Fiji, Samoa and Tonga. Rugby union continues to grow in the Americas and parts of Asia as well.
Rugby ball.
In rugby union, the International Rugby Board regulates the size and shape of the ball under Law 2 (also known as Law E.R.B); an official rugby union ball is oval and made of four panels, has a length in-line of 280–300 millimetres, a circumference (end to end) of 740–770 millimetres, and a circumference (in width) of 580–620 millimetres. It is made of leather or suitable synthetic material, and may be treated to make it water resistant and easier to grip. The rugby ball may not weigh more than 460 grams or less than 410 and has an air pressure of 65.71–68.75 kilopascals, or 0.67–0.70 kilograms per square centimetre, or 9.5–10.0 lbs per square inch. Spare balls are allowed under the condition that players or teams do not seek an advantage by changing the ball. Smaller sized balls may also be used in games between younger players.
Much larger versions of traditional balls are also available for purchase, but these are mainly for their novelty attraction.
World Cups.
The Rugby World Cup, which was first held in New Zealand and Australia in 1987, occurs every four years. It is an international tournament organized by the International Rugby Board. The event is played in the union format and features the top 20 teams from around the world.
The current world champions are New Zealand. The next world cup is to be held in 2015 in England.
The Rugby League World Cup was first held in France in 1954, and as of 2013 occurs on a 4-year cycle. It is an international tournament that is organized by the Rugby League International Federation. The event is played in the league format and features the top 14 teams from around the world.
The current world champions are Australia, who won the world cup in 2013, played in England, Wales, France and Ireland.
Rugby shirt.
Rugby shirts were formerly made of cotton but are now made of a cotton and polyester mix. This material has the advantage of not absorbing as much water or mud as cotton alone. Owing to the more aggressive nature of the game, rugby clothing in general is designed to be much more robust and hardwearing than that worn for soccer.
The rugby jerseys are slightly different depending on the type of rugby game played. The shirts worn by rugby league players commonly have a large "V" around the neck. The players in rugby union wear jerseys with a more traditional design, sometimes completely white (Cahors Rugby in France). The number of the player and his or her surname are placed on the upper back of the jersey (often name above number, with the number being significantly larger and more central), and the logo of the team on the upper left chest.
Rugby betting.
With the popularity of rugby over the years, many betting establishments have made it possible for viewers of the game to place wagers on games. The various types of wagers that can be placed on games vary, however the main types of bets that can be placed are as follows:
Like most team sports, both forms of rugby are vulnerable to match fixing, particularly bets involving easily manipulated outcomes, such as conceding penalties and first point scorer. A recent example is a deliberate infringement by Ryan Tandy in order for the first points scored to be a penalty goal in a 2010 NRL match; the attempt backfired when instead of taking a shot at goal, a try was scored.

</doc>
<doc id="25403" url="http://en.wikipedia.org/wiki?curid=25403" title="Russian">
Russian

Russian refers to anything related to Russia, including:
Russian may also refer to:

</doc>
<doc id="25405" url="http://en.wikipedia.org/wiki?curid=25405" title="Rugby union">
Rugby union

Rugby union football, usually called rugby union, or simply rugby, is a contact team sport which originated in England during the first half of the 19th century. One of the two codes of rugby football, it is based on running with the ball in hand. In its most common form a game is between two teams of 15 players using an oval-shaped ball on a rectangular field with H-shaped goalposts on each try line.
William Webb Ellis is often credited with the innovation of running with the ball in hand in 1823 at Rugby School when he allegedly caught the ball while playing football and ran towards the opposition goal. However, the evidence for the story is doubtful. In 1845, the first football laws were written by Rugby School pupils; other significant events in the early development of rugby include the Blackheath Club's decision to leave the Football Association in 1863 and the split between rugby union and rugby league in 1895. Historically an amateur sport, in 1995 World Rugby (WR) removed restrictions on payments to players, making the game openly professional at the highest level for the first time.
World Rugby, originally known as the International Rugby Football Board (IRFB) and from 1998 to November 2014 known as the International Rugby Board (IRB), has been the governing body for rugby union since its formation in 1886. Rugby union spread from the Home Nations of Great Britain and Ireland, and was absorbed by many of the countries associated with the British Empire. Early exponents of the sport included Australia, New Zealand and South Africa. Countries that have adopted rugby union as their "de facto" national sport include Fiji, Georgia, Madagascar, New Zealand, Samoa, Tonga and Wales. Rugby union is played in over 100 countries across six continents and as of 2014, WR has 101 full members and 18 associate members.
The Rugby World Cup, first held in 1987, takes place every four years with the winner of the tournament receiving the Webb Ellis Cup. The Six Nations Championship in Europe and The Rugby Championship in the Southern Hemisphere (the latter replacing the Tri Nations) are major international competitions held annually.
Major domestic competitions include the English Premiership in England, Top 14 in France, the ITM Cup in New Zealand and the Currie Cup in South Africa. Other transnational competitions include the Pro12, involving Irish, Italian, Scottish and Welsh teams; the European Rugby Champions Cup, involving the top European teams from their respective domestic competitions; and Super Rugby, involving Australian, New Zealand and South African teams and set to add teams in Argentina and Japan in 2016.
History.
The origin of rugby football is reputed to be an incident during a game of English school football at Rugby School in 1823 when William Webb Ellis is said to have picked up the ball and run with it. Although the evidence for the story is doubtful, it was immortalised at the school with a plaque unveiled in 1895. Despite the doubtful evidence, the Rugby World Cup trophy is named after Webb Ellis. Rugby football stems from the form of game played at Rugby School, which former pupils then introduced to their university. Old Rugbeian Albert Pell, a student at Cambridge, is credited with having formed the first "football" team. During this early period different schools used different rules, with former pupils from Rugby and Eton attempting to carry their preferred rules through to their universities.
A significant event in the early development of rugby football was the production of the first written laws of the game at Rugby School in 1845, which was followed by the 'Cambridge Rules' drawn up in 1848. Other important events include the Blackheath Club's decision to leave the Football Association in 1863 and the formation of the Rugby Football Union in 1871. The code was originally known as "rugby football"; it was not until after the schism in England in 1895, which resulted in the separate code of rugby league, that the sport took on the name "rugby union" to differentiate it from the league game. Despite the sport's full name of rugby union, it is known simply as rugby throughout most of the world.
The first rugby football international was played on 27 March 1871 between England and Scotland. By 1881 both Ireland and Wales had representative teams, and in 1883 the first international competition, the Home Nations Championship had begun. 1883 is also the year of the first rugby sevens tournament, the Melrose Sevens, which is still held annually. Five years later two important overseas tours took place: a British Isles team visited Australia and New Zealand—although a private venture, it laid the foundations for future British and Irish Lions tours; and the 1888–89 New Zealand Native football team brought the first overseas team to British spectators.
Between 1905 and 1908, all three major Southern Hemisphere rugby countries sent their first touring teams to the Northern Hemisphere: New Zealand in 1905, followed by South Africa in 1906 and Australia in 1908. All three teams brought new styles of play, fitness levels and tactics, and were far more successful than critics had expected. The New Zealand 1905 touring team performed a haka before each match, leading Welsh Rugby Union administrator Tom Williams to suggest that Wales player Teddy Morgan lead the crowd in singing the Welsh National Anthem, "Hen Wlad Fy Nhadau", as a response. After Morgan began singing, the crowd joined in: the first time a national anthem was sung at the start of a sporting event. In 1905 France played England in its first international match.
No international rugby games and union-sponsored club matches were played during the First World War, but competitions continued through service teams such as the New Zealand Army team. During the Second World War no international matches were played by most countries, though Italy, Germany and Romania played a limited number of games, and Cambridge and Oxford continued their annual University Match.
Rugby union was included as an event in the Olympic Games four times during the early 20th century. In 1973 the first officially sanctioned international sevens tournament took place at Murrayfield, one of Scotland's biggest stadiums, as part of the Scottish Rugby Union centenary celebrations. In 1987 the first Rugby World Cup was held in Australia and New Zealand, and the inaugural winners were New Zealand. The first World Cup Sevens tournament was held at Murrayfield in 1993. Rugby Sevens was introduced into the Commonwealth Games in 1998 and has been added to the Olympic Games of 2016.
Rugby union was an amateur sport until the IRB declared the game "open" in 1995, removing restrictions on payments to players. However, the pre-1995 period of rugby union was marked by frequent accusations of "shamateurism", including an investigation in Britain by a House of Commons Select committee. Following the introduction of professionalism trans-national club competitions were started, with the Heineken Cup in the Northern Hemisphere and Super Rugby in the Southern Hemisphere. The Tri Nations, an annual international tournament involving Australia, New Zealand and South Africa, kicked off in 1996. In 2012, this competition was extended to include Argentina, a country whose impressive performances in international games (especially finishing in third place in the 2007 Rugby World Cup) was deemed to merit inclusion in the competition. As a result of the expansion to four teams, the tournament was renamed The Rugby Championship.
Teams and positions.
Each team starts the match with 15 players on the field and seven or eight substitutes. Players in a team are divided into eight forwards (two more than in rugby league) and seven backs.
Forwards.
The main responsibilities of the forward players are to gain and retain possession of the ball. Players in these positions are generally bigger and stronger and take part in the scrum and line-out. The forwards are often collectively referred to as the 'pack', especially when in the scrum formation.
Front row
The front row consists of three players: two props (the loosehead prop and the tighthead prop) and the hooker. The role of the two props is to support the hooker during scrums, to provide support for the jumpers during line-outs and to provide strength and power in rucks and mauls. The third position in the front row is the hooker. The hooker is a key position in attacking and defensive play and is responsible for winning the ball in the scrum. Hookers normally throw the ball in at line-outs.
Second row
The second row consists of two locks or lock forwards. Locks are usually the tallest players in the team, and specialise as line-out jumpers. The main role of the lock in line-outs is to make a standing jump, often supported by the other forwards, to either collect the thrown ball or ensure the ball comes down on their side. Locks also have an important role in the scrum, binding directly behind the three front row players and providing forward drive.
Back row
The back row, not to be confused with ‘Backs’, is the third and final row of the forward positions, they are often referred to as the loose forwards. The three positions in the back row are the two flankers and the number 8. The two flanker positions, called the blindside flanker and openside flanker, are the final row in the scrum. They are usually the most mobile forwards in the game. Their main role is to win possession through 'turn overs'. The number 8 packs down between the two locks at the back of the scrum. His role in the scrum is to control the ball after it has been heeled back from the front of the pack and the position provides a link between the forwards and backs during attacking phases.
Backs.
The backs' role is to create and convert point-scoring opportunities. They are generally smaller, faster and more agile than the forwards. Another distinction between the backs and the forwards is that the backs are expected to have superior kicking skills, especially the fly-half and full-back.
Half-backs
The half-backs consist of two positions, the scrum-half and the fly-half. The fly-half is crucial to a team's game plan, orchestrating the team's performance. They are usually the first to receive the ball from the scrum-half following a breakdown, lineout, or scrum, and need to be decisive with what actions to take and be effective at communicating with the outside backs. Many fly-halfs are also their team's goal kickers. The scrum-half is the link between the forwards and the backs. They receive the ball from the lineout and remove the ball from the back of the scrum, usually passing it to the fly-half. They also feed the scrum and sometimes have to act as a fourth loose forward.
Three quarters
There are four three quarter positions, the inside centre, outside centre and left and right wings. The centres will attempt to tackle attacking players; whilst in attack they should employ speed and strength to breach opposition defences. The wings are generally positioned on the outside of the backline. Their primary function is to finish off moves and score tries. Wings are usually the fastest players in the team and are elusive runners who use their speed to avoid tackles.
Fullbacks
The fullback normally positions himself several metres behind the back line. He fields any opposition kicks and is often the last line of defence should an opponent break through the back line. Two of the most important attributes of a good fullback are dependable catching skills and a good kicking game.
Laws.
Scoring.
Rugby union is played between two teams – the one that scores more points wins the game. Points can be scored in several ways: a try, scored by grounding the ball in the in-goal area (between the goal line and the dead ball line), is worth 5 points and a subsequent conversion kick scores 2 points; a successful penalty kick or a drop goal each score 3 points. The values of each of these scoring methods have been changed over the years.
Playing field.
The field of play on a rugby pitch is as near as possible to a maximum of 144 m long by 70 m wide. In actual gameplay there should be a maximum of 100 m between the two try-lines, with anywhere between 10 and 22 metres behind each try line to serve as the in-goal area. There are several lines crossing it, notably the half way line and the "twenty two", which is 22 m from the goal line.
Stricter rules apply to the pitch size for matches between national representative teams. The same maximums apply in this case, but the distance between the two try-lines must also be at least 94 m and the pitch must be at least 68 m wide.
Rugby goalposts are H-shaped, and consist of two poles, 5.6 m apart, connected by a horizontal crossbar 3 m above the ground. The original pitch dimensions were in imperial units, but have since been converted to the metric system.
Match structure.
At the beginning of the game, the captains and the referee toss a coin to decide which team will kick off first. Play then starts with a drop kick, with the players chasing the ball into the opposition's territory, and the other side trying to retrieve the ball and advance it. If the ball does not reach the opponent’s 10-metre line the opposing team has two choices: to have the ball kicked off again, or to have a scrum at the centre of the half-way line and they throw in the ball.
If the player with the ball is tackled, frequently a ruck will result.
Games are divided into 40-minute halves, with a break in the middle. The sides exchange ends of the field after the half-time break. Stoppages for injury or to allow the referee to take disciplinary action do not count as part of the playing time, so that the elapsed time is usually longer than 80 minutes. The referee is responsible for keeping time, even when—as in many professional tournaments—he is assisted by an official time-keeper. If time expires while the ball is in play, the game continues until the ball is "dead", and only then will the referee blow the whistle to signal half-time or full-time; but if the referee awards a penalty or free-kick, the game continues.
In the knockout stages of rugby competitions, most notably the Rugby World Cup, two extra time periods of 10 minutes periods are played (with an interval of 5 minutes in between) if the game is tied after full-time. If scores are level after 100 minutes then the rules call for 20 minutes of sudden-death extra time to be played. If the sudden-death extra time period results in no scoring a kicking competition is used to determine the winner. However, no match in the history of the Rugby World Cup has ever gone past 100 minutes into a sudden-death extra time period.
Passing and kicking.
Forward passing (throwing the ball ahead to another player) is not allowed; the ball can be passed laterally or backwards. The ball tends to be moved forward in three ways — by kicking, by a player running with it or within a scrum or maul. Only the player with the ball may be tackled or rucked. When a ball is knocked forward by a player with his/her arms, a "knock-on" is committed, and play is restarted with a scrum.
Any player may kick the ball forward in an attempt to gain territory. When a player anywhere in the playing area kicks indirectly into touch so that the ball first bounces in the field of play the throw-in is taken where the ball went into touch. If the player kicks directly into touch (i.e. without bouncing in-field first) from within their own 22-metre line the lineout is taken by the opposition where the ball went into touch, but if the ball is kicked into touch directly by a player outside the 22-metre line the lineout is taken level to where the kick was taken.
Breakdowns.
The aim of the defending side is to stop the player with the ball, either by bringing them to ground (a tackle, which is frequently followed by a ruck), or by contesting for possession with the ball-carrier on their feet (a maul). Such a circumstance is called a breakdown and each is governed by a specific law.
A player may tackle an opposing player who has the ball by holding them while bringing them to ground. Tacklers cannot tackle above the shoulder (the neck and head are out of bounds), and the tackler has to attempt to wrap their arms around the player being tackled to complete the tackle. It is illegal to push, shoulder-charge, or to trip a player using feet or legs, but hands may be used (this being referred to as a tap-tackle or ankle-tap).
Mauls occur after a player with the ball has come into contact with an opponent but the handler remains on his feet; once any combination of at least three players have bound themselves a maul has been set. A ruck is similar to the maul, but in this case the ball has gone to ground with at least three attacking players binding themselves on the ground in an attempt to secure the ball.
Set pieces.
Lineout.
When the ball leaves the side of the field, a line-out is awarded against the team which last touched the ball. Forward players from each team line up a metre apart, perpendicular to the touchline and between 5 m and 15 m from the touchline. The ball is thrown from the touchline down the centre of the lines of forwards by a player (usually the hooker) from the team that did not play the ball into touch. The exception to this is when the ball went out from a penalty, in which case the side who gained the penalty throws the ball in.
Both sides compete for the ball and players may lift their teammates. A jumping player cannot be tackled until they stand and only shoulder-to-shoulder contact is allowed; deliberate infringement of this law is dangerous play, and results in a penalty kick.
Scrum.
A scrum is a way of restarting the game safely and fairly after a minor infringement. It is awarded when the ball has been knocked or passed forward, if a player takes the ball over his own try line and puts the ball down, when a player is accidentally offside or when the ball is trapped in a ruck or maul with no realistic chance of being retrieved. A team may also opt for a scrum if awarded a penalty.
A scrum is formed by the eight forwards from each team binding together in three rows. The front row consists of the two props (loosehead and tighthead) either side of the hooker. The second row consists of two locks and the two flankers. Behind the second row is the number 8. This formation is known as the 3–4–1 formation. Once a scrum is formed the scrum-half from the team awarded the "feed" rolls the ball into the gap between the two front-rows known as the "tunnel". The two hookers then compete for possession by hooking the ball backwards with their feet, while each pack tries to push the opposing pack backwards to help gain possession. The side that wins possession transfers the ball to the back of the scrum, where it is picked up either by the number 8 or by the scrum-half.
Officials and offences.
There are three match officials: a referee, and two assistant referees. The latter, formerly known as touch judges, had the primary function of indicating when the ball had gone "touch"; their role has been expanded and they are now expected to assist the referee in a number of areas, such as watching for foul play and checking off-side lines. In addition, for matches in high level competitions, there is often a television match official (TMO; popularly called the "video referee"), to assist with certain decisions, linked up to the referee by radio. The referees have a system of hand signals to indicate their decisions.
Common offences include tackling above the shoulders, collapsing a scrum, ruck or maul, not releasing the ball when on the ground, or being off-side. The non-offending team has a number of options when awarded a penalty: a "tap" kick, when the ball is kicked a very short distance from hand, allowing the kicker to regather the ball and run with it; a punt, when the ball is kicked a long distance from hand, for field position; a place-kick, when the kicker will attempt to score a goal; or a scrum. Players may be sent off (signalled by a red card) or temporarily suspended ("sin-binned") for ten minutes (yellow card) for foul play or repeated infringements, and may not be replaced.
Occasionally, infringements are not caught by the referee during the match and these may be "cited" by the citing commissioner after the match and have punishments (usually suspension for a number of weeks) imposed on the infringing player.
Replacements and substitutions.
During the match, players may be replaced (for injury) or substituted (for tactical reasons). A player who has been replaced may not rejoin play unless he was temporarily replaced to have bleeding controlled; a player who has been substituted may return temporarily, to replace a player who has a blood injury, or permanently, if he is replacing a front-row forward. In international matches, up to seven replacements are allowed; in domestic or cross-border tournaments, at the discretion of the responsible national union(s), the number may be increased to eight, of whom three must be sufficiently trained and experienced to provide cover for the three front row positions.
Equipment.
The most basic items of equipment for a game of rugby union are the ball itself, a rugby shirt (also known as a "jersey"), rugby shorts, socks and boots. The rugby ball is oval in shape, (technically a prolate spheroid), and is made up of four panels. The ball was historically made of leather, but in the modern era most games use a ball made from a synthetic material. The WR lays out specific dimensions for the ball, 280-300mm in length, 740-770mm in circumference of length and 580-620mm in circumference of width. Rugby boots have soles with studs to allow grip on the turf of the pitch. The studs may be either metal or plastic but must not have any sharp edges or ridges.
Protective equipment is optional and strictly regulated. The most common items are mouthguards, which are worn by almost all players, and are compulsory in some rugby-playing nations. Other protective items that are permitted include head gear; thin (not more than 10 mm thick), non-rigid shoulder pads and shin guards; which are worn underneath socks. Bandages or tape can be worn to support or protect injuries; some players wear tape around the head to protect the ears in scrums and rucks. Female players may also wear chest pads. Although not worn for protection, some types of fingerless mitts are allowed to aid grip.
It is the responsibility of the match officials to check players' clothing and equipment before a game to ensure that it conforms to the laws of the game.
Governing bodies.
The international governing body of rugby union (and associated games such as sevens) is World Rugby (WR). The WR headquarters are in Dublin, Ireland. WR, founded in 1886, governs the sport worldwide and publishes the game's laws and rankings. As of February 2014, WR (then known as the IRB, for International Rugby Board) recorded 119 unions in its membership, 101 full members and 18 associate member countries. According to WR, rugby union is played by men and women in over 100 countries. WR controls the Rugby World Cup, the Women's Rugby World Cup, Rugby World Cup Sevens, HSBC Sevens World Series, Women's Sevens World Series, World Under 20 Championship, World Under 20 Trophy, Nations Cup and the Pacific Nations Cup. WR holds votes to decide where each of these events are be held, except in the case of the Sevens World Series for men and women, for which WR contracts with several national unions to hold individual events.
Six regional associations, which are members of WR, form the next level of administration; these are:
SANZAR (South Africa, New Zealand and Australia Rugby) is a joint venture of the South African Rugby Union, the New Zealand Rugby Union and the Australian Rugby Union that operates Super Rugby and The Rugby Championship (formerly the Tri Nations before the entry of Argentina). Although the Argentine Rugby Union initially has no representation on the SANZAR board, it has been granted input into the organisation's issues, especially with regard to The Rugby Championship.
National unions oversee rugby union within individual countries and are affiliated to WR. The WR Council has 26 seats. Each of the eight foundation unions – Scotland, Ireland, Wales, England, Australia, New Zealand, South Africa and France – have two seats, and Argentina, Canada, Italy, Japan and the six regional associations each have one seat.
Global reach.
The earliest countries to adopt rugby union were England, the country of inception, followed by the other three Home Nations, Scotland, Ireland and Wales. The spread of rugby union as a global sport has its roots in the exporting of the game by British expatriates, military personnel and over-seas university students.
The first rugby club in France was formed by British residents in Le Havre in 1872, while the next year Argentina recorded its first game: 'Banks' v 'City' in Buenos Aires.
At least six countries have adopted rugby union as their de facto national sport; they are Fiji, Georgia, New Zealand, Samoa, Tonga and Wales.
Oceania.
A rugby club was formed in Sydney, New South Wales, Australia in 1864; while the sport was said to have been introduced to New Zealand by Charles Munro in 1870, who played rugby while a student at Christ's College, Finchley.
Several island nations have embraced the sport of rugby. Rugby was first played in Fiji circa 1884 by European and Fijian soldiers of the Native Constabulary at Ba on Viti Levu island. Fiji then sent their first overseas team to Samoa in 1924, who in turn set up their own union in 1927. Along with Tonga, other countries to have national rugby teams in Oceania include the Cook Islands, Niue, Papua New Guinea and the Solomon Islands.
North America and Caribbean.
In North America a club formed in Montreal in 1868, Canada's first club. The city of Montreal also played its part in the introduction of the sport in the United States, when students of McGill University played against a team from Harvard University in 1874.
Although the exact date of arrival of rugby union in Trinidad and Tobago is unknown, their first club Northern RFC was formed in 1923, a national team was playing by 1927 and due to a cancelled tour to British Guiana in 1933, switched their venue to Barbados; introducing rugby to the island. Other Atlantic countries to play rugby union include Jamaica and Bermuda.
Europe.
The growth of rugby union in Europe outside the 6 Nations countries in terms of playing numbers has been sporadic. Historically, British and Irish home teams played the Southern Hemisphere teams of Australia, New Zealand, and South Africa, as well as France. The rest of Europe were let to play amongst themselves . During a period when it had been isolated by the British and Irish Unions, France, lacking international competition, became the only European team from the top tier to regularly play the other European countries; mainly Belgium, the Netherlands, Germany, Spain, Romania, Poland, Italy and Czechoslovakia. In 1934, instigated by the French Rugby Federation, FIRA (Fédération Internationale de Rugby Amateur) was formed to organise rugby union outside the authority of the IRFB. The founding members were Italy, Romania, Netherlands, Portugal, Czechoslovakia, and Sweden. Other European rugby playing nations of note include Russia, whose first officially recorded match is marked by an encounter between Dynamo Moscow and the Moscow Institute of Physical Education in 1933. Rugby union in Portugal also took hold between the First and Second World Wars, with a Portuguese National XV set up in 1922 and an official championship started in 1927.
In 1999, FIRA agreed to place itself under the auspices of the IRB, transforming itself into a strictly European organising body. Accordingly, it changed its name to FIRA–AER (Fédération Internationale de Rugby Amateur – Association Européenne de Rugby). It adopted its current name of Rugby Europe in 2014.
South America.
Although Argentina is the best-known rugby playing nation in South America, founding the Argentine Rugby Union in 1899, several other countries on the continent have a long history. Rugby had been played in Brazil since the end of the 19th century, but the game was played regularly only from 1926, when São Paulo beat Santos in an inter-city match. It took Uruguay several aborted attempts to adapt to rugby, led mainly by the efforts of the Montevideo Cricket Club; these efforts succeeded in 1951 with the formation of a national league and four clubs. Other South American countries that formed a rugby union include Chile (1948), and Paraguay (1968).
Asia.
Many Asian countries have a tradition of playing rugby dating from the British Empire. India began playing rugby in the early 1870s, the Calcutta Football Club forming in 1872. After the withdrawal of the British military from the area at the end of the decade, rugby in India faltered. India's lasting legacy to the sport was the presentation of the Calcutta Cup to the Rugby Football Union; the world's oldest international rugby trophy which is played for annually between England and Scotland. Sri Lanka claims to have founded their union in 1878, and although little official information from the period is available, the team won the All-India cup in Madras in 1920. Malaysia also suffers from poor record keeping. Historically the first recorded match in Malaysia was in 1892, but the first confirmation of rugby is the existence of the "HMS Malaya Cup" which, named after the ship HMS "Malaya", was first presented in 1922 and is still awarded to the winners of the Malay sevens. Rugby union was introduced to Japan in 1899 by Ginnosuke Tanaka a student of Trinity Hall, Cambridge and Edward Bramwell Clarke, who studied at Corpus Christi College, Cambridge. The Japan RFU was founded in 1926 and its place in rugby history was cemented with the news that Japan will host the 2019 World Cup. It will be the first country outside the Commonwealth, Ireland and France to host the event, and is viewed by the IRB as an opportunity for rugby union to extend its reach, particularly in Asia. Other Asian playing countries of note include Singapore, South Korea, China and The Philippines, while the former British colony of Hong Kong is notable within rugby for its development of the rugby sevens game, especially the Hong Kong Sevens tournament which was founded in 1976.
Rugby in the Middle East and the Gulf States has its history in the 1950s, with clubs formed by British and French Services stationed in the region after the Second World War. When these servicemen left, the clubs and teams were kept alive by young professionals, mostly Europeans, working in these countries. The official union of Oman was formed in 1971, with His Majesty Qaboos bin Said al Said as Patron. Bahrain founded its union a year later, while in 1975 the Dubai Sevens, the Gulf's leading rugby tournament, was created by the Dubai Exiles Rugby Club. Rugby remains a minority sport in the region with Israel, as of 2011, being the only member union from the Middle East to be included in the IRB World Rankings.
Africa.
In 1875, rugby was introduced to South Africa by British soldiers garrisoned in Cape Town. During the late 19th and early 20th century, the sport in Africa was spread by settlers and colonials who often adopted a "whites-only" policy to playing the game. This resulted in rugby being viewed as a bourgeois sport by the indigenous people with limited appeal. The earliest countries to see the playing of competitive rugby include South Africa, and neighbouring Rhodesia (modern-day Zimbabwe), which formed the Rhodesia Rugby Football Union in 1895.
In more recent times the sport has been embraced by several African nations. In the early 21st century Madagascar has experienced crowds of 40,000 at national matches, while Namibia, whose history of rugby can be dated from 1915, have qualified for the final stages of the World Cup four times since 1999. Other African nations to be represented in the IRB World Rankings as Member Unions include Côte d'Ivoire, Kenya, Uganda and Zambia. South Africa and Kenya are among the 15 "core teams" that participate in every event of the men's Sevens World Series.
Women's rugby union.
Records of women's rugby football date from the late 19th century, with the first documented source being Emily Valentine's writings, stating that she set up a rugby team in Portora Royal School in Enniskillen, Ireland in 1887. Although there are reports of early women's matches in New Zealand and France, one of the first notable games to prove primary evidence was the 1917 war-time encounter between Cardiff Ladies and Newport Ladies; a photo of which shows the Cardiff team before the match at the Cardiff Arms Park. In the past 30 years the game has grown in popularity among female athletes, and, according to WR, is now played in over 100 countries.
The English-based Women's Rugby Football Union (WRFU), responsible for women's rugby in England, Scotland Ireland and Wales, was founded in 1983, and is the oldest formally organised national governing body for women's rugby. This was replaced in 1994 by the Rugby Football Union for Women (RFUW) in England with each of the other Home Nations governing their own countries. The premier international competition in rugby union for women is the Women's Rugby World Cup, first held in 1991. Since 1994 it has been held every four years.
Major international competitions.
The most important tournament in rugby union is the Rugby World Cup, a men's tournament that takes place every four years among the national rugby union teams. New Zealand is the current cup holder, winning the 2011 tournament held on home ground, beating France 8–7 in the final. No World Cup winner has yet retained the trophy. England (2003) were the first team from the Northern Hemisphere to win, the previous champions being New Zealand (1987 and 2011), Australia (1991 and 1999), and South Africa (1995 and 2007).
Major international competitions are the Six Nations Championship and The Rugby Championship, held in Europe and the Southern Hemisphere respectively.
The Six Nations is an annual competition involving the European teams England, France, Ireland, Italy, Scotland and Wales. Each country plays the other five once. After the initial internationals between England and Scotland, Ireland and Wales began competing in the 1880s, forming the "Home International Championships". France joined the tournament in the 1900s and in 1910 the term "Five Nations" first appeared. However, the Home Nations (England, Ireland, Scotland, and Wales) excluded France in 1931 amid a run of poor results, allegations of professionalism and concerns over on-field violence. France then rejoined in 1939–1940, though World War II halted proceedings for a further eight years. France has played in all the tournaments since WWII, the first of which was played in 1947. In 2000, Italy became the sixth nation in the contest and Rome's Stadio Olimpico has replaced Stadio Flaminio, as the venue for their home games since 2013. The current Six Nations champions are Ireland, who finished the tournament with a 22–20 victory over France.
The Rugby Championship is the Southern Hemisphere's annual international series for that region's top national teams. From its inception in 1996 through 2011, it was known as the Tri Nations, as it featured the hemisphere's traditional powers of Australia, New Zealand and South Africa. These teams have dominated world rankings in recent years, and many considered the Tri Nations to be the toughest competition in international rugby. The Tri Nations was initially played on a home and away basis with the three nations playing each other twice. In 2006 a new system was introduced where each nation plays the others three times, though in 2007 and 2011 the teams played each other only twice, as both were World Cup years. Since Argentina's strong performances in the 2007 World Cup, after the 2009 Tri Nations tournament, SANZAR (South Africa, New Zealand and Australian Rugby) invited the Argentine Rugby Union (UAR) to join an expanded Four Nations tournament in 2012. The competition has been officially rechristened as The Rugby Championship beginning with the 2012 edition. The competition reverted to the Tri Nations' original home-and-away format, but now involving four teams.
Rugby tours.
During the early history of rugby union, a time before commercial air travel, teams from different continents rarely met. The first two notable tours both took place in 1888—the British Isles team touring New Zealand and Australia, followed by the New Zealand team touring Europe. Traditionally the most prestigious tours were the Southern Hemisphere countries of Australia, New Zealand and South Africa making a tour of a Northern Hemisphere, and the return tours made by a joint British and Irish team. Tours would last for months, due to long traveling times and the number of games undertaken; the 1888 New Zealand team began their tour in Hawkes Bay in June and did not complete their schedule until August 1889, having played 107 rugby matches. Touring international sides would play Test matches against international opponents, including national, club and county sides in the case of Northern Hemisphere rugby, or provincial/state sides in the case of Southern Hemisphere rugby.
For lists of tours, see the category page .
Rugby within international tournaments.
Rugby union was played at the Olympic Games in 1900, 1908, 1920 and 1924. As per Olympic rules, the nations of Scotland, Wales and England were not allowed to play separately as they are not sovereign states. In 1900, France won the gold, beating Great Britain 27 points to 8 and defeating Germany 27 points to 17. In 1908, Australia defeated Great Britain, claiming the gold medal, the score being 32 points to three. In 1920, the United States, fielding a team with many players new to the sport of rugby, upset France in a shock win, eight points to zero. In 1924, the United States again defeated France 17 to 3, becoming the only team to win gold twice in the sport. In 2009 the International Olympic Committee voted with a majority of 81 to 8 that rugby union be reinstated as an Olympic sport in at least the 2016 and 2020 games, but in the sevens, 4-day tournament format. This is something the rugby world has aspired to for a long time and Bernard Lapasset, president of the International Rugby Board, said the Olympic gold medal would be considered to be "the pinnacle of our sport" (Rugby Sevens).
Rugby sevens has been played at the Commonwealth Games since the 1998 Games in Kuala Lumpur. The most gold medal holders are New Zealand who have won the competition on four successive occasions until South Africa beat them in 2014. Rugby union has also been an Asian Games event since the 1998 games in Bangkok, Thailand. In the 1998 and 2002 editions of the games, both the usual fifteen-a-side variety and rugby sevens were played, but from 2006 onwards, only rugby sevens was retained. In 2010, the women's rugby sevens event was introduced. The event is likely to remain a permanent fixture of the Asian Games due to elevation of rugby sevens as an Olympic sport from the 2016 Olympics onwards. The present gold medal holders in the sevens tournament, held in 2010, are Japan in the male event and Kazakhstan in the women's.
Women's international rugby.
Women's international rugby union began in 1982, with a match between France and Netherlands played in Utrecht. As of 2009 over six hundred women's internationals have been played by over forty different nations.
The first Women's Rugby World Cup was held in Wales in 1991, and was won by the United States. The second tournament took place in 1994, and since that date the competition has been held every four years. The New Zealand Women's team then won four straight World Cups (1998, 2002, 2006, 2010) before England won in 2014.
As well as the Women's Rugby World Cup there are also other regular tournaments, including a Six Nations, run in parallel to the men's competition. The Women's Six Nations, first played in 1996 has been dominated by England, who have won the tournament on 13 occasions, including a run of seven consecutive wins from 2006 to 2012.
Variants.
The game of rugby union has spawned several variants of the full-contact, 15-a-side code. The two more common differences applied to the variants of the sport lie in either fewer players or reduced player contact. Of the variants, the oldest is Rugby sevens (7's, or VIIs), a fast-paced variant which originated in Melrose, Scotland in 1883. In rugby sevens, there are only seven players per side, and each half is normally seven minutes. Major tournaments include the Hong Kong Sevens and Dubai Sevens, both held in areas not normally associated with the highest levels of the 15-a-side game. A more recent variant of the sport is Rugby tens (10's or Xs), a Malaysian variant with ten players per side.
Due to the physical nature of playing rugby, several variants have been created to introduce the sport to children with a reduced level of physical contact. Of these versions, Touch rugby, in which "tackles" are made by simply touching the ball carrier with two hands, is popular as a mixed sex version of the sport played by both children and adults. Tag Rugby, is a version in which the participants wear a belt with two hook-and-loop fastener tags, the removal of either counting as a 'tackle'. Tag Rugby also varies in the fact that kicking the ball is not allowed. Mini rugby is another variant of rugby union aimed at fostering the sport in children. It is played with only eight players and on a smaller pitch. Similar to Tag Rugby, American Flag Rugby, (AFR), is a mixed gender, non-contact imitation of rugby union designed for American children entering grades K-9. Both American Flag Rugby and Mini Rugby differ to Tag Rugby in that they introduce more advanced elements of rugby union as the participants age.
Other less formal variants include beach rugby and snow rugby.
Influence on other sports.
Rugby union football, and its immediate ancestor rugby football, has had a strong influence on several other sports. Most obviously rugby league which originally was formed as an administrative break from the English union before changing their laws and become a code in its own right. The two sports continue to influence each other to this day.
The Gridiron codes, American football and Canadian football, are derived from early forms of rugby. Confusingly, in Canada, Canadian football has also frequently been referred to as "rugby football", and a number of national and provincial bodies were called "Rugby Football Unions" or "Rugby Unions", such as the Ontario and Quebec Rugby Football Unions. For example, in the "Encyclopedia Canadiana", the entry "Rugby Football" begins by referring to "the Canadian development of rugby union or "English rugger" introduced into Canada in the third quarter of the nineteenth century", but later states that "the Canadian game is a radical departure from rugby union".
The primary influence on early Australian rules football was rugby football and other games originating in English public schools. Tom Wills, who is recognised as one of the pioneers of Australian football, also attended Rugby School.
James Naismith took aspects of many sports including rugby to invent basketball. The most obvious contribution is the jump ball's similarity to the line-out as well as the underhand shooting style that dominated the early years of the sport. Naismith played many years of rugby at McGill University.
Swedish football was a code whose rules were a mix of the association football rules and the rugby football rules. Some played the game with a round ball, while others played with an oval ball. It is no longer played.
Rugby lends its name to wheelchair rugby (also known as "quad rugby" or "murderball"), but the sport is more strongly influenced by wheelchair basketball, ice hockey and handball than rugby union.
Statistics and records.
According to a 2011 report by the Centre for the International Business of Sport at Coventry University, there are now over four and a half million people playing rugby union or one of its variants organised by the IRB. This is an increase of 19 percent since the previous report in 2007. The report also claimed that since 2007 participation has grown by 33 percent in Africa, 22 percent in South America and 18 percent in Asia and North America. In 2014 the IRB published a breakdown of the total number of players worldwide by national unions. It recorded a total of 6.6 million players globally, of those, 2.36 million were registered members playing for a club affiliated to their country's union.
Rugby union's premier event, the Rugby World Cup, has continued to grow since its inception in 1987. The first tournament, in which 16 teams competed for the title, was broadcast to 17 countries with an accumulated total of 230 million television viewers. Ticket sales during the pool stages and finals of the same tournament was less than a million. The 2007 World Cup was contested by 94 countries with ticket sales of 3,850,000 over the pool and final stage. The accumulated television audience for the event, then broadcast to 200 countries, was 4.2 billion.
The most capped international player from the tier 1 nations is Irish and British Lions centre Brian O'Driscoll who has played in 141 internationals. While the top scoring tier 1 international player is New Zealand's Dan Carter, who has amassed 1442 points during his career. In April 2010 Lithuania broke the record of consecutive international wins previously held by New Zealand and South Africa, which was 17 consecutive wins against tier 1 nations, with their 18th win in tier 2 in a match against Serbia. The highest scoring international match between two recognised unions was Hong Kong's 164–13 victory over Singapore on 27 October 1994 While the largest winning margin of 152 points is held by two countries, Japan (a 155–3 win over Chinese Taipei) and Argentina (152–0 over Paraguay) both in 2002.
The record attendance for a rugby union game was set on 15 July 2000 for a Bledisloe Cup game between Australia and New Zealand at Stadium Australia in Sydney. The match, won 39-35 by the All Blacks, was attended by 109,874 fans. The record attendance for a match in Europe of 104,000 (at the time a world record) was set on 1 March 1975 when Scotland defeated Wales 12-10 at Murrayfield in Edinburgh during the 1975 Five Nations Championship.
In culture.
Thomas Hughes 1857 novel "Tom Brown's Schooldays", set at Rugby School, includes a rugby football match, also portrayed in the 1940s film of the same name. James Joyce mentions Irish team Bective Rangers in several of his works, including Ulysses (1922) and Finnegans Wake (1939), while his 1916 semi-autobiographical work "A Portrait of the Artist as a Young Man" has an account of Ireland international James Magee. Sir Arthur Conan Doyle, in his 1924 Sherlock Holmes tale "The Adventure of the Sussex Vampire", mentions that Dr Watson played rugby for Blackheath.
Henri Rousseau's 1908 work "Joueurs de football" shows two pairs of rugby players competing. Other French artists to have represented the sport in their works include Albert Gleizes' "Les Joueurs de football" (1912), Robert Delaunay's "Football. L'Equipe de Cardiff" (1916) and André Lhote's "Partie de Rugby" (1917). The 1928 Gold Medal for Art at the Antwerp Olympics was won by Luxembourg's Jean Jacoby for his work "Rugby".
In film, Ealing Studios' 1949 comedy "A Run for Your Money" and the 1979 BBC Wales television film "Grand Slam" both centre on fans attending a match. Films that explore the sport in more detail include independent production "Old Scores" (1991) and "Forever Strong" (2008). "Invictus" (2009), based on John Carlin's book "Playing the Enemy", explores the events of the 1995 Rugby World Cup and Nelson Mandela's attempt to use the sport to connect South Africa's people post-apartheid.
In public art and sculpture there are many works dedicated to the sport. There is a 27 ft bronze statue of a rugby line-out by pop artist Gerald Laing at Twickenham and one of rugby administrator Sir Tasker Watkins at the Millennium Stadium. Rugby players to have been honoured with statues include Gareth Edwards in Cardiff and Danie Craven in Stellenbosch.
References.
Printed sources.
</dl>

</doc>
<doc id="25406" url="http://en.wikipedia.org/wiki?curid=25406" title="Rugby World Cup">
Rugby World Cup

The Rugby World Cup is a men's rugby union tournament contested every four years between the top international teams. The tournament was first held in 1987, when the tournament was co-hosted by New Zealand and Australia. The most recent tournament was held in 2011 in New Zealand, whose national team won the tournament by defeating France in the final.
The winners are awarded the William Webb Ellis Cup, named after William Webb Ellis, the Rugby School pupil who — according to a popular myth — invented rugby by picking up the ball during a football game. Three teams have won the trophy twice, Australia, New Zealand, and South Africa; while England have won the tournament once.
The tournament is administered by World Rugby, the sport's international governing body. Sixteen teams were invited to participate in the inaugural tournament in 1987, however since 1999 twenty teams have taken part. England will host the 2015 World Cup, while Japan will host the event in 2019.
Format.
Qualification.
Qualifying tournaments were introduced for the second tournament, where eight of the sixteen places were contested in a twenty-four-nation tournament. The inaugural World Cup in 1987, did not involve any qualifying process; instead, the 16 places were automatically filled by seven eligible International Rugby Football Board (IRFB, now World Rugby) member nations, and the rest by invitation.
The current format allows for twelve of the twenty available positions to be filled by automatic qualification, as the teams who finish third or better in the group (pool) stages of the previous tournament enter its successor (where they will be seeded). The qualification system for the remaining eight places is region-based, with Europe and the Americas allocated two qualifying places each, Africa, Asia and Oceania one place each, with the last place determined by a play-off.
The previous format, used in 2003 and 2007, allowed for eight of the twenty available positions to be filled by automatic qualification, as the eight quarter finalists of the previous tournament enter its successor. The remaining twelve positions were filled by continental qualifying tournaments. Positions were filled by three teams from the Americas, one from Asia, one from Africa, three from Europe and two from Oceania. Another two places were allocated for repechage. The first repechage place was determined by a match between the runners-up from the Africa and Europe qualifying tournaments, with that winner then playing the Americas runner-up to determine the place. The second repechage position was determined between the runners-up from the Asia and Oceania qualifiers.
Tournament.
The 2015 tournament will involve twenty nations competing over six weeks. There are two stages, a group and a knock-out. Nations are divided into four pools, A through to D, of five nations each. The teams are seeded before the start of the tournament, with the seedings taken from the World Rankings in December 2012. The four highest-ranked teams are drawn into pools A to D. The next four highest-ranked teams are then drawn into the pools at, followed by the next four. The remaining positions in each pool are filled by the qualifiers.
Nations play four pool games, playing their respective pool members once each. A bonus points system is used during pool play. If two or more teams are level on points, a system of criteria is used to determine the higher ranked; the sixth and final criterion decides the higher rank through the official World Rankings.
The winner and runner-up of each pool enter the knock-out stage. The knock-out stage consists of quarter- and semi-finals, and then the final. The winner of each pool is placed against a runner-up of a different pool in a quarter-final. The winner of each quarter-final goes on to the semi-finals, and the respective winners proceed to the final. Losers of the semi-finals contest for third place, called the 'Bronze Final'. If a match in the knock-out stages ends in a draw, the winner is determined through extra time. If that fails, the match goes into sudden death and the next team to score any points is the winner. As a last resort, a kicking competition is used.
History.
Prior to the Rugby World Cup, there were only regional international rugby union competitions. One of the largest and oldest is the Six Nations Championship, which started in 1883 as the "Home Nations" championship, a tournament between England, Ireland, Scotland and Wales. It became the Five Nations in 1910, when France joined the tournament. France did not participate from 1931 to 1939, during which period it reverted to a Home Nations championship. In 2000, Italy joined the competition, which became the Six Nations.
In the southern hemisphere, the equivalent competition is The Rugby Championship, involving Argentina, Australia, New Zealand, and South Africa. It began in 1996 as the Tri Nations with the latter three countries participating; Argentina debuted in the renamed competition in 2012.
Rugby union was also played at the Summer Olympics, first appearing at the 1900 Paris games and subsequently at London in 1908, Antwerp in 1920, and Paris again in 1924. France won the first gold medal, then Australasia, with the last two being won by the United States. However rugby union was soon removed from the Summer Olympic program.
The idea of a Rugby World Cup had been suggested on numerous occasions going back to the 1950s, but met with opposition from most unions in the IRFB. The idea resurfaced several times in the early 1980s, with the Australian Rugby Union (ARU) and the New Zealand Rugby Union (NZRU) independently writing to the IRFB seeking to conduct a World Cup tournament. In 1985, Australia, New Zealand and France were in favour of a world cup and, despite knowing that the international sports boycott of the apartheid regime would prevent their participation, the South African delegates also voted in favour, which was vital in tying the vote 8–8. When one English delegate followed by a Welsh delegate switched sides, the IRFB finally approved the inaugural cup, by 10 votes to 6.
The inaugural tournament, jointly hosted by Australia and New Zealand, was held in May and June 1987, with sixteen nations taking part. New Zealand became the first ever champions, defeating France 29–9 in the final. The subsequent 1991 tournament was hosted by England, with matches being played throughout Britain, Ireland and France. This tournament also saw the abolition of invitation qualification, with a qualifying tournament being introduced which involved thirty-five nations. Australia won the second tournament, defeating England 12–6 in the final.
The 1995 tournament was hosted by South Africa and was the first in which South Africa participated, following the end of the international sports boycott. The tournament had a fairytale ending, as South Africa were crowned champions over New Zealand, with then President Nelson Mandela, wearing a Springbok jersey and matching baseball cap, presenting the trophy to South Africa's captain, Francois Pienaar. The tournament in 1999 was hosted by Wales with matches also being held throughout the rest of the United Kingdom, Ireland and France. The tournament included a repechage system, alongside specific regional qualifying places, and an increase from sixteen to twenty participating nations. Australia claimed their second title, defeating France in the final.
The 2003 event was hosted by Australia, although it was originally intended to be held jointly with New Zealand. England emerged as champions defeating Australia in extra time. England's win was unique in that it broke the southern hemisphere's dominance in the event. Such was the celebration of England's victory, that an estimated 750,000 people gathered in central London to greet the team, making the day the largest sporting celebration of its kind ever in the United Kingdom.
The 2007 competition was hosted by France, with matches also being held in Wales and Scotland. South Africa claimed their second title by defeating defending champions England 15–6. The 2011 tournament was awarded to New Zealand in November 2005, ahead of bids from Japan and South Africa. The All Blacks reclaimed their place atop the rugby world with a narrow 8–7 win over France in the 2011 final.
Rugby World Cup Limited recommended to the IRB that the 2015 and 2019 World Cups be held in England and Japan, respectively, and in July 2009 it was announced that this proposal was adopted.
Trophy.
The Webb Ellis Cup is the prize presented to winners of the Rugby World Cup, named after William Webb Ellis. The trophy is also referred to simply as the "Rugby World Cup". The trophy was chosen in 1987 as an appropriate cup for use in the competition, and was created in 1906 by Garrard's Crown Jewellers. The words 'The International Rugby Football Board' and 'The Webb Ellis Cup' are engraved on the face of the cup. It stands thirty-eight centimetres high and is silver gilded in gold, and supported by two cast scroll handles, one with the head of a satyr, and the other a head of a nymph. In Australia the trophy is colloquially known as "Bill" — a reference to William Webb Ellis.
Selection of hosts.
Tournaments are organised by Rugby World Cup Ltd (RWCL), which is itself owned by World Rugby. The selection of host is decided by a vote of World Rugby Council members. The voting procedure is managed by a team of independent auditors, and the voting kept secret. The allocation of a tournament to a host nation is now made five or six years prior to the commencement of the event, for example New Zealand were awarded the 2011 event in late 2005.
The tournament has been hosted by multiple nations. For example the 1987 tournament was co-hosted by Australia and New Zealand. World Rugby requires that the hosts must have a venue with a capacity of at least 60,000 spectators for the final. Host nations sometimes construct or upgrade stadia in preparation for the World Cup, such as Millennium Stadium – purpose built for the 1999 tournament – and Eden Park, upgraded for 2011. The first country outside of the traditional rugby nations of SANZAR or the Six Nations to be awarded the hosting rights was Japan, who will host the 2019 tournament.
Tournament growth.
Media coverage.
Organizers of the 2015 tournament in England call the Rugby World Cup the third largest sporting event in the World, behind only the FIFA World Cup and the Olympics.
Reports emanating from World Rugby and its business partners have frequently touted the tournament's media growth, with cumulative worldwide television audiences of 300 million for the inaugural 1987 tournament, 1.75 billion in 1991, 2.67 billion in 1995, 3 billion in 1999, 3.5 billion in 2003, and 4 billion in 2007.
However, independent reviews have called into question the methodology of those growth estimates, pointing to factual inconsistencies. The event's supposed drawing power outside of a handful of rugby strongholds was also downplayed significantly, with an estimated 97 percent of the 33 million average audience produced by the 2007 final coming from Australasia, South Africa, the British Isles and France. Other sports have been accused of exaggerating their television reach over the years; such claims are not exclusive to the Rugby World Cup.
While the event's global popularity remains a matter of dispute, high interest in traditional rugby nations is well documented. The 2003 final, between Australia and England, became the most watched rugby union match in the history of Australian television.
Attendance.
Notes:
Revenue.
Notes:
Results.
Performance of nations.
Twenty-five nations have participated at the Rugby World Cup (excluding qualifying tournaments). Of the seven tournaments that have been held, all but one have been won by a national team from the southern hemisphere. The southern hemisphere's dominance has been broken only in 2003, when England beat Australia in the final.
Thus far the only nations to host and win a tournament are New Zealand (1987 and 2011) and South Africa (1995). The performance of other host nations includes England (1991 final hosts) and Australia (2003 hosts) finishing runners-up. France (2007 hosts) finished fourth, while Wales (1999 hosts) failed to reach the semi-finals. Of the twenty-five nations that have ever participated in at least one tournament, twelve of them have never missed a tournament.
Team records.
The following teams have reached the quarter-finals but never progressed beyond that stage:
Records and statistics.
The record for most points overall is held by English player Jonny Wilkinson, who scored 277 over his World Cup career. Grant Fox of New Zealand holds the record for most points in one competition, with 126 in 1987; Jason Leonard of England holds the record for most World Cup matches: 22 between 1991 and 2003. Simon Culhane holds the record for most points in a match by one player, 45, as well as the record for most conversions in a match, 20. Marc Ellis holds the record for most tries in a match, six, which he scored against Japan in 1995.
All Black Jonah Lomu holds a number of records: most career tries – 15 from the 1995 and 1999 tournaments, youngest player to appear in a final – aged 20 years and 43 days at the 1995 Final, and most tries in a single tournament – 8 in 1999. South African Bryan Habana equalled Lomu's record for most tries in one competition when he scored 8 in 2007. The record for most penalties in a match is 8, held by Matt Burke, Gonzalo Quesada, Gavin Hastings and Thierry Lacroix, and the record for most penalties in a tournament, 31, is held by Gonzalo Quesada. South Africa's Jannie de Beer kicked five drop-goals against England in 1999 – an individual record for a single World Cup match.
The most points scored in a game is 145 — by the All Blacks against Japan in 1995, while the widest winning margin is 142, held by Australia in a match against Namibia in 2003.
A total of 16 players have been sent off (red carded) in the tournament. Welsh lock Huw Richards was the first, while playing against New Zealand in 1987. No player has been red carded more than once.

</doc>
<doc id="25407" url="http://en.wikipedia.org/wiki?curid=25407" title="Recursion">
Recursion

Recursion is the process of repeating items in a self-similar way. For instance, when the surfaces of two mirrors are exactly parallel with each other, the nested images that occur are a form of infinite recursion. The term has a variety of meanings specific to a variety of disciplines ranging from linguistics to logic. The most common application of recursion is in mathematics and computer science, in which it refers to a method of defining functions in which the function being defined is applied within its own definition. Specifically, this defines an infinite number of instances (function values), using a finite expression that for some instances may refer to other instances, but in such a way that no loop or infinite chain of references can occur. The term is also used more generally to describe a process of repeating objects in a self-similar way.
Formal definitions.
In mathematics and computer science, a class of objects or methods exhibit recursive behavior when they can be defined by two properties:
For example, the following is a recursive definition of a person's ancestors:
The Fibonacci sequence is a classic example of recursion:
formula_1
formula_2
formula_3
Many mathematical axioms are based upon recursive rules. For example, the formal definition of the natural numbers by the Peano axioms can be described as: "0 is a natural number, and each natural number has a successor, which is also a natural number." By this base case and recursive rule, one can generate the set of all natural numbers.
Recursively defined mathematical objects include functions, sets, and especially fractals.
There are various more tongue-in-cheek "definitions" of recursion; see recursive humor.
Informal definition.
Recursion is the process a procedure goes through when one of the steps of the procedure involves invoking the procedure itself. A procedure that goes through recursion is said to be 'recursive'.
To understand recursion, one must recognize the distinction between a procedure and the running of a procedure. A procedure is a set of steps based on a set of rules. The running of a procedure involves actually following the rules and performing the steps. An analogy: a procedure is like a written recipe; running a procedure is like actually preparing the meal.
Recursion is related to, but not the same as, a reference within the specification of a procedure to the execution of some other procedure. For instance, a recipe might refer to cooking vegetables, which is another procedure that in turn requires heating water, and so forth. However, a recursive procedure is where (at least) one of its steps calls for a new instance of the very same procedure, like a sourdough recipe calling for some dough left over from the last time the same recipe was made. This of course immediately creates the possibility of an endless loop; recursion can only be properly used in a definition if the step in question is skipped in certain cases so that the procedure can complete, like a sourdough recipe that also tells you how to get some starter dough in case you've never made it before. Even if properly defined, a recursive procedure is not easy for humans to perform, as it requires distinguishing the new from the old (partially executed) invocation of the procedure; this requires some administration of how far various simultaneous instances of the procedures have progressed. For this reason recursive definitions are very rare in everyday situations. An example could be the following procedure to find a way through a maze. Proceed forward until reaching either an exit or a branching point (a dead end is considered a branching point with 0 branches). If the point reached is an exit, terminate. Otherwise try each branch in turn, using the procedure recursively; if every trial fails by reaching only dead ends, return on the path that led to this branching point and report failure. Whether this actually defines a terminating procedure depends on the nature of the maze: it must not allow loops. In any case, executing the procedure requires carefully recording all currently explored branching points, and which of their branches have already been exhaustively tried.
In language.
Linguist Noam Chomsky among many others has argued that the lack of an upper bound on the number of grammatical sentences in a language, and the lack of an upper bound on grammatical sentence length (beyond practical constraints such as the time available to utter one), can be explained as the consequence of recursion in natural language. This can be understood in terms of a recursive definition of a syntactic category, such as a sentence. A sentence can have a structure in which what follows the verb is another sentence: "Dorothy thinks witches are dangerous", in which the sentence "witches are dangerous" occurs in the larger one. So a sentence can be defined recursively (very roughly) as something with a structure that includes a noun phrase, a verb, and optionally another sentence. This is really just a special case of the mathematical definition of recursion.
This provides a way of understanding the creativity of language—the unbounded number of grammatical sentences—because it immediately predicts that sentences can be of arbitrary length: "Dorothy thinks that Toto suspects that Tin Man said that...". Of course, there are many structures apart from sentences that can be defined recursively, and therefore many ways in which a sentence can embed instances of one category inside another. Over the years, languages in general have proved amenable to this kind of analysis.
Recently, however, the generally-accepted idea that recursion is an essential property of human language has been challenged by Daniel Everett on the basis of his claims about the Pirahã language. Andrew Nevins, David Pesetsky and Cilene Rodrigues are among many who that have argued against this.
Recursion plays a crucial role not only in syntax, but also in natural language semantics. The word "and", for example, can be construed as a function that can apply to sentence meanings to create new sentences, and likewise for noun phrase meanings, verb phrase meanings, and others. It can also apply to intransitive verbs, transitive verbs, or ditransitive verbs. In order to provide a single denotation for it that is suitably flexible, "and" is typically defined so that it can take any of these different types of meanings as arguments. This can be done by defining it for a simple case in which it combines sentences, and then defining the other cases recursively in terms of the simple one.
Recursive humor.
Recursion is sometimes used humorously in computer science, programming, philosophy, or mathematics textbooks, generally by giving a circular definition or self-reference, in which the putative recursive step does not get closer to a base case, but instead leads to an infinite regress. It is not unusual for such books to include a joke entry in their glossary along the lines of:
A variation is found on page 269 in the index of some editions of Kernighan and Ritchie's book "The C Programming Language"; the index entry recursively references itself ("recursion 86, 139, 141, 182, 202, 269"). The earliest version of this joke was in "Software Tools" by Kernighan and Plauger, and also appears in "The UNIX Programming Environment" by Kernighan and Pike. It did not appear in the first edition of "The C Programming Language".
Another joke is that "To understand recursion, you must understand recursion." In the English-language version of the Google web search engine, when a search for "recursion" is made, the site suggests "Did you mean: "recursion"." An alternative form is the following, from Andrew Plotkin: "If you already know what recursion is, just remember the answer. Otherwise, find someone who is standing closer to Douglas Hofstadter than you are; then ask him or her what recursion is."
Recursive acronyms can also be examples of recursive humor. PHP, for example, stands for "PHP Hypertext Preprocessor", WINE stands for "Wine Is Not an Emulator." and GNU stands for "GNU's not Unix".
In mathematics.
Recursively defined sets.
Example: the natural numbers.
The canonical example of a recursively defined set is given by the natural numbers:
Example: The set of true reachable propositions.
Another interesting example is the set of all "true reachable" propositions in an axiomatic system.
This set is called 'true reachable propositions' because in non-constructive approaches to the foundations of mathematics, the set of true propositions may be larger than the set recursively constructed from the axioms and rules of inference. See also Gödel's incompleteness theorems.
Finite subdivision rules.
Finite subdivision rules are a geometric form of recursion, which can be used to create fractal-like images. A subdivision rule starts with a collection of polygons labelled by finitely many labels, and then each polygon is subdivided into smaller labelled polygons in a way that depends only on the labels of the original polygon. This process can be iterated. The standard `middle thirds' technique for creating the Cantor set is a subdivision rule, as is barycentric subdivision.
Functional recursion.
A function may be partly defined in terms of itself. A familiar example is the Fibonacci number sequence: "F"("n") = "F"("n" − 1) + "F"("n" − 2). For such a definition to be useful, it must lead to non-recursively defined values, in this case "F"(0) = 0 and "F"(1) = 1.
A famous recursive function is the Ackermann function, which—unlike the Fibonacci sequence—cannot easily be expressed without recursion.
Proofs involving recursive definitions.
Applying the standard technique of proof by cases to recursively defined sets or functions, as in the preceding sections, yields structural induction, a powerful generalization of mathematical induction widely used to derive proofs in mathematical logic and computer science.
Recursive optimization.
Dynamic programming is an approach to optimization that restates a multiperiod or multistep optimization problem in recursive form. The key result in dynamic programming is the Bellman equation, which writes the value of the optimization problem at an earlier time (or earlier step)
in terms of its value at a later time (or later step).
In computer science.
A common method of simplification is to divide a problem into subproblems of the same type. As a computer programming technique, this is called divide and conquer and is key to the design of many important algorithms. Divide and conquer serves as a top-down approach to problem solving, where problems are solved by solving smaller and smaller instances. A contrary approach is dynamic programming. This approach serves as a bottom-up approach, where problems are solved by solving larger and larger instances, until the desired size is reached.
A classic example of recursion is the definition of the factorial function, given here in C code:
The function calls itself recursively on a smaller version of the input (n - 1) and multiplies the result of the recursive call by n, until reaching the base case, analogously to the mathematical definition of factorial.
Recursion in computer programming is exemplified when a function is defined in terms of simpler, often smaller versions of itself. The solution to the problem is then devised by combining the solutions obtained from the simpler versions of the problem. One example application of recursion is in parsers for programming languages. The great advantage of recursion is that an infinite set of possible sentences, designs or other data can be defined, parsed or produced by a finite computer program.
Recurrence relations are equations to define one or more sequences recursively. Some specific kinds of recurrence relation can be "solved" to obtain a non-recursive definition.
Use of recursion in an algorithm has both advantages and disadvantages. The main advantage is usually simplicity. The main disadvantage is often that the algorithm may require large amounts of memory if the depth of the recursion is very large.
In art.
The Russian Doll or Matryoshka Doll is a physical artistic example of the recursive concept.
The recursion theorem.
In set theory, this is a theorem guaranteeing that recursively defined functions exist. Given a set "X", an element "a" of "X" and a function formula_7, the theorem states that there is a unique function formula_8 (where formula_4 denotes the set of natural numbers including zero) such that
for any natural number "n".
Proof of uniqueness.
Take two functions formula_8 and formula_13 such that:
where "a" is an element of "X".
It can be proved by mathematical induction that formula_18 for all natural numbers "n":
By induction, formula_18 for all formula_25.
Examples.
Some common recurrence relations are:
Bibliography.
</dl>

</doc>
<doc id="25408" url="http://en.wikipedia.org/wiki?curid=25408" title="Robert Byrd">
Robert Byrd

Robert Carlyle Byrd (born Cornelius Calvin Sale, Jr.; November 20, 1917 – June 28, 2010) was a United States Senator from West Virginia. A member of the Democratic Party, Byrd served as a U.S. Representative from 1953 until 1959 and as a U.S. Senator from 1959 to 2010. He was the longest-serving U.S. Senator and, at the time of his death, the longest-serving member in the history of the United States Congress. (In June 2013, his record was surpassed by U.S. Representative John Dingell of Michigan). Byrd, however, still holds the record as the longest-serving member of Congress to serve in both houses.
Initially elected to the United States House of Representatives in 1952, Byrd served there for six years before being elected to the Senate in 1958. He rose to become one of the Senate's most powerful members, serving as secretary of the Senate Democratic Caucus from 1967 to 1971 and—after defeating his longtime colleague, Ted Kennedy—as Senate Majority Whip from 1971 to 1977. Byrd led the Democratic caucus as Senate Majority Leader from 1977 to 1981 and 1987 to 1989, and as Senate Minority Leader from 1981 to 1987. From 1989 to 2010 he served as the President pro tempore of the United States Senate when the Democratic Party had a majority, and as President pro tempore emeritus during periods of Republican majority beginning in 2001. As President pro tempore, he was third in the line of presidential succession, behind the Vice President and the Speaker of the House of Representatives. He also served as the Chairman of the United States Senate Committee on Appropriations from 1989 to 1995, 2001 to 2003, and 2007 to 2009, giving him extraordinary influence over federal spending.
Byrd's seniority and leadership of the Appropriations Committee enabled him to steer a great deal of federal money toward projects in West Virginia. Critics derided his efforts as pork spending to appeal to his own constituents. He filibustered against the 1964 Civil Rights Act and supported the Vietnam War, but later backed civil rights measures and criticized the Iraq War.
Background.
Robert Byrd was born on November 20, 1917 as Cornelius Calvin Sale, Jr. in North Wilkesboro, North Carolina, to Cornelius Calvin Sale Sr. and his wife Ada Mae Kirby. When he was ten months old, his mother died in the 1918 Flu Pandemic. In accordance with his mother's wishes, his father dispersed their children among relatives. Calvin Jr. was adopted by his aunt and uncle, Titus and Vlurma Byrd, who changed his name to Robert Carlyle Byrd and raised him in the coal-mining region of southern West Virginia.
Byrd was valedictorian at Mark Twain High School in Tams, West Virginia and successively attended Beckley College, Concord College, Morris Harvey College, and Marshall University, all in West Virginia. He joined Tau Kappa Epsilon fraternity.
Marriage.
On May 29, 1937, Byrd married Erma Ora James (June 12, 1917 – March 25, 2006) who was born to a coal mining family in Floyd County, Virginia. Her family moved to Raleigh County, West Virginia, where she met Byrd when they attended the same school.
Children.
Robert Byrd had two children, Mona Byrd Fatemi and Marjorie Byrd Moore; two sons-in-law, Mohammad Fatemi and Jon Moore; six grandchildren, Erik Byrd Fatemi, Mona Byrd Moore Pearson, Darius Fatemi, Mary Anne Moore Clarkson, Fredrik Fatemi, and Jon Michael Moore (deceased automobile accident in the 1980s); and seven great-grandchildren, Caroline Byrd Fatemi, Emma James Clarkson, Kathryn James Fatemi, Hannah Byrd Clarkson, Michael Yoo Fatemi, Anna Cristina Fatemi, and James Matthew Fatemi.
Ku Klux Klan.
In the early 1940s, Byrd recruited 150 of his friends and associates to create a new chapter of the Ku Klux Klan in Sophia, West Virginia.
According to Byrd, a Klan official told him, "You have a talent for leadership, Bob ... The country needs young men like you in the leadership of the nation." Byrd later recalled, "Suddenly lights flashed in my mind! Someone important had recognized my abilities! I was only 23 or 24 years old, and the thought of a political career had never really hit me. But strike me that night, it did." Byrd became a recruiter and leader of his chapter. When it came time to elect the top officer (Exalted Cyclops) in the local Klan unit, Byrd won unanimously.
In 1946, Byrd wrote to segregationist Mississippi Senator Theodore G. Bilbo:
I shall never fight in the armed forces with a negro by my side ... Rather I should die a thousand times, and see Old Glory trampled in the dirt never to rise again, than to see this beloved land of ours become degraded by race mongrels, a throwback to the blackest specimen from the wilds.—Robert C. Byrd, in a letter to Sen. Theodore Bilbo (D-MS), 1946
In 1946, Byrd wrote a letter to a Grand Wizard stating, "The Klan is needed today as never before, and I am anxious to see its rebirth here in West Virginia and in every state in the nation." However, when running for the United States House of Representatives in 1952, he announced "After about a year, I became disinterested, quit paying my dues, and dropped my membership in the organization. During the nine years that have followed, I have never been interested in the Klan." He said he had joined the Klan because he felt it offered excitement and was anti-communist. 
In 1997, Byrd told an interviewer he would encourage young people to become involved in politics but also warned, "Be sure you avoid the Ku Klux Klan. Don't get that albatross around your neck. Once you've made that mistake, you inhibit your operations in the political arena." In his last autobiography, Byrd explained that he was a KKK member because he "was sorely afflicted with tunnel vision — a jejune and immature outlook — seeing only what I wanted to see because I thought the Klan could provide an outlet for my talents and ambitions." Byrd also said, in 2005, "I know now I was wrong. Intolerance had no place in America. I apologized a thousand times ... and I don't mind apologizing over and over again. I can't erase what happened."
Early career.
Byrd worked as a gas-station attendant, a grocery-store clerk, a shipyard welder during World War II, and a butcher, before he won a seat in the West Virginia House of Delegates in 1946, representing Raleigh County from 1947 to 1950. Byrd became a local celebrity after a radio station in Beckley, WV began broadcasting his "fiery fundamentalist lessons." In 1950, he was elected to the West Virginia Senate, where he served from 1951 to 1952.
In 1951, then–State Delegate Robert Byrd was among the official witnesses of the execution of Harry Burdette and Fred Painter, which was the first use of the electric chair in West Virginia. In 1965 the state abolished capital punishment, with the last execution having occurred in 1959.
Byrd began night classes at American University Washington College of Law in 1953, while a member of the United States House of Representatives. He received his J.D. "cum laude" a decade later, by which time he was a U.S. Senator. President John F. Kennedy spoke at the commencement ceremony on June 10, 1963 and presented the graduates their diplomas, including Byrd. Byrd completed law school in an era when undergraduate degrees were not a requirement. He later decided to complete his Bachelor of Arts degree in political science, and in 1994 he graduated "summa cum laude" from Marshall University.
Congressional service.
In 1952, Byrd was elected to the United States House of Representatives for West Virginia's 6th congressional district, succeeding E. H. Hedrick, who retired from the House to make an unsuccessful run for the Democratic nomination Governor. Byrd was re-elected to the House twice, serving from January 3, 1953 to 1959. Byrd defeated Republican incumbent W. Chapman Revercomb for the United States Senate in 1958. Revercomb's record supporting civil rights had become an issue, playing in Byrd's favor. Byrd was re-elected to the Senate eight times. He was West Virginia's junior senator for his first four terms; his colleague from 1959 to 1985 was Jennings Randolph, who had been elected on the same day as Byrd's first election in a special election to fill the seat of the late Senator Matthew Neely.
While Byrd faced some vigorous Republican opposition in his career, his last serious electoral opposition occurred in 1982 when he was challenged by freshman Congressman Cleve Benedict. Despite his tremendous popularity in the state, Byrd ran unopposed only once, in 1976. On two other occasions – in 1994 and 2000 – he won all 55 of West Virginia's counties. In his re-election bid in 2000, he won all but seven precincts. Shelley Moore Capito, a Congresswoman and the daughter of Byrd's longtime foe, former governor Arch Moore, Jr., briefly considered a challenge to Byrd in 2006 but decided against it.
In the 1960 Democratic presidential election primaries, Byrd – a close Senate ally of Lyndon B. Johnson – endorsed and campaigned for Hubert Humphrey over front-runner John F. Kennedy in the state's crucial primary. However, Kennedy won the state's primary and eventually the general election.
Public service records.
Byrd was elected to a record ninth consecutive full Senate term on November 7, 2006. He became the longest-serving senator in American history on June 12, 2006, surpassing Strom Thurmond of South Carolina with 17,327 days of service. On November 18, 2009, Byrd became the longest-serving member in congressional history, with 56 years, 320 days of combined service in the House and Senate, passing Carl Hayden, an Arizona politician. Previously, Byrd had held the record for the longest unbroken tenure in the Senate (Thurmond resigned during his first term and was re-elected seven months later). Including his tenure as a state legislator from 1947 to 1953, Byrd's service on the political front exceeded 60 continuous years. Byrd, who never lost an election, cast his 18,000th vote on June 21, 2007, the most of any senator in history. John Dingell broke Byrd's record as longest-serving member of Congress on June 7, 2013.
Upon the death of former Florida Senator George Smathers on January 20, 2007, Byrd became the last living United States Senator from the 1950s.
Byrd was the last surviving senator to have voted on a bill granting statehood to a U.S. territory. At the time of Byrd's death, fourteen sitting or former members of the Senate had not been born when Byrd's tenure in the Senate began, President Barack Obama among them.
Committee assignments.
These are the committee assignments for Sen. Byrd's 9th and final term.
Filibuster of the Civil Rights Act of 1964.
Byrd was a member of the wing of the Democratic Party that opposed desegregation and civil rights imposed by the federal government. However, despite his early career in the KKK, Byrd was linked to such senators as John C. Stennis, J. William Fulbright and George Smathers, who based their segregationist positions on their view of states' rights in contrast to senators like James Eastland, who held a reputation as a committed racist.
Byrd joined with Democratic senators to filibuster the Civil Rights Act of 1964, personally filibustering the bill for 14 hours, a move he later said he regretted. Despite an 83-day filibuster in the Senate, both parties in Congress voted overwhelmingly in favor of the Act, and President Johnson signed the bill into law. Byrd also opposed the Voting Rights Act of 1965 but voted for the Civil Rights Act of 1968. In 2005, Byrd told "The Washington Post" that his membership in the Baptist church led to a change in his views. In the opinion of one reviewer, Byrd, like other Southern and border-state Democrats, came to realize that he would have to temper "his blatantly segregationist views" and move to the Democratic Party mainstream if he wanted to play a role nationally.
Leadership roles.
Byrd served in the Senate Democratic leadership. He succeeded George Smathers as secretary of the Senate Democratic Conference from 1967 to 1971. He unseated Ted Kennedy in 1971 to become majority whip, or the second highest-ranking Democrat, until 1977. Smathers recalled that, "Ted was off playing. While Ted was away at Christmas, down in the islands, floating around having a good time with some of his friends, male and female, here was Bob up here calling on the phone. 'I want to do this, and would you help me?' He had it all committed so that when Teddy got back to town, Teddy didn't know what hit him, but it was already all over. That was Lyndon Johnson's style. Bob Byrd learned that from watching Lyndon Johnson." Byrd himself had told Smathers that " I have never in my life played a game of cards. I have never in my life had a golf club in my hand. I have never in life hit a tennis ball. I have—believe it or not—never thrown a line over to catch a fish. I don't do any of those things. I have only had to work all my life. And every time you told me about swimming, I don't know how to swim."
In 1976, Byrd was the "favorite son" Presidential candidate in West Virginia's primary. His easy victory gave him control of the delegation to the Democratic national convention. Byrd had the inside track as majority whip but focused most of his time running for majority leader, more so than for re-election to the Senate, as he was virtually unopposed for his fourth term. By the time the vote for majority leader came, his lead was so secure that his lone rival, Minnesota's Hubert Humphrey, withdrew before the balloting took place. From 1977 to 1989 Byrd was the leader of the Senate Democrats, serving as majority leader from 1977 to 1981 and 1987 to 1989, and as minority leader from 1981 to 1987.
Appropriations Committee.
Byrd was well known for steering federal dollars to West Virginia, one of the country's poorest states. He was called the "King of Pork" by Citizens Against Government Waste. After becoming chair of the Appropriations Committee in 1989, Byrd set a goal securing a total of $1 billion for public works in the state. He passed that mark in 1991, and funds for highways, dams, educational institutions and federal agency offices flowed unabated over the course of his membership. More than 30 existing or pending federal projects bear his name. He commented on his reputation for attaining funds for projects in West Virginia in August 2006, when he called himself "Big Daddy" at the dedication for the Robert C. Byrd Biotechnology Science Center. Examples of this ability to claim funds and projects for his state include the Federal Bureau of Investigation's repository for computerized fingerprint records as well as several United States Coast Guard computing and office facilities.
Parliamentary expertise.
Byrd also was known for using his knowledge of parliamentary procedure. Byrd frustrated Republicans with his encyclopedic knowledge of the inner workings of the Senate, particularly prior to the Reagan Revolution. From 1977 to 1979 he was described as "performing a procedural tap dance around the minority, outmaneuvering Republicans with his mastery of the Senate's arcane rules." In 1988, majority leader Byrd moved a call of the Senate, which was adopted by the majority present, in order to have the Sergeant-at-Arms arrest members not in attendance. One member (Robert Packwood, R-Oregon) was escorted back to the chamber by the Sergeant-at-Arms in order to obtain a quorum.
President pro tempore.
As the longest-serving Democratic senator, Byrd served as President pro tempore four times when his party was in the majority: from 1989 until the Republicans won control of the Senate in 1995; for 17 days in early 2001, when the Senate was evenly split between parties and outgoing Vice President Al Gore broke the tie in favor of the Democrats; when the Democrats regained the majority in June 2001 after Senator Jim Jeffords of Vermont left the Republican Party to become an independent; and again from 2007 to his death in 2010, as a result of the 2006 Senate elections. In this capacity, Byrd was third in the line of presidential succession at the time of his death, behind Vice President Joe Biden and House Speaker Nancy Pelosi.
Scholarships and TAH History Grants.
In 1969, Byrd launched a Scholastic Recognition Award; he also began to present a savings bond to valedictorians from high schools—public and private—in West Virginia. In 1985 Congress approved the nation's only merit-based scholarship program funded through the U.S. Department of Education, a program which Congress later named in Byrd's honor. The Robert C. Byrd Honors Scholarship Program initially comprised a one-year, $1,500 award to students with "outstanding academic achievement" who had been accepted at a college or university. In 1993, the program began providing four-year scholarships.
In 2002 Byrd secured unanimous approval for a major national initiative to strengthen the teaching of "traditional American history" in K-12 public schools. The Department of Education competitively awards $50 to $120 million a year to school districts (in amounts of about $500,000 to $1 million). The money goes to teacher training programs that are geared to improving the knowledge of history teachers. The Continuing Appropriations Act, 2011 eliminated funding for the Robert C. Byrd Honors Scholarship Program.
Senate historian.
Television cameras were first introduced to the House of Representatives on March 19, 1979, by C-SPAN. Unsatisfied that Americans only saw Congress as the House of Representatives, Byrd and others pushed to televise Senate proceedings to prevent the Senate from becoming the "invisible branch" of government, succeeding in June 1986.
To help introduce the public to the inner workings of the legislative process, Byrd launched a series of one hundred speeches based on his examination of the Roman Republic and the intent of the Framers. Byrd published a four-volume series on Senate history: "The Senate: 1789–1989: Addresses on the History of the Senate". The first volume won the Henry Adams Prize of the Society for History in the Federal Government as "an outstanding contribution to research in the history of the Federal Government." He also published "The Senate of the Roman Republic: Addresses on the History of Roman Constitutionalism".
In 2004, Byrd received the American Historical Association's first Theodore Roosevelt-Woodrow Wilson Award for Civil Service; in 2007, Byrd received the Friend of History Award from the Organization of American Historians. Both awards honor individuals outside the academy who have made a significant contribution to the writing and/or presentation of history. In 2014, began assessing the archiving of Senator Byrd's electronic correspondence and floor speeches in order to preserve these documents and make them available to the wider community.
Final-term Senate highlights.
On July 19, 2007, Byrd gave a 25-minute speech in the Senate against dog fighting, in response to the indictment of football player Michael Vick. In recognition of the speech, People for the Ethical Treatment of Animals named Byrd their "2007 Person of the Year".
For 2007, Byrd was deemed the fourteenth-most powerful senator, as well as the twelfth-most powerful Democratic senator.
On May 19, 2008, Byrd endorsed Barack Obama (D-Illinois). One week after the West Virginia Democratic Primary, in which Hillary Clinton defeated Obama by 41 to 32 percent, Byrd said, "Barack Obama is a noble-hearted patriot and humble Christian, and he has my full faith and support." When asked in October 2008 about the possibility that the issue of race would influence West Virginia voters, as Obama is an African-American, Byrd replied, "Those days are gone. Gone!" Obama lost West Virginia (by 13 percent) but won the election.
On January 26, 2009, Byrd was one of three Democrats to vote against the confirmation of Timothy Geithner as United States Secretary of the Treasury (along with Russ Feingold of Wisconsin and Tom Harkin of Iowa).
On February 26, 2009, Byrd was one of two Democrats to vote against the District of Columbia House Voting Rights Act of 2009, which if it had become law would have added a voting seat in the United States House of Representatives for the District of Columbia and add a seat for Utah (Democrat Max Baucus of Montana also cast a "nay" vote).
Although his health was poor, Byrd was present for every crucial vote during the December 2009 Senatorial healthcare debate; his vote was necessary so Democrats could obtain cloture to break a Republican filibuster. At the final vote on December 24, 2009, Byrd referenced recently deceased Senator Ted Kennedy, a devoted proponent, when casting his vote: "Mr. President, this is for my friend Ted Kennedy! Aye!"
Political views.
Race.
Late in his life, Byrd explicitly renounced his earlier views favoring racial segregation. Byrd said that he regretted filibustering and voting against the Civil Rights Act of 1964 and would change it if he had the opportunity. He said joining the KKK was "the greatest mistake I ever made." Byrd also said that his views changed dramatically after his teenage grandson was killed in a 1982 traffic accident, which put him in a deep emotional valley. "The death of my grandson caused me to stop and think," said Byrd, adding he came to realize that African-Americans love their children as much as he does his.
Byrd was the only senator to vote against the appointing of both Thurgood Marshall and Clarence Thomas to the United States Supreme Court, the only two African-American nominees. In the former instance, Byrd asked FBI Director J. Edgar Hoover to look into what Byrd believed to be the possibility that Marshall had either connections to communists or a communist past. In the latter instance, Byrd stated that he was offended by Thomas' use of the phrase "high-tech lynching of uppity blacks" in his defense and that he was "offended by the injection of racism" into the hearing. He called Thomas' comments a "diversionary tactic" and said "I thought we were past that stage." Regarding Anita Hill's sexual harassment charges against Thomas, Byrd supported Hill. Byrd joined 45 other Democrats in voting against confirming Thomas to the Supreme Court.
For the 2003–2004 session, the National Association for the Advancement of Colored People (NAACP) rated Byrd's voting record as being 100 percent in line with the NAACP's position on the 33 Senate bills they evaluated. 16 other senators received that rating. In June 2005, Byrd proposed an additional $10 million in federal funding for the Martin Luther King, Jr. National Memorial in Washington, D.C., remarking that, "With the passage of time, we have come to learn that his Dream was the American Dream, and few ever expressed it more eloquently."
In a March 4, 2001 interview with Tony Snow, Byrd said of race relations:
They're much, much better than they've ever been in my lifetime ... I think we talk about race too much. I think those problems are largely behind us ... I just think we talk so much about it that we help to create somewhat of an illusion. I think we try to have good will. My old mom told me, 'Robert, you can't go to heaven if you hate anybody.' We practice that. There are white niggers. I've seen a lot of white niggers in my time, if you want to use that word. We just need to work together to make our country a better country, and I'd just as soon quit talking about it so much.
Byrd's use of the term "white nigger" created immediate controversy. When asked about it, Byrd responded,
I apologize for the characterization I used on this program ... The phrase dates back to my boyhood and has no place in today's society ... In my attempt to articulate strongly held feelings, I may have offended people.
Clinton impeachment.
Byrd initially said that the impeachment proceedings against Clinton should be taken seriously. Although he harshly criticized any attempt to make light of the allegations, he made the motion to dismiss the charges and effectively end the matter. Even though he voted against both articles of impeachment, he was the sole Democrat to vote to censure Clinton.
Gay rights.
Byrd strongly opposed Clinton's 1993 efforts to allow gays to serve in the military and supported efforts to limit gay marriage. In 1996, before the passage of the Defense of Marriage Act, he said, "The drive for same-sex marriage is, in effect, an effort to make a sneak attack on society by encoding this aberrant behavior in legal form before society itself has decided it should be legal. [...] Let us defend the oldest institution, the institution of marriage between male and female as set forth in the Holy Bible."
Despite his previous position, he later stated his opposition to the Federal Marriage Amendment and argued that it was unnecessary because the states already had the power to ban gay marriages. However, when the amendment came to the Senate floor, he was one of the two Democratic senators who voted in favor of cloture.
Abortion.
He was pro-choice and in 1995 voted against a ban on intact dilation and extraction, a late-term abortion procedure typically referred to by its opponents as "partial-birth abortion", but voted for a ban on subsequent occasions. Byrd voted against the Unborn Victims of Violence Act, which recognizes a "child in utero" as a legal victim if he or she is injured or killed during the commission of a crime of violence.
In 2003, Byrd voted for the Partial-Birth Abortion Ban Act, which prohibits intact dilation and extraction.
George W. Bush era.
Byrd praised the nomination of John G. Roberts to fill the vacancy on the Supreme Court created by the death of Chief Justice William Rehnquist. Likewise, Byrd supported the confirmation of Samuel Alito to replace retiring Associate Justice Sandra Day O'Connor.
Like most Democrats, Byrd opposed Bush's tax cuts and his proposals to change the Social Security program.
Byrd opposed the 2002 Homeland Security Act, which created the Department of Homeland Security, stating that the bill ceded too much authority to the executive branch.
He also led the opposition to Bush's bid to win back the power to negotiate trade deals that Congress cannot amend, but lost overwhelmingly. In the 108th Congress, however, Byrd won his party's top seat on the new Homeland Security Appropriations Subcommittee.
In July 2004, Byrd released the book "Losing America: Confronting a Reckless and Arrogant Presidency", which criticized the Bush presidency and the war in Iraq.
Iraq War.
Byrd led a filibuster against the resolution granting President George W. Bush broad power to wage a "preemptive" war against Iraq, but he could not get even a majority of his own party to vote against cloture.
Byrd was one of the Senate's most outspoken critics of the 2003 invasion of Iraq.
Byrd anticipated the difficulty of fighting an insurgency in Iraq, stating on March 13, 2003,
If the United States leads the charge to war in the Persian Gulf, we may get lucky and achieve a rapid victory. But then we will face a second war: a war to win the peace in Iraq. This war will last many years and will surely cost hundreds of billions of dollars. In light of this enormous task, it would be a great mistake to expect that this will be a replay of the 1991 war. The stakes are much higher in this conflict.
On March 19, 2003, when Bush ordered the invasion after receiving congressional approval, Byrd said,
Today I weep for my country. I have watched the events of recent months with a heavy, heavy heart. No more is the image of America one of strong, yet benevolent peacekeeper. The image of America has changed. Around the globe, our friends mistrust us, our word is disputed, our intentions are questioned. Instead of reasoning with those with whom we disagree, we demand obedience or threaten recrimination.
Byrd also criticized Bush for his speech declaring the "end of major combat operations" in Iraq, which Bush made on the U.S.S. "Abraham Lincoln". Byrd stated on the Senate floor,
I do question the motives of a deskbound president who assumes the garb of a warrior for the purposes of a speech.
On October 17, 2003, Byrd delivered a speech expressing his concerns about the future of the nation and his unequivocal antipathy to Bush's policies. Referencing the Hans Christian Andersen children's tale "The Emperor's New Clothes", Byrd said of the president: "the emperor has no clothes." Byrd further lamented the "sheep-like" behavior of the "cowed Members of this Senate" and called on them to oppose the continuation of a "war based on falsehoods."
Byrd accused the Bush administration of stifling dissent:
The right to ask questions, debate, and dissent is under attack. The drums of war are beaten ever louder in an attempt to drown out those who speak of our predicament in stark terms. Even in the Senate, our history and tradition of being the world's greatest deliberative body is being snubbed. This huge spending bill—$87 billion—has been rushed through this chamber in just one month. There were just three open hearings by the Senate Appropriations Committee on $87 billion—$87 for every minute since Jesus Christ was born—$87 billion without a single outside witness called to challenge the administration's line.
Of the more than 18,000 votes he cast as a senator, Byrd said he was proudest of his vote against the Iraq war resolution. Byrd also voted to tie a timetable for troop withdrawal to war funding.
Gang of 14.
On May 23, 2005, Byrd was one of 14 senators (who became known as the "Gang of 14") to forge a compromise on the judicial filibuster, thus securing up and down votes for many judicial nominees and ending the threat of the so-called nuclear option that would have eliminated the filibuster entirely. Under the agreement, the senators retained the power to filibuster a judicial nominee in only an "extraordinary circumstance." It ensured that the appellate court nominees (Janice Rogers Brown, Priscilla Owen and William Pryor) would receive votes by the full Senate.
Other votes.
Byrd opposed the Flag Desecration Amendment, saying that, while he wanted to protect the American flag, he believed that amending the Constitution "is not the most expeditious way to protect this revered symbol of our Republic." As an alternative, Byrd cosponsored the Flag Protection Act of 2005 (S. 1370), a bill to prohibit destruction or desecration of the flag by anyone trying to incite violence or causing a breach of the peace, or who steals, damages, or destroys a flag on federal property, whether owned by the federal government or a private group or individual—can be imprisoned, fined or both. The bill did not pass.
In 2009, Byrd was one of three Democrats to oppose the confirmation of Secretary of the Treasury Timothy Geithner. After missing nearly two months while in hospital, Byrd returned to the Senate floor on July 21 to vote against the elimination of funding for the F-22 fighter plane.
Ratings groups.
Byrd received a 65-percent vote rating from the League of Conservation Voters for his support of environmentally friendly legislation. Additionally, he received a "liberal" rating of 65.5 percent by the National Journal—higher than six other Democratic senators.
In 2006, Byrd received a 67-percent rating from the American Civil Liberties Union for supporting rights-related legislation.
Health issues and death.
Byrd had an essential tremor; he was eventually confined to a wheelchair. His health declined through 2008, including several hospital admissions.
On January 20, 2009, Senator Ted Kennedy suffered a seizure during Barack Obama's inaugural luncheon and was taken away in an ambulance. Byrd, seated at the same table, became distraught and was himself removed to his office. Byrd's office reported that he was fine. On May 18, Byrd was admitted to the hospital after experiencing a fever due to a "minor infection", prolonged by a staphylococcal infection. Byrd was released on June 30, 2009.
Byrd's final hospital stay began on June 27, 2010, at Inova Fairfax Hospital in Fairfax County, Virginia. He died at approximately 3 a.m. EDT the next day at age 92 from natural causes.
Vice President Joe Biden recalled Byrd's standing in the rain with him as Biden buried his daughter when Biden had just been elected to the Senate. He called Byrd "a tough, compassionate, and outspoken leader and dedicated above all else to making life better for the people of the Mountain State." President Barack Obama said, "His profound passion for that body and its role and responsibilities was as evident behind closed doors as it was in the stemwinders he peppered with history. He held the deepest respect of members of both parties, and he was generous with his time and advice, something I appreciated greatly as a young senator." Senator Jay Rockefeller, who had served with Byrd since 1985, said, "I looked up to him, I fought next to him, and I am deeply saddened that he is gone." Former President Jimmy Carter noted, "He was my closest and most valuable adviser while I served as president. I respected him and attempted in every way to remain in his good graces. He was a giant among legislators, and was courageous in espousing controversial issues."
On July 1, 2010, Byrd lay in repose on the Lincoln Catafalque in the Senate chamber of the United States Capitol, becoming the first Senator to do so since his first year in the Senate, 1959. Byrd was then flown to Charleston, West Virginia, where he lay in repose in the Lower Rotunda of the West Virginia State Capitol.
A funeral was held on July 2, 2010, on the grounds of the State Capitol where Byrd was eulogized by President Barack Obama, Vice President Joe Biden, Governor Joe Manchin, Senate Majority Leader Harry Reid, Senate Minority Leader Mitch McConnell, Speaker of the House of Representatives Nancy Pelosi, Senator Jay Rockefeller, Congressman Nick Rahall, Victoria Reggie Kennedy, and former President Bill Clinton. After the funeral services in Charleston, his body was returned to Arlington, Virginia, for funeral services on July 6, 2010, at Memorial Baptist Church. After the funeral in Arlington, Byrd was buried next to his wife Erma at Columbia Gardens Cemetery in Arlington, although family members have stated that both the senator and Mrs. Byrd will be reinterred somewhere in West Virginia once a site is determined.
The song "Take Me Home, Country Roads" was played at the end of the funeral in a bluegrass fashion as his casket was being carried back up the stairs and into the West Virginia State Capitol Building.
On September 30, 2010, Congress appropriated $193,400 to be paid equally among Byrd's children and grandchildren, representing the salary he would have earned in the next fiscal year; a common practice when members of Congress die in office.
Reaction to death.
Multiple political figures issued statements following Byrd's death:
In popular culture.
Byrd had a prominent role in the 2008 Warner Bros. documentary "Body of War" directed by Phil Donahue. The film chronicles the life of Tomas Young, paralyzed from the chest down after a sniper shot him as he was riding in a vehicle in Iraq. Several long clips of Byrd show him passionately arguing against authorizing the use of force in Iraq. Later in the movie, Byrd has a one-on-one interview with Tomas Young in Byrd's Senate office, followed by a shot of Byrd walking beside the wheelchair-bound Young as they leave the Capitol.
A fictionalized version of Byrd, then the Senate Majority Leader, was a character in the Jeffrey Archer novel "Shall We Tell the President?".
Byrd was an avid fiddle player for most of his life, starting in his teens when he played in various square dance bands. Once he entered politics, his fiddling skills attracted attention and won votes. In 1978 when Byrd was Majority Leader, he recorded an album called "U.S. Senator Robert Byrd: Mountain Fiddler" (County, 1978). Byrd was accompanied by Country Gentlemen Doyle Lawson, James Bailey, and Spider Gilliam. Most of the LP consists of bluegrass music. Byrd covers "Don't Let Your Sweet Love Die," a Zeke Manners song, and "Will the Circle Be Unbroken". He has performed at the Kennedy Center, on the Grand Ole Opry and on "Hee Haw". He occasionally took a break from Senate business to entertain audiences with his fiddle. He stopped playing in 1982 when the symptoms of a benign essential tremor had begun to affect the use of his hands.
Byrd appeared in the Civil War movie "Gods and Generals" in 2003 along with former Virginia senator George Allen. Both played Confederate States officers.
The Creekdippers album "Political Manifest" features a song entitled 'Senator Byrd Speech' in honor of Senator Robert C. Byrd.
Robert C. Byrd Center for Legislative Studies.
In 2002, the Robert C. Byrd Center for Legislative Studies (CLS) was opened on the campus of Shepherd University. Adjoining the University's Ruth Scarborough Library, the CLS "advances representative democracy by promoting a better understanding of the United States Congress and the Constitution through programs and research that engage citizens." The CLS is an archival research facility, housing the papers of Senator Robert C. Byrd in addition to the papers of Congressmen Harley O. Staggers, Sr. and Harley O. Staggers, Jr., and Scot Faulkner, the first Chief Administrative Officer of the United States House of Representatives. The CLS is a founding institution of the Association of Centers for the Study of Congress, "an independent alliance of organizations and institutions which promote the study of the U.S. Congress." 

</doc>
<doc id="25409" url="http://en.wikipedia.org/wiki?curid=25409" title="Reptile">
Reptile

Reptiles, the class Reptilia, are an evolutionary grade of animals, comprising today's turtles, crocodilians, snakes, lizards and tuatara, their extinct relatives, and some of the extinct ancestors of mammals. Due to their evolutionary history and the diversity of extinct forms, the validity of the class is not universally supported in scientific circles, though in practice, it remains in use by some biologists and more laymen, especially in mass media. The study of reptiles, historically combined with that of amphibians, is called herpetology.
The earliest known reptiles originated around 315 million years ago during the Carboniferous period, having evolved from advanced reptile-like amphibians that became increasingly adapted to life on dry land. Some early examples include the lizard-like "Hylonomus", "Casineria" and possibly "Westlothiana", although "Westlothiana" l may be an advanced land-dwelling amphibian. In addition to the living reptiles, there are many diverse groups that are now extinct, in some cases due to mass extinction events. In particular, the K–Pg extinction wiped out the pterosaurs, plesiosaurs, ornithischians, and sauropods, as well as many species of theropods (e.g. tyrannosaurs and dromaeosaurids), crocodyliforms, and squamates (e.g. mosasaurids).
Modern reptiles inhabit every continent with the exception of Antarctica. Several living subgroups are recognized:
Reptiles are tetrapod vertebrates, creatures that either have four limbs or, like snakes, being descended from four-limbed ancestors. Unlike amphibians, reptiles do not have an aquatic larval stage. Most reptiles are oviparous, although several species of squamates are viviparous, as were some extinct aquatic clades — the fetus develops within the mother, contained in a placenta rather than an eggshell. As amniotes, reptile eggs are surrounded by membranes for protection and transport, which adapt them to reproduction on dry land. Many of the viviparous species feed their fetuses through various forms of placenta analogous to those of mammals, with some providing initial care for their hatchlings. Extant reptiles range in size from a tiny gecko, "Sphaerodactylus ariasae", which can grow up to 17 mm to the saltwater crocodile, "Crocodylus porosus", which may reach 6 m in length and weigh over 1000 kg.
Classification.
History of classification.
Linnaeus and the 18th century.
The reptiles were, from the outset of classification, grouped with the amphibians. Linnaeus, working from species-poor Sweden, where the common adder and grass snake are often found hunting in water, included all reptiles and amphibians in class "III – Amphibia" in his "Systema Naturæ".
The terms "reptile" and "amphibian" were largely interchangeable, "reptile" (from Latin "repere", "to creep") being preferred by the French.
Josephus Nicolaus Laurenti was the first to formally use the term "Reptilia" for an expanded selection of reptiles and amphibians basically similar to that of Linnaeus. Today, the two groups are still commonly treated under the same heading as herptiles.
"Antediluvian monsters".
It was not until the beginning of the 19th century that it became clear that reptiles and amphibians are, in fact, quite different animals, and Pierre André Latreille erected the class "Batracia" (1825) for the latter, dividing the tetrapods into the four familiar classes of reptiles, amphibians, birds, and mammals.
The British anatomist Thomas Henry Huxley made Latreille's definition popular and, together with Richard Owen, expanded Reptilia to include the various fossil "antediluvian monsters", including dinosaurs and the mammal-like (synapsid) "Dicynodon" he helped describe. This was not the only possible classification scheme: In the Hunterian lectures delivered at the Royal College of Surgeons in 1863, Huxley grouped the vertebrates into mammals, sauroids, and ichthyoids (the latter containing the fishes and amphibians). He subsequently proposed the names of Sauropsida and Ichthyopsida for the latter two groups.
In 1866, Haeckel demonstrated that vertebrates could be divided based on their reproductive strategies, and that reptiles, birds, and mammals were united by the amniotic egg.
The terms "Sauropsida" ("lizard faces") and "Theropsida" ("beast faces") were used again in 1916 by E.S. Goodrich to distinguish between lizards, birds, and their relatives on the one hand (Sauropsida) and mammals and their extinct relatives (Theropsida) on the other. Goodrich supported this division by the nature of the hearts and blood vessels in each group, and other features, such as the structure of the forebrain. According to Goodrich, both lineages evolved from an earlier stem group, Protosauria ("first lizards") in which he included some animals today considered reptile-like amphibians, as well as early reptiles.
In 1956, D.M.S. Watson observed that the first two groups diverged very early in reptilian history, so he divided Goodrich's Protosauria between them. He also reinterpreted Sauropsida and Theropsida to exclude birds and mammals, respectively. Thus his Sauropsida included Procolophonia, Eosuchia, Millerosauria, Chelonia (turtles), Squamata (lizards and snakes), Rhynchocephalia, Crocodilia, "thecodonts" (paraphyletic basal Archosauria), non-avian dinosaurs, pterosaurs, ichthyosaurs, and sauropterygians.
In the late 19th century, a number of definitions of Reptilia were offered. The traits listed by Lydekker in 1896, for example, include a single occipital condyle, a jaw joint formed by the quadrate and articular bones, and certain characteristics of the vertebrae. The animals singled out by these formulations, the amniotes other than the mammals and the birds, are still those considered reptiles today.
Skull openings in 20th-century classification.
The synapsid/sauropsid division supplemented another approach, one that split the reptiles into four subclasses based on the number and position of temporal fenestrae, openings in the sides of the skull behind the eyes. This classification was initiated by Henry Fairfield Osborn and elaborated and made popular by Romer's classic "Vertebrate Paleontology". Those four subclasses were:
The composition of Euryapsida was uncertain. Ichthyosaurs were, at times, considered to have arisen independently of the other euryapsids, and given the older name Parapsida. Parapsida was later discarded as a group for the most part (ichthyosaurs being classified as "incertae sedis" or with Euryapsida). However, four (or three if Euryapsida is sunk into Diapsida) subclasses remained more or less universal for non-specialist work throughout the 20th century. It has largely been abandoned among recent researchers: in particular, the anapsid condition has been found to occur so variably among unrelated groups that it is not now considered a useful distinction.
Phylogenetics and modern definition.
By the early 21st century, vertebrate paleontologists were beginning to adopt phylogenetic taxonomy, in which all groups are defined in such a way as to be monophyletic; that is, groups include all descendants of a particular ancestor. The reptiles as historically defined are paraphyletic, since they exclude both birds and mammals. These respectively evolved from dinosaurs and from early therapsids, which were both traditionally called reptiles. Birds are more closely related to crocodilians than the latter are to the rest of extant reptiles. Colin Tudge wrote:
Mammals are a clade, and therefore the cladists are happy to acknowledge the traditional taxon Mammalia; and birds, too, are a clade, universally ascribed to the formal taxon Aves. Mammalia and Aves are, in fact, subclades within the grand clade of the Amniota. But the traditional class Reptilia is not a clade. It is just a section of the clade Amniota: the section that is left after the Mammalia and Aves have been hived off. It cannot be defined by synapomorphies, as is the proper way. Instead, it is defined by a combination of the features it has and the features it lacks: reptiles are the amniotes that lack fur or feathers. At best, the cladists suggest, we could say that the traditional Reptilia are 'non-avian, non-mammalian amniotes'.
Despite the early proposals for replacing the paraphyletic Reptilia with a monophyletic Sauropsida which includes birds, that term was never adopted widely or, when it was, applied consistently. When Sauropsida was used, it often had the same content or even the same definition as Reptilia. In 1988 Jacques Gauthier proposed a cladistic definition of Reptilia as a monophyletic node-based crown group containing turtles, lizards and snakes, crocodilians, and birds, their common ancestor and all its descendants. Because the actual relationship of turtles to other reptiles was not yet well understood at this time, Gauthier's definition came to be considered inadequate. A variety of other definitions were proposed by other scientists in the years following Gauthier's paper. The first such new definition, which attempted to adhere to the standards of the PhyloCode, was published by Modesto and Anderson in 2004. Modesto and Anderson reviewed the many previous definitions and proposed a modified definition, which they intended to retain most traditional content of the group while keeping it stable and monophyletic. They defined Reptilia as all amniotes closer to "Lacerta agilis" and "Crocodylus niloticus" than to "Homo sapiens". This stem-based definition is equivalent to the more common definition of Sauropsida, which Modesto and Anderson synonymized with Reptilia, since the latter is more well known and more frequently used. Unlike most previous definitions of Reptilia, however, Modesto and Anderson's definition includes birds, as there is no other way to establish a monophyletic clade that includes both lizards and crocodiles.
Taxonomy.
Classification to order level of early amniotes and reptiles, after Benton, 2014.
Phylogeny.
The cladogram presented here illustrates the "family tree" of reptiles, and follows a simplified version of the relationships found by M.S. Lee, in 2013. All genetic studies have supported the hypothesis that turtles are diapsid reptiles; some have placed turtles within archosauriformes, though a few have recovered turtles as lepidosauriformes instead. The cladogram below used a combination of genetic (molecular) and fossil (morphological) data to obtain its results.
The position of turtles.
The placement of turtles has historically been highly variable. Classically, turtles were considered to be related to the primitive anapsid reptiles. Molecular work has usually placed turtles within the diapsids. So far three turtle genomes have been sequenced. The results place turtles as a sister clade to the archosaurs, the group that includes crocodiles, dinosaurs, and birds.
Evolutionary history.
Origin of the reptiles.
The origin of the reptiles lies about 310–320 million years ago, in the steaming swamps of the late Carboniferous period, when the first reptiles evolved from advanced reptiliomorph labyrinthodonts.
The oldest known animal that may have been an amniote, i.e. a primitive reptile rather than an advanced amphibian, is "Casineria" (though it may have been a temnospondyl amphibian). A series of footprints from the fossil strata of Nova Scotia dated to show typical reptilian toes and imprints of scales.
The tracks are attributed to "Hylonomus", the oldest unquestionable reptile known.
It was a small, lizard-like animal, about 20 to long, with numerous sharp teeth indicating an insectivorous diet. Other examples include "Westlothiana" (for the moment considered a reptiliomorph amphibian rather than a true amniote) and "Paleothyris", both of similar build and presumably similar habit.
Rise of the reptiles.
Earliest reptiles were largely overshadowed by bigger labyrinthodont amphibians, such as "Cochleosaurus", and remained a small, inconspicuous part of the fauna until the Carboniferous Rainforest Collapse. This sudden collapse affected several large groups. Amphibians were particularly devastated, while reptiles fared better, being ecologically adapted to the drier conditions that followed. Amphibians must return to water to lay eggs; in contrast, reptiles – whose eggs possess a shell that allows them to be laid on land – were better adapted to the new conditions. Reptiles acquired new niches at a faster rate than before the collapse and at a much faster rate than amphibians. They acquired new feeding strategies including herbivory and carnivory, previously only having been insectivores and piscivores. From this point forward, reptiles dominated communities and had a greater diversity than amphibians, setting the stage for the Mesozoic (known as the Age of Reptiles). One of the best known early reptiles is "Mesosaurus", a genus from the early Permian that had returned to water, feeding on fish.
Anapsids, synapsids, diapsids and sauropsids.
It was traditionally assumed that the first reptiles retained an anapsid skull inherited from their amphibian ancestors. This type of skull has a skull roof with only holes for the nostrils, eyes and a pineal eye. The discoveries of synapsid-like openings (see below) in the skull roof of the skulls of several members of Parareptilia (the clade containing most of reptiles traditionally referred to as anapsids), including lanthanosuchoids, millerettids, bolosaurids, some nycteroleterids, some procolophonoids and at least some mesosaurs made it more ambiguous and it's currently uncertain whether the ancestral reptile had an anapsid-like or synapsid-like skull. These animals are traditionally referred to as anapsids, and form a paraphyletic basic stock from which other groups evolved. Very shortly after the reptiles appeared, a lineage called Synapsida split off, characterized by a temporal opening in the skull behind each eye to give room for the jaw muscle to move. These are the "mammal-like reptiles" that later gave rise to the true mammals. Soon after, another group evolved a similar trait, this time with a double opening behind each eye, earning them the name Diapsida ("two arches"). The function of the holes in these groups was to lighten the skull and give room for the jaw muscles to move, allowing for a more powerful bite. Diapsids and the anapsid reptiles back to the last common ancestor of diapsids and synapsids are classed as the "true reptiles", Sauropsida.
Turtles have been traditionally believed to be surviving reptilian anapsids, on the basis of their skull structure. The rationale for this classification has been disputed, with some arguing that turtles are diapsids that reverted to this primitive state in order to improve their armor (see Parareptilia). Later morphological phylogenetic studies with this in mind placed turtles firmly within Diapsida. All molecular studies have strongly upheld the placement of turtles within diapsids, most commonly as a sister group to extant archosaurs.
Permian reptiles.
With the close of the Carboniferous, reptiles became the dominant tetrapod fauna. While the terrestrial reptiliomorph labyrinthodonts still existed, the synapsids evolved the first truly terrestrial megafauna (giant animals) in the form of pelycosaurs, such as "Edaphosaurus" and the carnivorous "Dimetrodon". In the mid-Permian period, the climate became drier, resulting in a change of fauna: The pelycosaurs were replaced by the therapsids.
The anapsid reptiles, whose massive skull roofs had no postorbital holes, continued and flourished throughout the Permian. The pareiasaurs reached giant proportions in the late Permian, eventually disappearing at the close of the period (the turtles being possible survivors).
Early in the period, the diapsid reptiles split into two main lineages, the archosaurs (forebears of crocodiles and dinosaurs) and the lepidosaurs (predecessors of modern snakes, lizards, and tuatara). Both groups remained lizard-like and relatively small and inconspicuous during the Permian.
The Mesozoic era.
The close of the Permian saw the greatest mass extinction known (see the Permian–Triassic extinction event), a prolonged event due to the accumulation of at least two distinct extinction pulses. Most of the earlier anapsid/synapsid megafauna disappeared, being replaced by the archosauromorph diapsids. The archosaurs were characterized by elongated hind legs and an erect pose, the early forms looking somewhat like long-legged crocodiles. The archosaurs became the dominant group during the Triassic period, though it took 30 million years before their diversity was as great as the animals that lived in the Permian. Archosaurs developed into the well-known dinosaurs and pterosaurs, as well as crocodiles and phytosaurs. Since reptiles, first rauisuchians and then dinosaurs, dominated the Mesozoic era, the interval is popularly known as the "Age of Reptiles". The dinosaurs also developed smaller forms, including the feather-bearing smaller theropods. In the mid-Jurassic period, these gave rise to the first birds.
The sister group to Archosauromorpha is Lepidosauromorpha, containing squamates and rhynchocephalians, as well as their fossil relatives. Lepidosauromorpha contained at least one major group of the Mesozoic sea reptiles: the mosasaurs, which emerged during the Cretaceous period. The phylogenetic placement of other main groups of fossil sea reptiles – the ichthyopterygians (including ichthyosaurs) and the sauropterygians, which evolved in the early Triassic – is more controversial. Different authors linked these groups either to lepidosauromorphs or to archosauromorphs, and ichthyopterygians were also argued to be diapsids that did not belong to the least inclusive clade containing lepidosauromorphs and archosauromorphs.
The therapsids came under increasing pressure from the dinosaurs in the early Mesozoic and developed into increasingly smaller and more nocturnal forms, the mammals being the only survivors of the line by the late Cretaceous.
Cenozoic era.
The close of the Cretaceous period saw the demise of the Mesozoic era reptilian megafauna (see the Cretaceous–Paleogene extinction event). Of the large marine reptiles, only sea turtles were left; and of the non-marine large reptiles, only the semi-aquatic crocodiles and broadly similar "Champsosaurus" survived the extinction, with the latter becoming extinct in the Miocene. Of the great host of dinosaurs dominating the Mesozoic, only the small feathered birds survived. This dramatic extinction pattern at the end of the Mesozoic led into the Cenozoic. Mammals and birds filled the empty niches left behind by the reptilian megafauna and, while reptile diversification slowed, bird and mammal diversification took an exponential turn.
After the extinction of most archosaur and marine reptile lines by the end of the Cretaceous, reptile diversification continued throughout the Cenozoic, with squamates undergoing a greater radiation than they did in the Mesozoic. Today, squamates make up the majority of living reptiles (> 95%), most species being lizards. Approximately 10,000 extant species of reptiles are known, about equal to birds, and almost twice compared with about 5,700 species of mammals alive today (excluding domesticated species).
Morphology and Physiology.
Circulation.
Many reptiles have a three-chambered heart consisting of two atria, one variably partitioned ventricle, and two aortas that lead to the systemic circulation. The degree of mixing of oxygenated and deoxygenated blood in the three-chambered heart varies depending on the species and physiological state. Under different conditions, deoxygenated blood can be shunted back to the body or oxygenated blood can be shunted back to the lungs. This variation in blood flow has been hypothesized to allow more effective thermoregulation and longer diving times for aquatic species, but has not been shown to be a fitness advantage.
There are exceptions to the general physiology. For instance, crocodilians have an anatomically four-chambered heart, but also have two systemic aortas and are therefore capable of bypassing only their pulmonary circulation. Also, some snake and lizard species (e.g., pythons and monitor lizards) have three-chambered hearts that become functionally four-chambered hearts during contraction. This is made possible by a muscular ridge that subdivides the ventricle during ventricular diastole and completely divides it during ventricular systole. Because of this ridge, some of these squamates are capable of producing ventricular pressure differentials that are equivalent to those seen in mammalian and avian hearts.
Metabolism.
Modern reptiles exhibit some form of cold-bloodedness (i.e. some mix of poikilothermy, ectothermy, and bradymetabolism) so that they have limited physiological means of keeping the body temperature constant and often rely on external sources of heat. Due to a less stable core temperature than birds and mammals, reptilian biochemistry requires enzymes capable of maintaining efficiency over a greater range of temperatures than in the case for warm-blooded animals. The optimum body temperature range varies with species, but is typically below that of warm-blooded animals; for many lizards, it falls in the 24°–35 °C (75°–95 °F) range, while extreme heat-adapted species, like the American desert iguana "Dipsosaurus dorsalis", can have optimal physiological temperatures in the mammalian range, between 35° and 40 °C (95° and 104 °F). While the optimum temperature is often encountered when the animal is active, the low basal metabolism makes body temperature drop rapidly when the animal is inactive.
As in all animals, reptilian muscle action produces heat. In large reptiles, like leatherback turtles, the low surface-to-volume ratio allows this metabolically produced heat to keep the animals warmer than their environment although they do not have a warm-blooded metabolism. This form of homeothermy is called gigantothermy; it has been suggested as having been common in large dinosaurs and other extinct large-bodied reptiles.
The benefit of a low resting metabolism is that it requires far less fuel to sustain bodily functions. By using temperature variations in their surroundings, or by remaining cold when they do not need to move, reptiles can save considerable amounts of energy compared to endothermic animals of the same size. A crocodile needs from a tenth to a fifth of the food necessary for a lion of the same weight and can live half a year without eating. Lower food requirements and adaptive metabolisms allow reptiles to dominate the animal life in regions where net calorie availability is too low to sustain large-bodied mammals and birds.
It is generally assumed that reptiles are unable to produce the sustained high energy output necessary for long distance chases or flying. Higher energetic capacity might have been responsible for the evolution of warm-bloodedness in birds and mammals. However, investigation of correlations between active capacity and thermophysiology show a weak relationship. Most extant reptiles are carnivores with a sit-and-wait feeding strategy, and whether reptiles are cold blooded due to their ecology or because their metabolism is a result of their ecology is not clear. Energetic studies on some reptiles have shown active capacities equal to or greater than similar sized warm-blooded animals.
Respiration.
Reptilian lungs.
All reptiles breathe using lungs. Aquatic turtles have developed more permeable skin, and some species have modified their cloaca to increase the area for gas exchange. Even with these adaptations, breathing is never fully accomplished without lungs. Lung ventilation is accomplished differently in each main reptile group. In squamates, the lungs are ventilated almost exclusively by the axial musculature. This is also the same musculature that is used during locomotion. Because of this constraint, most squamates are forced to hold their breath during intense runs. Some, however, have found a way around it. Varanids, and a few other lizard species, employ buccal pumping as a complement to their normal "axial breathing." This allows the animals to completely fill their lungs during intense locomotion, and thus remain aerobically active for a long time. Tegu lizards are known to possess a proto-diaphragm, which separates the pulmonary cavity from the visceral cavity. While not actually capable of movement, it does allow for greater lung inflation, by taking the weight of the viscera off the lungs.
Crocodilians actually have a muscular diaphragm that is analogous to the mammalian diaphragm. The difference is that the muscles for the crocodilian diaphragm pull the pubis (part of the pelvis, which is movable in crocodilians) back, which brings the liver down, thus freeing space for the lungs to expand. This type of diaphragmatic setup has been referred to as the "hepatic piston." The airways bronchia form a number of double tubular chambers within each lung. On inhalation and exhalation air moves through the airways in the same direction, thus creating an unidirectional airflow through the lungs. A similar system is found in birds, monitor lizards and iguanas.
Turtles and tortoises.
How turtles and tortoises breathe has been the subject of much study. To date, only a few species have been studied thoroughly enough to get an idea of how turtles breathe. The results indicate that turtles and tortoises have found a variety of solutions to this problem.
The difficulty is that most turtle shells are rigid and do not allow for the type of expansion and contraction that other amniotes use to ventilate their lungs. Some turtles, such as the Indian flapshell ("Lissemys punctata"), have a sheet of muscle that envelops the lungs. When it contracts, the turtle can exhale. When at rest, the turtle can retract the limbs into the body cavity and force air out of the lungs. When the turtle protracts its limbs, the pressure inside the lungs is reduced, and the turtle can suck air in. Turtle lungs are attached to the inside of the top of the shell (carapace), with the bottom of the lungs attached (via connective tissue) to the rest of the viscera. By using a series of special muscles (roughly equivalent to a diaphragm), turtles are capable of pushing their viscera up and down, resulting in effective respiration, since many of these muscles have attachment points in conjunction with their forelimbs (indeed, many of the muscles expand into the limb pockets during contraction).
Breathing during locomotion has been studied in three species, and they show different patterns. Adult female green sea turtles do not breathe as they crutch along their nesting beaches. They hold their breath during terrestrial locomotion and breathe in bouts as they rest. North American box turtles breathe continuously during locomotion, and the ventilation cycle is not coordinated with the limb movements. This is because they use their abdominal muscles to breathe during locomotion. The last species to have been studied is the red-eared slider, which also breathes during locomotion, but takes smaller breaths during locomotion than during small pauses between locomotor bouts, indicating that there may be mechanical interference between the limb movements and the breathing apparatus. Box turtles have also been observed to breathe while completely sealed up inside their shells.
Palate.
Most reptiles lack a secondary palate, meaning that they must hold their breath while swallowing. Crocodilians have evolved a bony secondary palate that allows them to continue breathing while remaining submerged (and protect their brains against damage by struggling prey). Skinks (family Scincidae) also have evolved a bony secondary palate, to varying degrees. Snakes took a different approach and extended their trachea instead. Their tracheal extension sticks out like a fleshy straw, and allows these animals to swallow large prey without suffering from asphyxiation.
Skin.
Reptilian skin is covered in a horny epidermis, making it watertight and enabling reptiles to live on dry land, in contrast to amphibians. Compared to mammalian skin, that of reptiles is rather thin and lacks the thick dermal layer that produces leather in mammals.
Exposed parts of reptiles are protected by scales or scutes, sometimes with a bony base, forming armor. In lepidosaurians such as lizards and snakes, the whole skin is covered in overlapping epidermal scales. Such scales were once thought to be typical of the class Reptilia as a whole, but are now known to occur only in lepidosaurians. The scales found in turtles and crocodiles are of dermal, rather than epidermal, origin and are properly termed scutes. In turtles, the body is hidden inside a hard shell composed of fused scutes.
Lacking a thick dermis, reptilian leather is not as strong as mammalian leather. It is used in leather-wares for decorative purposes for shoes, belts and handbags, particularly crocodile skin.
Excretion.
Excretion is performed mainly by two small kidneys. In diapsids, uric acid is the main nitrogenous waste product; turtles, like mammals, excrete mainly urea. Unlike the kidneys of mammals and birds, reptile kidneys are unable to produce liquid urine more concentrated than their body fluid. This is because they lack a specialized structure called a loop of Henle, which is present in the nephrons of birds and mammals. Because of this, many reptiles use the colon to aid in the reabsorption of water. Some are also able to take up water stored in the bladder. Excess salts are also excreted by nasal and lingual salt glands in some reptiles.
Digestion.
Most reptiles are insectivorous or carnivorous and have rather simple and comparatively short digestive tracts, meat being fairly simple to break down and digest. Digestion is slower than in mammals, reflecting their lower resting metabolism and their inability to divide and masticate their food. Their poikilotherm metabolism has very low energy requirements, allowing large reptiles like crocodiles and the large constrictors to live from a single large meal for months, digesting it slowly.
While modern reptiles are predominately carnivorous, during the early history of reptiles several groups produced some herbivorous megafauna: in the Paleozoic, the pareiasaurs and the synapsid dicynodonts; and in the Mesozoic several lines of dinosaurs. Today, the turtles are the only predominantly herbivorous reptile group, but several lines of agamas and iguanas have evolved to live wholly or partly on plants.
Herbivorous reptiles face the same problems of mastication as herbivorous mammals but, lacking the complex teeth of mammals, many species swallow rocks and pebbles (so called gastroliths) to aid in digestion: The rocks are washed around in the stomach, helping to grind up plant matter. Fossil gastroliths have been found associated with both ornithopods and sauropods, though whether they actually functioned as a gastric mill in the latter is disputed. Salt water crocodiles also use gastroliths as ballast, stabilizing them in the water or helping them to dive. A dual function as both stabilizing ballast and digestion aid has been suggested for gastroliths found in plesiosaurs.
Nerves.
The reptilian nervous system contains the same basic part of the amphibian brain, but the reptile cerebrum and cerebellum are slightly larger. Most typical sense organs are well developed with certain exceptions, most notably the snake's lack of external ears (middle and inner ears are present). There are twelve pairs of cranial nerves. Due to their short cochlea, reptiles use electrical tuning to expand their range of audible frequencies.
Intelligence.
Reptiles are generally considered less intelligent than mammals and birds. The size of their brain relative to their body is much less than that of mammals, the encephalization quotient being about one tenth of that of mammals, though larger reptiles can show more complex brain development. Larger lizards, like the monitors, are known to exhibit complex behavior, including cooperation. Crocodiles have relatively larger brains and show a fairly complex social structure. The Komodo dragon is even known to engage in play, as are turtles, which are also considered to be social creatures and sometimes switch between monogamy and promiscuity in their sexual behavior. One study found that wood turtles were better than white rats at learning to navigate mazes.
Vision.
Most reptiles are diurnal animals. The vision is typically adapted to daylight conditions, with color vision and more advanced visual depth perception than in amphibians and most mammals. In some species, such as blind snakes, vision is reduced.
Some snakes have extra sets of visual organs (in the loosest sense of the word) in the form of pits sensitive to infrared radiation (heat). Such heat-sensitive pits are particularly well developed in the pit vipers, but are also found in boas and pythons. These pits allow the snakes to sense the body heat of birds and mammals, enabling pit vipers to hunt rodents in the dark.
Reproduction.
Reptiles generally reproduce sexually, though some are capable of asexual reproduction. All reproductive activity occurs through the cloaca, the single exit/entrance at the base of the tail where waste is also eliminated. Most reptiles have copulatory organs, which are usually retracted or inverted and stored inside the body. In turtles and crocodilians, the male has a single median penis, while squamates, including snakes and lizards, possess a pair of hemipenes, only one of which is typically used in each session. Tuatara, however, lack copulatory organs, and so the male and female simply press their cloacas together as the male discharges sperm.
Most reptiles lay amniotic eggs covered with leathery or calcareous shells. An amnion, chorion, and allantois are present during embryonic life. The eggshell (1) protects the crocodile embryo (11) and keeps it from drying out, but it is flexible to allow gas exchange. The chorion (6) aids in gas exchange between the inside and outside of the egg. It allows carbon dioxide to exit the egg and oxygen gas to enter the egg. The albumin (9) further protects the embryo and serves as a reservoir for water and protein. The allantois (8) is a sac that collects the metabolic waste produced by the embryo. The amniotic sac (10) contains amniotic fluid (12) which protects and cushions the embryo. The amnion (5) aids in osmoregulation and serves as a saltwater reservoir. The yolk sac (2) surrounding the yolk (3) contains protein and fat rich nutrients that are absorbed by the embryo via vessels (4) that allow the embryo to grow and metabolize. The air space (7) provides the embryo with oxygen while it is hatching. This ensures that the embryo will not suffocate while it is hatching. There are no larval stages of development. Viviparity and ovoviviparity have evolved in many extinct clades of reptiles and in squamates. In the latter group, many species, including all boas and most vipers, utilize this mode of reproduction. The degree of viviparity varies; some species simply retain the eggs until just before hatching, others provide maternal nourishment to supplement the yolk, and yet others lack any yolk and provide all nutrients via a structure similar to the mammalian placenta. The earliest documented case of viviparity in reptiles is the Early Permian mesosaurs, although some individuals or taxa in that clade may also have been oviparous because a putative isolated egg has also been found. Several groups of Mesozoic marine reptiles also exhibited viviparity, such as mosasaurs, ichthyosaurs, and Sauropterygia, a group that include pachypleurosaurs and Plesiosauria.
Asexual reproduction has been identified in squamates in six families of lizards and one snake. In some species of squamates, a population of females is able to produce a unisexual diploid clone of the mother. This form of asexual reproduction, called parthenogenesis, occurs in several species of gecko, and is particularly widespread in the teiids (especially "Aspidocelis") and lacertids ("Lacerta"). In captivity, Komodo dragons (Varanidae) have reproduced by parthenogenesis.
Parthenogenetic species are suspected to occur among chameleons, agamids, xantusiids, and typhlopids.
Some reptiles exhibit temperature-dependent sex determination (TDSD), in which the incubation temperature determines whether a particular egg hatches as male or female. TDSD is most common in turtles and crocodiles, but also occurs in lizards and tuatara. To date, there has been no confirmation of whether TDSD occurs in snakes.
Defense mechanisms.
Many small reptiles, such as snakes and lizards that live on the ground or in the water, are vulnerable to being preyed on by all kinds of carnivorous animals. Thus avoidance is the most common form of defense in reptiles. At the first sign of danger, most snakes and lizards crawl away into the undergrowth, and turtles and crocodiles will plunge into water and sink out of sight.
Camouflage and warning.
Reptiles tend to avoid confrontation through camouflage. Two major groups of reptile predators are birds and other reptiles, both of which have well developed colour vision. Thus the skins of many reptiles have cryptic colouration of plain or mottled gray, green, and brown to allow them to blend into the background of their natural environment. Aided by the reptiles' capacity for remaining motionless for long periods, the camouflage of many snakes is so effective most people or domestic animals most typically are bitten because they accidentally step on them.
When camouflage fail to protect them, blue-tongued skinks will try to ward off attackers by displaying their blue tongues, and the frill-necked lizard will display its brightly coloured frill. These same displays are used in territorial disputes and during courtship. If danger arises so suddenly that flight is useless, crocodiles, turtles, some lizards, and some snakes hiss loudly when confronted by an enemy. Rattlesnakes rapidly vibrate the tip of the tail, which is composed of a series of nested, hollow beads to ward of approaching danger.
In contrast to the normal drab colouration of most reptiles, the lizards of the genus "Heloderma" (the Gila monster and the beaded lizard) and many of the coral snakes have high-contrast warning colouration, warning potential predators they are venomous. A number of non-venomous North American snake species have colourful markings similar those of the coral snake, an oft cited examples of Batesian mimicry.
Alternative defense in snakes.
Camouflage will not always fool a predator. When caught out, snake species will adopt different defensive tactics and use a complicated set of behaviors when attacked. Some will first elevate their head and spread out the skin of their neck in an effort to look large and threatening. Failure of this strategy may lead to other measures practiced particularly by cobras, vipers, and closely related species, who use venom to attack. The venom is modified saliva, delivered through fangs from a venom gland. Some non-venomous snakes, such as the American corn snake or European grass snake, play dead when in danger.
Defense in crocodilians.
When a crocodilian is concerned about its safety, it will gape to expose the teeth and yellow tongue. If this doesn't work, the crocodilian gets a little more agitated and typically begins to make hissing sounds. After this, the crocodilian will start to change its posture dramatically to make itself look more intimidating. The body is inflated to increase apparent size. If absolutely necessary it may decide to attack an enemy.
Some species try to bite immediately. Some will use their heads as sledgehammers and literally smash an opponent, some will rush or swim toward the threat from a distance, even chasing the opponent onto land or galloping after it. The main weapon in all crocodiles is the bite, which can generate very high bite force. Many species also possess canine-like teeth. These are used primarily for seizing prey, but are also used in fighting and display.
Shedding and regenerating tails.
Geckos, skinks, and other lizards that are captured by the tail will shed part of the tail structure through a process called autotomy and thus be able to flee. The detached tail will continue to wiggle, creating a deceptive sense of continued struggle and distracting the predator's attention from the fleeing prey animal. The detached tails of leopard geckos can wiggle for up to 20 minutes. In many species the tails are of a separate and dramatically more intense color than the rest of the body so as to encourage potential predators to strike for the tail first. In the shingleback skink and some species of geckos, the tail is short and broad and resemble the head, so that the predators may attack it rather than the more vulnerable front part.
Reptiles capable of shedding tails can partially regenerate them over a period of weeks. The new section will however contain cartilage rather than bone, and will never grow to the same length at the original tail. It is often also distinctly discolored compared to the rest of the body and may lack some of the external sculpting features seen in the original tail.
Reptiles in human culture.
Reptiles have played important roles in many human cultures, and human cultures have a heavy impact on reptile populations. In Hindu mythology, God Vishnu took the form of a turtle, Kurma. A snake is playing a prominent role in the biblical story of Genesis. Turtles have also served as food for millennia, as have other reptiles. Snake bite causes the death of an estimated 100,000 people annually. By contrast, reptiles have also been used as medicine, especially in China. Finally, human impact has threatened many reptile species with extinction.
Further reading.
</dl>

</doc>
<doc id="25410" url="http://en.wikipedia.org/wiki?curid=25410" title="Rhode Island">
Rhode Island

Rhode Island ( or ), officially the State of Rhode Island and Providence Plantations, is a state in the New England region of the United States. Rhode Island is the smallest in area, the eighth least populous, but the second most densely populated of the 50 US states (behind New Jersey). Rhode Island is bordered by Connecticut to the west and Massachusetts to the north and east, and it shares a water boundary with New York's Long Island to the southwest. It also has the longest official name of all the states.
Rhode Island was the first of the original Thirteen Colonies to declare independence from British rule, declaring itself independent on May 4, 1776, two months before any other colony. The state was also the last of the thirteen original colonies to ratify the United States Constitution.
Rhode Island's official nickname is "The Ocean State", a reference to the state's geography, since Rhode Island has several large bays and inlets that amount to about 14% of its total area. Its land area is 1045 sqmi, but its total area is significantly larger.
Origin of the name.
Despite its name, most of Rhode Island is located on the mainland of the United States. The official name of the state is "State of Rhode Island and Providence Plantations," which is derived from the merger of two settlements. "Rhode Island" colony was founded near present-day Newport, on what is now commonly called Aquidneck Island, the largest of several islands in Narragansett Bay. "Providence Plantations" was the name of the colony founded by Roger Williams in the area now known as the city of Providence.
It is unclear how Aquidneck Island came to be known as Rhode Island, although there are two popular theories.
Giovanni da Verrazzano named a place on Rhode Island "Puntum Iovianum" in honor of his friend Paolo Giovio (Jovium in Latin) (1483 - 1542) humanist and historian. Giovio owned the Codex Cellere of Giovanni da Verrazzano containing the text of his first trip. 
The earliest documented use of the name "Rhode Island" for Aquidneck was in 1637, by Roger Williams. The name was officially applied to the island in 1644 with these words: "Aquethneck shall be henceforth called the Isle of Rodes or Rhode-Island." The name "Isle of Rodes" is found used in a legal document as late as 1646. Dutch maps as late as 1659 call the island "Red Island" ("Roodt Eylant").
Williams was a theologian forced out of the Massachusetts Bay Colony. Seeking religious and political tolerance, he and others founded "Providence Plantations" as a free proprietary colony. "Providence" referred to the divine providence and "plantations" referred to an English term for a colony.
"State of Rhode Island and Providence Plantations" is the longest official name of any state in the Union. On June 25, 2009, the General Assembly voted to allow the people to decide whether to keep the name or drop "and Providence Plantations" due to the misperception that the name related to slavery. The referendum election was held on this subject during the November 2, 2010 elections, and the people overwhelmingly (78% to 22%) voted to keep the original name.
Geography.
Rhode Island covers an area of 1214 sqmi and is bordered on the north and east by Massachusetts, on the west by Connecticut, and on the south by Rhode Island Sound and the Atlantic Ocean. It shares a narrow maritime border with New York State between Block Island and Long Island. The mean elevation of the state is 200 ft. It is only 37 mi wide and 48 mi long, yet the state has a tidal shoreline on Narragansett Bay and the Atlantic Ocean of 384 mi.
Nicknamed the Ocean State, Rhode Island has a number of oceanfront beaches. It is mostly flat with no real mountains, and the state's highest natural point is Jerimoth Hill, 812 ft above sea level.
Located within the New England Region, Rhode Island has two distinct natural regions. Eastern Rhode Island contains the lowlands of the Narragansett Bay, while Western Rhode Island forms part of the New England Upland. Rhode Island's forests are part of the Northeastern coastal forests ecoregion.
Narragansett Bay is a major feature of the state's topography. Within the Bay, there are over 30 islands. The largest is Aquidneck Island, shared by the municipalities of Newport, Middletown, and Portsmouth. The second-largest island is Conanicut; the third-largest is Prudence. Block Island lies about 12 mi off the southern coast of the mainland and separates Block Island Sound and the Atlantic Ocean proper.
Geology.
A rare type of rock called Cumberlandite, found only in Rhode Island (specifically in the town of Cumberland), is the state rock. There were initially two known deposits of the mineral, but since it is an ore of iron, one of the deposits was extensively mined for its ferrous content. The state is underlain by the Avalon terrane and was once part of the micro-continent Avalonia prior to closure of the Iapetus ocean.
Climate.
Rhode Island is on the borderline between humid subtropical and humid continental climates with warm, rainy summers and chilly winters. The highest temperature recorded in Rhode Island was 104 °F, recorded on August 2, 1975, in Providence. The lowest recorded temperature in Rhode Island was -23 °F, on February 5, 1996, in Greene. Monthly average temperatures range from a high of 83 °F to a low of 20 °F.
History.
Colonial era: 1636–1770.
In 1636, Roger Williams, after being banished from the Massachusetts Bay Colony for his religious views, settled at the tip of Narragansett Bay, on land granted to him by the Narragansett and Pequot tribes. Both tribes were subservient to the Wampanoag tribe led by Massasoit. He called the site "Providence" "having a sense of God's merciful providence unto me in my distress." Eventually it became a place of religious freedom.
In 1638, after conferring with Williams, Anne Hutchinson, William Coddington, John Clarke, Philip Sherman, and other religious dissenters settled on Aquidneck Island (then known as Rhode Island), which was purchased from the local natives, who called it Pocasset. This settlement was called Portsmouth and was governed by the Portsmouth Compact. The southern part of the island became the separate settlement of Newport after disagreements among the founders.
Samuel Gorton purchased the Native American lands at Shawomet in 1642, precipitating a military dispute with the Massachusetts Bay Colony. In 1644, Providence, Portsmouth, and Newport united for their common independence as the Colony of Rhode Island and Providence Plantations, governed by an elected council and "president". Gorton received a separate charter for his settlement in 1648, which he named Warwick after his patron.
During King Philip's War (1675–1676), a force of Massachusetts, Connecticut and Plymouth militia under General Josiah Winslow invaded and destroyed the fortified Narragansett Indian village in the Great Swamp in what is now South Kingstown, Rhode Island, on December 19, 1675. The Indians referred to this as a massacre. The Wampanoag tribe under war-leader Metacomet, whom the colonists called "King Philip", invaded and burned down several of the towns in the area, including Providence which was attacked twice. In one of the final actions of the war, Benjamin Church killed King Philip in what is now Bristol, Rhode Island; King Philip's head was put on a pole and stood at the entrance to Plimoth Plantation as a warning to other Indians for years.
The colony was amalgamated into the Dominion of New England in 1686, as King James II attempted to enforce royal authority over the autonomous colonies in British North America. After the Glorious Revolution of 1688, the colony regained its independence under the Royal Charter. Slaves were introduced at this time, although there is no record of any law legalizing slave-holding, although the colony later prospered under the slave trade, by distilling rum to sell in Africa as part of a profitable triangular trade in slaves and sugar with the Caribbean.
Revolutionary to Civil War Period: 1770-1860.
Rhode Island's tradition of independence and dissent gave it a prominent role in the American Revolution. At approximately 2 a.m. on June 10, 1772, a band of Providence residents attacked, and subsequently burned to the waterline, the grounded revenue schooner "Gaspee" for enforcing unpopular trade regulations within Narragansett Bay. Rhode Island was the first of the thirteen colonies to renounce its allegiance to the British Crown, on May 4, 1776. It was also the last colony of the thirteen colonies to ratify the United States Constitution on May 29, 1790, once assurances were made that a Bill of Rights would become part of the Constitution. During the Revolution, the British occupied Newport. A combined Franco-American force fought to drive them off Aquidneck Island. Portsmouth was the site of the first African-American military unit, the 1st Rhode Island Regiment, to fight for the U.S. in the Battle of Rhode Island of August 29, 1778. The arrival of a French fleet forced the British to scuttle their own ships, rather than surrender them to the French. The celebrated march to Yorktown, Virginia in 1781 that ended with the defeat of the British at the Siege of Yorktown and the Battle of the Chesapeake began in Newport, Rhode Island under the joint command of General George Washington who led American troops and the Comte de Rochambeau who led French soldiers sent by King Louis XVI. In 2009, this was officially recognized by the National Park Service.
Rhode Island was heavily involved in the slave trade during the post-revolution era. In 1774, the slave population of Rhode Island was 6.3%, nearly twice as high as any other New England colony. In the years after the Revolution, Rhode Island merchants controlled between 60% and 90% of the American trade of African slaves.
In addition to the slave trade, Rhode Island was also heavily involved in the Industrial Revolution. The Industrial Revolution began in America in 1787 when Thomas Somers reproduced textile machine plans he imported from England. He helped to produce the Beverly Cotton Manufactory, which Moses Brown of Providence took an interest in. Teaming up with Samuel Slater, Moses Brown helped to create the second cotton mill in America, a water-powered textile mill. As the Industrial Revolution moved large numbers of workers into the cities, a permanently landless, and therefore voteless, class developed. By 1829, 60% of the state's free white males were ineligible to vote. After several unsuccessful attempts to address this problem, a new state constitution was passed in 1843 allowing landless white men to vote if they could pay a $1 poll tax.
In the early 19th Century, Rhode Island was subject to a tuberculosis outbreak which led to public hysteria about vampirism.
Civil War to Progressive Era: 1860–1929.
During the American Civil War, Rhode Island was the first Union state to send troops in response to President Lincoln's request for help from the states. Rhode Island furnished 25,236 fighting men, of whom 1,685 died. On the home front, Rhode Island, along with the other northern states, used its industrial capacity to supply the Union Army with the materials it needed to win the war. The United States Naval Academy moved to Rhode Island temporarily during the war.
In 1866, Rhode Island abolished racial segregation in the public schools throughout the state.
During World War I, Rhode Island furnished 28,817 soldiers, of whom 612 died. After the war, the state was hit hard by the Spanish Influenza.
In the 1920s and 1930s, rural Rhode Island saw a surge in Ku Klux Klan membership, largely in reaction to large waves of immigrants moving to the state. The Klan is believed to be responsible for burning the Watchman Industrial School in Scituate, which was a school for African-American children.
Growth in the modern era: 1929–present.
Since the Great Depression, the Rhode Island Democratic Party has dominated local politics. Rhode Island has comprehensive health insurance for low-income children, and a large social safety net. Many urban areas still have a high rate of children in poverty. Due to an influx of residents from Boston, increasing housing costs have resulted in more homeless in Rhode Island.
The 350th Anniversary of the founding of Rhode Island was celebrated with a free concert held on the tarmac of the Quonset State Airport on August 31, 1986. Performers included Chuck Berry, Tommy James and headliner Bob Hope.
In 2003, a nightclub fire in West Warwick claimed one hundred lives and resulted in nearly twice as many injured, and caught national attention. The fire resulted in criminal sentences.
In March 2010, areas of the state received record flooding due to rising rivers from heavy rain. The first period of rainy weather in mid-March caused localized flooding, and two weeks later, more rain caused more widespread flooding in many towns, especially south of Providence. Rain totals on March 29–30, 2010 exceeded 14 inches in many locales, resulting in the inundation of area rivers—especially the Pawtuxet River which runs through central Rhode Island. The overflow of the Pawtuxet River, nearly 11 ft above flood stage, submerged a sewage plant and closed a five-mile (8 km) stretch of Interstate 95. In addition, it flooded two shopping malls, numerous businesses, and many homes in the towns of Warwick, West Warwick, Cranston, and Westerly. Amtrak service between New York and Boston was also suspended during this period. Following the flood, Rhode Island was in a state of emergency for two days. The Federal Emergency Management Agency (FEMA) was called in to help flood victims.
Government.
The capital of Rhode Island is Providence. The state's current governor is Gina Raimondo (D), and the lieutenant governor is Daniel McKee (D). Raimondo became Rhode Island's first woman governor with a plurality of the vote in the November 2014 state elections. Its United States Senators are Jack Reed (D) and Sheldon Whitehouse (D). Rhode Island's two United States Representatives are David Cicilline (D-1) and Jim Langevin (D-2). "See congressional districts map."
Rhode Island is one of a few states that do not have an official Governor's residence. "See List of Rhode Island Governors."
The state legislature is the Rhode Island General Assembly, consisting of the 75-member House of Representatives and the 38-member Senate. Both houses of the bicameral body are currently dominated by the Democratic Party; the presence of the Republican Party is almost non-existent in the state government, with Republicans holding a handful of seats in both the Senate and House of Representatives.
Elections.
Because Rhode Island's population barely crosses the threshold for additional votes in both the federal House of Representatives and Electoral College, it is well represented relative to its population, with the eighth-highest number of electoral votes and second-highest number of House Representatives per resident. Based on its area, Rhode Island even has the highest density of electoral votes.
Federally, Rhode Island is a reliably Democratic state during presidential elections, often supporting the Democratic Presidential nominee. The state voted for the Republican Presidential candidate until 1908. Since then, it has voted for the Republican nominee for President seven times, and the Democratic nominee seventeen times. The last sixteen presidential elections in Rhode Island have resulted in the Democratic Party winning the Ocean State's Electoral College votes twelve times. In the 1980 presidential election, Rhode Island was one of six states to vote against Republican Ronald Reagan. No Republican since Reagan has even won any of the state's counties in a Presidential election. In 1988, Bush won over 40% of the state's popular vote, something no Republican since has done. Rhode Island was the Democrats' leading state in 1988 and 2000, and second-best in 1968, 1996 and 2004. Rhode Island's most one-sided Presidential election result was in 1964, with over 80% of Rhode Island's votes going for Lyndon B. Johnson. In 2004, Rhode Island gave John Kerry more than a 20-percentage-point margin of victory (the third-highest of any state), with 59.4% of its vote. All but three of Rhode Island's 39 cities and towns voted for the Democratic candidate. The exceptions were East Greenwich, West Greenwich and Scituate. In 2008, Rhode Island gave Barack Obama a 28-percentage-point margin of victory (the third-highest of any state), with 63% of its vote. All but one of Rhode Island's 39 cities and towns voted for the Democratic candidate (The exception being Scituate).
Politics.
Rhode Island has abolished capital punishment, making it one of 15 states that have done so. Rhode Island abolished the death penalty very early, just after Michigan, the first state to abolish it, and carried out its last execution in the 1840s. Rhode Island was the second to last state to make prostitution illegal. Until November 2009 Rhode Island law made prostitution legal provided it took place indoors. In a 2009 study Rhode Island was listed as the 9th safest state in the country.
In 2011, Rhode Island became the third state in the United States to pass legislation to allow the use of medical marijuana. Additionally, the Rhode Island General Assembly passed civil unions, and it was signed into law by Governor Lincoln Chafee on July 2, 2011. Rhode Island became the eighth state to fully recognize either same-sex marriage or civil unions. Same-Sex Marriage became legal on May 2, 2013 and took effect August 1.
Rhode Island has some of the highest taxes in the country, particularly its property taxes, ranking seventh in local and state taxes, and sixth in real estate taxes.
Demographics.
The United States Census Bureau estimates that the population of Rhode Island was 1,055,173 on July 1, 2014, a 0.25% increase since the 2010 United States Census. The center of population of Rhode Island is located in Providence County, in the city of Cranston. A corridor of population can be seen from the Providence area, stretching northwest following the Blackstone River to Woonsocket, where 19th-century mills drove industry and development.
According to the 2010 Census, 81.4% of the population was White (76.4% non-Hispanic white), 5.7% was Black or African American, 0.6% American Indian and Alaska Native, 2.9% Asian, 0.1% Native Hawaiian and other Pacific Islander, 3.3% from two or more races. 12.4% of the total population was of Hispanic or Latino origin (they may be of any race).
Of the people residing in Rhode Island, 58.7% were born in Rhode Island, 26.6% were born in a different state, 2.0% were born in Puerto Rico, U.S. Island areas, or born abroad to American parent(s), and 12.6% were foreign born.
According to the U.S. Census Bureau, as of 2012[ [update]], Rhode Island had an estimated population of 1,050,292, which is a decrease of -354, or -0.1%, from the prior year and an increase of 2,275, or 0.2%, since the year 2000. This includes a natural increase since the last census of 15,220 people (that is 66,973 births minus 51,753 deaths) and an increase due to net migration of 14,001 people into the state. Immigration from outside the United States resulted in a net increase of 18,965 people, and migration within the country produced a net decrease of 4,964 people.
The ten largest ancestry groups in Rhode Island are:
19.0% Italian
18.3% Irish
12.1% English
8.2% Portuguese
8.0% French
6.4% French Canadian
3.3% Dominican
3.3% Puerto Rican
2.2% Chinese
1.8% Guatemalan
Hispanics in the state make up 12.8% of the population, predominantly Dominican, Puerto Rican, and Guatemalan populations.
According to the 2000 U.S. Census, 84% of the population aged 5 and older spoke only American English, while 8.07% spoke Spanish at home, 3.80% Portuguese, 1.96% French, 1.39% Italian and 0.78% speak other languages at home accordingly.
The state's most populous ethnic group, non-Hispanic white, has declined from 96.1% in 1970 to 76.5% in 2011. In 2011, 40.3% of Rhode Island's children under the age of one belonged to racial or ethnic minority groups, meaning that they had at least one parent who was not non-Hispanic white.
6.1% of Rhode Island's population were reported as under 5, 23.6% under 18, and 14.5% were 65 or older. Females made up approximately 52% of the population.
Rhode Island has a higher percentage of Americans of Portuguese ancestry, including Portuguese Americans and Cape Verdean Americans than any other state in the nation. Additionally, the state also has the highest percentage of Liberian immigrants, with more than 15,000 residing in the state. Italian Americans make up a plurality in central and southern Providence County and French Canadians form a large part of northern Providence County. Irish Americans have a strong presence in Newport and Kent counties. Yankees of English ancestry still have a presence in the state as well, especially in Washington County, and are often referred to as "Swamp Yankees." African immigrants, including Cape Verdean Americans, Liberian Americans, Nigerian Americans and Ghanaian Americans, form significant and growing communities in Rhode Island.
Although Rhode Island has the smallest land area of all fifty states, it has the second highest population density of any state in the Union, second to that of New Jersey.
Religion.
A Pew survey of Rhode Island residents' religious self-identification showed the following distribution of affiliations: Roman Catholic 43%, Protestant 27%, Jewish 1%, Orthodox 1%, Jehovah's Witnesses 1%, Buddhism 1%, Mormonism 0.5%, Hinduism 0.5%, Islam 0.5% and Non-religious 23%. The largest denominations are the Roman Catholic Church with 456,598 adherents, the Episcopal Church (United States) with 19,377, and the American Baptist Churches USA with 15,220 adherents.
Rhode Island has one of the highest percentage of Roman Catholics in the nation mainly due to large Irish, Italian, and French Canadian immigration in the past; recently, significant Portuguese and various Hispanic communities have also been established in the state. Though it has one of the highest overall Catholic percentages of any state, none of Rhode Island's individual counties ranks among the 10 most Catholic in the United States, as Catholics are very evenly spread throughout the state.
The Jewish community of Rhode Island is centered in the Providence area, and emerged during a wave of Jewish immigration, (predominately from the Shtetl between 1880 and 1920. The presence of the Touro Synagogue in Newport, the oldest existing synagogue in the United States, emphasizes that these second-wave immigrants did not create Rhode Island's first Jewish community; a comparatively smaller wave of Portuguese Jews immigrated to Newport during the colonial era.
Cities and towns.
Rhode Island is divided into five counties, but along with Connecticut and to a partial extent the rest of New England, it has no county governments. The entire state is divided into municipalities, which handle all local government affairs.
There are 39 cities and towns in Rhode Island. Major population centers today result from historical factors—with the advent of the water-powered mill development took place predominantly along the Blackstone, Seekonk, and Providence Rivers. Providence is the base of a large metropolitan area.
Ranked by population, the state's 15 largest municipalities are:
In common with many other New England states, some of Rhode Island's cities and towns are further partitioned into villages. Notable villages include Kingston, in the town of South Kingstown, which houses the University of Rhode Island, Wickford, in the town of North Kingstown, the site of an annual international art festival, and the Town Hall of the Town of South Kingstown is located in the Village of Wakefield.
Economy.
The Rhode Island economy had a colonial base in fishing. The Blackstone River Valley was a major contributor to the American Industrial Revolution. It was in Pawtucket that Samuel Slater set up Slater Mill in 1793, using the waterpower of the Blackstone River to power his cotton mill. For a while, Rhode Island was one of the leaders in textiles. However, with the Great Depression, most textile factories relocated to southern US states. The textile industry still constitutes a part of the Rhode Island economy, but does not have the same power that it once had.
Other important industries in Rhode Island's past included toolmaking, costume jewelry and silverware. An interesting by-product of Rhode Island's industrial history is the number of abandoned factories—many of them now being used for condominiums, museums, offices, and low-income and elderly housing. Today, much of the economy of Rhode Island is based in services, particularly healthcare and education, and still to some extent, manufacturing. Per the 2013 American Communities Survey, Rhode Island has the highest paid elementary school teachers in the country, with an average salary of $72,630.
The headquarters of Citizens Financial Group, the 14th largest bank in the United States, is located in Providence. The Fortune 500 companies CVS Caremark and Textron are based in Woonsocket and Providence, respectively. FM Global, GTECH Corporation, Hasbro, American Power Conversion, Nortek, and Amica Mutual Insurance are all Fortune 1000 companies that are based in Rhode Island.
Rhode Island's 2000 total gross state product was $33 billion, placing it 45th in the nation. Its 2000 "per capita" personal income was $29,685, 16th in the nation. Rhode Island has the lowest level of energy consumption per capita of any state. Additionally, Rhode Island is a rated as the 5th most energy efficient state in the country. In December 2012, the state's unemployment rate was 10.2%.
Health services are Rhode Island's largest industry. Second is tourism, supporting 39,000 jobs, with tourism-related sales at $3.26 billion in the year 2000. The third-largest industry is manufacturing. Its industrial outputs are costume jewelry, fabricated metal products, electrical equipment, machinery, shipbuilding and boatbuilding. Rhode Island's agricultural outputs are nursery stock, vegetables, dairy products and eggs.
Rhode Island's taxes were appreciably higher than neighboring states, because Rhode Island's income tax was based on 25% of the payer's federal income tax payment. Former Governor Donald Carcieri claimed that the higher tax rate had an inhibitory effect on business growth in the state and called for reductions to increase the competitiveness of the state's business environment. In 2010, the Rhode Island General Assembly passed a new state income tax structure that was then signed into law on June 9, 2010, by Governor Carcieri. The income tax overhaul has now made Rhode Island competitive with other New England states by lowering its maximum tax rate to 5.99% and has reduced the number of tax brackets to three. The state's first income tax was first enacted in 1971.
Largest employers.
As of March 2011, the largest employers in Rhode Island (excluding employees of municipalities) are the following:
Transportation.
Bus.
The Rhode Island Public Transit Authority (RIPTA) operates statewide intra- and intercity bus transport from its hubs at Kennedy Plaza in Providence, Pawtucket, and Newport. RIPTA bus routes serve 38 of Rhode Island's 39 cities and towns. (New Shoreham on Block Island is not served). RIPTA currently operates 58 routes, including daytime trolley service (using trolley-style replica buses) in Providence and Newport.
Ferry.
From 2000 through 2008, RIPTA offered seasonal ferry service linking Providence and Newport (already connected by highway) funded by grant money from the United States Department of Transportation. Though the service was popular with residents and tourists, RIPTA was unable to continue on after the federal funding ended. Service was discontinued as of 2010[ [update]]. The privately run Block Island Ferry links Block Island with Newport and Narragansett with traditional and fast-ferry service, while the Prudence Island Ferry connects Bristol with Prudence Island. Private ferry services also link several Rhode Island communities with ports in Connecticut, Massachusetts, and New York. The Vineyard Fast Ferry offers seasonal service to Martha's Vineyard from Quonset Point with bus and train connections to Providence, Boston, and New York. Viking Fleet offers seasonal service from Block Island to New London, Connecticut and Montauk, New York.
Rail.
The MBTA Commuter Rail's Providence/Stoughton Line links Providence and T.F. Green Airport with Boston. The line was later extended southward to Wickford Junction, with service beginning April 23, 2012. The state hopes to extend the MBTA line to Kingston and Westerly. as well as explore the possibility of extending Connecticut's Shore Line East to T.F. Green Airport. Amtrak's Acela Express stops at Providence Station (the only Acela stop in Rhode Island), linking Providence to other cities in the Northeast Corridor. Amtrak's Northeast Regional service makes stops at Providence Station, Kingston, and Westerly.
Aviation.
Rhode Island's primary airport for passenger and cargo transport is T. F. Green Airport in Warwick, though Rhode Islanders who wish to travel internationally on direct flights or who seek a greater availability of flights and destinations often fly through Logan International Airport in Boston.
Limited access highways.
Interstate 95 runs southwest to northeast across the state, linking Rhode Island with other states along the East Coast. Interstate 295 functions as a partial beltway encircling Providence to the west. Interstate 195 provides a limited-access highway connection from Providence (and Connecticut and New York via I-95) to Cape Cod. Initially built as the easternmost link in the (now cancelled) extension of Interstate 84 from Hartford, Connecticut, a portion of U.S. Route 6 through northern Rhode Island is limited-access and links I-295 with downtown Providence.
Several Rhode Island highways extend the state's limited-access highway network. RI-4 is a major north-south freeway linking Providence and Warwick (via I-95) with suburban and beach communities along Narragansett Bay. RI-10 is an urban connector linking downtown Providence with Cranston and Johnston. RI-37 is an important east-west freeway through Cranston and Warwick and links I-95 with I-295. RI-99 links Woonsocket with Providence (via RI-146). RI-146 travels through the Blackstone Valley, linking Providence and I-95 with Worcester, Massachusetts and the Massachusetts Turnpike. RI-403 links RI-4 with Quonset Point.
Several bridges cross Narragansett Bay connecting Aquidneck Island and Conanicut Island to the mainland, most notably the Claiborne Pell Newport Bridge and the Jamestown-Verrazano Bridge.
Bicycle paths.
The East Bay Bike Path stretches from Providence to Bristol along the eastern shore of Narragansett Bay, while the Blackstone River Bikeway will eventually link Providence and Worcester. In 2011, Rhode Island completed work on a marked on-road bicycle path through Pawtucket and Providence, connecting the East Bay Bike Path with the Blackstone River Bikeway, completing a 33.5 mi bicycle route through the eastern side of the state. The William C. O'Neill Bike Path (commonly known as the South County Bike Path) is a 6-mile path through South Kingstown and Narragansett. The 14-mile Washington Secondary Bike Path stretches from Cranston to Coventry, and the 2-mile Ten Mile River Greenway path runs through East Providence and Pawtucket.
Environmental Issues.
On May 29, 2014, Governor Lincoln D. Chafee announced that Rhode Island was one of eight states to release a collaborative Action Plan to put 3.3 million zero emission vehicles on the roads by 2025. The goal of the plan is to reduce greenhouse gas and smog-causing emissions. The Action Plan covers promoting zero emission vehicles and investing in the infrastructure to support them.
In 2014, Rhode Island received grants from the Environmental Protection Agency in the amount of $2,711,685 to clean up Brownfield sites in eight locations. The intent of the grants was to provide communities with the funding necessary to assess, clean up, and redevelop contaminated properties, boost local economies, and leverage jobs while protecting public health and the environment.
In 2013, the "Lots of Hope" program was established in the City of Providence to focus on increasing the City's green space and local food production, improve urban neighborhoods, promote healthy lifestyles and improve environmental sustainability. "Lots of Hope" supported by a $100,000 grant will partner with the City of Providence, the Soutside Community Land Trust and the Rhode Island Foundation to convert city-owned vacant lots into productive urban farms.
In 2012, Rhode Island passed bill S2277/H7412, "An act relating to Health and Safety - Environmental Cleanup Objectives for Schools", informally known as the "School Siting Bill." The bill, sponsored by Senator Juan Pichardo and Representative Scott Slater and signed into law by the Governor, made Rhode Island the first state in the US to prohibit school construction on vapor intrusion Brownfield Sites where there is an ongoing potential for toxic vapors to negatively impact indoor air quality. It also creates a public participation process whenever a city or town considers building a school on any other kind of contaminated site.
Education.
Colleges and universities.
Rhode Island has several colleges and universities:
Culture.
Local accent.
Some Rhode Islanders speak with the distinctive, non-rhotic, traditional Rhode Island accent that many compare to a cross between the New York City and Boston accents (e.g. "water" sounds like "watuh"). Many Rhode Islanders distinguish a strong "aw" sound [ɔə] (i.e. do not exhibit the cot–caught merger), as one might hear in New Jersey or New York City; for example, the word "coffee" is pronounced [ˈkʰɔəfi] . This type of accent was brought to the region by early settlers from eastern England in the Puritan migration to New England in the mid-seventeenth century.
Rhode Islanders refer to a drinking fountain as a "bubbler" (sometimes pronounced "bubahluh") and sometimes call milkshakes "cabinets".
Food and beverages.
Several foods and dishes are unique to Rhode Island and some are hard to find outside of the state. Hot wieners, which are sometimes called gaggers, weinies, or New York System wieners, are smaller than a standard hot dog, served covered in a meat sauce, chopped onions, mustard, and celery salt. Famous to Rhode Island is Snail Salad, which is served at numerous restaurants throughout the state. The dish is normally prepared "family style" with over five pounds of snails mixed in with other ingredients commonly found in seafood dishes. "Grinders" are submarine sandwiches, with a popular version being the Italian grinder, which is made with cold cuts (usually ham, prosciutto, capicola, salami, and Provolone cheese). Linguiça or chouriço (a spicy Portuguese sausage) and peppers, eaten with hearty bread, is also popular among the state's large Portuguese community.
Pizza strips are prepared in Italian bakeries and sold in most supermarkets and convenience stores. They are rectangular strips of pizza without cheese. Their rich flavor comes solely from a dense, zesty tomato paste baked on a half inch tall pan pizza crust, and may be enjoyed warm or cold. Party pizza is a box of these pizza strips. Spinach pies are similar to a calzone but filled with seasoned spinach instead of meat, sauce and cheese. Variations can include black olives or pepperoni with the spinach.
As in colonial times, johnnycakes are made with corn meal and water, then pan-fried much like pancakes. During fairs and carnivals, Rhode Islanders enjoy dough boys, plate-sized disks of fried dough sprinkled with powdered sugar (or pizza sauce). Zeppoles are Italian doughnut-like pastries traditionally eaten on Saint Joseph's Day, often made with exposed centers of vanilla pudding, cream filling, or ricotta cream, and sometimes topped with a cherry.
As in many coastal states, seafood is readily available. Shellfish is extremely popular, with clams being used in multiple ways. The quahog, from the Narragansett Indian word "poquauhock"; see "A Key into the Language of America" by Roger Williams 1643) is a large clam usually used in a chowder. It is also ground and mixed with stuffing (and sometimes spicy minced sausage) and then baked in its shell to form a "stuffie". Steamed clams are also a very popular dish. Calamari (squid) is sliced into rings and fried and is served as an appetizer in most Italian restaurants, typically Sicilian-style, i.e. tossed with sliced banana peppers and with marinara sauce on the side.
Rhode Island, like the rest of New England, has a tradition of clam chowder. While both the white New England variety and the red Manhattan variety are popular, there is also a unique clear chowder, known as "Rhode Island Clam Chowder" available in many restaurants. According to Good Eats, the addition of tomatoes in place of milk was initially the work of Portuguese immigrants in Rhode Island, as tomato-based stews were already a traditional part of Portuguese cuisine, and milk was costlier than tomatoes. Scornful New Englanders called this modified version "Manhattan-style" clam chowder because, in their view, calling someone a New Yorker was an insult.
A culinary tradition in Rhode Island is the "clam cake". The clam cake (also known as a clam fritter outside of Rhode Island) is a deep fried ball of buttery dough with chopped bits of clam inside. They are sold by the half-dozen or dozen in most seafood restaurants around the state. The quintessential summer meal in Rhode Island is chowder and clam cakes.
Clams Casino originated in Rhode Island after being invented by Julius Keller, the maitre d' in the original Casino next to the seaside Towers in Narragansett. Clams Casino resemble the beloved stuffed quahog but are generally made with the smaller littleneck or cherrystone clam and are unique in their use of bacon as a topping.
According to a "Providence Journal" article, the state features both the highest number and highest density of coffee/doughnut shops per capita in the country, with 342 coffee/doughnut shops in the state. At one point, Dunkin' Donuts alone had over 225 locations; as of December 2013, there are still more than 175 Dunkin' Donuts shops within the state.
The official state drink of Rhode Island is "coffee milk", a beverage created by mixing milk with coffee syrup. This unique syrup was invented in the state and is sold in almost all Rhode Island supermarkets, as well as border states. Although coffee milk contains some caffeine, it is sold in school cafeterias throughout the state. Strawberry milk is also as popular as chocolate milk.
Low numbered license plates.
Since 1904, when the first black and white porcelain license plates were issued by the state, politicians have distributed low-numbered plates as a way to reward supporters or associates; such plates have become a status symbol, similar to the culture surrounding low-numbered plates in Delaware. State officials have seemingly legitimized this by making Rhode Island one of the few states to allow the owner to transfer their license plate(s) to other family members in their will. Additionally, there exists an official license plate lottery through the Governor's Office for "preferred plates", (Passenger plates with 1 letter and 1-3 digits, 2 letters with 1-2 digits, or no letters and 1-5 digits; Commercial/Motorcycle plates with 1-4 digits, Combination plates with 1-4 digits, Suburban/War Veteran's plates with 1-3 digits, and National Guard plates with 1-2 digits). A plate's value depends on its category, with the traditional "Ocean State" legend plate (or "wave plate") being the most valuable. The main branch of the Division of Motor Vehicles was also cooperative in allowing a prospective tag-holder to choose the two letters at the beginning of the plate serial, provided such a combination was available on-hand and was not considered a "preferred plate". As of early 2007, however, Rhode Island no longer issues AA-### format license plates, as had been the standard for over four decades. This ostensibly makes lower plate numbers more sought-after, as all new (non-vanity) registrations will be six numeric characters in length.
Popular culture.
The Farrelly brothers and Seth MacFarlane depict Rhode Island in popular culture, often making comedic parodies of the state. MacFarlane's television series "Family Guy" is based in a fictional Rhode Island city named Quahog, and notable local events and celebrities are regularly lampooned. Peter is seen working at the Pawtucket brewery, and other state locations are mentioned.
The movie "High Society", starring Bing Crosby, Grace Kelly and Frank Sinatra, was set in Newport, Rhode Island.
The film adaptation of The Great Gatsby from 1974 was also filmed in Newport.
Jacqueline Bouvier Kennedy Onassis and John F. Kennedy were married at St. Mary's church in Newport, RI. Their reception was held at Hammersmith Farm, the Bouvier summer home in Newport.
Cartoonist Don Bousquet, a state icon, has made a career out of Rhode Island culture, drawing Rhode Island-themed gags in the "Providence Journal" and "Yankee" magazine. These cartoons have been reprinted in the "Quahog" series of paperbacks ("I Brake for Quahogs", "Beware of the Quahog" and "The Quahog Walks Among Us".) Bousquet has also collaborated with humorist and "Providence Journal" columnist Mark Patinkin on two books: "The Rhode Island Dictionary" and "The Rhode Island Handbook".
The 1998 film "Meet Joe Black" was filmed at Aldrich Mansion in the Warwick Neck area of Warwick, RI.
"Body of Proof"'s first season was filmed entirely in Rhode Island. The show premiered on March 29, 2011.
The 2007 Steve Carell and Dane Cook film "Dan in Real Life" was filmed in various coastal towns in the state. The sunset scene with the entire family on the beach takes place at Napatree Point.
"Jersey Shore" star Pauly D filmed part of his spin-off, "The Pauly D Project" in his hometown of Johnston.
Famous firsts in Rhode Island.
Rhode Island has been the first in a number of initiatives. As a colony, the state enacted the first law prohibiting slavery in North America on May 18, 1652.
Slater Mill in Pawtucket was the first commercially successful cotton-spinning mill with a fully mechanized power system in America and was the birthplace of the Industrial Revolution in the US. The oldest Fourth of July Parade in the country is still held annually in Bristol, Rhode Island. The first Baptist Church in America was founded in Providence in 1638. Ann Smith Franklin of the Newport Mercury was the first female newspaper editor in America (August 22, 1762). She was the editor of "The Newport Mercury" in Newport, Rhode Island. Touro Synagogue, the first synagogue in America, was founded in Newport in 1763.
The first armed act of rebellion in America against the British Crown was the boarding and burning of the Revenue Schooner Gaspee in Narragansett Bay on June 10, 1772. The idea of a Continental Congress was first proposed at a town meeting in Providence on May 17, 1774. Rhode Island elected the first delegates (Stephen Hopkins and Samuel Ward) to the Continental Congress on June 15, 1774. The Rhode Island General Assembly created the first standing army in the colonies (1,500 men) on April 22, 1775. On June 15, 1775, the first naval engagement of the American Revolution occurred between a Colonial Sloop commanded by Capt. Abraham Whipple and an armed tender of the British Frigate Rose. The tender was chased aground and captured. Later in June, the General Assembly created the first American Navy when it commissioned the Sloops "Katy" and "Washington", armed with 24 guns and commanded by Abraham Whipple, who was promoted to Commodore. Rhode Island was the first Colony to declare independence from Britain on May 4, 1776.
Pelham Street in Newport was the first in America to be illuminated by gaslight in 1806. The first strike in the United States in which women participated occurred in Pawtucket in 1824. Watch Hill has the nation's oldest carousel that has been in continuous operation since 1850. The motion picture machine (a machine showing animated pictures) was patented in Providence on April 23, 1867. The first lunch wagon in America was introduced in Providence in 1872. The first nine hole golf course in America was completed in Newport in 1890. The first state health laboratory was established in Providence on September 1, 1894 The Rhode Island State House was the first building with an all-marble dome to be built in the United States (1895–1901) The first automobile race on a track was held in Cranston on September 7, 1896. The first automobile parade was held in Newport on September 7, 1899, on the grounds of Belcourt Castle.
The first NFL night game was held on November 6, 1929, at Providence's Kinsley Park. The Chicago (now Arizona) Cardinals defeated the Providence Steam Roller 16–0. In 1980, Rhode Island became the first state to decriminalize prostitution indoors, but indoor prostitution was outlawed again in 2009; see Prostitution in Rhode Island.
Miscellaneous local culture.
Nicknamed "The Ocean State", the nautical nature of Rhode Island's geography pervades its culture. Newport Harbor, in particular, holds many pleasure boats. In the lobby of the state's main airport, T. F. Green, is a large life size sailboat, and the state's license plates depict an ocean wave or a sailboat.
Additionally, the large number of beaches in Washington County lures many Rhode Islanders south for summer vacation.
The state was notorious for organized crime activity from the 1950s into the 1990s when the Patriarca crime family held sway over most of New England from its Providence headquarters.
Rhode Islanders developed a unique style of architecture in the 17th century, called the stone-ender.
Rhode Island is the only state to still celebrate Victory over Japan Day. It is known locally as "VJ Day", or simply "Victory Day".
Sports.
Rhode Island has two professional sports teams, both of which are top-level minor league affiliates for teams in Boston. The Pawtucket Red Sox baseball team, of the Triple-A International League, are an affiliate of the Boston Red Sox. They play at McCoy Stadium in Pawtucket and have won four league titles, the Governors' Cup, in 1973, 1984, 2012, and 2014. McCoy Stadium also has the distinction of being home to the longest professional baseball game ever played – 33 innings. The other professional minor league team is the Providence Bruins ice hockey team, of the American Hockey League, who are an affiliate of the Boston Bruins. They play in the Dunkin' Donuts Center in Providence and won the AHL's Calder Cup during the 1998–99 AHL season.
The Providence Reds were a hockey team that played in the Canadian-American Hockey League (CAHL) between 1926 and 1936 and the American Hockey League (AHL) from 1936 to 1977, the last season of which they played as the Rhode Island Reds. The team won the Calder Cup in 1938, 1940, 1949, and 1956. The Reds played at the Rhode Island Auditorium, located on North Main Street in Providence, Rhode Island, from 1926 through 1972, when the team affiliated with the New York Rangers and moved into the newly built Providence Civic Center. The team name came from the rooster known as the Rhode Island Red. They have since been moved to New York in 1977 and after multiple name changes are now called the Hartford Wolf Pack. They are the oldest oldest continuously operating minor-league hockey franchise in North America, having fielded a team in one form or another since 1926 in the CAHL. It is also the only AHL franchise to have never missed a season.The AHL returned to Providence in 1992 in the form of the Providence Bruins.
Rhode Island is home to one top level non-minor league team, the Rhode Island Rebellion rugby league team, a Semi-Professional Rugby League team that competes in the USA Rugby League, the Top Competition in the United States for the Sport of Rugby League. The Rebellion play their home games at Classical High School in Providence and fans can experience the game in the Stadium Seating that the Classical Alumni Association and the RI Rebellion funded in 2012. In 2013 the Rebellion finished the USA Rugby League regular season in third place. Their playoff run took them to the USARL Semi-Finals, falling to the Jacksonville Axemen, in Jacksonville in front of over 2,000 fans. This was the first time the Rebellion made the playoffs in its three-year history, narrowly missing out in 2011 and 2012. The Rhode Island Rebellion is a member of the USA Rugby League (USARL) which is the Top
Competition for the Sport of Rugby League in The United States. The USA Rugby League Competition takes place from May through August and you can catch the RI Rebellion at their home games at Classical High School on Saturday Nights.
The National Football League's New England Patriots and Major League Soccer's New England Revolution play at Gillette Stadium in nearby Foxborough, Massachusetts, approximately 18 mi north of Providence and 9 mi from the state's border.
There are four NCAA Division I schools in Rhode Island. All four schools compete in different conferences. The Brown University Bears compete in the Ivy League, the Bryant University Bulldogs compete in the Northeast Conference, the Providence College Friars compete in the Big East Conference and the University of Rhode Island Rams compete in the Atlantic-10 Conference. Three of the schools' football teams compete in the Football Championship Subdivision, the second-highest level of college football in the United States. Brown plays FCS football in the Ivy League, Bryant plays FCS football in the Northeast Conference, and Rhode Island plays FCS football in the Colonial Athletic Association. All four of the Division I schools in the State compete in an intrastate all-sports competition known as the Ocean State Cup, with Bryant winning the most recent cup in 2011–12 academic year.
Rhode Island also has a long and storied history for athletics. Prior to the great expansion of athletic teams all over the country Providence and Rhode Island in general played a great role in supporting teams. The Providence Grays won the first World Championship in baseball history in 1884. The team played their home games at the old Messer Street Field in Providence. The Grays played in the National League from 1878 to 1885. They defeated the New York Metropolitans of the American Association in a best of five game series at the Polo Grounds in New York. Providence won three straight games to become the first champions in major league baseball history. Babe Ruth played for the minor league Providence Grays of 1914 and hit his only official minor league home run for that team before being recalled by the Grays' parent club, the Boston Red Stockings.
A now-defunct professional football team, the Providence Steam Roller, won the 1928 NFL title. They played in a 10,000 person stadium called the Cycledrome. A team by a similar name, the Providence Steamrollers, played in the Basketball Association of America; which would become the National Basketball Association.
From 1930 to 1983, America's Cup races were sailed off Newport, and the both extreme-sport X Games and Gravity Games were founded and hosted in the state's capital city.
The International Tennis Hall of Fame is in Newport at the Newport Casino, site of the first U.S. National Championships in 1881. The Hall of Fame and Museum were established in 1954 by James Van Alen as "a shrine to the ideals of the game". The Hall of Fame Museum encompasses over 20000 sqft of tennis history, chronicling tennis excellence from the 12th century to today. The Hall of Fame has 13 grass courts, and is the site of the Hall of Fame Tennis Championships, the only professional tennis event played on grass courts in the United States. The first members of the Hall of Fame were inducted in 1955, and as of 2008[ [update]], there are 207 players, contributors, and court tennis players in the Hall of Fame.
Rhode Island is also home to the headquarters of the governing body for youth rugby league in the United States, the American Youth Rugby League Association or AYRLA. The AYRLA is a non-profit 501(c)(3) that is dedicated to bringing the sport of Rugby League to youth throughout the USA, especially to those youth who live in at risk communities. The AYRLA has started the first ever Rugby League youth competition in Providence Middle Schools, a program at the RI Training School in addition to starting the first High School Competition in the USA in Providence Public High School.
Landmarks.
The state capitol building is made of white Georgian marble. On top is the world's fourth largest self-supported marble dome. It houses the Rhode Island Charter granted by King Charles II in 1663, the Brown University charter and other state treasures.
The First Baptist Church in America is the oldest Baptist church in the Americas, founded by Roger Williams in 1638.
The first fully automated post office in the country is located in Providence. There are many historic mansions in the seaside city of Newport, including The Breakers, Marble House and Belcourt Castle. Also located there is the Touro Synagogue, dedicated on December 2, 1763, considered by locals to be the first synagogue within the United States (see below for information on New York City's claim), and still serving. The synagogue showcases the religious freedoms that were established by Roger Williams as well as impressive architecture in a mix of the classic colonial and Sephardic style. The Newport Casino is a National Historic Landmark building complex that presently houses the International Tennis Hall of Fame and features an active grass-court tennis club.
Scenic Route 1A (known locally as Ocean Road) is in Narragansett. "The Towers", a large stone arch, is located in Narragansett. It was once the entrance to a famous Narragansett casino that burned down in 1900. The Towers now serve as an event venue and host the local Chamber of Commerce, which operates a tourist information center. Rhode Island also has three of the nations tallest bridges.
The Newport Tower has been hypothesized to be of Viking origin, although most experts believe it was a Colonial-era windmill.
Bibliography.
Secondary sources.
</dl>

</doc>
