<doc id="22790" url="http://en.wikipedia.org/wiki?curid=22790" title="Ozzie Smith">
Ozzie Smith

Osborne Earl "Ozzie" Smith (born December 26, 1954) is a retired American baseball shortstop who played in Major League Baseball (MLB) for the San Diego Padres and St. Louis Cardinals from 1978 to 1996. Nicknamed "The Wizard" for his defensive brilliance, Smith set major league records for career assists (8,375) and double plays (1,590) by a shortstop (the latter since broken by Omar Vizquel), as well as the National League (NL) record with 2,511 career games at the position; Smith won the NL Gold Glove Award for play at shortstop for 13 consecutive seasons (1980–92). A 15-time All-Star, he accumulated 2,460 hits and 580 stolen bases during his career, and won the NL Silver Slugger Award as the best-hitting shortstop in 1987. He was elected to the Baseball Hall of Fame in his first year of eligibility in 2002. He was also elected to the St. Louis Cardinals Hall of Fame in the inaugural class of 2014.
Smith was born in Mobile, Alabama, but his family moved to Watts, Los Angeles, when he was six years old. While participating in childhood athletic activities, Smith developed quick reflexes; he went on to play baseball in high school and college, at Los Angeles' Locke High School and Cal Poly-San Luis Obispo respectively. Drafted as an amateur player by the Padres, Smith made his major league debut in 1978. He quickly established himself as an outstanding fielder, and later became known for performing backflips on special occasions while taking his position at the beginning of a game. Smith won his first Gold Glove Award in 1980, and made his first All-Star Game appearance in 1981. When conflict with Padres' ownership developed, he was traded to the Cardinals for shortstop Garry Templeton in 1982.
Upon joining the Cardinals, Smith helped the team win the 1982 World Series. Three years later, his game-winning home run during Game 5 of the 1985 National League Championship Series prompted broadcaster Jack Buck's "Go crazy, folks!" play-by-play call. Despite a rotator cuff injury during the 1985 season, Smith posted career highs in multiple offensive categories in 1987. Smith continued to earn Gold Gloves and All-Star appearances on an annual basis until 1993. During 1995 season, Smith had shoulder surgery and was out nearly three months. After tension with his new manager Tony La Russa developed in 1996, Smith retired at season's end, and his uniform number (No. 1) was subsequently retired by the Cardinals. Smith also served as host of the television show "This Week in Baseball" from 1997 to 1999.
Early life.
Smith was born in Mobile, Alabama, the second of Clovi and Marvella Smith's six children (five boys and one girl). While the family lived in Mobile, his father worked as a sandblaster at Brookley Air Force Base. When Smith was six his family moved to the Watts section of Los Angeles, California. His father became a delivery truck driver for Safeway stores, while his mother became an aide at a nursing home. His mother was an influential part of his life who stressed the importance of education and encouraged him to pursue his dreams.
Smith played a variety of sports in his youth, but considered baseball to be his favorite. He developed quick reflexes through various athletic and leisure activity, such as bouncing a ball off the concrete steps in front of his house, moving in closer to reduce reaction time with each throw. When not at the local YMCA or playing sports, Smith sometimes went with friends to the neighborhood lumberyard, springboarding off inner tubes and doing flips into sawdust piles (a precursor to his famous backflips). In 1965, at age ten, he endured the Watts Riots with his family, recalling that, "We had to sleep on the floor because of all the sniping and looting going on."
While Smith was attending junior high school, his parents divorced. Continuing to pursue his interest in baseball, he would ride the bus for nearly an hour to reach Dodger Stadium, cheering for the Los Angeles Dodgers at about 25 games a year. Upon becoming a student at Locke High School, Smith played on the basketball and baseball teams. Smith was a teammate of future National Basketball Association player Marques Johnson on the basketball team, and a teammate of future fellow Hall-of-Fame player Eddie Murray on the baseball side. After high school Smith attended Cal Poly San Luis Obispo in 1974 on a partial academic scholarship, and managed to walk-on to the baseball team. In addition to his academic education, he learned to switch-hit from Cal Poly coach Berdy Harr. When Cal Poly's starting shortstop broke his leg midway through the 1974 season, Smith subsequently took over the starting role. Later named an All-American athlete, he established school records in career at bats (754) and career stolen bases (110) before graduating in 1977.
Professional baseball career.
San Diego Padres.
Smith was playing semi-professional baseball in Clarinda, Iowa, in June 1976 when he was selected in the seventh round of the amateur entry draft by the Detroit Tigers. The parties could not agree on a contract; Smith wanted a $10,000 ($ today) signing bonus, while the Tigers offered $8,500 ($ today). Smith returned to Cal Poly for his senior year, then in the 1977 draft was selected in the fourth round by the San Diego Padres, ultimately agreeing to a contract that included a $5,000 signing bonus ($ today). Smith spent his first year of professional baseball, 1977, with the Class A Walla Walla Padres of the Northwest League.
Smith began 1978 as a non-roster invitee to the San Diego Padres' spring training camp in Yuma, Arizona. Smith credited Padres manager Alvin Dark for giving him confidence by telling reporters the shortstop job was Smith's until he proved he can't handle it. Even though Dark was fired in the middle of training camp, Smith made his Major League Baseball (MLB) debut on April 7, 1978.
"As I was in the air, the ball took a bad hop and caromed behind me, but I was able to catch it with my bare hand. I hit the ground, bounced back up, and threw Burroughs out at first."
—Ozzie Smith describes a fielding play he made in 1978
It did not take long for Smith to earn recognition in the major leagues, making what some consider his greatest fielding play only ten games into his rookie season. The Padres played host to the Atlanta Braves on April 20, 1978, and with two out in the top of the fourth inning, Atlanta's Jeff Burroughs hit a ground ball up the middle. Smith described the play by saying, "He hit a ball back up the middle that everybody thought was going into center field. I instinctively broke to my left and dove behind second. As I was in the air, the ball took a bad hop and caromed behind me, but I was able to catch it with my bare hand. I hit the ground, bounced back up, and threw Burroughs out at first."
During a roadtrip to Houston, later in the season, Smith met a part-time usherette at the Astrodome named Denise while making his way to the team bus outside the stadium. The couple developed a relationship that was sometimes long-distance in nature, and eventually decided to marry. It was also during the 1978 season that Smith introduced a signature move. Padres promotion director Andy Strasberg knew Smith could perform backflips, but that he only did them during practice before fans entered the stadium. Strasberg asked Smith to do a backflip for fans during Fan Appreciation Day on October 1, the Padres' last home game of the season. After conferring with veteran teammate Gene Tenace, Smith went ahead with the backflip, and it proved to be wildly popular. Smith finished the 1978 season with a .258 batting average and .970 fielding percentage, placing second in National League Rookie of the Year voting to Bob Horner.
After working with a hitting instructor during the offseason, Smith failed to record a base hit in his first 32 at-bats of the 1979 season. Among players with enough at-bats to qualify for the 1979 National League Triple Crown, Smith finished the season last in batting average (.211), home runs (0), and RBI (27). Off the field, conflict developed between Padres' ownership and the combination of Smith and his agent, Ed Gottlieb. The parties entered into a contract dispute before the 1980 season, and when negotiations lasted into spring training, the Padres renewed Smith's contract at his 1979 salary of $72,500 Smith's agent told the Padres the shortstop would forgo the season to race in the Tour de France, despite the fact Smith admitted to The Break Room on 96.5 WCMF in Rochester, NY he had never heard of the Tour. Angered by the Padres' attitude during those contract talks, Gottlieb took out a help-wanted ad in the "San Diego Union", part of which read, "Padre baseball player wants part-time employment to supplement income." When Joan Kroc, wife of Padres owner Ray Kroc, publicly offered Smith a job as an assistant gardener on her estate, Smith and Gottlieb's relationship with the organization deteriorated further.
Meanwhile, Smith was winning recognition for his accomplishments on the field. In 1980, he set the single-season record for most assists by a shortstop (621), and began his string of 13 consecutive Gold Glove awards. Smith's fielding play prompted the "Yuma Daily Sun" to use the nickname "The Wizard of Oz" in a March 1981 feature article about Smith. While "The Wizard of Oz" nickname was an allusion to the 1939 motion picture of the same name, Smith also came to be known as simply "The Wizard" during his playing career, as Smith's Baseball Hall of Fame plaque would later attest. In 1981, Smith made his first All-Star Game appearance as a reserve player.
Trade.
While Smith was having problems with the Padres' owners, the St. Louis Cardinals also found themselves unhappy with their shortstop. During a game at Busch Stadium on August 26, 1981, Garry Templeton made obscene gestures at fans before being pulled off the field by manager Whitey Herzog. Given the task of overhauling the Cardinals by owner Gussie Busch, Herzog was looking to trade Templeton when he was approached by Padres General Manager Jack McKeon at the 1981 baseball winter meetings. While McKeon had previously told Herzog that Smith was untouchable in any trade, the Padres were now so angry at Smith's agent Gottlieb that McKeon was willing to deal.
McKeon and Herzog agreed in principle to a six-player trade, with Templeton for Smith as the centerpiece. It was then that Padres manager Dick Williams informed Herzog that a no-trade clause had been included in Smith's 1981 contract. Upon learning of the trade, Smith's initial reaction was to invoke the clause and stay in San Diego, but he was still interested to hear what the Cardinals had to say. While the deal for the players beside Templeton and Smith went through, Herzog flew to San Diego to meet with Smith and Gottlieb over the Christmas holiday. Smith later recalled that, "Whitey told me that with me playing shortstop for the St. Louis Cardinals, we could win the pennant. He made me feel wanted, which was a feeling I was quickly losing from the Padres. The mere fact that Whitey would come all the way out there to talk to us was more than enough to convince me that St. Louis was the place I wanted to be."
St. Louis Cardinals.
1982–84.
After more behind-the-scenes contract wrangling, Smith became a St. Louis Cardinal on February 11, 1982. Herzog believed Smith could improve his offensive production by hitting more ground balls, and subsequently created a motivational tool designed to help Smith concentrate on that task. Approaching Smith one day during spring training, Herzog said, "Every time you hit a fly ball, you owe me a buck. Every time you hit a ground ball, I owe you a buck. We'll keep that going all year." Smith agreed to the wager, and by the end of the season had won close to $300 from Herzog. As the 1982 season got underway, Herzog's newly assembled team won 12 games in a row during the month of April, and finished the season atop the National League East division. Herzog would later say of Smith's contributions that, "If he saved two runs a game on defense, which he did many a night, it seemed to me that was just as valuable to the team as a player who drove in two runs a game on offense."
Smith became a father for the first time during the 1982 season with the birth of his son O.J., today known as Nikko, on April 28. Smith also developed a lasting friendship with teammate Willie McGee during the season, and Smith said he likes to think he "helped Willie get over some of the rough spots of adjusting to the major leagues". Smith later participated in the postseason for the first time when the Cardinals faced the Atlanta Braves in the best-of-five 1982 National League Championship Series (NLCS). Smith drove in the series' first run by hitting a sacrifice fly that scored McGee in Game 1, ultimately going five for nine in St. Louis' three-game series sweep.
Just as Herzog had predicted when he told Smith the Cardinals would win the pennant with him on the team, Smith found himself as the team's starting shortstop in the best-of-seven 1982 World Series against the Milwaukee Brewers. During the contest Smith scored three runs, had five hits, and did not commit an error in the field. When St. Louis was trailing 3–1 with one out in the sixth inning of Game 7, Smith started a rally with a base hit to left field, eventually scoring the first of the team's three runs that inning. The Cardinals scored two more runs in the 8th inning for a 6-3 win and the championship.
After the World Series championship, Smith and the Cardinals agreed on a new contract in January 1983 that paid Smith $1 million per year. Smith was voted in as the National League's starting shortstop in the All-Star Game for the first time in 1983, and at season's end won a fourth consecutive Gold Glove Award. During July of the 1984 season, Smith went on the disabled list with a broken wrist after being hit by a pitch during a game against the Padres. Smith's return to the lineup a month later was not enough to propel the Cardinals to a postseason berth.
1985–86.
"Smith corks one into right, down the line! It may go . . . Go crazy, folks, go crazy! It's a home run, and the Cardinals have won the game, by the score of 3 to 2, on a home run by the Wizard! Go crazy!"
—Jack Buck
"And that's driven to deep right field, back goes Marshall...gone!
—NBC's Vin Scully
In 1985, Smith amassed a .276 batting average, 31 stolen bases, and 591 assists in the field. The Cardinals as a team won 101 games during the season and earned another postseason berth. Facing the Los Angeles Dodgers in the now best-of-seven NLCS, a split of the first four games set the stage for Game 5 at Busch Stadium. With the score tied at two runs apiece in the bottom of the ninth inning, Dodgers manager Tommy Lasorda called upon closer Tom Niedenfuer to pitch. Smith batted left-handed against Niedenfuer with one out. Smith, who had never hit a home run in his previous 3,009 left-handed major league at-bats, pulled an inside fastball down the right-field line for a home run, ending Game 5 in a 3–2 Cardinals victory. Smith said, "I was trying to get an extra-base hit and get into scoring position. Fortunately, I was able to get the ball up." The home run not only prompted broadcaster Jack Buck's "Go crazy folks" play-by-play call, but was also later voted the greatest moment in Busch Stadium history by Cardinals fans.
After Smith's teammate Jack Clark hit a late-inning home run of his own in Game 6 to defeat the Dodgers, the Cardinals moved on to face the Kansas City Royals in the 1985 World Series. Once again sportswriters were quick to draw attention to Smith's outstanding defensive play instead of his 2 for 23 effort at the plate. After the Cardinals took a three-games-to-two advantage, a controversial Game 6 call by umpire Don Denkinger overshadowed the remainder of the Series (which the Royals won in seven games).
What was not publicly known during the regular season and playoffs was that Smith had torn his rotator cuff after suffering an impingement in his right shoulder during the July 11–14 homestand against the Padres. After suffering the impingement diving back into first base on a pickoff throw, Smith altered his throwing motion to such a degree that the rotator cuff tear subsequently developed. The 5'10" (1.78 m), 180-pound (82 kg) Smith opted to forgo surgery and instead built up his arm strength via weightlifting, playing through whatever pain he encountered. Said Smith, "I didn't tell anybody about the injury, because I wanted to keep playing and didn't want anybody thinking they could run on me or take advantage of the injury. I tried to do almost everything, except throw a baseball, left-handed: opening a door, turning on the radio—everything. It didn't get any better, but it was good enough that I didn't have to have surgery."
Because of his injury, Smith let his then four-year-old son Nikko perform his traditional Opening Day backflip before the Cardinals' first home game of the 1986 season. Smith made an "eye-popping" play later that season on August 5, during a game against the Philadelphia Phillies at Busch Stadium. In the top of the ninth inning, Phillies first baseman Von Hayes hit a short fly ball to left field, which was pursued by both Smith and left fielder Curt Ford. Running with his back to home plate, Smith dove forward, simultaneously catching the ball while parallel to the ground and flying over the diving Ford, avoiding a collision by inches.
1987–90.
"The thing about Ozzie is, if he misses a ball, you assume it's uncatchable. If any other shortstop misses a ball, your first thought is, 'Would Ozzie have had it?'"
 —Former New York Mets shortstop Bud Harrelson in 1987
After hitting in either the second or eighth spot in the batting order for most of his time in St. Louis, Herzog made Smith the number-two hitter full-time during the 1987 season. Over the course of the year, Smith accrued a .303 batting average, 43 stolen bases, 75 RBIs, 104 runs scored, and 40 doubles, good enough to earn him the Silver Slugger Award at shortstop. In addition to winning the Gold Glove Award at shortstop for the eighth consecutive time, Smith posted a career-high on-base percentage of .392. Smith was also the leading vote-getter in the 1987 All-Star Game. The Cardinals earned a postseason berth with 95 wins, and subsequently faced the San Francisco Giants in the 1987 National League Championship Series. Smith contributed a triple during the series, and the Cardinals won the contest in seven games.
The 1987 World Series matched the Cardinals against the American League champion Minnesota Twins. The home team won every game of the contest, as Minnesota won the series. In 28 at-bats during the Series, Smith scored three runs and had two RBIs. Smith finished second in MVP balloting to Andre Dawson, who had played on the last-place Chicago Cubs, largely because Smith and teammate Jack Clark split the first-place vote. Following the 1987 season, Smith was awarded the largest contract in the National League at $2,340,000.
While the team did not see the postseason for the remainder of the decade, Smith continued to rack up All-Star appearances and Gold Gloves. Combined with the attention he received from his contract, Smith continued to be a national figure. Known as a savvy dresser, he made the April 1988 cover of "GQ" magazine. Smith was witness to change within the Cardinal organization when owner Gussie Busch died in 1989 and Herzog quit as manager during the 1990 season.
1990–95.
"No one paid attention to my offense. So having 2,000 hits is one of the things that is an accomplishment."
—Ozzie Smith, from the 1993 St. Louis Cardinals Yearbook
Joe Torre became Smith's new manager in 1990, but the team did not reach the postseason during Torre's nearly five-year tenure. While the Cardinals celebrated their 100th anniversary in 1992, Smith marked milestones of his own, stealing his 500th career base on April 26, then notching a triple on May 26 in front of the home crowd for his 2,000th hit. St. Louis had a one-game lead in the National League East division on June 1, 1992, but injuries took their toll on the team, including Smith's two-week illness in late July after contracting chicken pox for the first time. As a testament to his national visibility during this time, Smith appeared in a 1992 episode of "The Simpsons" titled "Homer at the Bat". Smith became a free agent for the first time in his career on November 2, 1992, only to sign a new contract with the Cardinals on December 6.
Smith won his final Gold Glove in 1992, and his 13 consecutive Gold Gloves at shortstop in the National League has yet to be matched. The 1993 season marked the only time between 1981 and 1996 that Smith failed to make the All-Star team, and Smith finished the 1993 season with a .288 batting average and .974 fielding percentage. He appeared in 98 games during the strike-shortened 1994 season, and later missed nearly three months of the 1995 season after shoulder surgery on May 31. Smith was recognized for his community service efforts with the 1994 Branch Rickey Award and the 1995 Roberto Clemente Award. In February 1994, Smith took on the role of honorary chairman and official spokesman for the Missouri Governor's Council on Physical Fitness and Health.
1996.
As Smith entered the 1996 season, he finalized a divorce from his wife Denise during the first half of the year. Meanwhile, manager Tony La Russa began his first season with the Cardinals in tandem with a new ownership group. After General Manager Walt Jocketty acquired shortstop Royce Clayton during the offseason, La Russa emphasized an open competition for the spot that would give the Cardinals the best chance to win. When spring training concluded, Smith had amassed a .288 batting average and zero errors in the field, and Clayton batted .190 with eight errors. Smith believed he had earned the position with his spring training performance, but La Russa disagreed, and awarded Clayton the majority of playing time in the platoon situation that developed, where Smith typically saw action every third game. La Russa said, "I think it's fair to say he misunderstood how he compared to Royce in spring training...When I and the coaches evaluated the play in spring training—the whole game—Royce started very slowly offensively and you could see him start to get better. By what he was able to do defensively and on the bases, Royce deserved to play the majority of the games."
Smith missed the first month of the season with a hamstring injury, and continued to harbor ill feelings toward La Russa that had developed after spring training ended. In a closed-door meeting in mid-May, La Russa asked Smith if he would like to be traded. Instead, Smith and his agent negotiated a compromise with Cardinals management, agreeing to a buyout of special provisions in his contract in conjunction with Smith announcing his retirement. The agreement prompted a press conference at Busch Stadium on June 19, 1996, during which Smith announced he would retire from baseball at season's end.
As Smith made his final tour of the National League, he was honored by many teams, and received a standing ovation at the 1996 All-Star Game in Philadelphia. Between June 19 and September 1, Smith's batting average increased from .239 to .286. On September 2 Smith tied a career high by scoring four runs, one of which was a home run, and another on a close play at home plate in the bottom of the 10th inning against division leader Houston. The victory moved the Cardinals to within a half game of Houston in the National League Central Division, and the Cardinals went on to win the division by six games. The Cardinals held a special ceremony at Busch Stadium on September 28, 1996, before a game against the Cincinnati Reds, honoring Smith by retiring his uniform number. Noted for his ritual backflip before Opening Days, All-Star Games, and postseason games, Smith chose this occasion to perform it for one of the last times.
In the postseason, the Cardinals first faced the San Diego Padres in the 1996 National League Division Series. After sitting out Game 1, Smith got the start in Game 2 at Busch Stadium, helping his team go up two games in the series by notching a run, a hit and two walks at the plate, along with an assist and a putout in the field. The Cardinals then swept the series by winning Game 3 in San Diego.
The Cardinals faced the Atlanta Braves in the 1996 National League Championship Series. Smith started Game 1 and subsequently registered three putouts and one assist in the field, but went hitless in four at-bats in the Cardinals' 4–2 loss. The Cardinals then won Games 2, 3, and 4, contests in which Smith did not appear. Upon receiving the start in Game 5, Smith nearly duplicated his Game 1 performance with four putouts, one assist, and zero hits in four at-bats as part of another Cardinals defeat. The Cardinals also failed to win Game 6 or Game 7 in Atlanta, ending their season. When the Cardinals were trailing by ten runs during Game 7 on October 17, Smith flied out to right field while pinch-hitting in the sixth inning, marking the end of his playing career. Smith finished his career with distinctions ranging from the accumulation of more than 27.5 million votes in All-Star balloting, to holding the record for the most MLB at-bats without hitting a grand slam.
Post-playing career.
Upon retirement, Smith took over for Mel Allen as the host of the television series "This Week in Baseball" ("TWIB") in 1997. Smith also became color commentator for the local broadcast of Cardinals games on KPLR-TV from 1997 to 1999. When his stint on "This Week in Baseball" concluded, Smith then moved on to do work for CNN-SI beginning in 1999. After La Russa retired as manager of the Cardinals in 2011, Smith became active in the organization again, starting with his stint as a special instructor for the team's 2012 spring training camp.
On January 8, 2002 Smith learned via a phone call he had been elected to the Baseball Hall of Fame on his first ballot by receiving 91.7% of the votes cast. As it happened, the Olympic torch was passing through St. Louis on its way to Salt Lake City for the 2002 Winter Olympics, and Smith served as a torchbearer in a ceremony with St. Louis Rams' quarterback Kurt Warner that evening. Smith was inducted into the Hall of Fame during ceremonies on July 28, 2002. During his speech, he compared his baseball experiences with the characters from the novel "The Wonderful Wizard of Oz", after which his son Dustin presented his Hall of Fame plaque. Days later on August 11, Smith was back at Busch Memorial Stadium for the unveiling of a statue in his likeness made by sculptor Harry Weber. Weber chose to emphasize Smith's defensive skills by showing Smith stretched horizontal to the ground while fielding a baseball. At the ceremony Weber told Smith, "You spent half of your career up in the air. That makes it difficult for a sculptor to do something with it."
Smith has also been an entrepreneur in a variety of business ventures. Smith opened "Ozzie's" restaurant and sports bar in 1988, started a youth sports academy in 1990, became an investor in a grocery store chain in 1999, and partnered with David Slay to open a restaurant in the early 2000s. Of those businesses the youth academy remains in operation, with the restaurant having closed in 2010 after changing ownership and locations once. Aside from appearing in numerous radio and television commercials in the St. Louis area since retiring from baseball, Smith authored a children's book in 2006 and launched his own brand of salad dressing in 2008.
Besides the National Baseball Hall of Fame, Smith has been also inducted or honored in other halls of fame and recognitions. In 1999, he ranked number 87 on "The Sporting News"' list of the 100 Greatest Baseball Players, and finished third in voting at shortstop for the Major League Baseball All-Century Team. He was honored with induction into the Missouri Sports Hall of Fame, Alabama Sports Hall of Fame and the St. Louis Walk of Fame, and received an honorary Doctor of Humane Letters degree from Cal Poly. In January 2014, the Cardinals announced Smith among 22 former players and personnel to be inducted into the St. Louis Cardinals Hall of Fame Museum for the inaugural class of 2014.
Personal life.
Smith is father to three children from his marriage to former wife Denise; sons Nikko and Dustin, and daughter Taryn. Smith remains a visible figure around the St. Louis area, making varied appearances like playing the role of the Wizard in the St. Louis Municipal Opera's summer 2001 production of "The Wizard of Oz". Smith cheered on his son Nikko as he cracked the top ten finalists of the 2005 edition of "American Idol". In 2012, Smith made news headlines again, when he sold all of his Gold Gloves at auction together for more than $500,000.
Further reading.
</dl>

</doc>
<doc id="22791" url="http://en.wikipedia.org/wiki?curid=22791" title="Boeing OC-135B Open Skies">
Boeing OC-135B Open Skies

The OC-135B Open Skies United States Air Force observation aircraft supports the Treaty on Open Skies. The aircraft, a modified WC-135B, flies unarmed observation flights over participating parties of the treaty. Three OC-135B aircraft were modified by the Aeronautical Systems Center's 4950th Test Wing at Wright-Patterson Air Force Base in Ohio. The first operationally capable OC-135B was assigned to the 24th Reconnaissance Squadron at Offutt AFB in October 1993. It is now fitted with a basic set of navigational and sensor equipment, and placed in inviolate storage at the Aerospace Maintenance and Regeneration Center at Davis-Monthan Air Force Base near Tucson, Arizona. Two fully operational OC-135B aircraft were delivered in 1996 with the full complement of treaty allowed sensors, which includes an infrared line scanner, synthetic aperture radar and video scanning sensors.
Description of aircraft.
The interior seats 35 people, including the cockpit crew, aircraft maintenance crew, foreign country representatives and crew members from the U.S. Department of Defense's Defense Threat Reduction Agency (DTRA). Cameras installed include one vertical and two oblique KS-87E framing cameras used for low-altitude photography approximately 3,000 feet (900 m) above the ground, and one KA-91C panoramic camera, which scans from side to side to provide a wide sweep for each picture used for high-altitude photography at approximately 35000 ft.
The data annotation and recording system (DARMS) processes navigational, altitude, time and camera signals to annotate each picture with correct position, altitude, time, roll angle and other information. In addition, this system records every picture taken according to camera, frame and navigational position and downloads these data to a 3.5-inch floppy disk. A keyboard with trackball is the input device for operation of this system. Two Barco 12 in VGA color monitors display camera annotation and other camera data on screen for the sensor operator and observer use.
Camera control, located in the sensor operator's console, operates and adjusts individual cameras for cloud cover, frame overlap and other functions. The sensor operator console seats four and has all the equipment listed above plus camera bay heating control, chronometers, emergency oxygen, interphone and individual lighting. The flight following console also seats four and includes most of the equipment listed above except for DARMS and camera controls.
Seven commercial Norcoid Tek II coolers with individual refrigeration units maintain temperature and humidity control to maintain peak film performance. The units can be removed, if necessary, from the aircraft in order to transport film. The coolers are capable of storing 40000 ft of film.
Flight path.
The aircraft flies on its intended flight path throughout the entire mission with no reliance on ground-based navigation devices. A top-of-the-line commercial system, Litton 92 INS/GPS, which is an integrated inertial navigation system (INS) with a global positioning system (GPS), provides continuous updates. The GPS updates the INS several times per second to correct any deviations in the flight path. The INS also feeds precise latitude, longitude, time, roll angle and barometric altitude to the DARMS and camera systems. A true airspeed computer feeds true airspeed data to the INS.
A combined altitude radar altimeter provides precise height above ground information to the pilot for navigational purposes as well as a signal to DARMS for film annotation. It is accurate from 0 - above the ground level. Plus, a metric altimeter is installed on the pilot's instrument panel for altitude reference when flying in countries that use meters for altitude reference.
The aircraft are being upgraded with the Block 30 Pacer Crag Navigational System upgrade, a first step in making them compliant with ICAO mandated Global Air Traffic Management and Global Air Navigation Standards guidelines.
Modifications.
The OC-135B modifications center around four cameras installed in the rear of the aircraft. Since its primary mission is to take pictures, most of the installed equipment and systems provide direct support to the cameras and the camera operator. Other modifications to the aircraft also included installing an auxiliary power unit, crew luggage compartment, sensor operator console, flight following console and upgraded avionics.
Other modifications support the aircrew. A gaseous oxygen system replaced the liquid oxygen system to be more compatible with foreign airfields, and fluorescent lighting system was added throughout the cabin to provide adequate lighting for operation and inspections. Four upgraded seats with a conference table, interphone, lighting and oxygen comprise the mission commanders' station for both countries' mission commanders. A four channel interphone system enables segregated communications between various elements on board.
The auxiliary power unit enables the aircraft to start engines and provides electrical power and cabin heat independent of ground support equipment. It was manufactured by Allied Signal with the installation and design of the installation by E-Systems and World Auxiliary Power Company.
The aircraft are assigned to Air Combat Command at the 55th Wing, 45th Reconnaissance Squadron, Offutt Air Force Base near Omaha, Nebraska, for operations, training and maintenance. When tasked, ACC's role is to transport a DTRA observation team to an Open Skies point of entry airport, and conduct the observation flight, then return the team to the continental United States.
Specifications (OC-135).
General characteristics* Crew: Seven (three pilots, two navigators, and two sensor maintenance technicians), also DTRA mission flight crew: mission commander, deputy mission commander, two sensor operators and one flight follower
Performance
References.
This article includes public domain text from the following United States Government source:

</doc>
<doc id="22792" url="http://en.wikipedia.org/wiki?curid=22792" title="Treaty on Open Skies">
Treaty on Open Skies

The Treaty on Open Skies entered into force on January 1, 2002, and currently has 34 States Parties. It establishes a program of unarmed aerial surveillance flights over the entire territory of its participants. The treaty is designed to enhance mutual understanding and confidence by giving all participants, regardless of size, a direct role in gathering information about military forces and activities of concern to them. Open Skies is one of the most wide-ranging international efforts to date promoting openness and transparency of military forces and activities. The concept of "mutual aerial observation" was initially proposed to Soviet Premier Nikolai Bulganin at the Geneva Conference of 1955 by President Dwight D. Eisenhower; however, the Soviets promptly rejected the concept and it lay dormant for several years. The treaty was eventually signed as an initiative of US president (and former Director of Central Intelligence) George H. W. Bush in 1989. Negotiated by the then-members of NATO and the Warsaw Pact, the agreement was signed in Helsinki, Finland, on March 24, 1992.
This treaty is not related to civil-aviation open skies agreements.
Membership.
The 34 State Parties to the Open Skies Treaty are: Belarus, Belgium, Bosnia and Herzegovina, Bulgaria, Canada, Croatia, Czech Republic, Denmark, Estonia, Finland, France, Georgia, Germany, Greece, Hungary, Iceland, Italy, Latvia, Lithuania, Luxembourg, Netherlands, Norway, Poland, Portugal, Romania, Russian Federation, Slovak Republic, Slovenia, Spain, Sweden, Turkey, Ukraine, United Kingdom, and United States. Kyrgyzstan has signed but not yet ratified. Canada and Hungary are the depositories of the treaty in recognition of their special contribution to the Open Skies process. "Depository" countries maintain treaty documents and provide administrative support.
The treaty is of unlimited duration and open to accession by other States. States of the former Soviet Union that have not already become States Parties to the treaty may accede to it at any time. Applications from other interested States are subject to a consensus decision by the Open Skies Consultative Commission (OSCC), the Vienna-based organization charged with facilitating implementation of the treaty, to which all States Parties belong. The Organization for Security and Co-Operation in Europe meets monthly at its Vienna headquarters. Eight states have acceded to the treaty since entry into force: Finland, Sweden, Latvia, Bosnia and Herzegovina, Croatia, Slovenia, Estonia, and Lithuania.
Basic elements of the treaty.
Territory.
The Open Skies regime covers the territory over which the State Party exercises sovereignty, including land, islands, and internal and territorial waters. The treaty specifies that the entire territory of a State Party is open to observation. Observation flights may only be restricted for reasons of flight safety; not for reasons of national security.
Aircraft.
Observation aircraft may be provided by either the observing Party or (the "taxi option") by the observed Party, at the latter's choice. All Open Skies aircraft and sensors must pass specific certification and pre-flight inspection procedures to ensure that they are compliant with treaty standards. The official certified U.S. Open Skies aircraft is the OC-135B Open Skies.
Canada uses a C-130 Hercules aircraft equipped with a "SAMSON" sensor pod to conduct flights over other treaty nations. The pod is a converted CC-130 fuel tank modified to carry the permitted sensors, along with associated on-board mission systems. A consortium of nations consisting of Belgium, Netherlands, Luxemburg, Canada, France, Greece, Italy, Portugal, and Spain own and operate this system. The costs of maintaining the SAMSON Pod are shared, based on each nation's flight quota and actual use.
Bulgaria, Romania, Russia and Ukraine use the Antonov An-30 for their flights. The Czech Republic also used to use the An-30 for this purpose but they apparently retired all of theirs from service in 2003.
Russia also uses the Tu-154M-ON Monitoring Aircraft. Germany formerly used this type as well until the aircraft was lost in a 1997 accident.
Sweden uses a SAAB 340 aircraft ("OS-100") that was certified in 2004.
Sensors.
Open Skies aircraft may have video, optical panoramic and framing cameras for daylight photography, infra-red line scanners for a day/night capability, and synthetic aperture radar for a day/night all weather capability. Photographic image quality will permit recognition of major military equipment (e.g., permit a State Party to distinguish between a tank and a truck), thus allowing significant transparency of military forces and activities. Sensor categories may be added and capabilities improved by agreement among States Parties. All sensors used in Open Skies must be commercially available to all signatories. Imagery resolution is limited to 30 centimetres.
Quotas.
Each State Party is obligated to receive observation flights per its passive quota allocation. Each State Party may conduct as many observation flights - its active quota - as its passive quota. During the first three years after entry into force, each State will be obligated to accept no more than seventy-five percent of its passive quota. Since the overall annual passive quota for the United States is 42, this means that it will be obligated to accept no more than 31 observation flights a year during this three-year period. Only two flights were requested over the United States during 2005, by the Russian Federation and Republic of Belarus Group of States Parties (which functions as a single entity for quota allocation purposes). The United States is entitled to 8 of the 31 annual flights available over Russia/Belarus. Additionally, the United States is entitled to one flight over Ukraine, which is shared with Canada.
Data sharing and availability.
Imagery collected from Open Skies missions is available to any State Party upon request for the cost of reproduction. As a result, the data available to each State Party is much greater than that which it can collect itself under the treaty quota system.
History.
At a Geneva Conference meeting with Soviet Premier Nikolai Bulganin in 1955, President Eisenhower proposed that the United States and Soviet Union conduct surveillance overflights of each other's territory to reassure each country that the other was not preparing to attack. The fears and suspicions of the Cold War led Soviet General Secretary Nikita Khrushchev to reject Eisenhower's proposal. 
During a five-day summit conference held in Geneva, Switzerland at the end of July 1955, the Soviet Union and United States held serious talks about disarmament and the United States put forward proposals for mutual reconnaissance flights over each other's air space, known as the Open Skies proposal. The United States had a large number of RB-47s and RB-36 reconnaissance aircraft at its disposal for such activities, however the Soviets turned down this proposal. However, this Geneva Conference was universally accepted as a turning point in the Cold War. The tensions in Europe were felt to be a stalemate; however both the Soviet Union and United States were willing to talk about their differences, rather than increase them into a state of war.
Thirty-four years later, the Open Skies concept was reintroduced by President George H. W. Bush as a means to build confidence and security between all North Atlantic Treaty Organisation (NATO) and Warsaw Pact countries. In February 1990, an international Open Skies conference involving all NATO and Warsaw Pact countries opened in Ottawa, Canada. Subsequent rounds of negotiations were held in Budapest, Hungary, Vienna, Austria, and Helsinki, Finland.
On March 24, 1992, the Open Skies Treaty was signed in Helsinki by Secretary of State James Baker and foreign ministers from 23 other countries. The treaty entered into force on January 2, 2002, after Russia and Belarus completed ratification procedures.
In November 1992, President Bush assigned responsibility for overall training, management, leadership, coordination and support for U.S. Open Skies observation missions to the On-Site Inspection Agency (OSIA), now a part of the Defense Threat Reduction Agency (DTRA). Until entry into force in January 2002, DTRA support for the treaty involved participating in training and joint trial flights (JTFs). The U.S. has conducted over 70 JTFs since 1993. By March 2003, DTRA had successfully certified 16 camera configurations on the OC-135B aircraft. They also had contributed to the certification of the Bulgarian AN-30, Hungarian AN-26, POD Group (consisting of Belgium, Canada, France, Greece, Italy, Luxembourg, Netherlands, Norway, Portugal and Spain) C-130H,Romanian AN-30, Russian AN-30, and Ukrainian AN-30. The United States successfully flew its first Open Skies mission over Russia in December 2002.
With entry into force of the treaty, formal observation flights began in August 2002. During the first treaty year, States Parties conducted 67 observation flights. In 2004, States Parties conducted 74 missions, and planned 110 missions for 2005. On March 8 and 9, 2007, Russia conducted overflights of Canada under the Treaty. The OSCC continues to address modalities for conducting observation missions and other implementation issues.
Since 2002 a total of 40 missions have taken place over the UK there were 24 quota missions conducted by: Russia—20; Ukraine—three; and Sweden—one. There were 16 training flights conducted by: Benelux (joint with Estonia); Estonia (joint with Benelux); Georgia—three (one joint with Sweden); Sweden—three (one joint with Georgia); USA - three; Latvia; Lithuania; Romania; Slovenia; and Yugoslavia. Also since 2002 the UK has undertaken a total of 51 open skies missions. 38 were quota missions to the following countries: Ukraine (five); Georgia (seven) and Russia (26). 13 missions were training missions to the following nations: Bulgaria; Yugoslavia; Estonia; Slovenia (three); Sweden (three); USA; Latvia, Lithuania and the Benelux. Until 2008 they used an Andover aircraft but since then they have used a variety of aircraft including a Saab 340, An30, and an OS-135. The flights cost approximately £50,000 per operational mission, and approximately £25,000 for training missions with an approximate annual cost of £175,000.
References.
This article includes public domain text from the following United States Government sources:

</doc>
<doc id="22794" url="http://en.wikipedia.org/wiki?curid=22794" title="Limited overs cricket">
Limited overs cricket

Limited overs cricket, also known as one-day cricket and in a slightly different context as List A cricket, is a version of the sport of cricket in which a match is generally completed in one day, whereas Test and first-class matches can take up to five days to complete. The name reflects the rule that in the match each team bowls a set maximum number of overs, usually between 20 and 50, although shorter and longer forms of limited overs cricket have been played.
One-day cricket is popular with spectators as it can encourage aggressive, risky, entertaining batting, often results in cliffhanger endings, and ensures that a spectator can watch an entire match without committing to five days of continuous attendance.
Structure.
Each team bats only once, and each innings is limited to a set number of overs, usually fifty in a One Day International and between forty and sixty in a List A. List A is a classification of the limited-overs (one-day) form of cricket, technically as the domestic level.
Despite its name, important one-day matches, international and domestic, often have two days set aside, the second day being a "reserve" day to allow more chance of the game being completed if a result is not possible on the first day (for instance if play is prevented or interrupted by rain).
Bowling restrictions.
As mentioned above, in almost all competitive one-day games, a restriction is placed on the number of overs that may be bowled by any one bowler. This is to prevent a side playing two top-class bowlers with extremely good stamina who can bowl throughout their opponents' innings. The usual limitation is set so that a side must include at least five players who bowl. For example, the usual limit for twenty-over cricket is four overs per bowler, for forty-over cricket eight per bowler and for fifty-over cricket ten per bowler. There are exceptions: Pro Cricket in the United States restricts bowlers to five overs each, thus leaving a side requiring only four bowlers.
History.
The idea for a one day, limited 50-over cricket tournament, was first played in the inaugural match of the All India Pooja Cricket Tournament in 1951 in the small town of Tripunithura, Kerala, India. It is thought to be the brain child of KV Kelappan Thampuran, a former cricketer and the first Secretary of the Kerala Cricket Association. The one day limited over cricket game was later adapted and played between English county teams for the first instance on 2 May 1962. Leicestershire beat Derbyshire and Northamptonshire beat Nottinghamshire over 65 overs in the "Midlands Knock-Out Cup", which Northamptonshire went on to win a week later. The following year, the first full-scale one-day competition between first-class teams was played, the knock-out Gillette Cup, won by Sussex. The number of overs was reduced to 60 for the 1964 season. League one-day cricket also began in England, when the John Player Sunday League was started in 1969 with forty over matches. Both these competitions have continued every season since inauguration, though the sponsorship has changed. The knock-out cup is now the Friends Provident Trophy. The league is not exclusive to Sundays, with the competition now over 40 overs after some tinkering in the 1990s. It is now called the Natwest Pro40.
The first Limited Overs International (LOI) or One-Day International (ODI) match was played in Melbourne in 1971, and the quadrennial cricket World Cup began in 1975. Many of the "packaging" innovations, such as coloured clothing, were as a result of World Series Cricket, a "rebel" series set up outside the cricketing establishment by Australian entrepreneur Kerry Packer. For more details, see History of cricket.
Twenty20, a curtailed form of one-day cricket with 20 overs per side, was first played in England in 2003. It has proven very popular, and several Twenty20 matches have been played between national teams. It makes several changes to the usual laws of cricket, including the addition of a "bowl-out" (similar to a penalty shoot-out in football) to decide the result of tied matches, which was subsequently dispensed in favour of a Super Over.
One Day Internationals.
One Day International matches are usually played in brightly coloured clothing often in a "day-night" format where the first innings of the day occurs in the afternoon and the second occurs under stadium lights.
One Day International tournaments.
Every four years, the Cricket World Cup involves all the Test-playing nations and other national sides who qualify through the ICC World Cup Qualifier. It usually consists of round-robin stages, followed by semi-finals and a final. The International Cricket Council (ICC) determines the venue far in advance.
The ICC Champions Trophy also involves all the Test-playing nations, and is held between World Cups. It usually consists of a round-robin group stage, semifinals, and a final.
Each Test-playing country often hosts triangular tournaments, between the host nation and two touring sides. There is usually a round-robin group stage, and then the leading two teams play each other in a final, or sometimes a best-of-three final. When there is only one touring side, there is still often a best-of-five or best-of-seven series of limited overs matches.
Domestic one-day competitions.
Domestic one-day competitions exist in almost every country where cricket is played.
List A status.
List A cricket is a classification of the limited-overs (one-day) form of the sport of cricket. Much as domestic first-class cricket is the level below international Test match cricket, so List A cricket is the domestic level of one-day cricket below One Day Internationals. Twenty20 matches do not qualify for the present.
Most cricketing nations have some form of domestic List A competition. The number of overs in List A cricket ranges from forty to sixty overs per side.
The Association of Cricket Statisticians and Historians created this category for the purpose of providing an equivalent to first-class cricket, to allow the generation of career records and statistics for comparable one-day matches. Only the more important one-day competitions in each country, plus matches against a touring Test team, are included. The categorisation of cricket matches as "List A" was not officially endorsed by the International Cricket Council until 2006, when the ICC announced that it and its member associations would be determining this classification in a manner similar to that done for first class matches.
Australia.
The Ryobi One Day Cup is a 50 overs tournament held since 1969. The sides that compete are the following: 
In 2006 Cricket Australia introduced the KFC Twenty20 Big Bash which was amongst the state teams (as above). In 2011 this was expanded to the KFC Twenty20 Big Bash League, consisting of teams based in the capital cities of Australia. The teams are as follows:
Bangladesh.
The National One Day Cricket League is sponsored by Mirzapore Tea. It currently runs from November to March, with each team playing the other home and away once in a round-robin format. These six teams compete for the League title:
Pakistan.
The Pakistani domestic competition changes regularly, but for 2005–06 there are plans for three one-day tournaments for men:
South Africa.
The local competition in South Africa is the Standard Bank Cup (formerly Benson & Hedges Series) played between 6 teams:
The games are 45-overs, and based on a home-and-away round-robin match system (each team plays ten matches) with semi-finals and a final. The Eagles were the winners of the 2004/2005 and 2005/2006 competitions.
Sri Lanka.
20 teams compete in the Premier Limited-Overs Tournament, which is an expansion from 16 in the last season. Games are played over 50 overs per side, and the teams are divided into two groups, where each team meets the other once over a period of a month. The four top teams from each group qualify for the quarter-finals, and there is then a direct knock-out system until a winner is found after three knock-out stages. The competing teams are:
West Indies.
The KFC Cup is the main regional one-day competition in the West Indies, named after its chief sponsor, the fast food chain KFC. In recent years, it has been run over a week's time as a group stage followed by knock-out stages. Guyana are the current holders, after they beat Barbados in the final, and they are also the team to have won it most, with nine titles, although two of them have been shared. Trinidad and Tobago are second in that history, having won seven titles.
In the 2005–06 edition of the KFC Cup, the six permanent first class regions of the West Indies contested the tournament:
One-day records.
The world record for the highest innings total in any List A limited overs match is 496 for 4 by Surrey against Gloucestershire in their Friends Provident Trophy 50-overs match at the Oval, London on 29 April 2007. That surpassed the 443 for nine by Sri Lanka against the Netherlands in their One Day International 50-overs match at Amstelveen on 4 July 2006, which is currently the highest ODI score. The lowest ever total is 23 by Yorkshire against Middlesex at Headingley in 1974 in a 40-overs match.
The most runs scored by both sides in any List A limited overs match is 872: Australia, batting first, scored 434 for four in 50 overs, and yet were beaten by South Africa who scored 438 for nine with a ball to spare during their One Day International at Johannesburg in 2006.
The highest individual innings is 268 by Ali Brown for Surrey against Glamorgan in a 50-overs match at The Oval in 2002. The best bowling figures are eight for 15 by Rahul Sanghvi for Delhi against Himachal Pradesh in a 50-overs match at Una in 1997.
The highest international individual innings is by Rohit Sharma who scored 264.
The highest score in any formal limited overs match is believed to be United's 630 for five against Bay Area in a 45 overs match at Richmond, California in August 2006.
The most runs in an over was scored by Herschelle Gibbs of the South African cricket team when, in the 2007 Cricket World Cup in the West Indies, he hit 6 sixes in one over bowled by Daan van Bunge of the Netherlands.
This record is shared by Yuvraj Singh of India who achieved this feat in the 2007 ICC World Twenty20 in South Africa, he hit 6 sixes in an over bowled by Stuart Broad of England.
Sachin Tendulkar holds the record of being the first male cricketer to score a double century in ODIs (200 not out). He achieved this feat against South Africa on 24 February 2010, at Gwalior, India. Virender Sehwag is the second male cricketer to score a double century, when he scored 219 before being caught out against West Indies on 8 December 2011, at Indore, India. Rohit Sharma became the third male cricketer to score a double century,when he scored 264 against Sri Lanka on 13 November 2014.
References.
</dl>

</doc>
<doc id="22796" url="http://en.wikipedia.org/wiki?curid=22796" title="Organization for Security and Co-operation in Europe">
Organization for Security and Co-operation in Europe

The Organization for Security and Co-operation in Europe (OSCE) is the world's largest security-oriented intergovernmental organization. Its mandate includes issues such as arms control and the promotion of human rights, freedom of the press and fair elections. It employs around 400 people in its secretariat in Vienna, Austria, 200 in its institutions and 2,100 field staff. It has its origins in the 1975 Conference on Security and Co-operation in Europe (CSCE) held in Helsinki, Finland.
The OSCE is concerned with early warning, conflict prevention, crisis management, and post-conflict rehabilitation. Its 57 participating states are located in Europe, Asia and North America and cover most of the land area of the Northern Hemisphere. It was created during the Cold War era as an East–West forum.
History.
The Organization has its roots in the 1973 Conference on Security and Co-operation in Europe (CSCE). Talks had been mooted about a European security grouping since the 1950s but the Cold War prevented any substantial progress until the talks at Dipoli in Espoo began in November 1972. These talks were held at the suggestion of the Soviet Union which wished to use the talks to maintain its control over the communist countries in Eastern Europe, and President of Finland Urho Kekkonen hosted them in order to bolster his policy of neutrality. Western Europe, however, saw these talks as a way to reduce the tension in the region, furthering economic cooperation and obtaining humanitarian improvements for the populations of the Communist bloc.
The recommendations of the talks, in the form of "The Blue Book", gave the practical foundations for a three-stage conference called the "Helsinki process". The CSCE opened in Helsinki on 3 July 1973 with 35 states sending representatives. Stage I only took five days to agree to follow the Blue Book. Stage II was the main working phase and was conducted in Geneva from 18 September 1973 until 21 July 1975. The result of Stage II was the Helsinki Final Act which was signed by the 35 participating states during Stage III, which took place in Finlandia Hall from 30 July – 1 August 1975. It was opened by Holy See’s diplomat Cardinal Agostino Casaroli, who was chairman of the conference.
The concepts of improving relations and implementing the act were developed over a series of follow-up meeting, with major gatherings in Belgrade (4 October 1977 – 8 March 1978), Madrid (11 November 1980 – 9 September 1983) and Vienna (4 November 1986 – 19 January 1989).
The collapse of the Soviet Union required a change of role for the CSCE. The Charter of Paris for a New Europe, signed on 21 November 1990, marked the beginning of this change. With the changes capped by the renaming of the CSCE to the OSCE on 1 January 1995, accordingly to the results of the conference held in Budapest, Hungary, in 1994. The OSCE now had a formal secretariat, Senior Council, Parliamentary Assembly, Conflict Prevention Centre, and Office for Free Elections (later becoming the Office for Democratic Institutions and Human Rights).
In December 1996, the "Lisbon Declaration on a Common and Comprehensive Security Model for Europe for the Twenty-First Century" affirmed the universal and indivisible nature of security on the European continent.
In Istanbul on 19 November 1999, the OSCE ended a two-day summit by calling for a political settlement in Chechnya and adopting a Charter for European Security. According to then Minister of Foreign Affairs Igor Ivanov, this summit marked a turning point in Russian perception of the OSCE, from an organization that expressed Europe's collective will, to an organization that serves as a Western tool for "forced democratization".
After a group of thirteen Democratic United States senators petitioned Secretary of State Colin Powell to have foreign election monitors oversee the 2004 presidential election, the State Department acquiesced, and President George W. Bush invited the OSCE to do so.
Languages.
The six official languages of the OSCE are English, French, German, Italian, Russian and Spanish.
Legal Status.
A unique aspect of the OSCE is the non-binding status of its constitutive charter. Rather than being a formal treaty ratified by national legislatures, the Helsinki Final Act represents a political commitment by the heads of government of all signatories to build security and cooperation in Europe on the basis of its provisions. This allows the OSCE to remain a flexible "process" for the evolution of improved cooperation which avoids disputes and/or sanctions over implementation. By agreeing to these commitments, signatories for the first time accepted that treatment of citizens "within" their borders was also a matter of legitimate international concern. This open process of the OSCE is often given credit for helping build democracy in the Soviet Union and Eastern Europe, thus leading to the end of the Cold War. Unlike most international intergovernmental organizations, however, the OSCE is deprived of international legal personality on account of the lack of legal effect of its charter. As a result, its headquarters host, Austria, had to confer legal personality on the organization in order to be able to sign a legal agreement regarding its presence in Vienna.
Structure and institutions.
Political direction to the organization is given by heads of state or government during summits. Summits are not regular or scheduled but held as needed. The last summit took place in Astana (Kazakhstan), on 1 and 2 December 2010. The high-level decision-making body of the organization is the Ministerial Council, which meets at the end of every year. At ambassadorial level the Permanent Council convenes weekly in Vienna and serves as the regular negotiating and decision-making body. The chairperson of the Permanent Council is the ambassador to the Organization of the participating State which holds the chairmanship. From 1 January 2015 to 31 December 2015 the Chairman-in-Office is Minister for Foreign Affairs of Serbia, Ivica Dačić, who succeeded Swiss Foreign Minister Didier Burkhalter.
In addition to the Ministerial Council and Permanent Council, the Forum for Security Co-operation is also an OSCE decision-making body. It deals predominantly with matters of military co-operation, such as modalities for inspections according to the Vienna Document of 1999.
The OSCE's Secretariat is located in Vienna, Austria. The current Secretary General is Lamberto Zannier of Italy, who took over from Marc Perrin de Brichambaut of France. The organization also has offices in Copenhagen, Geneva, The Hague, Prague and Warsaw.
The OSCE employs approximately 400 people in its secretariat, 200 in its institutions and 2,100 in field operations.
The Parliamentary Assembly of the Organization for Security and Co-operation in Europe passes resolutions on matters such as political and security affairs, economic and environmental issues, and democracy and human rights. Representing the collective voice of OSCE parliamentarians, these resolutions and recommendations are meant to ensure that all participating states live up to their OSCE commitments. The Parliamentary Assembly also engages in parliamentary diplomacy, and has an extensive election observation program.
The oldest OSCE institution is the Office for Democratic Institutions and Human Rights (ODIHR), established in 1991 following a decision made at the 1990 Summit of Paris. It is based in Warsaw, Poland, and is active throughout the OSCE area in the fields of election observation, democratic development, human rights, tolerance and non-discrimination, rule of law, and Roma and Sinti issues. The ODIHR has observed over 150 elections and referendums since 1995, sending some 35,000 observers. It has operated outside its own area twice, sending a team that offered technical support to the 9 October 2004 presidential elections in Afghanistan, an OSCE Partner for Co-operation, and an election support team to assist with parliamentary and provincial council elections on 18 September 2005. ODIHR is headed by Michael Georg Link.
The Office of the OSCE Representative on Freedom of the Media, established in December 1997, acts as a watchdog to provide early warning on violations of freedom of expression in OSCE participating States. The representative also assists participating States by advocating and promoting full compliance with OSCE norms, principles and commitments regarding freedom of expression and free media. As of 2011, the current representative is expert in media law from Bosnia and Herzegovina Dunja Mijatovic.
The High Commissioner on National Minorities was created on July 8, 1992 by the Helsinki Summit Meeting of the Conference on Security and Cooperation in Europe. It is charged with identifying and seeking early resolution of ethnic tension that might endanger peace, stability or friendly relations between participating states.
Secretary-General.
The incumbent of this post acts as the representative of the Chairperson-in-Office, and as the OSCE's chief administrative officer. Since the post was created in 1992, Secretaries-General of the OSCE have been:
 Marc Perrin de Brichambaut (2005–2011)
Chairmanship.
The responsibilities of the Chairman-in-Office (CiO) include
The chairmanship rotates annually, and the post of the chairman-in-office is held by the foreign minister of the participating State which holds the chairmanship. The CiO is assisted by the previous and incoming chairman-in-office; the three of them together constitute the Troika. The origin of the institution lies with the Charter of Paris for a New Europe (1990), the Helsinki Document 1992 formally institutionalized this function.
The 2015 Troika consists of the current CiO, Serbian Foreign Minister Ivica Dačić; the former CiO, Head of the Swiss Department of Foreign Affairs Didier Burkhalter; and incoming CiO, German Foreign Minister Frank-Walter Steinmeier.
Chairmanship history.
Chairmanship of the OSCE is held by a member state on a calendar-year basis, with the minister for foreign affairs of that state performing the function of Chairman-in-Office. The table below shows the holders since 1991.
Fiscal history.
Since 1993, the OSCE's budget by year (in millions of [euro]s,) has been:
Relations with the United Nations.
The OSCE considers itself a regional organization in the sense of Chapter VIII of the United Nations Charter and is an observer in the United Nations General Assembly. The Chairman-in-Office gives routine briefings to the United Nations Security Council.
Politico-military dimension (first dimension).
The OSCE takes a comprehensive approach to the politico-military dimension of security, which includes a number of commitments by participating States and mechanisms for conflict prevention and resolution. The organization also seeks to enhance military security by promoting greater openness, transparency and co-operation.
The end of the Cold War resulted in a huge amount of surplus weapons becoming available in what is known as the international grey market for weapons. The OSCE helps to stop the - often illegal - spread of such weapons and offers assistance with their destruction. The OSCE hosts the annual exchange of information under the Conventional Forces in Europe treaty. The OSCE has also implemented two additional exchanges of information, the Vienna Document and the Global Exchange of Military Information. The Open Skies Consultative Commission, the implementing body for the Treaty on Open Skies, meets monthly at its Vienna headquarters.
The actions taken by the OSCE in border monitoring range from conflict prevention to post-conflict management, capacity building and institutional support.
With its expertise in conflict prevention, crisis management and early warning, the OSCE contributes to worldwide efforts in combating terrorism.
The OSCE works to prevent conflicts from arising and to facilitate lasting comprehensive political settlements for existing conflicts. It also helps with the process of rehabilitation in post-conflict areas.
The OSCE's Forum for Security Co-operation provides a framework for political dialogue on military reform, while practical activities are conducted by field operations, as well as the Conflict Prevention Centre.
OSCE police operations are an integral part of the organization's efforts in conflict prevention and post-conflict rehabilitation.
The OSCE was a rather small organization until selection by the international community to provide electoral organization to post war Bosnia and Herzegovina in early 1996. Ambassador Frowick was the first OSCE representative to initiate national election in September 1996, human rights issues and rule of law specifically designed to provide a foundation for judicial organization within Bosnia and Herzegovina.
The OSCE had regional offices and field offices, to include the office in Brcko in northeastern Bosnia and Herzegovina which remained in limbo until the Brcko Arbitration Agreement could be decided, finalized and implemented.
Brcko become a "special district" and remains so today.
The OSCE essentially took the place of the United Nations in Bosnia and Herzegovina in part because the Bosnian leadership felt deep contempt for the UN efforts to stop the war which began in 1991 and ended in 1995. During the time the United Nations were attempting a political solution, thousands of UN troops were posted in and around Bosnia and Herzegovina with special emphasis on Sarajevo. Between the inclusive dates of 1991 through 1995, over 200,000 Bosnians were killed and over one million displaced and another million as refugees.
The OSCE continues to have a presence and a number of initiatives to bring a sustained peace to the region.
Economic and environmental dimension (second dimension).
Activities in the economic and environmental dimension include the monitoring of developments related to economic and environmental security in OSCE participating States, with the aim of alerting them to any threat of conflict; assisting States in the creation of economic and environmental policies, legislation and institutions to promote security in the OSCE region.
Among the economic activities of the OSCE feature activities related to migration management, transport and energy security. Most activities are implemented in co-operation with partner organizations.
The OSCE has developed a range of activities in the environmental sphere aimed at addressing ecologic threats to security in its participating States. Among the activities feature projects in the area of hazardous waste, water management and access to information under the Aarhus Convention.
Human dimension (third dimension).
The commitments made by OSCE participating States in the human dimension aim to ensure full respect for human rights and fundamental freedoms; to abide by the rule of law; to promote the principles of democracy by building, strengthening and protecting democratic institutions; and to promote tolerance throughout the OSCE region.
Since 2003 the OSCE has had an established mechanism for combating trafficking in human beings, as defined by Article 3 of the Palermo Protocol, which is aimed at raising public awareness of the problem and building the political will within participating states to tackle it effectively.
The OSCE actions against trafficking in human beings are coordinated by the Office of the Special Representative and Co-ordinator for Combating Trafficking in Human Beings. Maria Grazia Giammarinaro, a judge in the Criminal Court of Rome, took Office as the Special Representative in March 2010. From 2006 to 2009 this Office was held by Eva Biaudet, a former Finnish Minister of Health and Social Services. Biaudet currently serves as Finnish Ombudsman for Minorities. Her predecessor was former Austrian Minister Helga Conrad, who served as the first OSCE Special Representative for Combating Trafficking in Human Beings.
The activities around Combating Trafficking in Human Beings in the OSCE Region of the Office of the Special Representative include:
The OSCE claims to promote democracy and assist the participating states in building democratic institutions. In practice, however, few states have more power in decision-making than others.
Education programmes are an integral part of the organization's efforts in conflict prevention and post-conflict rehabilitation.
As part of its democratization activities, the OSCE carries out election assistance projects in the run-up to, during, and following elections. However, the effectiveness of such assistance is arguable—Kazakhstan, for example, despite being the former chair of the OSCE, is considered by many to be one of the least democratic countries in the world. Moreover, the recent democratic advances made in other Central Asian republics, notably Kyrgyzstan, have led to rumours of Soviet-style disruption of the Kyrgyz democratic process by, in particular, Kazakhstan and Russia. This may be in large part due to fears over the long-term stability of these countries' own quasi-dictatorships.
The equality of men and women is an integral part of sustainable democracy. The OSCE aims to provide equal opportunities for men and women and to integrate gender equality in policies and practices.
The OSCE's human rights activities focus on such priorities as freedom of movement and religion, preventing torture and trafficking in persons.
OSCE could grant consultive status to NGOs and INGOs in the form of "Researcher-in-residence programme" (run by the Prague Office of the OSCE Secretariat): accredited representatives of national and international NGOs are granted access to all records and to numerous topical compilations related to OSCE field activities.
The OSCE observes relevant media developments in its participating states with a view to addressing and providing early warning on violations of freedom of expression.
Ethnic conflict is one of the main sources of large-scale violence in Europe today. The OSCE's approach is to identify and to seek early resolution of ethnic tensions, and to set standards for the rights of persons belonging to minority groups and High Commissioner on National Minorities has been established.
Criticism.
Following an unprecedented period of activity in the 1990s and early 2000s (decade), the OSCE has in the past few years faced accusations from the CIS states (primarily Russia) of being a tool for the Western states to advance their own interests. For instance, the events in Ukraine in 2004 (the "Orange Revolution") led to allegations by Russia of OSCE involvement on behalf of the pro-Western Viktor Yushchenko. At the 2007 Munich Conference on Security Policy, Vladimir Putin made this position very clear:
Also, following the Belorussian Presidential election of 2001, the OSCE denounced the election, claiming it to be neither 'free nor fair'; however, the OSCE had actually refused to observe the vote, and still made the aforementioned claim, despite Gérard Stoudmann of the Office for Democratic Institutions and Human Rights (ODIHR) of the OSCE acknowledging that there was "no evidence of manipulation or fraud of the results".
Russia and its allies are advancing the concept of a comprehensive OSCE reform, which would make the Secretariat, institutions and field presences more centralized and accountable to collective consensus-based bodies and focus the work of the Organization on topical security issues (human trafficking, terrorism, non-proliferation, arms control, etc.), at the expense of the "Human Dimension", or human rights issues. The move to reduce the autonomy of the theoretically independent OSCE institutions, such as ODIHR, would effectively grant a Russian veto over any OSCE activity. Western participating States are opposing this process, which they see as an attempt to prevent the OSCE from carrying out its democratization agenda in post-Soviet countries.
Following the 2008 U.S. presidential election, OSCE's ODIHR was accused of having double standards by Russia's lawmaker Slutsky. The point was made that while numerous violations of the voting process were registered, its criticism came only from within the United States (media, human rights organizations, McCain's election staff), while the OSCE known for its bashing criticism of elections on the post-Soviet space remained silent.
OSCE Parliamentary Assembly.
In 2004 the OSCE Parliamentary Assembly sent election observers to the U.S. Presidential elections. The OSCE Parliamentary Assembly’s president at the time was Democratic Congressman Alcee Hastings. Hastings had previously been impeached for corruption by the U.S. Congress. The OSCE faced criticism of partisanship and double standards due to Hastings's past and the fact that the OSCE's mandate was to promote democracy and the values of civil society.
In 2010 the Parliamentary Assembly of the Organization for Security and Co-operation in Europe was criticized from within by the Latvian delegation for lacking transparency and democracy. Spencer Oliver (b. 1938) secretary general of the OSCE Parliamentary Assembly, who has held the post since the organization's inception in 1992, faced a challenge from the Latvian Artis Pabriks. According to the rules of the OSCE Parliamentary Assembly the incumbent general secretary can only be replaced with a full consensus minus one. Pabriks called the rules "quite shocking from the perspective of an organization that's monitoring elections".
In 2014 Ilkka Kanerva was elected the president of the OSCE PA. Kanerva had previously been fired from his post as foreign minister of Finland after lying about sending over 200 text messages to an erotic dancer.
In 2012 Kanerva was found guilty of violation of duties and accepting bribes in relation to an election funding scandal and received a three and a half year suspended sentence.
2012 Texas controversy.
Before the U.S. presidential elections of November 2012, the OSCE announced its intention to send electoral observers to Texas and to other U.S. states. In response, Greg Abbott, the Attorney General of Texas, sent letters to U.S. Secretary of State Hillary Clinton threatening to arrest OSCE officials if they should enter electoral premises in Texas and break Texas law, and to the OSCE. In response, the U.S. Department of State indicated that OSCE observers enjoyed immunities. However no incidents between OSCE and Texas authorities were recorded during the elections.
Allegations of pro-Russian bias (2014).
The organization has come under increasing criticism in the Russian-Ukraine conflict. During the War in Donbass an OSCE observer allowed Russian separatists to use the organization's marked vehicle, which prompted the belief that the OSCE was biased in the war and not interested in carrying out its duties of mediating a ceasefire. The organization issued a statement regretting the incident. The organization has also been criticized by Ukraine for failing to monitor the implementation of the Minsk Protocol. The agreement called for a creation of a 40 km buffer zone, but upon Ukrainian forces withdrawing from their 20 km portion of the buffer, Russian separatists simply occupied the abandoned territory without withdrawing from their own 20 km buffer. Likewise there continues to be reports of separatists using OSCE marked vehicles for transportation. Moreover the mission also received criticism that only 2 checkpoints on the Russian-Ukrainian border are currently being monitored which has been described as "seriously inadequate" by Daniel Baerm the US ambassador to the OSCE. The mission has also been criticized for waiting months to deploy drones to help monitor the border as well as withdrawing them after only several weeks of use due to Russian electronic attacks. Ukraine has stated that approximately 80% of the OSCE observers located near Mariupol were Russian citizens and many had ties to Russian security agencies such as the FSB and GRU. The organization has also been accused of revealing the locations of Ukrainian troops to Russian forces during the conflict and that Russian OSCE observers may be directly coordinating separatist artillery strikes on Ukrainian positions. On 1 December 2014 an OSCE observer was injured by Ukrainian counter artillery fire while observing militants firing at Ukrainian forces. The OSCE team was located next to two pro Russian mortar teams. The OSCE team did not radio in or record the Russian mortar team firing on Ukrainian positions. Critics stated that the unorthodox behavior of being located next to an active separatist artillery position and not reporting the incident showed that the OSCE team was not acting in an impartial manner.

</doc>
<doc id="22798" url="http://en.wikipedia.org/wiki?curid=22798" title="Omri">
Omri

Omri (Hebrew: עמרי,  "Omri",  "ʻOmrî") (fl. 9th century BC) was the sixth king of Israel after Jeroboam, a successful military campaigner, and the founder of the House of Omri, an Israelite royal house which included other monarchs such as Ahab, Ahaziah, Joram, and Athaliah. Along with his predecessor king Zimri who ruled for only seven days, Omri is the first king mentioned in the Bible without a statement of his tribal origin: although some scholars speculate that Omri was from the tribe of Issachar, this is not confirmed by any biblical account.
Mentioned in the Hebrew Bible as well as extra-biblical sources such as the Mesha stele and the Black Obelisk of Shalmaneser III, Omri is also credited with the construction of Samaria and establishing it as his capital.
Struggle for the succession.
Omri was "commander of the army" of King Elah when Zimri, "commander of half the king's chariots", murdered Elah and made himself king. Instead, the troops at Gibbethon chose Omri as king, and he led them to Tirzah where they trapped Zimri in the royal palace. To avoid the certain tortures of capture, Zimri set fire to the palace and died after a reign of only seven days. Although Zimri was eliminated, "half of the people" supported Tibni in opposition to Omri. () It took Omri four years to subdue Tibni and at last proclaim himself undisputed king of Israel. Nothing is said in Scripture about the lineage of Omri. His name is either Amorite or Arabic, suggesting he was a foreign mercenary.
Reign.
Omri became king of Israel in the 31st year of Asa, king of Judah and reigned for 12 years, 6 years of which were in Tirzah. () The biblical reference to the period of rivalry with Tibni is from the 27th year of Asa () to the 31st year. () William F. Albright has dated his reign to 876 – 869 BC, while E. R. Thiele offers the dates of 888 BC to 880 BC for his rivalry with Tibni and 880 – 874 BC for his sole reign.
Initially, Omri's capital was in Tirzah, but the associations of Tirzah were so repellent and the location so poor for a capital, that Omri purchased a new site on a hill, from Shemer for two talents of silver (about 60 kg), after which he built a new capital of the kingdom in Samaria.
Omri's rule over Israel was secure enough that he could bequeath his kingdom to his son Ahab, thus beginning a new dynasty (sometimes called the "Omrides'), and his descendants not only ruled over the kingdom of Israel for the next forty years, but also briefly over Judah.
Omri in archaeological sources.
Bryant G. Wood mentions three archaeological sites indicating buildings constructed by Omri: a well-built, but unfinished structure at Tirzah, a subsequent royal house at Samaria, and a third palace at Jezreel. The fortress at Jezreel was situated on one of the main east-west routes through kingdom. Hugh Williamson believes it served not only a military function, but also a political one; a very visible example of grandiose public works used as a means of social control and to assert claims of legitimacy.
The Moabite Mesha stele (on display in the Louvre) indicates that Omri expanded his holdings to include northern Moab east of the Jordan River. It makes reference to the oppression of Moab by "Omri King of Israel". Israel would later become identified in sources as the "House of Omri" ("Bit-Humria"), with the term "Israel" being used less and less as history progressed (the other defining term for "Israel" is "Samaria", beginning in the reign of Joash). Thomas L. Thompson ("The Bible in History"), however, interprets the Mesha stele as suggesting that Omri is an eponym, or legendary founder of the kingdom rather than an historical person.
The Omride Dynasty.
The short-lived dynasty founded by Omri constitutes a new chapter in the history of the Northern Kingdom of Israel. It ended almost fifty years of constant civil war over the throne. There was peace with the Kingdom of Judah to the south, and even cooperation between the two rival states, while relations with neighboring Sidon to the north were bolstered by marriages negotiated between the two royal courts. This state of peace with two powerful neighbors enabled the Kingdom of Israel to expand its influence and even political control in Transjordan, and these factors combined brought economic prosperity to the kingdom.
On the other hand, peace with Sidon also resulted in the penetration of Phoenician religious ideas into the kingdom and led to a "kulturkampf" between traditionalists (as personified by the prophet Elijah and his followers) and the aristocracy (as personified by Omri's son and heir Ahab and his consort Jezebel). In foreign affairs, this period paralleled the rise of the Kingdom of Aram based in Damascus, and Israel soon found itself at war in the northeast. Most threatening, however, was the ascendancy of Assyria, which was beginning to expand westward from Mesopotamia: the Battle of Qarqar (853 BC), which pitted Shalmaneser III of Assyria against a coalition of local kings, including Ahab, was the first clash between Assyria and Israel. It was the first in a series of wars that would eventually lead to the destruction of the Kingdom of Israel in 722 BC and the reduction of the Kingdom of Judah to an Assyrian tributary state.
In 841 BC, the Assyrian king Shalmaneser III campaigned along the Mediterranean coast and forced Jehu to pay tribute. Assyrian kings frequently referred to Omri's successors as belonging to the "House of Omri" ("Bit Hu-um-ri-a"). Despite the fact that Jehu ended the Omrid dynasty, the Assyrian Black Obelisk in the British Museum credits Jehu as being the "son of Omri" while the Bible describes him to be "the son of Jehoshaphat the son of Nimshi".
In accounts of Tiglath-Pileser III's 732 BC campaign in Israel, Assyrian scribes referred to Israel as "Omri-Land".
Attitude in contemporary Israel.
The Bible displays a negative attitude to King Omri, and it has been followed by later rabbinical tradition. Modern secular Israelis, however, have re-evaluated many Biblical and later Jewish historical characters in accord with the criteria of a national movement in need of heroes. As in many European national movements, ancient warriors in general and warrior kings in particular have come to be regarded more positively. Omri, a successful warrior king and the founder of a strong dynasty, is a conspicuous example.

</doc>
<doc id="22799" url="http://en.wikipedia.org/wiki?curid=22799" title="Oxycodone">
Oxycodone

Oxycodone is a semisynthetic opioid synthesized from thebaine, an opioid alkaloid found in the Persian poppy and one of the many opioid alkaloids found in the opium poppy. It is an analgesic generally indicated for relief of moderate to severe pain. It was developed in 1917 in Germany as one of several new semi-synthetic opioids in an attempt to improve on the existing opioids.
Oxycodone is available as single-ingredient medication in immediate release and controlled release. Parenteral formulations of 10 mg/mL and 50mg/mL are available in the U.K. for IV/IM administration. Combination products formulated with non-narcotic ingredients such as nonsteroidal anti-inflammatory drugs (NSAID) and paracetamol (acetaminophen) are also available as immediate release formulations; a combination with naloxone is available in managed-release tablets, the naloxone precipitates opioid withdrawal symptoms & blocks the faster onset were the tablet to be crushed and filtered for injection or otherwise tampered with in a manner not indicated.
Medical uses.
Oxycodone has been in clinical use since 1916, and it is used for managing moderate to moderately severe acute or chronic pain. It has been found to improve quality of life for those with many types of pain. However, wrong prescription indication due to mistakes by prescriber can lead to severe addiction.
Controlled-release oral tablet form is intended to be taken every 12 hours. As is the case with other opioids, oxycodone is clearly useful for acute pain and in some instances of chronic cancer pain. Experts are divided regarding the efficacy of all opioids in non-malignant chronic pain. While the opioids induce acute pain relief, all of them have the potential for dependence, withdrawal and the induction of pain sensitivity and hyperalgesia, thereby causing the symptom (pain) that they are being used to treat.
An Italian study concluded from investigating multiple studies that controlled-release oxycodone is comparable to instant-release oxycodone, morphine and hydromorphone in management of moderate to severe cancer pain. It indicated that side effects appear to be less than those associated with morphine and that it is a valid alternative to morphine and a first-line treatment for cancer pain.
In 2014, the European Association for Palliative Care recommended that oral oxycodone could be taken as a second-line alternative to oral morphine for cancer pain.
Administration.
In the United States, Oxycodone is medically approved only for administration orally, and is only supplied in oral preparations, tablets and liquid. In the United Kingdom, Oxycodone is also medically approved for intravenous therapy (IV) and intramuscular injection (IM). When first introduced in Germany in 1917, IV/IM quickly became common for post-operative pain management of soldiers of the Central Powers during World War I.
Off-Label Use.
Unlike most opiods, oxycodone has a significant anti-depressant effect. Its use for this purpose may be illegal: see Legal Status below.
Side effects.
Common side effects include euphoria, constipation, fatigue, dizziness, nausea, vomiting, dry mouth, anxiety, itching, and sweating. Less common side effects (experienced by less than 5% of patients) include loss of appetite, nervousness, abdominal pain, diarrhea, urine retention, dyspnea, and hiccups.
In high doses, overdoses, or in patients not tolerant to opiates, oxycodone can cause shallow breathing, bradycardia, cold-clammy skin, apnea, hypotension, miosis, circulatory collapse, respiratory arrest, and death.
Oxycodone in combination with naloxone in managed-release tablets, has been formulated to reduce side effects.
Dependence, addiction and withdrawal.
The risk of experiencing severe withdrawal symptoms is high if a patient has become physically dependent or addicted and discontinues oxycodone abruptly. Therefore, particularly in cases where the drug has been taken regularly over an extended period, use should be discontinued gradually rather than abruptly. People who use oxycodone in a recreational, hazardous, or harmful fashion (not as intended by the prescribing physician) are at even higher risk of severe withdrawal symptoms, as they tend to use higher-than-prescribed doses. The symptoms of oxycodone withdrawal are the same as for other opiate-based painkillers, and may include "anxiety, panic attack, nausea, insomnia, muscle pain, muscle weakness, fevers, and other flu-like symptoms".
Withdrawal symptoms have also been reported in newborns whose mothers had been either injecting or orally taking oxycodone during pregnancy.
Hormone imbalance.
As with other opioids, oxycodone (particularly during chronic heavy use) often causes temporary hypogonadism or hormone imbalance.
Detection in biological fluids.
Oxycodone and/or its major metabolites may be measured in blood or urine to monitor for clearance, abuse, confirm a diagnosis of poisoning, or assist in a medicolegal death investigation. Many commercial opiate screening tests cross-react appreciably with oxycodone and its metabolites, but chromatographic techniques can easily distinguish oxycodone from other opiates.
Pharmacology.
Mechanism of action.
In 1997, a group of Australian researchers proposed (based on a study in rats) that oxycodone acts on κ-opioid receptors, unlike morphine, which acts upon μ-opioid receptors. Further research by this group indicated the drug appears to be a κ2b-opioid agonist. However, this conclusion has been disputed, primarily on the basis that oxycodone produces effects that are typical of μ-opioid agonists, mainly because oxycodone is metabolized in the liver to oxymorphone as a metabolite, which is a more potent opioid agonist with stronger/higher binding affinity to μ-opioid receptors compared to oxycodone.
In 2006, research by a Japanese group suggested the effect of oxycodone is mediated by different receptors in different situations. Specifically in diabetic mice, the κ-opioid receptor appears to be involved in the antinociceptive effects of oxycodone, while in nondiabetic mice, the μ1-opioid receptor seems to be primarily responsible for these effects.
After oxycodone binds to the opioid receptor, a G-protein complex is released, which inhibits the release of neurotransmitters by the cell by reducing the amount of cAMP produced, closing the Ca++ channels, and opening the K channels.
Absorption.
After a dose of conventional oral oxycodone, peak plasma levels of the drug are attained in about one hour; in contrast, after a dose of OxyContin (an oral controlled-release formulation), peak plasma levels of oxycodone occur in about three hours.
Distribution.
Oxycodone in the blood is distributed to skeletal muscle, liver, intestinal tract, lungs, spleen, and brain. Conventional oral preparations start to reduce pain within 10–15 minutes on an empty stomach; in contrast, OxyContin starts to reduce pain within one hour.
Metabolism.
Oxycodone is metabolized to α and β oxycodol; oxymorphone, then α and β oxymorphol and noroxymorphone; and noroxycodone, then α and β noroxycodol and noroxymorphone (N-desmethyloxycodone). (14-Methoxymetopon that in turn becomes 14-Hydroxydihydromorphine) These metabolites are true only for humans. As many as six metabolites for oxycodone (14-hydroxydihydromorphinone, 14-hydroxydihydrocodeine, 14-hydroxydihydrocodeinone N-oxide {oxycodone N-oxide}, 14-hydroxydihydroisocodeine, 14-hydroxydihydrocodeine N-oxide, and noroxycodone) have been found in rabbits, several of which are thought to be active metabolites to some extent, although a study using conventional oral oxycodone concluded oxycodone itself, and not its metabolites, is predominantly responsible for the drug's opioid effects on the brain.
Oxycodone is metabolized by the cytochrome P450 enzyme system in the liver, making it vulnerable to drug interactions. Some people are fast metabolizers, resulting in reduced analgesic effect, but increased adverse effects, while others are slow metabolisers, resulting in increased toxicity without improved analgesia. The dose of OxyContin must be reduced in patients with reduced hepatic function.
Elimination.
Oxycodone and its metabolites are mainly excreted in the urine and sweat; therefore, it accumulates in patients with renal impairment.
Dosage and administration.
Oxycodone can be administered orally, intranasally, via intravenous, intramuscular, or subcutaneous injection, or rectally. The bioavailability of oral administration of oxycodone averages 60–87%, with rectal administration yielding the same results; intranasal varies between individuals with a mean of 46%.
Equivalency.
Taken orally, the conversion ratio between morphine to extended release oxycodone is reported as 2:1.
Chemistry.
Oxycodone's chemical name is derived from codeine. The chemical structures are very similar, differing only in that
It is also similar to hydrocodone, differing only in that it has a hydroxyl group at carbon-14.
Expanded expression for the compound oxycodone in the academic literature include "dihydrohydroxycodeinone", "Eucodal", "Eukodal", "14-hydroxydihydrocodeinone", and "Nucodan". In a UNESCO convention, the translations of "oxycodone" are "oxycodon" (Dutch), "oxycodone" (French), "oxicodona" (Spanish), الأوكسيكودون (Arabic), 羟考酮 (Chinese), and оксикодон (Russian). The word "oxycodone" should not be confused with "oxandrolone", "oxazepam", "oxybutynin", "oxytocin", or "Roxanol".
In terms of biosynthesis, oxycodone has been found naturally in nectar extracts from the orchid family "Epipactis helleborine"; together along with another opioid: 3-{2-{3-{3-benzyloxypropyl}-3-indol, 7,8-didehydro- 4,5-epoxy-3,6-d-morphinan.
History.
Freund and Speyer of the University of Frankfurt in Germany first synthesized oxycodone from thebaine in 1916, a few years after the German pharmaceutical company Bayer had stopped the mass production of heroin due to hazardous use, harmful use, and dependence. It was hoped that a thebaine-derived drug would retain the analgesic effects of morphine and heroin with less dependence. To some extent this was achieved, as oxycodone does not have the same immediate effect as heroin or morphine, nor does it last as long.
The first clinical use of the drug was documented in 1917, the year after it was first developed. It was first introduced to the US market in May 1939. In early 1928, Merck introduced a combination product containing scopolamine, oxycodone and ephedrine under the German initials for the ingredients SEE, which was later renamed Scophedal (SCOpolamine ePHEDrine and eukodAL). This combination is essentially an oxycodone analogue of the morphine-based Twilight Sleep with ephedrine added to reduce circulatory and respiratory effects.
In the early 1960s the United States government classified Oxycodone as a schedule II drug. In 1995 the FDA approved OxyContin.
As of May 2013 an extended release version in the United States is only available as OxyContin brand.
Statistics.
The International Narcotics Control Board estimated 11.5 tons (23,000 lbs) of oxycodone were manufactured worldwide in 1998; by 2007 this figure had grown to 75.2 tons (150,400 lbs). United States accounted for 82% of consumption in 2007 at 51.6 tons. Canada, Germany, Australia and France combined accounted for 13% of consumption in 2007. In 2010, 122.5 tons of oxycodone were manufactured, according to the International Narcotics Control Board. This number had decreased slightly from the all time high in 2009 of 135.9 tons.
Recreational use.
Effects.
Oxycodone, like other opioid analgesics, tends to induce feelings of euphoria, relaxation and reduced anxiety in those who are occasional users. These effects, along with its addictive qualities and legal prohibition, make it one of the most commonly abused pharmaceutical drugs in the United States.
Preventive measures.
In August 2010, Purdue Pharma reformulated their long-acting oxycodone line, marketed as OxyContin, to use a misuse-resistant polymer designed to decrease abuse potential by defeating the release mechanism. The FDA approved relabeling the reformulated version as abuse-resistant in April 2013.
Pfizer manufactures a preparation of short-acting oxycodone, marketed as Oxecta, which contains inactive ingredients designed to induce nasal irritation if the tablet is crushed and snorted.
Australia.
The non-medical use of OxyContin began in Australia in the early 2000s. By 2015, 91% of a national sample of injection drug users in Australia had reported using oxycodone, and 27% had injected it in the last six months.
Canada.
Opioid-related deaths in Ontario had increased by 242 per cent from 1969 to 2014. By 2009 in Ontario there were more deaths from Oxycodone overdose than from cocaine overdose, Deaths from opioid pain relievers had increased from 13.7 deaths per million residents in 1991 to 27.2 deaths per million residents in 2004. The abuse of oxycodone in Canada became a problem. Areas where oxycodone is most problematic are Atlantic Canada and Ontario, where its abuse is prevalent in rural towns, and in many smaller to medium-sized cities. Oxycodone is also widely available across Western Canada, but methamphetamine and heroin are more serious problems in the larger cities, while oxycodone is more common in rural towns. Oxycodone is diverted through doctor shopping, prescription forgery, pharmacy theft, and overprescribing.
The Blood Tribe police claimed that since the fall of 2014 through to January 2015— Oxycodone pills or a lethal fake variation containing fentanyl made in illegal labs by members of organized crime— were responsible for ten deaths on the Blood Reserve, which is located southwest of Lethbridge, Alberta.
United Kingdom.
Abuse and diversion of oxycodone in the UK commenced in the early- to mid-2000s. The first known death due to overdose in the UK occurred in 2002. However, recreational use remains relatively rare.
United States.
In the United States, more than 12 million people abuse opioid drugs. In 2010, 16,652 deaths were related to opioid overdose in combination with other drugs such as benzodiazepines and alcohol. In September 2013, the FDA released new labeling guidelines for long acting and extended release opioids requiring manufacturers to remove moderate pain as indication for use, instead stating the drug is for "pain severe enough to require daily, around-the-clock, long term opioid treatment." The updated labeling will not restrict physicians from prescribing opioids for moderate, as needed use.
Based on statistical estimates by the US Department of Health and Human Services, about 11 million people in the US will consume at least one dose of this opioid in a non-medical way. About 100,000 men or women per year are admitted to US hospitals due to misuse of this drug, making it the most widely abused opioid drug in America. Diverted oxycodone is taken orally or ingested through insufflation, it can also be prepared for injection and administered intravenously, while some abusers will heat the pills on aluminum foil and inhale the smoke as a means of ingesting oxycodone. Other ways of abuse include intravenous injection of oral dosage forms, which are not designed for parenteral use. In 2008, oxycodone and hydrocodone misuse caused 14,800 deaths. Some of the cases, however, were due to the hepatotoxic effect of acetaminophen.
Legal status.
General.
Oxycodone is subject to international conventions on narcotic drugs. In addition, oxycodone is subject to national laws that differ by country. The 1931 Convention for Limiting the Manufacture and Regulating the Distribution of Narcotic Drugs of the League of Nations included oxycodone. The 1961 Single Convention on Narcotic Drugs of the United Nations, which replaced the 1931 convention, categorized oxycodone in Schedule I. Global restrictions on Schedule I drugs include "limit[ing] exclusively to medical and scientific purposes the production, manufacture, export, import, distribution of, trade in, use and possession of" these drugs; "requir[ing] medical prescriptions for the supply or dispensation of [these] drugs to individuals"; and "prevent[ing] the accumulation" of quantities of these drugs "in excess of those required for the normal conduct of business".
Australia.
Oxycodone is in Schedule I (derived from the Single Convention on Narcotic Drugs) of the Commonwealth's Narcotic Drugs Act 1967. In addition, it is in Schedule 8 of the Australian Standard for the Uniform Scheduling of Drugs and Poisons ("Poisons Standard"), meaning it is a "controlled drug... which should be available for use but require[s] restriction of manufacture, supply, distribution, possession and use to reduce abuse, misuse and physical or psychological dependence".
Canada.
Oxycodone is a controlled substance under Schedule I of the Controlled Drugs and Substances Act (CDSA).
Legislative changes regulating oxycodone in Canada.
In February 2012, Ontario passed legislation to allow the expansion of an already existing drug-tracking system for publicly funded drugs to include those that are privately insured. This database will function to identify and monitor patient’s attempts to seek prescriptions from multiple doctors or retrieve from multiple pharmacies. Other provinces have proposed similar legislation, while some, such as Nova Scotia, have legislation already in effect for monitoring prescription drug use. These changes have coincided with other changes in Ontario’s legislation to target the misuse of painkillers and high addiction rates to drugs such as oxycodone. As of February 29, 2012, Ontario passed legislation delisting oxycodone from the province’s public drug benefit program. This was a first for any province to delist a drug based on addictive properties. The new law prohibits prescriptions for OxyNeo except to certain patients under the Exceptional Access Program including palliative care and in other extenuating circumstances. Patients already prescribed oxycodone will receive coverage for an additional year for OxyNeo, and after that, it will be disallowed unless designated under the exceptional access program.
Much of the legislative activity has stemmed from Purdue Pharma’s decision in 2011 to begin a modification of oxycodone’s composition to make it more difficult to crush for snorting or injecting. The new formulation, OxyNeo, is intended to be preventative in this regard and retain its effectiveness as a pain killer. Since introducing its "Narcotics Safety and Awareness Act", Ontario has committed to focusing on drug addiction, particularly in the monitoring and identification of problem opioid prescriptions, as well as the education of patients, doctors, and pharmacists. This Act, introduced in 2010, commits to the establishment of a unified database to fulfill this intention. Both the public and medical community have received the legislation positively, though concerns about the ramifications of legal changes have been expressed. Because laws are largely provincially regulated, many speculate a national strategy is needed to prevent smuggling across provincial borders from jurisdictions with looser restrictions.
Lawsuits in Canada.
Several class action suits across Canada have been launched against the Purdue group of companies and affiliates. Claimants argue the pharmaceutical manufacturers did not meet a standard of care and were negligent in doing so. These lawsuits reference earlier judgments in the United States, which held that Purdue was liable for wrongful marketing practices and misbranding. Since 2007, the Purdue companies have paid over $650 million in settling litigation or facing criminal fines.
Germany.
The drug is in Appendix III of the Narcotics Act ("Betäubungsmittelgesetz" or BtMG). The law allows only physicians, dentists, and veterinarians ("Ärzte, Zahnärzte und Tierärzte") to prescribe oxycodone and the federal government to regulate the prescriptions (e.g., by requiring reporting).
Hong Kong.
Oxycodone is regulated under Part I of Schedule 1 of Hong Kong's Chapter 134 Dangerous Drugs Ordinance.
Singapore.
Oxycodone is listed as a Class A drug in the Misuse of Drugs Act of Singapore, which means offences in relation to the drug attract the most severe level of punishment. A conviction for unauthorized manufacture of the drug attracts a minimum sentence of 10 years of imprisonment and corporal punishment of five strokes of the cane, and a maximum sentence of life imprisonment or 30 years of imprisonment and 15 strokes of the cane. The minimum and maximum penalties for unauthorized trafficking in the drug are respectively five years of imprisonment and five strokes of the cane, and 20 years of imprisonment and 15 strokes of the cane.
United Kingdom.
Oxycodone is a Class A drug under the Misuse of Drugs Act. For Class A drugs, which are "considered to be the most likely to cause harm", possession without a prescription is punishable by up to seven years in prison, an unlimited fine, or both. Dealing of the drug illegally is punishable by up to life imprisonment, an unlimited fine, or both. In addition, oxycodone is a Schedule 2 drug per the Misuse of Drugs Regulations 2001 which "provide certain exemptions from the provisions of the Misuse of Drugs Act 1971".
United States.
Oxycodone is a Schedule II controlled substance whether by itself or part of a multi-ingredient medication. The DEA lists oxycodone both for sale and for use in manufacturing other opioids as ACSCN 9143 and in 2013 approved the following annual aggregate manufacturing quotas: 131.5 metric tons for sale, down from 153.75 in 2012, and 10.25 metric tons for conversion, unchanged from the previous year. The salts in use are the hydrochloride (free base conversion ratio .896), bitartrate (.667), tartrate (.750), camphosulphonate (.576), pectinate (.588), phenylpriopionate (.678), sulphate, (.887), phosphate (.763), and terephthalate (.792); the first and last are found together in Percodan and the hydrochloride by itself is the basis of most American oxycodone products whilst the bitartrate, tartrate, pectinate, and phosphate are also used alongside the other two in Europe. The methyiodide and hydroiodide are mentioned in older European publications.

</doc>
<doc id="22800" url="http://en.wikipedia.org/wiki?curid=22800" title="Occidental College">
Occidental College

Occidental College is a private, co-educational liberal arts college located in the Eagle Rock neighborhood of Los Angeles, California. Founded in 1887 by clergy and members of the Presbyterian Church, Occidental College is referred to as "Oxy" by some students and alumni.
Occidental College is the oldest liberal arts college in Los Angeles and one of the few liberal arts colleges located in a major city. In 2014, "U.S. News and World Report" ranked Occidental as No. 44 on the list of National Liberal Arts Colleges. "The New York Times" ranked Occidental No. 20 on its list of the most economically diverse U.S. colleges and universities. The Carnegie Foundation for the Advancement of Teaching selected Occidental as a "community engagement institution". The college was named to the 2014 President's Higher Education Community Service Honor Roll "with distinction".
History.
Early history.
Occidental College was founded on April 20, 1887, by a group of Presbyterian clergy, missionaries, and laymen, including James George Bell, Lyman Stewart, and Thomas Bard. The cornerstone of the school's first building was laid in September 1887 in the Boyle Heights neighborhood of Los Angeles. The college's first term began a year later with 27 men and 13 women students, and tuition of $50 a year.
In 1896, the Boyle Heights building was destroyed by fire. The college temporarily relocated to the old St. Vincent's College campus on Hill Street before a new site was selected in Highland Park in 1898. Eventually, the college erected three main buildings: the Academy Building, the Stimson Library, and the Hall of Arts and Letters (converted to apartments, the hall still stands today). The Highland Park site was also bisected by the tracks of the Santa Fe Railroad, and was the site of two presidential visits, first by William Howard Taft in 1909 and subsequently by President Theodore Roosevelt in 1911.
In 1909, the Pomona College Board of Trustees suggested a merger between Pomona and Occidental, but the proposal came to nothing. The following year, the college severed formal ties with the Presbyterian Church and became a non-sectarian, non-denominational institution. The small size of the 15-acre campus and the disruption caused by frequent freight trains pushed the college's trustees to find a new location.
1900s.
In 1912, the school began construction of a new campus located in Los Angeles' Eagle Rock neighborhood. The Eagle Rock campus was designed by noted California architect Myron Hunt, also known as the planner of the Caltech campus and as designer of the Huntington Library and Art Gallery and the Rose Bowl. That same year, Occidental President John Willis Baer announced the trustees' decision to convert Occidental College into an all-men's institution. However, students and faculty protested, and the idea was abandoned.
Two weeks after Booker T. Washington came to visit Occidental, on March 27, 1914, Swan, Fowler, and Johnson Halls were dedicated at its new Eagle Rock campus. Patterson Field, today one of the oldest collegiate sports stadiums in Los Angeles, was opened in 1916. In April 1917, shortly after the United States entered World War I, the college formed a Students Army Training Corps to aid the war effort.
Under Occidental President Remsen Bird, the school opened a series of new Hunt-designed buildings, including Clapp Library (1924), Hillside Theatre and a women's dormitory (Orr Hall) in 1925, Alumni Gymnasium (1926), the Freeman Student Union (1928) and a music and speech building (1929). The Delta of California Chapter of Phi Beta Kappa was established at Occidental in 1926, at a time when the only other chapters in California were at Stanford, UC Berkeley, and Pomona.
During World War II, many students left Occidental to fight in the war. In July 1943, the U.S. Navy established a Navy V-12 officer training program on campus that produced hundreds of graduates before it was disbanded at the end of the war in 1945. Occidental President Remsen Bird worked behind the scenes to help Oxy students of Japanese descent continue their education despite mandatory evacuation orders; his letters are included in the Japanese American Relocation Collection in Clapp Library.
After having its first Rhodes Scholar, Clarence Spaulding, named in 1908, Oxy seniors John Paden and Aaron Segal were awarded Rhodes Scholarships in 1958; the first and only time Occidental has produced two Rhodes Scholars in a single year. Rhodes scholars Aaron Segal and John Paden were among the 10 Occidental students who participated in Crossroads Africa that year, a forerunner to the Peace Corps that later became a national program.
In 1969, 42 students were suspended for peacefully protesting military recruiting on campus. One year later, faculty voted to suspend classes in the wake of the Kent State shootings and America's invasion of Cambodia. Subsequently, Oxy students wrote 7,000 letters to Washington D.C., protesting U.S. involvement in the war in Southeast Asia. Occidental launched one of the country's first Upward Bound programs in 1966, aimed at increasing the number of low-income, underrepresented high school students who become the first in their family to go to college.
Also in 1969, the school opened its first two co-ed dormitories, and two more followed a year later. In 1988, John Brooks Slaughter became Occidental's first black president. Building on faculty and student advocacy and a series of grants the college had received previously to increase the diversity of the Occidental student body, Slaughter led the process of creating a new mission statement that is still used today. Also, Slaughter led the college's community outreach expansion with the creation of the Center for Volunteerism and Community Service, the predecessor for the current Center for Community Based Learning. 
2000s.
In July 2006, Susan Prager became Occidental's first female president. She left her position in 2007 during the fall term. Robert Skotheim the former president of Whitman College and the Huntington Library, then served as interim president. In July 2009, Jonathan Veitch, formerly dean of The New School's Eugene Lang College, became Occidental's 15th president and the first to be a native Angeleno.
Campus.
Architect Myron Hunt created the original campus master plan for Occidental's Eagle Rock campus in 1911. He structured the campus in a Mediterranean style, with covered walkways and tile roofs. The campus landscape was designed and developed by Beatrix Farrand in the late 1930s. All of the 19 buildings designed by Hunt remain in use today, including Johnson Hall, now the home for the McKinnon Center for Global Affairs. 
Built on a hillside, the Eagle Rock campus covers over 120 acre, of which is undeveloped land that includes a local landmark known as Fiji Hill. There are 12 on-campus residence halls and the main dining facility is The Marketplace, which is located in the Johnson Student Center. Some buildings, such as the Hameetman Science Center (designed by Anshen + Allen, 2003), deviates from the original architecture with its large glass windows and metal balconies (its lobby houses a large Foucault pendulum). In 1979, Occidental installed "Water Forms II" (see image below), a kinetic fountain designed by professor George Baker. The fountain is a campus landmark and was featured prominently in the 1984 film "".
Occidental College was ranked as the sixth "Most Beautiful" campus by "Newsweek" in 2012. The school is home to a 1-megawatt ground-mounted solar array on an American college campus, as well as the largest in Los Angeles. The 4,886-panel installation was completed in Spring 2013 and inaugurated on the school's 126 year anniversary.
Academics.
There are 31 majors offered on campus and there is a 10:1 student-faculty ratio. The average class size is 19 students and most students take four classes per semester.
Since 1908, Occidental has graduated 10 Rhodes Scholars. The 2015 edition of The Fiske Guide to Colleges gave Occidental four-star ratings (out of five) in academics and quality of life. In "Forbes" 2014 rankings of America's Top Colleges, Occidental ranks 44th. In "U.S. News and World Report"'s 2014 rankings of American liberal arts colleges, Occidental is ranked 44th. Kiplinger’s Best College Values 2015 rankings places Occidental 55th among liberal arts colleges.
Core program.
Divided in three parts, the Core Program was designed by the faculty of Occidental to unify and enhance the liberal arts education offered by the school. The Core Program requires students to achieve the following:
First-year seminars (eight course hours in total) are the centerpiece of the Core Program. Students are given a variety of class choices to fulfill the seminar requirement and to satisfy the first-year writing requirement. While the classes range in topic, each is based on a curriculum of cultural studies. The classes are designed to expose students to the rigor of college academics and to the four principles of the college mission—Excellence, Equity, Community, and Service.
The Core Program's emphasis on global literacy requires students to take a minimum of three courses that touch on at least three of the following geographical areas: Africa and the Middle East; Asia and the Pacific; Europe; Latin America; the United States; and Intercultural. Students are also required to demonstrate proficiency in writing and in a foreign language and take courses in the fine arts and in the sciences, mathematics, or other courses that address formal methods of reasoning.
The final portion of the Core Program requires students to pass a senior comprehensive examination in their chosen field. Comprehensive examinations may include seminars, creative projects, fieldwork, oral exams, theses, or field research projects.
Exchange and cooperative joint degree programs.
California Institute of Technology (Caltech) and Columbia University.
Students at Occidental can take courses at the California Institute of Technology in nearby Pasadena free of charge. In addition, a 3-2 engineering program allows qualified students the opportunity to study at Occidental for three years, completing their undergraduate experience with an additional two years either at Caltech or Columbia University. At the end of the five years, the student receives two degrees, a Bachelor of Arts in the Combined Plan from Occidental and a Bachelor of Science in the selected field of engineering from the engineering school.
Art Center College of Design.
Art majors at Occidental College can take courses at the Art Center College of Design in Pasadena, one of the country's top-ranked art schools. The program is not open to first-year students, but as with the Caltech exchange program, students receive full course credit. No additional tuition payments are required.
Columbia University School of Law.
With a competitive GPA and LSAT scores, Columbia Law School admits students upon completion of their junior year at Occidental into its Accelerated Interdisciplinary Program in Legal Education. Admittance to the program enables students to earn a bachelor's degree from Occidental and a law degree from Columbia in six years.
Keck Graduate Institute.
Students who are interested in biotechnology and who become a biochemistry major maintaining a 3.2 GPA in the necessary courses will be guaranteed admission to the Keck master's in bioscience program. The Keck Graduate Institute is part of the Claremont Colleges consortium.
Student life.
At the beginning of every school year, freshmen participate in Convocation, a formal ceremony welcoming new students to the college in which the faculty wear their full academic regalia and students don robes. Founders Day is celebrated annually at the school on April 20, the day in 1887 when Occidental's incorporation papers were officially signed by the California Secretary of State.
For the first three years at Occidental, all students are required to live on campus and for seniors it is optional. Freshmen do not get to choose where they live; the Office of Residential Education & Housing Services arranges housing by pairing students based on a short form students fill in the summer before they arrive on campus. The Occidental College dorm life consists of 13 co-ed residential housing facilities. 
After a student's first year, he or she can choose to live in a number of dorms that house sophomores, juniors, and seniors; one-third of all these halls are reserved for each grade. These dorms include Bell-Young Hall, Wylie Hall, Erdman Hall, Haines Hall, Rangeview Hall and Stearns Hall. 
There are also themed-living communities which consist of the Multicultural Hall in Pauley (open to all years), all-women housing (Berkus House, named after alumnus Dave Berkus), the E. Norris Hall, the Pet House (where currently students get to live with a dog), and the Food Justice house.
Student activities.
Occidental College has various student-run clubs, organizations and ventures such as the Green Bean Coffee Lounge, organic garden, or the student-managed bike-sharing and repairing program. There are also traditional groups such as glee club, Greek organizations and student media outlets. 
Media.
The campus newspaper is the Occidental Weekly, an independent, student-run publication. It has been published continuously since 1893.
KOXY is a student-run campus radio station, in operation in the 1960s and 1970s, and again since 2000. It originally operated on the frequency 104.7 in and around campus from 1968 to 2009, but switched to only being available by webstream in 2009. KOXY sponsors several on-campus events.
In 2010, Occidental College launched a TV station called CatAList, launched by then-students Daniel Watson and Raffy Cortina; Cortina was also the first Occidental student to be awarded with a Student Academy Award from the Academy of Motion Picture Arts and Sciences for his short "Bottled Up". The station produces 20–30 minutes of student-run content weekly on a variety of topics.
Greek life.
Occidental College's Greek Council consists of 8 members: local sororities Alpha Lambda Phi Alpha, Delta Omicron Tau; national sororities Sigma Lambda Gamma and Kappa Alpha Theta; local fraternity Zeta Tau Zeta (co-ed), and national fraternities Kappa Alpha Psi, Phi Kappa Psi, Sigma Alpha Epsilon.
Local involvement.
There are various entities at Occidental College that promote local community involvement opportunities in Eagle Rock, Highland Park and Los Angeles. These include the Urban and Environmental Policy Institute (UEPI), the Office of Community Engagement (OCE), the Center for Community Based Learning (CCBL), the Neighborhood Partnership Program (NPP), and Upward Bound.
Athletics.
Occidental is one of the five schools that founded the Southern California Intercollegiate Athletic Conference (SCIAC) in 1915 and is currently a member of the SCIAC and NCAA Division III. Occidental features 21 varsity sports teams and a program of club sports and intramural competition. Approximately 25 percent of the student body participates in a varsity sports program.
During the 2006–2007 athletic season, the Tigers cross country, American football and basketball teams were Southern California Intercollegiate Athletic Conference champions. The school's Blackshirts Rugby union team was also league champion for the first time in five years. In 2011, Jeremy Castro ('99) and Patrick Guthrie ('86) steered the squad to a NSCRO final falling to Longwood University 36-27 in Virginia Beach, VA. In addition the college boasts a competitive and growing elite dance team that also performs at every home football and basketball game.
In 1982, the Occidental College football team had the rare opportunity for national prominence when, due to the NFL football strike, their game with San Diego was broadcast on national television.
In 2011, Occidental College lost a Basketball game to Caltech with a score of 46 to 45 giving the Caltech Beavers their first conference win in 26 years and putting an end to their 310-game losing streak.
Famous Occidental College Tigers include NFL coach Jim E. Mora, former American Football League Most Valuable Player Jack Kemp, former NFL player Vance Mueller, 2011 U.S. Senior Open Champion Olin Browne, CFL player Justin Goltz (Winnipeg Blue Bombers), and professional golfer Andrew Larkin.
Controversy.
In 1913, the Occidental College Board of Trustees announced plans to convert the college exclusively to a men's school. The plans were met with widespread backlash from students and faculty who protested the change. The community outcry garnered national headlines and the board later dropped the proposal.
English novelist Aldous Huxley, who spoke Occidental's convocation ceremony in the then-new Thorne Hall in 1938, lampooned President Remsen Bird as Dr. Herbert Mulge of Tarzana College in his 1939 novel, "After Many a Summer Dies the Swan". Huxley was never again invited back to campus.
In November 1990, the college, initially established as a Presbyterian institution, rededicated the campus' main chapel as the Herrick Memorial Chapel and Interfaith Center. The school also took down the crosses in the chapel in an attempt to "broaden Occidental's appeal among non-Christian students."
President Barack Obama attended Occidental for two years prior to transferring to Columbia University. Several "birther" conspiracies surfaced after he was elected as the 44th president of the U.S., some of which stemmed from a fictitious report produced in 2009 claiming his Occidental College transcripts revealed that Obama received financial aid as a foreign student from Indonesia. In 2012, Donald Trump offered the President $5 million to donate to the charity of his choice if he would provide his college transcripts and passport application.
A Federal civil rights complaint was filed in April 2013 by 37 students stating that the school "deliberately discouraged victims from reporting sexual assaults” as well as misled some students about their rights during campus investigations and possibly retaliated against whistle-blowers. This complaint is currently under active investigation by the Federal Department of Education's Office of Civil Rights. On September 18, 2013, the college settled a lawsuit brought by 10 students also alleging improper treatment of their sexual assault cases, on undisclosed terms. On May 1, 2014, Occidental was named one of fifty-five higher education institutions under investigation by the Office of Civil Rights “for possible violations of federal law over the handling of sexual violence and harassment complaints” by President Obama's White House Task Force To Protect Students from Sexual Assault. In response to student and faculty outcry the college has taken various actions to combat sexual assault such as adopting a new interim sexual misconduct policy, hiring a former assistant district attorney, Ruth Jones, as a full-time, independent Title IX coordinator, and the school added a new 24-hour, 7-days-a-week telephone hotline. The school also created a permanent Sexual Misconduct Advisory Board made up of students, faculty and staff. 
Notable alumni and faculty.
Notable graduates of Occidental College include filmmaker Terry Gilliam, football player and politician Jack Kemp, former New Orleans Saints and Indianapolis Colts head coach Jim E. Mora, and Warner Music Group CEO Stephen Cooper. Notable attendees include current US President Barack Obama, Academy Award-winning actor and filmmaker Ben Affleck, actor Luke Wilson, producer Todd Garner and actress Emily Osment.
Film and television at Occidental.
Occidental's campus, architecture, and proximity to Hollywood have made it a desired location for a number of film and television productions.
Film credits include:
TV credits include:

</doc>
<doc id="22801" url="http://en.wikipedia.org/wiki?curid=22801" title="1986 United States bombing of Libya">
1986 United States bombing of Libya

The 1986 United States bombing of Libya, code-named Operation El Dorado Canyon, comprised air strikes by the United States against Libya on Tuesday, 15 April 1986. The attack was carried out by the U.S. Air Force, U.S. Navy and U.S. Marine Corps via air strikes, in response to the 1986 Berlin discotheque bombing. There were 40 reported Libyan casualties, and one US plane was shot down, resulting in the death of two airmen.
Origins.
Libya represented a high priority for President Ronald Reagan shortly after his 1981 inauguration. Libyan leader Muammar Gaddafi was firmly anti-Israel and had supported violent organizations in the Palestinian territories and Syria. There were reports that Libya was attempting to become a nuclear power and Gaddafi's occupation of Chad, which was rich in uranium, was of major concern to the United States. Gaddafi's alignment with the Soviet Union and his ambitions to set up a federation of Arab and Muslim states in North Africa were also alarming to US interests. Furthermore, then-Secretary of State Alexander Haig wanted to take pro-active measures against Gaddafi because he had been using former Central Intelligence Agency (CIA) operatives to help set up terrorist camps (most notably Edwin P. Wilson and Frank E. Terpil).
After the December 1985 Rome and Vienna airport attacks, which killed 19 and wounded approximately 140, Gaddafi indicated that he would continue to support the Red Army Faction, the Red Brigades, and the Irish Republican Army as long as the European governments supported anti-Gaddafi Libyans.
The Foreign Minister of Libya also called the massacres "heroic acts".
After years of occasional skirmishes with Libya over Libyan territorial claims to the Gulf of Sidra, the United States contemplated a military attack to strike targets within the Libyan mainland. In March 1986, the United States, asserting the 12 nmi limit to territorial waters according to international law, sent a carrier task force to the region. Libya responded with aggressive counter-maneuvers on 24 March that led to the Gulf of Sidra incident.
On 5 April 1986, Libyan agents bombed "La Belle" nightclub in West Berlin, killing three people, one being a U.S. Serviceman, and injuring 229 people who were spending the evening there. West Germany and the United States obtained cable transcripts from Libyan agents in East Germany who were involved in the attack.
More detailed information was retrieved years later when Stasi archives were investigated by the reunited Germany. Libyan agents who had carried out the operation from the Libyan embassy in East Germany were identified and prosecuted by Germany in the 1990s.
After several unproductive days of meeting with European and Arab nations, and under the influence of an American serviceman's death, Ronald Reagan, on the 14th of April, ordered a lighting air raid on Libya. Eighteen F-111F strike aircraft of the 48th Tactical Fighter Wing, flying from RAF Lakenheath and supported by four EF-111A Ravens of the 20th Tactical Fighter Wing from RAF Upper Heyford in England, in conjunction with fifteen A-6, A-7, F/A-18 attack aircraft and EA-6B Prowler Electronic Warfare Aircraft from the aircraft carriers USS "Saratoga", USS "America" and USS "Coral Sea" on station in the Gulf of Sidra, struck five targets at 02:00 on 15 April, with the stated objective that their destruction would send a message and reduce Libya's ability to support and train terrorists. Reagan warned that "if necessary, [they] shall do it again."
The actual attack mission against Libya had been preceded in October 1985 by an exercise in which the 20th TFW stationed at RAF Upper Heyford airbase in the UK, which was equipped with F-111Es, received a top secret order to launch a simulated attack mission on 18 October, with ten F-111Es armed with eight 500 lb practice bombs, against a simulated airfield located in Newfoundland, Canada south of CFB Goose Bay. The mission was designated Operation Ghost Rider. The mission was a full rehearsal for a long range strike against Libya. The mission was completed successfully, with the exception of one aircraft that had all but one of its eight bombs hang up on one of its wing racks. The lessons learned were passed on to the 48th TFW which was equipped with the newer "F" models of the F-111.
Elements of the then-secret 4450th Tactical Group (USAF) were put on standby to fly the strike mission against Libya. Over 30 F-117s had already been delivered to Tactical Air Command (USAF) and were operating from secret bases in Nevada. Commanders in the North Africa/Mediterranean theaters knew nothing about the capabilities of the F-117, or that the aircraft even existed. Within an hour of the planned launch of the F-117s, the Secretary of Defense scrubbed the stealth mission, fearing a compromise of the secret aircraft and its development program. The air strike was carried out with conventional US Navy and US Air Force aircraft. The F-117 would remain completely unknown to the world for several more months, before being unveiled in 1988 and prominently featured in media coverage of Operation Desert Storm.
For the Libyan raid, the United States was denied overflight rights by France, Spain, and Italy as well as the use of European continental bases, forcing the Air Force portion of the operation to be flown around France and Spain, over Portugal and through the Straits of Gibraltar, adding 1,300 miles (2,100 km) each way and requiring multiple aerial refuelings. The French refusal alone added 2,800 km and was imposed despite the fact that France had itself been the target of terrorism directed by the Gaddafi government in Libya. French president Mitterrand refused overflight clearance because the United States refused to give to the French military all the details about the operation and he did not want to authorize any foreign operation that could not be analyzed by French authorities.
The raid.
The attack began at 0200 hours (Libyan time), and lasted about twelve minutes, with 60 tons of munitions dropped. Eighteen F-111 bombers supported by four EF-111 electronic countermeasures aircraft flying from the United Kingdom bombed Tripoli airfield, a frogman training center at a naval academy, and the Bab al-Azizia barracks in Tripoli. During the bombing of the Bab al-Azizia barracks, an American F-111 was shot down by a Libyan surface-to-air missile (SAM) over the Gulf of Sidra. Some bombs landed off-target, striking diplomatic and civilian sites in Tripoli, and narrowly missing the French embassy. Some Libyan soldiers abandoned their positions in fright and confusion, and officers were slow to give orders. Libyan anti-aircraft fire did not begin until after the planes had passed over their targets. Twenty-four A-6 Intruders and F/A-18 Hornets launched from aircraft carriers bombed radar and antiaircraft sites in Benghazi before bombing the Benina and Jamahiriya barracks.
Libyan air defenses.
The Libyan air defense network was extensive, and included:
Covering Tripoli alone were:
Casualties.
Libyan.
Forewarned by a telephone call, Libyan leader Muammar Gaddafi and his family rushed out of their residence in the Bab al-Azizia compound moments before the bombs dropped. It was long thought that the call came from Malta's Prime Minister, Karmenu Mifsud Bonnici. However, Italian politician Bettino Craxi was the person who actually warned Gaddafi, according to Giulio Andreotti, Italy's foreign minister at the time, and to Abdel Rahman Shalgham, Libya's then-ambassador to Italy. Shalgham's statement was also confirmed by Margherita Boniver, foreign affairs chief of Craxi's Socialist Party at the time.
According to medical staff in a nearby hospital, two dozen casualties were brought in wearing military uniforms, and two without uniforms. Total Libyan casualties were estimated at 60, including those at the bombed airbases. An infant girl was among the casualties; her body was shown to American reporters, who were told she was Gaddafi's recently adopted daughter Hanna. However, there was and remains much skepticism over the claim.
American.
Two U.S. Air Force captains — Fernando L. Ribas-Dominicci and Paul F. Lorence — were killed when their F-111 fighter-bomber was shot down over the Gulf of Sidra.
According to newspaper reports at the time, the U.S. fighter-bomber lost in the incursion crashed due to "pilot disorientation" or "systems failure". Initially the U.S. military refused to admit the fighter-bomber had been shot down, with Defense Secretary Caspar Weinberger suggesting that it could have experienced radio trouble or been diverted to another airfield. On 25 December 1988, Gaddafi offered to release the body of Lorence to his family through Pope John Paul II. The body, returned in 1989, was identified as Ribas-Dominicci's from dental records. An autopsy conducted in Spain confirmed that he had drowned after his plane was shot down over the Gulf of Sidra. Libya denies that it held Lorence's body. However, Lorence's brother said that he and his mother saw television footage of a Libyan holding a white helmet with the name "Lorence" stenciled on the back. Furthermore, William C. Chasey, who toured the Bab al-Azizia barracks, claimed to have seen two flight suits and helmets engraved with the names "Lorence" and "Ribas-Dominicci", as well as the wreckage of their F-111.
In 2001, Theodore D. Karantsalis, a reference librarian at Miami-Dade College, enlisted the aid of Congressman Wally Herger's office to petition Libya to return Lorence's remains on behalf of his family and friends. Karantsalis also created a website and invited visitors to sign a petition to Congressman Lincoln Diaz-Balart seeking the return of Capt. Lorence's remains. On 27 January 2005, Karantsalis filed a federal lawsuit under the Freedom of Information Act (FOIA) against the Department of Defense and the Department of the Air Force seeking "to know where Captain Paul Lorence's remains are located." Karantsalis had hoped to locate the remains before the 20th anniversary of Lorence's death.
Aftermath.
In Libya.
Gaddafi's announcements.
Gaddafi announced that he had "won a spectacular military victory over the United States" and the country was officially renamed the "Great Socialist People's Libyan Arab Jamahiriyah".
Gaddafi said reconciliation between Libya and the United States was impossible so long as Reagan was in the White House; of the president he said, "He is mad. He is foolish. He is an Israeli dog." He said he had no plans to attack the United States or U.S. targets. He claimed that Reagan wanted to kill him, stating "Was Reagan trying to kill me? Of course. The attack was concentrated on my house and I was in my house", he also described how he rescued his family.
When asked that if he is in danger of losing power, he told "Really, these reports and writings are not true. As you can see I am fine, and there has been no change in our country."
Other events.
The Government of Libya said that the United States had fallen prey to arrogance and madness of power and wanted to become the world's policeman. It charged that any party that did not agree to become an American vassal was an outlaw, a terrorist, and a devil.
Gaddafi quashed an internal revolt, the organization of which he blamed on the United States, although Gaddafi appeared to have left the public sphere for a time in 1986 and 1987.
The Libyan Post dedicated several postage stamps issues to the event, from 1986 until 2001. The first issue was released in 1986, 13 July (ref. Scott catalogue n.1311 – Michel catalogue n.1699). The last issue was released in 2001, 15 April (ref. Scott catalogue n.1653 – Michel catalogue n.2748–2763).
Libyan retaliation.
Immediate.
Libya responded by firing two Scud missiles at a United States Coast Guard station on the Italian island of Lampedusa which passed over the island and landed in the sea.
Later Libyan-connected terrorism.
There was only limited change in Libyan-connected terrorism.
The Libyan government was alleged to have ordered the hijacking of Pan Am Flight 73 in Pakistan on 5 September 1986, which resulted in the deaths of 20 people. The allegation did not come to light until it was reported by "The Sunday Times" in March 2004—days after British Prime Minister Tony Blair paid the first official visit to Tripoli by a Western leader in a generation.
In May 1987, Australia deported diplomats and broke off relations with Libya, claiming Libya sought to fuel violence in Australia and Oceania.
In late 1987 French authorities stopped a merchant vessel, the MV "Eksund", which was delivering 150 tons of Soviet arms from Libya to the Irish Republican Army (IRA) 
In Beirut, Lebanon, two British hostages held by the Libyan-supported Abu Nidal Organization, Leigh Douglas and Philip Padfield, along with an American named Peter Kilburn, were shot dead in revenge. In addition, journalist John McCarthy was kidnapped, and tourist Paul Appleby was murdered in Jerusalem, Israel. Another British hostage named Alec Collett was also killed in retaliation for the bombing of Libya. Collett was shown being hanged in a video tape. His body was found in November 2009.
On 21 December 1988, came the bombing of Pan Am Flight 103, which exploded in mid-air and crashed on the town of Lockerbie in Scotland after a bomb detonated, killing all 259 people aboard, and 11 people in Lockerbie. Iran was initially thought to have been responsible for the bombing in revenge for the downing of the Iranian Airbus by the USS "Vincennes", but in 1991 two Libyans were charged, one of whom was convicted of the crime in a controversial judgement on 31 January 2001. The Libyan Government accepted responsibility for the Pan Am Flight 103 bombing on 29 May 2002, and offered $2.7 billion to compensate the families of the 270 victims. The convicted Libyan, Abdelbaset al-Megrahi, who was suffering from terminal prostate cancer, was released in August 2009 by the Scottish Government on compassionate grounds. He died in 2012. In May 2014 a group of relatives of the Lockerbie victims continued to campaign for al-Megrahi's name to be cleared by reopening the case.
International response.
Immediate.
The attack was condemned by many countries. By a vote of 79 in favor to 28 against with 33 abstentions, the United Nations General Assembly adopted resolution 41/38 which "condemns the military attack perpetrated against the Socialist People's Libyan Arab Jamahiriya on 15 April 1986, which constitutes a violation of the Charter of the United Nations and of international law."
A meeting of the Non-Aligned Movement said that it condemned the "dastardly, blatant and unprovoked act of aggression". The League of Arab States expressed that it was outraged at the United States aggression and that it reinforced an element of anarchy in international relations. The Assembly of Heads of State of the African Union in its declaration said that the deliberate attempt to kill Libyans violated the principles of international law. The Government of Iran asserted that the attack constituted a policy of aggression, gunboat diplomacy, an act of war, and called for an extensive political and economic boycott of the United States. Others saw the United States motive as an attempt to eliminate Libya's revolution.
China stated that the US attack violated norms of international relations and had aggravated tension in the region. The Soviet Union said that there was a clear link between the attack and U.S. policy aimed at stirring up existing hotbeds of tension and creating new ones, and at destabilizing the international situation. West Germany stated that international disputes required diplomatic and not military solutions, and France also criticized the bombing. Italy, Spain, and France all denied the US use of their airspace en route to Libya. This forced the USAF's F-111s, stationed at RAF Lakenheath in Great Britain, to circumnavigate continental Europe and approach Libya via the Strait of Gibraltar.
Some observers held the opinion that Article 51 of the UN Charter set limitations on the use of force in exercising the legitimate right of self-defense in the absence of an act of aggression, and affirmed that there was no such act by Libya. It was charged that the United States did not bother to exhaust the Charter provisions for settling disputes under Article 33. Others asserted that Libya was innocent in the bombing of the West Berlin discotheque.
The U.S. received support from the United Kingdom, Canada, Australia, Israel, and 25 other countries. Its doctrine of declaring a war on what it called "terrorist havens" was not repeated until 1998, when President Bill Clinton ordered strikes on six terrorist camps in Afghanistan. Margaret Thatcher's approval of the use of Royal Air Force bases led to substantial criticism, including an unprecedented story in "The Sunday Times" suggesting the Queen was upset by an "uncaring" Prime Minister. Widespread criticism of the raid caused a temporary rift in UK-US relations and American tourists stayed away from Britain during the spring. Gaddafi himself responded by saying "Thatcher is a murderer...Thatcher is a prostitute. She sold herself to Reagan."
Although the Soviet Union was ostensibly in cooperation with Libya, it had, by the time of the Libya bombing, made its increasing ambivalence toward Libya apparent in public communications. Gaddafi had a history of verbally attacking the policy agendas and ideology of the Soviet Union, and he often engaged in various international interventions and meddling that conflicted with Soviet goals in a variety of spheres. During a period where the Soviet Union was apparently attempting to lead a subtle diplomatic effort that could impact its global status, close association with the whims of Gaddafi became a liability.
In the entire crisis, the Soviet Union explicitly announced that it would not provide additional help to Libya beyond resupplying basic armaments and munitions. It made no attempt to militarily intimidate the United States, despite the ongoing American operations in the Gulf of Sidra and its previous knowledge that the United States might launch an attack. The Soviet Union did not completely ignore the event, issuing a denunciation of this 'wild' and 'barbaric' act by the United States.
After the raid, Moscow did cancel a planned visit to the United States by foreign affairs minister Eduard Shevardnadze. At the same time, it clearly signaled that it did not want this action to affect negotiations about the upcoming summer summit between the United States and the Soviet Union and its plans for new arms control agreements.
Former U.S. Attorney General Ramsey Clark, acting for Libyan citizens who had been killed or injured in the bombing raid by the U.S. using British air bases, brought suit under international law against the United States and the United Kingdom in U.S. federal court. The lawsuit was dismissed as frivolous. A subsequent appeal was denied, and monetary sanctions against Clark were allowed. Saltany v. Reagan, 886 F. 2d 438 (D.C. Cir. 1989).
US bombing of Ferdinandea.
In 1986, US warplanes mistook the undersea shoal of Ferdinandea, near Sicily, for a Libyan submarine and dropped depth charges on it.
UN response.
Every year, between at least 1994 and 2006, the United Nations General Assembly scheduled a declaration from the Organization of African Unity about the incident, but systematically deferred the discussion year after year until formally putting it aside (along with several other issues which had been similarly rescheduled for years) in 2005.
First anniversary.
On the first anniversary of the bombing, April 1987, European and North American left-wing activists gathered to commemorate the anniversary. After a day of social and cultural networking with local Libyans, including a tour of Gaddafi's bombed house, the group gathered with other Libyans for a commemoration event.
20th anniversary.
Early on 15 April 2006 – to mark the 20th anniversary of the bombing raid – a concert involving U.S. singer Lionel Richie and Spanish tenor José Carreras was held in front of Gaddafi's bombed house in Tripoli. Diplomats, businessmen and politicians were among the audience of what Libya dubbed the "concert for peace". The BBC reported Lionel Richie as telling the audience, regarding Gaddafi's supposed adopted daughter, "Hanna will be honored tonight because of the fact that you've attached peace to her name."
2009 comment.
In June 2009, during a visit to Italy, Colonel Gaddafi criticized American foreign policy and, asked as to the difference between al-Qaeda attacks and the 1986 US bombing of Tripoli, he commented: "If al-Qaeda leader Osama Bin Laden has no state and is an outlaw, America is a state with international rules."
Settlement of claims.
On 28 May 2008, the United States began negotiations with Libya on a comprehensive claims settlement agreement to resolve outstanding claims of American and Libyan nationals against each country in their respective courts. Gaddafi's son Saif al-Islam publicly announced that an agreement was being negotiated in July of that year. On 14 August 2008, the resulting U.S.-Libya Comprehensive Claims Settlement Agreement was signed in Tripoli by Assistant Secretary of State for Near Eastern Affairs David Welch and by Libyan Secretary for American Affairs Ahmad Fituri.
In October 2008, Libya paid US$1.5 billion (in three installments of $300 million on 9 October 2008, $600 million on 30 October 2008, and US$600 million 31 October 2008) into a fund used to compensate the following victims and their relatives:
To pay the settlement, Libya demanded US$1.5 billion from global oil companies operating in Libya's oil fields, under threat of "serious consequences" to their leases. Libya's settlement was at least partially funded by several companies, including some based in the U.S., that chose to cooperate with Libya's demand.
On 4 August 2008, President George W. Bush signed into law the Libyan Claims Resolution Act, which had unanimously passed Congress on 31 July. The Act provided for the restoration of Libya’s sovereign, diplomatic, and official immunities before U.S. courts if the Secretary of State certified that the United States Government has received sufficient funds to resolve outstanding terrorism-related death and physical injury claims against Libya.
On 14 August 2008, the United States and Libya signed a comprehensive claims settlement agreement. Full diplomatic relations were restored between the two nations.

</doc>
<doc id="22804" url="http://en.wikipedia.org/wiki?curid=22804" title="Operational amplifier">
Operational amplifier

An operational amplifier ("op-amp") is a DC-coupled high-gain electronic voltage amplifier with a differential input and, usually, a single-ended output. In this configuration, an op-amp produces an output potential (relative to circuit ground) that is typically hundreds of thousands of times larger than the potential difference between its input terminals.
Operational amplifiers had their origins in analog computers, where they were used to do mathematical operations in many linear, non-linear and frequency-dependent circuits. 
The popularity of the op-amp as a building block in analog circuits is due to its versatility. Due to negative feedback, the characteristics of an op-amp circuit, its gain, input and output impedance, bandwidth etc. are determined by external components and have little dependence on temperature coefficients or manufacturing variations in the op-amp itself.
Op-amps are among the most widely used electronic devices today, being used in a vast array of consumer, industrial, and scientific devices. Many standard IC op-amps cost only a few cents in moderate production volume; however some integrated or hybrid operational amplifiers with special performance specifications may cost over $100 US in small quantities. Op-amps may be packaged as components, or used as elements of more complex integrated circuits.
The op-amp is one type of differential amplifier. Other types of differential amplifier include the fully differential amplifier (similar to the op-amp, but with two outputs), the instrumentation amplifier (usually built from three op-amps), the isolation amplifier (similar to the instrumentation amplifier, but with tolerance to common-mode voltages that would destroy an ordinary op-amp), and negative feedback amplifier (usually built from one or more op-amps and a resistive feedback network).
Operation.
The amplifier's differential inputs consist of a non-inverting input (+) with voltage "V"+ and an inverting input (–) with voltage "V"−; ideally the op-amp amplifies only the difference in voltage between the two, which is called the "differential input voltage". The output voltage of the op-amp "V"out is given by the equation:
where "A"OL is the open-loop gain of the amplifier (the term "open-loop" refers to the absence of a feedback loop from the output to the input).
Open loop amplifier.
The magnitude of "A"OL is typically very large—100,000 or more for integrated circuit op-amps—and therefore even a quite small difference between "V"+ and "V"− drives the amplifier output nearly to the supply voltage. Situations in which the output voltage is equal to or greater than the supply voltage are referred to as "saturation" of the amplifier. The magnitude of "A"OL is not well controlled by the manufacturing process, and so it is impractical to use an operational amplifier as a stand-alone differential amplifier.
Without negative feedback, and perhaps with positive feedback for regeneration, an op-amp acts as a comparator. If the inverting input is held at ground (0 V) directly or by a resistor Rg, and the input voltage Vin applied to the non-inverting input is positive, the output will be maximum positive; if Vin is negative, the output will be maximum negative. Since there is no feedback from the output to either input, this is an "open loop" circuit acting as a comparator.
Closed loop.
If predictable operation is desired, negative feedback is used, by applying a portion of the output voltage to the inverting input. The "closed loop" feedback greatly reduces the gain of the circuit. When negative feedback is used, the circuit's overall gain and response becomes determined mostly by the feedback network, rather than by the op-amp characteristics. If the feedback network is made of components with values small relative to the op amp's input impedance, the value of the op-amp's open loop response "A"OL does not seriously affect the circuit's performance. The response of the op-amp circuit with its input, output, and feedback circuits to an input is characterized mathematically by a transfer function; designing an op-amp circuit to have a desired transfer function is in the realm of electrical engineering. The transfer functions are important in most applications of op-amps, such as in analog computers. High input impedance at the input terminals and low output impedance at the output terminal(s) are particularly useful features of an op-amp.
In the non-inverting amplifier on the right, the presence of negative feedback via the voltage divider "R"f, "R"g determines the "closed-loop gain" "A"CL = "V"out / "V"in. Equilibrium will be established when "V"out is just sufficient to "reach around and pull" the inverting input to the same voltage as "V"in. The voltage gain of the entire circuit is thus 1 + "R"f/"R"g. As a simple example, if "V"in = 1 V and Rf = Rg, Vout will be 2 V, exactly the amount required to keep "V"− at 1 V. Because of the feedback provided by the "R"f, "R"g network, this is a "closed loop" circuit.
Another way to analyze this circuit proceeds by making the following (usually valid) assumptions:
The input signal "V"in appears at both (+) and (−) pins, resulting in a current "i" through "R"g equal to "V"in/"R"g. 
Since Kirchhoff's current law states that the same current must leave a node as enter it, and since the impedance into the (−) pin is near infinity, we can assume practically all of the same current "i" flows through "R"f, creating an output voltage
By combining terms, we determine the closed-loop gain "A"CL:
Op-amp characteristics.
Ideal op-amps.
An ideal op-amp is usually considered to have the following properties:
These ideals can be summarized by the two "golden rules":
The first rule only applies in the usual case where the op-amp is used in a closed-loop design (negative feedback, where there is a signal path of some sort feeding back from the output to the inverting input). These rules are commonly used as a good first approximation for analyzing or designing op-amp circuits.:177
None of these ideals can be perfectly realized. A real op-amp may be modeled with non-infinite or non-zero parameters using equivalent resistors and capacitors in the op-amp model. The designer can then include these effects into the overall performance of the final circuit. Some parameters may turn out to have negligible effect on the final design while others represent actual limitations of the final performance that must be evaluated.
Real op-amps.
Real op-amps differ from the ideal model in various aspects.
DC imperfections.
Real operational amplifiers suffer from several non-ideal effects:
AC imperfections.
The op-amp gain calculated at DC does not apply at higher frequencies. Thus, for high-speed operation, more sophisticated considerations must be used in an op-amp circuit design.
Power considerations.
Modern integrated FET or MOSFET op-amps approximate more closely the ideal op-amp than bipolar ICs when it comes to input impedance and input bias currents. Bipolars are generally better when it comes to input "voltage" offset, and often have lower noise. Generally, at room temperature, with a fairly large signal, and limited bandwidth, FET and MOSFET op-amps now offer better performance.
Internal circuitry of 741-type op-amp.
Sourced by many manufacturers, and in multiple similar products, an example of a bipolar transistor operational amplifier is the 741 integrated circuit designed by Dave Fullagar at Fairchild Semiconductor after Bob Widlar's LM301 integrated circuit design. 
In this discussion, we use the parameters of the Hybrid-pi model to characterize the small-signal, grounded emitter characteristics of a transistor. In this model, the current gain of a transistor is denoted "h"fe, more commonly called the β.
Architecture.
A small-scale integrated circuit,
the 741 op-amp shares with most op-amps an internal structure consisting of three gain stages: 
Additionally, it contains current mirror (outlined red) bias circuitry and a gain-stabilization capacitor (30 pF).
Differential amplifier.
A cascaded differential amplifier followed by a current-mirror active load, the input stage (outlined in blue) is a transconductance amplifier, turning a differential voltage signal at the bases of Q1, Q2 into a current signal into the base of Q15.
It entails two cascaded transistor pairs, satisfying conflicting requirements. 
The first stage consists of the matched NPN emitter follower pair Q1, Q2 that provide high input impedance. 
The second is the matched PNP common-base pair Q3, Q4 that eliminates the undesirable Miller effect; it drives an active load Q7 plus matched pair Q5, Q6.
That active load is implemented as a modified Wilson current mirror; its role is to convert the (differential) input current signal to a single-ended signal without the attendant 50% losses (increasing the op-amp's open-loop gain by 3 dB). 
Thus, a small-signal differential current in Q3 versus Q4 appears summed (doubled) at the base of Q15, the input of the voltage gain stage. 
Voltage amplifier.
The (class-A) voltage gain stage (outlined in magenta) consists of the two NPN transistors Q15/Q19 connected in a Darlington configuration and uses the output side of current mirror Q12/Q13 as its collector (dynamic) load to achieve its high voltage gain. The output sink transistor Q20 receives its base drive from the common collectors of Q15 and Q19; the level-shifter Q16 provides base drive for the output source transistor Q14. .
The transistor Q22 prevents this stage from delivering excessive current to Q20 and thus limits the output sink current.
Output amplifier.
The output stage (Q14, Q20, outlined in cyan) is a Class AB push-pull emitter follower amplifier. It provides an output drive with impedance of ≈50Ω, in essence, current gain. 
Transistor Q16 (outlined in green) provides the quiescent current for the output transistors, and Q17 provides output current limiting. 
Biasing circuits.
Provide appropriate quiescent current for each stage of the op-amp.
The resistor (39 kΩ) connecting the (diode-connected) Q11 and Q12, and the given supply voltage ("V""S"+−"V""S"−), determine the current in the current mirrors, (matched pairs) Q10/Q11 and Q12/Q13.
The collector current of Q11, "i"11 * 39 kΩ = "V""S"+ − "V""S"− − 2 "V"BE. For the typical "V""S" = ±20 V, the standing current in Q11/Q12 (as well as in Q13) would be ≈1 mA. 
A supply current for a typical 741 of about 2 mA agrees with the notion that these two bias currents dominate the quiescent supply current.
Transistors Q11 and Q10 form a Widlar current mirror, with quiescent current in Q10 "i"10 such that ln( "i"11 / "i"10 ) = "i"10 * 5 kΩ / 28 mV, where 5 kΩ represents the emitter resistor of Q10, and 28 mV is VT, the thermal voltage at room temperature. In this case "i"10 ≈ 20 μA.
Differential amplifier.
The biasing circuit of this stage is set by a feedback loop that forces the collector currents of Q10 and Q9 to (nearly) match. The small difference in these currents provides the drive for the common base of Q3/Q4 (note that the base drive for input transistors Q1/Q2 is the input bias current and must be sourced externally).
The summed quiescent currents of Q1/Q3 plus Q2/Q4 is mirrored from Q8 into Q9, where it is summed with the collector current in Q10, the result being applied to the bases of Q3/Q4.
The quiescent currents of Q1/Q3 (resp., Q2/Q4) "i"1 will thus be half of "i"10, of order ≈ 10 μA. 
Input bias current for the base of Q1 (resp. Q2) will amount to "i"1 / β; typically ≈50 nA, implying a current gain "h"fe ≈ 200 for Q1(Q2).
This feedback circuit tends to draw the common base node of Q3/Q4 to a voltage "V"com − 2 * "V"BE, where "V"com is the input common-mode voltage. At the same time, the magnitude of the quiescent current is relatively insensitive to the characteristics of the components Q1–Q4, such as "h"fe, that would otherwise cause temperature dependence or part-to-part variations.
Transistor Q7 drives Q5 and Q6 into conduction until their (equal) collector currents match that of Q1/Q3 and Q2/Q4. The quiescent current in Q7 is "V"BE / 50 kΩ, about 35μA, as is the quiescent current in Q15, with its matching operating point.
Thus, the quiescent currents are pairwise matched in Q1/Q2, Q3/Q4, Q5/Q6, and Q7/Q15. 
Voltage amplifier.
Quiescent currents in Q16 and Q19 are set by the current mirror Q12/Q13, which is running at ≈ 1 mA. Through some (?) mechanism, the collector current in Q19 tracks that standing current.
Output amplifier.
In the circuit involving Q16 (variously named rubber diode or "V"BE multiplier), the 4.5 kΩ resistor must be conducting about 100 μA, with the Q16 "V"BE roughly 700 mV. Then the "V"CB must be about 0.45 V and "V"CE at about 1.0 V. Because the Q16 collector is driven by a current source and the Q16 emitter drives into the Q19 collector current sink, the Q16 transistor establishes a voltage difference between Q14 base and Q20 base of ≈ 1 V, regardless of the common-mode voltage of Q14/Q20 base. The standing current in Q14/Q20 will be a factor exp(100 mV / VT ) ≈ 36 smaller than the 1 mA quiescent current in the class A portion of the op amp. This (small) standing current in the output transistors establishes the output stage in class AB operation and reduces the crossover distortion of this stage. 
Small-signal differential mode.
A small differential input voltage signal gives rise, through multiple stages of current amplification, to a much larger voltage signal on output.
Input impedance.
The input stage with Q1 and Q3 is similar to an emitter-coupled pair (long-tailed pair), with Q2 and Q4 adding some degenerating impedance. The input impedance is relatively high because of the small current through Q1-Q4.
A typical 741 op amp has an differential input impedance of about 2 MΩ. 
The common mode input impedance is even higher, as the input stage works at an essentially constant current.
Differential amplifier.
A differential voltage "V"In at the op-amp inputs (pins 3 and 2, respectively) gives rise to a small differential current in the bases of Q1 and Q2 "i"In ≈ "V"In / ( 2 "h"ie * "h"fe). 
This differential base current causes a change in the differential collector current in each leg by "i"In * "h"fe. Introducing the transconductance of Q1, "g""m" = "h"fe / "h"ie, the (small-signal) current at the base of Q15 (the input of the voltage gain stage) is "V"In * "g""m" / 2.
This portion of the op amp cleverly changes a differential signal at the op amp inputs to a single-ended signal at the base of Q15, and in a way that avoids wastefully discarding the signal in either leg. To see how, notice that a small negative change in voltage at the inverting input (Q2 base) drives it out of conduction, and this incremental decrease in current passes directly from Q4 collector to its emitter, resulting in an decrease in base drive for Q15. On the other hand, a small positive change in voltage at the non-inverting input (Q1 base) drives this transistor into conduction, reflected in an increase in current at the collector of Q3. This current drives Q7 further into conduction, which turns on current mirror Q5/Q6. Thus, the increase in Q3 emitter current is mirrored in an increase in Q6 collector current, resulting also in a decrease in base drive for Q15. Besides avoiding wasting 3 dB of gain here, this technique decreases common-mode gain and feedthrough of power supply noise. 
Voltage amplifier.
A current signal "i" at Q15's base gives rise to a current in Q19 of order "i" * β2 (the product of the "h"fe of each of Q15 and Q19, which are connected in a Darlington pair). This current signal develops a voltage at the bases of output transistors Q14/Q20 proportional to the "h"ie of the respective transistor.
Output amplifier.
Output transistors Q14 and Q20 are each configured as an emitter follower, so no voltage gain occurs there; instead, this stage provides current gain, equal to the "h"fe of Q14 (resp. Q20).
The output impedance is not zero, as it would be in an ideal op-amp, but with negative feedback it approaches zero at low frequencies.
Overall open-loop voltage gain.
The net open-loop small-signal voltage gain of the op amp involves the product of the current gain "h"fe of some 4 transistors. 
In practice, the voltage gain for a typical 741-style op amp is of order 200,000, and the current gain, the ratio of input impedance (≈2−6 MΩ) to output impedance (≈50Ω) provides yet more (power) gain.
Other linear characteristics.
Small-signal common mode gain.
The ideal op amp has infinite common-mode rejection ratio, or zero common-mode gain.
In the present circuit, if the input voltages change in the same direction, the negative feedback makes Q3/Q4 base voltage follow (with 2"V"BE below) the input voltage variations. Now the output part (Q10) of Q10-Q11 current mirror keeps up the common current through Q9/Q8 constant in spite of varying voltage. Q3/Q4 collector currents, and accordingly the output current at the base of Q15, remain unchanged.
In the typical 741 op amp, the common-mode rejection ratio is 90 dB, implying an open-loop common-mode voltage gain of about 6.
Frequency compensation.
The innovation of the Fairchild μA741 was the introduction of frequency compensation via an on-chip (monolithic) capacitor, simplifying application of the op amp by eliminating the need for external components for this function. 
The 30 pF capacitor stabilizes the amplifier via Miller compensation and functions in a manner similar to an op-amp integrator circuit. Also known as 'dominant pole compensation' because it introduces a pole that masks (dominates) the effects of other poles into the open loop frequency response; in a 741 op amp this pole can be as low as 10 Hz (where it causes a −3 dB loss of open loop voltage gain).
This internal compensation is provided to achieve unconditional stability of the amplifier in negative feedback configurations where the feedback network is non-reactive and the closed loop gain is unity or higher. 
By contrast, amplifiers requiring external compensation, such as the μA748, may require external compensation or closed-loop gains significantly higher than unity.
Input offset voltage.
The "offset null" pins may be used to place external resistors (typically in the form of the two ends of a potentiometer, with the slider connected to "V""S"–) in parallel with the emitter resistors of Q5 and Q6, to adjust the balance of the Q5/Q6 current mirror. The potentiometer is adjusted such that the output is null (midrange) when the inputs are shorted together.
Non-linear characteristics.
Input breakdown voltage.
The transistors Q3, Q4 help to increase the reverse "V"BE rating: the base-emitter junctions of the NPN transistors Q1 and Q2 break down at around 7V, but the PNP transistors Q3 and Q4 have "V"BE breakdown voltages around 50 V.
Output-stage voltage swing and current limiting.
Variations in the quiescent current with temperature, or between parts with the same type number, are common, so crossover distortion and quiescent current may be subject to significant variation.
The output range of the amplifier is about one volt less than the supply voltage, owing in part to "V"BE of the output transistors Q14 and Q20.
The 25 Ω resistor at the Q14 emitter, along with Q17, acts to limit Q14 current to about 25 mA; otherwise, Q17 conducts no current.
Current limiting for Q20 is performed in the voltage gain stage: Q22 senses the voltage across Q19's emitter resistor (50Ω); as it turns on, it diminishes the drive current to Q15 base.
Later versions of this amplifier schematic may show a somewhat different method of output current limiting.
Applicability considerations.
"Note: while the 741 was historically used in audio and other sensitive equipment, such use is now rare because of the improved noise performance of more modern op-amps. Apart from generating noticeable hiss, 741s and other older op-amps may have poor common-mode rejection ratios and so will often introduce cable-borne mains hum and other common-mode interference, such as switch 'clicks', into sensitive equipment.
The "741" has come to often mean a generic op-amp IC (such as μA741, LM301, 558, LM324, TBA221 — or a more modern replacement such as the TL071). The description of the 741 output stage is qualitatively similar for many other designs (that may have quite different input stages), except:
Classification.
Op-amps may be classified by their construction:
IC op-amps may be classified in many ways, including:
Applications.
Use in electronics system design.
The use of op-amps as circuit blocks is much easier and clearer than specifying all their individual circuit elements (transistors, resistors, etc.), whether the amplifiers used are integrated or discrete circuits. In the first approximation op-amps can be used as if they were ideal differential gain blocks; at a later stage limits can be placed on the acceptable range of parameters for each op-amp.
Circuit design follows the same lines for all electronic circuits. A specification is drawn up governing what the circuit is required to do, with allowable limits. For example, the gain may be required to be 100 times, with a tolerance of 5% but drift of less than 1% in a specified temperature range; the input impedance not less than one megohm; etc.
A basic circuit is designed, often with the help of circuit modeling (on a computer). Specific commercially available op-amps and other components are then chosen that meet the design criteria within the specified tolerances at acceptable cost. If not all criteria can be met, the specification may need to be modified.
A prototype is then built and tested; changes to meet or improve the specification, alter functionality, or reduce the cost, may be made.
Applications without using any feedback.
That is, the op-amp is being used as a voltage comparator. Note that a device designed primarily as a comparator may be better if, for instance, speed is important or a wide range of input voltages may be found, since such devices can quickly recover from full on or full off ("saturated") states.
A "voltage level detector" can be obtained if a reference voltage "V"ref is applied to one of the op-amp's inputs. This means that the op-amp is set up as a comparator to detect a positive voltage. If the voltage to be sensed, "E"i, is applied to op amp's (+) input, the result is a noninverting positive-level detector: when "E"i is above "V"ref, "V"O equals +"V"sat; when "E"i is below "V"ref, "V"O equals −"V"sat. If "E"i is applied to the inverting input, the circuit is an inverting positive-level detector: When "E"i is above "V"ref, "V"O equals −"V"sat.
A "zero voltage level detector" ("E"i = 0) can convert, for example, the output of a sine-wave from a function generator into a variable-frequency square wave. If "E"i is a sine wave, triangular wave, or wave of any other shape that is symmetrical around zero, the zero-crossing detector's output will be square. Zero-crossing detection may also be useful in triggering TRIACs at the best time to reduce mains interference and current spikes.
Positive feedback applications.
Another typical configuration of op-amps is with positive feedback, which takes a fraction of the output signal back to the non-inverting input. An important application of it is the comparator with hysteresis, the Schmitt trigger. Some circuits may use "Positive" feedback and "Negative" feedback around the same amplifier, for example Triangle wave oscillators and active filters.
Because of the wide slew-range and lack of positive feedback, the response of all the open-loop level detectors described above will be relatively slow. External overall positive feedback may be applied but (unlike internal positive feedback that may be applied within the latter stages of a purpose-designed comparator) this markedly affects the accuracy of the zero-crossing detection point. Using a general-purpose op-amp, for example, the frequency of "E"i for the sine to square wave converter should probably be below 100 Hz.
Negative feedback applications.
Non-inverting amplifier.
"In a non-inverting amplifier, the output voltage changes in the same direction as the input voltage."
The gain equation for the op-amp is:
However, in this circuit "V"− is a function of "V"out because of the negative feedback through the "R"1 "R"2 network. "R"1 and "R"2 form a voltage divider, and as "V"− is a high-impedance input, it does not load it appreciably. Consequently:
where
Substituting this into the gain equation, we obtain:
Solving for formula_9:
If formula_11 is very large, this simplifies to
The non-inverting input of the operational amplifier needs a path for DC to ground; if the signal source does not supply a DC path, or if that source requires a given load impedance, then the circuit will require another resistor from the non-inverting input to ground. When the operational amplifier's input bias currents are significant, then the DC source resistances driving the inputs should be balanced. The ideal value for the feedback resistors (to give minimum offset voltage) will be such that the two resistances in parallel roughly equal the resistance to ground at the non-inverting input pin. That ideal value assumes the bias currents are well-matched, which may not be true for all op-amps.
Inverting amplifier.
"In an inverting amplifier, the output voltage changes in an opposite direction to the input voltage."
As with the non-inverting amplifier, we start with the gain equation of the op-amp:
This time, "V"− is a function of both "V"out and "V"in due to the voltage divider formed by "R"f and "R"in. Again, the op-amp input does not apply an appreciable load, so:
Substituting this into the gain equation and solving for formula_9:
If formula_11 is very large, this simplifies to
A resistor is often inserted between the non-inverting input and ground (so both inputs "see" similar resistances), reducing the input offset voltage due to different voltage drops due to bias current, and may reduce distortion in some op-amps.
A DC-blocking capacitor may be inserted in series with the input resistor when a frequency response down to DC is not needed and any DC voltage on the input is unwanted. That is, the capacitive component of the input impedance inserts a DC zero and a low-frequency pole that gives the circuit a bandpass or high-pass characteristic.
The potentials at the operational amplifier inputs remain virtually constant (near ground) in the inverting configuration. The constant operating potential typically results in distortion levels that are lower than those attainable with the non-inverting topology.
Other applications.
Most single, dual and quad op-amps available have a standardized pin-out which permits one type to be substituted for another without wiring changes. A specific op-amp may be chosen for its open loop gain, bandwidth, noise performance, input impedance, power consumption, or a compromise between any of these factors.
Historical timeline.
1941: A vacuum tube op-amp. An op-amp, defined as a general-purpose, DC-coupled, high gain, inverting feedback amplifier, is first found in U.S. Patent "Summing Amplifier" filed by Karl D. Swartzel Jr. of Bell Labs in 1941. This design used three vacuum tubes to achieve a gain of 90 dB and operated on voltage rails of ±350 V. It had a single inverting input rather than differential inverting and non-inverting inputs, as are common in today's op-amps. Throughout World War II, Swartzel's design proved its value by being liberally used in the M9 artillery director designed at Bell Labs. This artillery director worked with the SCR584 radar system to achieve extraordinary hit rates (near 90%) that would not have been possible otherwise.
1947: An op-amp with an explicit non-inverting input. In 1947, the operational amplifier was first formally defined and named in a paper by John R. Ragazzini of Columbia University. In this same paper a footnote mentioned an op-amp design by a student that would turn out to be quite significant. This op-amp, designed by Loebe Julie, was superior in a variety of ways. It had two major innovations. Its input stage used a long-tailed triode pair with loads matched to reduce drift in the output and, far more importantly, it was the first op-amp design to have two inputs (one inverting, the other non-inverting). The differential input made a whole range of new functionality possible, but it would not be used for a long time due to the rise of the chopper-stabilized amplifier.
1949: A chopper-stabilized op-amp. In 1949, Edwin A. Goldberg designed a chopper-stabilized op-amp. This set-up uses a normal op-amp with an additional AC amplifier that goes alongside the op-amp. The chopper gets an AC signal from DC by switching between the DC voltage and ground at a fast rate (60 Hz or 400 Hz). This signal is then amplified, rectified, filtered and fed into the op-amp's non-inverting input. This vastly improved the gain of the op-amp while significantly reducing the output drift and DC offset. Unfortunately, any design that used a chopper couldn't use their non-inverting input for any other purpose. Nevertheless, the much improved characteristics of the chopper-stabilized op-amp made it the dominant way to use op-amps. Techniques that used the non-inverting input regularly would not be very popular until the 1960s when op-amp ICs started to show up in the field.
1953: A commercially available op-amp. In 1953, vacuum tube op-amps became commercially available with the release of the model K2-W from George A. Philbrick Researches, Incorporated. The designation on the devices shown, GAP/R, is an acronym for the complete company name. Two nine-pin 12AX7 vacuum tubes were mounted in an octal package and had a model K2-P chopper add-on available that would effectively "use up" the non-inverting input. This op-amp was based on a descendant of Loebe Julie's 1947 design and, along with its successors, would start the widespread use of op-amps in industry.
1961: A discrete IC op-amp. With the birth of the transistor in 1947, and the silicon transistor in 1954, the concept of ICs became a reality. The introduction of the planar process in 1959 made transistors and ICs stable enough to be commercially useful. By 1961, solid-state, discrete op-amps were being produced. These op-amps were effectively small circuit boards with packages such as edge connectors. They usually had hand-selected resistors in order to improve things such as voltage offset and drift. The P45 (1961) had a gain of 94 dB and ran on ±15 V rails. It was intended to deal with signals in the range of ±10 V.
1961: A varactor bridge op-amp. There have been many different directions taken in op-amp design. Varactor bridge op-amps started to be produced in the early 1960s. They were designed to have extremely small input current and are still amongst the best op-amps available in terms of common-mode rejection with the ability to correctly deal with hundreds of volts at their inputs.
1962: An op-amp in a potted module. By 1962, several companies were producing modular potted packages that could be plugged into printed circuit boards. These packages were crucially important as they made the operational amplifier into a single black box which could be easily treated as a component in a larger circuit.
1963: A monolithic IC op-amp. In 1963, the first monolithic IC op-amp, the μA702 designed by Bob Widlar at Fairchild Semiconductor, was released. Monolithic ICs consist of a single chip as opposed to a chip and discrete parts (a discrete IC) or multiple chips bonded and connected on a circuit board (a hybrid IC). Almost all modern op-amps are monolithic ICs; however, this first IC did not meet with much success. Issues such as an uneven supply voltage, low gain and a small dynamic range held off the dominance of monolithic op-amps until 1965 when the μA709 (also designed by Bob Widlar) was released.
1968: Release of the μA741. The popularity of monolithic op-amps was further improved upon the release of the LM101 in 1967, which solved a variety of issues, and the subsequent release of the μA741 in 1968. The μA741 was extremely similar to the LM101 except that Fairchild's facilities allowed them to include a 30 pF compensation capacitor inside the chip instead of requiring external compensation. This simple difference has made the 741 "the" canonical op-amp and many modern amps base their pinout on the 741s. The μA741 is still in production, and has become ubiquitous in electronics—many manufacturers produce a version of this classic chip, recognizable by part numbers containing "741". The same part is manufactured by several companies.
1970: First high-speed, low-input current FET design.
In the 1970s high speed, low-input current designs started to be made by using FETs. These would be largely replaced by op-amps made with MOSFETs in the 1980s. During the 1970s single sided supply op-amps also became available.
1972: Single sided supply op-amps being produced. A single sided supply op-amp is one where the input and output voltages can be as low as the negative power supply voltage instead of needing to be at least two volts above it. The result is that it can operate in many applications with the negative supply pin on the op-amp being connected to the signal ground, thus eliminating the need for a separate negative power supply.
The LM324 (released in 1972) was one such op-amp that came in a quad package (four separate op-amps in one package) and became an industry standard. In addition to packaging multiple op-amps in a single package, the 1970s also saw the birth of op-amps in hybrid packages. These op-amps were generally improved versions of existing monolithic op-amps. As the properties of monolithic op-amps improved, the more complex hybrid ICs were quickly relegated to systems that are required to have extremely long service lives or other specialty systems.
Recent trends. Recently supply voltages in analog circuits have decreased (as they have in digital logic) and low-voltage op-amps have been introduced reflecting this. Supplies of ±5 V and increasingly 3.3 V (sometimes as low as 1.8 V) are common. To maximize the signal range modern op-amps commonly have rail-to-rail output (the output signal can range from the lowest supply voltage to the highest) and sometimes rail-to-rail inputs.

</doc>
<doc id="22805" url="http://en.wikipedia.org/wiki?curid=22805" title="Ordinary language">
Ordinary language

 
The phrase ordinary language is often used in philosophy and logic to distinguish between ordinary, unsurprising uses of terms and their more specialized uses in theorizing, or jargon. For example, the statements ""I find that class of person very annoying" and "Birds fall into a different class from bees" might be said to contain ordinary English uses of "class". By contrast, when Bertrand Russell writes, in "The Principles of Mathematics", "A class [...] is neither a predicate nor a class-concept, for different predicates and different class-concepts may correspond to the same class."" Russell uses the word "class" in a sense that might or might not correspond neatly to any identifiable ordinary English use of the word; so we might say that he is not using ordinary language, but jargon.
Another example concerns recent use of ‘necessary and sufficient condition’ in logic versus its traditional use in ordinary English . For certain post-WWII logicians, by no means all, necessity and sufficiency are implicational relationships between statements. The assertion that one statement is a necessary and sufficient condition of another means that the former statement is true if and only if the latter is true. That is, the two statements must be either simultaneously true or simultaneously false. In ordinary English, ‘necessary’ and ‘sufficient’ indicate relations between conditions or states of affairs, not statements. Being male sibling is a necessary and sufficient condition for being a brother. Fred’s being male sibling is a necessary and sufficient condition for the truth of the statement that Fred is a brother.
The so-called ordinary language philosophy held that many philosophical problems arose due to confused and inappropriate uses of language that deviated from ordinary language. On their view, philosophers should always attempt to frame their problems in terms of, and to respect the "intuitions" of, ordinary language. This same phrase is still used, occasionally, by (broadly understood) analytic philosophers in supporting or criticizing philosophical positions. Even those who do not hold with the tenets of ordinary language philosophy sometimes regard it a damning criticism of a philosophical view if it involves the use of some term that deviates too widely from ordinary English (ordinary language).

</doc>
<doc id="22807" url="http://en.wikipedia.org/wiki?curid=22807" title="Oh Hell">
Oh Hell

Oh Hell is a trick-taking card game in which the object is to take "exactly" the number of tricks bid, unlike contract bridge and spades: taking more tricks than bid is a loss. Its first appearance dates to the early 1930s and it is sometimes credited to the McCandless family.
Concept.
The game of Oh Hell explores the idea of taking an exact number of tricks specified by a bid before the hand. It differs from other trick-taking games in that players play a fixed number of hands. The game uses trump, often decided by a cut of the deck after the hand's cards have been distributed.
Like many popular social card games, Oh Hell has many local variants, in both rules and names.
Famous players.
President Bill Clinton and Steven Spielberg are high profile Oh Hell players.
Rules.
There are many variations to this game; a common set of regulations is given here.
Oh Hell can be played with almost any number of players (3+) although 4-7 is considered optimal. The game is played using a standard 52-card deck, with ace (A) being the highest rank, two (2) the lowest. With six or more players, the game can be played with two decks combined or with a 63-card deck from six-player 500.
A game consists of a fixed number of hands, and each hand consists of dealing a certain number of cards to each player, depending on the variation and the number of players. During a hand, each player bids for a number of tricks, then attempts to take exactly that many tricks during the hand.
The dealer (initially determined by cutting cards) deals out the cards one by one, starting with the player to his left, in a clockwise direction, until the required number of cards has been dealt. After the dealing is complete, the next card is turned face up, and the suit of this card determines the trump suit for the deal, which is why only up to 12 cards are dealt in a four-player match. (If there are no unused cards, the largest hand is played without a trump suit. Alternatively, the maximal round trump suit can be determined in a variety of ways: for instance, by revealing the dealer's last card as in whist, by cutting the pack before dealing or the dealer can decide the trump before seeing his own cards.)
Each player now bids for the number of tricks he believes he can win. The player to the left of the dealer bids first. Bidding is unrestricted except for the "screw the dealer" rule: the number of tricks bid cannot equal the number available. That is, every deal must in total be either overbid or underbid. For example, if five cards are dealt, and the first three bids are two, zero and one, then the dealer may not bid two. However, if five cards are dealt, and the first three bids are three, one and two, then the dealer is free to make any bid. The "Screw the Dealer" rule is not used in the version played in West Virginia, Rural Maryland, and Pennsylvania with the dealer being free to make any bid.
When every player has made a bid, the player to the left of the dealer makes the opening lead. Play then proceeds as usual in a trick-taking game, with each player in turn playing one card. Players must follow suit, unless they have no cards of the led suit, in which case they may play any card. The highest card of the led suit wins the trick unless ruffed, when the highest trump card wins.
In multi-deck games, the first of identical cards to be played (say two queens of clubs) wins the trick. In a more complicated variant, identical cards cancel each other, leading to the possibility (if the number of players is even) of an entire trick being canceled out.
The player who wins the trick leads to the next trick.
Cooperative version.
In this variant, all bids must add up exactly to the number of cards dealt for that round. Players must then "make it work" to move on to the next round. If anyone takes more or less than their bid, the deal moves to the left and the round is re-dealt. With four players, a second deck may be used to specify the round to be played—the value of the upcard determines the number of cards dealt and the suit determines the trump suit for the round.
Prospect version.
This variant is played for money. Prior to dealing the first hand, players agree on the amount of money the “losers” will have to pay to the winner. The last place finisher pays the most and the second place finisher pays the least. The sliding scale in the Prospect version keeps all the players invested in the outcome of every hand, since their finishing rank corresponds to how much money they will owe the winner.
Tournaments.
The WPOHL World Championship is usually held in December in Rehoboth Beach Delaware using “Prospect” rules (e.g. 5 players make up a full table, blind bidding and drinking are allowed, smoking is not). The deal begins with 10 cards, plays down to 1, then back up to 10 for a total of 19 hands per round. Depending on the size of the field, the five or ten lowest scoring players in the room are eliminated each round until there is a five person "final table." The entry fee is typically under $50.00 (plus $10.00 to join the WPOHL, if not a member).
On December 15, 2013, Shawn O’Brien defeated a field of the world’s best Oh Hell players to win the 2013 World Prospect Oh Hell League (WPOHL) World Championship, earning $45.00 in prize money and temporary ownership of the Peterson Cup. The 46-year-old Pennsylvania native is the first official world champion in WPOHL history. The championship consisted of a series three games played in Montrose, Pennsylvania. The 2014 Championship is scheduled to take place December 13–14 in Rehoboth Beach, Delaware.
O'Brien easily defended his title on December 20, 2014 with commanding tournament play that earned him the nickname “Shawnicus Maximus” and laid the groundwork for a possible dynasty. The Pennsylvanian led the championship from wire to wire and clinched the Peterson Cup by winning the first two of three final rounds of play. With only one blind bid over the course of the 57 hand final series, Shawn made his bid an astounding 82% of the time.
In the early 1990s, the International Oh-Hell League’s annual Championship Tournament of All Creation was held each March in the Riverton, PA Fire Hall. Little current information is available about the tournament. Players vied for the league trophy, a 2-inch bronze reproduction of the Belgian landmark sculpture Manneken Pis - a naked, urinating urchin - which resided permanently in the home of tournament founder, Jack Mathews, regardless of who won the tournament. Thus, to "win" the trophy was not to possess it. Additional idiosyncratic tournament rules included the use of alcohol being off limits, but the use of tobacco being encouraged. A full table consisted of four players. Play began with a one card hand, went up to 13, then back down to one for a total of 25 hands. In each hand, except the 13th, when the entire deck was dealt, the first undealt card was turned over to establish the trump suit. The tournament entry fee was $5.00.
The Annual Cartier 'Oh Hell!' Tournament began in 1995. The tournament formula was created by Tessa Kennedy and Tomasz Starzewski. Cartier Ltd. sponsors the tournament with all money raised going to charity.
Tournament Organization: Two decks of cards are assigned to each table. As one deck is dealt, the other is shuffled in preparation for the following hand. The person to shuffle the cards is always the player sitting opposite the dealer in that hand. Players pick a random card from the deck to select the Dealer for the first hand (highest card is first Dealer).
The tournament is played with 32 people. The first round has all 32 people playing on 8 tables of 4 players each. The winner and first runner up from each table go on to play in the second round. The second round is therefore played with 16 people on 4 tables of 4 players. First round winners and runners-up are split up so they do not play each other again in the second round. The single winner from each table then goes on to the final round the final table of 4 players. The winner is the tournament champion.
Scoring.
There are several alternative methods of scoring:
Names.
Oh Hell is also known by a variety of names, including:
Dutch names.
Boerenbridge, Boerenlullen, Chinees poepen, Chinees dekken, Chinees bridgen, Koreaanse poker, 10 op en neer, jodelen, pronostieken, Slagenvragen, Hellen, Bollen, op-en-affen.

</doc>
<doc id="22808" url="http://en.wikipedia.org/wiki?curid=22808" title="On War">
On War

Vom Kriege (]) is a book on war and military strategy by Prussian general Carl von Clausewitz (1780–1831), written mostly after the Napoleonic wars, between 1816 and 1830, and published posthumously by his wife Marie von Brühl in 1832. It has been translated into English several times as On War. "On War" is actually an unfinished work; Clausewitz had set about revising his accumulated manuscripts in 1827, but did not live to finish the task. His wife edited his collected works and published them between 1832 and 1835. His 10-volume collected works contain most of his larger historical and theoretical writings, though not his shorter articles and papers or his extensive correspondence with important political, military, intellectual and cultural leaders in the Prussian state. "On War" is formed by the first three volumes and represents his theoretical explorations. It is one of the most important treatises on political-military analysis and strategy ever written, and remains both controversial and an influence on strategic thinking.
History.
Clausewitz was among those intrigued by the manner in which the leaders of the French Revolution, especially Napoleon, had changed the conduct of war through their ability to motivate the populace and to gain access to the full resources of the state; thus unleashing war on a greater scale than had previously been seen in Europe. Clausewitz was well educated and had strong interests in art, history, science, and education. He was a professional soldier who spent a considerable part of his life fighting against Napoleon. The insights he gained from his political and military experiences, combined with a solid grasp of European history, provided the basis for the book.
Synopsis.
The book contains a wealth of historical examples used to illustrate its various concepts. Frederick II of Prussia (the Great) figures prominently for having made very efficient use of the limited forces at his disposal, though Napoleon is perhaps the central figure.
According to Azar Gat, the "general message" of the book was that "the conduct of war could not be reduced to universal principles." Among many strands of thought, three stand out as essential to Clausewitz's concept:
Some of the key ideas (not necessarily original to Clausewitz or even to his mentor Gerhard von Scharnhorst) discussed in "On War" include (in no particular order of importance):
Clausewitz used a dialectical method to construct his argument, leading to frequent modern misinterpretation because he explores various—often opposed—ideas before coming to conclusions.
Modern perception of war are based on the concepts Clausewitz put forth in "On War", though these have been very diversely interpreted by various leaders (e.g., Moltke, Vladimir Lenin, Dwight D. Eisenhower, Mao Zedong, etc.), thinkers, armies, and peoples. Modern military doctrine, organization, and norms are all based on Napoleonic premises, even to this day—though whether these premises are necessarily also "Clausewitzian" is debatable.
The "dualism" of Clausewitz's view of war (i.e., that wars can vary a great deal between the two "poles" he proposed, based on the political objectives of the opposing sides and the context) seems simple enough, but few commentators have proven willing to accept this crucial variability—they insist that Clausewitz "really" argued for one end of the scale or the other. "On War" has been seen by some prominent critics as an argument for "total war".[a] It has been blamed for the level of destruction involved in the First and Second World Wars, but it seems rather that Clausewitz (who did not actually use the term "total war") had merely foreseen the inevitable development that started with the huge, patriotically motivated armies of the Napoleonic wars. These wars resulted (though war's evolution has not yet ended) in the atomic bombing of Hiroshima and Nagasaki, with all the forces and capabilities of the state devoted to destroying forces and capabilities of the enemy state (thus "total war"). Conversely, Clausewitz has also been seen as "The preeminent military and political strategist of limited war in modern times." (Robert Osgood, 1979)
Clausewitz and his proponents have been severely criticized by competing theorists--Antoine-Henri Jomini in the 19th century, B. H. Liddell Hart in the mid-20th century, and Martin van Creveld and John Keegan more recently. "On War" is a work rooted solely in the world of the nation state, says historian Martin Van Creveld, who alleges that Clausewitz takes the state "almost for granted" as he rarely looks at anything previous to Westphalia. He alleges that Clausewitz does not address any form of intra/supra-state conflict, such as rebellion and revolution, because he could not theoretically account for warfare before the existence of the state. Previous kinds of conflict were demoted to criminal activities without legitimacy and not worthy of the label "war." Van Creveld argues that "Clausewitzian war" requires the state to act in conjunction with the people and the army, the state becoming a massive engine built to exert military force against an identical opponent. He supports this statement by pointing to the conventional armies in existence throughout the 20th century. This view ignores, among many other things, the facts that Clausewitz died in the early "19th" century, that Prussia itself was not a "nation-state," and that the Napoleonic Wars included many non-conventional conflicts of which Clausewitz was well aware. In any case, revolutionaries like Karl Marx, Friedrich Engels, Vladimir Lenin, Leon Trotsky and Mao Zedong had no trouble adapting Clausewitz's concepts to their own purposes. Nor did conservatives like the Elder Moltke and Dwight D. Eisenhower. Much of Clausewitz's thinking was based on his experience as a Prussian war planner concerned with how to use popular forces in an insurrectionary struggle against the much-superior French forces which occupied Prussia after 1806—how, in short, to wage a "Spanish War in Germany."
Clausewitz himself never saw the 20th-century states and armies to which Creveld refers—the states with which he himself was familiar were quite different. In any case, the "Clausewitzian Trinity" that Van Creveld condemns as consisting of a rigid, static hierarchy of "People, Army, and Government," does not in fact consist of those three concrete actors. In fact, the words people, army, and government appear nowhere in the paragraph in which Clausewitz defines his famous Trinity. Rather, the Trinity of forces that drive the course of real-world war in Clausewitz's view are 1) violent emotion, 2) the interplay of chance and probability, and 3) political calculations driven by reason. It seems unlikely that emotion, chance, and rationality will cease to play a role in war any time soon, whatever the fate of the state.

</doc>
<doc id="22810" url="http://en.wikipedia.org/wiki?curid=22810" title="Orange Alternative">
Orange Alternative

Orange Alternative ("Pomarańczowa Alternatywa") is a name for an underground protest movement which was started in Wrocław, a city in south-west Poland and led by Waldemar Fydrych (sometimes misspelled as Frydrych), commonly known as "Major (Commander of Festung Breslau)" in the 1980s. Its main purpose was to offer a wider group of citizens an alternative way of opposition against the authoritarian communist regime by means of a peaceful protest that used absurd and nonsensical elements.
By doing this, Orange Alternative participants could not be arrested by the police for opposition to the regime without the authorities becoming a laughing stock. Orange Alternative has been viewed as part of the broader Solidarity movement. Academics Dennis Bos and Marjolein 't Hart have asserted it was the most effective of all Solidarity's factions in bringing about the movement's success.
Initially it painted ridiculous graffiti of dwarves on paint spots covering up anti-government slogans on city walls. Afterwards, beginning with 1985 through 1990, it organized a series of more than sixty happenings in several Polish cities, including Wrocław, Warsaw, Łódź, Lublin and Tomaszów Mazowiecki.
It was the most picturesque element of Polish opposition to Stalinist authoritarianism. It suspended activity in 1989, but reactivated in 2001 and has been active on a small scale ever since.
A statue of a dwarf, dedicated to the memory of the movement, stands today on Świdnicka Street in Wrocław, in the place where events took place.
Orange Alternative movement has inspired several other similar movements in authoritarian countries including Czechoslovakia and Hungary and it has also inspired and influenced the Pora and the so-called Orange Revolution movement in Ukraine, which was in turn supported by Poland.
Some utterances ascribed to Waldemar Fydrych:
The Beginnings.
The beginning of the Orange Alternative are in a student movement called the Movement for New Culture created in 1980 at the University of Wrocław. It is in that year that Waldemar "Major" Fydrych, one of the movement's founders, proclaims the Socialist Surrealism Manifesto, which becomes the ideological backbone behind a gazette known as "The Orange Alternative." Seven out of the total fifteen issues of this gazette appear during student strikes organized in November and December 1980 as part of the Solidarity upheaval. The first number is edited jointly by Major Waldemar Fydrych and Wiesław Cupała (a.k.a. "Captain") simply with an idea to have fun. The editors treat the strike and the surrounding reality as forms of Art. For the ensuing numbers, the editorial committee is joined by Piotr Adamcio, known as "Lieutenant Pablo," Andrzej Dziewit and Zenon Zegarski, nicknamed "Lieutenant Zizi Top." Although its avantgarde character, according to the student strike organizers, was a threat to the "higher aims of the strike", and notwithstanding attempts by the strike committee to censor it, the gazette became rapidly very popular among the students.
The Dwarves.
The first known actions of the Orange Alternative consisted of painting dwarf graffiti on spots created by the police's covering up anti-regime slogans on walls of the Polish cities. The first graffiti was painted by Major Waldemar Fydrych and Wiesław Cupała on the night from the 30 to 31 August 1982 on one of the residences in the Wrocław district of Biskupin and Sępolno.
Altogether more than one thousand of such graffiti were painted in the major Polish cities such as Wrocław, Kraków, Warsaw, Łódź, and Gdańsk.
Dwarves appearing in numbers all over Poland aroused the interest of both Polish pedestrians and the militia, whose intervention led to short term arrests of the graffiti artists.
During one of these incidents, Major, a detainee at a police station in Łódź, proclaimed, in reference to the Marxist and Hegelian dialectics, yet another artistic manifesto and referred to his graffiti art as "dialectic painting" stating: "The Thesis is the Anti-Regime Slogan. The Anti-thesis is the Spot and the Synthesis is the Dwarf. Quantity evolves into Quality. The more Dwarves there are, the better it is."
Happenings.
What brought the Orange Alternative the biggest fame were its street happenings which it organized throughout the second half of the 1980s. These actions gained it enormous popularity among the Polish youth, who joined the movement, seeing it an alternative to the opposition style presented by the Solidarity, which they viewed as more stiff and boring.
The first modest happening called the "Burning of Tubes" was organized as early as 1985 in Wrocław by Major Waldemar Fydrych accompanied by a small group of artists to which belonged: Krzysztof Skarbek, Piotr Petyszkowski, Andrzej Głuszek and Sławomir Monkiewicz.
The break-through moment came in the fall of 1987, during the Open Theatre Festival in Wrocław, when the Village Voice reported the Orange Alternative's action known as "Distribution of Toilet Paper" – a happening that satirized the annoying lack of that consumer product at the time. After the publication of this article, the Orange Alternative became of interest to a number of Polish and foreign media.
The biggest happenings however took place in the years 1987 through 1989, with the "orange" wave spilling over Poland into cities such as Warsaw, Łódź, Lublin and Tomaszów Mazowiecki following Major Fydrych's arrest on 8 March 1988.
The actions of the Orange Alternative – although its leaders and participants often expressed anarchistic viewpoints – were not inherently ideological. No serious demands were ever expressed. Rather, the slogans were surrealist in character (such as "Vivat Sorbovit" (Sorbovit being a popular soft drink at that time)) or "There is no freedom without dwarves." Often they paraphrased slogans used by the Solidarity Union or the communists. Their role was to laugh at absurdities and pompousness of both sides of the system and provoke independent thinking.
The open street formula allowed all individuals to take part in the happenings. This openness drew thousands of pedestrians to participate in the group's actions. In such a way, the majority of the happenings could assemble thousands of participants, of whom many were accidental passers-by. The culmination point in the movement's history was the action organized on 1 June 1988, known as the "Revolution of Dwarves", during which more than 10 thousand people marched through the center of Wrocław wearing orange dwarf hats.
The happenings usually terminated with the arrest of hundreds of participants, who did not manage to escape in time from the hands of the militia. At one point, the participants were even able to provoke the Communist militia to arrest 77 Santa Clauses or, on another occasion, anyone wearing anything orange.
For every one of its actions, the Orange Alternative printed leaflets and posters, featuring slogans like "Every militiaman is a piece of Art" or "Citizen, help the militia, beat yourself up."
External links.
 Media related to at Wikimedia Commons

</doc>
<doc id="22811" url="http://en.wikipedia.org/wiki?curid=22811" title="Otto IV, Holy Roman Emperor">
Otto IV, Holy Roman Emperor

Otto IV (1175 – May 19, 1218) was one of two rival kings of Germany from 1198 on, sole king from 1208 on, and Holy Roman Emperor from 1209 until he was forced to abdicate in 1215. The only German king of the Welf dynasty, he incurred the wrath of Pope Innocent III and was excommunicated in 1210.
Career.
Early life.
Otto was the third son of Henry the Lion, Duke of Bavaria and Saxony, and Matilda Plantagenet. His exact birthplace is not given by any original source. He grew up in England in the care of his grandfather King Henry II. Otto was fluent in French as well as German. He became the foster son of his maternal uncle, Richard I of England. In 1190, after he left England to join the Third Crusade, Richard appointed Otto Earl of York. The authenticity (or authority) of this grant was doubted by the vassals of Yorkshire, who prevented Otto taking possession of his earldom. Still, he probably visited Yorkshire in 1191, and he continued to claim the revenues of the earldom after becoming king of Germany, although he never secured them. Neither did he succeed in getting the 25,000 silver marks willed to him by his uncle in 1199.
In 1195, Richard began negotiations to marry Otto to Margaret, daughter and heiress of King William the Lion of Scotland. Lothian, as Margaret's dowry, would be handed over to Richard for safekeeping and the counties of Northumberland and Cumberland (Carlisle) would be granted to Otto and turned over to the king of Scotland. The negotiations dragged on until August 1198, when the birth of an heir to William rendered them unnecessary. Having failed in his efforts to secure Otto an English earldom or else a Scottish kingdom, in September 1196 Richard, as duke of Aquitaine, enfeoffed Otto with the county of Poitou. There is some disagreement over whether Otto received Poitou in exchange for or in addition to the earldom of York.
Otto was in Poitou from September 1196 until mid-1197, when he joined Richard in Normandy to confer over the appointment of bishops to the vacant sees of Poitiers, Limoges and Périgueux. He then participated in the war against Philip II of France on the side of Richard. In October he returned to Poitou. The German historian Jens Ahlers, taking into account Otto's life prior to 1198, considers that he might have been the first foreign king of Germany.
Conflict with Philip of Swabia.
After the death of Emperor Henry VI, the majority of the princes of the Empire, situated in the south, elected Henry’s brother, Philip, Duke of Swabia, king in March 1198, after receiving money and promises from Philip in exchange for their support. Those princes opposed to the Staufen dynasty also decided, on the initiative of Richard of England, to elect instead a member of the House of Welf. Otto's elder brother, Henry, was on a crusade at the time, and so the choice fell to Otto. Otto, soon recognized throughout the northwest and the lower Rhine region, was elected king by his partisans in Cologne on June 9, 1198. Otto took control of Aachen, the place of coronation, and was crowned by Adolf, Archbishop of Cologne, on July 12, 1198. This was of great symbolic importance, since the Archbishop of Cologne alone could crown the King of the Romans. Nevertheless, the coronation was done with fake regalia, because the actual materials were in the hands of the Staufen.
Otto's election pulled the empire into the conflict between England and France. Philip had allied himself with the French king, Philip II, while Otto was supported at first by Richard I, and after his death in 1199 by his brother John.
The papacy meanwhile, under Innocent III, determined to prevent the continued unification of Sicily and the Holy Roman Empire under one monarch seized the opportunity to extend its influence. Therefore, Innocent III favoured Otto, whose family had always been opposed to the house of Hohenstaufen. Otto himself also seemed willing to grant any demands that Innocent would make. The confusion in the empire allowed Innocent to drive out the imperial feudal lords from Ancona, Spoleto, and Perugia, who had been installed by Emperor Henry VI. At the same time, Innocent encouraged the cities in Tuscany to form a league, called the League of San Genesio, against imperial interests in Italy, and they placed themselves under Innocent’s protection. In 1201, Innocent announced that he recognized Otto as the only legitimate king. In return, Otto promised to support the pope's interests in Italy. Otto also had the support of Ottokar I, the king of Bohemia, who although at first siding with Philip of Swabia, eventually threw in his lot with Otto. Otto’s cause was further strengthened by the support of the Danish king, Valdemar II. But Philip achieved a great deal of success in the civil war that followed, allowing him in 1204 to be again crowned king, this time by the archbishop of Cologne.
In the following years, Otto's situation worsened because after England's defeat by France he lost England's financial support. Many of his allies changed sides to Philip, including his brother Henry. Otto was defeated and wounded in battle by Philip on July 27, 1206, near Wassenberg, and as a consequence he also lost the support of the pope, who began to favour the apparent winner in the conflict. Otto was forced to retire to his possessions near Braunschweig, leaving Philip virtually uncontested as German king.
Innocent III forced the two warring parties into negotiations at Cologne, and in exchange for renouncing his claim to the throne, Philip promised Otto the hand of his daughter Beatrix in marriage, together with the Duchy of Swabia and an enormous dowry. Otto refused, and as the civil war was again about to recommence, Philip was murdered on June 8, 1208.
After Philip's death, Otto made amends with the Staufen party and became engaged to Philip's daughter Beatrix. In an election in Frankfurt on November 11, 1208, he gained the support of all the electoral princes, as he promised he would not make hereditary claims to the imperial crown on behalf of any children he might father. Now fully reconciled with Innocent, Otto made preparations to be crowned Holy Roman Emperor. To secure Innocent’s support, he promised to restore to the Papal States all territory that it had possessed under Louis the Pious, including the March of Ancona, the Duchy of Spoleto, the former Exarchate of Ravenna, and the Pentapolis. Travelling down via Verona, Modena, and Bologna, he eventually arrived at Milan where he received the Iron Crown of Lombardy and the title of King of Italy in 1208. He was met at Viterbo by Pope Innocent and was taken to St. Peter's Basilica, where he was crowned emperor by Pope Innocent on October 21, 1209, before rioting broke out in Rome, forcing Otto to abandon the city.
Conflict with Innocent III.
Not content with his successes so far, Innocent also obtained from Otto further written concessions to the Papal See, including to allow all elections of German bishops to be conducted according to Church ordinances, and not to prevent any appeals to Rome. He also promised to hand over to the Church all income from any vacant sees which had been flowing into the imperial treasury.
After abandoning Rome, Otto marched north, reaching Pisa by November 20. Here, probably advised by Peter of Celano and Dipold, Count of Acerra, he was convinced to abandon his earlier promises, and Otto immediately worked to restore imperial power in Italy. After his consecration by the pope, he promised to restore the lands bequeathed to the church by the countess Matilda of Tuscany nearly a century before, and to not move against Frederick Roger, the King of Sicily. But all his promises he quickly broke. He threw out the papal troops from Ancona and Spoleto, reclaiming the territory as imperial fiefs. He then demanded that Frederick of Sicily do homage for the duchies of Calabria and Apulia, and when Frederick refused to appear, Otto declared those fiefs forfeited. Otto then marched on Rome, and commanded Innocent to annul the Concordat of Worms, and to recognise the imperial crown’s right of nominating to all vacant benefices.
Such actions infuriated Innocent and he was promptly excommunicated by the pope for this on November 18, 1210. Subsequently, he tried to conquer Sicily, which was held by the Staufen king Frederick, under the guardianship of Innocent III. Parallel to this, the German nobility by this time were growing ever more frustrated with Otto. They felt that instead of wasting his time in Italy, and playing power politics with the pope, it was his first duty to defend the northern provinces of the empire against Valdemar II of Denmark, who had taken advantage of Otto’s distractions by invading the northern provinces of the empire and possessing the whole Baltic coast from Holstein to Livonia. So while Otto was in southern Italy, several princes of the empire, including the archbishops of Mainz and Magdeburg, at the instigation of King Philip II of France and with the consent of the pope, elected Frederick King of the Romans at the Diet of Nuremberg in 1211.
Otto’s ambassadors from Milan appeared before the Fourth Lateran Council, pleading his case for his excommunication to be lifted. Although he claimed he had repented of his offences, and declared his willingness to be obedient to the Pope in all things, Innocent III had already recognised Frederick as emperor-elect.
Otto returned to Germany to deal with the situation, hopeful to salvage something from the looming disaster. He found most of the German princes and bishops had turned against him, and that Frederick, who had made his way up the Italian peninsula, had avoided Otto’s men who were guarding the passes through the Alps and had arrived at Constance. Otto soon discovered that after Beatrix died in the summer of 1212, and Frederick arrived in Germany with his army in September 1212, most of the former Staufen supporters deserted Otto for Frederick, forcing Otto to withdraw to Cologne. On December 5, 1212, Frederick was elected king for a second time by a majority of the princes.
The support that Philip II of France was giving to Frederick forced King John of England to throw his weight behind his nephew Otto. The destruction of the French fleet in 1213 by the English saw John begin preparations for an invasion of France, and Otto saw a way of both destroying Frederick’s French support as well as bolstering his own prestige. He agreed to join John in the invasion, and in February 1214, as John advanced from the Loire, Otto was supposed to make a simultaneous attack from Flanders, together with the Count of Flanders. Unfortunately, the three armies could not coordinate their efforts effectively. It was not until John, who had been disappointed in his hope for an easy victory after being driven from Roche-au-Moine and had retreated to his transports that the Imperial Army, with Otto at its head, assembled in the Low Countries.
On 27 July 1214, the opposing armies suddenly discovered they were in close proximity to each other, on the banks of the little river Marque (a tributary of the river Deûle), near the Bridge of Bouvines. Philip's army numbered some 15,000, while the allied forces possessed around 25,000 troops, and the armies clashed at the Battle of Bouvines. It was a tight battle, but it was lost when Otto was carried off the field by his wounded and terrified horse, causing his forces to abandon the field. It is said that Philip II had sent to Frederick the imperial eagle which Otto had left lying on the battlefield.
This defeat allowed Frederick to take Aachen and Cologne, as Otto was forced again to withdraw to his private possessions around Brunswick, and he was forced to abdicate the imperial throne in 1215. He died of disease, at Harzburg castle on May 19, 1218, requesting that he be mortally expiated in atonement of his sins. Historian Kantorowicz described the death as "gruesome": "deposed, dethroned, he was flung full length on the ground by the Abbot, confessing his sins, while the reluctant priests beat him bloodily to death. Such was the end of the first and last Welf Emperor." 
He is entombed in the Brunswick Cathedral.
Family.
Otto was related to every other King of Germany. He married twice:
He had no children from either Beatrice or Marie.
References.
<BR>

</doc>
<doc id="22812" url="http://en.wikipedia.org/wiki?curid=22812" title="Octavian (disambiguation)">
Octavian (disambiguation)

Octavian may refer to:

</doc>
<doc id="22816" url="http://en.wikipedia.org/wiki?curid=22816" title="Outcome-based education">
Outcome-based education

Outcome-based education (OBE) is an educational theory that bases each part of an educational system around goals (outcomes). By the end of the educational experience each student should have achieved the goal. There is no specified style of teaching or assessment in OBE; instead classes, opportunities, and assessments should all help students achieve the specified outcomes.
Outcome-based methods have been adopted in education systems around the world, at multiple levels. 
Australia and South Africa adopted OBE policies in the early 1990s but have since been phased out. The United States has had an OBE program in place since 1994 that has been adapted over the years. In 2005 Hong Kong adopted an outcome based approach for its universities. Malaysia implemented OBE in all of their public schools systems in 2008. The European Union has proposed an education shift to focus on outcomes, across the EU. In an international effort to accept OBE The Washington Accord was created in 1989, it is an agreement to accept undergraduate engineering degrees that were obtained using OBE methods. As of 2014 the signatories Australia, Canada, Taiwan, Hong Kong, India, Ireland, Japan, Korea, Malaysia, New Zealand, Russia, Singapore, South Africa, Sri Lanka, Turkey, the United Kingdom and the United States.
Differences from traditional education methods.
In a traditional education system, students are given grades and rankings compared to each other. Content and performance expectations are based primarily on what was taught in the past to students of a given age. The goal of traditional education was to present the knowledge and skills of an older generation to the new generation of students, and to provide students with an environment in which to learn. The process paid little attention (beyond the classroom teacher) to whether or not students learn any of the material.
Benefits of OBE.
Clarity.
The focus on outcomes creates a clear expectation of what needs to be accomplished by the end of the course. Students will understand what is expected of them and teachers will know what they need to teach during the course. Clarity is important over years of schooling and when team teaching is involved. Each team member, or year in school, will have a clear understanding of what needs to be accomplished in each class, or at each level, allowing students to progress. Those designing and planning the curriculum are expected to work backwards once an outcome has been decided upon, they must determine what knowledge and skills will be required to reach the outcome.
Flexibility.
With a clear sense of what needs to be accomplished, instructors will be able to structure their lessons around the student’s needs. OBE does not specify a specific method of instruction, leaving instructors free to teach their students using any method. Instructors will also be able to recognize diversity among students by using various teaching and assessment techniques during their class. OBE is meant to be a student-centered learning model. Teachers are meant to guide and help the students understand the material in any way necessary, study guides, and group work are some of the methods instructors can use to facilitate students learning.
Comparison.
OBE provides an opportunity for comparison across institutions. On an individual level, institutions can look at what outcomes a student has achieved to decide what level the student would be at within a new institution. On an institutional level, institutions can compare themselves, by checking to see what outcomes they have in common, and find places where they may need improvement, based on the achievement of outcomes at other institutions. The ability to compare easily across institutions allows students to move between institutions with relative ease. The institutions can compare outcomes to determine what credits to award the student. The clearly articulated outcomes should allow institutions to assess the student’s achievements rapidly, leading to increased movement of students. These outcomes also work for school to work transitions. A potential employer can look at records of the potential employee to determine what outcomes they have achieved. They can then determine if the potential employee has the skills necessary for the job.
Involvement.
Student involvement in the classroom is a key part of OBE, students are expected to do their own learning, so that they gain a full understanding of the material. Increased student involvement allows students to feel responsible for their own learning, and they should learn more through this individual learning. Another aspect of involvement is parental, and community involvement, while developing curriculum, or making changes to it. OBE outcomes are meant to be decided upon within a school system, or at a local level. Parents and community members are asked to give input in order to uphold the standards of education within a community, and to ensure that students will be prepared for life after school.
Drawbacks of OBE.
Definition.
The definitions of the outcomes decided upon are subject to interpretation by those implementing them. Across different programs or even different instructors outcomes could be interpreted differently, leading to a difference in education, even though the same outcomes were said to be achieved. By outlining specific outcomes, a holistic approach to learning is lost. Learning can find itself reduced to something that is specific, measurable, and observable. As a result, outcomes are not yet widely recognized as a valid way of conceptualizing what learning is about.
Assessment problems.
When determining if an outcome has been achieved assessments may become too mechanical, looking only to see if the student has acquired the knowledge. The ability to use and apply the knowledge in different ways may not be the focus of the assessment. The focus on determining if the outcome has been achieved leads to a loss of understanding and learning for students, who may never be shown how to use the knowledge they have gained. Instructors are faced with a challenge, they must learn to manage an environment that can become fundamentally different from what they are accustomed to. In regards to giving assessments they must be willing to put in the time required to create a valid, reliable assessment, that ideally would allow students to demonstrate their understanding of the information, while remaining objective.
Generality.
Education outcomes can lead to a constrained nature of teaching and assessment. Assessing liberal outcomes such as creativity, respect for self and others, responsibility, and self-sufficiency, can become problematic. There is not a measurable, observable, or specific way to determine if a student has achieved these outcomes. Due to the nature of specific outcomes, OBE may actually work against its ideals of serving and creating individuals that have achieved many outcomes.
Involvement.
Parental involvement, as discussed in the benefits section can also be a drawback, if parents and community members are not willing to express their opinions on the quality of the education system, the system may not see a need for improvement, and not change to meet student’s needs. Parents may also become too involved, requesting too many changes, so that important improvements get lost with other changes that are being suggested. Instructors will also find that their work is increased; they must work to first understand the outcome, then build a curriculum around each outcome they are required to meet. Instructors have found that implementing multiple outcomes is difficult to do equally, especially in primary school. Instructors will also find their work load increased if they chose to use an assessment method that evaluates students holistically.
Adoption and removal.
Australia.
In the early 1990s all states and territories in Australia developed intended curriculum documents largely based on OBE for their primary and secondary schools. Criticism arose shortly after implementation. Critics argued that no evidence existed that OBE could be implemented successfully on a large scale, in either the United States or Australia. An evaluation of Australian schools found that implementing OBE was difficult. Teachers felt overwhelmed by the amount of expected achievement outcomes. Educators believed that the curriculum outcomes did not attend to the needs of the students or teachers. Critics felt that too many expected outcomes left students with shallow understanding of the material. Many of Australia’s current education policies have moved away from OBE and towards a focus on fully understanding the essential content, rather than learning more content with less understanding.
European Union.
In December 2012, the European Commission presented a new strategy to decrease youth employment rate, which is close to 23% across the European Union. The European Qualifications Framework calls for a shift towards learning outcomes in primary and secondary schools throughout the EU. Students are expected to learn skills that they will need when they complete their education. It also calls for lessons to have a stronger link to employment through work based learning. Work based learning for students should also lead to recognition of vocational training for these students. The program also sets goals for learning foreign languages, and for teachers continued education. It also highlights the importance of using technology, especially the internet, in learning to make it relevant to students.
Hong Kong.
Hong Kong’s University Grants Committee adopted an outcomes based approach to teaching and learning in 2005. No specific approach was created leaving universities to design the approach themselves. Universities were also left with a goal of ensuring an education for their students that will contribute to social and economic development, as defined by the community in which the university resides. With little to no direction or feedback from the outside universities will have to determine if their approach is achieving its goals on their own.
Malaysia.
OBE has been practiced in Malaysia since the 1950s; however, as of 2008 OBE is being implemented at all levels of education, especially tertiary education. This change is a result of the belief that the education system used prior to OBE inadequately prepared graduates for life outside of school. The Ministry of Higher Education has pushed for this change because of the number of unemployed graduates. Findings in 2006 state that nearly 70% of graduates from public universities were considered unemployed. A further study of those graduates found that they felt they lacked, job experience, communication skills, and qualifications relevant to the current job market. The Malaysian Qualifications Agency (MQA) was created to oversee quality of education and to ensure outcomes were being reached. The MQA created a framework that includes eight levels of qualification within higher education, covering three sectors; skills, vocational and technical, and academic. Along with meeting the standards set by the MQA, universities set and monitor their own outcome expectations for students 
South Africa.
OBE was introduced to South Africa in the late 1990s by the post-apartheid government as part of its Curriculum 2005 program. , Initial support for the program derived from anti-apartheid education policies. The policy also gained support from the labor movements that borrowed ideas about competency based education, and Vocational education from New Zealand and Australia, as well as the labor movement that critiqued the apartheid education system. With no strong alternative proposals, the idea of outcome-based education, and a national qualification framework, became the policy of the African National Congress government. This policy was believed to be a democratization of education, people would have a say in what they wanted the outcomes of education to be. It was also believed to be a way to increase education standards and increase the availability of education. The National Qualifications Framework (NQF) went into effect in 1997. In 2001 people realized that the intended effects were not being seen. By 2006 no proposals to change the system had been accepted by the government, causing a hiatus of the program. The program came to be viewed as a failure and a new curriculum improvement process was announced in 2010, slated to be implemented between 2012 and 2014.
United States.
In 1983 a report from the National Commission on Excellence in Education declared that American education standards were eroding, that young people in the United States were not learning enough. In 1989 President Bush and the nation’s governors set national goals to be achieved by the year 2000. GOALS 2000: Educate America Act was signed in March 1994. The goal of this new reform was to show that results were being achieved in schools. In 2001 the No Child Left Behind Act took the place of Goals 2000. It mandated certain measurements as a condition of receiving federal education funds. States are free to set their own standards, but the federal law mandates public reporting of math and reading test scores for disadvantaged demographic subgroups, including racial minorities, low-income students, and special education students. Various consequences for schools that do not make "adequate yearly progress" are included in the law. In 2010 President Obama proposed improvements for the program. In 2012 the U.S. Department of Education invited states to request flexibility waivers in exchange for rigorous plans designed to improve students education in the state.
Pakistan.
In 2010 Pakistan has become a provisional member of the prestigious Washington Accord and since then Universities are working to implement OBE. 

</doc>
<doc id="22817" url="http://en.wikipedia.org/wiki?curid=22817" title="Olga of Kiev">
Olga of Kiev

Saint Olga (Old Church Slavonic: Ольга, born c. 890 died 11 July 969, Kiev) was a ruler of Kievan Rus' as regent (945–c. 963) for her son, Svyatoslav.
Early life.
Olga, a woman from Pskov, married the future Igor of Kiev, arguably in 903. The "Primary Chronicle" gives 879 as her date of birth, which is unlikely, given the birth of her only son probably some 65 years after that date. After Igor's death, Olga ruled Kievan Rus as regent (945-c. 963) on behalf of their son Svyatoslav. She was, hypothetically, of Varangian extraction Old Norse: "Helga"
Drevlian Uprising.
The following account is taken from the Primary Chronicle. Princess Olga was the wife of Igor of Kiev, who was killed by the Drevlians. At the time of her husband's death, their son Svyatoslav was three years old, making Olga the official ruler of Kievan Rus until he reached adulthood. The Drevlians wanted Olga to marry their Prince Mal, making him the ruler of Kievan Rus, but Olga was determined to remain in power and preserve it for her son.
The Drevlians sent twenty of their best men to persuade Olga to marry their Prince Mal and give up her rule of Kievan Rus. She had them buried alive. Then she sent word to Prince Mal that she accepted the proposal, but required their most distinguished men to accompany her on the journey in order for her people to accept the offer of marriage. The Drevlians sent their best men who governed their land. Upon their arrival, she offered them a warm welcome and an invitation to clean up after their long journey in a bathhouse. After they entered, she locked the doors and set fire to the building, burning them alive.
With the best and wisest men out of the way, she planned to destroy the remaining Drevlians. She invited them to a funeral feast so she could mourn over her husband's grave, where her servants waited on them. After the Drevlians were drunk, Olga's soldiers killed over 5,000 of them. She returned to Kiev and prepared an army to attack the survivors. The Drevlians begged for mercy and offered to pay for their freedom with honey and furs. She asked for three pigeons and three sparrows from each house, since she did not want to burden the villagers any further after the siege. They were happy to comply with such a reasonable request.
Now Olga gave to each soldier in her army a pigeon or a sparrow, and ordered them to attach by thread to each pigeon and sparrow a piece of sulfur bound with small pieces of cloth. When night fell, Olga bade her soldiers release the pigeons and the sparrows. So the birds flew to their nests, the pigeons to the cotes, and the sparrows under the eaves. The dove-cotes, the coops, the porches, and the haymows were set on fire. There was not a house that was not consumed, and it was impossible to extinguish the flames, because all the houses caught on fire at once. The people fled from the city, and Olga ordered her soldiers to catch them. Thus she took the city and burned it, and captured the elders of the city. Some of the other captives she killed, while some she gave to others as slaves to her followers. The remnant she left to pay tribute.
This tale, although most certainly legendary, is strikingly similar to a tactic investigated by the US Army during World War II (the so-called Bat bomb). It may therefore contain a kernel of truth.
Regency.
In 947, Princess Olga launched a punitive expedition against the tribal elites between the Luga and the Msta River. Following this successful campaign, a number of forts were erected at Olga’s orders. One of them is supposed to be Gorodets in the Luga region a fortification dated to the middle of the tenth century. Because of its isolated location, Gorodets does not seem to have been in any way associated with the pre-existing settlement pattern. Moreover, the fort produced another example of square timber frames designed to consolidate the rampart that was seen at Ryurikovo Gorodishche. The same building technique was in use a century later in the Novgorod fortifications.
Olga remained regent ruler of Kievan Rus with the support of the army and her people. She changed the system of tribute gathering (poliudie) in the first legal reform recorded in Eastern Europe. She continued to evade proposals of marriage, defended the city during the Siege of Kiev in 968, and saved the power of the throne for her son.
Christianity.
Olga was the first ruler of Rus' to convert to Christianity, in either 945 or 957. The ceremonies of her formal reception in Constantinople were minutely described by Emperor Constantine VII in his book "De Ceremoniis". Following her baptism, Olga took the Christian name Yelena, after the reigning Empress Helena Lekapena. The Slavonic chronicles add apocryphal details to the account of her baptism, such as the story of how she charmed and "outwitted" Constantine and spurned his proposals of marriage. In actuality, at the time of her baptism, Olga was an old woman, while Constantine already had a wife.
Olga was one of the first people of Rus' to be canonized, proclaimed a saint for her efforts to spread Christianity throughout the country. Because of her proselytizing influence, the Orthodox Church calls Saint Olga by the honorific "Isapóstolos", "Equal to the Apostles". However, she failed to convert Svyatoslav, and it was left to her grandson and pupil, Vladimir I, to make Christianity the lasting state religion. During her son's prolonged military campaigns, she remained in charge of Kiev, residing in the castle of Vyshgorod together with her grandsons. She died soon after the Pechenegs' siege of the city, in 969.
Relations with the Holy Roman Emperor.
Seven Latin sources document Olga's embassy to Holy Roman Emperor Otto I in 959. The continuation of Regino of Prüm mentions that the envoys requested the Emperor to appoint a bishop and priests for their nation. The chronicler accuses the envoys of lies, commenting that their trick was not exposed until later. Thietmar of Merseburg says that the first archbishop of Magdeburg, Saint Adalbert of Magdeburg, before being promoted to this high rank, was sent by Emperor Otto to the country of the Rus' ("Rusciae") as a simple bishop but was expelled by pagan allies of Svyatoslav I. The same data is duplicated in the annals of Quedlinburg and Hildesheim, among others.

</doc>
<doc id="22818" url="http://en.wikipedia.org/wiki?curid=22818" title="Olympus Mons">
Olympus Mons

Olympus Mons (Latin for Mount Olympus) is a very large shield volcano on the planet Mars. By one measure, it has a height of nearly 25 km (16 mi). Olympus Mons
stands almost three times as tall as Mount Everest's height above sea level. It is the youngest of the large volcanoes on Mars, having formed during Mars's Amazonian Period. It is currently the biggest discovered Volcano in the Solar System, and had been known to astronomers since the late 19th century as the albedo feature Nix Olympica (Latin for "Olympic Snow"). Its mountainous nature was suspected well before space probes confirmed its identity as a mountain.
The volcano is located in Mars's western hemisphere at approximately , just off the northwestern edge of the Tharsis bulge. The western portion of the volcano lies in the Amazonis quadrangle (MC-8) and the central and eastern portions in the adjoining Tharsis quadrangle (MC-9). Two impact craters on Olympus Mons have been assigned provisional names by the International Astronomical Union. They are the 15.6 km-diameter Karzok crater () and the 10.4 km-diameter Pangboche crater (). The craters are notable for being two of several suspected source areas for shergottites, the most abundant class of Martian meteorites.
Description.
As a shield volcano, Olympus Mons resembles in its morphology the large volcanoes making up the Hawaiian Islands. The edifice is about 600 km wide. Because the mountain is so large, with complex structure at its edges, allocating a height to the structure is difficult. It stands 21 km above the Mars global datum, and its local relief, from the foot of the cliffs which form its margin to the northwest to its peak, is nearly 22 km (a little over twice the height of Mauna Kea as measured from its base on the ocean floor). The total elevation change from the plains of Amazonis Planitia, over 1000 km to the northwest, to the summit approaches 26 km. The summit of the mountain has six nested calderas (collapse craters) forming an irregular depression 60 km × 80 km across and up to 3.2 km deep. The volcano's outer edge consists of an escarpment, or cliff, up to 8 km tall, a feature unique among the shield volcanoes of Mars. Olympus Mons covers an area approximately the size of Arizona, or about 295,254 sqkm.
Being a shield volcano, Olympus Mons has a very low profile. The average slope on the volcano's flanks is only 5°. Slopes are highest near the middle part of the flanks and grow shallower toward the base, giving the flanks a concave upward profile. The shape of Olympus Mons is distinctly unsymmetrical. Its flanks are shallower and extend out further from the summit in the northwestern direction than they do to the southeast. The volcano's shape and profile have been likened to a "circus tent" held up by a single pole that is shifted off center.
Because of the size of Olympus Mons and its shallow slopes, an observer standing on the Martian surface would be unable to view the entire profile of the volcano, even from a great distance. The curvature of the planet and the volcano itself would obscure such a synoptic view. Similarly, an observer near the summit would be unaware of standing on a high mountain, as the slope of the volcano would extend beyond the horizon, a mere 3 kilometers away.
The typical atmospheric pressure at the top of Olympus Mons is 72 pascal, about 12% of the average Martian surface pressure of 600 pascal. Both are exceedingly low by terrestrial standards. By comparison, the atmospheric pressure at the summit of Mount Everest is 32,000 pascals, or about 32% of Earth's sea level pressure. Even so, high-altitude orographic clouds frequently drift over the Olympus Mons summit, and airborne Martian dust is still present. Although the average Martian surface atmospheric pressure is less than one percent of Earth's, the much lower gravity on Mars increases the atmosphere's scale height; in other words, Mars's atmosphere is expansive and does not drop off in density with height as sharply as Earth's.
Olympus Mons is an unlikely landing location for automated space probes in the near future. The high elevations preclude parachute-assisted landings because of insufficient atmospheric thickness to slow the spacecraft down. Moreover, Olympus Mons stands in one of the dustiest regions of Mars. A mantle of fine dust covers much of the terrain, obscuring the underlying bedrock (rock samples might be hard to come by). The dust layer would also likely cause severe maneuvering problems for rovers.
Geology.
Olympus Mons is the result of many thousands of highly fluid, basaltic lava flows that poured from volcanic vents over a long period of time. (The Hawaiian Islands exemplify similar shield volcanoes on a smaller scale – see Mauna Kea.) The extraordinary size of Olympus Mons is likely because Mars lacks mobile tectonic plates. Unlike on Earth, the crust of Mars remains fixed over a stationary hotspot, and a volcano can continue to discharge lava until it reaches an enormous height.
The flanks of Olympus Mons are made up of innumerable lava flows and lava channels. Many of the flows have levees along their margins (pictured). Levees are parallel ridges formed at the edges of lava flows. The cooler, outer margins of the flow solidify, leaving a central trough of molten, flowing lava. Partially collapsed lava tubes are visible as chains of pit craters, and broad lava fans formed by lava emerging from intact, subsurface tubes are also common. In places along the volcano's base, lava flows can be seen spilling out into the surrounding plains, forming broad aprons, and burying the basal escarpment. (Note: Lava flows refer to both actively flowing lava and the solidified landforms they produce. The meaning here is the latter, since Mars has no active lava flows at the present time.) Crater counts from high-resolution images taken by the Mars Express orbiter in 2004 indicate that lava flows on the northwestern flank of Olympus Mons range in age from 115 million years old (Mya) to only 2 Mya. These ages are very recent in geological terms, suggesting that the mountain may still be volcanically active, though in a very quiescent and episodic fashion.
The caldera complex at the peak of the volcano is made of at least six overlapping calderas and caldera segments (pictured). Calderas are formed by roof collapse following depletion and withdrawal of the subsurface magma chamber after an eruption. Each caldera thus represents a separate pulse of volcanic activity on the mountain. The largest and oldest caldera segment appears to have formed as a single, large lava lake. The size of a caldera is a reflection of the size of the underlying magma chamber. Using geometric relationships of caldera dimensions from laboratory models, scientists have estimated that the magma chamber associated with the largest caldera on Olympus Mons lies at a depth of about 32 km below the caldera floor. Crater size-frequency distributions on the caldera floors indicate the calderas range in age from 350 Mya to about 150 Mya. All probably formed within 100 million years of each other.
Olympus Mons is asymmetrical structurally as well as topographically. The longer, more shallow northwestern flank displays extensional features, such as large slumps and normal faults. In contrast, the volcano's steeper southeastern side has features indicating compression. They include step-like terraces in the volcano's mid-flank region (interpreted as thrust faults) and a number of wrinkle ridges located at the basal escarpment. Why opposite sides of the mountain should show different styles of deformation is puzzling. The answer may lie in understanding how large shield volcanoes grow laterally and on how variations within the substrate of the volcano affect the final shape of the mountain.
Large shield volcanoes grow not only by adding material to their flanks as erupted lava, but also by spreading laterally at their bases. As a volcano grows in size, the stress field underneath the volcano changes from compressional to extensional. A subterranean rift may develop at the base of the volcano, causing the underlying crust to spread apart. If the volcano rests on sediments containing mechanically weak layers (e.g., beds of water-saturated clay), detachment zones (decollements) may develop in the weak layers. The extensional stresses in the detachment zones can produce giant landslides and normal faults on the volcano's flanks, leading to the formation of a basal escarpment. Further from the volcano, these detachment zones can express themselves as a succession of overlapping, gravity driven thrust faults. This mechanism has long been cited as an explanation of the Olympus Mons aureole deposits (discussed below).
Olympus Mons lies at the edge of the Tharsis bulge, a vast volcanic plateau that is very ancient. The formation of Tharsis was likely complete by the end of the Noachian Period. At the time Olympus Mons began to form in Hesperian times, the volcano was located on a shallow slope that descended from the high in Tharsis into the northern lowland basins. Over time, these basins would have received large volumes of sediment eroded from Tharsis and the southern highlands. The sediments likely contained abundant Noachian-aged phyllosilicates (clays) formed during an early period on Mars when surface water was abundant. The sediments would be thickest in the northwest where basin depth was greatest. As the volcano grew through lateral spreading, low-friction detachment zones preferentially developed in the thicker sediment layers to the northwest, creating the basal escarpment and widespread lobes of aureole material (Lycus Sulci). Spreading also occurred to the southeast; however, it was more constrained in that direction by the Tharsis rise, which presented a higher-friction zone at the volcano's base. Friction was higher in that direction because the sediments were thinner and probably consisted of coarser grained material resistant to sliding. The competent and rugged basement rocks of Tharsis acted as an additional source of friction. Thus, basal spreading of Olympus Mons was inhibited in the southeast direction, accounting for the structural and topographic asymmetry of the mountain. Numerical models of particle dynamics involving lateral differences in friction along the base of Olympus Mons have been shown to reproduce the volcano's present shape and asymmetry fairly well.
The detachment along the weak layers was likely aided by the presence of high-pressure water in the sediment pore spaces. This possibility has interesting astrobiological implications. If water-saturated zones still exist in sediments under the volcano, they would likely have been kept warm by a high geothermal gradient and residual heat from the volcano's magma chamber. Potential springs or seeps around the volcano would offer exciting possibilities for detecting microbial life.
Early observations and naming.
Olympus Mons and a few other volcanoes in the Tharsis region stand high enough to reach above the frequent Martian dust-storms recorded by telescopic observers as early as the 19th century. The astronomer Patrick Moore pointed out that Schiaparelli (1835–1910) "had found that his "Nodus Gordis" and "Olympic Snow" [Nix Olympica] were almost the only features to be seen" during dust storms, and "guessed correctly that they must be high".
The Mariner 9 spacecraft arrived in orbit around Mars in 1971 during a global dust-storm. The first objects to become visible as the dust began to settle, the tops of the Tharsis volcanoes, demonstrated that the altitude of these features greatly exceeded that of any mountain found on Earth, as astronomers expected. Observations of the planet from Mariner 9 confirmed that Nix Olympica was not just a mountain, but a volcano. Ultimately, astronomers adopted the name "Olympus Mons" for the albedo feature known as Nix Olympica.
Regional setting and surrounding features.
Olympus Mons is located between the northwestern edge of the Tharsis region and the eastern edge of Amazonis Planitia. It stands about 1200 km from the other three large Martian shield volcanoes, collectively called the Tharsis Montes (Arsia Mons, Pavonis Mons, and Ascraeus Mons). The Tharsis Montes are slightly smaller than Olympus Mons.
A wide, annular depression or moat about 2 km deep surrounds the base of Olympus Mons and is thought to be due to the volcano's immense weight pressing down on the Martian crust. The depth of this depression is greater on the northwest side of the mountain than on the southeast side.
Olympus Mons is partially surrounded by a region of distinctive grooved or corrugated terrain known as the Olympus Mons aureole. The aureole consists of several large lobes. Northwest of the volcano, the aureole extends a distance of up to 750 km and is known as Lycus Sulci (). East of Olympus Mons, the aureole is partially covered by lava flows, but where it is exposed it goes by different names (Gigas Sulci, for example). The origin of the aureole remains debated, but it was likely formed by huge landslides or gravity-driven thrust sheets that sloughed off the edges of the Olympus Mons shield.

</doc>
<doc id="22820" url="http://en.wikipedia.org/wiki?curid=22820" title="Odobenidae">
Odobenidae

Odobenidae is a family of Pinnipeds. The only living species is the walrus.
In the past, however, the group was much more diverse, and includes more than ten fossil genera.
Taxonomy.
All genera, except "Odobenus", are extinct.

</doc>
<doc id="22826" url="http://en.wikipedia.org/wiki?curid=22826" title="Object database">
Object database

An object database (also object-oriented database management system) is a database management system in which information is represented in the form of objects as used in object-oriented programming. Object databases are different from relational databases which are table-oriented. Object-relational databases are a hybrid of both approaches.
Object databases have been considered since the early 1980s.
Overview.
Object-oriented database management systems (OODBMSs) combine database capabilities with object-oriented programming language capabilities.
OODBMSs allow object-oriented programmers to develop the product, store them as objects, and replicate or modify existing objects to make new objects within the OODBMS. Because the database is integrated with the programming language, the programmer can maintain consistency within one environment, in that both the OODBMS and the programming language will use the same model of representation. Relational DBMS projects, by way of contrast, maintain a clearer division between the database model and the application.
As the usage of web-based technology increases with the implementation of Intranets and extranets, companies have a vested interest in OODBMSs to display their complex data. Using a DBMS that has been specifically designed to store data as objects gives an advantage to those companies that are geared towards multimedia presentation or organizations that utilize computer-aided design (CAD).
Some object-oriented databases are designed to work well with object-oriented programming languages such as Delphi, Ruby, Python, Perl, Java, C#, Visual Basic .NET, C++, Objective-C and Smalltalk; others have their own programming languages. OODBMSs use exactly the same model as object-oriented programming languages.
History.
Object database management systems grew out of research during the early to mid-1970s into having intrinsic database management support for graph-structured objects. The term "object-oriented database system" first appeared around 1985. Notable research projects included Encore-Ob/Server (Brown University), EXODUS (University of Wisconsin–Madison), IRIS (Hewlett-Packard), ODE (Bell Labs), ORION (Microelectronics and Computer Technology Corporation or MCC), Vodak (GMD-IPSI), and Zeitgeist (Texas Instruments). The ORION project had more published papers than any of the other efforts. Won Kim of MCC compiled the best of those papers in a book published by The MIT Press.
Early commercial products included Gemstone (Servio Logic, name changed to GemStone Systems), Gbase (Graphael), and Vbase (Ontologic). The early to mid-1990s saw additional commercial products enter the market. These included ITASCA (Itasca Systems), Jasmine (Fujitsu, marketed by Computer Associates), Matisse (Matisse Software), Objectivity/DB (Objectivity, Inc.), ObjectStore (Progress Software, acquired from eXcelon which was originally Object Design), ONTOS (Ontos, Inc., name changed from Ontologic), O2 (O2 Technology, merged with several companies, acquired by Informix, which was in turn acquired by IBM), POET (now from Versant which acquired Poet Software), Versant Object Database ( Corporation), VOSS (Logic Arts) and JADE ( Software Corporation). Some of these products remain on the market and have been joined by new open source and commercial products such as InterSystems Caché.
Object database management systems added the concept of persistence to object programming languages. The early commercial products were integrated with various languages: GemStone (Smalltalk), Gbase (LISP), Vbase (COP) and VOSS (Virtual Object Storage System for Smalltalk). For much of the 1990s, C++ dominated the commercial object database management market. Vendors added Java in the late 1990s and more recently, C#.
Starting in 2004, object databases have seen a second growth period when open source object databases emerged that were widely affordable and easy to use, because they are entirely written in OOP languages like Smalltalk, Java, or C#, such as Versant's db4o (db4objects), DTS/S1 from Obsidian Dynamics and Perst (McObject), available under dual open source and commercial licensing.
Adoption of object databases.
Object databases based on persistent programming acquired a niche in application areas such as
engineering and spatial databases, telecommunications, and scientific areas such as high energy physics and molecular biology.
Another group of object databases focuses on embedded use in devices, packaged software, and real-time systems.
Technical features.
Most object databases also offer some kind of query language, allowing objects to be found using a declarative programming approach. It is in the area of object query languages, and the integration of the query and navigational interfaces, that the biggest differences between products are found. An attempt at standardization was made by the ODMG with the Object Query Language, OQL.
Access to data can be faster because joins are often not needed (as in a tabular implementation of a relational database). This is because an object can be retrieved directly without a search, by following pointers.
Another area of variation between products is in the way that the schema of a database is defined. A general characteristic, however, is that the programming language and the database schema use the same type definitions.
Multimedia applications are facilitated because the class methods associated with the data are responsible for its correct interpretation.
Many object databases, for example Gemstone or VOSS, offer support for versioning. An object can be viewed as the set of all its versions. Also, object versions can be treated as objects in their own right. Some object databases also provide systematic support for triggers and constraints which are the basis of active databases.
The efficiency of such a database is also greatly improved in areas which demand massive amounts of data about one item. For example, a banking institution could get the user's account information and provide them efficiently with extensive information such as transactions, account information entries etc. The Big O Notation for such a database paradigm drops from O(n) to O(1), greatly increasing efficiency in these specific cases.
Standards.
The Object Data Management Group was a consortium of object database and object-relational mapping vendors, members of the academic community, and interested parties. Its goal was to create a set of specifications that would allow for portable applications that store objects in database management systems. It published several versions of its specification. The last release was ODMG 3.0. By 2001, most of the major object database and object-relational mapping vendors claimed conformance to the ODMG Java Language Binding. Compliance to the other components of the specification was mixed. In 2001, the ODMG Java Language Binding was submitted to the Java Community Process as a basis for the Java Data Objects specification. The ODMG member companies then decided to concentrate their efforts on the Java Data Objects specification. As a result, the ODMG disbanded in 2001.
Many object database ideas were also absorbed into and have been implemented in varying degrees in object-relational database products.
In 2005 Cook, Rai, and Rosenberger proposed to drop all standardization efforts to introduce additional object-oriented query APIs but rather use the OO programming language itself, i.e., Java and .NET, to express queries. As a result, Native Queries emerged. Similarly, Microsoft announced Language Integrated Query (LINQ) and DLINQ, an implementation of LINQ, in September 2005, to provide close, language-integrated database query capabilities with its programming languages C# and VB.NET 9.
In February 2006, the Object Management Group (OMG) announced that they had been granted the right to develop new specifications based on the ODMG 3.0 specification and the formation of the Object Database Technology Working Group (ODBT WG). The ODBT WG planned to create a set of standards that would incorporate advances in object database technology (e.g., replication), data management (e.g., spatial indexing), and data formats (e.g., XML) and to include new features into these standards that support domains where object databases are being adopted (e.g., real-time systems). The work of the ODBT WG was suspended in March 2009 when, subsequent to the economic turmoil in late 2008, the ODB vendors involved in this effort decided to focus their resources elsewhere.
In January 2007 the World Wide Web Consortium gave final recommendation status to the XQuery language. XQuery uses XML as its data model. Some of the ideas developed originally for object databases found their way into XQuery, but XQuery is not intrinsically object-oriented. Because of the popularity of XML, XQuery engines compete with object databases as a vehicle for storage of data that is too complex or variable to hold conveniently in a relational database. XQuery also allows modules to be written to provide encapsulation features that have been provided by Object-Oriented systems.
Comparison with RDBMSs.
An object database stores complex data and relationships between data directly, without mapping to relational rows and columns, and this makes them suitable for applications dealing with very complex data. Objects have a many to many relationship and are accessed by the use of pointers. Pointers are linked to objects to establish relationships. Another benefit of an OODBMS is that it can be programmed with small procedural differences without affecting the entire system.

</doc>
<doc id="22827" url="http://en.wikipedia.org/wiki?curid=22827" title="Ovo-lacto vegetarianism">
Ovo-lacto vegetarianism

An ovo-lacto vegetarian (or lacto-ovo vegetarian) is a vegetarian who does not eat any meat, fish, or poultry. A typical ovo-lacto vegetarian diet includes fruits, vegetables, grains, legumes, nuts, seeds, dairy, and egg products. 
Etymology.
The terminology stems from the Latin ' meaning "milk" (as in 'lactation'), ' meaning "egg", and the English term "vegetarian" (see Etymology of vegetarianism for the etymology of "vegetarian"), so as giving the definition of a vegetarian diet containing milk and eggs.
Diet.
In the Western World, ovo-lacto vegetarians are the most common type of vegetarian. Generally speaking, when one uses the term "vegetarian" an ovo-lacto vegetarian is assumed. Ovo-lacto vegetarians are often well-catered to in restaurants and shops, especially in some parts of Europe and metropolitan cities in North America.
Religion.
In Jainism all individuals eat only food materials derived from plant sources. Jainism prohibits causing harm to any animal, even eggs, as hurting a living being is against the values of Jainism.
In Hinduism many individuals are either raised as ovo-lacto vegetarians or lacto vegetarians. The cow is considered sacred in Hinduism.
The Bible Christian Church was a Christian vegetarian sect founded by William Cowherd in 1809. Cowherd was one of the philosophical forerunners of the Vegetarian Society founded in 1847. The Bible Christian Church promoted the use of eggs, dairy and honey as God’s given food per "the promised land flowing with milk and honey" (Exodus 3:8).
Many Seventh-day Adventist followers are lacto-ovo vegetarians. For over 130 years, Seventh-day Adventists have recommended a vegetarian diet which may include milk products and eggs.

</doc>
<doc id="22829" url="http://en.wikipedia.org/wiki?curid=22829" title="Orgy of the Dead">
Orgy of the Dead

Orgy of the Dead is an unrated 1965 film directed by Stephen C. Apostolof under the alias A. C. Stephen. The screenplay was adapted by cult film director Edward D. Wood, Jr from his own novel. It is a combination of horror and erotica, and is something of a transition for Wood, who began as a horror writer and later wrote pornography.
Genre.
The film belongs to the genre of nudie cuties, narrative-based films featuring female nudity. It was an evolution of earlier films, which featured striptease and burlesque shows. These predecessors mostly depicted actual stage performances, sometimes attached to a frame story.
Plot.
The film opens to two muscle-bound men dressed in loincloths approaching a crypt. They open the doors, revealing a coffin. They remove the lid and exit the crypt, then the inhabitant of the coffin (Criswell) sits up to deliver an opening narration. This narration mostly matches the prologue of "Night of the Ghouls" (1959), with one minor variation and an additional line. The phrase "world between the living and the dead" of the original is changed to "void between...". There is also a new line at the end: "A night with the ghouls, the ghouls reborn, from the innermost depths of the world!" The opening credits feature the image of "an immobile young woman clad in gold". The image was probably inspired by a memorable scene of "Goldfinger" (1964).
Following the credits, the camera shifts to a lone Chevrolet Corvair driving down a California desert road. Its passengers Bob (William Bates) and Shirley (Pat Barrington) are arguing over the decision to use this night to search for a cemetery. Bob is a horror writer who hopes that the scene of a cemetery at night will bring him inspiration. The conversation ends when Bob accidentally drives the car off the road and over a cliff.
The next scene opens to a nocturnal image of a fog-shrouded cemetery. The lonely figure of the Emperor (Criswell) walks towards a marble altar, sits, and then summons his "Princess of the Night", the Black Ghoul (Fawn Silver), who appears and bows before him. The Emperor warns that if the night's entertainment fails to please him, he will banish the souls of the entertainers to eternal damnation, indicating that he is an all-powerful demonic being.
As the full moon appears, the Black Ghoul summons the first dancer of the night, a Native American woman (Bunny Glaser). The Black Ghoul explains that this woman loved flames, and that both she and her lovers died in flames. The woman dances and strips before the flames of the cemetery. The Black Ghoul then introduces the second dancer of the night, a street walker in life. While the woman dances, Bob and Shirley make their way to the cemetery and start observing the dance from a distance. Shirley suspects that they are observing a college initiation, though Bob seriously doubts her theory.
The Emperor himself summons the third dancer, a woman who worshiped gold above else. The Golden Girl (Pat Barrington) dances in her turn, and the Emperor instructs his loin-clothed servants to reward her with gold. The supposed reward is soon revealed to be a punishment, as the servants place her in a cauldron with liquid gold. What emerges from the cauldron is a golden statue of the living woman who entered. The servants transport the immobile statue to a nearby crypt.
At this point, a werewolf (John Andrews) and mummy (Louis Ojena) appear and seize the intruding young couple. They are brought before the Emperor who decides to postpone deciding their fate. The intruders are tied up, side by side, and allowed to continue watching the dances. The Black Ghoul next introduces the fourth dancer, a "Cat Woman" (Texas Starr). She is depicted as a woman dressed in a leopard costume, which exposes her chest area. As she dances, a servant follows her around and thrashes her with a bullwhip. Offering a sadomasochistic show for the spectators.
The Emperor next calls for a Slave Girl (Nadejda Dobrev) to be whipped for his amusement. The slave wears a tunic and is chained to a wall. Following her torture session, the Slave Girl breaks free and becomes the fifth dancer of the night. Later, the Black Ghoul exhibits a fascination with Shirley and scratches a mark on her. She draws a knife and seems about to kill Shirley, when the Emperor decides it is not yet time for the intruders to properly join them. The female ghoul reluctantly obeys.
The Emperor is puzzled when a human skull appears instead of the next dancer. The Black Ghoul explains it is the symbol of the sixth dancer, who loved bullfighting and matadors. She used to dance over their demise, and now it's time to dance over her own. The dancer of apparent Spanish/Mexican heritage (Stephanie Jones) appears to perform. The Emperor and Ghoul briefly discuss the past of the dancer, who came to them on the Day of the Dead. The seventh dancer appears dressed in Polynesian garments. The Black Ghoul describes her as a worshiper of snakes, smoke, and flames. A rattlesnake is depicted along with her dance. The camera shifts to the mummy and the werewolf. The mummy voices his dislike of snakes and recalls the death of Cleopatra. He informs his companion that ancient Egypt had many snakes and they were the stuff of nightmares.
The Emperor next expresses his boredom and demands "unusual" entertainment, while the Black Ghoul notes that the night is almost over. She reminds her superior that they will be gone at the first sight of the morning sun. They proceed to argue over the fate of Shirley. The argument ends with the introduction of the eighth dancer (Barbara Nordin), a woman who murdered her husband on their wedding night. She dances with the skeleton of her spouse. The argument over Shirley then resumes, as the Ghoul claims her for her own. The Emperor feels the need to assert his own authority over the Black Ghoul.
The ninth dancer (Dene Starnes) was a zombie in life and remains zombie-like in death. The tenth and final dancer (Rene De Beau) is introduced as one who died for feathers, fur, and fluff. She starts her dance in clothing matching this style. When the final dance ends, the Emperor finally offers Shirley to the Ghoul. The Ghoul briefly dances herself as she prepares to claim her prize. But dawn arrives and with it sunlight. The Emperor and all his undead are reduced to bones. The final scene has Bob and Shirley waking up at the scene of the accident, surrounded by paramedics, suggesting it was all a dream. Criswell appears in his coffin to offer parting words to the audience.
Production and casting.
The film's graveyard prologue is a recreation of the opening scene from Ed Wood's then-unreleased 1958 film "Night of the Ghouls". Criswell reprises his role from the earlier film. The action begins when a young couple, Bob (William Bates) and Shirley (sexploitation actress Pat Barrington, billed as Pat Barringer) survive a car crash only to find themselves tied to posts in a misty cemetery where they are forced to watch dead spirits dance for the Emperor of the Night played by Criswell (best known for "Plan 9 From Outer Space"). Ten striptease performances by topless dancers from beyond the grave outfitted in various motifs comprise most of this movie. The Wolf Man (wearing a very obvious mask) and The Mummy are also tossed in for comic relief. Barrington doubles as the blond Gold Girl (inspired by Shirley Eaton in "Goldfinger") while her red-headed "Shirley" character watches her perform. Criswell's undead consort, the sexy Black Ghoul, was written for Maila Nurmi, a.k.a. Vampira, but was instead played by Fawn Silver, who wore a black bouffant wig.
Wood served as writer, production manager, casting agent, and even held up cue cards on this low-budget film, although he did not direct. An article on the making of this film was published in "Femme Fatales", 7:1 (June 1998).
The cape worn by Criswell as The Emperor is the same cape worn by Bela Lugosi as Count Dracula in Bud Abbott Lou Costello Meet Frankenstein (1948). 
The film based on the novel by Edward D. Wood Jr. has no werewolf character, like in the film. Wood received $600 for the novel.
The Black Ghoul appears to have "pasty white skin", with red fingernails and lipstick. She wears a black dress, implying the role of a funerary garment. Black, red, and white are the main colors associated with her.

</doc>
<doc id="22830" url="http://en.wikipedia.org/wiki?curid=22830" title="Ostwald process">
Ostwald process

The Ostwald process is a chemical process for making nitric acid (HNO3). Wilhelm Ostwald developed the process, and he patented it in 1902. The Ostwald process is a mainstay of the modern chemical industry, and it provides the main raw material for the most common type of fertilizer production. Historically and practically, the Ostwald process is closely associated with the Haber process, which provides the requisite raw material, ammonia (NH3).
Description.
Ammonia is converted to nitric acid in 2 stages. It is oxidized (in a sense "burnt") by heating with oxygen in the presence of a catalyst such as platinum with 10% rhodium, to form nitric oxide and water. This step is strongly exothermic, making it a useful heat source once initiated:
Stage two encompasses two reactions and is carried out in an absorption apparatus containing water. Initially nitric oxide is oxidized again to yield nitrogen dioxide: This gas is then readily absorbed by the water, yielding the desired product (nitric acid, albeit in a dilute form), while reducing a portion of it back to nitric oxide:
The NO is recycled, and the acid is concentrated to the required strength by distillation.
Alternatively, if the last step is carried out in air:
Typical conditions for the first stage, which contribute to an overall yield of about 98%, are:
A complication that needs to be taken into consideration involves a side-reaction in the first step that reverts the nitric oxide back to N2:
This is a secondary reaction that is minimised by reducing the time the gas mixtures are in contact with the catalyst.

</doc>
<doc id="22831" url="http://en.wikipedia.org/wiki?curid=22831" title="Oliver Heaviside">
Oliver Heaviside

Oliver Heaviside FRS (; 18 May 1850 – 3 February 1925) was a self-taught English electrical engineer, mathematician, and physicist who adapted complex numbers to the study of electrical circuits, invented mathematical techniques for the solution of differential equations (later found to be equivalent to Laplace transforms), reformulated Maxwell's field equations in terms of electric and magnetic forces and energy flux, and independently co-formulated vector analysis. Although at odds with the scientific establishment for most of his life, Heaviside changed the face of telecommunications, mathematics, and science for years to come.
Biography.
Early years.
Heaviside was born at 55 Kings Street (now Plender Street) in London's Camden Town. He was short and red-headed, and suffered from scarlet fever when young, which left him with a hearing impairment. A small legacy enabled the family to move to a better part of Camden when he was thirteen and he was sent to Camden House Grammar School. He was a good student (e.g. placed fifth out of five hundred students in 1865) but his parents couldn't keep him at school after he was 16 so he continued studying for a year by himself and had no further formal education.
Heaviside's uncle by marriage was Sir Charles Wheatstone (1802–1875), the original co-inventor of the first commercially successful telegraph in the mid-1830s, and an internationally celebrated expert in telegraphy and electromagnetism. Wheatstone took a strong interest in his nephew's education and in 1867 sent him north to work with his older brother Arthur who was managing one of Wheatstone's telegraph companies in Newcastle-upon-Tyne.
Two years later he took a job as a telegraph operator with the Danish Great Northern Telegraph Company laying a cable from Newcastle to Denmark using British contractors, soon becoming an electrician. Heaviside continued to study while working, and by the age of 22 he published an article in the prestigious Philosophical Magazine on "The Best Arrangement of Wheatstone's Bridge for measuring a Given Resistance with a Given Galvanometer and Battery" which received positive comments from physicists who had unsuccessfully tried to solve this algebraic problem, including Sir William Thomson, to whom he gave a copy of the paper, and James Clerk Maxwell. However, when he published an article on the duplex method of using a telegraph cable, he poked fun at R. S. Culley, the engineer in chief of the Post Office telegraph system who had been dismissing duplex as impractical. Later in 1873 his application to join the Society of Telegraph Engineers was turned down with the comment that "they didn't want telegraph clerks". This riled Heaviside who asked Thomson to sponsor him, and with the support also of the president he was admitted "despite the P.O. snobs".
In 1873 Heaviside had encountered Maxwell's newly published, and today famous, two-volume "Treatise on Electricity and Magnetism". In his old age Heaviside recalled:
I remember my first look at the great treatise of Maxwell's when I was a young man... I saw that it was great, greater and greatest, with prodigious possibilities in its power... I was determined to master the book and set to work. I was very ignorant. I had no knowledge of mathematical analysis (having learned only school algebra and trigonometry which I had largely forgotten) and thus my work was laid out for me. It took me several years before I could understand as much as I possibly could. Then I set Maxwell aside and followed my own course. And I progressed much more quickly... It will be understood that I preach the gospel according to my interpretation of Maxwell.
Doing research from home, he helped develop transmission line theory (also known as the "telegrapher's equations"). Heaviside showed mathematically that uniformly distributed inductance in a telegraph line would diminish both attenuation and distortion, and that, if the inductance were great enough and the insulation resistance not too high, the circuit would be distortionless while currents of all frequencies would have equal speeds of propagation. Heaviside's equations helped further the implementation of the telegraph.
Middle years.
From 1882 to 1902, except for three years, he contributed regular articles to the trade paper "The Electrician", which wished to improve its standing, for which he was paid £40 per year. This was hardly enough to live on, but his demands were very small and he was doing what he most wanted to. Between 1883 and 1887 these averaged 2–3 articles per month and these articles later formed the bulk of his "Electromagnetic Theory" and "Electrical Papers".
In 1880, Heaviside researched the skin effect in telegraph transmission lines. That same year he patented, in England, the coaxial cable. In 1884 he recast Maxwell's mathematical analysis from its original cumbersome form (they had already been recast as quaternions) to its modern vector terminology, thereby reducing twelve of the original twenty equations in twenty unknowns down to the four differential equations in two unknowns we now know as Maxwell's equations. The four re-formulated Maxwell's equations describe the nature of static and moving electric charges and magnetic dipoles, and the relationship between the two, namely electromagnetic induction.
Between 1880 and 1887, Heaviside developed the operational calculus (involving the "D" notation for the differential operator, which he is credited with creating), a method of solving differential equations by transforming them into ordinary algebraic equations which caused a great deal of controversy when first introduced, owing to the lack of rigour in his derivation of it. He famously said, "Mathematics is an experimental science, and definitions do not come first, but later on." He was replying to criticism over his use of operators that were not clearly defined. On another occasion he stated somewhat more defensively, "I do not refuse my dinner simply because I do not understand the process of digestion."
In 1887, Heaviside worked with his brother Arthur on a paper entitled "The Bridge System of Telephony". However the paper was blocked by Arthur's superior, William Henry Preece of the Post Office, because part of the proposal was that loading coils (inductors) should be added to telephone and telegraph lines to increase their self-induction and correct the distortion which they suffered. Preece had recently declared self-inductance to be the great enemy of clear transmission. Heaviside was also convinced that Preece was behind the sacking of the editor of "The Electrician" which brought his long-running series of articles to a halt (until 1891). There was a long history of animosity between Preece and Heaviside. Heaviside considered Preece to be mathematically incompetent; an assessment supported by the biographer Paul J. Nahin: "Preece was a powerful government official, enormously ambitious, and in some remarkable ways, an utter blockhead." Preece's motivations in suppressing Heaviside's work were more to do with protecting Preece's own reputation and avoiding having to admit error than any perceived faults in Heaviside's work.
The importance of Heaviside's work remained undiscovered for some time after publication in "The Electrician", and so its rights lay in the public domain. In 1897, AT&T employed one of its own scientists, George A. Campbell, and an external investigator Michael I. Pupin to find some respect in which Heaviside's work was incomplete or incorrect. Campbell and Pupin extended Heaviside's work, and AT&T filed for patents covering not only their research, but also the technical method of constructing the coils previously invented by Heaviside. AT&T later offered Heaviside money in exchange for his rights; it is possible that the Bell engineers' respect for Heaviside influenced this offer. However, Heaviside refused the offer, declining to accept any money unless the company were to give him full recognition. Heaviside was chronically poor, making his refusal of the offer even more striking.
But this setback had the effect of turning Heaviside's attention towards electromagnetic radiation, and in two papers of 1888 and 1889, Heaviside calculated the deformations of electric and magnetic fields surrounding a moving charge, as well as the effects of it entering a denser medium. This included a prediction of what is now known as Cherenkov radiation, and inspired his friend George FitzGerald to suggest what now is known as the Lorentz–FitzGerald contraction.
In 1889, Heaviside first published a correct derivation of the magnetic force on a moving charged particle, which is now called the Lorentz Force.
In the late 1880s and early 1890s, Heaviside worked on the concept of electromagnetic mass. Heaviside treated this as material mass, capable of producing the same effects. Wilhelm Wien later verified Heaviside's expression (for low velocities).
In 1891 the British Royal Society recognized Heaviside's contributions to the mathematical description of electromagnetic phenomena by naming him a Fellow of the Royal Society, and the following year devoting more than fifty pages of the "Philosophical Transactions" of the Society to his vector methods and electromagnetic theory. In 1905 Heaviside was given an honorary doctorate by the University of Göttingen.
Later years and views.
In 1896, Fitzgerald and John Parry obtained a civil list pension of £120 per year for Heaviside, who was now living in Devon, and persuaded him to accept it, after he had rejected other charitable offers from the Royal Society.
In 1902, Heaviside proposed the existence of what is now known as the Kennelly–Heaviside layer of the ionosphere. Heaviside's proposal included means by which radio signals are transmitted around the Earth's curvature. The existence of the ionosphere was confirmed in 1923. The predictions by Heaviside, combined with Planck's radiation theory, probably discouraged further attempts to detect radio waves from the Sun and other astronomical objects. For whatever reason, there seem to have been no attempts for 30 years, until Jansky's development of radio astronomy in 1932.
In later years his behavior became quite eccentric. According to associate B. A. Behrend, he became a recluse who was so averse to meeting people that he delivered the manuscripts of his "Electrician" papers to a grocery store, where the editors picked them up. Though he had been an active cyclist in his youth, his health seriously declined in his sixth decade. During this time Heaviside would sign letters with the initials "W.O.R.M."" after his name. Heaviside also reportedly started painting his fingernails pink and had granite blocks moved into his house for furniture. In 1922, he became the first recipient of the Faraday Medal, which was established that year.
On Heaviside's religious views, he was a Unitarian, but not a religious one. He was even said to have made fun of people who put their faith on a supreme being.
Heaviside died at Torquay in Devon, and is buried near the eastern corner of Paignton cemetery. He is buried with his father, Thomas Heaviside and his mother, Rachel Elizabeth Heaviside. The gravestone was cleaned thanks to an anonymous donor sometime in 2005. Most of his recognition was gained posthumously.
Heaviside Memorial Project.
In July 2014, academics at Newcastle University, UK and the Newcastle Electromagnetics Interest Group founded the Heaviside Memorial Project in a bid to fully restore the monument through public subscription. The restored memorial was ceremonially unveiled on 30 August 2014 by Alan Heather, a distant relative of Heaviside. The unveiling was attended by the Mayor of Torbay, the MP for Torbay, an ex-curator of the Science Museum (representing the Institution of Engineering and Technology), the Chairman of the Torbay Civic Society, and delegates from Newcastle University.
Innovations and discoveries.
Heaviside did much to develop and advocate vector methods and the vector calculus. Maxwell's formulation of electromagnetism consisted of 20 equations in 20 variables. Heaviside employed the curl and divergence operators of the vector calculus to reformulate 12 of these 20 equations into four equations in four variables (B, E, J, and ρ), the form by which they have been known ever since (see Maxwell's equations). Less well known is that Heaviside's equations and Maxwell's are not exactly the same, and in fact it is easier to modify the latter to make them compatible with quantum physics.
He invented the Heaviside step function and employed it to model the current in an electric circuit. He invented the operator method for solving linear differential equations, which resembles current Laplace transform methods (see inverse Laplace transform, also known as the "Bromwich integral"). The UK mathematician Thomas John I'Anson Bromwich later devised a rigorous mathematical justification for Heaviside's operator method.
Heaviside advanced the idea that the Earth's uppermost atmosphere contained an ionized layer known as the ionosphere; in this regard, he predicted the existence of what later was dubbed the Kennelly–Heaviside layer. In 1945 Edward Victor Appleton received the Nobel Prize in Physics for proving that this layer really existed. Heaviside developed the transmission line theory (also known as the "telegrapher's equations"), which had the effect of increasing the transmission rate over transatlantic cables by a factor of ten. It originally took ten minutes to transmit each character, and this immediately improved to one character per minute. Closely related to this was his discovery that telephone transmission could be greatly improved by placing electrical inductance in series with the cable. Heaviside also independently discovered the Poynting vector.
Electromagnetic terms.
Heaviside coined the following terms of art in electromagnetic theory:
Further reading.
Sorted by date.

</doc>
<doc id="22832" url="http://en.wikipedia.org/wiki?curid=22832" title="Book of Omni">
Book of Omni

The Book of Omni is one of the books that make up the "Book of Mormon". The book contains only one chapter although it covers more than two centuries of Nephite history (from "ca" 323 BC to 130 BC, according to footnotes).
The record passes from generation to generation.
Nephi, who wrote First and Second Nephi forged the record, a book written on sheets, or plates of gold.
Nephi passed them to his brother Jacob,
Jacob passed them to his son Enos,
Enos passed them to his son Jarom,
Jarom passes them to his son Omni.
In the Book of Omni, we find that:
Omni passes them to his son Amaron, ()
Amaron passes them to his brother Chemish, ()
Chemish passes them to his son Abinadom, ()
Abinadom passes them to his son Amaleki ().
The moral and general civilizational decline of the Nephites is reflected in the fact that with the exception of Abinadom who writes slightly more than his father Chemish, each successive author from Nephi to Abinadom writes less than his predecessor. The final author of the Book of Omni and the Small Plates of Nephi, Amaleki, breaks this general rule. Much like Mormon (who may have taken Amaleki as his model), this last historian of the civilization that lasted for 400 years in the land of Nephi rose to the occasion and, filled with a sense of longing for what has been lost, eloquently recounted the last days of the Nephite people in their ancestral homeland, the land of Nephi.
Narrative.
The initial author was Omni, but several others were charged with keeping the record as time passed, though few made significant contributions. Verse 5 explains that "the more wicked part of the Nephites were destroyed." There is little detail about the destruction, except to say that the Lord did visit them in great judgment because of their wickedness.
Abinadom speaks of many wars between the people of Nephi and the Lamanites.
Amaleki speaks of the then current Nephite king, named Mosiah. As had happened previously, the Lord told the king (who appears to be a spiritual leader [prophet] as well as a secular leader) to lead the righteous Nephites out of the land of Nephi, their ancestral home for the previous 400 years, to a new place. At the end of their journey they discover the Mulekite people whose ancestors had also come from Jerusalem, but after it was attacked by the Babylonians. These people, however, did not bring religious or historical records with them which had two results—they had lost their religion, and they were unable to preserve their language from generation to generation. These people are known as the people of Zarahemla (the name of their then current king and also the name given to the land). Mosiah arranges for the people of Zarahemla to be taught the Nephite language, and Zarahemla is able to recount to him their oral history.
The two groups of people united themselves with Mosiah as their king, and they are all known as Nephites.
The first mention of the Jaredites is found here as well. A large stone is found with writing on it. Mosiah is able to "interpret the engravings by the gift and power of God." It tells of a man named Coriantumr and the downfall of his people. Their history is recounted more fully in the Book of Ether.
Mosiah, the king dies and his son, Benjamin, becomes king. There is a war between the Nephites led by Benjamin and the Lamanites, which by this time is nothing new.
It is apparent that many of the Nephites were reluctant to leave their long-time homeland. Ameliki describes how some of the Nephites wished to return to the land of Nephi, apparently in an attempt to reclaim it. At the time Ameliki stops writing, he has not received word of them, including his brother who is among them.
Amaleki closes with some words about Christ, asserting that his words are true and that it is his intent to help others come unto Christ. He states at the close of the book that, having no descendants to carry on the record-keeping, he will give the records to King Benjamin.
The plates.
The Book of Omni is notable also for being the last of the books contained on the Small Plates of Nephi, one of two major divisions of the gold plates which Joseph Smith, Jr. translated to obtain the Book of Mormon.
From First Nephi to the end of Omni, the book is a first person narrative of the writers (although there are many quotations). The book immediately following Omni, the Words of Mormon, is an editorial insertion that explains how the first first person narrative came to be inserted into the Book of Mormon and how subsequent narrative will differ, being mostly third person narration by Mormon that summarizes more lengthy accounts taken from the Large Plates of Nephi. This third person record extends from Mosiah to Fourth Nephi.

</doc>
<doc id="22834" url="http://en.wikipedia.org/wiki?curid=22834" title="Ozone layer">
Ozone layer

The ozone layer or ozone shield refers to a region of Earth's stratosphere that absorbs most of the Sun's ultraviolet (UV) radiation. It contains high concentrations of ozone (O3) relative to other parts of the atmosphere, although still very small relative to other gases in the stratosphere. The ozone layer contains less than 10 parts per million of ozone, while the average ozone concentration in Earth's atmosphere as a whole is only about 0.3 parts per million. The ozone layer is mainly found in the lower portion of the stratosphere, from approximately 20 to above Earth, though the thickness varies seasonally and geographically.
The ozone layer was discovered in 1913 by the French physicists Charles Fabry and Henri Buisson. Its properties were explored in detail by the British meteorologist G. M. B. Dobson, who developed a simple spectrophotometer (the Dobsonmeter) that could be used to measure stratospheric ozone from the ground. Between 1928 and 1958, Dobson established a worldwide network of ozone monitoring stations, which continue to operate to this day. The "Dobson unit", a convenient measure of the amount of ozone overhead, is named in his honor.
The ozone layer absorbs 97–99% of the Sun's medium-frequency ultraviolet light (from about 200 nm to 315 nm wavelength), which otherwise would potentially damage exposed life forms near the surface.
The United Nations General Assembly has designated September 16 as the International Day for the Preservation of the Ozone Layer.
Sources.
The photochemical mechanisms that give rise to the ozone layer were discovered by the British physicist Sydney Chapman in 1930. Ozone in the Earth's stratosphere is created by ultraviolet light striking ordinary oxygen molecules containing two oxygen atoms (O2), splitting them into individual oxygen atoms (atomic oxygen); the atomic oxygen then combines with unbroken O2 to create ozone, O3. The ozone molecule is unstable (although, in the stratosphere, long-lived) and when ultraviolet light hits ozone it splits into a molecule of O2 and an individual atom of oxygen, a continuing process called the ozone-oxygen cycle.
Chemically, this can be described as:
About 90% of the ozone in our atmosphere is contained in the stratosphere. Ozone concentrations are greatest between about 20 and, where they range from about 2 to 8 parts per million. If all of the ozone were compressed to the pressure of the air at sea level, it would be only 3 millimeters thick.
Ultraviolet light.
Although the concentration of the ozone in the ozone layer is very small, it is vitally important to life because it absorbs biologically harmful ultraviolet (UV) radiation coming from the sun. Extremely short or vacuum UV (10–100 nm) is screened out by nitrogen. UV radiation capable of penetrating nitrogen is divided into three categories, based on its wavelength; these are referred to as UV-A (400–315 nm), UV-B (315–280 nm), and UV-C (280–100 nm).
UV-C, which is very harmful to all living things, is entirely screened out by a combination of dioxygen (< 200 nm) and ozone (> about 200 nm) by around 35 km altitude. UV-B radiation can be harmful to the skin and is the main cause of sunburn; excessive exposure can also cause cataracts, immune system suppression, and genetic damage, resulting in problems such as skin cancer. The ozone layer (which absorbs from about 200 nm to 310 nm with a maximal absorption at about 250 nm) is very effective at screening out UV-B; for radiation with a wavelength of 290 nm, the intensity at the top of the atmosphere is 350 million times stronger than at the Earth's surface. Nevertheless, some UV-B, particularly at its longest wavelengths, reaches the surface, and is important for the skin's production of vitamin D.
Ozone is transparent to most UV-A, so most of this longer-wavelength UV radiation reaches the surface, and it constitutes most of the UV reaching the Earth. This type of UV radiation is significantly less harmful to DNA, although it may still potentially cause physical damage, premature aging of the skin, indirect genetic damage, and skin cancer.
Distribution in the stratosphere.
The thickness of the ozone layer—that is, the total amount of ozone in a column overhead—varies by a large factor worldwide, being in general smaller near the equator and larger towards the poles. It also varies with season, being in general thicker during the spring and thinner during the autumn. The reasons for this latitude and seasonal dependence are complicated, involving atmospheric circulation patterns as well as solar intensity.
Since stratospheric ozone is produced by solar UV radiation, one might expect to find the highest ozone levels over the tropics and the lowest over polar regions. The same argument would lead one to expect the highest ozone levels in the summer and the lowest in the winter. The observed behavior is very different: most of the ozone is found in the mid-to-high latitudes of the northern and southern hemispheres, and the highest levels are found in the spring, not summer, and the lowest in the autumn, not winter in the northern hemisphere. During winter, the ozone layer actually increases in depth. This puzzle is explained by the prevailing stratospheric wind patterns, known as the Brewer-Dobson circulation. While most of the ozone is indeed created over the tropics, the stratospheric circulation then transports it poleward and downward to the lower stratosphere of the high latitudes. However, owing to the ozone hole phenomenon, the lowest amounts of column ozone found anywhere in the world are over the Antarctic in the southern spring period of September and October and to a lesser extent over the Arctic in the northern spring period of March, April, and May.
The ozone layer is higher in altitude in the tropics, and lower in altitude outside the tropics, especially in the polar regions. This altitude variation of ozone results from the slow circulation that lifts the ozone-poor air out of the troposphere into the stratosphere. As this air slowly rises in the tropics, ozone is produced as the sun overhead photolyzes oxygen molecules. As this slow circulation levels off and flows towards the mid-latitudes, it carries the ozone-rich air from the tropical middle stratosphere to the mid-and-high latitudes lower stratosphere. The high ozone concentrations at high latitudes are due to the accumulation of ozone at lower altitudes.
The Brewer-Dobson circulation moves very slowly. The time needed to lift an air parcel by 1 km in the lower tropical stratosphere is about 2 months (18 m per day). However, horizontal poleward transport in the lower stratosphere is much faster and amounts to approximately 100 km per day in the northern hemisphere whilst it is only half as much in the southern hemisphere (~51 km per day). Even though ozone in the lower tropical stratosphere is produced at a very slow rate, the lifting circulation is so slow that ozone can build up to relatively high levels by the time it reaches 26 km.
Ozone amounts over the continental United States (25°N to 49°N) are highest in the northern spring (April and May). These ozone amounts fall over the course of the summer to their lowest amounts in October, and then rise again over the course of the winter. Again, wind transport of ozone is principally responsible for the seasonal changes of these higher latitude ozone patterns.
The total column amount of ozone generally increases as we move from the tropics to higher latitudes in both hemispheres. However, the overall column amounts are greater in the northern hemisphere high latitudes than in the southern hemisphere high latitudes. In addition, while the highest amounts of column ozone over the Arctic occur in the northern spring (March–April), the opposite is true over the Antarctic, where the lowest amounts of column ozone occur in the southern spring (September–October).
Depletion.
The ozone layer can be depleted by free radical catalysts, including nitric oxide (NO), nitrous oxide (N2O), hydroxyl (OH), atomic chlorine (Cl), and atomic bromine (Br). While there are natural sources for all of these species, the concentrations of chlorine and bromine increased markedly in recent decades due to the release of large quantities of man-made organohalogen compounds, especially chlorofluorocarbons (CFCs) and bromofluorocarbons. These highly stable compounds are capable of surviving the rise to the stratosphere, where Cl and Br radicals are liberated by the action of ultraviolet light. Each radical is then free to initiate and catalyze a chain reaction capable of breaking down over 100,000 ozone molecules. By 2009, nitrous oxide was the largest ozone-depleting substance (ODS) emitted through human activities.
The breakdown of ozone in the stratosphere results in reduced absorption of ultraviolet radiation. Consequently, unabsorbed and dangerous ultraviolet radiation is able to reach the Earth’s surface at a higher intensity. Ozone levels have dropped by a worldwide average of about 4% since the late 1970s. For approximately 5% of the Earth's surface, around the north and south poles, much larger seasonal declines have been seen, and are described as "ozone holes". The discovery of the annual depletion of ozone above the Antarctic was first announced by Joe Farman, Brian Gardiner and Jonathan Shanklin, in a paper which appeared in "Nature" on May 16, 1985.
Regulation.
To support successful regulation attempts, the ozone case was communicated to lay persons "with easy-to-understand bridging metaphors derived from the popular culture" and related to "immediate risks with everyday relevance". The specific metaphors used in the discussion (ozone shield, ozone hole) proved quite useful and, compared to global climate change, was much more seen as an "hot issue" and imminent risk. Lay people were cautious about a depletion of the ozone layer and the risks of skin cancer.
In 1978, the United States, Canada and Norway enacted bans on CFC-containing aerosol sprays that damage the ozone layer. The European Community rejected an analogous proposal to do the same. In the U.S., chlorofluorocarbons continued to be used in other applications, such as refrigeration and industrial cleaning, until after the discovery of the Antarctic ozone hole in 1985. After negotiation of an international treaty (the Montreal Protocol), CFC production was capped at 1986 levels with commitments to long-term reductions. Since that time, the treaty was amended to ban CFC production after 1995 in the developed countries, and later in developing countries. Today, all of the world's 197 countries have signed the treaty. Beginning January 1, 1996, only recycled and stockpiled CFCs were available for use in developed countries like the US. This production phaseout was possible because of efforts to ensure that there would be substitute chemicals and technologies for all ODS uses.
On August 2, 2003, scientists announced that the global depletion of the ozone layer may be slowing down due to the international regulation of ozone-depleting substances. In a study organized by the American Geophysical Union, three satellites and three ground stations confirmed that the upper-atmosphere ozone-depletion rate slowed down significantly during the previous decade. Some breakdown can be expected to continue due to ODSs used by nations which have not banned them, and due to gases which are already in the stratosphere. Some ODSs, including CFCs, have very long atmospheric lifetimes, ranging from 50 to over 100 years. It has been estimated that the ozone layer will recover to 1980 levels near the middle of the 21st century.
Compounds containing C–H bonds (such as hydrochlorofluorocarbons, or HCFCs) have been designed to replace CFCs in certain applications. These replacement compounds are more reactive and less likely to survive long enough in the atmosphere to reach the stratosphere where they could affect the ozone layer. While being less damaging than CFCs, HCFCs can have a negative impact on the ozone layer, so they are also being phased out. These in turn are being replaced by hydrofluorocarbons (HFCs) and other compounds that do not destroy stratospheric ozone at all.

</doc>
<doc id="22841" url="http://en.wikipedia.org/wiki?curid=22841" title="Public Enemy (band)">
Public Enemy (band)

Public Enemy is an American hip hop group consisting of Chuck D, Flavor Flav, DJ Lord, The S1W group, Khari Wynn and Professor Griff. Formed in Long Island, New York in 1982, they are known for their politically charged lyrics and criticism of the American media, with an active interest in the frustrations and concerns of the African American community. Their first four albums during the late 1980s and early 1990s were all certified either gold or platinum and were, according to music critic Robert Hilburn in 1998, "the most acclaimed body of work ever by a rap act." In 2004, "Rolling Stone" magazine ranked Public Enemy number 44 on its list of the Immortals: 100 Greatest Artists of All Time. The group was inducted into the Long Island Music Hall of Fame in 2007. The band were announced as inductees for the 2013 class of the Rock and Roll Hall of Fame on December 11, 2012, making them the fourth hip-hop act to be inducted after Grandmaster Flash and the Furious Five, Run–D.M.C. and The Beastie Boys.
History.
Formation and early years (1982–1986).
Developing his talents as an MC with Flavor Flav while delivering furniture for his father's business, Chuck D (Carlton Douglas Ridenhour) and Spectrum City, as the group was called, released the record "Check Out the Radio", backed by "Lies", a social commentary—both of which would influence RUSH Productions' Run–D.M.C. and Beastie Boys. Chuck D put out a tape to promote WBAU (the radio station where he was working at the time) and to fend off a local MC who wanted to battle him. He called the tape "Public Enemy #1" because he felt like he was being persecuted by people in the local scene. This was the first reference to the notion of a public enemy in any of Chuck D's songs. The single was created by Chuck D with a contribution by Flavor Flav, though this was before the group "Public Enemy" was officially assembled. Around 1986, Bill Stephney, the former Program Director at WBAU, was approached by Ali Hafezi and offered a position with the label. Stephney accepted, and his first assignment was to help fledgling producer Rick Rubin sign Chuck D, whose song "Public Enemy Number One" Rubin had heard from Andre "Doctor Dré" Brown.
According to the book "The History of Rap Music" by Cookie Lommel, "Stephney thought it was time to mesh the hard-hitting style of Run DMC with politics that addressed black youth. Chuck recruited Spectrum City, which included Hank Shocklee, his brother Keith Shocklee, and Eric "Vietnam" Sadler, collectively known as the Bomb Squad, to be his production team and added another Spectrum City partner, Professor Griff, to become the group's Minister of Information. With the addition of Flavor Flav and another local mobile DJ named Terminator X, the group Public Enemy was born." According to Chuck, The S1W, which stands for Security of the First World, "represents that the black man can be just as intelligent as he is strong. It stands for the fact that we're not third-world people, we're first-world people; we're the original people." Public Enemy started out as opening act for the Beastie Boys during the latter's "Licensed to Ill" popularity, and in 1987 released their debut album "Yo! Bum Rush the Show". Over the next few years, Public Enemy released "It Takes a Nation of Millions to Hold Us Back", "Fear of a Black Planet", and "Apocalypse 91… The Enemy Strikes Black". In addition to ushering in the golden age of hip hop, during this time, Public Enemy reached the height of their popularity, adulation, and controversy. The group then separated from Def Jam and has since been independently producing, marketing, and publishing their music.
Mainstream success (1987–1994).
Their debut album, "Yo! Bum Rush the Show", was released in 1987 to critical acclaim. The album was the group's first step toward stardom. In October 1987, music critic Simon Reynolds dubbed Public Enemy "a superlative "rock" band". They released their second album "It Takes a Nation of Millions to Hold Us Back" in 1988, which performed better in the charts than their previous release, and included the hit single "Don't Believe the Hype" in addition to "Bring the Noise". "Nation of Millions..." was the first hip hop album to be voted album of the year in "The Village Voice"‍ '​s influential Pazz & Jop critics' poll.
In 1989, the group returned to the studio to record "Fear of a Black Planet", which continued their politically charged themes. The album was supposed to be released in late 1989, but was pushed back to April 1990. It was the most successful of any of their albums and, in 2005, was selected for preservation in the Library of Congress. It included the singles "Welcome To The Terrordome", "911 Is a Joke", which criticized emergency response units for taking longer to arrive at emergencies in the black community than those in the white community, and "Fight the Power". "Fight the Power" is regarded as one of the most popular and influential songs in hip hop history. It was the theme song of Spike Lee's "Do the Right Thing".
The group's next release, "Apocalypse '91...The Enemy Strikes Black", continued this trend, with songs like "Can't Truss It", which addressed the history of slavery and how the black community can fight back against oppression; "I Don't Wanna be Called Yo Nigga", a track that takes issue with the use of the word "nigga" outside of its original derogatory context. The album also included the controversial song and video "By the Time I Get to Arizona", which chronicled the black community's frustration that some US states did not recognize Martin Luther King Jr.'s birthday as a national holiday. The video featured members of Public Enemy taking out their frustrations on politicians in the states not recognizing the holiday. In 1992, the group was one of the first rap acts to perform at the Reading Festival, in England, headlining the second day of the three day festival.
Terminator X's exit and DJ Lord's entrance (1998–current).
After a 1994 motorcycle accident shattered his left leg and kept him in the hospital for a full month, Terminator X relocated to his 15-acre farm in Vance County, North Carolina. By 1998, he was ready to retire from the group and focus full-time on raising African black ostriches on his farm. In late 1998, the group started looking for Terminator X's permanent replacement. Following several months of searching for a DJ, Professor Griff saw DJ Lord at a Vestax Battle and approached him about becoming the DJ for Public Enemy. DJ Lord joined as the group's full-time DJ just in time for Public Enemy's 40th World Tour. Since 1999, he has been the official DJ for Public Enemy on albums and world tours while winning numerous turntablist competitions, including multiple DMC finals.
In 2007, the group released an album entitled "How You Sell Soul to a Soulless People Who Sold Their Soul?". Public Enemy's single from the album was "Harder Than You Think". Four years after "How You Sell Soul...", in January 2011, Public Enemy released the album "Beats and Places", a compilation of remixes and "lost" tracks. On July 13, 2012, "Most of My Heroes Still Don't Appear on No Stamp" was released and was exclusively available on iTunes. In July 2012, on UK television an advert for the London 2012 Summer Paralympics featured a short remix of the song "Harder Than You Think". The advert caused the song to reach No. 4 in the UK Singles Chart on September 2, 2012. On July 30, 2012, Public Enemy performed a free concert with Salt-N-Pepa and Kid 'n Play at Wingate Park in Brooklyn, New York as part of the Martin Luther King Jr. Concert Series. On August 26, 2012, Public Enemy performed at South West Four music festival in Clapham Common in London. On October 1, 2012 "The Evil Empire of Everything" was released. On June 29, 2013, they performed at Glastonbury Festival 2013. On September 14, 2013 they performed at Riot Fest & Carnival 2013 in Chicago, Illinois. On September 20, 2013 they performed at Riot Fest & Side Show in Byers, Colorado
Legacy.
Terminator X's innovative scratching tricks can be heard on the songs "Rebel Without a Pause", "Night of the Living Baseheads", and "Shut 'Em Down". The Bomb Squad offered up a web of innovative samples and beats. Critic Stephen Thomas Erlewine declared that PE "brought in elements of free jazz, hard funk, even musique concrète, via [its] producing team the Bomb Squad, creating a dense, ferocious sound unlike anything that came before."
Public Enemy made contributions to the hip-hop world with political, social and cultural consciousness, which infused itself into skilled and poetic rhymes, using raucous sound collages as a foundation. Public Enemy held a strong, pro-Black, political stance. Before PE, politically motivated hip-hop was defined by a few tracks by Ice-T, Grandmaster Flash and the Furious Five, and KRS-One. Other politically motivated opinions were shared by prototypical artists Gil Scott-Heron and the Last Poets. PE was a revolutionary hip-hop act, basing an entire image around a specified political stance. With the successes of Public Enemy, many hip-hop artists began to celebrate Afrocentric themes, such as Kool Moe Dee, Gang Starr, X Clan, Eric B. & Rakim, Queen Latifah, the Jungle Brothers, and A Tribe Called Quest.
Public Enemy was one of the first hip-hop groups to do well internationally. PE changed the Internet's music distribution capability by being one of the first groups to release MP3-only albums, a format virtually unknown at the time.
Public Enemy helped to create and define "rap metal" by collaborating with Living Colour in 1988 (Funny Vibe) and New York thrash metal outfit Anthrax in 1991. The single "Bring the Noise" was a mix of semi-militant black power lyrics, grinding guitars, and sporadic humor. The two bands, cemented by a mutual respect and the personal friendship between Chuck D and Anthrax's Scott Ian, introduced a hitherto alien genre to rock fans, and the two seemingly disparate groups toured together. Flavor Flav's pronouncement on stage that "They said this tour would never happen" (as heard on Anthrax's "Live: The Island Years" CD) has become a legendary comment in both rock and hip-hop circles. Metal guitarist Vernon Reid (of Living Colour) contributed to Public Enemy's recordings, and PE sampled Slayer's "Angel of Death" half-time riff on "She Watch Channel Zero?!"
Members of the Bomb Squad produced or remixed works for other acts, like Bell Biv DeVoe, Ice Cube, Vanessa Williams, Sinéad O'Connor, Blue Magic, Peter Gabriel, L.L. Cool J, Paula Abdul, Jasmine Guy, Jody Watley, Eric B & Rakim, Third Bass, Big Daddy Kane, EPMD, and Chaka Khan. According to Chuck D, "We had tight dealings with MCA Records and were talking about taking three guys that were left over from New Edition and coming up with an album for them. The three happened to be Ricky Bell, Michael Bivins, and Ronnie DeVoe, later to become Bell Biv DeVoe. Ralph Tresvant had been slated to do a solo album for years, Bobby Brown had left New Edition and experienced some solo success beginning in 1988, and Johnny Gill had just been recruited to come in, but [he] had come off a solo career and could always go back to that. At MCA, Hiram Hicks, who was their manager, and Louil Silas, who was running the show, were like, 'Yo, these kids were left out in the cold. Can y'all come up with something for them?' It was a task that Hank, Keith, Eric, and I took on to try to put some kind of hip-hop-flavored R&B shit down for them. Subsequently, what happened in the four weeks of December [1989] was that the Bomb Squad knocked out a large piece of the production and arrangement on Bell Biv DeVoe's three-million selling album "Poison". In January [1990], they knocked out "Fear of a Black Planet" in four weeks, and PE knocked out Ice Cube's album "AmeriKKKa's Most Wanted" in four to five weeks in February." They have also produced local talent such as Son of Bazerk, Young Black Teenagers, Kings of Pressure, and True Mathematics—and gave producer Kip Collins his start in the business.
Poet and hip-hop artist Saul Williams uses a sample from Public Enemy's "Welcome to the Terrordome" in his song "Tr[n]igger" on the "Niggy Tardust" album. He also used a line from the song in his poem, "amethyst rocks".
Public Enemy's brand of politically and socially conscious hip hop has been a direct influence on new hip hop artists such as The Cornel West theory.
The Manic Street Preachers track "Repeat (Stars And Stripes)" is a remix of the band's own anti-monarchy tirade by Public Enemy production team The Bomb Squad of whom James Dean Bradfield and Richey Edwards were big fans. The song samples "Countdown to Armageddon" from It Takes a Nation of Millions to Hold Us Back. The band had previously sampled Public Enemy on their 1991 single Motown Junk.
The influence of the band goes largely beyond hip-hop as the group was cited by artists as diverse as Autechre (selected in the All Tomorrow's Parties (music festival) in 2003), Nirvana (It Takes a Nation of Millions to Hold Us Back being cited by Kurt Cobain among his favorite albums), Nine Inch Nails (mentioned the band in Pretty Hate Machine credits), Björk (included Rebel Without a Pause in her The Breezeblock Mix in July 2007), Tricky (did a cover of Black Steel in the Hour of Chaos and appears in Do You Wanna Go Our Way ??? video), Prodigy (included Public Enemy No. 1 in The Dirtchamber Sessions Volume One), Ben Harper, Underground Resistance (cited by both Mad Mike and Jeff Mills), Orlando Voorn, M.I.A., Amon Tobin, Mathew Jonson and Aphex Twin (Welcome To The Terrordome being the first track played after the introduction at the Coachella festival in April 2008).
In September 2009, VH1 aired a show called "100 Greatest Hip Hop Songs" where Public Enemy earned the number one spot with their hit song, Fight the Power.
In December 2012, the group was announced as one of the inductees to the Rock and Roll Hall of Fame for its 2013 class.
Controversy.
Political activities.
In January, 1987, Arizona governor Evan Mecham canceled a state holiday for Martin Luther King, Jr. on the ground that the holiday had not been properly authorized. In response to this action, the group wrote a song entitled "By the Time I Get to Arizona." In the video for the song, the group was seen assassinating Mecham by planting a bomb underneath his limousine and detonating it by remote control, perhaps intending an analogy or other reference to the 1976 murder of Don Bolles, an investigator reporter for the Arizona Republic newspaper.
Anti-Semitism.
In 1989, in an interview with Public Enemy for the "Washington Times", the interviewing journalist, David Mills, lifted some quotations from a UK magazine in which the band were asked their opinion on the Arab–Israeli conflict. Professor Griff's comments apparently sympathized with the Palestinians and he was accused of anti-Semitism. According to Rap Attack 2, he suggested that "Jews are responsible for the majority of the wickedness in the world" (p. 177). (In turn a quote from" The International Jew") Shortly after, Ridenhour expressed an apology on his behalf. At a June 21, 1989 press conference, Ridenhour announced Griff's dismissal from the group, and a June 28 statement by Russell Simmons, president of Def Jam Recordings and Rush Artists Management, stated that Chuck D. had disbanded Public Enemy "for an indefinite period of time." By August 10, however, Ridenhour denied that he had disbanded the group, and stated that Griff had been re-hired as "Supreme Allied Chief of Community Relations" (in contrast to his previous position with the group as Minister of Information). Griff later denied holding anti-Semitic views and apologized for the remarks. Several people who had worked with Public Enemy expressed concern about Ridenhour's leadership abilities and role as a social spokesman.
In his 2009 book, entitled "Analytixz", Griff criticized his 1989 statement: "to say the Jews are responsible for the majority of wickedness that went on around the globe I would have to know about the majority of wickedness that went on around the globe, which is impossible... I'm not the best knower. Then, not only knowing that, I would have to know who is at the crux of all of the problems in the world and then blame Jewish people, which is not correct." Griff also said that not only were his words taken out of context, but that the recording has never been released to the public for an unbiased listen.
The controversy and apologies on behalf of Griff spurred Chuck D to reference the negative press they were receiving. In 1990, Public Enemy issued the single "Welcome to the Terrordome", which contains the lyrics: "Crucifixion ain't no fiction / So-called chosen frozen / Apologies made to whoever pleases / Still they got me like Jesus". These lyrics have been cited by some in the media as anti-Semitic, making supposed references to the concept of the "chosen people" with the lyric "so-called chosen" and Jewish deicide with the last line.
Homophobia.
In a letter to the editor, Leo Haber alludes to criticism by "New York Times" writer Peter Watrous of the group's supposed homophobia.
Reviewers John Alroy and David Wilson said that "Fear of a Black Planet" contained "homophobic babbling" which challenged politically correct thinking.
Zoe Williams defended Public Enemy against charges of homophobia by stating that:
If you look at the seminal black artists at the start of hip-hop, Public Enemy and Niggaz Wit Attitudes, you won't actually find much homophobia. The only recorded homophobic lyric in Public Enemy's canon was: 'Man to man/ I don't know if they can/ From what I know/ The parts don't fit' [a lyric from "Meet the G that Killed Me" on "Fear of a Black Planet"]".—Williams, Zoe, , "The Guardian", 29 April 2003
Although "Spin" magazine noted that 'It only brings agony, ask James Cagney / He beat up on a guy when he found he was a fagney / Cagney is a favorite he is my boy' from "A Letter to the "New York Post"" on their album "Apocalypse '91" has also been accused of homophobia.
Public Enemy have also been supporters of Nation of Islam Supreme Minister Louis Farrakhan, who has been controversial for his commentary which is often interpreted as being black supremacist, racist, homophobic, and anti-Semitic.
Awards and nominations.
Grammy Awards
American Music Awards
Rock and Roll Hall of Fame
Bibliography.
White, Miles. "Race, Rap and the performance of Mascinity in American Popular Culture". 2011. University of Illinois. Urbana. ISBN 978-0-252-07832-3

</doc>
<doc id="22860" url="http://en.wikipedia.org/wiki?curid=22860" title="Paleolithic">
Paleolithic

The Paleolithic (American spelling; British spelling: Palaeolithic; pronunciation: or ) Age, Era or Period is a prehistoric period of human history distinguished by the development of the most primitive stone tools discovered (Grahame Clark's Modes I and II), and covers roughly 95% of human technological prehistory. It extends from the earliest known use of stone tools, probably by hominins such as australopithecines, 2.6 million years ago, to the end of the Pleistocene around 10,000 BP.
The Paleolithic era is followed by the Mesolithic. The date of the Paleolithic—Mesolithic boundary may vary by locality as much as several thousand years.
During the Paleolithic period, humans grouped together in small societies such as bands, and subsisted by gathering plants and fishing, hunting or scavenging wild animals. The Paleolithic is characterized by the use of knapped stone tools, although at the time humans also used wood and bone tools. Other organic commodities were adapted for use as tools, including leather and vegetable fibers; however, due to their nature, these have not been preserved to any great degree. Surviving artifacts of the Paleolithic era are known as paleoliths. Humankind gradually evolved from early members of the genus "Homo" such as "Homo habilis" – who used simple stone tools – into fully behaviorally and anatomically modern humans ("Homo sapiens)"during the Paleolithic era. During the end of the Paleolithic, specifically the Middle and or Upper Paleolithic, humans began to produce the earliest works of art and engage in religious and spiritual behavior such as burial and ritual. The climate during the Paleolithic consisted of a set of glacial and interglacial periods in which the climate periodically fluctuated between warm and cool temperatures.
The term "Paleolithic" was coined by archaeologist John Lubbock in 1865. It derives from Greek: παλαιός, "palaios", "old"; and λίθος, "lithos", "stone", meaning "old age of the stone" or "Old Stone Age."
Human evolution.
Human evolution is the part of biological evolution concerning the emergence of humans as a distinct species.
Paleogeography and climate.
The Paleolithic Period coincides almost exactly with the Pleistocene epoch of geologic time, which lasted from 2.6 million years ago to about 12,000 years ago. This epoch experienced important geographic and climatic changes that affected human societies.
During the preceding Pliocene, continents had continued to drift from possibly as far as 250 km from their present locations to positions only 70 km from their current location. South America became linked to North America through the Isthmus of Panama, bringing a nearly complete end to South America's distinctive marsupial fauna. The formation of the Isthmus had major consequences on global temperatures, because warm equatorial ocean currents were cut off, and the cold Arctic and Antarctic waters lowered temperatures in the now-isolated Atlantic Ocean. Most of Central America formed during the Pliocene to connect the continents of North and South America, allowing fauna from these continents to leave their native habitats and colonize new areas. Africa's collision with Asia created the Mediterranean Sea, cutting off the remnants of the Tethys Ocean. During the Pleistocene, the modern continents were essentially at their present positions; the tectonic plates on which they sit have probably moved at most 100 km from each other since the beginning of the period.
Climates during the Pliocene became cooler and drier, and seasonal, similar to modern climates. Ice sheets grew on Antarctica. The formation of an Arctic ice cap around three million years ago is signaled by an abrupt shift in oxygen isotope ratios and ice-rafted cobbles in the North Atlantic and North Pacific ocean beds. Mid-latitude glaciation probably began before the end of the epoch. The global cooling that occurred during the Pliocene may have spurred on the disappearance of forests and the spread of grasslands and savannas.
The Pleistocene climate was characterized by repeated glacial cycles during which continental glaciers pushed to the 40th parallel in some places. Four major glacial events have been identified, as well as many minor intervening events. A major event is a general glacial excursion, termed a "glacial". Glacials are separated by "interglacials". During a glacial, the glacier experiences minor advances and retreats. The minor excursion is a "stadial"; times between stadials are "interstadials". Each glacial advance tied up huge volumes of water in continental ice sheets 1500–3000 m deep, resulting in temporary sea level drops of 100 m or more over the entire surface of the Earth. During interglacial times, such as at present, drowned coastlines were common, mitigated by isostatic or other emergent motion of some regions.
The effects of glaciation were global. Antarctica was ice-bound throughout the Pleistocene and the preceding Pliocene. The Andes were covered in the south by the Patagonian ice cap. There were glaciers in New Zealand and Tasmania. The now decaying glaciers of Mount Kenya, Mount Kilimanjaro, and the Ruwenzori Range in east and central Africa were larger. Glaciers existed in the mountains of Ethiopia and to the west in the Atlas mountains. In the northern hemisphere, many glaciers fused into one. The Cordilleran ice sheet covered the North American northwest; the Laurentide covered the east. The Fenno-Scandian ice sheet covered northern Europe, including Great Britain; the Alpine ice sheet covered the Alps. Scattered domes stretched across Siberia and the Arctic shelf. The northern seas were frozen. During the late Upper Paleolithic (Latest Pleistocene) "c." 18,000 BP, the Beringia land bridge between Asia and North America was blocked by ice, which may have prevented early Paleo-Indians such as the Clovis culture from directly crossing Beringa to reach the Americas.
According to Mark Lynas (through collected data), the Pleistocene's overall climate could be characterized as a continuous El Niño with trade winds in the south Pacific weakening or heading east, warm air rising near Peru, warm water spreading from the west Pacific and the Indian Ocean to the east Pacific, and other El Niño markers.
The Paleolithic is often held to finish at the end of the ice age (the end of the Pleistocene epoch), and Earth's climate became warmer. This may have caused or contributed to the extinction of the Pleistocene megafauna, although it is also possible that the late Pleistocene extinctions were (at least in part) caused by other factors such as disease and overhunting by humans. New research suggests that the extinction of the woolly mammoth may have been caused by the combined effect of climatic change and human hunting. Scientists suggest that climate change during the end of the Pleistocene caused the mammoths' habitat to shrink in size, resulting in a drop in population. The small populations were then hunted out by Paleolithic humans. The global warming that occurred during the end of the Pleistocene and the beginning of the Holocene may have made it easier for humans to reach mammoth habitats that were previously frozen and inaccessible. Small populations of wooly mammoths survived on isolated Arctic islands, Saint Paul Island and Wrangel Island, till circa 3700 and 1700 BCE respectively. The Wrangel Island population went extinct around the same time the island was settled by prehistoric humans. There's no evidence of prehistoric human presence on Saint Paul island (though early human settlements dating as far back as 6500 BCE were found on nearby Aleutian Islands).
Human way of life.
Nearly all of our knowledge of Paleolithic human culture and way of life comes from archaeology and ethnographic comparisons to modern hunter-gatherer cultures such as the !Kung San who live similarly to their Paleolithic predecessors. The economy of a typical Paleolithic society was a hunter-gatherer economy. Humans hunted wild animals for meat and gathered food, firewood, and materials for their tools, clothes, or shelters. Human population density was very low, around only one person per square mile. This was most likely due to low body fat, infanticide, women regularly engaging in intense endurance exercise, late weaning of infants and a nomadic lifestyle. Like contemporary hunter-gatherers, Paleolithic humans enjoyed an abundance of leisure time unparalleled in both Neolithic farming societies and modern industrial societies. At the end of the Paleolithic, specifically the Middle and or Upper Paleolithic, humans began to produce works of art such as cave paintings, rock art and jewellery and began to engage in religious behavior such as burial and ritual.
Distribution.
At the beginning of the Paleolithic, hominids were found primarily in eastern Africa, east of the Great Rift Valley. Most known hominid fossils dating earlier than one million years before present are found in this area, particularly in Kenya, Tanzania, and Ethiopia.
By 1.5-2 million years before present, groups of hominids began leaving Africa and settling southern Europe and Asia. Southern Caucasus was occupied by 1.7 million years BP, and northern China was reached by 1.66 million years BP. By the end of the Lower Paleolithic, members of the hominid family were living in what is now China, western Indonesia, and, in Europe, around the Mediterranean and as far north as England, southern Germany, and Bulgaria. Their further northward expansion may have been limited by the lack of control of fire: studies of cave settlements in Europe indicate no regular use of fire prior to 300,000-400,000 BP. East Asian fossils from this period are typically placed in the genus Homo erectus. Very little fossil evidence is available at known Lower Paleolithic sites in Europe, but it is believed that hominids who inhabited these sites were likewise "Homo erectus". There is no evidence of hominids in America, Australia, or almost anywhere in Oceania during this time period.
Fates of these early colonists, and their relationships to modern humans, are still subject to debate. According to current archeological and genetic models, there were at least two notable expansion events subsequent to peopling of Eurasia 2-1.5 million years BP. Around 500,000 BP, a group of early humans, frequently called Homo heidelbergensis, came to Europe from Africa and eventually evolved into Neanderthals. Both "Homo erectus" and Neanderthals went extinct by the end of the Paleolithic, having been replaced by a new wave of humans, the anatomically modern Homo sapiens, which emerged in eastern Africa circa 200,000 BP, left Africa around 50,000 BP and expanded throughout the planet. It is likely that multiple groups coexisted for some time in certain locations. Neanderthals were still found in parts of Eurasia 30,000 years before present, and engaged in a limited degree of interbreeding with "Homo sapiens". Hominid fossils not belonging either to "Homo neanderthalensis" or to "Homo sapiens" geni, found in Altai and Indonesia, were radiocarbon dated to 30,000-40,000 BP and 17,000 BP respectively.
The technological revolution of the Middle and Upper Paleolithic allowed humans to reach places that weren't accessible earlier. In the Middle Paleolithic, Neanderthals were present in Poland. By 40,000-50,000 BP, first humans set foot in Australia. By 45,000 BP, humans lived at 61° north latitude in Europe. By 30,000 BP, Japan was reached, and by 27,000 BP humans were present in Siberia above the Arctic Circle. At the end of the Upper Paleolithic, a group of humans crossed the Bering land bridge and quickly expanded throughout North and South America. Northern Eurasia became depopulated during the last Glacial Maximum (27,000 to 16,000 BP), but was repopulated as the climate got warmer and glaciers retreated.
For the duration of the Paleolithic, human populations remained low, especially outside the equatorial region. The entire population of Europe between 16,000-11,000 BP likely averaged some 30,000 individuals, and, between 40,000-16,000 BP, it was even lower, at 4,000-6,000 individuals.
Technology.
Tools.
Paleolithic humans made tools of stone, bone, and wood. The early paleolithic hominids, Australopithecus, were the first users of stone tools. Excavations in Gona, Ethiopia have produced thousands of artifacts, and through radioisotopic dating and magnetostratigraphy, the sites can be firmly dated to 2.6 million years ago. Evidence shows these early hominids intentionally selected raw materials with good flaking qualities and chose appropriate sized stones for their needs to produce sharp-edged tools for cutting. The earliest Paleolithic stone tool industry, the Olduwan, began around 2.6 million years ago. It contained tools such as choppers, burins and awls. It was completely replaced around 250,000 years ago by the more complex Acheulean industry, which was first conceived by "Homo ergaster" around 1.8 or 1.65 million years ago. The most recent Lower Paleolithic (Acheulean) implements completely vanished from the archeological record around 100,000 years ago and were replaced by more complex Middle Paleolithic/Middle Stone Age tool kits such as the Mousterian and the Aterian industries.
Lower Paleolithic humans used a variety of stone tools, including hand axes and choppers. Although they appear to have used hand axes often, there is disagreement about their use. Interpretations range from cutting and chopping tools, to digging implements, flake cores, the use in traps and a purely ritual significance, maybe in courting behavior. William H. Calvin has suggested that some hand axes could have served as "killer Frisbees" meant to be thrown at a herd of animals at a water hole so as to stun one of them. There are no indications of hafting, and some artifacts are far too large for that. Thus, a thrown hand axe would not usually have penetrated deeply enough to cause very serious injuries. Nevertheless, it could have been an effective weapon for defense against predators. Choppers and scrapers were likely used for skinning and butchering scavenged animals and sharp ended sticks were often obtained for digging up edible roots. Presumably, early humans used wooden spears as early as five million years ago to hunt small animals, much as their relatives, chimpanzees, have been observed to do in Senegal, Africa. Lower Paleolithic humans constructed shelters such as the possible wood hut at Terra Amata.
Fire use.
Fire was used by the Lower Paleolithic hominid "Homo erectus"/"Homo ergaster" as early as 300,000 or 1.5 million years ago and possibly even earlier by the early Lower Paleolithic (Oldowan) hominid "Homo habilis" and/or by robust australopithecines such as "Paranthropus". However, the use of fire only became common in the societies of the following Middle Stone Age/Middle Paleolithic Period. Use of fire reduced mortality rates and provided protection against predators. Early hominids may have begun to cook their food as early as the Lower Paleolithic ("c." 1.9 million years ago) or at the latest in the early Middle Paleolithic ("c." 250,000 years ago). Some scientists have hypothesized that Hominids began cooking food to defrost frozen meat, which would help ensure their survival in cold regions.
Rafts.
The Lower Paleolithic hominid "Homo erectus" possibly invented rafts ("c." 800,000 or 840,000 BP) to travel over large bodies of water, which may have allowed a group of "Homo erectus" to reach the island of Flores and evolve into the small hominid "Homo floresiensis". However, this hypothesis is disputed within the anthropological community. The possible use of rafts during the Lower Paleolithic may indicate that Lower Paleolithic Hominids such as "Homo erectus" were more advanced than previously believed, and may have even spoken an early form of modern language. Supplementary evidence from Neanderthal and Modern human sites located around the Mediterranean Sea such as Coa de sa Multa ("c." 300,000 BP) has also indicated that both Middle and Upper Paleolithic humans used rafts to travel over large bodies of water (i.e. the Mediterranean Sea) for the purpose of colonizing other bodies of land.
Advanced tools.
Around 200,000 BP, Middle Paleolithic Stone tool manufacturing spawned a tool making technique known as the prepared-core technique, that was more elaborate than previous Acheulean techniques. This technique increased efficiency by allowing the creation of more controlled and consistent flakes. It allowed Middle Paleolithic humans to create stone tipped spears, which were the earliest composite tools, by hafting sharp, pointy stone flakes onto wooden shafts. In addition to improving tool making methods, the Middle Paleolithic also saw an improvement of the tools themselves that allowed access to a wider variety and amount of food sources. For example microliths or small stone tools or points were invented around 70,000 or 65,000 BP and were essential to the invention of bows and spear throwers in the following Upper Paleolithic period. Harpoons were invented and used for the first time during the late Middle Paleolithic (c.90,000 years ago); the invention of these devices brought fish into the human diets, which provided a hedge against starvation and a more abundant food supply. Thanks to their technology and their advanced social structures, Paleolithic groups such as the Neanderthals who had a Middle Paleolithic level of technology, appear to have hunted large game just as well as Upper Paleolithic modern humans and the Neanderthals in particular may have likewise hunted with projectile weapons. Nonetheless, Neanderthal use of projectile weapons in hunting occurred very rarely (or perhaps never) and the Neanderthals hunted large game animals mostly by ambushing them and attacking them with mêlée weapons such as thrusting spears rather than attacking them from a distance with projectile weapons.
Other inventions.
During the Upper Paleolithic, further inventions were made, such as the net ("c." 22,000 or 29,000 BP) bolas, the spear thrower (c.30,000 BP), the bow and arrow ("c." 25,000 or 30,000 BP) and the oldest example of ceramic art, the Venus of Dolní Věstonice ("c." 29,000–25,000 BCE). Early dogs were domesticated, sometime between 30,000 BP and 14,000 BP, presumably to aid in hunting. However, the earliest instances of successful domestication of dogs may be much more ancient than this. Evidence from canine DNA collected by Robert K. Wayne suggests that dogs may have been first domesticated in the late Middle Paleolithic around 100,000 BP or perhaps even earlier. Archeological evidence from the Dordogne region of France demonstrates that members of the European early Upper Paleolithic culture known as the Aurignacian used calendars ("c." 30,000 BP). This was a lunar calendar that was used to document the phases of the moon. Genuine solar calendars did not appear until the following Neolithic period. Upper Paleolithic cultures were probably able to time the migration of game animals such as wild horses and deer. This ability allowed humans to become efficient hunters and to exploit a wide variety of game animals. Recent research indicates that the Neanderthals timed their hunts and the migrations of game animals long before the beginning of the Upper Paleolithic.
Social organization.
The social organization of the earliest Paleolithic (Lower Paleolithic) societies remains largely unknown to scientists, though Lower Paleolithic hominids such as "Homo habilis" and "Homo erectus" are likely to have had more complex social structures than chimpanzee societies. Late Oldowan/Early Acheulean humans such as "Homo ergaster"/"Homo erectus" may have been the first people to invent central campsites or home bases and incorporate them into their foraging and hunting strategies like contemporary hunter-gatherers, possibly as early as 1.7 million years ago; however, the earliest solid evidence for the existence of home bases or central campsites (hearths and shelters) among humans only dates back to 500,000 years ago.
Similarly, scientists disagree whether Lower Paleolithic humans were largely monogamous or polygynous. In particular, the Provisional model suggests that bipedalism arose in Pre Paleolithic australopithecine societies as an adaptation to monogamous lifestyles; however, other researchers note that sexual dimorphism is more pronounced in Lower Paleolithic humans such as "Homo erectus" than in Modern humans, who are less polygynous than other primates, which suggests that Lower Paleolithic humans had a largely polygynous lifestyle, because species that have the most pronounced sexual dimorphism tend more likely to be polygynous.
Human societies from the Paleolithic to the early Neolithic farming tribes lived without states and organized governments. For most of the Lower Paleolithic, human societies were possibly more hierarchical than their Middle and Upper Paleolithic descendants, and probably were not grouped into bands, though during the end of the Lower Paleolithic, the latest populations of the hominid "Homo erectus" may have begun living in small-scale (possibly egalitarian) bands similar to both Middle and Upper Paleolithic societies and modern hunter-gatherers.
Middle Paleolithic societies, unlike Lower Paleolithic and early Neolithic ones, consisted of bands that ranged from 20 to 30 or 25 to 100 members and were usually nomadic. These bands were formed by several families. Bands sometimes joined together into larger "macrobands" for activities such as acquiring mates and celebrations or where resources were abundant. By the end of the Paleolithic era, about 10,000 BP people began to settle down into permanent locations, and began to rely on agriculture for sustenance in many locations. Much evidence exists that humans took part in long-distance trade between bands for rare commodities (such as ochre, which was often used for religious purposes such as ritual) and raw materials, as early as 120,000 years ago in Middle Paleolithic. Inter-band trade may have appeared during the Middle Paleolithic because trade between bands would have helped ensure their survival by allowing them to exchange resources and commodities such as raw materials during times of relative scarcity (i.e. famine, drought). Like in modern hunter-gatherer societies, individuals in Paleolithic societies may have been subordinate to the band as a whole. Both Neanderthals and modern humans took care of the elderly members of their societies during the Middle and Upper Paleolithic.
Some sources claim that most Middle and Upper Paleolithic societies were possibly fundamentally egalitarian and may have rarely or never engaged in organized violence between groups (i.e. war).
Some Upper Paleolithic societies in resource-rich environments (such as societies in Sungir, in what is now Russia) may have had more complex and hierarchical organization (such as tribes with a pronounced hierarchy and a somewhat formal division of labor) and may have engaged in endemic warfare. Some argue that there was no formal leadership during the Middle and Upper Paleolithic. Like contemporary egalitarian hunter-gatherers such as the Mbuti pygmies, societies may have made decisions by communal consensus decision making rather than by appointing permanent rulers such as chiefs and monarchs. Nor was there a formal division of labor during the Paleolithic. Each member of the group was skilled at all tasks essential to survival, regardless of individual abilities. Theories to explain the apparent egalitarianism have arisen, notably the Marxist concept of primitive communism. Christopher Boehm (1999) has hypothesized that egalitarianism may have evolved in Paleolithic societies because of a need to distribute resources such as food and meat equally to avoid famine and ensure a stable food supply. Raymond C. Kelly speculates that the relative peacefulness of Middle and Upper Paleolithic societies resulted from a low population density, cooperative relationships between groups such as reciprocal exchange of commodities and collaboration on hunting expeditions, and because the invention of projectile weapons such as throwing spears provided less incentive for war, because they increased the damage done to the attacker and decreased the relative amount of territory attackers could gain. However, other sources claim that most Paleolithic groups may have been larger, more complex, sedentary and warlike than most contemporary hunter-gatherer societies, due to occupying more resource-abundant areas than most modern hunter-gatherers who have been pushed into more marginal habitats by agricultural societies.
Anthropologists have typically assumed that in Paleolithic societies, women were responsible for gathering wild plants and firewood, and men were responsible for hunting and scavenging dead animals. However, analogies to existent hunter-gatherer societies such as the Hadza people and the Australian aborigines suggest that the sexual division of labor in the Paleolithic was relatively flexible. Men may have participated in gathering plants, firewood and insects, and women may have procured small game animals for consumption and assisted men in driving herds of large game animals (such as woolly mammoths and deer) off cliffs. Additionally, recent research by anthropologist and archaeologist Steven Kuhn from the University of Arizona is argued to support that this division of labor did not exist prior to the Upper Paleolithic and was invented relatively recently in human pre-history.<ref name=NG2006/12/061207></ref> Sexual division of labor may have been developed to allow humans to acquire food and other resources more efficiently. Possibly there was approximate parity between men and women during the Middle and Upper Paleolithic, and that period may have been the most gender-equal time in human history. Archeological evidence from art and funerary rituals indicates that a number of individual women enjoyed seemingly high status in their communities, and it is likely that both sexes participated in decision making. The earliest known Paleolithic shaman ("c." 30,000 BP) was female. Jared Diamond suggests that the status of women declined with the adoption of agriculture because women in farming societies typically have more pregnancies and are expected to do more demanding work than women in hunter-gatherer societies. Like most contemporary hunter-gatherer societies, Paleolithic and the Mesolithic groups probably followed mostly matrilineal and ambilineal descent patterns; patrilineal descent patterns were probably rarer than in the following Neolithic period.
Art and music.
Early examples of artistic expression, such as the Venus of Tan-Tan and the patterns found on elephant bones from Bilzingsleben in Thuringia, may have been produced by Acheulean tool users such as "Homo erectus" prior to the start of the Middle Paleolithic period. However, the earliest undisputed evidence of art during the Paleolithic period comes from Middle Paleolithic/Middle Stone Age sites such as Blombos Cave –South Africa– in the form of bracelets, beads, rock art, and ochre used as body paint and perhaps in ritual. Undisputed evidence of art only becomes common in the following Upper Paleolithic period.
According to Robert G. Bednarik, Lower Paleolithic Acheulean tool users began to engage in symbolic behavior such as art around 850,000 BP and decorated themselves with beads and collected exotic stones for aesthetic rather than utilitarian qualities. According to Bednarik, traces of the pigment ochre from late Lower Paleolithic Acheulean archeological sites suggests that Acheulean societies, like later Upper Paleolithic societies, collected and used ochre to create rock art. Nevertheless, it is also possible that the ochre traces found at Lower Paleolithic sites is naturally occurring.
Vincent W. Fallio interprets Lower and Middle Paleolithic marking on rocks at sites such as Bilzingsleben (such as zig zagging lines) as accounts or representation of altered states of consciousness though some other scholars interpret them as either simple doodling or as the result of natural processes.
Upper Paleolithic humans produced works of art such as cave paintings, Venus figurines, animal carvings and rock paintings. Upper Paleolithic art can be divided into two broad categories: figurative art such as cave paintings that clearly depicts animals (or more rarely humans); and nonfigurative, which consists of shapes and symbols. Cave paintings have been interpreted in a number of ways by modern archeologists. The earliest explanation, by the prehistorian Abbe Breuil, interpreted the paintings as a form of magic designed to ensure a successful hunt. However, this hypothesis fails to explain the existence of animals such as saber-toothed cats and lions, which were not hunted for food, and the existence of half-human, half-animal beings in cave paintings. The anthropologist David Lewis-Williams has suggested that Paleolithic cave paintings were indications of shamanistic practices, because the paintings of half-human, half-animal paintings and the remoteness of the caves are reminiscent of modern hunter-gatherer shamanistic practices. Symbol-like images are more common in Paleolithic cave paintings than are depictions of animals or humans, and unique symbolic patterns might have been trademarks that represent different Upper Paleolithic ethnic groups. Venus figurines have evoked similar controversy. Archeologists and anthropologists have described the figurines as representations of goddesses, pornographic imagery, apotropaic amulets used for sympathetic magic, and even as self-portraits of women themselves.
R. Dale Guthrie has studied not only the most artistic and publicized paintings, but also a variety of lower-quality art and figurines, and he identifies a wide range of skill and ages among the artists. He also points out that the main themes in the paintings and other artifacts (powerful beasts, risky hunting scenes and the over-sexual representation of women) are to be expected in the fantasies of adolescent males during the Upper Paleolithic.
The Venus figurines have sometimes been interpreted as representing a mother goddess; the abundance of such female imagery has led some to believe that Upper Paleolithic (and later Neolithic) societies had a female-centered religion and a female-dominated society. For example, this was proposed by the archeologist Marija Gimbutas and the feminist scholar Merlin Stone who was the author of the 1978 book "When God Was a Woman." Various other explanations for the purpose of the figurines have been proposed, such as Catherine McCoid and LeRoy McDermott’s hypothesis that the figurines were created as self-portraits of actual women and R.Dale Gutrie's hypothesis that the venus figurines represented a kind of "stone age pornography".
The origins of music during the Paleolithic are unknown, since the earliest forms of music probably did not use musical instruments but instead used the human voice and or natural objects such as rocks, which leave no trace in the archaeological record. However, the anthropological and archeological designation suggests that human music first arose when language, art and other modern behaviors developed in the Middle or the Upper Paleolithic period. Music may have developed from rhythmic sounds produced by daily activities such as cracking nuts by hitting them with stones, because maintaining a rhythm while working may have helped people to become more efficient at daily activities. An alternative theory originally proposed by Charles Darwin explains that music may have begun as a hominid mating strategy as many birds and some other animals produce music like calls to attract mates. This hypothesis is generally less accepted than the previous hypothesis, but it nonetheless provides a possible alternative. Another explanation is that humans began to make music simply because of the pleasure it produced.
Upper Paleolithic (and possibly Middle Paleolithic) humans used flute-like bone pipes as musical instruments, and music may have played a large role in the religious lives of Upper Paleolithic hunter-gatherers. As with modern hunter-gatherer societies, music may have been used in ritual or to help induce trances. In particular, it appears that animal skin drums may have been used in religious events by Upper Paleolithic shamans, as shown by the remains of drum-like instruments from some Upper Paleolithic graves of shamans and the ethnographic record of contemporary hunter-gatherer shamanic and ritual practices.
Religion and beliefs.
According to James B. Harrod humankind first developed religious and spiritual beliefs during the Middle Paleolithic or Upper Paleolithic. Controversial scholars of prehistoric religion and anthropology, James Harrod and Vincent W. Fallio, have recently proposed that religion and spirituality (and art) may have first arisen in Pre-Paleolithic chimpanzees or Early Lower Paleolithic (Oldowan) societies. According to Fallio, the common ancestor of chimpanzees and humans experienced altered states of consciousness and partook in ritual, and ritual was used in their societies to strengthen social bonding and group cohesion.
Middle Paleolithic humans' use of burials at sites such as Krapina, Croatia ("c." 130,000 BP) and Qafzeh, Israel ("c." 100,000 BP) have led some anthropologists and archeologists, such as Philip Lieberman, to believe that Middle Paleolithic humans may have possessed a belief in an afterlife and a "concern for the dead that transcends daily life". Cut marks on Neanderthal bones from various sites, such as Combe-Grenal and Abri Moula in France, suggest that the Neanderthals like some contemporary human cultures may have practiced ritual defleshing for (presumably) religious reasons. According to recent archeological findings from "H. heidelbergensis" sites in Atapuerca, humans may have begun burying their dead much earlier, during the late Lower Paleolithic; but this theory is widely questioned in the scientific community.
Likewise, some scientists have proposed that Middle Paleolithic societies such as Neanderthal societies may also have practiced the earliest form of totemism or animal worship, in addition to their (presumably religious) burial of the dead. In particular, Emil Bächler suggested (based on archeological evidence from Middle Paleolithic caves) that a bear cult was widespread among Middle Paleolithic Neanderthals. A claim that evidence was found for Middle Paleolithic animal worship c 70,000 BCE originates from the Tsodilo Hills in the African Kalahari desert has been denied by the original investigators of the site. Animal cults in the following Upper Paleolithic period, such as the bear cult, may have had their origins in these hypothetical Middle Paleolithic animal cults. Animal worship during the Upper Paleolithic was intertwined with hunting rites. For instance, archeological evidence from art and bear remains reveals that the bear cult apparently involved a type of sacrificial bear ceremonialism, in which a bear was sliced with arrows, finished off by a blast in the lungs, and ritualistically worshipped near a clay bear statue covered by a bear fur with the skull and the body of the bear buried separately. Barbara Ehrenreich controversially theorizes that the sacrificial hunting rites of the Upper Paleolithic (and by extension Paleolithic cooperative big-game hunting) gave rise to war or warlike raiding during the following Epi-Paleolithic/Mesolithic or late Upper Paleolithic period.
The existence of anthropomorphic images and half-human, half-animal images in the Upper Paleolithic period may further indicate that Upper Paleolithic humans were the first people to believe in a pantheon of gods or supernatural beings, though such images may instead indicate shamanistic practices similar to those of contemporary tribal societies. The earliest known undisputed burial of a shaman (and by extension the earliest undisputed evidence of shamans and shamanic practices) dates back to the early Upper Paleolithic era ("c." 30,000 BP) in what is now the Czech Republic. However, during the early Upper Paleolithic it was probably more common for all members of the band to participate equally and fully in religious ceremonies, in contrast to the religious traditions of later periods when religious authorities and part-time ritual specialists such as shamans, priests and medicine men were relatively common and integral to religious life. Additionally, it is also possible that Upper Paleolithic religions, like contemporary and historical animistic and polytheistic religions, believed in the existence of a single creator deity in addition to other supernatural beings such as animistic spirits.
Vincent W. Fallio writes that ancestor cults first emerged in complex Upper Paleolithic societies. He argues that the elites of these societies (like the elites of many more contemporary complex hunter-gatherers such as the Tlingit) may have used special rituals and ancestor worship to solidify control over their societies, by convincing their subjects that they possess a link to the spirit world that also gives them control over the earthly realm. Secret societies may have served a similar function in these complex quasi-theocratic societies, by dividing the religious practices of these cultures into the separate spheres of Popular Religion and Elite Religion.
Religion was possibly apotropaic; specifically, it may have involved sympathetic magic. The Venus figurines, which are abundant in the Upper Paleolithic archeological record, provide an example of possible Paleolithic sympathetic magic, as they may have been used for ensuring success in hunting and to bring about fertility of the land and women. The Upper Paleolithic Venus figurines have sometimes been explained as depictions of an earth goddess similar to Gaia, or as representations of a goddess who is the ruler or mother of the animals. James Harrod has described them as representative of female (and male) shamanistic spiritual transformation processes.
Diet and nutrition.
Paleolithic hunting and gathering people ate varying proportions of leafy vegetables, fruit, nuts and insects, meat, fish, and shellfish. However, there is little direct evidence of the relative proportions of plant and animal foods. Although the term "paleolithic diet", without references to a specific timeframe or locale, is sometimes used with an implication that most humans shared a certain diet during the entire era, that is not entirely accurate. The Paleolithic was an extended period of time, during which multiple technological advances were made, many of which had impact on human dietary structure. For example, humans probably did not possess the control of fire until the Middle Paleolithic, or tools necessary to engage in extensive fishing. On the other hand, both these technologies are generally agreed to have been widely available to humans by the end of the Paleolithic (consequently, allowing humans in some regions of the planet to rely heavily on fishing and hunting). In addition, the Paleolithic involved a substantial geographical expansion of human populations. During the Lower Paleolithic, ancestors of modern humans are thought to have been constrained to Africa east of the Great Rift Valley. During the Middle and Upper Paleolithic, humans greatly expanded their area of settlement, reaching ecosystems as diverse as New Guinea and Alaska, and adapting their diets to whatever local resources available.
Another view is that until the Upper Paleolithic, humans were frugivores (fruit eaters) who supplemented their meals with carrion, eggs, and small prey such as baby birds and mussels, and only on rare occasions managed to kill and consume big game such as antelopes. This view is supported by studies of higher apes, particularly chimpanzees. Chimpanzees are the closest to humans genetically, sharing more than 96% of their DNA code with humans, and their digestive tract is functionally very similar to that of humans. Chimpanzees are primarily frugivores, but they could and would consume and digest animal flesh, given the opportunity. In general, their actual diet in the wild is about 95% plant-based, with the remaining 5% filled with insects, eggs, and baby animals. In some ecosystems, however, chimpanzees are predatory, forming parties to hunt monkeys. Some comparative studies of human and higher primate digestive tracts do suggest that humans have evolved to obtain greater amounts of calories from sources such as animal foods, allowing them to shrink the size of the gastrointestinal tract relative to body mass and to increase the brain mass instead.
A difficulty with the frugivore point of view is that humans are established to conditionally require certain long-chain polyunsaturated fatty acids (LC-PUFAs), such as AA and DHA, from the diet. Humans' LC-PUFA requirements are much greater than chimpanzees' because of humans' larger brain mass, and humans' abilities to synthesize them from other nutrients are poor, suggesting readily available external sources. Pregnant and lactating females require 100 mg of DHA per day. However, LC-PUFAs are almost nonexistent in plants and in most tissues of warm-climate animals.
Anthropologists have diverse opinions about the proportions of plant and animal foods consumed. Just as with still existing hunters and gatherers, there were many varied "diets" - in different groups - and also varying through this vast amount of time. Some paleolithic hunter-gatherers consumed a significant amount of meat and possibly obtained most of their food from hunting, while others are shown as a primarily plant-based diet, Most, if not all, are believed to have been opportunistic omnivores. One hypothesis is that carbohydrate tubers (plant underground storage organs) may have been eaten in high amounts by pre-agricultural humans. It is thought that the Paleolithic diet included as much as 1.65–1.9 kilograms per day of fruit and vegetables. The relative proportions of plant and animal foods in the diets of Paleolithic people often varied between regions, with more meat being necessary in colder regions (which weren't populated by anatomically modern humans until 30,000-50,000 BP). It is generally agreed that many modern hunting and fishing tools, such as fish hooks, nets, bows, and poisons, weren't introduced until the Upper Paleolithic and possibly even Neolithic. The only hunting tools widely available to humans during any significant part of the Paleolithic period were hand-held spears and harpoons. There's evidence of Paleolithic people killing and eating seals and elands as far as 100,000 years BP. On the other hand, buffalo bones found in African caves from the same period are typically of very young or very old individuals, and there's no evidence that pigs, elephants or rhinos were hunted by humans at the time.
Paleolithic peoples suffered less famine and malnutrition than the Neolithic farming tribes that followed them. This was partly because Paleolithic hunter-gatherers accessed to a wider variety natural foods, which allowed them a more nutritious diet and a decreased risk of famine. Many of the famines experienced by Neolithic (and some modern) farmers were caused or amplified by their dependence on a small number of crops. It is thought that wild foods can have a significantly different nutritional profile than cultivated foods. The greater amount of meat obtained by hunting big game animals in Paleolithic diets than Neolithic diets may have also allowed Paleolithic hunter-gatherers to enjoy a more nutritious diet than Neolithic agriculturalists. It has been argued that the shift from hunting and gathering to agriculture resulted in an increasing focus on a limited variety of foods, with meat likely taking a back seat to plants. It is also unlikely that Paleolithic hunter-gatherers were affected by modern diseases of affluence such as Type 2 diabetes, coronary heart disease and cerebrovascular disease, because they ate mostly lean meats and plants and frequently engaged in intense physical activity, and because the average lifespan was shorter than the age of common-onset of these conditions.
Large-seeded legumes were part of the human diet long before the Neolithic agricultural revolution, as evident from archaeobotanical finds from the Mousterian layers of Kebara Cave, in Israel.<ref name="doi10.1016/j.jas.2004.11.006"></ref> There is evidence suggesting that Paleolithic societies were gathering wild cereals for food use at least as early as 30,000 years ago. However, seeds, such as grains and beans, were rarely eaten and never in large quantities on a daily basis.<ref name=doi:10.1080/11026480510032043></ref> Recent archeological evidence also indicates that winemaking may have originated in the Paleolithic, when early humans drank the juice of naturally fermented wild grapes from animal-skin pouches. Paleolithic humans consumed animal organ meats, including the livers, kidneys and brains. Upper Paleolithic cultures appear to have had significant knowledge about plants and herbs and may have, albeit very rarely, practiced rudimentary forms of horticulture. In particular, bananas and tubers may have been cultivated as early as 25,000 BP in southeast Asia. Late Upper Paleolithic societies also appear to have occasionally practiced pastoralism and animal husbandry, presumably for dietary reasons. For instance, some European late Upper Paleolithic cultures domesticated and raised reindeer, presumably for their meat or milk, as early as 14,000 BP. Humans also probably consumed hallucinogenic plants during the Paleolithic period. The Australian Aborigines have been consuming a variety of native animal and plant foods, called bushfood, for an estimated 60,000 years, since the Middle Paleolithic.
People during the Middle Paleolithic, such as the Neanderthals and Middle Paleolithic Homo sapiens in Africa, began to catch shellfish for food as revealed by shellfish cooking in Neanderthal sites in Italy about 110,000 years ago and Middle Paleolithic "Homo sapiens" sites at Pinnacle Point, in Africa around 164,000 BP.<ref name=NYTIMES/10/08/07></ref> Although fishing only became common during the Upper Paleolithic, fish have been part of human diets long before the dawn of the Upper Paleolithic and have certainly been consumed by humans since at least the Middle Paleolithic. For example, the Middle Paleolithic "Homo sapiens" in the region now occupied by the Democratic Republic of the Congo hunted large 6 ft-long catfish with specialized barbed fishing points as early as 90,000 years ago. The invention of fishing allowed some Upper Paleolithic and later hunter-gatherer societies to become sedentary or semi-nomadic, which altered their social structures. Example societies are the Lepenski Vir as well as some contemporary hunter-gatherers such as the Tlingit. In some instances (at least the Tlingit) they developed social stratification, slavery and complex social structures such as chiefdoms.
Anthropologists such as Tim White suggest that cannibalism was common in human societies prior to the beginning of the Upper Paleolithic, based on the large amount of “butchered human" bones found in Neanderthal and other Lower/Middle Paleolithic sites. Cannibalism in the Lower and Middle Paleolithic may have occurred because of food shortages. However, it may have been for religious reasons, and would coincide with the development of religious practices thought to have occurred during the Upper Paleolithic. Nonetheless, it remains possible that Paleolithic societies never practiced cannibalism, and that the damage to recovered human bones was either the result of ritual post-mortem bone cleaning or predation by carnivores such as saber tooth cats, lions and hyenas.

</doc>
<doc id="22873" url="http://en.wikipedia.org/wiki?curid=22873" title="Presidential Medal of Freedom">
Presidential Medal of Freedom

The Presidential Medal of Freedom is an award bestowed by the President of the United States and is—along with the 
comparable Congressional Gold Medal, bestowed by an act of U.S. Congress—the highest civilian award of the United States. It recognizes those individuals who have made "an especially meritorious contribution to the security or national interests of the United States, world peace, cultural or other significant public or private endeavors". The award is not limited to U.S. citizens and, while it is a civilian award, it can also be awarded to military personnel and worn on the uniform.
It was established in 1963 and replaced the earlier Medal of Freedom that was established by President Harry S. Truman in 1945 to honor civilian service during World War II.
History of the award.
Similar in name to the Medal of Freedom, but much closer in meaning and precedence to the Medal for Merit: the Presidential Medal of Freedom is currently the supreme civilian decoration in precedence, whereas the Medal of Freedom was inferior in precedence to the Medal for Merit; the Medal of Freedom was awarded by any of three Cabinet secretaries, whereas the Medal for Merit was awarded by the president, as is the Presidential Medal of Freedom. Another measure of the difference between these two similarly named but very distinct awards is their per-capita frequency of award: from 1946 to 1961 the average annual incidence of award of the Medal of Freedom was approximately 1 per every 86,500 adult U.S. citizens; from 1996 to 2011 the average annual incidence of award of the Presidential Medal of Freedom was approximately 1 per every 20,500,000 adult U.S. citizens (so on an annualized per capita basis, 240 Medals of Freedom have been awarded per one Presidential Medal of Freedom).
President John F. Kennedy established the current decoration in 1963 through Executive Order , with unique and distinctive insignia, vastly expanded purpose, and far higher prestige. It was the first U.S. civilian neck decoration and, in the grade of Awarded With Distinction, is the only U.S. sash and star decoration (the Chief Commander degree of the Legion of Merit – which may only be awarded to foreign heads of state – is a star decoration, but without a sash). The Executive Order calls for the medal to be awarded annually on or around July 4, and at other convenient times as chosen by the president, but it has not been awarded every year (e.g., 2001, 2010). Recipients are selected by the president, either on his own initiative or based on recommendations. The order establishing the medal also expanded the size and the responsibilities of the Distinguished Civilian Service Awards Board so it could serve as a major source of such recommendations.
The medal may be awarded to an individual more than once; John Kenneth Galbraith and Colin Powell each have received two awards; Ellsworth Bunker received both of his awards With Distinction. It may also be awarded posthumously; examples include Cesar Chavez, Paul "Bear" Bryant, Roberto Clemente, Jack Kemp, John F. Kennedy, Thurgood Marshall and Lyndon Johnson.
Insignia.
The badge of the Presidential Medal of Freedom is in the form of a golden star with white enamel, with a red enamel pentagon behind it; the central disc bears thirteen gold stars on a blue enamel background (taken from the Great Seal of the United States) within a golden ring. Golden American bald eagles with spread wings stand between the points of the star. It is worn around the neck on a blue ribbon with white edge stripes.
A special grade of the medal, known as the Presidential Medal of Freedom with Distinction, has a larger execution of the same medal design worn as a star on the left chest along with a sash over the right shoulder (similar to how the insignia of a Grand Cross is worn), with its rosette (blue with white edge, bearing the central disc of the medal at its center) resting on the left hip. When the medal With Distinction is awarded, the star may be presented depending from a neck ribbon and can be identified by its larger size than the standard medal (compare size of medals in pictures below; President Reagan's was awarded With Distinction).
Both medals may also be worn in miniature form on a ribbon on the left chest, with a silver American bald eagle with spread wings on the ribbon, or a golden American bald eagle for a medal awarded With Distinction. In addition, the medal is accompanied by a service ribbon for wear on military service uniform, a miniature medal pendant for wear on mess dress or civilian formal wear, and a lapel badge for wear on civilian clothes (all shown in the accompanying photograph of the full presentation set).

</doc>
<doc id="22915" url="http://en.wikipedia.org/wiki?curid=22915" title="Planet">
Planet

A planet (from " "ἀστήρ πλανήτης", astēr planētēs, "or πλάνης ἀστήρ", plánēs astēr", meaning "wandering star") is an astronomical object orbiting a star or stellar remnant that
The term "planet" is ancient, with ties to history, science, mythology, and religion. Several planets in the Solar System can be seen with the naked eye. These were regarded by many early cultures as divine, or as emissaries of deities. As scientific knowledge advanced, human perception of the planets changed, incorporating a number of disparate objects. In 2006, the International Astronomical Union (IAU) officially adopted a resolution defining planets within the Solar System. This definition is controversial because it excludes many objects of planetary mass based on where or what they orbit. Although eight of the planetary bodies discovered before 1950 remain "planets" under the modern definition, some celestial bodies, such as Ceres, Pallas, Juno, Vesta (each an object in the solar asteroid belt), and Pluto (the first trans-Neptunian object discovered), that were once considered planets by the scientific community are no longer viewed as such.
The planets were thought by Ptolemy to orbit Earth in deferent and epicycle motions. Although the idea that the planets orbited the Sun had been suggested many times, it was not until the 17th century that this view was supported by evidence from the first telescopic astronomical observations, performed by Galileo Galilei. By careful analysis of the observation data, Johannes Kepler found the planets' orbits were not circular but elliptical. As observational tools improved, astronomers saw that, like Earth, the planets rotated around tilted axes, and some shared such features as ice caps and seasons. Since the dawn of the Space Age, close observation by space probes has found that Earth and the other planets share characteristics such as volcanism, hurricanes, tectonics, and even hydrology.
Planets are generally divided into two main types: large low-density giant planets, and smaller rocky terrestrials. Under IAU definitions, there are eight planets in the Solar System. In order of increasing distance from the Sun, they are the four terrestrials, Mercury, Venus, Earth, and Mars, then the four giant planets, Jupiter, Saturn, Uranus, and Neptune. Six of the planets are orbited by one or more natural satellites.
More than a thousand planets around other stars ("extrasolar planets" or "exoplanets") have been discovered in the Milky Way: as of none }}, 1919 known extrasolar planets in 1212 planetary systems (including 482 multiple planetary systems), ranging in size from just above the size of the Moon to gas giants about twice as large as Jupiter. On December 20, 2011, the Kepler Space Telescope team reported the discovery of the first Earth-sized extrasolar planets, Kepler-20e and Kepler-20f, orbiting a Sun-like star, Kepler-20. A 2012 study, analyzing gravitational microlensing data, estimates an average of at least 1.6 bound planets for every star in the Milky Way.
Around one in five Sun-like stars is thought to have an Earth-sized planet in its habitable zone.
History.
The idea of planets has evolved over its history, from the divine wandering stars of antiquity to the earthly objects of the scientific age. The concept has expanded to include worlds not only in the Solar System, but in hundreds of other extrasolar systems. The ambiguities inherent in defining planets have led to much scientific controversy.
The five classical planets, being visible to the naked eye, have been known since ancient times and have had a significant impact on mythology, religious cosmology, and ancient astronomy. In ancient times, astronomers noted how certain lights moved across the sky in relation to the other stars. Ancient Greeks called these lights πλάνητες ἀστέρες ("planētes asteres", "wandering stars") or simply πλανῆται ("planētai", "wanderers"), from which today's word "planet" was derived. In ancient Greece, China, Babylon, and indeed all pre-modern civilizations, it was almost universally believed that Earth was the center of the Universe and that all the "planets" circled Earth. The reasons for this perception were that stars and planets appeared to revolve around Earth each day and the apparently common-sense perceptions that Earth was solid and stable and that it was not moving but at rest.
Babylon.
The first civilization known to have a functional theory of the planets were the Babylonians, who lived in Mesopotamia in the first and second millennia BC. The oldest surviving planetary astronomical text is the Babylonian Venus tablet of Ammisaduqa, a 7th-century BC copy of a list of observations of the motions of the planet Venus, that probably dates as early as the second millennium BC. The MUL.APIN is a pair of cuneiform tablets dating from the 7th century BC that lays out the motions of the Sun, Moon and planets over the course of the year. The Babylonian astrologers also laid the foundations of what would eventually become Western astrology. The "Enuma anu enlil", written during the Neo-Assyrian period in the 7th century BC, comprises a list of omens and their relationships with various celestial phenomena including the motions of the planets. Venus, Mercury and the outer planets Mars, Jupiter and Saturn were all identified by Babylonian astronomers. These would remain the only known planets until the invention of the telescope in early modern times.
Greco-Roman astronomy.
The ancient Greeks initially did not attach as much significance to the planets as the Babylonians. The Pythagoreans, in the 6th and 5th centuries BC appear to have developed their own independent planetary theory, which consisted of the Earth, Sun, Moon, and planets revolving around a "Central Fire" at the center of the Universe. Pythagoras or Parmenides is said to have been the first to identify the evening star (Hesperos) and morning star (Phosphoros) as one and the same (Aphrodite, Greek corresponding to Latin Venus). In the 3rd century BC, Aristarchus of Samos proposed a heliocentric system, according to which Earth and the planets revolved around the Sun. The geocentric system remained dominant until the Scientific Revolution.
By the 1st century BC, during the Hellenistic period, the Greeks had begun to develop their own mathematical schemes for predicting the positions of the planets. These schemes, which were based on geometry rather than the arithmetic of the Babylonians, would eventually eclipse the Babylonians' theories in complexity and comprehensiveness, and account for most of the astronomical movements observed from Earth with the naked eye. These theories would reach their fullest expression in the "Almagest" written by Ptolemy in the 2nd century CE. So complete was the domination of Ptolemy's model that it superseded all previous works on astronomy and remained the definitive astronomical text in the Western world for 13 centuries. To the Greeks and Romans there were seven known planets, each presumed to be circling Earth according to the complex laws laid out by Ptolemy. They were, in increasing order from Earth (in Ptolemy's order): the Moon, Mercury, Venus, the Sun, Mars, Jupiter, and Saturn.
India.
In 499 CE, the Indian astronomer Aryabhata propounded a planetary model that explicitly incorporated Earth's rotation about its axis, which he explains as the cause of what appears to be an apparent westward motion of the stars. He also believed that the orbits of planets are elliptical.
Aryabhata's followers were particularly strong in South India, where his principles of the diurnal rotation of Earth, among others, were followed and a number of secondary works were based on them.
In 1500, Nilakantha Somayaji of the Kerala school of astronomy and mathematics, in his "Tantrasangraha", revised Aryabhata's model. In his "Aryabhatiyabhasya", a commentary on Aryabhata's "Aryabhatiya", he developed a planetary model where Mercury, Venus, Mars, Jupiter and Saturn orbit the Sun, which in turn orbits Earth, similar to the Tychonic system later proposed by Tycho Brahe in the late 16th century. Most astronomers of the Kerala school who followed him accepted his planetary model.
Medieval Muslim astronomy.
In the 11th century, the transit of Venus was observed by Avicenna, who established that Venus was, at least sometimes, below the Sun. In the 12th century, Ibn Bajjah observed "two planets as black spots on the face of the Sun", which was later identified as a transit of Mercury and Venus by the Maragha astronomer Qotb al-Din Shirazi in the 13th century. Ibn Bajjah could not have observed a transit of Venus, because none occurred in his lifetime.
European Renaissance.
With the advent of the Scientific Revolution, use of the term "planet" changed from something that moved across the sky (in relation to the star field); to a body that orbited Earth (or that were believed to do so at the time); and by the 18th century to something that directly orbited the Sun when the heliocentric model of Copernicus, Galileo and Kepler gained sway.
Thus, Earth became included in the list of planets, whereas the Sun and Moon were excluded. At first, when the first satellites of Jupiter and Saturn were discovered in the 17th century, the terms "planet" and "satellite" were used interchangeably – although the latter would gradually become more prevalent in the following century. Until the mid-19th century, the number of "planets" rose rapidly because any newly discovered object directly orbiting the Sun was listed as a planet by the scientific community.
19th century.
In the 19th century astronomers began to realize that recently discovered bodies that had been classified as planets for almost half a century (such as Ceres, Pallas, and Vesta) were very different from the traditional ones. These bodies shared the same region of space between Mars and Jupiter (the asteroid belt), and had a much smaller mass; as a result they were reclassified as "asteroids". In the absence of any formal definition, a "planet" came to be understood as any "large" body that orbited the Sun. Because there was a dramatic size gap between the asteroids and the planets, and the spate of new discoveries seemed to have ended after the discovery of Neptune in 1846, there was no apparent need to have a formal definition.
20th century.
In the 20th century, Pluto was discovered. After initial observations led to the belief it was larger than Earth, the object was immediately accepted as the ninth planet. Further monitoring found the body was actually much smaller: in 1936, Raymond Lyttleton suggested that Pluto may be an escaped satellite of Neptune, and Fred Whipple suggested in 1964 that Pluto may be a comet. As it was still larger than all known asteroids and seemingly did not exist within a larger population, it kept its status until 2006.
In 1992, astronomers Aleksander Wolszczan and Dale Frail announced the discovery of planets around a pulsar, PSR B1257+12. This discovery is generally considered to be the first definitive detection of a planetary system around another star. Then, on October 6, 1995, Michel Mayor and Didier Queloz of the University of Geneva announced the first definitive detection of an exoplanet orbiting an ordinary main-sequence star (51 Pegasi).
The discovery of extrasolar planets led to another ambiguity in defining a planet: the point at which a planet becomes a star. Many known extrasolar planets are many times the mass of Jupiter, approaching that of stellar objects known as "brown dwarfs". Brown dwarfs are generally considered stars due to their ability to fuse deuterium, a heavier isotope of hydrogen. Although objects more massive than 75 times that of Jupiter fuse hydrogen, objects of only 13 Jupiter masses can fuse deuterium. Deuterium is quite rare, and most brown dwarfs would have ceased fusing deuterium long before their discovery, making them effectively indistinguishable from supermassive planets.
21st century.
With the discovery during the latter half of the 20th century of more objects within the Solar System and large objects around other stars, disputes arose over what should constitute a planet. There were particular disagreements over whether an object should be considered a planet if it was part of a distinct population such as a belt, or if it was large enough to generate energy by the thermonuclear fusion of deuterium.
A growing number of astronomers argued for Pluto to be declassified as a planet, because many similar objects approaching its size had been found in the same region of the Solar System (the Kuiper belt) during the 1990s and early 2000s. Pluto was found to be just one small body in a population of thousands.
Some of them, such as Quaoar, Sedna, and Eris, were heralded in the popular press as the tenth planet, failing to receive widespread scientific recognition. The announcement of Eris in 2005, an object 27% more massive than Pluto, created the necessity and public desire for an official definition of a planet.
Acknowledging the problem, the IAU set about creating the definition of planet, and produced one in August 2006. The number of planets dropped to the eight significantly larger bodies that had cleared their orbit (Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune), and a new class of dwarf planets was created, initially containing three objects (Ceres, Pluto and Eris).
Extrasolar planet definition.
In 2003, The International Astronomical Union (IAU) Working Group on Extrasolar Planets made a position statement on the definition of a planet that incorporated the following working definition, mostly focused upon the boundary between planets and brown dwarfs:
This definition has since been widely used by astronomers when publishing discoveries of exoplanets in academic journals. Although temporary, it remains an effective working definition until a more permanent one is formally adopted. It does not address the dispute over the lower mass limit, and so it steered clear of the controversy regarding objects within the Solar System. This definition also makes no comment on the planetary status of objects orbiting brown dwarfs, such as 2M1207b.
One definition of a sub-brown dwarf is a planet-mass object that formed through cloud collapse rather than accretion. This formation distinction between a sub-brown dwarf and a planet is not universally agreed upon; astronomers are divided into two camps as whether to consider the formation process of a planet as part of its division in classification. One reason for the dissent is that often it may not be possible to determine the formation process. For example, a planet formed by accretion around a star may get ejected from the system to become free-floating, and likewise a sub-brown dwarf that formed on its own in a star cluster through cloud collapse may get captured into orbit around a star.
The 13 Jupiter-mass cutoff is a rule of thumb rather than something of precise physical significance. The question arises: what is meant by deuterium burning? This question arises because large objects will burn most of their deuterium and smaller ones will burn only a little, and the 13 MJ value is somewhere in between. The amount of deuterium burnt depends not only on mass but also on the composition of the planet, on the amount of helium and deuterium present. The Extrasolar Planets Encyclopaedia includes objects up to 25 Jupiter masses, saying, "The fact that there is no special feature around 13 MJ in the observed mass spectrum reinforces the choice to forget this mass limit." The Exoplanet Data Explorer includes objects up to 24 Jupiter masses with the advisory: "The 13 Jupiter-mass distinction by the IAU Working Group is physically unmotivated for planets with rocky cores, and observationally problematic due to the sin i ambiguity."
The NASA Exoplanet Archive includes objects with a mass (or minimum mass) equal to or less than 30 Jupiter masses.
Another criterion for separating planets and brown dwarfs, rather than deuterium burning, formation process or location, is whether the core pressure is dominated by coulomb pressure or electron degeneracy pressure.
2006 definition.
The matter of the lower limit was addressed during the 2006 meeting of the IAU's General Assembly. After much debate and one failed proposal, 232 members of the 10,000 member assembly, who nevertheless constituted a large majority of those remaining at the meeting, voted to pass a resolution. The 2006 resolution redefines planets within the Solar System as:
 A celestial body that (a) is in orbit around the Sun, (b) has sufficient mass for its self-gravity to overcome rigid body forces so that it assumes a hydrostatic equilibrium (nearly round) shape, and (c) has cleared the neighbourhood around its orbit.
Under this definition, the Solar System is considered to have eight planets. Bodies that fulfill the first two conditions but not the third (such as Ceres, Pluto, and Eris) are classified as dwarf planets, provided they are not also natural satellites of other planets. Originally an IAU committee had proposed a definition that would have included a much larger number of planets as it did not include (c) as a criterion. After much discussion, it was decided via a vote that those bodies should instead be classified as dwarf planets.
This definition is based in theories of planetary formation, in which planetary embryos initially clear their orbital neighborhood of other smaller objects. As described by astronomer Steven Soter:
 The end product of secondary disk accretion is a small number of relatively large bodies (planets) in either non-intersecting or resonant orbits, which prevent collisions between them. Minor planets and comets, including KBOs [Kuiper belt objects], differ from planets in that they can collide with each other and with planets.
Beyond the scientific community, Pluto still holds cultural significance for many in the general public due to its historical classification as a planet from 1930 to 2006.
Objects formerly considered planets.
The table below lists Solar System bodies once considered to be planets.
A few astronomers, such as Alan Stern, consider dwarf planets and the larger moons to be planets, based on a purely geophysical definition of "planet".
Mythology and naming.
The names for the planets in the Western world are derived from the naming practices of the Romans, which ultimately derive from those of the Greeks and the Babylonians. In ancient Greece, the two great luminaries the Sun and the Moon were called "Helios" and "Selene"; the farthest planet (Saturn) was called "Phainon", the shiner; followed by "Phaethon" (Jupiter), "bright"; the red planet (Mars) was known as "Pyroeis", the "fiery"; the brightest (Venus) was known as "Phosphoros", the light bringer; and the fleeting final planet (Mercury) was called "Stilbon", the gleamer. The Greeks also made each planet sacred to one among their pantheon of gods, the Olympians: Helios and Selene were the names of both planets and gods; Phainon was sacred to Cronus, the Titan who fathered the Olympians; Phaethon was sacred to Zeus, Cronus's son who deposed him as king; Pyroeis was given to Ares, son of Zeus and god of war; Phosphoros was ruled by Aphrodite, the goddess of love; and Hermes, messenger of the gods and god of learning and wit, ruled over Stilbon.
The Greek practice of grafting of their gods' names onto the planets was almost certainly borrowed from the Babylonians. The Babylonians named Phosphoros after their goddess of love, "Ishtar"; Pyroeis after their god of war, "Nergal", Stilbon after their god of wisdom Nabu, and Phaethon after their chief god, "Marduk". There are too many concordances between Greek and Babylonian naming conventions for them to have arisen separately. The translation was not perfect. For instance, the Babylonian Nergal was a god of war, and thus the Greeks identified him with Ares. Unlike Ares, Nergal was also god of pestilence and the underworld.
Today, most people in the western world know the planets by names derived from the Olympian pantheon of gods. Although modern Greeks still use their ancient names for the planets, other European languages, because of the influence of the Roman Empire and, later, the Catholic Church, use the Roman (Latin) names rather than the Greek ones. The Romans, who, like the Greeks, were Indo-Europeans, shared with them a common pantheon under different names but lacked the rich narrative traditions that Greek poetic culture had given their gods. During the later period of the Roman Republic, Roman writers borrowed much of the Greek narratives and applied them to their own pantheon, to the point where they became virtually indistinguishable. When the Romans studied Greek astronomy, they gave the planets their own gods' names: "Mercurius" (for Hermes), "Venus" (Aphrodite), "Mars" (Ares), "Iuppiter" (Zeus) and "Saturnus" (Cronus). When subsequent planets were discovered in the 18th and 19th centuries, the naming practice was retained with "Neptūnus" (Poseidon). Uranus is unique in that it is named for a Greek deity rather than his Roman counterpart.
Some Romans, following a belief possibly originating in Mesopotamia but developed in Hellenistic Egypt, believed that the seven gods after whom the planets were named took hourly shifts in looking after affairs on Earth. The order of shifts went Saturn, Jupiter, Mars, Sun, Venus, Mercury, Moon (from the farthest to the closest planet). Therefore, the first day was started by Saturn (1st hour), second day by Sun (25th hour), followed by Moon (49th hour), Mars, Mercury, Jupiter and Venus. Because each day was named by the god that started it, this is also the order of the days of the week in the Roman calendar after the Nundinal cycle was rejected – and still preserved in many modern languages. In English, "Saturday, Sunday," and "Monday" are straightforward translations of these Roman names. The other days were renamed after "Tiw", (Tuesday) "Wóden" (Wednesday), "Thunor" (Thursday), and "Fríge" (Friday), the Anglo-Saxon gods considered similar or equivalent to Mars, Mercury, Jupiter, and Venus, respectively.
Earth is the only planet whose name in English is not derived from Greco-Roman mythology. Because it was only generally accepted as a planet in the 17th century, there is no tradition of naming it after a god. (The same is true, in English at least, of the Sun and the Moon, though they are no longer generally considered planets.) The name originates from the 8th century Anglo-Saxon word "erda", which means ground or soil and was first used in writing as the name of the sphere of Earth perhaps around 1300. As with its equivalents in the other Germanic languages, it derives ultimately from the Proto-Germanic word "ertho", "ground", as can be seen in the English "earth", the German "Erde", the Dutch "aarde", and the Scandinavian "jord". Many of the Romance languages retain the old Roman word "terra" (or some variation of it) that was used with the meaning of "dry land" as opposed to "sea". The non-Romance languages use their own native words. The Greeks retain their original name, "Γή" "(Ge)".
Non-European cultures use other planetary-naming systems. India uses a system based on the Navagraha, which incorporates the seven traditional planets (Surya for the Sun, Chandra for the Moon, and Budha, Shukra, Mangala, Bṛhaspati and Shani for Mercury, Venus, Mars, Jupiter and Saturn) and the ascending and descending lunar nodes Rahu and Ketu. China and the countries of eastern Asia historically subject to Chinese cultural influence (such as Japan, Korea and Vietnam) use a naming system based on the five Chinese elements: water (Mercury), metal (Venus), fire (Mars), wood (Jupiter) and earth (Saturn).
Formation.
It is not known with certainty how planets are formed. The prevailing theory is that they are formed during the collapse of a nebula into a thin disk of gas and dust. A protostar forms at the core, surrounded by a rotating protoplanetary disk. Through accretion (a process of sticky collision) dust particles in the disk steadily accumulate mass to form ever-larger bodies. Local concentrations of mass known as planetesimals form, and these accelerate the accretion process by drawing in additional material by their gravitational attraction. These concentrations become ever denser until they collapse inward under gravity to form protoplanets. After a planet reaches a diameter larger than the Moon, it begins to accumulate an extended atmosphere, greatly increasing the capture rate of the planetesimals by means of atmospheric drag.
When the protostar has grown such that it ignites to form a star, the surviving disk is removed from the inside outward by photoevaporation, the solar wind, Poynting–Robertson drag and other effects. Thereafter there still may be many protoplanets orbiting the star or each other, but over time many will collide, either to form a single larger planet or release material for other larger protoplanets or planets to absorb. Those objects that have become massive enough will capture most matter in their orbital neighbourhoods to become planets. Protoplanets that have avoided collisions may become natural satellites of planets through a process of gravitational capture, or remain in belts of other objects to become either dwarf planets or small bodies.
The energetic impacts of the smaller planetesimals (as well as radioactive decay) will heat up the growing planet, causing it to at least partially melt. The interior of the planet begins to differentiate by mass, developing a denser core. Smaller terrestrial planets lose most of their atmospheres because of this accretion, but the lost gases can be replaced by outgassing from the mantle and from the subsequent impact of comets. (Smaller planets will lose any atmosphere they gain through various escape mechanisms.)
With the discovery and observation of planetary systems around stars other than the Sun, it is becoming possible to elaborate, revise or even replace this account. The level of metallicity—an astronomical term describing the abundance of chemical elements with an atomic number greater than 2 (helium)—is now believed to determine the likelihood that a star will have planets. Hence, it is thought that a metal-rich population I star will likely have a more substantial planetary system than a metal-poor, population II star.
Solar System.
According to the IAU, there are eight planets in the Solar System. In increasing distance from the Sun, the planets are:
Jupiter is the largest, at 318 Earth masses, whereas Mercury is the smallest, at 0.055 Earth masses.
The planets of the Solar System can be divided into categories based on their composition:
Exoplanets.
An exoplanet (extrasolar planet) is a planet outside the Solar System. Around 1800 such planets have been discovered
(1919 planets in 1212 planetary systems including 482 multiple planetary systems as of none }}).
In early 1992, radio astronomers Aleksander Wolszczan and Dale Frail announced the discovery of two planets orbiting the pulsar PSR 1257+12. This discovery was confirmed, and is generally considered to be the first definitive detection of exoplanets. These pulsar planets are believed to have formed from the unusual remnants of the supernova that produced the pulsar, in a second round of planet formation, or else to be the remaining rocky cores of giant planets that survived the supernova and then decayed into their current orbits.
The first confirmed discovery of an extrasolar planet orbiting an ordinary main-sequence star occurred on 6 October 1995, when Michel Mayor and Didier Queloz of the University of Geneva announced the detection of an exoplanet around 51 Pegasi. From then until the Kepler mission most known extrasolar planets were gas giants comparable in mass to Jupiter or larger as they were more easily detected. The catalog of Kepler candidate planets consists mostly of planets the size of Neptune and smaller, down to smaller than Mercury.
There are types of planets that do not exist in the Solar System: super-Earths and mini-Neptunes, which could be rocky like Earth or a mixture of volatiles and gas like Neptune—a radius of 1.75 times that of Earth is a possible dividing line between the two types of planet. There are hot Jupiters that orbit very close to their star and may evaporate to become chthonian planets, which are the leftover cores. Another possible type of planet is carbon planets, which form in systems with a higher proportion of carbon than in the Solar System.
A 2012 study, analyzing gravitational microlensing data, estimates an average of at least 1.6 bound planets for every star in the Milky Way.
On December 20, 2011, the Kepler Space Telescope team reported the discovery of the first Earth-size exoplanets, Kepler-20e and Kepler-20f, orbiting a Sun-like star, Kepler-20.
Around 1 in 5 Sun-like stars have an "Earth-sized" planet in the habitable zone, so the nearest would be expected to be within 12 light-years distance from Earth.
The frequency of occurrence of such terrestrial planets is one of the variables in the Drake equation, which estimates the number of intelligent, communicating civilizations that exist in the Milky Way.
There are exoplanets that are much closer to their parent star than any planet in the Solar System is to the Sun, and there are also exoplanets that are much further from their star. Mercury, the closest planet to the Sun at 0.4AU, takes 88-days for an orbit, but the shortest known orbits for exoplanets take only a few hours, e.g. Kepler-70b. The Kepler-11 system has five of its planets in shorter orbits than Mercury. Neptune is 30AU from the Sun and takes 165 years to orbit, but there are exoplanets that are hundreds of AU from their star and take more than a thousand years to orbit, e.g. 1RXS1609 b.
The next few space telescopes to study exoplanets are expected to be Gaia launched in December 2013, CHEOPS in 2017, TESS in 2017, and the James Webb Space Telescope in 2018.
Planetary-mass objects.
A planetary-mass object (PMO), planemo, or planetary body is a celestial object with a mass that falls within the range of the definition of a planet: massive enough to achieve hydrostatic equilibrium (to be rounded under its own gravity), but not enough to sustain core fusion like a star. By definition, all planets are "planetary-mass objects", but the purpose of this term is to refer to objects that do not conform to typical expectations for a planet. These include dwarf planets, the larger moons, and free-floating planemos, which may have been ejected from a system (rogue planets) or formed through cloud-collapse rather than accretion (sometimes called sub-brown dwarfs).
Rogue planets.
Several computer simulations of stellar and planetary system formation have suggested that some objects of planetary mass would be ejected into interstellar space. Some scientists have argued that such objects found roaming in deep space should be classed as "planets", although others have suggested that they should be called low-mass brown dwarfs.
Sub-brown dwarfs.
Stars form via the gravitational collapse of gas clouds, but smaller objects can also form via cloud-collapse. Planetary-mass objects formed this way are sometimes called sub-brown dwarfs. Sub-brown dwarfs may be free-floating such as Cha 110913-773444 and OTS 44, or orbiting a larger object such as 2MASS J04414489+2301513.
For a brief time in 2006, astronomers believed they had found a binary system of such objects, Oph 162225-240515, which the discoverers described as "planemos", or "planetary-mass objects". Recent analysis of the objects has determined that their masses are probably each greater than 13 Jupiter-masses, making the pair brown dwarfs.
Former stars.
In close binary star systems one of the stars can lose mass to a heavier companion. See accretion-powered pulsars. The shrinking star can then become a planetary-mass object. An example is a Jupiter-mass object orbiting the pulsar PSR J1719-1438. See also Helium planet.
Satellite planets and belt planets.
Some large satellites are of similar size or larger than the planet Mercury, e.g. Jupiter's Galilean moons and Titan. Alan Stern has argued that location should not matter and that only geophysical attributes should be taken into account in the definition of a planet, and proposes the term "satellite planet" for a planet-sized satellite. Likewise, dwarf planets in the asteroid belt and Kuiper belt should be considered planets according to Stern.
Captured planets.
Free-floating planets in stellar clusters have similar velocities to the stars and so can be recaptured. They are typically captured into wide orbits between 100 and 105 AU. The capture efficiency decreases with increasing cluster size, and for a given cluster size it increases with the host/primary mass. It is almost independent of the planetary mass. Single and multiple planets could be captured into arbitrary unaligned orbits, non-coplanar with each other or with the stellar host spin, or pre-existing planetary system.
Attributes.
Although each planet has unique physical characteristics, a number of broad commonalities do exist among them. Some of these characteristics, such as rings or natural satellites, have only as yet been observed in planets in the Solar System, whereas others are also commonly observed in extrasolar planets.
Dynamic characteristics.
Orbit.
According to current definitions, all planets must revolve around stars; thus, any potential "rogue planets" are excluded. In the Solar System, all the planets orbit the Sun in the same direction as the Sun rotates (counter-clockwise as seen from above the Sun's north pole). At least one extrasolar planet, WASP-17b, has been found to orbit in the opposite direction to its star's rotation. The period of one revolution of a planet's orbit is known as its sidereal period or "year". A planet's year depends on its distance from its star; the farther a planet is from its star, not only the longer the distance it must travel, but also the slower its speed, because it is less affected by its star's gravity. No planet's orbit is perfectly circular, and hence the distance of each varies over the course of its year. The closest approach to its star is called its periastron (perihelion in the Solar System), whereas its farthest separation from the star is called its apastron (aphelion). As a planet approaches periastron, its speed increases as it trades gravitational potential energy for kinetic energy, just as a falling object on Earth accelerates as it falls; as the planet reaches apastron, its speed decreases, just as an object thrown upwards on Earth slows down as it reaches the apex of its trajectory.
Each planet's orbit is delineated by a set of elements:
Axial tilt.
Planets also have varying degrees of axial tilt; they lie at an angle to the plane of their stars' equators. This causes the amount of light received by each hemisphere to vary over the course of its year; when the northern hemisphere points away from its star, the southern hemisphere points towards it, and vice versa. Each planet therefore has seasons; changes to the climate over the course of its year. The time at which each hemisphere points farthest or nearest from its star is known as its solstice. Each planet has two in the course of its orbit; when one hemisphere has its summer solstice, when its day is longest, the other has its winter solstice, when its day is shortest. The varying amount of light and heat received by each hemisphere creates annual changes in weather patterns for each half of the planet. Jupiter's axial tilt is very small, so its seasonal variation is minimal; Uranus, on the other hand, has an axial tilt so extreme it is virtually on its side, which means that its hemispheres are either perpetually in sunlight or perpetually in darkness around the time of its solstices. Among extrasolar planets, axial tilts are not known for certain, though most hot Jupiters are believed to have negligible to no axial tilt as a result of their proximity to their stars.
Rotation.
The planets rotate around invisible axes through their centres. A planet's rotation period is known as a stellar day. Most of the planets in the Solar System rotate in the same direction as they orbit the Sun, which is counter-clockwise as seen from above the Sun's north pole, the exceptions being Venus and Uranus, which rotate clockwise, though Uranus's extreme axial tilt means there are differing conventions on which of its poles is "north", and therefore whether it is rotating clockwise or anti-clockwise. Regardless of which convention is used, Uranus has a retrograde rotation relative to its orbit.
The rotation of a planet can be induced by several factors during formation. A net angular momentum can be induced by the individual angular momentum contributions of accreted objects. The accretion of gas by the giant planets can also contribute to the angular momentum. Finally, during the last stages of planet building, a stochastic process of protoplanetary accretion can randomly alter the spin axis of the planet. There is great variation in the length of day between the planets, with Venus taking 243 days to rotate, and the giant planets only a few hours. The rotational periods of extrasolar planets are not known, but their proximity to their stars means that hot Jupiters are tidally locked (their orbits are in sync with their rotations). This means they only ever show one face to their stars, with one side in perpetual day, the other in perpetual night.
Orbital clearing.
The defining dynamic characteristic of a planet is that it has "cleared its neighborhood". A planet that has cleared its neighborhood has accumulated enough mass to gather up or sweep away all the planetesimals in its orbit. In effect, it orbits its star in isolation, as opposed to sharing its orbit with a multitude of similar-sized objects. This characteristic was mandated as part of the IAU's official definition of a planet in August, 2006. This criterion excludes such planetary bodies as Pluto, Eris and Ceres from full-fledged planethood, making them instead dwarf planets. Although to date this criterion only applies to the Solar System, a number of young extrasolar systems have been found in which evidence suggests orbital clearing is taking place within their circumstellar discs.
Physical characteristics.
Mass.
A planet's defining physical characteristic is that it is massive enough for the force of its own gravity to dominate over the electromagnetic forces binding its physical structure, leading to a state of hydrostatic equilibrium. This effectively means that all planets are spherical or spheroidal. Up to a certain mass, an object can be irregular in shape, but beyond that point, which varies depending on the chemical makeup of the object, gravity begins to pull an object towards its own centre of mass until the object collapses into a sphere.
Mass is also the prime attribute by which planets are distinguished from stars. The upper mass limit for planethood is roughly 13 times Jupiter's mass for objects with solar-type isotopic abundance, beyond which it achieves conditions suitable for nuclear fusion. Other than the Sun, no objects of such mass exist in the Solar System; but there are exoplanets of this size. The 13-Jupiter-mass limit is not universally agreed upon and the Extrasolar Planets Encyclopaedia includes objects up to 20 Jupiter masses, and the Exoplanet Data Explorer up to 24 Jupiter masses.
The smallest known planet is PSR B1257+12A, one of the first extrasolar planets discovered, which was found in 1992 in orbit around a pulsar. Its mass is roughly half that of the planet Mercury. The smallest known planet orbiting a main-sequence star other than the Sun is Kepler-37b, with a mass (and radius) slightly higher than that of the Moon.
Internal differentiation.
Every planet began its existence in an entirely fluid state; in early formation, the denser, heavier materials sank to the centre, leaving the lighter materials near the surface. Each therefore has a differentiated interior consisting of a dense planetary core surrounded by a mantle that either is or was a fluid. The terrestrial planets are sealed within hard crusts, but in the giant planets the mantle simply blends into the upper cloud layers. The terrestrial planets have cores of elements such as iron and nickel, and mantles of silicates. Jupiter and Saturn are believed to have cores of rock and metal surrounded by mantles of metallic hydrogen. Uranus and Neptune, which are smaller, have rocky cores surrounded by mantles of water, ammonia, methane and other ices. The fluid action within these planets' cores creates a geodynamo that generates a magnetic field.
Atmosphere.
All of the Solar System planets except Mercury have substantial atmospheres because their gravity is strong enough to keep gases close to the surface. The larger giant planets are massive enough to keep large amounts of the light gases hydrogen and helium, whereas the smaller planets lose these gases into space. The composition of Earth's atmosphere is different from the other planets because the various life processes that have transpired on the planet have introduced free molecular oxygen.
Planetary atmospheres are affected by the varying insolation or internal energy, leading to the formation of dynamic weather systems such as hurricanes, (on Earth), planet-wide dust storms (on Mars), an Earth-sized anticyclone on Jupiter (called the Great Red Spot), and holes in the atmosphere (on Neptune). At least one extrasolar planet, HD 189733 b, has been claimed to have such a weather system, similar to the Great Red Spot but twice as large.
Hot Jupiters, due to their extreme proximities to their host stars, have been shown to be losing their atmospheres into space due to stellar radiation, much like the tails of comets. These planets may have vast differences in temperature between their day and night sides that produce supersonic winds, although the day and night sides of HD 189733 b appear to have very similar temperatures, indicating that that planet's atmosphere effectively redistributes the star's energy around the planet.
Magnetosphere.
One important characteristic of the planets is their intrinsic magnetic moments, which in turn give rise to magnetospheres. The presence of a magnetic field indicates that the planet is still geologically alive. In other words, magnetized planets have flows of electrically conducting material in their interiors, which generate their magnetic fields. These fields significantly change the interaction of the planet and solar wind. A magnetized planet creates a cavity in the solar wind around itself called magnetosphere, which the wind cannot penetrate. The magnetosphere can be much larger than the planet itself. In contrast, non-magnetized planets have only small magnetospheres induced by interaction of the ionosphere with the solar wind, which cannot effectively protect the planet.
Of the eight planets in the Solar System, only Venus and Mars lack such a magnetic field. In addition, the moon of Jupiter Ganymede also has one. Of the magnetized planets the magnetic field of Mercury is the weakest, and is barely able to deflect the solar wind. Ganymede's magnetic field is several times larger, and Jupiter's is the strongest in the Solar System (so strong in fact that it poses a serious health risk to future manned missions to its moons). The magnetic fields of the other giant planets are roughly similar in strength to that of Earth, but their magnetic moments are significantly larger. The magnetic fields of Uranus and Neptune are strongly tilted relative the rotational axis and displaced from the centre of the planet.
In 2004, a team of astronomers in Hawaii observed an extrasolar planet around the star HD 179949, which appeared to be creating a sunspot on the surface of its parent star. The team hypothesized that the planet's magnetosphere was transferring energy onto the star's surface, increasing its already high 7,760 °C temperature by an additional 400 °C.
Secondary characteristics.
Several planets or dwarf planets in the Solar System (such as Neptune and Pluto) have orbital periods that are in resonance with each other or with smaller bodies (this is also common in satellite systems). All except Mercury and Venus have natural satellites, often called "moons". Earth has one, Mars has two, and the giant planets have numerous moons in complex planetary-type systems. Many moons of the giant planets have features similar to those on the terrestrial planets and dwarf planets, and some have been studied as possible abodes of life (especially Europa).
The four giant planets are also orbited by planetary rings of varying size and complexity. The rings are composed primarily of dust or particulate matter, but can host tiny 'moonlets' whose gravity shapes and maintains their structure. Although the origins of planetary rings is not precisely known, they are believed to be the result of natural satellites that fell below their parent planet's Roche limit and were torn apart by tidal forces.
No secondary characteristics have been observed around extrasolar planets. The sub-brown dwarf Cha 110913-773444, which has been described as a rogue planet, is believed to be orbited by a tiny protoplanetary disc and the sub-brown dwarf OTS 44 was shown to be surrounded by a substantial protoplanetary disk of at least 10 Earth masses.

</doc>
<doc id="22918" url="http://en.wikipedia.org/wiki?curid=22918" title="Paramount Pictures">
Paramount Pictures

Paramount Pictures Corporation (commonly known as Paramount Pictures or simply Paramount, and formerly known as Famous Players-Lasky Corporation) is a film studio, television production company and motion picture distributor, consistently ranked as one of the "Big Six" film studios of Hollywood. It is a subsidiary of U.S. media conglomerate Viacom. Paramount is a member of the Motion Picture Association of America (MPAA). It has distributed several successful film series, such as "Transformers", "", the Marvel Cinematic Universe series (2008–11), "Indiana Jones" (1981–2008), "The Godfather", "Star Trek", "Jack Ryan", "Jackass", "The Bad News Bears", "Beverly Hills Cop", ""Crocodile" Dundee", "Paranormal Activity", "Friday the 13th" and "G.I. Joe".
In 2014, Paramount Pictures became the first major Hollywood studio to distribute all of its films in digital-form only.
History.
1911–1920: Early history.
Paramount is the fifth oldest surviving film studio in the world after the French studios Gaumont Film Company (1895) and Pathé (1896), followed by the Nordisk Film company (1906), and Universal Studios (1912). It is the last major film studio still headquartered in the Hollywood district of Los Angeles.
Paramount Pictures dates its existence from the 1912 founding date of the Famous Players Film Company. Founder Hungarian-born Adolph Zukor, who had been an early investor in nickelodeons, saw that movies appealed mainly to working-class immigrants. With partners Daniel Frohman and Charles Frohman he planned to offer feature-length films that would appeal to the middle class by featuring the leading theatrical players of the time (leading to the slogan "Famous Players in Famous Plays"). By mid-1913, Famous Players had completed five films, and Zukor was on his way to success.
That same year, another aspiring producer, Jesse L. Lasky, opened his Lasky Feature Play Company with money borrowed from his brother-in-law, Samuel Goldfish, later known as Samuel Goldwyn. The Lasky company hired as their first employee a stage director with virtually no film experience, Cecil B. DeMille, who would find a suitable location site in Hollywood, near Los Angeles, for his first feature film, "The Squaw Man".
Starting in 1914, both Lasky and Famous Players released their films through a start-up company, Paramount Pictures Corporation, organized early that year by a Utah theatre owner, W. W. Hodkinson, who had bought and merged several smaller firms. Hodkinson and actor, director, producer Hobart Bosworth had started production of a series of Jack London movies. Paramount was the first successful nationwide distributor; until this time, films were sold on a statewide or regional basis which had proved costly to film producers. Also, Famous Players and Lasky were privately owned while Paramount was a corporation.
In 1916, Zukor maneuvered a three-way merger of his Famous Players, the Lasky Company, and Paramount. Zukor and Lasky bought Hodkinson out of Paramount, and merged the three companies into one. The new company Lasky and Zukor founded, Famous Players-Lasky Corporation, grew quickly, with Lasky and his partners Goldwyn and DeMille running the production side, Hiram Abrams in charge of distribution, and Zukor making great plans. With only the exhibitor-owned First National as a rival, Famous Players-Lasky and its "Paramount Pictures" soon dominated the business.
1921–1930: The rise.
Because Zukor believed in stars, he signed and developed many of the leading early stars, including Mary Pickford, Marguerite Clark, Pauline Frederick, Douglas Fairbanks, Gloria Swanson, Rudolph Valentino, and Wallace Reid. With so many important players, Paramount was able to introduce "block booking", which meant that an exhibitor who wanted a particular star's films had to buy a year's worth of other Paramount productions. It was this system that gave Paramount a leading position in the 1920s and 1930s, but which led the government to pursue it on antitrust grounds for more than twenty years.
The driving force behind Paramount's rise was Zukor. Through the teens and twenties, he built the Publix Theatres Corporation, a chain of nearly 2,000 screens, ran two production studios (in Astoria, New York, and Hollywood, California), and became an early investor in radio, taking a 50% interest in the new Columbia Broadcasting System in 1928 (selling it within a few years; this would not be the last time Paramount and CBS crossed paths).
In 1926, Zukor hired independent producer B. P. Schulberg, an unerring eye for new talent, to run the new West Coast operations. They purchased the Robert Brunton Studios, a 26-acre facility at 5451 Marathon Street for US$1 million. In 1927, Famous Players-Lasky took the name Paramount Famous Lasky Corporation. Three years later, because of the importance of the Publix Theatres, it became Paramount Publix Corporation.
In 1928, Paramount began releasing "Inkwell Imps," animated cartoons produced by Max and Dave Fleischer's Fleischer Studios in New York City. The Fleischers, veterans in the animation industry, were among the few animation producers capable of challenging the prominence of Walt Disney. The Paramount newsreel series Paramount News ran from 1927 to 1957. In 1929 Paramount Released their first musical "Innocents of Paris." Richard A. Whiting and Leo Robin composed the score for the film; Maurice Chevalier starred and sung the most famous song from the film, "Louise".
Publix, Balaban and Katz, Loew's competition, and wonder theaters.
By acquiring the successful Balaban & Katz chain in 1926, Zukor gained the services of Barney Balaban (who would eventually become Paramount's president in 1936), his brother A. J. Balaban (who would eventually supervise all stage production nationwide and produce talkie shorts), and their partner Sam Katz (who would run the Paramount-Publix theatre chain in New York City from the thirty-five-story Paramount Theatre Building on Times Square).
Balaban and Katz had developed the Wonder Theater concept, first publicized around 1918 in Chicago. The Chicago Theater was created as a very ornate theater and advertised as a "wonder theater." When Publix acquired Balaban, they embarked on a project to expand the wonder theaters, and starting building in New York in 1927. While Balaban and Public were dominant in Chicago, Loew's was the big player in New York, and did not want the Publix theaters to overshadow theirs. The two companies brokered a non-competition deal for New York and Chicago, and Loew's took over the New York area projects, developing five wonder theaters. Publix continued Balaban's wonder theater development in its home area.
1931–1940: Receivership.
Eventually, Zukor shed most of his early partners; the Frohman brothers, Hodkinson and Goldwyn were out by 1917 while Lasky hung on until 1932, when, blamed for the near-collapse of Paramount in the Depression years, he too was tossed out. Zukor's over-expansion and use of overvalued Paramount stock for purchases led the company into receivership in 1933. A bank-mandated reorganization team, led by John Hertz and Otto Kahn kept the company intact, and, miraculously, Zukor was kept on. In 1935, Paramount-Publix went bankrupt. In 1936, Barney Balaban became president, and Zukor was bumped up to chairman of the board. In this role, Zukor reorganized the company as Paramount Pictures, Inc. and was able to successfully bring the studio out of bankruptcy.
As always, Paramount films continued to emphasize stars; in the 1920s there were Swanson, Valentino, and Clara Bow. By the 1930s, talkies brought in a range of powerful new draws: Miriam Hopkins, Marlene Dietrich, Mae West, W.C. Fields, Jeanette MacDonald, Claudette Colbert, the Marx Brothers (whose first two films were shot at Paramount's Astoria, New York, studio), Dorothy Lamour, Carole Lombard, Bing Crosby, band leader Shep Fields, famous Argentine tango singer Carlos Gardel, and Gary Cooper among them. In this period Paramount can truly be described as a movie factory, turning out sixty to seventy pictures a year. Such were the benefits of having a huge theater chain to fill, and of block booking to persuade other chains to go along. In 1933, Mae West would also add greatly to Paramount's success with her suggestive movies "She Done Him Wrong" and "I'm No Angel". However, the sex appeal West gave in these movies would also lead to the enforcement of the Production Code, as the newly formed organization the Catholic Legion of Decency threatened a boycott if it was not enforced.
Paramount cartoons produced by Fleischer Studios continued to be successful, with characters such as Betty Boop and Popeye the Sailor becoming widely successful. One Fleischer series, "Screen Songs", featured live-action music stars under contract to Paramount hosting sing-alongs of popular songs. However, a huge blow to Fleischer Studios occurred in 1934, after the Production Code was enforced and Betty Boop's popularity declined as she was forced to have a more tame personality and wear a longer skirt. The animation studio would rebound with Popeye, and in 1935, polls showed that Popeye was even more popular than Mickey Mouse. After an unsuccessful expansion into feature films, as well as the fact that Max and Dave Fleischer were no longer speaking to one another, Fleischer Studios was acquired by Paramount, which renamed the operation Famous Studios. That incarnation of the animation studio continued cartoon production until 1967, but has been historically dismissed as having largely failed to maintain the artistic acclaim the Fleischer brothers achieved under their management.
1941–1950: United States v. Paramount Pictures, Inc..
In 1940, Paramount agreed to a government-instituted consent decree: block booking and "pre-selling" (the practice of collecting up-front money for films not yet in production) would end. Immediately Paramount cut back on production, from seventy-one pictures to a more modest nineteen annually in the war years. Still, with more new stars like Bob Hope, Alan Ladd, Veronica Lake, Paulette Goddard, and Betty Hutton, and with war-time attendance at astronomical numbers, Paramount and the other integrated studio-theatre combines made more money than ever. At this, the Federal Trade Commission and the Justice Department decided to reopen their case against the five integrated studios. Paramount also had a monopoly over Detroit movie theaters through subsidiary company United Detroit Theaters as well. This led to the Supreme Court decision United States v. Paramount Pictures, Inc. (1948) holding that movie studios could not also own movie theater chains. This decision broke up Adolph Zukor's creation and effectively brought an end to the classic Hollywood studio system.
1951–1966: Split and after.
With the separation of production and exhibition forced by the U.S. Supreme Court, Paramount Pictures Inc. was split in two. Paramount Pictures Corporation was formed to be the production distribution company, with the 1,500-screen theater chain handed to the new United Paramount Theaters on December 31, 1949. Leonard Goldenson, who had headed the chain since 1938, remained as the new company's president. The Balaban and Katz theatre division was spun off with UPT; its trademark eventually became the property of the Balaban and Katz Historical Foundation. The Foundation has recently acquired ownership of the Famous Players Trademark. Cash-rich and controlling prime downtown real estate, Goldenson began looking for investments. Barred from film-making by prior anti-trust rulings, he acquired the struggling ABC television network in February 1953, leading it first to financial health, and eventually, in the mid-1970s, to first place in the national Nielsen ratings, before selling out to Capital Cities in 1985 (Capital Cities would eventually sell out, in turn, to The Walt Disney Company in 1996). United Paramount Theaters was renamed ABC Theaters in 1965 and was sold to businessman Henry Plitt in 1974. The movie theater chain was renamed Plitt Theaters. In 1985, Cineplex Odeon Corporation merged with Plitt. In later years, Paramount's TV division would develop a strong relationship with ABC, providing many hit series to the network.
The DuMont Network.
Paramount Pictures had been an early backer of television, launching experimental stations in 1939 in Los Angeles and Chicago. The Los Angeles station eventually became KTLA, the first commercial station on the West Coast. The Chicago station got a commercial license as WBKB in 1943, but was sold to UPT along with Balaban & Katz in 1948 and was eventually resold to CBS as WBBM-TV.
In 1938, Paramount bought a stake in television manufacturer DuMont Laboratories. Through this stake, it became a minority owner of the DuMont Television Network. Also Paramount launched its own network, Paramount Television Network, in 1948 through its television unit, Television Productions, Inc.
However, Paramount proved to be a timid and obstructionist partner in DuMont; its minority stake hampered the network's efforts to expand. Paramount management planned to acquire additional owned-and-operated stations ("O&Os"); the company applied to the FCC for additional stations in San Francisco, Detroit, and Boston. The FCC, however, denied Paramount's applications. A few years earlier, the federal regulator had placed a five-station cap on all television networks: no network was allowed to own more than five VHF television stations. Paramount was hampered by its minority stake in the DuMont Television Network. Although both DuMont and Paramount executives stated that the companies were separate, the FCC ruled that Paramount's partial ownership of DuMont meant that DuMont and Paramount were in theory branches of the same company. Since DuMont owned three television stations and Paramount owned two, the federal agency ruled neither network could acquire additional television stations. The FCC requested that Paramount relinquish its stake in DuMont, but Paramount refused. According to television historian William Boddy, "Paramount's checkered anti-trust history" helped convince the FCC that Paramount controlled DuMont. Both DuMont and Paramount Television Network suffered as a result, with neither company able to acquire five O&Os. Meanwhile, CBS, ABC, and NBC had each acquired the maximum of five stations by the mid-1950s.
When ABC accepted a merger offer from UPT in 1953, DuMont quickly realized that ABC now had more resources than it could possibly hope to match. It quickly reached an agreement in principle to merge with ABC. However, Paramount vetoed the deal in part due to an earlier FCC ruling that Paramount controlled DuMont, as well as concerns that UPT was still a Paramount subsidiary. Within two years of the failed ABC deal, DuMont was no more.
In 1951, Paramount bought a stake in International Telemeter, an experimental pay TV service which operated with a coin inserted into a box. The service began operating in Palm Springs, California on November 27, 1953, but due to pressure from the FCC, the service ended on May 15, 1954.
With the loss of the theater chain, Paramount Pictures went into a decline, cutting studio-backed production, releasing its contract players, and making production deals with independents. By the mid-1950s, all the great names were gone; only C.B. DeMille, associated with Paramount since 1913, kept making pictures in the grand old style. Despite Paramount's losses, DeMille would, however, give the studio some relief and create his most successful film at Paramount, a 1956 remake of his 1923 film "The Ten Commandments". DeMille died in 1959. Like some other studios, Paramount saw little value in its film library, and sold 764 of its pre-1948 films to MCA Inc. (known today as Universal Studios Inc.) in February 1958.
1966–1970: Early Gulf+Western era.
By the early 1960s, Paramount's future was doubtful. The high-risk movie business was wobbly; the theater chain was long gone; investments in DuMont and in early pay-television came to nothing; and the end of the Golden Age of Hollywood, even the flagship Paramount building in Times Square was sold to raise cash, as was KTLA (sold to Gene Autry in 1964 for a then-phenomenal $12.5 million). Founding father Adolph Zukor (born in 1873) was still chairman emeritus; he referred to chairman Barney Balaban (born 1888) as "the boy." Such aged leadership was incapable of keeping up with the changing times, and in 1966, a sinking Paramount was sold to Charles Bluhdorn's industrial conglomerate, Gulf + Western Industries Corporation. Bluhdorn immediately put his stamp on the studio, installing a virtually unknown producer named Robert Evans as head of production. Despite some rough times, Evans held the job for eight years, restoring Paramount's reputation for commercial success with "The Odd Couple", "Love Story", "The Godfather", "3 Days of the Condor", "Chinatown", and "Rosemary's Baby."
Gulf + Western Industries also bought the neighboring Desilu television studio (once the lot of RKO Pictures) from Lucille Ball in 1967. Using some of Desilu's established shows such as ', ', and "Mannix" as a foot in the door at the networks, the newly reincorporated Paramount Television eventually became known as a specialist in half-hour situation comedies.
1971–1980: CIC formation and high-concept era.
In 1970, Paramount teamed with Universal Studios to form Cinema International Corporation, a new company that would distribute films by the two studios outside the United States. Metro-Goldwyn-Mayer would become a partner in the mid-1970s. Both Paramount and CIC entered the video market with Paramount Home Video (now Paramount Home Entertainment) and CIC Video, respectively.
Robert Evans abandoned his position as head of production in 1974; his successor, Richard Sylbert, proved to be too literary and too tasteful for Gulf + Western's Bluhdorn. By 1976, a new, television-trained team was in place headed by Barry Diller and his "Killer-Dillers", as they were called by admirers or "Dillettes" as they were called by detractors. These associates, made up of Michael Eisner, Jeffrey Katzenberg, Dawn Steel and Don Simpson would each go on and head up major movie studios of their own later in their careers.
The Paramount specialty was now simpler. "High concept" pictures such as "Saturday Night Fever" and "Grease" hit big, hit hard and hit fast all over the world, and Diller's television background led him to propose one of his longest-standing ideas to the board: Paramount Television Service, a fourth commercial network. Paramount Pictures purchased the Hughes Television Network (HTN) including its satellite time in planning for PTVS in 1976. Paramount sold HTN to Madison Square Garden in 1979. But Diller believed strongly in the concept, and so took his fourth-network idea with him when he moved to 20th Century Fox in 1984, where Fox's then freshly installed proprietor, Rupert Murdoch was a more interested listener. Meanwhile, concentrating on hot films, Paramount was met with critical success with the release of "The Godfather", based on the popular novel.
However, the television division would be playing catch-up for over a decade after Diller's departure in 1984 before launching its own television network – UPN – in 1995. Lasting eleven years before being merged with The WB network to become The CW in 2006, UPN would feature many of the shows it originally produced for other networks, and would take numerous gambles on series such as ' and ' that would have otherwise either gone direct-to-cable or become first-run syndication to independent stations across the country (as ' and ' were).
Paramount Pictures was not connected to either Paramount Records (1910s-1935) or ABC-Paramount Records (1955–66) until it purchased the rights to use the name (but not the latter's catalog) in the late 1960s. The Paramount name was used for soundtrack albums and some pop re-issues from the Dot Records catalog which Paramount had acquired in 1958. By 1970, Dot had become an all-country label and in 1974, Paramount sold all of its record holdings to ABC Records, which in turn was sold to MCA (now Universal Music Group) in 1979.
1980–1994: Continuous success.
Paramount's successful run of pictures extended into the 1980s and 1990s, generating hits like "Airplane!", "American Gigolo", "Ordinary People", "An Officer and a Gentleman", "Flashdance", "Terms of Endearment", "Footloose", "Pretty in Pink", "Top Gun", ""Crocodile" Dundee", "Fatal Attraction", "Ghost", the "Friday the 13th" slasher series, as well as "Raiders of the Lost Ark" and its sequels. Other examples are the "Star Trek" series and a string of films starring comedian Eddie Murphy like "Trading Places", "Coming to America", and "Beverly Hills Cop" and its sequels. While the emphasis was decidedly on the commercial, there were occasional less commercial but more artistic and intellectual efforts like "I'm Dancing as Fast as I Can", "Atlantic City", "Reds", "Witness", "Children of a Lesser God" and "The Accused". During this period, responsibility for running the studio passed from Eisner and Katzenberg to Frank Mancuso, Sr. (1984) and Ned Tanen (1984) to Stanley R. Jaffe (1991) and Sherry Lansing (1992). More so than most, Paramount's slate of films included many remakes and television spinoffs; while sometimes commercially successful, there have been few compelling films of the kind that once made Paramount the industry leader.
In August 25, 1983, fire struck the Paramount Studios. Two or three sound stages and four outdoor sets were destroyed, but the rest of the Studios were still intact.
When Charles Bluhdorn died unexpectedly, his successor Martin Davis dumped all of G+W's industrial, mining, and sugar-growing subsidiaries and refocused the company, renaming it Paramount Communications in 1989. With the influx of cash from the sale of G+W's industrial properties in the mid-1980s, Paramount bought a string of television stations and KECO Entertainment's theme park operations, renaming them Paramount Parks. These parks included Paramount's Great America, Paramount Canada's Wonderland, Paramount's Carowinds, Paramount's Kings Dominion, and Paramount's Kings Island.
In 1993, Sumner Redstone's entertainment conglomerate Viacom made a bid for a merger with Paramount Communications; this quickly escalated into a bidding war with Barry Diller's QVC. But Viacom prevailed, ultimately paying $10 billion for the Paramount holdings. Viacom and Paramount had planned to merge as early as 1989.
Paramount is the last major film studio located in Hollywood proper. When Paramount moved to its present home in 1927, it was in the heart of the film community. Since then, former next-door neighbor RKO closed up shop in 1957; Warner Bros. (whose old Sunset Boulevard studio was sold to Paramount in 1949 as a home for KTLA) moved to Burbank in 1930; Columbia joined Warners in Burbank in 1973 then moved again to Culver City in 1989; and the Pickford-Fairbanks-Goldwyn-United Artists lot, after a lively history, has been turned into a post-production and music-scoring facility for Warners, known simply as "The Lot". For a time the semi-industrial neighborhood around Paramount was in decline, but has now come back. The recently refurbished studio has come to symbolize Hollywood for many visitors, and its studio tour is a popular attraction.
1994–2004: Dolgen/Lansing and "old" Viacom era.
During this time period, Paramount Pictures went under the guidance of Jonathan Dolgen, chairman and Sherry Lansing, president. During their administration over Paramount, the studio had an extremely successful period of films with two of Paramount's ten highest grossing films being produced during this period. The most successful of these films, "Titanic", a joint production with 20th Century Fox, became the highest grossing film up to that time, grossing over $1.8 billion worldwide. Also during this time, three Paramount Pictures films won the Academy Award for Best Picture; "Titanic, Braveheart", and "Forrest Gump".
Paramount's most important property, however, was "Star Trek". Studio executives had begun to call it "the franchise" in the 1980s due to its reliable revenue, and other studios envied its "untouchable and unduplicatable" success. By 1998 "Star Trek" TV shows, movies, books, videotapes, and licensing provided so much of the studio's profit that "it is not possible to spend any reasonable amount of time at Paramount and not be aware of [its] presence"; filming for "Star Trek: Voyager" and "Star Trek: Deep Space Nine" required up to nine of the largest of the studio's 36 sound stages.:49–50,54
In 1995, Viacom and Chris-Craft Industries' United Television launched United Paramount Network (UPN) with "Star Trek: Voyager" as its flagship series, fulfilling Barry Diller's plan for a Paramount network from 25 years earlier. In 1999, Viacom bought out United Television's interests, and handed responsibility for the start-up network to the newly acquired CBS unit, which Viacom bought in 1999 – an ironic confluence of events as Paramount had once invested in CBS, and Viacom had once been the syndication arm of CBS as well. During this period the studio acquired some 30 TV stations to support the UPN network as well acquiring and merging in the assets of Republic Pictures, Spelling Television and Viacom Television, almost doubling the size of the studio's TV library. The TV division produced the dominant prime time show for the decade in "Frasier" as well as such long running hits as NCSI and "Becker" and the dominant prime time magazine show "Entertainment Tonight."
During this period, Paramount and its related subsidiaries and affiliates, operating under the name "Viacom Entertainment Group" also included the fourth largest group of theme parks in the United States and Canada which in addition to traditional rides and attractions launched numerous successful location based entertainment units including a long running "Star Trek" attraction at the Las Vegas Hilton. Famous Music - the company's celebrated music publishing arm almost doubled in size and developed artists including Pink, Bush, Green Day as well as catalog favorites including Duke Ellington and Henry Mancini. The Paramount/Viacom licensing group under the leadership of Tom McGrath created the "Cheers" franchise bars and restaurants and a chain of restaurants borrowing from the studio's academy award winning film "Forrest Gump" - "The Bubba Gump Shrimp Company". Through the combined efforts of Famous Music and the studio over ten "Broadway" musicals were created including Irving Berlin's "White Christmas", "Footloose, Saturday Night Fever", Andrew Lloyd Weber's "Sunset Boulevard" among others. The Company's international arm, United International Pictures (UIP), was the dominant distributor internationally for ten straight years representing Paramount, Universal and MGM. Simon and Schuster became part of the Viacom Entertainment Group emerging as the US' dominant trade book publisher.
In 2002, Paramount, Buena Vista Distribution, 20th Century Fox, Sony Pictures, Universal Studios, and Warner Bros. formed the Digital Cinema Initiatives. Operating under a waiver form the anti-trust law, the studios combined under the leadership of Paramount Chief Operating Officer Tom McGrath to develop technical standards for the eventual introduction of digital film projection - replacing the now 100 year old film technology. DCI was created "to establish and document voluntary specifications for an open architecture for digital cinema that ensures a uniform and high level of technical performance, reliability and quality control." McGrath also headed up Paramount's initiative for the creation and launch of the Blu-ray DVD.
2005: Dissolution of the Viacom Entertainment Group and Paramount.
In 2005, Viacom announced the spinoff of CBS into a separate public entity. As part of this spinoff, the Entertainment Group that was led by Dolgen, Lansing and McGrath, was dissolved and Paramount broken up into its separate assets. Famous Music, part of the company since its founding by Jesse Lasky, was sold to Sony Music. The UPN network and its TV stations were transferred to CBS. Paramount itself was broken into two parts and the television production and assets were stripped and made part of CBS. The theme parks group was sold to Cedar Fair in 2006 and renamed the parks by taking out the "Paramount's" prefix. Simon and Schuster also became part of CBS. The company's three chains of movie theaters were divested - Famous Players Theaters, the dominant theater circuit in Canada was sold to its competitor Cineplex Odeon. UCI which dominated the international theater markets consisting of 1300+ screens in 11 countries was sold to buyout firm Terra Firma. Mann Theaters was slowly divested screen by screen with the world famous "Graumann's Chinese Theater" being sold to a consortium led by Eli Samaha.
The resulting company, approximately 20% of its former size coalesced in 2006 under the leadership of its new CEO, Brad Grey who held the same title as Sherry Lansing despite the much smaller size of the business under his leadership.
2005–present: Paramount today.
CBS Corporation/Viacom split.
Reflecting in part the troubles of the broadcasting business, in 2005 Viacom wrote off over $18 billion from its radio acquisitions and, early that year, announced that it would split itself in two. The split was completed in January 2006.
With the announcement of the split of Viacom, Dolgen and Lansing were replaced by former television executives Brad Grey and Gail Berman. The Viacom Inc. board split the company into CBS Corporation and a separate company under the Viacom name. The board scheduled the division for the first quarter of 2006. Under the plan, CBS Corp. would comprise CBS and UPN networks, Viacom Television Stations Group, Infinity Broadcasting, Viacom Outdoor, Paramount Television, KingWorld, Showtime, Simon and Schuster, Paramount Parks, and CBS News. The revamped Viacom would include "MTV, VH1, Nickelodeon, BET and several other cable networks as well as the Paramount movie studio". Paramount's home entertainment unit continues to distribute the Paramount TV library through CBS DVD, as both Viacom and CBS Corporation are controlled by Sumner Redstone's National Amusements.
In 2009, CBS stopped using the Paramount name in its series and changed the name of the production arm to CBS Television Studios, eliminating the Paramount name from television, to distance itself from the latter.
DreamWorks purchased.
On December 11, 2005, The Paramount Motion Pictures Group announced that it had purchased DreamWorks SKG (which was co-founded by former Paramount executive Jeffrey Katzenberg) in a deal worth $1.6 billion. The announcement was made by Brad Grey, chairman and CEO of Paramount Pictures who noted that enhancing Paramount's pipeline of pictures is a "key strategic objective in restoring Paramount's stature as a leader in filmed entertainment." The agreement does not include DreamWorks Animation SKG Inc., the most profitable part of the company that went public the previous year.
Under the deal, Paramount is required to distribute the DreamWorks animated films for a small fee intended only to cover Paramount's costs with no profit to the studio, including the "Shrek" franchise (and ending for the 2004 installment, "Shrek 2"). The first film distributed under this deal was "Over the Hedge".
The deal closed on February 6, 2006. This acquisition was seen at the time as a stopgap measure as Brad Grey had been unsuccessful in assembling sufficient films for production and distribution and the DreamWorks films would fill the gap.
On October 6, 2008, DreamWorks executives announced that they were leaving Paramount and relaunching an independent DreamWorks. The DreamWorks trademarks remained with DreamWorks Animation when that company was spun off before the Paramount purchase, and DreamWorks Animation transferred the license to the name to the new company.
UIP, Famous Music, and Digital Entertainment.
Grey also broke up the famous UIP international distribution company, the most successful international film distributor in history, after a 25-year partnership with Universal Studios and has started up a new international group. As a consequence Paramount fell from No.1 in the international markets to the lowest ranked major studio in 2006 but recovered in 2007.
DreamWorks films, acquired by Paramount but still distributed internationally by Universal, are included in Paramount's market share.
Grey also launched a Digital Entertainment division to take advantage of emerging digital distribution technologies. This led to Paramount becoming the second movie studio to sign a deal with Apple Inc. to sell its films through the iTunes Store.
Also, in 2007, Paramount sold another one of its "heritage" units, Famous Music, to Sony/ATV Music Publishing (best known for publishing many songs by The Beatles, and for being co-owned by Michael Jackson), ending a nearly-eight-decade run as a division of Paramount, being the studio's music publishing arm since the period when the entire company went by the name "Famous Players."
In early 2008, Paramount partnered with Los Angeles-based developer FanRocket to make short scenes taken from its film library available to users on Facebook. The application, called VooZoo, allows users to send movie clips to other Facebook users and to post clips on their profile pages. Paramount engineered a similar deal with Makena Technologies to allow users of vMTV and There.com to view and send movie clips.
In March 2010, Paramount founded Insurge Pictures, an independent distributor of "micro budget" films. The distributor planned ten movies with budgets of $100,000 each. The first release was "The Devil Inside", a movie with a budget of about US$1 million.
In March 2015, following waning box office returns, Paramount shuttered Insurge Pictures and moved its operations to the main studio.
In July 2011, in the wake of critical and box office success of the animated feature, "Rango", and the departure of DreamWorks Animation upon completion of their distribution contract in 2012, Paramount announced the formation of a new division, devoted to the creation of animated productions. It marks Paramount's return to having its own animated division for the first time since 1967, when Paramount Cartoon Studios shut down (it was formerly Famous Studios until 1956).
In December 2013, The Walt Disney Studios (via its parent company's purchase of LucasFilm, Ltd. a year earlier) purchased Paramount's remaining distribution and marketing rights to future "Indiana Jones" films, while Paramount will continue to distribute the first four films for Disney, and will receive "financial participation" from any additional films.
Investments.
DreamWorks.
In 2006, Paramount became the parent of DreamWorks SKG. Soros Strategic Partners and Dune Entertainment II soon afterwards acquired controlling interest in the live-action films released through September 16, 2005, the latest film in this package was "Just Like Heaven". The remaining live-action films through March 2006 remained under direct Paramount control.
However, Paramount does own distribution (and other ancillary) rights to the Soros/Dune films.
On February 8, 2010, Viacom repurchased Soros' controlling stake in the pre-2005 DreamWorks Pictures library for around $400 million.
Even as DreamWorks switches distribution of live-action films that are not part of existing franchises to Walt Disney Studios Motion Pictures, Paramount will continue to own the films released before the merger, and the films that Paramount themselves distributed (including sequel rights; such films as "Little Fockers" will be distributed by Paramount and DreamWorks, since it is a sequel to an existing DreamWorks film – in this case, "Meet the Parents" and "Meet the Fockers", though Paramount will only own international rights to this title, whereas Universal Studios will handle domestic distribution).
As for the DreamWorks Animation library, Paramount owned distribution rights to the pre-2013 library, and their previous distribution deal to future DWA titles expired at the end of 2012 with the last Paramount-distributed feature, "Rise of the Guardians". 20th Century Fox now handles distribution on future titles beginning with "The Croods", though Paramount's rights to distribute every film released by DreamWorks Animation before 2013 will expire 16 years after each film's initial theatrical release date. However in July 2014, DreamWorks Animation purchased Paramount's distribution rights to the pre-2013 library with DreamWorks Animation's current distributor 20th Century Fox to distribute the library.
The CBS library.
Independent company Hollywood Classics now represents Paramount in the theatrical distribution of all the films produced by the various motion picture divisions of CBS over the years, as a result of the Viacom/CBS merger.
Paramount (via CBS Home Entertainment) has outright video distribution to the aforementioned CBS library with few exceptions-for example, the original "Twilight Zone" DVDs are handled by Image Entertainment. Until 2009, the video rights to "My Fair Lady" were with original theatrical distributor Warner Bros., under license from CBS (the video license to that film has now reverted to CBS Home Entertainment under Paramount).
The CBS-produced/owned films, unlike other films in Paramount's library, are still distributed by CBS Television Distribution on TV, and not by Trifecta Entertainment & Media, because CBS (or a subdivision) is the copyright holder for these films.
Units.
Other interests.
In March 2012, Paramount licensed their name and logo to a luxury hotel investment group which subsequently named the company Paramount Hotels and Resorts. The investors plan to build 50 hotels throughout the world based on the themes of Hollywood and the California lifestyle. Among the features are private screening rooms and the Paramount library available in the hotel rooms. On April 2013, Paramount Hotels and Dubai-based DAMAC Properties announced the building of the first resort: "DAMAC Towers by Paramount," in Dubai.
Logo.
The distinctively pyramidal Paramount mountain has been the company's logo since its inception and is the oldest surviving Hollywood film logo. In the sound era, the logo was accompanied by a fanfare called "Paramount on Parade" after the film of the same name, released in 1930. The words to the fanfare, originally sung in the 1930 film, were "Proud of the crowd that will never be loud, it's Paramount on Parade."
Legend has it that the mountain is based on a doodle made by W. W. Hodkinson during a meeting with Adolph Zukor. It is said to be based on the memories of his childhood in Utah. Some claim that Utah's Ben Lomond is the mountain Hodkinson doodled, and that Peru's Artesonraju is the mountain in the live-action logo, while others claim that the Italian side of Monviso inspired the logo. Some editions of the logo bear a striking resemblance to the Pfeifferhorn, another Wasatch Range peak.
The motion picture logo has gone through many changes over the years:
Visiting Paramount.
Those wishing to visit Paramount can take studio tours, which are offered seven days a week. Reservations are required, and can be made by visiting the tour website. The tour offers a behind-the-scenes look at the current operations of the studio, and what can be seen varies day to day. Most of the buildings on the tour are named for historical Paramount executives or the artists that worked at Paramount over the years. Many of the stars' dressing rooms have been converted into working offices. The stages where "Samson and Delilah, Sunset Blvd.", "White Christmas", "Rear Window", "Sabrina", "Breakfast at Tiffany's", and many other classic films were shot are still in use today. The studio's backlot set, "New York Street", features numerous blocks of facades that depict a number of New York locales: "Washington Square", (where some scenes in "The Heiress", starring Olivia de Havilland, were shot) "Brooklyn", "Financial District", and others. Led by a guide on a golf cart, the tour takes approximately two hours.

</doc>
<doc id="22921" url="http://en.wikipedia.org/wiki?curid=22921" title="Psychology">
Psychology

Psychology is the study of mind and behavior. It is an academic discipline and an applied science which seeks to understand individuals and groups by establishing general principles and researching specific cases. In this field, a professional or researcher is called a psychologist and can be classified as a social, behavioral, or cognitive scientist. Psychologists attempt to understand the role of mental functions in individual and social behavior, while also exploring the physiological and biological processes that underlie cognitive functions and behaviors.
Psychologists explore concepts such as perception, cognition, attention, emotion, intelligence, phenomenology, motivation, brain functioning, personality, behavior, and interpersonal relationships, including psychological resilience, family resilience, and other areas. Psychologists of diverse orientations also consider the unconscious mind. Psychologists employ empirical methods to infer causal and correlational relationships between psychosocial variables. In addition, or in opposition, to employing empirical and deductive methods, some—especially clinical and counseling psychologists—at times rely upon symbolic interpretation and other inductive techniques. Psychology has been described as a "hub science", with psychological findings linking to research and perspectives from the social sciences, natural sciences, medicine, humanities, and philosophy.
While psychological knowledge is often applied to the assessment and treatment of mental health problems, it is also directed towards understanding and solving problems in several spheres of human activity. By many accounts psychology ultimately aims to benefit society. The majority of psychologists are involved in some kind of therapeutic role, practicing in clinical, counseling, or school settings. Many do scientific research on a wide range of topics related to mental processes and behavior, and typically work in university psychology departments or teach in other academic settings (e.g., medical schools, hospitals). Some are employed in industrial and organizational settings, or in other areas such as human development and aging, sports, health, and the media, as well as in forensic investigation and other aspects of law.
Etymology and definitions.
The word "psychology" derives from Greek roots meaning study of the psyche, or soul (ψυχή "psukhē", "breath, spirit, soul" and -λογία "-logia", "study of" or "research"). The Latin word "psychologia" was first used by the Croatian humanist and Latinist Marko Marulić in his book, "Psichiologia de ratione animae humanae" in the late 15th century or early 16th century. The earliest known reference to the word "psychology" in English was by Steven Blankaart in 1694 in "The Physical Dictionary" which refers to "Anatomy, which treats the Body, and Psychology, which treats of the Soul."
In 1890, William James defined "psychology" as "the science of mental life, both of its phenomena and their conditions". This definition enjoyed widespread currency for decades. However, this meaning was contested, notably by radical behaviorists such as John Watson, who in his 1913 manifesto defined the discipline of psychology as the acquisition of information useful to the control of behavior. Also since James defined it, the term more strongly connotes techniques of scientific experimentation. Folk psychology refers to the understanding of ordinary people, as contrasted with that of psychology professionals.
History.
The ancient civilizations of Egypt, Greece, China, India, and Persia all engaged in the philosophical study of psychology. Historians note that Greek philosophers, including Thales, Plato, and Aristotle (especially in his "De Anima" treatise), addressed the workings of the mind. As early as the 4th century BC, Greek physician Hippocrates theorized that mental disorders had physical rather than supernatural causes.
In China, psychological understanding grew from the philosophical works of Laozi and Confucius, and later from the doctrines of Buddhism. This body of knowledge involves insights drawn from introspection and observation, as well as techniques for focused thinking and acting. It frames the universe as a division of, and interaction between, physical reality and mental reality, with an emphasis on purifying the mind in order to increase virtue and power. An ancient text known as "The Yellow Emperor's Classic of Internal Medicine" identifies the brain as the nexus of wisdom and sensation, includes theories of personality based on yin–yang balance, and analyzes mental disorder in terms of physiological and social disequilibria. Chinese scholarship focused on the brain advanced in the Qing Dynasty with the work of Western-educated Fang Yizhi (1611–1671), Liu Zhi (1660–1730), and Wang Qingren (1768–1831). Wang Qingren emphasized the importance of the brain as the center of the nervous system, linked mental disorder with brain diseases, investigated the causes of dreams and insomnia, and advanced a theory of hemispheric lateralization in brain function.
Distinctions in types of awareness appear in the ancient thought of India, influenced by Hinduism. A central idea of the Upanishads is the distinction between a person's transient mundane self and their eternal unchanging soul. Divergent Hindu doctrines, and Buddhism, have challenged this hierarchy of selves, but have all emphasized the importance of reaching higher awareness. Yoga is a range of techniques used in pursuit of this goal. Much of the Sanskrit corpus was suppressed under the British East India Company followed by the British Raj in the 1800s. However, Indian doctrines influenced Western thinking via the Theosophical Society, a New Age group which became popular among Euro-American intellectuals.
Psychology was a popular topic in Enlightenment Europe. In Germany, Gottfried Wilhelm Leibniz (1646–1716) applied his principles of calculus to the mind, arguing that mental activity took place on an indivisible continuum—most notably, that among an infinity of human perceptions and desires, the difference between conscious and unconscious awareness is only a matter of degree. Christian Wolff identified psychology as its own science, writing "Psychologia empirica" in 1732 and "Psychologia rationalis" in 1734. This notion advanced further under Immanuel Kant, who established the idea of anthropology, with psychology as an important subdivision. However, Kant explicitly and notoriously rejected the idea of experimental psychology, writing that "the empirical doctrine of the soul can also never approach chemistry even as a systematic art of analysis or experimental doctrine, for in the manifold of inner observation can be separated only by mere division in thought, and cannot then be held separate and recombined at will (but still less does another thinking subject suffer himself to be experimented upon to suit our purpose), and even observation by itself already changes and displaces the state of the observed object." Having consulted philosophers Hegel and Herbart, in 1825 the Prussian state established psychology as a mandatory discipline in its rapidly expanding and highly influential educational system. However, this discipline did not yet embrace experimentation. In England, early psychology involved phrenology and the response to social problems including alcoholism, violence, and the country's well-populated mental asylums.
Beginning of experimental psychology.
Gustav Fechner began conducting psychophysics research in Leipzig in the 1830s, articulating the principle that human perception of a stimulus varies logarithmically according to its intensity. Fechner's 1950 "Elements of Psychophysics" challenged Kant's stricture against quantitative study of the mind. In Heidelberg, Hermann von Helmholtz conducted parallel research on sensory perception, and trained physiologist Wilhelm Wundt. Wundt, in turn, came to Leipzig University, establishing the psychological laboratory which brought experimental psychology to the world. Wundt focused on breaking down mental processes into the most basic components, motivated in part by an analogy to recent advances in chemistry, and its successful investigation of the elements and structure of material. Paul Flechsig and Emil Kraepelin soon created another influential psychology laboratory at Leipzig, this one focused on more on experimental psychiatry.
Psychologists in Germany, Denmark, Austria, England, and the United States soon followed Wundt in setting up laboratories. G. Stanley Hall who studied with Wundt, formed a psychology lab at Johns Hopkins University in Maryland, which became internationally influential. Hall, in turn, trained Yujiro Motora, who brought experimental psychology, emphasizing psychophysics, to the Imperial University of Tokyo. Wundt assistant Hugo Münsterberg taught psychology at Harvard to students such as Narendra Nath Sen Gupta—who, in 1905, founded a psychology department and laboratory at the University of Calcutta. Wundt students Walter Dill Scott, Lightner Witmer, and James McKeen Cattell worked on developing tests for mental ability. Catell, who also studied with eugenicist Francis Galton, went on to found the Psychological Corporation. Wittmer focused on mental testing of children; Scott, on selection of employees.
Another student of Wundt, Edward Titchener, created the psychology program at Cornell University and advanced a doctrine of "structuralist" psychology. Structuralism sought to analyze and classify different aspects of the mind, primarily through the method of introspection. William James, John Dewey and Harvey Carr advanced a more expansive doctrine called functionalism, attuned more to human–environment actions. In 1890 James wrote an influential book, "The Principles of Psychology", which expanded on the realm of structuralism, memorably described the human "stream of consciousness", and interested many American students in the emerging discipline. Dewey integrated psychology with social issues, most notably by promoting the cause progressive education to assimilate immigrants and inculcate moral values in children.
A different strain of experimentalism, with more connection to physiology, emerged in South America, under the leadership of Horacio G. Piñero at the University of Buenos Aires. Russia, too, placed greater emphasis on the biological basis for psychology, beginning with Ivan Sechenov's 1873 essay, "Who Is to Develop Psychology and How?" Sechenov advanced the idea of brain reflexes and aggressively promoted a deterministic viewpoint on human behavior.
Wolfgang Kohler, Max Wertheimer and Kurt Koffka co-founded the school of Gestalt psychology (not to be confused with the Gestalt therapy of Fritz Perls). This approach is based upon the idea that individuals experience things as unified wholes. Rather than breaking down thoughts and behavior into smaller elements, as in structuralism, the Gestaltists maintained that whole of experience is important, and differs from the sum of its parts. Other 19th-century contributors to the field include the German psychologist Hermann Ebbinghaus, a pioneer in the experimental study of memory, who developed quantitative models of learning and forgetting at the University of Berlin, and the Russian-Soviet physiologist Ivan Pavlov, who discovered in dogs a learning process that was later termed "classical conditioning" and applied to human beings.
Consolidation and funding.
One of the earliest psychology societies was "La Société de Psychologie Physiologique" in France, which lasted 1885–1893. The first meeting of the International Congress of Psychology took place in Paris, in August 1889, amidst the World's Fair celebrating the centennial of the French Revolution. William James was one of three Americans among the four hundred attendees. The American Psychological Association was founded soon after, in 1892. The International Congress continued to be held, at different locations in Europe, with wider international participation. The Sixth Congress, Geneva 1909, included presentations in Russian, Chinese, and Japanese, as well as Esperanto. After a hiatus for War War I, the Seventh Congress met in Oxford, with substantially greater participation from the war-victorious Anglo-Americans. In 1929, the Congress took place at Yale University in New Haven, Connecticut, attended by hundreds of members of the American Psychological Association Tokyo Imperial University led the way in bringing the new psychology to the East, and from Japan these ideas diffused into China.
American psychology gained status during World War I, during which a standing committee headed by Robert Yerkes administered mental tests (“Army Alpha” and “Army Beta”) to almost 1.8 million GIs. Subsequent funding for behavioral research came in large part from the Rockefeller family, via the Social Science Research Council. Rockefeller charities funded the National Committee on Mental Hygiene, which promoted the concept of mental illness and lobbied for psychological supervision of child development. Through the Bureau of Social Hygiene and later funding of Alfred Kinsey, Rockefeller foundations established sex research as a viable discipline in the U.S. Under the influence of the Carnegie-funded Eugenics Record Office, the Draper-funded Pioneer Fund, and other institutions, the eugenics movement also had a significant impact on American psychology; in the 1910s and 1920s, eugenics became a standard topic in psychology classes.
During World War II and the Cold War, the U.S. military and intelligence agencies established themselves as leading funders of psychology—through the armed forces and in the new Office of Strategic Services intelligence agency. University of Michigan psychologist Dorwin Cartwright reported that university researchers began large-scale propaganda research in 1939–1941, and "the last few months of the war saw a social psychologist become chiefly responsible for determining the week-by-week-propaganda policy for the United States Government." Cartwright also wrote that psychologists had significant roles in managing the domestic economy. The Army rolled out its new General Classification Test and engaged in massive studies of troop morale. In the 1950s, the Rockefeller Foundation and Ford Foundation collaborated with the Central Intelligence Agency to fund research on psychological warfare. In 1965, public controversy called attention to the Army's Project Camelot—the “Manhattan Project” of social science—an effort which enlisted psychologists and anthropologists to analyze foreign countries for strategic purposes.
In Germany after World War I, psychology held institutional power through the military, and subsequently expanded along with the rest of the military under the Third Reich. Under the direction of Hermann Göring's cousin Matthias Göring, the Berlin Psychoanalytic Institute was renamed the Göring Institute. Freudian psychoanalysts were expelled and persecuted under the anti-Jewish policies of the Nazi Party, and all psychologists had to distance themselves from Freud and Adler. The Göring Institute was well-financed throughout the war with a mandate to create a “New German Psychotherapy”. This psychotherapy aimed to align suitable Germans with the overall goals of the Reich; as described by one physician: "Despite the importance of analysis, spiritual guidance and the active cooperation of the patient represent the best way to overcome individual mental problems and to subordinate them to the requirements of the "Volk" and the "Gemeinschaft"." Psychologists were to provide "Seelenführung", leadership of the mind, to integrate people into the new vision of a German community. Harald Schultz-Hencke melded psychology with the Nazi theory of biology and racial origins, criticizing psychoanalysis as a study of the weak and deformed. Johannes Heinrich Schultz, a German psychologist recognized for developing the technique of autogenic training, prominently advocated sterilization and euthanasia of men considered genetically undesirable, and devised techniques for facilitating this process. After the war, some new institutions were created and some psychologists were discredited due to Nazi affiliation. Alexander Mitscherlich founded a prominent applied psychoanalysis journal called "Psyche" and with funding from the Rockefeller Foundation established the first clinical psychosomatic medicine division at Heidelberg University. In 1970, psychology was integrated into the required studies of medical students.
After the Russian Revolution, psychology was heavily promoted by the Bolsheviks as a way to engineer the "New Man" of socialism. Thus, university psychology departments trained large numbers of students, for whom positions were made available at schools, workplaces, cultural institutions, and in the military. An especial focus was pedology, the study of child development, regarding which Lev Vygotsky became a prominent writer. The Bolsheviks also promoted free love and embranced the doctrine of psychoanalysis as an antidote to sexual repression. Although pedology and intelligence testing fell out of favor in 1936, psychology maintained its privileged position as an instrument of the Soviet state. Stalinist purges took a heavy toll and instilled a climate of fear in the profession, as elsewhere in Soviet society. Following World War II, Jewish psychologists past and present (including Vygotsky, A. R. Luria, and Aron Zalkind) were denounced; Ivan Pavlov (posthumously) and Stalin himself were aggrandized as heroes of Soviet psychology. Soviet academics was speedily liberalized during the Khrushchev Thaw, and cybernetics, linguistics, genetics, and other topics became acceptable again. There emerged a new field called "engineering psychology" which studied mental aspects of complex jobs (such as pilot and cosmonaut). Interdisciplinary studies became popular and scholars such as Georgy Shchedrovitsky developed systems theory approaches to human behavior.
Twentieth-century Chinese psychology originally modeled the United States, with translations from American authors like William James, the establishment of university psychology departments and journals, and the establishment of groups including the Chinese Association of Psychological Testing (1930) and the Chinese Psychological Society (1937). Chinese psychologists were encouraged to focus on education and language learning, with the aspiration that education would enable modernization and nationalization. John Dewey, who lectured to Chinese audiences in 1918–1920, had a significant influence on this doctrine. Chancellor T'sai Yuan-p'ei introduced him at Peking University as a greater thinker than Confucius. Kuo Zing-yang who received a PhD at the University of California, Berkeley, became President of Zhejiang University and popularized behaviorism. After the Chinese Communist Party gained control of the country, the Stalinist USSR became the leading influence, with Marxism–Leninism the leading social doctrine and Pavlovian conditioning the approved concept of behavior change. Chinese psychologists elaborated on Lenin's model of a "reflective" consciousness, envisioning an "active consciousness" ("tzu-chueh neng-tung-li") able to transcend material conditions through hard work and ideological struggle. They developed a concept of "recognition" ("jen-shih") which referred the interface between individual perceptions and the socially accepted worldview. (Failure to correspond with party doctrine was "incorrect recognition".) Psychology education was centralized under the Chinese Academy of Sciences, supervised by the State Council. In 1951 the Academy created a Psychology Research Office, which in 1956 became the Institute of Psychology. Most leading psychologists were educated in the United States, and the first concern of the Academy was re-education of these psychologists in the Soviet doctrines. Child psychology and pedagogy for nationally cohesive education remained a central goal of the discipline.
Disciplinary organization.
Institutions.
In 1920, Édouard Claparède and Pierre Bovet created a new applied psychology organization called the International Congress of Psychotechnics Applied to Vocational Guidance, later called the International Congress of Psychotechnics and then the International Association of Applied Psychology. The IAAP is considered the oldest international psychology association. Today, at least 65 international groups deal specialized aspects of psychology. In response to male predominance in the field, female psychologists in the U.S. formed National Council of Women Psychologists in 1941. This organization became the International Council of Women Psychologists after World War II, and the International Council of Psychologists in 1959. Several associations including the Association of Black Psychologists and the Asian American Psychological Association have arisen to promote non-European racial groups in the profession.
The world federation of national psychological societies is the International Union of Psychological Science (IUPsyS), founded in 1951 under the auspices of UNESCO, the United Nations cultural and scientific authority. Psychology departments have since proliferated around the world, based primarily on the Euro-American model. Since 1966, the Union has published the "International Journal of Psychology". IAAP and IUPsyS agreed in 1976 each to hold a congress every four years, on a staggered basis.
The International Union recognizes 66 national psychology associations and at least 15 others exist. The American Psychological Association is the oldest and largest. Its membership has increased from 5,000 in 1945 to 100,000 in the present day. The APA includes 54 divisions, which since 1960 have steadily proliferated to include more specialties. Some of these divisions, such as the Society for the Psychological Study of Social Issues and the American Psychology–Law Society, began as autonomous groups.
The Interamerican Society of Psychology, founded in 1951, aspires to promote psychology and coordinate psychologists across the Western Hemisphere. It holds the Interamerican Congress of Psychology and had 1000 members in year 2000. The European Federation of Professional Psychology Associations, founded in 1981, represents 30 national associations with a total of 100,000 individual members. At least 30 other international groups organize psychologists in different regions.
In some places, governments legally regulate who can provide psychological services or represent themselves as a "psychologist". The American Psychological Association defines a psychologist as someone with a doctoral degree in psychology.
Boundaries.
Early practitioners of experimental psychology distinguished themselves from parapsychology, which in the late nineteenth century enjoyed great popularity (including the interest of scholars such as William James), and indeed constituted the bulk of what people called "psychology". Parapsychology, hypnotism, and psychism were major topics of the early International Congresses. But students of these fields were eventually ostractized, and more or less banished from the Congress in 1900–1905. Parapsychology persisted for a time at Imperial University, with publications such as "Clairvoyance and Thoughtography" by Tomokichi Fukurai, but here too it was mostly shunned by 1913.
As a discipline, psychology has long sought to fend off accusations that it is a "soft" science. Philosopher of science Thomas Kuhn's 1962 critique implied psychology overall was in a pre-paradigm state, lacking the agreement on overarching theory found in mature sciences such as chemistry and physics. Because some areas of psychology rely on research methods such as surveys and questionnaires, critics asserted that psychology is not an objective science. Skeptics have suggested that personality, thinking, and emotion, cannot be directly measured and are often inferred from subjective self-reports, which may be problematic. Experimental psychologists have devised a variety of ways to indirectly measure these elusive phenomenological entities.
Divisions still exist within the field, with some psychologists more oriented towards the unique experiences of individual humans, which cannot be understood only as data points within a larger population. Critics inside and outside the field have argued that maintstream psychology has become increasingly dominated by a "cult of empiricism" which limits the scope of its study by using only methods derived from the physical sciences. Feminist critiques along these lines have argued that claims to scientific objectivity obscure the values and agenda of (historically mostly male) researchers. Jean Grimshaw, for example, argues that mainstream psychological research has advanced a patriarchal agenda through its efforts to control behavior.
Major schools of thought.
Biological.
Psychologists generally consider the organism the basis of the mind, and therefore a vitally related area of study. Psychiatrists and neuropsychologists work at the interface of mind and body. 
Biological psychology, also known as physiological psychology, or neuropsychology is the study of the biological substrates of behavior and mental processes. Key research topics in this field include comparative psychology, which studies humans in relation to other animals, and perception which involves the physical mechanics of sensation as well as neural and mental processing. For centuries, a leading question in biological psychology has been whether and how mental functions might be localized in the brain. From Phineas Gage to H. M. and Clive Wearing, have inspired new discoveries in this area. Modern neuropsychology could be said to originate in the 1870s, when in France Paul Broca traced production of speech to the left frontal gyrus, thereby also demonstrating hemispheric lateralization of brain function. Soon after, Carl Wernicke identified a related area necessary for the understanding of speech.
The contemporary field of behavioral neuroscience focuses on physical causes underpinning behavior. For example, physiological psychologists use animal models, typically rats, to study the neural, genetic, and cellular mechanisms that underlie specific behaviors such as learning and memory and fear responses. Cognitive neuroscientists investigate the neural correlates of psychological processes in humans using neural imaging tools, and neuropsychologists conduct psychological assessments to determine, for instance, specific aspects and extent of cognitive deficit caused by brain damage or disease. The biopsychosocial model is an integrated perspective toward understanding consciousness, behavior, and social interaction. It assumes that any given behavior or mental process affects and is affected by dynamically interrelated biological, psychological, and social factors.
Evolutionary psychology examines cognition and personality traits from an evolutionary perspective. This perspective suggests that psychological adaptations evolved to solve recurrent problems in human ancestral environments. Evolutionary psychology offers complementary explanations for the mostly proximate or developmental explanations developed by other areas of psychology: that is, it focuses mostly on ultimate or "why?" questions, rather than proximate or "how?" questions.
The search for biological origins of psychological phenomena has long involved debates about the importance of race, and especially the relationship between race and intelligence. The idea of white supremacy and indeed the modern concept of race itself arose during the process of world conquest by Europeans. Carl von Linnaeus's four-fold classification of humans classifies Europeans as intelligent and severe, Americans as contented and free, Asians as ritualistic, and Africans as lazy and capricious. Race was also used to justify the construction of socially specific mental disorders such as "drapetomania" and "dysaesthesia aethiopica"—the behavior of uncooperative African slaves. After the creation of experimental psychology, "ethnical psychology" emerged as a subdiscipline, based on the assumption that studying primitive races would provide an important link between animal behavior and the psychology of more evolved humans.
Behavioral.
Psychologists take human behavior as a main area of study. Much of the research in this area began with tests on mammals, based on the idea that humans exhibit similar fundamental tendencies. Behavioral research ever aspires to improve the effectiveness of techniques for behavior modification.
Early behavioral researchers studied stimulus–response pairings, now known as classical conditioning. They demonstrated that behaviors could be linked through repeated association with stimuli eliciting pain or pleasure. Ivan Pavlov—known best for inducing dogs to salivate in the presence of a stimulus previous linked with food—became a leading figure in the Soviet Union and inspired followers to use his methods on humans. In the United States, Edward Lee Thorndike initiated "connectionism" studies by trapping animals in "puzzle boxes" and rewarding them for escaping. Thorndike wrote in 1911: "There can be no moral warrant for studying man's nature unless the study will enable us to control his acts." From 1910–1913 the American Psychological Association went through a sea change of opinion, away from mentalism and towards "behavioralism", and in 1913 John B. Watson coined the term behaviorism for this school of thought. Watson's famous Little Albert experiment in 1920 demonstrated that repeated use of upsetting loud noises could instill phobias (aversions to other stimuli) in an infant human. Karl Lashley, a close collaborator with Watson, examined biological manifestations of learning in the brain.
Embraced and extended by Clark L. Hull, Edwin Guthrie, and others, behaviorism became a widely used research paradigm. A new method of "instrumental" or "operant" conditioning added the concepts of reinforcement and punishment to the model of behavior change. Radical behaviorists avoided discussing the inner workings of the mind, especially the unconscious mind, which they considered impossible to assess scientifically. Operant conditioning was first described by Miller and Kanorski and popularized in the U.S. by B.F. Skinner, who emerged as a leading intellectual of the behaviorist movement.
Noam Chomsky delivered an influential critique of radical behaviorism on the grounds that it could not adequately explain the complex mental process of language acquisition. Martin Seligman and colleagues discovered that the conditioning of dogs led to outcomes ("learned helplessness") that opposed the predictions of behaviorism. Skinner's behaviorism did not die, perhaps in part because it generated successful practical applications. Edward C. Tolman advanced a hybrid “cognitive behaviorial” model, most notably with his 1948 publication discussing the cognitive maps used by rats to guess at the location of food at the end of a modified maze.
The Association for Behavior Analysis International was founded in 1974 and by 2003 had members from 42 countries. The field has been especially influential in Latin America, where it has a regional organization known as ALAMOC: "La Asociación Latinoamericana de Análisis y Modificación del Comportamiento". Behaviorism also gained a strong foothold in Japan, where it gave rise to the Japanese Society of Animal Psychology (1933), the Japanese Association of Special Education (1963), the Japanese Society of Biofeedback Research (1973), the Japanese Association for Behavior Therapy (1976), the Japanese Association for Behavior Analysis (1979), and the Japanese Association for Behavioral Science Research (1994). Today the field of behaviorism is also commonly referred to as behavior modification or behavior analysis.
Cognitive.
Green Red BluePurple Blue Purple
Blue Purple RedGreen Purple Green
The Stroop effect refers to the fact that naming the color of the first set of words is easier and quicker than the second.
Cognitive psychology studies cognition, the mental processes underlying mental activity. Perception, attention, reasoning, thinking, problem solving, memory, learning, language, and emotion are areas of research. Classical cognitive psychology is associated with a school of thought known as cognitivism, whose adherents argue for an information processing model of mental function, informed by functionalism and experimental psychology.
On a broader level, cognitive science is an interdisciplinary enterprise of cognitive psychologists, cognitive neuroscientists, researchers in artificial intelligence, linguists, human–computer interaction, computational neuroscience, logicians and social scientists. Computer simulations are sometimes used to model phenomena of interest.
Starting in the 1950s, the experimental techniques developed by Wundt, James, Ebbinghaus, and others re-emerged as experimental psychology became increasingly cognitivist—concerned with information and its processing—and, eventually, constituted a part of the wider cognitive science. Some called this development the cognitive revolution because it rejected the anti-mentalist dogma of behaviorism as well as the strictures of psychoanalysis.
Social learning theorists, such as Albert Bandura, argued that the child's environment could make contributions of its own to the behaviors of an observant subject.
Technological advances also renewed interest in mental states and representations. English neuroscientist Charles Sherrington and Canadian psychologist Donald O. Hebb used experimental methods to link psychological phenomena with the structure and function of the brain. The rise of computer science, cybernetics and artificial intelligence suggested the value of comparatively studying information processing in humans and machines. Research in cognition had proven practical since World War II, when it aided in the understanding of weapons operation.
A popular and representative topic in this area is cognitive bias, or irrational thought. Psychologists (and economists) have classified and described a sizeable catalogue of biases which recur frequently in human thought. The availability heuristic, for example, is the tendency to overestimate the importance of something which happens to come readily to mind.
Elements of behaviorism and cognitive psychology were synthesized to form cognitive behavioral therapy, a form of psychotherapy modified from techniques developed by American psychologist Albert Ellis and American psychiatrist Aaron T. Beck. Cognitive psychology was subsumed along with other disciplines, such as philosophy of mind, computer science, and neuroscience, under the cover discipline of cognitive science.
Social.
Social psychology is the study of how humans think about each other and how they relate to each other. Social psychologists study such topics as the influence of others on an individual's behavior (e.g. conformity, persuasion), and the formation of beliefs, attitudes, and stereotypes about other people. Social cognition fuses elements of social and cognitive psychology in order to understand how people process, remember, or distort social information. The study of group dynamics reveals information about the nature and potential optimization of leadership, communication, and other phenomena that emerge at least at the microsocial level. In recent years, many social psychologists have become increasingly interested in implicit measures, mediational models, and the interaction of both person and social variables in accounting for behavior. The study of human society is therefore a potentially valuable source of information about the causes of psychiatric disorder. Some sociological concepts applied to psychiatric disorders are the social role, sick role, social class, life event, culture, migration, social, and total institution.
Psychoanalysis.
Psychoanalysis comprises a method of investigating the mind and interpreting experience; a systematized set of theories about human behavior; and a form of psychotherapy to treat psychological or emotional distress, especially conflict originating in the unconscious mind. This school of thought originated in the 1890s with Austrian medical doctors including Josef Breuer (physician), Alfred Adler (physician), Otto Rank (psychoanalyst), and most prominently Sigmund Freud (neurologist). Freud's psychoanalytic theory was largely based on interpretive methods, introspection and clinical observations. It became very well known, largely because it tackled subjects such as sexuality, repression, and the unconscious. These subjects were largely taboo at the time, and Freud provided a catalyst for their open discussion in polite society. Clinically, Freud helped to pioneer the method of free association and a therapeutic interest in dream interpretation.
Swiss psychiatrist Carl Jung, influenced by Freud, elaborated a theory of the collective unconscious—a primordial force present in all humans, featuring archetypes which exerted a profound influence on the mind. Jung's competing vision formed the basis for analytical psychology, which later led to the archetypal and process-oriented schools. Other well-known psychoanalytic scholars of the mid-20th century include Erik Erikson, Melanie Klein, D.W. Winnicott, Karen Horney, Erich Fromm, John Bowlby, and Sigmund Freud's daughter, Anna Freud. Throughout the 20th century, psychoanalysis evolved into diverse schools of thought which could be called Neo-Freudian. Among these schools are ego psychology, object relations, and interpersonal, Lacanian, and relational psychoanalysis.
Psychologists such as Hans Eysenck and philosophers including Karl Popper criticized psychoanalysis. Popper argued that psychoanalysis had been misrepresented as a scientific discipline, whereas Eysenck said that psychoanalytic tenets had been contradicted by experimental data. By the end of 20th century, psychology departments in American universities mostly marginalized Freudian theory, dismissing it as a "desiccated and dead" historical artifact. However, researchers in the emerging field of neuro-psychoanalysis today defend some of Freud's ideas on scientific grounds, while scholars of the humanities maintained that Freud was not a "scientist at all, but ... an interpreter."
Existential-humanistic theories.
Humanistic psychology developed in the 1950s as a movement within academic psychology, in reaction to both behaviorism and psychoanalysis. The humanistic approach sought to glimpse the whole person, not just fragmented parts of the personality or isolated cognitions. Humanism focused on uniquely human issues, such as free will, personal growth, self-actualization, self-identity, death, aloneness, freedom, and meaning. It emphasized subjective meaning, rejection of determinism, and concern for positive growth rather than pathology. Some founders of the humanistic school of thought were American psychologists Abraham Maslow, who formulated a hierarchy of human needs, and Carl Rogers, who created and developed client-centered therapy. Later, positive psychology opened up humanistic themes to scientific modes of exploration.
The "American Association for Humanistic Psychology", formed in 1963, declared:
Humanistic psychology is primarily an orientation toward the whole of psychology rather than a distinct area or school. It stands for respect for the worth of persons, respect for differences of approach, open-mindedness as to acceptable methods, and interest in exploration of new aspects of human behavior. As a “third force” in contemporary psychology, it is concerned with topics having little place in existing theories and systems: e.g., love, creativity, self, growth, organism, basic need-gratification, self-actualization, higher values, being, becoming, spontaneity, play, humor, affection, naturalness, warmth, ego-transcendence, objectivity, autonomy, responsibility, meaning, fair-play, transcendental experience, peak experience, courage, and related concepts.
In the 1950s and 1960s, influenced by philosophers Søren Kierkegaard and Martin Heidegger and, psychoanalytically trained American psychologist Rollo May pioneered an existential branch of psychology, which included existential psychotherapy: a method based on the belief that inner conflict within a person is due to that individual's confrontation with the givens of existence. Swiss psychoanalyst Ludwig Binswanger and American psychologist George Kelly may also be said to belong to the existential school. Existential psychologists differed from more "humanistic" psychologists in their relatively neutral view of human nature and their relatively positive assessment of anxiety. Existential psychologists emphasized the humanistic themes of death, free will, and meaning, suggesting that meaning can be shaped by myths, or narrative patterns, and that it can be encouraged by an acceptance of the free will requisite to an authentic, albeit often anxious, regard for death and other future prospects.
Austrian existential psychiatrist and Holocaust survivor Viktor Frankl drew evidence of meaning's therapeutic power from reflections garnered from his own internment. He created a variation of existential psychotherapy called logotherapy, a type of existentialist analysis that focuses on a "will to meaning" (in one's life), as opposed to Adler's Nietzschean doctrine of "will to power" or Freud's "will to pleasure".
Themes.
Personality.
Personality psychology is concerned with enduring patterns of behavior, thought, and emotion—commonly referred to as personality—in individuals. Theories of personality vary across different psychological schools and orientations. They carry different assumptions about such issues as the role of the unconscious and the importance of childhood experience. According to Freud, personality is based on the dynamic interactions of the id, ego, and super-ego. Trait theorists, in contrast, attempt to analyze personality in terms of a discrete number of key traits by the statistical method of factor analysis. The number of proposed traits has varied widely. An early model, proposed by Hans Eysenck, suggested that there are three traits which comprise human personality: extraversion–introversion, neuroticism, and psychoticism. Raymond Cattell proposed a theory of 16 personality factors. Dimensional models of personality are receiving increasing support, and some version of dimensional assessment will be included in the forthcoming DSM-V.
Myriad approach to systematically assess different personality types, with the Woodworth Personal Data Sheet, developed during World War I, an early example of the modern technique. The Myers–Briggs Type Indicator sought to assess people according to the personality theories of Carl Jung. Behaviorist resistance to introspection led to the development of the Strong Vocational Interest Blank and Minnesota Multiphasic Personality Inventory, tests which ask more empirical questions and focus less on the psychodynamics of the respondent.
Unconscious mind.
Study of the unconscious mind, a part of the psyche outside the awareness of the individual which nevertheless influenced thoughts and behavior was a hallmark of early psychology. In one of the first psychology experiments conducted in the USA, C.S. Peirce and Joseph Jastrow found in 1884 that subjects could choose the minutely heavier of two weights even if consciously uncertain of the difference. Freud popularized this concept, with terms like Freudian slip entering popular culture, to mean an uncensored intrusion of unconscious thought into one's speech and action. His 1901 text "The Psychopathology of Everyday Life" catalogues hundreds of everyday events which Freud explains in terms of unconscious influence. Pierre Janet advanced the idea of a subconscious mind, which could contain autonomous mental elements unavailable to the scrutiny of the subject.
Behaviorism notwithstanding, the unconscious mind has maintained its importance in psychology. Cognitive psychologists have used a “filter” model of attention, according to which much information processing takes place below the threshold of consciousness, and only certain processes, limited by nature and by simultaneous quantity, make their way through the filter. Copious research has shown that subconscious "priming" of certain ideas can covertly influence thoughts and behavior. A significant hurdle in this research is proving that a subject's conscious mind has not grasped a certain stimulus, due to the unreliability of self-reporting. For this reason, some psychologists prefer to distinguish between "implicit" and "explicit" memory. In another approach, one can also describe a subliminal stimulus as meeting an "objective" but not a "subjective" threshold.
The automaticity model, which became widespread following exposition by John Bargh and others in the 1980s, describes sophisticated processes for executing goals which can be selected and performed over an extended duration without conscious awareness. Some experimental data suggests that the brain begins to consider taking actions before the mind becomes aware of them. This influence of unconscious forces on people's choices naturally bears on philosophical questions free will. John Bargh, Daniel Wegner, and Ellen Langer are some prominent contemporary psychologists who describe free will as an illusion.
Motivation.
Psychologists such as William James initially used the term "motivation" to refer to intention, in a sense similar to the concept of "will" in European philosophy. With the steady rise of Darwinian and Freudian thinking, instinct also came to be seen as a primary source of motivation. According to drive theory, the forces of instinct combine into a single source of energy which exerts a constant influence. Psychoanalysis, like biology, regarded these forces as physical demands made by the organism on the nervous system. However, they believed that these forces, especially the sexual instincts, could become entangled and transmuted within the psyche. Classical psychoanalysis conceives of a struggle between the pleasure principle and the reality principle, roughly corresponding to id and ego. Later, in "Beyond the Pleasure Principle", Freud introduced the concept of the "death drive", a compulsion towards aggression, destruction, and psychic repetition of traumatic events. Meanwhile, behaviorist researchers used simple dichotomous models (pleasure/pain, reward/punishment) and well-established principles such as the idea that a thirsty creature will take pleasure in drinking. Clark Hull formalized the latter idea with his drive reduction model.
Hunger, thirst, fear, sexual desire, and thermoregulation all seem to constitute fundamental motivations for animals. Humans also seem to exhibit a more complex set of motivations—though theoretically these could be explained as resulting from primordial instincts—including desires for belonging, self-image, self-consistency, truth, love, and control.
Motivation can be modulated or manipulated in many different ways. Researchers have found that eating, for example, depends not only on the organism's fundamental need for homeostasis—an important factor causing the experience of hunger—but also on circadian rhythms, food availability, food palatability, and cost. Abstract motivations are also malleable, as evidenced by such phenomena as "goal contagion": the adoption of goals, sometimes unconsciously, based on inferences about the goals of others. Vohs and Baumeister suggest that contrary to the need-desire-fulfilment cycle of animal instincts, human motivations sometimes obey a "getting begets wanting" rule: the more you get a reward such as self-esteem, love, drugs, or money, the more you want it. They suggest that this principle can even apply to food, drink, sex, and sleep.
Development.
Mainly focusing on the development of the human mind through the life span, developmental psychology seeks to understand how people come to perceive, understand, and act within the world and how these processes change as they age. This may focus on cognitive, affective, moral, social, or neural development. Researchers who study children use a number of unique research methods to make observations in natural settings or to engage them in experimental tasks. Such tasks often resemble specially designed games and activities that are both enjoyable for the child and scientifically useful, and researchers have even devised clever methods to study the mental processes of infants. In addition to studying children, developmental psychologists also study aging and processes throughout the life span, especially at other times of rapid change (such as adolescence and old age). Developmental psychologists draw on the full range of psychological theories to inform their research.
Applications.
Psychology encompasses many subfields and includes different approaches to the study of mental processes and behavior:
Mental testing.
Psychological testing has ancient origins, such as examinations for the Chinese civil service dating back to 2200 B.C. Written exams began during the Han dynasty (202 B.C.–A.D. 200). By 1370, the Chinese system required a stratified series of tests, involving essay writing and knowledge of diverse topics. The system was ended in 1906. In Europe, mental assessment took a more physiological approach, with theories of physiognomy—judgment of character based on the face—described by Aristotle in fourth century B.C. Greece. Physiognomy remained current through the Enlightenment, and added the doctrine of phrenology: a study of mind and intelligence based on simple assessment of neuroanatomy.
When experimental psychology came to Britain, Francis Galton was a leading practitioner, and, with his procedures for measuring reaction time and sensation, is considered an inventor of modern mental testing (a.k.a. "psychometrics"). James McKeen Cattell, a student of Wundt and Galton, brought the concept to the USA, and in fact coined the term "mental test". In 1901, Cattell's student Clark Wissler published discouraging results, suggesting that mental testing of Columbia and Barnard students failed to predict their academic performance. In response to 1904 orders from the Minister of Public Instruction, French psychologists Alfred Binet and Théodore Simon elaborated a new test of intelligence in 1905–1911, using a range of questions diverse in their nature and difficulty. Binet and Simon introduced the concept of mental age and referred to the lowest scorers on their test as "idiots". Henry H. Goddard put the Binet-Simon scale to work and introduced classifications of mental level such as "imbecile" and "feebleminded". In 1916 (after Binet's death), Stanford professor Lewis M. Terman modified the Binet-Simon scale (renamed the Stanford-Binet scale) and introduced the intelligence quotient as a score report. From this test, Terman concluded that mental retardation "represents the level of intelligence which is very, very common among Spanish-Indians and Mexican families of the Southwest and also among negroes. Their dullness seems to be racial."
Following the Army Alpha and Army Beta tests for soldiers in World War I, mental testing became popular in the US, where it was soon applied to school children. The federally created National Intelligence Test was administered to 7 million children in the 1920s, and in 1926 the College Entrance Examination Board created the Scholastic Aptitude Test to standardize college admissions. The results of intelligence tests were used to argue for segregated schools and economic functions—i.e. the preferential training of Black Americans for manual labor. These practices were criticized by black intellectuals such a Horace Mann Bond and Allison Davis. Eugenicists used mental testing to justify and organize compulsory sterilization of individuals classified as mentally retarded. In the United States, tens of thousands of men and women were sterilized. Setting a precedent which has never been overturned, the U.S. Supreme Court affirmed the constitutionality of this practice in the 1907 case "Buck v. Bell".
Today mental testing is a routine phenomenon for people of all ages in Western societies. Modern testing aspires to criteria including standardization of procedure, consistency of results, output of an interpretable score, statistical norms describing population outcomes, and, ideally, effective prediction of behavior and life outcomes outside of testing situations.
Mental health care.
The provision of psychological health services is generally called "clinical psychology" in the U.S. The definitions of this term are various and it may include school psychology and counseling psychology. The definition typically includes people who have graduated from doctoral programs in clinical psychology but may also include others. In Canada, the above groups usually fall within the larger category of "professional psychology". In Canada and the US, practitioners get bachelor's degrees and doctorates, then spend one year in an internship and one year in postdoctoral education. In Mexico and most other Latinamericano and European countries, psychologists do not get bachelor's and doctorate degrees: they take a three year professional course following high school. Clinical psychology is at present the largest specialization within psychology. It includes the study and application of psychology for the purpose of understanding, preventing, and relieving psychologically based distress, dysfunction or mental illness and to promote subjective well-being and personal development. Central to its practice are psychological assessment and psychotherapy, although clinical psychologists may also engage in research, teaching, consultation, forensic testimony, and program development and administration.
Credit for the first psychology clinic in the USA typically goes to Lightner Witmer, who established his practice in Philadelphia in 1896. Another modern psychotherapist was Morton Prince. For the most part, in the first part of th twentieth century, most mental health care in the United States was performed by specialized medical doctors called psychiatrists. Psychology entered the field with its refinements of mental testing, which promised to improve diagnosis of mental problems. For their part, some psychiatrists became interested in using psychoanalysis and other forms of psychodynamic psychotherapy to understand and treat the mentally ill. In this type of treatment, a specially trained therapist develops a close relationship with the patient, who discusses wishes, dreams, social relationships, and other aspects of mental life. The therapist seeks to uncover repressed material and to understand why the patient creates defences against certain thoughts and feelings. An important aspect of the therapeutic relationship is transference, in which deep unconscious feelings in a patient reorient themselves and become manifest in relation to the therapist.
Psychiatric psychotherapy blurred the distinction between psychiatry and psychology, and this trend continued with the rise of community mental health facilities and behavioral therapy, a thoroughly non-psychodynamic model which used behaviorist learning theory to change the actions of patients. A key aspect of behavior therapy is empirical evaluation of the treatment's effectiveness. In the 1970s, cognitive-behavior therapy arose, using similar methods and now including the cognitive constructs which had gained popularity in theoretical psychology. A key practice in behavioral and cognitive-behavioral therapy is exposing patients to things they fear, based on the premise that their responses (fear, panic, anxiety) can be deconditioned.
Mental health care today involves psychologists and social workers in increasing numbers. In 1977, National Institute of Mental Health director Bertram Brown described this shift as a source of “intense competition and role confusion”. Graduate programs issuing doctorates in psychology (PsyD) emerged in the 1950s and underwent rapid increase through the 1980s. This degree is intended to train practitioners who might conduct scientific research.
Some clinical psychologists may focus on the clinical management of patients with brain injury—this area is known as clinical neuropsychology. In many countries, clinical psychology is a regulated mental health profession. The emerging field of "disaster psychology" (see crisis intervention) involves professionals who respond to large-scale traumatic events.
The work performed by clinical psychologists tends to be influenced by various therapeutic approaches, all of which involve a formal relationship between professional and client (usually an individual, couple, family, or small group). Typically they encourage new ways of thinking, feeling, or behaving. Four major theoretical perspectives are psychodynamic, cognitive behavioral, existential–humanistic, and systems or family therapy. There has been a growing movement to integrate the various therapeutic approaches, especially with an increased understanding of issues regarding culture, gender, spirituality, and sexual orientation. With the advent of more robust research findings regarding psychotherapy, there is evidence that most of the major therapies have equal effectiveness, with the key common element being a strong therapeutic alliance. Because of this, more training programs and psychologists are now adopting an eclectic therapeutic orientation.
Diagnosis in clinical psychology usually follows the "Diagnostic and Statistical Manual of Mental Disorders" (DSM), a handbook first published by the American Psychiatric Association in 1952. New editions over time have increased in size and focused more on medical language. The study of mental illnesses is called abnormal psychology.
Education.
Educational psychology is the study of how humans learn in educational settings, the effectiveness of educational interventions, the psychology of teaching, and the social psychology of schools as organizations. The work of child psychologists such as Lev Vygotsky, Jean Piaget, Bernard Luskin, and Jerome Bruner has been influential in creating teaching methods and educational practices. Educational psychology is often included in teacher education programs in places such as North America, Australia, and New Zealand.
School psychology combines principles from educational psychology and clinical psychology to understand and treat students with learning disabilities; to foster the intellectual growth of gifted students; to facilitate prosocial behaviors in adolescents; and otherwise to promote safe, supportive, and effective learning environments. School psychologists are trained in educational and behavioral assessment, intervention, prevention, and consultation, and many have extensive training in research.
Work.
Industrialists soon brought the nascent field of psychology to bear on the study of scientific management techniques for improving workplace efficiency. This field was at first called "economic psychology" or "business psychology"; later, "industrial psychology", "employment psychology", or "psychotechnology". An important early study examined workers at Western Electric's Hawthorne plant in Cicero, Illinois from 1924–1932. With funding from the Laura Spelman Rockefeller Fund and guidance from Australian psychologist Elton Mayo, Western Electric experimented on thousands of factory workers to assess their responses to illumination, breaks, food, and wages. The researchers came to focus on workers' responses to observation itself, and the term Hawthorne effect is now used to describe the fact that people work harder when they think they're being watched.
The name industrial and organizational psychology (I–O) arose in the 1960s and became enshrined as the Society for Industrial and Organizational Psychology, Division 14 of the American Psychological Association, in 1973. The goal is to optimize human potential in the workplace. Personnel psychology, a subfield of I–O psychology, applies the methods and principles of psychology in selecting and evaluating workers. I–O psychology's other subfield, organizational psychology, examines the effects of work environments and management styles on worker motivation, job satisfaction, and productivity. The majority of I–O psychologists work outside of academia, for private and public organizations and as consultants. A psychology consultant working in business today might expect to provide executives with information and ideas about their industry, their target markets, and the organization of their company.
Military and intelligence.
One role for psychologists in the military is to evaluate and counsel soldiers and other personnel. In the U.S., this function began during World War I, when Robert Yerkes established the School of Military Psychology at Fort Oglethorpe in Georgia, to provide psychological training for military staff military. Today, U.S Army psychology includes psychological screening, clinical psychotherapy, suicide prevention, and treatment for post-traumatic stress, as well as other aspects of health and workplace psychology such as smoking cessation.
Psychologists may also work on a diverse set of campaigns known broadly as psychological warfare. Psychologically warfare chiefly involves the use of propaganda to influence enemy soldiers and civilians. In the case of so-called black propaganda the propaganda is designed to seem like it originates from a different source. The CIA's MKULTRA program involves more individualized efforts at mind control, involving techniques such as hypnosis, torture, and covert involuntary administration of LSD. The U.S. military used the name Psychological Operations (PSYOP) until 2010, when these were reclassified as Military Information Support Operations (MISO), part of Information Operations (IO).
Health, well-being, and social change.
Medical facilities increasingly employ psychologists to perform various roles. A prominent aspect of health psychology is the psychoeducation of patients: instructing them in how to follow a medical regimen. Health psychologists can also educate doctors and conduct research on patient compliance.
Psychologists in the field of public health use a wide variety of interventions to influence human behavior. These range from public relations campaigns and outreach to governmental laws and policies. Psychologists study the composite influence of all these different tools in an effort to influence whole populations of people.
Black American psychologists Kenneth and Mamie Clark studied the psychological impact of segregation and testified with their findings in the desegregation case "Brown v. Board of Education" (1954).
Positive psychology is the study of factors which contribute to human happiness and well-being, focusing more on people who are currently health. In 2010 "Clinical Psychological Review" published a special issue devoted to positive psychological interventions, such as gratitude journaling and the physical expression of gratitude. Positive psychological interventions have been limited in scope, but their effects are thought to be superior to that of placebos, especially with regard to helping people with body image problems.
Research methods.
Quantitative psychological research lends itself to the statistical testing of hypotheses. Although the field makes abundant use of randomized and controlled experiments in laboratory settings, such research can only assess a limited range of short-term phenomena. Thus, psychologists also rely on creative statistical methods to glean knowledge from clinical trials and population data. These include the Pearson product–moment correlation coefficient, the analysis of variance, multiple linear regression, logistic regression, structural equation modeling, and hierarchical linear modeling. The measurement and operationalization of important constructs is an essential part of these research designs.
Controlled experiments.
A true experiment with random allocation of subjects to conditions allows researchers to make strong inferences about causal relationships. In an experiment, the researcher alters parameters of influence, called independent variables, and measures resulting changes of interest, called dependent variables. Prototypical experimental research is conducted in a laboratory with a carefully controlled environment.
Repeated-measures experiments are those which take place through intervention on multiple occasions. In research on the effectiveness of psychotherapy, experimenters often compare a given treatment with placebo treatments, or compare different treatments against each other. Treatment type is the independent variable. The dependent variables are outcomes, ideally assessed in several ways by different professionals. Using crossover design, researchers can further increase the strength of their results by testing both of two treatments on two groups of subjects.
Quasi-experimental design refers especially to situations precluding random assignment to different conditions. Researchers can use common sense to consider how much the nonrandom assignment threatens the study's validity. For example, in research on the best way to affect reading achievement in the first three grades of school, school administrators may not permit educational psychologists to randomly assign children to phonics and whole language classrooms, in which case the psychologists must work with preexisting classroom assignments. Psychologists will compare the achievement of children attending phonics and whole language classes.
Experimental researchers typically use a statistical hypothesis testing model which involves making predictions before conducting the experiment, then assessing how well the data supports the predictions. (These predictions may originate from a more abstract scientific hypothesis about how the phenomenon under study actually works.) Analysis of variance (ANOVA) statistical techiques are used to distinguish unique results of the experiment from the null hypothesis that variations result from random fluctuations in data. In psychology, the widely usd standard ascribes statistical significance to results which have less than 5% probability of being explained by random variation.
Other forms of statistical inference.
Statistical surveys are used in psychology for measuring attitudes and traits, monitoring changes in mood, checking the validity of experimental manipulations, and for other psychological topics. Most commonly, psychologists use paper-and-pencil surveys. However, surveys are also conducted over the phone or through e-mail. Web-based surveys are increasingly used to conveniently reach many subjects.
Neuropsychological tests, such as the Wechsler scales and Wisconsin Card Sorting Test), are mostly questionnaires or simple tasks used which assess a specific type of mental function in the respondent. These can be used in experiments, as in the case of lesion experiments evaluating the results of damage to a specific part of the brain.
Observational studies analyze uncontrolled data in search of correlations; multivariate statistics are typically used to interpret the more complex situation. Cross-sectional observational studies use data from a single point in time, whereas longitudinal studies are used to study trends across the life span. Longitudinal studies track the same people, and therefore detect more individual, rather than cultural, differences. However, they sufer from lack of controls and from confounding factors such as "selective attrition" (the bias introduced when a certain type of subject disproportionately leaves a study).
Exploratory data analysis refers to a variety of practices which researchers can use to visualize and analyze existing sets of data. In Peirce's three modes of inference, exploratory data anlysis corresponds to abduction, or hypothesis formation. Meta-analysis is the technique of integrating the results from multiple studies and interpreting the statistical properties of the pooled dataset.
Technological assays.
A classic and popular tool used to relate mental and neural activity is the electroencephalogram (EEG), a technique using amplified electrodes on a person's scalp to measure voltage changes in different parts of the brain. Hans Berger, the first researcher to use EEG on an unopened skull, quickly found that brains exhibit signature “brain waves”: electric oscillations which correspond to different states of consciousness. Researchers subsequently refined statistical methods for synthesizing the electrode data, and identified unique brain wave patterns such as the delta wave observed during non-REM sleep.
Newer functional neuroimaging techniques include functional magnetic resonance imaging and positron emission tomography, both of which track the flow of blood through the brain. These technologies provide more localized information about activity in the brain and create representations of the brain with widespread appeal. They also provide insight which avoids the classic problems of subjective self-reporting. It remains challenging to draw hard conclusions about where in the brain specific thoughts originate—or even how usefully such localization corresponds with reality. However, neuroimaging has delivered unmistakeable results showing the existence of correlations between mind and brain. Some of these draw on a systemic neural network model rather than a localized function model.
Psychiatric interventions such as transcranial magnetic stimulation and of course drugs also provide information about brain–mind interactions. Psychopharmacology is the study of drug-induced mental effects.
Computer simulation.
Computational modeling is a tool used in mathematical psychology and cognitive psychology to simulate behavior. This method has several advantages. Since modern computers process information quickly, simulations can be run in a short time, allowing for high statistical power. Modeling also allows psychologists to visualize hypotheses about the functional organization of mental events that couldn't be directly observed in a human. Connectionism uses neural networks to simulate the brain. Another method is symbolic modeling, which represents many mental objects using variables and rules. Other types of modeling include dynamic systems and stochastic modeling.
Animal studies.
Animal experiments aid in investigating many aspects of human psychology, including perception, emotion, learning, memory, and thought, to name a few. In the 1890s, Russian physiologist Ivan Pavlov famously used dogs to demonstrate classical conditioning. Non-human primates, cats, dogs, pigeons, rats, and other rodents are often used in psychological experiments. Ideally, controlled experiments introduce only one independent variable at a time, in order to ascertain its unique effects upon dependent variables. These conditions are approximated best in laboratory settings. In contrast, human environments and genetic backgrounds vary so widely, and depend upon so many factors, that it is difficult to control important variables for human subjects. Of course, there are pitfalls in generalizing findings from animal studies to humans through animal models.
Comparative psychology refers to the scientific study of the behavior and mental processes of non-human animals, especially as these relate to the phylogenetic history, adaptive significance, and development of behavior. Research in this area explores the behavior of many species, from insects to primates. It is closely related to other disciplines that study animal behavior such as ethology. Research in comparative psychology sometimes appears to shed light on human behavior, but some attempts to connect the two have been quite controversial, for example the Sociobiology of E. O. Wilson. Animal models are often used to study neural processes related to human behavior, e.g. in cognitive neuroscience.
Qualitative and descriptive research.
Research designed to answer questions about the current state of affairs such as the thoughts, feelings, and behaviors of individuals is known as "descriptive research". Descriptive research can be qualitative or quantitative in orientation. "Qualitative research" is descriptive research that is focused on observing and describing events as they occur, with the goal of capturing all of the richness of everyday behavior and with the hope of discovering and understanding phenomena that might have been missed if only more cursory examinations have been made.
Qualitative psychological research methods include interviews, first-hand observation, and participant observation. Creswell (2003) identifies five main possibilities for qualitative research, including narrative, phenomenology, ethnography, case study, and grounded theory. Qualitative researchers sometimes aim to enrich interpretations or critiques of symbols, subjective experiences, or social structures. Sometimes hermeneutic and critical aims can give rise to quantitative research, as in Erich Fromm's study of Nazi voting or Stanley Milgram's studies of obedience to authority.
Just as Jane Goodall studied chimpanzee social and family life by careful observation of chimpanzee behavior in the field, psychologists conduct naturalistic observation of ongoing human social, professional, and family life. Sometimes the participants are aware they are being observed, and other times the participants do not know they are being observed. Strict ethical guidelines must be followed when covert observation is being carried out.
Contemporary issues in methodology and practice.
In 1959 statistician Theodore Sterling examined the results of psychological studies and discovered that 97% of them supported their initial hypotheses, implying a possible publication bias. Similarly, Fanelli (2010) found that 91.5% of psychiatry/psychology studies confirmed the effects they were looking for, and concluded that the odds of this happening (a positive result) was around five times higher than in fields such as space- or geosciences. Fanelli argues that this is because researchers in "softer" sciences have fewer constraints to their conscious and unconscious biases.
Some popular media outlets have in recent years spotlighted a replication crisis in psychology, arguing that many findings in the field cannot be reproduced. Repeats of some famous studies have not reached the same conclusions, and some researchers have been accused of outright fraud in their results. Focus on this issue has led to renewed efforts in the discipline to re-test important findings.
Some critics view statistical hypothesis testing as misplaced. Psychologist and statistician Jacob Cohen wrote in 1994 that psychologists routinely confuse statistical significance with practical importance, enthusiastically reporting great certainty in unimportant facts. Some psychologists have responded with an increased use of effect size statistics, rather than sole reliance on the Fisherian "p" < .05 significance criterion (whereby an observed difference is deemed "statistically significant" if an effect of that size or larger would occur with 5% -or less- probability in independent replications, assuming the truth of the null-hypothesis of no difference between the treatments).
In 2010, a group of researchers reported a systemic bias in psychology studies towards WEIRD ("western, educated, industrialized, rich and democratic") subjects. Although only 1/8 people worldwide fall into the WEIRD classification, the researchers claimed that 60–90% of psychology studies are performed on WEIRD subjects. The article gave examples of results that differ significantly between WEIRD subjects and tribal cultures, including the Müller-Lyer illusion.
Some observers perceive a gap between scientific theory and its application—in particular, the application of unsupported or unsound clinical practices. Critics say there has been an increase in the number of mental health training programs that do not instill scientific competence. One skeptic asserts that practices, such as "facilitated communication for infantile autism"; memory-recovery techniques including body work; and other therapies, such as rebirthing and reparenting, may be dubious or even dangerous, despite their popularity. In 1984, Allen Neuringer made a similar point regarding the experimental analysis of behavior. Psychologists, sometimes divided along the lines of laboratory vs. clinic, continue to debate these issues.
Ethics.
Ethical standards in the discipline have changed over time. Some famous past studies are today considered unethical and in violation of established codes (Ethics Code of the American Psychological Association, the Canadian Code of Conduct for Research Involving Humans, and the Belmont Report).
The most important contemporary standards are informed and voluntary consent. After World War II, the Nuremberg Code was established because of Nazi abuses of experimental subjects. Later, most countries (and scientific journals) adopted the Declaration of Helsinki. In the U.S., the National Institutes of Health established the Institutional Review Board in 1966, and in 1974 adopted the National Research Act (HR 7724). All of these measures encouraged researchers to obtain informed consent from human participants in experimental studies. A number of influential studies led to the establishment of this rule; such studies included the MIT and Fernald School radioisotope studies, the Thalidomide tragedy, the Willowbrook hepatitis study, and Stanley Milgram's studies of obedience to authority.
Humans.
University psychology departments have ethics committees dedicated to the rights and well-being of research subjects. Researchers in psychology must gain approval of their research projects before conducting any experiment to protect the interests of human participants and laboratory animals.
The ethics code of the American Psychological Association originated in 1951 as "Ethical Stanards of Psychologists." This code has guided the formation of licensing laws in most American states. It has changed multiple times over the decades since its adoption. In 1989 the APA revised its policies on advertising and referral fees to negotiate the end of an investigation by the Federal Trade Commission. The 1992 incarnation was the first to distinguish between "aspirational" ethical standards and "enforceable" ones. Members of the public have a 5-year window to file ethics complaints about APA members with the APA ethics committee; members of the APA have a 3-year window.
Some of the ethical issues considered most important are the requirement to practice only within the area of competence, to maintain confidentiality with the patients, and to avoid sexual relations with them. Another important principle is informed consent, the idea that a patient or research subject must understand and freely choose a procedure they are undergoing. Some of the most common complaints against clinical psychologists include sexual misconduct, and involvement in child custody evaluations.
Other animals.
Current ethical guidelines state that using non-human animals for scientific purposes is only acceptable when the harm (physical or psychological) done to animals is outweighed by the benefits of the research. Keeping this in mind, psychologists can use certain research techniques on animals that could not be used on humans.

</doc>
<doc id="22923" url="http://en.wikipedia.org/wiki?curid=22923" title="PhpWiki">
PhpWiki

PhpWiki is a web-based wiki software application.
It began as a clone of WikiWikiWeb and was the first wiki written in PHP.
PhpWiki has been used to edit and format paper books for publication.
History.
The first version, by Steve Wainstead, was in December 1999 and was the first Wiki written in PHP to be publicly released.
The first version ran under PHP 3.x and ran on DBM files only. 
It was a feature-for-feature reimplementation of the original WikiWikiWeb at c2.com.
In early 2000 Arno Hollosi contributed a second database library to run PhpWiki on MySQL.
From then on the features and contributions started to grow, including a templating system, color diffs, rewrites of the rendering engine and much more.
Arno was interested in running a wiki for the game Go.
Jeff Dairiki was the next major contributor, and soon headed the project for the next few years, then Reini Urban up to 1.4, and then Marc-Etienne Vargenau since 1.5.
Supports Wikicreole 1.0 including additions and MediaWiki markup syntax since Version 1.4.0. With Version 1.5.0 PHP 4 was deprecated.

</doc>
<doc id="22926" url="http://en.wikipedia.org/wiki?curid=22926" title="Poetry">
Poetry

Poetry is a form of literature that uses aesthetic and rhythmic qualities of language—such as phonaesthetics, sound symbolism, and metre—to evoke meanings in addition to, or in place of, the prosaic ostensible meaning.
Poetry has a long history, dating back to the Sumerian "Epic of Gilgamesh". Early poems evolved from folk songs such as the Chinese "Shijing", or from a need to retell oral epics, as with the Sanskrit "Vedas", Zoroastrian "Gathas", and the Homeric epics, the "Iliad" and the "Odyssey". Ancient attempts to define poetry, such as Aristotle's "Poetics", focused on the uses of speech in rhetoric, drama, song and comedy. Later attempts concentrated on features such as repetition, verse form and rhyme, and emphasized the aesthetics which distinguish poetry from more objectively informative, prosaic forms of writing. From the mid-20th century, poetry has sometimes been more generally regarded as a fundamental creative act employing language.
Poetry uses forms and conventions to suggest differential interpretation to words, or to evoke emotive responses. Devices such as assonance, alliteration, onomatopoeia and rhythm are sometimes used to achieve musical or incantatory effects. The use of ambiguity, symbolism, irony and other stylistic elements of poetic diction often leaves a poem open to multiple interpretations. Similarly figures of speech such as metaphor, simile and metonymy create a resonance between otherwise disparate images—a layering of meanings, forming connections previously not perceived. Kindred forms of resonance may exist, between individual verses, in their patterns of rhyme or rhythm.
Some poetry types are specific to particular cultures and genres and respond to characteristics of the language in which the poet writes. Readers accustomed to identifying poetry with Dante, Goethe, Mickiewicz and Rumi may think of it as written in lines based on rhyme and regular meter; there are, however, traditions, such as Biblical poetry, that use other means to create rhythm and euphony. Much modern poetry reflects a critique of poetic tradition, playing with and testing, among other things, the principle of euphony itself, sometimes altogether forgoing rhyme or set rhythm. In today's increasingly globalized world, poets often adapt forms, styles and techniques from diverse cultures and languages.
History.
Poetry as an art form may predate literacy. Epic poetry, from the Indian "Vedas" (1700–1200 BC) and Zoroaster's "Gathas" to the "Odyssey" (800–675 BC), appears to have been composed in poetic form to aid memorization and oral transmission, in prehistoric and ancient societies. Other forms of poetry developed directly from folk songs. The earliest entries in the ancient compilation "Shijing", were initially lyrics, preceding later entries intended to be read.
The oldest surviving epic poem is the "Epic of Gilgamesh", from the 3rd millennium BC in Sumer (in Mesopotamia, now Iraq), which was written in cuneiform script on clay tablets and, later, papyrus. The oldest love poem is only slightly younger sitting among Sumerian documents such as a court verdict from 2030 B.C. Other ancient epic poetry includes the Greek epics "Iliad" and "Odyssey", the Old Iranian books the "Gathic Avesta" and "Yasna", the Roman national epic, Virgil's "Aeneid", and the Indian epics "Ramayana" and "Mahabharata".
The efforts of ancient thinkers to determine what makes poetry distinctive as a form, and what distinguishes good poetry from bad, resulted in "poetics"—the study of the aesthetics of poetry. Some ancient poetic traditions; such as, contextually, Classical Chinese poetry in the case of the "Shijing" ("Classic of Poetry"), which records the development of poetic canons with ritual and aesthetic importance. More recently, thinkers have struggled to find a definition that could encompass formal differences as great as those between Chaucer's "Canterbury Tales" and Matsuo Bashō's "Oku no Hosomichi", as well as differences in context spanning Tanakh religious poetry, love poetry, and rap.
Western traditions.
Classical thinkers employed classification as a way to define and assess the quality of poetry. Notably, the existing fragments of Aristotle's "Poetics" describe three genres of poetry—the epic, the comic, and the tragic—and develop rules to distinguish the highest-quality poetry in each genre, based on the underlying purposes of the genre. Later aestheticians identified three major genres: epic poetry, lyric poetry, and dramatic poetry, treating comedy and tragedy as subgenres of dramatic poetry.
Aristotle's work was influential throughout the Middle East during the Islamic Golden Age, as well as in Europe during the Renaissance. Later poets and aestheticians often distinguished poetry from, and defined it in opposition to prose, which was generally understood as writing with a proclivity to logical explication and a linear narrative structure.
This does not imply that poetry is illogical or lacks narration, but rather that poetry is an attempt to render the beautiful or sublime without the burden of engaging the logical or narrative thought process. English Romantic poet John Keats termed this escape from logic "Negative Capability". This "romantic" approach views form as a key element of successful poetry because form is abstract and distinct from the underlying notional logic. This approach remained influential into the 20th century.
During this period, there was also substantially more interaction among the various poetic traditions, in part due to the spread of European colonialism and the attendant rise in global trade. In addition to a boom in translation, during the Romantic period numerous ancient works were rediscovered.
20th-century and 21st-century disputes.
Some 20th-century literary theorists, relying less on the opposition of prose and poetry, focused on the poet as simply one who creates using language, and poetry as what the poet creates. The underlying concept of the poet as creator is not uncommon, and some modernist poets essentially do not distinguish between the creation of a poem with words, and creative acts in other media. Yet other modernists challenge the very attempt to define poetry as misguided.
The rejection of traditional forms and structures for poetry that began in the first half of the 20th century coincided with a questioning of the purpose and meaning of traditional definitions of poetry and of distinctions between poetry and prose, particularly given examples of poetic prose and prosaic poetry. Numerous modernist poets have written in non-traditional forms or in what traditionally would have been considered prose, although their writing was generally infused with poetic diction and often with rhythm and tone established by non-metrical means. While there was a substantial formalist reaction within the modernist schools to the breakdown of structure, this reaction focused as much on the development of new formal structures and syntheses as on the revival of older forms and structures.
Recently, postmodernism has come to convey more completely prose and poetry as distinct entities, and also among genres of poetry, as having meaning only as cultural artifacts. Postmodernism goes beyond modernism's emphasis on the creative role of the poet, to emphasize the role of the reader of a text (Hermeneutics), and to highlight the complex cultural web within which a poem is read. Today, throughout the world, poetry often incorporates poetic form and diction from other cultures and from the past, further confounding attempts at definition and classification that were once sensible within a tradition such as the Western canon.
The early 21st century poetic tradition appears to continue to strongly orient itself to earlier precursor poetic traditions such as those initiated by Whitman, Emerson, and Wordsworth. The literary critic Geoffrey Hartman has used the phrase "the anxiety of demand" to describe contemporary response to older poetic traditions as "being fearful that the fact no longer has a form", building on a trope introduced by Emerson. Emerson had maintained that in the debate concerning poetic structure where either "form" or "fact" could predominate, that one need simply "Ask the fact for the form." This has been challenged at various levels by other literary scholars such as Bloom who has stated in summary form concerning the early 21st century that: "The generation of poets who stand together now, mature and ready to write the major American verse of the twenty-first century, may yet be seen as what Stevens called 'a great shadow's last embellishment,' the shadow being Emerson's."
Elements.
Prosody.
Prosody is the study of the meter, rhythm, and intonation of a poem. Rhythm and meter are different, although closely related. Meter is the definitive pattern established for a verse (such as iambic pentameter), while rhythm is the actual sound that results from a line of poetry. Prosody also may be used more specifically to refer to the scanning of poetic lines to show meter.
Rhythm.
The methods for creating poetic rhythm vary across languages and between poetic traditions. Languages are often described as having timing set primarily by accents, syllables, or moras, depending on how rhythm is established, though a language can be influenced by multiple approaches. Japanese is a mora-timed language. Syllable-timed languages include Latin, Catalan, French, Leonese, Galician and Spanish. English, Russian and, generally, German are stress-timed languages. Varying intonation also affects how rhythm is perceived. Languages can rely on either pitch, such as in Vedic Sanskrit or Ancient Greek, or tone. Tonal languages include Chinese, Vietnamese and most Subsaharan languages.
Metrical rhythm generally involves precise arrangements of stresses or syllables into repeated patterns called feet within a line. In Modern English verse the pattern of stresses primarily differentiate feet, so rhythm based on meter in Modern English is most often founded on the pattern of stressed and unstressed syllables (alone or elided). In the classical languages, on the other hand, while the metrical units are similar, vowel length rather than stresses define the meter. Old English poetry used a metrical pattern involving varied numbers of syllables but a fixed number of strong stresses in each line.
The chief device of ancient Hebrew Biblical poetry, including many of the psalms, was "parallelism", a rhetorical structure in which successive lines reflected each other in grammatical structure, sound structure, notional content, or all three. Parallelism lent itself to antiphonal or call-and-response performance, which could also be reinforced by intonation. Thus, Biblical poetry relies much less on metrical feet to create rhythm, but instead creates rhythm based on much larger sound units of lines, phrases and sentences. Some classical poetry forms, such as Venpa of the Tamil language, had rigid grammars (to the point that they could be expressed as a context-free grammar) which ensured a rhythm. In Chinese poetry, tones as well as stresses create rhythm. Classical Chinese poetics identifies four tones: the level tone, rising tone, departing tone, and entering tone.
The formal patterns of meter used in Modern English verse to create rhythm no longer dominate contemporary English poetry. In the case of free verse, rhythm is often organized based on looser units of cadence rather than a regular meter. Robinson Jeffers, Marianne Moore, and William Carlos Williams are three notable poets who reject the idea that regular accentual meter is critical to English poetry. Jeffers experimented with sprung rhythm as an alternative to accentual rhythm.
Meter.
In the Western poetic tradition, meters are customarily grouped according to a characteristic metrical foot and the number of feet per line. The number of metrical feet in a line are described using Greek terminology: tetrameter for four feet and hexameter for six feet, for example. Thus, "iambic pentameter" is a meter comprising five feet per line, in which the predominant kind of foot is the "iamb". This metric system originated in ancient Greek poetry, and was used by poets such as Pindar and Sappho, and by the great tragedians of Athens. Similarly, "dactylic hexameter", comprises six feet per line, of which the dominant kind of foot is the "dactyl". Dactylic hexameter was the traditional meter of Greek epic poetry, the earliest extant examples of which are the works of Homer and Hesiod. Iambic pentameter and dactylic hexameter were later used by a number of poets, including William Shakespeare and Henry Wadsworth Longfellow, respectively. The most common metrical feet in English are:
There are a wide range of names for other types of feet, right up to a choriamb, a four syllable metric foot with a stressed syllable followed by two unstressed syllables and closing with a stressed syllable. The choriamb is derived from some ancient Greek and Latin poetry. Languages which utilize vowel length or intonation rather than or in addition to syllabic accents in determining meter, such as Ottoman Turkish or Vedic, often have concepts similar to the iamb and dactyl to describe common combinations of long and short sounds.
Each of these types of feet has a certain "feel," whether alone or in combination with other feet. The iamb, for example, is the most natural form of rhythm in the English language, and generally produces a subtle but stable verse. Scanning meter can often show the basic or fundamental pattern underlying a verse, but does not show the varying degrees of stress, as well as the differing pitches and lengths of syllables.
There is debate over how useful a multiplicity of different "feet" is in describing meter. For example, Robert Pinsky has argued that while dactyls are important in classical verse, English dactylic verse uses dactyls very irregularly and can be better described based on patterns of iambs and anapests, feet which he considers natural to the language. Actual rhythm is significantly more complex than the basic scanned meter described above, and many scholars have sought to develop systems that would scan such complexity. Vladimir Nabokov noted that overlaid on top of the regular pattern of stressed and unstressed syllables in a line of verse was a separate pattern of accents resulting from the natural pitch of the spoken words, and suggested that the term "scud" be used to distinguish an unaccented stress from an accented stress.
Metrical patterns.
Different traditions and genres of poetry tend to use different meters, ranging from the Shakespearean iambic pentameter and the Homeric dactylic hexameter to the anapestic tetrameter used in many nursery rhymes. However, a number of variations to the established meter are common, both to provide emphasis or attention to a given foot or line and to avoid boring repetition. For example, the stress in a foot may be inverted, a caesura (or pause) may be added (sometimes in place of a foot or stress), or the final foot in a line may be given a feminine ending to soften it or be replaced by a spondee to emphasize it and create a hard stop. Some patterns (such as iambic pentameter) tend to be fairly regular, while other patterns, such as dactylic hexameter, tend to be highly irregular. Regularity can vary between language. In addition, different patterns often develop distinctively in different languages, so that, for example, iambic tetrameter in Russian will generally reflect a regularity in the use of accents to reinforce the meter, which does not occur, or occurs to a much lesser extent, in English.
Some common metrical patterns, with notable examples of poets and poems who use them, include:
Rhyme, alliteration, assonance.
Rhyme, alliteration, assonance and consonance are ways of creating repetitive patterns of sound. They may be used as an independent structural element in a poem, to reinforce rhythmic patterns, or as an ornamental element. They can also carry a meaning separate from the repetitive sound patterns created. For example, Chaucer used heavy alliteration to mock Old English verse and to paint a character as archaic.
Rhyme consists of identical ("hard-rhyme") or similar ("soft-rhyme") sounds placed at the ends of lines or at predictable locations within lines ("internal rhyme"). Languages vary in the richness of their rhyming structures; Italian, for example, has a rich rhyming structure permitting maintenance of a limited set of rhymes throughout a lengthy poem. The richness results from word endings that follow regular forms. English, with its irregular word endings adopted from other languages, is less rich in rhyme. The degree of richness of a language's rhyming structures plays a substantial role in determining what poetic forms are commonly used in that language.
Alliteration is the repetition of letters or letter-sounds at the beginning of two or more words immediately succeeding each other, or at short intervals; or the recurrence of the same letter in accented parts of words. Alliteration and assonance played a key role in structuring early Germanic, Norse and Old English forms of poetry. The alliterative patterns of early Germanic poetry interweave meter and alliteration as a key part of their structure, so that the metrical pattern determines when the listener expects instances of alliteration to occur. This can be compared to an ornamental use of alliteration in most Modern European poetry, where alliterative patterns are not formal or carried through full stanzas. Alliteration is particularly useful in languages with less rich rhyming structures. Assonance, where the use of similar vowel sounds within a word rather than similar sounds at the beginning or end of a word, was widely used in skaldic poetry, but goes back to the Homeric epic. Because verbs carry much of the pitch in the English language, assonance can loosely evoke the tonal elements of Chinese poetry and so is useful in translating Chinese poetry. Consonance occurs where a consonant sound is repeated throughout a sentence without putting the sound only at the front of a word. Consonance provokes a more subtle effect than alliteration and so is less useful as a structural element.
Rhyming schemes.
In many languages, including modern European languages and Arabic, poets use rhyme in set patterns as a structural element for specific poetic forms, such as ballads, sonnets and rhyming couplets. However, the use of structural rhyme is not universal even within the European tradition. Much modern poetry avoids traditional rhyme schemes. Classical Greek and Latin poetry did not use rhyme. Rhyme entered European poetry in the High Middle Ages, in part under the influence of the Arabic language in Al Andalus (modern Spain). Arabic language poets used rhyme extensively from the first development of literary Arabic in the sixth century, as in their long, rhyming qasidas. Some rhyming schemes have become associated with a specific language, culture or period, while other rhyming schemes have achieved use across languages, cultures or time periods. Some forms of poetry carry a consistent and well-defined rhyming scheme, such as the chant royal or the rubaiyat, while other poetic forms have variable rhyme schemes.
Most rhyme schemes are described using letters that correspond to sets of rhymes, so if the first, second and fourth lines of a quatrain rhyme with each other and the third line does not rhyme, the quatrain is said to have an "a-a-b-a" rhyme scheme. This rhyme scheme is the one used, for example, in the rubaiyat form. Similarly, an "a-b-b-a" quatrain (what is known as "enclosed rhyme") is used in such forms as the Petrarchan sonnet. Some types of more complicated rhyming schemes have developed names of their own, separate from the "a-b-c" convention, such as the ottava rima and terza rima. The types and use of differing rhyming schemes is discussed further in the main article.
Form.
Poetic form is more flexible in modernist and post-modernist poetry, and continues to be less structured than in previous literary eras. Many modern poets eschew recognisable structures or forms, and write in free verse. But poetry remains distinguished from prose by its form; some regard for basic formal structures of poetry will be found in even the best free verse, however much such structures may appear to have been ignored. Similarly, in the best poetry written in classic styles there will be departures from strict form for emphasis or effect.
Among major structural elements used in poetry are the line, the stanza or verse paragraph, and larger combinations of stanzas or lines such as cantos. Also sometimes used are broader visual presentations of words and calligraphy. These basic units of poetic form are often combined into larger structures, called "poetic forms" or poetic modes (see following section), as in the sonnet or haiku.
Lines and stanzas.
Poetry is often separated into lines on a page. These lines may be based on the number of metrical feet, or may emphasize a rhyming pattern at the ends of lines. Lines may serve other functions, particularly where the poem is not written in a formal metrical pattern. Lines can separate, compare or contrast thoughts expressed in different units, or can highlight a change in tone. See the article on line breaks for information about the division between lines.
Lines of poems are often organized into stanzas, which are denominated by the number of lines included. Thus a collection of two lines is a couplet (or distich), three lines a triplet (or tercet), four lines a quatrain, and so on. These lines may or may not relate to each other by rhyme or rhythm. For example, a couplet may be two lines with identical meters which rhyme or two lines held together by a common meter alone.
Other poems may be organized into verse paragraphs, in which regular rhymes with established rhythms are not used, but the poetic tone is instead established by a collection of rhythms, alliterations, and rhymes established in paragraph form. Many medieval poems were written in verse paragraphs, even where regular rhymes and rhythms were used.
In many forms of poetry, stanzas are interlocking, so that the rhyming scheme or other structural elements of one stanza determine those of succeeding stanzas. Examples of such interlocking stanzas include, for example, the ghazal and the villanelle, where a refrain (or, in the case of the villanelle, refrains) is established in the first stanza which then repeats in subsequent stanzas. Related to the use of interlocking stanzas is their use to separate thematic parts of a poem. For example, the strophe, antistrophe and epode of the ode form are often separated into one or more stanzas.
In some cases, particularly lengthier formal poetry such as some forms of epic poetry, stanzas themselves are constructed according to strict rules and then combined. In skaldic poetry, the dróttkvætt stanza had eight lines, each having three "lifts" produced with alliteration or assonance. In addition to two or three alliterations, the odd numbered lines had partial rhyme of consonants with dissimilar vowels, not necessarily at the beginning of the word; the even lines contained internal rhyme in set syllables (not necessarily at the end of the word). Each half-line had exactly six syllables, and each line ended in a trochee. The arrangement of dróttkvætts followed far less rigid rules than the construction of the individual dróttkvætts.
Visual presentation.
Even before the advent of printing, the visual appearance of poetry often added meaning or depth. Acrostic poems conveyed meanings in the initial letters of lines or in letters at other specific places in a poem. In Arabic, Hebrew and Chinese poetry, the visual presentation of finely calligraphed poems has played an important part in the overall effect of many poems.
With the advent of printing, poets gained greater control over the mass-produced visual presentations of their work. Visual elements have become an important part of the poet's toolbox, and many poets have sought to use visual presentation for a wide range of purposes. Some Modernist poets have made the placement of individual lines or groups of lines on the page an integral part of the poem's composition. At times, this complements the poem's rhythm through visual caesuras of various lengths, or creates juxtapositions so as to accentuate meaning, ambiguity or irony, or simply to create an aesthetically pleasing form. In its most extreme form, this can lead to concrete poetry or asemic writing.
Diction.
Poetic diction treats the manner in which language is used, and refers not only to the sound but also to the underlying meaning and its interaction with sound and form. Many languages and poetic forms have very specific poetic dictions, to the point where distinct grammars and dialects are used specifically for poetry. Registers in poetry can range from strict employment of ordinary speech patterns, as favoured in much late-20th-century prosody, through to highly ornate uses of language, as in medieval and Renaissance poetry.
Poetic diction can include rhetorical devices such as simile and metaphor, as well as tones of voice, such as irony. Aristotle wrote in the "Poetics" that "the greatest thing by far is to be a master of metaphor." Since the rise of Modernism, some poets have opted for a poetic diction that de-emphasizes rhetorical devices, attempting instead the direct presentation of things and experiences and the exploration of tone. On the other hand, Surrealists have pushed rhetorical devices to their limits, making frequent use of catachresis.
Allegorical stories are central to the poetic diction of many cultures, and were prominent in the West during classical times, the late Middle Ages and the Renaissance. "Aesop's Fables", repeatedly rendered in both verse and prose since first being recorded about 500 B.C., are perhaps the richest single source of allegorical poetry through the ages. Other notables examples include the "Roman de la Rose", a 13th-century French poem, William Langland's "Piers Ploughman" in the 14th century, and Jean de la Fontaine's "Fables" (influenced by Aesop's) in the 17th century. Rather than being fully allegorical, however, a poem may contain symbols or allusions that deepen the meaning or effect of its words without constructing a full allegory.
Another element of poetic diction can be the use of vivid imagery for effect. The juxtaposition of unexpected or impossible images is, for example, a particularly strong element in surrealist poetry and haiku. Vivid images are often endowed with symbolism or metaphor. Many poetic dictions use repetitive phrases for effect, either a short phrase (such as Homer's "rosy-fingered dawn" or "the wine-dark sea") or a longer refrain. Such repetition can add a sombre tone to a poem, or can be laced with irony as the context of the words changes.
Forms.
Specific poetic forms have been developed by many cultures. In more developed, closed or "received" poetic forms, the rhyming scheme, meter and other elements of a poem are based on sets of rules, ranging from the relatively loose rules that govern the construction of an elegy to the highly formalized structure of the ghazal or villanelle. Described below are some common forms of poetry widely used across a number of languages. Additional forms of poetry may be found in the discussions of poetry of particular cultures or periods and in the glossary.
Sonnet.
Among the most common forms of poetry through the ages is the sonnet, which by the 13th century was a poem of fourteen lines following a set rhyme scheme and logical structure. By the 14th century, the form further crystallized under the pen of Petrarch, whose sonnets were later translated in the 16th century by Sir Thomas Wyatt, who is credited with introducing the sonnet form into English literature. A sonnet's first four lines typically introduce the topic, the second elaborates and the third posits a problem - the couplet usually, but not always, includes a twist, or an afterthought. A sonnet usually follows an a-b-a-b-c-d-c-d-e-f-e-f-gg rhyme pattern. The sonnet's conventions have changed over its history, and so there are several different sonnet forms. Traditionally, in sonnets English poets use iambic pentameter, the Spenserian and Shakespearean sonnets being especially notable. In the Romance languages, the hendecasyllable and Alexandrine are the most widely used meters, though the Petrarchan sonnet has been used in Italy since the 14th century.
Sonnets are particularly associated with love poetry, and often use a poetic diction heavily based on vivid imagery, but the twists and turns associated with the move from octave to sestet and to final couplet make them a useful and dynamic form for many subjects. Shakespeare's sonnets are among the most famous in English poetry, with 20 being included in the "Oxford Book of English Verse".
Shi.
"Shi" () Is the main type of Classical Chinese poetry. Within this form of poetry the most important variations are "folk song" styled verse ("yuefu"), "old style" verse ("gushi"), "modern style" verse ("jintishi"). In all cases, rhyming is obligatory. The Yuefu is a folk ballad or a poem written in the folk ballad style, and the number of lines and the length of the lines could be irregular. For the other variations of "shi" poetry, generally either a four line (quatrain, or "jueju") or else an eight line poem is normal; either way with the even numbered lines rhyming. The line length is scanned by according number of characters (according to the convention that one character equals one syllable), and are predominantly either five or seven characters long, with a caesura before the final three syllables. The lines are generally end-stopped, considered as a series of couplets, and exhibit verbal parallelism as a key poetic device. The "old style" verse ("gushi") is less formally strict than the "jintishi", or regulated verse, which, despite the name "new style" verse actually had its theoretical basis laid as far back to Shen Yue, in the 5th or 6th century, although not considered to have reached its full development until the time of Chen Zi'ang (661-702) A good example of a poet known for his "gushi" poems is Li Bai. Among its other rules, the jintishi rules regulate the tonal variations within a poem, including the use of set patterns of the four tones of Middle Chinese The basic form of jintishi (lushi) has eight lines in four couplets, with parallelism between the lines in the second and third couplets. The couplets with parallel lines contain contrasting content but an identical grammatical relationship between words. Jintishi often have a rich poetic diction, full of allusion, and can have a wide range of subject, including history and politics. One of the masters of the form was Du Fu, who wrote during the Tang Dynasty (8th century).
Villanelle.
The villanelle is a nineteen-line poem made up of five triplets with a closing quatrain; the poem is characterized by having two refrains, initially used in the first and third lines of the first stanza, and then alternately used at the close of each subsequent stanza until the final quatrain, which is concluded by the two refrains. The remaining lines of the poem have an a-b alternating rhyme. The villanelle has been used regularly in the English language since the late 19th century by such poets as Dylan Thomas, W. H. Auden, and Elizabeth Bishop.
Tanka.
Tanka is a form of unrhymed Japanese poetry, with five sections totalling 31 "onji" (phonological units identical to morae), structured in a 5-7-5-7-7 pattern. There is generally a shift in tone and subject matter between the upper 5-7-5 phrase and the lower 7-7 phrase. Tanka were written as early as the Asuka period by such poets as Kakinomoto no Hitomaro, at a time when Japan was emerging from a period where much of its poetry followed Chinese form. Tanka was originally the shorter form of Japanese formal poetry (which was generally referred to as "waka"), and was used more heavily to explore personal rather than public themes. By the tenth century, tanka had become the dominant form of Japanese poetry, to the point where the originally general term "waka" ("Japanese poetry") came to be used exclusively for tanka. Tanka are still widely written today.
Haiku.
Haiku is a popular form of unrhymed Japanese poetry, which evolved in the 17th century from the "hokku", or opening verse of a renku. Generally written in a single vertical line, the haiku contains three sections totalling 17 "onji", structured in a 5-7-5 pattern. Traditionally, haiku contain a kireji, or cutting word, usually placed at the end of one of the poem's three sections, and a kigo, or season-word. The most famous exponent of the haiku was Matsuo Bashō (1644–1694). An example of his writing:
Ode.
Odes were first developed by poets writing in ancient Greek, such as Pindar, and Latin, such as Horace. Forms of odes appear in many of the cultures that were influenced by the Greeks and Latins. The ode generally has three parts: a strophe, an antistrophe, and an epode. The antistrophes of the ode possess similar metrical structures and, depending on the tradition, similar rhyme structures. In contrast, the epode is written with a different scheme and structure. Odes have a formal poetic diction, and generally deal with a serious subject. The strophe and antistrophe look at the subject from different, often conflicting, perspectives, with the epode moving to a higher level to either view or resolve the underlying issues. Odes are often intended to be recited or sung by two choruses (or individuals), with the first reciting the strophe, the second the antistrophe, and both together the epode. Over time, differing forms for odes have developed with considerable variations in form and structure, but generally showing the original influence of the Pindaric or Horatian ode. One non-Western form which resembles the ode is the qasida in Persian poetry.
Ghazal.
The ghazal (also ghazel, gazel, gazal, or gozol) is a form of poetry common in Arabic, Persian, Turkish, Azerbaijani, Urdu and Bengali poetry. In classic form, the ghazal has from five to fifteen rhyming couplets that share a refrain at the end of the second line. This refrain may be of one or several syllables, and is preceded by a rhyme. Each line has an identical meter. The ghazal often reflects on a theme of unattainable love or divinity.
As with other forms with a long history in many languages, many variations have been developed, including forms with a quasi-musical poetic diction in Urdu. Ghazals have a classical affinity with Sufism, and a number of major Sufi religious works are written in ghazal form. The relatively steady meter and the use of the refrain produce an incantatory effect, which complements Sufi mystical themes well. Among the masters of the form is Rumi, a 13th-century Persian poet.
One of the most famous poet in this type of poetry is Hafez. Themes of his Ghazal is exposing hypocrisy. His life and poems have been the subject of much analysis, commentary and interpretation, influencing post-fourteenth century Persian writing more than any other author. West-östlicher Diwan of Johann Wolfgang von Goethe that is a collection of lyrical poems, has been inspired by the Persian poet Hafez.
Genres.
In addition to specific forms of poems, poetry is often thought of in terms of different genres and subgenres. A poetic genre is generally a tradition or classification of poetry based on the subject matter, style, or other broader literary characteristics. Some commentators view genres as natural forms of literature. Others view the study of genres as the study of how different works relate and refer to other works.
Narrative poetry.
Narrative poetry is a genre of poetry that tells a story. Broadly it subsumes epic poetry, but the term "narrative poetry" is often reserved for smaller works, generally with more appeal to human interest. Narrative poetry may be the oldest type of poetry. Many scholars of Homer have concluded that his "Iliad" and "Odyssey" were composed from compilations of shorter narrative poems that related individual episodes. Much narrative poetry—such as Scottish and English ballads, and Baltic and Slavic heroic poems—is performance poetry with roots in a preliterate oral tradition. It has been speculated that some features that distinguish poetry from prose, such as meter, alliteration and kennings, once served as memory aids for bards who recited traditional tales.
Notable narrative poets have included Ovid, Dante, Juan Ruiz, Chaucer, William Langland, Luís de Camões, Shakespeare, Alexander Pope, Robert Burns, Fernando de Rojas, Adam Mickiewicz, Alexander Pushkin, Edgar Allan Poe and Alfred Tennyson.
Epic poetry.
Epic poetry is a genre of poetry, and a major form of narrative literature. This genre is often defined as lengthy poems concerning events of a heroic or important nature to the culture of the time. It recounts, in a continuous narrative, the life and works of a heroic or mythological person or group of persons. Examples of epic poems are Homer's "Iliad" and "Odyssey", Virgil's Aeneid, the "Nibelungenlied", Luís de Camões' "Os Lusíadas", the "Cantar de Mio Cid", the "Epic of Gilgamesh", the "Mahabharata", Valmiki's "Ramayana", Ferdowsi's "Shahnama", Nizami (or Nezami)'s Khamse (Five Books), and the "Epic of King Gesar". While the composition of epic poetry, and of long poems generally, became less common in the west after the early 20th century, some notable epics have continued to be written. Derek Walcott won a Nobel prize to a great extent on the basis of his epic, "Omeros".
Dramatic poetry.
Dramatic poetry is drama written in verse to be spoken or sung, and appears in varying, sometimes related forms in many cultures. Greek tragedy in verse dates to the 6th century B.C., and may have been an influence on the development of Sanskrit drama, just as Indian drama in turn appears to have influenced the development of the "bianwen" verse dramas in China, forerunners of Chinese Opera. East Asian verse dramas also include Japanese Noh. Examples of dramatic poetry in Persian literature include Nizami's two famous dramatic works, "Layla and Majnun" and "Khosrow and Shirin", Ferdowsi's tragedies such as "Rostam and Sohrab", Rumi's "Masnavi", Gorgani's tragedy of "Vis and Ramin", and Vahshi's tragedy of "Farhad".
Satirical poetry.
Poetry can be a powerful vehicle for satire. The Romans had a strong tradition of satirical poetry, often written for political purposes. A notable example is the Roman poet Juvenal's satires.
The same is true of the English satirical tradition. John Dryden (a Tory), the first Poet Laureate, produced in 1682 "Mac Flecknoe", subtitled "A Satire on the True Blue Protestant Poet, T.S." (a reference to Thomas Shadwell). Another master of 17th-century English satirical poetry was John Wilmot, 2nd Earl of Rochester. Satirical poets outside England include Poland's Ignacy Krasicki, Azerbaijan's Sabir and Portugal's Manuel Maria Barbosa du Bocage.
Light poetry.
Light poetry, or light verse, is poetry that attempts to be humorous. Poems considered "light" are usually brief, and can be on a frivolous or serious subject, and often feature word play, including puns, adventurous rhyme and heavy alliteration. Although a few free verse poets have excelled at light verse outside the formal verse tradition, light verse in English is usually formal. Common forms include the limerick, the clerihew, and the double dactyl.
While light poetry is sometimes condemned as doggerel, or thought of as poetry composed casually, humor often makes a serious point in a subtle or subversive way. Many of the most renowned "serious" poets have also excelled at light verse. Notable writers of light poetry include Lewis Carroll, Ogden Nash, X. J. Kennedy, Willard R. Espy, and Wendy Cope.
Lyric poetry.
Lyric poetry is a genre that, unlike epic and dramatic poetry, does not attempt to tell a story but instead is of a more personal nature. Poems in this genre tend to be shorter, melodic, and contemplative. Rather than depicting characters and actions, it portrays the poet's own feelings, states of mind, and perceptions. Notable poets in this genre include John Donne, Gerard Manley Hopkins, and Antonio Machado.
Elegy.
An elegy is a mournful, melancholy or plaintive poem, especially a lament for the dead or a funeral song. The term "elegy," which originally denoted a type of poetic meter (elegiac meter), commonly describes a poem of mourning. An elegy may also reflect something that seems to the author to be strange or mysterious. The elegy, as a reflection on a death, on a sorrow more generally, or on something mysterious, may be classified as a form of lyric poetry.
Notable practitioners of elegiac poetry have included Propertius, Jorge Manrique, Jan Kochanowski, Chidiock Tichborne, Edmund Spenser, Ben Jonson, John Milton, Thomas Gray, Charlotte Turner Smith, William Cullen Bryant, Percy Bysshe Shelley, Johann Wolfgang von Goethe, Evgeny Baratynsky, Alfred Tennyson, Walt Whitman, Louis Gallet, Antonio Machado, Juan Ramón Jiménez, William Butler Yeats, Rainer Maria Rilke, and Virginia Woolf.
Verse fable.
The fable is an ancient literary genre, often (though not invariably) set in verse. It is a succinct story that features anthropomorphized animals, plants, inanimate objects, or forces of nature that illustrate a moral lesson (a "moral"). Verse fables have used a variety of meter and rhyme patterns.
Notable verse fabulists have included Aesop, Vishnu Sarma, Phaedrus, Marie de France, Robert Henryson, Biernat of Lublin, Jean de La Fontaine, Ignacy Krasicki, Félix María de Samaniego, Tomás de Iriarte, Ivan Krylov and Ambrose Bierce.
Prose poetry.
Prose poetry is a hybrid genre that shows attributes of both prose and poetry. It may be indistinguishable from the micro-story ( the "short short story", "flash fiction"). While some examples of earlier prose strike modern readers as poetic, prose poetry is commonly regarded as having originated in 19th-century France, where its practitioners included Aloysius Bertrand, Charles Baudelaire, Arthur Rimbaud and Stéphane Mallarmé. Since the late 1980s especially, prose poetry has gained increasing popularity, with entire journals, such as "The Prose Poem: An International Journal", "Contemporary Haibun Online" devoted to that genre.
Speculative poetry.
Speculative poetry, also known as fantastic poetry, (of which weird or macabre poetry is a major subclassification), is a poetic genre which deals thematically with subjects which are 'beyond reality', whether via extrapolation as in science fiction or via weird and horrific themes as in horror fiction. Such poetry appears regularly in modern science fiction and horror fiction magazines. Edgar Allan Poe is sometimes seen as the "father of speculative poetry".
Further reading.
Listen to this article ()
This audio file was created from a revision of the "Poetry" article dated 2005-04-20, and does not reflect subsequent edits to the article. ()
More spoken articles

</doc>
<doc id="22934" url="http://en.wikipedia.org/wiki?curid=22934" title="Probability">
Probability

Probability is the measure of the likeliness that an event will occur. Probability is quantified as a number between 0 and 1 (where 0 indicates impossibility and 1 indicates certainty). The higher the probability of an event, the more certain we are that the event will occur. A simple example is the toss of a fair coin. Since the two outcomes are equally probable, the probability of "heads" equals the probability of "tails", so the probability is 1/2 (or 50%) chance of either "heads" or "tails".
These concepts have been given an axiomatic mathematical formalization in probability theory (see probability axioms), which is used widely in such areas of study as mathematics, statistics, finance, gambling, science (in particular physics), artificial intelligence/machine learning, computer science, and philosophy to, for example, draw inferences about the expected frequency of events. Probability theory is also used to describe the underlying mechanics and regularities of complex systems.
Interpretations.
When dealing with experiments that are random and well-defined in a purely theoretical setting (like tossing a fair coin), probabilities can be numerically described by the statistical number of outcomes considered favorable divided by the total number of all outcomes (tossing a fair coin twice will yield head-head with probability 1/4, because the four outcomes head-head, head-tails, tails-head and tails-tails are equally likely to occur). When it comes to practical application however there are two major competing categories of probability interpretations, whose adherents possess different views about the fundamental nature of probability:
Etymology.
The word "probability" derives from the Latin "probabilitas", which can also mean "probity", a measure of the authority of a witness in a legal case in Europe, and often correlated with the witness's nobility. In a sense, this differs much from the modern meaning of "probability", which, in contrast, is a measure of the weight of empirical evidence, and is arrived at from inductive reasoning and statistical inference.
History.
The scientific study of probability is a modern development. Gambling shows that there has been an interest in quantifying the ideas of probability for millennia, but exact mathematical descriptions arose much later. There are reasons of course, for the slow development of the mathematics of probability. Whereas games of chance provided the impetus for the mathematical study of probability, are still obscured by the superstitions of gamblers.
According to Richard Jeffrey, "Before the middle of the seventeenth century, the term 'probable' (Latin "probabilis") meant "approvable", and was applied in that sense, univocally, to opinion and to action. A probable action or opinion was one such as sensible people would undertake or hold, in the circumstances." However, in legal contexts especially, 'probable' could also apply to propositions for which there was good evidence.
The sixteenth century polymath Gerolamo Cardano demonstrated the efficacy of defining odds as the ratio of favourable to unfavourable outcomes (which implies that the probability of an event is given by the ratio of favourable outcomes to the total number of possible outcomes ).
Aside from the elementary work by Cardano, the doctrine of probabilities dates to the correspondence of Pierre de Fermat and Blaise Pascal (1654). Christiaan Huygens (1657) gave the earliest known scientific treatment of the subject. Jakob Bernoulli's "Ars Conjectandi" (posthumous, 1713) and Abraham de Moivre's "Doctrine of Chances" (1718) treated the subject as a branch of mathematics. See Ian Hacking's "The Emergence of Probability" and James Franklin's "The Science of Conjecture" for histories of the early development of the very concept of mathematical probability.
The theory of errors may be traced back to Roger Cotes's "Opera Miscellanea" (posthumous, 1722), but a memoir prepared by Thomas Simpson in 1755 (printed 1756) first applied the theory to the discussion of errors of observation. The reprint (1757) of this memoir lays down the axioms that positive and negative errors are equally probable, and that certain assignable limits define the range of all errors. Simpson also discusses continuous errors and describes a probability curve.
The first two laws of error that were proposed both originated with Pierre-Simon Laplace. The first law was published in 1774 and stated that the frequency of an error could be expressed as an exponential function of the numerical magnitude of the error, disregarding sign. The second law of error was proposed in 1778 by Laplace and stated that the frequency of the error is an exponential function of the square of the error. The second law of error is called the normal distribution or the Gauss law. "It is difficult historically to attribute that law to Gauss, who in spite of his well-known precocity had probably not made this discovery before he was two years old."
Daniel Bernoulli (1778) introduced the principle of the maximum product of the probabilities of a system of concurrent errors.
Adrien-Marie Legendre (1805) developed the method of least squares, and introduced it in his "Nouvelles méthodes pour la détermination des orbites des comètes" ("New Methods for Determining the Orbits of Comets"). In ignorance of Legendre's contribution, an Irish-American writer, Robert Adrain, editor of "The Analyst" (1808), first deduced the law of facility of error,
where formula_2 is a constant depending on precision of observation, and formula_3 is a scale factor ensuring that the area under the curve equals 1. He gave two proofs, the second being essentially the same as John Herschel's (1850). Gauss gave the first proof that seems to have been known in Europe (the third after Adrain's) in 1809. Further proofs were given by Laplace (1810, 1812), Gauss (1823), James Ivory (1825, 1826), Hagen (1837), Friedrich Bessel (1838), W. F. Donkin (1844, 1856), and Morgan Crofton (1870). Other contributors were Ellis (1844), De Morgan (1864), Glaisher (1872), and Giovanni Schiaparelli (1875). Peters's (1856) formula for "r", the probable error of a single observation, is well known.
In the nineteenth century authors on the general theory included Laplace, Sylvestre Lacroix (1816), Littrow (1833), Adolphe Quetelet (1853), Richard Dedekind (1860), Helmert (1872), Hermann Laurent (1873), Liagre, Didion, and Karl Pearson. Augustus De Morgan and George Boole improved the exposition of the theory.
Andrey Markov introduced the notion of Markov chains (1906), which played an important role in stochastic processes theory and its applications. The modern theory of probability based on the measure theory was developed by Andrey Kolmogorov (1931).
On the geometric side (see integral geometry) contributors to "The Educational Times" were influential (Miller, Crofton, McColl, Wolstenholme, Watson, and Artemas Martin).
Theory.
Like other theories, the theory of probability is a representation of probabilistic concepts in formal terms—that is, in terms that can be considered separately from their meaning. These formal terms are manipulated by the rules of mathematics and logic, and any results are interpreted or translated back into the problem domain.
There have been at least two successful attempts to formalize probability, namely the Kolmogorov formulation and the Cox formulation. In Kolmogorov's formulation (see probability space), sets are interpreted as events and probability itself as a measure on a class of sets. In Cox's theorem, probability is taken as a primitive (that is, not further analyzed) and the emphasis is on constructing a consistent assignment of probability values to propositions. In both cases, the laws of probability are the same, except for technical details.
There are other methods for quantifying uncertainty, such as the Dempster–Shafer theory or possibility theory, but those are essentially different and not compatible with the laws of probability as usually understood.
Applications.
Probability theory is applied in everyday life in risk assessment and in trade on financial markets. Governments apply probabilistic methods in environmental regulation, where it is called pathway analysis.
A good example is the effect of the perceived probability of any widespread Middle East conflict on oil prices—which have ripple effects in the economy as a whole. An assessment by a commodity trader that a war is more likely vs. less likely sends prices up or down, and signals other traders of that opinion. Accordingly, the probabilities are neither assessed independently nor necessarily very rationally. The theory of behavioral finance emerged to describe the effect of such groupthink on pricing, on policy, and on peace and conflict.
The discovery of rigorous methods to assess and combine probability assessments has changed society. It is important for most citizens to understand how probability assessments are made, and how they contribute to decisions.
Another significant application of probability theory in everyday life is reliability. Many consumer products, such as automobiles and consumer electronics, use reliability theory in product design to reduce the probability of failure. Failure probability may influence a manufacturer's decisions on a product's warranty.
The cache language model and other statistical language models that are used in natural language processing are also examples of applications of probability theory.
Mathematical treatment.
Consider an experiment that can produce a number of results. The collection of all results is called the sample space of the experiment. The power set of the sample space is formed by considering all different collections of possible results. For example, rolling a die can produce six possible results. One collection of possible results gives an odd number on the dice. Thus, the subset {1,3,5} is an element of the power set of the sample space of dice rolls. These collections are called "events." In this case, {1,3,5} is the event that the dice falls on some odd number. If the results that actually occur fall in a given event, the event is said to have occurred.
A probability is a way of assigning every event a value between zero and one, with the requirement that the event made up of all possible results (in our example, the event {1,2,3,4,5,6}) is assigned a value of one. To qualify as a probability, the assignment of values must satisfy the requirement that if you look at a collection of mutually exclusive events (events with no common results, e.g., the events {1,6}, {3}, and {2,4} are all mutually exclusive), the probability that at least one of the events will occur is given by the sum of the probabilities of all the individual events.
The probability of an event "A" is written as "P"("A"), "p"("A") or Pr("A"). This mathematical definition of probability can extend to infinite sample spaces, and even uncountable sample spaces, using the concept of a measure.
The "opposite" or "complement" of an event "A" is the event [not "A"] (that is, the event of "A" not occurring); its probability is given by "P"(not "A") = 1 − "P"("A"). As an example, the chance of not rolling a six on a six-sided die is 1 – (chance of rolling a six)formula_4. See Complementary event for a more complete treatment.
If two events "A" and "B" occur on a single performance of an experiment, this is called the intersection or joint probability of "A" and "B", denoted as formula_5.
Independent events.
If two events, "A" and "B" are independent then the joint probability is
for example, if two coins are flipped the chance of both being heads is formula_7.
Mutually exclusive events.
If either event "A" or event "B" occurs on a single performance of an experiment this is called the union of the events "A" and "B" denoted as formula_8.
If two events are mutually exclusive then the probability of either occurring is
For example, the chance of rolling a 1 or 2 on a six-sided die is formula_10
Not mutually exclusive events.
If the events are not mutually exclusive then
For example, when drawing a single card at random from a regular deck of cards, the chance of getting a heart or a face card (J,Q,K) (or one that is both) is formula_12, because of the 52 cards of a deck 13 are hearts, 12 are face cards, and 3 are both: here the possibilities included in the "3 that are both" are included in each of the "13 hearts" and the "12 face cards" but should only be counted once.
Conditional probability.
"Conditional probability" is the probability of some event "A", given the occurrence of some other event "B".
Conditional probability is written formula_13, and is read "the probability of "A", given "B"". It is defined by
If formula_15 then formula_13 is formally undefined by this expression. However, it is possible to define a conditional probability for some zero-probability events using a σ-algebra of such events (such as those arising from a continuous random variable).
For example, in a bag of 2 red balls and 2 blue balls (4 balls in total), the probability of taking a red ball is formula_17; however, when taking a second ball, the probability of it being either a red ball or a blue ball depends on the ball previously taken, such as, if a red ball was taken, the probability of picking a red ball again would be formula_18 since only 1 red and 2 blue balls would have been remaining.
Inverse probability.
In probability theory and applications, Bayes' rule relates the odds of event formula_19 to event formula_20, before (prior to) and after (posterior to) conditioning on another event formula_21. The odds on formula_19 to event formula_20 is simply the ratio of the probabilities of the two events. When arbitrarily many events formula_24 are of interest, not just two, the rule can be rephrased as posterior is proportional to prior times likelihood, formula_25 where the proportionality symbol means that the left hand side is proportional to (i.e., equals a constant times) the right hand side as formula_24 varies, for fixed or given formula_21 (Lee, 2012; Bertsch McGrayne, 2012). In this form it goes back to Laplace (1774) and to Cournot (1843); see Fienberg (2005). See Inverse probability and Bayes' rule.
Relation to randomness.
In a deterministic universe, based on Newtonian concepts, there would be no probability if all conditions were known (Laplace's demon), (but there are situations in which sensitivity to initial conditions exceeds our ability to measure them, i.e. know them). In the case of a roulette wheel, if the force of the hand and the period of that force are known, the number on which the ball will stop would be a certainty (though as a practical matter, this would likely be true only of a roulette wheel that had not been exactly levelled — as Thomas A. Bass' Newtonian Casino revealed). Of course, this also assumes knowledge of inertia and friction of the wheel, weight, smoothness and roundness of the ball, variations in hand speed during the turning and so forth. A probabilistic description can thus be more useful than Newtonian mechanics for analyzing the pattern of outcomes of repeated rolls of a roulette wheel. Physicists face the same situation in kinetic theory of gases, where the system, while deterministic "in principle", is so complex (with the number of molecules typically the order of magnitude of Avogadro constant 6.02·1023) that only a statistical description of its properties is feasible.
Probability theory is required to describe quantum phenomena. A revolutionary discovery of early 20th century physics was the random character of all physical processes that occur at sub-atomic scales and are governed by the laws of quantum mechanics. The objective wave function evolves deterministically but, according to the Copenhagen interpretation, it deals with probabilities of observing, the outcome being explained by a wave function collapse when an observation is made. However, the loss of determinism for the sake of instrumentalism did not meet with universal approval. Albert Einstein famously in a letter to Max Born: "I am convinced that God does not play dice". Like Einstein, Erwin Schrödinger, who discovered the wave function, believed quantum mechanics is a statistical approximation of an underlying deterministic reality. In modern interpretations, quantum decoherence accounts for subjectively probabilistic behavior.

</doc>
<doc id="22936" url="http://en.wikipedia.org/wiki?curid=22936" title="Poland">
Poland

 </td>
 </tr>
 
 <tr style="font-size:85%;" class="mergedbottomrow">
 <td colspan="2" style="padding-left:0;"> ^b The adoption of Christianity in Poland is seen by many Poles, regardless of their religious affiliation or lack thereof, as one of the most significant events in their country's history, as it was used to unify the tribes in the region.
Poland (; Polish: "Polska" ]), officially the Republic of Poland (Polish: "Rzeczpospolita Polska",   ), is a country in Central Europe bordered by Germany to the west; the Czech Republic and Slovakia to the south; Ukraine and Belarus to the east; and the Baltic Sea, Kaliningrad Oblast (a Russian exclave) and Lithuania to the north. The total area of Poland is 312679 km2, making it the 71st largest country in the world and the 9th largest in Europe. With a population of over 38.5 million people, Poland is the 34th most populous country in the world, the sixth most populous member of the European Union, and the most populous post-communist member of the European Union. Poland is a unitary state divided into 16 administrative subdivisions.
Many historians trace the establishment of a Polish state to 966, when Mieszko I, ruler of a territory roughly coextensive with that of present-day Poland, converted to Christianity. The Kingdom of Poland was founded in 1025, and in 1569 it cemented a longstanding political association with the Grand Duchy of Lithuania by signing the Union of Lublin, forming the Polish–Lithuanian Commonwealth. The Commonwealth gradually ceased to exist in the years 1772–1795, when the Polish territory was partitioned among Prussia, the Russian Empire, and Austria. Poland regained its independence (as the Second Polish Republic) at the end of World War I, in 1918.
Two decades later, in September 1939, World War II started with the invasions of Poland by Nazi Germany and the Soviet Union (as part of the Molotov–Ribbentrop Pact). More than six million Polish citizens died in the war. In 1944, a Soviet-backed Polish provisional government was formed which, after a period of conflict, falsified a referendum and an election, giving rise to a satellite state of the Soviet Union, "Polish Republic" ("Rzeczpospolita Polska"), renamed to the People's Republic of Poland ("Polska Rzeczpospolita Ludowa") in 1952. During the Revolutions of 1989, Poland's Marxist–Leninist government was overthrown and Poland adopted a new constitution establishing itself as a democracy under the name "Rzeczpospolita Polska", often referred to as the "Third Polish Republic" ("III Rzeczpospolita").
Despite the vast destruction the country experienced during World War II, Poland managed to preserve much of its cultural wealth. There are 14 heritage sites inscribed on the UNESCO World Heritage and 54 Historical Monuments and many objects of cultural heritage. Since the end of the communist period, Poland has achieved a "very high" ranking in terms of human development, as well as gradually improving economic freedom. Poland is the sixth largest economy within the European Union and among the fastest rising economic states in the world. The country is the sole member nation of the European Union to have escaped a decline in GDP and in recent years was able to create probably the most varied GDP growth in its history. 
Etymology.
The source of the name Poland and the ethnonyms for the Poles include endonyms (the way Polish people refer to themselves and their country) and exonyms (the way other peoples refer to the Poles and their country). Endonyms and most exonyms for Poles and Poland derive from the name of the West Slavic tribe of the Polans ("Polanie").
The origin of the name "Polanie" itself is uncertain. It may derive from such Polish words as "pole" (field). The early tribal inhabitants denominated it from the nature of the country. Lowlands and low hills predominate throughout the vast region from the Baltic shores to the foothills of the Carpathian Mountains. "Between the Alps, Hungary, and the ocean, lies Poland, which is called in their native tongue Campania" (Latin: "Inter Alpes Huniae et Oceanum est Polonia, sic dicta in eorum idiomate quasi Campania") is the description by Gervase of Tilbury in his "Otia imperialia" ("Recreation for the Emperor") of 1211. In some languages the exonyms for Poland derive from another tribal name, Lechites ("Lechici").
History.
Prehistory and protohistory of Poland.
Historians have postulated that throughout Late Antiquity, many distinct ethnic groups populated the regions of what is now Poland. The ethnicity and linguistic affiliation of these groups have been hotly debated; the time and route of the original settlement of Slavic peoples in these regions lacks written records and can only be defined as fragmented.
The most famous archaeological find from the prehistory and protohistory of Poland is the Biskupin fortified settlement (now reconstructed as an open air museum), dating from the Lusatian culture of the early Iron Age, around 700 BC. The Slavic groups who would form Poland migrated to these areas in the second half of the 5th century AD. Up until the creation of Mieszko's state and his subsequent conversion to Christianity in 966 AD, the main religion of Slavic tribes that inhabited the geographical area of present-day Poland was Slavic paganism. After the Baptism of Poland the new religion accepted by the Polish ruler was Catholicism. The transition to Christianity was not a smooth and instantaneous process for the rest of the population as evident from the pagan reaction of the 1030s.
Piast dynasty.
Poland began to form into a recognizable unitary and territorial entity around the middle of the 10th century under the Piast dynasty. Poland's first historically documented ruler, Mieszko I, accepted Baptism in 966 and adopted Christianity as the new official religion of his subjects. The bulk of the population converted in the course of the next few centuries. In 1000, Boleslaw the Brave, continuing the policy of his father Mieszko, held a Congress of Gniezno and created the metropolis of Gniezno and the dioceses of Kraków, Kołobrzeg, and Wrocław. The pagan unrest however, led to the transfer of the capital to Kraków in 1038 by Casimir I the Restorer.
Prince Bolesław III Wrymouth defeated the King of Germany Henry V in the 1109 Battle of Hundsfeld, writes Gallus Anonymus in his 1118 chronicle. In 1138, Poland fragmented into several smaller duchies when Bolesław divided his lands among his sons. In 1226, Konrad I of Masovia, one of the regional Piast dukes, invited the Teutonic Knights to help him fight the Baltic Prussian pagans; a decision which led to centuries of warfare with the Knights. Elements of what is called now human rights may be found in early times of the Polish state. The Statute of Kalisz or the General Charter of Jewish Liberties (issued in 1264) introduced numerous right for the Jews in Poland, leading to a nearly autonomous "nation within a nation".<ref name="Dembkowski/Lublin"></ref>
In the middle of 13th-century the Silesian branch of the Piast dynasty (Henry I the Bearded and Henry II the Pious, ruled 1238–1241) almost succeeded in uniting the Polish lands, but the Mongols devastated the country and won the Battle of Legnica where Duke Henry II the Pious died (1241). In 1320, after a number of earlier unsuccessful attempts by regional rulers at uniting the Polish dukedoms, Władysław I consolidated his power, took the throne and became the first King of a reunified Poland. His son, Casimir III (reigned 1333–1370), has a reputation as one of the greatest Polish kings, and gained wide recognition for improving the country's infrastructure. Casimir also extended royal protection to Jews, and encouraged their immigration to Poland.
The education of Polish society was a goal of rulers as early as the 12th century, and Polish nobility became one of the most educated groups in Europe. The library catalogue of the Cathedral Chapter of Kraków dating back to 1110 shows that in the early 12th-century Polish intellectuals had access to European literature.
Casimir III realized that the nation needed a class of educated people, especially lawyers, who could codify the country's laws and administer the courts and offices. His efforts to found an institution of higher learning in Poland were finally rewarded when Pope Urban V granted him permission to open the University of Kraków.
The Golden Liberty of the nobles began to develop under Casimir's rule, when in return for their military support, the king made serious concessions to the aristocrats, finally establishing their status as superior to that of the townsmen, and aiding their rise to power. When Casimir died in 1370 he left no legitimate male heir and, considering his other male descendants either too young or unsuitable, was laid to rest as the last of the nation's Piast rulers.
Poland also became a magnet for migrants. Germans settled in the towns; the Jewish community began to settle and flourish in Poland during this era (see History of the Jews in Poland); the same applies in smaller number to Armenians. The Black Death which afflicted most parts of Europe from 1347 to 1351 affected Poland less severely.
Jagiellon dynasty.
The rule of the Jagiellon dynasty spanned the late Middle Ages and early Modern Era of Polish history. Beginning with the Lithuanian Grand Duke Jogaila (Władysław II Jagiełło), the Jagiellon dynasty (1386–1572) formed the Polish–Lithuanian union. The partnership brought vast Lithuania-controlled Rus' areas into Poland's sphere of influence and proved beneficial for the Poles and Lithuanians, who coexisted and cooperated in one of the largest political entities in Europe for the next four centuries. In the Baltic Sea region Poland's struggle with the Teutonic Knights continued and included the Battle of Grunwald (1410), where a Polish-Lithuanian army inflicted a decisive defeat on the Teutonic Knights, both countries' main adversary, allowing Poland's and Lithuania's territorial expansion into the far north region of Livonia. In 1466, after the Thirteen Years' War, King Casimir IV Jagiellon gave royal consent to the milestone Peace of Thorn, which created the future Duchy of Prussia, a Polish vassal. The Jagiellons at one point also established dynastic control over the kingdoms of Bohemia (1471 onwards) and Hungary. In the south Poland confronted the Ottoman Empire and the Crimean Tatars (by whom they were attacked on 75 separate occasions between 1474 and 1569), and in the east helped Lithuania fight the Grand Duchy of Moscow. Some historians estimate that Crimean Tatar slave-raiding cost Poland one million of its population from 1494 to 1694.
Poland was developing as a feudal state, with a predominantly agricultural economy and an increasingly powerful landed nobility. The "Nihil novi" act adopted by the Polish Sejm (parliament) in 1505, transferred most of the legislative power from the monarch to the Sejm, an event which marked the beginning of the period known as "Golden Liberty", when the state was ruled by the "free and equal" Polish nobility. Protestant Reformation movements made deep inroads into Polish Christianity, which resulted in the establishment of policies promoting religious tolerance, unique in Europe at that time. This tolerance allowed the country to avoid most the religious turmoil that spread over Europe during the late Middle Ages. The European Renaissance evoked in late Jagiellon Poland (kings Sigismund I the Old and Sigismund II Augustus) a sense of urgency in the need to promote a cultural awakening, and during this period Polish culture and the nation's economy flourished. In 1543 the Pole, Nicolaus Copernicus, an astronomer from Toruń, published his epochal works, "De revolutionibus orbium coelestium" ("On the Revolutions of the Celestial Spheres"), and thus became the first proponent of a predictive mathematical model confirming heliocentric theory which became the accepted basic model for the practice of modern astronomy. Another major figure associated with the era is classicist poet Jan Kochanowski.
Polish–Lithuanian Commonwealth.
The 1569 Union of Lublin established the Polish–Lithuanian Commonwealth, a more closely unified federal state with an elective monarchy, but which was governed largely by the nobility, through a system of local assemblies with a central parliament. The Warsaw Confederation (1573) confirmed the religious freedom of all residents of Poland, which was extremely important for the stability of the multiethnic Polish society of the time. Serfdom was banned in 1588. The establishment of the Commonwealth coincided with a period of stability and prosperity in Poland, with the union thereafter becoming a European power and a major cultural entity, occupying approximately one million square kilometers of Central and Eastern Europe, as well as an agent for the dissemination of 'Western culture' through Polonization in modern-day Ukraine, Belarus and Western Russia. Poland suffered from a number of dynastic crises during the reigns of the Vasa kings Sigismund III and Władysław IV and found itself engaged in major conflicts with Russia, Sweden and the Ottoman Empire, as well as a series of minor Cossack uprisings. In 1610 Hetman Stanisław Żółkiewski seized Moscow after winning the Battle of Klushino.
From the middle of the 17th century, the nobles' democracy, suffering from internal disorder, gradually declined, thus leaving the once powerful Commonwealth vulnerable to foreign intervention.
From 1648, the Cossack Khmelnytsky Uprising engulfed the south and east eventually leaving Ukraine divided, with the eastern part, lost by the Commonwealth, becoming a dependency of the Tsardom of Russia. This was followed by the 'Deluge', a Swedish invasion, which marched through the Polish heartlands and damaged Poland's population, culture and infrastructure. Around four million of Poland's eleven million population died in famines and epidemics in this period.
However, under John III Sobieski the Commonwealth's military prowess was re-established, and in 1683 Polish forces played a major part in relieving Vienna of a Turkish siege which was being conducted by Kara Mustafa in hope of eventually marching his troops further into Europe to spread Islam.
Sobieski's reign marked the end of the nation's golden-era. Finding itself subjected to almost constant warfare and suffering enormous population losses as well as massive damage to its economy, the Commonwealth fell into decline. The government became ineffective as a result of large-scale internal conflicts (e.g. Lubomirski Rebellion against John II Casimir and rebellious confederations) and corrupted legislative processes. The nobility fell under the control of a handful of "magnats", and this, compounded with two relatively weak kings of the Saxon Wettin dynasty, Augustus II and Augustus III, as well as the rise of Russia and Prussia after the Great Northern War only served to worsen the Commonwealth's plight. Despite this The Commonwealth-Saxony personal union gave rise to the emergence of the Commonwealth's first reform movement, and laid the foundations for the Polish Enlightenment.
During the later part of the 18th century, the Commonwealth made attempts to implement fundamental internal reforms; with the second half of the century bringing a much improved economy, significant population growth and far-reaching progress in the areas of education, intellectual life, art, and especially toward the end of the period, evolution of the social and political system. The most populous capital city of Warsaw replaced Gdańsk (Danzig) as the leading centre of commerce, and the role of the more prosperous townsfolk increased.
The royal election of 1764 resulted in the elevation of Stanisław II August, a refined and worldly aristocrat connected to a major magnate faction, to the monarchy. However, a one-time lover of Empress Catherine II of Russia, the new king spent much of his reign torn between his desire to implement reforms necessary to save his nation, and his perceived necessity to remain in a relationship with his Russian sponsor. This led to the formation of the 1768 Bar Confederation, a "szlachta" rebellion directed against Russia and the Polish king that fought to preserve Poland's independence and the "szlachta"'s traditional privileges.
Attempts at reform provoked the union's neighbours, and in 1772 the First Partition of the Commonwealth by Russia, Austria and Prussia took place; an act which the "Partition Sejm", under considerable duress, eventually "ratified" "fait accompli". Disregarding this loss, in 1773 the king established the Commission of National Education, the first government education authority in Europe. Corporal punishment of children was officially prohibited in 1783 as first in the world at all schools.
The Great Sejm convened by Stanisław II August in 1788 successfully adopted the 3 May Constitution, the first set of modern supreme national laws in Europe. However, this document, accused by detractors of harbouring revolutionary sympathies, generated strong opposition from the Commonwealth's nobles and conservatives as well as from Catherine II, who, determined to prevent the rebirth of a strong Commonwealth set about planning the final dismemberment of the Polish-Lithuanian state. Russia was aided in achieving its goal when the Targowica Confederation, an organisation of Polish nobles, appealed to the Empress for help. In May 1792 Russian forces crossed the Commonwealth's frontier, thus beginning the Polish-Russian War.
The defensive war fought by the Poles ended prematurely when the King, convinced of the futility of resistance, capitulated and joined the Targowica Confederation. The Confederation then took over the government. Russia and Prussia, fearing the mere existence of a Polish state, arranged for, and in 1793 executed, the Second Partition of the Commonwealth, which left the country deprived of so much territory that it was practically incapable of independent existence. Eventually, in 1795, following the failed Kościuszko Uprising, the Commonwealth was partitioned one last time by all three of its more powerful neighbours, and with this, effectively ceased to exist.
The Age of Partitions.
Poles rebelled several times against the partitioners, particularly near the end of the 18th century and the beginning of the 19th century. An unsuccessful attempt at defending Poland's sovereignty took place in 1794 during the Kościuszko Uprising, where a popular and distinguished general Tadeusz Kosciuszko, who had served under Washington in America, led Polish insurgents against numerically superior Russian forces. Despite the victory at the Battle of Racławice, his ultimate defeat ended Poland's independent existence for 123 years. In 1807, Napoleon I of France temporarily recreated a Polish state as a satellite Duchy of Warsaw, but after the failed Napoleonic Wars, Poland was again split between the victorious Allies at the Congress of Vienna of 1815. The eastern part was ruled by the Russian tsar as a Congress Kingdom which possessed a very liberal constitution. However, the tsars reduced Polish freedoms, and Russia annexed the country in virtually all but name. Thus in the latter half of the 19th century, only Austrian-ruled Galicia, and particularly the Free City of Kraków, created good environment for free Polish cultural life to flourish.
Throughout the period of the partitions, political and cultural repression of the Polish nation led to the organisation of a number of uprisings against the authorities of the occupying Russian, Prussian and Austrian governments. Notable among these are the November Uprising of 1830 and January Uprising of 1863, both of which were attempts to free Poland from the rule of tsarist Russia. The November uprising began on 29 November 1830 in Warsaw when, led by Lieutenant Piotr Wysocki, young non-commissioned officers at the Imperial Russian Army's military academy in that city revolted. They were joined by large segments of Polish society, and together forced Warsaw's Russian garrison to withdraw north of the city.
Over the course of the next seven months, Polish forces successfully defeated the Russian armies of Field Marshal Hans Karl von Diebitsch and a number of other Russian commanders; however, finding themselves in a position unsupported by any other foreign powers, save distant France and the newborn United States, and with Prussia and Austria refusing to allow the import of military supplies through their territories, the Poles accepted that the uprising was doomed to failure. Upon the surrender of Warsaw to General Ivan Paskievich, many Polish troops, feeling they could not go on, withdrew into Germany and there laid down their arms. Poles would have to wait another 32 years for another opportunity to free their homeland.
When in January 1863 a new Polish uprising against Russian rule began, it did so as a spontaneous protest by young Poles against conscription into the Imperial Russian Army. However, the insurrectionists, despite being joined by high-ranking Polish-Lithuanian officers and numerous politicians, were still severely outnumbered and lacking in foreign support. They were forced to resort to guerrilla warfare tactics. They failed to win any major military victories. Afterwards no major uprising was witnessed in the Russian-controlled Congress Poland, and Poles resorted instead to fostering economic and cultural self-improvement.
Despite the political unrest experienced during the partitions, Poland did benefit from large-scale industrialisation and modernisation programs, instituted by the occupying powers, which helped it develop into a more economically coherent and viable entity. This was particularly true in the Greater Poland, Pomerania and Warmia annexed by Prussia (later becoming a part of the German Empire); an area which eventually, thanks largely to the Greater Poland Uprising, was reconstituted as a part of the Second Polish Republic and became one of its most productive regions.
Reconstitution of Poland.
During World War I, all the Allies agreed on the reconstitution of Poland that United States President Woodrow Wilson proclaimed in Point 13 of his Fourteen Points. A total of 2 million Polish troops fought with the armies of the three occupying powers, and 450,000 died. Shortly after the armistice with Germany in November 1918, Poland regained its independence as the Second Polish Republic ("II Rzeczpospolita Polska"). It reaffirmed its independence after a series of military conflicts, the most notable being the Polish–Soviet War (1919–1921) when Poland inflicted a crushing defeat on the Red Army at the Battle of Warsaw, an event which is considered to have halted the advance of Communism into Europe and forced Vladimir Lenin to rethink his objective of achieving global socialism. Nowadays the event is often referred to as the "Miracle at the Vistula".
During this period, Poland successfully managed to fuse the territories of the three former partitioning powers into a cohesive nation state. Railways were restructured to direct traffic towards Warsaw instead of the former imperial capitals, a new network of national roads was gradually built up and a major seaport was opened on the Baltic Coast, so as to allow Polish exports and imports to bypass the politically charged Free City of Danzig.
The inter-war period heralded in a new era of Polish politics. Whilst Polish political activists had faced heavy censorship in the decades up until the First World War, the country now found itself trying to establish a new political tradition. For this reason, many exiled Polish activists, such as Ignacy Paderewski (who would later become Prime Minister) returned home to help; a significant number of them then went on to take key positions in the newly formed political and governmental structures. Tragedy struck in 1922 when Gabriel Narutowicz, inaugural holder of the Presidency, was assassinated at the Zachęta Gallery in Warsaw by painter and right-wing nationalist Eligiusz Niewiadomski.
The 1926 May Coup of Józef Piłsudski turned rule of the Second Polish Republic over to the Sanacja movement. By the 1930s Poland had become increasingly authoritarian; a number of 'undesirable' political parties, such as the Polish Communists, had been banned and following Piłsudski's death, the regime, unable to appoint a new leader, began to show its inherent internal weaknesses and unwillingness to cooperate in any way with other political parties.
World War II.
The beginning of World War II was marked by the Nazi German invasion of Poland on 1 September 1939, followed by the Soviet invasion of Poland on 17 September in violation of the Soviet–Polish Non-Aggression Pact. On 28 September 1939 Warsaw capitulated. As agreed earlier in the Molotov–Ribbentrop Pact, Poland was split into two occupied zones, one subdivided by Nazi Germany, while the other, including all of eastern Kresy fell under the control of the Soviet Union. In 1939–1941, the Soviets had deported hundreds of thousands of Poles out to the most distant parts of the Soviet Union. The Soviet NKVD secretly executed thousands of Polish prisoners of war (inter alia Katyn massacre) ahead of the Operation Barbarossa.
All in all, Poland made the fourth-largest troop contribution to the Allied war effort, after the Soviets, the British, and the Americans.[a] Polish troops fought under the command of both the Polish Government in Exile in the theatre of war west of Germany and under Soviet leadership in the theatre of war east of Germany. The Polish expeditionary corps, which was controlled by the exiled pre-war government based in London, played an important role in the Italian and North African Campaigns. They are particularly well remembered for their conduct at the Battle of Monte Cassino, a conflict which culminated in the raising of a Polish flag over the ruins of the mountain-top abbey by the 12th Podolian Uhlans. The Polish forces in the theatre of war east of Germany were commanded by Lieutenant General Władysław Anders who had received his command from Prime Minister of the exiled government Władysław Sikorski. On the east of Germany, the Soviet-backed Polish 1st Army distinguished itself in the battles for Berlin and Warsaw, although its actions in support of the latter have often been criticized.
Polish servicemen were also active in the theatres of naval and air warfare; during the Battle of Britain Polish squadrons such as the No. 303 "Kościuszko" fighter squadron achieved considerable success, and by the end of the war the exiled Polish Air Forces could claim 769 confirmed kills. Meanwhile, the Polish Navy was active in the protection of convoys in the North Sea and Atlantic Ocean.
In addition to the organised units of the 1st Army and the Forces in the Nazi-occupied Europe, the domestic underground resistance movement, the Armia Krajowa, or "Home Army", fought to free Poland from German occupation and establish an independent Polish state. The wartime resistance movement in Poland was one of the three largest resistance movements of the entire war,[b] and encompassed an unusually broad range of clandestine activities, which essentially functioned as an underground state complete with degree-awarding universities and a court system. The resistance was, however, largely loyal to the exiled government and generally resented the idea of a communist Poland; for this reason, in the summer of 1944 they initiated Operation Tempest, of which the Warsaw Uprising that begun on 1 August 1944 was the best known operation. The objective of the uprising was to drive the German occupiers from the city and help with the larger fight against Germany and the Axis powers, however secondary motives for the uprising sought to see Warsaw liberated before the Soviets could reach the capital, so as to underscore Polish sovereignty by empowering the Polish Underground State before the Soviet-backed Polish Committee of National Liberation could assume control. However, a lack of available allied military aid and Stalin's reluctance to allow the 1st Army to help their fellow countrymen take the city, led to the uprising's failure and subsequent planned destruction of the city.
During the war, German forces under direct order from Adolf Hitler set up six major extermination camps, all of which operated in the heart of Poland. They included the notorious Treblinka and Auschwitz killing grounds. This allowed the Germans to transport the condemned Jews away from public eye in the Third Reich or across occupied Europe and – under the guise of resettlement – murder them in the General Government and in brand new Warthegau among other annexed areas. The Nazi crimes against the Polish nation claimed the lives of 2.7 to 2.9 million Polish Jews,<ref name="Materski/Szarota-2">Wojciech Materski, Tomasz Szarota (2009), at the Wayback Machine (archived ). "Quote:" Liczba Żydów i Polaków żydowskiego pochodzenia, obywateli II Rzeczypospolitej, zamordowanych przez Niemców sięga 2,7- 2,9 mln osób. "Translation:" The number of Jewish victims is estimated at 2,7–2,9 million. This was about 90% of the 3.3 million Jews living in prewar Poland. "Source:" IPN.</ref> and 2.77 million ethnic Poles,<ref name="Materski/Szarota">Wojciech Materski, Tomasz Szarota (2009), at the Wayback Machine (archived ). Retrieved 27 October 2014. "Quote:" Łączne straty śmiertelne ludności polskiej pod okupacją niemiecką oblicza się obecnie na ok. 2 770 000. "Translation:" Current estimate is roughly 2,770,000 victims of German occupation. This was 11.3% of the 24.4 million ethnic Poles in prewar Poland.</ref> including Polish intelligentsia, doctors, lawyers, nobility, priests and numerous others. Since 3,5 million Jews lived in pre-war Poland, Jewish victims make up the largest percentage of all victims of the Nazis' extermination program. It is estimated that, of pre-war Poland's Jewry, approximately 90% were killed. Throughout the occupation, many members of the Armia Krajowa, supported by the Polish government in exile, and millions of ordinary Poles – at great risk to themselves and their families – engaged in rescuing Jews from the Nazi Germans. Grouped by nationality, Poles represent the largest number of people who rescued Jews during the Holocaust. To date, 6,394 Poles have been awarded the title of "Righteous Among the Nations" by the State of Israel–more than any other nation. Some estimates put the number of Poles involved in rescue efforts at up to 3 million, and credit Poles with sheltering up to 450,000 Jews.
At the war's conclusion in 1945, Poland's borders were shifted westwards, resulting in considerable territorial lossess. Most of the Polish inhabitants of Kresy were expelled along the Curzon Line in accordance with Stalin's agreements. The western border was moved to the Oder-Neisse line. As a result, Poland's territory was reduced by 20%, or 77500 km2. The shift forced the migration of millions of other people, most of whom were Poles, Germans, Ukrainians, and Jews. Of all the countries involved in the war, Poland lost the highest percentage of its citizens: over 6 million perished – nearly one-fifth of Poland's population — half of them Polish Jews. Over 90% of deaths were non-military in nature. Population numbers did not recover until the 1970s. An estimated 600,000 Soviet soldiers died fighting Germans on Polish soil during World War II.
Postwar communist Poland.
At the insistence of Joseph Stalin, the Yalta Conference sanctioned the formation of a new provisional pro-Communist coalition government in Moscow, which ignored the Polish government-in-exile based in London; a move which angered many Poles who considered it a betrayal by the Allies. In 1944, Stalin had made guarantees to Churchill and Roosevelt that he would maintain Poland's sovereignty and allow democratic elections to take place. However, upon achieving victory in 1945, the elections organized by the occupying Soviet authorities were falsified and were used to provide a veneer of 'legitimacy' for Soviet hegemony over Polish affairs. The Soviet Union instituted a new communist government in Poland, analogous to much of the rest of the Eastern Bloc. As elsewhere in Communist Europe the Soviet occupation of Poland met with armed resistance from the outset which continued into the fifties.
Despite widespread objections, the new Polish government accepted the Soviet annexation of the pre-war eastern regions of Poland (in particular the cities of Wilno and Lwów) and agreed to the permanent garrisoning of Red Army units on Poland's territory. Military alignment within the Warsaw Pact throughout the Cold War came about as a direct result of this change in Poland's political culture and in the European scene came to characterise the full-fledged integration of Poland into the brotherhood of communist nations.
The People's Republic of Poland ("Polska Rzeczpospolita Ludowa") was officially proclaimed in 1952. In 1956 after the death of Bolesław Bierut, the régime of Władysław Gomułka became temporarily more liberal, freeing many people from prison and expanding some personal freedoms. A similar situation repeated itself in the 1970s under Edward Gierek, but most of the time persecution of anti-communist opposition groups persisted. Despite this, Poland was at the time considered to be one of the least oppressive states of the Soviet Bloc.
Labour turmoil in 1980 led to the formation of the independent trade union "Solidarity" ("Solidarność"), which over time became a political force. Despite persecution and imposition of martial law in 1981, it eroded the dominance of the Polish United Workers' Party and by 1989 had triumphed in Poland's first partially free and democratic parliamentary elections since the end of the Second World War. Lech Wałęsa, a Solidarity candidate, eventually won the presidency in 1990. The Solidarity movement heralded the collapse of communist regimes and parties across Europe.
Present-day Poland.
A shock therapy programme, initiated by Leszek Balcerowicz in the early 1990s enabled the country to transform its socialist-style planned economy into a market economy. As with all other post-communist countries, Poland suffered temporary slumps in social and economic standards, but it became the first post-communist country to reach its pre-1989 GDP levels, which it achieved by 1995 largely thanks to its booming economy.
Most visibly, there were numerous improvements in human rights, such as the freedom of speech, internet freedom (no censorship), civil liberties (1st class) and political rights (1st class), according to Freedom House. In 1991, Poland became a member of the Visegrád Group and joined the North Atlantic Treaty Organization (NATO) alliance in 1999 along with the Czech Republic and Hungary. Poles then voted to join the European Union in a referendum in June 2003, with Poland becoming a full member on 1 May 2004. Poland joined the Schengen Area in 2007, as a result of which, the country's borders with other member states of the European Union have been dismantled, allowing for full freedom of movement within most of the EU. In contrast to this, a section of Poland's eastern border now comprises the external EU border with Belarus, Russia and Ukraine. That border has become increasingly well protected, and has led in part to the coining of the phrase 'Fortress Europe', in reference to the seeming 'impossibility' of gaining entry to the EU for citizens of the former Soviet Union.
Poland has been one of the most prominent voices of establishing a common European Armed Forces, with Poland's Premier along with Chancellor Angela Merkel and President Francois Hollande (collectively also part of Weimar Triangle) taking steps to negotiate such a deal, in hope of drastically reducing dependence on NATO and increasing readiness. Poland has already built several commands of a common battle group with Hungary, Czech Republic and Slovakia, with a total of 12,000 troops ready for deployment. Poland is seeking to build more battle groups with Lithuania and Ukraine. These battle groups have vowed to serve under the European Union, and not NATO. Eurosceptics criticize such moves as further unnecessary integration and a new major step towards a federalized European Union under one government. Military integration is judged to be the most significant step after a monetary union.
On 10 April 2010, the President of the Republic of Poland, Lech Kaczyński, along with 89 other high-ranking Polish officials died in a plane crash near Smolensk, Russia. The president's party were on their way to attend an annual service of commemoration for the victims of the Katyń massacre when the tragedy took place.
In 2011, the Presidency of the Council of the European Union responsible for the functioning of the Council was awarded to Poland. The same year parliamentary elections took place to both the Senate and the Sejm. They were won by the ruling Civic Platform. Poland joined European Space Agency in 2012, as well as organised the UEFA Euro 2012 (along with Ukraine). In 2013, Poland also became a member of the Development Assistance Committee. In 2014 the Prime Minister of Poland, Donald Tusk, was elected President of the European Council.
Geography.
Poland's territory extends across several geographical regions, between latitudes 49° and 55° N, and longitudes 14° and 25° E. In the north-west is the Baltic seacoast, which extends from the Bay of Pomerania to the Gulf of Gdańsk. This coast is marked by several spits, coastal lakes (former bays that have been cut off from the sea), and dunes. The largely straight coastline is indented by the Szczecin Lagoon, the Bay of Puck, and the Vistula Lagoon. The centre and parts of the north lie within the North European Plain.
Rising above these lowlands is a geographical region comprising the four hilly districts of moraines and moraine-dammed lakes formed during and after the Pleistocene ice age. These lake districts are the Pomeranian Lake District, the Greater Polish Lake District, the Kashubian Lake District, and the Masurian Lake District. The Masurian Lake District is the largest of the four and covers much of north-eastern Poland. The lake districts form part of the Baltic Ridge, a series of moraine belts along the southern shore of the Baltic Sea.
South of the Northern European Lowlands lie the regions of Lusatia, Silesia and Masovia, which are marked by broad ice-age river valleys. Farther south lies the Polish mountain region, including the Sudetes, the Kraków-Częstochowa Upland, the Świętokrzyskie Mountains, and the Carpathian Mountains, including the Beskids. The highest part of the Carpathians is the Tatra Mountains, along Poland's southern border.
Geology.
The geological structure of Poland has been shaped by the continental collision of Europe and Africa over the past 60 million years and, more recently, by the Quaternary glaciations of northern Europe. Both processes shaped the Sudetes and the Carpathian Mountains. The moraine landscape of northern Poland contains soils made up mostly of sand or loam, while the ice age river valleys of the south often contain loess. The Kraków-Częstochowa Upland, the Pieniny, and the Western Tatras consist of limestone, while the High Tatras, the Beskids, and the Karkonosze are made up mainly of granite and basalts. The Polish Jura Chain is one of the oldest mountain ranges on earth.
Poland has 70 mountains over 2,000 m in elevation, all in the Tatras. The Polish Tatras, which consist of the High Tatras and the Western Tatras, is the highest mountain group of Poland and of the entire Carpathian range. In the High Tatras lies Poland's highest point, the north-western summit of Rysy, 2499 m in elevation. At its foot lies the mountain lakes of Czarny Staw pod Rysami (Black Lake below Mount Rysy), and Morskie Oko (the Marine Eye).<ref name="CIA/World">The CIA World Factbook, Retrieved 3 November 2014.</ref>
The second highest mountain group in Poland is the Beskids, whose highest peak is Babia Góra, at 1725 m. The next highest mountain groups is the Karkonosze in the Sudetes, whose highest point is Śnieżka, at 1603 m; Śnieżnik Mountains whose highest point is Śnieżnik, at 1425 m.
Tourists also frequent the Bieszczady Mountains in the far southeast of Poland, whose highest point in Poland is Tarnica, with an elevation of 1346 m, Gorce Mountains in Gorce National Park, whose highest point is Turbacz, with elevations 1310 m, and the Pieniny in Pieniny National Park, whose highest point is Wysokie Skałki (Wysoka), with elevations 1050 m. The lowest point in Poland – at 2 m below sea level – is at Raczki Elbląskie, near Elbląg in the Vistula Delta.
The only desert located in Poland stretches over the Zagłębie Dąbrowskie (the Coal Fields of Dąbrowa) region. It is called the Błędów Desert, located in the Silesian Voivodeship in southern Poland. It has a total area of 32 km2. It is one of only five natural deserts in Europe. But also, it is the warmest desert that appears at this latitude. Błędów Desert was created thousands of years ago by a melting glacier. The specific geological structure has been of big importance. The average thickness of the sand layer is about 40 m, with a maximum of 70 m, which made the fast and deep drainage very easy.
The Baltic Sea activity in Słowiński National Park created sand dunes which in the course of time separated the bay from the sea. As waves and wind carry sand inland the dunes slowly move, at a speed of 3 to meters per year. Some dunes are quite high – up to 30 m. The highest peak of the park – Rowokol (115 m above sea level) — is also an excellent observation point.
Waters.
The longest rivers are the Vistula (Polish: "Wisła"), 1047 km long; the Oder (Polish: "Odra") which forms part of Poland's western border, 854 km long; its tributary, the Warta, 808 km long; and the Bug, a tributary of the Vistula, 772 km long. The Vistula and the Oder flow into the Baltic Sea, as do numerous smaller rivers in Pomerania.
The Łyna and the Angrapa flow by way of the Pregolya to the Baltic, and the Czarna Hańcza flows into the Baltic through the Neman. While the great majority of Poland's rivers drain into the Baltic Sea, Poland's Beskids are the source of some of the upper tributaries of the Orava, which flows via the Váh and the Danube to the Black Sea. The eastern Beskids are also the source of some streams that drain through the Dniester to the Black Sea.
Poland's rivers have been used since early times for navigation. The Vikings, for example, traveled up the Vistula and the Oder in their longships. In the Middle Ages and in early modern times, when the Polish–Lithuanian Commonwealth was the breadbasket of Europe; the shipment of grain and other agricultural products down the Vistula toward Gdańsk and onward to other parts of Europe took on great importance.
With almost ten thousand closed bodies of water covering more than 1 ha each, Poland has one of the highest numbers of lakes in the world. In Europe, only Finland has a greater density of lakes. The largest lakes, covering more than 100 km2, are Lake Śniardwy and Lake Mamry in Masuria, and Lake Łebsko and Lake Drawsko in Pomerania.
In addition to the lake districts in the north (in Masuria, Pomerania, Kashubia, Lubuskie, and Greater Poland), there is also a large number of mountain lakes in the Tatras, of which the Morskie Oko is the largest in area. The lake with the greatest depth—of more than 100 m—is Lake Hańcza in the Wigry Lake District, east of Masuria in Podlaskie Voivodeship.
Among the first lakes whose shores were settled are those in the Greater Polish Lake District. The stilt house settlement of Biskupin, occupied by more than one thousand residents, was founded before the 7th century BC by people of the Lusatian culture.
Lakes have always played an important role in Polish history and continue to be of great importance to today's modern Polish society. The ancestors of today's Poles, the Polanie, built their first fortresses on islands in these lakes. The legendary Prince Popiel ruled from Kruszwica tower erected on the Lake Gopło. The first historically documented ruler of Poland, Duke Mieszko I, had his palace on an island in the Warta River in Poznań. Nowadays the Polish lakes provide a location for the pursuit of water sports such as yachting and wind-surfing.
The Polish Baltic coast is approximately 528 km long and extends from Świnoujście on the islands of Usedom and Wolin in the west to Krynica Morska on the Vistula Spit in the east. For the most part, Poland has a smooth coastline, which has been shaped by the continual movement of sand by currents and winds. This continual erosion and deposition has formed cliffs, dunes, and spits, many of which have migrated landwards to close off former lagoons, such as Łebsko Lake in Słowiński National Park.
Prior to the end of the Second World War and subsequent change in national borders, Poland had only a very small coastline; this was situated at the end of the 'Polish Corridor', the only internationally recognised Polish territory which afforded the country access to the sea. However, after World War II, the redrawing of Poland's borders and resulting 'shift' of the country's borders left it with an expanded coastline, thus allowing for far greater access to the sea than was ever previously possible. The significance of this event, and importance of it to Poland's future as a major industrialised nation, was alluded to by the 1945 Wedding to the Sea.
The largest spits are Hel Peninsula and the Vistula Spit. The largest Polish Baltic island is Wolin. The largest sea harbours are Szczecin, Świnoujście, Gdańsk, Gdynia, Police and Kołobrzeg. The main coastal resorts are Świnoujście, Międzyzdroje, Kołobrzeg, Łeba, Sopot, Władysławowo and the Hel Peninsula.
Land use.
Poland is the fourth most forested country in Europe. Forests cover about 30.5% of Poland's land area based on international standards. Its overall percentage is still increasing. Forests of Poland is managed by the national program of reforestation (KPZL), aiming at an increase of forest-cover to 33% in 2050. The richness of Polish forest (per SoEF 2011 statistics) is more than twice as high as European average (with Germany and France at the top), containing 2.304 billion cubic metres of trees. The largest forest complex in Poland is Lower Silesian Wilderness.
More than 1% of Poland's territory, 3145 km2, is protected within 23 Polish national parks. Three more national parks are projected for Masuria, the Kraków-Częstochowa Upland, and the eastern Beskids. In addition, wetlands along lakes and rivers in central Poland are legally protected, as are coastal areas in the north. There are over 120 areas designated as landscape parks, along with numerous nature reserves and other protected areas (e.g. Natura 2000).
Since Poland's accession to the European Union in 2004, Polish agriculture has performed extremely well and the country has over two million private farms. It is the leading producer in Europe of potatoes and rye (world's second largest in 1989), the world's largest producer of triticale, and one of the more important producers of barley, oats, sugar beets, flax, and fruits. It is the European Union's fourth largest supplier of pigmeat after Germany, Spain and France. The government continues debating further agricultural reform and pursuing the option of auctioning off large tracts of state-owned agricultural land.
Biodiversity.
Phytogeographically, Poland belongs to the Central European province of the Circumboreal Region within the Boreal Kingdom. According to the World Wide Fund for Nature, the territory of Poland belongs to three Palearctic Ecoregions of the continental forest spanning Central and Northern European temperate broadleaf and mixed forest ecoregions as well as the Carpathian montane conifer forest.
Many animals that have since died out in other parts of Europe still survive in Poland, such as the wisent in the ancient woodland of the Białowieża Forest and in Podlaskie. Other such species include the brown bear in Białowieża, in the Tatras, and in the Beskids, the gray wolf and the Eurasian lynx in various forests, the moose in northern Poland, and the beaver in Masuria, Pomerania, and Podlaskie.
In the forests, one also encounters game animals, such as red deer, roe deer and wild boars. In eastern Poland there are a number of ancient woodlands, like Białowieża forest, that have never been cleared by people. There are also large forested areas in the mountains, Masuria, Pomerania, Lubusz Land and Lower Silesia.
Poland is the most important breeding ground for a variety of European migratory birds. Out of all of the migratory birds who come to Europe for the summer, one quarter of the global population of White Storks (40,000 breeding pairs) live in Poland, particularly in the lake districts and the wetlands along the Biebrza, the Narew, and the Warta, which are part of nature reserves or national parks.
Climate.
The climate is mostly temperate throughout the country. The climate is oceanic in the north and west and becomes gradually warmer and continental towards the south and east. Summers are generally warm, with average temperatures between 18 and depending on a region. Winters are rather cold, with average temperatures around 3 °C in the northwest and -6 °C in the northeast. Precipitation falls throughout the year, although, especially in the east; winter is drier than summer.
The warmest region in Poland is Lower Silesia located in south-western Poland where temperatures in the summer average between 24 and but can go as high as 34 to on some days in the warmest month of July and August. The warmest cities in Poland are Tarnów, which is situated in Lesser Poland and Wrocław, which is located in Lower Silesia. The average temperatures in Wrocław are 20 °C in the summer and 0 °C in the winter, but Tarnów has the longest summer in all of Poland, which lasts for 115 days, from mid-May to mid-September. The coldest region of Poland is in the northeast in the Podlaskie Voivodeship near the border of Belarus and Lithuania. Usually the coldest city is Suwałki. The climate is affected by cold fronts which come from Scandinavia and Siberia. The average temperature in the winter in Podlaskie ranges from -6 to.
Politics.
Poland is a democracy, with a president as a head of state, whose current constitution dates from 1997. Poland is a peaceful country. The government structure centers on the Council of Ministers, led by a prime minister. The president appoints the cabinet according to the proposals of the prime minister, typically from the majority coalition in the Sejm. The president is elected by popular vote every five years. The president is Bronisław Komorowski. Komorowski replaced President Lech Kaczyński following the latter's death in an 10 April 2010 air crash. Since 2007 Polish government has been formed by the Civic Platform party. The current prime minister, Ewa Kopacz, was appointed in 2014.
Polish voters elect a bicameral parliament consisting of a 460-member lower house (Sejm) and a 100-member Senate (Senat). The Sejm is elected under proportional representation according to the d'Hondt method, a method similar to that used in many parliamentary political systems. The Senat, on the other hand, is elected under the First-past-the-post voting method, with one senator being returned from each of the 100 constituencies.
With the exception of ethnic minority parties, only candidates of political parties receiving at least 5% of the total national vote can enter the Sejm. When sitting in joint session, members of the Sejm and Senat form the National Assembly (the "Zgromadzenie Narodowe"). The National Assembly is formed on three occasions: when a new President takes the oath of office; when an indictment against the President of the Republic is brought to the State Tribunal ("Trybunał Stanu"); and when a president's permanent incapacity to exercise his duties due to the state of his health is declared. To date only the first instance has occurred.
The judicial branch plays an important role in decision-making. Its major institutions include the Supreme Court of the Republic of Poland ("Sąd Najwyższy"); the Supreme Administrative Court of the Republic of Poland ("Naczelny Sąd Administracyjny"); the Constitutional Tribunal of the Republic of Poland ("Trybunał Konstytucyjny"); and the State Tribunal of the Republic of Poland ("Trybunał Stanu"). On the approval of the Senat, the Sejm also appoints the ombudsman or the Commissioner for Civil Rights Protection ("Rzecznik Praw Obywatelskich") for a five-year term. The ombudsman has the duty of guarding the observance and implementation of the rights and liberties of Polish citizens and residents, of the law and of principles of community life and social justice.
Law.
The Constitution of Poland is the supreme law in contemporary Poland, and the Polish legal system is based on the principle of civil rights, governed by the code of Civil Law. Historically, the most famous Polish legal act is the Constitution of 3 May 1791. Historian Norman Davies describes it as the first of its kind in Europe. The Constitution was instituted as a Government Act (Polish: "Ustawa rządowa") and then adopted on 3 May 1791 by the Sejm of the Polish–Lithuanian Commonwealth. Primarily, it was designed to redress long-standing political defects of the federative Polish–Lithuanian Commonwealth and its Golden Liberty. Previously only the Henrican articles signed by each of Poland's elected kings could perform the function of a set of basic laws.
The new Constitution introduced political equality between townspeople and the nobility ("szlachta"), and placed the peasants under the protection of the government. The Constitution abolished pernicious parliamentary institutions such as the "liberum veto", which at one time had placed the sejm at the mercy of any deputy who might choose, or be bribed by an interest or foreign power, to have rescinded all the legislation that had been passed by that sejm. The 3 May Constitution sought to supplant the existing anarchy fostered by some of the country's reactionary magnates, with a more egalitarian and democratic constitutional monarchy. The adoption of was treated as a threat by Poland's neighbours. In response Prussia, Austria and Russia formed an anti-Polish alliance and over the next decade collaborated with one another to partition their weaker neighbour and destroyed the Polish state. In the words of two of its co-authors, Ignacy Potocki and Hugo Kołłątaj, the constitution represented "the last will and testament of the expiring Fatherland." Despite this, its text influenced many later democratic movements across the globe. In Poland, freedom of expression is guaranteed by the Article 25 (section I. The Republic) and Article 54 (section II. The Freedoms, Rights and Obligations of Persons and Citizens) of the Constitution of Poland.
Feminism in Poland started in 1800s in the age of the foreign Partitions. Poland's precursor of feminism, Narcyza Żmichowska, founded a group of Suffragettes in 1842. Prior to the last Partition in 1795, tax-paying females were allowed to take part in political life. Since 1918, following the return to independence, all women could vote. Poland was the 15th (12th sovereign) country to introduce universal women's suffrage. Nevertheless, there is a number of issues concerning women in modern-day Poland such as the abortion rights (formally allowed only in special circumstances) and the "glass ceiling". Homosexuality in Poland was confirmed as legal in 1932. Poland recognises gender change. A transgender Pole Anna Grodzka has become a Member of Parliament (MP) in the 2011 parliamentary elections, and is the only transgender MP in the world presently, and one of the first ever in European history. Also in 2011, Robert Biedroń was elected to the Sejm as its first openly gay member of parliament.<ref name="thenews/MP"> TheNews.pl</ref>
A 2010 article in "Rzeczpospolita" reported that in a 2008 study three-quarters of Poles were against gay marriage or the adoption of children by gay couples in accordance with the Catholic teachings. The same study revealed that 66% of respondents were opposed to Pride parade as the demonstration of a way of life, and 69% believed that gay people should not show their sexual orientation in public.<ref name="interia/Polska"></ref> Poland belongs to the group of 'Tier 1' countries in Trafficking in Persons Report. Trafficking women is 'illegal and rare' (top results worldwide).
Poland's current constitution was adopted by the National Assembly of Poland on 2 April 1997, approved by a national referendum on 25 May 1997, and came into effect on 17 October 1997. It guarantees a multi-party state, the freedoms of religion, speech and assembly, and specifically casts off many Communist ideals to create a 'free market economic system'. It requires public officials to pursue ecologically sound public policy and acknowledges the inviolability of the home, the right to form trade unions, and to strike, whilst at the same time prohibiting the practices of forced medical experimentation, torture and corporal punishment.
Foreign relations.
In recent years, Poland has extended its responsibilities and position in European and international affairs, supporting and establishing friendly relations with other European nations and a large number of 'developing' countries.
Poland is a member of the European Union, NATO, the UN, the World Trade Organization, the Organisation for Economic Co-operation and Development (OECD), European Economic Area, International Energy Agency, Council of Europe, Organization for Security and Co-operation in Europe, International Atomic Energy Agency, European Space Agency, G6, Council of the Baltic Sea States, Visegrád Group, Weimar Triangle and Schengen Agreement.
In 1994, Poland became an associate member of the European Union (EU) and its defensive arm, the Western European Union (WEU), having submitted preliminary documentation for full membership in 1996, it formally joined the European Union in May 2004, along with the other members of the Visegrád group. In 1996, Poland achieved full OECD membership, and at the 1997 Madrid Summit was invited to join the North Atlantic Treaty Organisation (NATO) in the first wave of policy enlargement finally becoming a full member of NATO in March 1999.
As changes since the fall of Communism in 1989 have redrawn the map of Europe, Poland has tried to forge strong and mutually beneficial relationships with its seven new neighbours, this has notably included signing 'friendship treaties' to replace links severed by the collapse of the Warsaw Pact. The Poles have forged special relationships with Lithuania and particularly Ukraine, with whom they co-hosted the UEFA Euro 2012 football tournament, in an effort to firmly anchor these countries within the Western world and provide them with an alternative to aligning themselves with the Russian Federation respectively. Despite many positive developments in the region, Poland has found itself in a position where it must seek to defend the rights of ethnic Poles living in the former Soviet Union; this is particularly true of Belarus, where in 2005 the Lukashenko regime launched a campaign against the Polish ethnic minority.
Poland is the sixth most populous member state of the European Union and, ever since joining in 2004, has pursued policies to increase its role in European affairs. Poland has a grand total of 51 representatives in the European Parliament. From 2009 to 2012, Jerzy Buzek, a former Prime Minister of Poland, was President of the European Parliament.
Administrative divisions.
Poland's current voivodeships (provinces) are largely based on the country's historic regions, whereas those of the past two decades (to 1998) had been centred on and named for individual cities. The new units range in area from less than 10000 km2 for Opole Voivodeship to more than 35000 km2 for Masovian Voivodeship. Administrative authority at voivodeship level is shared between a government-appointed voivode (governor), an elected regional assembly ("sejmik") and an executive elected by that assembly.
The voivodeships are subdivided into "powiats" (often referred to in English as counties), and these are further divided into "gminas" (also known as communes or municipalities). Major cities normally have the status of both "gmina" and "powiat". Poland has 16 voivodeships, 379 powiats (including 65 cities with "powiat" status), and 2,478 "gminas".
Military.
The Polish armed forces are composed of four branches: Land Forces ("Wojska Lądowe"), Navy ("Marynarka Wojenna"), Air Force ("Siły Powietrzne") and Special Forces ("Wojska Specjalne"). The military is subordinate to the Minister for National Defence, however its sole commander in chief is the President of the Republic.
The Polish army consists of 65,000 active personnel, whilst the navy and air force respectively employ 14,300 and 26,126 servicemen and women. The Polish Navy is one of the larger navies on the Baltic Sea and is mostly involved in Baltic operations such as search and rescue provision for the section of the Baltic under Polish command, as well as hydrographic measurements and research; however, the Polish Navy played a more international role as part of the 2003 invasion of Iraq, providing logistical support for the United States Navy. The current position of the Polish Air Force is much the same; it has routinely taken part in Baltic Air Policing assignments, but otherwise, with the exception of a number of units serving in Afghanistan, has seen no active combat since the end of the Second World War. In 2003, the F-16C Block 52 was chosen as the new general multi-role fighter for the air force, the first deliveries taking place in November 2006; it is expected (2010) that the Polish Air Force will create three squadrons of F-16s, which will all be fully operational by 2012.
The most important mission of the armed forces is the defence of Polish territorial integrity and Polish interests abroad. Poland's national security goal is to further integrate with NATO and European defence, economic, and political institutions through the modernisation and reorganisation of its military. The armed forces is being re-organised according to NATO standards, and as of 1 January 2010, the transition to an entirely contract-based military has been completed. During the previous period, men were obliged to undertake compulsory military service. In the final stage of validity of this type of military service (since 2007 until the amendment of the law on conscription in 2008) the duration of compulsory service amounted nine months.
Polish military doctrine reflects the same defensive nature as that of its NATO partners. From 1953 to 2009 Poland was a large contributor to various United Nations peacekeeping missions. The Polish Armed Forces took part in the 2003 invasion of Iraq, deploying 2,500 soldiers in the south of that country and commanding the 17-nation Multinational force in Iraq.
The military was temporarily, but severely, affected by the loss of many of its top commanders in the wake the 2010 Polish Air Force Tu-154 crash near Smolensk, Russia, which killed all 96 passengers and crew, including, among others, the Chief of the Polish Army's General Staff Franciszek Gągor and Polish Air Force commanding general Andrzej Błasik. They were en route from Warsaw to attend an event to mark the 70th anniversary of the Katyn massacre, whose site is commemorated approximately 19 km west of Smolensk.
Law enforcement and emergency services.
Poland has a highly developed system of law enforcement with a long history of effective policing by the State Police Service. The structure of law enforcement agencies within Poland is a multi-tier one, with the State Police providing criminal-investigative services, Municipal Police serving to maintain public order and a number of other specialised agencies, such as the Polish Border Guard, acting to fulfil their assigned missions. In addition to these state services, private security companies are also common, although they possess no powers assigned to state agencies, such as, for example, the power to make an arrest or detain a suspect.
Emergency services in Poland consist of the Emergency Medical Services, Search and Rescue units of the Polish Armed Forces and State Fire Service. Emergency medical services in Poland are, unlike other services, provided for by local and regional government.
Since joining the European Union all of Poland's emergency services have been undergoing major restructuring and have, in the process, acquired large amounts of new equipment and staff. All emergency services personnel are now uniformed and can be easily recognised thanks to a number of innovative design features, such as reflective paint and printing, present throughout their service dress and vehicle liveries. In addition to this, in an effort to comply with EU standards and safety regulations, the police and other agencies have been steadily replacing and modernising their fleets of vehicles; this has left them with thousands of new automobiles, as well as many new aircraft, boats and helicopters.
Economy.
Poland's high-income economy is considered to be one of the healthiest of the post-Communist countries and is one of the fastest growing within the EU. Having a strong domestic market, low private debt, flexible currency, and not being dependent on a single export sector, Poland is the only European economy to have avoided the late-2000s recession. Since the fall of the communist government, Poland has pursued a policy of liberalising the economy. It is an example of the transition from a centrally planned to a primarily market-based economy. In 2009 Poland had the highest GDP growth in the EU - 1.6%. The country's most successful exports include machinery, furniture, foods and meats, motor boats, light planes, hardwood products, casual clothing, shoes and cosmetics. Germany is by far the biggest importer of Poland's exports as of 2013.
The privatization of small and medium state-owned companies and a liberal law on establishing new firms have allowed the development of the private sector. As a consequence, consumer rights organizations have also appeared. Restructuring and privatisation of "sensitive sectors" such as coal, steel, rail transport and energy has been continuing since 1990. Between 2007 and 2010, the government plans to float twenty public companies on the Warsaw Stock Exchange, including parts of the coal industry. The biggest privatisations have been the sale of the national telecoms firm Telekomunikacja Polska to France Télécom in 2000, and an issue of 30% of the shares in Poland's largest bank, PKO Bank Polski, on the Polish stockmarket in 2004.
The Polish banking market is the largest in East Central and Eastern European region, with 32.3 branches per 100,000 adults.<ref name="datatopics/poland">World Bank, The World Bank Group. Retrieved 6 November 2014.</ref> The banks are the largest and most developed sector of the country's financial markets. They are regulated by the Polish Financial Supervision Authority. During the transformation to a market-oriented economy, the government privatized some of them, recapitalized the rest, and introduced legal reforms that made the sector competitive. This has attracted a significant number of strategic foreign investors (ICFI). Poland's banking sector has approximately 5 national banks, a network of nearly 600 cooperative banks and 18 branches of foreign-owned banks. In addition, foreign investors have controlling stakes in nearly 40 commercial banks, which make up 68% of the banking capital.
Poland has a large number of private farms in its agricultural sector, with the potential to become a leading producer of food in the European Union. The biggest money-makers abroad include smoked and fresh fish, fine chocolate, and dairy products, meats and specialty breads, with the exchange rate conducive to export growth. Food exports amounted to 62 billion zloty in 2011, increasing by 17% from 2010. Structural reforms in health care, education, the pension system, and state administration have resulted in larger-than-expected fiscal pressures. Warsaw leads Central Europe in foreign investment. GDP growth had been strong and steady from 1993 to 2000 with only a short slowdown from 2001 to 2002.
The economy had growth of 3.7% annually in 2003, a rise from 1.4% annually in 2002. In 2004, GDP growth equaled 5.4%, in 2005 3.3% and in 2006 6.2%. According to Eurostat data, Polish PPS GDP per capita stood at 67% of the EU average in 2012.
In terms of the clarity, efficiency and neutrality of Poland's legal framework for multinational investors, a 2012 report by the World Economic Forum concluded that the ongoing foreign business disputes may "have damaged Poland's reputation as an attractive location for FDI" from other countries by creating the impression of "substandard reputation for maintaining an efficient and neutral framework to settle business disputes." Ernst and Young's 2010 European attractiveness survey reported that Poland saw a 52% decrease in FDI foreign job creation and a 42% decrease in number of FDI projects since 2008.
Average salaries in the enterprise sector in December 2010 were 3,848 PLN (1,012 euro or 1,374 US dollars) and growing sharply. Salaries vary between the regions: the median wage in the capital city Warsaw was 4,603 PLN (1,177 euro or 1,680 US dollars) while in Kielce it was 3,083 PLN (788 euro or 1125 US dollars). There is a wide distribution of salaries among the various districts of Poland. They range from 2,020 PLN (517 euro or 737 US dollars) in Kępno County, which is located in Greater Poland Voivodeship to 5,616 (1,436 euro or 2,050 US dollars) in Lubin County, which lies in Lower Silesian Voivodeship.
According to a Credit Suisse report, Poles are the second wealthiest (after Czechs) of the Central European peoples. Even though since World War II Poland is almost an ethnically homogeneous country, the number of foreign investors among immigrants is growing every year.
Since the opening of the labor market in the European Union, Poland experienced a mass emigration of over 2.3 million abroad, mainly due to higher wages offered abroad, and due to the raise in levels of unemployment following the global Great Recession of 2008. The out migration has increased the average wages for the workers who remained in Poland, in particular for those with intermediate level skills.
Commodities produced in Poland include: electronics, cars (Arrinera, Leopard), buses (Solaris, Solbus), helicopters (PZL Świdnik), transport equipment, locomotives, planes (PZL Mielec), ships, military engineering (including tanks, SPAAG systems), medicines (Polpharma, Polfa), food, clothes, glass, pottery (Bolesławiec), chemical products and others.
Corporations.
Poland is recognised as a regional economic power within East-Central Europe, with nearly 40 percent of the 500 biggest companies in the region (by revenues) as well as a high globalisation rate. Poland was the only member of the EU to avoid the recession of the late 2000s, a testament to the Polish economy's stability. The country's most competitive firms are components of the WIG30 which is traded on the Warsaw Stock Exchange.
Well known Polish brands include, among others, PKO BP, PKN Orlen, PGE, PZU, PGNiG, Tauron Group, Lotos Group, KGHM Polska Miedź, Asseco, Plus, Play, PLL LOT, Poczta Polska, PKP, Biedronka, and TVP.
Poland is recognised as having an economy with development potential, overtaking the Netherlands in mid-2010 to become Europe's sixth largest economy. Foreign Direct Investment in Poland has remained steady ever since the country's re-democratisation following the Round Table Agreement in 1989. However, problems still exist. It is believed that progress of privatization was uneven across sectors due to emergence of interest groups supporting government's push for the reforms based on "feasibility" rather than "efficiency", at the cost of Poland's remaining sectors in need of development and modernisation, such as the extractive industries.
The list includes the largest companies by turnover in 2011, but does not include major banks or insurance companies:
Tourism.
Poland experienced an increase in the number of tourists after joining the European Union. Tourism contributes significantly to Poland's overall economy and makes up a relatively large proportion of the country's service market.<ref name="unwto.org/en/press-release"></ref>
Kraków was the former capital and a relic of Poland's Golden Age of Renaissance. It contains the place of coronation of most Polish kings. It was named a European Capital of Culture by the European Union for the year 2000. The city of Wrocław, designated as a European Capital of Culture in 2016, is one of the oldest in Poland. During World War II, Wrocław was a fortress (Festung Breslau), and was heavily damaged in the nearly three months long Battle of Breslau. The city has been restored and attracts several million tourists every year. The Old Town of Poland's capital, Warsaw, was reconstructed after its wartime destruction and it offers a variety of attractions. Other cities attracting tourists include Gdańsk, Poznań, Szczecin, Lublin and Toruń. The historic site of the Nazi-German Auschwitz concentration camp is near Oświęcim.
Poland's main tourist offerings include outdoor activities such as skiing, sailing and mountain hiking, as well as agrotourism, sightseeing walks, countryside excursions and also holiday and business trips. Poland is the 17th most visited country in the world by foreign tourists, as ranked by World Tourism Organization (UNWTO) in 2012. Tourist destinations include the Baltic Sea coast in the north, the Masurian Lake District and Białowieża Forest in the east, the northern Karkonosze, the Table Mountains and the Tatra Mountains, where Rysy, the highest peak of Poland, and the famous Orla Perć long-distance path are located. The Pieniny and Bieszczady Mountains lie in the extreme south-east. There are over 100 castles in the country, many along the popular Trail of the Eagles' Nests.
Energy.
The electricity generation sector in Poland is largely fossil-fuel–based. Many power plants nationwide use Poland's position as a major European exporter of coal to their advantage by continuing to use coal as the primary raw material in production of their energy. In 2013 Poland scored 48 out of 129 states in the Energy Sustainability Index. The three largest Polish coal mining firms (Węglokoks, Kompania Węglowa and JSW) extract around 100 million tonnes of coal annually. All three of these companies are key constituents of the Warsaw Stock Exchange's lead economic indexes.
Renewable forms of energy account for a small proportion of Poland's full energy generation capacity. However, the national government has set targets for the development of renewable energy sources in Poland which should see the portion of power produced by renewable resources climb to 7.5% by 2010 and 15% by 2020. This is to be achieved mainly through the construction of wind farms and a number of hydroelectric stations.
Poland is thought to have around 164,800,000,000 m³ of proven natural gas reserves and around 96,380,000 barrels of proven oil reserves. These reserves are exploited by energy supply companies such as PKN Orlen ("the only Polish company listed in the Fortune Global 500"). However, the small amounts of fossil fuels naturally occurring in Poland is insufficient to satisfy the full energy consumption needs of the population. Therefore the country is a net importer of oil and natural gas.
Transport.
Transport in Poland is provided by means of rail, road, marine shipping and air travel. Positioned in Central Europe with its eastern and part of its northeastern border constituting the longest land border of the Schengen Area with the rest of Northern and Central Europe, Poland has long been and remains a key country through which imports to the European Union and exports from it pass.
Since joining the EU in May 2004, Poland has invested large amounts of money into the modernisation of its transport networks. The country now has a developing expressway network composed of motorways such as the A1, A2, A4, A8, A18 and express roads such as the S1, S3, S5, S7, S8. In addition to these newly built roads, many local and regional roads are being rebuilt as part of a national programme to rebuild all roads in Poland.
Polish authorities maintain a program of improving operating speeds across the entire Polish rail network. Polish State Railways (PKP) are using new rolling stock such as Siemens Taurus ES64U4, which is in principle capable of speeds up to 200 km/h. In December 2014, Poland began to implement high–speed rail routes connecting major Polish cities. The Polish government has revealed that it intends to connect all major cities to a future high-speed rail network by 2020. The new PKP Pendolino ETR 610 test train set the record for the fastest train in the history of Poland, reaching 293 km/h on 24 November 2013. Previously, the speed record had been 160 km/h since 1985. Most intercity rail routes in Poland are operated by PKP Intercity, whilst regional trains are run by a number of operators, the largest of which is Przewozy Regionalne.
On 14 December 2014, Polish State Railways started passenger service using the PKP Pendolino ED250, operating at 200 km/h speed on 80 km of line between Olszamowice and Zawiercie (part of the Central Rail Line from Warsaw to Kraków). Currently it is the line with highest railway speed in Poland. Poland is the first country from the 2004 enlargement of the European Union which offers passenger rail services with scheduled speeds exceeding 160 km/h.
The air and maritime transport markets in Poland are largely well developed. Poland has a number of international airports, the largest of which is Warsaw Chopin Airport, the primary global hub for LOT Polish Airlines. LOT is the 28th largest European airline and the world's 12th oldest still in operation, established in 1929 from a merger of Aerolloyd (1922) and Aero (1925). Major airports with international connections exist in almost every region, for example John Paul II International Airport Kraków–Balice and Wrocław–Copernicus Airport.
Seaports exist all along Poland's Baltic coast, with most freight operations using Szczecin, Świnoujście, Gdynia and Gdańsk as well as Police, Kołobrzeg and Elbląg as their base. Passenger ferries link Poland with Scandinavia all year round; these services are provided from Gdańsk and Świnoujście by Polferries, Stena Line from Gdynia and Unity Line from the Port of Świnoujście.
Science and technology.
According to Frost & Sullivan's Country Industry Forecast the country is becoming an interesting location for research and development investments. Multinational companies such as: ABB, Delphi, GlaxoSmithKline, Google, Hewlett–Packard, IBM, Intel, LG Electronics, Microsoft, Motorola, Siemens and Samsung have set up research and development centres in Poland. Over 40 research and development centers and 4,500 researchers make Poland the biggest research and development hub in Central and Eastern Europe. Companies chose Poland because of the availability of highly qualified labour force, presence of universities, support of authorities, and the largest market in East-Central Europe.
Today Poland's tertiary education institutions; traditional universities (found in its major cities), as well as technical, medical, and economic institutions, employ around 61,000 researchers and members of staff. There are around 300 research and development institutes, with about 10,000 researchers. In total, there are around 91,000 scientists in Poland today. However, in the 19th and 20th centuries many Polish scientists worked abroad; one of the most important of these exiles was Maria Skłodowska-Curie, a physicist and chemist who lived much of her life in France. In the first half of the 20th century, Poland was a flourishing centre of mathematics. Outstanding Polish mathematicians formed the Lwów School of Mathematics (with Stefan Banach, Hugo Steinhaus, Stanisław Ulam) and Warsaw School of Mathematics (with Alfred Tarski, Kazimierz Kuratowski, Wacław Sierpiński). The events of World War II pushed many of them into exile. Such was the case of Benoît Mandelbrot, whose family left Poland when he was still a child. An alumnus of the Warsaw School of Mathematics was Antoni Zygmund, one of the shapers of 20th-century mathematical analysis.
According to a KPMG report 80% of Poland's current investors are content with their choice and willing to reinvest. In 2006, Intel decided to double the number of employees in its research and development centre in Gdańsk.
Communications.
The share of the telecom sector in the GDP is 4.4% (end of 2000 figure), compared to 2.5% in 1996. The coverage increased from 78 users per 1,000 inhabitants in 1989 to 282 in 2000. The value of the telecommunication market is zl 38.2bn (2006), and it grew by 12.4% in 2007 PMR. The coverage mobile cellular is over 1000 users per 1000 people (2007). Telephones—mobile cellular: 38.7 million (Onet.pl & GUS Report, 2007), telephones—main lines in use: 12.5 million (Telecom Team Report, 2005).
With regard to internet access, the most popular ADSL services for home users in Poland are Neostrada provided by TPSA, and Net24 provided by Netia. Business users as well as some home users use Internet DSL TP also offered by TPSA. According to Eurostat, OECD and others, Internet access in Poland is amidst the most expensive in Europe. This is mostly caused by the lack of competitiveness. New operators, such as Dialog and GTS Energis are making their own provider lines and offer more attractive and cheaper service. The Polish Office of Electronical Communication is forcing the TPSA to rent 51% of their ADSL lines to other ISPs for 60% lower prices. This move will affect the prices of DSL in Poland. In 2012, the process of converting to Digital terrestrial television started, to be compatible with the rest of Europe.
The public postal service in Poland is operated by "Poczta Polska" (the Polish Post). It was created on 18 October 1558, when King Zygmunt August established a permanent postal route from Kraków to Venice. The service was dissolved during the foreign partitions. After regaining independence in 1918, Poland saw the rapid development of the postal system as new services were introduced including money transfers, payment of pensions, delivery of magazines, and air mail. During wars and national uprisings communication was provided mainly through the military authorities. Many important events in the history of Poland involved the postal service, like the heroic defence of the Polish Post Office in Gdańsk in 1939, and the participation of the Polish Scouts' Postal Service in the Warsaw Uprising. Nowadays the service is a modern state-owned company that provides a number of standard and express delivery as well as home-delivery services. Digital technologies are made available through the Internet platform "Envelo".
Demographics.
Poland, with 38,544,513 inhabitants, has the eighth-largest population in Europe and the sixth-largest in the European Union. It has a population density of 122 inhabitants per square kilometer (328 per square mile).
Poland historically contained many languages, cultures and religions on its soil. The country had a particularly large Jewish population prior to World War II, when the Nazi Germany's regime led to The Holocaust. There were an estimated 3 million Jews before the war; 300,000 after. The outcome of the war, particularly the shift of Poland's borders to the area between the Curzon Line and the Oder-Neisse line, coupled with post-war expulsion of minorities, significantly reduced the country's ethnic diversity. Over 7 million Germans fled or were expelled from the Polish side of the Oder-Neisse boundary.
According to the 2002 census, 36,983,700 people, or 96.74% of the population, consider themselves Polish, while 471,500 (1.23%) declared another nationality, and 774,900 (2.03%) did not declare any nationality. The largest minority nationalities and ethnic groups in Poland are Silesians (173,153 according to the census), Germans (152,897 according to the census, 92% of whom live in Opole Voivodeship and Silesian Voivodeship), Belarusians (c. 49,000), Ukrainians (c. 30,000), Lithuanians, Russians, Roma, Jews, Lemkos, Slovaks, Czechs, and Lipka Tatars. Among foreign citizens, the Vietnamese are the largest ethnic group, followed by Greeks and Armenians.
The Polish language, part of the West Slavic branch of the Slavic languages, functions as the official language of Poland. Until recent decades Russian was commonly learned as a second language but has been replaced by English and German as the most common second languages studied and spoken.
In recent years, Poland's population has decreased due to an increase in emigration and a sharp decline in the birth rate. Since Poland's accession to the European Union, a significant number of Poles have emigrated, primarily to the United Kingdom, Germany and Republic of Ireland in search of better work opportunities abroad.
Polish minorities are still present in the neighboring countries of Ukraine, Belarus, and Lithuania, as well as in other countries (see Poles for population numbers). Altogether, the number of ethnic Poles living abroad is estimated to be around 20 million. The largest number of Poles outside of Poland can be found in the United States.
The total fertility rate (TFR) in Poland was estimated in 2013 at 1.32 children born/woman, which is below the replacement rate of 2.1.
Languages.
Polish.
Polish ("język polski", "polszczyzna") is a Slavic language spoken primarily in Poland and the native language of the Poles. It belongs to the Lechitic subgroup of West Slavic languages. Polish is the official language of Poland, but it is also used throughout the world by Polish minorities in other countries. It is one of the official languages of the European Union. Its written standard is the Polish alphabet, which has 9 additions to the letters of the basic Latin script ("ą", "ć", "ę", "ł", "ń", "ó", "ś", "ź", "ż").
Sign language.
The deaf communities use Polish Sign Language belonging to the German family of Sign Languages.
Minority languages.
According to the Act of 6 January 2005 on national and ethnic minorities and on the regional languages, 16 other languages have officially recognized status of minority languages: 1 regional language, 10 languages of 9 national minorities (the minorities that have their own independent state elsewhere) and 5 languages of 4 ethnic minorities spoken by the members of minorities not having a separate state elsewhere). Jewish and Romani minorities each have 2 minority languages recognized.
Languages having the status of ethnic minority's language.
The official recognition gives to the representatives of the minority certain rights (under certain conditions prescribed by the laws): of education in their language, of having the language established as the secondary administrative language or help language in their municipalities, of financial support of the state to the promotion of their language and culture etc.
Religion.
Religion in Poland according to 2011 survey of 91,2% of citizens 
   Roman Catholic
 (87.5%)  Opting out of answer (7.1%)  Non believer (2.4%)  Not stated (1.6%)   Orthodox
 (0.7%)  Other religions (1%)
From its beginnings, Poland has contributed substantially to the development of religious freedom. Since the country adopted Christianity in 966, it was also welcoming to other religions through a series of laws: Statute of Kalisz (1264), Warsaw Confederation (1573). However, the Polish king Władysław II Jagiełło was pressed by the Catholic Church to issue the Edict of Wieluń (1424), outlawing early Protestant Hussitism. Polish theological thought include theological movements, such as Calvinist Polish Brethren and a number of other Protestant groups, as well as atheists, such as ex-Jesuit philosopher Kazimierz Łyszczyński, one of the first atheist thinkers in Europe.
Until World War II Poland was a religiously diverse society, in which substantial Jewish, Christian Orthodox, Protestant and Roman Catholic groups coexisted. In the Second Polish Republic, Roman Catholic was the dominant religion, declared by about 65% of the Polish citizens, followed by other Christian denominations, and about 3% of Judaism believers. As a result of the Holocaust and the post–World War II flight and expulsion of German and Ukrainian populations, Poland has become overwhelmingly Roman Catholic. In 2007, 88.4% of the population belonged to the Catholic Church. Though rates of religious observance are lower, at 52% or 51% of the Polish Catholics, Poland remains one of the most devoutly religious countries in Europe.
From 16 October 1978 until his death on 2 April 2005 Karol Józef Wojtyła (later Pope John Paul II), a Polish native, reigned as Supreme Pontiff of the Roman Catholic Church. He has been the only Slavic and Polish Pope to date, and was the first non-Italian Pope since Dutch Pope Adrian VI in 1522. Additionally he is credited with having played a significant role in hastening the downfall of communism in Poland and throughout Central and Eastern Europe; he is famously quoted as having, at the height of communism in 1979, told Poles "not be afraid", later praying: "Let your Spirit descend and change the image of the land... this land".
Religious minorities include Polish Orthodox (about 506,800), various Protestants (about 150,000), Jehovah's Witnesses (126,827), Eastern Catholics, Mariavites, Polish Catholics, Jews, and Muslims (including the Tatars of Białystok). Members of Protestant churches include about 77,500 in the largest Evangelical-Augsburg Church, and a similar number in smaller Pentecostal and Evangelical churches. There are also a few thousand pagans some of whom are members of such officially registered churches as the Native Polish Church, (Rodzimy Kościół Polski).
Freedom of religion is now guaranteed by the 1989 statute of the Polish Constitution, enabling the emergence of additional denominations. The Concordat between the Holy See and Poland guarantees the teaching of religion in state schools. According to a 2007 survey, 72% of respondents were not opposed to religious instruction in public schools; alternative courses in ethics are available only in one percent of the entire public educational system.
Famous sites of Christian pilgrimage in Poland include the Monastery of Jasna Góra in the southern Polish city of Częstochowa, as well as the Family home of John Paul II in Wadowice just outside of Kraków.
Health.
Poland's healthcare system is based on an all-inclusive insurance system. State subsidised healthcare is available to all Polish citizens who are covered by this general health insurance program. However, it is not compulsory to be treated in a state-run hospital as a number of private medical complexes do exist nationwide.
All medical service providers and hospitals in Poland are subordinate to the Polish Ministry of Health, which provides oversight and scrutiny of general medical practice as well as being responsible for the day-to-day administration of the healthcare system. In addition to these roles, the ministry is also tasked with the maintenance of standards of hygiene and patient-care.
Hospitals in Poland are organised according to the regional administrative structure, resultantly most towns have their own hospital "(Szpital Miejski)". Larger and more specialised medical complexes tend only to be found in larger cities, with some even more specialised units located only in the capital, Warsaw. However, all voivodeships have their own general hospital (most have more than one), all of which are obliged to have a trauma centre; these types of hospital, which are able to deal with almost all medical problems are called 'regional hospitals' "(Szpital Wojewódzki)". The last category of hospital in Poland is that of specialised medical centres, an example of which would be the Skłodowska-Curie Institute of Oncology, Poland's leading, and most highly specialised centre for the research and treatment of cancer.
In 2012, the Polish health-care industry experienced a transformation. Hospitals were given priority for refurbishment where necessary. As a result of this process, many hospitals were updated with the latest medical equipment.
In 2013, the average life expectancy at birth was 76.45 years
(72.53 years infant male/80.62 years infant female).
Education.
The Commission of National Education ("Komisja Edukacji Narodowej") established in 1773, was the world's first state ministry of education. The education of Polish society was a goal of rulers as early as the 12th century. Poland became one of the most educated countries in Europe. The library catalogue of the Cathedral Chapter of Kraków dating back to 1110 shows that in the early 12th-century Polish intellectuals had access to European literature. The Jagiellonian University, founded in 1364 by King Casimir III in Kraków was blessed by Pope Urban V. It is the world's 19th oldest university.
The modern-day Programme for International Student Assessment, coordinated by the Organisation for Economic Co-operation and Development, ranks Poland's educational system in its PISA 2012 as the 10th best in the world, scoring higher than the OECD average.
Elementary and secondary.
Education in Poland starts at the age of five or six (with the particular age chosen by the parents) for the '0' class (Kindergarten) and six or seven years in the 1st class of primary school (Polish "szkoła podstawowa"). It is compulsory that children participate in one year of formal education before entering the 1st class at no later than 7 years of age. Corporal punishment of children in schools is officially prohibited since 1783 (before the partitions) and criminalised since 2010 (in schools as well as at home).
At the end of the 6th class when students are 13, students take a compulsory exam that will determine their acceptance and transition into a specific lower secondary school ("gimnazjum, pronounced gheem-nah-sium") (Middle School/Junior High). They will attend this school for three years during classes 7, 8, and 9. Students then take another compulsory exam to determine the upper secondary level school they will attend. There are several alternatives, the most common being the three years in a "liceum" or four years in a technikum. Both end with a maturity examination (matura, quite similar to French baccalauréat), and may be followed by several forms of upper education, leading to licencjat or inżynier (the Polish Bologna Process first cycle qualification), magister (second cycle qualification) and eventually doktor (third cycle qualification).
Higher education.
There are 500 university-level institutions for the pursuit of higher education in Poland, one of the largest number in Europe. The Jagiellonian University in Kraków, the first Polish university, was founded in 1364 by King Casimir III, as the 19th oldest university in the world, established in 1364.
There are 18 fully accredited traditional universities in Poland. There are twenty technical universities, nine independent medical universities, five universities for the study of economics, nine agricultural academies, three pedagogical universities, a theological academy and three maritime service universities.
There are a number of higher educational institutions dedicated to the teaching of the arts. Amongst these are the seven higher state academies of music. There are a number of private educational institutions and four national military academies (two for the army and one each for the other branches of service).
Culture.
The culture of Poland is closely connected with its intricate 1,000-year history Its unique character developed as a result of its geography at the confluence of European cultures. With origins in the culture of the Proto-Slavs, over time Polish culture has been profoundly influenced by its interweaving ties with the Germanic, Latinate and Byzantine worlds as well as in continual dialog with the many other ethnic groups and minorities living in Poland. The people of Poland have traditionally been seen as hospitable to artists from abroad and eager to follow cultural and artistic trends popular in other countries. In the 19th and 20th centuries the Polish focus on cultural advancement often took precedence over political and economic activity. These factors have contributed to the versatile nature of Polish art, with all its complex nuances.
Famous people.
The list of famous Poles begins in earnest with the polymath Mikołaj Kopernik, who studied at the Jagiellonian University founded in 1364 by Casimir the Great from proceeds of his Wieliczka Salt Mine. Poland is the birthplace of many distinguished personalities among whom are: Fryderyk Chopin, Maria Skłodowska Curie, Tadeusz Kościuszko, Kazimierz Pułaski, Józef Piłsudski, Lech Wałęsa and Pope John Paul II (Karol Wojtyła). Great Polish painter Jan Matejko devoted his monumental art to the most significant historical events on Polish lands, along with the playwright, painter and poet Stanisław Wyspiański. Stanisław Ignacy Witkiewicz (Witkacy) was an example of a Polish avant-garde philosopher and author of aesthetic theories. Polish Joseph Conrad was a notable author of works in English. Many world famous Polish movie directors include Academy Awards winners Roman Polański, Andrzej Wajda, Zbigniew Rybczyński, Janusz Kamiński, Krzysztof Kieślowski, and Agnieszka Holland. Actresses known outside of Poland, include Helena Modjeska and Pola Negri.
Society.
Poland has a long-standing tradition of tolerance towards minorities, as well as an absence of discrimination on the grounds of religion, nationality or race.
Prior to World War II, ethnic minorities made up a significant proportion of the Polish population. Poland has maintained a high level of gender equality, an established disability rights movement and promotes peaceful equality.
Poland was the first country in the world to prohibit corporal punishment in all its forms. Poland has, throughout most of its long history, experienced only very limited immigration from abroad; this trend can be largely attributed to Poland's rejection of slavery and to a lack of overseas colonies as well as occupation of its territories during much of the 19th and early 20th centuries. Despite this, the country has for a long time been regarded as having a very tolerant society, which affords equal rights to all people no matter what their ethnic background. This can be said to stem largely from the reign of King Casimir III the Great and his acceptance for Poland's Jewish community, in a time when most of Europe recessed into antisemitic moods and actions. The history of Jews in Poland exemplifies peaceful co-existence of a nation with a particular ethnic group.
Today, as many as 96.7% of Polish citizens declare to be Poles, and 97.8% declare that they speak Polish at home (Census 2002). The population of Poland became one of the most ethnically homogeneous in the world as a result of the radically altered borders after World War II and the subsequent migrations. This homogeneity is a result of post World War II deportations ordered by the Soviet authorities, who wished to remove the sizeable Polish minorities from Lithuania, Belarus and Ukraine and repatriation of Ukrainians from Poland to the Soviet Union (see territorial changes of Poland and historical demography of Poland for details). Unlike in many other countries, the ethnic minority rights in Poland are guaranteed directly by the Constitution of Poland (art. 35), and today there are, among others, sizeable German, Ukrainian and Belarusian minorities in the country.
In 2013, the Polish parliament rejected proposed legislation for civil partnerships, which the majority of Polish society is against, but for the first time it gave an asylum to a gay person from Uganda on the basis of the sexual orientation. In a 2013 opinion poll conducted by CBOS, 60% of Poles were against homosexual civil partnerships, 72% were against same-sex marriage, 88% were against adoption by same-sex couples, and 68% were against gays and lesbians publicly showing their way of life. Article 18 of the Constitution of Poland bans same-sex marriage.
The results of an Organization for Security and Co-operation in Europe (OSCE) survey from 2004 showed that Poles worked the second most hours per week of any nationality worldwide. Poland remains one of the most peaceful countries in the world.
Music.
Artists from Poland, including famous composers like Chopin or Penderecki and traditional, regionalized folk musicians, create a lively and diverse music scene, which even recognizes its own music genres, such as poezja śpiewana and disco polo. As of 2006, Poland is one of the few countries in Europe where rock and hip hop dominate over pop music, while all kinds of alternative music genres are encouraged.
The origins of Polish music can be traced as far back as the 13th century; manuscripts have been found in Stary Sącz, containing polyphonic compositions related to the Parisian Notre Dame School. Other early compositions, such as the melody of "Bogurodzica" and "Bóg się rodzi" (a coronation polonaise for Polish kings by an unknown composer), may also date back to this period, however, the first known notable composer, Mikołaj z Radomia, was born and lived in the 15th century. During the 16th century, two main musical groups – both based in Kraków and belonging to the King and Archbishop of the Wawel – led to the rapid development of Polish music. Composers writing during this period include Wacław z Szamotuł, Mikołaj Zieleński, and Mikołaj Gomółka. Diomedes Cato, a native-born Italian who lived in Kraków from about the age of five, became a renown lutenists at the court of Sigismund III, and not only imported some of the musical styles from southern Europe, but blended them with native folk music.
At the end of the 18th century, Polish classical music evolved into national forms like the polonaise. In the 19th century the most popular composers were: Józef Elsner and his pupils Fryderyk Chopin and Ignacy Dobrzyński. Important opera composers of the era were Karol Kurpiński and Stanisław Moniuszko whilst the list of famous soloists and composers included Henryk Wieniawski, Juliusz Zarębski. At the turn of the 19th and 20th centuries the most prominent composers could said to have been Władysław Zeleński and Mieczysław Karłowicz, with Karol Szymanowski gaining prominence prior to World War II. Alexandre Tansman lived in Paris but had strong connections with Poland. Witold Lutosławski, Henryk Górecki, and Krzysztof Penderecki composed in Poland, Andrzej Panufnik emigrated.
Traditional Polish folk music has had a major effect on the works of many well-known Polish composers, and no more so than on Fryderyk Chopin, a widely recognised national hero of the arts. All of Chopin's works involve the piano and are technically demanding, emphasising nuance and expressive depth. As a great composer, Chopin invented the musical form known as the instrumental ballade and made major innovations to the piano sonata, mazurka, waltz, nocturne, polonaise, étude, impromptu and prélude, he was also the composer of a number of polonaises which borrowed heavily from traditional Polish folk music. It is largely thanks to him that the such pieces gained great popularity throughout Europe during the 19th century. Nowadays the most distinctive folk music can be heard in the towns and villages of the mountainous south, particularly in the region surrounding the winter resort town of Zakopane.
Today Poland has a very active music scene, with the jazz and metal genres being particularly popular among the contemporary populace. Polish jazz musicians such as Krzysztof Komeda, created a unique style, which was most famous in 1960s and 1970s and continues to be popular to this day. Since the fall of Communism, Poland has become a major venue for large-scale music festivals, chief among which are the Open'er Festival, Opole Festival and Sopot Festival.
Visual arts.
Polish art has always reflected European trends while maintaining its unique character. The Kraków school of Historicist painting developed by Jan Matejko produced monumental portrayals of customs and significant events in Polish history. Stanisław Witkiewicz was an ardent supporter of Realism in Polish art, its main representative being Jozef Chełmoński. The Młoda Polska (Young Poland) movement witnessed the birth of modern Polish art, and engaged in a great deal of formal experimentation led by Jacek Malczewski (Symbolism), Stanisław Wyspiański, Józef Mehoffer, and a group of Polish Impressionists. Artists of the twentieth-century Avant-Garde represented various schools and trends. The art of Tadeusz Makowski was influenced by Cubism; while Władysław Strzemiński and Henryk Stażewski worked within the Constructivist idiom. Distinguished contemporary artists include Roman Opałka, Leon Tarasewicz, Jerzy Nowosielski, Wojciech Siudmak, Mirosław Bałka, and Katarzyna Kozyra and Zbigniew Wąsiel in the younger generation. The most celebrated Polish sculptors include Xawery Dunikowski, Katarzyna Kobro, Alina Szapocznikow and Magdalena Abakanowicz. Since the inter-war years, Polish art and documentary photography has enjoyed worldwide recognition. In the sixties the Polish Poster School was formed, with Henryk Tomaszewski and Waldemar Świerzy at its head. Top fine Art schools in Poland are Jan Matejko Academy of Fine Arts, Cracow School of Art and Fashion Design, Academy of Fine Arts in Warsaw, Art Academy of Szczecin, University of Fine Arts in Poznań and Eugeniusz Geppert Academy of Fine Arts.
Architecture.
Polish cities and towns reflect the whole spectrum of European styles. Romanesque architecture is represented by St. Andrew's Church, Kraków, and St. Mary's Church, Gdańsk, is characteristic for the Brick Gothic style found in Poland. Richly decorated attics and arcade loggias are the common elements of the Polish Renaissance architecture, as evident in the City Hall in Poznań. For some time the late renaissance style known as mannerism, most notably in the Bishop's Palace in Kielce, coexisted with the early baroque style, typified in the Church of SS. Peter and Paul in Kraków.
History has not been kind to Poland's architectural monuments. Nonetheless, a number of ancient structures has survived: castles, churches, and stately homes, often unique in the regional or European context. Some of them have been painstakingly restored, like Wawel Castle, or completely reconstructed after being destroyed in the Second World War, including the Old Town and Royal Castle of Warsaw and the Old Town of Gdańsk.
The architecture of Gdańsk is mostly of the Hanseatic variety, a Gothic style common among the former trading cities along the Baltic sea and in the northern part of Central Europe. The architectural style of Wrocław is mainly representative of German architecture, since it was for centuries located within the German states. The centre of Kazimierz Dolny on the Vistula is a good example of a well-preserved medieval town. Poland's ancient capital, Kraków, ranks among the best-preserved Gothic and Renaissance urban complexes in Europe. Meanwhile, the legacy of the Kresy Marchlands of Poland's eastern regions, where Wilno and Lwów (now "Vilnius" and "Lviv") were recognised as two major centres for the arts, played a special role in the development of Polish architecture, with Catholic church architecture deserving special note.
The second half of the 17th century is marked by baroque architecture. Side towers, such as those of Branicki Palace in Białystok, are typical for the Polish baroque. The classical Silesian baroque is represented by the University in Wrocław. The profuse decorations of the Branicki Palace in Warsaw are characteristic of the rococo style. The centre of Polish classicism was Warsaw under the rule of the last Polish king Stanisław August Poniatowski. The Palace on the Water is the most notable example of Polish neoclassical architecture. Lublin Castle represents the Gothic Revival style in architecture, while the Izrael Poznański Palace in Łódź is an example of eclecticism.
Literature.
Adam Mickiewicz, was a strong advocate of Poland's heritage during his years in exile, 1798–1855 
Polish literature dates back to the 12th century, and includes many renowned writers. Two Polish novelists have won the Nobel Prize in Literature: Henryk Sienkiewicz, and Władysław Reymont; along with two poets: Czesław Miłosz, and Wisława Szymborska. A prose poet of the highest order, Joseph Conrad (1857–1924), son of the Polish dramatist Apollo Korzeniowski, won world-wide fame with his English-language novels and stories that are informed with elements of the Polish national experience. Among the best known Polish Romantics are the "Three Bards" — the three national poets active in the age of Partitions: Adam Mickiewicz, Juliusz Słowacki, and Zygmunt Krasiński.
During the Middle Ages, most Polish writers and scholars (e.g., Jan Długosz) wrote only in Latin, the common language of European letters. This tradition was broken by Jan Kochanowski, who became one of the first Polish Renaissance authors to write most of his works in Polish, along with Mikołaj Rej. Especially notable 19th- and 20th-century Polish authors include Bolesław Prus, Kornel Makuszyński, Stanisław Lem, and Witold Gombrowicz among others.
Media.
Poland has instituted freedom of press since the fall of communism, a system under which the media was heavily politically controlled and censored. However, public TV and radio are still regulated by the government, this is exercised through an agency called "Krajowa Rada Radiofonii i Telewizji" ("The National Radio and Television Committee"), which is similar to television regulatory commissions in other developed nations.
Poland has a number of major media outlets, chief among which are the national television channels. TVP is Poland's public broadcasting corporation; about a third of its income comes from a broadcast receiver licence, while the rest is made through revenue from commercials and sponsorships. State television operates two mainstream channels, TVP 1 and TVP 2, as well as regional programs (TVP Info) for each of the country's 16 voivodeships. In addition to these general channels, TVP runs a number of genre-specific programmes such as TVP Sport, TVP Historia, TVP Kultura, TVP Seriale and TV Polonia, the latter is a state-run channel dedicated to the transmission of Polish language television for the Polish diaspora abroad.
Poland has a number of internationally broadcast and 24-hour news channels, chief among which are Polsat News, TVN 24. There are a number of major private television outlets such as Polsat and the TVN network.
Poland has a highly developed printed news industry, with daily newspapers like Gazeta Wyborcza "(The Electoral Gazette)", Rzeczpospolita "(The Republic)" and Gazeta Polska Codziennie providing more traditional, intellectually stimulating reporting and tabloids such as Fakt providing more sensationalist writing which is less current affairs orientated. Rzeczpospolita is one of the nation's oldest publications still in operation today, founded in 1920, it has become a stalwart bastion of Polish reporting and in 2006 won a prestigious award for being, along with the Guardian (a British daily), the best designed newspaper in the world. The most popular weeklies are Tygodnik Angora, Polityka, Wprost, Newsweek Polska, Gość Niedzielny, and Gazeta Polska.
Cuisine.
Polish cuisine has evolved over the centuries to become very eclectic due to Poland's history. Polish cuisine shares many similarities with other Central European cuisines, especially German and Austrian as well as Jewish, Belarussian, Ukrainian, Russian, French and Italian culinary traditions. It is rich in meat, especially pork, chicken and beef (depending on the region) and winter vegetables (cabbage in the dish "bigos"), and spices. It is also characteristic in its use of various kinds of noodles the most notable of which are kluski as well as cereals such as "kasha" (from the Polish word kasza). Polish cuisine is hearty and uses a lot of cream and eggs. Festive meals such as the meatless Christmas eve dinner ("Wigilia") or Easter breakfast could take days to prepare in their entirety.
The main course usually includes a serving of meat, such as roast, chicken, or "kotlet schabowy" (breaded pork cutlet), vegetables, side dishes and salads, including "surówka" ] – shredded root vegetables with lemon and sugar (carrot, celeriac, seared beetroot) or sauerkraut (Polish: "kapusta kiszona", ]). The side dishes are usually potatoes, rice or "kasza" (cereals). Meals conclude with a dessert such as "sernik", "makowiec" (a poppy seed pastry), or "drożdżówka" ] yeast pastry, and tea.
The Polish national dishes are "bigos" ]; "pierogi" ]; "kielbasa"; "kotlet schabowy" ] breaded cutlet; "gołąbki" ] cabbage rolls; "zrazy" ] roulade; "pieczeń" roast ]; sour cucumber soup ("zupa ogórkowa", ]); mushroom soup, ("zupa grzybowa", ] quite different from the North American cream of mushroom); "zupa pomidorowa" tomato soup ]; "rosół" ] variety of meat broth; "żurek" ] sour rye soup; "flaki" ] tripe soup; "barszcz" ] and "chłodnik" ] among others.
Traditional alcoholic beverages include honey mead, widespread since the 13th century, beer, wine and vodka (old Polish names include "okowita" and "gorzałka"). The world's first written mention of vodka originates from Poland. The most popular alcoholic drinks at present are beer and wine which took over from vodka more popular in the years 1980-1998. Tea remains common in Polish society since the 19th century, whilst coffee is drunk widely since the 18th century. Other frequently consumed beverages include various mineral waters and juices, soft drinks popularized by the fast-food chains since the late 20th century, as well as buttermilk, soured milk and kefir.
Sports.
Football (soccer) is one of country's most popular sports, with a rich history of international competitions. Track and field, basketball, volleyball, handball, boxing, MMA, motorcycle speedway, ski jumping, cross-country skiing, ice hockey, tennis, fencing, swimming and weightlifting are other popular sports.
The golden era of football in Poland occurred throughout the 1970s and went on until the early 1980s when the Polish national football team achieved their best results in any FIFA World Cup competitions finishing 3rd place in the 1974 and the 1982 tournaments. The team won a gold medal in football at the 1972 Summer Olympics and two silver medals, in 1976 and in 1992. Poland, along with Ukraine, hosted the UEFA European Football Championship in 2012.
The Polish men's national volleyball team is ranked as 3rd in the world. Mariusz Pudzianowski is a highly successful strongman competitor and has won more World's Strongest Man titles than any other competitor in the world, winning the event in 2008 for the fifth time. The first Polish Formula One driver, Robert Kubica, has brought awareness of Formula One Racing to Poland.
Poland has made a distinctive mark in motorcycle speedway racing thanks to Tomasz Gollob, a highly successful Polish rider. The top Ekstraliga division has one of the highest average attendances for any sport in Poland. The national speedway team of Poland, one of the major teams in international speedway, has won the Speedway World Team Cup championships three times consequtively, in 2009, 2010, and 2011. No team has ever managed such feat.
Poles made significant achievements in mountaineering, in particular, in the Himalayas and the winter ascending of the eight-thousanders. The most famous Polish climbers are Jerzy Kukuczka, Krzysztof Wielicki, Piotr Pustelnik, Andrzej Zawada, Maciej Berbeka, Artur Hajzer, Andrzej Czok, Wojciech Kurtyka, and women Wanda Rutkiewicz, and Kinga Baranowska. Polish mountains are one of the tourist attractions of the country. Hiking, climbing, skiing and mountain biking and attract numerous tourists every year from all over the world. Popular summer recreation activities centre around water sports with ample locations for fishing, canoeing, kayaking, sailing and windsurfing especially in the northern regions of the country.
International rankings.
The following are links to international rankings of Poland from selected research institutes and foundations including economic output and various composite indices.
Notes.
a ^ Numerous sources state that Polish Army was the Allies' fourth biggest fighting contingent. Steven J. Zaloga and Richard Hook write that "by the war's end the Polish Army was the fourth largest contingent of the Allied coalition after the armed forces of the Soviet Union, the United States and the United Kingdom." Jerzy Jan Lerski writes "All in all, the Polish units, although divided and controlled by different political orientation, constituted the fourth largest Allied force, after the America, British and Soviet Armies." M. K. Dziewanowski has noted that "if Polish forces fighting in the east and west were added to the resistance fighters, Poland had the fourth largest Allied army in the war (after the USSR, the U.S. and Britain)".
The claim of the fourth biggest Ally needs to be reconsidered, however. Throughout the war, Poland's position varied from the 2nd biggest Ally (after the fall of France, when Polish army outnumbered the French) to perhaps the 5th at the end of it (after the USA, Soviet Union, China and Britain). Please, see the analysis in Polish contribution to World War II.
b ^ Sources vary with regards to what was the largest resistance movement during World War II. The confusion often stems from the fact that as war progressed, some resistance movements grew larger – and other diminished. Polish territories were mostly freed from Nazi German control in the years 1944–1945, eliminating the need for their respective (anti-Nazi) partisan forces (in Poland (although the cursed soldiers continued to fight against the Soviets). Several sources note that Polish Armia Krajowa was the largest resistance movement in Nazi-occupied Europe. Norman Davies wrote: "Armia Krajowa (Home Army), the AK, which could fairly claim to be the largest of European resistance"; Gregor Dallas wrote "Home Army (Armia Krajowa or AK) in late 1943 numbered around 400000, making it the largest resistance organization in Europe"; Mark Wyman wrote "Armia Krajowa was considered the largest underground resistance unit in wartime Europe". Certainly, Polish resistance was the largest resistance till German invasion of Yugoslavia and invasion of the Soviet Union in 1941. After that point, the numbers of Soviet partisans and Yugoslav partisans begun growing rapidly. The numbers of Soviet partisans quickly caught up and were very similar to that of the Polish resistance. The numbers of Tito's Yugoslav partisans were roughly similar to those of the Polish and Soviet partisans in the first years of the war (1941–1942), but grew rapidly in the latter years, outnumbering the Polish and Soviet partisans by 2:1 or more (estimates give Yugoslavian forces about 800,000 in 1945, to Polish and Soviet forces of 400,000 in 1944).
</dl>

</doc>
<doc id="22938" url="http://en.wikipedia.org/wiki?curid=22938" title="Performing arts">
Performing arts

Performing arts are art forms in which artists use their voices and/or the movements of their bodies, often in relation to other objects, to convey artistic expression—as opposed to, for example, purely visual arts, in which artists use paint/canvas or various materials to create physical or static art objects. Performing arts include a variety of disciplines but all are intended to be performed in front of a live audience.
Performers.
Artists who participate in performing arts in front of an audience are called performers. Example of this include actors, comedians, dancers, magicians, circus artists, musicians, and singers. Performing arts are also supported by workers in related fields, such as songwriting, choreography and stagecraft.
A performer who excels in acting, singing, and dancing is commonly referred to as a "triple threat". Well-known examples of historical triple threat artists include Gene Kelly, Fred Astaire, and Judy Garland.
Performers often adapt their appearance, such as with costumes and stage makeup, stage lighting, and sound.
Types.
Performing arts may include dance, music, opera, theatre and musical theatre, magic, illusion, mime, spoken word, puppetry, circus arts, performance art, recitation and public speaking.
There is also a specialized form of fine art, in which the artists "perform" their work live to an audience. This is called performance art. Most performance art also involves some form of plastic art, perhaps in the creation of props. Dance was often referred to as a "plastic art" during the Modern dance era.
Theatre.
Theatre is the branch of performing arts; concerned with acting out stories in front of an audience, using a combination of speech, gesture, music, dance, sound and spectacle. Any one or more of these elements is performing arts. In addition to the standard narrative dialogue style of plays. Theatre takes such forms as plays, musicals, opera, ballet, illusion, mime, classical Indian dance, kabuki, mummers' plays, improvisational theatre, stand-up comedy, pantomime, and non-conventional or contemporary forms like postmodern theatre, postdramatic theatre, or performance art .
Dance.
In the context of performing arts, dance generally refers to human movement, typically rhythmic and to music, used as a form of audience entertainment in a performance setting. Definitions of what constitutes dance are dependent on social, cultural, aesthetic artistic and moral constraints and range from functional movement (such as folk dance) to codified, virtuoso techniques such as ballet.
Dance is a powerful impulse, but the art of dance is that impulse channeled by skillful performers into something that becomes intensely expressive and that may delight spectators who feel no wish to dance themselves. These two concepts of the art of dance—dance as a powerful impulse and dance as a skillfully choreographed art practiced largely by a professional few—are the two most important connecting ideas running through any consideration of the subject. In dance, the connection between the two concepts is stronger than in some other arts, and neither can exist without the other.
Choreography is the art of making dances, and the person who practices this art is called a choreographer.
History of Western performing arts.
Starting in the 6th century BC, the Classical period of performing art began in Greece, ushered in by the tragic poets such as Sophocles. These poets wrote plays which, in some cases, incorporated dance (see Euripides). The Hellenistic period began the widespread use of comedy.
However by the 6th century AD, Western performing arts had been largely ended, as the Dark Ages began. Between the 9th century and 14th century, performing art in the West was limited to religious historical enactments and morality plays, organized by the Church in celebration of holy days and other important events.
Renaissance.
In the 15th century performing arts, along with the arts in general, saw a revival as the Renaissance began in Italy and spread throughout Europe plays, some of which incorporated dance, which were performed and Domenico da Piacenza credited with the first use of the term "ballo" (in "De Arte Saltandi et Choreas Ducendi") instead of "danza" (dance) for his "baletti" or "balli". The term eventually became "Ballet". The first Ballet "per se" is thought to be Balthasar de Beaujoyeulx's Ballet Comique de la Reine (1581).
By the mid-16th century Commedia Dell'arte became popular in Europe, introducing the use of improvisation. This period also introduced the Elizabethan masque, featuring music, dance and elaborate costumes as well as professional theatrical companies in England. William Shakespeare's plays in the late 16th century developed from this new class of professional performance.
In 1597, the first opera, Dafne was performed and throughout the 17th century, opera would rapidly become the entertainment of choice for the aristocracy in most of Europe, and eventually for large numbers of people living in cities and towns throughout Europe.
Modern era.
The introduction of the proscenium arch in Italy during the 17th century established the traditional theatre form that persists to this day. Meanwhile, in England, the Puritans forbade acting, bringing a halt to performing arts that lasted until 1660. After that, women began to appear in both French and English plays. The French introduced a formal dance instruction in the late 17th century.
It is also during this time that the first plays were performed in the American Colonies.
During the 18th century, the introduction of the popular opera buffa brought opera to the masses as an accessible form of performance. Mozart's "The Marriage of Figaro" and "Don Giovanni" are landmarks of the late 18th century opera.
At the turn of the 19th century Beethoven and the Romantic movement ushered in a new era that lead first to the spectacles of grand opera and then to the musical dramas of Giuseppe Verdi and the Gesamtkunstwerk (total work of art) of the operas of Richard Wagner leading directly to the music of the 20th century.
The 19th century was a period of growth for the performing arts for all social classes, technical advances such as the introduction of gaslight to theatres, burlesque, minstrel dancing, and variety theatre. In ballet, women make great progress in the previously male-dominated art.
Modern dance began in the late 19th century and early 20th century in response to the restrictions of traditional ballet.
Konstantin Stanislavski's "System" revolutionized acting in the early 20th century, and continues to have a major influence on actors of stage and screen to the current day. Both impressionism and modern realism were introduced to the stage during this period.
The arrival of Sergei Diaghilev's Ballets Russes (1909–1929) revolutionized ballet and the performing arts generally throughout the Western world, most importantly through Diaghilev's emphasis on collaboration, which brought choreographers, dancers, set designers/artists, composers and musicians together to revitalize and revolutionize ballet. It is extremely complex.
With the invention of the motion picture in the late 19th century by Thomas Edison, and the growth of the motion picture industry in Hollywood. In the early 20th century, film became a dominant performance medium throughout the 20th and 21st centuries.
Rhythm and blues, a cultural phenomenon of black America, became to prominence in the early 20th century; influencing a range of later popular music styles internationally.
In the 1930s Jean Rosenthal introduced what would become modern stage lighting, changing the nature of the stage as the Broadway musical became a phenomenon in the United States.
Post-War performance.
Post-World War II performing arts were highlighted by the resurgence of both ballet and opera in the Western world.
Postmodernism in performing arts dominated the 1960s to large extent.
Eastern performing arts.
Middle East.
The earliest recorded theatrical event dates back to 2000 BC with the passion plays of Ancient Egypt. This story of the god Osiris was performed annually at festivals throughout the civilization, marking the known beginning of a long relationship between theatre and religion.
The most popular forms of theater in the medieval Islamic world were puppet theatre (which included hand puppets, shadow plays and marionette productions) and live passion plays known as "ta'ziya", where actors re-enact episodes from Muslim history. In particular, Shia Islamic plays revolved around the "shaheed" (martyrdom) of Ali's sons Hasan ibn Ali and Husayn ibn Ali. Live secular plays were known as "akhraja", recorded in medieval "adab" literature, though they were less common than puppetry and "ta'ziya" theater.
Iran.
In Iran there are other forms of theatrical events such as "Naghali" (story telling), "ٰRu-Howzi", "Siah-Bazi", "Parde-Khani, ""Mareke giri".
India and Pakistan.
Folk theatre and dramatics can be traced to the religious ritualism of the Vedic peoples in the 2nd millennium BC. This folk theatre of the misty past was mixed with dance, food, ritualism, plus a depiction of events from daily life. The last element made it the origin of the classical theatre of later times. Many historians, notably D. D. Kosambi, Debiprasad Chattopadhyaya, Adya Rangacharaya, etc. have referred to the prevalence of ritualism amongst Indo-Aryan tribes in which some members of the tribe acted as if they were wild animals and some others were the hunters. Those who acted as mammals like goats, buffaloes, reindeer, monkeys, etc. were chased by those playing the role of hunters.
Bharata Muni (fl. 5th–2nd century BC) was an ancient Indian writer best known for writing the "Natya Shastra of Bharata", a theoretical treatise on Indian performing arts, including theatre, dance, acting, and music, which has been compared to Aristotle's "Poetics". Bharata is often known as the father of Indian theatrical arts. His "Natya Shastra" seems to be the first attempt to develop the technique or rather art, of drama in a systematic manner. The Natya Shastra tells us not only what is to be portrayed in a drama, but how the portrayal is to be done. Drama, as Bharata Muni says, is the imitation of men and their doings ("loka-vritti"). As men and their doings have to be respected on the stage, so drama in Sanskrit is also known by the term "roopaka," which means portrayal.
The "Ramayana" and "Mahabharata" can be considered the first recognized plays that originated in India. These epics provided the inspiration to the earliest Indian dramatists and they do it even today. Indian dramatists such as Bhasa in the 2nd century BC wrote plays that were heavily inspired by the "Ramayana" and "Mahabharata".
Kālidāsa in the 1st century BC, is arguably considered to be ancient India's greatest dramatist. Three famous romantic plays written by Kālidāsa are the "Mālavikāgnimitram" ("Mālavikā and Agnimitra"), "Vikramuurvashiiya" ("Pertaining to Vikrama and Urvashi"), and "Abhijñānaśākuntala" ("The Recognition of Shakuntala"). The last was inspired by a story in the "Mahabharata" and is the most famous. It was the first to be translated into English and German. In comparison to Bhasa, who drew heavily from the epics, Kālidāsa can be considered an original playwright.
The next great Indian dramatist was Bhavabhuti (c. 7th century). He is said to have written the following three plays: "Malati-Madhava", "Mahaviracharita" and "Uttar Ramacharita". Among these three, the last two cover between them, the entire epic of "Ramayana". The powerful Indian emperor Harsha (606–648) is credited with having written three plays: the comedy "Ratnavali", "Priyadarsika", and the Buddhist drama "Nagananda". Many other dramatists followed during the Middle Ages.
There were many performing art forms in the southern part of India, Kerala is such a state with different such art forms like Koodiyattam, Nangyarkoothu, Kathakali, Chakyar koothu and there were many prominent artists like Painkulam Raman Chakyar and others.
China.
There are references to theatrical entertainments in China as early as 1500 BC during the Shang Dynasty; they often involved music, clowning and acrobatic displays.
The Tang Dynasty is sometimes known as "The Age of 1000 Entertainments". During this era, Emperor Xuanzong formed an acting school known as the Children of the Pear Garden to produce a form of drama that was primarily musical.
During the Han Dynasty, shadow puppetry first emerged as a recognized form of theatre in China. There were two distinct forms of shadow puppetry, Cantonese southern and Pekingese northern. The two styles were differentiated by the method of making the puppets and the positioning of the rods on the puppets, as opposed to the type of play performed by the puppets. Both styles generally performed plays depicting great adventure and fantasy, rarely was this very stylized form of theatre used for political propaganda. Cantonese shadow puppets were the larger of the two. They were built using thick leather that created more substantial shadows. Symbolic color was also very prevalent; a black face represented honesty, a red one bravery. The rods used to control Cantonese puppets were attached perpendicular to the puppets' heads. Thus, they were not seen by the audience when the shadow was created. Pekingese puppets were more delicate and smaller. They were created out of thin, translucent leather usually taken from the belly of a donkey. They were painted with vibrant paints, thus they cast a very colorful shadow. The thin rods that controlled their movements were attached to a leather collar at the neck of the puppet. The rods ran parallel to the bodies of the puppet then turned at a ninety degree angle to connect to the neck. While these rods were visible when the shadow was cast, they laid outside the shadow of the puppet; thus they did not interfere with the appearance of the figure. The rods attached at the necks to facilitate the use of multiple heads with one body. When the heads were not being used, they were stored in a muslin book or fabric lined box. The heads were always removed at night. This was in keeping with the old superstition that if left intact, the puppets would come to life at night. Some puppeteers went so far as to store the heads in one book and the bodies in another, to further reduce the possibility of reanimating puppets. Shadow puppetry is said to have reached its highest point of artistic development in the 11th century before becoming a tool of the government.
In the Song Dynasty, there were many popular plays involving acrobatics and music. These developed in the Yuan Dynasty into a more sophisticated form with a four or five act structure. Yuan drama spread across China and diversified into numerous regional forms, the best known of which is Beijing Opera, which is still popular today.
Thailand.
In Thailand, it has been a tradition from the Middle Ages to stage plays based on plots drawn from Indian epics. In particular, the theatrical version of Thailand's national epic "Ramakien", a version of the Indian "Ramayana", remains popular in Thailand even today.
Cambodia.
In Cambodia, at the ancient capital Angkor Wat, stories from the Indian epics "Ramayana" and "Mahabharata" have been carved on the walls of temples and palaces. Similar reliefs are found at Borobudur in Indonesia.
Japan.
During the 14th century, there were small companies of actors in Japan who performed short, sometimes vulgar comedies. A director of one of these companies, Kan'ami (1333–1384), had a son, Zeami Motokiyo (1363–1443) who was considered one of the finest child actors in Japan. When Kan'ami's company performed for Ashikaga Yoshimitsu (1358–1408), the Shogun of Japan, he implored Zeami to have a court education for his arts. After Zeami succeeded his father, he continued to perform and adapt his style into what is today Noh. A mixture of pantomime and vocal acrobatics, this style has fascinated the Japanese for hundreds of years.
Japan, after a long period of civil wars and political disarray, was unified and at peace primarily due to shogun Tokugawa Ieyasu (1600–1668). However, alarmed at increasing Christian growth, he cut off contact from Japan to Europe and China and outlawed Christianity. When peace did come, a flourish of cultural influence and growing merchant class demanded its own entertainment. The first form of theatre to flourish was Ningyō jōruri (commonly referred to as Bunraku). The founder of and main contributor to Ningyō jōruri, Chikamatsu Monzaemon (1653–1725), turned his form of theatre into a true art form. Ningyō jōruri is a highly stylized form of theatre using puppets, today about 1/3d the size of a human. The men who control the puppets train their entire lives to become master puppeteers, when they can then operate the puppet's head and right arm and choose to show their faces during the performance. The other puppeteers, controlling the less important limbs of the puppet, cover themselves and their faces in a black suit, to imply their invisibility. The dialogue is handled by a single person, who uses varied tones of voice and speaking manners to simulate different characters. Chikamatsu wrote thousands of plays during his lifetime, most of which are still used today.
Kabuki began shortly after Bunraku, legend has it by an actress named Okuni, who lived around the end of the 16th century. Most of Kabuki's material came from Nõ and Bunraku, and its erratic dance-type movements are also an effect of Bunraku. However, Kabuki is less formal and more distant than Nõ, yet very popular among the Japanese public. Actors are trained in many varied things including dancing, singing, pantomime, and even acrobatics. Kabuki was first performed by young girls, then by young boys, and by the end of the 16th century, Kabuki companies consisted of all men. The men who portrayed women on stage were specifically trained to elicit the essence of a woman in their subtle movements and gestures.

</doc>
<doc id="22939" url="http://en.wikipedia.org/wiki?curid=22939" title="Physics">
Physics

Physics (from Ancient Greek: φυσική (ἐπιστήμη) "phusikḗ (epistḗmē)" "knowledge of nature", from φύσις "phúsis" "nature") is the natural science that involves the study of matter and its motion through space and time, along with related concepts such as energy and force. More broadly, it is the general analysis of nature, conducted in order to understand how the universe behaves.
Physics is one of the oldest academic disciplines, perhaps the oldest through its inclusion of astronomy. Over the last two millennia, physics was a part of natural philosophy along with chemistry, certain branches of mathematics, and biology, but during the scientific revolution in the 17th century, the natural sciences emerged as unique research programs in their own right. Physics intersects with many interdisciplinary areas of research, such as biophysics and quantum chemistry, and the boundaries of physics are not rigidly defined. New ideas in physics often explain the fundamental mechanisms of other sciences while opening new avenues of research in areas such as mathematics and philosophy.
Physics also makes significant contributions through advances in new technologies that arise from theoretical breakthroughs. For example, advances in the understanding of electromagnetism or nuclear physics led directly to the development of new products that have dramatically transformed modern-day society, such as television, computers, domestic appliances, and nuclear weapons; advances in thermodynamics led to the development of industrialization, and advances in mechanics inspired the development of calculus.
History.
Ancient astronomy.
Astronomy is the oldest of the natural sciences. The earliest civilizations dating back to beyond 3000 BCE, such as the Sumerians, ancient Egyptians, and the Indus Valley Civilization, all had a predictive knowledge and a basic understanding of the motions of the Sun, Moon, and stars. The stars and planets were often a target of worship, believed to represent their gods. While the explanations for these phenomena were often unscientific and lacking in evidence, these early observations laid the foundation for later astronomy.
According to Asger Aaboe, the origins of Western astronomy can be found in Mesopotamia, and all Western efforts in the exact sciences are descended from late Babylonian astronomy. Egyptian astronomers left monuments showing knowledge of the constellations and the motions of the celestial bodies, while Greek poet Homer wrote of various celestial objects in his "Iliad" and "Odyssey"; later Greek astronomers provided names, which are still used today, for most constellations visible from the northern hemisphere.
Natural philosophy.
Natural philosophy has its origins in Greece during the Archaic period, (650 BC – 480 BC), when Pre-Socratic philosophers like Thales rejected non-naturalistic explanations for natural phenomena and proclaimed that every event had a natural cause. They proposed ideas verified by reason and observation, and many of their hypotheses proved successful in experiment; for example, atomism was found to be correct approximately 2000 years after it was first proposed by Leucippus and his pupil Democritus.
Classical physics.
Physics became a separate science when early modern Europeans used experimental and quantitative methods to discover what are now considered to be the laws of physics.
Major developments in this period include the replacement of the geocentric model of the solar system with the helio-centric Copernican model, the laws governing the motion of planetary bodies determined by Johannes Kepler between 1609 and 1619, pioneering work on telescopes and observational astronomy by Galileo Galilei in the 16th and 17th Centuries, and Isaac Newton's discovery and unification of the laws of motion and universal gravitation that would come to bear his name. Newton also developed calculus, the mathematical study of change, which provided new mathematical methods for solving physical problems.
The discovery of new laws in thermodynamics, chemistry, and electromagnetics resulted from greater research efforts during the Industrial Revolution as energy needs increased. The laws comprising classical physics remain very widely used for objects on everyday scales travelling at non-relativistic speeds, since they provide a very close approximation in such situations, and theories such as quantum mechanics and the theory of relativity simplify to their classical equivalents at such scales. However, inaccuracies in classical mechanics for very small objects and very high velocities led to the development of modern physics in the 20th century.
Modern physics.
Modern physics began in the early 20th century with the work of Max Planck in quantum theory and Albert Einstein's theory of relativity. Both of these theories came about due to inaccuracies in classical mechanics in certain situations. Classical mechanics predicted a varying speed of light, which could not be resolved with the constant speed predicted by Maxwell's equations of electromagnetism; this discrepancy was corrected by Einstein's theory of special relativity, which replaced classical mechanics for fast-moving bodies and allowed for a constant speed of light. Black body radiation provided another problem for classical physics, which was corrected when Planck proposed that light comes in individual packets known as photons; this, along with the photoelectric effect and a complete theory predicting discrete energy levels of electron orbitals, led to the theory of quantum mechanics taking over from classical physics at very small scales.
Quantum mechanics would come to be pioneered by Werner Heisenberg, Erwin Schrödinger and Paul Dirac. From this early work, and work in related fields, the Standard Model of particle physics was derived. Following the discovery of a particle with properties consistent with the Higgs boson at CERN in 2012, all fundamental particles predicted by the standard model, and no others, appear to exist; however, physics beyond the Standard Model, with theories such as supersymmetry, is an active area of research.
Philosophy.
In many ways, physics stems from ancient Greek philosophy. From Thales' first attempt to characterize matter, to Democritus' deduction that matter ought to reduce to an invariant state, the Ptolemaic astronomy of a crystalline firmament, and Aristotle's book "Physics" (an early book on physics, which attempted to analyze and define motion from a philosophical point of view), various Greek philosophers advanced their own theories of nature. Physics was known as natural philosophy until the late 18th century.
By the 19th century, physics was realized as a discipline distinct from philosophy and the other sciences. Physics, as with the rest of science, relies on philosophy of science to give an adequate description of the scientific method. The scientific method employs "a priori reasoning" as well as "a posteriori" reasoning and the use of Bayesian inference to measure the validity of a given theory.
The development of physics has answered many questions of early philosophers, but has also raised new questions. Study of the philosophical issues surrounding physics, the philosophy of physics, involves issues such as the nature of space and time, determinism, and metaphysical outlooks such as empiricism, naturalism and realism.
Many physicists have written about the philosophical implications of their work, for instance Laplace, who championed causal determinism, and Erwin Schrödinger, who wrote on quantum mechanics. The mathematical physicist Roger Penrose has been called a Platonist by Stephen Hawking, a view Penrose discusses in his book, "The Road to Reality". Hawking refers to himself as an "unashamed reductionist" and takes issue with Penrose's views.
Core theories.
Though physics deals with a wide variety of systems, certain theories are used by all physicists. Each of these theories were experimentally tested numerous times and found correct as an approximation of nature (within a certain domain of validity). For instance, the theory of classical mechanics accurately describes the motion of objects, provided they are much larger than atoms and moving at much less than the speed of light. These theories continue to be areas of active research, and a remarkable aspect of classical mechanics known as chaos was discovered in the 20th century, three centuries after the original formulation of classical mechanics by Isaac Newton (1642–1727).
These central theories are important tools for research into more specialised topics, and any physicist, regardless of their specialisation, is expected to be literate in them. These include classical mechanics, quantum mechanics, thermodynamics and statistical mechanics, electromagnetism, and special relativity.
Classical physics.
Classical physics includes the traditional branches and topics that were recognised and well-developed before the beginning of the 20th century—classical mechanics, acoustics, optics, thermodynamics, and electromagnetism. Classical mechanics is concerned with bodies acted on by forces and bodies in motion and may be divided into statics (study of the forces on a body or bodies not subject to an acceleration), kinematics (study of motion without regard to its causes), and dynamics (study of motion and the forces that affect it); mechanics may also be divided into solid mechanics and fluid mechanics (known together as continuum mechanics), the latter including such branches as hydrostatics, hydrodynamics, aerodynamics, and pneumatics. Acoustics is the study of how sound is produced, controlled, transmitted and received. Important modern branches of acoustics include ultrasonics, the study of sound waves of very high frequency beyond the range of human hearing; bioacoustics the physics of animal calls and hearing, and electroacoustics, the manipulation of audible sound waves using electronics. Optics, the study of light, is concerned not only with visible light but also with infrared and ultraviolet radiation, which exhibit all of the phenomena of visible light except visibility, e.g., reflection, refraction, interference, diffraction, dispersion, and polarization of light. Heat is a form of energy, the internal energy possessed by the particles of which a substance is composed; thermodynamics deals with the relationships between heat and other forms of energy. Electricity and magnetism have been studied as a single branch of physics since the intimate connection between them was discovered in the early 19th century; an electric current gives rise to a magnetic field, and a changing magnetic field induces an electric current. Electrostatics deals with electric charges at rest, electrodynamics with moving charges, and magnetostatics with magnetic poles at rest.
Modern physics.
Classical physics is generally concerned with matter and energy on the normal scale of observation, while much of modern physics is concerned with the behavior of matter and energy under extreme conditions or on a very large or very small scale. For example, atomic and nuclear physics studies matter on the smallest scale at which chemical elements can be identified. The physics of elementary particles is on an even smaller scale since it is concerned with the most basic units of matter; this branch of physics is also known as high-energy physics because of the extremely high energies necessary to produce many types of particles in large particle accelerators. On this scale, ordinary, commonsense notions of space, time, matter, and energy are no longer valid.
The two chief theories of modern physics present a different picture of the concepts of space, time, and matter from that presented by classical physics. Quantum theory is concerned with the discrete, rather than continuous, nature of many phenomena at the atomic and subatomic level and with the complementary aspects of particles and waves in the description of such phenomena. The theory of relativity is concerned with the description of phenomena that take place in a frame of reference that is in motion with respect to an observer; the special theory of relativity is concerned with relative uniform motion in a straight line and the general theory of relativity with accelerated motion and its connection with gravitation. Both quantum theory and the theory of relativity find applications in all areas of modern physics.
Difference between classical and modern physics.
While physics aims to discover universal laws, its theories lie in explicit domains of applicability. Loosely speaking, the laws of classical physics accurately describe systems whose important length scales are greater than the atomic scale and whose motions are much slower than the speed of light. Outside of this domain, observations do not match their predictions. Albert Einstein contributed the framework of special relativity, which replaced notions of absolute time and space with spacetime and allowed an accurate description of systems whose components have speeds approaching the speed of light. Max Planck, Erwin Schrödinger, and others introduced quantum mechanics, a probabilistic notion of particles and interactions that allowed an accurate description of atomic and subatomic scales. Later, quantum field theory unified quantum mechanics and special relativity. General relativity allowed for a dynamical, curved spacetime, with which highly massive systems and the large-scale structure of the universe can be well-described. General relativity has not yet been unified with the other fundamental descriptions; several candidate theories of quantum gravity are being developed.
Relation to other fields.
Prerequisites.
Mathematics is the language used for compact description of the order in nature, especially the laws of physics. This was noted and advocated by Pythagoras, Plato, Galileo, and Newton.
Physics theories use mathematics to obtain order and provide precise formulas, precise or estimated solutions, quantitative results and predictions. Experiment results in physics are numerical measurements. Technologies based on mathematics, like computation have made computational physics an active area of research.
Ontology is a prerequisite for physics, but not for mathematics. It means physics is ultimately concerned with descriptions of the real world, while mathematics is concerned with abstract patterns, even beyond the real world. Thus physics statements are synthetic, while mathematical statements are analytic. Mathematics contains hypotheses, while physics contains theories. Mathematics statements have to be only logically true, while predictions of physics statements must match observed and experimental data.
The distinction is clear-cut, but not always obvious. For example, mathematical physics is the application of mathematics in physics. Its methods are mathematical, but its subject is physical. The problems in this field start with a "mathematical model of a physical situation" and a "mathematical description of a physical law". Every mathematical statement used for solution has a hard-to-find physical meaning. The final mathematical solution has an easier-to-find meaning, because it is what the solver is looking for.
Physics is a branch of fundamental science, not practical science. Physics is also called "the fundamental science" because the subject of study of all branches of natural science like chemistry, astronomy, geology and biology are constrained by laws of physics, similar to how chemistry is often called the central science because of its role in linking the physical sciences. For example, chemistry studies properties, structures, and reactions of matter (chemistry's focus on the atomic scale distinguishes it from physics). Structures are formed because particles exert electrical forces on each other, properties include physical characteristics of given substances, and reactions are bound by laws of physics, like conservation of energy, mass and charge.
Physics is applied in industries like engineering and medicine. 
Application and influence.
Applied physics is a general term for physics research which is intended for a particular use. An applied physics curriculum usually contains a few classes in an applied discipline, like geology or electrical engineering. It usually differs from engineering in that an applied physicist may not be designing something in particular, but rather is using physics or conducting physics research with the aim of developing new technologies or solving a problem.
The approach is similar to that of applied mathematics. Applied physicists can also be interested in the use of physics for scientific research. For instance, people working on accelerator physics might seek to build better particle detectors for research in theoretical physics.
Physics is used heavily in engineering. For example, statics, a subfield of mechanics, is used in the building of bridges and other static structures. The understanding and use of acoustics results in sound control and better concert halls; similarly, the use of optics creates better optical devices. An understanding of physics makes for more realistic flight simulators, video games, and movies, and is often critical in forensic investigations.
With the standard consensus that the laws of physics are universal and do not change with time, physics can be used to study things that would ordinarily be mired in uncertainty. For example, in the study of the origin of the earth, one can reasonably model earth's mass, temperature, and rate of rotation, as a function of time allowing one to extrapolate forward and backward in time and so predict prior and future conditions. It also allows for simulations in engineering which drastically speed up the development of a new technology.
But there is also considerable interdisciplinarity in the physicist's methods, so many other important fields are influenced by physics (e.g., the fields of econophysics and sociophysics).
Research.
Scientific method.
Physicists use the scientific method to test the validity of a physical theory, using a methodical approach to compare the implications of the theory in question with the associated conclusions drawn from experiments and observations conducted to test it. Experiments and observations are collected and compared with the predictions and hypotheses made by a theory, thus aiding in the determination or the validity/invalidity of the theory.
A scientific law is a concise verbal or mathematical statement of a relation which expresses a fundamental principle of some theory, such as Newton's law of universal gravitation.
Theory and experiment.
Theorists seek to develop mathematical models that both agree with existing experiments and successfully predict future experimental results, while experimentalists devise and perform experiments to test theoretical predictions and explore new phenomena. Although theory and experiment are developed separately, they are strongly dependent upon each other. Progress in physics frequently comes about when experimentalists make a discovery that existing theories cannot explain, or when new theories generate experimentally testable predictions, which inspire new experiments.
Physicists who work at the interplay of theory and experiment are called phenomenologists. Phenomenologists look at the complex phenomena observed in experiment and work to relate them to fundamental theory.
Theoretical physics has historically taken inspiration from philosophy; electromagnetism was unified this way. Beyond the known universe, the field of theoretical physics also deals with hypothetical issues, such as parallel universes, a multiverse, and higher dimensions. Theorists invoke these ideas in hopes of solving particular problems with existing theories. They then explore the consequences of these ideas and work toward making testable predictions.
Experimental physics expands, and is expanded by, engineering and technology. Experimental physicists involved in basic research design and perform experiments with equipment such as particle accelerators and lasers, whereas those involved in applied research often work in industry developing technologies such as magnetic resonance imaging (MRI) and transistors. Feynman has noted that experimentalists may seek areas which are not well-explored by theorists.
Scope and aims.
Physics covers a wide range of phenomena, from elementary particles (such as quarks, neutrinos, and electrons) to the largest superclusters of galaxies. Included in these phenomena are the most basic objects composing all other things. Therefore physics is sometimes called the "fundamental science". Physics aims to describe the various phenomena that occur in nature in terms of simpler phenomena. Thus, physics aims to both connect the things observable to humans to root causes, and then connect these causes together.
For example, the ancient Chinese observed that certain rocks (lodestone) were attracted to one another by some invisible force. This effect was later called magnetism, and was first rigorously studied in the 17th century. A little earlier than the Chinese, the ancient Greeks knew of other objects such as amber, that when rubbed with fur would cause a similar invisible attraction between the two. This was also first studied rigorously in the 17th century, and came to be called electricity. Thus, physics had come to understand two observations of nature in terms of some root cause (electricity and magnetism). However, further work in the 19th century revealed that these two forces were just two different aspects of one force—electromagnetism. This process of "unifying" forces continues today, and electromagnetism and the weak nuclear force are now considered to be two aspects of the electroweak interaction. Physics hopes to find an ultimate reason (Theory of Everything) for why nature is as it is (see section "Current research" below for more information).
Research fields.
Contemporary research in physics can be broadly divided into condensed matter physics; atomic, molecular, and optical physics; particle physics; astrophysics; geophysics and biophysics. Some physics departments also support physics education research and physics outreach.
Since the 20th century, the individual fields of physics have become increasingly specialized, and today most physicists work in a single field for their entire careers. "Universalists" such as Albert Einstein (1879–1955) and Lev Landau (1908–1968), who worked in multiple fields of physics, are now very rare.
The major fields of physics, along with their subfields and the theories they employ, are shown in the following table.
Condensed matter.
Condensed matter physics is the field of physics that deals with the macroscopic physical properties of matter. In particular, it is concerned with the "condensed" phases that appear whenever the number of particles in a system is extremely large and the interactions between them are strong.
The most familiar examples of condensed phases are solids and liquids, which arise from the bonding by way of the electromagnetic force between atoms. More exotic condensed phases include the superfluid and the Bose–Einstein condensate found in certain atomic systems at very low temperature, the superconducting phase exhibited by conduction electrons in certain materials, and the ferromagnetic and antiferromagnetic phases of spins on atomic lattices.
Condensed matter physics is the largest field of contemporary physics. Historically, condensed matter physics grew out of solid-state physics, which is now considered one of its main subfields. The term "condensed matter physics" was apparently coined by Philip Anderson when he renamed his research group—previously "solid-state theory"—in 1967. In 1978, the Division of Solid State Physics of the American Physical Society was renamed as the Division of Condensed Matter Physics. Condensed matter physics has a large overlap with chemistry, materials science, nanotechnology and engineering.
Atomic, molecular, and optical physics.
Atomic, molecular, and optical physics (AMO) is the study of matter–matter and light–matter interactions on the scale of single atoms and molecules. The three areas are grouped together because of their interrelationships, the similarity of methods used, and the commonality of their relevant energy scales. All three areas include both classical, semi-classical and quantum treatments; they can treat their subject from a microscopic view (in contrast to a macroscopic view).
Atomic physics studies the electron shells of atoms. Current research focuses on activities in quantum control, cooling and trapping of atoms and ions, low-temperature collision dynamics and the effects of electron correlation on structure and dynamics. Atomic physics is influenced by the nucleus (see, e.g., hyperfine splitting), but intra-nuclear phenomena such as fission and fusion are considered part of high-energy physics.
Molecular physics focuses on multi-atomic structures and their internal and external interactions with matter and light. Optical physics is distinct from optics in that it tends to focus not on the control of classical light fields by macroscopic objects but on the fundamental properties of optical fields and their interactions with matter in the microscopic realm.
High-energy physics (particle physics) and nuclear physics.
Particle physics is the study of the elementary constituents of matter and energy and the interactions between them. In addition, particle physicists design and develop the high energy accelerators, detectors, and computer programs necessary for this research. The field is also called "high-energy physics" because many elementary particles do not occur naturally but are created only during high-energy collisions of other particles.
Currently, the interactions of elementary particles and fields are described by the Standard Model. The model accounts for the 12 known particles of matter (quarks and leptons) that interact via the strong, weak, and electromagnetic fundamental forces. Dynamics are described in terms of matter particles exchanging gauge bosons (gluons, W and Z bosons, and photons, respectively). The Standard Model also predicts a particle known as the Higgs boson. In July 2012 CERN, the European laboratory for particle physics, announced the detection of a particle consistent with the Higgs boson, an integral part of a Higgs mechanism.
Nuclear physics is the field of physics that studies the constituents and interactions of atomic nuclei. The most commonly known applications of nuclear physics are nuclear power generation and nuclear weapons technology, but the research has provided application in many fields, including those in nuclear medicine and magnetic resonance imaging, ion implantation in materials engineering, and radiocarbon dating in geology and archaeology.
Astrophysics.
Astrophysics and astronomy are the application of the theories and methods of physics to the study of stellar structure, stellar evolution, the origin of the solar system, and related problems of cosmology. Because astrophysics is a broad subject, astrophysicists typically apply many disciplines of physics, including mechanics, electromagnetism, statistical mechanics, thermodynamics, quantum mechanics, relativity, nuclear and particle physics, and atomic and molecular physics.
The discovery by Karl Jansky in 1931 that radio signals were emitted by celestial bodies initiated the science of radio astronomy. Most recently, the frontiers of astronomy have been expanded by space exploration. Perturbations and interference from the earth's atmosphere make space-based observations necessary for infrared, ultraviolet, gamma-ray, and X-ray astronomy.
Physical cosmology is the study of the formation and evolution of the universe on its largest scales. Albert Einstein's theory of relativity plays a central role in all modern cosmological theories. In the early 20th century, Hubble's discovery that the universe is expanding, as shown by the Hubble diagram, prompted rival explanations known as the steady state universe and the Big Bang.
The Big Bang was confirmed by the success of Big Bang nucleosynthesis and the discovery of the cosmic microwave background in 1964. The Big Bang model rests on two theoretical pillars: Albert Einstein's general relativity and the cosmological principle. Cosmologists have recently established the ΛCDM model of the evolution of the universe, which includes cosmic inflation, dark energy, and dark matter.
Numerous possibilities and discoveries are anticipated to emerge from new data from the Fermi Gamma-ray Space Telescope over the upcoming decade and vastly revise or clarify existing models of the universe. In particular, the potential for a tremendous discovery surrounding dark matter is possible over the next several years. Fermi will search for evidence that dark matter is composed of weakly interacting massive particles, complementing similar experiments with the Large Hadron Collider and other underground detectors.
IBEX is already yielding new astrophysical discoveries: "No one knows what is creating the ENA (energetic neutral atoms) ribbon" along the termination shock of the solar wind, "but everyone agrees that it means the textbook picture of the heliosphere — in which the solar system's enveloping pocket filled with the solar wind's charged particles is plowing through the onrushing 'galactic wind' of the interstellar medium in the shape of a comet — is wrong."
Current research.
Research in physics is continually progressing on a large number of fronts.
In condensed matter physics, an important unsolved theoretical problem is that of high-temperature superconductivity. Many condensed matter experiments are aiming to fabricate workable spintronics and quantum computers.
In particle physics, the first pieces of experimental evidence for physics beyond the Standard Model have begun to appear. Foremost among these are indications that neutrinos have non-zero mass. These experimental results appear to have solved the long-standing solar neutrino problem, and the physics of massive neutrinos remains an area of active theoretical and experimental research. Particle accelerators have begun probing energy scales in the TeV range, in which experimentalists are hoping to find evidence for the Higgs boson and supersymmetric particles.
Theoretical attempts to unify quantum mechanics and general relativity into a single theory of quantum gravity, a program ongoing for over half a century, have not yet been decisively resolved. The current leading candidates are M-theory, superstring theory and loop quantum gravity.
Many astronomical and cosmological phenomena have yet to be satisfactorily explained, including the existence of ultra-high energy cosmic rays, the baryon asymmetry, the acceleration of the universe and the anomalous rotation rates of galaxies.
Although much progress has been made in high-energy, quantum, and astronomical physics, many everyday phenomena involving complexity, chaos, or turbulence are still poorly understood. Complex problems that seem like they could be solved by a clever application of dynamics and mechanics remain unsolved; examples include the formation of sandpiles, nodes in trickling water, the shape of water droplets, mechanisms of surface tension catastrophes, and self-sorting in shaken heterogeneous collections.
These complex phenomena have received growing attention since the 1970s for several reasons, including the availability of modern mathematical methods and computers, which enabled complex systems to be modeled in new ways. Complex physics has become part of increasingly interdisciplinary research, as exemplified by the study of turbulence in aerodynamics and the observation of pattern formation in biological systems. In 1932, Horace Lamb said:
I am an old man now, and when I die and go to heaven there are two matters on which I hope for enlightenment. One is quantum electrodynamics, and the other is the turbulent motion of fluids. And about the former I am rather optimistic.—Horace Lamb, Annual Reviews in Fluid Mechanics
External links.
General
Organizations

</doc>
<doc id="22943" url="http://en.wikipedia.org/wiki?curid=22943" title="Papua New Guinea">
Papua New Guinea

Papua New Guinea (PNG; ; Tok Pisin: "Papua Niugini"; Hiri Motu: "Papua Niu Gini"), officially the Independent State of Papua New Guinea, is an Oceanian country that occupies the eastern half of the island of New Guinea and its offshore islands in Melanesia, a region of the southwestern Pacific Ocean north of Australia. Its capital, located along its southeastern coast, is Port Moresby. The western half of New Guinea forms the Indonesian provinces of Papua and West Papua.
Papua New Guinea is one of the most culturally diverse countries in the world; 848 languages are listed for the country, of which 12 have no known living speakers. Most of the population of over 7 million people live in customary communities, which are as diverse as the languages. It is also one of the most rural, as only 18 per cent of its people live in urban centres. The country is one of the world's least explored, culturally and geographically, and many undiscovered species of plants and animals are thought to exist in the interior.
Strong growth in Papua New Guinea's mining and resource sector has led to the country becoming the sixth fastest-growing economy in the world as of 2011. Many people in the country live in extreme poverty when measured in terms of money, with about one-third of the population living on less than US$1.25 per day.
At the local level, the majority of the population still live in strong customary societies and - while social life is overlaid with traditional religious cosmologies and modern practices, including conventional primary education - customary subsistence-based agriculture remains fundamental. These societies and clans are explicitly acknowledged within the nation's constitutional framework. The Papua New Guinea Constitution expresses the wish for "traditional villages and communities to remain as viable units of Papua New Guinean society" and for active steps to be taken in their continuing importance to local and national community life.
At the national level, after being ruled by three external powers since 1884, Papua New Guinea established its sovereignty in 1975 following 70 years of Australian administration. It became a separate Commonwealth realm with Queen Elizabeth II as its head of state and became a member of the Commonwealth of Nations in its own right.
History.
Humans first arrived in Papua New Guinea around 42,000 – 45,000 years BP.
Agriculture was independently developed in the New Guinea highlands around 7000 BC, making it one of the few areas in the world where people independently domesticated plants. A major migration of Austronesian speaking peoples to coastal regions of New Guinea took place around 500 BC. This has been correlated with the introduction of pottery, pigs, and certain fishing techniques. 
More recently, in the 18th century, the sweet potato was brought to New Guinea, having been introduced to the Moluccas by Portuguese traders, who obtained it from South America. The far higher crop yields from sweet potato gardens radically transformed traditional agriculture; sweet potato largely supplanted the previous staple, taro, and gave rise to a significant increase in population in the highlands.
Although headhunting and cannibalism have been practically eradicated, in the past they were practised in many parts of the country as part of rituals related to warfare and taking in enemy spirits or powers. For example, in 1901, on Goaribari Island in the Gulf of Papua, a missionary, Harry Dauncey, found 10,000 skulls in the island's Long Houses. According to the writer Marianna Torgovnick, "The most fully documented instances of cannibalism as a social institution come from New Guinea, where head-hunting and ritual cannibalism survived, in certain isolated areas, into the Fifties, Sixties, and Seventies, and still leave traces within certain social groups."
Little was known in Europe about the island until the 19th century, although Portuguese and Spanish explorers, such as Dom Jorge de Meneses and Yñigo Ortiz de Retez, had encountered it as early as the 16th century. Traders from Southeast Asia had visited New Guinea beginning 5,000 years ago to collect bird of paradise plumes. The country's dual name results from its complex administrative history before independence. The word "papua" is derived from an old local term of uncertain origin. "New Guinea" ("Nueva Guinea") was the name coined by the Spanish explorer Yñigo Ortiz de Retez. In 1545, he noted the resemblance of the people to those he had earlier seen along the Guinea coast of Africa. Guinea, on its turn, is etymologically derived from Portuguese word "Guiné".
In the nineteenth century, Germany ruled the northern half of the country as a colony for some decades, beginning in 1884, as German New Guinea. The southern half was colonised in the same year by the United Kingdom as British New Guinea. In 1904 with the passage of the Papua Act, 1905, it transferred this territory to the newly formed Commonwealth of Australia, which took on its administration. Additionally, from 1905, British New Guinea was renamed the Territory of Papua.
During World War I, German New Guinea was occupied by Australia, which after the war was given a League of Nations Mandate to administer it. Papua, by contrast, was deemed to be an External Territory of the Australian Commonwealth, though as a matter of law it remained a British possession. This was significant for the country's post-independence legal system. The difference in legal status meant that up, until 1949, Papua and New Guinea had entirely separate administrations, both controlled by Australia.
The New Guinea campaign (1942–1945) was one of the major military campaigns of World War II. Approximately 216,000 Japanese, Australian, and US servicemen died. After World War II, the two territories were combined into the Territory of Papua and New Guinea, which later was simply referred to as "Papua New Guinea".
However, certain statutes continued to have application only in one of the two territories. This territorial difference of law was complicated further by the adjustment of the former boundary among contiguous provinces with respect to road access and language groups. Some of the statutes apply only on one side of a boundary that no longer exists.
The natives of Papua appealed to the United Nations for oversight and independence. The nation established independence from Australia on 16 September 1975, and maintains close ties. (Australia continues as the largest aid donor to Papua New Guinea). Papua New Guinea was admitted to membership in the United Nations on 10 October 1975.
A secessionist revolt in 1975–76 on Bougainville Island resulted in an eleventh-hour modification of the draft Constitution of Papua New Guinea to allow for Bougainville and the other eighteen districts to have quasi-federal status as provinces. A renewed uprising started in 1988 and claimed 20,000 lives until it was resolved in 1997. Following the revolt, the autonomous Bougainville elected Joseph Kabui as president in 2005 and he served until 2008. He was succeeded by his deputy John Tabinaman, who continued to be re-elected as leader until the election of December 2008, which James Tanis won.
Anti-Chinese rioting involving tens of thousands of people broke out in May 2009. The initial spark was a fight between Chinese and Papua New Guinean workers at a nickel factory under construction by a Chinese company. Native resentment against Chinese ownership of numerous small businesses and their commercial success led to the rioting. The Chinese have traditionally been merchants in Papua New Guinea.
Politics.
Papua New Guinea is a Commonwealth realm; as such Queen Elizabeth II acts as its Sovereign and Head of State. It was expected by the constitutional convention, which prepared the draft constitution, and by Australia, the outgoing metropolitan power, that Papua New Guinea would choose not to retain its link with the monarchy. The founders, however, considered that imperial honours had a cachet that the newly independent state would not be able to confer with a purely indigenous honours system, so the monarchy was retained. The Queen is represented by the Governor-General of Papua New Guinea, currently Sir Michael Ogio. Papua New Guinea and the Solomon Islands are unusual among Commonwealth realms in that Governors-General are elected by the legislature rather than appointment by the executive branch.
Actual executive power lies with the Prime Minister, who heads the cabinet of 31 MPs from the ruling Coalition, which make up the government. The current Prime Minister is Peter O'Neill. The unicameral National Parliament has 111 seats, of which 22 are occupied by the governors of the 21 provinces (2 new ones were approved by Parliament in 2012) and the National Capital District (NCD). Candidates for members of parliament are voted upon when the prime minister asks the Governor-General to call a national election, a maximum of five years after the previous national election.
In the early years of independence, the instability of the party system led to frequent votes of no confidence in Parliament with resulting changes of the government of the day, but with referral to the electorate, through national elections only occurring every five years. In recent years, successive governments have passed legislation preventing such votes sooner than 18 months after a national election and within 12-month of the next election, and in December 2012 the first 2 (of 3) readings were passed to prevent votes of no confidence occurring within the first 30 months. This restriction on votes of no confidence has arguably resulted in greater stability, although perhaps at a cost of reducing the accountability of the executive branch of government.
Elections in PNG attract large numbers of candidates. After independence in 1975, members were elected by the first past the post system, with winners frequently gaining less than 15% of the vote. Electoral reforms in 2001 introduced the Limited Preferential Vote system (LPV), a version of the Alternative Vote. The 2007 general election was the first to be conducted using LPV.
In foreign policy, Papua New Guinea is a member of the Commonwealth of Nations, Pacific Islands Forum and the Melanesian Spearhead Group (MSG) of countries and was accorded Observer status within ASEAN in 1976, followed later by Special Observer status in 1981. It is also a member of APEC and an ACP country, associated with the European Union.
Since August 2011, there was a political crisis between the parliament-elect Prime Minister, Peter O'Neill (voted into office by a large majority of MPs) and Sir Michael Somare, who was deemed by the Supreme Court (in a December Opinion, 3:2) to retain office. The stand-off between Parliament and the Supreme Court continued until the July 2012 National Elections, with legislation passed effectively removing the Chief Justice and subjecting the Supreme Court members to greater control by the Legislature, as well as a series of other laws passed, for example limiting the age for a Prime Minister. The confrontation reached a peak, with the Deputy Prime Minister entering the Supreme Court, during a hearing, escorted by some police, ostensibly to 'arrest' the Chief Justice. There was strong pressure amongst some MPs to defer the National Elections for a further six months-1-year, although their powers to do that were highly questionable. The Parliament-elect 'Prime Minister' and other cooler-headed MPs carried the votes for the writs for the new Election to be issued, slightly late, but for the Election itself to occur on time, thereby avoiding a continuation of the constitutional crisis. The crisis was tense at times, but largely restricted to the political and legal fraternity, plus some police factions, but the public and public service (including most police and military) standing back. It was a period when, with increased telecommunication access and use of social media (notably Facebook and mobile phones) the public and students played some part in helping maintain restraint and demanding the leadership to adhere to constitutional processes and not to defer the elections and the people's say in who should be their legitimate representatives for the next five years.
Under an amendment of 2002, the leader of the party winning the largest number of seats in the Election is invited by the Governor-General to form the Government, if he can muster the necessary majority in Parliament. The process of forming such a coalition in PNG, where there is little ideologically binding parties together, involves considerable horsetrading right up until the last moment. Peter O'Neil emerged as Papua New Guinea's Prime Minister after the July 2012 Election, and formed a Government with the former Governor of East New Britain Province, Leon Dion as Deputy Prime Minister.
Law.
The unicameral Parliament enacts legislation in the same manner as in other jurisdictions that have "cabinet," "responsible government," or "parliamentary democracy": it is introduced by the executive government to the legislature, debated and, if passed, becomes law when it receives royal assent by the Governor-General. Most legislation is actually regulation implemented by the bureaucracy under enabling legislation previously passed by Parliament.
All ordinary statutes enacted by Parliament must be consistent with the Constitution. The courts have jurisdiction to rule on the constitutionality of statutes, both in disputes before them and on a reference where there is no dispute but only an abstract question of law. Unusual among developing countries, the judicial branch of government in Papua New Guinea has remained remarkably independent, and successive executive governments have continued to respect its authority.
The "underlying law" (Papua New Guinea's common law) consists of principles and rules of common law and equity in England common law as it stood on 16 September 1975 (the date of Independence), and thereafter the decisions of PNG's own courts. The courts are directed by the Constitution and, latterly, the "Underlying Law Act", to take note of the "custom" of traditional communities, with a view to determining which customs are common to the whole country and may be declared also to be part of the underlying law. In practice, this has proved extremely difficult and has been largely neglected. Statutes are largely adapted from overseas jurisdictions, primarily Australia and England. Advocacy in the courts follows the adversarial pattern of other common law countries.
This national court system used in towns and cities is supported by a village court system in the more remote areas. The law underpinning the village courts is 'customary law' and these courts are discussed further on the Law of Papua New Guinea page.
Human rights.
Papua New Guinea is often labelled as potentially the worst place in the world for gender violence. A 2013 study in "The Lancet" found that 41% of men on Bougainville Island, Papua New Guinea, reported having raped a non-partner while 14.1% reported having committed gang rape. According to UNICEF, nearly half of reported rape victims are under 15 years of age and 13% are under 7 years of age while a report by ChildFund Australia citing former Parliamentarian Dame Carol Kidu claimed 50% of those seeking medical help after rape are under 16, 25% are under 10 and 10% are under 8.
Administrative divisions.
Papua New Guinea is divided into four regions, which are not the primary administrative divisions but are quite significant in many aspects of government, commercial, sporting and other activities.
The nation has 22 province-level divisions: twenty provinces, the Autonomous Region of Bougainville and the National Capital District. Each province is divided into one or more districts, which in turn are divided into one or more Local Level Government areas.
Provinces are the primary administrative divisions of the country. Provincial governments are branches of the national government – Papua New Guinea is not a federation of provinces. The province-level divisions are as follows:
In 2009, Parliament approved the creation of two additional provinces: Hela Province, consisting of part of the existing Southern Highlands Province, and Jiwaka Province, formed by dividing Western Highlands Province. Jiwaka and Hela officially became separate provinces on 17 May 2012.
Geography.
At 462840 km2, Papua New Guinea is the world's fifty-fourth largest country. Including all its islands, it lies between latitudes 0° and 12°S, and longitudes 140° and 160°E.
The country's geography is diverse and, in places, extremely rugged. A spine of mountains, the New Guinea Highlands, runs the length of the island of New Guinea, forming a populous highlands region mostly covered with tropical rainforest, and the long Papuan Peninsula, known as the 'Bird's Tail'. Dense rainforests can be found in the lowland and coastal areas as well as very large wetland areas surrounding the Sepik and Fly rivers. This terrain has made it difficult for the country to develop transportation infrastructure. Some areas are accessible only on foot or by aeroplane. The highest peak is Mount Wilhelm at 4509 m. Papua New Guinea is surrounded by coral reefs which are under close watch, in the interests of preservation.
The country is situated on the Pacific Ring of Fire, at the point of collision of several tectonic plates. There are a number of active volcanoes, and eruptions are frequent. Earthquakes are relatively common, sometimes accompanied by tsunamis.
The mainland of the country is the eastern half of New Guinea island, where the largest towns are also located, including Port Moresby (capital) and Lae; other major islands within Papua New Guinea include New Ireland, New Britain, Manus and Bougainville.
Papua New Guinea is one of the few regions close to the equator that experience snowfall, which occurs in the most elevated parts of the mainland.
Ecology.
Papua New Guinea is part of the Australasia ecozone, which also includes Australia, New Zealand, eastern Indonesia, and several Pacific island groups, including the Solomon Islands and Vanuatu.
Geologically, the island of New Guinea is a northern extension of the Indo-Australian tectonic plate, forming part of a single land mass which is Australia-New Guinea (also called "Sahul" or "Meganesia"). It is connected to the Australian segment by a shallow continental shelf across the Torres Strait, which in former ages had lain exposed as a land bridge, particularly during ice ages when sea levels were lower than at present.
Consequently, many species of birds and mammals found on New Guinea have close genetic links with corresponding species found in Australia. One notable feature in common for the two landmasses is the existence of several species of marsupial mammals, including some kangaroos and possums, which are not found elsewhere.
Many of the other islands within PNG territory, including New Britain, New Ireland, Bougainville, the Admiralty Islands, the Trobriand Islands, and the Louisiade Archipelago, were never linked to New Guinea by land bridges. As a consequence, they have their own flora and fauna; in particular, they lack many of the land mammals and flightless birds that are common to New Guinea and Australia.
Australia and New Guinea are portions of the ancient supercontinent of Gondwana, which started to break into smaller continents in the Cretaceous era, 66–130 million years ago. Australia finally broke free from Antarctica about 45 million years ago. All the Australasian lands are home to the Antarctic flora, descended from the flora of southern Gondwana, including the coniferous podocarps and "Araucaria" pines, and the broadleafed southern beech ("Nothofagus"). These plant families are still present in Papua New Guinea.
As the Indo-Australian Plate (which includes landmasses of India, Australia, and the Indian Ocean floor in between) drifts north, it collides with the Eurasian Plate. The collision of the two plates pushed up the Himalayas, the Indonesian islands, and New Guinea's Central Range. The Central Range is much younger and higher than the mountains of Australia, so high that it is home to rare equatorial glaciers. New Guinea is part of the humid tropics, and many Indomalayan rainforest plants spread across the narrow straits from Asia, mixing together with the old Australian and Antarctic floras.
PNG includes a number of terrestrial ecoregions:
At current rates of deforestation, more than half of the country's forests could be lost or seriously degraded by 2021, according to a new satellite study of the region. Nearly one-quarter of Papua New Guinea's rainforests were damaged or destroyed between 1972 and 2002.
Three new species of mammals were discovered in the forests of Papua New Guinea by an Australian lead expedition. A small wallaby, a large eared mouse and shrew like marsupial were discovered. The expedition was also successful in capturing photographs and video footage of some other rare animals such as the Tenkile tree kangaroo and the Weimang tree kangaroo.
Economy.
Papua New Guinea is richly endowed with natural resources, including mineral and renewable resources, such as forests, marine (including a large portion of the world's major tuna stocks), and in some parts agriculture. The rugged terrain — including high mountain ranges and valleys, swamps and islands — and high cost of developing infrastructure, combined with other factors (including serious law and order problems in some centres and the system of customary land title) makes it difficult for outside developers. Local developers are handicapped by years of deficient investment in education, health, ICT and access to finance. Agriculture, for subsistence and cash crops, provides a livelihood for 85% of the population and continues to provide some 30% of GDP. Mineral deposits, including gold, oil, and copper, account for 72% of export earnings. Oil palm production has grown steadily over recent years (largely from estates and with extensive outgrower output), with palm oil now the main agricultural export. In households participating, coffee remains the major export crop (produced largely in the Highlands provinces), followed by cocoa and coconut oil/copra from the coastal areas, each largely produced by smallholders and tea, produced on estates and rubber. The Iagifu/Hedinia Field was discovered in 1986 in the Papuan fold and thrust belt.:471
Former Prime Minister Sir Mekere Morauta tried to restore integrity to state institutions, stabilise the kina, restore stability to the national budget, privatise public enterprises where appropriate, and ensure ongoing peace on Bougainville following the 1997 agreement which ended Bougainville's secessionist unrest. The Morauta government had considerable success in attracting international support, specifically gaining the backing of the IMF and the World Bank in securing development assistance loans. Significant challenges face Prime Minister Sir Michael Somare, including gaining further investor confidence, continuing efforts to privatise government assets, and maintaining the support of members of Parliament.
In March 2006, the United Nations Development Programme Policy called for Papua New Guinea's designation of developing country to be downgraded to least-developed country because of protracted economic and social stagnation. However, an evaluation by the International Monetary Fund in late 2008 found that "a combination of prudent fiscal and monetary policies, and high global prices for mineral commodity exports, have underpinned Papua New Guinea's recent buoyant economic growth and macroeconomic stability. By 2012 PNG had enjoyed a decade of positive economic growth, at over 6% since 2007, even during the Global Financial Crisis years of 2008/9. PNG's Real GDP growth rate as at 2011 was 8.9%., and 9.2% for 2012, according to the Asian Development Bank. This economic growth has been primarily attributed to strong commodity prices, particularly mineral but also agricultural, with the high demand for mineral products largely sustained even during the crisis by the buoyant Asian markets a booming mining sector, and particularly since 2009 by a buoyant outlook and the construction phase for natural gas exploration, production, and exportation in liquefied form (Liquefied Natural Gas or "LNG") by LNG tankers (LNG carrier), all of which will require multi-billion-dollar investments (exploration, production wells, pipelines, storage, liquefaction plants, port terminals, LNG tanker ships).
The first major gas project is the PNG LNG project of a consortium led by ExxonMobil, scheduled to commence production in late 2014, for export largely to China, Japan, South Korea and other Asian countries. This ExxonMobil-led consortium includes a PNG company named Oil Search, based in Port Moresby, which has a 29% share.
A second major project is based on initial rights held by the French oil and gas major Total S.A. and the US company InterOil Corp. (IOC), which have partly combined their assets after Total agreed in December 2013 to purchase 61.3% of IOC's Antelope and Elk gas fields rights, with the plan to develop them starting in 2016, including the construction of a liquefaction plant to allow export of LNG. Total S.A. has separately another joint operating agreement with the PNG company Oil Search.
The Anglo-Dutch major Royal Dutch Shell has indicated in 2011 that it is considering the possibility of investing in gas exploration and production in Papua New Guinea.
Further gas and mineral projects are proposed (including the large Wafi-Golpu copper-gold mine), with extensive exploration ongoing across the country.
Economic 'development' based on the extractive industries carries difficult consequences for local communities. There has been much contention around river tailings in the vast Fly River, submarine tailings from the new Ramu-Nickel-cobalt mine, commencing exports in late 2012 (after a delay from landowner-led court challenges), and from proposed submarine mining in the Bismarck Sea (by Nautilus Minerals). One major project conducted through the PNG Department for Community Development suggested that other pathways to sustainable development should be considered.
The PNG government's long-term Vision 2050 and shorter-term policy documents, including the 2013 Budget and the 2014 Responsible Sustainable Development Strategy, emphasise the need for a more diverse economy, based upon sustainable industries and avoiding the effects of Dutch Disease from major resource extraction projects undermining other industries, as has occurred in many countries experiencing oil or other mineral booms, notably in Western Africa, undermining much of their agriculture sector, manufacturing and tourism, and with them broad-based employment prospects. Measures have been taken to mitigate these effects, including through the establishment of a sovereign wealth fund, partly to stabilise revenue and expenditure flows, but much will depend upon the readiness to make real reforms to effective use of revenue, tackling rampant corruption and empowering households and businesses to access markets, services and develop a more buoyant economy, with lower costs, especially for small- to medium-size enterprises.
The Institute of National Affairs, a PNG independent policy think tank, provides a report on the business and investment environment of Papua New Guinea every five years, based upon a survey of large and small, local and overseas companies, highlighting law and order problems and corruption, as the worst impediments, followed by the poor state of transport, power and communications infrastructure.
Land tenure.
The PNG legislature has enacted laws in which a type of tenure called "customary land title" is recognised, meaning that the traditional lands of the indigenous peoples have some legal basis to inalienable tenure. This customary land notionally covers most of the usable land in the country (some 97% of total land area); alienated land is either held privately under state lease or is government land. Freehold title (also known as fee simple) can only be held by Papua New Guinean citizens.
Only some 3% of the land of Papua New Guinea is in private hands; it is privately held under 99-year state lease, or it is held by the State. There is virtually no freehold title; the few existing freeholds are automatically converted to state lease when they are transferred between vendor and purchaser. Unalienated land is owned under customary title by traditional landowners. The precise nature of the seisin varies from one culture to another. Many writers portray land as in the communal ownership of traditional clans; however, closer studies usually show that the smallest portions of land whose ownership cannot be further divided are held by the individual heads of extended families and their descendants or their descendants alone if they have recently died.
This is a matter of vital importance because a problem of economic development is identifying the membership of customary landowning groups and the owners. Disputes between mining and forestry companies and landowner groups often devolve on the issue of whether the companies entered into contractual relations for the use of land with the true owners. Customary property — usually land — cannot be devised by will. It can only be inherited according to the custom of the deceased's people. The Lands Act was amended in 2010 along with the Land Group Incorporation Act, intended to improve the management of state land, mechanisms for dispute resolution over land, and to enable customary landowners to be better able to access finance and possible partnerships over portions of their land, if they seek to develop it for urban or rural economic activities. The Land Group Incorporation Act requires more specific identification of the customary landowners than hitherto and their more specific authorisation before any land arrangements are determined; (a major issue in recent years has been a land grab, using, or rather misusing, the Lease-Leaseback provision under the Land Act, notably using 'Special Agricultural and Business Leases' (SABLs) to acquire vast tracts of customary land, purportedly for agricultural projects, but in an almost all cases as a back-door mechanism for securing tropical forest resources for logging — circumventing the more exacting requirements of the Forest Act, for securing Timber Permits (which must comply with sustainability requirements and be competitively secured, and with the customary landowners approval). Following a national outcry, these SABLs have been subject to a Commission of Inquiry, established in mid-2011, for which the report is still awaited for initial presentation to the Prime Minister and Parliament.
Demographics.
Papua New Guinea is one of the most heterogeneous nations in the world. There are hundreds of ethnic groups indigenous to Papua New Guinea, the majority being from the group known as Papuans, whose ancestors arrived in the New Guinea region tens of thousands of years ago. The other indigenous peoples are Austronesians, their ancestors having arrived in the region less than four thousand years ago. 
There are also numerous people from other parts of the world now resident, including Chinese, Europeans, Australians, Filipinos, Polynesians, and Micronesians (the last three belonging to the Austronesian family). Around 40,000 expatriates, mostly from Australia and China, were living in Papua New Guinea in 1975.
Papua New Guinea has more languages than any other country, with over 820 indigenous languages, representing 12% of the world's total, but most have fewer than 1,000 speakers. The most widely spoken indigenous language is Enga, with about 200,000 speakers, followed by Melpa and Huli. Indigenous languages are classified into two large groups, Austronesian languages and non-Austronesian, or Papuan, languages. There are three official languages for Papua New Guinea: English, Tok Pisin, and Hiri Motu.
English is the language of government and the education system, but it is not spoken widely.
The primary lingua franca of the country is Tok Pisin (commonly known in English as New Guinean Pidgin or Melanesian Pidgin), in which much of the debate in Parliament is conducted, many information campaigns and advertisements are presented, and until recently a national newspaper, "Wantok", was published. The only area where Tok Pisin is not prevalent is the southern region of Papua, where people often use the third official language, Hiri Motu.
Although it lies in the Papua region, Port Moresby has a highly diverse population which primarily uses Tok Pisin, and to a lesser extent English, with Motu spoken as the indigenous language in outlying villages. With an average of only 7,000 speakers per language, Papua New Guinea has a greater density of languages than any other nation on earth except Vanuatu.
Health.
Public expenditure was at 7.3% of all government expenditure in 2006, whereas private expenditure was at 0.6% of the GDP. There were five physicians per 100,000 people in the early 2000s. Malaria is the leading cause of illness and death in New Guinea. In 2003, the most recently reported year, 70,226 cases of laboratory confirmed malaria were reported, along with 537 deaths. A total of 1,729,697 cases were probable.
Papua New Guinea has the highest incidence of HIV and AIDS in the Pacific region and is the fourth country in the Asia Pacific region to fit the criteria for a generalised HIV/AIDS epidemic. Lack of HIV/AIDS awareness is a major problem, especially in rural areas.
In June 2011, the United Nations Population Fund released a report on "The State of the World's Midwifery". It contained new data on the midwifery workforce and policies relating to newborn and maternal mortality for 58 countries. The 2010 maternal mortality rate per 100,000 births for Papua New Guinea is 250. This is compared with 311.9 in 2008 and 476.3 in 1990. The under 5 mortality rate, per 1,000 births is 69 and the neonatal mortality as a percentage of under 5's mortality is 37. The aim of this report is to highlight ways in which the Millennium Development Goals can be achieved, particularly Goal 4 – Reduce child mortality and Goal 5 – Improve maternal health. In Papua New Guinea the number of midwives per 1,000 live births is 1 and the lifetime risk of death for pregnant women is 1 in 94.
Religion.
The courts and government practice uphold the constitutional right to freedom of speech, thought, and belief, and no legislation to curb those rights has been adopted. The 2000 census found that 96% of citizens identified themselves as members of a Christian church; however, many citizens combine their Christian faith with some traditional indigenous religious practices. The census percentages were as follows:
There are also approximately 4,000 Muslims in the country. Majority belong to the Sunni group, while a small number are Ahmadi. Non-traditional Christian churches and non-Christian religious groups are active throughout the country. The Papua New Guinea Council of Churches has stated that both Muslim and Confucian missionaries are active, and foreign missionary activity in general is high.
Traditional religions were often animist. Some also tended to have elements of Veneration of the dead, though generalisation is suspect given the extreme heterogeneity of Melanesian societies. Prevalent among traditional tribes is the belief in "masalai", or evil spirits, which are blamed for "poisoning" people, causing calamity and death, and the practice of puripuri (sorcery).
Culture.
It is estimated that more than a thousand cultural groups exist in Papua New Guinea. Because of this diversity, many styles of cultural expression have emerged; each group has created its own expressive forms in art, dance, weaponry, costumes, singing, music, architecture and much more.
Most of these cultural groups have their own language. People typically live in villages that rely on subsistence farming. In some areas people hunt and collect wild plants (such as yam roots) to supplement their diets. Those who become skilled at hunting, farming and fishing earn a great deal of respect.
On the Sepik river, there is a tradition of wood carving, often in the form of plants or animals, representing ancestor spirits.
Sea shells are no longer the currency of Papua New Guinea, as they were in some regions — sea shells were abolished as currency in 1933. However, this tradition is still present in local customs; in some cultures, to get a bride, a groom must bring a certain number of golden-edged clam shells as a bride price. In other regions, the bride price is paid in lengths of shell money, pigs, cassowaries or cash. Elsewhere, it is brides who traditionally pay a dowry.
People of the highlands engage in colourful local rituals that are called "sing sings". They paint themselves and dress up with feathers, pearls and animal skins to represent birds, trees or mountain spirits. Sometimes an important event, such as a legendary battle, is enacted at such a musical festival.
Sport.
Sport is an important part of Papua New Guinean culture and rugby league is by far the most popular sport. In a nation where communities are far apart and many people live at a minimal subsistence level, rugby league has been described as a replacement for tribal warfare as a way of explaining the local enthusiasm for the game (a matter of life and death). Many Papua New Guineans have become instant celebrities by representing their country or playing in an overseas professional league. Even Australian rugby league players who have played in the annual State of Origin series, which is celebrated feverishly every year in PNG, are among the most well known people throughout the nation.
State of Origin is a highlight of the year for most Papua New Guineans, although the support is so passionate that many people have died over the years in violent clashes supporting their team. The Papua New Guinea national rugby league team usually plays against the Australian Prime Minister's XIII (a selection of NRL players) each year, normally in Port Moresby.
Other major sports which have a part in the Papua New Guinea sporting landscape are Australian rules football, Association football, rugby union and, in eastern Papua, cricket.
The capital city, Port Moresby will be hosting the Pacific Games in 2015.
Cuisine.
The cuisine of Papua New Guinea is very varied, and usually features locally abundant fruit and vegetables along with rice, fish and seafood. Due to the country's colonial history, it's heavily influenced by European, Chinese and Indonesian cooking. The staple dish is sago, a powdery starch made from the sago palm that is highly versatile and is often served alongside cooked seafood, meats and greens.
Education.
A large proportion of the population is illiterate, with women predominating in this area. Much of the education in the country is provided by church institutions. This includes 500 schools of the Evangelical Lutheran Church of Papua New Guinea.
Papua New Guinea has six universities apart from other major tertiary institutions. The two founding universities are the University of Papua New Guinea based in the National Capital District, and the Papua New Guinea University of Technology based outside of Lae, in Morobe Province.
The four other universities which were once colleges were established recently after gaining government recognition. These are the University of Goroka in the Eastern Highlands province, Divine Word University (run by the Catholic Church's Divine Word Missionaries) in Madang Province, Vudal University in East New Britain Province and Pacific Adventist University (run by the Seventh-day Adventist Church) in the National Capital District.
Transport.
Transport in Papua New Guinea is heavily limited by the country's mountainous terrain. Port Moresby is not linked by road to any of the other major towns, and many remote villages can only be reached by light aircraft or on foot. As a result, air travel is the single most important form of transport for human and high value freight. In addition to two international airfields, Papua New Guinea has 578 airstrips, most of which are unpaved. Assets are not maintained to good operating standards and poor transport remains a major impediment to the development of ties of national unity.
Air travel.
Air travel is the single most important form of transport in Papua New Guinea, for the transport of humans and high density/value freight. Airplanes made it possible to open up the country during its early colonial period. Even today the two largest cities, Port Moresby and Lae, are only directly connected by planes.
Jacksons International Airport is the major international airport in Papua New Guinea, located 5 miles from Port Moresby.
See also.
Lists
References.
External links.
Government
General information

</doc>
<doc id="22946" url="http://en.wikipedia.org/wiki?curid=22946" title="List of painters by name">
List of painters by name

The following list of painters by name includes over 3,100 painters from all ages and parts of the world.
 

</doc>
<doc id="22948" url="http://en.wikipedia.org/wiki?curid=22948" title="Poseidon">
Poseidon

Poseidon (; Greek: Ποσειδῶν, ]) is one of the twelve Olympian deities of the pantheon in Greek mythology. His main domain is the ocean, and he is called the "God of the Sea". Additionally, he is referred to as "Earth-Shaker" due to his role in causing earthquakes, and has been called the "tamer of horses". He is usually depicted as an older male with curly hair and beard.
The name of the sea-god Nethuns in Etruscan was adopted in Latin for Neptune in Roman mythology; both were sea gods analogous to Poseidon. Linear B tablets show that Poseidon was venerated at Pylos and Thebes in pre-Olympian Bronze Age Greece as a chief deity, but he was integrated into the Olympian gods as the brother of Zeus and Hades. According to some folklore, he was saved by his mother Rhea, who concealed him among a flock of lambs and pretended to have given birth to a colt, which was devoured by Cronos.
There is a Homeric hymn to Poseidon, who was the protector of many Hellenic cities, although he lost the contest for Athens to Athena. According to the references from Plato in his dialogues "Timaeus" and "Critias", the island of Atlantis was the chosen domain of Poseidon.
Etymology.
The earliest attested occurrence of the name, written in Linear B, is 𐀡𐀮𐀆𐀃 "Po-se-da-o" or 𐀡𐀮𐀆𐀺𐀚 "Po-se-da-wo-ne", which correspond to "Poseidaōn" and "Poseidawonos" in Mycenean Greek; in Homeric Greek it appears as Ποσειδάων ("Poseidaōn"); in Aeolic as Ποτειδάων ("Poteidaōn"); and in Doric as Ποτειδάν ("Poteidan"), Ποτειδάων ("Poteidaōn"), and Ποτειδᾶς ("Poteidas"). A common epithet of Poseidon is Γαιήοχος "Gaiēochos", "Earth-shaker," an epithet which is also identified in Linear B tablets. Another attested word 𐀁𐀚𐀯𐀅𐀃𐀚, "E-ne-si-da-o-ne", recalls his later epithets "Ennosidas" and "Ennosigaios" indicating the chthonic nature of Poseidon.
The origins of the name "Poseidon" are unclear. One theory breaks it down into an element meaning "husband" or "lord" (Greek πόσις ("posis"), from PIE "*pótis") and another element meaning "earth" (δᾶ ("da"), Doric for γῆ ("gē")), producing something like lord or spouse of "Da", i.e. of the earth; this would link him with Demeter, "Earth-mother." Walter Burkert finds that "the second element "da-" remains hopelessly ambiguous" and finds a "husband of Earth" reading "quite impossible to prove."
Another theory interprets the second element as related to the word *δᾶϝον "dâwon", "water"; this would make *"Posei-dawōn" into the master of waters. There is also the possibility that the word has Pre-Greek origin. Plato in his dialogue Cratylus gives two alternative etymologies: either the sea restrained Poseidon when walking as a "foot-bond" (ποσίδεσμον), or he "knew many things" (πολλά εἰδότος or πολλά εἰδῶν).
Bronze Age Greece.
If surviving Linear B clay tablets can be trusted, the name "po-se-da-wo-ne" ("Poseidon") occurs with greater frequency than does "di-u-ja" ("Zeus"). A feminine variant, "po-se-de-ia", is also found, indicating a lost consort goddess, in effect a precursor of Amphitrite.
Poseidon carries frequently the title "wa-na-ka" ( wanax) in Linear B inscriptions, as king of the underworld. The chthonic nature of Poseidon-Wanax is also indicated by his title "E-ne-si-da-o-ne" in Mycenean Knossos and Pylos, a powerful attribute (earthquakes had accompanied the collapse of the Minoan palace-culture). In the cave of Amnisos (Crete) "Enesidaon" is related with the cult of Eileithyia, the goddess of childbirth. 
Tablets from Pylos record sacrificial goods destined for "the Two Queens and Poseidon" ("to the Two Queens and the King": "wa-na-soi", "wa-na-ka-te"). The "Two Queens" may be related with Demeter and Persephone, or their precursors, goddesses who were not associated with Poseidon in later periods. The illuminating exception is the archaic and localised myth of the stallion Poseidon and mare Demeter at Phigalia in isolated and conservative Arcadia, noted by Pausanias (2nd century AD) as having fallen into desuetude; the violated Demeter was "Demeter Erinys".
It is possible that Demeter appears as "Da-ma-te" in a Linear B (Mycenean Greek) inscription (PN EN 609), however the interpretetion is still under dispute In Linear B inscriptions found at Pylos, "E-ne-si-da-o-ne" is related with Poseidon, and "Si-to Po-tini-ja" is probably related with Demeter.
In the heavily sea-dependent Mycenaean culture, no connection between Poseidon and the sea has yet surfaced. Homer and Hesiod suggest that Poseidon became lord of the sea following the defeat of his father Kronos, when the world was divided by lot among his three sons; Zeus was given the sky, Hades the underworld, and Poseidon the sea, with the Earth and Mount Olympus belonging to all three.
Given Poseidon's connection with horses as well as the sea, and the landlocked situation of the likely Indo-European homeland, Nobuo Komita has proposed that Poseidon was originally an aristocratic Indo-European horse-god who was then assimilated to Near Eastern aquatic deities when the basis of the Greek livelihood shifted from the land to the sea, or a god of fresh waters who was assigned a secondary role as god of the sea, where he overwhelmed the original Aegean sea deities such as Proteus and Nereus. Conversely, Walter Burkert suggests that the Hellene cult worship of Poseidon as a horse god may be connected to the introduction of the horse and war-chariot from Anatolia to Greece around 1600 BC.
In any case, the early importance of Poseidon can still be glimpsed in Homer's Odyssey, where Poseidon rather than Zeus is the major mover of events.
Worship of Poseidon.
Poseidon was a major civic god of several cities: in Athens, he was second only to Athena in importance, while in Corinth and many cities of Magna Graecia he was the chief god of the polis.
In his benign aspect, Poseidon was seen as creating new islands and offering calm seas. When offended or ignored, he supposedly struck the ground with his trident and caused chaotic springs, earthquakes, drownings and shipwrecks. Sailors prayed to Poseidon for a safe voyage, sometimes drowning horses as a sacrifice; in this way, according to a fragmentary papyrus, Alexander the Great paused at the Syrian seashore before the climactic battle of Issus, and resorted to prayers, "invoking Poseidon the sea-god, for whom he ordered a four-horse chariot to be cast into the waves."
According to Pausanias, Poseidon was one of the caretakers of the oracle at Delphi before Olympian Apollo took it over. Apollo and Poseidon worked closely in many realms: in colonization, for example, Delphic Apollo provided the authorization to go out and settle, while Poseidon watched over the colonists on their way, and provided the lustral water for the foundation-sacrifice. Xenophon's "Anabasis" describes a group of Spartan soldiers in 400–399 BC singing to Poseidon a paean—a kind of hymn normally sung for Apollo.
Like Dionysus, who inflamed the maenads, Poseidon also caused certain forms of mental disturbance. A Hippocratic text of ca 400 BC, "On the Sacred Disease" says that he was blamed for certain types of epilepsy.
Epithets.
Poseidon was known in various guises, denoted by epithets. In the town of Aegae in Euboea, he was known as "Poseidon Aegaeus" and had a magnificent temple upon a hill. Poseidon also had a close association with horses, known under the epithet "Poseidon Hippios". He is more often regarded as the tamer of horses, but in some myths he is their father, either by spilling his seed upon a rock or by mating with a creature who then gave birth to the first horse.
In the historical period, Poseidon was often referred to by the epithets "Enosichthon", "Seisichthon" and "Ennosigaios", all meaning "earth-shaker" and referring to his role in causing earthquakes.
Poseidon in mythology.
Birth.
Poseidon was the second son of Cronus and Rhea. In most accounts he is swallowed by Cronus at birth but later saved, with his other brothers and sisters, by Zeus.
However in some versions of the story, he, like his brother Zeus, did not share the fate of his other brother and sisters who were eaten by Cronus. He was saved by his mother Rhea, who concealed him among a flock of lambs and pretended to have given birth to a colt, which she gave to Cronus to devour.
According to John Tzetzes the "kourotrophos", or nurse of Poseidon was Arne, who denied knowing where he was, when Cronus came searching; according to Diodorus Siculus Poseidon was raised by the Telchines on Rhodes, just as Zeus was raised by the Korybantes on Crete.
According to a single reference in the "Iliad", when the world was divided by lot in three, Zeus received the sky, Hades the underworld and Poseidon the sea. In the "Odyssey" (v.398), Poseidon has a home in "Aegae".
The foundation of Athens.
Athena became the patron goddess of the city of Athens after a competition with Poseidon. Yet Poseidon remained a numinous presence on the Acropolis in the form of his surrogate, Erechtheus. At the dissolution festival at the end of the year in the Athenian calendar, the Skira, the priests of Athena and the priest of Poseidon would process under canopies to Eleusis. They agreed that each would give the Athenians one gift and the Athenians would choose whichever gift they preferred. Poseidon struck the ground with his trident and a spring sprang up; the water was salty and not very useful, whereas Athena offered them an olive tree.
The Athenians or their king, Cecrops, accepted the olive tree and along with it Athena as their patron, for the olive tree brought wood, oil and food. After the fight, infuriated at his loss, Poseidon sent a monstrous flood to the Attic Plain, to punish the Athenians for not choosing him. The depression made by Poseidon's trident and filled with salt water was surrounded by the northern hall of the Erechtheum, remaining open to the air. "In cult, Poseidon was identified with Erechtheus," Walter Burkert noted; "the myth turns this into a temporal-causal sequence: in his anger at losing, Poseidon led his son Eumolpus against Athens and killed Erectheus."
The contest of Athena and Poseidon was the subject of the reliefs on the western pediment of the Parthenon, the first sight that greeted the arriving visitor.
This myth is construed by Robert Graves and others as reflecting a clash between the inhabitants during Mycenaean times and newer immigrants.
It is interesting to note that Athens at its height was a significant sea power, at one point defeating the Persian fleet at Salamis Island in a sea battle.
The walls of Troy.
Poseidon and Apollo, having offended Zeus by their rebellion in Hera's scheme, were temporarily stripped of their divine authority and sent to serve King Laomedon of Troy. He had them build huge walls around the city and promised to reward them well, a promise he then refused to fulfill. In vengeance, before the Trojan War, Poseidon sent a sea monster to attack Troy. The monster was later killed by Heracles.
Consorts and children.
Poseidon was said to have had many lovers of both sexes (see expandable list below). His consort was Amphitrite, a nymph and ancient sea-goddess, daughter of Nereus and Doris.
Poseidon was the father of many heroes. He is thought to have fathered the famed Theseus.
A mortal woman named Tyro was married to Cretheus (with whom she had one son, Aeson) but loved Enipeus, a river god. She pursued Enipeus, who refused her advances. One day, Poseidon, filled with lust for Tyro, disguised himself as Enipeus, and from their union were born the heroes Pelias and Neleus, twin boys. Poseidon also had an affair with Alope, his granddaughter through Cercyon, his son and King of Eleusis, begetting the Attic hero Hippothoon. Cercyon had his daughter buried alive but Poseidon turned her into the spring, Alope, near Eleusis.
Poseidon rescued Amymone from a lecherous satyr and then fathered a child, Nauplius, by her.
After having raped Caeneus, Poseidon fulfilled her request and changed her into a male warrior.
A mortal woman named Cleito once lived on an isolated island; Poseidon fell in love with the human mortal and created a dwelling sanctuary at the top of a hill near the middle of the island and surrounded the dwelling with rings of water and land to protect her. She gave birth to five sets of twin boys(the firstborn who being named Atlas) became the first rulers of Atlantis.
Not all of Poseidon's children were human. In an archaic myth, Poseidon once pursued Demeter. She spurned his advances, turning herself into a mare so that she could hide in a herd of horses; he saw through the deception and became a stallion and captured her. Their child was a horse, Arion, which was capable of human speech. Poseidon also had sexual intercourse with Medusa on the floor of a temple to Athena.
Medusa was then changed into a monster by Athena. When she was later beheaded by the hero Perseus, Chrysaor and Pegasus emerged from her neck. There is also Triton (the merman), Polyphemus (the cyclops) and, finally, Alebion and Bergion and Otos and Ephialtae (the giants).
List of Poseidon's consorts and children.
Female lovers and offspring.
In Plato's myth of Atlantis, Poseidon consorted with Cleito, daughter of the autochthons Evenor and Leucippe, and had by her ten sons: Ampheres, Atlas, Autochthon, Azaes, Diaprepes, Elasippus, Euaemon, Eumelus (Gadeirus), Mestor, Mneseus.
Poseidon in literature and art.
In Greek art, Poseidon rides a chariot that was pulled by a hippocampus or by horses that could ride on the sea. He was associated with dolphins and three-pronged fish spears (tridents). He lived in a palace on the ocean floor, made of coral and gems.
In the "Iliad" Poseidon favors the Greeks, and on several occasion takes an active part in the battle against the Trojan forces. However, in Book XX he rescues Aeneas after the Trojan prince is laid low by Achilles.
In the "Odyssey", Poseidon is notable for his hatred of Odysseus who blinded the god's son, the cyclops Polyphemus. The enmity of Poseidon prevents Odysseus's return home to Ithaca for many years. Odysseus is even told, notwithstanding his ultimate safe return, that to placate the wrath of Poseidon will require one more voyage on his part.
In the "Aeneid", Neptune is still resentful of the wandering Trojans, but is not as vindictive as Juno, and in Book I he rescues the Trojan fleet from the goddess's attempts to wreck it, although his primary motivation for doing this is his annoyance at Juno's having intruded into his domain.
A hymn to Poseidon included among the Homeric Hymns is a brief invocation, a seven-line introduction that addresses the god as both "mover of the earth and barren sea, god of the deep who is also lord of Helicon and wide Aegae, and specificies his twofold nature as an Olympian: "a tamer of horses and a saviour of ships."
Poseidon appears in Percy Jackson and the Olympians as the father of Percy Jackson and Tyson the Cyclops.
Poseidon appears in the ABC television series "Once Upon a Time" as the guest star of the second half of season four played by Ernie Hudson. In this version, Poseidon is the father of the Sea Witch Ursula.

</doc>
<doc id="22949" url="http://en.wikipedia.org/wiki?curid=22949" title="Population">
Population

A population is a summation of all the organisms of the same group or species, which live in a particular geographical area, and have the capability of interbreeding.
In ecology, the population of a certain species in a certain area is estimated using the Lincoln Index. The area that is used to define a sexual population is defined as the area where inter-breeding is potentially possible between any pair within the area. The probability of interbreeding is greater than the probability of cross-breeding with individuals from other areas. Under normal conditions, breeding is substantially more common within the area than across the border.
In sociology, population refers to a collection of humans. Demography is a social science which entails the statistical study of human populations. This article refers mainly to human population.
Population genetics (ecology).
In population genetics a sexual population is a set of organisms in which any pair of members can breed together. This means that they can regularly exchange gametes to produce normally-fertile offspring, and such a breeding group is also known therefore as a "gamodeme". This also implies that all members belong to the same of species, such as humans.
If the gamodeme is very large (theoretically, approaching infinity), and all gene alleles are uniformly distributed by the gametes within it, the gamodeme is said to be panmictic. Under this state, allele (gamete) frequencies can be converted to genotype (zygote) frequencies by expanding an appropriate quadratic equation, as shown by Sir Ronald Fisher in his establishment of quantitative genetics.
This seldom occurs in nature : localisation of gamete exchange – through dispersal limitations, or preferential mating, or cataclysm, or other cause – may lead to small actual gamodemes which exchange gametes reasonably uniformly within themselves, but are virtually separated from their neighbouring gamodemes. However, there may be low frequencies of exchange with these neighbours. This may be viewed as the breaking up of a large sexual population(panmictic)into smaller overlapping sexual populations. This failure of panmixia leads to two important changes in overall population structure: (1).the component gamodemes vary (through gamete sampling) in their allele frequencies when compared with each other and with the theoretical panmictic original (this is known as "dispersion", and its details can be estimated using expansion of an appropriate binomial equation); and (2). the level of homozygosity rises in the entire collection of gamodemes. The overall rise in homozygosity is quantified by the "inbreeding coefficient" ("f" or "φ"). Note that "all homozygotes" are increased in frequency – both the deleterious and the desirable! The mean phenotype of the gamodemes collection is lower than that of the panmictic "original" – which is known as "inbreeding depression". It is most important to note, however, that some dispersion lines will be superior to the panmictic original, while some will be about the same, and some will be inferior. The probabilities of each can be estimated from those binomial equations. In plant and animal breeding, procedures have been developed which deliberately utilise the effects of dispersion (such as line breeding, pure-line breeding, back-crossing). It can be shown that "dispersion-assisted selection" leads to the greatest "genetic advance" ("ΔG" = change in the phenotypic mean), and is much more powerful than selection acting without attendant dispersion. This is so for both allogamous (random fertilization)
and autogamous (self-fertilization) gamodemes
World human population.
As of today's date, the world population is estimated by the United States Census Bureau to be billion./7185 million The US Census Bureau estimates the 7 US billion/7000 million number was surpassed on 12 March 2012. According to a separate estimate by the United Nations, Earth’s population exceeded seven US billion in October 2011, a milestone that offers unprecedented challenges and opportunities to all of humanity, according to UNFPA, the United Nations Population Fund.
According to papers published by the United States Census Bureau,the world population hit 6.5 US billion/6500 million on 24 February 2006. The United Nations Population Fund designated 12 October 1999 as the approximate day on which world population reached 6 US billion/6000 million. This was about 12 years after world population reached 5 US billion/5000 million in 1987, and 6 years after world population reached 5.5 US billion/5500 million in 1993. The population of some countries, such as Nigeria, is not even known to the nearest million, so there is a considerable margin of error in such estimates.
Researcher Carl Haub calculated that a total of over 100 US billion/100 000 million people have probably been born in the last 2000 years.
Predicted growth and decline.
Population growth increased significantly as the Industrial Revolution gathered pace from 1700 onwards. The last 50 years have seen a yet more rapid increase in the rate of population growth due to medical advances and substantial increases in agricultural productivity, particularly beginning in the 1960s, made by the Green Revolution. In 2007 the United Nations Population Division projected that the world's population will likely surpass 10 billion in 2055.
In the future, the world's population is expected to peak, after which it will decline due to economic reasons, health concerns, land exhaustion and environmental hazards. According to one report, it is very likely that the world's population will stop growing before the end of the 21st century. Further, there is some likelihood that population will actually decline before 2100. Population has already declined in the last decade or two in Eastern Europe, the Baltics and in the Commonwealth of Independent States.
The population pattern of less-developed regions of the world in recent years has been marked by gradually declining birth rates. These followed an earlier sharp reduction in death rates. This transition from high birth and death rates to low birth and death rates is often referred to as the demographic transition.
Control.
Human population control is the practice of artificially altering the rate of growth of a human population. Historically, human population control has been implemented with the goal of increasing the rate of population growth. In the period from the 1950s to the 1980s, concerns about global population growth and its effects on poverty, environmental degradation and political stability led to efforts to reduce population growth rates. While population control can involve measures that improve people's lives by giving them greater control of their reproduction, a few programmes, most notably the Chinese government's one-child per family policy, have resorted to coercive measures.
In the 1980s, tension grew between population control advocates and women's health activists who advanced women's reproductive rights as part of a human rights-based approach. Growing opposition to the narrow population control focus led to a significant change in population control policies in the early 1990s.

</doc>
<doc id="22951" url="http://en.wikipedia.org/wiki?curid=22951" title="Psychological egoism">
Psychological egoism

Psychological egoism is the view that humans are always motivated by self-interest, even in what seem to be acts of altruism. It claims that, when people choose to help others, they do so ultimately because of the personal benefits that they themselves expect to obtain, directly or indirectly, from doing so. This is a descriptive rather than normative view, since it only makes claims about how things are, not how they ought to be. It is, however, related to several other normative forms of egoism, such as ethical egoism and rational egoism.
A specific form of psychological egoism is psychological hedonism, the view that the ultimate motive for all voluntary human action is the desire to experience pleasure or to avoid pain. Many discussions of psychological egoism focus on this type, but the two are not the same: theorists have explained behavior motivated by self-interest without using pleasure and pain as the final causes of behavior. Psychological hedonism argues actions are caused by both a need for pleasure immediately and in the future. However, immediate gratification can be sacrificed for a chance of greater, future pleasure. Further, humans are not motivated to strictly avoid pain and only pursue pleasure, but, instead, humans will endure pain to achieve the greatest net pleasure. Accordingly, all actions are tools for increasing pleasure or decreasing pain, even those defined as altruistic and those that do not cause an immediate change in satisfaction levels.
Foundations.
Beginning with ancient philosophy, Epicureanism claims humans live to maximize pleasure. Epicurus argued the theory of human behavior being motivated by pleasure alone is evidenced from infancy to adulthood. Humanity performs altruistic, honorable, and virtuous acts not for the sake of another or because of a moral code but rather to increase the well being of the self.
In modern philosophy, Jeremy Bentham asserted, like Epicurus, that human behavior is governed by a need to increase pleasure and decrease pain. Bentham explicitly described what types and qualities of pain and pleasure exist, and how human motives are singularly explained using psychological hedonism. Bentham attempted to quantify psychological hedonism. Bentham endeavored to find the ideal human behavior based on hedonic calculus or the measurement of relative gains and losses in pain and pleasure to determine the most pleasurable action a human could choose in a situation.
From an evolutionary perspective, Herbert Spencer, a psychological egoist, argued that humans and animals primarily seek to survive and protect their lineage. Essentially, the need for the individual and for the individual's immediate family to live supersedes the others' need to live. All species attempt to maximize their own chances of survival and, therefore, well being. Spencer asserted the best adapted creatures will have their pleasure levels outweigh their pain levels in their environments. Thus, pleasure meant an animal or human was fulfilling its egoist goal of self survival, and pleasure would always be pursued because species constantly strive for survival.
Contributions to modern psychology.
Psychoanalysis.
Although Sigmund Freud was not a psychological egoist, his concept of the pleasure principle borrowed much from psychological egoism and psychological hedonism in particular. The pleasure principle rules the behavior of the Id which is an unconscious force driving humans to release tension from unfulfilled desires. When Freud introduced Thanatos and its opposing force, Eros, the pleasure principle emanating from psychological hedonism became aligned with the Eros, which drives a person to satiate sexual and reproductive desires. Alternatively, Thanatos seeks the cessation of pain through death and the end of the pursuit of pleasure: thus a hedonism rules Thanatos, but it centers on the complete avoidance of pain rather than psychological hedonist function which pursues pleasure and avoids pain. Therefore, Freud believed in qualitatively different hedonisms where the total avoidance of pain hedonism and the achievement of the greatest net pleasure hedonism are separate and associated with distinct functions and drives of the human psyche. Although Eros and Thanatos are ruled by qualitatively different types of hedonism, Eros remains under the rule of Jeremy Bentham's quantitative psychological hedonism because Eros seeks the greatest net pleasure.
Behaviorism.
Traditional behaviorism dictates all human behavior is explained by classical conditioning and operant conditioning. Operant conditioning works through reinforcement and punishment which adds or removes pleasure and pain to manipulate behavior. Using pleasure and pain to control behavior means behaviorists assumed the principles of psychological hedonism could be applied to predicting human behavior. For example, Thorndike's law of effect states that behaviors associated with pleasantness will be learned and those associated with pain will be extinguished. Often, behaviorist experiments using humans and animals are built around the assumption that subjects will pursue pleasure and avoid pain. Although psychological hedonism is incorporated into the fundamental principles and experimental designs of behaviorism, behaviorism itself explains and interprets only observable behavior and therefore does not theorize about the ultimate cause of human behavior. Thus, behaviorism uses but does not strictly support psychological hedonism over other understandings of the ultimate drive of human behavior.
The debate.
Psychological egoism is controversial. Proponents cite evidence from introspection: reflection on one's own actions may reveal their motives and intended results to be based on self-interest. Psychological egoists and hedonists have found through numerous observations of natural human behavior that behavior can be manipulated through reward and punishment both of which have direct effects of pain and pleasure. Also, the work of some social scientists has empirically supported this theory. Further, they claim psychological egoism posits a theory that is a more parsimonious explanation than competing theories.
Opponents have argued that psychological egoism is not more parsimonious than other theories. For example, a theory that claims altruism occurs for the sake of altruism explains altruism with less complexity than the egoistic approach. The psychological egoist asserts humans act altruistically for selfish reasons even when cost of the altruistic action is far outweighed by the reward of acting selfishly because altruism is performed to fulfill the desire of a person to act altruistically. Other critics argue that it is false either because it is an over-simplified interpretation of behavior or that there exists empirical evidence of altruistic behaviour. Recently, some have argued that evolutionary theory provides evidence against it.
Critics have stated that proponents of psychological egoism often confuse the satisfaction of their own desires with the satisfaction of their own "self-regarding" desires. Even though it is true that every human being seeks his own satisfaction, this sometimes may only be achieved via the well-being of his neighbor. An example of this situation could be phoning for an ambulance when a car accident has happened. In this case, the caller desires the well-being of the victim, even though the desire itself is the caller's own.
To counter this critique, psychological egoism asserts that all such desires for the well being of others are ultimately derived from self-interest. For example, German philosopher Friedrich Nietzsche was a psychological egoist for some of his career, though he is said to have repudiated that later in his campaign against morality. He argues in §133 of "The Dawn", that in such cases compassionate impulses arise out of the projection of our identity unto the object of our feeling. He gives some hypothetical examples as illustrations to his thesis: that of a person, feeling horrified after witnessing a personal feud, coughing blood, or that of the impulse felt to save a person who is drowning in the water. In such cases, according to Nietzsche, there comes into play unconscious fears regarding our own safety. The suffering of another person is felt as a threat to our own happiness and sense of safety, because it reveals our own vulnerability to misfortunes, and thus, by relieving it, one could also ameliorate those personal sentiments. Essentially, proponents argue that altruism is rooted in self-interest whereas opponents claim altruism occurs for altruism's sake or is caused by a non-selfish reason.
The problem of apparent altruism.
David Hume once wrote, "What interest can a fond mother have in view, who loses her health by assiduous attendance on her sick child, and afterwards languishes and dies of grief, when freed, by its death [the child's], from the slavery of that attendance?". It seems incorrect to describe such a mother's goal as self-interested.
Psychological egoists, however, respond that helping others in such ways is ultimately motivated by some form of self-interest, such as non-sensory satisfaction, the expectation of reciprocation, the desire to gain respect or reputation, or by the expectation of a reward in a putative afterlife. The helpful action is merely instrumental to these ultimately selfish goals.
In the ninth century, "Mohammed Ibn Al-Jahm Al-Barmaki محمد بن الجـَهْم البَرمَكي" has been quoted saying:
"No one deserves thanks from another about something he has done for him or goodness he has done, he is either willing to get a reward from God, therefore he wanted to serve himself, or he wanted to get a reward from people, therefore, he has done that to get profit for himself, or to be mentioned and praised by people, therefore, to it is also for himself, or due to his mercy and tenderheartedness, so he has simply done that goodness to pacify these feelings and treat himself."
This sort of explanation appears to be close to the view of La Rochefoucauld (and perhaps Hobbes).
According to psychological hedonism, the ultimate egoistic motive is to gain good feelings of pleasure and avoid bad feelings of pain. Other, less restricted forms of psychological egoism may allow the ultimate goal of a person to include such things as avoiding punishments from oneself or others (such as guilt or shame) and attaining rewards (such as pride, self-worth, power or reciprocal beneficial action).
Some psychologists explain empathy in terms of psychological hedonism. According to the "merge with others hypothesis," empathy increases the more an individual feels like they are one with another person, and decreases as the oneness decreases. Therefore, altruistic actions emanating from empathy and empathy itself are caused by making others' interests our own, and the satisfaction of their desires becomes our own, not just theirs. Both cognitive studies and neuropsychological experiments have provided evidence for this theory: as humans increase our oneness with others our empathy increases, and as empathy increases our inclination to act altruistically increases. Neuropsychological studies have linked mirror neurons to humans experiencing empathy. Mirror neurons are activated both when a human (or animal) performs an action and when they observe another human (or animal) performs the same action. Researchers have found that the more these mirror neurons fire the more human subjects report empathy. From a neurological perspective, scientists argue that when a human empathizes with another, the brain operates as if the human is actually participating in the actions of the other person. Thus, when performing altruistic actions motivated by empathy, humans experience someone else's pleasure of being helped. Therefore, in performing acts of altruism, people act in their own self interests even at a neurological level.
Criticisms.
Explanatory power.
Even accepting the theory of universal positivity, it is difficult to explain, for example, the actions of a soldier who sacrifices his life by jumping on a grenade in order to save his comrades. In this case, there is simply no time to experience positivity toward one's actions, although a psychological egoist may argue that the soldier experiences moral positivity in knowing that he is sacrificing his life to ensure the survival of his comrades, or that he is avoiding negativity associated with the thought of all his comrades dying. Psychological egoists argue that although some actions may not clearly cause physical nor social positivity, nor avoid negativity, one's current contemplation or reactionary mental expectation of these is the main factor of the decision. When a dog is first taught to sit, it is given a biscuit. This is repeated until, finally, the dog sits without requiring a biscuit. Psychological egoists could claim that such actions which do not 'directly' result in positivity, or reward, are not dissimilar from the actions of the dog. In this case, the action (sitting on command) will have become a force of habit, and breaking such a habit would result in mental discomfort. This basic theory of conditioning behavior, applied to other seemingly ineffective positive actions, can be used to explain moral responses that are instantaneous and instinctive such as the soldier jumping on the grenade.
Circularity.
Psychological egoism has been accused of being circular: "If a person willingly performs an act, that means he derives personal enjoyment from it; therefore, people only perform acts that give them personal enjoyment." In particular, seemingly altruistic acts must be performed because people derive enjoyment from them and are therefore, in reality, egoistic. This statement is circular because its conclusion is identical to its hypothesis: it assumes that people only perform acts that give them personal enjoyment, and concludes that people only perform acts that give them personal enjoyment. This objection was tendered by William Hazlitt and Thomas Macaulay in the 19th century, and has been restated many times since. An earlier version of the same objection was made by Joseph Butler in 1726.
Joel Feinberg, in his 1958 paper "Psychological Egoism", embraces a similar critique by drawing attention to the infinite regress of psychological egoism. He expounds it in the following cross-examination:

</doc>
<doc id="22954" url="http://en.wikipedia.org/wiki?curid=22954" title="Plato">
Plato

Plato (; Greek: Πλάτων "Plátōn" "broad"] in Classical Attic; 428/427 or 424/423 – 348/347 BCE) was a philosopher, as well as mathematician, in Classical Greece. He is considered an essential figure in the development of philosophy, especially the Western tradition, and he founded the Academy in Athens, the first institution of higher learning in the Western world. Along with his teacher Socrates and his most famous student, Aristotle, Plato laid the foundations of Western philosophy and science. Alfred North Whitehead once noted: "the safest general characterization of the European philosophical tradition is that it consists of a series of footnotes to Plato."
Plato's dialogues have been used to teach a range of subjects, including philosophy, logic, ethics, rhetoric, religion and mathematics. His lasting themes include Platonic love, the theory of forms, the five regimes, innate knowledge, among others. His theory of forms launched a unique perspective on abstract objects, and led to a school of thought called Platonism. Plato's writings have been published in several fashions; this has led to several conventions regarding the naming and referencing of Plato's texts.
Biography.
Early life.
Little can be known about Plato's early life and education, due to very few accounts. The philosopher came from one of the wealthiest and most politically active families in Athens. Ancient sources describe him as a bright though modest boy who excelled in his studies. His father contributed all which was necessary to give to his son a good education, and, therefore, Plato must have been instructed in grammar, music, gymnastics and philosophy by some of the most distinguished teachers of his era.
Birth and family.
The exact time and place of Plato's birth are not known, but it is certain that he belonged to an aristocratic and influential family. Based on ancient sources, most modern scholars believe that he was born in Athens or Aegina[c] between 429 and 423 BCE.[a] His father was Ariston. According to a disputed tradition, reported by Diogenes Laertius, Ariston traced his descent from the king of Athens, Codrus, and the king of Messenia, Melanthus. Plato's mother was Perictione, whose family boasted of a relationship with the famous Athenian lawmaker and lyric poet Solon. Perictione was sister of Charmides and niece of Critias, both prominent figures of the Thirty Tyrants, the brief oligarchic regime, which followed on the collapse of Athens at the end of the Peloponnesian War (404–403 BCE). Besides Plato himself, Ariston and Perictione had three other children; these were two sons, Adeimantus and Glaucon, and a daughter Potone, the mother of Speusippus (the nephew and successor of Plato as head of his philosophical Academy). The brothers Adeimantus and Glaucon are mentioned in the "Republic" as sons of Ariston, and presumably brothers of Plato, but some have argued they were uncles. But in a scenario in the Memorabilia, Xenophon confused the issue by presenting a Glaucon much younger than Plato.
The traditional date of Plato's birth (428/427) is based on a dubious interpretation of Diogenes Laertius, who says, "When [Socrates] was gone, [Plato] joined Cratylus the Heracleitean and Hermogenes, who philosophized in the manner of Parmenides. Then, at twenty-eight, Hermodorus says, [Plato] went to Euclides in Megara." As Debra Nails argues, "The text itself gives no reason to infer that Plato left immediately for Megara and implies the very opposite." In his Seventh Letter, Plato notes that his coming of age coincided with the taking of power by the Thirty, remarking, "But a youth under the age of twenty made himself a laughingstock if he attempted to enter the political arena." Thus, Nails dates Plato's birth to 424/423.
According to some accounts, Ariston tried to force his attentions on Perictione, but failed in his purpose; then the god Apollo appeared to him in a vision, and as a result, Ariston left Perictione unmolested. Another legend related that, when Plato was an infant, bees settled on his lips while he was sleeping: an augury of the sweetness of style in which he would discourse about philosophy.
Ariston appears to have died in Plato's childhood, although the precise dating of his death is difficult. Perictione then married Pyrilampes, her mother's brother, who had served many times as an ambassador to the Persian court and was a friend of Pericles, the leader of the democratic faction in Athens. Pyrilampes had a son from a previous marriage, Demus, who was famous for his beauty. Perictione gave birth to Pyrilampes' second son, Antiphon, the half-brother of Plato, who appears in "Parmenides".
In contrast to reticence about himself, Plato often introduced his distinguished relatives into his dialogues, or referred to them with some precision: Charmides has a dialogue named after him; Critias speaks in both "Charmides" and "Protagoras"; and Adeimantus and Glaucon take prominent parts in the "Republic". These and other references suggest a considerable amount of family pride and enable us to reconstruct Plato's family tree. According to Burnet, "the opening scene of the "Charmides" is a glorification of the whole [family] connection ... Plato's dialogues are not only a memorial to Socrates, but also the happier days of his own family."
Name.
According to Diogenes Laërtius, the philosopher was named "Aristocles" (Ἀριστοκλῆς) after his grandfather. It was common in Athenian society for boys to be named after grandfathers (or fathers). But there is only one inscriptional record of an Aristocles, an early Archon of Athens in 605/4 BCE. There no record of a line from Aristocles to Plato's father, Ariston. However, if Plato was not named after an ancestor named Plato (there is no record of one), then the origin of his renaming as "Plato" becomes a conundrum. 
The sources of Diogenes account for this fact by claiming that his wrestling coach, Ariston of Argos, dubbed him "Platon", meaning "broad," on account of his robust figure or that Plato derived his name from the breadth (πλατύτης, "platytēs") of his eloquence, or else because he was very wide (πλατύς, "platýs") across the forehead. Recently a scholar has argued that even the name Aristocles for Plato was a much later invention. Although "Plato" was a fairly common name, (31 instances are known from Athens alone), the name does not occur in Plato's known family line. The fact that the philosopher in his maturity called himself "Plato" is indisputable, but the origin of this naming must remain moot unless the record is made to yield more information.
Education.
Apuleius informs us that Speusippus praised Plato's quickness of mind and modesty as a boy, and the "first fruits of his youth infused with hard work and love of study". Plato must have been instructed in grammar, music, and gymnastics by the most distinguished teachers of his time. Dicaearchus went so far as to say that Plato wrestled at the Isthmian games. Plato had also attended courses of philosophy; before meeting Socrates, he first became acquainted with Cratylus (a disciple of Heraclitus, a prominent pre-Socratic Greek philosopher) and the Heraclitean doctrines. W. A. Borody argues that an Athenian openness towards a wider range of sexuality may have contributed to the Athenian philosophers' openness towards a wider range of thought, a cultural situation Borody describes as "polymorphously discursive."
Plato and Pythagoras.
Although Socrates influenced Plato directly as related in the dialogues, the influence of Pythagoras upon Plato also appears to have significant discussion in the philosophical literature. Pythagoras, or in a broader sense, the Pythagoreans, allegedly exercised an important influence on the work of Plato. According to R. M. Hare, this influence consists of three points: (1) The platonic Republic might be related to the idea of "a tightly organized community of like-minded thinkers", like the one established by Pythagoras in Croton. (2) There is evidence that Plato possibly took from Pythagoras the idea that mathematics and, generally speaking, abstract thinking is a secure basis for philosophical thinking as well as "for substantial theses in science and morals". (3) Plato and Pythagoras shared a "mystical approach to the soul and its place in the material world". It is probable that both were influenced by Orphism.
Aristotle claimed that the philosophy of Plato closely followed the teachings of the Pythagoreans, and Cicero repeats this claim: "Platonem ferunt didicisse Pythagorea omnia" ("They say Plato learned all things Pythagorean"). Bertrand Russell, in his "A History of Western Philosophy", contended that the influence of Pythagoras on Plato and others was so great that he should be considered the most influential of all Western philosophers.
Plato and Socrates.
The precise relationship between Plato and Socrates remains an area of contention among scholars. Plato makes it clear in his "Apology of Socrates", that he was a devoted young follower of Socrates. In that dialogue, Socrates is presented as mentioning Plato by name as one of those youths close enough to him to have been corrupted, if he were in fact guilty of corrupting the youth, and questioning why their fathers and brothers did not step forward to testify against him if he was indeed guilty of such a crime (33d-34a). Later, Plato is mentioned along with Crito, Critobolus, and Apollodorus as offering to pay a fine of 30 minas on Socrates' behalf, in lieu of the death penalty proposed by Meletus (38b). In the "Phaedo", the title character lists those who were in attendance at the prison on Socrates' last day, explaining Plato's absence by saying, "Plato was ill." ("Phaedo" 59b)
Plato never speaks in his own voice in his dialogues. In the "Second Letter", it says, "no writing of Plato exists or ever will exist, but those now said to be his are those of a Socrates become beautiful and new" (341c); if the Letter is Plato's, the final qualification seems to call into question the dialogues' historical fidelity. In any case, Xenophon and Aristophanes seem to present a somewhat different portrait of Socrates from the one Plato paints. Some have called attention to the problem of taking Plato's Socrates to be his mouthpiece, given Socrates' reputation for irony and the dramatic nature of the dialogue form.
Aristotle attributes a different doctrine with respect to the Ideas to Plato and Socrates ("Metaphysics" 987b1–11). Putting it in a nutshell, Aristotle merely suggests that Socrates' idea of forms can be discovered through investigation of the natural world, unlike Plato's Forms that exist beyond and outside the ordinary range of human understanding.
Later life.
Plato may have traveled in Italy, Sicily, Egypt and Cyrene, Libya. Said to have returned to Athens at the age of forty, Plato founded one of the earliest known organized schools in Western Civilization on a plot of land in the Grove of Hecademus or Academus. The Academy was a large enclosure of ground about six stadia outside of Athens proper. One story is that the name of the Academy comes from the ancient hero, Academus. Another story is that the name came from a supposed a former owner, a citizen of Athens also named Academus. Yet another account is that it was named after a member of the army of Castor and Pollux, an Arcadian named Echedemus. The Academy operated until it was destroyed by Lucius Cornelius Sulla in 84 BCE. Neoplatonists revived the Academy in the early 5th century, and it operated until AD 529, when it was closed by Justinian I of Byzantium, who saw it as a threat to the propagation of Christianity. Many intellectuals were schooled in the Academy, the most prominent one being Aristotle.
Throughout his later life, Plato became entangled with the politics of the city of Syracuse. According to Diogenes Laertius, Plato initially visited Syracuse while it was under the rule of Dionysius. During this first trip Dionysius's brother-in-law, Dion of Syracuse, became one of Plato's disciples, but the tyrant himself turned against Plato. Plato almost faced death, but he was sold into slavery, then Anniceris bought Plato's freedom for twenty minas, and sent him home. After Dionysius's death, according to Plato's "Seventh Letter", Dion requested Plato return to Syracuse to tutor Dionysius II and guide him to become a philosopher king. Dionysius II seemed to accept Plato's teachings, but he became suspicious of Dion, his uncle. Dionysius expelled Dion and kept Plato against his will. Eventually Plato left Syracuse. Dion would return to overthrow Dionysius and ruled Syracuse for a short time before being usurped by Calippus, a fellow disciple of Plato.
Death.
A variety of sources have given accounts of Plato's death. One story, based on a mutilated manuscript, suggests Plato died in his bed, whilst a young Thracian girl played the flute to him. Another tradition suggests Plato died at a wedding feast. The account is based on Diogenes Laertius's reference to an account by Hermippus, a third-century Alexandrian. According to Tertullian, Plato simply died in his sleep.
Philosophy.
Recurrent themes.
Plato often discusses the father-son relationship and the question of whether a father's interest in his sons has much to do with how well his sons turn out. In ancient Athens, a boy was socially located by his family identity, and Plato often refers to his characters in terms of their paternal and fraternal relationships. Socrates was not a family man, and saw himself as the son of his mother, who was apparently a midwife. A divine fatalist, Socrates mocks men who spent exorbitant fees on tutors and trainers for their sons, and repeatedly ventures the idea that good character is a gift from the gods. Crito reminds Socrates that orphans are at the mercy of chance, but Socrates is unconcerned. In the "Theaetetus", he is found recruiting as a disciple a young man whose inheritance has been squandered. Socrates twice compares the relationship of the older man and his boy lover to the father-son relationship ("Lysis" 213a, "Republic" 3.403b), and in the "Phaedo", Socrates' disciples, towards whom he displays more concern than his biological sons, say they will feel "fatherless" when he is gone.
In several of Plato's dialogues, Socrates promulgates the idea that knowledge is a matter of recollection, and not of learning, observation, or study. He maintains this view somewhat at his own expense, because in many dialogues, Socrates complains of his forgetfulness. Socrates is often found arguing that knowledge is not empirical, and that it comes from divine insight. In many middle period dialogues, such as the "Phaedo", "Republic" and "Phaedrus" Plato advocates a belief in the immortality of the soul, and several dialogues end with long speeches imagining the afterlife. More than one dialogue contrasts knowledge and opinion, perception and reality, nature and custom, and body and soul.
Several dialogues tackle questions about art: Socrates says that poetry is inspired by the muses, and is not rational. He speaks approvingly of this, and other forms of divine madness (drunkenness, eroticism, and dreaming) in the "Phaedrus "(265a–c), and yet in the 'Republic' wants to outlaw Homer's great poetry, and laughter as well. In "Ion", Socrates gives no hint of the disapproval of Homer that he expresses in the "Republic". The dialogue "Ion" suggests that Homer's "Iliad" functioned in the ancient Greek world as the Bible does today in the modern Christian world: as divinely inspired literature that can provide moral guidance, if only it can be properly interpreted.
Socrates and his company of disputants had something to say on many subjects, including politics and art, religion and science, justice and medicine, virtue and vice, crime and punishment, pleasure and pain, rhetoric and rhapsody, human nature and sexuality, as well as love and wisdom.
Metaphysics.
"Platonism" is a term coined by scholars to refer to the intellectual consequences of denying, as Plato's Socrates often does, the reality of the material world. In several dialogues, most notably the "Republic", Socrates inverts the common man's intuition about what is knowable and what is real. While most people take the objects of their senses to be real if anything is, Socrates is contemptuous of people who think that something has to be graspable in the hands to be real. In the "Theaetetus", he says such people are "eu amousoi" (εὖ ἄμουσοι), an expression that means literally, "happily without the muses" ("Theaetetus" 156a). In other words, such people live without the divine inspiration that gives him, and people like him, access to higher insights about reality.
Socrates's idea that reality is unavailable to those who use their senses is what puts him at odds with the common man, and with common sense. Socrates says that he who sees with his eyes is blind, and this idea is most famously captured in his allegory of the cave, and more explicitly in his description of the divided line. The allegory of the cave (begins "Republic" 7.514a) is a paradoxical analogy wherein Socrates argues that the invisible world is the most intelligible ("noeton") and that the visible world ("(h)oraton") is the least knowable, and the most obscure.
Socrates says in the "Republic" that people who take the sun-lit world of the senses to be good and real are living pitifully in a den of evil and ignorance. Socrates admits that few climb out of the den, or cave of ignorance, and those who do, not only have a terrible struggle to attain the heights, but when they go back down for a visit or to help other people up, they find themselves objects of scorn and ridicule.
According to Socrates, physical objects and physical events are "shadows" of their ideal or perfect forms, and exist only to the extent that they instantiate the perfect versions of themselves. Just as shadows are temporary, inconsequential epiphenomena produced by physical objects, physical objects are themselves fleeting phenomena caused by more substantial causes, the ideals of which they are mere instances. For example, Socrates thinks that perfect justice exists (although it is not clear where) and his own trial would be a cheap copy of it.
The allegory of the cave (often said by scholars to represent Plato's own epistemology and metaphysics) is intimately connected to his political ideology (often said to also be Plato's own), that only people who have climbed out of the cave and cast their eyes on a vision of goodness are fit to rule. Socrates claims that the enlightened men of society must be forced from their divine contemplations and be compelled to run the city according to their lofty insights. Thus is born the idea of the "philosopher-king", the wise person who accepts the power thrust upon him by the people who are wise enough to choose a good master. This is the main thesis of Socrates in the "Republic", that the most wisdom the masses can muster is the wise choice of a ruler.
Theory of Forms.
The theory of Forms (or theory of Ideas) typically refers to the belief that the material world as it seems to us is not the real world, but only an "image" or "copy" of the real world. In some of Plato's dialogues, this is expressed by Socrates, who spoke of forms in formulating a solution to the problem of universals. The forms, according to Socrates, are archetypes or abstract representations of the many types of things, and properties we feel and see around us, that can only be perceived by reason (Greek: λογική). (That is, they are universals.) In other words, Socrates was able to recognize two worlds: the apparent world, which constantly changes, and an unchanging and unseen world of forms, which may be the cause of what is apparent.
Epistemology.
Many have interpreted Plato as stating—even having been the first to write—that knowledge is justified true belief, an influential view that informed future developments in epistemology. This interpretation is partly based on a reading of the "Theaetetus" wherein Plato argues that knowledge is distinguished from mere true belief by the knower having an "account" of the object of her or his true belief ("Theaetetus" ). And this theory may again be seen in the "Meno", where it is suggested that true belief can be raised to the level of knowledge if it is bound with an account as to the question of "why" the object of the true belief is so ("Meno" ). Many years later, Edmund Gettier famously demonstrated the problems of the justified true belief account of knowledge. That the modern theory of justified true belief as knowledge which Gettier addresses is equivalent to Plato's is accepted by some scholars but rejected by others. Plato himself also identified problems with the "justified true belief" definition in the "Theaetetus", concluding that justification (or an "account") would require knowledge of "differentness", meaning that the definition of knowledge is circular ("Theaetetus" ).
Later in the "Meno", Socrates uses a geometrical example to expound Plato's view that knowledge in this latter sense is acquired by recollection. Socrates elicits a fact concerning a geometrical construction from a slave boy, who could not have otherwise known the fact (due to the slave boy's lack of education). The knowledge must be present, Socrates concludes, in an eternal, non-experiential form.
In other dialogues, the "Sophist", "Statesman", "Republic", and the "Parmenides", Plato himself associates knowledge with the apprehension of unchanging Forms and their relationships to one another (which he calls "expertise" in Dialectic), including through the processes of "collection" and "division". More explicitly, Plato himself argues in the "Timaeus" that knowledge is always proportionate to the realm from which it is gained. In other words, if one derives one's account of something experientially, because the world of sense is in flux, the views therein attained will be mere opinions. And opinions are characterized by a lack of necessity and stability. On the other hand, if one derives one's account of something by way of the non-sensible forms, because these forms are unchanging, so too is the account derived from them. That apprehension of forms is required for knowledge may be taken to cohere with Plato's theory in the "Theaetetus" and "Meno". Indeed, the apprehension of Forms may be at the base of the "account" required for justification, in that it offers foundational knowledge which itself needs no account, thereby avoiding an infinite regression.
The state.
Plato's philosophical views had many societal implications, especially on the idea of an ideal state or government. There is some discrepancy between his early and later views. Some of the most famous doctrines are contained in the "Republic" during his middle period, as well as in the "Laws" and the "Statesman". However, because Plato wrote dialogues, it is assumed that Socrates is often speaking for Plato. This assumption may not be true in all cases.
Plato, through the words of Socrates, asserts that societies have a tripartite class structure corresponding to the appetite/spirit/reason structure of the individual soul. The appetite/spirit/reason are analogous to the castes of society.
In the Timaeus, Plato locates the parts of the soul within the human body: Reason is located in the head, spirit in the top third of the torso, and the appetite in the middle third of the torso, down to the navel.
According to this model, the principles of Athenian democracy (as it existed in his day) are rejected as only a few are fit to rule. Instead of rhetoric and persuasion, Plato says reason and wisdom should govern. As Plato puts it:
Plato describes these "philosopher kings" as "those who love the sight of truth" ("Republic" 475c) and supports the idea with the analogy of a captain and his ship or a doctor and his medicine. According to him, sailing and health are not things that everyone is qualified to practice by nature. A large part of the "Republic" then addresses how the educational system should be set up to produce these philosopher kings.
However, it must be taken into account that the ideal city outlined in the "Republic" is qualified by Socrates as the ideal "luxurious" city, examined to determine how it is that injustice and justice grow in a city ("Republic" 372e). According to Socrates, the "true" and "healthy" city is instead the one first outlined in book II of the "Republic", 369c–372d, containing farmers, craftsmen, merchants, and wage-earners, but lacking the guardian class of philosopher-kings as well as delicacies such as "perfumed oils, incense, prostitutes, and pastries", in addition to paintings, gold, ivory, couches, a multitude of occupations such as poets and hunters, and war.
In addition, the ideal city is used as an image to illuminate the state of one's soul, or the will, reason, and desires combined in the human body. Socrates is attempting to make an image of a rightly ordered human, and then later goes on to describe the different kinds of humans that can be observed, from tyrants to lovers of money in various kinds of cities. The ideal city is not promoted, but only used to magnify the different kinds of individual humans and the state of their soul. However, the philosopher king image was used by many after Plato to justify their personal political beliefs. The philosophic soul according to Socrates has reason, will, and desires united in virtuous harmony. A philosopher has the moderate love for wisdom and the courage to act according to wisdom. Wisdom is knowledge about the Good or the right relations between all that exists.
Wherein it concerns states and rulers, Plato has made interesting arguments. For instance he asks which is better—a bad democracy or a country reigned by a tyrant. He argues that it is better to be ruled by a bad tyrant, than be a bad democracy (since here all the people are now responsible for such actions, rather than one individual committing many bad deeds.) This is emphasised within the "Republic" as Plato describes the event of mutiny on board a ship. Plato suggests the ships crew to be in line with the democratic rule of many and the captain, although inhibited through ailments, the tyrant. Plato's description of this event is parallel to that of democracy within the state and the inherent problems that arise.
According to Plato, a state made up of different kinds of souls will, overall, decline from an aristocracy (rule by the best) to a timocracy (rule by the honorable), then to an oligarchy (rule by the few), then to a democracy (rule by the people), and finally to tyranny (rule by one person, rule by a tyrant). Aristocracy is the form of government ("politeia") advocated in Plato's
"Republic". This regime is ruled by a philosopher king, and thus is grounded on wisdom and reason. The aristocratic state, and the man whose nature corresponds to it, are the objects of Plato's analyses throughout much of the "Republic", as opposed to the other four types of states/men, who are discussed later in his work. In Book VIII, Plato states in order the other four imperfect societies with a description of the state's structure and individual character. In timocracy the ruling class is made up primarily of those with a warrior-like character. In his description, Plato has Sparta in mind. Oligarchy is made up of a society in which wealth is the criterion of merit and the wealthy are in control. In democracy, the state bears resemblance to ancient Athens with traits such as equality of political opportunity and freedom for the individual to do as he likes. Democracy then degenerates into tyranny from the conflict of rich and poor. It is characterized by an undisciplined society existing in chaos, where the tyrant rises as popular champion leading to the formation of his private army and the growth of oppression.
Unwritten doctrines.
For a long time, Plato's unwritten doctrine had been controversial. Many modern books on Plato seem to diminish its importance; nevertheless, the first important witness who mentions its existence is Aristotle, who in his "Physics" (209 b) writes: "It is true, indeed, that the account he gives there [i.e. in "Timaeus"] of the participant is different from what he says in his so-called "unwritten teachings" (ἄγραφα δόγματα)." The term "ἄγραφα δόγματα" literally means "unwritten doctrines" and it stands for the most fundamental metaphysical teaching of Plato, which he disclosed only orally, and some say only to his most trusted fellows, and which he may have kept secret from the public. The importance of the unwritten doctrines does not seem to have been seriously questioned before the 19th century.
A reason for not revealing it to everyone is partially discussed in "Phaedrus" (276 c) where Plato criticizes the written transmission of knowledge as faulty, favoring instead the spoken logos: "he who has knowledge of the just and the good and beautiful ... will not, when in earnest, write them in ink, sowing them through a pen with words, which cannot defend themselves by argument and cannot teach the truth effectually." The same argument is repeated in Plato's "Seventh Letter" (344 c): "every serious man in dealing with really serious subjects carefully avoids writing." In the same letter he writes (341 c): "I can certainly declare concerning all these writers who claim to know the subjects that I seriously study ... there does not exist, nor will there ever exist, any treatise of mine dealing therewith." Such secrecy is necessary in order not "to expose them to unseemly and degrading treatment" (344 d).
It is, however, said that Plato once disclosed this knowledge to the public in his lecture "On the Good" (Περὶ τἀγαθοῦ), in which the Good (τὸ ἀγαθόν) is identified with the One (the Unity, τὸ ἕν), the fundamental ontological principle. The content of this lecture has been transmitted by several witnesses. Aristoxenus describes the event in the following words: "Each came expecting to learn something about the things that are generally considered good for men, such as wealth, good health, physical strength, and altogether a kind of wonderful happiness. But when the mathematical demonstrations came, including numbers, geometrical figures and astronomy, and finally the statement Good is One seemed to them, I imagine, utterly unexpected and strange; hence some belittled the matter, while others rejected it." Simplicius quotes Alexander of Aphrodisias, who states that "according to Plato, the first principles of everything, including the Forms themselves are One and Indefinite Duality (ἡ ἀόριστος δυάς), which he called Large and Small (τὸ μέγα καὶ τὸ μικρόν)", and Simplicius reports as well that "one might also learn this from Speusippus and Xenocrates and the others who were present at Plato's lecture on the Good".
Their account is in full agreement with Aristotle's description of Plato's metaphysical doctrine. In "Metaphysics" he writes: "Now since the Forms are the causes of everything else, he [i.e. Plato] supposed that their elements are the elements of all things. Accordingly the material principle is the Great and Small [i.e. the Dyad], and the essence is the One (τὸ ἕν), since the numbers are derived from the Great and Small by participation in the One" (987 b). "From this account it is clear that he only employed two causes: that of the essence, and the material cause; for the Forms are the cause of the essence in everything else, and the One is the cause of it in the Forms. He also tells us what the material substrate is of which the Forms are predicated in the case of sensible things, and the One in that of the Forms - that it is this the duality (the Dyad, ἡ δυάς), the Great and Small (τὸ μέγα καὶ τὸ μικρόν). Further, he assigned to these two elements respectively the causation of good and of evil" (988 a).
The most important aspect of this interpretation of Plato's metaphysics is the continuity between his teaching and the neoplatonic interpretation of Plotinus or Ficino which has been considered erroneous by many but may in fact have been directly influenced by oral transmission of Plato's doctrine. A modern scholar who recognized the importance of the unwritten doctrine of Plato was Heinrich Gomperz who described it in his speech during the 7th International Congress of Philosophy in 1930. All the sources related to the ἄγραφα δόγματα have been collected by Konrad Gaiser and published as "Testimonia Platonica". These sources have subsequently been interpreted by scholars from the German "Tübingen School of interpretation" such as Hans Joachim Krämer or Thomas A. Szlezák.
Dialectic.
The role of dialectic in Plato's thought is contested but there are two main interpretations: a type of reasoning and a method of intuition. Simon Blackburn adopts the first, saying that Plato's dialectic is "the process of eliciting the truth by means of questions aimed at opening out what is already implicitly known, or at exposing the contradictions and muddles of an opponent's position." A similar interpretation has been put forth by Louis Hartz, who suggests that elements of the dialectic are borrowed from Hegel. According to this view, opposing arguments improve upon each other, and prevailing opinion is shaped by the synthesis of many conflicting ideas over time. Each new idea exposes a flaw in the accepted model, and the epistemological substance of the debate continually approaches the truth. Hartz's is a teleological interpretation at the core, in which philosophers will ultimately exhaust the available body of knowledge and thus reach "the end of history." Karl Popper, on the other hand, claims that dialectic is the art of intuition for "visualising the divine originals, the Forms or Ideas, of unveiling the Great Mystery behind the common man's everyday world of appearances."
The dialogues.
Thirty-five dialogues and thirteen letters (the "Epistles") have traditionally been ascribed to Plato, though modern scholarship doubts the authenticity of at least some of these. Plato's writings have been published in several fashions; this has led to several conventions regarding the naming and referencing of Plato's texts.
The usual system for making unique references to sections of the text by Plato derives from a 16th-century edition of Plato's works by Henricus Stephanus. An overview of Plato's writings according to this system can be found in the Stephanus pagination article.
One tradition regarding the arrangement of Plato's texts is according to tetralogies. This scheme is ascribed by Diogenes Laertius to an ancient scholar and court astrologer to Tiberius named Thrasyllus.
The works are usually grouped into "Early", (sometimes by some into "Transitional"), "Middle", and "Late" period. This choice to group chronologically is thought worthy of criticism by some (Cooper "et al"), given that it's recognised that there is no absolute agreement as to the true chronologicity, since the facts of the temporal order of writing are not confidently ascertained.
Early : "Apology (of Socrates)", "Charmides", "Crito", "Euthyphro", "Gorgias", "(Lesser) Hippias (minor)", "(Greater) Hippias (major)", "Ion", "Laches", "Lysis","Protagoras" 
Middle/Transitional : "Cratylus", 'Euthydemus", "Meno", "Parmenides", "Phaedo", "Phaedrus", "Republic", "Symposium",
Middle/Late : "Theaetetus"
Late : "Critias", "Sophist", "Statesman / Politicus", "Timaeus" , "Philebus", "Laws"
Chronologicity was not a consideration in ancient times, in that grouping of this nature are "virtually absent" (Tarrant) in the extant writings of ancient Platonists.
Writings of doubted authenticity.
Jowett mentions in his Appendix to Menexenus, that works which bore the character of a writer were attributed to that writer even when the actual author was unknown.
For below:
(*) if there is no consensus among scholars as to whether Plato is the author, and (‡) if most scholars agree that Plato is "not" the author of the work.
"First Alcibiades" (*), "Second Alcibiades" (‡) , "Clitophon" (*) , "Epinomis" (‡), "Epistles" (*), "Hipparchus" (‡), "Menexenus"(*), "Minos" (‡) "(Rival) Lovers" (‡), "Theages" (‡) 
Spurious writings.
The following works were transmitted under Plato's name, most of them already considered spurious in antiquity, and so were not included by Thrasyllus in his tetralogical arrangement. These works are labelled as "Notheuomenoi" ("spurious") or "Apocrypha".
Composition of the dialogues.
No one knows the exact order Plato's dialogues were written in, nor the extent to which some might have been later revised and rewritten. A significant distinction of the early Plato and the later Plato has been offered by scholars such as E.R. Dodds and has been summarized by Harold Bloom in his book titled "Agon": "E.R. Dodds is the classical scholar whose writings most illuminated the Hellenic descent (in) "The Greeks and the Irrational" [...] In his chapter on Plato and the Irrational Soul [...] Dodds traces Plato's spiritual evolution from the pure rationalist of the "Protagoras" to the transcendental psychologist, influenced by the Pythagoreans and Orphics, of the later works culminating in the "Laws"."
Lewis Campbell was the first to make exhaustive use of stylometry to prove objectively that the "Critias", "Timaeus", "Laws", "Philebus", "Sophist", and "Statesman" were all clustered together as a group, while the "Parmenides", "Phaedrus", "Republic", and "Theaetetus" belong to a separate group, which must be earlier (given Aristotle's statement in his "Politics" that the "Laws" was written after the "Republic"; cf. Diogenes Laertius "Lives" 3.37). What is remarkable about Campbell's conclusions is that, in spite of all the stylometric studies that have been conducted since his time, perhaps the only chronological fact about Plato's works that can now be said to be "proven" by stylometry is the fact that "Critias", "Timaeus", "Laws", "Philebus", "Sophist", and "Statesman" are the latest of Plato's dialogues, the others earlier.
Increasingly in the most recent Plato scholarship, writers are skeptical of the notion that the order of Plato's writings can be established with any precision, though Plato's works are still often characterized as falling at least roughly into three groups. The following represents one relatively common such division. It should, however, be kept in mind that many of the positions in the ordering are still highly disputed, and also that the very notion that Plato's dialogues can or should be "ordered" is by no means universally accepted.
Among those who classify the dialogues into periods of composition, Socrates figures in all of the "early dialogues" and they are considered the most faithful representations of the historical Socrates. They include "The Apology of Socrates", "Charmides", "Crito", "Euthyphro", "Ion", "Laches", "Lesser Hippias", "Lysis", "Menexenus", and "Protagoras" (often considered one of the last of the "early dialogues"). Three dialogues are often considered "transitional" or "pre-middle": "Euthydemus", "Gorgias", and "Meno".
Whereas those classified as "early dialogues" often conclude in aporia, the so-called "middle dialogues" provide more clearly stated positive teachings that are often ascribed to Plato such as the theory of Forms. These dialogues include "Cratylus", "Phaedo", "Phaedrus", "Republic", "Symposium", "Parmenides", and "Theaetetus". Proponents of dividing the dialogues into periods often consider the "Parmenides" and "Theaetetus" to come late in this period and be transitional to the next, as they seem to treat the theory of Forms critically ("Parmenides") or only indirectly ("Theaetetus"). Ritter's stylometric analysis places "Phaedrus" as probably after "Theaetetus" and "Parmenides", although it does not relate to the theory of Forms in the same way. The first book of the "Republic" is often thought to have been written significantly earlier than the rest of the work, although possibly having undergone revisions when the later books were attached to it.
The remaining dialogues are classified as "late" and are generally agreed to be difficult and challenging pieces of philosophy. This grouping is the only one proven by stylometric analysis. While looked to for Plato's "mature" answers to the questions posed by his earlier works, those answers are difficult to discern. Some scholars indicate that the theory of Forms is absent from the late dialogues, its having been refuted in the "Parmenides", but there isn't total consensus that the "Parmenides" actually refutes the theory of Forms. The so-called "late dialogues" include "Critias", "Laws", "Philebus", "Sophist", "Statesman", and "Timaeus".
Narration of the dialogues.
Plato never presents himself as a participant in any of the dialogues, and with the exception of the "Apology", there is no suggestion that he heard any of the dialogues firsthand. Some dialogues have no narrator but have a pure "dramatic" form (examples: "Meno", "Gorgias", "Phaedrus", "Crito", "Euthyphro"), some dialogues are narrated by Socrates, wherein he speaks in first person (examples: "Lysis", "Charmides", "Republic"). One dialogue, "Protagoras", begins in dramatic form but quickly proceeds to Socrates' narration of a conversation he had previously with the sophist for whom the dialogue is named; this narration continues uninterrupted till the dialogue's end.
Two dialogues "Phaedo" and "Symposium" also begin in dramatic form but then proceed to virtually uninterrupted narration by followers of Socrates. "Phaedo", an account of Socrates' final conversation and hemlock drinking, is narrated by Phaedo to Echecrates in a foreign city not long after the execution took place. The "Symposium" is narrated by Apollodorus, a Socratic disciple, apparently to Glaucon. Apollodorus assures his listener that he is recounting the story, which took place when he himself was an infant, not from his own memory, but as remembered by Aristodemus, who told him the story years ago.
The "Theaetetus" is a peculiar case: a dialogue in dramatic form imbedded within another dialogue in dramatic form. In the beginning of the "Theaetetus" (142c-143b), Euclides says that he compiled the conversation from notes he took based on what Socrates told him of his conversation with the title character. The rest of the "Theaetetus" is presented as a "book" written in dramatic form and read by one of Euclides' slaves (143c). Some scholars take this as an indication that Plato had by this date wearied of the narrated form. With the exception of the "Theaetetus", Plato gives no explicit indication as to how these orally transmitted conversations came to be written down.
Trial of Socrates.
The trial of Socrates is the central, unifying event of the great Platonic dialogues. Because of this, Plato's "Apology" is perhaps the most often read of the dialogues. In the "Apology", Socrates tries to dismiss rumors that he is a sophist and defends himself against charges of disbelief in the gods and corruption of the young. Socrates insists that long-standing slander will be the real cause of his demise, and says the legal charges are essentially false. Socrates famously denies being wise, and explains how his life as a philosopher was launched by the Oracle at Delphi. He says that his quest to resolve the riddle of the oracle put him at odds with his fellow man, and that this is the reason he has been mistaken for a menace to the city-state of Athens.
If Plato's important dialogues do not refer to Socrates' execution explicitly, they allude to it, or use characters or themes that play a part in it. Five dialogues foreshadow the trial: In the "Theaetetus" (210d) and the "Euthyphro" (2a–b) Socrates tells people that he is about to face corruption charges. In the "Meno" (94e–95a), one of the men who brings legal charges against Socrates, Anytus, warns him about the trouble he may get into if he does not stop criticizing important people. In the "Gorgias", Socrates says that his trial will be like a doctor prosecuted by a cook who asks a jury of children to choose between the doctor's bitter medicine and the cook's tasty treats (521e–522a). In the "Republic" (7.517e), Socrates explains why an enlightened man (presumably himself) will stumble in a courtroom situation. The "Apology" is Socrates' defense speech, and the "Crito" and "Phaedo" take place in prison after the conviction. In the "Protagoras", Socrates is a guest at the home of Callias, son of Hipponicus, a man whom Socrates disparages in the "Apology" as having wasted a great amount of money on sophists' fees.
Unity and diversity of the dialogues.
Two other important dialogues, the "Symposium" and the "Phaedrus", are linked to the main storyline by characters. In the "Apology" (19b, c), Socrates says Aristophanes slandered him in a comic play, and blames him for causing his bad reputation, and ultimately, his death. In the "Symposium", the two of them are drinking together with other friends. The character Phaedrus is linked to the main story line by character (Phaedrus is also a participant in the "Symposium" and the "Protagoras") and by theme (the philosopher as divine emissary, etc.) The "Protagoras" is also strongly linked to the "Symposium" by characters: all of the formal speakers at the "Symposium" (with the exception of Aristophanes) are present at the home of Callias in that dialogue. Charmides and his guardian Critias are present for the discussion in the "Protagoras". Examples of characters crossing between dialogues can be further multiplied. The "Protagoras" contains the largest gathering of Socratic associates.
In the dialogues Plato is most celebrated and admired for, Socrates is concerned with human and political virtue, has a distinctive personality, and friends and enemies who "travel" with him from dialogue to dialogue. This is not to say that Socrates is consistent: a man who is his friend in one dialogue may be an adversary or subject of his mockery in another. For example, Socrates praises the wisdom of Euthyphro many times in the "Cratylus", but makes him look like a fool in the "Euthyphro". He disparages sophists generally, and Prodicus specifically in the "Apology", whom he also slyly jabs in the "Cratylus" for charging the hefty fee of fifty drachmas for a course on language and grammar. However, Socrates tells Theaetetus in his namesake dialogue that he admires Prodicus and has directed many pupils to him. Socrates' ideas are also not consistent within or between or among dialogues.
Platonic scholarship.
Although their popularity has fluctuated over the years, the works of Plato have never been without readers since the time they were written. Plato's thought is often compared with that of his most famous student, Aristotle, whose reputation during the Western Middle Ages so completely eclipsed that of Plato that the Scholastic philosophers referred to Aristotle as "the Philosopher". However, in the Byzantine Empire, the study of Plato continued.
The Medieval scholastic philosophers did not have access to most of the works of Plato, nor the knowledge of Greek needed to read them. Plato's original writings were essentially lost to Western civilization until they were brought from Constantinople in the century of its fall, by George Gemistos Plethon. It is believed that Plethon passed a copy of the Dialogues to Cosimo de' Medici when in 1438 the Council of Ferrara, called to unify the Greek and Latin Churches, was adjourned to Florence, where Plethon then lectured on the relation and differences of Plato and Aristotle, and fired Cosimo with his enthusiasm; Cosimo would supply Marsilio Ficino with Plato's text for translation to Latin. During the early Islamic era, Persian and Arab scholars translated much of Plato into Arabic and wrote commentaries and interpretations on Plato's, Aristotle's and other Platonist philosophers' works (see Al-Farabi, Avicenna, Averroes, Hunayn ibn Ishaq). Many of these comments on Plato were translated from Arabic into Latin and as such influenced Medieval scholastic philosophers.
During the Renaissance, with the general resurgence of interest in classical civilization, knowledge of Plato's philosophy would become widespread again in the West. Many of the greatest early modern scientists and artists who broke with Scholasticism and fostered the flowering of the Renaissance, with the support of the Plato-inspired Lorenzo (grandson of Cosimo), saw Plato's philosophy as the basis for progress in the arts and sciences. His political views, too, were well-received: the vision of wise philosopher-kings of the "Republic" matched the views set out in works such as Machiavelli's "The Prince". More problematic was Plato's belief in metempsychosis, transmigration of the soul, as well as his ethical views (on polyamory and euthanasia in particular), which did not match those of Christianity. It was Plethon's student Bessarion who reconciled Plato with Christian theology, arguing that Plato's views were only ideals, unattainable due to the fall of man.
By the 19th century, Plato's reputation was restored, and at least on par with Aristotle's. Notable Western philosophers have continued to draw upon Plato's work since that time. Plato's influence has been especially strong in mathematics and the sciences. He helped to distinguish between pure and applied mathematics by widening the gap between "arithmetic", now called number theory and "logistic", now called arithmetic. He regarded "logistic" as appropriate for business men and men of war who "must learn the art of numbers or he will not know how to array his troops," while "arithmetic" was appropriate for philosophers "because he has to arise out of the sea of change and lay hold of true being." Plato's resurgence further inspired some of the greatest advances in logic since Aristotle, primarily through Gottlob Frege and his followers Kurt Gödel, Alonzo Church, and Alfred Tarski. Albert Einstein suggested that the scientist who takes philosophy seriously would have to avoid systematization and take on many different roles, and possibly appear as a Platonist or Pythagorean, in that such a one would have "the viewpoint of logical simplicity as an indispensable and effective tool of his research."
Many recent philosophers have diverged from what some would describe as the ontological models and moral ideals characteristic of traditional Platonism. A number of these postmodern philosophers have thus appeared to disparage Platonism from more or less informed perspectives. Friedrich Nietzsche notoriously attacked Plato's "idea of the good itself" along with many fundamentals of Christian morality, which he interpreted as "Platonism for the masses" in one of his most important works, "Beyond Good And Evil "(1886). Martin Heidegger argued against Plato's alleged obfuscation of "Being "in his incomplete tome, "Being and Time" (1927), and the philosopher of science Karl Popper argued in "The Open Society and Its Enemies" (1945) that Plato's alleged proposal for a utopian political regime in the "Republic" was prototypically totalitarian. The political philosopher and professor Leo Strauss is considered by some as the prime thinker involved in the recovery of Platonic thought in its more political, and less metaphysical, form. Strauss' political approach was in part inspired by the appropriation of Plato and Aristotle by medieval Jewish and Islamic political philosophers, especially Maimonides and Al-Farabi, as opposed to the Christian metaphysical tradition that developed from Neoplatonism. Deeply influenced by Nietzsche and Heidegger, Strauss nonetheless rejects their condemnation of Plato and looks to the dialogues for a solution to what all three latter day thinkers acknowledge as 'the crisis of the West.'
Textual sources and history.
Some 250 known manuscripts of Plato survive. The texts of Plato as received today apparently represent the complete written philosophical work of Plato and are generally good by the standards of textual criticism. No modern edition of Plato in the original Greek represents a single source, but rather it is reconstructed from multiple sources which are compared with each other. These sources are medieval manuscripts written on vellum (mainly from 9th-13th century AD Byzantium), papyri (mainly from late antiquity in Egypt), and from the independent "testimonia" of other authors who quote various segments of the works (which come from a variety of sources). The text as presented is usually not much different from what appears in the Byzantine manuscripts, and papyri and testimonia just confirm the manuscript tradition. In some editions however the readings in the papyri or testimonia are favoured in some places by the editing critic of the text. Reviewing editions of papyri for the "Republic" in 1987, Slings suggests that the use of papyri is hampered due to some poor editing practices.
In the first century AD, Thrasyllus of Mendes had compiled and published the works of Plato in the original Greek, both genuine and spurious. While it has not survived to the present day, all the extant medieval Greek manuscripts are based on his edition.
The oldest surviving complete manuscript for many of the dialogues is the Clarke Plato (Codex Oxoniensis Clarkianus 39, or Codex Boleianus MS E.D. Clarke 39), which was written in Constantinople in 895 and acquired by Oxford University in 1809. The Clarke is given the siglum "B" in modern editions. "B" contains the first six tetralogies and is described internally as being written by "John the Calligrapher" on behalf of Arethas of Caesarea. It appears to have undergone corrections by Arethas himself. For the last two tetralogies and the apocrypha, the oldest surviving complete manuscript is Codex Parisinus graecus 1807, designated "A", which was written nearly contemporaneously to "B", circa 900 AD. "A" must be a copy of the edition edited by the patriarch, Patriarch Photius, teacher of Arethas."A" probably had an initial volume containing the first 7 tetralogies which is now lost, but of which a copy was made, Codex Venetus append. class. 4, 1, which has the siglum "T". The oldest manuscript for the seventh tetralogy is Codex Vindobonensis 54. suppl. phil. Gr. 7, with siglum "W", with a supposed date in the twelfth century. In total there are fifty-one such Byzantine manuscripts known, while others may yet be found.
To help establish the text, the older evidence of papyri and the independent evidence of the testimony of commentators and other authors (i.e., those who quote and refer to an old text of Plato which is no longer extant) are also used. Many papyri which contain fragments of Plato's texts are among the Oxyrhynchus Papyri. The 2003 Oxford Classical Texts edition by Slings even cites the Coptic translation of a fragment of the "Republic" in the Nag Hammadi library as evidence. Important authors for testimony include Olympiodorus the Younger, Plutarch, Proclus, Iamblichus, Eusebius, and Stobaeus.
During the early Renaissance, the Greek language and, along with it, Plato's texts were reintroduced to Western Europe by Byzantine scholars. In September or October of 1484 Filippo Valori and Francesco Berlinghieri printed 1025 copies of Ficino's translation, using the printing press at the Dominican convent S.Jacopo di Ripoli. Cosimo had been influenced toward studying Plato by the many Byzantine Platonists in Florence during his day, including George Gemistus Plethon. Henri Estienne's edition, including parallel Greek and Latin, was published in 1578. It was this edition which established Stephanus pagination, still in use today.
Modern editions.
The Oxford Classical Texts offers the current standard complete Greek text of Plato's complete works. In five volumes edited by John Burnet, its first edition was published 1900-1907, and it is still available from the publisher, having last been printed in 1993. The second edition is still in progress with only the first volume, printed in 1995, and the "Republic", printed in 2003, available. The "Cambridge Greek and Latin Texts" and "Cambridge Classical Texts and Commentaries" series includes Greek editions of the "Protagoras", "Symposium", "Phaedrus", "Alcibiades", and "Clitophon", with English philological, literary, and, to an extent, philosophical commentary. One distinguished edition of the Greek text is E. R. Dodds' of the "Gorgias", which includes extensive English commentary.
The modern standard complete English edition is the 1997 Hackett "Plato, Complete Works", edited by John M. Cooper. For many of these translations Hackett offers separate volumes which include more by way of commentary, notes, and introductory material. There is also the "Clarendon Plato Series" by Oxford University Press which offers English translations and thorough philosophical commentary by leading scholars on a few of Plato's works, including John McDowell's version of the "Theaetetus". Cornell University Press has also begun the "Agora" series of English translations of classical and medieval philosophical texts, including a few of Plato's.
Notes.
a. ^ Plato is a nickname from the adjective "platýs" "broad". Diogenes Laertius mentions three possible meanings of the nickname:
Seneca mentions the meaning of Plato's name in connection to a moral lesson:
b. ^ The grammarian Apollodorus of Athens argues in his "Chronicles" that Plato was born in the first year of the eighty-eighth Olympiad (427 BCE), on the seventh day of the month Thargelion; according to this tradition the god Apollo was born this day. According to another biographer of him, Neanthes, Plato was eighty-four years of age at his death. If we accept Neanthes' version, Plato was younger than Isocrates by six years, and therefore he was born in the second year of the 87th Olympiad, the year Pericles died (429 BCE). According to the "Suda," Plato was born in Aegina in the 88th Olympiad amid the preliminaries of the Peloponnesian war, and he lived 82 years. Sir Thomas Browne also believes that Plato was born in the 88th Olympiad. Renaissance Platonists celebrated Plato's birth on November 7. Ulrich von Wilamowitz-Moellendorff estimates that Plato was born when Diotimos was archon eponymous, namely between July 29, 428 BCE and July 24, 427 BCE. Greek philologist Ioannis Kalitsounakis believes that the philosopher was born on May 26 or 27, 427 BCE, while Jonathan Barnes regards 428 BCE as year of Plato's birth. For her part, Debra Nails asserts that the philosopher was born in 424/423 BCE. According to Seneca Plato died at the age of 81 on the same day he was born.
c. ^ Diogenes Laertius mentions that Plato "was born, according to some writers, in Aegina in the house of Phidiades the son of Thales". Diogenes mentions as one of his sources the "Universal History" of Favorinus. According to Favorinus, Ariston, Plato's family, and his family were sent by Athens to settle as cleruchs (colonists retaining their Athenian citizenship), on the island of Aegina, from which they were expelled by the Spartans after Plato's birth there. Nails points out, however, that there is no record of any Spartan expulsion of Athenians from Aegina between 431–411 BCE. On the other hand, at the Peace of Nicias, Aegina was silently left under Athens' control, and it was not until the summer of 411 that the Spartans overran the island. Therefore, Nails concludes that "perhaps Ariston was a cleruch, perhaps he went to Aegina in 431, and perhaps Plato was born on Aegina, but none of this enables a precise dating of Ariston's death (or Plato's birth). Aegina is regarded as Plato's place of birth by Suda as well.
</dl>
References.
Primary sources (Greek and Roman).
 #if: 
 #if:  
 |, 
 #if: 
 }}{{
 #if: 
 #if: 
 | ()
 |{{
 #if: 
 #if: 
 | {{#if:||}}{{
 #if: 
 #if: 
 #if: {{
 #if: Charmides (Plato)Charmides
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 |: {{
 #if: Charmides (Plato)Charmides
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 
 #if:  
 |{{
 #if: Plato
 }} {{Citation/make link
 | 1={{
 #if: 
 #if: 
 #if: 
 |{{
 #if: 
 | 2="  
 #if:| []
 #if: 
 }}{{
 #if: 
 }}{{
 #if: 
 }}{{
 #if: 
 }}{{
 #if: 
 | ( ed.)
 #if: 
 }}{{
 #if: 
 #if: 
 |,
 #if: Plato
 |{{
 #if: 
 #if:
}}{{
 #if: 
 #ifeq: | 
 |{{
 #if: 
 #if: Plato
 | (published )
 |{{
 #if: 
 | (published )
}}{{
 #if: 
 |{{
 #if: {{
 #if: Charmides (Plato)Charmides
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 |, {{
 #if: Charmides (Plato)Charmides
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
}}{{
 #if:
 | , {{#ifeq: | no
 | {{#if:
 |{{Citation/make link||{{#ifeq:|.|A|a}}rchived}} from the original
 |{{#ifeq:|.|A|a}}rchived
 | {{#ifeq:|.|A|a}}rchived{{#if:
 }}{{#if:| on }}{{
 |. {{citation error|nocat=
 #if:  
 |, {{
 #if: 
 |
 |, {{
 #if: 
 |
 }}{{
 #if: 
 | {{#ifeq:|,|, r|. R}}etrieved 
}}{{#if:
}}{{#if:
}}{{#if:
}}<span
 class="Z3988"
 title="ctx_ver=Z39.88-2004&rft_val_fmt={{urlencode:info:ofi/fmt:kev:mtx:}}{{
 #if: 
 |journal&rft.genre=article&rft.atitle={{urlencode:  
 |book{{
 #if: 
 |&rft.genre=bookitem&rft.btitle={{urlencode:}}&rft.atitle={{urlencode:  
 |&rft.genre=book&rft.btitle={{urlencode:  
 #if: Plato |&rft.aulast={{urlencode:Plato}}{{
 }}{{
 #if: Plato |&rft.au={{urlencode:Plato}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: {{
 #if: Charmides (Plato)Charmides
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 |&rft.pages={{urlencode: {{
 #if: Charmides (Plato)Charmides
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 }}{{
 }}&rfr_id=info:sid/en.wikipedia.org:{{FULLPAGENAMEE}}"> 
 |IncludedWorkTitle = 
 |IncludedWorkURL = 
 |Other = Translated by Benjamin Jowett
 |Edition = 
 |Place = 
 |PublicationPlace = 
 |Publisher = Wikisource
 |PublicationDate = 
 |EditorSurname1 = 
 |EditorSurname2 = 
 |EditorSurname3 = 
 |EditorSurname4 = 
 |EditorGiven1 = 
 |EditorGiven2=
 |EditorGiven3=
 |EditorGiven4=
 |Editorlink1=
 |Editorlink2=
 |Editorlink3=
 |Editorlink4=
 |language = 
 |format = 
 |ARXIV=
 |ASIN=
 |BIBCODE=
 |DOI=
 |DoiBroken=
 |ISBN=
 |ISSN=
 |JFM=
 |JSTOR=
 |LCCN=
 |MR=
 |OCLC=
 |OL=
 |OSTI=
 |PMC=
 |Embargo=1010-10-10
 |PMID=
 |RFC=
 |SSRN=
 |ZBL=
 |ID=
 |AccessDate=
 |DateFormat=none
 |quote = 
 |laysummary = 
 |laydate = 
 |Ref=
 |Sep = .
 |PS = .
 |AuthorSep = ; 
 |NameSep = , 
 |Trunc = 8
 |amp = 
}} See original text in .
 #if: 
 #if:  
 |, 
 #if: 
 }}{{
 #if: 
 #if: 
 | ()
 |{{
 #if: 
 #if: 
 | {{#if:||}}{{
 #if: 
 #if: 
 #if: {{
 #if: Gorgias
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 |: {{
 #if: Gorgias
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 
 #if:  
 |{{
 #if: Plato
 }} {{Citation/make link
 | 1={{
 #if: 
 #if: 
 #if: 
 |{{
 #if: 
 | 2="  
 #if:| []
 #if: 
 }}{{
 #if: 
 }}{{
 #if: 
 }}{{
 #if: 
 }}{{
 #if: 
 | ( ed.)
 #if: 
 }}{{
 #if: 
 #if: 
 |,
 #if: Plato
 |{{
 #if: 
 #if:
}}{{
 #if: 
 #ifeq: | 
 |{{
 #if: 
 #if: Plato
 | (published )
 |{{
 #if: 
 | (published )
}}{{
 #if: 
 |{{
 #if: {{
 #if: Gorgias
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 |, {{
 #if: Gorgias
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
}}{{
 #if:
 | , {{#ifeq: | no
 | {{#if:
 |{{Citation/make link||{{#ifeq:|.|A|a}}rchived}} from the original
 |{{#ifeq:|.|A|a}}rchived
 | {{#ifeq:|.|A|a}}rchived{{#if:
 }}{{#if:| on }}{{
 |. {{citation error|nocat=
 #if:  
 |, {{
 #if: 
 |
 |, {{
 #if: 
 |
 }}{{
 #if: 
 | {{#ifeq:|,|, r|. R}}etrieved 
}}{{#if:
}}{{#if:
}}{{#if:
}}<span
 class="Z3988"
 title="ctx_ver=Z39.88-2004&rft_val_fmt={{urlencode:info:ofi/fmt:kev:mtx:}}{{
 #if: 
 |journal&rft.genre=article&rft.atitle={{urlencode:  
 |book{{
 #if: 
 |&rft.genre=bookitem&rft.btitle={{urlencode:}}&rft.atitle={{urlencode:  
 |&rft.genre=book&rft.btitle={{urlencode:  
 #if: Plato |&rft.aulast={{urlencode:Plato}}{{
 }}{{
 #if: Plato |&rft.au={{urlencode:Plato}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: {{
 #if: Gorgias
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 |&rft.pages={{urlencode: {{
 #if: Gorgias
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 }}{{
 }}&rfr_id=info:sid/en.wikipedia.org:{{FULLPAGENAMEE}}"> 
 |IncludedWorkTitle = 
 |IncludedWorkURL = 
 |Other = Translated by Benjamin Jowett
 |Edition = 
 |Place = 
 |PublicationPlace = 
 |Publisher = Wikisource
 |PublicationDate = 
 |EditorSurname1 = 
 |EditorSurname2 = 
 |EditorSurname3 = 
 |EditorSurname4 = 
 |EditorGiven1 = 
 |EditorGiven2=
 |EditorGiven3=
 |EditorGiven4=
 |Editorlink1=
 |Editorlink2=
 |Editorlink3=
 |Editorlink4=
 |language = 
 |format = 
 |ARXIV=
 |ASIN=
 |BIBCODE=
 |DOI=
 |DoiBroken=
 |ISBN=
 |ISSN=
 |JFM=
 |JSTOR=
 |LCCN=
 |MR=
 |OCLC=
 |OL=
 |OSTI=
 |PMC=
 |Embargo=1010-10-10
 |PMID=
 |RFC=
 |SSRN=
 |ZBL=
 |ID=
 |AccessDate=
 |DateFormat=none
 |quote = 
 |laysummary = 
 |laydate = 
 |Ref=
 |Sep = .
 |PS = .
 |AuthorSep = ; 
 |NameSep = , 
 |Trunc = 8
 |amp = 
}} See original text in .
 #if: 
 #if:  
 |, 
 #if: 
 }}{{
 #if: 
 #if: 
 | ()
 |{{
 #if: 
 #if: 
 | {{#if:||}}{{
 #if: 
 #if: 
 #if: {{
 #if: The Republic
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 |: {{
 #if: The Republic
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 
 #if:  
 |{{
 #if: Plato
 }} {{Citation/make link
 | 1={{
 #if: 
 #if: 
 #if: 
 |{{
 #if: 
 | 2="  
 #if:| []
 #if: 
 }}{{
 #if: 
 }}{{
 #if: 
 }}{{
 #if: 
 }}{{
 #if: 
 | ( ed.)
 #if: 
 }}{{
 #if: 
 #if: 
 |,
 #if: Plato
 |{{
 #if: 
 #if:
}}{{
 #if: 
 #ifeq: | 
 |{{
 #if: 
 #if: Plato
 | (published )
 |{{
 #if: 
 | (published )
}}{{
 #if: 
 |{{
 #if: {{
 #if: The Republic
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 |, {{
 #if: The Republic
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
}}{{
 #if:
 | , {{#ifeq: | no
 | {{#if:
 |{{Citation/make link||{{#ifeq:|.|A|a}}rchived}} from the original
 |{{#ifeq:|.|A|a}}rchived
 | {{#ifeq:|.|A|a}}rchived{{#if:
 }}{{#if:| on }}{{
 |. {{citation error|nocat=
 #if:  
 |, {{
 #if: 
 |
 |, {{
 #if: 
 |
 }}{{
 #if: 
 | {{#ifeq:|,|, r|. R}}etrieved 
}}{{#if:
}}{{#if:
}}{{#if:
}}<span
 class="Z3988"
 title="ctx_ver=Z39.88-2004&rft_val_fmt={{urlencode:info:ofi/fmt:kev:mtx:}}{{
 #if: 
 |journal&rft.genre=article&rft.atitle={{urlencode:  
 |book{{
 #if: 
 |&rft.genre=bookitem&rft.btitle={{urlencode:}}&rft.atitle={{urlencode:  
 |&rft.genre=book&rft.btitle={{urlencode:  
 #if: Plato |&rft.aulast={{urlencode:Plato}}{{
 }}{{
 #if: Plato |&rft.au={{urlencode:Plato}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: {{
 #if: The Republic
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 |&rft.pages={{urlencode: {{
 #if: The Republic
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 }}{{
 }}&rfr_id=info:sid/en.wikipedia.org:{{FULLPAGENAMEE}}"> 
 |IncludedWorkTitle = 
 |IncludedWorkURL = 
 |Other = Translated by Benjamin Jowett
 |Edition = 
 |Place = 
 |PublicationPlace = 
 |Publisher = Wikisource
 |PublicationDate = 
 |EditorSurname1 = 
 |EditorSurname2 = 
 |EditorSurname3 = 
 |EditorSurname4 = 
 |EditorGiven1 = 
 |EditorGiven2=
 |EditorGiven3=
 |EditorGiven4=
 |Editorlink1=
 |Editorlink2=
 |Editorlink3=
 |Editorlink4=
 |language = 
 |format = 
 |ARXIV=
 |ASIN=
 |BIBCODE=
 |DOI=
 |DoiBroken=
 |ISBN=
 |ISSN=
 |JFM=
 |JSTOR=
 |LCCN=
 |MR=
 |OCLC=
 |OL=
 |OSTI=
 |PMC=
 |Embargo=1010-10-10
 |PMID=
 |RFC=
 |SSRN=
 |ZBL=
 |ID=
 |AccessDate=
 |DateFormat=none
 |quote = 
 |laysummary = 
 |laydate = 
 |Ref=
 |Sep = .
 |PS = .
 |AuthorSep = ; 
 |NameSep = , 
 |Trunc = 8
 |amp = 
}} See original text in .
 (1683) [written in the late 1st century]{{
 #if: 
 #if:Lives
 }}""{{
 #if: 
 }}{{
 #if: 
 #if: 
 | ()
 |{{
 #if: 
 #if: 
 | {{#if:||}}{{
 #if: 
 #if: 
 #if: {{
 #if: Lives (Dryden translation)
 #if: 
 #if: Pericles
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 |: {{
 #if: Lives (Dryden translation)
 #if: 
 #if: Pericles
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 
 #if: Lives
 #if: Plutarch
 |,
 }} {{Citation/make link
 | 1={{
 #if: 
 #if: 
 #if: 
 |{{
 #if: 
 | 2="Lives{{
 #if:| []
 #if: 
 }}{{
 #if: 
 }}{{
 #if: 
 }}{{
 #if: 
 }}{{
 #if: 
 | ( ed.)
 #if: 
 }}{{
 #if: 
 #if: 
 |,
 #if: Plutarch
 |
 #if: 1683
 |, 1683{{
 #if:written in the late 1st century
 | [written in the late 1st century]
 #if: 
 #ifeq: | 1683
 |{{
 #if: 
 #if: Plutarch
 |, 
 | (published )
 |{{
 #if: 
 | (published )
}}{{
 #if: 
 |{{
 #if: {{
 #if: Lives (Dryden translation)
 #if: 
 #if: Pericles
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 |, {{
 #if: Lives (Dryden translation)
 #if: 
 #if: Pericles
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
}}{{
 #if:
 | , {{#ifeq: | no
 | {{#if:
 |{{Citation/make link||{{#ifeq:|.|A|a}}rchived}} from the original
 |{{#ifeq:|.|A|a}}rchived
 | {{#ifeq:|.|A|a}}rchived{{#if:
 }}{{#if:| on }}{{
 |. {{citation error|nocat=
 #if: Lives
 #if: 
 |
 |, {{
 #if: 
 |
 }}{{
 #if: 
 | {{#ifeq:|,|, r|. R}}etrieved 
}}{{#if:
}}{{#if:
}}{{#if:
}}<span
 class="Z3988"
 title="ctx_ver=Z39.88-2004&rft_val_fmt={{urlencode:info:ofi/fmt:kev:mtx:}}{{
 #if: 
 |book{{
 #if: 
 }}{{
 #if: Plutarch
 |&rft.aulast={{urlencode: Plutarch
 }}{{
 #if: Plutarch
 |&rft.au={{urlencode: Plutarch
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: {{
 #if: Lives (Dryden translation)
 #if: 
 #if: Pericles
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 |&rft.pages={{urlencode: {{
 #if: Lives (Dryden translation)
 #if: 
 #if: Pericles
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 }}{{
 }}&rfr_id=info:sid/en.wikipedia.org:{{FULLPAGENAMEE}}"> 
 |IncludedWorkTitle =  
 |IncludedWorkURL = 
 |Other = Translated by John Dryden
 |Edition = 
 |Place = 
 |PublicationPlace = 
 |Publisher = Wikisource
 |PublicationDate = 
 |EditorSurname1 = 
 |EditorSurname2 = 
 |EditorSurname3 = 
 |EditorSurname4 = 
 |EditorGiven1 = 
 |EditorGiven2=
 |EditorGiven3=
 |EditorGiven4=
 |Editorlink1=
 |Editorlink2=
 |Editorlink3=
 |Editorlink4=
 |language = 
 |format = 
 |ARXIV=
 |ASIN=
 |BIBCODE=
 |DOI=
 |DoiBroken=
 |ISBN=
 |ISSN=
 |JFM=
 |JSTOR=
 |LCCN=
 |MR=
 |OCLC=
 |OL=
 |OSTI=
 |PMC=
 |Embargo=1010-10-10
 |PMID=
 |RFC=
 |SSRN=
 |ZBL=
 |ID=
 |AccessDate=
 |DateFormat=none
 |quote = 
 |laysummary = 
 |laydate = 
 |Ref=
 |Sep = .
 |PS = .
 |AuthorSep = ; 
 |NameSep = , 
 |Trunc = 8
 |amp = 
}} See original text in .
 #if: 
 #if:  
 |, 
 #if: 
 }}{{
 #if: 
 #if: 
 | ()
 |{{
 #if: 
 #if: 
 | {{#if:||}}{{
 #if: 
 #if: 
 #if: {{
 #if: Moral letters to Lucilius/Letter 58Moral Letters to Lucilius: Letter 58
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 |: {{
 #if: Moral letters to Lucilius/Letter 58Moral Letters to Lucilius: Letter 58
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 
 #if:  
 |{{
 #if: Seneca the Younger
 |,
 }} {{Citation/make link
 | 1={{
 #if: 
 #if: 
 #if: 
 |{{
 #if: 
 | 2="  
 #if:| []
 #if: 
 }}{{
 #if: 
 }}{{
 #if: 
 }}{{
 #if: 
 }}{{
 #if: 
 | ( ed.)
 #if: 
 }}{{
 #if: 
 #if: 
 |,
 #if: Seneca the Younger
 |
 #if: 
 #if:
}}{{
 #if: 
 #ifeq: | 
 |{{
 #if: 
 #if: Seneca the Younger
 |, 
 | (published )
 |{{
 #if: 
 | (published )
}}{{
 #if: 
 |{{
 #if: {{
 #if: Moral letters to Lucilius/Letter 58Moral Letters to Lucilius: Letter 58
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 |, {{
 #if: Moral letters to Lucilius/Letter 58Moral Letters to Lucilius: Letter 58
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
}}{{
 #if:
 | , {{#ifeq: | no
 | {{#if:
 |{{Citation/make link||{{#ifeq:|.|A|a}}rchived}} from the original
 |{{#ifeq:|.|A|a}}rchived
 | {{#ifeq:|.|A|a}}rchived{{#if:
 }}{{#if:| on }}{{
 |. {{citation error|nocat=
 #if:  
 |, {{
 #if: 
 |
 |, {{
 #if: 
 |
 }}{{
 #if: 
 | {{#ifeq:|,|, r|. R}}etrieved 
}}{{#if:
}}{{#if:
}}{{#if:
}}<span
 class="Z3988"
 title="ctx_ver=Z39.88-2004&rft_val_fmt={{urlencode:info:ofi/fmt:kev:mtx:}}{{
 #if: 
 |journal&rft.genre=article&rft.atitle={{urlencode:  
 |book{{
 #if: 
 |&rft.genre=bookitem&rft.btitle={{urlencode:}}&rft.atitle={{urlencode:  
 |&rft.genre=book&rft.btitle={{urlencode:  
 #if: Seneca the Younger
 |&rft.aulast={{urlencode: Seneca the Younger
 }}{{
 #if: Seneca the Younger
 |&rft.au={{urlencode: Seneca the Younger
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: {{
 #if: Moral letters to Lucilius/Letter 58Moral Letters to Lucilius: Letter 58
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 |&rft.pages={{urlencode: {{
 #if: Moral letters to Lucilius/Letter 58Moral Letters to Lucilius: Letter 58
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 }}{{
 }}&rfr_id=info:sid/en.wikipedia.org:{{FULLPAGENAMEE}}"> 
 |IncludedWorkTitle = 
 |IncludedWorkURL = 
 |Other = Translated by Richard Mott Gummere
 |Edition = 
 |Place = 
 |PublicationPlace = 
 |Publisher = Wikisource
 |PublicationDate = 
 |EditorSurname1 = 
 |EditorSurname2 = 
 |EditorSurname3 = 
 |EditorSurname4 = 
 |EditorGiven1 = 
 |EditorGiven2=
 |EditorGiven3=
 |EditorGiven4=
 |Editorlink1=
 |Editorlink2=
 |Editorlink3=
 |Editorlink4=
 |language = 
 |format = 
 |ARXIV=
 |ASIN=
 |BIBCODE=
 |DOI=
 |DoiBroken=
 |ISBN=
 |ISSN=
 |JFM=
 |JSTOR=
 |LCCN=
 |MR=
 |OCLC=
 |OL=
 |OSTI=
 |PMC=
 |Embargo=1010-10-10
 |PMID=
 |RFC=
 |SSRN=
 |ZBL=
 |ID=
 |AccessDate=
 |DateFormat=none
 |quote = 
 |laysummary = 
 |laydate = 
 |Ref=
 |Sep = .
 |PS = .
 |AuthorSep = ; 
 |NameSep = , 
 |Trunc = 8
 |amp = 
}} See original text in .
 #if: 
 #if:  
 |, 
 #if: 
 }}{{
 #if: 
 #if: 
 | ()
 |{{
 #if: 
 #if: 
 | {{#if:||}}{{
 #if: 
 #if: 
 #if: {{
 #if: History of the Peloponnesian War
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 |: {{
 #if: History of the Peloponnesian War
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 
 #if:  
 |{{
 #if: Thucydides
 |,
 }} {{Citation/make link
 | 1={{
 #if: 
 #if: 
 #if: 
 |{{
 #if: 
 | 2="  
 #if:| []
 #if: 
 }}{{
 #if: 
 }}{{
 #if: 
 }}{{
 #if: 
 }}{{
 #if: 
 | ( ed.)
 #if: 
 }}{{
 #if: 
 #if: 
 |,
 #if: Thucydides
 |
 #if: 
 #if:
}}{{
 #if: 
 #ifeq: | 
 |{{
 #if: 
 #if: Thucydides
 |, 
 | (published )
 |{{
 #if: 
 | (published )
}}{{
 #if: 
 |{{
 #if: {{
 #if: History of the Peloponnesian War
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 |, {{
 #if: History of the Peloponnesian War
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
 #if: 
}}{{
 #if:
 | , {{#ifeq: | no
 | {{#if:
 |{{Citation/make link||{{#ifeq:|.|A|a}}rchived}} from the original
 |{{#ifeq:|.|A|a}}rchived
 | {{#ifeq:|.|A|a}}rchived{{#if:
 }}{{#if:| on }}{{
 |. {{citation error|nocat=
 #if:  
 |, {{
 #if: 
 |
 |, {{
 #if: 
 |
 }}{{
 #if: 
 | {{#ifeq:|,|, r|. R}}etrieved 
}}{{#if:
}}{{#if:
}}{{#if:
}}<span
 class="Z3988"
 title="ctx_ver=Z39.88-2004&rft_val_fmt={{urlencode:info:ofi/fmt:kev:mtx:}}{{
 #if: 
 |journal&rft.genre=article&rft.atitle={{urlencode:  
 |book{{
 #if: 
 |&rft.genre=bookitem&rft.btitle={{urlencode:}}&rft.atitle={{urlencode:  
 |&rft.genre=book&rft.btitle={{urlencode:  
 #if: Thucydides
 |&rft.aulast={{urlencode: Thucydides
 }}{{
 #if: Thucydides
 |&rft.au={{urlencode: Thucydides
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: |&rft.au={{urlencode:}}{{
 }}{{
 #if: {{
 #if: History of the Peloponnesian War
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 |&rft.pages={{urlencode: {{
 #if: History of the Peloponnesian War
 #if: 
 #if: 
 #switch: 
 #if: 
 #if: 
 |{{
 #switch: 
 #if: 
 #if: 
 }}{{
 }}&rfr_id=info:sid/en.wikipedia.org:{{FULLPAGENAMEE}}"> 
 |IncludedWorkTitle = 
 |IncludedWorkURL = 
 |Other = Translated by Richard Crawley
 |Edition = 
 |Place = 
 |PublicationPlace = 
 |Publisher = Wikisource
 |PublicationDate = 
 |EditorSurname1 = 
 |EditorSurname2 = 
 |EditorSurname3 = 
 |EditorSurname4 = 
 |EditorGiven1 = 
 |EditorGiven2=
 |EditorGiven3=
 |EditorGiven4=
 |Editorlink1=
 |Editorlink2=
 |Editorlink3=
 |Editorlink4=
 |language = 
 |format = 
 |ARXIV=
 |ASIN=
 |BIBCODE=
 |DOI=
 |DoiBroken=
 |ISBN=
 |ISSN=
 |JFM=
 |JSTOR=
 |LCCN=
 |MR=
 |OCLC=
 |OL=
 |OSTI=
 |PMC=
 |Embargo=1010-10-10
 |PMID=
 |RFC=
 |SSRN=
 |ZBL=
 |ID=
 |AccessDate=
 |DateFormat=none
 |quote = 
 |laysummary = 
 |laydate = 
 |Ref=
 |Sep = .
 |PS = .
 |AuthorSep = ; 
 |NameSep = , 
 |Trunc = 8
 |amp = 
}}, V, VIII. See original text in .
</dl>
Secondary sources.
</dl>
Further reading.
</dl>

</doc>
<doc id="22958" url="http://en.wikipedia.org/wiki?curid=22958" title="Sample space">
Sample space

In probability theory, the sample space of an experiment or random trial is the set of all possible outcomes or results of that experiment. A sample space is usually denoted using set notation, and the possible outcomes are listed as elements in the set. It is common to refer to a sample space by the labels "S", Ω, or "U" (for "universal set").
For example, if the experiment is tossing a coin, the sample space is typically the set {head, tail}. For tossing two coins, the corresponding sample space would be {(head,head), (head,tail), (tail,head), (tail,tail)}. For tossing a single six-sided die, the typical sample space is {1, 2, 3, 4, 5, 6} (in which the result of interest is the number of pips facing up).
A well-defined sample space is one of three basic elements in a probabilistic model (a probability space); the other two are a well-defined set of possible events (a sigma-algebra) and a probability assigned to each event (a probability measure function).
Multiple sample spaces.
For many experiments, there may be more than one plausible sample space available, depending on what result is of interest to the experimenter. For example, when drawing a card from a standard deck of fifty-two playing cards, one possibility for the sample space could be the various ranks (Ace through King), while another could be the suits (clubs, diamonds, hearts, or spades). A more complete description of outcomes, however, could specify both the denomination and the suit, and a sample space describing each individual card can be constructed as the Cartesian product of the two sample spaces noted above (this space would contain fifty-two equally likely outcomes). Still other sample spaces are possible, such as {right-side up, up-side down} if some cards have been flipped when shuffling.
Equally likely outcomes.
In some sample spaces, it is reasonable to estimate or assume that all outcomes in the space are equally likely (that they occur with equal probability). For example, when tossing an ordinary coin, one typically assumes that the outcomes "head" and "tail" are equally likely to occur. An implicit assumption that all outcomes in the sample space are equally likely underpins most randomization tools used in common games of chance (e.g. rolling dice, shuffling cards, spinning tops or wheels, drawing lots, etc.). Of course, players in such games can try to cheat by subtly introducing systematic deviations from equal likelihood (e.g. with marked cards, loaded or shaved dice, and other methods).
Some treatments of probability assume that the various outcomes of an experiment are always defined so as to be equally likely. However, there are experiments that are not easily described by a sample space of equally likely outcomes— for example, if one were to toss a thumb tack many times and observe whether it landed with its point upward or downward, there is no symmetry to suggest that the two outcomes should be equally likely.
Though most random phenomena do not have equally likely outcomes, it can be helpful to define a sample space in such a way that outcomes are at least approximately equally likely, since this condition significantly simplifies the computation of probabilities for events within the sample space. If each individual outcome occurs with the same probability, then the probability of any event becomes simply::346–347
Simple random sample.
In statistics, inferences are made about characteristics of a population by studying a sample of that population's individuals. In order to arrive at a sample that presents an unbiased estimate of the true characteristics of the population, statisticians often seek to study a simple random sample— that is, a sample in which every individual in the population is equally likely to be included.:274–275 The result of this is that every possible combination of individuals who could be chosen for the sample is also equally likely (that is, the space of simple random samples of a given size from a given population is composed of equally likely outcomes).
Infinitely large sample spaces.
In an elementary approach to probability, any subset of the sample space is usually called an event. However, this gives rise to problems when the sample space is infinite, so that a more precise definition of an event is necessary. Under this definition only measurable subsets of the sample space, constituting a σ-algebra over the sample space itself, are considered events.
However, this has essentially only theoretical significance, since in general the σ-algebra can always be defined to include all subsets of interest in applications.

</doc>
<doc id="22960" url="http://en.wikipedia.org/wiki?curid=22960" title="Elementary event">
Elementary event

In probability theory, an elementary event (also called an atomic event or simple event) is an event which contains only a single outcome in the sample space. Using set theory terminology, an elementary event is a singleton. Elementary events and their corresponding outcomes are often written interchangeably for simplicity, as such an event corresponds to precisely one outcome. 
The following are examples of elementary events:
Probability of an elementary event.
Elementary events may occur with probabilities that are between zero and one (inclusively). In a discrete probability distribution whose sample space is finite, each elementary event is assigned a particular probability. In contrast, in a continuous distribution, individual elementary events must all have a probability of zero because there are infinitely many of them— then non-zero probabilities can only be assigned to non-elementary events. 
Some "mixed" distributions contain both stretches of continuous elementary events and some discrete elementary events; the discrete elementary events in such distributions can be called atoms or atomic events and can have non-zero probabilities. 
Under the measure-theoretic definition of a probability space, the probability of an elementary event need not even be defined. In particular, the set of events on which probability is defined may be some σ-algebra on "S" and not necessarily the full power set.

</doc>
<doc id="22961" url="http://en.wikipedia.org/wiki?curid=22961" title="Event (probability theory)">
Event (probability theory)

In probability theory, an event is a set of outcomes of an experiment (a subset of the sample space) to which a probability is assigned. A single outcome may be an element of many different events, and different events in an experiment are usually not equally likely, since they may include very different groups of outcomes. An event defines a complementary event, namely the complementary set (the event "not" occurring), and together these define a Bernoulli trial: did the event occur or not?
Typically, when the sample space is finite, any subset of the sample space is an event ("i"."e". all elements of the power set of the sample space are defined as events). However, this approach does not work well in cases where the sample space is uncountably infinite, most notably when the outcome is a real number. So, when defining a probability space it is possible, and often necessary, to exclude certain subsets of the sample space from being events (see "Events in probability spaces", below).
A simple example.
If we assemble a deck of 52 playing cards with no jokers, and draw a single card from the deck, then the sample space is a 52-element set, as each card is a possible outcome. An event, however, is any subset of the sample space, including any singleton set (an elementary event), the empty set (an impossible event, with probability zero) and the sample space itself (a certain event, with probability one). Other events are proper subsets of the sample space that contain multiple elements. So, for example, potential events include: 
Since all events are sets, they are usually written as sets (e.g. {1, 2, 3}), and represented graphically using Venn diagrams. Given that each outcome in the sample space Ω is equally likely, the probability of an event "A" is the following formula: 
This rule can readily be applied to each of the example events above.
Events in probability spaces.
Defining all subsets of the sample space as events works well when there are only finitely many outcomes, but gives rise to problems when the sample space is infinite. For many standard probability distributions, such as the normal distribution, the sample space is the set of real numbers or some subset of the real numbers. Attempts to define probabilities for all subsets of the real numbers run into difficulties when one considers 'badly behaved' sets, such as those that are nonmeasurable. Hence, it is necessary to restrict attention to a more limited family of subsets. For the standard tools of probability theory, such as joint and conditional probabilities, to work, it is necessary to use a σ-algebra, that is, a family closed under complementation and countable unions of its members. The most natural choice is the Borel measurable set derived from unions and intersections of intervals. However, the larger class of Lebesgue measurable sets proves more useful in practice.
In the general measure-theoretic description of probability spaces, an event may be defined as an element of a selected σ-algebra of subsets of the sample space. Under this definition, any subset of the sample space that is not an element of the σ-algebra is not an event, and does not have a probability. With a reasonable specification of the probability space, however, all "events of interest" are elements of the σ-algebra.
A note on notation.
Even though events are subsets of some sample space Ω, they are often written as propositional formulas involving random variables. For example, if "X" is a real-valued random variable defined on the sample space Ω, the event
can be written more conveniently as, simply,
This is especially common in formulas for a probability, such as
The set "u" < "X" ≤ "v" is an example of an inverse image under the mapping "X" because formula_5 if and only if formula_6.

</doc>
<doc id="22973" url="http://en.wikipedia.org/wiki?curid=22973" title="Pig Latin">
Pig Latin

 
Pig Latin is a language in which words in English are altered, according to Aiden Latin. The objective is to conceal the meaning of the words from others not familiar with the rules. The reference to Latin is a deliberate misnomer, as it is simply a form of jargon, used only for its English connotations as a strange and foreign-sounding language.
Origins.
The origins of Pig Latin are unknown. A youthful Thomas Jefferson wrote letters to friends in Pig Latin. One early mention of the name was in "Putnam's Magazine" in May "1869" "I had plenty of ammunition in reserve, to say nothing, Tom, of our pig Latin. 'Hoggibus, piggibus et shotam damnabile grunto,' and all that sort of thing," although the language cited is not modern Pig Latin, but rather what would be called today Dog Latin.
"The Atlantic" January 1895 also included a mention of the subject: "They all spoke a queer jargon which they themselves had invented. It was something like the well-known 'pig Latin' that all sorts of children like to play with."
Rules.
For words that begin with consonant sounds, the initial consonant or consonant cluster is moved to the end of the word, and "ay" (some people just add "a") is added, as in the following examples:
For words which begin with vowel sounds or silent letter, one just adds "way" (or "wa") to the end. Examples are:
This is to avoid having for speakers to disfavor pronouncing otherwise hard words which either sounds awkward, the human tongue cannot articulate, or both. As opposed to the last three examples above, the avoided words are:
Some people also follow this rule with words that begin with vowel sounds, only the first letter is moved to the end of the word, then one just adds "way" after. 
Examples:
Some people who speak Pig Latin follow an alternate second rule; this version of the rule dictates that if a word begins with a vowel (either a, e, i, o, or u) only the first letter is moved and the phrase added to the end is "i", however this form is fairly uncommon.
Examples:
Similar language games.
In English.
Similar languages to Pig Latin are Opish, in which "op" is added after each consonant (thus, "cat" becomes "copatop"); Turkey Irish, in which "ab" is added before each vowel (thus, "run" becomes "rabun"), and Double Dutch, in which each consonant is replaced with a different consonant cluster (thus, "how are you" becomes ""hutch"o"wash" a"rug"e "yub"ou").
In popular culture.
Among other "languages", Google provides an option for displaying the site in Pig Latin. "Images" becomes "Imagesway", "Blogger" "Oggerblay", and "Sign In" "Ignsay Inway".
In the opening of the film "Gold Diggers of 1933", Ginger Rogers sings a verse of "We're in the Money" in Pig Latin.
The American punk rock band The Offspring's fourth studio album is entitled "Ixnay on the Hombre".
Pig Latin is mentioned in the autobiographical novel "I Know Why The Caged Bird Sings" by author Maya Angelou.
The song "Who Gon Stop Me" on the 2011 album "Watch the Throne" by Kanye West and Jay-Z mentions Pig Latin and includes the lyrics "itch-bay", "ixnay" and "dicksnay".
The song "Rap Game" by D12 and 50 Cent on the soundtrack to the 2002 movie "8 Mile" includes lyrics in Pig Latin.
The song "Gettin' Jiggy With It" by Will Smith includes lyrics in Pig Latin.
In November 2013, Microsoft launched a negative advertising campaign against Google promoting their electronic communication services; Outlook, referencing this language with the claim that using it enables you to avoid Gmail's advertisement algorithms.
In episode 18 of Two and a Half Men (season 7) 'Ixnay on the Oggie Day', Charlie Harper tells Gail to keep what happened between them as a secret in Pig Latin- 'Ixnay on the Oggie Day aisle stay'. It can be translated as - 'Nix on the doggie style'.
In the comedic film "Polyester" the character Cuddles Kovinsky, a poor maid who has inherited a large sum of money, answers the phone in pig Latin.
In "The Lion King", Zazu says "ixnay on the upid-stay", to warn Simba and Nala to stop talking about the hyenas. One of the hyenas, Banzai replies "Who you callin' upid-stay?"
In "Monsters, Inc.", Sully, whilst trying to keep the fact he has a human child in his bag secret from those around him, whispers to Mike to "Ooklay in the agbay", before explaining "Look in the bag" when Mike doesn't comprehend.
In the episode "Dear Mildred," in the fourth season of the television program "M*A*S*H" the character Margaret Houlihan addresses the character Frank Burns with a short sentence in Pig Latin, the joke being that it takes Burns several seconds to interpret what she has told him.
In a "Phineas and Ferb" episode of "Ferb Latin", the language game, named after Ferb, is deliberately a game which is inspired by Pig Latin; only, users take the first consonant, place it at the end if the word, and end the word entirely by using "fur". An example in the episode would be "nakesfur" (or, snake).
In 2014, a Geico commercial makes use of Pig Latin, where a couple is shown talking in Pig Latin to avoid being understood by one of the Geico mascots, which ironically, is a pig.
In "Racing Stripes", Franny said to Tucker that Stripes asked him why would he quit training the racehorses "Ixnay on the other-may. Comprende?" Tucker replies "Just say what you mean, Franny. We haven't spoken Latin since the pigs left."
In a 2014 episode of USA "Who Wants to Be A Millionaire", hosted by Terry Crews, contestant Bryan McMullin was asked "Isthay estionquay isay ittenwray inay atwhay anguagelay?" (This question is written in what language?) with the correct response being 'Pig Latin'. 
In the movie "Short Circuit 2", just before Johnny 5 is attacked, there is a bit of Pig Latin. The sentence was "Etgay Ehindbay Imhay", as Oscar instructs his cohorts to sneak up behind Johnny..
There is a short conversation in Pig Latin in "The Mask" where the Lieutenant tries to tell his partner that Stanley has a gun, to which his partner replies "Pig Latin, right? Eesay ouya aterlay."
In the song "God Of No More", on the 2014 album "Player Select" by Starbomb, Kratos says that he also killed the God of Pig Latin: "And I even ewslay the ittlelay itchbay odgay of Pig Latin!"
In the children's novel series "Dragon Slayers' Academy" by Kate McMullan, the main protagonist, Wiglaf is fluent in pig Latin as a result of his best friend/pet pig, Daisy, speaking in it after the wizard, Zelnoc, granted the pig the ability of speech due to Wiglaf's wish. However, the spell went wrong and the pig could only speak Pig Latin rather than regular English.
In other languages.
In Bernese German, a variety of Pig Latin called Mattenenglisch was used in the "Matte", the traditional working-class neighborhood. Though it has fallen out of use since the mid-20th century, it is still cultivated by voluntary associations. A characteristic of the Mattenenglisch Pig Latin is the complete substitution of the first vowel by "i", in addition to the usual moving of the initial consonant cluster and the adding of "ee".
The Swedish equivalent of Pig Latin is Allspråket, which uses the same or similar rules but with the suffix "-all." Additionally, the Swedish language game Fikonspråket ("Fig language") is similar to Pig Latin. Further, Norwegian, Danish and Swedish languages have "Røverspråket/Røversproget/Rövarspråket" (English: The robber language"), where consonants (spelling matters, not pronunciation) are doubled, and an o is inserted in-between ( t = tot). Vowels are left intact. For example would the sentence "I love bacon" become " I lolovove bobacocanon" in the robber language. 
French has the "loucherbem" (or "louchébem", aka "largonji") coded language, which supposedly was originally used by butchers ("boucher" in French). In "loucherbem", the leading consonant cluster is moved to the end of the word (as in Pig Latin) and replaced by an "l", and then a suffix is added at the end of the word (-"oche", -"em", -"oque", etc., depending on the word). Example: "combien" (how much) = "lombienquès". Similar coded languages are "verlan" and "langue de feu". A few louchébem words have become usual French words: "fou" (crazy) = "loufoque", "portefeuille" (wallet) = "larfeuille", "en douce" (on the quiet) = "en loucedé".
The Portuguese language equivalent of Pig Latin is called Língua do Pê ("P Language", in Portuguese), which has at least three different variations.
Another equivalent of Pig Latin is used throughout Balkan. It is called "Šatra" (/sha-tra/)or "Šatrovački" (/shatro-vachki/) and was used in crime-related and street language. For instance, marihuana (trava) turns to "vutra", Balkan slang name for cocaine (belo - meaning "white") turns to lobe, a pistol (pištolj) turns to štoljpi, bro (brate) turns to tebra. In the past few years it has become widely used between teenage immigrants in former Yugoslavian countries.
In computer games.
"Total Annihilation" references Pig Latin.
Pig Latin has been used extensively by most characters in "Rayman Origins" game developed by Ubisoft.
References.
</dl>

</doc>
<doc id="22975" url="http://en.wikipedia.org/wiki?curid=22975" title="Polish language">
Polish language

Polish ("język polski", "polszczyzna") is a Slavic language spoken primarily in Poland and the native language of the Poles. It belongs to the Lechitic subgroup of West Slavic languages. Polish is the official language of Poland, but it is also used throughout the world by Polish minorities in other countries. It is one of the official languages of the European Union. Its written standard is the Polish alphabet, which has 9 additions to the letters of the basic Latin script ("ą", "ć", "ę", "ł", "ń", "ó", "ś", "ź", "ż"). Polish is closely related to Kashubian, Lower Sorbian, Upper Sorbian, Czech and Slovak.
Although the Austrian, German and Russian administrations exerted much pressure on the Polish nation (during the 19th and early 20th centuries) following the Partitions of Poland, which resulted in attempts to suppress the Polish language, a rich literature has regardless developed over the centuries and the language currently has the largest number of speakers of the West Slavic group. It is also the second most widely spoken Slavic language, after Russian and just ahead of Ukrainian, which comes third.
In history, Polish is known to be an important language, both diplomatically and academically in Central and Eastern Europe. Today, Polish is spoken by over 38.5 million people as their first language in Poland. It is also spoken as a second language in western parts of Belarus, Lithuania and Ukraine, as well as northern parts of the Czech Republic and Slovakia. Because of the emigration from Poland during different time periods, most notably after World War II, millions of Polish speakers can be found in countries such as Australia, Brazil, Canada, the United Kingdom and the United States. There are 40 million Polish language speakers around the world.
History.
The originality of Polish culture is tied to its language and to its Slavonic roots. Linguistic studies indicate that 5000 to 4000 years ago early Balto-Slavic languages were part of the Aryan or the Eastern Indo-European languages. Over 3500 years ago, the languages of the Balto-Slavs separated from the Aryan languages; some 3000 years ago, the Baltic and Slavic languages separated from each other; and for the next 1500 years, the Slavic languages evolved parallel to the Greek, Latin, Celtic, Germanic, and other languages. The evolution of the Polish language occurred during the following 1500 years.
Polish began to emerge around the 10th century, the process largely triggered by the establishment and development of the Polish state. Mieszko I, ruler of the Polans tribe from Greater Poland region, united a few culturally and linguistically related tribes from the basins of the Vistula and Odra before eventually accepting baptism in 966. With Christianity, Poland also adopted the Latin alphabet, which made it possible to write down Polish, until then existing only as a spoken language.
The precursor to modern Polish is the Old Polish language. Ultimately, Polish is thought to descend from the unattested Proto-Slavic language.
Polish was a "lingua franca" from 1500-1700 in small parts of Central and large portions of Eastern Europe, because of the political, cultural, scientific and military influence of the Polish-Lithuanian Commonwealth.
Geographic distribution.
Poland is the most linguistically homogeneous European country; nearly 97% of Poland's citizens declare Polish as their native language. Elsewhere, ethnic Poles constitute large minorities in Lithuania, Belarus, and Ukraine. Polish is the most widely used minority language in Lithuania's Vilnius (Wilno) County (26% of the population, according to the 2001 census results, with Wilno (Vilnius) having been part of Poland until 1939) and is found elsewhere in southeastern Lithuania. In Ukraine it is most common in the western Lwów (Lviv) and Wołyń (Volyn) "oblast" (provinces), while in Western Belarus it is used by the significant Polish minority, especially in the Brest and Grodno regions and in areas along the Lithuanian border.
There are also significant numbers of Polish speakers among Polish emigrants and their descendants in many other countries, including Argentina, Andorra, Australia, Austria, Azerbaijan, Belarus, Belgium, Brazil, Canada, the Czech Republic, Croatia, Denmark, Estonia, the Faroe Islands, Finland, France, Germany, Greece, Hungary, Israel, Iceland, Ireland, Italy, Kazakhstan, Latvia, Lebanon, Luxembourg, Mexico, the Netherlands, New Zealand, Norway, Peru, Portugal, Romania, Russia, Serbia, Slovakia, Slovenia, South Africa, Sweden, Spain, Turkey, Ukraine, the UAE, the UK, the United States, and Uruguay.
In the United States, Polish Americans number more than 11 million (See also: Polish language in the United States) but most of them cannot speak Polish fluently. According to the United States 2000 Census, 667,414 Americans of age five years and over reported Polish as the language spoken at home, which is about 1.4% of people who speak languages other than English, 0.25% of the US population, and 6% of the Polish-American population. The largest concentrations of Polish speakers reported in the census (over 50%) were found in three states: Illinois (185,749), New York (111,740), and New Jersey (74,663). Enough people in these areas speak Polish that PNC Financial Services (which has a large number of branches and ATMs in all of these areas) offer ATM services available in Polish at all of their ATMs in addition to English and Spanish.
According to the 2011 census there are now over 500,000 people in England and Wales who consider Polish to be their "main" language. In Canada, there is a significant Polish Canadian population: There are 242,885 speakers of Polish according to the 2006 census, with a particular concentration in Toronto (91,810 speakers) and Montreal.
The geographical distribution of the Polish language was greatly affected by the border changes and population transfers that followed World War II. Poles settled in the "Recovered Territories" in the west and north, which had previously been mostly German-speaking. Some Poles remained in the previously Polish-ruled territories in the east that were annexed by the USSR, resulting in the present-day Polish-speaking minorities in Lithuania, Belarus, and Ukraine, although many Poles were expelled or emigrated from those areas to areas within Poland's new borders. Meanwhile the flight and expulsion of Germans, as well as the expulsion of Ukrainians and resettlement of Ukrainians within Poland, contributed to the country's linguistic homogeneity.
Dialects.
The Polish language became far more homogeneous in the second half of the 20th century, in part due to the mass migration of several million Polish citizens from the eastern to the western part of the country after the Soviet annexation of the Kresy in 1939, and the acquisition of former German territory after World War II. This tendency toward a homogeneity also stems from the vertically integrated nature of the authoritarian Polish People's Republic.
The inhabitants of different regions of Poland still[ [update]] speak "standard" Polish somewhat differently, although the differences between regional dialects appear slight. First-language speakers of Polish have no trouble understanding each other, and non-native speakers may have difficulty distinguishing regional variations.
Polish is normally described as consisting of four or five main dialects:
Kashubian, spoken in the Pomorze region west of Gdańsk on the Baltic Sea, is often considered a fifth dialect. It contains a number of features not found elsewhere in Poland, e.g. nine distinct oral vowels (vs. the five of standard Polish) and (in the northern dialects) phonemic word stress, an archaic feature preserved from Common Slavic times and not found anywhere else among the West Slavic languages. However, it "lacks most of the linguistic and social determinants of language-hood".
Many linguistic sources about the Slavic languages describe Silesian as a dialect of Polish. However, many Silesians consider themselves a separate ethnicity and have been advocating for the recognition of a Silesian language. According to the last official census in Poland in 2011, over half a million people declared Silesian as their native language. Many sociolinguistic sources (e.g. by Tomasz Kamusella, Agnieszka Pianka, Alfred F. Majewicz, Tomasz Wicherkiewicz) assume that extralinguistic criteria decide whether something is a language or a dialect of the language: users of speech or/and political decisions, and this is dynamic (i.e. change over time). Also, language organizations like as SIL International and resources for the academic field of linguistics like as Ethnologue, Linguist List and other, for example Ministry of Administration and Digitization recognized Silesian language. In July 2007, the Silesian language was recognized by an ISO, was attributed an ISO code of szl.
Some more characteristic but less widespread regional dialects include:
Phonology.
Polish has six oral vowels (all monophthongs) and two nasal vowels. The oral vowels are (spelled "i"), /ɨ/ (spelled "y"), (spelled "e"), (spelled "a"), (spelled "o") and (spelled "u" or "ó"). The nasal vowels are (spelled "ę") and (spelled "ą").
The Polish consonant system shows more complexity: its characteristic features include the series of affricates and palatal consonants that resulted from four Proto-Slavic palatalizations and two further palatalizations that took place in Polish and Belarusian. The full set of consonants, together with their most common spellings, can be presented as follows (although other phonological analyses exist):
Neutralization occurs between voiced–voiceless consonant pairs in certain environments: at the end of words (where devoicing occurs), and in certain consonant clusters (where assimilation occurs). For details, see "Voicing and devoicing" in the article on Polish phonology.
Most Polish words are paroxytones (that is, the stress falls on the second-to-last syllable of a polysyllabic word), although there are exceptions.
Orthography.
The Polish alphabet derives from the Latin script, but includes certain additional letters formed using diacritics. The Polish alphabet was one of three major forms of Latin-based orthography developed for Slavic languages, the other being Czech orthography and Croatian orthography, the latter being a 19th-century invention trying to make a compromise between the first two. Kashubian uses a Polish-based system, Slovak uses a Czech-based system, and Slovene follows the Croatian one; the Sorbian languages blend the Polish and the Czech ones.
The diacritics used in the Polish alphabet are the "kreska" (graphically similar to the acute accent) in the letters "ć, ń, ó, ś, ź" and through the letter in "ł"; the "kropka" (superior dot) in the letter "ż", and the "ogonek" ("little tail") in the letters "ą, ę". The letters "q, v, x" are often not considered part of the Polish alphabet; they are used only in foreign words and names.
Polish orthography is largely phonemic—there is a consistent correspondence between letters (or digraphs and trigraphs) and phonemes (for exceptions see below). The letters of the alphabet and their normal phonemic values are listed in the following table.
The following digraphs and trigraphs are used:
Voiced consonant letters frequently come to represent voiceless sounds (as shown in the tables); this occurs at the end of words and in certain clusters, due to the neutralization mentioned in the "Phonology" section above. Occasionally also voiceless consonant letters can represent voiced sounds in clusters.
The spelling rule for the palatal sounds , , /tɕ/, /dʑ/ and /ɲ/ is as follows: before the vowel "i" the plain letters "s, z, c, dz, n" are used; before other vowels the combinations "si, zi, ci, dzi, ni" are used; when not followed by a vowel the diacritic forms "ś, ź, ć, dź, ń" are used. For example, the "s" in "siwy" ("grey-haired"), the "si" in "siarka" ("sulphur") and the "ś" in "święty" ("holy") all represent the sound . The exceptions to the above rule are certain loanwords from Latin, Italian, French, Russian or English—where "s" before "i" is pronounced as "s", e.g. "sinus", "sinologia", "do re mi fa sol la si do", "Saint-Simon i saint-simoniści", "Sierioża", "Siergiej", "Singapur", "singiel". In other loanwords the vowel "i" is changed to "y", e.g. "Syria", "Sybir", "synchronizacja", "Syrakuzy".
The following table shows the correspondence between the sounds and spelling:
digraphs and trigraphs are used:
Similar principles apply to /kʲ/, /ɡʲ/, /xʲ/ and /lʲ/, except that these can only occur before vowels, so the spellings are "k, g, (c)h, l" before "i", and "ki, gi, (c)hi, li" otherwise. Most Polish speakers, however, do not consider palatalisation of "k, g, (c)h" or "l" as creating new sounds.
Except in the cases mentioned above, the letter "i" if followed by another vowel in the same word usually represents , yet a palatalisation of the previous consonant is always assumed.
The letters "ą" and "ę", when followed by plosives and affricates, represent an oral vowel followed by a nasal consonant, rather than a nasal vowel. For example, "ą" in "dąb" ("oak") is pronounced , and "ę" in "tęcza" ("rainbow") is pronounced (the nasal assimilates with the following consonant). When followed by "l" or "ł" (for example "przyjęli", "przyjęły"), "ę" is pronounced as just "e". When "ę" is at the end of the word it is often pronounced as just .
Note that, depending on the word, the phoneme can be spelt "h" or "ch", the phoneme can be spelt "ż" or "rz", and can be spelt "u" or "ó". In several cases it determines the meaning, for example: "może" ("maybe") and "morze" ("sea").
In occasional words, letters that normally form a digraph are pronounced separately. For example, "rz" represents , not , in words like "zamarzać" ("freeze") and in the name "Tarzan".
Notice that doubled letters represent separate occurrences of the sound in question; for example "Anna" is pronounced in Polish (the double "n" is often pronounced as a lengthened single "n").
There are certain clusters where a written consonant would not be pronounced. For example, the "ł" in the words "mógł" ("could") and "jabłko" ("apple") might be omitted in ordinary speech, leading to the pronunciations "muk" and "japko" or "jabko".
Grammar.
Polish is a highly inflected language, with relatively free word order, although the dominant arrangement is subject–verb–object (SVO). There are no articles, and subject pronouns are often dropped.
Nouns may belong to three genders: masculine, feminine and neuter. A distinction is also made between animate and inanimate masculine nouns in the singular, and between masculine personal and non-personal nouns in the plural. There are seven cases: nominative, genitive, dative, accusative, instrumental, locative and vocative.
Adjectives agree with nouns in terms of gender, case and number. Attributive adjectives most commonly precede the noun, although in certain cases, especially in fixed phrases (like "język polski", "Polish (language)"), the noun may come first. Most short adjectives and their derived adverbs form comparatives and superlatives by inflection (the superlative is formed by prefixing "naj-" to the comparative).
Verbs are of imperfective or perfective aspect, often occurring in pairs. Imperfective verbs have a present tense, past tense, compound future tense (except for "być" "to be", which has a simple future "będę" etc., this in turn being used to form the compound future of other verbs), subjunctive/conditional (formed with the detachable particle "by"), imperatives, an infinitive, present participle, present gerund and past participle. Perfective verbs have a simple future tense (formed like the present tense of imperfective verbs), past tense, subjunctive/conditional, imperatives, infinitive, present gerund and past participle. Conjugated verb forms agree with their subject in terms of person, number, and (in the case of past tense and subjunctive/conditional forms) gender.
Passive-type constructions can be made using the auxiliary "być" or "zostać" ("become") with the passive participle. There is also an impersonal construction where the active verb is used (in third person singular) with no subject, but with the reflexive pronoun "się" present to indicate a general, unspecified subject (as in "pije się wódkę" "vodka is drunk"—note that "wódka" appears in the accusative). A similar sentence type in the past tense uses the passive participle with the ending "-o", as in "widziano ludzi" ("people were seen"). As in other Slavic languages, there are also subjectless sentences formed using such words as "można" ("it is possible") together with an infinitive.
Yes-no questions (both direct and indirect) are formed by placing the word "czy" at the start. Negation uses the word "nie", before the verb or other item being negated; "nie" is still added before the verb even if the sentence also contains other negatives such as "nigdy" ("never") or "nic" ("nothing").
Cardinal numbers have a complex system of inflection and agreement. Numbers higher than five (except for those ending with the digit 2, 3 or 4) govern the genitive case rather than the nominative or accusative. Special forms of numbers (collective numerals) are used with certain classes of noun, which include "dziecko" ("child") and exclusively plural nouns such as "drzwi" ("door").
Borrowed words.
Polish has, over the centuries, borrowed a number of words from other languages. When borrowing, pronunciation was adapted to Polish phonemes and spelling was altered to match Polish orthography. In addition, word endings are liberally applied to almost any word to produce verbs, nouns, adjectives, as well as adding the appropriate endings for cases of nouns, adjectives, diminutives, augmentatives, etc.
Depending on the historical period, borrowing has proceeded from various languages. Notable influences have been Latin (9th–18th centuries), Czech (10th and 14th–15th centuries), Italian (15th–16th centuries), French (18th–19th centuries), German (13–15th and 18th–20th centuries), Hungarian (14th–16th centuries) and Turkish (17th century). Currently, English words are the most common imports to Polish.
The Latin language, for a very long time the only official language of the Polish state, has had a great influence on Polish. Many Polish words ("rzeczpospolita" from "res publica", "zdanie" for both "opinion" and "sentence", from "sententia") were direct borrowings from Latin. Latin was known to a larger or smaller degree by most of the numerous szlachta in the 16th to 18th centuries (and it continued to be extensively taught at secondary schools until World War II). Apart from dozens of loanwords, its influence can also be seen in a number of verbatim Latin phrases in Polish literature (especially from the 19th century and earlier).
During the 12th and 13th centuries, Mongolian words were brought to the Polish language during wars with the armies of Genghis Khan and his descendants, e.g. "dzida" (spear) and "szereg" (a line or row).
Words from Czech, an important influence during the 10th and 14th–15th centuries include "sejm", "hańba" and "brama".
In 1518, the Polish king Sigismund the Old married Bona Sforza, the niece of the Holy Roman emperor Maximilian, who introduced Italian cuisine to Poland, especially vegetables. Hence, words from Italian include "pomidor" from "pomodoro" (tomato), "kalafior" from "cavolfiore" (cauliflower), and "pomarańcza", a portmanteau from Italian "pomo" (pome) plus "arancio" (orange). A later word of Italian origin is "autostrada" (from Italian "autostrada", highway).
In the 18th century, with the rising prominence of France in Europe, French supplanted Latin as an important source of words. Some French borrowings also date from the Napoleonic era, when the Poles were enthusiastic supporters of Napoleon. Examples include "ekran" (from French "écran", screen), "abażur" ("abat-jour", lamp shade), "rekin" ("requin", shark), "meble" ("meuble", furniture), "bagaż" ("bagage", luggage), "walizka" ("valise", suitcase), "fotel" ("fauteuil", armchair), "plaża" ("plage", beach) and "koszmar" ("cauchemar", nightmare). Some place names have also been adapted from French, such as the Warsaw borough of Żoliborz ("joli bord" = beautiful riverside), as well as the town of Żyrardów (from the name Girard, with the Polish suffix -ów attached to refer to the founder of the town).
Many words were borrowed from the German language from the sizable German population in Polish cities during medieval times. German words found in the Polish language are often connected with trade, the building industry, civic rights and city life. Some words were assimilated verbatim, for example "handel" (trade) and "dach" (roof); others are pronounced the same, but differ in writing "schnur"—"sznur" (cord). As a result of being neighbours with Germany, Polish has many German expressions which have become literally translated (calques). Interestingly, the regional dialects of Upper Silesia and Masuria (Modern Polish East Prussia) have noticeably more German loanwords than other dialects.
The contacts with Ottoman Turkey in the 17th century brought many new words, some of them still in use, such as: "jar" (deep valley), "szaszłyk" (shish kebab), "filiżanka" (cup), "arbuz" (watermelon), "dywan" (carpet), etc.
From the founding of the Kingdom of Poland in 1025 through the early years of the Polish-Lithuanian Commonwealth created in 1569, Poland was the most tolerant country of Jews in Europe. Known as paradisus Iudaeorum (Latin for "paradise for the Jews"), it became a shelter for persecuted and expelled European Jewish communities and the home to the world's largest Jewish community of the time. As a result, many Polish words come from Yiddish, spoken by the large Polish Jewish population that existed until the Holocaust. Borrowed Yiddish words include "bachor" (an unruly boy or child), "bajzel" (slang for mess), "belfer" (slang for teacher), "ciuchy" (slang for clothing), "cymes" (slang for very tasty food), "geszeft" (slang for business), "kitel" (slang for apron), "machlojka" (slang for scam), "mamona" (money), "menele" (slang for oddments and also for homeless people), "myszygine" (slang for lunatic), "pinda" (slang for girl, pejoratively), "plajta" (slang for bankruptcy), "rejwach" (noise), "szmal" (slang for money), and "trefny" (dodgy).
The mountain dialects of the Górale in southern Poland, have quite a number of words borrowed from Hungarian (e.g. "baca", "gazda", "juhas", "hejnał") and Romanian as a result of historical contacts with Hungarian-dominated Slovakia and Wallachian herders who travelled north along the Carpathians.
Thieves' slang includes such words as "kimać" (to sleep) or "majcher" (knife) of Greek origin, considered then unknown to the outside world.
Direct borrowings from Russian are extremely rare, in spite of long periods of dependence on Tsarist Russia and the Soviet Union, and are limited to a few internationalisms, such as "sputnik" and "pierestrojka" . Russian personal names are transcribed into Polish likewise; thus Tchaikovsky's name is spelled "Piotr Iljicz Czajkowski".
Recent loanwords come primarily from the English language, mainly those that have Latin or Greek roots, for example "komputer" (computer), "korupcja" (from 'corruption', but sense restricted to 'bribery'), etc. Slang sometimes borrows and alters common English words, e.g. "luknąć" (to look). Concatenation of parts of words (e.g. "auto-moto"), which is not native to Polish but common in English, for example, is also sometimes used. When borrowing English words, Polish often changes their spelling. For example, Latin suffix '-tio' corresponds to "-cja". To make the word plural, "-cja" becomes "-cje". Examples of this include "inauguracja" (inauguration), "dewastacja" (devastation), "recepcja" (reception), "konurbacja" (conurbation) and "konotacje" (connotations). Also, the digraph "qu" becomes "kw" ("kwadrant" = quadrant; "kworum" = quorum).
Loanwords from Polish.
The Polish language has influenced others. Particular influences appear in other Slavic languages and in German — due to their proximity and shared borders. Examples of loanwords include German "Grenze" (border), Dutch and Afrikaans "Grens" from Polish "granica"; German "Peitzker" from Polish "piskorz" (weatherfish); German "Zobel", French "Zibeline", Swedish "Sabel", and English "Sable" from Polish "soból"; and "ogonek" ("little tail") — the word describing a diacritic hook-sign added below some letters in various alphabets. "," a Polish-Ruthenian word for "mop" or "rag" became part of Yiddish.
Quite a few culinary loanwords exist in German and in other languages, some of which describe distinctive features of Polish cuisine. These include German and English "Quark" from "twaróg" (a kind of fresh cheese; see: quark (dairy product)) and German "Gurke", English "gherkin" from "ogórek" (cucumber). The word "pierogi" (Polish dumplings) has spread internationally, as well as "pączki" (Polish donuts) and kiełbasa (sausage) (see e.g. "kolbaso" in Esperanto). As far as "pierogi" concerned, the original Polish word is already in plural (sing. "pieróg", plural "pierogi"; stem "pierog-", plural ending "-i"; NB. "o" becomes "ó" in a closed syllable, like here in singular), yet it is commonly used with the English plural ending "-s" in Canada and United States of America, "pierogis", thus making it a "double plural". (A similar situation happened in the opposite direction to the Polish loanword from English "czipsy" ("potato chips")—from English "chips" being already plural in the original ("chip" + "-s"), yet it has obtained the Polish plural ending "-y".)
The word "spruce" entered the English language from the Polish name of Prusy (a historical region, today part of Poland). It became "spruce" because in Polish, "z Prus", sounded like "spruce" in English (transl. "from Prussia") and was a generic term for commodities brought to England by Hanseatic merchants and because the tree was believed to have come from Polish Ducal Prussia.

</doc>
<doc id="22977" url="http://en.wikipedia.org/wiki?curid=22977" title="Pulp magazine">
Pulp magazine

Pulp magazines (often referred to as "the pulps") are inexpensive fiction magazines that were published from 1896 through the 1950s. The term "pulp" derives from the cheap wood pulp paper on which the magazines were printed; in contrast, magazines printed on higher quality paper were called "glossies" or "slicks". The typical pulp magazine had 128 pages; it was 7 in wide by 10 in high, and 0.5 inch thick, with ragged, untrimmed edges.
In their first decades, pulps were most often priced at ten cents per magazine, while competing slicks cost 25 cents a piece. Pulps were the successors to the penny dreadfuls, dime novels, and short fiction magazines of the 19th century. Although many respected writers wrote for pulps, the magazines were best known for their lurid and exploitative stories and sensational cover art. Modern superhero comic books are sometimes considered descendants of "hero pulps"; pulp magazines often featured illustrated novel-length stories of heroic characters, such as The Shadow, Doc Savage, and The Phantom Detective.
Origins.
The first "pulp" was Frank Munsey's revamped "Argosy Magazine" of 1896, with about 135,000 words (192 pages) per issue, on pulp paper with untrimmed edges, and no illustrations, even on the cover. The steam-powered printing press had been in widespread use for some time, enabling the boom in dime novels; prior to Munsey, however, no one had combined cheap printing, cheap paper and cheap authors in a package that provided affordable entertainment to young working-class people. In six years "Argosy" went from a few thousand copies per month to over half a million.
Street & Smith, a dime novel and boys' weekly publisher, was next on the market. Seeing "Argosy"'s success, they launched "The Popular Magazine" in 1903, which they billed as the "biggest magazine in the world" by virtue of its being two pages (the interior sides of the front and back cover) longer than "Argosy". Due to differences in page layout however, the magazine had substantially less text than "Argosy". "The Popular Magazine" did introduce color covers to pulp publishing, and the magazine began to take off when the publishers in 1905 acquired the rights to serialize "Ayesha", by H. Rider Haggard, a sequel to his popular novel "She". Haggard's Lost World genre influenced several key pulp writers, including Edgar Rice Burroughs, Robert E. Howard, Talbot Mundy and Abraham Merritt. In 1907, the cover price rose to 15 cents and 30 pages were added to each issue; along with establishing a stable of authors for each magazine, this change proved successful and circulation began to approach that of "Argosy". Street and Smith's next innovation was the introduction of specialized genre pulps, with each magazine focusing on a particular genre, such as detective stories, romance, etc.
Popularity.
At their peak of popularity in the 1920s and 1930s, the most successful pulps could sell up to one million copies per issue. The most successful pulp magazines were "Argosy", "Adventure", "Blue Book" and "Short Stories", collectively described by some pulp historians as "The Big Four". Among the best-known other titles of this period were "Amazing Stories", "Black Mask", "Dime Detective", "Flying Aces", "Horror Stories", "Love Story Magazine", "Marvel Tales", "Oriental Stories", "Planet Stories", "Spicy Detective", "Startling Stories", "Thrilling Wonder Stories", "Unknown", "Weird Tales" and "Western Story Magazine".
Although pulp magazines were primarily an American phenomenon, there were also a number of British pulp magazines published between the Edwardian era and World War II. Notable UK pulps included "Pall Mall Magazine", "The Novel Magazine", "Cassell's Magazine", "The Story-Teller", "The Sovereign Magazine", "Hutchinson's Adventure-Story" and "Hutchinson's Mystery-Story". The German fantasy magazine "Der Orchideengarten" had a similar format to American pulp magazines, in that it was printed on rough pulp paper and heavily illustrated.
World War II and market decline.
The Second World War paper shortages had a serious impact on pulp production, starting a steady rise in costs and the decline of the pulps. Beginning with "Ellery Queen's Mystery Magazine" in 1941, pulp magazines began to switch to digest size; smaller, thicker magazines. In 1949, Street & Smith closed most of their pulp magazines in order to move upmarket and produce slicks.
The pulp format declined from rising expenses, but even more due to the heavy competition from comic books, television, and the paperback novel. In a more affluent post-war America, the price gap compared to slick magazines was far less significant. In the 1950s, men's adventure magazines began to replace the pulp.
The 1957 liquidation of the American News Company, then the primary distributor of pulp magazines, has sometimes been taken as marking the end of the "pulp era"; by that date, many of the famous pulps of the previous generation, including "Black Mask," "The Shadow," "Doc Savage," and "Weird Tales," were defunct. Almost all of the few remaining pulp magazines are science fiction or mystery magazines now in formats similar to "digest size", such as "Analog Science Fiction and Fact" and "Ellery Queen's Mystery Magazine". The format is still in use for some lengthy serials, like the German science fiction weekly "Perry Rhodan" (over 2,650 issues as of 2012).
Over the course of their evolution, there were a huge number of pulp magazine titles; Harry Steeger of Popular Publications claimed that his company alone had published over 300, and at their peak they were publishing 42 titles per month. Many titles of course survived only briefly. While the most popular titles were monthly, many were bimonthly and some were quarterly.
The collapse of the pulp industry changed the landscape of publishing because pulps were the single largest sales outlet for short stories. Combined with the decrease in slick magazine fiction markets, writers attempting to support themselves by creating fiction switched to novels and book-length anthologies of shorter pieces.
Genres.
Pulp magazines often contained a wide variety of genre fiction, including, but not limited to,
The American Old West was a mainstay genre of early turn of the 20th century novels as well as later pulp magazines, and lasted longest of all the traditional pulps. In many ways, the later men's adventure ("the sweats") was the replacement of pulps.
Many classic science fiction and crime novels were originally serialized in pulp magazines such as "Weird Tales", "Amazing Stories", and "Black Mask".
Notable original characters.
While the majority of pulp magazines were anthology titles featuring many different authors, characters and settings, some of the most enduringly popular magazines were those that featured a single recurring character. These were often referred to as "hero pulps" because the recurring character was almost always a larger-than-life hero in the mold of Doc Savage or The Shadow.
Popular pulp characters included:
Illustrators.
Pulp covers were printed in color on higher-quality (slick) paper. They were famous for their half-dressed damsels in distress, usually awaiting a rescuing hero. Cover art played a major part in the marketing of pulp magazines. The early pulp magazines could boast covers by some distinguished American artists; "The Popular Magazine" had covers by N.C. Wyeth, and Edgar Franklin Wittmack contributed cover art to "Argosy" and "Short Stories". Later, many artists specialized in creating covers mainly for the pulps; a number of the most successful cover artists became as popular as the authors featured on the interior pages. Among the most famous pulp artists were Walter Baumhofer, Earle K. Bergey, Margaret Brundage, Edd Cartier, Virgil Finlay, Frank R. Paul, Norman Saunders, Nick Eggenhofer, (who specialized in Western illustrations), Hugh J. Ward, George Rozen, and Rudolph Belarski. Covers were important enough to sales that sometimes they would be designed first; authors would then be shown the cover art and asked to write a story to match.
Later pulps began to feature interior illustrations, depicting elements of the stories. The drawings were printed in black ink on the same cream-colored paper used for the text, and had to use specific techniques to avoid blotting on the coarse texture of the cheap pulp. Thus, fine lines and heavy detail were usually not an option. Shading was by crosshatching or pointillism, and even that had to be limited and coarse. Usually the art was black lines on the paper's background, but Finlay and a few others did some work that was primarily white lines against large dark areas.
Authors and editors.
Another way pulps kept costs down was by paying authors less than other markets; thus many eminent authors started out in the pulps before they were successful enough to sell to better-paying markets, and similarly, well-known authors whose careers were slumping or who wanted a few quick dollars could bolster their income with sales to pulps. Additionally, some of the earlier pulps solicited stories from amateurs who were quite happy to see their words in print and could thus be paid token amounts.
There were also career pulp writers, capable of turning out huge amounts of prose on a steady basis, often with the aid of dictation to stenographers, machines or typists. Before he became a novelist, Upton Sinclair was turning out at least 8,000 words per day seven days a week for the pulps, keeping two stenographers fully employed. Pulps would often have their authors use multiple pen names so that they could use multiple stories by the same person in one issue, or use a given author's stories in three or more successive issues, while still appearing to have varied content. One advantage pulps provided to authors was that they paid "upon acceptance" for material instead of on publication; since a story might be accepted months or even years before publication, to a working writer this was a crucial difference in cash flow.
Some pulp editors became known for cultivating good fiction and interesting features in their magazines. Preeminent pulp magazine editors included Arthur Sullivant Hoffman ("Adventure)", Robert H. Davis ("All-Story Weekly"), Harry E. Maule ("Short Stories"), Donald Kennicott ("Blue Book"), Joseph T. Shaw ("Black Mask"), Farnsworth Wright ("Weird Tales", "Oriental Stories"), John W. Campbell ("Astounding Science Fiction", "Unknown") and Daisy Bacon ("Love Story Magazine", "Detective Story Magazine").
Authors featured.
Well-known authors who wrote for pulps include:
Sinclair Lewis, first American winner of the Nobel Prize in Literature, worked as an editor for "Adventure", writing filler paragraphs (brief facts or amusing anecdotes designed to fill small gaps in page layout), advertising copy and a few stories.
Legacy.
The term "pulp fiction" can also refer to mass market paperbacks since the 1950s. The Brown Popular Culture Library News noted:
In 1994, Quentin Tarantino directed a film titled "Pulp Fiction". The working title of the film was "Black Mask", in homage to the pulp magazine of that name, and it embodied the seedy, violent, often crime-related spirit found in pulp magazines.
After the year 2000, several small independent publishers released magazines which published short fiction, either short stories or novel-length presentations, in the tradition of the pulp magazines of the early 20th century. These included "Blood 'N Thunder", "High Adventure" and a short-lived magazine which revived the title "Argosy". These specialist publications, printed in limited press runs, were pointedly not printed on the brittle, high-acid wood pulp paper of the old publications and were not mass market publications targeted at a wide audience. In 2004, Lost Continent Library published "Secret of the Amazon Queen" by E.A. Guest, their first contribution to a "New Pulp Era", featuring the hallmarks of pulp fiction for contemporary mature readers: violence, horror and sex. E.A. Guest was likened to a blend of pulp era icon Talbot Mundy and Stephen King by real-life explorer David Hatcher Childress. 
Moonstone Books, a comic book and prose anthology publisher, began publishing original pulp tales featuring characters such as "The Phantom", "Zorro", "The Spider", "The Avenger", "Domino Lady" and more in 2001.
In 2002, the tenth issue of "McSweeney's Quarterly" was guest edited by Michael Chabon. Published as "McSweeney's Mammoth Treasury of Thrilling Tales", it is a collection of "pulp fiction" stories written by such current well-known authors as Stephen King, Nick Hornby, Aimee Bender and Dave Eggers. Explaining his vision for the project, Chabon wrote in the introduction, "I think that we have forgotten how much fun reading a short story can be, and I hope that if nothing else, this treasury goes some small distance toward reminding us of that lost but fundamental truth."
The Scottish publisher DC Thomson publishes "My Weekly Compact Novel" every week. It is literally a pulp novel, though it does not fall into the hard-edged genre most associated with pulp fiction.
Sources.
</dl>

</doc>
<doc id="22980" url="http://en.wikipedia.org/wiki?curid=22980" title="Phoneme">
Phoneme

A phoneme is a basic unit of a language's phonology, which is combined with other phonemes to form meaningful units, morphemes. The phoneme can be described as "The smallest contrastive linguistic unit which may bring about a change of meaning". In this way the difference in meaning between the English words "kill" and "kiss" is a result of the exchange of the phoneme /l/ for the phoneme /s/. Two words that differ in meaning through a contrast of a single phoneme form a minimal pair.
Within linguistics there are differing views as to exactly what phonemes are and how a given language should be analyzed in "phonemic" (or "phonematic") terms. However, a phoneme is generally regarded as an abstraction of a set (or equivalence class) of speech sounds ("phones") which are perceived as equivalent to each other in a given language. For example, in English, the "k" sounds in the words "kit" and "skill" are not identical (as described below), but they are distributional variants of a single phoneme /k/. Different speech sounds that are realizations of the same phoneme are known as allophones. Allophonic variation may be conditioned, in which case a certain phoneme is realized as a certain allophone in particular phonological environments, or it may be free in which case it may vary randomly. In this way, phonemes are often considered to constitute an abstract underlying representation for segments of words, while speech sounds make up the corresponding phonetic realization, or surface form.
Notation.
Phonemes are conventionally placed between slashes in transcription, whereas speech sounds (phones) are placed between square brackets. Thus /pʊʃ/ represents a sequence of three phonemes /p/, /ʊ/, /ʃ/ (the word "push" in standard English), while [pʰʊʃ] represents the phonetic sequence of sounds [pʰ] (aspirated "p"), [ʊ], [ʃ] (the usual pronunciation of "push"). (Another similar convention is the use of angle brackets to enclose the units of orthography, namely graphemes; for example, ⟨f⟩ represents the written letter (grapheme) "f".)
The symbols used for particular phonemes are often taken from the International Phonetic Alphabet (IPA), the same set of symbols that are most commonly used for phones. (For computer typing purposes, systems such as X-SAMPA and Kirshenbaum exist to represent IPA symbols in plain text.) However, descriptions of particular languages may use different conventional symbols to represent the phonemes of those languages. For languages whose writing systems employ the phonemic principle, ordinary letters may be used to denote phonemes, although this approach is often hampered by the complexity of the relationship between orthography and pronunciation (see Correspondence between letters and phonemes below).
Assignment of speech sounds to phonemes.
A phoneme is a sound or a group of different sounds perceived to have the same function by speakers of the language or dialect in question. An example is the English phoneme /k/, which occurs in words such as cat", kit", "school", "skill". Although most native speakers do not notice this, in most English dialects the "c/k" sounds in these words are not identical: in cat" and kit" the sound is aspirated, while in "school" and "skill" it is unaspirated (listen to U.S. pronunciations of    and   ). The words therefore contain different "speech sounds", or "phones", transcribed [kʰ] for the aspirated form, [k] for the unaspirated one. These different sounds are nonetheless considered to belong to the same phoneme, because if a speaker used one instead of the other, the meaning of the word would not change: using the aspirated form [kʰ] in "skill" might sound odd, but the word would still be recognized. By contrast, some other sounds would cause a change in meaning if substituted: for example, substitution of the sound [t] would produce the different word "still", and that sound must therefore be considered to represent a different phoneme (the phoneme /t/).
The above shows that in English, [k] and [kʰ] are allophones of a single phoneme /k/. In some languages, however, [kʰ] and [k] are perceived by native speakers as different sounds, and substituting one for the other can change the meaning of a word; this means that in those languages, the two sounds represent different phonemes. For example, in Icelandic, [kʰ] is the first sound of "kátur" meaning "cheerful", while [k] is the first sound of "gátur" meaning "riddles". Icelandic therefore has two separate phonemes /kʰ/ and /k/.
Minimal pairs.
A pair of words like "kátur" and "gátur" (above) that differ only in one phone is called a minimal pair for the two alternative phones in question (in this case, [kʰ] and [k]). The existence of minimal pairs is a common test to decide whether two phones represent different phonemes or are allophones of the same phoneme. To take another example, the minimal pair tip" and dip" illustrates that in English, [t] and [d] belong to separate phonemes, /t/ and /d/; since these two words have different meanings, English speakers must be conscious of the distinction between the two sounds. In other languages, though, including Korean, even though both sounds [t] and [d] occur, no such minimal pair exists. The lack of minimal pairs distinguishing [t] and [d] in Korean provides evidence that in this language they are allophones of a single phoneme /t/. The word /tata/ is pronounced [tada], for example. That is, when they hear this word, Korean speakers perceive the same sound in both the beginning and middle of the word, whereas an English speaker would perceive different sounds in these two locations.
However, the absence of minimal pairs for a given pair of phones does not always mean that they belong to the same phoneme: they may be too dissimilar phonetically for it to be likely that speakers perceive them as the same sound. For example, English has no minimal pair for the sounds [h] (as in hat") and [ŋ] (as in "bang), and the fact that they can be shown to be in complementary distribution could be used to argue for them being allophones of the same phoneme. However, they are so dissimilar phonetically that they are considered separate phonemes.
Phonologists have sometimes had recourse to "near minimal pairs" to show that speakers of the language perceive two sounds as significantly different even if no exact minimal pair exists in the lexicon. It is virtually impossible to find a minimal pair to distinguish English /ʃ/ from /ʒ/, yet it seems uncontroversial to claim that the two consonants are distinct phonemes. The two words 'pressure' /preʃə/ and 'pleasure' /pleʒə/ can serve as a near minimal pair.
Other features with phonemic status.
While phonemes are normally conceived of as abstractions of discrete segmental speech sounds (vowels and consonants), there are other features of pronunciation – principally tone and stress – which in some languages can change the meaning of words in the way that phoneme contrasts do, and are consequently called "phonemic" features of those languages.
"Phonemic stress" is encountered in languages such as English. For example, the word "invite" stressed on the second syllable is a verb, but when stressed on the first syllable (without changing any of the individual sounds) it becomes a noun. The position of the stress in the word affects the meaning, and therefore a full phonemic specification (providing enough detail to enable the word to be pronounced unambiguously) would include indication of the position of the stress: /ɪnˈvaɪt/ for the verb, /ˈɪnvaɪt/ for the noun. In other languages, such as French, word stress cannot have this function (its position is generally predictable) and is therefore not phonemic (and is not usually indicated in dictionaries).
"Phonemic tones" are found in languages such as Mandarin Chinese, in which a given syllable can have five different tonal pronunciations. For example, the character 妈 (pronounced "mā", high level pitch) means "mom", 麻 ("má", rising pitch) means "hemp", 马 ("mǎ", falling then rising) means "horse", 骂 ("mà", falling) means "scold", and 吗 ("ma", neutral tone) is an interrogative particle. The tone "phonemes" in such languages are sometimes called "tonemes". Languages such as English do not have phonemic tone, although they use intonation for functions such as emphasis and attitude.
Distribution of allophones.
When a phoneme has more than one allophone, the one actually heard at a given occurrence of that phoneme may be dependent on the phonetic environment (surrounding sounds) – allophones which normally cannot appear in the same environment are said to be in complementary distribution. In other cases the choice of allophone may be dependent on the individual speaker or other unpredictable factors – such allophones are said to be in free variation.
Background and related ideas.
The term "phonème" (from Ancient Greek φώνημα "phōnēma", "sound made, utterance") was reportedly first used by A. Dufriche-Desgenettes in 1873, but it referred only to a speech sound. The term "phoneme" as an abstraction was developed by the Polish linguist Jan Niecisław Baudouin de Courtenay and his student Mikołaj Kruszewski during 1875–1895. The term used by these two was "fonema", the basic unit of what they called "psychophonetics". The concept of the phoneme was then elaborated in the works of Nikolai Trubetzkoi and others of the Prague School (during the years 1926–1935), and in those of structuralists like Ferdinand de Saussure, Edward Sapir, and Leonard Bloomfield. Some structuralists (though not Sapir) rejected the idea of a cognitive or psycholinguistic function for the phoneme
Later, it was used and redefined in generative linguistics, most famously by Noam Chomsky and Morris Halle, and remains central to many accounts of the development of modern phonology. As a theoretical concept or model, though, it has been supplemented and even replaced by others.
Some linguists (such as Roman Jakobson and Morris Halle) proposed that phonemes may be further decomposable into features, such features being the true minimal constituents of language. Features overlap each other in time, as do suprasegmental phonemes in oral language and many phonemes in sign languages. Features could be characterized in different ways: Jakobson and colleagues defined them in acoustic terms, Chomsky and Halle used a predominantly articulatory basis, though retaining some acoustic features, while Ladefoged's system is a purely articulatory system apart from the use of the acoustic term 'sibilant'.
In the description of some languages, the term chroneme has been used to indicate contrastive length or "duration" of phonemes. In languages in which tones are phonemic, the tone phonemes may be called tonemes. Not all scholars working on such languages use these terms, which may be considered obsolete.
By analogy with the phoneme, linguists have proposed other sorts of underlying objects, giving them names with the suffix "-eme", such as "morpheme" and "grapheme". These are sometimes called emic units. The latter term was first used by Kenneth Pike, who also generalized the concepts of emic and etic description (from "phonemic" and "phonetic" respectively) to applications outside linguistics.
Restrictions on occurrence.
Languages do not generally allow words or syllables to be built of any arbitrary sequences of phonemes; there are phonotactic restrictions on which sequences of phonemes are possible and in which environments certain phonemes can occur. Phonemes that are significantly limited by such restrictions may be called "restricted phonemes". Examples of such restrictions in English include:
Some phonotactic restrictions can alternatively be analyzed as cases of neutralization. See Neutralization and archiphonemes below, particularly the example of the occurrence of the three English nasals before stops.
Biuniqueness.
Biuniqueness is a requirement of classic structuralist phonemics. It means that a given phone, wherever it occurs, must unambiguously be assigned to one and only one phoneme. In other words, the mapping between phones and phonemes is required to be many-to-one rather than many-to-many. The notion of biuniqueness was controversial among some pre-generative linguists and was prominently challenged by Morris Halle and Noam Chomsky in the late 1950s and early 1960s.
An example of the problems arising from the biuniqueness requirement is provided by the phenomenon of flapping in North American English. This may cause either /t/ or /d/ (in the appropriate environments) to be realized with the phone [ɾ] (an alveolar flap). For example, the same flap sound may be heard in the words "hitting" and "bidding", although it is clearly intended to realize the phoneme /t/ in the first word and /d/ in the second. This appears to contradict biuniqueness.
For further discussion of such cases, see the next section.
Neutralization and archiphonemes.
Phonemes that are contrastive in certain environments may not be contrastive in all environments. In the environments where they do not contrast, the contrast is said to be neutralized. In these positions it may become less clear which phoneme a given phone represents. Some phonologists prefer not to specify a unique phoneme in such cases, since to do so would mean providing redundant or even arbitrary information – instead they use the technique of underspecification. An archiphoneme is an object sometimes used to represent an underspecified phoneme.
An example of neutralization is provided by the Russian vowels /a/ and /o/. These phonemes are contrasting in stressed syllables, but in unstressed syllables the contrast is lost, since both are reduced to the same sound, usually [ə] (for details, see Vowel reduction in Russian). In order to assign such an instance of [ə] to one of the phonemes /a/ and /o/, it is necessary to consider morphological factors (such as which of the vowels occurs in other forms of the words, or which inflectional pattern is followed). In some cases even this may not provide an unambiguous answer. A description using the approach of underspecification would not attempt to assign [ə] to a specific phoneme in some or all of these cases, although it might be assigned to an archiphoneme, written something like |A|, which reflects the two neutralized phonemes in this position.
A somewhat different example is found in English, with the three nasal phonemes /m, n, ŋ/. In word-final position these all contrast, as shown by the minimal triplet "sum" /sʌm/, "sun" /sʌn/, "sung" /sʌŋ/. However, before a stop such as /p, t, k/ (provided there is no morpheme boundary between them), only one of the nasals is possible in any given position: /m/ before /p/, /n/ before /t/ or /d/, and /ŋ/ before /k/, as in "limp, lint, link" ( /lɪmp/, /lɪnt/, /lɪŋk/). The nasals are therefore not contrastive in these environments, and according to some theorists this makes it inappropriate to assign the nasal phones heard here to any one of the phonemes (even though, in this case, the phonetic evidence is unambiguous). Instead they may analyze these phones as belonging to a single archiphoneme, written something like |N|, and state the underlying representations of "limp, lint, link" to be |lɪNp|, |lɪNt|, |lɪNk|.
This latter type of analysis is often associated with Nikolai Trubetzkoy of the Prague school. Archiphonemes are often notated with a capital letter within pipes, as with the examples |A| and |N| given above. Other ways the second of these might be notated include , {m, n, ŋ}, or |n*|.
Another example from English, but this time involving complete phonetic convergence as in the Russian example, is the flapping of /t/ and /d/ in some American English (described above under Biuniqueness). Here the words "betting" and "bedding" might both be pronounced [ˈbɛɾɪŋ], and if a speaker applies such flapping consistently, it would be necessary to look for morphological evidence (the pronunciation of the related forms "bet" and "bed", for example) in order to determine which phoneme the flap represents. As in the previous examples, some theorists would prefer not to make such a determination, and simply assign the flap in both cases to a single archiphoneme, written (for example) |D|.
For a special kind of neutralization proposed in generative phonology, see absolute neutralization.
Morphophonemes.
A morphophoneme is a theoretical unit at a deeper level of abstraction than traditional phonemes, and is taken to be a unit from which morphemes are built up. A morphophoneme within a morpheme can be expressed in different ways in different allomorphs of that morpheme (according to morphophonological rules). For example, the English plural morpheme "-s" appearing in words such as "cats" and "dogs" can be considered to consist of a single morphophoneme, which might be written (for example) //z// or |z|, and which is pronounced as [s] after most voiceless consonants (as in "cats) and [z] in most other cases (as in "dogs).
Numbers of phonemes in different languages.
A given language will use only a small subset of the many possible sounds that the human speech organs can produce, and (because of allophony) the number of distinct phonemes will generally be smaller than the number of identifiably different sounds. Different languages vary considerably in the number of phonemes they have in their systems (although apparent variation may sometimes result from the different approaches taken by the linguists doing the analysis). The total phonemic inventory in languages varies from as few as 11 in Rotokas and Pirahã to as many as 141 in !Xũ.
The number of phonemically distinct vowels can be as low as two, as in Ubyx and Arrernte. At the other extreme, the Bantu language Ngwe has 14 vowel qualities, 12 of which may occur long or short, making 26 oral vowels, plus 6 nasalized vowels, long and short, making a total of 38 vowels; while !Xóõ achieves 31 pure vowels, not counting its additional variation by vowel length, by varying the phonation. As regards consonant phonemes, Puinave has just seven, and Rotokas has only six. !Xóõ, on the other hand, has somewhere around 77, and Ubyx 81. The English language uses a rather large set of 13 to 21 vowel phonemes, including diphthongs, although its 22 to 26 consonants are close to average.
Some languages, such as French, have no phonemic tone or stress, while several of the Kam–Sui languages have nine tones, and one of the Kru languages, Wobe, has been claimed to have 14, though this is disputed.
The most common vowel system consists of the five vowels /i/, /e/, /a/, /o/, /u/. The most common consonants are /p/, /t/, /k/, /m/, /n/. Relatively few languages lack any of these consonants, although it does happen: for example, Arabic lacks /p/, standard Hawaiian lacks /t/, Mohawk and Tlingit lack /p/ and /m/, Hupa lacks both /p/ and a simple /k/, colloquial Samoan lacks /t/ and /n/, while Rotokas and Quileute lack /m/ and /n/.
Correspondence between letters and phonemes.
Phonemes are considered to be the basis for alphabetic writing systems. In such systems the written symbols (graphemes) represent, in principle, the phonemes of the language being written. This is most obviously the case when the alphabet was invented with a particular language in mind; for example, the Latin alphabet was devised for Classical Latin, and therefore the Latin of that period enjoyed a near one-to-one correspondence between phonemes and graphemes in most cases, though the devisers of the alphabet chose not to represent the phonemic effect of vowel length. However, because changes in the spoken language are often not accompanied by changes in the established orthography (as well as other reasons, including dialect differences, the effects of morphophonology on orthography, and the use of foreign spellings for some loanwords), the correspondence between spelling and pronunciation in a given language may be highly distorted; this is the case with English, for example.
The correspondence between symbols and phonemes in alphabetic writing systems is not necessarily a one-to-one correspondence. A phoneme might be represented by a combination of two or more letters (digraph, trigraph, etc.), like <sh> in English or <sch> in German (both representing phonemes /ʃ/). Also a single letter may represent two phonemes, as the Cyrilic letter я in some positions. There may also exist spelling/pronunciation rules (such as those for the pronunciation of <c> in Italian) that further complicate the correspondence of letters to phonemes, although they need not affect the ability to predict the pronunciation from the spelling and vice versa, provided the rules are known.
Phonemes in sign languages.
In sign languages, the basic elements of gesture and location were formerly called "cheremes" or "cheiremes" but they are now generally referred to as phonemes, as with oral languages.
Sign language phonemes are combinations of articulation bundles in ASL. These bundles may be classified as "tab" (elements of location, from Latin "tabula"), "dez" (the hand shape, from "designator"), "sig" (the motion, from "signation"), and with some researchers, "ori" (orientation). Facial expression and mouthing are also considered articulation bundles. Just as with spoken languages, when these bundles are combined, they create phonemes.
Stokoe notation is no longer used by researchers to denote the phonemes of sign languages; his research, while still considered seminal, has been found to not describe American Sign Language and cannot be used interchangeably with other signed languages. Originally developed for American Sign Language, it has also been applied to British Sign Language by Kyle and Woll, and to Australian Aboriginal sign languages by Adam Kendon. Other sign notations, such as the Hamburg Notation System and SignWriting, are phonetic scripts capable of writing any sign language. Stokoe's work has been succeeded and improved upon by researcher Scott Liddell in his book "Grammar, Gesture, and Meaning in American Sign Language", and both Stokoe and Liddell's work have been included in the Linguistics of American Sign Language, 5th Edition.
Bibliography.
</dl>

</doc>
<doc id="22981" url="http://en.wikipedia.org/wiki?curid=22981" title="Phone (phonetics)">
Phone (phonetics)

In phonetics and linguistics, the word phone may refer to any speech sound or gesture considered as a physical event without regard to its place in the phonology of a language. In contrast, a phoneme is a set of phones or a set of sound features that are thought of as the same element within the phonology of a particular language. .
In the context of spoken languages, a phone is an unanalyzed sound of a language . A phone is a speech segment that possesses distinct physical or perceptual properties, and serves as the basic unit of phonetic speech analysis. Phones are generally either vowels or consonants.
A phonetic transcription (based on phones) is enclosed within square brackets ([ ]), rather than the slashes (/ /) of a phonemic transcription (based on phonemes). Phones (and often phonemes also) are commonly represented using symbols of the International Phonetic Alphabet (IPA).
For example, the English word "spin" consists of four phones, [s], [p], [ɪ] and [n], and thus has the phonetic representation [spɪn]. The word "pin" has three phones; in this case the initial sound is aspirated, and so can be represented as [pʰ]; the word's phonetic representation will then be [pʰɪn]. (Precisely which features are shown in a phonetic representation will depend on whether a narrow or broad transcription is being used, and to which features the writer wishes to draw attention in the context.)
When phones are considered to be realizations of the same phoneme, they are called allophones of that phoneme (more information on the methods of making such assignments can be found under Phoneme). In English, for example, [p] and [pʰ] are considered allophones of a single phoneme, written as /p/. The phonemic transcriptions of the above two words will consequently be /spɪn/ and /pɪn/, aspiration no longer being shown, since it is not distinctive.

</doc>
