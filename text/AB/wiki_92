<doc id="25109" url="http://en.wikipedia.org/wiki?curid=25109" title="Public limited company">
Public limited company

A public limited company (legally abbreviated to plc) is a type of public company (publicly held company) under United Kingdom company law, some Commonwealth jurisdictions, and the Republic of Ireland. It is a limited (liability) company whose shares may be freely sold and traded to the public (although a plc may also be privately held, often by another plc), with a minimum share capital of £50,000 and the letters PLC after its name. Similar companies in the United States are called "publicly traded companies".
A PLC can be either an unlisted or listed company on the stock exchanges. In the United Kingdom, a public limited company usually must include the words "public limited company" or the abbreviation "PLC" or "plc" at the end and as part of the legal company name. Welsh companies may instead choose to end their names with ccc, an abbreviation for cwmni cyfyngedig cyhoeddus. However, some public limited companies (mostly nationalised concerns) incorporated under special legislation are exempted from bearing any of the identifying suffixes.
The term "public limited company" and the "PLC"/"plc" suffix were introduced in 1974; prior to this, all limited companies bore the suffix "Limited" ("Ltd"), which is still used by private limited companies.
Registration.
When a new company incorporates in England and Wales or in Scotland, it must register with Companies House, an executive agency of the Department for Business, Innovation and Skills. In Northern Ireland, although prior to October 2009, companies in that jurisdiction were registered with the Northern Ireland Executive's Department of Enterprise, Trade and Investment, companies registrations are now handled by the Companies House like the rest of the United Kingdom.
Company directors.
Formation of a public limited company requires a minimum of two directors (differing from country to country: in India three directors are required). In general terms anyone can be a company director, provided they are not disqualified on one of the following grounds:
Some people who are not British or European Union citizens are restricted as to what work they may do while in the UK, which may exclude them from being a director.
Share capital.
The members must agree to take some, or all, of the shares when the company is registered. The memorandum of association must show the names of the people who have agreed to take shares and the number of shares each will take. These people are called the subscribers.
There is a minimum share capital for public limited companies: Before it can start business, it must have allotted shares to the value of at least £50,000. A quarter of them, £12,500, must be paid up. Each allotted share must be paid up to at least one quarter of its nominal value together with the whole of any premium.
A company can increase its authorised share capital by passing an ordinary resolution (unless its articles of association require a special or extraordinary resolution). A copy of the resolution – and notice of the increase on Form 123 – must reach Companies House within 15 days of being passed. No fee is payable to Companies House.
A company can decrease its authorised share capital by passing an ordinary resolution to cancel shares which have not been taken or agreed to be taken by any person. Notice of the cancellation, on Form 122, must reach Companies House within one month. No fee is payable to Companies House.
Share types.
A company may have as many different types of shares as it wishes, all with different conditions attached to them. Generally share types are divided into the following categories:
A plc has access to capital markets and can offer its shares for sale to the public through a recognised stock exchange. It can also issue advertisements offering any of its securities for sale to the public. In contrast, a private company may not offer to the public any shares in itself.
Company formation.
Most companies are now formed electronically via company formation agents.
Paper process.
The following documents, together with the registration fee are sent to the Registrar of Companies:
Electronic process.
The key difference with the paper process is that there is no Form 12 and requirement for a statutory declaration. This significantly speeds the process and Companies House's record for an Electronic Company formation is 23 minutes.
Because the electronic process requires compatible software that works with Companies House eFiling service, companies are usually formed through a Company Formation Agent.
Annual returns.
Every company must deliver an annual return to Companies House at least once every twelve months. It has 28 days from the date to which the return is made up to do this. Failure to file a return is a criminal offence, for which the officers of the company may be fined.
There is an annual document-processing fee of £30 (or £15 for users of the Electronic Filing or WebFilings services), which must be sent to Companies House with the annual return.
Conversion.
Private limited company to a public limited company.
Both a private company limited by shares and an unlimited company with a share capital may re-register as a plc, but a company without a share capital cannot do so.
A private company must pass a special resolution that it be so re-registered and deliver a copy of the resolution together with an application form to the Registrar. The resolution must also:
If it does not already have sufficient share capital, the company must issue £50,000 in shares a minimum of 25% part paid.
Public limited company to a private limited company.
In some jurisdictions a public limited company may re-register as a private limited company or private unlimited company at any time with few formalities.
A court may also order a public company to re-register as private on approving a 'minute of reduction' of share capital which results in the issued share capital falling below the statutory minimum. In such a case the court will also specify alterations to the company's memorandum and articles. A special resolution to re-register is not required.

</doc>
<doc id="25114" url="http://en.wikipedia.org/wiki?curid=25114" title="Posada, Sardinia">
Posada, Sardinia

Posada (Latin: "Pheronia", Sardinian: "Pasada"), also previously known as "Feronia" or "Pausata", is a "comune" (municipality) in the Province of Nuoro in the Italian region Sardinia. The city sits on the coast of the Tyrrhenian Sea. As of 31 December 2004, it had a population of 2,394 and an area of 33.52 km2.
Posada borders the following municipalities: Budoni, Siniscola and Torpè.
History.
Within Posada's territory was the ancient city of Feronia or Pheronia, the foundation of which is ascribed to the Faliscans, which contained a now lost temple to the Etruscan goddess Feronia.
During the Roman period, the town's importance declined with the foundation of nearby Portus Luguidonis.
In the Middle Ages, Posada was main town of an historical district called "Baronia di Posada" or "Baronia Alta" (to be distinguished from Baronia Bassa or Baronia di Orosei/Galtelli'), on the Tyrrhenian coast of the island.
The ancient part of the town is in a spectacular position on the top of a hill, where it preserves a particular medieval historical center, with ruins of a castle (Castello della Fava) and a square panoramic tower of the 13th century.
The castle has been the equivalent of a holiday residence for the "Giudichessa" Eleanor of Arborea, and was object of alternate possession by the Giudicato d'Arborea and the Aragon, during the long fight before the Spanish conquest.
The castle became then the seat of the Baron of Posada, a title and a fief created in 1431 for Don Nicolò Carroz and formally ended in 1856, when it was finally bought by the kingdom of Sardinia (the last one of all Sardinian fiefs).
Tourism.
Tourism in Posada is the main economic activity.
External links.
 

</doc>
<doc id="25117" url="http://en.wikipedia.org/wiki?curid=25117" title="Puget Sound Naval Shipyard and Intermediate Maintenance Facility">
Puget Sound Naval Shipyard and Intermediate Maintenance Facility

Puget Sound Naval Shipyard and Intermediate Maintenance Facility (PSNS & IMF) is a United States Navy shipyard covering 179 acres (0.7 km²) on Puget Sound at Bremerton, Washington in uninterrupted use since its establishment in 1891; it has also been known as Navy Yard Puget Sound, Bremerton Navy Yard, and Puget Sound Naval Shipyard. 
It is bordered on the south by Sinclair Inlet, on the west by the Bremerton Annex of Naval Base Kitsap, and on the north and east by the city of Bremerton, Washington. It is the Pacific Northwest's largest naval shore facility and one of Washington state's largest industrial installations. PSNS & IMF provides the Navy with maintenance, modernization, and technical and logistics support.
History.
Puget Sound Naval Shipyard was established in 1891 as a Naval Station and was designated Navy Yard Puget Sound in 1901. During World War I, the Navy Yard constructed ships, including 25 subchasers, seven submarines, two minesweepers, seven seagoing tugs, and two ammunition ships, as well as 1,700 small boats. During World War II, the shipyard's primary effort was the repair of battle damage to ships of the U.S. fleet and those of its allies.
Following World War II, Navy Yard Puget Sound was designated Puget Sound Naval Shipyard. It engaged in an extensive program of modernizing carriers, including converting conventional flight decks to angle decks. During the Korean War, the shipyard was engaged in the activation of ships. In the late 1950s, it entered an era of new construction with the building of a new class of guided missile frigates. In 1965, USS "Sculpin" (SSN 590) became the first nuclear-powered submarine to be maintained at PSNS. The shipyard was designated a National Historic Landmark in 1992. The historic district includes 22 contributing buildings and 42 contributing structures, as well as 49 non-contributing buildings, structures, and objects.
Installations.
Perhaps the most visible feature of the shipyard is its huge green hammerhead crane, built in 1933. The PSNS hammerhead crane is 250 ft tall and 80 ft wide with a lifting capacity of 250 tons. The hammerhead crane has not been used for many years.
Ship-Submarine Recycling Program.
In 1990 the Navy authorized the Ship-Submarine Recycling Program (SRP) to recycle nuclear-powered ships at PSNS. Approximately 25% of the shipyard's workload involves inactivation, reactor compartment disposal, and recycling of ships. It has pioneered an environmentally safe method of deactivating and recycling nuclear-powered ships. This process places the U.S. Navy in the role of being the world's only organization to design, build, operate, and recycle nuclear-powered ships. On May 15, 2003 PSNS and IMF were consolidated into what is now known as PSNS & IMF.
Mothball Fleet.
The shipyard contains a portion of the United States Navy reserve fleet, a large collection of inactive U.S. Navy vessels, including four aircraft carriers: the , the , the and the . The ships are mothballed, meaning that they are stored in case they are needed by the Navy in the future.(Update-USS Constellation CV-64 is currently being scrapped in Brownsville,Texas.
Environmental Issues.
Gorst Creek Ravine near Port Orchard, Washington was a hazardous waste dump for the Navy's shipyard waste between 1969 and 1970, when the site was not permitted by local authorities to take waste. After several collapses since 1997 the landfill could blow out Highway 3. The landfill is an "ongoing source of pesticides, polychlorinated biphenyls and metals flowing downstream with the potential to affect groundwater wells, sport fisheries and the Suquamish Tribe's fish hatchery. In October 2014, the US EPA ordered the Navy to fix the problems. 

</doc>
<doc id="25119" url="http://en.wikipedia.org/wiki?curid=25119" title="Poeciliidae">
Poeciliidae

The Poeciliidae are a family of freshwater fishes of the order Cyprinodontiformes, the tooth-carps, and include well-known live-bearing aquarium fish, such as the guppy, molly, platy, and swordtail. The original distribution of the family was the southeastern United States to north of Rio de la Plata, Argentina, and Africa, including Madagascar. However, due to release of aquarium specimens and the widespread use of species of the genera "Poecilia" and "Gambusia" for mosquito control, poeciliids can today be found in all tropical and subtropical areas of the world. In addition, "Poecilia" and "Gambusia" specimens have been identified in hot springs pools as far north as Banff, Alberta.
Live-bearing.
Although the whole family Poeciliidae is known as "live bearers" (viviparous), some species are egg-scattering with external fertilization. All African species are egg-layers, and (with the exception of the members of the genus "Tomeurus") all American species are live-bearers. Among the three subfamilies, Aplocheilichthyinae is restricted to Africa, Poeciliinae is primarily from the Americas (the only exception is the African "Rhexipanchax"), and Procatopodinae is mainly from Africa (the South American "Fluviphylax" and "Pseudopoecilia" are the only exceptions). This distribution suggests that the Poeciliidae predate the split between Africa and South America 100 million years ago, and that live-bearing subsequently evolved in South America. Poeciliids colonized North America through the Antilles while they were connected 44 million years ago. Poeciliids then moved to Central America by the Aves land bridge on the Caribbean Plate. When South America connected to Central America three million years ago, some further dispersal southward occurred, but South American species did not move into Central America.
Among the live-bearing species, differences in the mode and degree of support the female gives the developing larvae occur. Many members of the family Poeciliidae are considered to be lecithotrophic (the mother provisions the oocyte with all the resources it needs prior to fertilization, so the egg is independent of the mother), but others are matrotrophic (literally "mother feeding": the mother provides the majority of resources to the developing offspring after fertilization).
Members of the genus "Poeciliopsis", for example, show variable reproductive life history adaptations. "Poeciliopsis monacha", "P. lucida", and "P. prolifica" form part of the same clade within that genus. However, their modes of maternal provisioning vary greatly. "P. monacha" can be considered to be lecithotrophic because it does not really provide any resources for its offspring after fertilization - the pregnant female is basically a swimming egg sac. "P. lucida" shows an intermediate level of matrotrophy, meaning that to a certain extent the offspring's metabolism can actually affect the mother's metabolism, allowing for increased nutrient exchange. "P. prolifica" is considered to be highly matrotrophic, and almost all of the nutrients and materials needed for fetal development are supplied to the oocyte after it has been fertilized. This level of matrotrophy allows "Poeciliopsis" to carry several broods at different stages of development, a phenomenon known as superfetation. Because the space for developing embryos is limited, viviparity reduces brood size. Superfetation can compensate for this loss by keeping embryos at various stages and sizes during development. 
"P. elongata", "P. turneri" and "P. presidionis" form another clade which could be considered an outgroup to the "P. monacha", "P.lucida", and "P. prolifica" clade. These three species are very highly matrotrophic - so much so that in 1947, C. L. Turner described the follicular cells of "P. turneri" as "pseudo-placenta, pseudo-chorion, and pseudo-allantois".

</doc>
<doc id="25120" url="http://en.wikipedia.org/wiki?curid=25120" title="Polar coordinate system">
Polar coordinate system

In mathematics, the polar coordinate system is a two-dimensional coordinate system in which each point on a plane is determined by a distance from a reference point and an angle from a reference direction.
The reference point (analogous to the origin of a Cartesian system) is called the "pole", and the ray from the pole in the reference direction is the "polar axis". The distance from the pole is called the "radial coordinate" or "radius", and the angle is the "angular coordinate", "polar angle", or "azimuth".
History.
The concepts of angle and radius were already used by ancient peoples of the 1st millennium BC. The Greek astronomer and astrologer Hipparchus (190–120 BC) created a table of chord functions giving the length of the chord for each angle, and there are references to his using polar coordinates in establishing stellar positions.
In "On Spirals", Archimedes describes the Archimedean spiral, a function whose radius depends on the angle. The Greek work, however, did not extend to a full coordinate system.
From the 8th century AD onward, astronomers developed methods for approximating and calculating the direction to Mecca (qibla)—and its distance—from any location on the Earth. From the 9th century onward they were using spherical trigonometry and map projection methods to determine these quantities accurately. The calculation is essentially the conversion of the equatorial polar coordinates of Mecca (i.e. its longitude and latitude) to its polar coordinates (i.e. its qibla and distance) relative to a system whose reference meridian is the great circle through the given location and the Earth's poles, and whose polar axis is the line through the location and its antipodal point.
There are various accounts of the introduction of polar coordinates as part of a formal coordinate system. The full history of the subject is described in Harvard professor Julian Lowell Coolidge's "Origin of Polar Coordinates." Grégoire de Saint-Vincent and Bonaventura Cavalieri independently introduced the concepts in the mid-seventeenth century. Saint-Vincent wrote about them privately in 1625 and published his work in 1647, while Cavalieri published his in 1635 with a corrected version appearing in 1653. Cavalieri first used polar coordinates to solve a problem relating to the area within an Archimedean spiral. Blaise Pascal subsequently used polar coordinates to calculate the length of parabolic arcs.
In "Method of Fluxions" (written 1671, published 1736), Sir Isaac Newton examined the transformations between polar coordinates, which he referred to as the "Seventh Manner; For Spirals", and nine other coordinate systems. In the journal "Acta Eruditorum" (1691), Jacob Bernoulli used a system with a point on a line, called the "pole" and "polar axis" respectively. Coordinates were specified by the distance from the pole and the angle from the "polar axis". Bernoulli's work extended to finding the radius of curvature of curves expressed in these coordinates.
The actual term "polar coordinates" has been attributed to Gregorio Fontana and was used by 18th-century Italian writers. The term appeared in English in George Peacock's 1816 translation of Lacroix's "Differential and Integral Calculus". Alexis Clairaut was the first to think of polar coordinates in three dimensions, and Leonhard Euler was the first to actually develop them.
Conventions.
The radial coordinate is often denoted by "r" or "ρ", and the angular coordinate by "ϕ", "θ", or "t". The angular coordinate is specified as "ϕ" by ISO standard 31-11.
Angles in polar notation are generally expressed in either degrees or radians (2π rad being equal to 360°). Degrees are traditionally used in navigation, surveying, and many applied disciplines, while radians are more common in mathematics and mathematical physics.
In many contexts, a positive angular coordinate means that the angle "ϕ" is measured counterclockwise from the axis.
In mathematical literature, the polar axis is often drawn horizontal and pointing to the right.
Uniqueness of polar coordinates.
Adding any number of full turns (360°) to the angular coordinate does not change the corresponding direction. Also, a negative radial coordinate is best interpreted as the corresponding positive distance measured in the opposite direction. Therefore, the same point can be expressed with an infinite number of different polar coordinates ("r", "ϕ" ± "n"×360°) or (−"r", "ϕ" ± (2"n" + 1)180°), where "n" is any integer. Moreover, the pole itself can be expressed as (0, "ϕ") for any angle "ϕ".
Where a unique representation is needed for any point, it is usual to limit "r" to non-negative numbers ("r" ≥ 0) and "ϕ" to the interval [0, 360°) or (−180°, 180°] (in radians, [0, 2π) or (−π, π]). One must also choose a unique azimuth for the pole, e.g., "ϕ" = 0.
Converting between polar and Cartesian coordinates.
The polar coordinates "r" and "ϕ" can be converted to the Cartesian coordinates "x" and "y" by using the trigonometric functions sine and cosine:
The Cartesian coordinates "x" and "y" can be converted to polar coordinates "r" and "ϕ" with "r" ≥ 0 and "ϕ" in the interval (−π, π] by:
where atan2 is a common variation on the arctangent function defined as
The value of "ϕ" above is the principal value of the complex number function arg applied to "x"+"iy". An angle in the range [0, 2π) may be obtained by adding 2π to the value in case it is negative.
Polar equation of a curve.
The equation defining an algebraic curve expressed in polar coordinates is known as a "polar equation". In many cases, such an equation can simply be specified by defining "r" as a function of "ϕ". The resulting curve then consists of points of the form ("r"("ϕ"), "ϕ") and can be regarded as the graph of the polar function "r".
Different forms of symmetry can be deduced from the equation of a polar function "r". If the curve will be symmetrical about the horizontal (0°/180°) ray, if "r"(π − "ϕ") = "r"("ϕ") it will be symmetric about the vertical (90°/270°) ray, and if "r"("ϕ" − α) = "r"("ϕ") it will be rotationally symmetric by α counterclockwise about the pole.
Because of the circular nature of the polar coordinate system, many curves can be described by a rather simple polar equation, whereas their Cartesian form is much more intricate. Among the best known of these curves are the polar rose, Archimedean spiral, lemniscate, limaçon, and cardioid.
For the circle, line, and polar rose below, it is understood that there are no restrictions on the domain and range of the curve.
Circle.
The general equation for a circle with a center at ("r"0, formula_6) and radius "a" is
This can be simplified in various ways, to conform to more specific cases, such as the equation
for a circle with a center at the pole and radius "a".
When "r"0 = a, or when the origin lies on the circle, the equation becomes
In the general case, the equation can be solved for "r", giving
the solution with a minus sign in front of the square root gives the same curve.
Line.
"Radial" lines (those running through the pole) are represented by the equation
where ɣ is the angle of elevation of the line; that is, where "m" is the slope of the line in the Cartesian coordinate system. The non-radial line that crosses the radial line perpendicularly at the point ("r0", ɣ) has the equation
Otherwise stated ("r0", ɣ) is the point in which the tangent intersects the imaginary circle of radius "r0".
Polar rose.
A polar rose is a famous mathematical curve that looks like a petaled flower, and that can be expressed as a simple polar equation,
for any constant ɣ0 (including 0). If "k" is an integer, these equations will produce a "k"-petaled rose if "k" is odd, or a 2"k"-petaled rose if "k" is even. If "k" is rational but not an integer, a rose-like shape may form but with overlapping petals. Note that these equations never define a rose with 2, 6, 10, 14, etc. petals. The variable "a" represents the length of the petals of the rose.
Archimedean spiral.
The Archimedean spiral is a famous spiral that was discovered by Archimedes, which can also be expressed as a simple polar equation. It is represented by the equation
Changing the parameter "a" will turn the spiral, while "b" controls the distance between the arms, which for a given spiral is always constant. The Archimedean spiral has two arms, one for "ϕ" > 0 and one for "ϕ" < 0. The two arms are smoothly connected at the pole. Taking the mirror image of one arm across the 90°/270° line will yield the other arm. This curve is notable as one of the first curves, after the conic sections, to be described in a mathematical treatise, and as being a prime example of a curve that is best defined by a polar equation.
Conic sections.
A conic section with one focus on the pole and the other somewhere on the 0° ray (so that the conic's major axis lies along the polar axis) is given by:
where "e" is the eccentricity and formula_16 is the semi-latus rectum (the perpendicular distance at a focus from the major axis to the curve). If "e" > 1, this equation defines a hyperbola; if , it defines a parabola; and if "e" < 1, it defines an ellipse. The special case of the latter results in a circle of radius formula_16.
Intersection of two polar curves.
The graphs of two polar functions formula_18 and formula_19 have possible intersections in 3 cases:
Complex numbers.
Every complex number can be represented as a point in the complex plane, and can therefore be expressed by specifying either the point's Cartesian coordinates (called rectangular or Cartesian form) or the point's polar coordinates (called polar form). The complex number "z" can be represented in rectangular form as
where "i" is the imaginary unit, or can alternatively be written in polar form (via the conversion formulae given above) as
and from there as
where "e" is Euler's number, which are equivalent as shown by Euler's formula. (Note that this formula, like all those involving exponentials of angles, assumes that the angle "ϕ" is expressed in radians.) To convert between the rectangular and polar forms of a complex number, the conversion formulae given above can be used.
For the operations of multiplication, division, and exponentiation of complex numbers, it is generally much simpler to work with complex numbers expressed in polar form rather than rectangular form. From the laws of exponentiation:
Calculus.
Calculus can be applied to equations expressed in polar coordinates.
The angular coordinate "ϕ" is expressed in radians throughout this section, which is the conventional choice when doing calculus.
Differential calculus.
Using and , one can derive a relationship between derivatives in Cartesian and polar coordinates. For a given function, "u"("x","y"), it follows that (by computing its total derivatives)
or
Hence, we have the following formulae:
Using the inverse coordinates transformation, an analogous reciprocal relationship can be derived between the derivatives. Given a function "u"("r","ϕ"), it follows that
or
Hence, we have the following formulae:
To find the Cartesian slope of the tangent line to a polar curve "r"("ϕ") at any given point, the curve is first expressed as a system of parametric equations.
Differentiating both equations with respect to "ϕ" yields
Dividing the second equation by the first yields the Cartesian slope of the tangent line to the curve at the point ("r"("ϕ"), "ϕ"):
For other useful formulas including divergence, gradient, and Laplacian in polar coordinates, see curvilinear coordinates.
Integral calculus (arc length).
The arc length (length of a line segment) defined by a polar function is found by the integration over the curve "r"("ϕ"). Let "L" denote this length along the curve starting from points "A" through to point "B", where these points correspond to "ϕ" = "a" and "ϕ" = "b" such that 0 < "b" − "a" < 2π. The length of "L" is given by the following integral
Integral calculus (area).
Let "R" denote the region enclosed by a curve "r"("ϕ") and the rays "ϕ" = "a" and "ϕ" = "b", where 0 < "b" − "a" ≤ 2π. Then, the area of "R" is
This result can be found as follows. First, the interval ["a", "b"] is divided into "n" subintervals, where "n" is an arbitrary positive integer. Thus Δ"ϕ", the length of each subinterval, is equal to "b" − "a" (the total length of the interval), divided by "n", the number of subintervals. For each subinterval "i" = 1, 2, …, "n", let "ϕ""i" be the midpoint of the subinterval, and construct a sector with the center at the pole, radius "r"("ϕ""i"), central angle Δ"ϕ" and arc length "r"("ϕ""i")Δ"ϕ". The area of each constructed sector is therefore equal to
Hence, the total area of all of the sectors is
As the number of subintervals "n" is increased, the approximation of the area continues to improve. In the limit as "n" → ∞, the sum becomes the Riemann sum for the above integral.
A mechanical device that computes area integrals is the planimeter, which measures the area of plane figures by tracing them out: this replicates integration in polar coordinates by adding a joint so that the 2-element linkage effects Green's theorem, converting the quadratic polar integral to a linear integral.
Generalization.
Using Cartesian coordinates, an infinitesimal area element can be calculated as "dA" = "dx" "dy". The substitution rule for multiple integrals states that, when using other coordinates, the Jacobian determinant of the coordinate conversion formula has to be considered:
Hence, an area element in polar coordinates can be written as
Now, a function, that is given in polar coordinates, can be integrated as follows:
Here, "R" is the same region as above, namely, the region enclosed by a curve "r"("ϕ") and the rays "ϕ" = "a" and "ϕ" = "b".
The formula for the area of "R" mentioned above is retrieved by taking "f" identically equal to 1. A more surprising application of this result yields the Gaussian integral
Vector calculus.
Vector calculus can also be applied to polar coordinates. For a planar motion, let formula_60 be the position vector ("r"cos("ϕ"), "r"sin("ϕ")), with "r" and "ϕ" depending on time "t".
We define the unit vectors
in the direction of r and
in the plane of the motion perpendicular to the radial direction, where formula_63 is a unit vector normal to the plane of the motion.
Then
Centrifugal and Coriolis terms.
The term formula_68 is sometimes referred to as the "centrifugal term", and the term formula_69 as the "Coriolis term". For example, see Shankar. Although these equations bear some resemblance in form to the centrifugal and Coriolis effects found in rotating reference frames, nonetheless these are not the same things. For example, the physical centrifugal and Coriolis forces appear only in non-inertial frames of reference. In contrast, these terms, that appear when acceleration is expressed in polar coordinates, are a mathematical consequence of differentiation; these terms appear wherever polar coordinates are used. In particular, these terms appear even when polar coordinates are used in inertial frames of reference, where the physical centrifugal and Coriolis forces never appear.
Co-rotating frame.
For a particle in planar motion, one approach to attaching physical significance to these terms is based on the concept of an instantaneous "co-rotating frame of reference". To define a co-rotating frame, first an origin is selected from which the distance "r"("t") to the particle is defined. An axis of rotation is set up that is perpendicular to the plane of motion of the particle, and passing through this origin. Then, at the selected moment "t", the rate of rotation of the co-rotating frame Ω is made to match the rate of rotation of the particle about this axis, "dϕ"/"dt". Next, the terms in the acceleration in the inertial frame are related to those in the co-rotating frame. Let the location of the particle in the inertial frame be ("r("t"), "ϕ"("t")), and in the co-rotating frame be ("r(t), "ϕ"′(t)"). Because the co-rotating frame rotates at the same rate as the particle, "dϕ"′/"dt" = 0. The fictitious centrifugal force in the co-rotating frame is "mrΩ2, radially outward. The velocity of the particle in the co-rotating frame also is radially outward, because "dϕ"′/"dt" = 0. The "fictitious Coriolis force" therefore has a value −2"m"("dr"/"dt")Ω, pointed in the direction of increasing "ϕ" only. Thus, using these forces in Newton's second law we find:
where over dots represent time differentiations, and F is the net real force (as opposed to the fictitious forces). In terms of components, this vector equation becomes:
which can be compared to the equations for the inertial frame:
This comparison, plus the recognition that by the definition of the co-rotating frame at time "t" it has a rate of rotation Ω = "dϕ"/"dt", shows that we can interpret the terms in the acceleration (multiplied by the mass of the particle) as found in the inertial frame as the negative of the centrifugal and Coriolis forces that would be seen in the instantaneous, non-inertial co-rotating frame.
For general motion of a particle (as opposed to simple circular motion), the centrifugal and Coriolis forces in a particle's frame of reference commonly are referred to the instantaneous osculating circle of its motion, not to a fixed center of polar coordinates. For more detail, see centripetal force.
Connection to spherical and cylindrical coordinates.
The polar coordinate system is extended into three dimensions with two different coordinate systems, the cylindrical and spherical coordinate system.
Applications.
Polar coordinates are two-dimensional and thus they can be used only where point positions lie on a single two-dimensional plane. They are most appropriate in any context where the phenomenon being considered is inherently tied to direction and length from a center point. For instance, the examples above show how elementary polar equations suffice to define curves—such as the Archimedean spiral—whose equation in the Cartesian coordinate system would be much more intricate. Moreover, many physical systems—such as those concerned with bodies moving around a central point or with phenomena originating from a central point—are simpler and more intuitive to model using polar coordinates. The initial motivation for the introduction of the polar system was the study of circular and orbital motion.
Position and navigation.
Polar coordinates are used often in navigation as the destination or direction of travel can be given as an angle and distance from the object being considered. For instance, aircraft use a slightly modified version of the polar coordinates for navigation. In this system, the one generally used for any sort of navigation, the 0° ray is generally called heading 360, and the angles continue in a clockwise direction, rather than counterclockwise, as in the mathematical system. Heading 360 corresponds to magnetic north, while headings 90, 180, and 270 correspond to magnetic east, south, and west, respectively. Thus, an aircraft traveling 5 nautical miles due east will be traveling 5 units at heading 90 (read zero-niner-zero by air traffic control).
Modeling.
Systems displaying radial symmetry provide natural settings for the polar coordinate system, with the central point acting as the pole. A prime example of this usage is the groundwater flow equation when applied to radially symmetric wells. Systems with a radial force are also good candidates for the use of the polar coordinate system. These systems include gravitational fields, which obey the inverse-square law, as well as systems with point sources, such as radio antennas.
Radially asymmetric systems may also be modeled with polar coordinates. For example, a microphone's pickup pattern illustrates its proportional response to an incoming sound from a given direction, and these patterns can be represented as polar curves. The curve for a standard cardioid microphone, the most common unidirectional microphone, can be represented as at its target design frequency. The pattern shifts toward omnidirectionality at lower frequencies.
References.
</dl>

</doc>
<doc id="25121" url="http://en.wikipedia.org/wiki?curid=25121" title="Polymath">
Polymath

A polymath (Greek: πολυμαθής, "polymathēs", "having learned much") is a person whose expertise spans a significant number of different subject areas; such a person is known to draw on complex bodies of knowledge to solve specific problems. The term was first used in the seventeenth century; the related term, polyhistor, is an ancient term with similar meaning.
The term is often used to describe great thinkers of the Renaissance and the Enlightenment who excelled at several fields in science and the arts. In the Italian Renaissance, the idea of the polymath was expressed by Leon Battista Alberti (1404–1472), in the statement that "a man can do all things if he will". Embodying a basic tenet of Renaissance humanism that humans are limitless in their capacity for development, the concept led to the notion that people should embrace all knowledge and develop their capacities as fully as possible. This was expressed in the term "Renaissance man" which is often applied to the gifted people of that age who sought to develop their abilities in all areas of accomplishment: intellectual, artistic, social and physical. This term entered the lexicon during the twentieth century and has now been applied to great thinkers living before and after the Renaissance.
Renaissance ideal: the Renaissance man.
"Renaissance man" was first recorded in written English in the early 20th century. It is now used to refer to great thinkers living before, during, or after the Renaissance. Leonardo da Vinci has often been described as the archetype of the Renaissance man, a man of "unquenchable curiosity" and "feverishly inventive imagination".
Many notable polymaths lived during the Renaissance period, a cultural movement that spanned roughly the 14th through to the 17th century and that began in Italy in the late Middle Ages and later spread to the rest of Europe. These polymaths had a rounded approach to education that reflected the ideals of the humanists of the time. A gentleman or courtier of that era was expected to speak several languages, play a musical instrument, write poetry, and so on, thus fulfilling the Renaissance ideal. The idea of a universal education was essential to achieving polymath ability, hence the word university was used to describe a seat of learning. At this time universities did not specialize in specific areas but rather trained students in a broad array of science, philosophy, and theology. This universal education gave them a grounding from which they could continue into apprenticeship toward becoming a Master of a specific field.
During the Renaissance, Baldassare Castiglione, in his guide "The Book of the Courtier", described how an ideal courtier should have polymathic traits. Castiglione's guide stressed the kind of attitude that should accompany the many talents of a polymath, an attitude he called "sprezzatura". A courtier should have a detached, cool, nonchalant attitude, and speak well, sing, recite poetry, have proper bearing, be athletic, know the humanities and classics, paint and draw and possess many other skills, always without showy or boastful behavior, in short, with "sprezzatura". The many talents of the polymath should appear to others to be performed without effort, in an unstrained way, almost without thought.
In some ways, the gentlemanly requirements of Castiglione recall the Chinese sage, Confucius, who far earlier depicted the courtly behavior, piety and obligations of service required of a gentleman. The easy facility in difficult tasks also resembles the effortlessness inculcated by Zen, such as in archery where no conscious attention, but pure spontaneity, produces better and more noble skill. For Castiglione, the attitude of apparent effortlessness should accompany great skill in many separate fields. In word or deed the courtier should "avoid affectation ... (and) ... practice ... a certain "sprezzatura" ... conceal all art and make whatever is done or said appear to be without effort and almost without any thought about it".
This Renaissance ideal differed slightly from the polymath in that it involved more than just intellectual advancement. Historically (roughly 1450–1600) it represented a person who endeavored to "develop his capacities as fully as possible" ("Britannica", "Renaissance Man") both mentally and physically.
When someone is called a "Renaissance man" or "Renaissance woman" today, it is meant that, rather than simply having broad interests or superficial knowledge in several fields, he or she possesses a more profound knowledge and a proficiency, or even an expertise, in at least some of those fields.
Today, the expression "Renaissance man" is usually used to describe a person with intellectual or scholastic proficiency and not necessarily the more universal learning implied by Renaissance humanism. Some dictionaries use the term "Renaissance man" to describe someone with many interests or talents, while others give a meaning restricted to the Renaissance and more closely related to Renaissance ideals.
Related terms.
Aside from "Renaissance man" as mentioned above, similar terms in use are "Homo Universalis" (Latin) and "" (Italian), which translate to "universal person" or "universal man". The related term "generalist" – contrasted with a "specialist" – is used to describe a person with a general approach to knowledge.
The term "Universal Genius" is also used, with Leonardo da Vinci as the prime example again. The term seems to be used especially when a person has made lasting contributions in at least one of the fields in which he was actively involved, and when he had a universality of approach.
When a person is described as having "encyclopedic knowledge", he or she exhibits a vast scope of knowledge. This designation may be anachronistic, however, in the case of persons such as Eratosthenes whose reputation for having encyclopedic knowledge pre-dates the existence of any encyclopedic object.
Polymath and polyhistor compared.
Many dictionaries of word origins list these words as synonyms or as words with very similar meanings. Thomas Moore took the words as corresponding to similarly erudite "polys" in his poem "The Devil Among Scholars":
"Off I fly, careering far"<br>
"In chase of Pollys, prettier far"<br>
"Than any of their namesakes are"<br>
"—The Polymaths and Polyhistors,"<br>
"Polyglots and all their sisters."
According to the "Oxford English Dictionary," the words mean practically the same; "the classical Latin word "polyhistor" was used exclusively, and the Greek word frequently, of Alexander Polyhistor", but "polymathist" appeared later, and then "polymath." Thus today, regardless of any differentiation they may have had when originally coined, they are often taken to mean the same thing.
In sports.
In Britain, phrases such as "polymath sportsman", "sporting polymath", or simply "polymath" are occasionally used in a restricted sense to refer to athletes who have performed at a high level in several very different sports, rather than to those gifted in many fields of study. One whose accomplishments are limited to athletics would not be considered a "polymath" in the usual sense of the word. An example is Howard Baker, who was called a "sporting polymath" by the" Encyclopedia of British Football "for winning high jump titles and playing cricket, football, and water polo.

</doc>
<doc id="25122" url="http://en.wikipedia.org/wiki?curid=25122" title="PowerBook">
PowerBook

The PowerBook (known as Macintosh PowerBook before 1997) is a line of Macintosh laptop computers that was designed, manufactured and sold by Apple Computer, Inc. from 1991 to 2006. During its lifetime, the PowerBook went through several major revisions and redesigns, often being the first to incorporate features that would later become standard in competing laptops. The PowerBook line was targeted at the professional market, and received numerous awards, especially in the second half of its life, such as the 2001 Industrial Design Excellence Awards "Gold" status, and Engadget's 2005 "Laptop of the Year". In 1999, the line was supplemented by the consumer iBook range. The PowerBook and iBook lines were discontinued and replaced by the MacBook Pro and MacBook families respectively by 2006.
History.
In September 1989, Apple Inc. released the Macintosh Portable, the first Macintosh computer intended to be easily portable. However, its price ($6500), size, and weight made actual portability difficult. Because of this, the demand for a true portable Macintosh was not met.
Early models.
PowerBook 100 series.
In October 1991 Apple released the first three PowerBooks: the low-end PowerBook 100, the more powerful PowerBook 140, and the high end PowerBook 170, the only one with an active matrix display. These machines caused a stir in the industry with their compact dark grey cases, built-in trackball, and the innovative positioning of the keyboard which left room for palmrests on either side of the pointing device. Portable PC computers at the time were still oriented toward DOS, and tended to have the keyboard forward towards the user, with empty space behind it that was often used for function key reference cards. In the early days of Microsoft Windows, many notebooks came with a clip on trackball that fit on the edge of the keyboard molding. As usage of DOS gave way to the graphical user interface, the PowerBook's arrangement became the standard layout all future notebook computers would follow.
The PowerBook 140 and 170 were the original PowerBook designs, while the PowerBook 100 was the result of Apple having sent the schematics of the Mac Portable to Sony, who miniaturized the components. Hence the PowerBook 100's design does not match those of the rest of the series, as it was actually designed after the 140 & 170 and further benefited from improvements learned during their development. The PowerBook 100, however, did not sell well until Apple dropped the price substantially.
The 100 series PowerBooks were intended to tie into the rest of the Apple desktop products utilizing the corporate Snow White design language incorporated into all product designs since 1986. However, unlike the Macintosh Portable which was essentially a battery powered desktop in weight and size, the light colors and decorative recessed lines did not seem appropriate for the scaled down designs. In addition to adopting the darker grey colour scheme which co-ordinated with the official corporate look, they also adopted a raised series of ridges mimicking the indented lines on the desktops. The innovative look not only unified their entire product line, but set Apple apart in the marketplace. These early series would be the last to utilize the aging Snow White look, with the 190 adopting a new look along with the introduction of the 500 series.
The first series of PowerBooks were hugely successful, capturing 40% of all laptop sales. Despite this, the original team left to work at Compaq, setting back updated versions for some time. When attempting to increase processing power, Apple was hampered by the overheating problems of the 68040; this resulted in the 100-series PowerBook being stuck with the aging 68030 which could not compete with newer-generation Intel 80486-based PC laptops introduced in 1994. For several years, new PowerBook and PowerBook Duo computers were introduced which featured incremental improvements, including color screens, but by mid-decade, most other companies had copied the majority of the PowerBook's features. Apple was unable to ship a 68040-equipped PowerBook until the PowerBook 500 series in 1994.
The original PowerBook 100, 140, and 170 were replaced by the 145 (updated to the 145B in 1993), 160, and 180 in 1992. The 160 and 180 having video output allowing them to drive an external monitor. In addition, the PowerBook 180 had a superb-for-the-time active-matrix grayscale display, making it popular with the Mac press. In 1993, the PowerBook 165c was the first PowerBook with a color screen, later followed by the 180c. In 1994, the last true member of the 100-series form factor introduced was the PowerBook 150, targeted at value-minded consumers and students. The PowerBook 190, released in 1995, bears no resemblance to the rest of the PowerBook 100 series, and is in fact simply a Motorola 68LC040-based version of the PowerBook 5300 (and the last Macintosh model to utilize a Motorola 68k-family processor). However, like the 190, the 150 also used the 5300 IDE-based logic-board architecture. From the 100's 68000 processor, to the 190's 68LC040 processor, the 100 series PowerBooks span the entire Apple 68K line, with the 190 even upgradable to a PowerPC processor.
PowerBook Duo.
In 1992 Apple released a hybrid portable/desktop computer, the PowerBook Duo, continuing to streamline the subnotebook features introduced with the PowerBook 100. The Duos were a series of very thin and lightweight laptops with a minimum of features, which could be inserted into a docking station to provide the system with extra video memory, storage space, connectors, and could be connected to a monitor.
PowerBook 500 series.
1994 saw the introduction of the Motorola 68LC040-based PowerBook 500 series, code-named Blackbird. These models of PowerBooks were much sleeker and faster than the 100 series, which they replaced as the mid and high-end models. The 500 series featured DSTN (520) or active-matrix LCD displays (540 and 550), stereo speakers, and was the first computer to use a trackpad (although a similar technology had been included on the pioneering Gavilan SC 11 years earlier); it was also the first portable computer to offer built-in Ethernet networking. The PowerBook 500 series was the mainstay of the product line until the PowerBook 5300. The 500 series was the first PowerBook to feature PCMCIA slots, although this was an optional feature which required the user to sacrifice one of the two available battery slots to house the PCMCIA expansion cage.
The PowerBook 500 series was released as Apple was already moving its desktop machines to the PowerPC processor range, and a future upgrade was promised from the start. This came in 1995, as an Apple Motherboard containing a 100 MHz 603e processor and 8 MB of RAM (which snapped into a slot containing the previous 25 or 33 MHz 68040 processor and the 4 MB of RAM on the previous daughterboard). At the same time Newer Technology offered an Apple-authorized 117 MHz Motherboard, which was more popular than the Apple product, and optionally came without any RAM. The company later offered 167 MHz and 183 MHz upgrades containing more memory and onboard cache memory to improve performance. However, the internal architecture of the 500 series meant that the speed increase provided by the 100 and 117 MHz upgrades was, for most users, relatively small.
The 500 series was completely discontinued upon the introduction of its replacement the PPC-based PowerBook 5300, with the PowerBook 190 replacing the 500 as the only 68LC040 PowerBook Apple offered.
PowerPC-Based PowerBooks.
The PowerBook 5300, while highly anticipated as one of the first PowerPC-based PowerBooks (along with the PowerBook Duo 2300c, both released on the same day), had numerous problems. In its 5300ce incarnation with a TFT of 800x600 pixels, Apple offered a 117 MHz PPC, 32 MB of on-board RAM, and a hot-swappable drive bay. With all of these features, though, the 5300ce was quite ahead of other laptop models at the time. Multiple problems with reliability, stability and safety (by some, the model was referred as the "HindenBook" because the lithium ion batteries used actually burst into flame in Apple tests, necessitating a recall and downgrade to nickel metal hydride batteries) were present in the early 5300s. These drawbacks by far failed to meet the quality standard expected for the price. After Apple offered an Extended Repair Program, the series turned into a remarkably attractive machine, but never lost its bad reputation. The bad publicity of 5300 series added to the woes of "beleaguered Apple" during the mid-1990s.
Apple recovered from the 5300 debacle in 1996 and 1997 by introducing three new PowerBooks: the PowerBook 1400, intended to replace the 5300 as a general-purpose PowerBook; the PowerBook 2400, intended as a slim, sleek sub-notebook to replace the PowerBook Duo; and the luxury model PowerBook 3400. The PowerBook 1400 and 3400 were the first PowerBooks ever to include an internal CD drive. Late in 1997, the PowerBook 3400 was adapted into the first PowerBook G3, codenamed the Kanga. This series was the last PowerBook model to employ a "real" keyboard with 1 cm high keys; all later models have flat keys.
PowerBook G3.
The first PowerBook G3 Series (completely redesigned from the Kanga) was released in 1998, although it was still an Old World ROM Mac.
These new PowerBooks took design cues from the 500 series PowerBook, sporting dramatic curves and a jet-black plastic case. They were so fashionable that various G3 models became the personal computer of Carrie Bradshaw in the long-running Sex and the City television show. Debuting at roughly the same time as the G3 iMac, the "WallStreet/Mainstreet" series composed of models with varying features, such as different processing speeds (from 233 to 300 MHz) and the choice of 12-, 13-, or 14-inch screens. They all included dual drive bays capable of accommodating floppy drives, CD-ROM/DVD-ROM drives, hard drives, or even extra batteries. A second PowerBook G3 Series code-named "PDQ" was introduced later in 1998, with minor changes in configuration options, notably the inclusion of L2 cache in even the lowest-priced 233 MHz model, which helped overall performance.
Apple introduced two later G3 PowerBook models, similar in appearance (curved, black plastic case with black rubberized sections) but thinner, lighter and with revised internal systems. The "Lombard" appeared in 1999, (AKA: Bronze Keyboard) a thinner, lighter, and faster (333 or 400 MHz) PowerBook with a longer battery life and had both USB and SCSI built in and was a New World ROM Mac, and then the "Pismo" in 2000, which replaced the single SCSI port with two FireWire ports, updated the PowerBook line to AGP graphics, a 100 MHz bus speed, and DVD-ROM optical drives standard, in addition to dropping the "G3" from the PowerBook name. The Pismo revision also brought AirPort wireless networking capability (802.11b), which had debuted in Apple's iBook in July 1999. CPU upgrade cards are available for both Lombard and Pismo models.
PowerBook G4.
Interim CEO Steve Jobs turned his eye to the redesign of the PowerBook series in 2000. The result, introduced in January 2001, was a completely re-designed New World PowerBook with a titanium skin and a 15.2-inch wide-aspect screen suitable for watching widescreen movies. Built with the PowerPC G4 processor, it was billed as "the first supercomputer you can actually take with you on an airplane." It was lighter than most PC based laptops, and due to the low power consumption of the PowerPC it outlasted them by hours.
The "TiBooks", as they were nicknamed, became a fashion item. They were especially popular in the entertainment business, where they adorned many desks in Hollywood motion pictures. Because of their large screens and high performance, Titanium Powerbooks were the first laptops to be widely deployed as desktop replacement computers.
The industrial design of the notebooks quickly became a standard that others in the industry would follow, creating a new wave of wide-screened notebook computers.
The Titanium PowerBooks were released in configurations of 400 MHz, 500 MHz, 550 MHz, 667 MHz, 800 MHz, 867 MHz, and 1 GHz. They are the last PowerBooks able to boot MacOS 9.
In 2003, Apple launched both the largest-screen laptop in the world and Apple's smallest full-featured notebook computer. Both machines were made of anodized aluminum (coining the new nickname "AlBook"), featured DVD-burning capabilities, AirPort Extreme networking, Bluetooth, and 12.1-inch or 17-inch LCD displays. The 17-inch model included a fiber optic-illuminated keyboard, which eventually became standard on all 15-inch and 17-inch PowerBooks. Two ambient light sensors, located under each speaker grille, adjusted the brightness of the backlit keyboard and the display according to the light level.
The 12-inch PowerBook's screen did not use the same panel as that used on the 12-inch iBook, while the 17-inch PowerBook used the same screen as that used on the 17-inch flat-panel iMac, but with a thinner backlight.
Later in 2003, the 15-inch PowerBooks were redesigned and featured the same aluminum body style as their smaller and larger siblings, and with the same feature set as the 17-inch model (including the backlit keyboard). This basic design would carry through the transition to the Intel-based MacBook Pro, lasting until late 2008.
In April 2004, the aluminum PowerBooks were upgraded. The SuperDrive was upgraded to 4× burning speed for DVDs, the fastest processor available was upgraded to 1.5 GHz, and the graphics cards were replaced with newer models, offering up to 128 MB of video memory. A third built-in speaker was added to the 12-inch model for improved midrange sound. In addition, AirPort Extreme cards became standard for all PowerBooks instead of being offered as an add-on option.
In January 2005, the specifications of the aluminum PowerBooks were revised once more to accompany a price decrease. Processor speeds were increased to a maximum of 1.67 GHz on the higher specification 15-inch and all 17-inch versions, while the lower specification 15-inch model and the 12-inch unit saw an increase in speed to 1.5 GHz. Optical audio output was added to the 17-inch version. Memory and hard drive defaults were increased to 512 MB and 5400 rpm, respectively, with a new storage maximum of 100 GB on the 17-inch model. Each model also received an enhanced trackpad with scrolling capabilities, a revised Bluetooth module supporting BT 2.0+EDR, and a new feature which parks the drive heads when sudden motion is detected by an internal sensor. Support for the 30-inch Apple Cinema display was also introduced in the new 17-inch model and was optional in the 15-inch model via a build-to-order upgrade to the computer's video hardware. The SuperDrive now included DVD+R capability.
In October 2005, the two higher-end PowerBooks were upgraded once again, with higher-resolution displays (1440 × 960 pixels on the 15-inch model, and 1680 × 1050 pixels on the 17-inch model) and faster 533 MHz DDR2 (PC2-4200) memory. The SuperDrive became standard equipment and included support for dual-layer DVDs on the 15- and 17-inch models. The 17-inch model was updated with a 120 GB standard hard drive, as well as a 7200 rpm, 100 GB build-to-order option. These drives were also options on the 15-inch PowerBook. The 12-inch model with SuperDrive remained unchanged in this respect, although each new PowerBook boasted a longer battery life.
Battery recall.
On May 20, 2005, Apple and the Consumer Product Safety Commission announced the recall of some Apple PowerBook G4 batteries. The joint Apple/CPSC press release stated that an internal short could cause the battery cells to overheat, posing a fire hazard. Approximately 128,000 defective units were sold.
Though the problems first appeared to be solved, they continued for many users. In early August 2006, Engadget reported that a PowerBook had "violently exploded" because of faulty battery. On August 24, 2006, Apple and the CPSC announced an additional recall of more batteries for the same PowerBook models.
About 1.1 million battery packs in the United States were recalled; an additional 700,000 were sold outside the U.S.
These batteries were manufactured by Sony. Sony, Dell, Toshiba, Lenovo, HP, Fujitsu and Acer laptops were also affected by the defective batteries.
Discontinuation.
At the 2006 Macworld Conference & Expo, the MacBook Pro was introduced. The new notebooks, however, only came in 15.4-inch models and the 12-inch and 17-inch PowerBooks remained available for sale at Apple stores and retailers, as well as the 15-inch model, which was sold until supplies ran out. On April 24, 2006 the 17-inch PowerBook G4 was replaced by a 17-inch MacBook Pro variant. The 12-inch PowerBook G4 remained available until May 16, 2006, when the MacBook was introduced as a replacement for the iBook. Because of its availability in highly powerful configurations, it was also considered a replacement for the 12-inch PowerBook, ending the nearly 15-year production of PowerBook-branded computers.
Timeline of portable Macintoshes.
Traditionally, the portable line trailed the desktops in the utilization of the latest processors, with the notable exception of the PowerBook G3 which occurred simultaneously with the desktop Power Macintosh G3 introduction. However, it would continue to trail behind the desktop Macs, never even adopting the G5 processor. This was due primarily to the extreme heat caused by most of the full-sized processors available and unacceptable power consumption. With the introduction of the Intel-based Macs, once again, the MacBook Pro joined the iMac in sharing the new technology simultaneously.

</doc>
<doc id="25123" url="http://en.wikipedia.org/wiki?curid=25123" title="Phil Ochs">
Phil Ochs

Philip David "Phil" Ochs (; December 19, 1940 – April 9, 1976) was an American protest singer (or, as he preferred, a topical singer) and songwriter who was known for his sharp wit, sardonic humor, earnest humanism, political activism, insightful and alliterative lyrics, and distinctive voice. He wrote hundreds of songs in the 1960s and '70s and released eight albums.
Ochs performed at many political events during the 1960s counterculture era, including anti-Vietnam War and civil rights rallies, student events, and organized labor events over the course of his career, in addition to many concert appearances at such venues as New York City's Town Hall and Carnegie Hall. Politically, Ochs described himself as a "left social democrat" who became an "early revolutionary" after the protests at the 1968 Democratic National Convention in Chicago led to a police riot, which had a profound effect on his state of mind.
After years of prolific writing in the 1960s, Ochs's mental stability declined in the 1970s. He eventually succumbed to a number of problems including bipolar disorder and alcoholism, and took his own life in 1976.
Some of Ochs's major musical influences were Woody Guthrie, Pete Seeger, Buddy Holly, Elvis Presley, Bob Gibson, Faron Young, and Merle Haggard. His best-known songs include "I Ain't Marching Anymore", "Changes", "Crucifixion", "Draft Dodger Rag", "Love Me, I'm a Liberal", "Outside of a Small Circle of Friends", "Power and the Glory", "There but for Fortune", and "The War Is Over".
Biography.
Early years.
Phil Ochs was born in El Paso, Texas, to Jacob ("Jack") Ochs, a physician who was born in New York in 1910, and Gertrude Phin Ochs, who was born in Scotland. His parents met and married in Edinburgh where Jack was attending medical school. After their marriage, they moved to the United States. Jack, drafted into the army, was sent overseas at the end of World War II, where he treated soldiers at the Battle of the Bulge. His war experiences affected his mental health and he received an honorable medical discharge in November 1945. Suffering from bipolar disorder and depression on his return home, Jack was unable to establish a successful medical practice and instead worked at a series of hospitals around the country. As a result, the Ochs family moved frequently: to Far Rockaway, New York, when Ochs was a teenager; then to Perrysburg in upstate New York, where he first studied music; and then to Columbus, Ohio. Ochs grew up with an older sister, Sonia (known as Sonny), and a younger brother, Michael. The Ochs family was middle class and Jewish, but not religious. His father was distant from his wife and children, and was hospitalized for depression. He died in 1963 from a cerebral hemorrhage.
As a teenager, Ochs was recognized as a talented clarinet player; in an evaluation, one music instructor wrote: "You have exceptional musical feeling and the ability to transfer it on your instrument is abundant." His musical skills allowed him to play clarinet with the orchestra at the Capital University Conservatory of Music in Ohio, where he rose to the status of principal soloist before he was 16. Although Ochs played classical music, he soon became interested in other sounds he heard on the radio, such as early rock icons Buddy Holly and Elvis Presley and country music artists including Faron Young, Ernest Tubb, Hank Williams, Sr., and Johnny Cash. Ochs also spent a lot of time at the movies. He especially liked big screen heroes such as John Wayne and Audie Murphy. Later on, he developed an interest in movie rebels, including Marlon Brando and James Dean.
From 1956 to 1958, Ochs was a student at the Staunton Military Academy in rural Virginia, and when he graduated he returned to Columbus and enrolled in the Ohio State University. Unhappy after his first semester, he took a leave of absence and went to Florida. While in Miami, the 18-year-old Ochs was jailed for two weeks for sleeping on a park bench, an incident he would later recall: "Somewhere during the course of those fifteen days I decided to become a writer. My primary thought was journalism ... so in a flash I decided — I'll be a writer and a major in journalism."
Ochs returned to Ohio State to study journalism and developed an interest in politics, with a particular interest in the Cuban Revolution of 1959. At Ohio State he met Jim Glover, a fellow student who was a devotee of folk music. Glover introduced Ochs to the music of Pete Seeger, Woody Guthrie, and The Weavers. Glover taught Ochs how to play guitar, and they debated politics. Ochs began writing newspaper articles, often on radical themes. When the student paper refused to publish some of his more radical articles, he started his own underground newspaper called "The Word". His two main interests, politics and music, soon merged, and Ochs began writing topical political songs. Ochs and Glover formed a duet called "The Singing Socialists", later renamed "The Sundowners", but the duo broke up before their first professional performance and Glover went to New York City to become a folksinger.
Ochs's parents and brother had moved from Columbus to Cleveland, and Ochs started to spend more time there, performing professionally at a local folk club called Farragher's Back Room. He was the opening act for a number of musicians in the summer of 1961, including the Smothers Brothers. Ochs met Bob Gibson that summer as well, and according to Dave Van Ronk, Gibson became ""the" seminal influence" on Ochs's writing. Ochs continued at Ohio State into his senior year, but was bitterly disappointed at not being appointed editor-in-chief of the college newspaper, and dropped out in his last semester without graduating. He left for New York, as Glover had, to become a folksinger.
1962–1966.
Ochs arrived in New York City in 1962 and began performing in numerous small folk nightclubs, eventually becoming an integral part of the Greenwich Village folk music scene. He emerged as an unpolished but passionate vocalist who wrote pointed songs about current events: war, civil rights, labor struggles and other topics. While others described his music as "protest songs", Ochs preferred the term "topical songs".
Ochs described himself as a "singing journalist", saying he built his songs from stories he read in "Newsweek". By the summer of 1963 he was sufficiently well known in folk circles to be invited to sing at the Newport Folk Festival, where he performed "Too Many Martyrs" (co-written with Bob Gibson), "Talking Birmingham Jam", and "Power and the Glory"—his patriotic Guthrie-esque anthem that brought the audience to its feet. Other performers at the 1963 folk festival included Peter, Paul and Mary, Joan Baez, Bob Dylan, and Tom Paxton. Ochs's return appearance at Newport in 1964, when he performed "Draft Dodger Rag" and other songs, was widely praised. But he was not invited to appear in 1965, the festival when Dylan infamously performed "Maggie's Farm" with an electric guitar. Although many in the folk world decried Dylan's choice, Ochs was amused, and admired Dylan's courage in defying the folk establishment.
During 1963, Ochs performed at New York's Carnegie Hall and Town Hall in hootenannies. He made his first solo appearance at Carnegie Hall in 1966. Throughout his career, Ochs would perform at a wide range of venues, including civil rights rallies, anti-war demonstrations, and concert halls.
Ochs contributed many songs and articles to the influential "Broadside Magazine". He recorded his first three albums for Elektra Records: "All the News That's Fit to Sing" (1964), "I Ain't Marching Anymore" (1965), and "Phil Ochs in Concert" (1966). Critics wrote that each album was better than its predecessors, and fans seemed to agree; record sales increased with each new release.
On these records, Ochs was accompanied only by an acoustic guitar. The albums contain many of Ochs's topical songs, such as "Too Many Martyrs", "I Ain't Marching Anymore", and "Draft Dodger Rag"; and some musical reinterpretation of older poetry, such as "The Highwayman" (poem by Alfred Noyes) and "The Bells" (poem by Edgar Allan Poe). "Phil Ochs in Concert" includes some more introspective songs, such as "Changes" and "When I'm Gone".
During the early period of his career, Ochs and Bob Dylan had a friendly rivalry. Dylan said of Ochs, "I just can't keep up with Phil. And he just keeps getting better and better and better". On another occasion, when Ochs criticized one of Dylan's songs, Dylan threw him out of his limousine, saying, "You're not a folksinger. You're a journalist".
In 1962, Ochs married Alice Skinner, who was pregnant with their daughter Meegan, in a City Hall ceremony with Jim Glover as best man and Jean Ray as bridesmaid, and witnessed by Dylan's sometime girlfriend, Suze Rotolo. Phil and Alice separated in 1965, but they never divorced.
Like many people of his generation, Ochs deeply admired President John F. Kennedy, even though he disagreed with the president on issues such as the Bay of Pigs Invasion, the Cuban Missile Crisis, and the growing involvement of the United States in the Vietnamese civil war. When Kennedy was assassinated on November 22, 1963, Ochs wept. He told his wife that he thought he was going to die that night. It was the only time she ever saw Ochs cry.
Ochs's managers during this part of his career were Albert Grossman (who also managed Dylan and Peter, Paul, and Mary) followed by Arthur Gorson. Gorson had close ties with such groups as Americans For Democratic Action, the Student Nonviolent Coordinating Committee, and Students for a Democratic Society.
Ochs was writing songs at an amazing pace. Some of the songs he wrote during this period were held back and recorded on his later albums.
1967–1969.
In 1967, Ochs—now managed by his brother Michael—left Elektra for A&M Records and moved to California. He recorded four studio albums for A&M: "Pleasures of the Harbor" (1967), "Tape from California" (1968), "Rehearsals for Retirement" (1969), and the ironically titled "Greatest Hits" (1970) (which actually consisted of all new material). For his A&M albums, Ochs moved away from simply produced solo acoustic guitar performances and experimented with ensemble and even orchestral instrumentation, "baroque-folk", in the hopes of producing a pop-folk hybrid that would be a hit.
Critic Robert Christgau, writing in "Esquire" of "Pleasures of the Harbor" in May 1968, did not consider this new direction a good turn. While describing Ochs as "unquestionably a nice guy", he went on to say, "too bad his voice shows an effective range of about half an octave [and] his guitar playing would not suffer much if his right hand were webbed." "Pleasures of the Harbor", Christgau continued, "epitomizes the decadence that has infected pop since "Sgt. Pepper". [The] gaudy musical settings ... inspire nostalgia for the three-chord strum." With an ironic sense of humor, Ochs included Christgau's "webbed hand" comment in his 1968 songbook "The War is Over" on a page titled "The Critics Raved", opposite a full-page picture of Ochs standing in a large metal garbage can. Despite his sense of humor, Ochs was unhappy that his work was not receiving the critical acclaim and popular success he had hoped for. Still, Ochs would joke on the back cover of "Greatest Hits" that there were 50 Phil Ochs fans ("50 fans can't be wrong!"), a sarcastic reference to an Elvis Presley album that bragged of 50 million Elvis fans.
None of Ochs's songs became hits, although "Outside of a Small Circle of Friends" received a good deal of airplay. It reached #119 on "Billboard"'s national "Hot Prospect" listing before being pulled from some radio stations because of its lyrics, which sarcastically suggested that "smoking marijuana is more fun than drinking beer". It was the closest Ochs ever came to the Top 40. Joan Baez, however, did have a Top Ten hit in the U.K. in August 1965, reaching #8 with her cover of Ochs's song "There but for Fortune", which was also nominated for a Grammy Award for "Best Folk Recording". In the U.S. it peaked at #50 on the "Billboard" charts—a good showing, but not a hit.
Although he was trying new things musically, Ochs did not abandon his protest roots. He was profoundly concerned with the escalation of the Vietnam War, performing tirelessly at anti-war rallies across the country. In 1967 he organized two rallies to declare that "The War Is Over"—"Is everybody sick of this stinking war? In that case, friends, do what I and thousands of other Americans have done—declare the war over."—one in Los Angeles in June, the other in New York in November. He continued to write and record anti-war songs, such as "The War Is Over" and "White Boots Marching in a Yellow Land". Other topical songs of this period include "Outside of a Small Circle of Friends", inspired by the murder of Kitty Genovese, who was stabbed to death outside of her New York City apartment building while dozens of her neighbors reportedly ignored her cries for help, and "William Butler Yeats Visits Lincoln Park and Escapes Unscathed", about the despair he felt in the aftermath of the Chicago 1968 Democratic National Convention police riot.
Ochs was writing more personal songs as well, such as "Crucifixion", in which he compared the deaths of Jesus Christ and President John F. Kennedy as part of a "cycle of sacrifice" in which people build up heroes and then celebrate their destruction; "Chords of Fame", a warning against the dangers and corruption of fame; "Pleasures of the Harbor", a lyrical portrait of a lonely sailor seeking human connection far from home; and "Boy in Ohio", a plaintive look back at Ochs's childhood in Columbus.
A lifelong movie fan, Ochs worked the narratives of justice and rebellion that he had seen in films into his music, describing some of his songs as "cinematic". He was disappointed and bitter when his onetime hero John Wayne embraced the Vietnam War with what Ochs saw as the blind patriotism of Wayne's 1968 film, "The Green Berets":
[H]ere we have John Wayne, who was a major artistic and psychological figure on the American scene, ... who at one point used to make movies of soldiers who had a certain validity, ... a certain sense of honor [about] what the soldier was doing... Even if it was a cavalry movie doing a historically dishonorable thing to the Indians, even as there was a feeling of what it meant to be a man, what it meant to have some sense of duty... Now today we have the same actor making his new war movie in a war so hopelessly corrupt that, without seeing the movie, I'm sure it is perfectly safe to say that it will be an almost technically-robot-view of soldiery, just by definition of how the whole country has deteriorated. And I think it would make a very interesting double feature to show a good old Wayne movie like, say, "She Wore a Yellow Ribbon" with "The Green Berets". Because that would make a very striking comment on what has happened to America in general.
Ochs was involved in the creation of the Youth International Party, known as the Yippies, along with Jerry Rubin, Abbie Hoffman, Stew Albert, and Paul Krassner. At the same time, Ochs actively supported Eugene McCarthy's more mainstream bid for the 1968 Democratic nomination for President, a position at odds with the more radical Yippie point of view. Still, Ochs helped plan the Yippies' "Festival of Life" which was to take place at the 1968 Democratic National Convention along with demonstrations by other anti-war groups including the National Mobilization Committee to End the War in Vietnam. Despite warnings that there might be trouble, Ochs went to Chicago both as a guest of the McCarthy campaign and to participate in the demonstrations. He performed in Lincoln Park, Grant Park, and at the Chicago Coliseum, witnessed the violence perpetrated by the Chicago police against the protesters, and was himself arrested at one point.
The events of 1968—the assassinations of Martin Luther King, Jr. and Robert F. Kennedy, the police riot in Chicago, and the election of Richard Nixon—left Ochs feeling disillusioned and depressed. The cover of his 1969 album "Rehearsals for Retirement" eerily portrays a tombstone with the words:
PHIL OCHS<br>
(AMERICAN)<br>
BORN: EL PASO, TEXAS, 1940<br>
DIED: CHICAGO, ILLINOIS, 1968
At the trial of the Chicago Seven in December 1969, Ochs testified for the defense. His testimony included his recitation of the lyrics to his song "I Ain't Marching Anymore". On his way out of the courthouse, Ochs sang the song for the press corps; to Ochs's amusement, his singing was broadcast that evening by Walter Cronkite on the CBS Evening News.
1970.
After the riot in Chicago and the subsequent trial, Ochs changed direction again. The events of 1968 convinced him that the average American was not listening to topical songs or responding to Yippie tactics. Ochs thought that by playing the sort of music that had moved him as a teenager he could speak more directly to the American public.
Ochs turned to his musical roots in country music and early rock and roll. He decided he needed to be "part Elvis Presley and part Che Guevara", so he commissioned a gold lamé suit from Elvis Presley's costumer Nudie Cohn. Ochs wore the gold suit on the cover of his 1970 album, "Greatest Hits", which consisted of new songs largely in rock and country styles.
Ochs went on tour wearing the gold suit, backed by a rock band, singing his own material along with medleys of songs by Buddy Holly, Elvis, and Merle Haggard. His fans did not know how to respond. This new Phil Ochs drew a hostile reaction from his audience. Ochs's March 27, 1970, concerts at Carnegie Hall were the most successful, and by the end of that night's second show Ochs had won over many in the crowd. The show was recorded and released as "Gunfight at Carnegie Hall".
During this period, Ochs was taking drugs to get through performances. He had been taking Valium for years to help control his nerves, and he was also drinking heavily. Pianist Lincoln Mayorga said of that period, "He was physically abusing himself very badly on that tour. He was drinking a lot of wine and taking uppers. The wine was pulling him one way and the uppers were pulling him another way, and he was kind of a mess. There were so many pharmaceuticals around—so many pills. I'd never seen anything like that." Ochs tried to cut back on the pills, but alcohol remained his drug of choice for the rest of his life.
Depressed by his lack of widespread appreciation and suffering from writer's block, Ochs did not record any further albums. He slipped deeper into depression and alcoholism. His personal problems notwithstanding, Ochs performed at the inaugural benefit for Greenpeace on October 16, 1970, at the Pacific Coliseum in Vancouver, BC. A recording of his performance, along with performances by Joni Mitchell and James Taylor, was released by Greenpeace in 2009.
1971–1975.
In August 1971, Phil went to Chile, where Salvador Allende, a Marxist, had been democratically elected in the 1970 election. There he met Chilean folksinger Víctor Jara, an Allende supporter, and the two became friends. In October, Ochs left Chile to visit Argentina. Later that month, after singing at a political rally in Uruguay, he and his American traveling companion David Ifshin were arrested and detained overnight. When the two returned to Argentina, they were arrested as they got off the airplane. After a brief stay in an Argentinian prison, Ochs and Ifshin were sent to Bolivia via a commercial airliner where authorities were to detain them. Ifshin had previously been warned by Argentine leftist friends that when authorities sent dissidents to Bolivia, they would disappear forever. When the airliner arrived in Bolivia, the American captain of the Braniff International Airways aircraft allowed Ochs and Ifshin to stay on the aircraft and barred Bolivian authorities from entering. The aircraft then flew to Peru where the two disembarked and they were not detained. Fearful that Peruvian authorities might arrest him, Ochs returned to the United States a few days later.
Ochs was having difficulties writing new songs during this period, but he had occasional breakthroughs. He updated his sarcastic song "Here's to the State of Mississippi" as "Here's to the State of Richard Nixon", with cutting lines such as "the speeches of the Spiro are the ravings of a clown", a reference to Nixon's vitriolic vice president, Spiro Agnew—sung as "the speeches of the President are the ravings of a clown" after Agnew's resignation.
Ochs was personally invited by John Lennon to sing at a large benefit at the University of Michigan in December 1971 on behalf of John Sinclair, an activist poet who had been arrested on minor drug charges and given a severe sentence. Ochs performed at the John Sinclair Freedom Rally along with Stevie Wonder, Allen Ginsberg, David Peel, Abbie Hoffman and many others. The rally culminated with Lennon and Yoko Ono, who were making their first public performance in the United States since the breakup of The Beatles.
Although the 1968 election had left him deeply disillusioned, Ochs continued to work for the election campaigns of anti-war candidates, such as George McGovern's unsuccessful Presidential bid in 1972.
In 1972, Ochs was asked to write the theme song for the film "Kansas City Bomber". The task proved difficult, as Ochs struggled to overcome his writer's block. Although his song was not used in the soundtrack, it was released as a single.
Ochs decided to travel. In mid-1972, he went to Australia and New Zealand. He traveled to Africa in 1973, where he visited Ethiopia, Kenya, Tanzania, Malawi, and South Africa. One night, Ochs was attacked and strangled by robbers in Dar es Salaam, Tanzania, which damaged his vocal cords, causing a loss of the top three notes in his vocal range. The attack also exacerbated his growing mental problems, and he became increasingly paranoid. Ochs believed the attack may have been arranged by government agents—perhaps the CIA. Still, he continued his trip, even recording a single in Kenya, "Bwatue".
On September 11, 1973, the Allende government of Chile was overthrown in a "coup d'état". Allende died during the bombing of the presidential palace, and Jara was publicly tortured and killed. When Ochs heard about the manner in which his friend had been killed, he was outraged. He decided to organize a benefit concert to bring to public attention the situation in Chile and raise funds for the people of Chile. The concert, "An Evening with Salvador Allende", included films of Allende; singers such as Pete Seeger, Arlo Guthrie, and Bob Dylan; and political activists such as former U.S. Attorney General Ramsey Clark. Dylan had agreed to perform at the last minute when he heard that the concert had sold so few tickets that it was in danger of being canceled. Once his participation was announced, the event quickly sold out.
After the Chile benefit, Ochs and Dylan discussed the possibility of a joint concert tour, playing small nightclubs. Nothing came of the Dylan-Ochs plans, but the idea eventually evolved into Dylan's Rolling Thunder Revue.
The Vietnam War ended on April 30, 1975. Ochs planned a final "War Is Over" rally, which was held in New York's Central Park on May 11. More than 100,000 people came to hear Ochs, joined by Harry Belafonte, Odetta, Pete Seeger and others. Ochs and Joan Baez sang a duet of "There but for Fortune" and he closed with his song "The War Is Over"—finally a true declaration that the war was over.
Decline and death.
Ochs's drinking became more and more of a problem, and his behavior became increasingly erratic. He frightened his friends both with his drunken rants about the FBI and CIA, and about his claiming to want to have Elvis's manager Colonel Tom Parker or Kentucky Fried Chicken's Colonel Sanders manage his career.
In mid-1975, Ochs took on the identity of John Butler Train. He told people that Train had murdered Ochs, and that he, John Butler Train, had replaced him. Train was convinced that someone was trying to kill him, so he carried a weapon at all times: a hammer, a knife, or a lead pipe.
Ochs's friends tried to help him. His brother Michael attempted to have him committed to a psychiatric hospital. Friends pleaded with him to get help voluntarily. They feared for his safety, because he was getting into fights with bar patrons. Unable to pay his rent, he began living on the streets.
After several months, the Train persona faded and Ochs returned, but his talk of suicide disturbed his friends and family. They hoped it was a passing phase, but Ochs was determined. One of his biographers explains Ochs's motivation:
By Phil's thinking, he had died a long time ago: he had died politically in Chicago in 1968 in the violence of the Democratic National Convention; he had died professionally in Africa a few years later, when he had been strangled and felt that he could no longer sing; he had died spiritually when Chile had been overthrown and his friend Victor Jara had been brutally murdered; and, finally, he had died psychologically at the hands of John Train.
In January 1976, Ochs moved to Far Rockaway, New York, to live with his sister Sonny. He was lethargic; his only activities were watching television and playing cards with his nephews. Ochs saw a psychiatrist, who diagnosed his bipolar disorder. He was prescribed medication, and he told his sister he was taking it. On April 9, 1976, Ochs hanged himself.
Years after his death, it was revealed that the FBI had a file of nearly 500 pages on Ochs. Much of the information in those files relates to his association with counterculture figures, protest organizers, musicians, and other people described by the FBI as "subversive". The FBI was often sloppy in collecting information on Ochs: his name was frequently misspelled "Oakes" in their files, and they continued to consider him "potentially dangerous" after his death.
Congresswoman Bella Abzug (Democrat from New York), an outspoken anti-war activist herself who had appeared at the 1975 "War is Over" rally, entered this statement into the "Congressional Record" on April 29, 1976:
Mr. Speaker, a few weeks ago, a young folksinger whose music personified the protest mood of the 1960s took his own life. Phil Ochs—whose original compositions were compelling moral statements against war in Southeast Asia—apparently felt that he had run out of words.
While his tragic action was undoubtedly motivated by terrible personal despair, his death is a political as well as an artistic tragedy. I believe it is indicative of the despair many of the activists of the 1960s are experiencing as they perceive a government which continues the distortion of national priorities that is exemplified in the military budget we have before us.
Phil Ochs' poetic pronouncements were part of a larger effort to galvanize his generation into taking action to prevent war, racism, and poverty. He left us a legacy of important songs that continue to be relevant in 1976—even though "the war is over".
Just one year ago—during this week of the anniversary of the end of the Vietnam War—Phil recruited entertainers to appear at the "War is Over" celebration in Central Park, at which I spoke.
It seems particularly appropriate that this week we should commemorate the contributions of this extraordinary young man.
Robert Christgau, who had been so critical of "Pleasures of the Harbor" and Ochs's guitar skills eight years earlier, wrote warmly of Ochs in his obituary in the "Village Voice". "I came around to liking Phil Ochs' music, guitar included," Christgau wrote. "My affection [for Ochs] no doubt prejudiced me, so it is worth [noting] that many observers who care more for folk music than I do remember both his compositions and his vibrato tenor as close to the peak of the genre."
Legacy.
Almost forty years after his death, Ochs's songs remain relevant. Ochs continues to influence singers and fans worldwide, many of whom never saw him perform live. There are mailing lists and online discussion groups dedicated to Ochs and his music; websites that have music samples, photographs, and other links; and articles and books continue to be written and published about him.
His sister Sonny Ochs (Tanzman) runs a series of "Phil Ochs Song Nights" with a rotating group of performers who keep Ochs's music and legacy alive by singing his songs in cities across the U.S. Michael Ochs is a photographic archivist of 20th-century music and entertainment personalities. Meegan Lee Ochs worked with Michael to produce a box set of Ochs's music titled "Farewells & Fantasies", the title of which was taken from Ochs's sign-off on the "postcard" on the back of "Tape from California": "Farewells & Fantasies, Folks, P. Ochs". Meegan has a son named Caidan, Ochs's only grandchild. Alice Skinner Ochs was a photographer; she died in November 2010.
In February 2009, the North American Folk Music and Dance Alliance gave the 2009 Elaine Weissman Lifetime Achievement Award to Phil Ochs.
In September 2014, Meegan Ochs announced that she was donating her father's archives to the Woody Guthrie Center in Tulsa, Oklahoma. Included are many of his notebooks, journals, videotapes of his performances, the gold lamé suit, photographs, and other documents and memorabilia that Meegan had preserved since his death.
Covers and updates.
Ochs's songs have been covered by scores of performers, including Eric Andersen, Peter Asher, Joan Baez, Bastro, Cilla Black, Black 47, Billy Bragg, Eugene Chadbourne, Cher, Gene Clark, Judy Collins, Henry Cow, Allison Crowe, John Denver, Kevin Devine, Ani DiFranco, disappear fear, Mark Eitzel, Marianne Faithfull, Julie Felix, Diamanda Galás, Dick Gaughan, Ronnie Gilbert, Thea Gilmore, Nanci Griffith, John Wesley Harding, Carolyn Hester, Pat Humphries, Jason & the Scorchers, Jim and Jean, Jeannie Lewis, Gordon Lightfoot, Christy Moore, Ray Naylor, Harry Nilsson, Will Oldham, Brian Ritchie, David Rovics, Melanie Safka, Pete Seeger, The Shrubs, Squirrel Bait, Crispian St. Peters, Teenage Fanclub, Tempest, They Might Be Giants, Dave Van Ronk, Eddie Vedder, and The Weakerthans. Wyclef Jean performed "Here's to the State of Mississippi" in the 2009 documentary "Soundtrack for a Revolution".
In 1998, Sliced Bread Records released "", a two CD set of 28 covers by artists that includes Eric Andersen, Billy Bragg, John Gorka, Nanci Griffith, Arlo Guthrie, Pat Humphries, Magpie, Tom Paxton, Dave Van Ronk, Sammy Walker, Peter Yarrow, and others. The liner notes indicate that all record company profits from the sale of the set were to be divided between the American Civil Liberties Union Foundation of Southern California and "Sing Out!" magazine.
Wood Records released an indie rock/experimental rock tribute album titled " in 2003.
In 2005, Kind Of Like Spitting released an album, ", consisting of covers of nine songs written by Ochs, to pay tribute to his music and raise awareness of the artist, whom they felt had been overlooked. 
Jello Biafra and Mojo Nixon, on their album "Prairie Home Invasion", recorded a version of "Love Me, I'm a Liberal" with lyrics updated to the Clinton era. Evan Greer, part of the Riot-Folk collective, later updated the song for the George W. Bush era. Ryan Harvey, also part of Riot-Folk, remade "Cops Of The World" with updated lyrics. The Clash used some of the lyrics to "United Fruit" in their song "Up in Heaven (Not Only Here)", which appeared on their 1980 album "Sandinista!". During their performance on "VH1 Storytellers", Pearl Jam covered "Here's to the State of Mississippi" with updated lyrics to include Jerry Falwell, Dick Cheney, John Roberts, Alberto Gonzales, and George W. Bush. In 2002, with the agreement of Ochs's sister Sonny, Richard Thompson added an extra verse to "I Ain't Marching Anymore" to reflect recent American foreign policy. Jefferson Starship recorded "I Ain't Marching Anymore" with additional lyrics by band member Cathy Richardson for their 2008 release "Jefferson's Tree of Liberty".
In 2013 Neil Young performed "Changes" at Farm Aid and included it in his 2014 tour set; it also is the lead track on "A Letter Home", his 2014 vinyl album of covers.
Tributes.
On learning of Ochs's death, Tom Paxton wrote a touching song titled "Phil", which he recorded for his 1978 album "Heroes". Ochs is also the subject of "I Dreamed I Saw Phil Ochs Last Night", by Billy Bragg, from his 1990 album "The Internationale", which was based on the Alfred Hayes/Earl Robinson song "Joe Hill" which Ochs helped popularize; Ochs also had his own, different song ("Joe Hill") about the early 20th-century union activist/songwriter. "Thin Wild Mercury," by Peter Cooper and Todd Snider, is about Ochs's infamous clash with Dylan and getting thrown out of Dylan's limo. Ochs is mentioned in the Dar Williams song "All My Heroes Are Dead", the Will Oldham song "Gezundheit", the Chumbawamba song "Love Me", and the They Might Be Giants song "The Day". The Josh Joplin Group recorded a tribute to Ochs on their album "Useful Music". Schooner Fare recorded "Don't Stop To Rest (Song for Phil Ochs)" on their 1981 album "Closer to the Wind". Latin Quarter memorialized him in the song "Phil Ochs" on their album "Long Pig" (1993).
John Wesley Harding recorded a song titled "Phil Ochs, Bob Dylan, Steve Goodman, David Blue and Me", the title a reference to the Ochs song "Bach, Beethoven, Mozart and Me". Singer-songwriter Nanci Griffith wrote a song about Phil entitled "Radio Fragile". English folk/punk songwriter Al Baker recorded a song about Ochs entitled "All The News That's Fit To Sing", a reference to the title of Ochs's first album. Cajun musician Vic Sadot wrote a song about Ochs entitled "Broadside Balladeer". Singer-songwriter Jen Cass's "Standing In Your Memory", and Harry Chapin's "The Parade's Still Passing By" are tributes to Ochs. Leslie Fish recorded "Chickasaw Mountain", which is dedicated to Ochs, on her 1986 album of that name. The punk band Squirrel Bait cited Ochs as a major creative influence in the liner notes of their 1986 album "Skag Heaven", and cover his "Tape From California". Ochs has also influenced Greek folk-rock songwriters; Dimitris Panagopoulos' "Astathis Isoropia" ("Unstable Equilibrium") (1987) and Dimitris Lampos' "Lampoons, Songs and Laments for the 21st Century" (2012) were dedicated to the memory of Phil Ochs. On the 2005 Kind Of Like Spitting album "In the Red", songwriter Ben Barnett included his song "Sheriff Ochs", which was inspired by reading a biography of Ochs. On April 9, 2009, Jim Glover performed a tribute to Ochs at Mother's Musical Bakery in Sarasota, Florida.
Popular culture.
Among Ochs's many admirers were the short story writer Breece D'J Pancake and actor Sean Penn. Meegan Lee Ochs, who worked as Sean Penn's personal assistant from 1983 to 1985, wrote in her Foreword to "Farewells & Fantasies" that she and Penn discussed "over many years" the possibility of making a movie about her father; the plan has not yet come to fruition, although Penn expressed an interest in the project as recently as February 2009. Author Jim Carroll's autobiography, "The Basketball Diaries" (1978), was dedicated in memory of Phil Ochs. On the cover of The Go-Betweens' "The Lost Album", Grant McLennan wore a shirt with the words "Get outta the car, Ochs", a reference to the limousine incident involving Ochs and Dylan. The 1994 film "Spanking the Monkey" makes reference to Ochs and his suicide. Ochs is mentioned in the Stephen King novels "The Tommyknockers" and "Hearts in Atlantis".
Films.
Michael Korolenko directed the 1984 biopic "Chords of Fame", which featured Bill Burnett as Ochs. The film included interviews with people who had known Ochs, including Yippies Abbie Hoffman and Jerry Rubin, manager Harold Leventhal, and Mike Porco, the owner of Gerde's Folk City. "Chords of Fame" also included performances of Ochs songs by folk musicians who knew him, including Bob Gibson, Pete Seeger, Tom Paxton, Dave Van Ronk, and Eric Andersen.
Filmmaker Ken Bowser directed the documentary film "", which premiered at the 2010 Woodstock Film Festival in Woodstock, New York. Its theatrical run began on January 5, 2011, at the IFC Theater in Greenwich Village, New York City, opening in cities around the US and Canada thereafter. The film features extensive archival footage of Ochs and many pivotal events from the 1960s civil rights and peace movements, as well as interviews with friends, family and colleagues who knew Ochs through music and politics. The PBS "American Masters" series opened its 2012 season with an edited version of the film.
In the 2011 film "Chicago 8", Ochs is played by actor Steven Schub, lead singer of ska bands The Fenwicks & HaSkaLA.
References.
</dl>

</doc>
<doc id="25125" url="http://en.wikipedia.org/wiki?curid=25125" title="Prayer wheel">
Prayer wheel

A prayer wheel is a cylindrical wheel (Tibetan: འཁོར་, Wylie: "'khor"
) on a spindle made from metal, wood, stone, leather or coarse cotton. Traditionally, the mantra Om Mani Padme Hum written in Sanskrit on the outside of the wheel. Also sometimes depicted are Dakinis, Protectors and very often the 8 auspicious symbols Ashtamangala. At the core of the cylinder is a "Life Tree" often made of wood or metal with certain mantras written on or wrapped around it. Many thousands (or in the case of larger prayer wheels, millions) of mantras are then wrapped around this life tree. The Mantra Om Mani Padme Hum is most commonly used, but other mantras may be used as well. According to the Tibetan Buddhist tradition based on the lineage texts regarding prayer wheels, spinning such a wheel will have much the same meritorious effect as orally reciting the prayers.
Nomenclature and etymology.
Prayer wheel or Mani wheel (Tibetan: མ་ནི་ཆོས་འཁོར་, Wylie: "mani-chos-'khor"
). The Tibetan term is a contraction: "Mani" itself is a contraction of Sanskrit "cintamani"; "chos" is Tibetan for "Dharma"; and "khor" or "khorlo" means "chakrano
Origins.
The earliest recorded prayer wheels were written of by a Chinese pilgrim around 400 C.E. in Ladakh. The concept of the prayer wheel is a physical manifestation of the phrase "turning the wheel of Dharma," which describes the way in which the Buddha taught. Prayer Wheels originated from ‘The School of Shakyamuni sutra, volume 3 – pagoda and temple’ which states that, “those who set up the place for worship, use the knowledge to propagate the dharma to common people, should there be any man or woman who are illiterate and unable to read the sutra, they should then set up the prayer wheel to facilitate those illiterate to chant the sutra, and the effect is the same as reading the sutra”
According to the Tibetan tradition, the prayer wheel lineage traces back to the famous Indian master, Arya Nagarjuna. Tibetan texts also say that the practice was taught by the Indian Buddhist masters Tilopa and Naropa as well as the Tibetan masters Marpa and Milarepa.
Practice.
According to the lineage texts on prayer wheels, prayer wheels are used to accumulate wisdom and merit (good karma) and to purify negativities (bad karma). In Buddhism, Buddhas and Bodhisattvas have created a variety of skillful means (upaya) to help bring practitioners ever closer to realizing enlightenment. The idea of spinning mantras relates to numerous Tantric practices whereby the Tantric practitioner visualizes mantras revolving around the nadis and especially around the meridian chakras such as the heart and crown. Therefore, prayer wheels are a visual aid for developing one's capacity for these types of Tantric visualizations. The spiritual method for those practicing with a prayer wheel is very specific (with slight variations according to different Buddhist sects). The practitioner most often spins the wheel clockwise, as the direction in which the mantras are written is that of the movement of the sun across the sky. On rare occasions, advanced Tantric practitioners such as Senge Dongma, the Lion-Faced Dakini, spin prayer wheels counterclockwise to manifest a more wrathful protective energy. As the practitioner turns the wheel, it is best to focus the mind and repeat the Om Mani Padme Hum mantra. Not only does this increase the merit earned by the wheel's use, but it is a mind-stabilization technique that trains the mind while the body is in motion. Intoning the mani mantra with mindfulness and the "Bodhicitta" motivation dramatically enhances the effects of the prayer wheel. However, it is said that even turning it while distracted has benefits and merits, and it is stated in the lineage text that even insects that cross a prayer wheel's shadow will get some benefit. Each revolution is as meritorious as reading the inscription aloud as many times as it is written on the scroll, and this means that the more Om Mani Padme Hum mantras that are inside a prayer wheel, the more powerful it is. It is best to turn the wheel with a gentle rhythm and not too fast or frantically. While turning smoothly, one keeps in mind the motivation and spirit of compassion and "bodhichitta" (the noble mind that aspires to full enlightenment for the benefit of all beings).
The benefits attributed to the practice of turning the wheel are vast. Not only does it help wisdom, compassion and bodhichitta arise in the practitioner, it also enhances siddhis (spiritual powers such as clairvoyance, precognition, reading others thoughts, etc.). The practitioner can repeat the mantra as many times as possible during the turning of the wheel, stabilizing a calm, meditative mind. At the end of a practice session, there is a Tibetan Buddhist tradition of dedicating any accumulated merits that one may have gathered during practice to the benefit of all sentient beings. Then Om Ah Hum 3 times. This is customary with Tibetans upon completing any Buddhist practice, including the practice of the prayer wheel.
Thubten Zopa Rinpoche has commented that installing a prayer wheel has the capacity to completely transform a place, which becomes "...peaceful, pleasant, and conducive to the mind."
Simply touching a prayer wheel is said to bring great purification to negative karmas and obscurations.
Types.
Mani wheel.
The "mani wheel", or hand prayer wheel, has a cylindrical, generally sheet-metal body (often beautifully embossed) mounted on a metal shaft or pin set into a wooden or metal handle that turns on a circular bearing commonly made of "Turbinella" (conch) shell. The cylinder itself is affixed with a cord or chain terminating in a metal weight allowing it to be spun by a slight rotation of the wrist. The weighted chain, known as a “governor” in Western technology, stabilizes the wheel and keeps it spinning with less input from the practitioner than would otherwise be the case. The common term, “prayer wheel” is a double misnomer. A long strip of rolled-up paper bearing printed or inscribed mantras (Tib. "mani") rather than prayers, per se, is inside the cylinder. “Mill,” defined as “a spinning object that generates something,” is a better translation of the Tibetan "‘khor-lo" than is “wheel” since it is thought that the spinning cylinder emanates positive energy, allowing the practitioner to accumulate wisdom and merit. The Tibetan name of this device is mani-chos-'khor (མ་ནི་ཆོས་འཁོར་).
Water wheels.
This type of prayer wheel is simply a prayer wheel that is turned by flowing water. The water that is touched by the wheel is said to become blessed and carries its purifying power into all life forms in the oceans and lakes that it feeds into.
Fire wheel.
This wheel is turned by the heat of a candle or electric light. The light emitted from the prayer wheel then purifies the negative karmas of the living beings it touches.
Wind wheel.
This type of wheel is turned by wind. The wind that touches the prayer wheel helps alleviate the negative karma of those it touches.
Stationary prayer wheels.
Many monasteries around Tibet have large, fixed, metal wheels set side by side in a row. Passersby can turn the entire row of wheels simply by sliding their hands over each one.
Electric dharma wheels.
Some prayer wheels are powered by electric motors. "Thardo Khorlo," as these electric wheels are sometimes known, contain one thousand copies of the mantra of Chenrezig and many copies of other mantras. The Thardo Khorlo can be accompanied by lights and music if one so chooses. However, Lama Zopa Rinpoche has said, "The merit of turning an electric prayer wheel goes to the electric company. This is why I prefer practitioners to use their own 'right energy' to turn a prayer wheel".

</doc>
<doc id="25126" url="http://en.wikipedia.org/wiki?curid=25126" title="Postage stamp">
Postage stamp

A postage stamp is a small piece of paper that is purchased and displayed on an item of mail as evidence of payment of postage. Typically, stamps are printed on special custom-made paper, show a national designation and a denomination (value) on the front, and have a gum adhesive on the back. Postage stamps are purchased from a postal administration or other authorized vendor, and are used to pay for the costs involved in moving mail, as well as other business necessities such as insurance and registration. They are sometimes a source of net profit to the issuing agency, especially when sold to collectors who will not actually use them for postage.
Stamps are usually rectangular, but triangles or other shapes are occasionally used. The stamp is affixed to an envelope or other postal cover (e.g., packet, box, mailing cylinder) the customer wishes to send. The item is then processed by the postal system, where a postmark, sometimes known as a cancellation mark, is usually applied in overlapping manner to stamp and cover. This procedure marks the stamp as used to prevent its reuse. In modern usage, postmarks generally indicate the date and point of origin of the mailing. The mailed item is then delivered to the address the customer has applied to the envelope or parcel.
Postage stamps have facilitated the delivery of mail since the 1840s. Before then, ink and hand-stamps (hence the word 'stamp'), usually made from wood or cork, were often used to frank the mail and confirm the payment of postage. The first adhesive postage stamp, commonly referred to as the Penny Black, was issued in the United Kingdom in 1840. The invention of the stamp was part of an attempt to reform and improve the postal system in the United Kingdom of Great Britain and Ireland, which, in the early 19th century, was in disarray and rife with corruption. There are varying accounts of the inventor or inventors of the stamp.
Before the introduction of postage stamps, mail in the UK was paid for by the recipient, a system that was associated with an irresolvable problem: the costs of delivering mail were not recoverable by the postal service when recipients were unable or unwilling to pay for delivered items, and senders had no incentive to restrict the number, size, or weight of items sent, whether or not they would ultimately be paid for. The postage stamp resolved this issue in a simple and elegant manner, with the additional benefit of room for an element of beauty to be introduced. Concurrently with the first stamps, the UK offered wrappers for mail. Later related inventions include postal stationery such as prepaid-postage envelopes, post cards, lettercards, aerogrammes, postage meters, and, more recently, specialty boxes and envelopes provided free to the customer by the U.S. postal service for priority or express mailing.
The postage stamp afforded convenience for both the mailer and postal officials, more effectively recovered costs for the postal service, and ultimately resulted in a better, faster postal system. With the conveniences stamps offered, their use resulted in greatly increased mailings during the 19th and 20th centuries. Postage stamps during this era were the most popular way of paying for mail; however, by the end of the 20th century were rapidly being eclipsed by the use of metered postage and bulk mailing by businesses.
As postage stamps with their engraved imagery began to appear on a widespread basis, historians and collectors began to take notice. The study of postage stamps and their use is referred to as philately. Stamp collecting can be both a hobby and a form of historical study and reference, as government-issued postage stamps and their mailing systems have always been involved with the history of nations.
Invention.
Throughout modern history, numerous innovations were used to apply or indicate that postage has been paid on a mailed item, hence the invention of the postage stamp has been accredited to several different people.
In 1680 William Dockwra, an English merchant in London, and his partner Robert Murray established the London Penny Post, a mail system that delivered letters and small parcels inside the city of London for the sum of one penny. The postage for the mailed item was prepaid by the use of a hand-"stamp" to frank the mailed item, confirming payment of postage. Though this 'stamp' was applied to a letter instead of a separate piece of paper it is considered by many historians as the world's first postage stamp.
In 1835, the Slovene civil servant Lovrenc Košir from Ljubljana in Austria-Hungary (now Slovenia), suggested the use of "artificially affixed postal tax stamps" using "gepresste papieroblate" which translates as "pressed paper wafers" but although the suggestion was looked at in detail, it was not adopted.
The Englishman Sir Rowland Hill began interest in postal reform in 1835. In 1836, a Member of Parliament, Robert Wallace, provided Hill with numerous books and documents, which Hill described as a "half hundred weight of material". Hill commenced a detailed study of these documents, leading him to the 1837 publication of a pamphlet entitled "Post Office Reform its Importance and Practicability". He submitted a copy of this to the Chancellor of the Exchequer, Thomas Spring-Rice, on 4 January 1837. This first edition was marked "private and confidential," and was not released to the general public. The Chancellor summoned Hill to a meeting during which the Chancellor suggested improvements and changes to be presented in a supplement, which Hill duly produced and supplied on 28 January 1837.
Rowland Hill then received a summons to give evidence before the Commission for Post Office Enquiry on 13 February 1837. During his evidence, he read from the letter he wrote to the Chancellor, including a statement the notation of paid postage could be created "...by using a bit of paper just large enough to bear the stamp, and covered at the back with a glutinous wash...". This is the first publication of an unambiguous description of a modern adhesive postage stamp (though the term "postage stamp" did not yet exist at that time). Shortly afterward, the second edition of Hill’s booklet, dated 22 February 1837, was published, and made available to the general public. This booklet, containing some 28,000 words, incorporated the supplement given to the Chancellor, and statements he made to the Commission.
Hansard records that on 15 December 1837, Benjamin Hawes inquired to the Chancellor of the Exchequer "whether it was the intention of the Government to give effect to the recommendation of the Commissioners of the Post-office, contained in their ninth report relating to the reduction of the rates of postage, and the issuing of penny stamps?"
Hill’s ideas for postage stamps and charging paid-postage based upon weight soon took hold, and were adopted in many countries throughout the world. With the new policy of charging by weight, using envelopes for mailing documents became the norm. Hill’s brother Edwin Hill invented a prototype envelope-making machine that folded paper into envelopes quickly enough to match the pace of the growing demand for postage stamps.
Rowland Hill and the postal reforms he introduced to the UK postal system are commemorated on several commemorative postage issues of the United Kingdom.
Scotsman Patrick Chalmers asserted the claim that his father, James Chalmers, was the inventor of the first postage stamp in the 1881 publication "The Penny Postage Scheme of 1837." In this book, the son claims James Chalmers first produced an essay describing and advocating a stamp in August 1834; however, no evidence for this is provided in the book. Until his death in 1891, Patrick Chalmers campaigned to gain recognition for his father as the inventor of the postage stamp.
The first independent evidence for Chalmers' claim is the essay and proposal he submitted for adhesive postage stamps to the General Post Office, dated 8 February 1838 and received by the Post Office on 17 February 1838. In this approximately 800-word document concerning methods of indication letters postage-paid he states, "Therefore, of Mr Hill’s plan of a uniform rate of postage ... I conceive that the most simple and economical mode ... would be by Slips ... in the hope that Mr Hill’s plan may soon be carried into operation I would suggest that sheets of Stamped Slips should be prepared ... then be rubbed over on the back with a strong solution of gum ...". Chalmers' original document is now in the UK's National Postal Museum.
Given the postage denominations stated in James Chalmers' essay mirrored those proposed by Rowland Hill in February 1837, it is clear Chalmers was aware of Hill’s proposals. It is unknown whether Chalmers obtained a copy of Hill’s booklet, or simply read about it in "The Times" newspaper that on two occasions - 25 March 1837, 20 December 1837 - reported in great detail Hill’s proposals. Neither of Hill's articles mention of "a bit of paper just large enough to bear the stamp," hence available information at the time via the Times' article could not have made Chalmers aware Hill previously made such a proposal. This suggests either Chalmers previously read Hill's booklet and was merely expounding on Hill's idea, or he concurrently and independently developed the idea of the modern postage stamp.
James Chalmers organized petitions "for a low and uniform rate of postage". The first such petition was presented in the House of Commons on 4 December 1837 (from Montrose). Further petitions organised by him were presented on 1 May 1838 (from Dunbar and Cupar), 14 May 1838 (from the county of Forfar), and 12 June 1839. In this period of time, other groups organized petitions and presented them to Parliament. All petitions for consumer-oriented, low-cost, volume based postal rates following the disclosure of Hill's proposals.
Other claimants include or have included
History.
Although a number of people laid claim to the concept of the postage stamp, it is well documented that stamps were first introduced in the United Kingdom on 1 May 1840 as a part of postal reforms promoted by Sir Rowland Hill. With its introduction, the postage fee was then to be paid by the sender and not the recipient, though it was still possible to send mail without prepaying. Postmarks have been applied over stamps, "obliterating" them from further usage, since the first postage stamps came into use.
The first stamp, the penny black, became available for purchase 1 May 1840, to be valid as of 6 May 1840. Two days later, 8 May 1840, the two pence blue was introduced. Both stamps exhibit an engraving of the young Queen Victoria, neither bearing perforations, as the first stamps were separated from their sheets by cutting mechanisms (e.g. scissors). At the time of issuance, given no need for indication of origin, no country name was included on the postage stamps. The UK remains the only country to omit itself by name on postal stamps, using the reigning monarch’s head as implicit identification. Following the introduction of the postage stamp in the UK, the use of this prepaid postage innovation drastically accelerated the number of postal-sent. Prior to 1839, the number of letters sent was 76 million. By 1850 this volume increased five-fold to 350 million, continuing to grow rapidly thereafter, until the end of the 20th century when newer methods of indicating postage-paid drastically reduced the use of delivery systems requiring stamps.
Other countries soon followed in example the United Kingdom with their own stamps. The Canton of Zürich in Switzerland issued the Zurich 4 and 6 rappen on 1 March 1843. Although the Penny Black could be used to send a letter less than half an ounce anywhere within the United Kingdom, the Swiss did not initially adopt that system, instead continuing to calculate mail rates based on distance to be delivered. Brazil issued the Bull’s Eye stamp on 1 August 1843. Using the same printer as for the Penny Black, Brazil opted for an abstract design instead of portrait of Emperor Pedro II, so his image would be not be disfigured by a postmark. In 1845 some postmasters in the United States issued their own stamps, but it was not until 1847 that the first official U.S. stamps were created: 5 and 10 cent issues depicting Benjamin Franklin and George Washington. A few other countries issued stamps in the late 1840s. Many others, such as India, initiated their use in the 1850s, and by the 1860s most countries issued stamps.
Perforation of postage stamps began January 1854. The first officially perforated stamps were issued in February 1854. Stamps from Henry Archer's perforation trials were issued the last few months of 1850; during the 1851 parliamentary session at the House of Commons, and finally in 1853/54 after the government paid Mr. Archer £4,000 for his machine and the patent.
Design.
When the first postage stamps were issued in the 1840s, they followed an almost identical standard in shape, size and general subject matter. They were rectangular in shape. They bore the images of Queens, Presidents and other political figures. They also depicted the denomination of the postage-paid, and with the exception of the United Kingdom, depicted the name of the country from which issued. Nearly all early postage stamps depict images of national leaders only. Soon after the introduction of the postage stamp, other subjects and designs began to appear. Some designs were welcome, others widely criticized. For example, in 1869, the U.S. Post Office broke tradition of depicting presidents or other famous historical figures, instead using other subjects including a train, and horse. (See: 1869 Pictorial Issue.) The change was greeted with general disapproval, and sometimes harsh criticism from the American public.
Perforations.
Perforations are small holes made between individual postage stamps on a sheet of stamps, facilitating separation of a desired number of stamps. The resulting frame-like, rippled edge surrounding the separated stamp defines a characteristic meme for the appearance of a postage stamp.
In the first decade of postage stamps' existence (depending on the country), stamps were issued without perforations. Scissors or other cutting mechanisms were required to separate a desired number of stamps from a full sheet. If cutting tools were not used, individual stamps were torn off. This is evidenced by the ragged edges of surviving examples. Mechanically separating stamps from a sheet proved an inconvenience for postal clerks and businesses, both dealing with large numbers of individual stamps on a daily basis. By 1850, methods such as rouletting wheels were being devised in efforts of making stamp separation more convenient, and less time consuming.
The United Kingdom was the first country to issue postage stamps with perforations. The first machine specifically designed to perforate sheets of postage stamps was invented in London by Henry Archer, an Irish landowner and railroad man from Dublin, Ireland. The 1850 Penny Red. was the first stamp to be perforated during trial course of Archer's perforating machine. After a period of trial and error and modifications of Archer's invention, new machines based on the principles pioneered by Archer were purchased and in 1854 the U.K. postal authorities started continuously issuing perforated postage stamps in the Penny Red and all subsequent designs.
The United States government and the Post Office were quick to follow the lead of the U.K. In the U.S., the use of postage stamps caught on quickly and became more widespread when on March 3, 1851, the last day of its legislative session, Congress passed the "Act of March 3, 1851" ("An Act to reduce and modify the Rates of Postage in the United States"). Similarly introduced on the last day of the Congressional session four years later, the "Act of March 3, 1855" required the prepayment of postage on all mailings. Thereafter, postage stamp use in the U.S. quickly doubled, and by 1861 had quadrupled. In 1856, under the direction of Postmaster General James Campbell, Toppan and Carpenter, ("commissioned by the U.S. government to print U.S. postage stamps through the 1850s") purchased a rotary machine designed to separate stamps, patented in England in 1854 by William and Henry Bemrose, who were printers in Derby, England. The original machine cut slits into the paper rather than punching holes, but the machine was soon modified. The first stamp issue to be officially perforated, the 3-cent George Washington, was issued by the U.S. Post Office on February 24, 1857. Between 1857 and 1861 all stamps originally issued between 1851 to 1856 were reissued with perforations. Initial capacity was insufficient to perforate all stamps printed, thus perforated issues used between February and July 1857 are scarce and quite valuable.
Shapes and materials.
In addition to the most common rectangular shape, stamps have been issued in geometric (circular, triangular and pentagonal) and irregular shapes. The United States issued its first circular stamp in 2000 as a hologram of the earth. Sierra Leone and Tonga have issued stamps in the shapes of fruit. Stamps that are printed on sheets are generally separated by perforations, though, more recently, with the advent of gummed stamps that do not have to be moistened prior to affixing them, designs can incorporate smooth edges (although a purely decorative perforated edge is often present).
Stamps are most commonly made from paper designed specifically for them, and are printed in sheets, rolls, or small booklets. Less commonly, postage stamps are made of materials other than paper, such as embossed foil (sometimes of gold). Switzerland made a stamp that contained a bit of lace and one of wood. The United States produced one of plastic. East Germany issued a stamp of synthetic chemicals. In the Netherlands a stamp was made of silver foil. Bhutan issued one with its national anthem on a playable record.
Graphic characteristics.
The subjects found on the face of postage stamps are generally what defines a particular stamp issue to the public and are often a reason why they are saved by collectors or history enthusiasts. Graphical subjects found on postage stamps have ranged from the early portrayals of kings, queens and presidents to later depictions of ships, birds and satellites, famous people, historical events, comics, dinosaurs, hobbies (knitting, stamp collecting), sports, holiday themes, and a wealth of other subjects too numerous to list.
Artists, designers, engravers and administrative officials are involved with the choice of subject matter and the method of printing stamps. Early stamp images were almost always produced from engravings — a design etched into a steel die, which was then hardened and whose impression was transferred to a printing plate. Using an "engraved" image was deemed a more secure way of printing stamps as it was nearly impossible to counterfeit a finely detailed image with raised lines unless you were a master engraver. In the mid-20th century, stamp issues produced by other forms of printing began to emerge, such as lithography, photogravure, intaglio and web offset printing. These later printing methods were less expensive and typically produced images of lesser quality.
Types.
Apart from these, there are also Revenue (used to collect taxes or fees on items such as documents, tobacco, alcoholic drinks, hunting licenses and medicines) and Telegraph stamps (for sending telegrams), which fall in a separate category from postage stamps.
First day covers.
Postage stamps are first issued on a specific date, often referred to as the "First day of issue." A "first day cover" usually consists of an envelope, a postage stamp and a postmark with the date of the stamp’s first day of issue thereon. Starting in the mid-20th century some countries began assigning the first day of issue to a place associated with the subject of the stamp design, such as a specific town or city. There are two basic types of "First Day Covers" (FDCs) noted by collectors. The first and often most desirable type among advanced collectors is a cover sent through the mail in the course of everyday usage, without the intention of the envelope and stamp ever being retrieved and collected. The second type of FDC is often referred to as "Philatelic," that is, an envelope and stamp sent by someone with the intention of retrieving and collecting the mailed item at a later time and place. The envelope used for this type of FDC often bears a printed design or cachet of its own in correspondence with the stamp’s subject and is usually printed well in advance of the first day of issue date. The latter type of FDC is usually far more common, and is usually inexpensive and relatively easy to acquire. Covers that were sent without any secondary purpose are considered "non-philatelic" and often are much more challenging to find and collect.'
Souvenir or miniature sheets.
Postage stamps are sometimes issued in souvenir sheets or miniature sheets containing one or a small number of stamps. Souvenir sheets typically include additional artwork or information printed on the selvage, the border surrounding the stamps. Sometimes the stamps make up a greater picture. Some countries, and some issues, are produced as individual stamps as well as sheets.
Stamp collecting.
Stamp collecting is a popular hobby. Collecting is not the same as philately, which is defined as the study of stamps. It is not necessary to closely study stamps in order to enjoy collecting them. Many casual collectors enjoy accumulating stamps without worrying about the details. The creation of a valuable or comprehensive collection, however, may require some philatelic knowledge.
Stamp collectors are an important source of revenue for some small countries that create limited runs of elaborate stamps designed mainly to be bought by stamp collectors. The stamps produced by these countries may far exceed their postal needs. Hundreds of countries, each producing scores of different stamps each year, resulted in 400,000 different types of stamps in existence by the year 2000. Annual world output averages about 10,000 types.
Some countries authorize the production of postage stamps that have no postal use, but are intended instead solely for collectors. Other countries issue large numbers of low denomination stamps that are bundled together in starter packs for new collectors. "Official reprints" are often printed by companies who have purchased or contacted for those rights and such reprints see no postal use. All of these stamps are often found "canceled to order", meaning they are postmarked without ever having passed through the postal system. Most national post offices produce stamps that would not be produced if there were no collectors, some to a far more prolific degree than others. It is up to individual collectors whether this concerns them; collecting such issues is as legitimate an endeavor as any other collection, but is unlikely to result in a collection of any value or to provide a monetary return on an investment (though it may be found worthwhile in other ways, such as teaching geography or collecting methods to a child, or sheer pleasure in the beauty of some of these issues). Others may argue that since these stamps are virtually worthless, they will be discarded in large numbers and eventually become less common and thus collectable in their own right, though this process would likely take many decades.
Sales of stamps to collectors who do not use them for mailing can result in large profits. Good examples of excessive issues have been (1) the stamps produced by Nicholas F. Seebeck and (2) stamps produced for the component states of the United Arab Emirates. Seebeck operated in the 1890s as an agent of Hamilton Bank Note Company. He approached Latin American countries with an offer to produce their entire postage stamp needs for free. In return he would have exclusive rights to market stamps to collectors. Each year a new issue would be produced, but would expire at the end of the year. This assured Seebeck of a continuing supply of remainders. In the 1960s, printers such as the Barody Stamp Company contracted to produce stamps for the separate Emirates and other countries. The sparse population of the desert states made it wholly unlikely that many of these stamps would ever be used for mailing purposes, and earned them the name of the "sand dune" countries. Another example of what might be considered by some to be excessive issues is that, at the time of the millennium, the United Kingdom issued 96 different stamps over about 24 months, all for pre-existing values with the same four rates for each set.
In the United States there is concern among some collectors that the United States Postal Service has become a promotional agent for the media and entertainment industry, as it has frequently issued entire sets of stamps featuring movie stars and cartoon characters like Mickey Mouse and Bart Simpson Over the decades the annual average number of new postage stamp issued by the U.S.P.S. has significantly increased.

</doc>
<doc id="25127" url="http://en.wikipedia.org/wiki?curid=25127" title="Pavo">
Pavo

Pavo or Parvo may refer to:

</doc>
<doc id="25130" url="http://en.wikipedia.org/wiki?curid=25130" title="Ponte Vecchio">
Ponte Vecchio

The Ponte Vecchio ("Old Bridge", ]) is a Medieval stone closed-spandrel segmental arch bridge over the Arno River, in Florence, Italy, noted for still having shops built along it, as was once common. Butchers initially occupied the shops; the present tenants are jewelers, art dealers and souvenir sellers. The Ponte Vecchio's two neighbouring bridges are the Ponte Santa Trinita and the Ponte alle Grazie.
History and construction.
The bridge spans the Arno at its narrowest point where it is believed that a bridge was first built in Roman times, when the via Cassia crossed the river at this point. The Roman piers were of stone, the superstructure of wood. The bridge first appears in a document of 996. After being destroyed by a flood in 1117 it was reconstructed in stone but swept away again in 1333 save two of its central piers, as noted by Giovanni Villani in his "Nuova Cronica". It was rebuilt in 1345, Giorgio Vasari recorded the tradition in his day, that attributed its design to Taddeo Gaddi, besides Giotto one of the few artistic names of the trecento still recalled two hundred years later. Modern historians present Neri di Fioravanti as a possible candidate. Sheltered in a little loggia at the central opening of the bridge is a weathered dedication stone, which once read "Nel trentatrè dopo il mille-trecento, il ponte cadde, per diluvio dell' acque: poi dieci anni, come al Comun piacque, rifatto fu con questo adornamento". The Torre dei Mannelli was built at the southeast corner of the bridge to defend it.
The bridge consists of three segmental arches: the main arch has a span of 30 m the two side arches each span 27 m. The rise of the arches is between 3.5 and 4.4 meters (11½ to 14½ feet), and the span-to-rise ratio 5:1.
It has always hosted shops and merchants who displayed their goods on tables before their premises, after authorization of the Bargello (a sort of a lord mayor, a magistrate and a police authority). The back shops ("retrobotteghe") that may be seen from upriver, were added in the seventeenth century.
It is said that the economic concept of bankruptcy originated here: when a money-changer could not pay his debts, the table on which he sold his wares (the "banco") was physically broken ("rotto") by soldiers, and this practice was called "bancorotto" (broken table; possibly it can come from "banca rotta" which means "broken bank"). Not having a table anymore, the merchant was not able to sell anything.
During World War II, the Ponte Vecchio was not destroyed by Germans during their retreat on the advance of the liberating British 8th Army on August 4, 1944, unlike all other bridges in Florence. This was allegedly, according to many locals and tour guides, because of an express order by Hitler. Access to Ponte Vecchio was, however, obstructed by the destruction of the buildings at both ends, which have since been rebuilt using a combination of original and modern design.
Vasari's Corridor.
In order to connect the Palazzo Vecchio (Florence's town hall) with the Palazzo Pitti, in 1565 Cosimo I de' Medici had Giorgio Vasari build the Vasari Corridor above it. To enforce the prestige of the bridge, in 1593 the Medici Grand Dukes prohibited butchers from selling there; their place was immediately taken by several gold merchants. The corporative association of butchers had monopolised the shops on the bridge since 1442. A stone with an inscription from Dante ("Paradiso" xvi. 140-7) records the spot at the entrance to the bridge where Buondelmonte de' Buondelmonti was murdered on behalf of the Amidei, in 1215, initiating the urban fighting of the Guelfs and Ghibellines.
Recent history.
Along the Ponte Vecchio, there can be seen many padlocks affixed in various places, especially to the railing around the statue of Benvenuto Cellini. This is a recent tradition for the Ponte Vecchio, although it has been practiced in Russia and in Asia before. It was perhaps introduced by the padlock shop owner at the end of the bridge. It is popularly connected to idea of love and lovers: by locking the padlock and throwing the key into the river, the lovers became eternally bonded. This is an example of the negative impact of mass tourism: thousands of padlocks needed to be removed frequently, spoiling or damaging the structure of the centuries-old bridge; however, it seems to have decreased after the city administration put a sign on the bridge mentioning a €160 penalty for those caught locking something to the fence.
There is a similar ongoing padlock phenomenon at Ponte Milvio, due to one of Federico Moccia's books.
The bridge was severely damaged in the 1966 flood of the Arno.
The bridge is mentioned in the aria "O mio babbino caro" by Giacomo Puccini.
Panoramic view of the Ponte Vecchio, from the West.

</doc>
<doc id="25133" url="http://en.wikipedia.org/wiki?curid=25133" title="Porto Ottiolu">
Porto Ottiolu

Porto Ottiolu is a private marina and a tourist destination located in the commune of Budoni, Province of Olbia-Tempio, 
Sardinia, Italy, on Tyrrhenian Sea, some 35 km south of Olbia.
Overview.
It was built in 1988 in the place in where was once the ancient Roman port of "Portiolum," and after its immediate success, a huge village was built around it with the same name.
The marina can host 405 boats in 8 classes and has complete services. It is the largest marina of the East coast of Sardinia.
In its waters, apneist diver Gianluca Genoni repeatedly scored new world records.
Other activities include fishing.

</doc>
<doc id="25134" url="http://en.wikipedia.org/wiki?curid=25134" title="Peenemünde Army Research Center">
Peenemünde Army Research Center

The Peenemünde Army Research Center (German: "Heeresversuchsanstalt Peenemünde",‡ HVP) was founded in 1937 as one of five military proving grounds under the German Army Weapons Office (Heeres Waffenamt).:85 It is widely regarded as the birthplace of modern rocketry and spaceflight.
On April 2, 1936, the Ministry of Aviation (Nazi Germany) paid 750,000 reichsmarks to the town of Wolgast:41 for the whole Northern peninsula of the Baltic island of Usedom.:17 The site had been suggested by Wernher von Braun's mother as 'just the place for you and your friends'. By the middle of 1938, the Army facility had been separated from the Luftwaffe facility and was nearly complete, with personnel moved from Kummersdorf. The Army Research Center ("Peenemünde Ost") consisted of "Werk Ost" and "Werk Süd", while "Werk West" (Peenemünde West) was the Luftwaffe Test Site ("Erprobungsstelle der Luftwaffe"),:55one of the four test and research facilities of the Luftwaffe, with its headquarters facility at "Erprobungsstelle Rechlin"
HVP Organization.
Wernher von Braun was the HVP technical director (Dr Walter Thiel was deputy director) and there were nine major departments::38
The Measurements Group (Gerhard Reisig) was part of the BSM, and additional departments included the Production Planning Directorate (Detmar Stahlknecht),:161 the Personnel Office (Richard Sundermeyer), and the Drawings Change Service.
Guided missile and rocket development at Peenemünde.
Several German guided missiles and rockets of World War II were developed by the HVP, including the V-2 rocket (A-4) (see test launches), and the Wasserfall (35 Peenemünde trial firings), Schmetterling, Rheintochter, Taifun, and Enzian missiles. The HVP also performed preliminary design work on very-long-range missiles for use against the United States. That project was sometimes called the "V - 3", and its existence is well documented. The Peenemünde establishment also developed other techniques, such as the first closed-circuit television system in the world, installed at Test Stand VII to track the launching rockets.
The supersonic wind tunnel at Peenemünde's "Aerodynamic Institute" eventually had nozzles for speeds up to the record speed of Mach 4.4 (in 1942 or 1943), as well as an innovative desiccant system to reduce the condensation clouding caused by the use of liquid oxygen, in 1940. Led by Rudolph Hermann who arrived in April 1937 from the University of Aachen, the number of technical staff members reached two hundred in 1943, and it also included Hermann Kurzweg of the (University of Leipzig) and Walter Haeussermann.
Initially set up under the HVP as a rocket training battery (Number 444), "Heimat-Artillerie-Park 11 Karlshagen/Pomerania":125 (HAP 11) also contained the A-A Research Command North:65 for the testing of anti-aircraft rockets. The chemist Magnus von Braun, the youngest brother of Wernher von Braun, was employed in the attempted development at Peenemünde of anti-aircraft rockets.:66 These were never very successful as weapons during World War II. Their development as practical weapons took another decade of development in the United States and in the U.S.S.R.
Peenemünde V-2 Production Plant.
In November 1938, Walther von Brauchitsch ordered construction of an A-4 Production Plant at Peenemünde, and in January 1939, Walter Dornberger created a subsection of Wa Pruf 11 for planning the Peenemünde Production Plant project, headed by G. Schubert, a senior Army civil servant. By midsummer 1943, the first trial runs of the assembly-line in the Production Works at "Werke Süd" were made,
 but after the end of July 1943 when the enormous hangar "Fertigungshalle 1" (F-1, Mass Production Plant No. 1) was just about to go into operation, Operation Hydra bombed Peenemünde. On August 26, 1943, Albert Speer called a meeting with Hans Kammler, Dornberger, Gerhard Degenkolb, and Karl Otto Saur to negotiate the move of A-4 main production to an underground factory in the Harz mountains.:123:202 In early September, Peenemünde machinery and personnel for production (including Alban Sawatzki, Arthur Rudolph, and about ten engineers):79 were moved to the Mittelwerk, which also received machinery and personnel from the two other planned A-4 assembly sites. On October 13, 1943, the Peenemünde prisoners from the small F-1 concentration camp boarded rail cars bound for Kohnstein mountain.
Operation Crossbow.
Two Polish janitors:52 of Peenemünde's Camp Trassenheide in early 1943:52 provided maps, sketches and reports to Polish Home Army Intelligence, and in June 1943 British intelligence had received two such reports which identified the "rocket assembly hall', 'experimental pit', and 'launching tower'.:139
As the opening attack of the British Operation Crossbow, the Operation "Hydra" air-raid attacked the HVP's "Sleeping & Living Quarters" (to specifically target scientists), then the "Factory Workshops", and finally the "Experimental Station" on the night of August 17/18, 1943. The Polish janitors were given advance warning of the attack, but the workers could not leave due to SS security and the facility had no air raid shelters for the prisoners.:82
A year later on July 18, August 4,:111 and August 25,:273 the US Eighth Air Force:141 conducted three additional Peenemünde raids to counter suspected hydrogen peroxide production.
Evacuation.
As with the move of the V-2 Production Works to the Mittelwerk, the complete withdrawal of the "development" of guided missiles was approved by the Army and SS in October 1943. On August 26, 1943, at a meeting in Albert Speer's office, Hans Kammler suggested moving the A-4 Development Works to a proposed underground site in Austria. After a site survey in September by Papa Riedel and Schubert, Kammler chose the code name Zement ("cement") for it in December, and work to blast an underground cavern into a cliff at Lake Traunsee near Gmunden commenced in January 1944.:109 In early 1944, construction work started for the test stands and launching pads in the Austrian Alps (code name Salamander), with target areas planned for the Tatra Mountains, the Arlberg range, and the area of the Ortler mountain. Other evacuation locations included:
For people being relocated from Peenemünde, the new organization was to be designated Entwicklungsgemeinschaft Mittelbau (English: Mittelbau Development Company):291 and Kammler's order to relocate to Thuringia arrived by teleprinter on January 31, 1945.:288 On February 3, 1945, at the last meeting at Peenemünde held regarding the relocation, the HVP consisted of A-4 development/ modification (1940 people), A-4b development (27), Wasserfall and Taifun development (1455), support and administration (760).:289 The first train departed on February 17 with 525 people en route to Thuringia (including Bleicherode, Sangerhausen (district), and Bad Sachsa) and the evacuation was complete in mid-March.:247
Another reaction to the aerial bombing was the creation of a back-up research test range near Blizna, in southeastern Poland. Carefully camouflaged, this secret facility was built by 2000 prisoners from the Pustkow concentration camp. The Polish resistance movement ("Armia Krajowa") succeeded in capturing an intact V2 rocket here in 1943. It had been launched for a test flight, failed but didn't explode, and was retrieved intact from the Bug River and transferred secretly to London.
Post-war.
The last V-2 launch at Peenemünde happened in February 1945, and on May 5, 1945, the soldiers of the Soviet 2nd Belorussian Front under General Konstantin Rokossovsky captured the seaport of Swinemünde and all of Usedom Island. Soviet infantrymen under the command of Major Anatole Vavilov stormed the installations at Peenemünde and found "75 percent wreckage". All of the research buildings and rocket test stands had been demolished.
Although rumors spread that the Soviet space program revived Peenemünde as a test range, more destruction of the technical facilities of Peenemünde took place between 1948 and 1961. Only the power station, the airport, and the railroad link to Zinnowitz remained functional. The gas plant for the production of liquid oxygen still lies in ruins at the entrance to Peenemünde. Very little remains of most of the other Nazi German facilities there.
The Peenemünde Historical Technical Museum opened in 1992 in the shelter control room and the area of the former power station and is an anchor point of ERIH, the European Route of Industrial Heritage.
References.
^‡ A different spelling is "Heeresversuchsstelle Peenemünde",:36 and "Heeresanstalt Peenemünde" appears on a German document with Wasserfall velocity calculations.:78

</doc>
<doc id="25135" url="http://en.wikipedia.org/wiki?curid=25135" title="Padstow">
Padstow

Padstow (Cornish: Lannwedhenek) is a town, civil parish and fishing port on the north coast of Cornwall, England, United Kingdom. The town is situated on the west bank of the River Camel estuary approximately 5 mi northwest of Wadebridge, 10 mi northwest of Bodmin and 10 mi northeast of Newquay. The population of Padstow civil parish was 3,162 in the 2001 census, reducing to 2,993 at the 2011 census In addition an electoral ward with the same name exists but extends as far as Trevose Head. The population for this ward is 4,434
History.
Padstow was originally named "Petroc-stow", Petroc-stowe, or 'Petrock's Place', after the Welsh missionary Saint Petroc, who landed at Trebetherick around AD 500. After his death a monastery (Lanwethinoc, the church of Wethinoc an earlier holy man) was established here which was of great importance until "Petroces stow" (probably Padstow) was raided by the Vikings in 981, according to the Anglo-Saxon Chronicle. Whether as a result of this attack or later the monks moved inland to Bodmin taking with them the relics of St Petroc. The cult of St Petroc was important both in Padstow and Bodmin.
Padstow is recorded in the Domesday Book (1086) when it was held by Bodmin Monastery. There was land for 4 ploughs, 5 villeins who had 2 ploughs, 6 smallholders and 24 acres of pasture. It was valued at 10/-.
In the medieval period Padstow was commonly called Aldestowe ('old place' in contrast to Bodmin, the 'new place'). or Hailemouth (hayle" being Cornish for estuary). The modern Cornish form "Lannwedhenek" derives from "Lanwethinoc" and in a simpler form appears in the name of the Lodenek Press, a publisher based in Padstow.
The seal of the borough of Padstow was a ship with three masts the sails furled and an anchor hanging from the bow, with the legend "Padstow." 
Churches.
The church of St Petroc is one of four said to have been founded by the saint, the others being Little Petherick,Parracombe and Bodmin. It is quite large and mostly of 13th and 14th century date. There is a fine 15th century font of Catacleuse p : the pulpit of ca. 1530 is also of interest. There are two fine monuments to members of the Prideaux family (Sir 
Nicholas, 1627 and Edmund, 1693): there is also a monumental brass of 1421.
Maritime traffic.
During the mid-nineteenth century, ships carrying timber from Canada (particularly Quebec City) would arrive at Padstow and offer cheap travel to passengers wishing to emigrate. Shipbuilders in the area would also benefit from the quality of their cargoes. Among the ships that sailed were the barques "Clio", "Belle" and "Voluna"; and the brig "Dalusia".
The approach from the sea into the River Camel is partially blocked by the Doom Bar, a bank of sand extending across the estuary which is a significant hazard to shipping and the cause of many shipwrecks.
For ships entering the estuary, the immediate loss of wind due to the cliffs was a particular hazard, often resulting in ships being swept onto the Doom Bar. A manual capstan was installed on the west bank of the river (its remains can still be seen) and rockets were fired to carry a line to ships so that they could be winched to safety.
There have been ferries across the Camel estuary for centuries and the current service, the Black Tor Ferry, carries pedestrians between Padstow and Rock daily throughout the year.
Economy.
Traditionally a fishing port, Padstow is now a popular tourist destination. Although some of its former fishing fleet remains, it is mainly a yachting haven on a dramatic coastline with few easily navigable harbours. The influence of restaurateur Rick Stein can be seen in the port, and tourists travel from long distances to eat at his restaurant and cafés.
However, the boom in the popularity of the port has caused house price inflation both in the port and surrounding areas, as people buy homes to live in, or as second or holiday homes. This has meant significant numbers of locals cannot afford to buy property in the area, with prices often well over 10 times the average salary of around £15,000. This has led to a population decline.
Plans to build a skatepark in Padstow have been proposed and funds are being raised to create this at the Recreation Ground (Wheal Jubilee Parc).
Railway.
From 1899 until 1967 Padstow railway station was the westernmost point of the former Southern Railway. The station was the terminus of an extension from Wadebridge of the former Bodmin and Wadebridge Railway and North Cornwall Railway. These lines were part of the London and South Western Railway (LSWR), then incorporated into the Southern Railway in 1923 and British Railways in 1948, but were proposed for closure during the Beeching Axe of the 1960s.
The LSWR (and Southern Railway) promoted Padstow as a holiday resort; these companies were rivals to the Great Western Railway (which was the larger railway in the West of England). Until 1964, Padstow was served by the Atlantic Coast Express – a direct train service to/from London (Waterloo) – but the station was closed in 1967. The old railway line is now the Camel Trail, a footpath and cycle path which is popular owing to its picturesque route beside the River Camel. One of the railway mileposts is now embedded outside the Shipwright's Arms public house on the Harbour Front.
Today, the nearest railway station is at Bodmin Parkway, a few miles south of Bodmin. Western Greyhound operate buses to the station.
Footpaths.
The South West Coast Path runs on both sides of the River Camel estuary and crosses from Padstow to Rock via the Black Tor ferry. The path gives walking access to the coast with Stepper Point and Trevose Head within an easy day's walk of Padstow.
The Saints' Way long-distance footpath runs from Padstow to Fowey on the south coast of Cornwall.
The Camel Trail cycleway follows the course of the former railway ("see above") from Padstow. It is open to walkers, cyclists and horse riders and suitable for disabled access. The 17.3 mi long route leads to Wadebridge and on to Wenford Bridge and Bodmin and used by an estimated 400,000 users each year generating an income of approximately £3 million a year.
Culture.
'Obby 'Oss festival.
Padstow is best known for its "'Obby 'Oss" festival. Although its origins are unclear, it most likely stems from an ancient fertility rite, perhaps the Celtic festival of Beltane. The festival starts at midnight on May Eve when townspeople gather outside the Golden Lion Inn to sing the "Night Song." By morning, the town has been dressed with greenery and flowers placed around the maypole. The excitement begins with the appearance of one of the 'Obby 'Osses. Male dancers cavort through the town dressed as one of two 'Obby 'Osses, the "Old" and the "Blue Ribbon" 'Obby 'Osses; as the name suggests, they are stylised kinds of horses. Prodded on by acolytes known as "Teasers," each wears a mask and black frame-hung cape under which they try to catch young maidens as they pass through the town. Throughout the day, the two parades, led by the "Mayer" in his top hat and decorated stick, followed by a band of accordions and drums, then the 'Oss and the Teaser, with a host of people - all singing the "Morning Song." - pass along the streets of the town. Finally, late in the evening, the two 'osses meet, at the maypole, before returning to their respective stables where the crowd sings of the 'Obby 'Oss death, until its resurrection the following May Eve.
Mummers' or Darkie Day.
On Boxing Day and New Year's Day, it is a tradition for some residents to don blackface and parade through the town singing 'minstrel' songs. This is an ancient midwinter celebration that occurs every year in Padstow and was originally part of the pagan heritage of midwinter celebrations that were regularly celebrated all over Cornwall where people would guise dance and disguise themselves by blackening up their faces or wearing masks. Recently the people of Penzance have revived its midwinter celebration with the Montol Festival which like Padstow at times would have had people darkening or painting their skin to disguise themselves as well as masking.)
Folklorists associate the practice with the widespread British custom of blacking up for mumming and morris dancing, and suggest there is no record of slave ships coming to Padstow. Once an unknown local charity event, the day has recently become controversial, perhaps since a description was published. 
Also some now suggest it is racist for white people to "black up" for any reason. 
Although "outsiders" have linked the day with racism, Padstonians insist that this is not the case and are incredulous at both description and allegations. Long before the controversy Charlie Bate, noted Padstow folk advocate, recounted that in the 1970s the content and conduct of the day were carefully reviewed to avoid potential offence. 
The Devon and Cornwall Constabulary have taken video evidence twice and concluded there were no grounds for prosecution. 
Nonetheless protests resurface annually. The day has now been renamed "Mummers' Day" in an attempt to avoid offence and identify it more clearly with established Cornish tradition. 
The debate has now been subject to academic scrutiny.
Other similar traditions that use the black-face disguise and are still celebrated within the United Kingdom are the Border Morris dancers, and Molly dancers of the East Midlands and East Anglia.
Antiquities.
"Time Team" visited Padstow for the episode "From Constantinople to Cornwall," broadcast on 9 March 2008.

</doc>
<doc id="25136" url="http://en.wikipedia.org/wiki?curid=25136" title="Dakar Rally">
Dakar Rally

The Dakar Rally (or simply "The Dakar"; formerly known as the "Paris–Dakar Rally") is an annual rally raid organised by the Amaury Sport Organisation. Most events since the inception in 1978 were from Paris, France, to Dakar, Senegal, but due to security threats in Mauritania, which led to the cancellation of the 2008 rally, the 2009 Dakar Rally was run in South America (Argentina and Chile). It has been held in South America each year since 2009. The race is open to amateur and professional entries, amateurs typically making up about eighty percent of the participants.
Despite its "rally" name, it is an off-road endurance race, properly called a "rally raid" rather than a conventional rally. The terrain that the competitors traverse is much tougher and the vehicles used are true off-road vehicles rather than the modified on-road vehicles used in rallies. Most of the competitive special sections are off-road, crossing dunes, mud, camel grass, rocks, and erg among others. The distances of each stage covered vary from short distances up to 800 - per day.
History.
Thierry Sabine years.
The race originated in December 1978, a year after Thierry Sabine got lost in the Ténéré desert whilst competing in the Abidjan-Nice rally and decided that the desert would be a good location for a regular rally. 182 vehicles took the start of the inaugural rally in Paris, with 74 surviving the 10,000 km trip to the Senegalese capital of Dakar. Cyril Neveu holds the distinction of being the event's first winner, riding a Yamaha motorcycle. The event rapidly grew in popularity, with 216 vehicles taking the start in 1980 and 291 in 1981. Neveu won the event for a second time in 1980, Hubert Auriol taking honours in 1981 for BMW. By this stage, the rally had already begun to attract the participation of famous names from elsewhere in motorsport, such as Henri Pescarolo and Jacky Ickx.
Now boasting 382 competitors, more than double the amount that took the start in 1979, Neveu won the event for a third time in 1982, this time riding a Honda motorcycle, while victory in the car class went to the Marreau brothers, driving a privately entered Renault 20, whose buccaneering exploits seemed to perfectly capture the spirit of the early years of the rally. Auriol captured his second bikes class victory in 1983, the first year that Japanese manufacturer Mitsubishi competed in the rally, beginning an association that would last all the way until 2009.
At the behest of 1983 car class winner Jacky Ickx, Porsche entered the Dakar in 1984, with the total number of entries now at 427. The German marque won the event at their first attempt courtesy of René Metge, who had previously won in the car category in 1981, whilst Ickx finished sixth. Gaston Rahier meanwhile continued BMW's success in the motorcycle category with back-to-back wins in 1984 and 1985, the year of Mitsubishi's first victory of 12 in the car category, Patrick Zaniroli taking the spoils. The 1986 event, won by Metge and Neveu, was marred by the death of event founder Sabine in a helicopter crash, his father Gilbert taking over organisation of the rally.
Peugeot-Citroën domination.
The 1987 rally marked the start of an era of increased official factory participation in the car category, as French manufacturer Peugeot arrived and won the event with former World Rally champion Ari Vatanen. The 1987 event was also notable for a ferocious head-to-head duel between Neveu and Auriol in the motorcycle category, the former taking his fifth victory after Auriol was forced to drop out of the rally after breaking both ankles in a fall. The 1988 event saw the event reach its zenith in terms of entry numbers, with 603 starters. Vatanen's title defence was derailed when his Peugeot was stolen from the service area at Bamako. Though it was later found, Vatanen was subsequently disqualified from the event, victory instead going to compatriot and teammate Juha Kankkunen.
Peugeot and Vatanen returned to winning ways in 1989 and 1990, the latter marking Peugeot's final year of rally competition before switching to the World Sportscar Championship. Sister brand Citroën took Peugeot's place, Vatanen taking a third consecutive victory in 1991. The 1991 event also saw Stéphane Peterhansel take his first title in the motorcycle category with Yamaha, marking the beginning of an era of domination by the Frenchman.
The 1992 event saw the finish line move to Cape Town, South Africa in a bid to combat a declining number of competitors, where GPS technology was used for the first time. Auriol became the first person to win in multiple classes after taking Mitsubishi's second victory in the car class, while Peterhansel successfully defended his motorcycle category title. The 1993 rally saw the entry list slump to just 153 competitors, around half of the preceding year's figure and around a quarter of that of 1988. The event was also the last to be organised by Gilbert Sabine, with the Amaury Sport Organisation taking over the following year. With the finish line now back in its traditional location of Dakar, Bruno Saby won a third title for Mitsubishi, Peterhansel taking a third straight success in the motorcycle category.
The 1994 event saw the competitors return to Paris after reaching Dakar, resulting in a particularly gruelling event. Pierre Lartigue took Citroën's second win in acrimonious circumstances, as Mitsubishi's leading drivers were forced to withdraw from exhaustion after traversing some particularly demanding sand dunes in the Mauritanian desert that the Citroen crews had opted to skip. Peterhansel's non-appearance due to a disagreement between Yamaha and the race organisers over the regulations meanwhile allowed Edi Orioli to claim a third title in the bikes category. The 1995 and 1996 events saw the rally begin from the Spanish city of Granada, Lartigue racking up a further two wins for Citroen in both years. Peterhansel meanwhile returned to take a fourth bikes category win in 1995, but lost out to Orioli in 1996 because of refuelling problems.
Mitsubishi in the ascendancy.
The 1997 rally saw the event run exclusively in Africa for the first time, with the route running from Dakar to Agadez, Niger and back to Dakar. Citroen's withdrawal due to a rule change paved the way for Mitsubishi to take a fourth victory, Japan's Kenjiro Shinozuka becoming the first non-European to win the event. Peterhansel meanwhile equalled Neveu's record of five motorcycle category wins in 1997, before going one better in 1998, a year which saw the event return to its traditional Paris-Dakar route and Dakar veteran Jean-Pierre Fontenay take another win for Mitsubishi in the car class.
1999 saw the start return to Granada and a maiden success for erstwhile Formula One and sportscar driver Jean-Louis Schlesser, who had constructed his own buggies to take part in the race since 1992. With the help of Renault backing, Schlesser overcame the works Mitsubishi and Nissan crews to take victory, whilst Peterhansel's decision to switch to the car category allowed Richard Sainct to take BMW's first title in the bikes category since 1985. Schlesser and Sainct both successfully defended their titles in 2000, which saw the competitors travel from Dakar to the Egyptian capital of Cairo.
2001 marked the final time that the rally would use the familiar Paris-Dakar route, and was notable for Mitsubishi's Jutta Kleinschmidt becoming the first woman to win the rally - albeit only after Schlesser was penalised one hour for unsportsmanlike conduct. Fabrizio Meoni also took the first Dakar win for Austrian manufacturer KTM, beginning a winning streak that has lasted until the present day. 2002 saw the start move to the French town of Arras, long-time Dakar participant Hiroshi Masuoka finally winning the event for Mitsubishi having led for much of the previous year's rally. The 2003 rally featured an unorthodox route from Marseille to Sharm El Sheikh, and saw Masuoka defend his title after teammate and long-time leader Peterhansel was plagued by mechanical problems in the penultimate stage. Sainct meanwhile took honours in the motorcycle category, the third title for both he and KTM.
The Dakar at its peak.
The mid-2000s saw the Dakar Rally reach the height of its popularity. The entry list by 2004 had swollen to 595, up from 358 in 2001, with a record 688 competitors taking the start in 2005. Alongside Mitsubishi and Nissan, Volkswagen now boasted a full factory effort, while Schlesser's Ford-powered buggies and BMWs of the German X-Raid team proved thorns in the side of the big budget works teams. The 2004 event was run from Clermont-Ferrand to Dakar, and was the year Peterhansel emulated Hubert Auriol's feat of winning the rally on both two wheels and four. The Frenchman defended his title in 2005, which saw the rally start for the first time in Barcelona. In the bikes category, KTM continued their success with Nani Roma in 2004, who switched to the car category the following year, and Cyril Despres in 2005.
2006 saw the start of the rally move to Lisbon, Nissan pulling out having failed to provide effective opposition to Mitsubishi, who took a sixth consecutive victory, this time with former skiing champion Luc Alphand after Peterhansel committed a series of errors late in the rally. Peterhansel made amends in 2007, however, taking his third title in the car category for Mitsubishi after a close contest with Alphand after the increasingly competitive Volkswagens retired with mechanical problems. In what would be the final African edition of the Dakar, Despres took his second title in the bikes category, having conceded victory in 2006 to Marc Coma after suffering an injury.
The 2008 event, due to depart Lisbon as per the previous two years, was cancelled on January 4, 2008 amid fears of terrorist attacks, causing serious doubts over the future of the rally. Chile and Argentina offered to host subsequent events, an offer later accepted by the ASO. 
The ASO also decided to establish the Dakar Series competition, whose first event was the 2008 Central Europe Rally, located in Hungary and Romania, which acted as a replacement for the cancelled 2008 edition of the Dakar.
South America.
The 2009 event, the first held in South America with a respectable entry of 501, saw Volkswagen finally take its first win in the Dakar as a works entrant courtesy of Giniel de Villiers. Teammate and former WRC champion Carlos Sainz had been leading comfortably until crashing out, but seized the opportunity to win the event in 2010. By now, however, Mitsubishi had withdrawn after a poor showing in 2009, leaving Volkswagen as the sole works entrant. The German marque duly won the race for a third time in 2011, this time with Nasser Al-Attiyah, before themselves withdrawing to focus on their upcoming WRC entry and leaving the Dakar with no factory participants in the car class. In the bikes, Despres and Coma stretched KTM's incredible unbroken run of success, both tied on three victories apiece after Coma's third win in 2011.
The 2012 rally saw the X-Raid team come to the fore, now using Minis in lieu of BMWs. Peterhansel had joined the team in 2010 after Mitsubishi's departure, but had been unable to challenge the Volkswagen drivers. Following Volkswagen's withdrawal however, Peterhansel was able to secure his fourth win in the car category and his tenth in total, his main opposition coming from within his own team. Peterhansel successfully defended his title in 2013, the Damen Jefferies buggies of Sainz and Al-Attiyah failing to last the distance. Despres also racked up a further two wins for KTM in the bikes class in 2012 and 2013, bringing his tally to five, aided by Coma's absence due to injury in the latter year. Coma struck back on his return to the Dakar in 2014, taking a comfortable fourth title and a 13th in succession for KTM, whilst Nani Roma emulated Auriol and Peterhansel by taking his maiden title in the cars class a decade on from his victory on two wheels - albeit only after team orders by X-Raid slowed down Peterhansel.
Peugeot returned for the 2015 event with an all-new, diesel-powered, two-wheel drive contender, but failed to make an impact as X-Raid's Minis once more dominated. Al-Attiyah won the event in his second year for the team, while Coma racked up a fifth title in the bikes after the defection of long-time rival Despres to the car class and Peugeot.
Vehicles and classes.
The four major competitive groups in the Dakar are the motorcycles, quads, the cars class, (which range from buggies to small SUVs) and the trucks class. Many vehicle manufacturers exploit the harsh environment the rally offers as a testing ground and consequently to demonstrate the durability of their vehicles, although most vehicles are heavily modified or purpose built.
Motorbikes.
As of 2011, the engine capacity limit for all motorbikes competing in the Dakar Rally is 450cc. Engines may be either single or twin cylinder. Riders are divided into two groups, "Elite" (Group 1) and Non-Elite (Group 2), with the latter subdivided into two further groups - the "Super Production" (Group 2.1) and "Marathon" (Group 2.2) classes. "Marathon" competitors are not permitted to change such key components as the engine (including the engine case, cylinders and cylinder heads), the frame, the forks or swinging arm, whereas those in the "Super Production" and "Elite" classes may replace these components.
KTM have dominated the motorcycle class in recent years, although Honda, Yamaha, Sherco and Gas Gas also compete currently. BMW and Cagiva have also enjoyed success in the past.
Quads.
Prior to 2009, Quads were a subdivision of the motorbike category, but they were granted their own separate classification in 2009 and are designated Group 3 in the current regulations. They are divided into two subgroups - Group 3.1, which features two-wheel drive quads with a single cylinder engine with a maximum capacity of 750cc, and Group 3.2, which permits four-wheel drive quads with a maximum engine capacity of 900cc, in either single or twin cylinder layout.
Yamaha are unbeaten in the Quad category since 2009, with their main current opposition coming courtesy of Honda and Can-Am.
Cars.
The car class is made up of vehicles weighing less than 3500 kg, which are subdivided into several categories. The T1 Group is made up of "Improved Cross-Country Vehicles", subdivided according to engine type (petrol or diesel) and drive type (two-wheel or four-wheel drive). The T2 Group is made up of "Cross-Country Series Production Vehicles", which are subdivided into petrol and diesel categories, while the T3 Group is for "Light Vehicles". There is also an "Open" category catering for vehicles conforming to SCORE regulations.
Mini have been the most successful marque in the car category in recent years, thanks to the efforts of the non-factory X-Raid team, with limited involvement currently coming from Toyota, Ford and Haval. Several constructors also produce bespoke buggies for the event, most notably SMG and Damen Jefferies.
Mitsubishi is historically the most successful manufacturer in the car class, with Volkswagen, Citroen, Peugeot and Porsche having all tasted success in the past with factory teams. Jean-Louis Schlesser has also won the event twice with his Renault-supported buggies. Factory teams from Nissan and SEAT have also won stages, as has BMW, courtesy of the X-Raid team.
Trucks.
The Truck class (T4), first run as a separate category in 1980, is made up of vehicles weighing more than 3500 kg. Trucks participating in the competition are subdivided into "Series Production" trucks (T4.1) and "Modified" trucks (T4.2), whilst Group T4.3 (formerly known as T5) trucks are rally support trucks - meaning they travel from bivouac to bivouac to support the competition vehicles. These were introduced to the rally in 1998. The truck event was not run in 1989 after it was decided the vehicles, by this stage with twin engines generating in excess of 1000 horsepower, were too dangerous following the death of a DAF crew member in an accident during the 1988 rally.
Kamaz has dominated the truck category since the turn of the century, although it has come under increasing pressure from rivals such as Iveco, MAN and Tatra, which enjoyed much success in the 1990s. Hino, DAF, Perlini and Mercedes-Benz have also been among the winners in the past.
Television coverage.
Over 190 different countries take the international feed of the event with a roundup of every day being made into a 26-minute programme. This has been commentated on by Toby Moody for ten years, and most recently Ben Constanduros.
The organisers provide 20 edit stations for various countries to produce their own programmes. There are four TV helicopters, six stage cameras, and three bivouac crews to make over 1,000 hours of TV over the two-week period. In the United States, coverage can be seen on NBC Sports Network.
A 2006 television documentary "Race to Dakar" described the experiences of a team, including the English actor Charley Boorman, in preparation for and entry into the 2006 Dakar Rally.
According to Gert Vermersch, the media coverage of the Dakar rally, particularly in Europe, has been decreasing. This has been triggered by the fact that the new South American edition of the race has proven to be less spectacular, at least in regards to the scenery as the original edition.
Incidents.
In 1982, Mark Thatcher, son of the then British Prime Minister Margaret Thatcher, along with his French co-driver Anne-Charlotte Verney and their mechanic, disappeared for six days. On January 9, the trio became separated from a convoy of vehicles after they stopped to make repairs to a faulty steering arm. They were declared missing on January 12; after a large-scale search, a Lockheed L100 search plane from the Algerian military spotted their white Peugeot 504 some 50 km off course. Thatcher, Verney, and the mechanic were all unharmed.
The organiser of the rally, Thierry Sabine, was killed when his Ecureuil helicopter crashed at 7:30 p.m. on Tuesday 14 January 1986, into a dune at Mali during a sudden sand-storm. Also killed onboard was the singer-songwriter Daniel Balavoine, helicopter pilot François-Xavier Bagnoud, journalist Nathalie Odent, and Jean-Paul Lefur who was a radiophonic engineer for RTL.
Six people were killed during the 1988 race, three participants and three local residents. In one incident, Baye Sibi, a 10-year-old Malian girl, was killed by a racer while she crossed a road. A film crew's vehicle killed a mother and daughter in Mauritania on the last day of the race. The race participants killed, in three separate crashes, were a Dutch navigator on the DAF Trucks team, a French privateer, and a French rider. Racers were also blamed for starting a wildfire that caused a panic on a train running between Dakar and Bamako, where three more people were killed.
In 2003 French driver Daniel Nebot both rolled and crashed his Toyota heavily at high speed killing his co-driver Bruno Cauvy.
In 2005, Spanish motorcyclist José Manuel Pérez died in a Spanish hospital on Monday, January 10 after crashing the week before on the 7th stage. Italian motorcyclist Fabrizio Meoni, a two-time winner of the event, became the second Dakar Rally rider to die in two days, following Pérez on January 11 on stage 11. Meoni was the 11th motorcyclist and the 45th person overall to die in the history of the race. On January 13, a five-year-old Senegalese girl was hit and killed by a service lorry after wandering onto a main road, bringing the total deaths to five.
In 2006, 41-year-old Australian KTM motorcyclist Andy Caldecott, in his third time in the Dakar, died January 9 as a result of neck injuries sustained in a crash approximately 250 km into stage 9, between Nouakchott and Kiffa, only a few kilometers (miles) from the location where Meoni had his fatal wreck the year before. He won the third stage of the 2006 event between Nador and Er Rachidia only a few days before his death. The death occurred despite efforts by the event organisers to improve competitor safety, including limiting speed, mandatory rest at fuel stops, and reduced fuel capacity requirements for the bike classes. On January 13, a 10-year-old boy died while crossing the course after being hit by a car driven by Latvian Māris Saukāns, while on January 14 a 12-year-old boy was killed after being hit by a support lorry.
In 2007, 29-year-old South African motor racer Elmer Symons died of injuries sustained in a crash during the fourth stage of the Rally. Symons crashed with his bike in the desert between Er Rachidia and Ouarzazate, Morocco. Another death occurred on January 20, the night before the race's finish, when 42-year-old motorcyclist Eric Aubijoux died suddenly. The cause of death was initially believed to be a heart attack, however it was later suggested that Aubijoux had died of internal injuries sustained in a crash earlier that day while competing in the 14th stage of the race.
The 2008 Dakar Rally was cancelled due to security concerns after al-Qaeda's murder of four French tourists on Christmas Eve in December 2007 in Mauritania (a country in which the rally spent eight days), various accusations against the rally calling it "neo-colonialist", and al-Qaeda's accusations against Mauritania calling it a supporter of "crusaders, apostates and infidels". The French-based Amaury Sport Organisation in charge of the 6000 km rally said in a statement that they had been advised by the French government to cancel the race, which had been due to begin on January 5, 2008 from Lisbon. They said direct threats had also been made against the event by al-Qaeda related organisations.
Omar Osama bin Laden, the son of Osama bin Laden, attracted news coverage in 2008 by promoting himself as an "ambassador of peace" and proposing a 3000 mi horse race across North Africa as a replacement to the Dakar Rally, with sponsors' money going to support child victims of war, saying "I heard the rally was stopped because of al-Qaida. I don't think they are going to stop me."
On 7 January 2009, the body of 49-year-old motorcyclist Pascal Terry from France was found. He had been missing for three days and his body lay on a remote part of the second stage between Santa Rosa de la Pampa and Puerto Madryn.
On 4 January 2010, a woman watching the Dakar Rally was killed when a vehicle taking part in the race veered off the course and hit her during the opening stage.
On 1 January 2012, motorcyclist Jorge Martinez Boero of Argentina died after suffering a cardiac arrest after a fall. He was treated by medical staff within five minutes of the accident, but died on the way to hospital.
On 7 January 2015, motorcycle rider Michal Hernik died from unknown circumstances during Stage 3 of the 2015 rally.
Overall about 61 people, including 28 competitors, have died in the Dakar Rally.
Criticism.
When the race was held in Africa, it was subject to criticism from several sources, generally focusing on the race's impact on the inhabitants of the African countries through which it passed.
Some African residents along the race's course in previous years have said they saw limited benefits from the race; that race participants spent little money on the goods and services local residents can offer. The racers produced substantial amounts of dust along the course, and were blamed for hitting and killing livestock, in addition to occasionally injuring or killing people.
After the 1988 race, when three Africans were killed in collisions with vehicles involved in the race, PANA, a Dakar-based news agency, wrote that the deaths were "insignificant for the [race's] organisers". The Vatican City newspaper "L'Osservatore Romano" called the race a "vulgar display of power and wealth in places where men continue to die from hunger and thirst." During a 2002 protest at the race's start in Arras, France, a Green Party of France statement described the race as "colonialism that needs to be eradicated".
The environmental impact of the race has been another area of criticism. This criticism of the race is notably the topic of the song "500 connards sur la ligne de départ" ("500 Assholes at the Starting Line"), on the album "Marchand de cailloux" by French singer Renaud. According to recent figures provided by the Dakar Rally, the carbon emissions of the two-week race are approximately equivalent to a single Formula One race.

</doc>
<doc id="25140" url="http://en.wikipedia.org/wiki?curid=25140" title="Perception">
Perception

Perception (from the Latin "perceptio, percipio") is the organization, identification, and interpretation of sensory information in order to represent and understand the environment. All perception involves signals in the nervous system, which in turn result from physical or chemical stimulation of the sense organs. For example, vision involves light striking the retina of the eye, smell is mediated by odor molecules, and hearing involves pressure waves. Perception is not the passive receipt of these signals, but is shaped by learning, memory, expectation, and attention.
Perception can be split into two processes Firstly processing sensory input which transforms these low-level information to higher-level information (e.g., extracts shapes for object recognition). Secondly processing which is connected with person's concept and expectations (knowledge), and selective mechanisms (attention) that influence perception.
Perception depends on complex functions of the nervous system, but subjectively seems mostly effortless because this processing happens outside conscious awareness.
Since the rise of experimental psychology in the 19th Century, psychology's understanding of perception has progressed by combining a variety of techniques. Psychophysics quantitatively describes the relationships between the physical qualities of the sensory input and perception. Sensory neuroscience studies the brain mechanisms underlying perception. Perceptual systems can also be studied computationally, in terms of the information they process. Perceptual issues in philosophy include the extent to which sensory qualities such as sound, smell or color exist in objective reality rather than in the mind of the perceiver.
Although the senses were traditionally viewed as passive receptors, the study of illusions and ambiguous images has demonstrated that the brain's perceptual systems actively and pre-consciously attempt to make sense of their input. There is still active debate about the extent to which perception is an active process of hypothesis testing, analogous to science, or whether realistic sensory information is rich enough to make this process unnecessary.
The perceptual systems of the brain enable individuals to see the world around them as stable, even though the sensory information is typically incomplete and rapidly varying. Human and animal brains are structured in a modular way, with different areas processing different kinds of sensory information. Some of these modules take the form of sensory maps, mapping some aspect of the world across part of the brain's surface. These different modules are interconnected and influence each other. For instance, taste is strongly influenced by smell.
Process and terminology.
The process of perception begins with an object in the real world, termed the "distal stimulus" or "distal object". By means of light, sound or another physical process, the object stimulates the body's sensory organs. These sensory organs transform the input energy into neural activity—a process called "transduction". This raw pattern of neural activity is called the "proximal stimulus". These neural signals are transmitted to the brain and processed. The resulting mental re-creation of the distal stimulus is the "percept". Perception is sometimes described as the process of constructing mental representations of distal stimuli using the information available in proximal stimuli.
An example would be a person looking at a shoe. The shoe itself is the distal stimulus. When light from the shoe enters a person's eye and stimulates their retina, that stimulation is the proximal stimulus. The image of the shoe reconstructed by the brain of the person is the percept. Another example would be a telephone ringing. The ringing of the telephone is the distal stimulus. The sound stimulating a person's auditory receptors is the proximal stimulus, and the brain's interpretation of this as the ringing of a telephone is the percept. The different kinds of sensation such as warmth, sound, and taste are called "sensory modalities".
Psychologist Jerome Bruner has developed a model of perception. According to him people go through the following process to form opinions:
According to Alan Saks and Gary Johns, there are three components to perception.
Stimuli are not necessarily translated into a percept and rarely does a single stimulus translate into a percept. An ambiguous stimulus may be translated into multiple percepts, experienced randomly, one at a time, in what is called "multistable perception". And the same stimuli, or absence of them, may result in different percepts depending on subject’s culture and previous experiences. Ambiguous figures demonstrate that a single stimulus can result in more than one percept; for example the Rubin vase which can be interpreted either as a vase or as two faces. The percept can bind sensations from multiple senses into a whole. A picture of a talking person on a television screen, for example, is bound to the sound of speech from speakers to form a percept of a talking person. "Percept" is also a term used by Leibniz, Bergson, Deleuze and Guattari to define perception independent from perceivers.
Reality.
In the case of visual perception, some people can actually see the percept shift in their mind's eye. Others, who are not picture thinkers, may not necessarily perceive the 'shape-shifting' as their world changes. The 'esemplastic' nature has been shown by experiment: an ambiguous image has multiple interpretations on the perceptual level.
This confusing ambiguity of perception is exploited in human technologies such as camouflage, and also in biological mimicry, for example by European Peacock butterflies, whose wings bear eye markings that birds respond to as though they were the eyes of a dangerous predator.
There is also evidence that the brain in some ways operates on a slight "delay", to allow nerve impulses from distant parts of the body to be integrated into simultaneous signals.
Perception is one of the oldest fields in psychology. The oldest quantitative laws in psychology are Weber's law – which states that the smallest noticeable difference in stimulus intensity is proportional to the intensity of the reference – and Fechner's law which quantifies the relationship between the intensity of the physical stimulus and its perceptual counterpart (for example, testing how much darker a computer screen can get before the viewer actually notices). The study of perception gave rise to the Gestalt school of psychology, with its emphasis on holistic approach.
Features.
Constancy.
"Perceptual constancy" is the ability of perceptual systems to recognise the same object from widely varying sensory inputs. For example, individual people can be recognised from views, such as frontal and profile, which form very different shapes on the retina. A coin looked at face-on makes a circular image on the retina, but when held at angle it makes an elliptical image. In normal perception these are recognised as a single three-dimensional object. Without this correction process, an animal approaching from the distance would appear to gain in size. One kind of perceptual constancy is "color constancy": for example, a white piece of paper can be recognised as such under different colors and intensities of light. Another example is "roughness constancy": when a hand is drawn quickly across a surface, the touch nerves are stimulated more intensely. The brain compensates for this, so the speed of contact does not affect the perceived roughness. Other constancies include melody, odor, brightness and words. These constancies are not always total, but the variation in the percept is much less than the variation in the physical stimulus. The perceptual systems of the brain achieve perceptual constancy in a variety of ways, each specialized for the kind of information being processed.
Grouping.
The "principles of grouping" (or "Gestalt laws of grouping") are a set of principles in psychology, first proposed by Gestalt psychologists to explain how humans naturally perceive objects as organized patterns and objects. Gestalt psychologists argued that these principles exist because the mind has an innate disposition to perceive patterns in the stimulus based on certain rules. These principles are organized into six categories. The principle of "proximity" states that, all else being equal, perception tends to group stimuli that are close together as part of the same object, and stimuli that are far apart as two separate objects. The principle of "similarity" states that, all else being equal, perception lends itself to seeing stimuli that physically resemble each other as part of the same object, and stimuli that are different as part of a different object. This allows for people to distinguish between adjacent and overlapping objects based on their visual texture and resemblance. The principle of "closure" refers to the mind’s tendency to see complete figures or forms even if a picture is incomplete, partially hidden by other objects, or if part of the information needed to make a complete picture in our minds is missing. For example, if part of a shape’s border is missing people still tend to see the shape as completely enclosed by the border and ignore the gaps. The principle of "good continuation" makes sense of stimuli that overlap: when there is an intersection between two or more objects, people tend to perceive each as a single uninterrupted object. The principle of "common fate" groups stimuli together on the basis of their movement. When visual elements are seen moving in the same direction at the same rate, perception associates the movement as part of the same stimulus. This allows people to make out moving objects even when other details, such as color or outline, are obscured. The principle of "good form" refers to the tendency to group together forms of similar shape, pattern, color, etc. Later research has identified additional grouping principles.
Contrast effects.
A common finding across many different kinds of perception is that the perceived qualities of an object can be affected by the qualities of context. If one object is extreme on some dimension, then neighboring objects are perceived as further away from that extreme. "Simultaneous contrast effect" is the term used when stimuli are presented at the same time, whereas "successive contrast" applies when stimuli are presented one after another.
The contrast effect was noted by the 17th Century philosopher John Locke, who observed that lukewarm water can feel hot or cold, depending on whether the hand touching it was previously in hot or cold water. In the early 20th Century, Wilhelm Wundt identified contrast as a fundamental principle of perception, and since then the effect has been confirmed in many different areas. These effects shape not only visual qualities like color and brightness, but other kinds of perception, including how heavy an object feels. One experiment found that thinking of the name "Hitler" led to subjects rating a person as more hostile. Whether a piece of music is perceived as good or bad can depend on whether the music heard before it was pleasant or unpleasant. For the effect to work, the objects being compared need to be similar to each other: a television reporter can seem smaller when interviewing a tall basketball player, but not when standing next to a tall building. In the brain, contrast exerts effects on both neuronal firing rates and neuronal synchrony.
Effect of experience.
With experience, organisms can learn to make finer perceptual distinctions, and learn new kinds of categorization. Wine-tasting, the reading of X-ray images and music appreciation are applications of this process in the human sphere. Research has focused on the relation of this to other kinds of learning, and whether it takes place in peripheral sensory systems or in the brain's processing of sense information. 
Effect of motivation and expectation.
A "perceptual set", also called "perceptual expectancy" or just "set" is a predisposition to perceive things in a certain way. It is an example of how perception can be shaped by "top-down" processes such as drives and expectations. Perceptual sets occur in all the different senses. They can be long term, such as a special sensitivity to hearing one's own name in a crowded room, or short term, as in the ease with which hungry people notice the smell of food. A simple demonstration of the effect involved very brief presentations of non-words such as "sael". Subjects who were told to expect words about animals read it as "seal", but others who were expecting boat-related words read it as "sail".
Sets can be created by motivation and so can result in people interpreting ambiguous figures so that they see what they want to see. For instance, how someone perceives what unfolds during a sports game can be biased if they strongly support one of the teams. In one experiment, students were allocated to pleasant or unpleasant tasks by a computer. They were told that either a number or a letter would flash on the screen to say whether they were going to taste an orange juice drink or an unpleasant-tasting health drink. In fact, an ambiguous figure was flashed on screen, which could either be read as the letter B or the number 13. When the letters were associated with the pleasant task, subjects were more likely to perceive a letter B, and when letters were associated with the unpleasant task they tended to perceive a number 13.
Perceptual set has been demonstrated in many social contexts. People who are primed to think of someone as "warm" are more likely to perceive a variety of positive characteristics in them, than if the word "warm" is replaced by "cold". When someone has a reputation for being funny, an audience is more likely to find them amusing. Individual's perceptual sets reflect their own personality traits. For example, people with an aggressive personality are quicker to correctly identify aggressive words or situations.
One classic psychological experiment showed slower reaction times and less accurate answers when a deck of playing cards reversed the color of the suit symbol for some cards (e.g. red spades and black hearts).
Philosopher Andy Clark explains that perception, although it occurs quickly, is not simply a bottom-up process (where minute details are put together to form larger wholes). Instead, our brains use what he calls 'predictive coding'. It starts with very broad constraints and expectations for the state of the world, and as expectations are met, it makes more detailed predictions (errors lead to new predictions, or learning processes). Clark says this research has various implications; not only can there be no completely "unbiased, unfiltered" perception, but this means that there is a great deal of feedback between perception and expectation (perceptual experiences often shape our beliefs, but those perceptions were based on existing beliefs).
Theories.
Perception as direct perception.
Cognitive theories of perception assume there is a poverty of stimulus. This (with reference to perception) is the claim that are, by themselves, unable to provide a unique description of the world. Sensations require 'enriching', which is the role of the mental model. A different type of theory is the perceptual ecology approach of James J. Gibson. Gibson rejected the assumption of a poverty of stimulus by rejecting the notion that perception is based upon sensations – instead, he investigated what information is actually presented to the perceptual systems. His theory "assumes the existence of stable, unbounded, and permanent stimulus-information in the ambient optic array. And it supposes that the visual system can explore and detect this information. The theory is information-based, not sensation-based." He and the psychologists who work within this paradigm detailed how the world could be specified to a mobile, exploring organism via the lawful projection of information about the world into energy arrays. Specification is a 1:1 mapping of some aspect of the world into a perceptual array; given such a mapping, no enrichment is required and perception is direct perception.
Perception-in-action.
An ecological understanding of perception derived from Gibson's early work is that of "perception-in-action", the notion that perception is a requisite property of animate action; that without perception, action would be unguided, and without action, perception would serve no purpose. Animate actions require both perception and motion, and perception and movement can be described as "two sides of the same coin, the coin is action". Gibson works from the assumption that singular entities, which he calls "invariants", already exist in the real world and that all that the perception process does is to home in upon them. A view known as constructivism (held by such philosophers as Ernst von Glasersfeld) regards the continual adjustment of perception and action to the external input as precisely what constitutes the "entity", which is therefore far from being invariant.
Glasersfeld considers an "invariant" as a target to be homed in upon, and a pragmatic necessity to allow an initial measure of understanding to be established prior to the updating that a statement aims to achieve. The invariant does not and need not represent an actuality, and Glasersfeld describes it as extremely unlikely that what is desired or feared by an organism will never suffer change as time goes on. This social constructionist theory thus allows for a needful evolutionary adjustment.
A mathematical theory of perception-in-action has been devised and investigated in many forms of controlled movement, and has been described in many different species of organism using the General Tau Theory. According to this theory, tau information, or time-to-goal information is the fundamental 'percept' in perception.
Evolutionary psychology (EP) and perception.
Many philosophers, such as Jerry Fodor, write that the purpose of perception is knowledge, but evolutionary psychologists hold that its primary purpose is to guide action. For example, they say, depth perception seems to have evolved not to help us know the distances to other objects but rather to help us move around in space. Evolutionary psychologists say that animals from fiddler crabs to humans use eyesight for collision avoidance, suggesting that vision is basically for directing action, not providing knowledge.
Building and maintaining sense organs is metabolically expensive, so these organs evolve only when they improve an organism's fitness. More than half the brain is devoted to processing sensory information, and the brain itself consumes roughly one-fourth of one's metabolic resources, so the senses must provide exceptional benefits to fitness. Perception accurately mirrors the world; animals get useful, accurate information through their senses.
Scientists who study perception and sensation have long understood the human senses as adaptations. Depth perception consists of processing over half a dozen visual cues, each of which is based on a regularity of the physical world. Vision evolved to respond to the narrow range of electromagnetic energy that is plentiful and that does not pass through objects. Sound waves provide useful information about the sources of and distances to objects, with larger animals making and hearing lower-frequency sounds and smaller animals making and hearing higher-frequency sounds. Taste and smell respond to chemicals in the environment that were significant for fitness in the environment of evolutionary adaptedness. The sense of touch is actually many senses, including pressure, heat, cold, tickle, and pain. Pain, while unpleasant, is adaptive. An important adaptation for senses is range shifting, by which the organism becomes temporarily more or less sensitive to sensation. For example, one's eyes automatically adjust to dim or bright ambient light. Sensory abilities of different organisms often coevolve, as is the case with the hearing of echolocating bats and that of the moths that have evolved to respond to the sounds that the bats make.
Evolutionary psychologists claim that perception demonstrates the principle of modularity, with specialized mechanisms handling particular perception tasks. For example, people with damage to a particular part of the brain suffer from the specific defect of not being able to recognize faces (prospagnosia). EP suggests that this indicates a so-called face-reading module.
Physiology.
A "sensory system" is a part of the nervous system responsible for processing sensory information. A sensory system consists of sensory receptors, neural pathways, and parts of the brain involved in sensory perception. Commonly recognized sensory systems are those for vision, hearing, somatic sensation (touch), taste and olfaction (smell). It has been suggested that the immune system is an overlooked sensory modality. In short, senses are transducers from the physical world to the realm of the mind.
The receptive field is the specific part of the world to which a receptor organ and receptor cells respond. For instance, the part of the world an eye can see, is its receptive field; the light that each rod or cone can see, is its receptive field. Receptive fields have been identified for the visual system, auditory system and somatosensory system, so far.
Types.
Of sound.
Hearing (or "audition") is the ability to perceive sound by detecting vibrations. Frequencies capable of being heard by humans are called audio or "sonic". The range is typically considered to be between 20 Hz and 20,000 Hz. Frequencies higher than audio are referred to as ultrasonic, while frequencies below audio are referred to as infrasonic. The auditory system includes the outer ears which collect and filter sound waves, the middle ear for transforming the sound pressure (impedance matching), and the inner ear which produces neural signals in response to the sound. By the ascending auditory pathway these are led to the primary auditory cortex within the temporal lobe of the human brain, which is where the auditory information arrives in the cerebral cortex and is further processed there.
Sound does not usually come from a single source: in real situations, sounds from multiple sources and directions are superimposed as they arrive at the ears. Hearing involves the computationally complex task of separating out the sources of interest, often estimating their distance and direction as well as identifying them.
Of speech.
"Speech perception" is the process by which the sounds of language are heard, interpreted and understood. Research in speech perception seeks to understand how human listeners recognize speech sounds and use this information to understand spoken language. The sound of a word can vary widely according to words around it and the tempo of the speech, as well as the physical characteristics, accent and mood of the speaker. Listeners manage to perceive words across this wide range of different conditions. Another variation is that reverberation can make a large difference in sound between a word spoken from the far side of a room and the same word spoken up close. Experiments have shown that people automatically compensate for this effect when hearing speech.
The process of perceiving speech begins at the level of the sound within the auditory signal and the process of audition. After processing the initial auditory signal, speech sounds are further processed to extract acoustic cues and phonetic information. This speech information can then be used for higher-level language processes, such as word recognition. Speech perception is not necessarily uni-directional. That is, higher-level language processes connected with morphology, syntax, or semantics may interact with basic speech perception processes to aid in recognition of speech sounds. It may be the case that it is not necessary and maybe even not possible for a listener to recognize phonemes before recognizing higher units, like words for example. In one experiment, Richard M. Warren replaced one phoneme of a word with a cough-like sound. His subjects restored the missing speech sound perceptually without any difficulty and what is more, they were not able to identify accurately which phoneme had been disturbed.
Touch.
"Haptic perception" is the process of recognizing objects through touch. It involves a combination of somatosensory perception of patterns on the skin surface (e.g., edges, curvature, and texture) and proprioception of hand position and conformation. People can rapidly and accurately identify three-dimensional objects by touch. This involves exploratory procedures, such as moving the fingers over the outer surface of the object or holding the entire object in the hand. Haptic perception relies on the forces experienced during touch.
Gibson defined the haptic system as "The sensibility of the individual to the world adjacent to his body by use of his body". Gibson and others emphasized the close link between haptic perception and body movement: haptic perception is active exploration. The concept of haptic perception is related to the concept of extended physiological proprioception according to which, when using a tool such as a stick, perceptual experience is transparently transferred to the end of the tool.
Taste.
Taste (or, the more formal term, "gustation") is the ability to perceive the flavor of substances including, but not limited to, food. Humans receive tastes through sensory organs called "taste buds", or "gustatory calyculi", concentrated on the upper surface of the tongue. The human tongue has 100 to 150 taste receptor cells on each of its roughly ten thousand taste buds. There are five primary tastes: sweetness, bitterness, sourness, saltiness, and umami. Other tastes can be mimicked by combining these basic tastes. The recognition and awareness of umami is a relatively recent development in Western cuisine. The basic tastes contribute only partially to the sensation and flavor of food in the mouth — other factors include smell, detected by the olfactory epithelium of the nose; texture, detected through a variety of mechanoreceptors, muscle nerves, etc.; and temperature, detected by thermoreceptors. All basic tastes are classified as either "appetitive" or "aversive", depending upon whether the things they sense are harmful or beneficial.
Other senses.
Other senses enable perception of body balance, acceleration, gravity, position of body parts, temperature, pain, time, and perception of internal senses such as suffocation, gag reflex, intestinal distension, fullness of rectum and urinary bladder, and sensations felt in the throat and lungs.
Of the social world.
"Social perception" is the part of perception that allows people to understand the individuals and groups of their social world, and thus an element of social cognition.
References.
</dl>

</doc>
<doc id="25141" url="http://en.wikipedia.org/wiki?curid=25141" title="Pitch of brass instruments">
Pitch of brass instruments

The pitch of a brass instrument is determined by its vibratory length, which determines the fundamental frequency of the open instrument and the frequencies of its overtones. Additional pitches are achieved by varying the length using the instrument's valve, slide, key or crook system. The fundamental frequency is not playable on some brass instruments. The table provides the pitch of the second overtone (an octave above the fundamental frequency) and length for some common brass instruments in descending order of pitch. This pitch is notated transpositionally as middle C for many of these brass instruments.
Range.
The normal playing range of most three-valved brass instruments extends from three whole tones below the 2nd harmonic of the condensed instrument to the 10th harmonic. Skilled players can produce tones outside this range. For many transposing brass instruments, this range is written as extending from F♯ below middle C to E two octaves and a third above middle C.
The orchestral horn is an exception as it was classically assigned a range beginning at its fourth harmonic.
Whole tube vs half tube.
The ease with which a player produces the fundamental note of each harmonic series for each tubing length of a modern brass instrument varies with the instrument's design. As bore width increases relative to length, it becomes easier for the player to resist the instrument's tendency to jump to the first harmonic (second partial) instead of producing the fundamental frequency. Brass instruments with sufficient bore to allow the "whole tube" to vibrate easily, as opposed to "half the tube" (i.e., the second partial), are called "whole-tube" instruments.
Certain low brass instruments such as trombone, tuba, euphonium, and alto horn are whole-tube and can play the fundamental tone (first partial) of each harmonic series with relative ease. Furthermore, the low brass often use valves to extend their range uniformly, since the fundamental is chromatically discontinuous with the lowest 2nd partial reachable on a three-valve instrument or via the seven-position slide on a trombone. Trombone and tuba in particular are often called upon to play pedal notes (1st partial notes) and so-called "false harmonics" and "false tones" below their normal range.
Horn.
The modern standard orchestral horn is a double B♭/F horn. The player can switch between the two modes using a thumb-operated fourth valve. The fundamental pitch of the F horn is near that of the tuba. Horn notation is a complex subject beyond the scope of this article, but what is written as middle C for the horn is the fourth harmonic of the unlengthened instrument, not the second. Horn music makes greater use of the higher range of the harmonic series than do most other modern brass instruments.
Modern bass trombone.
The modern bass trombone is the same length as a tenor trombone, but typically has two valves, one pitched in F and one in G♭. When combined, these valves put the instrument into D. Modern contrabass trombones are constructed in F and BB♭. The F contrabass trombone is often fitted with a valve that puts it into D, and a valve that puts it into E♭, and when combined, these put the instrument into the key of B♭. The B♭ contrabass is often fitted with a valve in F and has been fitted with both a valve in F and G♭, so that it matches its bass trombone counterpart, but is pitched an octave lower.
See Types of trombones
Tuba.
The bass tuba is commonly available in F and E♭, while contrabass tubas are available in C and B♭.

</doc>
<doc id="25142" url="http://en.wikipedia.org/wiki?curid=25142" title="Pig">
Pig

A pig is any of the animals in the genus Sus, within the Suidae family of even-toed ungulates. Pigs include the domestic pig and its ancestor, the common Eurasian wild boar ("Sus scrofa"), along with other species; related creatures outside the genus include the peccary, the babirusa, and the warthog. Pigs, like all suids, are native to the Eurasian and African continents. Juvenile pigs are known as piglets. Pigs are omnivores and are highly social and intelligent animals.
Description and behaviour.
A typical pig has a large head with a long snout which is strengthened by a special prenasal bone and by a disk of cartilage at the tip. The snout is used to dig into the soil to find food and is a very acute sense organ. There are four hoofed toes on each trotter (foot), with the two larger central toes bearing most of the weight, but the outer two also being used in soft ground.
The dental formula of adult pigs is 3.1.4.33.1.4.3, giving a total of 44 teeth. The rear teeth are adapted for crushing. In the male the canine teeth form tusks, which grow continuously and are sharpened by constantly being ground against each other.
Occasionally, captive mother pigs may savage their own piglets, often if they become severely stressed. Some attacks on newborn piglets are non-fatal. Others may cause the death of the piglets and sometimes, the mother may eat the piglets. It is estimated that 50% of piglet fatalities are due to the mother attacking, or unintentionally crushing, the newborn pre-weaned animals.
Distribution and evolution.
With around 1 billion individuals alive at any time, the domesticated pig is one of the most numerous large mammals on the planet.
The ancestor of the domesticated pig is the wild boar, which is one of the most numerous and widespread large mammals. Its many subspecies are native to all but the harshest climates of continental Eurasia and its islands and Africa as well, from Ireland and India to Japan and north to Siberia. Although it has been exterminated in some areas, its numbers are stable, or even increasing rapidly, in most of its native range.
Long isolated from other pigs on the many islands of Indonesia, Malaysia, and the Philippines, pigs have evolved into many different species, including wild boar, bearded pigs, and warty pigs. Humans have introduced pigs into Australia, North and South America, and numerous islands, either accidentally as escaped domestic pigs which have gone feral, or as wild boar. These have typically adapted well, and are increasing in number and broadening their range outside human control.
Habitat and reproduction.
The wild pig ("Sus scrofa") can take advantage of any forage resources. Therefore, it can live in virtually any productive habitat that can provide enough water to sustain large mammals such as pigs. If there is increased foraging of wild pigs in certain areas, it can cause a nutritional shortage which can cause the pig population to decrease. If the nutritional state returns to normal, the pig population will most likely rise due to the pigs' naturally increased reproduction rate.
Diet and foraging.
Pigs are omnivores, which means that they consume both plants and animals. In the wild, they are foraging animals, primarily eating leaves, grasses, roots, fruits, and flowers. In confinement, pigs are fed mostly corn and soybean meal with a mixture of vitamins and minerals added to the diet. Traditionally they were raised on dairy farms and called "mortgage lifters" due to their ability to use the excess milk as well as whey from cheese and butter making combined with pasture. Older pigs will consume three to five gallons of water per day.
Relationship with humans.
Domesticated pigs, called swine, are raised commercially for meat (generally called pork, hams, gammon or bacon), as well as for leather. Their bristly hairs are also used for brushes. Due to their common use as livestock, adult swine have gender specific names: the males are "boars" and the females are "sows". In Britain, the word "hog" can refer to a castrated adult male pig. Young swine are called "piglets" or "pigs". Pork is one of the most popular forms of meat for human consumption, accounting for 38% of worldwide meat production.
Pigs that are allowed to forage may be watched by swineherds. Because of their foraging abilities and excellent sense of smell, they are used to find truffles in many European countries.
Both wild and feral pigs are commonly hunted. Some breeds of pig, such as the Asian pot-bellied pig, are kept as pets. There are two instances in the 2000s where farm hogs ate human beings. The first was in 2004 in Romania, where a woman died after her ears, half of her face and her fingers were consumed; the other in 2012 in Oregon—whether the farmer was killed by his hogs or died of another cause before being consumed is unknown.
Species.
The genus "Sus" is currently thought to contain ten living species. A number of extinct species (†) are known from fossils.
The pygmy hog, formerly "Sus salvanius" is now placed in the monotypic genus "Porcula".
Domestic pigs.
Pigs have been domesticated since ancient times in the Old World. Archaeological evidence suggests that pigs were being managed in the wild in a way similar to the way they are managed by some modern New Guineans from wild boar as early as 13,000–12,700 BP in the Near East in the Tigris Basin. Remains of pigs have been dated to earlier than 11,400 BP in Cyprus that must have been introduced from the mainland which suggests domestication in the adjacent mainland by then. A separate domestication also occurred in China.
In India, pigs have been domesticated for a long time mostly in Goa and some rural areas for pig toilets. This was also done in China. Though ecologically logical as well as economical, pig toilets are waning in popularity as use of septic tanks and/or sewerage systems is increasing in rural areas.
Pigs were brought to southeastern North America from Europe by Hernando de Soto and other early Spanish explorers. Pigs are particularly valued in China and on certain oceanic islands, where their self-sufficiency allows them to be turned loose, although the practice is not without its drawbacks (see environmental impact).
The domestic pig ("Sus scrofa domesticus") is usually given the scientific name "Sus scrofa", although some authors call it "S. domesticus", reserving "S. scrofa" for the wild boar. It was domesticated approximately 5,000 to 7,000 years ago. Their coats are coarse and bristly. They are born brownish coloured and tend to turn more grayish coloured with age. The upper canines form sharp distinctive tusks that curve outward and upward. Compared to other artiodactyles, their head is relatively long, pointed, and free of warts. Their head and body length ranges from 0.9 to and they can weigh between 50 and.
Pigs are intelligent and can be trained to perform numerous tasks and tricks. Recently, they have enjoyed a measure of popularity as house pets, particularly the dwarf breeds.
Cultural and religious reference to pigs.
Pigs appear in the traditional art and literature of many societies, where they sometimes carry religious symbolism. In Asia the wild boar is one of twelve animal images comprising the Chinese zodiac, while in Europe the boar represents a standard charge in heraldry. Many Abrahamic religions view pigs and those who handle them negatively. Pigs are frequently alluded to in proverbs, metaphors, idioms, and folk art.
Environmental impacts.
Domestic pigs that have escaped from farms or were allowed to forage in the wild, and in some cases wild boars which were introduced as prey for hunting, have given rise to large populations of feral pigs in North and South America, Australia, New Zealand, Hawaii, and other areas where pigs are not native. Accidental or deliberate releases of pigs into countries or environments where they are an alien species have caused extensive environmental change. Their omnivorous diet, aggressive behaviour, and their feeding method of rooting in the ground all combine to severely alter ecosystems unused to pigs. Pigs will even eat small animals and destroy nests of ground nesting birds. The Invasive Species Specialist Group lists feral pigs on the list of the world's 100 worst invasive species and says:
Feral pigs like other introduced mammals are major drivers of extinction and ecosystem change. They have been introduced into many parts of the world, and will damage crops and home gardens as well as potentially spreading disease. They uproot large areas of land, eliminating native vegetation and spreading weeds. This results in habitat alteration, a change in plant succession and composition and a decrease in native fauna dependent on the original habitat.
Health issues.
Pigs can harbour a range of parasites and diseases that can be transmitted to humans. These include trichinosis, "Taenia solium", cysticercosis, and brucellosis. Pigs are also known to host large concentrations of parasitic ascarid worms in their digestive tract. According to the USDA fact sheet modern pork can be enjoyed cooked rare at 145 °F with pink in the middle. Today trichinellosis infections from eating undercooked pork are rare in more technologically developed countries due to refrigeration, health laws, and public awareness. Some religious groups have dietary laws that make pork an "unclean" meat, and adherents sometimes interpret these health issues as validation of their views.
Pigs have health issues of their own. Pigs have small lungs in relation to their body size and are thus more susceptible than other domesticated animals to fatal bronchitis and pneumonia. Some strains of influenza are endemic in pigs (see swine influenza). Pigs also can acquire human influenza.
Pigs can be aggressive in defending themselves and their young. Pig-induced injuries are thus not unusual in areas where pigs are raised or where they form part of the wild or feral fauna.
In November 2012 scientists managed to sequence the genome of the domestic pig. The similarities between the pig and human genomes mean that the new data may have wide applications in the study and treatment of human genetic diseases.

</doc>
<doc id="25144" url="http://en.wikipedia.org/wiki?curid=25144" title="Packet radio">
Packet radio

Packet radio is a form of packet switching technology used to transmit digital data via radio or wireless communications links. It uses the same concepts of data transmission via Datagram that are fundamental to communications via the Internet, as opposed to the older techniques used by dedicated or switched circuits.
Purpose and advantages.
Packet radio is a digital radio communications mode. Earlier digital modes were telegraphy (Morse Code), teleprinter (Baudot) and facsimile. Like those earlier modes, packet was intended as a way to reliably transmit written information. The primary advantage was initially expected to be increased speed, but as the protocol developed, other capabilities surfaced.
By the early 1990s, packet radio was recognized as a way not only to send text, but also to send files (including small computer programs), handle repetitive transmissions, control remote systems, etc.
The technology itself was a leap forward, making it possible for nearly any packet station to act as a "digipeater," linking distant stations with each other through ad hoc networks. This makes packet especially useful for emergency communications. In addition, mobile packet radio stations can automatically transmit their location, and check in periodically with the network to show that they are still operating.
The most common use of packet is in amateur radio, to construct wireless computer networks. Packet radio uses the AX.25 (Amateur X.25) data link layer protocol, derived from the X.25 protocol suite and adapted for amateur radio use. AX.25 was developed in the 1970s and is based on the wired network protocol X.25. AX.25 includes a digipeater field to allow other stations to automatically repeat packets to extend the range of transmitters. One advantage is that every packet sent contains the sender's and recipient's amateur radio callsign, thus providing station identification with every transmission.
Timeline.
Aloha and PRNET.
Since radio circuits inherently possess a broadcast network topology (i.e., many or all nodes are connected to the network simultaneously), one of the first technical challenges faced in the implementation of packet radio networks was a means to control access to a shared communications channel. Professor Norman Abramson of the University of Hawaii developed a packet radio network known as ALOHAnet and performed a number of experiments around 1970 to develop methods to arbitrate access to a shared radio channel by network nodes. This system operated on UHF frequencies at 9600 baud. From this work the Aloha multiple access protocol was derived. Subsequent enhancements in channel access techniques made by Leonard Kleinrock "et al." in 1975 would lead Robert Metcalfe to use carrier sense multiple access (CSMA) protocols in the design of the now commonplace Ethernet local area network (LAN) technology.
Over 1973-1976, DARPA created a packet radio network called PRNET in the San Francisco Bay area and conducted a series of experiments with SRI to verify the use of ARPANET (a precursor to the Internet) communications protocols (later known as IP) over packet radio links between mobile and fixed network nodes. This system was quite advanced, as it made use of direct sequence spread spectrum (DSSS) modulation and forward error correction (FEC) techniques to provide 100 kbit/s and 400 kbit/s data channels. These experiments were generally considered to be successful, and also marked the first demonstration of Internetworking, as in these experiments data was routed between the ARPANET, PRNET, and SATNET (a satellite packet radio network) networks. Throughout the 1970s and 1980s, DARPA operated a number of terrestrial and satellite packet radio networks connected to the ARPANET at various military and government installations.
Amateur Packet Radio and the AMPRNet.
Amateur radio operators began experimenting with packet radio in 1978, when - after obtaining authorization from the Canadian government - Robert Rouleau, VE2PY, Norm Pearl, VE2BQS, and Jacques Orsali, VE2EHP of the Montreal Amateur Radio Club Montreal, Quebec began experimenting with transmitting ASCII encoded data over VHF amateur radio frequencies using homebuilt equipment. In 1980, Doug Lockhart VE7APU, and the Vancouver Area Digital Communications Group (VADCG) in Vancouver, British Columbia began producing standardized equipment (Terminal Node Controllers) in quantity for use in amateur packet radio networks. In 2003, Rouleau was inducted into CQ Amateur Radio magazine's hall of fame for his work on the Montreal Protocol in 1978.
Not long after this activity began in Canada, amateurs in the US became interested in packet radio. In 1980, the U.S. Federal Communications Commission (FCC) granted authorization for U.S. amateurs to transmit ASCII codes via amateur radio. The first known amateur packet radio activity in the US occurred in San Francisco during December 1980, when a packet repeater was put into operation on 2 meters by Hank Magnuski KA6M, and the Pacific Packet Radio Society (PPRS). In keeping with the dominance of DARPA and ARPANET at the time, the nascent amateur packet radio network was dubbed the AMPRNet in DARPA style. Magnuski obtained IP address allocations in the 44.0.0.0 network for amateur radio use worldwide.
Many groups of amateur radio operators interested in packet radio soon formed throughout the country including the Pacific Packet Radio Society (PPRS) in California, the Tucson Amateur Packet Radio Corporation (TAPR) in Arizona and the Amateur Radio Research and Development Corporation (AMRAD) in Washington, D.C.
By 1983, TAPR was offering the first TNC available in kit form. Packet radio started becoming more and more popular across North America and by 1984 the first packet based bulletin board systems began to appear. Packet radio proved its value for emergency operations following the crash of an Aeromexico airliner in a neighborhood in Cerritos, California Labor Day weekend, 1986. Volunteers linked several key sites to pass text traffic via packet radio which kept voice frequencies clear.
For an objective description of early developments in amateur packet radio, refer to the article "Packet Radio in the Amateur Service".
The most common use of packet radio today is in amateur radio, to construct wireless computer networks. Its name is a reference to the use of packet switching between network nodes. Packet radio networks use the AX.25 data link layer protocol, derived from the X.25 protocol suite and adapted for amateur radio use.
Commercial systems.
Many commercial operations, particularly those that make use of vehicle dispatch (i.e. taxis, tow trucks, police) were quick to note the value of packet radio systems to provide simple mobile data systems. This led to the rapid development of a number of commercial packet radio systems:
Evolution.
Voice not Data.
One of the first challenges faced by amateurs implementing packet radio is that almost all amateur radio equipment (and most surplus commercial/military equipment) has historically been designed to transmit voice, not data. Like any other digital communications system that uses analog media, packet radio systems require a modem. Since the radio equipment to be used with the modem was intended for voice, early amateur packet systems used AFSK modems that followed telephone standards (notably the Bell 202 standard). While this approach worked, it was not optimal, because it used a 25 kHz FM channel to transmit at 1200 baud; when using a direct FSK modulation like G3RUH's packet radio modem, a 9600 baud transmission is easily made in the same channel.
In addition, the baseband characteristics of the audio channel provided by voice radios are often quite different from those of telephone audio channels. This led to the need in some cases to enable or disable pre-emphasis or de-emphasis circuits in the radios and/or modems.
Asynchronous framing.
Another problem faced by early "packeteers" was the issue of asynchronous versus synchronous data transfer. At the time, most personal computers had asynchronous RS-232 serial ports for data communications between the computer and devices such as modems. The RS-232 standard specifies an asynchronous, start-stop mode of data transmission where data is sent in groups (characters) of 7 or 8 bits. Unfortunately, the simple AFSK modems typically used to provide no timing signal to indicate the start of a packet frame. That led to the need for a mechanism to enable the receiver to know when to start assembling each packet frame. The method used is called asynchronous framing. The receiver looks for the "frame boundary octet," then begins decoding the packet data that follows it. Another frame boundary octet marks the end of the packet frame.
Sharing the channel.
A number of data 'conversations' are possible on a single radio channel over a finite period.
Station configuration.
A basic packet radio station consists of a computer or dumb terminal, a modem, and a transceiver with an antenna. Traditionally, the computer and modem are combined in one unit, the terminal node controller (TNC), with a dumb terminal (or terminal emulator) used to input and display data. Increasingly, however, personal computers are taking over the functions of the TNC, with the modem either a standalone unit or implemented entirely in software. Alternatively, multiple manufacturers (including Kenwood and Alinco) now market handheld or mobile radios with built-in TNCs, allowing connection directly to the serial port of a computer or terminal with no other equipment required.
The computer is responsible for managing network connections, formatting data as AX.25 packets, and controlling the radio channel. Frequently it provides other functionality as well, such as a simple bulletin board system to accept messages while the operator is away.
Layers.
Following the OSI model, packet radio networks can be described in terms of the physical, data link, and network layer protocols on which they rely.
Physical layer: modem and radio channel.
Modems used for packet radio vary in throughput and modulation technique, and are normally selected to match the capabilities of the radio equipment in use.
Most commonly used method is one using audio frequency-shift keying (AFSK) within the radio equipment's existing speech bandwidth.
The first amateur packet radio stations were constructed using surplus Bell 202 1,200 bit/s modems, and despite its low data rate, Bell 202 modulation has remained the standard for VHF operation in most areas. More recently, 9,600 bit/s has become a popular, albeit more technically demanding, alternative. At HF frequencies, Bell 103 modulation is used, at a rate of 300 bit/s.
Due to historical reasons, all commonly used modulations are based on an idea of minimal modification of the radio itself, usually just connecting the external speaker or headphone output directly to the transmit microphone input and receiver audio output directly to the computer microphone input. Upon adding a "turn the transmitter on" output signal ("PTT") for transmitter control, one has made a "radio modem".
Due to this simplicity, and just having suitable microchips at hand, the "Bell 202" modulation became standard way to send the packet radio data over the radio as two distinct tones. The tones are 1200 Hz for Mark and 2200 Hz for space (1000 Hz shift). In the case of "Bell 103" modulation, a 200 Hz shift is used. The data is differentially encoded with a NRZI pattern, where a data zero bit is encoded by a change in tones and a data one bit is encoded by no change in tones.
Ways to achieve higher speeds than 1,200 bits/s, include using telephone modem chips via the microphone and audio out connectors. This has been proven to work at speeds up to 4800 bit/s using fax V.27 modems in half-duplex mode. These modems use phase shift keying which works fine when there is no amplitude shift keying, but at faster speeds such as 9600 bit/s, signal levels become critical and they are extremely sensitive to group delay in the radio. These systems were pioneered by Simon Taylor (G1NTX) and Jerry Sandys (G8DXZ) in the 1980s. Other systems which involved small modification of the radio were developed by James Miller (G3RUH) and operated at 9600 bit/s.
1200 bit/s AFSK node controllers on 2 meters (144-148 MHz) are the most commonly found packet radio. For 1200/2400 bit/s UHF/VHF packet radio, amateurs use commonly available narrow band FM voice radios. For HF packet, 300 bit/s data is used over single side band (SSB) modulation. For high speed packet (9600 bit/s upwards), special radios or modified FM radios must be used.
Custom modems have been developed which allow throughput rates of 19.2 kbit/s, 56 kbit/s, and even 1.2 Mbit/s over amateur radio links on FCC permitted frequencies of 440 MHz and above. However, special radio equipment is needed to carry data at these speeds. The interface between the "modem" and the "radio" is at the "intermediate frequency" part of the radio as opposed to the audio section used for 1200 bit/s operation. The adoption of these high speed links has been limited.
In many commercial data radio applications, audio baseband modulation is not used. Data is transmitted by altering the transmitter output frequency between two distinct frequencies (in the case of FSK modulation, other alternates exist).
High-speed multimedia radio.
One notable detail is that the 2.4 GHz WLAN band partially overlaps an amateur radio band, Thus WLAN hardware can readily be used by licensed amateur radio operators at higher power levels than the "license free" usage allows. The restrictions inherent in Amateur Radio licenses ("signal must be free to receive by anybody", "transmit only between licensed radio amateurs", and "no encryption or other privacy techniques may be used", as well as various content restrictions) prevents this from being an appealing technique for connecting to the internet. Regulation details differ around the world.
Data link layer: AX.25.
Packet radio networks rely on the AX.25 data link layer protocol, derived from the X.25 protocol suite and intended specifically for amateur radio use. Despite its name, AX.25 defines both the physical and data link layers of the OSI model. (It also defines a network layer protocol, though this is seldom used.)
Network layer.
Packet radio has most often been used for direct, keyboard-to-keyboard connections between stations, either between two live operators or between an operator and a bulletin board system. No network services above the data link layer are required for these applications.
To provide automated routing of data between stations (important for the delivery of electronic mail), several network layer protocols have been developed for use with AX.25. Most prominent among these are NET/ROM & TheNET, ROSE, FlexNet and TexNet.
In principle, any network layer protocol may be used, including the ubiquitous Internet protocol.
Further reading.
</dl>

</doc>
<doc id="25146" url="http://en.wikipedia.org/wiki?curid=25146" title="Pizza cheese">
Pizza cheese

Pizza cheese encompasses several varieties and types of cheeses and dairy products that are designed and manufactured for use specifically on pizza, including processed and modified cheese such as mozzarella-like processed cheeses and Mozzarella variants. Pizza cheese can also refer to any type of cheese suitable for use on pizza. Estimates have placed 30% of all pizza cheese used in the United States is mozzarella cheese. The most popular cheeses used in the preparation of pizza are mozzarella, provolone, cheddar and Parmesan. Emmental, Romano and ricotta are often used as toppings, and processed pizza cheeses manufactured specifically for pizza are used often in mass production environments.
Processed pizza cheese is manufactured to produce preferable qualities in browning, melting, stretchiness and fat and moisture content. Many studies and experiments have analyzed the impact of vegetable oil, manufacturing and culture processes, denatured whey proteins and other changes to create ideal and economical pizza cheeses. In 1997 it was estimated that annual production of pizza cheese was 2 billion pounds in the United States and 200 million pounds in Europe, and in 2000 demand for pizza cheese in Europe was increasing by 8% per year.
Varieties and types.
The "International Dictionary of Food and Cooking" defines pizza cheese as "a soft spun-curd cheese similar to Mozzarella made from cow's milk..." that is "...used particularly for pizzas and contains somewhat less water than real Mozzarella..." Most pizza cheeses are at least 95 percent Mozzarella, with different moisture and fat densities. Cheese for frozen pizzas may be "comminuted", in which the cheese is processed into minute granules or fragments. Many varieties such as low-moisture Mozzarella are formulated specifically for pizza. Others are processed into blocks, from which the product can be grated, made into granules or sliced for use on pizza and in the preparation of other foods. Pizza cheese frequently consists of a blend of two or more cheeses. Low-moisture Mozzarella and Provolone is the most common blend.
Processed pizza cheeses.
Pasteurized and processed pizza cheese dairy products that are designed to melt well and remain chewy are used on many mass-produced pizzas in North America, the United Kingdom and elsewhere. These types of cheeses are referred to as "analogue pizza cheese" and "analog pizza cheese". It has been stated that analogue pizza cheese appears to be the leading type of cheese analogue produced globally. Each year in the United States, 700 million frozen pizzas are sold, three-quarters of which contain cheese substitutes.
Analogue pizza cheeses may be formulated for processing with less sophisticated cheese-making equipment than required by Mozzarella cheese, such as the processes of mixing and molding. They tend to have a soft texture and once melted, may have a slightly "stringy" quality when pulled or bitten into. They may lack in a fusion, or melting together of the shredded product when cooked. New stabilizer systems have been developed that have helped to enable the creation of analogue pizza cheeses. An example of a processed pizza cheese is Provel pasteurized processed pizza cheese, which uses Cheddar, Swiss, and Provolone cheeses as flavorants. Some analogue pizza cheese types are made with casein, a by-product of milk, and vegetable oil, rather than milk fat. Rennet casein-based Mozzarella-like imitation processed cheeses exist that are used as a Mozzarella substitute on frozen pizzas.
In some instances, the production of analogue pizza cheese can be very similar to the production of cream cheese, although the process of homogenization may be avoided, and additional differences in production are existent. In the production of some varieties, the product is heated to remain at a specific temperature and for a specific amount of time, which causes the proteins in the mix to gelatinize. During this process, salts in the mix serve to emulsify it and thus improve the meltability of the final product. The heated product is then placed in packaging such as bags-in-boxes while still hot, as it is more easily handled in this state compared to when existing as a solid. Upon being packaged, these types of pizza cheeses are then quick-cooled to avoid browning of the product vis-a-vis the Maillard reaction.
Research and development.
Manufacturers and academics have conducted studies and experiments in an effort to improve the stretchiness, melting characteristics, browning, fat content and water retention of pizza cheese. Several patents exist for specialized varieties of pizza cheese and for its processing. A study by Rudan and Barbano found that the addition of a thin layer of vegetable oil atop low- and reduced-fat pizza cheese increased meltability and reduced browning and dehydration when the product was cooked, but the texture remained overly chewy and tough. A study by Perry (et al.) found various methods to heighten the melt of low-fat pizza cheese by increasing its moisture, including the use of pre-acidification, fat-replacers, and exopolysaccharide starter cultures as well as higher pasteurization temperatures.
Manufacturers aim for a moisture content of 50-to-52 percent and a fat-in-dry-matter content of 35-to-40 percent. A study published in the "International Journal of Food & Science Technology" found that a 12.5:87.5 blend of vetch-bovine milk improved stretchiness and melting characteristics. An experiment published in the "International Journal of Dairy Technology" suggested that the level of galactose can be reduced using different culture techniques. An article in the "International Journal of Food Engineering" found that trisodium citrate slightly improved the preferred qualities of pizza cheese. Research published in "Dairy Industries International" suggested that denatured whey proteins increased moisture retention, but that the improvements were very slight and not economical. Some consumers prefer pizza cheese with less browning, which can be achieved using low-moisture part-skim Mozzarella with a low galactose content. Some pizza cheeses derived from skim mozzarella variants were designed not to require aging or the use of starter. Others can be made through the direct acidification of milk.
Production and business.
In the United States, several hundred million pounds of pizza cheese is consumed annually. In 1997, it was estimated that annual production of pizza cheese was 1 million tons (2 billion pounds) in the United States and 100,000 tons (200 million pounds) in Europe. It has been estimated that 30% of all pizza cheese used in the United States is Mozzarella cheese. As of 2000, demand for pizza cheese was growing in Europe by 8 percent per year. The world's largest manufacturer of pizza cheese, Leprino Foods Company, processes 600,000 tonnes (1.2 billion pounds) a year. Leprino Foods holds patents for some specialized Mozzarella production processes that enable the quick manufacture of pizza cheese. One such product is a frozen shredded cheese used for pizza that is created in a few hours from milk.
Use by region.
Provel cheese is commonly used in St. Louis-style pizza. Whole milk mozzarella is popular in pizzas in the East and Southwest regions of the US, while one survey showed that Provolone was more popular on the east and west coast. Cheddar is thought to be used more in the Eastern and Southern regions.

</doc>
<doc id="25147" url="http://en.wikipedia.org/wiki?curid=25147" title="Peggy Lee">
Peggy Lee

Peggy Lee (born Norma Deloris Egstrom; May 26, 1920 – January 21, 2002) was an American jazz and popular music singer, songwriter, composer and actress, in a career spanning six decades. From her beginning as a vocalist on local radio to singing with Benny Goodman's big band, she forged a sophisticated persona, evolving into a multi-faceted artist and performer. She wrote music for films, acted, and created conceptual record albums—encompassing poetry, jazz, chamber pop, and art songs.
Early life.
Lee was born Norma Deloris Egstrom in Jamestown, North Dakota, the seventh of eight children of Marvin Olof Egstrom, a station agent for the Midland Continental Railroad, and his wife Selma Amelia (Anderson) Egstrom. She and her family were Lutherans. Her father was Swedish American and her mother was Norwegian American. Her mother died when Lee was just four years old. Afterward, her father married Min Schaumber, who treated her with great cruelty while her alcoholic father did little to stop it. Later, she developed her musical talent and took several part-time jobs so that she could be away from home.
Lee first sang professionally over KOVC radio in Valley City, North Dakota. She later had her own series on a radio show sponsored by a local restaurant that paid her a salary in food. Both during and after her high school years, Lee sang for small sums on local radio stations. Radio personality Ken Kennedy, of WDAY in Fargo, North Dakota (the most widely heard station in North Dakota), changed her name from Norma to Peggy Lee. Miss Lee left home and traveled to Los Angeles at the age of 17.
She returned to North Dakota for a tonsillectomy, and was noticed by hotel owner Frank Beringin while working at the Doll House in Palm Springs, California. It was here that she developed her trademark sultry purr – having decided to compete with the noisy crowd with subtlety rather than volume. Beringin offered her a gig at The Buttery Room, a nightclub in the Ambassador Hotel East in Chicago. There, she was noticed by bandleader Benny Goodman. According to Lee, "Benny's then-fiancée, Lady Alice Duckworth, came into The Buttery, and she was very impressed. So the next evening she brought Benny in, because they were looking for a replacement for Helen Forrest. And although I didn't know, I was it. He was looking at me strangely, I thought, but it was just his preoccupied way of looking. I thought that he didn't like me at first, but it just was that he was preoccupied with what he was hearing." She joined his band in 1941 and stayed for two years.
Recording career.
In 1942 Lee had her first No. 1 hit, "Somebody Else Is Taking My Place", followed by 1943's "Why Don't You Do Right?" (originally sung by Lil Green), which sold over a million copies and made her famous. She sang with Goodman's orchestra in two 1943 films, "Stage Door Canteen" and "The Powers Girl".
In March 1943 Lee married Dave Barbour, a guitarist in Goodman's band. Peggy said, "David joined Benny's band and there was a ruling that no one should fraternize with the girl singer. But I fell in love with David the first time I heard him play, and so I married him. Benny then fired David, so I quit, too. Benny and I made up, although David didn't play with him anymore. Benny stuck to his rule. I think that's not too bad a rule, but you can't help falling in love with somebody."
When Lee and Barbour left the band, the idea was that he would work in the studios and she would keep house and raise their daughter, Nicki. But she drifted back to songwriting and occasional recording sessions for the fledgling Capitol Records in 1947, for whom she produced a long string of hits, many of them with lyrics and music by Lee and Barbour, including "I Don't Know Enough About You" (1946) and "It's a Good Day" (1947). With the release of the US No. 1-selling record of 1948, "Mañana", her "retirement" was over. In 1948, Lees work was part of Capitol's library of electrical transcriptions for radio stations. An ad for Capitol Transcriptions in a trade magazine noted that the transcriptions included "special voice introductions by Peggy."
In 1948 Lee joined Perry Como and Jo Stafford as a rotating host of the NBC Radio musical program "The Chesterfield Supper Club". She was also a regular on NBC's "Jimmy Durante Show" and appeared frequently on Bing Crosby's radio shows throughout the late 1940s and early 1950s.
She left Capitol for Decca Records in 1952, but returned to Capitol in 1957. She is most famous for her cover version of the Little Willie John hit "Fever" written by Eddie Cooley and John Davenport, to which she added her own, uncopyrighted lyrics ("Romeo loved Juliet," "Captain Smith and Pocahontas") and her rendition of Leiber and Stoller's "Is That All There Is?". Her relationship with the Capitol label spanned almost three decades, aside from her brief but artistically rich detour (1952–1956) at Decca Records, where in 1953 she recorded one of her most acclaimed albums, "Black Coffee". While recording for Decca, Lee had hit singles with the songs "Lover" and "Mister Wonderful".
In her 60-year-long career, Peggy was the recipient of three Grammy Awards (including the Lifetime Achievement Award), an Academy Award nomination, The American Society of Composers, Authors and Publishers (ASCAP) Award, the President's Award, the Ella Award for Lifetime Achievement, and the Living Legacy Award from the Women's International Center. In 1999 Lee was inducted into the Songwriters Hall of Fame.
Songwriting.
Lee was a successful songwriter, with songs from the Disney movie "Lady and the Tramp", for which she also supplied the singing and speaking voices of four characters. Her collaborators included Laurindo Almeida, Harold Arlen, Sonny Burke, Cy Coleman, Duke Ellington, Dave Grusin, Quincy Jones, Francis Lai, Jack Marshall, Johnny Mandel, Marian McPartland, Willard Robison, Lalo Schifrin and Victor Young.
She wrote the lyrics for:
Her first published song was in 1941, "Little Fool". "What More Can a Woman Do?" was recorded by Sarah Vaughan with Dizzy Gillespie and Charlie Parker. "Mañana (Is Soon Enough for Me)" was no.1 for 9 weeks on the Billboard singles chart in 1948, from the week of March 13 to May 8.
Lee was a mainstay of Capitol Records when rock and roll came onto the American music scene. She was among the first of the "old guard" to recognize this new genre, as seen by her recording music from The Beatles, Randy Newman, Carole King, James Taylor and other up-and-coming songwriters. From 1957 until her final disc for the company in 1972, she produced a steady stream of two or three albums per year which usually included standards (often arranged quite differently from the original), her own compositions, and material from young artists.
Acting career.
In 1952, Lee starred opposite Danny Thomas in "The Jazz Singer" (1952) a Technicolor remake of the early Al Jolson part-talkie film "The Jazz Singer" (1927).
Lee played an alcoholic blues singer in "Pete Kelly's Blues" (1955), for which she was nominated for the Academy Award for Best Supporting Actress.
Lee did the speaking and singing voices for several characters in Disney's "Lady and the Tramp" (1955): she played the human "Darling" (in the first part of the movie), the dog "Peg", and the two Siamese cats "Si and Am".
In 1957, Lee guest starred on the short-lived ABC variety program, "The Guy Mitchell Show".
Personal life.
Lee was married four times; each marriage ended in divorce:
Retirement and death.
Lee continued to perform into the 1990s, sometimes in a wheelchair. After years of poor health, Lee died of complications from diabetes and a heart attack at age 81. She was buried in Westwood Village Memorial Park Cemetery in Los Angeles' Westwood, Los Angeles, California neighborhood. On her marker in a garden setting is inscribed, "Music is my life's breath."
Legacy.
Academy Awards memorial omission.
She was not featured in the memorial tribute during the 2002 Academy Awards ceremony. When her family requested she be featured in the following year's ceremony, the Academy stated they did not honor requests and Lee was omitted because her contribution to film and her legacy were not deemed significant enough, although she had been nominated for Best Supporting Actress for her performance in "Pete Kelly's Blues". Her family pointed out that, although she had been omitted, R&B singer/actress Aaliyah, who had died a few months earlier, was included, despite having been in only one moderately successful film, "Romeo Must Die" ("Queen of the Damned" had yet to be released). The Academy provided no comment on the oversight.
Awards.
Lee was nominated for 12 Grammy Awards, winning Best Contemporary Vocal Performance for her 1969 hit "Is That All There Is?" In 1995 she was given the Grammy Lifetime Achievement Award.
Lee is a recipient of North Dakota's Rough Rider Award; the Pied Piper Award from The American Society of Composers, Authors and Publishers (ASCAP); the Presidents Award, from the Songwriters Guild of America; the Ella Award for Lifetime Achievement, from the Society of Singers; and the Living Legacy Award, from the Women's International Center. In 1999 she was inducted into the Songwriters Hall of Fame.
Carnegie Hall tribute.
In 2003, "There'll Be Another Spring: A Tribute to Miss Peggy Lee" was held at Carnegie Hall. Produced by recording artist Richard Barone, the sold-out event included performances by Cy Coleman, Debbie Harry, Nancy Sinatra, Rita Moreno, Marian McPartland, Chris Connor, Petula Clark, and others. In 2004 Barone brought the event to a sold-out Hollywood Bowl, and then to Chicago's Ravinia Festival, with expanded casts including Maureen McGovern, Jack Jones and Bea Arthur. The Carnegie Hall concert was broadcast on NPR's "Jazz Set".

</doc>
<doc id="25156" url="http://en.wikipedia.org/wiki?curid=25156" title="Pinuccio Sciola">
Pinuccio Sciola

Pinuccio Sciola (born 1942) is an Italian sculptor and muralist from San Sperate, Sardinia. His work has been mentioned as a major attraction of the nearby town of Assemini. His work has also been exhibited in Alghero.
Forms in which he works include "pietre sonore" or "sound stones": large sculptures (mainly limestones or basalts) that resonate when rubbed by human hands or small rocks.

</doc>
<doc id="25157" url="http://en.wikipedia.org/wiki?curid=25157" title="Paolo Fresu">
Paolo Fresu

Paolo Fresu (born February 10, 1961) is an Italian trumpeter and flugelhorn jazz player, as well as an arranger of music, and music composer.
Career.
Paolo Fresu: award winner, internationally acclaimed Sardinian trumpet player has performed around the world over the past 30 years, with a track record of 300 recordings.
Fresu is also professor and artistic director of internationally renowned jazz festivals such as Time in Jazz and Nuoro Jazz.
He is involved in the production of numerous multimedia projects, cooperating with actors, dancers, painters, sculptors, and poets, as well as writing music for film, documentary, video, ballet, and theater pieces.
Fresu is based in Paris, Bologna and Sardinia. 
His unique trumpet sound is recognized as one of the most distinctive in the contemporary jazz scene.
Bands.
Paolo Fresu has played with the following bands:

</doc>
<doc id="25159" url="http://en.wikipedia.org/wiki?curid=25159" title="Punta Sardegna">
Punta Sardegna

Punta Sardegna is a panoramic site on the coast of northern Sardinia, near Porto Rafael, Palau.
A curious air force observatory with a view on Bocche di Bonifacio and La Maddalena.

</doc>
<doc id="25160" url="http://en.wikipedia.org/wiki?curid=25160" title="Progressive multifocal leukoencephalopathy">
Progressive multifocal leukoencephalopathy

Progressive multifocal leukoencephalopathy (PML) is a rare and usually fatal viral disease characterized by progressive damage ("-pathy") or inflammation of the white matter ("leuko-") of the brain ("-encephalo-") at multiple locations ("multifocal"). It is caused by the JC virus, which is normally present and kept under control by the immune system. JC virus is harmless except in cases of weakened immune systems. In general, PML has a mortality rate of 30–50 percent in the first few months and those who survive can be left with varying degrees of neurological disabilities.
PML occurs almost exclusively in patients with severe immune deficiency, most commonly among patients with acquired immune deficiency syndrome (AIDS), but people on chronic immunosuppressive medications including chemotherapy are also at increased risk of PML, such as patients with transplants, Hodgkin's Lymphoma, multiple sclerosis, psoriasis and other autoimmune diseases.
Signs and symptoms.
Symptoms can develop over several weeks to months. Symptoms depend on location of damage in the brain and the degree of damage. The most prominent symptoms are "clumsiness, progressive weakness and visual, speech, and sometimes personality changes"
The lesions affecting the parietal and occipital lobes can lead to a phenomenon known as alien hand syndrome.
Cause.
JC Virus infection.
The cause of PML is a type of polyomavirus called the JC virus (JCV), after the initials of the patient from whose tissue the virus was first successfully cultured. Recent publications indicate 39% to 58% of the general population are seropositive for antibodies to JCV, indicating current or previous infection with the virus. JCV causes persistent asymptomatic infection in approximately one-third of the adult population, based on viral shedding into the urine from the site of asymptomatic infection in the kidney. The virus causes disease only when the immune system has been severely weakened.
Immunosuppression.
PML is most common in people with HIV1 infection; prior to the advent of effective antiretroviral therapy, as many as 5% of people with AIDS eventually developed PML. It is unclear why PML occurs more frequently in AIDS than in other immunosuppressive conditions; some research suggests the effects of HIV on brain tissue, or on JCV itself, make JCV more likely to become active in the brain and increase its damaging inflammatory effects.
PML can occur in people on chronic immunosuppressive therapy like corticosteroids, for organ transplant, in people with cancer (such as Hodgkin’s disease or lymphoma) and individuals with autoimmune diseases such as multiple sclerosis, rheumatoid arthritis, psoriasis, and systemic lupus erythematosis with or without biological therapies that depress the immune response and allow JC virus reactivation. These therapies include efalizumab, belatacept, rituximab, natalizumab, infliximab, cytotoxic chemotherapy, corticosteroids, and various transplant drugs such as tacrolimus.
Multiple sclerosis medications.
Natalizumab (Tysabri) was approved in 2004 by the FDA for multiple sclerosis (MS). It was subsequently withdrawn from the market by its manufacturer after it was linked with three cases of PML. All 3 initial cases were taking natalizumab in combination with interferon beta-1a. After a safety review the drug was returned to the market in 2006 as a monotherapy for MS under a special prescription program. As of May 2011, over 130 cases of PML had been reported in MS patients, all in patients who had taken natalizumab for more than a year. While none of them had taken the drug in combination with other disease-modifying treatments, previous use of MS treatments increases the risk of PML between 3 and 4-fold. The estimated prevalence of PML in MS is 1.5 cases per thousand natalizumab users. Around 20% of MS patients with PML die, and most of the rest are very disabled.
Pathogenesis.
PML is a demyelinating disease, in which the myelin sheath covering the axons of nerve cells is gradually destroyed, impairing the transmission of nerve impulses. It affects the subcortical white matter, particularly that of the parietal and occipital lobes. PML destroys oligodendrocytes and produces intranuclear inclusions. PML is similar to another demyelinating disease, multiple sclerosis, but progresses much more quickly. The breakdown of myelin is commensurate with the degree of immunocompromise.
Diagnosis.
PML is diagnosed in a patient with a progressive course of the disease, finding JC virus DNA in spinal fluid together with consistent white matter lesions on brain magnetic resonance imaging (MRI); alternatively, a brain biopsy is diagnostic when the typical histopathology of demyelination, bizarre astrocytes, and enlarged oligodendroglial nuclei are present, coupled with techniques showing the presence of JC virus.
Characteristic evidence of PML on brain CT scan images are multifocal, non-contrast enhancing hypodense lesions without mass effect, but MRI is far more sensitive than CT. The most common area of involvement is the cortical white matter of frontal and parieto- occipital lobes, but lesions may occur anywhere in the brain, like the basal ganglia, external capsule, and posterior cranial fossa structures like the brainstem and cerebellum.
Although typically multifocal, natalizumab-associated PML is often monofocal, predominantly in the frontal lobe.
Treatment.
There are no effective drugs that inhibit or cure the virus infection without toxicity. Therefore treatment aims at reversing the immune deficiency to slow or stop the disease progress. In patients on immunosuppression this means stopping the drugs or using plasma exchange to accelerate the removal of the biologic agent that put the person at risk for PML.
In HIV infected people this may mean starting highly active antiretroviral therapy (HAART). AIDS patients starting HAART after being diagnosed with PML tend to have a slightly longer survival time than patients who were already on HAART and then develop PML. Some AIDS patients with PML have been able to survive for several years, with HAART. A rare complication of effective HAART is immune reconstitution inflammatory syndrome (IRIS), in which increased immune system activity actually increases the damage caused by the JCV infection; Although IRIS can often be managed with medication, it is extremely dangerous in PML.
Cidofovir was studied as possible treatment for PML and has been used on a case by case basis, working in some but not not others.
Cytarabine (also known as ARA-C), a chemotherapy drug used to treat certain cancers, has been prescribed on an experimental basis for a small number of non-AIDS PML patients and stabilized the neurological condition of a minority of these patients. One patient regained some cognitive function lost as a result of PML.
In June 2010, the first case report appeared of a PML patient being successfully treated with the anti malaria drug mefloquine with activity against the JC virus. The patient cleared the virus and had no further neurological deterioration.
Two case reports of using interleukin-2 successfully have been published.
A number of drugs work against JC Virus in cell culture, but there is no proven, effective therapy in humans. 
For example, 1-O-hexadecyloxypropyl-cidofovir (CMX001), suppresses JCV but has been found to have toxicity at therapeutic dosage. The number of patients treated with other therapies is too low to demonstrate effectiveness.
Prognosis.
One third up to one half of people with PML die in the first few months following diagnosis, depending on the severity of their underlying disease. Survivors can be left with variable degrees of neurological disabilities.

</doc>
<doc id="25161" url="http://en.wikipedia.org/wiki?curid=25161" title="Idiopathic intracranial hypertension">
Idiopathic intracranial hypertension

Idiopathic intracranial hypertension (IIH), sometimes called by the older names benign intracranial hypertension (BIH) or pseudotumor cerebri (PTC), is a neurological disorder that is characterized by increased intracranial pressure (pressure around the brain) in the absence of a tumor or other diseases. The main symptoms are headache, nausea, and vomiting, as well as pulsatile tinnitus (sounds perceived in the ears, with the sound occurring in the same rhythm as the pulse), double vision and other visual symptoms. If untreated, it may lead to swelling of the optic disc in the eye, which can progress to vision loss.
IIH is diagnosed with a brain scan (to rule out other causes) and a lumbar puncture; lumbar puncture may also provide temporary and sometimes permanent relief from the symptoms. Some respond to medication (with the drug acetazolamide), but others require surgery to relieve the pressure. The condition may occur in all age groups, but is most common in women aged 20–40, especially those with obesity.
Signs and symptoms.
The most common symptom of IIH is headache, which occurs in almost all (92–94%) cases. It is characteristically worse in the morning, generalized in character and throbbing in nature. It may be associated with nausea and vomiting. The headache can be made worse by any activity that further increases the intracranial pressure, such as coughing and sneezing. The pain may also be experienced in the neck and shoulders. Many have pulsatile tinnitus, a whooshing sensation in one or both ears (64–87%); this sound is synchronous with the pulse. Various other symptoms, such as numbness of the extremities, generalized weakness, loss of smell, and loss of coordination, are reported more rarely; none are specific for IIH. In children, numerous nonspecific signs and symptoms may be present.
The increased pressure leads to compression and traction of the cranial nerves, a group of nerves that arise from the brain stem and supply the face and neck. Most commonly, the abducens nerve (sixth nerve) is involved. This nerve supplies the muscle that pulls the eye outward. Those with sixth nerve palsy therefore experience horizontal double vision which is worse when looking towards the affected side. More rarely, the oculomotor nerve and trochlear nerve (third and fourth nerve palsy, respectively) are affected; both play a role in eye movements. The facial nerve (seventh cranial nerve) is affected occasionally –- the result is total or partial weakness of the muscles of facial expression on one or both sides of the face.
The increased pressure leads to papilledema, which is swelling of the optic disc, the spot where the optic nerve enters the eyeball. This occurs in practically all cases of IIH, but not everyone experiences symptoms from this. Those who do experience symptoms typically report "transient visual obscurations", episodes of difficulty seeing that occur in both eyes but not necessarily at the same time. Long-term untreated papilledema leads to visual loss, initially in the periphery but progressively towards the center of vision.
Physical examination of the nervous system is typically normal apart from the presence of papilledema, which is seen on examination of the eye with a small device called an ophthalmoscope or in more detail with a fundus camera. If there are cranial nerve abnormalities, these may be noticed on eye examination in the form of a squint (third, fourth, or sixth nerve palsy) or as facial nerve palsy. If the papilledema has been longstanding, visual fields may be constricted and visual acuity may be decreased. Visual field testing by automated (Humphrey) perimetry is recommended as other methods of testing may be less accurate. Longstanding papilledema leads to optic atrophy, in which the disc looks pale and visual loss tends to be advanced.
Causes.
"Idiopathic" means "of unknown etiology". Therefore, IIH can only be diagnosed if there is no alternative explanation for the symptoms. Intracranial pressure may be increased due to medications such as high-dose vitamin A derivatives (e.g. isotretinoin for acne), long-term tetracycline antibiotics (for a variety of skin conditions) and hormonal contraceptives. There are numerous other diseases, mostly rare conditions, that may lead to intracranial hypertension. If there is an underlying cause, the condition is termed "secondary intracranial hypertension". Common causes of secondary intracranial hypertension include obstructive sleep apnea (a sleep-related breathing disorder), systemic lupus erythematosus (SLE), chronic kidney disease, and Behçet's disease.
Mechanism.
The cause of IIH is not known. The Monro-Kellie rule states that the intracranial pressure (literally: pressure inside the skull) is determined by the amount of brain tissue, cerebrospinal fluid (CSF) and blood inside the bony cranial vault. Three theories therefore exist as to why the pressure might be raised in IIH: an excess of CSF production, increased volume of blood or brain tissue, or obstruction of the veins that drain blood from the brain.
The first theory, that of increased production of cerebrospinal fluid, was proposed in early descriptions of the disease. However, there is no experimental data that supports a role for this process in IIH.
The second theory posits that either increased blood flow to the brain or increase in the brain tissue itself may result in the raised pressure. Little evidence has accumulated to support the suggestion that increased blood flow plays a role, but recently Bateman et al. in phase contrast MRA studies have quantified cerebral blood flow (CBF) in vivo and suggests that CBF is abnormally elevated in many patients with IIH. Both biopsy samples and various types of brain scans have shown an increased water content of the brain tissue. It remains unclear why this might be the case.
The third theory suggests that restricted venous drainage from the brain may be impaired resulting in congestion. Many patients with IIH have narrowing of the transverse sinuses. It is not clear whether these stenoses are the pathogenesis of the disease or a secondary phenomenon or both. It has been proposed that a positive biofeedback loop may exist, where raised ICP (intracranial pressure) causes venous narrowing in the transverse sinuses, resulting in venous hypertension (raised venous pressure), decreased CSF resorption via arachnoid granulation and further rise in ICP.
Diagnosis.
The diagnosis may be suspected on the basis of the history and examination. To confirm the diagnosis, as well as excluding alternative causes, several investigations are required; more investigations may be performed if the history is not typical or the patient is more likely to have an alternative problem: children, men, the elderly, or women who are not overweight.
Investigations.
Neuroimaging, usually with computed tomography (CT/CAT) or magnetic resonance imaging (MRI), is used to exclude any mass lesions. In IIH these scans typically appear to be normal, although small or slit-like ventricles, dilatation and buckling of the optic nerve sheaths and "empty sella sign" (flattening of the pituitary gland due to increased pressure) and enlargement of Meckel's caves may be seen.
An MR venogram is also performed in most cases to exclude the possibility of venous sinus stenosis/obstruction or cerebral venous sinus thrombosis. A contrast-enhanced MRV (ATECO) scan has a high detection rate for abnormal transverse sinus stenoses. These stenoses can be more adequately identified and assessed with catheter cerebral venography and manometry. Buckling of the bilateral optic nerves with increased perineural fluid is also often noted on MRI imaging.
Lumbar puncture is performed to measure the opening pressure, as well as to obtain cerebrospinal fluid (CSF) to exclude alternative diagnoses. If the opening pressure is increased, CSF may be removed for transient relief (see below). The CSF is examined for abnormal cells, infections, antibody levels, the glucose level, and protein levels. In IIH, by definition all of these are within their normal limits. Occasionally, the CSF pressure measurement may be normal despite very suggestive symptoms. This may be attributable to the fact that CSF pressure may fluctuate over the course of the normal day. If the suspicion of problems remains high, it may be necessary to perform more long-term monitoring of the ICP by a pressure catheter.
Classification.
The original criteria for IIH were described by Dandy in 1937.
They were modified by Smith in 1985 to become the "modified Dandy criteria". Smith included the use of more advanced imaging: Dandy had required ventriculography, but Smith replaced this with computed tomography. In a 2001 paper, Digre and Corbett amended Dandy's criteria further. They added the requirement that the patient is awake and alert, as coma precludes adequate neurological assessment, and require exclusion of venous sinus thrombosis as an underlying cause. Furthermore, they add the requirement that no other cause for the raised ICP is found.
In a 2002 review, Friedman and Jacobson propose an alternative set of criteria, derived from Smith's. These require the absence of symptoms that could not be explained by a diagnosis of IIH, but do not require the actual presence of any symptoms (such as headache) attributable to IIH. These criteria also require that the lumbar puncture is performed with patient lying sideways, as a lumbar puncture performed in the upright sitting position can lead to artificially high pressure measurements. Friedman and Jacobson also do not insist on MR venography for every patient; rather, this is only required in atypical cases (see "diagnosis" above).
Treatment.
The primary goal in treatment of IIH is the prevention of visual loss and blindness, as well as symptom control. IIH is treated mainly through the reduction of CSF pressure and, where applicable, weight loss. IIH may resolve after initial treatment, may go into spontaneous remission (although it can still relapse at a later stage), or may continue chronically.
Lumbar puncture.
The first step in symptom control is drainage of cerebrospinal fluid by lumbar puncture. If necessary, this may be performed at the same time as a diagnostic LP (such as done in search of a CSF infection). In some cases, this is sufficient to control the symptoms, and no further treatment is needed.
The procedure can be repeated if necessary, but this is generally taken as a clue that additional treatments may be required to control the symptoms and preserve vision. Repeated lumbar punctures are regarded as unpleasant by patients, and they present a danger of introducing spinal infections if done too often. Repeated lumbar punctures are sometimes needed to control the ICP urgently if the patient's vision deteriorates rapidly.
Medication.
The best-studied medical treatment for intracranial hypertension is acetazolamide (Diamox), which acts by inhibiting the enzyme carbonic anhydrase, and it reduces CSF production by six to 57 percent. It can cause the symptoms of hypokalemia (low blood potassium levels), which include muscle weakness and tingling in the fingers. Acetazolamide cannot be used in pregnancy, since it has been shown to cause embryonic abnormalities in animal studies. Also, in human beings it has been shown to cause metabolic acidosis as well as disruptions in the blood electrolyte levels of newborn babies. The diuretic furosemide is sometimes used for a treatment if acetazolamide is not tolerated, but this drug sometimes has little effect on the ICP.
Various analgesics (painkillers) may be used in controlling the headaches of intracranial hypertension. In addition to conventional agents such as paracetamol, a low dose of the antidepressant amitriptyline or the anticonvulsant topiramate have shown some additional benefit for pain relief.
The use of steroids in the attempt to reduce the ICP is controversial. These may be used in severe papilledema, but otherwise their use is discouraged.
Venous sinus stenting.
Venous sinus stenoses leading to venous hypertension appear to play a significant part in relation to raised ICP, and stenting of a transverse sinus may resolve venous hypertension, leading to improved CSF resorption, decreased ICP, cure of papilloedema and other symptoms of IIH.
A self-expanding metal stent is permanently deployed within the dominant transverse sinus across the stenosis under general anaesthesia. In general patients are discharged the next day. Patients require double antiplatelet therapy for a period of up to 3 months after the procedure and aspirin therapy for up to 1 year.
In a systematic analysis of 19 studies with 207 cases, there was an 87% improvement in overall symptom rate and 90% cure rate for treatment of papilloedema. Major complications only occurred in 3/207 patients (1.4%). In the largest single series of transverse sinus stenting there was a 11% rate of recurrence after one stent, requiring further stenting.
Due to the permanence of the stent and small but definite risk of complications, most experts will recommend that patients with IIH must have papilloedema and have failed medical therapy or are intolerant to medication before stenting is undertaken.
Consultation with a neurologist, neurophthalmologist and/or ophthalmologist in combination with a neurointerventionalist who performs the procedure is generally recommended.
Surgery.
Two main surgical procedures exist in the treatment of IIH: "optic nerve sheath decompression and fenestration" and shunting. Surgery would normally only be offered if medical therapy is either unsuccessful or not tolerated. The choice between these two procedures depends on the predominant problem in IIH. Neither procedure is perfect: both may cause significant complications, and both may eventually fail in controlling the symptoms. There are no randomized controlled trials to guide the decision as to which procedure is best.
Optic nerve sheath fenestration is an ophthalmological operation that involves the making of an incision in the connective tissue lining of the optic nerve in its portion behind the eye. It is not entirely clear how it protects the eye from the raised pressure, but it may be the result of either diversion of the CSF into the orbit or the creation of an area of scar tissue that lowers the pressure. The effects on the intracranial pressure itself are more modest. Moreover, the procedure may lead to significant complications, including blindness in 1–2%. The procedure is therefore recommended mainly in those who have limited headache symptoms but significant papilledema or threatened vision, or in those who have undergone unsuccessful treatment with a shunt or have a contraindication for shunt surgery.
Shunt surgery, usually performed by neurosurgeons, involves the creation of a conduit by which CSF can be drained into another body cavity. The initial procedure is usually a lumboperitoneal (LP) shunt, which connects the subarachnoid space in the lumbar spine with the peritoneal cavity. Generally, a pressure valve is included in the circuit to avoid excessive drainage when the patient is erect. LP shunting provides long-term relief in about half the cases; others require revision of the shunt, often on more than one occasion—usually due to shunt obstruction. If the lumboperitoneal shunt needs repeated revisions, a "ventriculoatrial" or "ventriculoperitoneal shunt" may be considered. These shunts are inserted in one of the lateral ventricles of the brain, usually by stereotactic surgery, and then connected either to the right atrium of the heart or the peritoneal cavity, respectively. Given the reduced need for revisions in ventricular shunts, it is possible that this procedure will become the first-line type of shunt treatment.
It has been shown that in obese people, bariatric surgery (and especially gastric bypass surgery) can lead to resolution of the condition in over 95%.
Prognosis.
It is not known what percentage of people with IIH will remit spontaneously, and what percentage will develop chronic disease.
IIH does not normally affect life expectancy. The major complications from IIH arise from untreated or treatment-resistant papilledema. In various case series, the long-term risk of ones vision being significantly affected by IIH is reported to lie anywhere between 10 and 25%.
Epidemiology.
On average, IIH occurs in about one per 100,000 people, and can occur in children and adults. The median age at diagnosis is 30. IIH occurs predominantly in women, especially in the ages 20 to 45, who are four to eight times more likely than men to be affected. Overweight and obesity strongly predispose a person to IIH: women who are more than ten percent over their ideal body weight are thirteen times more likely to develop IIH, and this figure goes up to nineteen times in women who are more than twenty percent over their ideal body weight. In men this relationship also exists, but the increase is only five-fold in those over 20 percent above their ideal body weight.
Despite several reports of IIH in families, there is no known genetic cause for IIH. People from all ethnicities may develop IIH. In children, there is no difference in incidence between males and females.
From national hospital admission databases it appears that the need for neurosurgical intervention for IIH has increased markedly over the period between 1988 and 2002. This has been attributed at least in part to the rising prevalence of obesity, although some of this increase may be explained by the increased popularity of shunting over optic nerve sheath fenestration.
History.
The first report of IIH was by the German physician Heinrich Quincke, who described it in 1893 under the name serous meningitis. The term "pseudotumor cerebri" was introduced in 1904 by his compatriot Max Nonne. Numerous other cases appeared in the literature subsequently; in many cases, the raised intracranial pressure may actually have resulted from underlying conditions. For instance, the otitic hydrocephalus reported by London neurologist Sir Charles Symonds may have resulted from venous sinus thrombosis caused by middle ear infection. Diagnostic criteria for IIH were developed in 1937 by the Baltimore neurosurgeon Walter Dandy; Dandy also introduced subtemporal decompressive surgery in the treatment of the condition.
The terms "benign" and "pseudotumor" derive from the fact that increased intracranial pressure may be associated with brain tumors. Those patients in whom no tumour was found were therefore diagnosed with "pseudotumor cerebri" (a disease mimicking a brain tumor). The disease was renamed "benign intracranial hypertension" in 1955 to distinguish it from intracranial hypertension due to life-threatening diseases (such as cancer); however, this was also felt to be misleading because any disease that can blind someone should not be thought of as benign, and the name was therefore revised in 1989 to "idiopathic (of no identifiable cause) intracranial hypertension".
Shunt surgery was introduced in 1949; initially, ventriculoperitoneal shunts were used. In 1971, good results were reported with lumboperitoneal shunting. Negative reports on shunting in the 1980s led to a brief period (1988–1993) during which optic nerve fenestration (which had initially been described in an unrelated condition in 1871) was more popular. Since then, shunting is recommended predominantly, with occasional exceptions.

</doc>
<doc id="25162" url="http://en.wikipedia.org/wiki?curid=25162" title="Plymouth Hoe">
Plymouth Hoe

Plymouth Hoe, referred to locally as the Hoe, is a large south facing open public space in the English coastal city of Plymouth. The Hoe is adjacent to and above the low limestone cliffs that form the seafront and it commands views of Plymouth Sound, Drake's Island, and across the Hamoaze to Mount Edgcumbe in Cornwall. The name derives from the Anglo-Saxon word "Hoe", a sloping ridge shaped like an inverted foot and heel.
History.
John Lucas, sergeant, had 8d. for cutting Gogmagog.
”
—An audit book of 1514.
 Until the early 17th century large outline images of the giants Gog and Magog (or Goemagot and Corineus) had for a long time been cut into the turf of the Hoe exposing the white limestone beneath. These figures were periodically re-cut and cleaned. No trace of them remains today, but this likely commemorates the Cornish foundation myth, being the point, "Lam Goemagot – the Giant's Leap -" from which the Giant was cast into the sea by the hero Corin.
Plymouth Hoe is perhaps best known for the probably apocryphal story that Sir Francis Drake played his famous game of bowls here in 1588 while waiting for the tide to change before sailing out with the English fleet to engage with the Spanish Armada. The British Library holds a from this era.
A Tudor fortress guarded the neck of water between the eastern Hoe and Mount Batten and some sheer granite and limestone cannon points remain, however in the late 1660s, following The Restoration, a massive star-shaped stone fortress known as the Royal Citadel, was constructed to replace it. Its purpose was to protect the port and probably also to intimidate the townsfolk who had leaned towards Parliament during the Civil War. It remains occupied by the military.
From 1880 there was a popular bandstand on the Hoe. It was removed for scrap metal during the Second World War and never rebuilt. A three tier belvedere built in 1891 survives; it was built on the site of a camera obscura, probably built in the 1830s, which showed views of the harbour. Below this site was the Bull Ring (now a memorial garden), and a grand pleasure pier, started in 1880, which provided a dance hall, refreshment, promenading and a landing place for boat trips. The pier was destroyed by German bombing in World War II.
There is an imposing series of Victorian terraces to the west of the naval memorial which previously continued to the Grand Hotel and, until it was destroyed by bombing, the grand clubhouse of the Royal Western Yacht Club. The club then merged with the Royal Southern and occupied that club's older premises which it had created from the regency public steam baths by the basin at West Hoe before the rejuvenated club moved in the late 1980s to Queen Anne Battery.
Landmarks.
A prominent landmark on the Hoe is Smeaton's Tower. This is the upper portion of John Smeaton's Eddystone Lighthouse, which was originally built on the Eddystone Rocks (22.5 km south) in 1759. It was dismantled in 1877 and moved, stone by stone, to the Hoe where it was re-erected.
Smeaton's Tower overlooks Tinside Pool, an unusual 1930s outdoor lido which sits upon the limestone shoreline at the base of the cliff. Most of the works to create the swimming areas and Madeira Road were carried out to make work for the local unemployed during the Depression.
A statue of Sir Francis Drake by Joseph Boehm (a copy of the original in his home town of Tavistock) was placed here in 1884 to commemorate him. There are also several war memorials along the northern side of the Hoe. The largest commemorates the Royal Naval dead of the two world wars; its central obelisk is by Robert Lorimer and was unveiled in 1924, while the surrounding sunken garden was added by Edward Maufe in 1954.
The Hoe also includes a long broad tarmacked promenade (currently a disabled motorists car park) which serves as a spectacular military parade ground and which is often used for displays by Plymouth-based Royal Navy, Royal Marines, the Army garrison, as well as for funfairs and open-air concerts.
Set into the shape of the southern sea facing fortifications of the Royal Citadel is the Citadel Hill Laboratory of the Marine Biological Association of the UK, which also houses the Sir Alister Hardy Foundation for Ocean Science. Below and to the east, perched on the rocky foreshore is the clubhouse of the Royal Plymouth Corinthian Yacht Club.
Tourism.
The Hoe is a popular area for Plymothians and visitors. There is always a great deal of activity on the water, including frequent warship movements, ferries going and coming from France and Spain, fishing trawlers and a swarm of larger and smaller sailing boats. The Fastnet yacht race ends here. The annual two-day British Firework Championships attracts tens of thousands of spectators.
For forty years, there has been controversy about development on the edges of the Hoe green space. The erection of two discount hotel chain box buildings, at the southern end of Armada Way and the other at the Sound end of Leigham Street, contrast with their Victorian surroundings. The former Grand Hotel has been converted into apartments and the long derelict yacht club site has now been filled by a modern block of flats. The Plymouth Dome, a turreted and domed building, built into a small old quarry site above Tinside as an historical theme tourist attraction, failed to obtain sufficient funding and closed in 2006, despite having been visited by 2.3 million people. In January 2013, it reopened as a restaurant owned by celebrity chef Gary Rhodes, his only venue outside London.
Tombstoning.
Plymouth Hoe has become notorious for the practice of tombstoning which involves leaping feet-first into the sea from any accessible high point. This has caused a number of serious injuries and deaths, leading to the dismantling of seafront diving boards and closure of parts of the waterfront to discourage the activity.

</doc>
<doc id="25163" url="http://en.wikipedia.org/wiki?curid=25163" title="Plymouth Sound">
Plymouth Sound

Plymouth Sound, or locally just The Sound, is a bay on the English Channel at Plymouth in England.
Its southwest and southeast corners are Penlee Point in Cornwall and Wembury Point in Devon, a distance of about 3 nautical miles (6 km). Its northern limit is Plymouth Hoe giving a north-south distance of nearly 3 nautical miles (6 km).
The Sound has three water entrances. The marine entrance is from the English Channel to the south, with a deep-water channel to the west of the Plymouth Breakwater. There are two freshwater inlets: one, from the northwest, is from the River Tamar via the Hamoaze and Devonport Dockyard, the largest naval dockyard in western Europe. The other, at northeast, is from the River Plym disgorging into its narrow estuary, Cattewater harbour between Mount Batten and the Royal Citadel.
In addition to ships of the Royal Navy, large commercial vessels, including ferries to France and Spain use the Sound from Millbay Docks. Fishing vessels use it from Sutton Harbour beside the old town of Plymouth, called the Barbican. There are marinas at Sutton Harbour, Mount Wise in the Hamoaze and at Turnchapel. Waterborne traffic in the Sound is controlled by the Queen's Harbour Master for Plymouth.
In the centre of the Sound, midway between Bovisand Bay and Cawsand Bay, is Plymouth Breakwater, which creates a harbour protecting anchored ships from the frequent south-western storms. The breakwater is around 1700 yd long, stands in around 11 metres / 36 feet of water and was built by John Rennie and Joseph Whidbey starting in 1812. The breakwater has a 23 m lighthouse on its western end and a 9 m beacon with a spherical cage on top at the eastern end. It is said that the cage is a lifesaving device designed to keep wrecked sailors from drowning in the huge waves of a storm on the low-lying breakwater.
Drake's Island is 400 metres long and around 100 metres wide and situated at the north of the Sound. It was fortified to defend Drake's Channel, the only deep-water route to Devonport. The "Bridge" is a shallow reef that links Drake's Island and the Cornish mainland. At low water the depth of the Bridge can be less than one metre but at high water it can rise to 5 metres. In World War I this natural barrier was supplemented by other obstructions to prevent submarines and small ships attacking the naval base.
Mount Batten, a former Royal Air Force flying boat and search and rescue base, is located at the northeast corner of the Sound. T. E. Lawrence was stationed here as Aircraftman Shaw.
Over the years, the Sound has been defended by Drake's Island, Picklecombe Fort, Cawsand Fort, the Breakwater Fort, Fort Bovisand, Staddon Fort and Stamford Fort.
A harbour and reservoir were built at Bovisand before the fort existed to supply men-o-war anchored in the Sound with fresh water. Joseph Whidbey supervised the building of the Breakwater from Bovisand Lodge, from which there is a view down the full length of the breakwater.
The Titanic was supposed to have docked here briefly on its return voyage to Britain, and the ship had a painting of Plymouth sound on board.
Notable events.
The Sound has been the site of a number of aircraft crashes and shipwrecks:
References.
Fort Bovisand, Kendal McDonald ISBN 0-9528637-1-5

</doc>
<doc id="25169" url="http://en.wikipedia.org/wiki?curid=25169" title="Quentin Tarantino">
Quentin Tarantino

Quentin Jerome Tarantino (; born March 27, 1963) is an American film director, screenwriter, cinematographer, producer, and actor. His films are characterized by non-linear storylines, satirical subject matter, and an aestheticization of violence, as well as features of neo-noir film and spaghetti Westerns.
Tarantino grew up an obsessed film fan and worked at Video Archives, a video rental store while training to act. His career began in the late 1980s, when he wrote and directed "My Best Friend's Birthday", the screenplay of which formed the basis for "True Romance". In the early 1990s, he began his career as an independent filmmaker with the release of "Reservoir Dogs" in 1992; regarded as a classic and cult hit, it was called the "Greatest Independent Film of All Time" by "Empire". Its popularity was boosted by the release in 1994 of his second film, "Pulp Fiction", a neo-noir crime film that became a major critical and commercial success and judged the greatest film of the past 25 years (1983-2008) by "Entertainment Weekly". Paying homage to the blaxploitation films of the 1970s, Tarantino released "Jackie Brown" in 1997, an adaptation of the novel "Rum Punch".
"Kill Bill", a highly stylized "revenge flick" in the cinematic traditions of Japanese martial arts, spaghetti westerns and Italian horror, followed six years later, and was released as two films: "Vol. 1" in 2003, and "Vol. 2" in 2004. Tarantino directed "Death Proof" (2007) as part of a double feature with friend Robert Rodriguez, under the collective title "Grindhouse". His long-postponed "Inglourious Basterds", which tells the fictional alternate history story of two plots to assassinate Nazi Germany's political leadership, was released in 2009 to positive reviews. His most recent work is 2012's critically acclaimed "Django Unchained", a western film set in the antebellum era of the Deep South. It became the highest-grossing film of his career so far, making over $425 million at the box office.
Tarantino's films have garnered both critical and commercial success. He has received many industry awards, including two Academy Awards, two Golden Globe Awards, two BAFTA Awards and the Palme d'Or, and has been nominated for an Emmy and a Grammy. He was named one of the "100 Most Influential People in the World" by "Time" in 2005, and filmmaker and historian Peter Bogdanovich has called him "the single most influential director of his generation".
Early life.
Tarantino was born in Knoxville, Tennessee in 1963. He is the son of actor and amateur musician Tony Tarantino and nurse Connie McHugh. He has a younger half-brother named Ron. Tarantino's father, from Queens, New York, is of Italian descent, while his mother has Irish and Cherokee ancestry. His stepfather was Curt Zastoupil, a musician. Tarantino was raised by his mother, as his parents separated before his birth. Tarantino has stated that his mother dated NBA star Wilt Chamberlain. When he was four years old, they moved to Torrance, California and later to the Harbor City neighborhood of Los Angeles, where he attended Fleming Junior High School. He attended Narbonne High School in Harbor City for his first year, but dropped out of school when he was 15 to attend an acting class full-time at the James Best Theater Company in Toluca Lake. In an interview with NPR in 2013, Tarantino talked about how his mother's boyfriends would take him to blaxploitation movies.
Tarantino grew bored with the James Best Acting School and left after two years, although he kept in touch with all of his acting friends. He then landed a job which threatened to interfere with his long-term acting ambitions. As an employee of Video Archives, a now-defunct video rental store in Manhattan Beach, he and fellow movie enthusiasts (including Roger Avary) discussed cinema and customer video recommendations at length. He paid close attention to the types of films people liked to rent and has cited that experience as inspiration for his directorial career. Tarantino has been quoted as saying: "When people ask me if I went to film school I tell them 'no, I went to films.'"
Film career.
1980s.
After Tarantino met Lawrence Bender at a Hollywood party, Bender encouraged him to write a screenplay. Tarantino co-wrote and directed a movie called "My Best Friend's Birthday" in 1987. The final reel of the film was almost completely destroyed in a lab fire that occurred during editing, but its screenplay later formed the basis for "True Romance".
1990s.
In January 1992, Tarantino's "Reservoir Dogs" was screened at the Sundance Film Festival. It was an immediate hit, with the film receiving a positive response from critics. The dialogue-driven heist movie set the tone for Tarantino's later films. Tarantino wrote the script for the film in three-and-a-half weeks and Bender forwarded it to director Monte Hellman. Hellman helped Tarantino to secure funding from Richard Gladstein at Live Entertainment (which later became Artisan, now known as Lionsgate). Harvey Keitel read the script and also contributed to the funding, taking a role as co-producer and also playing a part in the movie.
Tarantino's screenplay "True Romance" was optioned and the film was eventually released in 1993. The second script that Tarantino sold was for the film "Natural Born Killers", which was revised by Dave Veloz, Richard Rutowski and director Oliver Stone. Tarantino was given story credit and in an interview stated that he wished the film well. The film engendered enmity, and the publication of a 'tell all' book titled "Killer Instinct" by Jane Hamsher—who with Don Murphy had an original option on the screenplay and produced the film—led to Tarantino physically assaulting Murphy in the AGO restaurant in West Hollywood, CA in October 1997. Murphy subsequently filed a $5m lawsuit against Tarantino, which was eventually settled out of court. Following the success of "Reservoir Dogs", Tarantino was approached by Hollywood and offered numerous projects, including "Speed" and "Men in Black", but he instead retreated to Amsterdam to work on his script for "Pulp Fiction".
In "Pulp Fiction" (1994), Tarantino maintained the "aestheticization of violence", for which he is known, as well as his non-linear storylines. Tarantino received an Academy Award in the Best Writing (Original Screenplay) category, which he shared with Roger Avary. He also received a nomination in the Best Director category. The film received another five nominations, including for Best Picture. Tarantino also won the Palme d'Or for the film at the Cannes Film Festival. The film has grossed over $200 million and was met with outstanding reviews.
After "Pulp Fiction" was completed, Tarantino directed episode four of "Four Rooms", "The Man from Hollywood", a tribute to the episode "Man from the South" from the television show "Alfred Hitchcock Presents", which starred Steve McQueen in an adaptation of a Roald Dahl story. "Four Rooms" was a collaborative effort with filmmakers Allison Anders, Alexandre Rockwell and Robert Rodriguez. The film was very poorly received by critics.
Tarantino appeared in and wrote the script for Robert Rodriguez's "From Dusk till Dawn" (1996), which saw mixed reviews from the critics. It nevertheless quickly reached cult status, spawning a continuing saga of two sequels, for which Tarantino and Rodriguez only served as executive producers, and a 2014 tv series, .
Tarantino's third feature film was "Jackie Brown" (1997), an adaptation of "Rum Punch", a novel by Elmore Leonard. An homage to blaxploitation films, it starred Pam Grier, who starred in many of the films of that genre in the 1970s. Leonard considered "Jackie Brown" to be the favourite of the 26 different screen adaptations of his novels and short stories.
2000s.
Tarantino had next planned to make "Inglourious Basterds", as it was provisionally titled, but postponed this to write and direct "Kill Bill", a highly stylized "revenge flick" in the cinematic traditions of "Wuxia" (Chinese martial arts), "Jidaigeki" (Japanese period cinema), spaghetti westerns and Italian horror. It was originally set for a single theatrical release, but its 4-hour plus running time prompted Tarantino to divide it into two movies. "Vol. 1" was released in late 2003 and "Vol. 2" was released in 2004. It was based on a character called The Bride and a plot that he and "Kill Bill"‍ '​s lead actress Uma Thurman had developed during the making of "Pulp Fiction".
In 2004, Tarantino attended the Cannes film festival, where he served as President of the Jury. Although "Kill Bill" was not in competition, "Vol. 2" had an evening screening, and was also shown on the morning of the final day in its original 3-hour plus version, with Tarantino himself attending the full screening. Tarantino went on to be credited as "Special Guest Director" in Robert Rodriguez's 2005 neo-noir film "Sin City", for his work directing the car sequence featuring Clive Owen and Benicio del Toro.
In May 2005, Tarantino co-wrote and directed "Grave Danger", the finale of "". For this episode, Tarantino was nominated for a Primetime Emmy Award for Outstanding Directing for a Drama Series on the 57th Primetime Emmy Awards.
Tarantino's next film project was "Grindhouse", which he co-directed with Rodriguez. Released in theaters on April 6, 2007, Tarantino's contribution to the "Grindhouse" project was titled "Death Proof". It began as a take on 1970s slasher films, but evolved dramatically as the project unfolded. Ticket sales were low despite mostly positive reviews.
Among Tarantino's producing credits are the horror film "Hostel", which included numerous references to his own "Pulp Fiction"; the adaptation of Elmore Leonard's "Killshot", for which Tarantino was credited as an executive producer, although he was no longer associated with the film after its 2009 release; and "Hell Ride", written and directed by Larry Bishop and Jonny Lane who both appeared in "Kill Bill Vol. 2".
Tarantino's film "Inglourious Basterds", released in 2009, is the story of a group of Jewish-American guerilla soldiers in Nazi-occupied France during World War II. Filming began in October 2008. The film opened on August 21, 2009 to very positive reviews and reached the No. 1 spot at the box office worldwide. It went on to become Tarantino's highest-grossing film until it was surpassed by "Django Unchained" three years later.
2010s.
In 2011, production began on "Django Unchained", a film about the revenge of a slave in the U.S. South in 1858. The film stemmed from Tarantino's desire to produce a spaghetti western set in America's Deep South. Tarantino called the proposed style "a southern", stating that he wanted "to do movies that deal with America's horrible past with slavery and stuff but do them like spaghetti westerns, not like big issue movies. I want to do them like they're genre films, but they deal with everything that America has never dealt with because it's ashamed of it, and other countries don't really deal with because they don't feel they have the right to". The film was released on December 25, 2012. During an interview with Krishnan Guru-Murthy about the film on Channel 4 News, Tarantino reacted angrily when, in light of the Sandy Hook Elementary School shooting, he was questioned about an alleged link between movie violence and real-life violence.
In November 2013, Tarantino said he was working on a new film and that it would be another Western. He stated that it would not be a sequel to "Django". On January 12, 2014, it was revealed that the film would be titled "The Hateful Eight". The production of the western would most likely have begun in the summer of 2014, but after the script for the film leaked in January 2014, Tarantino considered dropping the movie and publishing it as a novel instead. He claimed to have given the script to a few trusted colleagues, including Bruce Dern, Tim Roth and Michael Madsen.
On April 19, 2014, Tarantino directed a live reading of the leaked script at the United Artists Theater in the Ace Hotel, Los Angeles. The event was organized by the Film Independent at LACMA, as part of the "Live Read" series. Tarantino explained that they would read the first draft of the script, and added that he was writing two new drafts with a different ending. The actors who joined Tarantino included Samuel L. Jackson, Kurt Russell, Amber Tamblyn, James Parks, Walton Goggins and the first three actors to be given the script before the leakage, Bruce Dern, Tim Roth and Michael Madsen. In October 2014, Jennifer Jason Leigh was in talks to join as female lead for the film. On November 7, 2014, it was announced that Leigh, Channing Tatum, and Demián Bichir would join the cast.
As producer.
In recent years, Tarantino has used his Hollywood power to give smaller and foreign films more attention than they might have received otherwise. These films are usually labeled "Presented by Quentin Tarantino" or "Quentin Tarantino Presents". The first of these productions was in 2001 with the Hong Kong martial arts film "Iron Monkey", which made over $14 million in the United States, seven times its budget. In 2004 he brought the Chinese martial arts film "Hero" to U.S. shores. It ended up having a No. 1 opening at the box office and making $53.5 million. In 2006, the latest "Quentin Tarantino presents" production, "Hostel", opened at No. 1 at the box office with a $20.1 million opening weekend, good for 8th all time in January. He presented 2006's "The Protector", and is a producer of the 2007 film "". In 2008 he produced the Larry Bishop-helmed "Hell Ride", a revenge biker film.
In addition, in 1995 Tarantino formed Rolling Thunder Pictures with Miramax to release or re-release several independent and foreign features. By 1997, Miramax had shut down the company due to "lack of interest" in the pictures released. The following films were released by Rolling Thunder Pictures: "Chungking Express" (1994, dir. Wong Kar-wai), "Switchblade Sisters" (1975, dir. Jack Hill), "Sonatine" (1993, dir. Takeshi Kitano), "Hard Core Logo" (1996, dir. Bruce McDonald), "The Mighty Peking Man" (1977, dir. Ho Meng-Hua), "Detroit 9000" (1973, dir. Arthur Marks), "The Beyond" (1981, dir. Lucio Fulci) and "Curdled" (1996, dir. Reb Braddock).
Other potential films.
Before "Inglourious Basterds", Quentin Tarantino had considered making "The Vega Brothers". The film would have starred Michael Madsen and John Travolta reprising their roles of Vic (Mr. Blonde) from "Reservoir Dogs" and Vincent from "Pulp Fiction". In 2007, because of the age of the actors and the onscreen deaths of both characters, he claimed that the film—which he intended to call "Double V Vega"—is "kind of unlikely now".
In 2009, in an interview for Italian TV, after being asked about the success of the two "Kill Bill" films, Tarantino said, "You haven't asked me about the third one", and implied that he would be making a third "Kill Bill" film with the words, "The Bride will fight again!" Later that year, at the Morelia International Film Festival, Tarantino announced that he would like to film "Kill Bill: Vol. 3." He explained that he wanted ten years to pass between The Bride's last conflict, in order to give her and her daughter a period of peace.
In a 2012 interview for the website "We Got This Covered", Tarantino said that a third "Kill Bill" film would "probably not" happen. He also said that he would not be directing a new James Bond film, saying that he was only interested in directing "Casino Royale" at one point. In a late 2012 interview with the online magazine "The Root", Tarantino clarified his remarks and described his next film as being the final entry in a "Django-Inglourious Basterds" trilogy called "Killer Crow". The film will depict a group of World War II-era black troops who have "been fucked over by the American military and kind of go apeshit. They basically – the way Lt. Aldo Raine (Brad Pitt) and the Basterds are having an 'Apache resistance' – [the] black troops go on an Apache warpath and kill a bunch of white soldiers and white officers on a military base and are just making a warpath to Switzerland."
A long-running rumor in the industry is that Tarantino is interested in filming a new version of Bret Easton Ellis′ 1985 novel, "Less Than Zero". His friend Roger Avary adapted "Rules of Attraction", another novel by Ellis, to film in 2002, and since both he and Tarantino like the works by Ellis, Tarantino has been eyeing the possibility of adapting "Less Than Zero". Ellis recently confirmed, in an interview for "Vice" magazine, that Tarantino had been "trying to get Fox to let him remake it". At a Q&A session at Harvard Book Store in 2012, in reply to a question asking whether "Less Than Zero" would be remade, Ellis once again confirmed that Tarantino "has shown interest" in adapting the story. At the 2014 Comic-Con, Tarantino revealed he is contemplating a possible science-fiction film.
Personal life.
Tarantino has been romantically linked with American actress Mira Sorvino, directors Allison Anders and Sofia Coppola, actress Julie Dreyfus, and comedian Margaret Cho. There have been rumors about his relationship with Uma Thurman, whom he has referred to as his "muse". However, Tarantino has stressed that their relationship is strictly platonic.
Tarantino has described himself as non-religious yet has often stated a belief in divine inspiration, which he has admitted confuses him. He believes in reincarnation.
Tarantino has also said, "I'm not saying that I'll never get married or have a kid before I'm 60. But I've made a choice, so far, to go on this road alone. Because this is my time to make movies."
His best friend is fellow filmmaker and frequent collaborator Robert Rodriguez who, in the credits of "Kill Bill Volume 2", he refers to as his brother. He is also close friends with Fiona Apple, Paul Thomas Anderson, Kevin Smith, Edgar Wright and Harvey Keitel.
Tarantino has said that he plans to retire from filmmaking when he is 60, in order to focus on writing novels and film literature. He is skeptical of the film industry going digital, saying, "If it actually gets to the place where you can't show 35 mm film in theatres anymore and everything is digital projection, I won't even make it to 60." He has then stated that he has a plan, although "not etched in stone", to retire after making his tenth movie: "If I get to the 10th, do a good job and don’t screw it up, well that sounds like a good way to end the old career.”
On February 18, 2010, it was announced that Tarantino had bought the New Beverly Cinema. Tarantino has allowed the current owners to continue operating the theater, but he will be making programming suggestions from time to time. He was quoted as saying: "As long as I'm alive, and as long as I'm rich, the New Beverly will be there, showing films shot on 35mm."
Influences and style of filmmaking.
An awards ceremony in the Critics Choice Awards celebrated Tarantino, citing his start in filmmaking when he was in his twenties. Music is an important part of Tarantino's filmmaking style, and he said that he would listen to music in his bedroom and create scenes which correlated to the music that was being played.
In the 2012 "Sight & Sound" directors' poll, Tarantino listed his top 12 films: "Apocalypse Now", "The Bad News Bears", "Carrie", "Dazed and Confused", "The Great Escape", "His Girl Friday", "Jaws", "Pretty Maids All in a Row", "Rolling Thunder", "Sorcerer", "Taxi Driver" and "The Good, the Bad and the Ugly", with the last being his favorite. In 2009, he named Kinji Fukasaku's violent action film "Battle Royale" as his favorite film released since he became a director in 1992. He is also a fan of the 1981 film "Blow Out" directed by Brian De Palma, so much so that he used the main star of the film, John Travolta, in "Pulp Fiction". Tarantino praised Mel Gibson's 2006 film "Apocalypto", saying, "I think it's a masterpiece. It was perhaps the best film of that year.". In August 2007, while teaching in a four-hour film course during the 9th Cinemanila International Film Festival in Manila, Tarantino cited Filipino directors Cirio Santiago, Eddie Romero and Gerardo de León as personal icons from the 1970s. He referred to De Leon's "soul-shattering, life-extinguishing" movies on vampires and female bondage, citing in particular "Women in Cages"; "It is just harsh, harsh, harsh", he said, and described the final shot as one of "devastating despair". Upon his arrival in the Philippines, Tarantino was quoted in the local newspaper as saying, "I'm a big fan of RP [Republic of the Philippines] cinema."
Tarantino often uses graphic violence that has proven seductive to audiences, and he has been harshly criticised for his use of gore and blood in an entrancing yet simultaneously repulsive way. His films have been staunchly criticised and scorned for their use of violence, blood and action as a "colour" within cinema, and rebuked for allegedly using human suffering as a punchline.
Actor Steve Buscemi has described Tarantino's novel style of filmmaking as "bursting with energy" and "focused", a style that has earned him many accolades worldwide. According to Tarantino, a hallmark of all his movies is that there is a different sense of humor in each one, which gets the audience to laugh at things that are not funny. However, he insists that his films are dramas, not comedies. Michael Winner, while appearing on an episode of "Piers Morgan's Life Stories", a British ITV production, stated that Quentin Tarantino was a "big fan" of his own film "Death Wish".
Tarantino has stated that the celebrated animation-action sequence in "Kill Bill" (2003) was inspired by the use of 2D animated sequences in actor Kamal Hassan's Tamil film "Aalavandhan". He often seeks to harness, manipulate and ultimately imitate the aesthetic elements and conventions typically used in the cartoon medium. More specifically, he often attempts to meld comic strip formulas and aesthetics within a live action film sequence, in some cases by the literal use of cartoon or anime images. Tarantino's cinematic ambition to marry artistic expression via live action and cartoonism is yet another example of his ability to morph genres and conventions to produce a new and authentic style of his own.
Tarantino often manipulates the use of commodities in order to propel plot development or to present an intriguing juxtaposition that ultimately enhances his notorious combination of humor and violence, equating a branded genre with branded consumption. He often pairs bizarre props with an equally bizarre scene, in which the prop itself develops into something of higher substance. Likewise, he often favors particular brand names of his own creation to make promotional appearances. The typical brands he uses within his films are "Acuña Boys Tex-Mex Food", "Big Kahuna Burger", "G.O. Juice", "Jack Rabbit Slim's", "K-Billy", "Red Apple cigarettes", "Tenku Brand Beer" and "Teriyaki Donut".
On the biopic genre, Tarantino has said that he has "no respect" for biopics, saying that they "are just big excuses for actors to win Oscars. ... Even the most interesting person – if you are telling their life from beginning to end, it’s going to be a fucking boring movie.” However, in an interview with Charlie Rose, he said:
There is one story that I could be interested in, but it would probably be one of the last movies I [ever make] ... My favorite hero in American history is John Brown. He's my favorite American who ever lived. He basically single-handedly started the road to end slavery and ... he killed people to do it. He decided, 'If we start spilling white blood, then they're going to start getting the idea.'
Tarantino has stated in many interviews that his writing process is like writing a novel before formatting it into a script, saying that this creates the blueprint of the film and makes the film feel like literature. About his writing process he told website The Talks:
[My] head is a sponge. I listen to what everyone says, I watch little idiosyncratic behavior, people tell me a joke and I remember it. People tell me an interesting story in their life and I remember it. ... when I go and write my new characters, my pen is like an antenna, it gets that information, and all of a sudden these characters come out more or less fully formed. I don’t write their dialogue, I get them talking to each other.
In 2013, a survey of 17 academics was carried out to discover which filmmakers had been referenced the most in essays and dissertations on film that had been marked in the previous five years. It revealed that Tarantino was the most-studied director in the UK, ahead of Christopher Nolan, Alfred Hitchcock, Martin Scorsese and Steven Spielberg.
Controversies.
Gun violence.
Tarantino does not believe that violence in movies inspires acts of violence in real life. In an interview after the Sandy Hook Elementary School shooting in 2012, he expressed "annoyance" at the suggestion that there is a link between the two, saying, "I think it's disrespectful to [the] memory of those who died to talk about movies. ... Obviously the issue [here] is gun control and mental health." When asked in 2013 by Britain's "Channel 4 News" reporter Krishnan Guru-Murthy, "Why are you so sure that there's no link between enjoying movie violence and enjoying real violence?", Tarantino responded by saying, "I have explained [my view on this] many times over the last 20 years, I just refuse to repeat myself over and over again."
Racial epithets.
Spike Lee questioned Tarantino's use of racial epithets in his films, particularly the word "nigger". In a "Variety" interview discussing "Jackie Brown", Lee said, "I'm not against the word...And some people speak that way. But Quentin is infatuated with that word. What does he want to be made–an honorary black man?" Tarantino responded on "Charlie Rose" by stating:
As a writer, I demand the right to write any character in the world that I want to write. I demand the right to be them, I demand the right to think them and I demand the right to tell the truth as I see they are, all right? And to say that I can't do that because I'm white, but the Hughes brothers can do that because they're black, that is racist. That is the heart of racism, all right. And I do not accept that ... That is how a segment of the black community that lives in Compton, lives in Inglewood, where "Jackie Brown" takes place, that lives in Carson, that is how they talk. I'm telling the truth. It would not be questioned if I was black, and I resent the question because I'm white. I have the right to tell the truth. I do not have the right to lie.
In addition, Tarantino retaliated on "The Howard Stern Show" by stating that Lee would have to "stand on a chair to kiss my ass". Samuel L. Jackson, who has appeared in both directors' films, defended Tarantino's use of the word. At the Berlin Film Festival, where "Jackie Brown" was being screened, Jackson responded to Lee's criticism by saying:
I don't think the word is offensive in the context of this film ... Black artists think they are the only ones allowed to use the word. Well, that's bull. "Jackie Brown" is a wonderful homage to black exploitation films. This is a good film, and Spike hasn't made one of those in a few years.
Tarantino has defended his use of the word, arguing that black audiences have an appreciation of his blaxploitation-influenced films that eludes some of his critics, and indeed, that "Jackie Brown" was primarily made for "black audiences".
According to a 1995 "Premiere" magazine article, actor Denzel Washington also confronted Tarantino on his usage of racial slurs in his pictures, but mentioned that Tarantino was a "fine artist".
"Django Unchained" was the subject of controversy because of its use of racial epithets and depiction of slavery. Many reviewers have defended the use of the language by pointing out the historic context of race and slavery in America. Spike Lee, in an interview with "Vibe" magazine said that he would not see the film, explaining, "All I'm going to say is that it's disrespectful to my ancestors. That's just me...I'm not speaking on behalf of anybody else." Lee later tweeted, "American Slavery Was Not A Sergio Leone Spaghetti Western. It Was A Holocaust. My Ancestors Are Slaves. Stolen From Africa. I Will Honor Them." Writing in "The Los Angeles Times", journalist Erin Aubry Kaplan noted the difference between Tarantino's "Jackie Brown" and "Django Unchained": "It is an institution whose horrors need no exaggerating, yet "Django" does exactly that, either to enlighten or entertain. A white director slinging around the n-word in a homage to '70s blaxploitation à la "Jackie Brown" is one thing, but the same director turning the savageness of slavery into pulp fiction is quite another".
Gawker lawsuit over "The Hateful Eight".
In January 2014, Gawker leaked a copy of the script for Tarantino's upcoming film titled "The Hateful Eight". After the script was released online, Tarantino decided to scrap the project altogether and chose to use the story for a novel instead.
The controversy did not stop there; Tarantino filed a copyright lawsuit against Gawker, and stated in the lawsuit that "Gawker Media has made a business of predatory journalism, violating people's rights to make a buck" (quote from "The Hollywood Reporter"). The lawsuit also demanded compensation in the amount of $1,000,000. Tarantino later dropped the lawsuit but his statements have led many to believe that he will be refiling the lawsuit at a later date. Tarantino stated in his motion: "This dismissal is made without prejudice, whereby plaintiff may later advance an action and refile a complaint after further investigations to ascertain and plead the identities of additional infringers" ("The Hollywood Reporter"). Tarantino has yet to refile a claim but retains the legal right to do so in the future.
At the 2014 San Diego Comic-Con International, Tarantino confirmed the film, and stated that he was working on a third draft of the film, set for a potential release in 2015. This retracted his earlier statements which suggested that the film was not going to be made.
Filmography.
Frequent collaborators.
Tarantino has built up an informal "repertory company" of actors who have appeared in multiple roles in films that he has directed. Most notable of these is Samuel L. Jackson, who has appeared in five films directed by Tarantino, and a sixth that was written by him, "True Romance". Other frequent collaborators include Uma Thurman, whom Tarantino has described as his "muse", Christoph Waltz and Zoë Bell.
Editor Sally Menke, who worked on all Tarantino films until her death in 2010, was described by Tarantino in 2007 as "hands down my number one collaborator". Editing duties since her death have been taken over by Fred Raskin.
Awards.
Academy Awards
BAFTA Awards
Golden Globe Awards
Film Independent Spirit Awards
Saturn Awards
Primetime Emmy Awards
Cannes Film Festival
Reception.
Critical, public and commercial reception to films Tarantino has directed as of January 6, 2015.

</doc>
<doc id="25170" url="http://en.wikipedia.org/wiki?curid=25170" title="Quartile">
Quartile

Computing methods.
For discrete distributions, there is no universal agreement on selecting the quartile values.
Method 1.
This rule is employed by the TI-83 calculator boxplot and "1-Var Stats" functions.
Method 2.
The values found by this method are also known as "Tukey's hinges".
Method 3.
This always gives the arithmetic mean of Methods 1 and 2; it ensures that the median value is given its correct weight, and thus quartile values change as smoothly as possible as additional data points are added.
Example 1.
Ordered Data Set: 6, 7, 15, 36, 39, 40, 41, 42, 43, 47, 49
Example 2.
Ordered Data Set: 7, 15, 36, 39, 40, 41
As there are an even number of data points, all three methods give the same results.
Outliers.
There are methods by which to check for outliers in the discipline of statistics and statistical analysis. As is the basic idea of descriptive statistics, when encountering an outlier, we have to explain this value by further analysis of the cause or origin of the outlier. In cases of extreme observations, which are not an infrequent occurrence, the typical values must be analyzed. In the case of quartiles, the Interquartile Range (IQR) may be used to characterize the data when there may be extremities that skew the data; the interquartile range is a relatively robust statistic (also sometimes called "resistance") compared to the range and standard deviation. There is also a mathematical method to check for outliers and determining "fences", upper and lower limits from which to check for outliers.
After determining the first and third quartiles and the interquartile range as outlined above, then fences are calculated using the following formula:
where "Q"1 and "Q"3 are the first and third quartiles, respectively. The Lower fence is the "lower limit" and the Upper fence is the "upper limit" of data, and any data lying outside these defined bounds can be considered an outlier. Anything below the Lower fence or above the Upper fence can be considered such a case. The fences provide a guideline by which to define an outlier, which may be defined in other ways. The fences define a "range" outside of which an outlier exists; a way to picture this is a boundary of a fence, outside of which are "outsiders" as opposed to outliers.

</doc>
<doc id="25175" url="http://en.wikipedia.org/wiki?curid=25175" title="Quadratic equation">
Quadratic equation

In elementary algebra, a quadratic equation (from the Latin "quadratus" for "square") is any equation having the form 
where "x" represents an unknown, and "a", "b", and "c" represent known numbers such that "a" is not equal to 0. If , then the equation is linear, not quadratic. The numbers "a", "b", and "c" are the "coefficients" of the equation, and may be distinguished by calling them, respectively, the "quadratic coefficient", the "linear coefficient" and the "constant" or "free term". 
Because the quadratic equation involves only one unknown, it is called "univariate". The quadratic equation only contains powers of "x" that are non-negative integers, and therefore it is a polynomial equation, and in particular it is a second degree polynomial equation since the greatest power is two.
Quadratic equations can be solved by a process known in American English as factoring and in other varieties of English as "factorising", by completing the square, by using the quadratic formula, or by graphing. Solutions to problems equivalent to the quadratic equation were known as early as 2000 BC.
Examples and applications.
The golden ratio is found as the solution of the quadratic equation formula_2
The equations of the circle and the other conic sections—ellipses, parabolas, and hyperbolas—are quadratic equations in two variables.
Given the cosine or sine of an angle, finding the cosine or sine of the angle that is half as large involves solving a quadratic equation.
The process of simplifying expressions involving the square root of an expression involving the square root of another expression involves finding the two solutions of a quadratic equation.
Descartes' theorem states that for every four kissing (mutually tangent) circles, their radii satisfy a particular quadratic equation.
The equation given by Fuss' theorem, giving the relation among the radius of a bicentric quadrilateral's inscribed circle, the radius of its circumscribed circle, and the distance between the centers of those circles, can be expressed as a quadratic equation for which the distance between the two circles' centers in terms of their radii is one of the solutions. The other solution of the same equation in terms of the relevant radii gives the distance between the circumscribed circle's center and the center of the excircle of an ex-tangential quadrilateral.
Solving the quadratic equation.
A quadratic equation with real or complex coefficients has two solutions, called "roots". These two solutions may or may not be distinct, and they may or may not be real.
Factoring by inspection.
It may be possible to express a quadratic equation "ax"2 + "bx" + "c" = 0 as a product ("px" + "q")("rx" + "s") = 0. In some cases, it is possible, by simple inspection, to determine values of "p", "q", "r," and "s" that make the two forms equivalent to one another. If the quadratic equation is written in the second form, then the "Zero Factor Property" states that the quadratic equation is satisfied if "px" + "q" = 0 or "rx" + "s" = 0. Solving these two linear equations provides the roots of the quadratic.
For most students, factoring by inspection is the first method of solving quadratic equations to which they are exposed.:202–207 If one is given a quadratic equation in the form "x"2 + "bx" + "c" = 0, the sought factorization has the form ("x" + "q")("x" + "s"), and one has to find two numbers "q" and "s" that add up to "b" and whose product is "c" (this is sometimes called "Vieta's rule" and is related to Vieta's formulas). The more general case where "a" does not equal 1 can require a considerable effort in trial and error guess-and-check, assuming that it can be factored at all by inspection.
Except for special cases such as where or , factoring by inspection only works for quadratic equations that have rational roots. This means that the great majority of quadratic equations that arise in practical applications cannot be solved by factoring by inspection.:207
Completing the square.
The process of completing the square makes use of the algebraic identity
which represents a well-defined algorithm that can be used to solve any quadratic equation.:207 Starting with a quadratic equation in standard form, "ax"2 + "bx" + "c" = 0 
We illustrate use of this algorithm by solving 2"x"2 + 4"x" − 4 = 0
The plus-minus symbol "±" indicates that both and are solutions of the quadratic equation.
Quadratic formula and its derivation.
Completing the square can be used to derive a general formula for solving quadratic equations, called the quadratic formula. The mathematical proof will now be briefly summarized. It can easily be seen, by polynomial expansion, that the following equation is equivalent to the quadratic equation:
Taking the square root of both sides, and isolating "x", gives:
Some sources, particularly older ones, use alternative parameterizations of the quadratic equation such as "ax"2 + 2"bx" + "c" = "0" or "ax"2 − 2"bx" + "c" = 0 , where "b" has a magnitude one half of the more common one, possibly with opposite sign. These result in slightly different forms for the solution, but are otherwise equivalent.
A number of alternative derivations can be found in the literature. These proofs are simpler than the standard completing the square method, represent interesting applications of other frequently used techniques in algebra, or offer insight into other areas of mathematics.
Reduced quadratic equation.
It is sometimes convenient to reduce a quadratic equation so that its leading coefficient is one. This is done by dividing both sides by "a", which is always possible since "a" is non-zero. This produces the "reduced quadratic equation":
where "p" = "b"/"a" and "q" = "c"/"a". This monic equation has the same solutions as the original.
The quadratic formula for the solutions of the reduced quadratic equation, written in terms of its coefficients, is:
Discriminant.
In the quadratic formula, the expression underneath the square root sign is called the "discriminant" of the quadratic equation, and is often represented using an upper case "D" or an upper case Greek delta:
A quadratic equation with "real" coefficients can have either one or two distinct real roots, or two distinct complex roots. In this case the discriminant determines the number and nature of the roots. There are three cases:
Thus the roots are distinct if and only if the discriminant is non-zero, and the roots are real if and only if the discriminant is non-negative.
Geometric interpretation.
The function is the quadratic function. The graph of any quadratic function has the same general shape, which is called a parabola. The location and size of the parabola, and how it opens, depend on the values of "a", "b", and "c". As shown in Figure 1, if "a" > 0, the parabola has a minimum point and opens upward. If "a" < 0, the parabola has a maximum point and opens downward. The extreme point of the parabola, whether minimum or maximum, corresponds to its vertex. The "x-coordinate" of the vertex will be located at formula_18, and the "y-coordinate" of the vertex may be found by substituting this "x-value" into the function. The "y-intercept" is located at the point (0, "c").
The solutions of the quadratic equation "ax"2 + "bx" + "c" = 0 correspond to the roots of the function , since they are the values of "x" for which . As shown in Figure 2, if "a", "b", and "c" are real numbers and the domain of "f" is the set of real numbers, then the roots of "f" are exactly the "x"-coordinates of the points where the graph touches the "x"-axis. As shown in Figure 3, if the discriminant is positive, the graph touches the "x"-axis at two points; if zero, the graph touches at one point; and if negative, the graph does not touch the "x"-axis.
Quadratic factorization.
The term
is a factor of the polynomial
if and only if "r" is a root of the quadratic equation
It follows from the quadratic formula that
In the special case where the quadratic has only one distinct root ("i.e." the discriminant is zero), the quadratic polynomial can be factored as
Graphing for real roots.
For most of the 20th century, graphing was rarely mentioned as a method for solving quadratic equations in high school or college algebra texts. Students learned to solve quadratic equations by factoring, completing the square, and applying the quadratic formula. Recently, graphing calculators have become common in schools and graphical methods have started to appear in textbooks, but they are generally not highly emphasized.
Being able to use a graphing calculator to solve a quadratic equation requires the ability to produce a graph of , the ability to scale the graph appropriately to the dimensions of the graphing surface, and the recognition that when , "x" is a solution to the equation. The skills required to solve a quadratic equation on a calculator are in fact applicable to finding the real roots of any arbitrary function.
Since an arbitrary function may cross the "x"-axis at multiple points, graphing calculators generally require one to identify the desired root by positioning a cursor at a "guessed" value for the root. (Some graphing calculators require bracketing the root on both sides of the zero.) The calculator then proceeds, by an iterative algorithm, to refine the estimated position of the root to the limit of calculator accuracy.
Avoiding loss of significance.
Although the quadratic formula provides what in principle should be an exact solution, it does not, from a numerical analysis standpoint, provide a completely stable method for evaluating the roots of a quadratic equation. If the two roots of the quadratic equation vary greatly in absolute magnitude, "b" will be very close in magnitude to formula_24, and the subtraction of two nearly equal numbers will cause loss of significance or catastrophic cancellation. A second form of cancellation can occur between the terms "b"2 and −4"ac" of the discriminant, which can lead to loss of up to half of correct significant figures.
History.
Babylonian mathematicians, as early as 2000 BC (displayed on Old Babylonian clay tablets) could solve problems relating the areas and sides of rectangles. There is evidence dating this algorithm as far back as the Third Dynasty of Ur. In modern notation, the problems typically involved solving a pair of simultaneous equations of the form:
which are equivalent to the equation::86
The steps given by Babylonian scribes for solving the above rectangle problem were as follows:
Geometric methods were used to solve quadratic equations in Babylonia, Egypt, Greece, China, and India. The Egyptian Berlin Papyrus, dating back to the Middle Kingdom (2050 BC to 1650 BC), contains the solution to a two-term quadratic equation. In the Indian Sulba Sutras, circa 8th century BC, quadratic equations of the form and "ax"2 + "bx" = "c" were explored using geometric methods. Babylonian mathematicians from circa 400 BC and Chinese mathematicians from circa 200 BC used geometric methods of dissection to solve quadratic equations with positive roots. Rules for quadratic equations were given in the "The Nine Chapters on the Mathematical Art", a Chinese treatise on mathematics. These early geometric methods do not appear to have had a general formula. Euclid, the Greek mathematician, produced a more abstract geometrical method around 300 BC. With a purely geometric approach Pythagoras and Euclid created a general procedure to find solutions of the quadratic equation. In his work "Arithmetica", the Greek mathematician Diophantus solved the quadratic equation, but giving only one root, even when both roots were positive.
In 628 AD, Brahmagupta, an Indian mathematician, gave the first explicit (although still not completely general) solution of the quadratic equation "ax"2 + "bx" = "c" as follows: "To the absolute number multiplied by four times the [coefficient of the] square, add the square of the [coefficient of the] middle term; the square root of the same, less the [coefficient of the] middle term, being divided by twice the [coefficient of the] square is the value." ("Brahmasphutasiddhanta", Colebrook translation, 1817, page 346):87 This is equivalent to:
The "Bakhshali Manuscript" written in India in the 7th century AD contained an algebraic formula for solving quadratic equations, as well as quadratic indeterminate equations (originally of type Muhammad ibn Musa al-Khwarizmi (Persia, 9th century), inspired by Brahmagupta, developed a set of formulas that worked for positive solutions. Al-Khwarizmi goes further in providing a full solution to the general quadratic equation, accepting one or two numerical answers for every quadratic equation, while providing geometric proofs in the process. He also described the method of completing the square and recognized that the discriminant must be positive,:230 which was proven by his contemporary 'Abd al-Hamīd ibn Turk (Central Asia, 9th century) who gave geometric figures to prove that if the discriminant is negative, a quadratic equation has no solution.:234 While al-Khwarizmi himself did not accept negative solutions, later Islamic mathematicians that succeeded him accepted negative solutions,:191 as well as irrational numbers as solutions. Abū Kāmil Shujā ibn Aslam (Egypt, 10th century) in particular was the first to accept irrational numbers (often in the form of a square root, cube root or fourth root) as solutions to quadratic equations or as coefficients in an equation. The 9th century Indian mathematician Sridhara wrote down rules for solving quadratic equations.
The Jewish mathematician Abraham bar Hiyya Ha-Nasi (12th century, Spain) authored the first European book to include the full solution to the general quadratic equation. His solution was largely based on Al-Khwarizmi's work. The writing of the Chinese mathematician Yang Hui (1238–1298 AD) is the first known one in which quadratic equations with negative coefficients of 'x' appear, although he attributes this to the earlier Liu Yi. By 1545 Gerolamo Cardano compiled the works related to the quadratic equations. The quadratic formula covering all cases was first obtained by Simon Stevin in 1594. In 1637 René Descartes published "La Géométrie" containing the quadratic formula in the form we know today. The first appearance of the general solution in the modern mathematical literature appeared in an 1896 paper by Henry Heaton.
Advanced topics.
Alternative methods of root calculation.
Vieta's formulas.
Vieta's formulas give a simple relation between the roots of a polynomial and its coefficients. In the case of the quadratic polynomial, they take the following form:
and
These results follow immediately from the relation:
which can be compared term by term with
The first formula above yields a convenient expression when graphing a quadratic function. Since the graph is symmetric with respect to a vertical line through the vertex, when there are two real roots the vertex's "x"-coordinate is located at the average of the roots (or intercepts). Thus the "x"-coordinate of the vertex is given by the expression
The "y"-coordinate can be obtained by substituting the above result into the given quadratic equation, giving
As a practical matter, Vieta's formulas provide a useful method for finding the roots of a quadratic in the case where one root is much smaller than the other. If | "x" 2| « | "x" 1|, then "x" 1 + "x" 2 ≈ "x" 1, and we have the estimate:
The second Vieta's formula then provides:
These formulas are much easier to evaluate than the quadratic formula under the condition of one large and one small root, because the quadratic formula evaluates the small root as the difference of two very nearly equal numbers (the case of large "b"), which causes round-off error in a numerical evaluation. Figure 5 shows the difference between (i) a direct evaluation using the quadratic formula (accurate when the roots are near each other in value) and (ii) an evaluation based upon the above approximation of Vieta's formulas (accurate when the roots are widely spaced). As the linear coefficient "b" increases, initially the quadratic formula is accurate, and the approximate formula improves in accuracy, leading to a smaller difference between the methods as "b" increases. However, at some point the quadratic formula begins to lose accuracy because of round off error, while the approximate method continues to improve. Consequently the difference between the methods begins to increase as the quadratic formula becomes worse and worse.
This situation arises commonly in amplifier design, where widely separated roots are desired to ensure a stable operation (see step response).
Trigonometric solution.
In the days before calculators, people would use mathematical tables—lists of numbers showing the results of calculation with varying arguments—to simplify and speed up computation. Tables of logarithms and trigonometric functions were common in math and science textbooks. Specialized tables were published for applications such as astronomy, celestial navigation and statistics. Methods of numerical approximation existed, called prosthaphaeresis, that offered shortcuts around time-consuming operations such as multiplication and taking powers and roots. Astronomers, especially, were concerned with methods that could speed up the long series of computations involved in celestial mechanics calculations.
It is within this context that we may understand the development of means of solving quadratic equations by the aid of trigonometric substitution. Consider the following alternate form of the quadratic equation,
[1]   formula_37
where the sign of the ± symbol is chosen so that "a" and "c" may both be positive. By substituting
[2]   formula_38
and then multiplying through by cos2"θ", we obtain
[3]   formula_39
Introducing functions of 2"θ" and rearranging, we obtain
[4]   formula_40
[5]   formula_41
where the subscripts "n" and "p" correspond, respectively, to the use of a negative or positive sign in equation [1]. Substituting the two values of "θ"n or "θ"p found from equations [4] or [5] into [2] gives the required roots of [1]. Complex roots occur in the solution based on equation [5] if the absolute value of sin 2"θ"p exceeds unity. The amount of effort involved in solving quadratic equations using this mixed trigonometric and logarithmic table look-up strategy was two-thirds the effort using logarithmic tables alone. Calculating complex roots would require using a different trigonometric form.
Solution for complex roots in polar coordinates.
If the quadratic equation formula_1 with real coefficients has two complex roots—the case where formula_51 requiring "a" and "c" to have the same sign as each other—then the solutions for the roots can be expressed in polar form as
where formula_53 and formula_54
Geometric solution.
The quadratic equation may be solved geometrically in a number of ways. One way is via Lill's method. The three coefficients "a", "b", "c" are drawn with right angles between them as in SA, AB, and BC in Figure 6. A circle is drawn with the start and end point SC as a diameter. If this cuts the middle line AB of the three then the equation has a solution, and the solutions are given by negative of the distance along this line from A divided by the first coefficient "a" or SA. If "a" is 1 the coefficients may be read off directly. Thus the solutions in the diagram are −AX1/SA and −AX2/SA.
The Carlyle circle, named after Thomas Carlyle, has the property that the solutions of the quadratic equation are the horizontal coordinates of the intersections of the circle with the horizontal axis. Carlyle circles have been used to develop ruler-and-compass constructions of regular polygons.
Generalization of quadratic equation.
The formula and its derivation remain correct if the coefficients "a", "b" and "c" are complex numbers, or more generally members of any field whose characteristic is not 2. (In a field of characteristic 2, the element 2"a" is zero and it is impossible to divide by it.)
The symbol
in the formula should be understood as "either of the two elements whose square is "b"2 − 4"ac", if such elements exist". In some fields, some elements have no square roots and some have two; only zero has just one square root, except in fields of characteristic 2. Even if a field does not contain a square root of some number, there is always a quadratic extension field which does, so the quadratic formula will always make sense as a formula in that extension field.
Characteristic 2.
In a field of characteristic 2, the quadratic formula, which relies on 2 being a unit, does not hold. Consider the monic quadratic polynomial
over a field of characteristic 2. If , then the solution reduces to extracting a square root, so the solution is
and there is only one root since
In summary,
See quadratic residue for more information about extracting square roots in finite fields.
In the case that "b" ≠ 0, there are two distinct roots, but if the polynomial is irreducible, they cannot be expressed in terms of square roots of numbers in the coefficient field. Instead, define the 2-root "R"("c") of "c" to be a root of the polynomial "x"2 + "x" + "c", an element of the splitting field of that polynomial. One verifies that "R"("c") + 1 is also a root. In terms of the 2-root operation, the two roots of the (non-monic) quadratic "ax"2 + "bx" + "c" are
and
For example, let "a" denote a multiplicative generator of the group of units of "F"4, the Galois field of order four (thus "a" and "a" + 1 are roots of "x"2 + "x" + 1 over "F"4. Because ("a" + 1)2 = "a", "a" + 1 is the unique solution of the quadratic equation "x"2 + "a" = 0. On the other hand, the polynomial "x"2 + "ax" + 1 is irreducible over "F"4, but it splits over "F"16, where it has the two roots "ab" and "ab" + "a", where "b" is a root of "x"2 + "x" + "a" in "F"16.
This is a special case of Artin–Schreier theory.

</doc>
<doc id="25179" url="http://en.wikipedia.org/wiki?curid=25179" title="Quark">
Quark

A quark ( or ) is an elementary particle and a fundamental constituent of matter. Quarks combine to form composite particles called hadrons, the most stable of which are protons and neutrons, the components of atomic nuclei. Due to a phenomenon known as "color confinement", quarks are never directly observed or found in isolation; they can be found only within hadrons, such as baryons (of which protons and neutrons are examples), and mesons. For this reason, much of what is known about quarks has been drawn from observations of the hadrons themselves.
Quarks have various intrinsic properties, including electric charge, mass, color charge and spin. Quarks are the only elementary particles in the Standard Model of particle physics to experience all four fundamental interactions, also known as "fundamental forces" (electromagnetism, gravitation, strong interaction, and weak interaction), as well as the only known particles whose electric charges are not integer multiples of the elementary charge.
There are six types of quarks, known as "flavors": up, down, strange, charm, top, and bottom. Up and down quarks have the lowest masses of all quarks. The heavier quarks rapidly change into up and down quarks through a process of particle decay: the transformation from a higher mass state to a lower mass state. Because of this, up and down quarks are generally stable and the most common in the universe, whereas strange, charm, bottom, and top quarks can only be produced in high energy collisions (such as those involving cosmic rays and in particle accelerators). For every quark flavor there is a corresponding type of antiparticle, known as an "antiquark", that differs from the quark only in that some of its properties have equal magnitude but opposite sign. 
The quark model was independently proposed by physicists Murray Gell-Mann and George Zweig in 1964. Quarks were introduced as parts of an ordering scheme for hadrons, and there was little evidence for their physical existence until deep inelastic scattering experiments at the Stanford Linear Accelerator Center in 1968. Accelerator experiments have provided evidence for all six flavors. The top quark was the last to be discovered at Fermilab in 1995.
Classification.
The Standard Model is the theoretical framework describing all the currently known elementary particles. This model contains six flavors of quarks (#redirect ), named up (#redirect ), down (#redirect ), strange (#redirect ), charm (#redirect ), bottom (#redirect ), and top (#redirect ). Antiparticles of quarks are called "antiquarks", and are denoted by a bar over the symbol for the corresponding quark, such as #redirect for an up antiquark. As with antimatter in general, antiquarks have the same mass, mean lifetime, and spin as their respective quarks, but the electric charge and other charges have the opposite sign.
Quarks are spin-1⁄2 particles, implying that they are fermions according to the spin-statistics theorem. They are subject to the Pauli exclusion principle, which states that no two identical fermions can simultaneously occupy the same quantum state. This is in contrast to bosons (particles with integer spin), any number of which can be in the same state. Unlike leptons, quarks possess color charge, which causes them to engage in the strong interaction. The resulting attraction between different quarks causes the formation of composite particles known as "hadrons" (see "Strong interaction and color charge" below).
The quarks which determine the quantum numbers of hadrons are called "valence quarks"; apart from these, any hadron may contain an indefinite number of virtual (or "sea") quarks, antiquarks, and gluons which do not influence its quantum numbers. There are two families of hadrons: baryons, with three valence quarks, and mesons, with a valence quark and an antiquark. The most common baryons are the proton and the neutron, the building blocks of the atomic nucleus. A great number of hadrons are known (see list of baryons and list of mesons), most of them differentiated by their quark content and the properties these constituent quarks confer. The existence of "exotic" hadrons with more valence quarks, such as tetraquarks (#redirect #redirect #redirect #redirect ) and pentaquarks (#redirect #redirect #redirect #redirect #redirect ), has been conjectured but not proven.
Elementary fermions are grouped into three generations, each comprising two leptons and two quarks. The first generation includes up and down quarks, the second strange and charm quarks, and the third bottom and top quarks. All searches for a fourth generation of quarks and other elementary fermions have failed, and there is strong indirect evidence that no more than three generations exist. Particles in higher generations generally have greater mass and less stability, causing them to decay into lower-generation particles by means of weak interactions. Only first-generation (up and down) quarks occur commonly in nature. Heavier quarks can only be created in high-energy collisions (such as in those involving cosmic rays), and decay quickly; however, they are thought to have been present during the first fractions of a second after the Big Bang, when the universe was in an extremely hot and dense phase (the quark epoch). Studies of heavier quarks are conducted in artificially created conditions, such as in particle accelerators.
Having electric charge, mass, color charge, and flavor, quarks are the only known elementary particles that engage in all four fundamental interactions of contemporary physics: electromagnetism, gravitation, strong interaction, and weak interaction. Gravitation is too weak to be relevant to individual particle interactions except at extremes of energy (Planck energy) and distance scales (Planck distance). However, since no successful quantum theory of gravity exists, gravitation is not described by the Standard Model.
See the table of properties below for a more complete overview of the six quark flavors' properties.
History.
The quark model was independently proposed by physicists Murray Gell-Mann
(pictured) and George Zweig in 1964. The proposal came shortly after Gell-Mann's 1961 formulation of a particle classification system known as the "Eightfold Way"—or, in more technical terms, SU(3) flavor symmetry. Physicist Yuval Ne'eman had independently developed a scheme similar to the Eightfold Way in the same year.
At the time of the quark theory's inception, the "particle zoo" included, amongst other particles, a multitude of hadrons. Gell-Mann and Zweig posited that they were not elementary particles, but were instead composed of combinations of quarks and antiquarks. Their model involved three flavors of quarks, up, down, and strange, to which they ascribed properties such as spin and electric charge. The initial reaction of the physics community to the proposal was mixed. There was particular contention about whether the quark was a physical entity or a mere abstraction used to explain concepts that were not fully understood at the time.
In less than a year, extensions to the Gell-Mann–Zweig model were proposed. Sheldon Lee Glashow and James Bjorken predicted the existence of a fourth flavor of quark, which they called "charm". The addition was proposed because it allowed for a better description of the weak interaction (the mechanism that allows quarks to decay), equalized the number of known quarks with the number of known leptons, and implied a mass formula that correctly reproduced the masses of the known mesons.
In 1968, deep inelastic scattering experiments at the Stanford Linear Accelerator Center (SLAC) showed that the proton contained much smaller, point-like objects and was therefore not an elementary particle. Physicists were reluctant to firmly identify these objects with quarks at the time, instead calling them "partons"—a term coined by Richard Feynman. The objects that were observed at SLAC would later be identified as up and down quarks as the other flavors were discovered. Nevertheless, "parton" remains in use as a collective term for the constituents of hadrons (quarks, antiquarks, and gluons).
The strange quark's existence was indirectly validated by SLAC's scattering experiments: not only was it a necessary component of Gell-Mann and Zweig's three-quark model, but it provided an explanation for the kaon (#redirect ) and pion (#redirect ) hadrons discovered in cosmic rays in 1947.
In a 1970 paper, Glashow, John Iliopoulos and Luciano Maiani presented further reasoning for the existence of the as-yet undiscovered charm quark. The number of supposed quark flavors grew to the current six in 1973, when Makoto Kobayashi and Toshihide Maskawa noted that the experimental observation of CP violation could be explained if there were another pair of quarks.
Charm quarks were produced almost simultaneously by two teams in November 1974 (see November Revolution)—one at SLAC under Burton Richter, and one at Brookhaven National Laboratory under Samuel Ting. The charm quarks were observed bound with charm antiquarks in mesons. The two parties had assigned the discovered meson two different symbols, J and ψ; thus, it became formally known as the #redirect [[Template:Subatomic particle]] meson. The discovery finally convinced the physics community of the quark model's validity.
In the following years a number of suggestions appeared for extending the quark model to six quarks. Of these, the 1975 paper by Haim Harari was the first to coin the terms "top" and "bottom" for the additional quarks.
In 1977, the bottom quark was observed by a team at Fermilab led by Leon Lederman. This was a strong indicator of the top quark's existence: without the top quark, the bottom quark would have been without a partner. However, it was not until 1995 that the top quark was finally observed, also by the CDF and DØ teams at Fermilab. It had a mass much larger than had been previously expected, almost as large as that of a gold atom.
Etymology.
For some time, Gell-Mann was undecided on an actual spelling for the term he intended to coin, until he found the word "quark" in James Joyce's book "Finnegans Wake":
<poem>
Three quarks for Muster Mark!
Sure he has not got much of a bark
And sure any he has it's all beside the mark.
</poem>—James Joyce, "Finnegans Wake"
Gell-Mann went into further detail regarding the name of the quark in his book "The Quark and the Jaguar":
In 1963, when I assigned the name "quark" to the fundamental constituents of the nucleon, I had the sound first, without the spelling, which could have been "kwork". Then, in one of my occasional perusals of "Finnegans Wake", by James Joyce, I came across the word "quark" in the phrase "Three quarks for Muster Mark". Since "quark" (meaning, for one thing, the cry of the gull) was clearly intended to rhyme with "Mark", as well as "bark" and other such words, I had to find an excuse to pronounce it as "kwork". But the book represents the dream of a publican named Humphrey Chimpden Earwicker. Words in the text are typically drawn from several sources at once, like the "portmanteau" words in "Through the Looking-Glass". From time to time, phrases occur in the book that are partially determined by calls for drinks at the bar. I argued, therefore, that perhaps one of the multiple sources of the cry "Three quarks for Muster Mark" might be "Three quarts for Mister Mark", in which case the pronunciation "kwork" would not be totally unjustified. In any case, the number three fitted perfectly the way quarks occur in nature.
Zweig preferred the name "ace" for the particle he had theorized, but Gell-Mann's terminology came to prominence once the quark model had been commonly accepted.
The quark flavors were given their names for a number of reasons. The up and down quarks are named after the up and down components of isospin, which they carry. Strange quarks were given their name because they were discovered to be components of the strange particles discovered in cosmic rays years before the quark model was proposed; these particles were deemed "strange" because they had unusually long lifetimes. Glashow, who coproposed charm quark with Bjorken, is quoted as saying, "We called our construct the 'charmed quark', for we were fascinated and pleased by the symmetry it brought to the subnuclear world." The names "bottom" and "top", coined by Harari, were chosen because they are "logical partners for up and down quarks". In the past, bottom and top quarks were sometimes referred to as "beauty" and "truth" respectively, but these names have somewhat fallen out of use. While "truth" never did catch on, accelerator complexes devoted to massive production of bottom quarks are sometimes called "beauty factories".
Properties.
Electric charge.
Quarks have fractional electric charge values – either 1⁄3 or 2⁄3 times the elementary charge (e), depending on flavor. Up, charm, and top quarks (collectively referred to as "up-type quarks") have a charge of +2⁄3 e, while down, strange, and bottom quarks ("down-type quarks") have −1⁄3 e. Antiquarks have the opposite charge to their corresponding quarks; up-type antiquarks have charges of −2⁄3 e and down-type antiquarks have charges of +1⁄3 e. Since the electric charge of a hadron is the sum of the charges of the constituent quarks, all hadrons have integer charges: the combination of three quarks (baryons), three antiquarks (antibaryons), or a quark and an antiquark (mesons) always results in integer charges. For example, the hadron constituents of atomic nuclei, neutrons and protons, have charges of 0 e and +1 e respectively; the neutron is composed of two down quarks and one up quark, and the proton of two up quarks and one down quark.
Spin.
Spin is an intrinsic property of elementary particles, and its direction is an important degree of freedom. It is sometimes visualized as the rotation of an object around its own axis (hence the name ""), though this notion is somewhat misguided at subatomic scales because elementary particles are believed to be point-like.
Spin can be represented by a vector whose length is measured in units of the reduced Planck constant "ħ" (pronounced "h bar"). For quarks, a measurement of the spin vector component along any axis can only yield the values +"ħ"/2 or −"ħ"/2; for this reason quarks are classified as spin-1⁄2 particles. The component of spin along a given axis – by convention the "z" axis – is often denoted by an up arrow ↑ for the value +1⁄2 and down arrow ↓ for the value −1⁄2, placed after the symbol for flavor. For example, an up quark with a spin of +1⁄2 along the "z" axis is denoted by u↑.
Weak interaction.
A quark of one flavor can transform into a quark of another flavor only through the weak interaction, one of the four fundamental interactions in particle physics. By absorbing or emitting a W boson, any up-type quark (up, charm, and top quarks) can change into any down-type quark (down, strange, and bottom quarks) and vice versa. This flavor transformation mechanism causes the radioactive process of beta decay, in which a neutron (#redirect ) "splits" into a proton (#redirect ), an electron (#redirect ) and an electron antineutrino (#redirect ) (see picture). This occurs when one of the down quarks in the neutron (#redirect #redirect #redirect ) decays into an up quark by emitting a virtual #redirect boson, transforming the neutron into a proton (#redirect #redirect #redirect ). The #redirect boson then decays into an electron and an electron antineutrino.
Both beta decay and the inverse process of "inverse beta decay" are routinely used in medical applications such as positron emission tomography (PET) and in experiments involving neutrino detection.
While the process of flavor transformation is the same for all quarks, each quark has a preference to transform into the quark of its own generation. The relative tendencies of all flavor transformations are described by a mathematical table, called the Cabibbo–Kobayashi–Maskawa matrix (CKM matrix). Enforcing unitarity, the approximate magnitudes of the entries of the CKM matrix are:
where "V""ij" represents the tendency of a quark of flavor "i" to change into a quark of flavor "j" (or vice versa).
There exists an equivalent weak interaction matrix for leptons (right side of the W boson on the above beta decay diagram), called the Pontecorvo–Maki–Nakagawa–Sakata matrix (PMNS matrix). Together, the CKM and PMNS matrices describe all flavor transformations, but the links between the two are not yet clear.
Strong interaction and color charge.
According to quantum chromodynamics (QCD), quarks possess a property called "color charge". There are three types of color charge, arbitrarily labeled "blue", "green", and "red". Each of them is complemented by an anticolor – "antiblue", "antigreen", and "antired". Every quark carries a color, while every antiquark carries an anticolor.
The system of attraction and repulsion between quarks charged with different combinations of the three colors is called strong interaction, which is mediated by force carrying particles known as "gluons"; this is discussed at length below. The theory that describes strong interactions is called quantum chromodynamics (QCD). A quark, which will have a single color value, can form a bound system with an antiquark carrying the corresponding anticolor. The result of two attracting quarks will be color neutrality: a quark with color charge "ξ" plus an antiquark with color charge −"ξ" will result in a color charge of 0 (or "white" color) and the formation of a meson. This is analogous to the additive color model in basic optics. Similarly, the combination of three quarks, each with different color charges, or three antiquarks, each with anticolor charges, will result in the same "white" color charge and the formation of a baryon or antibaryon.
In modern particle physics, gauge symmetries – a kind of symmetry group – relate interactions between particles (see gauge theories). Color SU(3) (commonly abbreviated to SU(3)c) is the gauge symmetry that relates the color charge in quarks and is the defining symmetry for quantum chromodynamics. Just as the laws of physics are independent of which directions in space are designated "x", "y", and "z", and remain unchanged if the coordinate axes are rotated to a new orientation, the physics of quantum chromodynamics is independent of which directions in three-dimensional color space are identified as blue, red, and green. SU(3)c color transformations correspond to "rotations" in color space (which, mathematically speaking, is a complex space). Every quark flavor "f", each with subtypes "f"B, "f"G, "f"R corresponding to the quark colors, forms a triplet: a three-component quantum field which transforms under the fundamental representation of SU(3)c. The requirement that SU(3)c should be local – that is, that its transformations be allowed to vary with space and time – determines the properties of the strong interaction, in particular the existence of eight gluon types to act as its force carriers.
Mass.
Two terms are used in referring to a quark's mass: "current quark mass" refers to the mass of a quark by itself, while "constituent quark mass" refers to the current quark mass plus the mass of the gluon particle field surrounding the quark. These masses typically have very different values. Most of a hadron's mass comes from the gluons that bind the constituent quarks together, rather than from the quarks themselves. While gluons are inherently massless, they possess energy – more specifically, quantum chromodynamics binding energy (QCBE) – and it is this that contributes so greatly to the overall mass of the hadron (see mass in special relativity). For example, a proton has a mass of approximately 938 MeV/c2, of which the rest mass of its three valence quarks only contributes about 11 MeV/c2; much of the remainder can be attributed to the gluons' QCBE.
The Standard Model posits that elementary particles derive their masses from the Higgs mechanism, which is related to the Higgs boson. Physicists hope that further research into the reasons for the top quark's large mass of ~173 GeV/c2, almost the mass of a gold atom, might reveal more about the origin of the mass of quarks and other elementary particles.
Table of properties.
The following table summarizes the key properties of the six quarks. Flavor quantum numbers (isospin ("I"3), charm ("C"), strangeness ("S", not to be confused with spin), topness ("T"), and bottomness ("B"′)) are assigned to certain quark flavors, and denote qualities of quark-based systems and hadrons. The baryon number ("B") is +1⁄3 for all quarks, as baryons are made of three quarks. For antiquarks, the electric charge ("Q") and all flavor quantum numbers ("B", "I"3, "C", "S", "T", and "B"′) are of opposite sign. Mass and total angular momentum ("J"; equal to spin for point particles) do not change sign for the antiquarks.
Interacting quarks.
As described by quantum chromodynamics, the strong interaction between quarks is mediated by gluons, massless vector gauge bosons. Each gluon carries one color charge and one anticolor charge. In the standard framework of particle interactions (part of a more general formulation known as perturbation theory), gluons are constantly exchanged between quarks through a virtual emission and absorption process. When a gluon is transferred between quarks, a color change occurs in both; for example, if a red quark emits a red–antigreen gluon, it becomes green, and if a green quark absorbs a red–antigreen gluon, it becomes red. Therefore, while each quark's color constantly changes, their strong interaction is preserved.
Since gluons carry color charge, they themselves are able to emit and absorb other gluons. This causes "asymptotic freedom": as quarks come closer to each other, the chromodynamic binding force between them weakens. Conversely, as the distance between quarks increases, the binding force strengthens. The color field becomes stressed, much as an elastic band is stressed when stretched, and more gluons of appropriate color are spontaneously created to strengthen the field. Above a certain energy threshold, pairs of quarks and antiquarks are created. These pairs bind with the quarks being separated, causing new hadrons to form. This phenomenon is known as "color confinement": quarks never appear in isolation. This process of hadronization occurs before quarks, formed in a high energy collision, are able to interact in any other way. The only exception is the top quark, which may decay before it hadronizes.
Sea quarks.
Hadrons, along with the "valence quarks" (#redirect ) that contribute to their quantum numbers, contain virtual quark–antiquark (#redirect #redirect ) pairs known as "sea quarks" (#redirect ). Sea quarks form when a gluon of the hadron's color field splits; this process also works in reverse in that the annihilation of two sea quarks produces a gluon. The result is a constant flux of gluon splits and creations colloquially known as "the sea". Sea quarks are much less stable than their valence counterparts, and they typically annihilate each other within the interior of the hadron. Despite this, sea quarks can hadronize into baryonic or mesonic particles under certain circumstances.
Other phases of quark matter.
Under sufficiently extreme conditions, quarks may become deconfined and exist as free particles. In the course of asymptotic freedom, the strong interaction becomes weaker at higher temperatures. Eventually, color confinement would be lost and an extremely hot plasma of freely moving quarks and gluons would be formed. This theoretical phase of matter is called quark–gluon plasma. The exact conditions needed to give rise to this state are unknown and have been the subject of a great deal of speculation and experimentation. A recent estimate puts the needed temperature at kelvin. While a state of entirely free quarks and gluons has never been achieved (despite numerous attempts by CERN in the 1980s and 1990s), recent experiments at the Relativistic Heavy Ion Collider have yielded evidence for liquid-like quark matter exhibiting "nearly perfect" fluid motion.
The quark–gluon plasma would be characterized by a great increase in the number of heavier quark pairs in relation to the number of up and down quark pairs. It is believed that in the period prior to 10−6 seconds after the Big Bang (the quark epoch), the universe was filled with quark–gluon plasma, as the temperature was too high for hadrons to be stable.
Given sufficiently high baryon densities and relatively low temperatures – possibly comparable to those found in neutron stars – quark matter is expected to degenerate into a Fermi liquid of weakly interacting quarks. This liquid would be characterized by a condensation of colored quark Cooper pairs, thereby breaking the local SU(3)c symmetry. Because quark Cooper pairs harbor color charge, such a phase of quark matter would be color superconductive; that is, color charge would be able to pass through it with no resistance.

</doc>
<doc id="25180" url="http://en.wikipedia.org/wiki?curid=25180" title="Queen">
Queen

A Queen is a female monarch. 
Queen may refer to:

</doc>
<doc id="25182" url="http://en.wikipedia.org/wiki?curid=25182" title="Quantization (physics)">
Quantization (physics)

In physics, quantization is the process of transition from a classical understanding of physical phenomena to a newer understanding known as "quantum mechanics". It is a procedure for constructing a quantum field theory starting from a classical field theory. This is a generalization of the procedure for building quantum mechanics from classical mechanics. One also speaks of field quantization, as in the "quantization of the electromagnetic field", where one refers to photons as field "quanta" (for instance as light quanta). This procedure is basic to theories of particle physics, nuclear physics, condensed matter physics, and quantum optics.
Quantization methods.
Quantization converts classical fields into operators acting on quantum states of the field theory. The lowest energy state is called the vacuum state. The reason for quantizing a theory is to deduce properties of materials, objects or particles through the computation of quantum amplitudes, which may be very complicated. Such computations have to deal with certain subtleties called renormalization, which, if neglected, can often lead to nonsense results, such as the appearance of infinities in various amplitudes. The full specification of a quantization procedure requires methods of performing renormalization.
The first method to be developed for quantization of field theories was canonical quantization. While this is extremely easy to implement on sufficiently simple theories, there are many situations where other methods of quantization yield more efficient procedures for computing quantum amplitudes. However, the use of canonical quantization has left its mark on the language and interpretation of quantum field theory.
Canonical quantization.
Canonical quantization of a field theory is analogous to the construction of quantum mechanics from classical mechanics. The classical field is treated as a dynamical variable called the canonical coordinate, and its time-derivative is the canonical momentum. One introduces a commutation relation between these which is exactly the same as the commutation relation between a particle's position and momentum in quantum mechanics. Technically, one converts the field to an operator, through combinations of creation and annihilation operators. The field operator acts on quantum states of the theory. The lowest energy state is called the vacuum state. The procedure is also called second quantization.
This procedure can be applied to the quantization of any field theory: whether of fermions or bosons, and with any internal symmetry. However, it leads to a fairly simple picture of the vacuum state and is not easily amenable to use in some quantum field theories, such as quantum chromodynamics which is known to have a complicated vacuum characterized by many different condensates.
Covariant canonical quantization.
There is a way to perform a canonical quantization without having to resort to the noncovariant approach of foliating spacetime and choosing a Hamiltonian. This method is based upon a classical action, but is different from the functional integral approach.
The method does not apply to all possible actions (for instance, actions with a noncausal structure or actions with gauge "flows"). It starts with the classical algebra of all (smooth) functionals over the configuration space. This algebra is quotiented over by the ideal generated by the Euler–Lagrange equations. Then, this quotient algebra is converted into a Poisson algebra by introducing a Poisson bracket derivable from the action, called the Peierls bracket. This Poisson algebra is then formula_1-deformed in the same way as in canonical quantization.
There is also a way to quantize actions with gauge "flows". It involves the Batalin–Vilkovisky formalism, an extension of the BRST formalism.
Deformation quantization.
"Main article: Weyl quantization".
Also see the phase space formulation of quantum mechanics, Moyal bracket, Star product, and Wigner quasi-probability distribution.
Geometric quantization.
In mathematical physics, geometric quantization is a mathematical approach to defining a quantum theory corresponding to a given classical theory. It attempts to carry out quantization, for which there is in general no exact recipe, in such a way that certain analogies between the classical theory and the quantum theory remain manifest. For example, the similarity between the Heisenberg equation in the Heisenberg picture of quantum mechanics and the Hamilton equation in classical physics should be built in.<br>
One of the earliest attempts at a natural quantization was Weyl quantization, proposed by Hermann Weyl in 1927. Here, an attempt is made to associate a quantum-mechanical observable (a self-adjoint operator on a Hilbert space) with a real-valued function on classical phase space. The position and momentum in this phase space are mapped to the generators of the Heisenberg group, and the Hilbert space appears as a group representation of the Heisenberg group. In 1946, H. J. Groenewold considered the product of a pair of such observables and asked what the corresponding function would be on the classical phase space. This led him to discover the phase-space star-product of a pair of functions.
More generally, this technique leads to deformation quantization, where the ★-product is taken to be a deformation of the algebra of functions on a symplectic manifold or Poisson manifold. However, as a natural quantization scheme (a functor), Weyl's map is not satisfactory. For example, the Weyl map of the classical angular-momentum-squared is not just the quantum angular momentum squared operator, but it further contains a constant term 3ħ2/2. (This extra term is actually physically significant, since it accounts for the nonvanishing angular momentum of the ground-state Bohr orbit in the hydrogen atom. As a mere representation change, however, Weyl's map underlies the alternate Phase space formulation of conventional quantum mechanics.
The geometric quantization procedure falls into the following three steps: prequantization, polarization, and metaplectic correction. Prequantization of a symplectic manifold provides a representation of elements of the Poisson algebra of smooth real functions on by first order differential operators on sections of a complex line bundle . In accordance with the Kostant – Souriau prequantization formula, these operators are expressed via a connection on whose curvature form obeys the prequantization condition. By polarization is meant an integrable maximal distribution on such that for all . Integrable means for (sections of T). The quantum algebra of a symplectic manifold consists of the operators of functions whose Hamiltonian vector fields satisfy the condition. In accordance with the metaplectic correction, elements of the quantum algebra act in the pre-Hilbert space of half-forms with values in the prequantization Line bundle on a symplectic manifold . The quantization is simply where is the Lie derivative of a half-form with respect to a vector field X. Geometric quantization of Poisson manifolds and symplectic foliations also is developed. For instance, this is the case of partially integrable and superintegrable Hamiltonian systems and non-autonomous mechanics.
Loop quantization.
See Loop quantum gravity.
Path integral quantization.
A classical mechanical theory is given by an action with the permissible configurations being the ones which are extremal with respect to functional variations of the action. A quantum-mechanical description of the classical system can also be constructed from the action of the system by means of the path integral formulation.
Quantum statistical mechanics approach.
See Uncertainty principle
Schwinger's variational approach.
See Schwinger's quantum action principle

</doc>
<doc id="25184" url="http://en.wikipedia.org/wiki?curid=25184" title="Quantile">
Quantile

Quantiles are values taken at regular intervals from the inverse of the cumulative distribution function (CDF) of a random variable. Dividing ordered data into formula_1 essentially equal-sized data subsets is the motivation for formula_1-quantiles; the quantiles are the data values marking the boundaries between consecutive subsets. Put another way, a formula_3 formula_1-quantile for a random variable is a value formula_5 such that the probability that the random variable will be less than formula_5 is at most formula_7 and the probability that the random variable will be greater than formula_5 is at most formula_9. There are formula_10 of the formula_1-quantiles, one for each integer formula_12 satisfying formula_13. In some cases the value of a quantile may not be uniquely determined, as can be the case for the median of a uniform probability distribution on a set of even size.
Specialized quantiles.
Some "q"-quantiles have special names: 
More generally, one can consider the quantile function for any distribution. This is defined for real variables between zero and one and is mathematically the inverse of the cumulative distribution function.
20-quantiles are also called twentiles. This term is preferred in the predictive modeling field. Twentiles are the default for gains charts in many analytical tools such as SAS Enterprise Miner. 
Quantiles of a population.
For a population of discrete values, or for a continuous population density, the formula_12th formula_1-quantile is the data value where the cumulative distribution function crosses formula_16 That is, formula_5 is a formula_12th formula_1-quantile for a variable formula_20 if
and
For a finite population of formula_25 values indexed 1...,formula_25 from lowest to highest, the formula_12th formula_1-quantile of this population can be computed via the value of formula_29. If formula_30 is not an integer, then round up to the next integer to get the appropriate index; the corresponding data value is the formula_12th formula_1-quantile. On the other hand, if formula_30 is an integer then any number from the data value at that index to the data value of the next can be taken as the quantile, and it is conventional (though arbitrary) to take the average of those two values (see Estimating the quantiles).
If, instead of using integers formula_12 and formula_1, the “formula_36-quantile” is based on a real number formula_36 with formula_38, then formula_36 replaces formula_7 in the above formulae. Some software programs (including Microsoft Excel) regard the minimum and maximum as the 0th and 100th percentile, respectively; however, such terminology is an extension beyond traditional statistics definitions.
Examples.
The following two examples use the Nearest Rank definition of quantile with rounding. For an explanation of this definition, see percentiles.
Even-sized population.
Consider an ordered population of 10 data values {3, 6, 7, 8, 8, 10, 13, 15, 16, 20}. What are the 4-quantiles (the "quartiles") of this dataset?
So the first, second and third 4-quantiles (the "quartiles") of the dataset {3, 6, 7, 8, 8, 10, 13, 15, 16, 20} are {7, 9, 15}. If also required, the zeroth quartile is 3 and the fourth quartile is 20.
Odd-sized population.
Consider an ordered population of 11 data values {3, 6, 7, 8, 8, 9, 10, 13, 15, 16, 20}. What are the 4-quantiles (the "quartiles") of this dataset?
So the first, second and third 4-quantiles (the "quartiles") of the dataset {3, 6, 7, 8, 8, 9, 10, 13, 15, 16, 20} are {7, 9, 15}. If also required, the zeroth quartile is 3 and the fourth quartile is 20.
Discussion.
Standardized test results are commonly misinterpreted as a student scoring "in the 80th percentile," for example, as if the 80th percentile is an interval to score "in," which it is not; one can score "at" some percentile, or between two percentiles, but not "in" some percentile. Perhaps by this example it is meant that the student scores between the 80th and 81st percentiles, or "in" the group of students whose score placed them at the 80th percentile.
If a distribution is symmetric, then the median is the mean (so long as the latter exists). But, in general, the median and the mean differ. For instance, with a random variable that has an exponential distribution, any particular sample of this random variable will have roughly a 63% chance of being less than the mean. This is because the exponential distribution has a long tail for positive values but is zero for negative numbers.
Quantiles are useful measures because they are less susceptible than means to long-tailed distributions and outliers. Empirically, if the data being analyzed are not actually distributed according to an assumed distribution, or if there are other potential sources for outliers that are far removed from the mean, then quantiles may be more useful descriptive statistics than means and other moment-related statistics.
Closely related is the subject of least absolute deviations, a method of regression that is more robust to outliers than is least squares, in which the sum of the absolute value of the observed errors is used in place of the squared error. The connection is that the mean is the single estimate of a distribution that minimizes expected squared error while the median minimizes expected absolute error. Least absolute deviations shares the ability to be relatively insensitive to large deviations in outlying observations, although even better methods of robust regression are available.
The quantiles of a random variable are preserved under increasing transformations, in the sense that, for example, if formula_41 is the median of a random variable formula_20, then formula_43 is the median of formula_44, unless an arbitrary choice has been made from a range of values to specify a particular quantile. (See quantile estimation, below, for examples of such interpolation.) Quantiles can also be used in cases where only ordinal data are available.
Estimating the quantiles of a population.
There are several methods for estimating the quantiles. The most comprehensive breadth of methods is available in the R and GNU Octave programming languages, which include nine sample quantile methods. SAS includes five sample quantile methods, SciPy and Maple both include eight, STATA includes two, and Microsoft Excel includes one.
In effect, the methods compute "Q""p", the estimate for the "k"th "q"-quantile, where "p" = "k" / "q", from a sample of size "N" by computing a real valued index "h". When "h" is an integer, the "h"th smallest of the "N" values, "x""h", is the quantile estimate. Otherwise a rounding or interpolation scheme is used to compute the quantile estimate from "h", "x"⌊"h"⌋, and "x"⌈"h"⌉. (For notation, see floor and ceiling functions).
Estimate types include:
Notes:
The standard error of a quantile estimate can in general be estimated via the bootstrap. The Maritz-Jarrett method can also be used.

</doc>
<doc id="25185" url="http://en.wikipedia.org/wiki?curid=25185" title="Q">
Q

Q (named "cue" ) is the 17th letter of the ISO basic Latin alphabet.
History.
The Semitic sound value of Qôp (perhaps originally "qaw", "cord of wool", and possibly based on an Egyptian hieroglyph) was /q/ (voiceless uvular stop), a sound common to Semitic languages, but not found in English or most Indo-European ones. In Greek, this sign as Qoppa Ϙ probably came to represent several labialized velar stops, among them /kʷ/ and /kʷʰ/. As a result of later sound shifts, these sounds in Greek changed to /p/ and /pʰ/ respectively. Therefore, Qoppa was transformed into two letters: Qoppa, which stood for a number only, and Phi Φ which stood for the aspirated sound /pʰ/ that came to be pronounced /f/ in Modern Greek.
In the earliest Latin inscriptions, the letters C, K and Q were all used to represent the two sounds /k/ and /ɡ/, which were not differentiated in writing. Of these, Q was used before a rounded vowel (e.g. ⟨EQO⟩ 'ego'), K before /a/, and C elsewhere. Later, the use of C (and its variant G) replaced most usages of K and Q: Q survived only to represent /k/ when immediately followed by a /w/ sound.
The Etruscans used Q in conjunction with V to represent /kʷ/.
Use in English.
In English the digraph 'qu' most often denotes the cluster , except in borrowings from French where it represents as in 'plaque'. See list of English words containing Q not followed by U. Q is the second-least-common letter in the English language, with a frequency of just 0.09% in words. Only Z occurs less often.
Use in other languages.
In most European languages written in the Latin script, such as in Romance and Germanic languages, 'q' appears almost exclusively in the digraph 'qu'. Notable exceptions to this are Albanian, in which 'q' represents the voiceless palatal stop [c]; and Maltese and Võro, which use 'q' to represent the glottal stop [ʔ]. In French, Occitan, Catalan and Portuguese, 'qu' represents /k/ or /kw/; in Spanish, it represents /k/. 'qu' replaces 'c' for /k/ before front vowels 'i' and 'e', since in those languages 'c' represents a fricative or affricate before front vowels. In Italian 'qu' represents [kw] (where [w] is the semivowel allophone of /u/).
Q has a wide variety of pronunciations among non-European languages that have adopted the Latin alphabet. The International Phonetic Alphabet uses Q for the voiceless uvular stop, and it has this value in Aymara, Crimean Tatar, Greenlandic, Quechua, Uyghur and Uzbek. In Azerbaijani, 'q' stands for a voiced velar stop [ɡ]. In Chinese Hanyu Pinyin, 'q' is used to represent the sound [tɕʰ], which is close to English 'ch' in "cheese", but pronounced further toward the front of the mouth. 'q' in Fijian has the value of a prenasalized voiced velar stop [ŋɡ]. In Kiowa, 'q' represents a glottalized velar stop [kʼ]. In Xhosa and Zulu, 'q' is used for the postalveolar click [kǃ]. In transliteration of Classical Mongolian, 'q' represents a voiceless velar fricative [x].
Forms and variants.
The lowercase Q (q) is usually seen as a lowercase O with a descender (i.e., downward vertical tail) extending from the right side of the bowl, with or without a swash (i.e., flourish), even a reversed lowercase p. The lowercase Q's descender is usually typed without a swash due to the major style difference typically seen between the descenders of the lowercase G (a loop) and lowercase Q (vertical). The descender of the lowercase Q is sometimes handwritten finishing with a rightward swash to distinguish from the leftward facing curved descender on the lowercase G.

</doc>
<doc id="25187" url="http://en.wikipedia.org/wiki?curid=25187" title="History of Qatar">
History of Qatar

The history of Qatar spans from its first duration of human settlement to its formation as a modern state. Human habitation of Qatar dates back to 50,000 years ago and Stone Age settlements and tools have been unearthed in the peninsula. Mesopotamia also had a presence in the area, with potsherds purportedly originating from the Ubaid period being discovered along the coast. The peninsula fell under the domain of several different empires during its early years of settlement, including the Seleucid, the Parthians and the Sasanians. In 628, the peninsula converted to Islam after Muhammad sent an envoy to Munzir ibn Sawa. It became a pearl trading center by the 8th century. The Abbasid era saw the rise of several settlements. After the Bani Utbah and other Arab tribes conquered Bahrain in 1783, the Al Khalifa imposed their authority over Bahrain and mainland Qatar. Over the following centuries, Qatar was a site of contention between the Wahhabi of Najd and the Al Khalifa. The Ottomans expanded their empire into Eastern Arabia in 1871, but they withdrew from the area before the beginning of World War I in 1913.
The country became a British protectorate in 1916 and a treaty was signed by Abdullah bin Jassim Al Thani which stipulated that he could only cede territory to the British, in return for protection from all aggression by sea and support in case of a land attack. A 1934 treaty granted more extensive protection. In 1935, a 75-year oil concession was granted to the Qatar Petroleum Company and high-quality oil was discovered in 1940 in Dukhan.
During the 1950s and 1960s, increasing oil revenues brought prosperity, rapid immigration, substantial social progress, and the beginnings of the country's modern history. When, in 1968, the U.K. announced a policy of ending the treaty relationships with the Persian Gulf sheikdoms, Qatar joined the other eight states then under British protection in a plan to form a union of Arab emirates. By mid-1971, as the termination date of the British treaty relationship approached, the nine still had not agreed on terms of union. Accordingly, Qatar declared its independence on September 3, 1971. On June 27, 1995, deputy emir Hamad bin Khalifa deposed his father Khalifa bin Hamad in a bloodless coup. The emir announced his intention for Qatar to move toward democracy and permitted more liberal press and municipal elections as a precursor to parliamentary elections. A new constitution was approved via public referendum in April 2003 and came into effect in June 2005.
Prehistory.
Archaeological evidence has dated human habitation of the Qatar Peninsula to 50,000 years in the past, when small groups of Stone Age inhabitants built coastal encampments, settlements, and sites for working flint. Other finds have included pottery from the Ubaid culture of Mesopotamia and northern Arabia (ca. 5000 B.C.), rock carvings, burial mounds, and a large town that dates from about 500 B.C. at Wusail, twenty kilometers north of Doha. One of the oldest known-settlement in the country, known as Ash Shaqra, is located in the south-east of Qatar and dates back to 6,000 BC. A two-room structure, flints and remnants of fish and molluscs were found at the site.
Regularly used as rangeland for nomadic tribes from the Najd and Al Hasa regions in Saudi Arabia, a number of seasonal encampments were constructed around sources of water. In addition, fishing and pearling settlements were established on the parts of the coast near a major well.
Neolithic period (6500–3800 BC).
Remnants of pottery originating from the Ubaid, the period of Mesopotamia which transpired from ca. 6500 to 3800 BC, were uncovered in Qatar during three separate expeditions during the 1970s and 1980s. Microprobe analyses carried out on the potsherds deduced that they originated from southern Mesopotamia. Owing to the fact that the Qatari Peninsula would not have accommodated the necessary conditions for a pottery-making civilization to flourish, it has been hypothesized that the pottery was produced in Ur and traded down the Persian Gulf settlements. As there is a distinct absence of pottery in overland routes, it is believed that trading was primarily facilitated by sea routes.
Al Da'asa, located on the north east coast of Qatar, is the most important Ubaid site in the country. It was excavated by a Danish team in 1961. The site is theorized to have accommodated a small seasonal encampment, possibly a lodging for a hunting-fishing-gathering group who may have made recurrent visits. This is evidenced by the discovery of nearly sixty fire pits at the site, which were utilized to cure fish, in addition to flint tools such as scrapers, cutters, blades and arrow heads. Furthermore, many painted Ubaid potsherds and a Carnelian bead were found in the fire pits, which suggests overseas connections. Three small fragments of red pottery unrelated to the Ubaid were also found at the site. 
Further potsherds of a later date of origin were found in nearby Ras Abaruk during a 1973–74 expedition. Owing to the quantity of flint debris and animal remnants in the area, it has been suggested that the inhabitants of Qatar gradually adapted their traditionally fish-based diet to include more terrestrial animals towards the end of the Ubaid period.
In an excavation done in Al Khor in 1977–78, several Ubaid graves were uncovered in what is the earliest recorded burial site in the country. One grave contained the cremated remains of a young woman with no grave goods. Eight other graves contained grave goods, including beads made of shell, carnelian and obsidian. The obsidian most likely originated from Najran in south west Arabia.
Bronze Age (2100–1155 BC).
The Qatari Peninsula was close enough to the Dilmun civilization in Bahrain to have felt its influence. Around 2100 to 1700 BC, when the people of Dilmun began engaging in maritime activities, the inhabitants of Qatar started diving for pearls in the Persian Gulf. The Qataris were engaged in the trading of pearls and date palms during this era. Barbar pottery was excavated in two sites by the Qatar Archaeology Project, evidencing the country's involvement in Dilmun's trade network.
It has been reasoned that, while remains of Dilmun settlements were found in Qatar, this does not represent major evidence of any long-lasting human habitation. Qatar remained relatively uninhabited during this period due to regular migration by nomadic Arab tribes searching for untapped sources food and water.
Kassite Babylonian-influenced materials dating back to the second millennium BC, which were found in Al Khor, reveal evidence of trade relations between the inhabitants of Qatar and the Kassite. It is the only archaelogical site attributable to the second millenium. Among the findings were 3,000,000 crushed snail shells and Kassite potsherds. It has been asserted that Qatar was the site of the earliest known production of shellfish dye and that the Kassite operated a purple dye industry along the coast. The dye was obtained from the Murex snail and was later dubbed "Tyrian purple".
Iron Age and Babylonian–Persian control (680–325 BC).
Assyrian king Esarhaddon led a successful campaign against "Bazu", an area encompassing Dilmun and Qatar, in c. 680 BC. As Assyrian power declined, the Babylonians took control over the Assyrian-held Arab lands around 612 BC. In 539 BC, the Persians conquered Babylon under Cyrus the Great and incorporated the territories encompassing the Arabian Peninsula into their empire. To date, no archaeological evidence of Iron Age settlements have been discovered in the Peninsula.
Hellenistic period (325–250 BC).
Around 325 BC, Alexander the Great sent his top admiral, Androsthenes of Thasos, to survey the entire Persian Gulf. The requested charts arrived shortly after Alexander died in 323. Seleucus I Nicator was awarded the eastern part of the Ancient Greek Empire after Alexander's death. Starting from 312, he expanded the Seleucid Empire eastward of Babylon, and it has been proposed that the territories encompassed parts of Eastern Arabia. There is archaeological evidence of Greek influence in the Arabian Peninsula, notably in Bahrain and Oman. Archaeological evidence has also been discovered in Qatar. Excavations north of Dukhan uncovered potsherds of Selucid characteristic, and a cairnfield consisting of 100 burial mounds dating to the era was discovered in Ras Abaruk. The relatively large number of cairns suggest a sizable sea-faring community prevailed in the area.
After losing most of their territories in the Persian Gulf, Seleucid influence ceased in the area by c. 250 BC.
Persian control (250 BC–642 AD).
Following the eviction of the Seleucid by the Parthian Empire in c. 250 BC, the latter gained dominion over the Persian Gulf and Arabian Coast. As the Parthians were dependent on trade routes through the Persian Gulf, they established garrisons along the coast. Pottery recovered from expeditions in Qatar has demonstrated links to the Parthian Empire.
Ras Abaruk, a coastal city north of Dukhan, housed a fishing station which foreign vessels used to dry fish in 140 BC. A number of stone structures and large quantities of fish bones were recovered from the site.
Pliny the Elder wrote the earliest known account of the inhabitants of the Peninsula around the mid-first century AD. He referred to them as the "Catharrei" and described them as nomads who roamed in constant search of water and food. In 224 AD, the Sasanian Empire gained control over the territories surrounding the Persian Gulf.
Qatar played a role in the commercial activity of the Sasanids, contributing to at least two commodities: precious pearls and purple dye. Sasanid pottery and glassware were found in Mezru'ah, a city north-west of Doha, and fragments of glassware and pottery were discovered in a settlement in Umm al-Ma'a.
Under the Sasanid reign, many of the inhabitants in Eastern Arabia were introduced to Christianity after the religion was dispersed eastward by Mesopotamian Christians. Monasteries were constructed in Qatar during this era, and further settlements were founded. The Arab nomads in Eastern Arabia retained their Christian faith for a longer period than the Arab tribes in Western Arabia.
Muhammad sent a Muslim envoy to a ruler in Eastern Arabia named Munzir ibn Sawa Al Tamimi in 628 and requested that he and his people accept Islam. Munzir obliged his request and most Arab tribes converted to Islam. Munzir ibn Sawa's seat of administration has been speculated to have existed in the Marwab or Umm al-Ma'a area of Qatar. This theory is lent credence by an archaeological find of approximately 100 small stone-built Islamic-period houses and fortified palaces of a tribal leader in Marwab, which are proposed to have originated from the early Islamic period.
After the adoption of Islam, the Arabs led the Muslim conquest of Persia which resulted in the fall of the Sasanian Empire.
Muslim rule.
Umayyad period (661–750).
Qatar was described as a famous horse and camel breeding centre during the Umayyad period. It began to benefit from its commercially strategic position in the Persian Gulf during the 8th century. It also became a center of pearl trading around the 8th century.
During the Second Fitna, a renowned Khawarij commander named Qatari ibn al-Fuja'a, who was described as the most popular, admired and powerful Khawarji leader, led the Azariqa, a Kharjite sub-sect, in to numerous battles. He was known as the 'Prince of the Believers' and ruled over the radical Azariqa movement for more than 10 years. There were many revolts against the Umayyad at the end of the seventh century, particularly in Qatar and Bahrain. Ibn al-Fuja'a led an uprising against the Umayyad caliphs for more than twenty years. Some scholars have linked the historical root of the country's name to Qatari ibn al-Fuja'a.
Abbasid period (750–1253).
Several settlements, including Marwab, were developed during the Abbasid period. Over 100 stone-built houses, two mosques, and an Abbasid fort constructed in Marwab have been dated to this era. Marwab fort is the oldest intact fort in the country and was built over the ruins of a previous fort which was destroyed by fire. The town was the site of the first sizable settlement established off the coastal area of Qatar. A similar site, containing T'ang stoneware and dating to the 9th and 10th centuries, was discovered in Al Naman (north of Zubarah).
Substantial development in the pearling industry around the Qatari Peninsula occurred during the Abbasid era. Ships from Basra en route to India and China would make stops in the port of Qatar during this period. Chinese porcelain, West African coins and pieces from Thailand have been discovered in Qatar. Archaeological remains from the 9th century suggest that Qatar's inhabitants used greater wealth, perhaps from pearl trade, to construct higher quality homes and public buildings. However, when the caliphate's prosperity declined in Iraq, so too did it in Qatar.
Most of Eastern Arabia, particularly Bahrain and the Qatari Peninsula, were sites of revolt against the Abbasid Caliphate around 868. Mohammed ibn Ali, a revolutionary, roused the people of Bahrain and Qatar into a rebellion, but the rebellion was unsuccessful and he relocated to Basra. He was later successful in instigating the Zanj Rebellion.
A radical Isma'ili group called the Qarmatians established a utopian republic in Eastern Arabia in 899. They considered the pilgrimage to Mecca a superstition and once in control of the Bahraini state they launched raids along the pilgrim routes crossing the Arabian Peninsula. In 906 they ambushed the pilgrim caravan returning from Mecca and massacred 20,000 pilgrims.
Qatar is mentioned in 13th-century Muslim scholar Yaqut al-Hamawi's book, "Mu'jam Al-Buldan (Dictionary of Countries)", which alludes to the Qataris' fine striped woven cloaks and their skills in improvement and finishing of spears, known as khattiyah spears. The spears acquired their name as an homage to the region of Al-Khatt which encompassed present-day Qatif, Uqair and Qatar.
Post-Islamic Golden Age.
Usfurids and Ormus control (1253–1515).
Much of Eastern Arabia was controlled by the Usfurids in 1253, but control of the region was later seized by the prince of Ormus in 1320. Qatar's pearls provided the kingdom with one of its main sources of income. The Portuguese defeated the Ormus by 1507 following the destruction of their fleet by Afonso de Albuquerque's forces. However, Albuquerque's captains grew rebellious and he was compelled abandoned the Ormus island. Ultimately, in 1515, King Manuel I killed Reis Hamed, pressuring Sultan Saifuddin to become a vassal of King Manuel.
Portuguese and Ottoman control (1521–1670).
Bahrain and mainland Qatar had been seized by the Portuguese in 1521. After the Portuguese were in control, they constructed a series of fortresses along the Arabian Coast. However, there have been no significant Portuguese ruins found in Qatar. The Portuguese focused on creating a commercial empire in Eastern Arabia, and exported gold, silver, silks, cloves, amber, horses and pearls. The population of Al-Hasa submitted voluntarily to the rule of the Ottomans in 1550, preferring them to the Portuguese.
The Portuguese were expelled from the area in 1602 by the Dutch and British. With no opposing major force in the area, the Ottomans saw little need to maintain a military presence in Al-Hasa. As a result, the Ottomans were expelled by the Bani Khalid in 1670.
Rule of Bani Khalid (1670–1783).
Having expelled the Ottomans, the Bani Khalid held jurisdiction over Qatar from 1670 onward. In 1766, the Utub tribes of Al Jalahma and Al Khalifa migrated from Kuwait to Zubarah in Qatar. After the Persian Occupation of Basra in 1777 many merchants and families moved from Basra and Kuwait to Zubarah. The town became a thriving center of trade and pearling in the Persian Gulf region after this movement.
The Al Khalifa claimed Qatar and Bahrain by 1783, but Bani Khalid control of neighboring Al-Hasa officially came to an end in 1795.
Al Khalifa control (1783–1792).
By the time of the Utub's arrival in Zubarah in 1776, the Bani Khalid exercised weak power over Qatar, though the largest village was ruled by distant kin of the Bani Khalid.
Following Persian aggression towards Zubarah, the Utub and other Arab tribes drove out the Persians from Bahrain in 1783. Al Jalahma seceded from the Utub alliance sometime before the Utub annexed Bahrain in 1783 and returned to Zubarah. This left the Al Khalifa tribe in undisputed possession of Bahrain, who had then transferred their power base from Zubarah to Manama. They also exerted authority over the mainland and paid tribute to the Wahhabi to ward off challenges on Qatar. However, Qatar did not develop a centralized authority because the Al Khalifa oriented their focus towards Bahrain. As a result, Qatar went through many periods of 'transitory sheikhs', with the most notable being Rahmah ibn Jabir al-Jalahimah. By 1790, Zubarah was described as a safe heaven for merchants who enjoyed complete protection and no customs duties.
Following the swearing in of Saud ibn Abd al-Aziz as crown prince of the Wahhabi in 1788, he moved to expand his empire's territory east-ward into the Persian Gulf. In 1792, amid strong resistance in Al-Hasa, Sulaiman ibn Ufaisan led a raid against Qatar and subjugated the region's population.
Wahhabi control (1792–1811).
The coastal towns of Zubarah and Huwailah were besieged by the Wahhabi in 1795 in response to the former providing shelter for refugees from Al-Hasa. After defeating the Bani Khalid in 1795, the Wahhabi were attacked on two fronts. The Ottomans and Egyptians assaulted the western front, while the Al Khalifa in Bahrain and the Omanis launched an attack against the eastern front. The Wahhabi allied themselves with the Al Jalahmah in Qatar, who then engaged the Al Khalifa and Omanis on the eastern frontier.
Upon being made aware of advancements by the Egyptians on the western frontier, in 1811, the Wahhabi amir reduced his garrisons in Bahrain and Zubarah in order to re-position his troops. Said bin Sultan of Muscat capitalized on this opportunity and attacked the Wahhabi garrisons in Bahrain and Zubarah. The fort in Zubarah was set ablaze and the Al Khalifa were effectively returned to power.
19th–20th centuries.
Al Khalifa control (1811–1868).
Britain's desire for secure passage for East India Company ships led it to impose its own order in the Persian Gulf. An agreement known as the General Maritime Treaty was signed between the East India Company and the sheikhs of the coastal area (later to be known as the Trucial Coast) in 1820. It acknowledged British authority in the Persian Gulf and sought to end piracy and the slave trade. Bahrain became a party to the treaty, and it was assumed that Qatar, as a dependency, was also a party to it.
A report compiled by Major Colebrook in 1820 gives the first descriptions of the major towns in Qatar. All of the coastal cities mentioned in his report were situated near the Persian Gulf pearl banks and had been practicing pearl fishing for millenniums. Until the late eighteenth century, all of the principal towns of Qatar including Al Huwaila, Fuwayrit, Al Bidda and Doha were situated on the east coast. Doha developed around the largest of these, Al Bidda. The population consisted of nomadic and settled Arabs and a significant proportion of slaves brought from East Africa. As punishment for piracy committed by the inhabitants of Doha, an East India Company vessel bombarded the town in 1821. They razed the town, forcing between 300 and 400 natives to flee.
A survey carried out by the British in 1825 notes that Qatar did not have a central authority and was governed by local sheikhs. Doha was ruled by the Al-Buainain tribe. In 1828, a member of the Al-Buainain named Mohammed bin Khamis murdered a native of Bahrain, prompting the Bahraini sheikh to imprison the offender. The Al-Buainain tribe revolted, provoking the Al Khalifa to destroy their fort and expel them from Doha. The latter gained additional jurisdiction in the town after the tribe's expulsion.
Residents of the peninsula were susceptible to skirmishes between the forces of the sheikh of Bahrain and the Egyptian military commander of Al-Hasa, owing to the volatile relations between the two parties. At the end of 1839 or beginning of 1840, the governor of Al Hasa dispatched troops to lay waste to Qatar following the Al Nuaim tribe's refusal to pay the demanded tribute. The assassination of a governor in Hofuf prematurely ended the expedition before the forces could reach the country.
In 1847, Abdullah bin Ahmed Al Khalifa and a prominent Qatari chief named Isa bin Tarif formed a coalition against Mohammed bin Khalifa, the ruler of Bahrain. In November, bin Khalifa landed in Al Khor with 500 troops and support from the governors of Qatif and Al-Hasa. The opposition forces numbered 600 troops and were led by bin Tarif. On 17 November, a decisive battle, which came to be known as the "Battle of Fuwayrit", took place between the coalition forces and the Bahraini forces. The coalition forces were defeated after bin Tarif and eighty of his men were killed. After he defeated the resistance troop, bin Khalifa demolished Al Bidda and moved all of its inhabitants to Bahrain. He sent his brother, Ali bin Khalifa, as an envoy to Al Bidda. However, he did not exercise any administrative powers, and local tribal leaders remained responsible for local and external affairs in Qatar.
Wahhabi contention.
Desiring to keep surveillance over the proceedings of the Wahhabi, Bahrain stationed a government official named Abdullah bin Ahmad Al-Khalifa on the coast of Qatar as early as 1833. With his help, the people of Al Huwailah revolted against the Al Khalifa opened up a correspondence with the Wahhabi in 1835. Shortly after the revolt, a peace agreement was signed by both parties under the mediation of the son of the Sultan of Muscat. As part of the stipulations, Al Huwailah was demolished and its residents were removed to Bahrain. Nephews of Abdullah bin Ahmed almost immediately violated the agreement when they incited members of the Al Kuwari tribe to attack Al Huwailah. A dependent of Isa bin Tarif, a prominent leader among the people of Al Huwailah, died in a naval encounter during this incident.
Having concocted a plan to invade Bahrain, the Wahhabi amir Faisal bin Turki left his headquarters in Najd with a platoon of troops in February 1851. Several offers of appeasement were made on behalf of Mohammed bin Khalifa, but these were met with rejections by Faisal. Accordingly, Ali bin Khalifa moved to enlist military support in Qatar, but Mohammed bin Thani was persuaded to grant support to Faisal's forces when they reached Al Bidda in May. On June 8, forces loyal to Al Thani took possession of an important tower situated close to Ali bin Khalifa's residence in the Al Bidda fort. Bahrain attempted to negotiate a protective treaty with the British for the sake of halting Faisal's advances. They were initially unsuccessful in doing so, but the British reconsidered their position after receiving an intelligence report on the conflict. They promptly situated a naval blockade in Manama. In July, the Wahhabi allied tribe Al Qays attacked an Al Khalifa naval blockade and lost over 150 men in the encounter. Accompanied with a peace treaty, the sheikh of Bahrain agreed to pay a fee of 4,000 German krones in return for the restoration of an Al Bidda fort and the disassociation of the Wahhabi from the inhabitants of Qatar on 25 July 1851.
In a move which angered Mohammed bin Khalifa, Faisal bin Turki relocated Abdullah bin Ahmed's sons to Dammam in 1852. In response, bin Khalifa attempted to drive away residents of Al Bidda and Doha who were suspected of being loyal to the Wahhabi by imposing an economic blockade on the inhabitants which prevented them from engaging in pearl fishing. The blockade continued until the end of 1852. In February 1853, the Wahhabi began marching from Al-Hasa to Al Khor. After receiving assurance from the Qataris that they would not cooperate with them if they crossed into their borders, Bahrain sent Ali bin Khalifa to the mainland to act as a collaborator with the local resistance. A British-mediated peace agreement was reached between the two parties in 1853.
Hostilities were provoked again after the Bahraini sheikh, in response to the harboring of Bahraini fugitivese in Dammam, stopped paying tribute to the Wahhabi amir in 1859 and proceeded to instigate Qatari tribes to attack its subjects. After Abdullah bin Faisal threatened to attack Bahrain, the British navy dispatched a ship off the coast of Dammam to prevent any attacks. The situation escalated in May 1860 when Abdullah threatened to occupy the coast of Qatar until the annual tribute was paid. In May 1861, Bahrain signed a treaty with the British government in which the latter agreed to offer protection and recognize Qatar as a dependent of Bahrain.
In February 1862, the treaty was ratified by the Indian government. Proceeding the agreement, the sway that the Al Khalifa tribe held over Qatar's affairs began declining. Mohammed bin Thani was described by Gifford Palgrave as the acknowledged governor of the Qatar Peninsula in 1863. Some of Al Wakrah's inhabitants were forced to vacate the town by the Bahraini sheikh in April 1863 due to alleged links with the Wahhabi. The town's chief, Mohammed Bu Kuwara, was taken into custody on a similar charge. In 1866, a report by the British revealed that Qatar was paying an annual zakat of 4,000 German krones to the Wahhabi, in encroachment of the 1861 British treaty. The report also contended that the Al Khalifa were taxing the people of Qatar the same annual tax.
Qatari–Bahraini War.
In June 1867, a representative of Mohammed Al Khalifa seized a Bedouin from Al Wakrah and deported him to Bahrain. Mohammed bin Thani demanded his release, but the representative refused. This prompted Mohammed bin Thani to expel the representative from his headquarters in Al Wakrah. Upon receiving news of this, Mohammed Al Khalifa released the Bedouin prisoner and expressed his desire of renewed peace talks. Jassim bin Mohammed Al Thani, the son of Mohammed bin Thani, traveled to Bahrain on his behalf. He was imprisoned on arrival and a large number of ships and troops were soon sent to punish the people of Al Wakrah and Al Bidda. Abu Dhabi joined on Bahrain's behalf due to the conception that Al Wakrah served as a refuge for fugitives from Oman. Later that year, the combined forces sacked the two aforementioned Qatari cities with 2,000 men in what would come to be known as the Qatari–Bahraini War. A British record later stated "that the towns of Doha and Wakrah were, at the end of 1867 temporarily blotted out of existence, the houses being dismantled and the inhabitants deported". In June 1868, Qatari tribes retaliated against Bahrain and a battle ensued in which 60 boats were sunk and 1000 men were killed. Afterwards, the Bahraini sheikh agreed to free Jassim bin Mohammed in return for captured Bahraini prisoners. This attack, and the Qatari counterattack, prompted the British political agent, Colonel Lewis Pelly, to impose a settlement in 1868. Pelly's mission to Bahrain and Qatar and the peace treaty that resulted were milestones in Qatar's history. It implicitly recognized the distinctness of Qatar from Bahrain and explicitly acknowledged the position of Mohammed bin Thani as an important representative of the Peninsula's tribes.
Ottoman control (1871–1915).
The Ottoman Empire expanded into Eastern Arabia in 1871. After establishing themselves on Al-Hasa coast, they advanced towards Qatar. Al Bidda soon came to serve as a base of operations for Bedouins harassing the Ottomans in the south, and Abdullah II Al-Sabah of Kuwait was sent to the town to secure a landing for the Ottoman troops. He brought with him four Ottoman flags for the most influential personages in Qatar. Mohammed bin Thani received and accepted one of the flags, but he sent it to Al Wakrah and continued hoisting the Arab flag above his house. Jassim bin Mohammed accepted a flag and flew it above his house. A third flag was given to Ali bin Abdul Aziz, the ruler of Al Khor. The British reacted negatively to the Ottoman's advancements, which they perceived as unjustified. Receiving no response to their objections, the British gunboat Hugh Rose arrived in Qatar on 19 July 1971. After inspecting the situation, Sidney Smith, the assistant political resident in the Gulf, discovered that Qatar flew the flags willingly. To further add to their apprehension, Jassim bin Mohammed, who assumed his father's role during this period, authorized the Ottomans to send 100 troops and equipment to Al Bidda in December 1871. By January 1872, the Ottomans incorporated Qatar into their dominion. It was designated a province in Najd under the control of the sanjak of Najd. Jassim bin Mohammed was appointed as the Kaymakam (sub-governor) of the district, and most other Qataris were allowed to keep their positions in the new government.
Assistant political resident Charles Grant falsely reported that the Ottomans sent a contingent of 100 troops from Qatif to Zubarah under the command of Hossein Effendi in August 1873. The sheikh of Bahrain reacted negatively to this because the Al Nuaim tribe which resided in Zubarah had signed a treaty agreeing to be subjects of his. Upon being confronted by the sheikh, Grant referred him to political resident Edward Ross. Ross informed the sheikh that he believed he had no right to protect tribes residing in Qatar. In September, the sheikh reiterated his sovereignty over the town and tribe. Grant replied by arguing that there was no special mention of the Al Nuaim or Zubarah in any treaties signed with Bahrain. A government official agreed with his views and concurred "that it was desirable that the Chief of Bahrain should, as far as practicable abstain from interfering in complications on the mainland."
Another chance arose for the Al Khalifa to renew their claim on Zubarah in 1874 after an opposition leader named Nasir bin Mubarak moved to Qatar. They believed that Mubarak, with the assistance of Jassim bin Mohammed, would target the Al Nuaim living in Zubarah as a prelude to an invasion. As a result, a contingent of Bahraini reinforcements were sent to Zubarah, much to the disapproval of the British who suggested that the sheikh was involving himself in complications. Edward Ross made it apparent that a government council decision advised the sheikh that he should not interfere in the affairs of Qatar. The Al Khalifa remained in consistent contact with the Al Nuaim, drafting 100 members of the tribe in their army and offering financial assistance. Jassim bin Mohammed expelled some members of the tribe after they attacked ships near Al Bidda in 1878.
Despite the opposition of many prominent Qatari tribes, Jassim bin Mohammed continued to show support for the Ottomans. However, there were no signs of improvement in the partnership between the two parties, and relations further deteriorated when the Ottomans refused to aid Jassim in his expedition of Abu Dhabi-occupied Al Khor in 1882. In addition, the Ottomans supported the Ottoman subject Mohammed bin Abdul Wahab who attempted to supplant Jassim bin Mohammed in 1888.
Battle of Al Wajbah.
In February 1893, Mehmed Hafiz Pasha arrived in Qatar in the interests of seeking unpaid taxes and accosting Jassim bin Mohammed's opposition to proposed Ottoman administrative reforms. Fearing that he would face death or imprisonment, Jassim bin Mohammed moved to Al Wajbah (10 miles west of Doha); he was accompanied by several tribe members. Mehmed demanded that he disband his troops and pledge his loyalty to the Ottomans. However, Jassim bin Mohammed remained adamant in his refusal to comply with Ottoman authority. In March 1893, Mehmed imprisoned his brother, Ahmed bin Mohammed Al Thani, in addition to 13 prominent Qatari tribal leaders on the Ottoman corvette "Merrikh". After Mehmed declined an offer to release the captives for a fee of ten thousand liras, he ordered a column of approximately 200 Ottoman troops to advance towards Jassim bin Mohammed's fortress in Al Wajbah under the command of Yusuf Effendi.
Shortly after arriving to Al Wajbah, Effendi's troops came under heavy gunfire by Qatari infantry and cavalry troops, which totaled 3,000 to 4,000 men. They retreated to Shebaka fortress, where they once again sustained casualties from a Qatari incursion. After they retreated to the fortress of Al Bidda, Jassim bin Mohammed's advancing column besieged the fortress and cut off the water supply of the neighborhood. The Ottomans conceded defeat and agreed to relinquish the Qatari captives in return for the safe passage of Mehmed Pasha's cavalry to Hofuf by land. Although Qatar did not gain full independence from the Ottoman Empire, the result of the battle forced a treaty that would later form the basis of Qatar emerging as an autonomous separate country within the empire.
20th–21st centuries.
British protectorate (1916–1971).
The Ottomans officially renounced sovereignty over Qatar in 1913, and in 1916 the new ruler Abdullah bin Jassim Al Thani signed a treaty with Britain, thereby instating the area under the trucial system. This meant that Qatar relinquished its autonomy in foreign affairs, such as the power to cede territory, and other affairs, in exchange for Britain's military protection from external threats. The treaty also had provisions suppressing slavery, piracy, and gunrunning, but the British were not strict about enforcing those provisions.
Despite Qatar coming under British protection, Abdullah bin Jassim's position was insecure. Recalcitrant tribes refused to pay tribute; disgruntled family members intrigued against him; and he felt vulnerable to the designs of Bahrain and the Wahhabi. The Al Thani were merchant princes, reliant on trade and especially the pearl trade, and dependent on other tribes to do their fighting for them, primarily the Bani Hajer who owed their allegiance to Ibn Saud, amir of the Najd and Al-Hasa. Despite numerous requests by Abdullah bin Jassim for strong military support, weapons, and a loan, the British were reluctant to become involved in inland affairs. This changed in the 1930s, when competition for oil concessions in the region intensified.
Oil drilling.
The scramble for oil raised the stakes in regional territorial disputes and signified the need to establish territorial borders. The first move came in 1922 at a boundary conference in Uqair when prospector Major Frank Holmes attempted to include Qatar in an oil concession he was discussing with Ibn Saud. Sir Percy Cox, the British representative, saw through the ploy and drew a line on the map separating the Qatar Peninsula from the mainland. The first oil survey took place in 1926 under the direction of George Martin Lees, a geologist contracted to the Anglo-Persian Oil Company, but no oil was found. The oil issue raised its head again in 1933 after an oil strike in Bahrain. Lees had already noted that, in such an eventuality, Qatar should be investigated again. After lengthy negotiations on 17 May 1935, Abdullah bin Jassim signed a concession agreement with Anglo-Persian representatives for a period of 75 years in return for 400,000 rupees on signature and 150,000 rupees per annum with royalties. As part of the agreement, Great Britain made more specific promises of assistance than they had in earlier treaties. Anglo-Persian transferred the concession to the IPC subsidiary company Petroleum Development (Qatar) Ltd. in order to meet its obligations under the Red Line Agreement.
Bahrain claimed rule over a group of islands encompassing the two countries in 1936. The largest island was Hawar Islands, situated off the west coast of Qatar, where the Bahrainis had established a small military garrison. Britain accepted the Bahraini claim over Abdullah bin Jassim's objections, in large part because the Bahraini sheikh's personal British adviser was able to phrase their case in a legal manner familiar to British officials. In 1937, the Bahrainis again laid claim to the deserted town of Zubarah after being involved in a dispute involving the Al Nuaim tribe. Abdullah bin Jassim sent a large, heavily armed force and succeeded in defeating the Al Nuaim. The British political resident in Bahrain supported Qatar's claim and warned Hamad ibn Isa Al Khalifa, the ruler of Bahrain, not to intervene militarily. Indignant over the loss of Zubarah, Hamad ibn Isa imposed a crushing embargo on trade and travel to Qatar.
Drilling of the first oil well began in Dukhan in October 1938 and over a year later, the well struck oil in the Upper Jurassic limestone. Unlike the Bahraini strike, this was similar to Saudi Arabia’s Dammam field discovered three years before. Production was halted between 1942 and 1947 because of World War II and its aftermath. The disruption of food supplies caused by the war prolonged a period of economic hardship in Qatar which began in the 1920s with the collapse of the pearl trade and was exacerbated in the early 1930s with the onsets of the Great Depression and the Bahraini embargo. As was the case in previous times of privation, entire families and tribes moved to other parts of the Persian Gulf, leaving many Qatari villages deserted. Abdullah bin Jassim went into debt and groomed his favored second son, Hamad bin Abdullah Al Thani, to be his successor in preparation for his retirement. However, Hamad bin Abdullah's death in 1948 led to a succession crisis in which the main candidates were Abdullah bin Jassim's eldest son, Ali bin Abdullah Al Thani, and Hamad bin Abdullah's teenage son, Khalifa bin Hamad Al Thani.
Oil exports and payments for offshore rights began in 1949 and marked a turning point in Qatar. The oil revenues would dramatically transform the economy and society and would also provide the focus for domestic disputes and foreign relations. This became apparent to Abdullah bin Jassim when several of his relatives threatened armed opposition if they did not receive increases in their allowances. Aged and anxious, Abdullah bin Jassim turned to the British. He promised to abdicate and agreed to an official British presence in Qatar in exchange for recognition and support of Ali bin Abdullah as ruler in 1949.
Under British tutelage, the 1950s witnessed the development of government structures and public services. Ali bin Abdullah was at first reluctant to share power, which had centered in his household, with an infant bureaucracy run and staffed mainly by outsiders. Ali bin Abdullah's increasing financial difficulties and inability to control striking oil workers and obstreperous sheikhs led him to succumb to British pressure. The first official budget was drawn up by a British adviser in 1953. By 1954 there were forty-two Qatari government employees.
Protests and reforms.
Large numbers of protests against the British and the ruling family occurred during the 1950s. One of the largest protests took place in 1956; it drew 2,000 participants, most of whom were high-ranking Qataris allied with Arab nationalists and dissatisfied oil workers. During another protest which took place in August 1956, the participants waved Egyptian flags and chanted anti-colonialism slogans. In October 1956, protesters tried to sabotage oil pipelines in the Persian Gulf by destroying the pipelines with a bulldozer. These were major impetuses to the development of the British-run police force which was established by the British in 1949. The demonstrations led Ali bin Abdullah to invest the police with his personal authority and support. This was a significant reversal of his previous reliance on his retainers and Bedouin fighters.
Public services developed slowly during the 1950s. The first telephone exchange opened in 1953, the first desalination plant in 1954, and the first power plant in 1957. Also built in this period were a dock, a customs warehouse, an airstrip, and a police headquarters. In the 1950s, 150 adult males of the ruling family received grants from the government. Sheikhs also received land and government positions. This mollified them as long as oil revenues increased. However, when revenues declined in the late 1950s, Ali bin Abdullah could not handle the family pressures this engendered. Discontent was fueled by his residence in Switzerland, extravagant spending, and hunting trips in Pakistan, especially among those who were excluded from the regime's largesse (non-Al Thani Qataris) and among other branches of Al Thani who desired more privileges. Seniority and proximity to the sheikh determined the size of allowances.
Succumbing to family pressures and poor health, Ali bin Abdullah abdicated in 1960. Instead of handing power over to Khalifa bin Hamad, who had been named heir apparent in 1948, he made his son, Ahmad bin Ali, ruler. Nonetheless, Khalifa bin Hamad gained considerable power as heir apparent and deputy ruler, in large part because Ahmad bin Ali spent much time outside the country. One of his first acts was to increase funding for the sheikhs at the expense of development projects and social services. In addition to allowances, adult male Al Thani were given government positions. This added to the anti-regime resentment already felt by, among others, oil workers, low-ranking Al Thani, dissident sheikhs, and some leading government officials. These individuals formed the National Unity Front in response to a fatal shooting of a protester on 19 April 1963 by one of Sheikh Ahmad bin Ali's nephews. While the Saudi monarch was at the ruler's palace on 20 April 1963, a demonstration occurred in front of the building. Police fired and killed three demonstrators, prompting the National Unity Front to organize a general strike on 21 April. The strike lasted around two weeks, and most public services were affected.
The group made a statement that week where it listed 35 of its demands to the government entailing less authority for the ruling family; protection for oil workers; recognition of trade unions; voting rights for citizens and the Arabization of the leadership. Ahmed bin Ali rejected most of these demands and moved to arrest and detain fifty of the most prominent National Unity Front members and sympathizers without trial in early May. The government also instituted some reforms in response to the movements. This included the provision of land and loans to poor farmers, instituting a policy of preferential hiring of Qatari citizens, and the election of a municipal council.
The infrastructure, foreign labor force, and bureaucracy continued to grow in the 1960s, largely under the instruction of Khalifa bin Hamad. There were also some early attempts at diversifying Qatar's economic base, most notably with the establishment of a cement factory, a national fishing company, and small-scale agriculture.
Independence (1971–present).
In 1968 Britain announced its intention of withdrawing its military commitments east of Suez, including those in force with Qatar, by 1971. The rulers of Bahrain, Qatar and the Trucial Coast contemplated forming a federation after the British withdrawal. However, a dispute arose between Ahmad bin Ali and Khalifa bin Hamad because Khalifa bin Hamad opposed Bahrain's attempts to become the senior partner in the federation. Still giving public support to the federation, Ahmad bin Ali nonetheless promulgated a provisional constitution in April 1970 which declared Qatar an independent Arab Islamic state with the Sharia as its basic law. Khalifa bin Hamad was appointed prime minister in May. The first Council of Ministers was sworn in on 1 January 1970 and seven of its ten members were Al Thani. Khalifa bin Hamad's argument prevailed with regard to the federation proposal.
Qatar declared its independence on 1 September 1971 and became an independent state on 3 September. When Ahmad bin Ali issued the formal announcement from his Swiss villa instead of from his palace in Doha, many Qataris were convinced that it was time for a change in leadership. On 22 February 1972, Khalifa bin Hamad deposed Ahmad bin Ali when he was on a hunting trip in Iran. Khalifa bin Hamad had the tacit support of the Al Thani and Britain and also had the political, financial and military support of Saudi Arabia.
In contrast to his predecessor's policies, Khalifa bin Hamad cut family allowances and increased spending on social programs, including housing, health, education, and pensions. In addition, he filled many top government posts with close relatives. In 1993, Khalifa bin Hamad remained the Emir, but his son, Hamad bin Khalifa, the heir apparent and minister of defense, had taken over much of the day-to-day running of the country. The two consulted with each other on all matters of importance.
On 27 June 1995, deputy emir Sheikh Hamad bin Khalifa deposed his father Khalifa in a bloodless coup. An unsuccessful counter-coup was staged in 1996. The emir and his father are now reconciled, although some supporters of the counter-coup remain in prison. The emir announced his intention for Qatar to move toward democracy and permitted more liberal press and municipal elections as a precursor to expected parliamentary elections. A new constitution was approved via public referendum in April 2003 and came into effect in June 2005. Economic, social, and democratic reforms have occurred in recent years. In 2003, a woman was appointed to the cabinet as minister of education.
Qatar and Bahrain have had disputes over the ownership of Hawar Islands since the mid-20th century. In 2001, the International Court of Justice awarded Bahrain sovereignty over Hawar Islands while allotting Qatar sovereignty over smaller disputed islands and the Zubarah region in mainland Qatar. During the trial, Qatar provided the court with 82 forged documents to substantiate their claims of sovereignty over the territories in question. These claims were withdrawn at a later stage after Bahrain discovered the forgeries. In June 2013, Sheikh Hamad Bin Khalifa stepped down as emir and transferred leadership to his son and heir Sheikh Tamim bin Hamad Al Thani.

</doc>
<doc id="25188" url="http://en.wikipedia.org/wiki?curid=25188" title="Geography of Qatar">
Geography of Qatar

Qatar is a peninsula in the east of Arabia, bordering the Persian Gulf and Saudi Arabia, in a strategic location near major petroleum deposits. Qatar occupies 11,437 km2 on a peninsula that extends approximately 160 km north into the Persian Gulf from the Arabian Peninsula. Varying in width between 55 and, the land is mainly flat (the highest point is 103 m) and rocky. Notable features include coastal salt pans, elevated limestone formations (the Dukhan anticline) along the west coast under which lies the Dukhan oil field, and massive sand dunes surrounding Khawr al Udayd, an inlet of the Persian Gulf in the southeast known to local English speakers as the Inland Sea. Of the islands belonging to Qatar, Halul is the most important. Lying about 90 km east of Doha, it serves as a storage area and loading terminal for oil from the surrounding offshore fields. Hawar and the adjacent islands immediately off the west coast are the subject of a territorial dispute between Qatar and Bahrain.
The capital, Doha, is located on the central east coast on a sweeping (if shallow) harbor. Other ports include Umm Said, Al Khawr, and Al Wakrah. Only Doha and Umm Said are capable of handling commercial shipping, although a large port and a terminal for loading natural gas are planned at Ras Laffan Industrial City, north of Al Khawr. Coral reefs and shallow coastal waters make navigation difficult in areas where channels have not been dredged.
Qatar has one land border. The country borders Saudi Arabia to the south. The boundary with Saudi Arabia was settled in 1965 but never demarcated. Qatar's northwest coast is fewer than 30 km from the main islands of Bahrain, while the small Hawar Islands of Bahrain are only 1.4 km (0.8 mi) off that coast.
Doha is the capital of the country and the major administrative, commercial, and population center. In 1993 it was linked to other towns and development sites by a system of about 1,000 km of paved roads. Doha's international airport has an approximately 4,500 m main runway, capable of receiving all kinds of aircraft.
Geographic coordinates: 
Climate.
The long summer (May through September) is characterized by intense heat and alternating dryness and humidity, with temperatures reaching 50 °C. Temperatures are moderate from November to May, although possibly falling to 5 °C. Rainfall is negligible, averaging 100 mm per year, confined to the winter months, and falling in brief, sometimes heavy storms that often flood the small ravines and the usually dry wadis. Sudden, violent dust storms occasionally descend on the peninsula, blotting out the sun, causing wind damage, and temporarily disrupting transport and other services.
The scarcity of rainfall and the limited underground water, most of which has such a high mineral content that it is unsuitable for drinking or irrigation, restricted the population and the extent of agricultural and industrial development the country could support until desalination projects began. Although water continues to be provided from underground sources, most is obtained by desalination of seawater.
Vegetation zones.
Although most of the country consists of sand deserts, a small part of the country houses different vegetation zones, where trees, reeds and shrubs like tamarind, phragmites, and mace can grow. These regions are mostly to the east, near the coast.
Area and land boundaries.
Area:
<br>"total:"
11,437 km2
<br>"land:"
11,437 km2
<br>"water:"
0 km2
Land boundaries:
<br>"total:"
60 km
<br>"border countries:"
Saudi Arabia 60 km
Coastline:
563 km
Maritime claims:
<br>"contiguous zone:"
24 nmi
<br>"exclusive economic zone:"
as determined by bilateral agreements, or the median line
<br>"territorial sea:"
12 nmi
Elevation extremes:
<br>"lowest point:"
Persian Gulf 0 m
<br>"highest point:"
Qurayn Abu al Bawl 103 m
Resources and land use.
Natural resources:
petroleum, natural gas, fish
Land use:
<br>"arable land:"
1%
<br>"permanent crops:"
0%
<br>"permanent pastures:"
5%
<br>"forests and woodland:"
0%
<br>"other:"
94% (1993 est.)
Irrigated land:
80 km2 (1993 est.)
Environmental concerns.
Natural hazards:
haze, dust storms, sandstorms common
Environment - current issues:
limited natural fresh water resources are increasing dependence on large-scale desalination facilities
Environment - international agreements:
<br>"party to:"
Biodiversity, Climate Change, Desertification, Hazardous Wastes, Law of the Sea, Ozone Layer Protection 
<br>"signed, but not ratified:" none of the selected agreements

</doc>
<doc id="25189" url="http://en.wikipedia.org/wiki?curid=25189" title="Demographics of Qatar">
Demographics of Qatar

Natives of the Arabian Peninsula, many Qataris are descended from a number of migratory tribes that came to Qatar in the 18th century to escape the harsh conditions of the neighboring areas of Nejd and Al-Hasa. Some are descended from Omani tribes. Qatar has over 2.2 million people, the majority of whom (about 90%) live in Doha, the capital. Foreign workers with temporary residence status make up almost 90% of the population, with Indians being the largest community numbering around 545,000. As of 2014, there were a further 400,000 Nepalis, 200,000 Filipinos, 180,000 Egyptians, 150,000 Bangladeshis, 100,000 Sri Lankans and 90,000 Pakistanis among .
The Qataris are mainly Sunni Muslims. Islam is the official religion, and Islamic jurisprudence is the basis of Qatar's legal system. Arabic is the official language and English is the lingua franca of business. Urdu is also widely spoken, especially by the South Asian foreign workers. Education is compulsory and free for all residents 6–16 years old. Qatar has an increasingly high literacy rate.
Ethnicity.
Qataris can be divided into three ethnic groups: Bedouins, Hadar, and Abd. Bedouins are descended from the nomads of the Arabian Peninsula. The Hadar are mostly descended from Iran, Pakistan, and Afghanistan and are occasionally referred to as "Irani-Qataris". The Abd are descendants of slaves brought from East Africa, namely Sudan and Somalia (the ones bought from Somalia originally hailed from the Swahili coast).
CIA World Factbook demographic statistics.
The following demographic statistics are from the CIA World Factbook, unless otherwise indicated.
Population.
2,123,160 (July 2014 est.) Qatar is the 146th most populated nation.
Age structure.
"0–14 years:" 21.8% (male 92,896/female 87,201)
"15–64 years:" 76.8% (male 451,127/female 182,330)
"65 years and over:" 1.4% (male 6,545/female 4,690) (2008 est.)
Population growth rate.
1.093% (2008 est.)
<br> 9.56% – World Bank (2009 est.)
<br> 3.58% – CIA World FactBook (2014 est.)
<br> 2.11% – 2005–2010 List by the United Nations
Sex ratio.
At birth: 1.02 male(s)/female
<br>0–14 years: 1.03 male(s)/female
<br>15–24 years: 2.83 male(s)/female
<br>25–54 years: 4.61 male(s)/female
<br>55–64 years: 3.41 male(s)/female
<br>65 years and over: 1.5 male(s)/female
<br>total population: 3.29 male(s)/female (2013 est.)
Life expectancy at birth.
"Total population:"
75.19 years
<br>"male:"
73.5 years
<br>"female:"
76.98 years (2008 est.)
Total fertility rate.
2.08 children born/woman (2010 est.) (Qataris: 3.59, Foreign nationals: 1.75)
Nationality.
"noun:"
Qatari(s)
<br>"adjective:"
Qatari
Ethnic groups.
Arab (40%) is the largest ethnic group in Qatar. At 18% each, Indian and Pakistani are the largest ethnic minorities. The remainder of the population is Iranian (10%) and other (14%).
Religions.
Islam 71–77.5%, Christian 8.5–10.3%, Hindu 7.2–12.7%, Buddhist 5%, other 1%
Languages.
Arabic (official), English (commonly used as a second language).
Genetics.
Y-chromosome DNA.
Y-Chromosome DNA Y-DNA represents the male lineage, The Qatari Y-chromosome in large belongs to haplogroup J which comprises two thirds of the total chromosomes
Mitochondrial DNA.
Mitochondrial DNA mtDNA represents the female lineage The Qatari mitochondrial DNA shows much more diversity than the Y-DNA lineages, with more than 35% of the lineages showing African ancestry (East African & Subsaharan) & the rest of the lineages being Eurasian.

</doc>
<doc id="25190" url="http://en.wikipedia.org/wiki?curid=25190" title="Politics of Qatar">
Politics of Qatar

The political system of Qatar is an absolute monarchy, with the Emir of Qatar as head of state and head of government. Under the 2003 constitutional referendum it should become a constitutional monarchy. Sharia Law is the main source of Qatari legislation according to Qatar's Constitution.
Legal system.
Sharia law is the main source of Qatari legislation according to Qatar's Constitution. Sharia law is applied to laws pertaining to family law, inheritance, and several criminal acts (including adultery, robbery and murder). In some cases in Sharia-based family courts, a female's testimony is worth half a man's and in some cases a female witness is not accepted at all. Codified family law was introduced in 2006. In practice, Qatar's legal system is a mixture of civil law and Islamic law.
Flogging is used in Qatar as a punishment for alcohol consumption or illicit sexual relations. Article 88 of Qatar's criminal code declares the punishment for adultery is 100 lashes. Adultery is punishable by death when a Muslim woman and a non-Muslim man are involved. In 2006, a Filipino woman was sentenced to 100 lashes for adultery. In 2010, at least 18 people (mostly foreign nationals) were sentenced to flogging of between 40 and 100 lashes for offences related to “illicit sexual relations” or alcohol consumption. In 2011, at least 21 people (mostly foreign nationals) were sentenced to floggings of between 30 and 100 lashes for offences related to “illicit sexual relations” or alcohol consumption. In 2012, six expatriates were sentenced to floggings of either 40 or 100 lashes. Only Muslims considered medically fit were liable to have such sentences carried out. It is unknown if the sentences were implemented. More recently in April 2013, a Muslim expatriate was sentenced to 40 lashes for alcohol consumption. In June 2014, a Muslim expatriate was sentenced to 40 lashes for consuming alcohol and driving under the influence. Judicial corporal punishment is common in Qatar due to the Hanbali interpretation of Sharia Law.
Stoning is a legal punishment in Qatar. Apostasy is a crime punishable by the death penalty in Qatar. Blasphemy is punishable by up to seven years in prison and proselytizing can be punished by up to 10 years in prison. Homosexuality is a crime punishable by the death penalty for Muslims.
Alcohol consumption is partially legal in Qatar, some five-star luxury hotels are allowed to sell alcohol to their non-Muslim customers. Muslims are not allowed to consume alcohol in Qatar and Muslims caught consuming alcohol are liable to flogging or deportation. Non-Muslim expatriates can obtain a permit to purchase alcohol for personal consumption. The Qatar Distribution Company (a subsidiary of Qatar Airways) is permitted to import alcohol and pork; it operates the one and only liquor store in the country, which also sells pork to holders of liquor licences. Qatari officials have also indicated a willingness to allow alcohol in "fan zones" at the 2022 FIFA World Cup.
Until recently, restaurants on the Pearl-Qatar (a man-made island near Doha) were allowed to serve alcoholic drinks. In December 2011, however, restaurants on the Pearl were told to stop selling alcohol. No explanation was given for the ban. Speculation about the reason includes the government's desire to project a more pious image in advance of the country's first election of a royal advisory body and rumours of a financial dispute between the government and the resort's developers.
In 2014, Qatar launched a modesty campaign to remind tourists of the modest dress code. Female tourists are advised not to wear leggings, miniskirts, sleeveless dresses and short or tight clothing in public. Men are advised against wearing only shorts and singlets.
As of 2014, certain provisions of the Qatari Criminal Code allows punishments such as flogging and stoning to be imposed as criminal sanctions. The UN Committee Against Torture found that these practices constituted a breach of the obligations imposed by the UN Convention Against Torture. Qatar retains the death penalty, mainly for threats against national security.
Under the provisions of Qatar's sponsorship law, sponsors have the unilateral power to cancel workers' residency permits, deny workers' ability to change employers, report a worker as "absconded" to police authorities, and deny permission to leave the country. As a result, sponsors may restrict workers’ movements and workers may be afraid to report abuses or claim their rights. According to the ITUC, the visa sponsorship system allows the exaction of forced labour by making it difficult for a migrant worker to leave an abusive employer or travel overseas without permission. Qatar also does not maintain wage standards for its immigrant labour. Qatar commissioned international law firm DLA Piper to produce a report investigating the immigrant labour system. In May 2014 DLA Piper released over 60 recommendations for reforming the kafala system including the abolition of exit visas and the introduction of a minimum wage which Qatar has pledged to implement.
Cases of ill-treatment of immigrant labour have been observed. The Nepalese ambassador to Qatar, Maya Kumari Sharma, described the emirate as an "open jail".
Qatar does not have national occupational health standards or guidelines, and workplace injuries are the third highest cause of accidental deaths. In May 2012, Qatari officials declared their intention to allow the establishment of an independent trade union. Qatar also announced it will scrap its sponsor system for foreign labour, which requires that all foreign workers be sponsored by local employers, who in some cases hold workers' passports and can deny them permission to change jobs.
Executive branch.
In Qatar, the ruling Al Thani (ال ثاني) family continued to hold power following the declaration of independence in 1971. The head of state is the Emir, and the right to rule Qatar is passed on within the Al Thani family. Politically, Qatar is evolving from a traditional society into a modern welfare state. Government departments have been established to meet the requirements of social and economic progress. The Basic Law of Qatar 1970 institutionalized local customs rooted in Qatar's conservative Islamic heritage, granting the Emir preeminent power. The Emir's role is influenced by continuing traditions of consultation, rule by consensus, and the citizen's right to appeal personally to the Emir. The Emir, while directly accountable to no one, cannot violate the Sharia (Islamic law) and, in practice, must consider the opinions of leading notables and the religious establishment. Their position was institutionalized in the Advisory Council, an appointed body that assists the Emir in formulating policy. There is no electoral system. Political parties are banned.
The influx of expatriate Arabs has introduced ideas that call into question the tenets of Qatar's traditional society, but there has been no serious challenge to Al Thani rule.
In February 1972, the Deputy Ruler and Prime Minister, Sheikh Khalifa bin Hamad Al Thani, deposed his cousin, Emir Ahmad, and assumed power. This move was supported by the key members of Al Thani and took place without violence or signs of political unrest.
On 27 June 1995, the Deputy Ruler, Sheikh Hamad bin Khalifa Al Thani, deposed his father, Emir Khalifa, in a bloodless coup. Emir Hamad and his father reconciled in 1996. Increased freedom of the press followed, and the Qatar-based Al Jazeera television channel (founded late 1996) is widely regarded as an example of free and uncensored source of news in Arab countries.
On 25 June 2013 Tamim bin Hamad Al Thani became the Emir of Qatar after his father Hamad bin Khalifa Al Thani handed over power in a televised speech.
Ministries.
Source: Ministry of Interior
Consultative Assembly.
The Consultative Assembly ("Majlis as-Shura") has 35 appointed members with only consultative tasks. However, the 2003 Constitution of Qatar calls for a 45 member elected Legislature, which is to be made up of 30 elected representatives and 15 appointed by the Emir. In 2006, Prime Minister Al Thani – then the Deputy PM – announced that elections would be held in 2007. However, only a legislative council to review the subject was created that year. The actual elections have been postponed three times; most recently in June 2010, when the Emir extended the Consultative Assembly's tenure until 2013.
Political parties and elections.
Qatar held a constitutional referendum in 2003, which was overwhelmingly supported. The first municipal elections with men and women voters and candidates were held in 2007 and 2011. The first legislative election, for two thirds of the legislative council's 45 seats, are planned for 2013.
Suffrage is currently limited to municipal elections and two thirds of the seats in the legislative council, with the voting age set at 18. Expatriate residents are excluded, as are the vast number of residents who are prevented from applying for citizenship. The elected Municipal Council has no executive powers but may offer advice to the Minister.
Human rights.
The Qatari authorities keep a relatively tight rein on freedom of expression and moves for equality. The Freedom in the World 2010 report by Freedom House lists Qatar as "Not Free", and on a 1–7 scale (1 being the most "free") rates the country a 6 for political rights and 5 for civil liberties. s of 2011[ [update]], the Democracy Index describes Qatar as an "authoritarian regime" with a score of 3.18 out of ten, and it ranks 138th out of the 167 countries covered.
Administrative divisions.
9 municipalities (baladiyat, singular - baladiyah); Ad Dawhah, Al Ghuwayriyah, Al Jumayliyah, Al Khawr, Al Wakrah, Al Rayyan, Jarayan al Batinah, Madinat ash Shamal, Umm Salal.
Foreign relations.
On October 10, 2005, for the first time, Qatar was elected to a two-year term on the UN Security Council for 2006–2007.
According to BBC, in April 2006 Qatar announced that it will give US$50 million (£28 million) to the new Hamas-led Palestinian government. Hamas, an ally of Iran and Hezbollah, is considered by the US and the EU to be a terrorist organization.
In May 2006, Qatar pledged more than $100 million to Hurricane Katrina relief to colleges and universities in Louisiana affected by the hurricane. Some of this money was also distributed to families looking to repair damaged homes by Neighborhood Housing Services of New Orleans, Inc.
With the advent of the Arab Spring in 2011, Qatar has been seen as meddling in the affairs of other Arab countries, supporting insurgents, generally and increasingly radical Islamists and Salafists. This policy has led to rebukes by neighboring Gulf states such as Saudi Arabia, Bahrain, and the United Arab Emirates. Qatar joined NATO operations in Libya and reportedly armed Libyan opposition groups. It is also became a major provider of money and support for rebel groups in the Syrian civil war. With close ties to the Muslim Brotherhood the emirate's funding for rebels strongly favored Islamic and Salafist forces in both Libya and Syria.
The government of Qatar owns the Al Jazeera television network. The network has been accused of being biased and taking an active role in the affairs of other countries specifically during the Arab Spring in 2011. Numerous countries have complained about biased reporting in support of Qatar policy.
Most of the developed countries (plus Brunei and Indonesia) are exempt from visa requirements. Citizens of exempted countries can also request a joint visa that allows them to travel to Oman as well.
Qatar is member of ABEDA, AFESD, AL, AMF, ESCWA, FAO, G-77, GCC, IAEA, IBRD, ICAO, ICRM, IDB, IFAD, IFRCS, IHO (pending member), ILO, IMF, International Maritime Organization, Inmarsat, Intelsat, Interpol, IOC, ISO (correspondent), ITU, NAM, OAPEC, OIC, OPCW, OPEC, UN, UNCTAD, UNESCO, UNIDO, UPU, WCO, WHO, WIPO, WMO, and WTO.

</doc>
<doc id="25191" url="http://en.wikipedia.org/wiki?curid=25191" title="Economy of Qatar">
Economy of Qatar

Petroleum and liquefied natural gas are the cornerstones of Qatar's economy and account for more than 70% of total government revenue, more than 60% of gross domestic product, and roughly 85% of export earnings. Proved oil reserves of 15 billion barrels (588,000,000 m3) should ensure continued output at current levels for 23 years. Oil has given Qatar a per capita GDP that ranks among the highest in the world. Qatar's proved reserves of natural gas exceed 7000 km3, more than 5% of the world total and the third-largest reserves of any country in the world. Production and export of natural gas are becoming increasingly important. Long-term goals include the development of off-shore petroleum and the diversification of the economy.
Macro-economic trend.
Qatar is now the richest country in the world. Current GDP per capita registered a world record-breaking peak growth of 1,156% in the 70s. This became quickly unsustainable and Qatar's current GDP per capita contracted 53% in the 80s. But rising global oil demand helped current GDP per capita to expand 94% in the 90s. Diversification is still a long-term issue for this over-exposed economy.
This is a table of gross domestic product of Qatar at market prices estimated by the International Monetary Fund with figures in millions of Qatari Rials.
For purchasing power parity comparisons, the US Dollar is exchanged at 5.82 Qatari Riyals only. Mean wages were $59.99 per manhour in 2009.
In February 2012, the International Bank of Qatar reported that GDP grew by 19.9% in 2011, but estimated that 2012 growth would slow to 9.8%
Energy sector.
Before the emergence of petrol-based industry, Qatar was a poor pearl fishing country. The exploitation of oil and gas fields began in 1939. In 1973, oil production and revenues increased dramatically, moving Qatar out of the ranks of the world's poorest countries and providing it with one of the highest per capita incomes in the world.
Qatar's economy was in a downturn from 1982 to 1989. OPEC (Organization of Petroleum Exporting Countries) quotas on crude oil production, the lower price for oil, and the generally unpromising outlook on international markets reduced oil earnings. In turn, the Qatari government's spending plans had to be cut to match lower income. The resulting recessionary local business climate caused many firms to lay off expatriate staff. With the economy recovering in the 1990s, expatriate populations, particularly from Egypt and South Asia, have grown again.
Oil production will not long remain at peak levels of 500,000 barrels (80,000 m³) per day, as oil fields are projected to be mostly depleted by 2023. However, large natural gas reserves have been located off Qatar's northeast coast. Qatar's proved reserves of gas are the third-largest in the world, exceeding 7000 km³ (250 trillion cubic feet). The economy was boosted in 1991 by completion of the $1.5-billion Phase I of North Field gas development. In 1996, the Qatargas project began exporting liquefied natural gas (LNG) to Japan. Further phases of North Field gas development costing billions of dollars are in various stages of planning and development.
Qatar's heavy industrial projects, all based in Umm Said, include a refinery with a 50,000 barrels (8,000 m³) per day capacity, a fertilizer plant for urea and ammonia, a steel plant, and a petrochemical plant. All these industries use gas for fuel. Most are joint ventures between European and Japanese firms and the state-owned Qatar General Petroleum Corporation (QGPC). The U.S. is the major equipment supplier for Qatar's oil and gas industry, and U.S. companies are playing a major role in North Field gas development.
890-
Qatar pursues a vigorous program of "Qatarization", under which all joint venture industries and government departments strive to move Qatari nationals into positions of greater authority. Growing numbers of foreign-educated Qataris, including many educated in the U.S., are returning home to assume key positions formerly occupied by expatriates. In order to control the influx of expatriate workers, Qatar has tightened the administration of its foreign manpower programs over the past several years. Security is the principal basis for Qatar's strict entry and immigration rules and regulations.
Industry.
The government considers industry to be an integral part of its plan to diversify the economy and maximise its huge natural gas reserves, which serve as the primary feedstock for the sector. Accordingly, careful planning has gone into industrial development. With an eye towards exports, development has been clustered around the ports of Ras Laffan and Mesaieed, which are also key centres of energy. The result has seen considerable growth over the years. Industries Qatar (IQ), a producer of petrochemicals, fertilisers and steel, is a regional powerhouse, surpassed only in size by Saudi Basic Industries Corporation (SABIC), the Middle East’s largest chemical producer. In 2007 the manufacturing sector made the third-largest contribution to GDP among non-oil and gas sectors, equivalent to about 7.5% of GDP. Petrochemicals and fertilisers supply make up a large portion of the industrial base, along with steel and other construction materials, through Qatar Steel and Qatar Primary Material Company (QPMC). Indeed over the past few years, demand for construction materials experienced a major surge as the development boom swept the Gulf. But the global financial crisis has put a significant dent in demand in the region, as project credit lines dry up and investor sentiment remains cautious. The crisis has in fact impacted the whole of the industrial sector – IQ saw its net profit drop in the fourth quarter of 2008 more than 90% over the same period the previous year. But in relative terms, the sector has fared better than most and IQ still managed to post an annual profit of $2bn. Large profit chunks from years past have been channelled into capital investments, which should help the sector ride out the storm. IQ, for example, is pushing several major expansion projects, worth almost $6bn, ahead. Qatar is expected to be one of the fastest growing economies in 2009 – the hope is it will be enough to keep the industrial sector on an upward trajectory.
Financial sector.
The Qatari banking sector managed to escape the direct impact of the global subprime fallout, but was not altogether unscathed by its aftershocks. Overall, it was the best performing of the Gulf Cooperation Council markets in the last quarter of 2008 and most banks posted substantial profits for 2008. But the sector is also facing issues of liquidity, declining customer confidence and a forced reluctance to lend. In a bid to strengthen the banks’ positions, the Qatar Investment Authority (QIA) announced in early 2009 that it was willing to take a 10-20% stake in any interested local listed banks by way of a capital injection, although this was later reduced to 5% stakes and an additional 5% at the end of 2009. The Qatari government also announced in March 2009 that it was planning to buy the investment portfolio of the banks in the hope this would encourage them to continue lending. Cautious sector sentiment has also been compounded by the Qatar Central Bank’s (QCB’s) lending restrictions, which demand a loan-to-deposit ratio of 90%. Given the high level of integration between Qatar’s economy and the Gulf region, as well as the wider world, a slowdown in business and banking activity seemed inevitable. Nevertheless, Qatar’s banking sector has been faring relatively well, considering the strife experienced in other countries, and insiders are confident that activity will return to its previous brisk pace in the second half of 2009 as confidence slowly rebuilds around the globe.
Islamic finance.
The Islamic finance sector enjoyed increased activity in 2008 and is expected to continue to grow into 2009 as more sophisticated financial instruments spark the interest of investors. In addition to Islamic banks, such as Qatar Islamic Bank (QIB), Qatar International Islamic Bank (QIIB) and newcomer Al Masraf Al Rayyan, conventional banks have also been entering the sharia-compliant sector and are coming to view an Islamic subsidiary as a virtual necessity in order to maintain market standing. Islamic banks currently take the lion’s share of sharia-compliant business, though the conventional banks are working hard to take a greater share of market activity. Both Islamic banks and Islamic subsidiaries did remarkably well in the first three quarters of 2008, during which overall financing activity increased by 70.6% compared to the same period in the previous year. The global financial crisis has certainly thrown a dampener on this growth, though. Poor market conditions have contributed to a marked slowdown of Islamic bond, or sukuk, activity in 2008 throughout the Gulf. But other segments, such as Islamic insurance, or takaful, have not seen a similar downturn. In fact, takaful still shows significant room for expansion as it currently makes up less than 20% of the total insurance market. Overall, challenges to further growth remain, including a lack of qualified staff to meet the growing demand for sharia-compliant banking services. In order to compete with the conventional banking sector and expand its customer base, Islamic banks need to invest in suitable human resources.
Capital market.
The stock market capitalisation of listed companies in Qatar was valued at $95,487 million in 2007 by the World Bank. . As 2008 drew to a close, no capital markets around the globe, including Qatar’s, were immune to the effects of the sub-prime fallout. That said, there is considerable optimism that Qatar’s bourse, the Doha Securities Market (DSM), will remain relatively resilient to the ongoing international turbulence. It has followed the same peak-trough trajectory as many others around the globe, hitting record highs in mid-2008, before diving in late 2008 and early 2009. Between December 2006 and July 2008 the DSM Index rose about 117% before the global financial crisis wiped out most of these gains. In the first few months of 2009, the DSM lost about 40% of its value. In an effort to stave off further losses, the government announced in February 2009 that it would step in to buy up shares of troubled banks amounting to about 10% of the market’s capitalisation. The move dramatically improved investor optimism and is hoped to prevent the market from falling further. The proposal to create a single unified regulator as early as 2010 to oversee all banking and financial services is viewed as another promising development that will dramatically transform the financial sector for the better. Underlining these developments is strong optimism that the solid base of Qatar’s economy, which has maintained a favourable outlook, will be enough to buoy capital markets and lure shaken-up investors back to the trading floor.
Tourism.
Under the ambitious five-year development plan of the Qatar Tourism and Exhibitions Authority (QTEA), the government aims to boost the number of visitors from 964,000 as of 2007 to 1.5m by 2010. The funding needed to meet this goal is certainly there – in 2008 the state allocated some $17bn for tourism development through 2014, most of which is going towards hotels, exhibition space and infrastructure. In order to keep up with a rising number of visitors, the government hopes to increase hotel capacity 400% by 2012. In addition to financial support, the government has also worked to ease business regulations in a bid to increase private sector activity. A major aspect of expansion plans is the New Doha International Airport (NDIA), which will have the capacity to handle up to 24m passengers upon the completion of the first phase in 2012. Considering the vast majority of these visitors are members of the business community, the government has naturally targeted the meetings, incentives, conferences and exhibitions segment as a viable source of development, with two new convention centres slated to open in 2011. Other niche tourism segments receiving special focus include cultural tourism on the back of the recent headline-grabbing opening of Doha’s Museum of Islamic Art, and sports tourism, initially spurred by the Asian Games, to which Qatar played host in 2006. The government appears to be committed to long-term expansion plans, but challenges nevertheless remain, including effective marketing to the international community as well as the effect of the financial crisis on global tourism appetite.
Transport.
With a fast-expanding population and substantial economic growth over the past decade, a reliable and extensive transportation network is becoming increasingly necessary within Qatar. So far the government, the primary transport developer, has done well in terms of keeping up with demand for new transportation options. In 2008 the Public Works Authority (Ashghal), one of the bodies that oversees infrastructure development, underwent a major reorganisation in order to streamline and modernise the authority in preparation for major project expansions across all segments in the near future. Ashghal works in tandem with the Urban Planning and Development Authority (UPDA), the body that designed the transportation master plan, instituted in March 2006 and running to 2025.
As driving is the primary mode of transport in Qatar, the road network is a major focus of the plan. Project highlights in this segment include the multibillion-dollar Doha Expressway and the Qatar Bahrain Causeway, which will connect Qatar to Bahrain and Saudi Arabia and is considered a milestone in regional interconnectivity. Mass-transit options, such as a Doha metro, light-rail system and more extensive bus networks, are also under development to ease road congestion. In addition, the railway system is being significantly expanded and could eventually form an integral part of a GCC-wide network linking all the Gulf states. The airport, too, is expanding capacity to keep up with rising visitor numbers. The New Doha International Airport is one of the largest projects in Qatar today and will boast a capacity of 50m passengers upon completion in 2015. Finally, port infrastructure is seen as an integral part of Qatar’s economic development as it focuses on LNG and industrial exports. The port at Mesaieed is undergoing expansion and will be able to handle around 1m twenty-foot-equivalent units by 2020. While the financial crisis may present challenges to infrastructure development, once all projects are up and running Qatar will have one of the most advanced and modern transport infrastructures in the region.

</doc>
<doc id="25192" url="http://en.wikipedia.org/wiki?curid=25192" title="Telecommunications in Qatar">
Telecommunications in Qatar

Telephones - main lines in use:
205,400 (2005)
Telephones - mobile cellular:
1,000,000 (2007)
Telephone system:
modern system centered in Doha
<br>"domestic:"
NA
<br>"international:"
tropospheric scatter to Bahrain; microwave radio relay to Saudi Arabia and UAE; submarine cable to Bahrain and UAE; satellite earth stations - 2 Intelsat (1 Atlantic Ocean and 1 Indian Ocean) and 1 Arabsat
Radio broadcast stations:
AM 6, FM 5, shortwave 1 (1998)
Radios:
256,000 (1997)
Television broadcast stations:
1 (plus three repeaters) (1997)
Televisions:
230,000 (1997)
Internet.
Internet Service Providers (ISPs):
Q-Tel: now called ooredoo http://www.ooredoo.qa/
Vodafone as well offeres fixed, leased, and mobile Internet connectivity. http://www.vodafone.qa
Internet users:
75,000 (2001)
Country code (Top level domain): QA
ADSL launched 2002 in Qatar provided by ooredoo with 25000 ADSL users with ooredoo in the process of upgrading to Fibre which will provide higher bandwidth at the same prices as ADSL.
Speeds:
Links:

</doc>
<doc id="25193" url="http://en.wikipedia.org/wiki?curid=25193" title="Transport in Qatar">
Transport in Qatar

This article is about transport in Qatar.
Public transport.
In 2002, the Qatari government launched Mowasalat, a company 100% owned by the government, managed and operated by the state authorities to ensure the smooth provision of "integrated ground transport services" for the entire country with a growing population of more than 1,400,000 people. Previously, 3,000 privately owned orange taxis used to rule the streets of Qatar but the government took them off the roads as they saw them as a threat to the new Mowasalat taxis. There has been much controversy over this move, as it is now very hard to find a taxi in Doha.
Public buses now service over 35 routes covering most locations of Doha with minimal fares making public transport in Qatar a thrifty solution to the problems of rush hours and parking difficulties.
Presently, Mowasalat, under the brand-name 'Karwa', now operates more than 3,000 new and well-maintained taxi sedans including the recently acquired airport taxis with spacious cabins using the 2007 Ford Freestars, and more than 120 public buses, school buses and private-hire coaches. In 2009, the Mowasalat created a world record for the largest parade of buses numbering 300 in all. In addition, its Doha Limousine Service has 100 standard (unbranded, no Karwa logo) limousines and 200 (Jaguar XJ) VIP units that are mostly placed at the Doha International Airport and at major hotels.
However, those who are with no own transportation still face difficulties to move around since the number of taxis are much less compared to the actual need of the increased population. All the line buses operate only through the assigned specific lines based to the Central Bus Stations at Al-Ghanem area of the old city.
Railways.
There are currently no railways in Qatar.
In August 2008 Qatari Diar Real Estate Investment created a Joint-Venture with Deutsche Bahn International of Germany, Qatar Railway Development Company to plan a railway network in Qatar.
On 22 November 2009 Deutsche Bahn and Qatari signed a memorandum of Agreement to build high-speed railway lines and underground transport networks in Qatar and Bahrain. This agreement has never been executed.
The Qatar Railways Development Company (QRDC) was created in 2011, and, soon after this, it has been decided that Qatar Rail will be the sole owner and manager of Qatar’s rail network and will be responsible for the design, construction, commissioning, operation and maintenance of the entire rail network and systems. However,
Qatar Rail will consist of:
The total length of the Qatar Rail network will consist of approximately: 
In June 2013, Qatar Rail awarded four design and build contracts worth approximately $8.2 billion for phase one of the Doha metro. The project will include four rail lines and an underground section in the center of the capital Doha and will link stadiums for the 2022 World Cup soccer tournament. The contracts were for the Red Line North project, the Red Line South project, the Green Line project and another one to design and build the metro’s major stations. The projects are expected to employ more than 20,000 workers at its peak, construction is scheduled to begin later this year for completion by 2019. Construction of the metro was originally planned to start in the first quarter of 2010.
Highways.
Most of the main roads in this tiny country have been updated to multilane, double carriageway motorways, including the following:
Pipelines.
Crude Oil 235 km; Natural Gas 400 km
Airports.
Hamad International Airport is the only international passenger airport in Qatar. There are five other airfields in the country, three paved, two unpaved.
References.
 This article incorporates public domain material from websites or documents of the .
External links.
 Media related to at Wikimedia Commons

</doc>
<doc id="25194" url="http://en.wikipedia.org/wiki?curid=25194" title="Qatar Armed Forces">
Qatar Armed Forces

The Qatar Armed Forces are the military forces of Qatar. The country maintains a modest military force of approximately 11,800 men, including an army (8,500), navy (1,800) and air force (1,500). Qatar's defence expenditures were a total of $1.913 billion, about 1.5% of the national GDP, as of 2010 according to the SIPRI. Qatar has recently signed defence pacts with the United States in 2002 and 2013 and with the United Kingdom, as well as with France earlier in 1994. Qatar plays an active role in the collective defence efforts of the Gulf Cooperation Council; the other five members are Saudi Arabia, Kuwait, Bahrain, the UAE, and Oman. The presence of a large American military base in the country provides the country with a guaranteed source of defence and national security. SIPRI states that Qatar's plans to transform and significantly enlarge its armed forces have accelerated in 2014, and in 2010-14 Qatar was the 46th largest arms importer in the world. Orders in 2013 for 62 tanks and 24 self-propelled guns from Germany were followed in 2014 by a number of other contracts, including 24 combat helicopters and 3 AEW aircraft from the USA, and 2 tanker aircraft from Spain.
History.
Qatar took part in the Gulf War of 1991, with a battalion at the Battle of Khafji. It also hosted the 614th Tactical Fighter Squadron at Doha.
In July 2008, the US Defence Security Cooperation Agency announced Qatar’s official request for logistics support, training, and associated equipment and services. The total value of the support arrangements could be as high as $400 million.
In March 2011, Qatar announced the participation of its Air Force in the enforcement of the Libyan no-fly zone.
Army.
This is the largest branch of the Qatar Armed Forces. Qatar maintains a modest military force of approximately 11,800 men; the army is made of 8,500 men. The lack of sufficient indigenous manpower to staff the army is a continuing problem, Qatari citizens constitute only 30 percent of the army, in which more than twenty nationalities are represented.
Initially outfitted with British weaponry, Qatar shifted much of its procurement to France during the 1980s in response to French efforts to develop closer relations. The tank battalion is equipped with French-built AMX-30 main battle tanks. Other armored vehicles include French AMX-10P APCs and the French VAB, adopted as the standard wheeled combat vehicle. The artillery unit has a few French 155mm self-propelled howitzers. The principal antitank weapons are French Milan and HOT wire-guided missiles.
Qatar had also illicitly acquired a few Stinger shoulder-fired SAMs, possibly from Afghan rebel groups, at a time when the United States was trying to maintain tight controls on Stingers in the Middle East. When Qatar refused to turn over the missiles, the United States Senate in 1988 imposed a ban on the sale of all weapons to Qatar. The ban was repealed in late 1990 when Qatar satisfactorily accounted for its disposition of the Stingers.
Qatari tank battalion fought in the Gulf war in 1991, their AMX-30's took part in the battle of Khafji. Qatari contingent, composed mostly of Pakistani recruits, acquitted itself well during the war.
Qatar signed a contract with the German defence company Krauss-Maffei Wegmann (KMW) for the delivery of 24 artillery systems PzH 2000 and 62 LEOPARD 2 main battle tanks.
The US DSCA announces that Qatar wants to join its neighbor the UAE, and field 2 medium-range THAAD batteries of its own.
Their request is worth up to $6.5 billion, and includes up to 12 THAAD Launchers, 150 THAAD missiles, 2 THAAD Fire Control and Communications units, 2 AN/TPY-2 THAAD Radars, and 1 Early Warning Radar (EWR). The USA would also sell them the required trucks, generators, electrical power units, trailers, communications equipment, fire unit test & maintenance equipment, system integration and checkout, repair and return, training, and other support.
Qatar Emiri Air Force.
The Qatar Emiri Air Force was formed in 1974, three years after achieving independence from Great Britain in 1971. Initially equipped with ex-RAF Hawker Hunters, the air force soon began expansion with six Dassault/Dornier Alpha Jets in 1979. Fourteen Dassault Mirage F1 were delivered between 1980-84. After the Gulf War, Qatar's air force infrastructure was upgraded by France for $200 million, leading to the order of nine single seat Mirage 2000-5DEA multi-role combat aircraft and three two seat Mirage 2000-5DDA combat trainers in August 1994. Deliveries started in December 1997, and involved the buy back of the remaining 11 Mirage F1s by France that were later sold on to Spain., The current commander of the Qatar Emiri Air Force is Brigadier General Mubarak Mohammed Al Kumait Al Khayarin.
British pilots in Oman remain on duty with the air force, and French specialists are employed in a maintenance capacity. Nevertheless, an increasing number of young Qataris have been trained as pilots and technicians.
Its units include:
As of January 1993, all the air force's aircraft were based at Doha International Airport.
Air Force equipment.
Future aircraft.
In May 2015, the Air Force signed a deal for 24 Dassault Rafale fighters worth €6.3 billion ($7 billion). This deal makes Qatar the third export customer for the fighter after Egypt and India.
The Defense Security Cooperation Agency notified Congress April 16 of a possible Foreign Military Sale to Kuwait for 1 C-17 Globemaster III aircraft and associated equipment, parts, training and logistical support for an estimated cost of $371 million.
Navy.
Qatar has a small 1,800-man navy, including its marine police force and coastal defence artillery. Since 1990, the Qatari Navy has increased its manpower.
The navy headquarters is at Doha there is also a base at Halul island. The commander of the Navy is Commodore Mohammed Nasser al-Mohanadi.
Future Acquisitions.
The patrol boat program calls for the delivery of six patrol boats with the first unit beginning construction in 2012 and being delivered by 2014. Although the proposals for the corvette program are due in the near-term as well, AMI believes that the four corvettes may not begin construction for several more years as Damen/Nakilat may want to gain some experience with the smaller 62-meter patrol boat hulls prior to moving on the larger Sigma hulls. If the QENF wishes to move the corvette program forward to an earlier date, it could start some of the hull blocks at Nakilat and/or at Damen in the Netherlands much earlier.
The Qatar Coast Guard Services placed an order for 17 new fast patrol boast from Turkish company ARES Shipyard. The deal of 17 vessels consists in 10x "ARES 110 Hercules" multi-role patrol craft 117 tons, 5x "ARES 75 Hercules" multi-role patrol craft 58 tons and 2x "ARES 150 Hercules" multi-role patrol craft 245 tons. These Fast Patrol Boats will be constructed using advanced composite materials and are expected to be completed within the next 5 years.
March 31, 2014. Nakilat Damen Shipyards Qatar (NDSQ) and Qatar Armed Forces have signed two MoUs for the construction of seven vessels at Qatar’s premier shipyard ($851 million). The MoUs signed by NDSQ and Qatar Armed Forces concern six 50m-long axe-bow high-speed patrol vessels and one 52m-long diving support vessel for the Qatar Armed Forces. All vessels are highly sophisticated state-of-the-art naval ships built based on proven designs providing unparalleled seaworthiness. The diving support vessel includes decompression capabilities. A large Integrated Logistic Support package is also mentioned in the MoUs.

</doc>
<doc id="25195" url="http://en.wikipedia.org/wiki?curid=25195" title="Foreign relations of Qatar">
Foreign relations of Qatar

Qatar achieved full independence on 3 September 1971. Arab states were among the first to recognise Qatar, and the state promptly gained admittance to the United Nations and the Arab League. Qatar established diplomatic relations with the Soviet Union, and Communist China in 1988. The country was an early member of OPEC and a founding member of the Gulf Cooperation Council (GCC). Its policy and external relations are managed by its Ministry of Foreign Affairs. 
Breakthrough as an international player.
The Emir of Qatar was Sheikh Hamad bin Khalifa Al Thani from 1995 to 2013. He boosted Qatar's image as a serious Middle East foreign player. The first major move in this regard was the founding of Al-Jazeera. Qatar maintains close relationship with western powers--Al Udeid Air Base plays host to US and UK air forces—and eastern powers, and has often tried to bridge the gap between Muslim and non-Muslim states. Qatar has a population of around 1.8 million people, however only 280,000 of these are citizens; the majority of the population are foreigners who work and live in the state. It is also one of the few countries in which citizens do not have to pay any taxes. Qatar is a member of Organisation of Islamic Cooperation, Gulf Cooperation Council, OPEC and the Council of Arab Economic Unity.
Role in Arab world and conflict with other Gulf States.
Qatar has become an influential player in Arab world. Qatar supported several rebel groups during the Arab Spring both financially and by asserting global influence through its expanding news group, Al Jazeera.
Qatar's support for the Muslim Brotherhood and allied groups throughout the middle east, as well as positions taken by Al Jazeera have led to increasing tensions with other Gulf States. These came to a head during a March 2014 meeting of the Gulf Cooperation Council, after which the UAE, Saudi Arabia and Bahrain announced the recall of their ambassadors to Qatar 
Some financial economists have interpreted the 2014 Saudi-Qatari rift as the tangible political sign of a growing economic rivalry between oil and natural gas producers, which could “have deep and long-lasting consequences” beyond the MENA area
In March 2014 Qatar made overtures to Oman in order to counteract the influence of Saudi Arabia on politics in the region.
Other global activities.
Of late money, the Emirate has been tremendously active in the global realm. The Sudanese government and the strongest Darfur rebel group, the Justice and Equality Movement, signed an agreement in Doha. While Doha also took a tough stand in the reaction to the Israeli invasion of Gaza. Following this reaction and apparent closeness with Iran the 2009 Arab League summit in Doha was met with further controversy although Qatar was seen as emerging further with the follow-up Arab-Latin American (Latam) summit.
On 4 May 2009, the Qatari Minister of State for Foreign Affairs Ahmad Abdullah Al Mahmud said that Chad and Sudan had agreed to end hostilities against each other and to normalise relations Qatari mediated talks in Doha. However, the agreement soon broke down. Qatar hosted a donors conference to help rebuild war-ravaged Darfur in April 2013.
In June 2010, Qatari peacekeeping forces deployed in the disputed Ras Doumeira area on the border between Djibouti and Eritrea after the latter withdrew from the area. The intention was to help start bilateral negotiations and solve the territorial dispute which had previously turned violent.
Having been selected to host the 2022 FIFA World Cup, Qatar will be the first Middle Eastern country to host the FIFA World Cup. Qatar-funded Qatar Airways has gone on an aggressive expansion campaign by competing with nearby Emirates Airline to reach more destinations and serve more passengers. The Sixty-sixth session of the United Nations General Assembly was presided over by former permanent representative of Qatar to the UN Nassir Abdulaziz Al-Nasser.
In September 2013, Qatar funded 70% of a US$16 million mosque to be built in Slovenia (the only mosque in that country). It is due for completion in 2016. Due to its natural resource revenue and low indigenous population, Qatar has been able to take bold moves in expanding its global presence, particularly its regional role following the Arab Spring funding the oppositions in the Libyan Civil War and the Syrian civil war, as well as the Islamist government of Egypt (which was opposed by other fellow GCC states).
Bilateral relations.
According to Immanuel Wallerstein, Qatar is seeking to become a major player in the Middle East. As such the country played a crucial role in the Libyan Civil War, while seeking to do the same in the Syrian civil war, adding that Qatar and Saudi Arabia were in competition to be a more powerful regional player.
Afghanistan.
During the waning years of Operation Enduring Freedom in 2010 the United States and the Taliban initiated exploratory talks in regards to the ending the conflict in Afghanistan after the latter announced its intention to open an office in Doha. Though they were halted later amid Taliban accusations of malfeasance by the United States, President Hamid Karzai suggested the two parties had held daily talks in Qatar, although the U.S.and the Taliban denied it.
Bahrain.
The territorial dispute with Bahrain over the Hawar Islands and the maritime boundary dispute with Bahrain were solved by the International Court of Justice (ICJ) in The Hague. In the 2001 decision, Bahrain kept the Hawar Islands and Qit'at Jaradah but dropped claims to Janan Island and Zubarah on mainland Qatar, while Qatar retained significant maritime areas and their resources.
Brunei.
Brunei has an embassy in Doha, and Qatar has an embassy in Bandar Seri Begawan. Relations between the two countries was established on 2 October 1991.
France.
France maintains an embassy in Doha, while Qatar maintains an embassy in Paris.
In 2012, Qatar became France's seventh largest customer and sixth largest supplier in the Near East. Exports from France focus mainly on the supply of capital goods, deliveries of Airbus aircrafts, and trade. In May 2015, French President François Hollande and Qatari Emir Tamim bin Hamad Al Thani signed an agreement for Qatar to purchase 24 Dassault Rafale fighter jets to be used for reconnaissance missions.
Malaysia.
Malaysia has an embassy in Doha, and Qatar has an embassy in Kuala Lumpur.
Nepal.
The Nepalese ambassador to Qatar Maya Kumari Sharma described the emirate as an "open jail".
Philippines.
The Philippines and Qatar established diplomatic relations on 5 May 1981. As of 2014, about 200,000 Filipinos live in Qatar.
Zaire.
Qatar cut its relations with Zaire due to the latter's reestablishment of the diplomatic ties with Israel in May 1982.
Israel.
Qatar established trade relations with the State of Israel in 1996. In January 2008 Israeli Defense Minister Ehud Barak met with former Qatari Prime Minister Sheikh Abdullah bin Khalifa al-Thani in Switzerland, at the Davos Economic Forum. The existence of the surreptitious talks has so far been kept secretive by Israel. Despite Qatar's support of Hamas and its good relations with Hizbullah, Israeli leaders have maintained direct contact with the emirate. In January 2007, in his last months as vice premier, current President Shimon Peres paid a high-profile visit to the capital city of Doha. Peres visited Qatar in 1996, when he launched the new Israeli trade bureau there.
Israeli Foreign Affairs Minister Tzipi Livni met with the Qatari Emir at a UN conference. In April 2008, she visited Qatar where she attended a conference and met the Emir, the Prime Minister and the Minister of Oil and Gas.
Following the 2008–2009 Israel–Gaza conflict, Qatar hosted an emergency conference of Arab states and Iran to discuss the conflict. The Hamas administration in Gaza, as opposed to the Fatah-controlled Palestinian Authority in the West Bank, represented the Palestinians, undermining support for Palestinian President Mahmoud Abbas. Khalid Meshaal, the leader of Hamas, President Bashar al-Assad of Syria, and President Ahmadinejad of Iran urged all Arab states to cut any remaining ties to Israel. 
In 2010, Qatar twice offered to restore trade relations with Israel and allow the reinstatement of the Israeli mission in Doha, on condition that Israel allow Qatar to send building materials and money to Gaza to help rehabilitate infrastructure, and that Israel make a public statement expressing appreciation for Qatar's role and acknowledging its standing in the Middle East. Israel refused, on the grounds that Qatari supplies could be used by Hamas to build bunkers and reinforced positions from which to fire rockets at Israeli cities and towns, and that Israel did not want to get involved in the competition between Qatar and Egypt over the Middle East mediation.
On 30 April 2013, Qatari Prime Minister Sheikh Hamad bin Jassim al-Thani said that final status agreements with the Palestinians could involve land swaps instead of sticking to the 1967 borders. This was received positively in Israel with Justice Minister Tzipi Livni saying: "This news is very positive. In the tumultuous world around ... it could allow the Palestinians to enter the room and make the needed compromises and it sends a message to the Israeli public that this is not just about us and the Palestinians", adding that "peace between the Palestinians and the Israelis is ... a strategic choice for the Arab states".
Arab World.
In September 1992, tensions arose between Qatar and Saudi Arabia when Saudi forces allegedly attacked a Qatari border post, resulting in two deaths. Since the event relations have improved. A joint commission has been set up to demarcate the border as agreed between the two governments. Most, but not all, of the border issues have now been resolved. In 2010, the Emir became the first Arab leader to tour South Lebanon and view the various projects it funded following the 2006 Lebanon War. He inaugurated an hospital in Bint Jbeil and a nearby mosque and church, while accompanied by Lebanon's President Michel Sleiman and Prime Minister Saad al-Hariri. He also became the first international leader to visit the Gaza Strip.
During the Syrian Civil War, Qatar, along with Saudi Arabia, Turkey and western states, vocally and materially supported the rebels with arms and funds against the government. Qatar has been the biggest sponsor of opposition forces during the civil war.
Qatar provides an option for joint tourist visas that allows visitors to visit Qatar and Oman as well. 
Qatar's support for the Muslim Brotherhood across the MENA area, Hamas and extremist Islamists in Libya have led to increasing tensions with other Arab states of the Persian Gulf. On 5 March 2014, the three countries withdrew their ambassadors from Qatar in protest at what they called Qatar's non-compliance with a November 2013 agreement not to "interfere" in countries' internal affairs. In early 2014 Qatar and Saudi Arabia appeared to be exploring ways of ending the rift.

</doc>
<doc id="25198" url="http://en.wikipedia.org/wiki?curid=25198" title="Quaternary">
Quaternary

The Quaternary Period () is the current and most recent of the three periods of the Cenozoic Era in the geologic time scale of the International Commission on Stratigraphy (ICS). It follows the Neogene Period and spans from 2.588 ± 0.005 million years ago to the present. The Quaternary Period is divided into two epochs: the Pleistocene (2.588 million years ago to 11.7 thousand years ago) and the Holocene (11.7 thousand years ago to today). The informal term "Late Quaternary" refers to the past 0.5–1.0 million years.
The Quaternary period is typically defined by the cyclic growth and decay of continental ice sheets driven by Milankovitch cycles and the associated climate and environmental changes that occurred.
Research history.
The term Quaternary ("fourth") was proposed by Giovanni Arduino in 1759 for alluvial deposits in the Po River valley in northern Italy. It was introduced by Jules Desnoyers in 1829 for sediments of France's Seine Basin that seemed clearly to be younger than Tertiary Period rocks.
The Quaternary Period follows the Neogene Period and extends to the present. The Quaternary covers the time span of glaciations classified as the Pleistocene, and includes the present interglacial period, the Holocene.
This places the start of the Quaternary at the onset of Northern Hemisphere glaciation approximately 2.6 million years ago. Prior to 2009, the Pleistocene was defined to be from 1.805 million years ago to the present, so the current definition of the Pleistocene includes a portion of what was, prior to 2009, defined as the Pliocene.
Quaternary stratigraphers usually worked with regional subdivisions. From the 1970s, the International Commission on Stratigraphy (ICS) tried to make a single geologic time scale based on GSSP's, which could be used internationally. The Quaternary subdivisions were defined based on biostratigraphy instead of paleoclimate.
This led to the problem that the proposed base of the Pleistocene was at 1.805 Mya, long after the start of the major glaciations of the northern hemisphere. The ICS then proposed to abolish use of the name Quaternary altogether, which appeared unacceptable to the International Union for Quaternary Research (INQUA).
In 2009, it was decided to make the Quaternary the youngest period of the Cenozoic Era with its base at 2.588 Mya and including the Gelasian stage, which was formerly considered part of the Neogene Period and Pliocene Epoch.
The Anthropocene has been proposed as a third epoch as a mark of the anthropogenic impact on the global environment starting with the Industrial Revolution, or about 200 years ago. The Anthropocene is not officially designated by the ICS, however, but a working group is currently aiming to complete a proposal for the creation of an epoch or sub-period by 2016.
Geology.
The 2.6 million years of the Quaternary represents the time during which recognizable humans existed. Over this short time period, there has been relatively little change in the distribution of the continents due to plate tectonics.
The Quaternary geological record is preserved in greater detail than that for earlier periods.
The major geographical changes during this time period included the emergence of the Strait of Bosphorus and Skagerrak during glacial epochs, which respectively turned the Black Sea and Baltic Sea into fresh water, followed by their flooding (and return to salt water) by rising sea level; the periodic filling of the English Channel, forming a land bridge between Britain and the European mainland; the periodic closing of the Bering Strait, forming the land bridge between Asia and North America; and the periodic flash flooding of Scablands of the American Northwest by glacial water.
The current extent of Hudson Bay, the Great Lakes and other major lakes of North America are a consequence of the Canadian Shield's readjustment since the last ice age; different shorelines have existed over the course of Quaternary time.
Climate.
The climate was one of periodic glaciations with continental glaciers moving as far from the poles as 40 degrees latitude. There was a major extinction of large mammals in Northern areas at the end of the Pleistocene Epoch. Many forms such as saber-toothed cats, mammoths, mastodons, glyptodonts, etc., became extinct worldwide. Others, including horses, camels and American cheetahs became extinct in North America.
Quaternary glaciation.
Glaciation took place repeatedly during the Quaternary Ice Age – a term coined by Schimper in 1839 that began with the start of the Quaternary about 2.58 Mya and continues to the present-day.
Last glacial period.
In 1821, a Swiss engineer, Ignaz Venetz, presented an article in which he suggested the presence of traces of the passage of a glacier at a considerable distance from the Alps. This idea was initially disputed by another Swiss scientist, Louis Agassiz, but when he undertook to disprove it, he ended up affirming his colleague's hypothesis. A year later, Agassiz raised the hypothesis of a great glacial period that would have had long-reaching general effects. This idea gained him international fame and led to the establishment of the Glacial Theory.
In time, thanks to the refinement of geology, it has been demonstrated that there were several periods of glacial advance and retreat and that past temperatures on Earth were very different from today.
In particular, the Milankovitch cycles of Milutin Milankovitch are based on the premise that variations in incoming solar radiation are a fundamental factor controlling Earth's climate.
During this time, substantial glaciers advanced and retreated over much of North America and Europe, parts of South America and Asia, and all of Antarctica. The Great Lakes formed and giant mammals thrived in parts of North America and Eurasia not covered in ice. These mammals became extinct when the glacial period Age ended about 11,700 years ago. Modern humans evolved about 190,000 years ago (source: Leakey). During the Quaternary period, mammals, flowering plants, and insects dominated the land. 

</doc>
<doc id="25199" url="http://en.wikipedia.org/wiki?curid=25199" title="Quotation">
Quotation

A quotation is the repetition of one expression as part of another one, particularly when the quoted expression is well-known or explicitly attributed by citation to its original source, and it is indicated by (punctuated with) quotation marks.
A quotation can also refer to the repeated use of units of any other form of expression, especially parts of artistic works: elements of a painting, scenes from a movie or sections from a musical composition.
Misquotations.
Many quotations are routinely incorrect or attributed to the wrong authors, and quotations from obscure or unknown writers are often attributed to far more famous writers. Examples of this are Winston Churchill, to whom many political quotations of uncertain origin are attributed, and Oscar Wilde, to whom anonymous humorous quotations are sometimes attributed.
Deliberate misquotation is also common, though this often goes unnoticed, usually because the misquotation is better known or because the misquotation better fits a situation. For example, the "Star Trek" catchphrase "Beam me up, Scotty" did not appear in that form in the original series—likewise, the famous Dirty Harry quotation "Are you feeling lucky, punk?" is a rewording of the original dialogue: "You've got to ask yourself one question: 'Do I feel lucky?' Well, do ya punk?" Humphrey Bogart's character Rick in "Casablanca" never said "Play it again, Sam." The actual expression is "Play it, Sam." Darth Vader in "Star Wars IV" (for Blu-ray) says "No, I am your father" which George Lucas re-worded from the original expression "Luke, I am your father" from the original version of the film.
Reasons for using quotations.
Quotations are used for a variety of reasons: to illuminate the meaning or to support the arguments of the work in which it is being quoted, to provide direct information about the work being quoted (whether in order to discuss it, positively or negatively), to pay homage to the original work or author, to make the user of the quotation seem well-read, and/or to comply with copyright law. Quotations are also commonly printed as a means of inspiration and to invoke philosophical thoughts from the reader.
Common quotation sources.
Famous quotations are frequently collected in books that are sometimes called quotation dictionaries or treasuries. Of these, "Bartlett's Familiar Quotations", "The Oxford Dictionary of Quotations", "The Columbia Dictionary of Quotations", "The Yale Book of Quotations" and "The MacMillan Book of Proverbs, Maxims, and Famous Phrases" are considered among the most reliable and comprehensive sources. Diaries and calendars often include quotations for entertainment or inspirational purposes, and small, dedicated sections in newspapers and weekly magazines—with recent quotations by leading personalities on current topics—have also become commonplace.
Quotations and the Internet.
Chiefly a text medium in the beginning, the World Wide Web gave rise to any number of personal quotation collections that continue to flourish, even though very few of them seem to facilitate accurate information or correct citation. On June 27, 2003, a sister project of the Wikimedia Foundation called Wikiquote was created as a free online encyclopedia of quotations in every language and it is now the biggest single quotation collection in the world.
The increase of written means of informal communication brought about by the Internet has produced the practice of using quotations as personal flags, as in one's own signature block. This is most commonly seen in email messages and Usenet posts, while it is almost never seen in blog posts. Quotations are also popular as a user's personal message, a line under the user's nickname in some Instant Messaging clients (and here they often go uncited). In all these cases, quotations are usually included to give a glimpse of the user's personality, to make a statement of their beliefs, or to spread views and ideas.
The sheer bulk of online quotations, combined with more efficient search engines, has effectively made the Internet the world's quotation storehouse, encompassing an unprecedented number of easily obtainable quotations. Though matters of accuracy still remain, features such as Amazon.com's Search Inside the Book and Google Book Search may serve to alleviate such concerns.
United Kingdom copyright law.
Section 30(1) of the United Kingdom Copyright, Designs and Patents Act 1988 (apparently in transposition of Article 5(3)(d) of the EU Copyright Directive on quotations) allows fair dealing with a copyrighted work for the purpose of criticism or review, provided that it is accompanied by sufficient acknowledgement.

</doc>
<doc id="25202" url="http://en.wikipedia.org/wiki?curid=25202" title="Quantum mechanics">
Quantum mechanics

Quantum mechanics (QM; also known as quantum physics, or quantum theory) is a fundamental branch of physics which deals with physical phenomena at nanoscopic scales, where the action is on the order of the Planck constant. The name derives from the observation that some physical quantities can change only in "discrete" amounts (Latin "quanta"), and not in a continuous ("cf." analog) way. It departs from classical mechanics primarily at the "quantum realm" of atomic and subatomic length scales. Quantum mechanics provides a mathematical description of much of the dual "particle-like" and "wave-like" behavior and interactions of energy and matter. Quantum mechanics provides a substantially useful framework for many features of the modern periodic table of elements, including the behavior of atoms during chemical bonding, and has played a significant role in the development of many modern technologies.
In advanced topics of quantum mechanics, some of these behaviors are macroscopic (see macroscopic quantum phenomena) and emerge at only extreme (i.e., very low or very high) energies or temperatures (such as in the use of superconducting magnets). In the context of quantum mechanics, the wave–particle duality of energy and matter and the uncertainty principle provide a unified view of the behavior of photons, electrons, and other atomic-scale objects.
The mathematical formulations of quantum mechanics are abstract. A mathematical function, the wave function, provides information about the probability amplitude of position, momentum, and other physical properties of a particle. Mathematical manipulations of the wave function usually involve bra–ket notation, which requires an understanding of complex numbers and linear functionals. The wavefunction formulation treats the particle as a quantum harmonic oscillator, and the mathematics is akin to that describing acoustic resonance. Many of the results of quantum mechanics are not easily visualized in terms of classical mechanics. For instance, in a quantum mechanical model, the lowest energy state of a system, the ground state, is non-zero as opposed to a more "traditional" ground state with zero kinetic energy (all particles at rest). Instead of a traditional static, unchanging zero energy state, quantum mechanics allows for far more dynamic, chaotic possibilities, according to John Wheeler.
The earliest versions of quantum mechanics were formulated in the first decade of the 20th century. About this time, the atomic theory and the corpuscular theory of light (as updated by Einstein) first came to be widely accepted as scientific fact; these latter theories can be viewed as quantum theories of matter and electromagnetic radiation, respectively. Early quantum theory was significantly reformulated in the mid-1920s by Werner Heisenberg, Max Born and Pascual Jordan (matrix mechanics); Louis de Broglie and Erwin Schrödinger (wave mechanics); and Wolfgang Pauli and Satyendra Nath Bose (statistics of subatomic particles). Moreover, the Copenhagen interpretation of Niels Bohr became widely accepted. By 1930, quantum mechanics had been further unified and formalized by the work of David Hilbert, Paul Dirac and John von Neumann with a greater emphasis placed on measurement in quantum mechanics, the statistical nature of our knowledge of reality, and philosophical speculation about the role of the observer. Quantum mechanics has since permeated throughout many aspects of 20th-century physics and other disciplines including quantum chemistry, quantum electronics, quantum optics, and quantum information science. Much 19th-century physics has been re-evaluated as the "classical limit" of quantum mechanics and its more advanced developments in terms of quantum field theory, string theory, and speculative quantum gravity theories.
History.
Scientific inquiry into the wave nature of light began in the 17th and 18th centuries, when scientists such as Robert Hooke, Christiaan Huygens and Leonhard Euler proposed a wave theory of light based on experimental observations. In 1803, Thomas Young, an English polymath, performed the famous double-slit experiment that he later described in a paper entitled "On the nature of light and colours". This experiment played a major role in the general acceptance of the wave theory of light.
In 1838, Michael Faraday discovered cathode rays. These studies were followed by the 1859 statement of the black-body radiation problem by Gustav Kirchhoff, the 1877 suggestion by Ludwig Boltzmann that the energy states of a physical system can be discrete, and the 1900 quantum hypothesis of Max Planck. Planck's hypothesis that energy is radiated and absorbed in discrete "quanta" (or energy elements) precisely matched the observed patterns of black-body radiation.
In 1896, Wilhelm Wien empirically determined a distribution law of black-body radiation, known as Wien's law in his honor. Ludwig Boltzmann independently arrived at this result by considerations of Maxwell's equations. However, it was valid only at high frequencies and underestimated the radiance at low frequencies. Later, Planck corrected this model using Boltzmann's statistical interpretation of thermodynamics and proposed what is now called Planck's law, which led to the development of quantum mechanics.
Among the first to study quantum phenomena in nature were Arthur Compton, C.V. Raman, and Pieter Zeeman, each of whom has a quantum effect named after him. Robert A. Millikan studied the photoelectric effect experimentally, and Albert Einstein developed a theory for it. At the same time, Niels Bohr developed his theory of the atomic structure, which was later confirmed by the experiments of Henry Moseley. In 1913, Peter Debye extended Niels Bohr's theory of atomic structure, introducing elliptical orbits, a concept also introduced by Arnold Sommerfeld. This phase is known as old quantum theory.
According to Planck, each energy element ("E")" "is proportional to its frequency ("ν"):
where "h" is Planck's constant.
Planck cautiously insisted that this was simply an aspect of the "processes" of absorption and emission of radiation and had nothing to do with the "physical reality" of the radiation itself. In fact, he considered his quantum hypothesis a mathematical trick to get the right answer rather than a sizable discovery. However, in 1905 Albert Einstein interpreted Planck's quantum hypothesis realistically and used it to explain the photoelectric effect, in which shining light on certain materials can eject electrons from the material. He won the 1921 Nobel Prize in Physics for this work.
Einstein further developed this idea to show that an electromagnetic wave such as light could also be described as a particle (later called the photon), with a discrete quantum of energy that was dependent on its frequency.
The foundations of quantum mechanics were established during the first half of the 20th century by Max Planck, Niels Bohr, Werner Heisenberg, Louis de Broglie, Arthur Compton, Albert Einstein, Erwin Schrödinger, Max Born, John von Neumann, Paul Dirac, Enrico Fermi, Wolfgang Pauli, Max von Laue, Freeman Dyson, David Hilbert, Wilhelm Wien, Satyendra Nath Bose, Arnold Sommerfeld, and . In the mid-1920s, developments in quantum mechanics led to its becoming the standard formulation for atomic physics. In the summer of 1925, Bohr and Heisenberg published results that closed the old quantum theory. Out of deference to their particle-like behavior in certain processes and measurements, light quanta came to be called photons (1926). From Einstein's simple postulation was born a flurry of debating, theorizing, and testing. Thus, the entire field of quantum physics emerged, leading to its wider acceptance at the Fifth Solvay Conference in 1927.
It was found that subatomic particles and electromagnetic waves are neither simply particle nor wave but have certain properties of each. This originated the concept of wave–particle duality.
While quantum mechanics traditionally described the world of the very small, it is also needed to explain certain recently investigated macroscopic systems such as superconductors, superfluids, and large organic molecules.
The word "quantum" derives from the Latin, meaning "how great" or "how much". In quantum mechanics, it refers to a discrete unit assigned to certain physical quantities such as the energy of an atom at rest (see Figure 1). The discovery that particles are discrete packets of energy with wave-like properties led to the branch of physics dealing with atomic and subatomic systems which is today called quantum mechanics. It underlies the mathematical framework of many fields of physics and chemistry, including condensed matter physics, solid-state physics, atomic physics, molecular physics, computational physics, computational chemistry, quantum chemistry, particle physics, nuclear chemistry, and nuclear physics. Some fundamental aspects of the theory are still actively studied.
Quantum mechanics is essential to understanding the behavior of systems at atomic length scales and smaller. If the physical nature of an atom was solely described by classical mechanics, electrons would not "orbit" the nucleus, since orbiting electrons emit radiation (due to circular motion) and would eventually collide with the nucleus due to this loss of energy. This framework was unable to explain the stability of atoms. Instead, electrons remain in an uncertain, non-deterministic, "smeared", probabilistic wave–particle orbital about the nucleus, defying the traditional assumptions of classical mechanics and electromagnetism.
Quantum mechanics was initially developed to provide a better explanation and description of the atom, especially the differences in the spectra of light emitted by different isotopes of the same chemical element, as well as subatomic particles. In short, the quantum-mechanical atomic model has succeeded spectacularly in the realm where classical mechanics and electromagnetism falter.
Broadly speaking, quantum mechanics incorporates four classes of phenomena for which classical physics cannot account:
Mathematical formulations.
In the mathematically rigorous formulation of quantum mechanics developed by Paul Dirac, David Hilbert, John von Neumann, and Hermann Weyl, the possible states of a quantum mechanical system are represented by unit vectors (called "state vectors"). Formally, these reside in a complex separable Hilbert space—variously called the "state space" or the "associated Hilbert space" of the system—that is well defined up to a complex number of norm 1 (the phase factor). In other words, the possible states are points in the projective space of a Hilbert space, usually called the complex projective space. The exact nature of this Hilbert space is dependent on the system—for example, the state space for position and momentum states is the space of square-integrable functions, while the state space for the spin of a single proton is just the product of two complex planes. Each observable is represented by a maximally Hermitian (precisely: by a self-adjoint) linear operator acting on the state space. Each eigenstate of an observable corresponds to an eigenvector of the operator, and the associated eigenvalue corresponds to the value of the observable in that eigenstate. If the operator's spectrum is discrete, the observable can attain only those discrete eigenvalues.
In the formalism of quantum mechanics, the state of a system at a given time is described by a complex wave function, also referred to as state vector in a complex vector space. This abstract mathematical object allows for the calculation of probabilities of outcomes of concrete experiments. For example, it allows one to compute the probability of finding an electron in a particular region around the nucleus at a particular time. Contrary to classical mechanics, one can never make simultaneous predictions of conjugate variables, such as position and momentum, with accuracy. For instance, electrons may be considered (to a certain probability) to be located somewhere within a given region of space, but with their exact positions unknown. Contours of constant probability, often referred to as "clouds", may be drawn around the nucleus of an atom to conceptualize where the electron might be located with the most probability. Heisenberg's uncertainty principle quantifies the inability to precisely locate the particle given its conjugate momentum.
According to one interpretation, as the result of a measurement the wave function containing the probability information for a system collapses from a given initial state to a particular eigenstate. The possible results of a measurement are the eigenvalues of the operator representing the observable—which explains the choice of "Hermitian" operators, for which all the eigenvalues are real. The probability distribution of an observable in a given state can be found by computing the spectral decomposition of the corresponding operator. Heisenberg's uncertainty principle is represented by the statement that the operators corresponding to certain observables do not commute.
The probabilistic nature of quantum mechanics thus stems from the act of measurement. This is one of the most difficult aspects of quantum systems to understand. It was the central topic in the famous Bohr-Einstein debates, in which the two scientists attempted to clarify these fundamental principles by way of thought experiments. In the decades after the formulation of quantum mechanics, the question of what constitutes a "measurement" has been extensively studied. Newer interpretations of quantum mechanics have been formulated that do away with the concept of "wavefunction collapse" (see, for example, the relative state interpretation). The basic idea is that when a quantum system interacts with a measuring apparatus, their respective wavefunctions become entangled, so that the original quantum system ceases to exist as an independent entity. For details, see the article on measurement in quantum mechanics.
Generally, quantum mechanics does not assign definite values. Instead, it makes a prediction using a probability distribution; that is, it describes the probability of obtaining the possible outcomes from measuring an observable. Often these results are skewed by many causes, such as dense probability clouds. Probability clouds are approximate, but better than the Bohr model, whereby electron location is given by a probability function, the wave function eigenvalue, such that the probability is the squared modulus of the complex amplitude, or quantum state nuclear attraction. Naturally, these probabilities will depend on the quantum state at the "instant" of the measurement. Hence, uncertainty is involved in the value. There are, however, certain states that are associated with a definite value of a particular observable. These are known as eigenstates of the observable ("eigen" can be translated from German as meaning "inherent" or "characteristic").
In the everyday world, it is natural and intuitive to think of everything (every observable) as being in an eigenstate. Everything appears to have a definite position, a definite momentum, a definite energy, and a definite time of occurrence. However, quantum mechanics does not pinpoint the exact values of a particle's position and momentum (since they are conjugate pairs) or its energy and time (since they too are conjugate pairs); rather, it provides only a range of probabilities in which that particle might be given its momentum and momentum probability. Therefore, it is helpful to use different words to describe states having "uncertain" values and states having "definite" values (eigenstates). Usually, a system will not be in an eigenstate of the observable (particle) we are interested in. However, if one measures the observable, the wavefunction will instantaneously be an eigenstate (or "generalized" eigenstate) of that observable. This process is known as wavefunction collapse, a controversial and much-debated process that involves expanding the system under study to include the measurement device. If one knows the corresponding wave function at the instant before the measurement, one will be able to compute the probability of the wavefunction collapsing into each of the possible eigenstates. For example, the free particle in the previous example will usually have a wavefunction that is a wave packet centered around some mean position "x"0 (neither an eigenstate of position nor of momentum). When one measures the position of the particle, it is impossible to predict with certainty the result. It is probable, but not certain, that it will be near "x"0, where the amplitude of the wave function is large. After the measurement is performed, having obtained some result "x", the wave function collapses into a position eigenstate centered at "x".
The time evolution of a quantum state is described by the Schrödinger equation, in which the Hamiltonian (the operator corresponding to the total energy of the system) generates the time evolution. The time evolution of wave functions is deterministic in the sense that - given a wavefunction at an "initial" time - it makes a definite prediction of what the wavefunction will be at any "later" time.
During a measurement, on the other hand, the change of the initial wavefunction into another, later wavefunction is not deterministic, it is unpredictable (i.e., random). A time-evolution simulation can be seen here.
Wave functions change as time progresses. The Schrödinger equation describes how wavefunctions change in time, playing a role similar to Newton's second law in classical mechanics. The Schrödinger equation, applied to the aforementioned example of the free particle, predicts that the center of a wave packet will move through space at a constant velocity (like a classical particle with no forces acting on it). However, the wave packet will also spread out as time progresses, which means that the position becomes more uncertain with time. This also has the effect of turning a position eigenstate (which can be thought of as an infinitely sharp wave packet) into a broadened wave packet that no longer represents a (definite, certain) position eigenstate.
Some wave functions produce probability distributions that are constant, or independent of time—such as when in a stationary state of constant energy, time vanishes in the absolute square of the wave function. Many systems that are treated dynamically in classical mechanics are described by such "static" wave functions. For example, a single electron in an unexcited atom is pictured classically as a particle moving in a circular trajectory around the atomic nucleus, whereas in quantum mechanics it is described by a static, spherically symmetric wavefunction surrounding the nucleus () (note, however, that only the lowest angular momentum states, labeled "s", are spherically symmetric).
The Schrödinger equation acts on the "entire" probability amplitude, not merely its absolute value. Whereas the absolute value of the probability amplitude encodes information about probabilities, its phase encodes information about the interference between quantum states. This gives rise to the "wave-like" behavior of quantum states. As it turns out, analytic solutions of the Schrödinger equation are available for only a very small number of relatively simple model Hamiltonians, of which the quantum harmonic oscillator, the particle in a box, the hydrogen molecular ion, and the hydrogen atom are the most important representatives. Even the helium atom—which contains just one more electron than does the hydrogen atom—has defied all attempts at a fully analytic treatment.
There exist several techniques for generating approximate solutions, however. In the important method known as perturbation theory, one uses the analytic result for a simple quantum mechanical model to generate a result for a more complicated model that is related to the simpler model by (for one example) the addition of a weak potential energy. Another method is the "semi-classical equation of motion" approach, which applies to systems for which quantum mechanics produces only weak (small) deviations from classical behavior. These deviations can then be computed based on the classical motion. This approach is particularly important in the field of quantum chaos.
Mathematically equivalent formulations of quantum mechanics.
There are numerous mathematically equivalent formulations of quantum mechanics. One of the oldest and most commonly used formulations is the "transformation theory" proposed by Paul Dirac, which unifies and generalizes the two earliest formulations of quantum mechanics - matrix mechanics (invented by Werner Heisenberg) and wave mechanics (invented by Erwin Schrödinger).
Especially since Werner Heisenberg was awarded the Nobel Prize in Physics in 1932 for the creation of quantum mechanics, the role of Max Born in the development of QM was overlooked until the 1954 Nobel award. The role is noted in a 2005 biography of Born, which recounts his role in the matrix formulation of quantum mechanics, and the use of probability amplitudes. Heisenberg himself acknowledges having learned matrices from Born, as published in a 1940 "festschrift" honoring Max Planck. In the matrix formulation, the instantaneous state of a quantum system encodes the probabilities of its measurable properties, or "observables". Examples of observables include energy, position, momentum, and angular momentum. Observables can be either continuous (e.g., the position of a particle) or discrete (e.g., the energy of an electron bound to a hydrogen atom). An alternative formulation of quantum mechanics is Feynman's path integral formulation, in which a quantum-mechanical amplitude is considered as a sum over all possible classical and non-classical paths between the initial and final states. This is the quantum-mechanical counterpart of the action principle in classical mechanics.
Interactions with other scientific theories.
The rules of quantum mechanics are fundamental. They assert that the state space of a system is a Hilbert space and that observables of that system are Hermitian operators acting on that space—although they do not tell us which Hilbert space or which operators. These can be chosen appropriately in order to obtain a quantitative description of a quantum system. An important guide for making these choices is the correspondence principle, which states that the predictions of quantum mechanics reduce to those of classical mechanics when a system moves to higher energies or, equivalently, larger quantum numbers, i.e. whereas a single particle exhibits a degree of randomness, in systems incorporating millions of particles averaging takes over and, at the high energy limit, the statistical probability of random behaviour approaches zero. In other words, classical mechanics is simply a quantum mechanics of large systems. This "high energy" limit is known as the "classical" or "correspondence limit". One can even start from an established classical model of a particular system, then attempt to guess the underlying quantum model that would give rise to the classical model in the correspondence limit.
When quantum mechanics was originally formulated, it was applied to models whose
correspondence limit was non-relativistic classical mechanics. For instance, the well-known model of the quantum harmonic oscillator uses an explicitly non-relativistic expression for the kinetic energy of the oscillator, and is thus a quantum version of the classical harmonic oscillator.
Early attempts to merge quantum mechanics with special relativity involved the replacement of the Schrödinger equation with a covariant equation such as the Klein–Gordon equation or the Dirac equation. While these theories were successful in explaining many experimental results, they had certain unsatisfactory qualities stemming from their neglect of the relativistic creation and annihilation of particles. A fully relativistic quantum theory required the development of quantum field theory, which applies quantization to a field (rather than a fixed set of particles). The first complete quantum field theory, quantum electrodynamics, provides a fully quantum description of the electromagnetic interaction. The full apparatus of quantum field theory is often unnecessary for describing electrodynamic systems. A simpler approach, one that has been employed since the inception of quantum mechanics, is to treat charged particles as quantum mechanical objects being acted on by a classical electromagnetic field. For example, the elementary quantum model of the hydrogen atom describes the electric field of the hydrogen atom using a classical formula_2 Coulomb potential. This "semi-classical" approach fails if quantum fluctuations in the electromagnetic field play an important role, such as in the emission of photons by charged particles.
Quantum field theories for the strong nuclear force and the weak nuclear force have also been developed. The quantum field theory of the strong nuclear force is called quantum chromodynamics, and describes the interactions of subnuclear particles such as quarks and gluons. The weak nuclear force and the electromagnetic force were unified, in their quantized forms, into a single quantum field theory (known as electroweak theory), by the physicists Abdus Salam, Sheldon Glashow and Steven Weinberg. These three men shared the Nobel Prize in Physics in 1979 for this work.
It has proven difficult to construct quantum models of gravity, the remaining fundamental force. Semi-classical approximations are workable, and have led to predictions such as Hawking radiation. However, the formulation of a complete theory of quantum gravity is hindered by apparent incompatibilities between general relativity (the most accurate theory of gravity currently known) and some of the fundamental assumptions of quantum theory. The resolution of these incompatibilities is an area of active research, and theories such as string theory are among the possible candidates for a future theory of quantum gravity.
Classical mechanics has also been extended into the complex domain, with complex classical mechanics exhibiting behaviors similar to quantum mechanics.
Quantum mechanics and classical physics.
Predictions of quantum mechanics have been verified experimentally to an extremely high degree of accuracy. According to the correspondence principle between classical and quantum mechanics, all objects obey the laws of quantum mechanics, and classical mechanics is just an approximation for large systems of objects (or a statistical quantum mechanics of a large collection of particles). The laws of classical mechanics thus follow from the laws of quantum mechanics as a statistical average at the limit of large systems or large quantum numbers. However, chaotic systems do not have good quantum numbers, and quantum chaos studies the relationship between classical and quantum descriptions in these systems.
Quantum coherence is an essential difference between classical and quantum theories as illustrated by the Einstein–Podolsky–Rosen (EPR) paradox — an attack on a certain philosophical interpretation of quantum mechanics by an appeal to local realism. Quantum interference involves adding together "probability amplitudes", whereas classical "waves" infer that there is an adding together of "intensities". For microscopic bodies, the extension of the system is much smaller than the coherence length, which gives rise to long-range entanglement and other nonlocal phenomena characteristic of quantum systems. Quantum coherence is not typically evident at macroscopic scales, though an exception to this rule may occur at extremely low temperatures (i.e. approaching absolute zero) at which quantum behavior may manifest itself macroscopically. This is in accordance with the following observations:
Copenhagen interpretation of quantum versus classical kinematics.
A big difference between classical and quantum mechanics is that they use very different kinematic descriptions.
In Niels Bohr's mature view, quantum mechanical phenomena are required to be experiments, with complete descriptions of all the devices for the system, preparative, intermediary, and finally measuring. The descriptions are in macroscopic terms, expressed in ordinary language, supplemented with the concepts of classical mechanics. The initial condition and the final condition of the system are respectively described by values in a configuration space, for example a position space, or some equivalent space such as a momentum space. Quantum mechanics does not admit a completely precise description, in terms of both position and momentum, of an initial condition or "state" (in the classical sense of the word) that would support a precisely deterministic and causal prediction of a final condition. In this sense, advocated by Bohr in his mature writings, a quantum phenomenon is a process, a passage from initial to final condition, not an instantaneous "state" in the classical sense of that word. Thus there are two kinds of processes in quantum mechanics: stationary and transitional. For a stationary process, the initial and final condition are the same. For a transition, they are different. Obviously by definition, if only the initial condition is given, the process is not determined. Given its initial condition, prediction of its final condition is possible, causally but only probabilistically, because the Schrödinger equation is deterministic for wave function evolution, but the wave function describes the system only probabilistically.
For many experiments, it is possible to think of the initial and final conditions of the system as being a particle. In some cases it appears that there are potentially several spatially distinct pathways or trajectories by which a particle might pass from initial to final condition. It is an important feature of the quantum kinematic description that it does not permit a unique definite statement of which of those pathways is actually followed. Only the initial and final conditions are definite, and, as stated in the foregoing paragraph, they are defined only as precisely as allowed by the configuration space description or its equivalent. In every case for which a quantum kinematic description is needed, there is always a compelling reason for this restriction of kinematic precision. An example of such a reason is that for a particle to be experimentally found in a definite position, it must be held motionless; for it to be experimentally found to have a definite momentum, it must have free motion; these two are logically incompatible.
Classical kinematics does not primarily demand experimental description of its phenomena. It allows completely precise description of an instantaneous state by a value in phase space, the Cartesian product of configuration and momentum spaces. This description simply assumes or imagines a state as a physically existing entity without concern about its experimental measurability. Such a description of an initial condition, together with Newton's laws of motion, allows a precise deterministic and causal prediction of a final condition, with a definite trajectory of passage. Hamiltonian dynamics can be used for this. Classical kinematics also allows the description of a process analogous to the initial and final condition description used by quantum mechanics. Lagrangian mechanics applies to this. For processes that need account to be taken of actions of a small number of Planck constants, classical kinematics is not adequate; quantum mechanics is needed.
Relativity and quantum mechanics.
Even with the defining postulates of both Einstein's theory of general relativity and quantum theory being indisputably supported by rigorous and repeated empirical evidence, and while they do not directly contradict each other theoretically (at least with regard to their primary claims), they have proven extremely difficult to incorporate into one consistent, cohesive model.
Einstein himself is well known for rejecting some of the claims of quantum mechanics. While clearly contributing to the field, he did not accept many of the more "philosophical consequences and interpretations" of quantum mechanics, such as the lack of deterministic causality. He is famously quoted as saying, in response to this aspect, "My God does not play with dice". He also had difficulty with the assertion that a single subatomic particle can occupy numerous areas of space at one time. However, he was also the first to notice some of the apparently exotic consequences of entanglement, and used them to formulate the Einstein–Podolsky–Rosen paradox in the hope of showing that quantum mechanics had unacceptable implications if taken as a complete description of physical reality. This was 1935, but in 1964 it was shown by John Bell (see Bell inequality) that - although Einstein was correct in identifying seemingly paradoxical implications of quantum mechanical nonlocality - these implications could be experimentally tested. Alain Aspect's initial experiments in 1982, and many subsequent experiments since, have definitively verified quantum entanglement.
According to the paper of J. Bell and the Copenhagen interpretation—the common interpretation of quantum mechanics by physicists since 1927 - and contrary to Einstein's ideas, quantum mechanics was "not", at the same time a "realistic" theory and a "local" theory.
The Einstein–Podolsky–Rosen paradox shows in any case that there exist experiments by which one can measure the state of one particle and instantaneously change the state of its entangled partner - although the two particles can be an arbitrary distance apart. However, this effect does not violate causality, since no transfer of information happens. Quantum entanglement forms the basis of quantum cryptography, which is used in high-security commercial applications in banking and government.
Gravity is negligible in many areas of particle physics, so that unification between general relativity and quantum mechanics is not an urgent issue in those particular applications. However, the lack of a correct theory of quantum gravity is an important issue in cosmology and the search by physicists for an elegant "Theory of Everything" (TOE). Consequently, resolving the inconsistencies between both theories has been a major goal of 20th and 21st century physics. Many prominent physicists, including Stephen Hawking, have labored for many years in the attempt to discover a theory underlying "everything". This TOE would combine not only the different models of subatomic physics, but also derive the four fundamental forces of nature - the strong force, electromagnetism, the weak force, and gravity - from a single force or phenomenon. While Stephen Hawking was initially a believer in the Theory of Everything, after considering Gödel's Incompleteness Theorem, he has concluded that one is not obtainable, and has stated so publicly in his lecture "Gödel and the End of Physics" (2002).
Attempts at a unified field theory.
The quest to unify the fundamental forces through quantum mechanics is still ongoing. Quantum electrodynamics (or "quantum electromagnetism"), which is currently (in the perturbative regime at least) the most accurately tested physical theory in competition with general relativity, (blog) has been successfully merged with the weak nuclear force into the electroweak force and work is currently being done to merge the electroweak and strong force into the electrostrong force. Current predictions state that at around 1014 GeV the three aforementioned forces are fused into a single unified field. Beyond this "grand unification", it is speculated that it may be possible to merge gravity with the other three gauge symmetries, expected to occur at roughly 1019 GeV. However — and while special relativity is parsimoniously incorporated into quantum electrodynamics — the expanded general relativity, currently the best theory describing the gravitation force, has not been fully incorporated into quantum theory. One of those searching for a coherent TOE is Edward Witten, a theoretical physicist who formulated the M-theory, which is an attempt at describing the supersymmetrical based string theory. M-theory posits that our apparent 4-dimensional spacetime is, in reality, actually an 11-dimensional spacetime containing 10 spatial dimensions and 1 time dimension, although 7 of the spatial dimensions are - at lower energies - completely "compactified" (or infinitely curved) and not readily amenable to measurement or probing.
Another popular theory is Loop quantum gravity (LQG), a theory that describes the quantum properties of gravity. It is also a theory of quantum space and quantum time, because in general relativity the geometry of spacetime is a manifestation of gravity. LQG is an attempt to merge and adapt standard quantum mechanics and standard general relativity. The main output of the theory is a physical picture of space where space is granular. The granularity is a direct consequence of the quantization. It has the same nature of the granularity of the photons in the quantum theory of electromagnetism or the discrete levels of the energy of the atoms. But here it is space itself which is discrete.
More precisely, space can be viewed as an extremely fine fabric or network "woven" of finite loops. These networks of loops are called spin networks. The evolution of a spin network over time, is called a spin foam. The predicted size of this structure is the Planck length, which is approximately 1.616×10−35 m. According to theory, there is no meaning to length shorter than this (cf. Planck scale energy). Therefore LQG predicts that not just matter, but also space itself, has an atomic structure. Loop quantum Gravity was first proposed by Carlo Rovelli.
Philosophical implications.
Since its inception, the many counter-intuitive aspects and results of quantum mechanics have provoked strong philosophical debates and many interpretations. Even fundamental issues, such as Max Born's basic rules concerning probability amplitudes and probability distributions, took decades to be appreciated by society and many leading scientists. Richard Feynman once said, "I think I can safely say that nobody understands quantum mechanics." According to Steven Weinberg, "There is now in my opinion no entirely satisfactory interpretation of quantum mechanics."
The Copenhagen interpretation - due largely to the Danish theoretical physicist Niels Bohr - remains the quantum mechanical formalism that is currently most widely accepted amongst physicists, some 75 years after its enunciation. According to this interpretation, the probabilistic nature of quantum mechanics is not a "temporary" feature which will eventually be replaced by a deterministic theory, but instead must be considered a "final" renunciation of the classical idea of "causality." It is also believed therein that any well-defined application of the quantum mechanical formalism must always make reference to the experimental arrangement, due to the conjugate nature of evidence obtained under different experimental situations.
Albert Einstein, himself one of the founders of quantum theory, disliked this loss of determinism in measurement. Einstein held that there should be a local hidden variable theory underlying quantum mechanics and, consequently, that the present theory was incomplete. He produced a series of objections to quantum theory, the most famous of which has become known as the Einstein–Podolsky–Rosen paradox. John Bell showed that this "EPR" paradox led to experimentally testable differences between quantum mechanics and local realistic theories. Experiments have been performed confirming the accuracy of quantum mechanics, thereby demonstrating that the physical world cannot be described by any local realistic theory. The "Bohr-Einstein debates" provide a vibrant critique of the Copenhagen Interpretation from an epistemological point of view.
The Everett many-worlds interpretation, formulated in 1956, holds that "all" the possibilities described by quantum theory "simultaneously" occur in a multiverse composed of mostly independent parallel universes. This is not accomplished by introducing some "new axiom" to quantum mechanics, but on the contrary, by "removing" the axiom of the collapse of the wave packet. "All" of the possible consistent states of the measured system and the measuring apparatus (including the observer) are present in a "real" physical - not just formally mathematical, as in other interpretations - quantum superposition. Such a superposition of consistent state combinations of different systems is called an entangled state. While the multiverse is deterministic, we perceive non-deterministic behavior governed by probabilities, because we can only observe the universe (i.e., the consistent state contribution to the aforementioned superposition) that we, as observers, inhabit. Everett's interpretation is perfectly consistent with John Bell's experiments and makes them intuitively understandable. However, according to the theory of quantum decoherence, these "parallel universes" will never be accessible to us. The inaccessibility can be understood as follows: once a measurement is done, the measured system becomes entangled with "both" the physicist who measured it "and" a huge number of other particles, some of which are photons flying away at the speed of light towards the other end of the universe. In order to prove that the wave function did not collapse, one would have to bring "all" these particles back and measure them again, together with the system that was originally measured. Not only is this completely impractical, but even if one "could" theoretically do this, it would have to destroy any evidence that the original measurement took place (including the physicist's memory). In light of these Bell tests, Cramer (1986) formulated his transactional interpretation. Relational quantum mechanics appeared in the late 1990s as the modern derivative of the Copenhagen Interpretation.
Applications.
Quantum mechanics has had enormous success in explaining many of the features of our universe. Quantum mechanics is often the only tool available that can reveal the individual behaviors of the subatomic particles that make up all forms of matter (electrons, protons, neutrons, photons, and others). Quantum mechanics has strongly influenced string theories, candidates for a Theory of Everything (see reductionism).
Quantum mechanics is also critically important for understanding how individual atoms combine covalently to form molecules. The application of quantum mechanics to chemistry is known as quantum chemistry. Relativistic quantum mechanics can, in principle, mathematically describe most of chemistry. Quantum mechanics can also provide quantitative insight into ionic and covalent bonding processes by explicitly showing which molecules are energetically favorable to which others and the magnitudes of the energies involved. Furthermore, most of the calculations performed in modern computational chemistry rely on quantum mechanics.
A great deal of modern technological inventions operate at a scale where quantum effects are significant. Examples include the laser, the transistor (and thus the microchip), the electron microscope, and magnetic resonance imaging (MRI). The study of semiconductors led to the invention of the diode and the transistor, which are indispensable parts of modern electronics systems and devices.
Researchers are currently seeking robust methods of directly manipulating quantum states. Efforts are being made to more fully develop quantum cryptography, which will theoretically allow guaranteed secure transmission of information. A more distant goal is the development of quantum computers, which are expected to perform certain computational tasks exponentially faster than classical computers. Instead of using classical bits, quantum computers use qubits, which can be in superpositions of states. Another active research topic is quantum teleportation, which deals with techniques to transmit quantum information over arbitrary distances.
Quantum tunneling is vital to the operation of many devices. Even in the simple light switch, the electrons in the electric current could not penetrate the potential barrier made up of a layer of oxide without quantum tunneling. Flash memory chips found in USB drives use quantum tunneling to erase their memory cells.
While quantum mechanics primarily applies to the smaller atomic regimes of matter and energy, some systems exhibit quantum mechanical effects on a large scale. Superfluidity, the frictionless flow of a liquid at temperatures near absolute zero, is one well-known example. So is the closely related phenomenon of superconductivity, the frictionless flow of an electron gas in a conducting material (an electric current) at sufficiently low temperatures.
Quantum theory also provides accurate descriptions for many previously unexplained phenomena, such as black-body radiation and the stability of the orbitals of electrons in atoms. It has also given insight into the workings of many different biological systems, including smell receptors and protein structures. Recent work on photosynthesis has provided evidence that quantum correlations play an essential role in this fundamental process of plants and many other organisms. Even so, classical physics can often provide good approximations to results otherwise obtained by quantum physics, typically in circumstances with large numbers of particles or large quantum numbers. Since classical formulas are much simpler and easier to compute than quantum formulas, classical approximations are used and preferred when the system is large enough to render the effects of quantum mechanics insignificant.
Examples.
Free particle.
For example, consider a free particle. In quantum mechanics, there is wave–particle duality, so the properties of the particle can be described as the properties of a wave. Therefore, its quantum state can be represented as a wave of arbitrary shape and extending over space as a wave function. The position and momentum of the particle are observables. The Uncertainty Principle states that both the position and the momentum cannot simultaneously be measured with complete precision. However, one "can" measure the position (alone) of a moving free particle, creating an eigenstate of position with a wavefunction that is very large (a Dirac delta) at a particular position "x", and zero everywhere else. If one performs a position measurement on such a wavefunction, the resultant "x" will be obtained with 100% probability (i.e., with full certainty, or complete precision). This is called an eigenstate of position—or, stated in mathematical terms, a "generalized position eigenstate (eigendistribution)". If the particle is in an eigenstate of position, then its momentum is completely unknown. On the other hand, if the particle is in an eigenstate of momentum, then its position is completely unknown.
In an eigenstate of momentum having a plane wave form, it can be shown that the wavelength is equal to "h/p", where "h" is Planck's constant and "p" is the momentum of the eigenstate.
Step potential.
The potential in this case is given by:
The solutions are superpositions of left- and right-moving waves:
where the wave vectors are related to the energy via
with coefficients A and B determined from the boundary conditions and by imposing a continuous derivative on the solution.
Each term of the solution can be interpreted as an incident, reflected, or transmitted component of the wave, allowing the calculation of transmission and reflection coefficients. Notably, in contrast to classical mechanics, incident particles with energies greater than the potential step are partially reflected.
Rectangular potential barrier.
This is a model for the quantum tunneling effect which plays an important role in the performance of modern technologies such as flash memory and scanning tunneling microscopy. Quantum tunneling is central to physical phenomena involved in superlattices.
Particle in a box.
The particle in a one-dimensional potential energy box is the most mathematically simple example where restraints lead to the quantization of energy levels. The box is defined as having zero potential energy everywhere "inside" a certain region, and infinite potential energy everywhere "outside" that region. For the one-dimensional case in the formula_8 direction, the time-independent Schrödinger equation may be written
With the differential operator defined by
the previous equation is evocative of the classic kinetic energy analogue,
with state formula_12 in this case having energy formula_13 coincident with the kinetic energy of the particle.
The general solutions of the Schrödinger equation for the particle in a box are
or, from Euler's formula,
The infinite potential walls of the box determine the values of "C", "D", and "k" at and where "ψ" must be zero. Thus, at ,
and . At ,
in which "C" cannot be zero as this would conflict with the Born interpretation. Therefore, since , "kL" must be an integer multiple of π,
The quantization of energy levels follows from this constraint on "k", since
Finite potential well.
A finite potential well is the generalization of the infinite potential well problem to potential wells having finite depth.
The finite potential well problem is mathematically more complicated than the infinite particle-in-a-box problem as the wavefunction is not pinned to zero at the walls of the well. Instead, the wavefunction must satisfy more complicated mathematical boundary conditions as it is nonzero in regions outside the well.
Harmonic oscillator.
As in the classical case, the potential for the quantum harmonic oscillator is given by
This problem can either be treated by directly solving the Schrödinger, which is not trivial, or by using the more elegant "ladder method" first proposed by Paul Dirac. The eigenstates are given by
where "Hn" are the Hermite polynomials,
and the corresponding energy levels are
This is another example illustrating the quantization of energy for bound states.
References.
The following titles, all by working physicists, attempt to communicate quantum theory to lay people, using a minimum of technical apparatus.
More technical:
</dl>

</doc>
<doc id="25203" url="http://en.wikipedia.org/wiki?curid=25203" title="Quilting">
Quilting

Quilting can refer either to the process of creating a quilt or to the sewing of two or more layers of material together to make a thicker padded material. "Quilting" as the process of creating a quilt uses "quilting" as the joining of layers as one of its steps, often along with designing, piecing, appliqué, binding and other steps. A quilter is the name given to someone who works at quilting. Quilting can be done by hand, by sewing machine, or by a specialized longarm quilting system.
The process of quilting uses a needle and thread to join two or more layers of material to make a quilt. Typical quilting is done with three layers: the top fabric or quilt top, batting or insulating material and backing material. The quilter's hand or sewing machine passes the needle and thread through all layers and then brings the needle back up. The process is repeated across the entire area where quilting is wanted. A rocking, straight or running stitch is commonly used and these stitches can be purely functional, or decorative and elaborate. Quilting is done to create bed spreads, art quilt wall hangings, clothing, and a variety of textile products. Quilting can make a project thick, or with dense quilting, can raise one area so that another stands out.
Quilt stores often sell fabric, thread, patterns and other goods that are used for quilting. They often have group sewing and quilting classes, where one can learn how to sew or quilt and work with others to exchange skills. Quilt stores often have quilting machines that can be rented out for use, or customers can drop off their quilts and have them professionally quilted.
History.
Early functional quilting.
The word "quilt" comes from the Latin "culcita" meaning a stuffed sack, but it came into the English language from the French word "cuilte". The origins of quilting remain unknown, but sewing techniques of piecing, appliqué, and quilting have been used for clothing and furnishings in diverse parts of the world for several millennia.
The earliest known quilted garment is depicted on the carved ivory figure of a Pharaoh of the Egyptian First Dynasty, about 3400 B.C.
In 1924 archaeologists discovered a quilted floor covering in Mongolia. They estimated its date as between 100 BC to 200 AD. There are numerous references to quilts in literature and inventories of estates. Crusaders brought quilted objects from the Middle East to Europe in the late 11th century. Quilted garments known as gambesons were popular in the European Middle Ages. Knights wore them under their armor for comfort and sometimes as an outer garment to protect the metal armor from the weather. The earliest known surviving European bed quilt is from late 14th century Sicily. It is made of linen and padded with wool. The blocks across the center are scenes from the legend of Tristan. The quilt is 122" by 106" and is in the Victoria and Albert Museum in London.
Quilting has been part of the needlework tradition in Europe from about the 5th century CE. Early objects contain Egyptian cotton, which may indicate that Egyptian and Mediterranean trade provided a conduit for the technique. Quilted objects were relatively rare in Europe until approximately the 12th century, when quilted bedding and other items appeared after the return of the Crusaders from the Middle East. The medieval quilted gambeson, aketon and arming doublet were garments worn under, or instead of, armor of maille or plate armor. These developed into the later quilted doublet worn as part of fashionable European male clothing from the 14th to 17th century. Quilting clothing began to be generally used in the 14th century, with quilted doublets and armor worn in France, Germany, and England and quilted tunics in Italy.
American quilts.
In American Colonial times, most women were busy spinning, weaving, and making clothing. Meanwhile, women of the wealthier classes prided themselves on their fine quilting of wholecloth quilts with fine needlework. Quilts made during the early 19th century were not constructed of pieced blocks but were instead whole cloth quilts. Broderie perse quilts and medallion quilts were made. Some antique quilts made in North America have worn-out blankets or older quilts as the internal batting layer, quilted between new layers of fabric and thereby extending the usefulness of old material.
During American pioneer days, "paper" quilting became popular. Paper was used as a pattern and each individual piece of cut fabric was basted around the paper pattern. Paper was a scarce commodity in the early American west, and women would save letters from home, newspaper clippings, and catalogs to use as patterns. The paper not only served as a pattern but as an insulator. The paper found between the old quilts has become a primary source of information about pioneer life.
Quilts made without any insulation or batting were referred to as summer quilts. They were not made for warmth, only to keep the chill off during cooler summer evenings.
African-American quilts.
African-American women developed a distinctive style of quilting, notably different from the style most strongly associated with the Amish.
Harriet Powers, a slave-born African American woman, made two famous story quilts. She was just one of the many African American quilters who contributed to the evolution of quilting. The Gee's Bend quilting community was celebrated in an exhibition that travelled to museums including the Smithsonian. The contributions made by her and other quilters of Gee's Bend, Alabama has been recognized by the US Postal Service with a series of stamps. The "communal" nature of the quilting process (and how it can bring together women of varied races and backgrounds) was honored in the series of stamps.
During the American Civil War, slaves used quilts as a means to share and transmit secret messages to escape slavery and travel the Underground Railroad. A lack of written record on the topic has created debate among historians and scholars. However, an oral history has been told and preserved.
Hawaiian quilting.
"Hawaiian quilting was well established by the beginning of the twentieth century. Hawaiian women learned to quilt from the wives of missionaries from New England in the 1820s. Though they learned both pieced work and applique; by the 1870s they had adapted applique techniques to create a uniquely Hawaiian mode of expression. The classic Hawaiian quilt design is a large, bold, curvilinear appliqué pattern that covers much of the surface of the quilt, and the symmetrical design is cut from only one piece of fabric."
Art quilting.
During the late 20th century, art quilts became popular for their aesthetic and artistic qualities rather than for functionality (they are displayed on a wall or table rather than spread on a bed). "It is believed that decorative quilting came to Europe and Asia during the Crusades (A.D. 1100-1300), a likely idea because textile arts were more developed in China and India than in the West."
Quilting in fashion and design.
Unusual quilting designs have increasingly become popular as decorative textiles. Industrial sewing technology has become more precise and flexible, and quilting using exotic fabrics and embroidery began to appear in home furnishings in the early 21st century.
Quilt blocks.
The quilt block is traditionally a patterned square of fabric that is repeated with plain blocks to form the overall design of a quilt. There are a variety of different designs for quilt blocks including the Nine-Patch, Shoo Fly, Churn Dash, and the Prairie Queen.
A Nine Patch is made by sewing five patterned or dark pieces (patches) to four light square pieces in alternating order. These nine sewn squares make one block.
The Shoo Fly varies from the Nine Patch by dividing each of the four corner pieces into a light and dark triangle.
Another variation develops when one square piece is divided into two equal rectangles in the basic Nine Patch design. The Churn Dash block combines the triangles and rectangle to expand the Nine Patch.
The Prairie Queen block combines two large scale triangles in the corner section with the middle section using four squares. The center piece is one full size square. Each of the nine sections does have the same overall measurement and fits together.
Types and equipment.
Many types of quilting exist today. The two most widely used are hand-quilting and machine quilting.
Hand quilting is the process of using a needle and thread to sew a running stitch by hand across the entire area to be quilted. This binds the layers together. A quilting frame or hoop is often used to assist in holding the piece being quilted off the quilter's lap. A quilter can make one stitch at a time by first driving the needle through the fabric from the right side, then pushing it back up through the material from the wrong side to complete the stitch; this is called a stab stitch. Another option is called a rocking stitch, where the quilter has one hand, usually with a finger wearing a thimble, on top of the quilt, while the other hand is located beneath the piece to push the needle back up. A third option is called "loading the needle" and involves doing four or more stitches before pulling the needle through the cloth. Hand quilting is still practiced by the Amish and Mennonites within the United States and Canada, and is enjoying a resurgence worldwide.
Machine quilting is the process of using a home sewing machine or a longarm machine to sew the layers together. With the home sewing machine, the layers are tacked together before quilting. This involves laying the top, batting, and backing out on a flat surface and either pinning (using large safety pins) or tacking the layers together. Longarm Quilting involves placing the layers to be quilted on a special frame. The frame has bars on which the layers are rolled, keeping these together without the need for tacking or pinning. These frames are used with a professional sewing machine mounted on a platform. The platform rides along tracks so that the machine can be moved across the layers on the frame. A Longarm machine is moved across the fabric. In contrast, the fabric is moved through a home sewing machine.
Tying is another technique of fastening the three layers together (and is not a form of quilting at all). This is done primarily on quilts that are made to be used and are needed quickly. The process of tying the quilt is done with yarns or multiple strands of thread. Square knots are used to finish off the ties so that the quilt may be washed and used without fear of the knots coming undone. This technique is commonly called "tacking." In the Midwest, tacked bed covers are referred to as comforters.
Quilting is now taught in some American schools. It is also taught at senior centers around the U.S., but quilters of all ages attend classes. These forms of workshop or classes are also available in other countries in guilds and community colleges.
Contemporary quilters use a wide range of quilting designs and styles, from ancient and ethnic to post-modern futuristic patterns. There is no one single school or style that dominates the quilt-making world. Regardless of skill level, all quilters know the importance of having the right tools when quilting. Having the right tools increases the fluid process of making a quilt and can even be improved over time with practice. Having the right tools will maximize efficiency and make the quilting experience one to remember. Hand quilters spend much more time on making the quilts compared to machine quilters because of all of the tools that are incorporated into the machine compared to the hand quilters’ ability to only use their hands. There are many other tools and machines to use to make quilts. Below is a list of the different tools and tips that can be used to make a quilt by hand or machine: 
When making a quilt it is important to mark the fabric that you are cutting in order to have some kind of guidance when cutting the fabric. When marking the fabric it is advised that you use a “fabric marker” which is a marker that washes out when the quilt is washed or will fade away after repeated washes. 
The long arm quilting machine is something that every quilter would love to work with. This machine makes it easier to make larger quilts because of the extended arm that is used. Being able to leverage the larger machine and not having to hold the material that is being used while quilting helps the process move along much faster and makes it easier on the quilter. 
When quilting the most important tool that is used is the needle. Regardless of if you are quilting by hand or by machine, the needle that is being used is critical to the final result. Using the wrong needle can lead to puckering, bumps, or even the material being torn. There are many different styles of needles and looking at Sewing Needles will be a good guide. 
Understanding how Pins and Thimbles work is also very important in the process of making quilts. Many different combinations of pins and thimbles can be used in order get similar results and the exciting part is figuring out existing combinations as well as coming up with new combinations. Thimbles are not required but are always seen as good practice. 
Many different options are available for quilting hoops and frames and the quilter has the option of which one they want to use. Looking at quilting hoops or quilting frames will be beneficial in making that decision. 
Choosing the right types of threads for a quilt can be difficult and beginners may need some assistance from an expert or more advanced quilter. The color, composition, and type of thread that is used will have a pivotal role in the outcome of the final quilt. 
What a quilter uses to cut the fabric is a vital step in the quilting process. It is very important each piece is perfectly aligned in order to prevent an uneven or sloppy appearance and to prevent rework. A rotary cutter offers even the shakiest of hands the ability to produce perfect even slices and minimizes the chance of error.
Quilts can have many different templates and they can have a large impact on the final result. There are a number of mediums that can be used and depending on the usage, size and style they will give your quilt a varied look. Templates are generally considered the basis of the structure of the quilt, like a blueprint for a house. If used properly it can help quilters produce a quilt of their liking and give them a sense of satisfaction and vision for future quilts they want to make.
Processes and definitions.
The Basics of Quilt Assembly.
Disclaimer: This section describes basic information about the assembly of quilts using machine quilting techniques. There are many different ways to make quilts and it would be impractical to attempt to cover all of these methods. It is, however, worth noting that many cultures and groups in different parts of the world have their own unique approaches, methods and styles of quilting which are not addressed below.
Assembling the Quilt Top.
 Selecting Fabric: The top-most layer of a quilt is usually made from cotton quilting fabric. Selecting the fabric can be a challenging exercise, and the number of different fabrics required depends on the quilting pattern selected. A good way to coordinate the colours of a quilt is to start by choosing a patterned or 'focus' fabric with the colour scheme that you like. Using this patterned fabric, you can pick out certain colours from within the pattern and select other fabrics with complimentary colours and tones. It is important to note that complimentary fabrics do not necessarily have identical colours, rather that each additional fabric selected draws out one or more shade, tone or aspect of the original focus fabric. Many quilters will also make use of fabrics from home, incorporating fabrics with a particular sentimental importance. When making use of these re-purposed fabrics, it is important to select fabrics that are not too worn in order to create a quilt which will last. 
 Fabric Preparation: Newly bought fabric is often washed before being cut or sewn. If not pre-washed, there is a risk of the fabric dyes bleeding into each other when the final product is washed. Many fabric manufacturers take this into account and have taken steps to prevent colour-bleeding. However, the only way to be absolutely certain is to wash the fabrics yourself. Washing, and subsequently drying, the fabric will also shrink some fabrics, so it is best to do this before cutting the fabric into the shapes and sizes needed. Whether you choose to wash your fabric or not, it must be ironed flat before cutting to prevent creases or wrinkles from altering your measurements.
 Cutting Fabric: With large scale projects like quilts, it is often advantageous to have a rotary cutter and mat. A rotary cutter is a cutting tool with a round blade, making it easy to cut a smooth, continuous line. Rotary cutters come with different sized blades: a larger blade is useful for large projects with straight lines, while a smaller blade is helpful for small areas or curved lines. A rotary mat works to protect your tables and surfaces from the blade, while also protecting your cutting edge from damage. A quilting ruler will also be useful to help ensure that all pieces are cut to consistent sizes. Quilting rulers are made of clear plastic and possess marked grid-lines across the surface of the ruler. This type of ruler makes it possible to cut a piece of fabric in the correct width or length without having to use a measuring tape and fabric chalk. As you measure and cut, it is important to make sure that your measurements account for the seam allowance that you will be using when assembling your quilt.
 Sewing the Pattern: Accurate seam allowances are especially important when it comes to quilting. With dozens, sometimes hundreds of different seams, if each seam is off by even 0.5 cm you will find it hard to make all of the components fit together evenly. When sewing a large quilt it is advantageous to use an assembly line method to maximize speed: pin together all similar fabric sections and sew the pieces together one after another without breaking the threads. Once all of the sections are sewn, clip the threads between them to separate before pressing flat. Always press the seams flat before attaching further segments.
Quilting the "Sandwich:".
 Layers of Quilts: There are generally three layers in a quilt: the quilt top, the middle layer of batting, and the fabric backing. The quilt top is the design layer. The cotton or polyester batting in the middle layer is what determines the warmth of the quilt. Batting comes in different thicknesses depending on the purpose of the final quilt, and multiple layers of batting can be combined to increase the warmth of the final product. The bottom layer is often a simple layer of cotton fabric, in a neutral or complimentary colour and design scheme, though some quilters use the extra or spare fabric from the quilt top to make a secondary design for the backing.
 Basting the Layers: Before actually quilting your fabrics, it is important to baste them together. Basting is the practice of making long, loose stitches in a grid format across the surface of the quilt to hold the layers of the quilt together and to prevent them from shifting during the quilting process. Basting can also be done using large curved safety pins rather than machine or hand basting.
 Quilting: Once the quilt has been basted, it is possible to quilt the layers together, either by hand or through the use of a sewing machine. One method of quilting involves the use of an outline or stencil applied to the surface of the quilt using fabric chalk, washable marker or iron-on pattern. The quilter will then sew along the applied pattern, washing or wiping the stencil off after the quilt is complete. Some quilters choose not to make use of a pattern. Free-motion quilting is the process of quilting without the use of a stencil or other guide, requiring a steady hand and a great deal of practice.
 Binding: Once the layers have been quilted, the edges must be finished and bound. There are many different ways to bind a quilt, one of the simplest involves sewing one side of a strip of fabric to the front side of the quilt, through all of the layers of fabric, then folding the strip over to the back side of the fabric and hand stitching the binding closed.
Note: If the quilt will be hung on the wall, there is an additional step: making and attaching the hanging sleeve.
In China.
Throughout China, a simple method of producing quilts is employed. It involves setting up a temporary roadside site. A frame is assembled within which a lattice work of cotton thread is made. Cotton batting, either new or retrieved from discarded quilts, is prepared in a mobile carding machine. The mechanism of the carding machine is powered by a small, petrol motor. The batting is then added, layer by layer, to the area within the frame. Between each layer, a new lattice of thread is created with a wooden disk used to tamp down the layer.
Definitions.
Pieced Quilt- Pieced quilts are also known as Patchworks. They consist of geometric shapes taken from different fabrics and are sewn together. After that process, it is referred to as a quilt top. The quilting patterns generally follow the design of the geometric patterns. The quilt ends up being a mixture of different fabrics and geometric designs and shapes that are organized in some fashion. 
Quilting is usually completed by starting from the middle, and moving outward toward the edges of the quilt.
Quilting can be elaborately decorative, comprising stitching fashioned into complex designs and patterns, simple or complex geometric grids, "motifs" traced from published quilting patterns or traced pictures, freehand, or complex repeated designs called tessellations. The quilter may choose to emphasize these designs by using threads that are multicolored or metallic, or that contrast highly to the fabric. Conversely, the quilter may choose to make the quilting disappear, using "invisible" nylon or polyester thread,thread that matches the quilt top, or stitching within the patchwork seams themselves (commonly known as "stitch in the ditch"). Some quilters draw the quilting design on the quilt top before stitching, while others prefer to stitch "freehand."
Quilting is often combined with embroidery, patchwork, applique, and other forms of needlework.

</doc>
<doc id="25204" url="http://en.wikipedia.org/wiki?curid=25204" title="Qt (software)">
Qt (software)

Qt ( "cute", or unofficially as Q-T "cue-tee") is a cross-platform application framework that is widely used for developing application software that can be run on various software and hardware platforms with little or no change in the underlying codebase, while having the power and speed of native applications. Qt is currently being developed both by the Qt Company, a subsidiary of Digia, and the Qt Project under open-source governance, involving individual developers and firms working to advance Qt. Digia owns the Qt trademark and copyright. Qt is available with both commercial and open source GPL v3, LGPL v3 and LGPL v2 licenses.
Purposes and abilities.
Qt is used mainly for developing application software with graphical user interfaces (GUIs); however, programs without a GUI can be developed, such as command-line tools and consoles for servers. An example of a non-GUI program using Qt is the Cutelyst web framework. GUI programs created with Qt can have a native-looking interface, in which cases Qt is classified as a "widget toolkit".
Qt uses standard C++ with extensions including signals and slots that simplifies handling of events, and this helps in development of both GUI and server applications which receive their own set of event information and should process them accordingly. Qt supports many compilers, including the GCC C++ compiler and the Visual Studio suite. Qt also provides Qt Quick, that includes a declarative scripting language called QML that allows using JavaScript to provide the logic. With Qt Quick, rapid application development for mobile devices became possible, although logic can be written with native code as well to achieve the best possible performance. Qt can be used in several other programming languages via language bindings. It runs on the major desktop platforms and some of the mobile platforms. It has extensive internationalization support. Non-GUI features include SQL database access, XML parsing, JSON parsing, thread management and network support.
Software architecture.
Qt, when it was first released, relied on a few key concepts:
Supported platforms.
Qt works on several different platforms, which makes it attractive for those who want a single code base to work virtually everywhere in Write once, compile anywhere fashion. qt.io website, the new home for Qt developers, introduces Qt as: "1 framework, 15 platforms, 95% satisfaction, 800,000+ users". The following platforms are officially supported by Digia:
After Nokia opened the Qt source code to the community on Gitorious various ports appeared. There are also some ports of Qt that may be available, but are not supported anymore. These platforms are listed in List of platforms supported by Qt.
Editions.
There are four editions of Qt available, Community, Indie Mobile, Professional and Enterprise. The Community version is under the open source licenses, while the Indie Mobile, Professional and Enterprise versions, which contain additional functionality and libraries, e.g. Charts and Data Visualization, Enterprise Controls, Virtual Keyboard etc. are commercially sold by The Qt Company.
Qt is available under the following copyright licenses: Qt Commercial License, GNU GPL-3.0, GNU LGPL-3.0 and GNU LGPL-2.1 (with Qt special exception)
Releases.
Qt 5.
Qt 5 was officially released on 19 December 2012. This new version marked a major change in the platform, with hardware-accelerated graphics, QML and JavaScript playing a major role. The traditional C++-only QWidgets continued to be supported, but did not benefit from the performance improvements available through the new architecture. Qt5 brings significant improvements to the speed and ease of developing user interfaces.
Framework development of Qt 5 moved to open governance, taking place at qt-project.org. It is now possible for developers outside Digia to submit patches and have them reviewed.
Software modules.
Starting with Qt 4.0 the framework was split into individual modules. With Qt 5.0 the architecture was modularized even further. Qt is now split into "essential" and "add-on" modules.
Tools.
Qt comes with its own set of tools to ease cross-platform development, that is otherwise cumbersome due to different set of development tools. Qt Creator is a cross-platform IDE for C++ and QML. Qt Designer's GUI layout/design functionality is integrated into this relatively new IDE, although Qt Designer can still be called as a standalone tool.
In addition to Qt Creator, Qt provides a handy makefile generation tool, qmake, a tool that automates the generation of Makefiles for development project across different platforms. Without qmake, one should write different makefiles for each platform, so it is a useful tool for transparent handling of differences in various platforms.
There are other tools available in Qt, including Qt Designer, Qt Assistant (both are embedded in Qt Creator now), Qt Linguist (for translating GUI), uic (user interface compiler), moc (Meta-object System compiler for handling Signals and slots). Various other converters, compiling and linking also released with Qt.
Programming language bindings.
Qt has a range of bindings for various languages, which implement some or all of its feature set.
Uses.
Organizations using Qt.
Because of simplicity, robustness, native performance, cross-platform compatibility and both commercial and open source licenses, many organizations in many parts of the world use Qt. These include but are not limited to European Space Agency, DreamWorks, Lucasfilm, Panasonic, Philips, Samsung, Siemens, Volvo, Walt Disney Animation Studios, Blizzard Entertainment
Software using Qt.
Example applications using Qt are Autodesk Maya; 
Mathematica; 
Google Earth; 
RStudio, an IDE for the R programming language; 
Skype;
Spotify for Linux;
VirtualBox, an OS virtualization software package; 
and the VLC media player.
The KDE desktop environment for UNIX-like operating systems uses Qt as its widget toolkit.
History.
Haavard Nord and Eirik Chambe-Eng (the original developers of Qt and the CEO and President, respectively, of Trolltech) began development of "Qt" in 1991, three years before the company was incorporated as Quasar Technologies, then changed the name to Troll Tech and then to Trolltech.
The toolkit was called Qt because the letter Q looked appealing in Haavard's Emacs typeface, and "t" was inspired by Xt, the X toolkit.
The first two versions of Qt had only two flavors: Qt/X11 for Unix and Qt/Windows for Windows. The Windows platform was only available under a proprietary license, which meant free/open source applications written in Qt for X11 could not be ported to Windows without purchasing the proprietary edition.
At the end of 2001, Trolltech released Qt 3.0, which added support for Mac OS X. The Mac OS X support was available only in the proprietary license until June 2003, when Trolltech released Qt 3.2 with Mac OS X support available under the GPL.
In June 2005, Trolltech released Qt 4.0.
Nokia acquired Trolltech ASA on 17 June 2008 and changed the name first to Qt Software, then to Qt Development Frameworks.
Since then it focused on Qt development to turn it into the main development platform for its devices, including a port to the Symbian S60 platform. Version 1.0 of the Nokia Qt SDK was released on 23 June 2010. The source code was made available over Gitorious, a community oriented git source code repository, to gather an even broader community that is not only using Qt but also helping to improve it.
In February 2011, Nokia announced its decision to drop Symbian technologies and base their future smartphones on Microsoft platform instead. One month later, Nokia announced the sale of Qt's commercial licensing and professional services to Digia, with the immediate goal of taking Qt support to Android, iOS and Windows 8 platforms, and to continue focusing on desktop and embedded development, although Nokia was to remain the main development force behind the framework at that time.
In March 2011, Nokia sold the commercial licensing part of Qt to Digia creating Qt Commercial. In August 2012, Digia announced that it will acquire Qt from Nokia The Qt team started working in Digia in September 2012. Qt team at Digia, released Qt 5.0 within a month, and released newer versions every 6 months with new features and additional supported platforms.
Licensing.
At all times, Qt was available under a commercial license that allows developing proprietary applications with no restrictions on licensing. In addition, Qt has been gradually made available under several increasingly free licenses.
Until version 1.45, source code for Qt was released under the FreeQt license. This was viewed as not compliant with the open source principle by the Open Source Initiative and the free software definition by Free Software Foundation because, while the source was available, it did not allow the redistribution of modified versions.
Controversy erupted around 1998 when it became clear that the K Desktop Environment (now known as the KDE Software Compilation) was going to become one of the leading desktop environments for Linux. As it was based on Qt, many people in the free software movement worried that an essential piece of one of their major operating systems would be proprietary.
With the release of version 2.0 of the toolkit, the license was changed to the Q Public License (QPL), a free software license but one regarded by the Free Software Foundation as incompatible with the GPL. Compromises were sought between KDE and Trolltech whereby Qt would not be able to fall under a more restrictive license than the QPL, even if Trolltech was bought out or went bankrupt. This led to the creation of the , which guarantees that Qt would fall under a BSD-style license should no free/open source version of Qt be released during 12 months.
In 2000, Qt/X11 2.2 was released under the GPL v2, ending all controversy regarding GPL compatibility.
In 2002, members of the KDE on Cygwin project began porting the GPL licensed Qt/X11 code base to Windows. This was in response to Trolltech's refusal to license Qt/Windows under the GPL on the grounds that Windows was not a free/open source software platform. The project achieved reasonable success although it never reached production quality.
This was resolved when Trolltech released Qt/Windows 4 under the GPL in June 2005. Qt 4 now supports the same set of platforms in the free software/open source editions as in the proprietary edition, so it is now possible to create GPL-licensed free/open source applications using Qt on all supported platforms. The GPL v3 with special exception was later added as an added licensing option. The GPL exception allows the final application to be licensed under various GPL-incompatible free software/open source licenses such as the Mozilla Public License 1.1.
On 14 January 2009, Qt version 4.5 added another option, the LGPL, which should make Qt even more attractive for non-GPL open source projects and for closed applications.
In March 2011, Nokia sold the commercial licensing part of Qt to Digia creating Qt Commercial. In September 2014, Digia transferred the Qt business and copyrights to their wholly owned subsidiary, the Qt Company.
References.
Bibliography.
</dl>

</doc>
<doc id="25207" url="http://en.wikipedia.org/wiki?curid=25207" title="QuakeC">
QuakeC

QuakeC is an interpreted language developed in 1996 by John Carmack of id Software to program parts of the video game "Quake". Using QuakeC, a programmer is able to customize "Quake" to great extents by adding weapons, changing game logic and physics, and programming complex scenarios. It can be used to control many aspects of the game itself, such as parts of the AI, triggers, or changes in the level. The "Quake" engine was the only game engine to use QuakeC. Following engines used DLL game modules for customization written in C and C++ from id Tech 4 on.
Overview.
The QuakeC source to the original id Software "Quake" game logic was published in 1996 and used as the basis for modifications like capture the flag and others. QuakeC source code is compiled using a tool called qcc into a bytecode kept in a file called progs.dat. The programmers of "Quake" modifications could then publish their progs.dat bytecode without revealing their source code. Most "Quake" mods were published this way.
QuakeC allowed the "Quake" engine to dominate the direction of the first-person shooter genre. Thanks to Carmack's idea of extending video game life by adding unlimited expandability (extensibility already played a big role in "Doom"), an enormous Internet community of gamers and programmers alike has arisen and many modern multiplayer games are extensible in some form.
QuakeC is known as interpreted because as "Quake" runs, it is continually interpreting the progs.dat file.
Limitations.
The syntax of QuakeC is based on that of the C programming language, explaining its name, but it does not support the implementation of new types, structures, arrays, or any kind of referencing other than the "entity" type (which is always a reference). QuakeC also suffers from the fact that many built-in functions (functions prototyped in the QuakeC code but actually defined within the game engine and written in C) return strings in a temporary string buffer, which can only hold one string at any given time. In other words, a construct such as
will fail because the second call to codice_2 (which converts a floating-point value to a string) overwrites the string returned by the first call before SomeFunction can do something with it. QuakeC does not contain any string handling functions or file handling functions, which were simply not needed by the original game.
Most video games at the time had their game logic written in plain C/C++ and compiled into the executable, which is faster. However, this makes it harder for the community to create mods and it makes the process of porting the game to another platform (such as GNU/Linux) more costly.
Despite its advantages, the concept of implementing the game logic in a separate scripting language and writing an interpreter for it was soon dropped (even by John Carmack who had implemented this concept) because of the overall inflexibility of an interpreted language, the increasingly complex game logic and the fact that the game logic could be packaged into a native dynamic link library whose source code could be released to the mod community.
Modified compilers and language extensions.
As is their custom to do with nearly everything they make, id Software released the source of codice_3, their QuakeC compiler, along with the original QuakeC code in 1996. Modified versions soon sprung up, including Jonathan Roy's codice_4 and Ryan "FrikaC" Smith's FrikQCC. These added functionality, optimizations, and compiling speed boosts.
In 1999, when id Software released the code from Quake's engine under the GNU General Public License (GPL), the workings of the bytecode interpreter were examined and new QuakeC compilers were released, such as J.P. Grossman's codice_5 and a new version of FrikQCC. These compilers took advantage of newly discovered features in a backwards-compatible way so that the bytecode could still be properly interpreted by unmodified Quake engines. New features include arrays, pointers, integers, for loops and string manipulation.
With the "Quake" engine source code now able to be changed, further features were added to QuakeC in the form of new built-in functions. Features long yearned for by QuakeC coders finally reached realization as QuakeC now had file and string handling functions, enlarged string buffers, more math functions, and so on. However, programmers taking advantage of these changes lost backwards compatibility with the unmodified Quake engine.
"Xonotic" since version 0.7 uses the compiler.

</doc>
<doc id="25208" url="http://en.wikipedia.org/wiki?curid=25208" title="Quad Cities">
Quad Cities

The Quad Cities is a region of four counties in northwest Illinois and Southeastern Iowa. The urban core consists of five principal cities: Davenport and Bettendorf in Iowa, and Rock Island, Moline, and East Moline in Illinois. These cities are the center of the Quad Cities Metropolitan Area, which, as of 2013, had a population estimate of 383,781 and a CSA (Combined Statistical Area) population of 474,937, making it the 90th largest CSA in the nation. 
History.
Early history.
Before European settlers came to inhabit the Quad Cities, the confluence of rivers had attracted many varying cultures of indigenous peoples, who used the waterways and riverbanks for their settlements for thousands of years. At the time of European encounter, it was a home and principal trading place of the Sauk and Fox tribes of Native Americans. "Saukenuk" was the principal village of the Sauk tribe and birthplace of its 19th-century war chief, Black Hawk. In 1832, Sauk chief "Keokuk" and General Winfield Scott signed a treaty in Davenport after the US defeated the Sauk and their allies in the Black Hawk War. The treaty resulted in the Native Americans' ceding 6 million acres (24,000 km²) of land to the United States in exchange for a much smaller reservation elsewhere. Black Hawk State Historic Site in Rock Island preserves part of historic Saukenuk and is listed on the National Register of Historic Places.
The history of urban settlements in the Quad-Cities was stimulated by riverboat traffic. For fourteen miles (21 km) between LeClaire, Iowa, and Rock Island, the Mississippi River flowed across a series of finger-like rock projections protruding from either bank. These rapids were difficult for steamboats to traverse. As demand for river-based transportation increased along the upper Mississippi, the navigability of the river throughout the "Rock Island Rapids" became a greater concern. Over time, a minor industry grew up in the area to meet the steamboats' needs. Boats needed rest areas to stop before encountering the rapids, places to hire expert pilots such as Phillip Suiter, who was the first licensed pilot on the upper Mississippi River, to guide the boat through the rocky waters, or, when the water was low, places where goods could be removed and transported by wagon on land past the Rapids. (Today, the troublesome rocks are submerged six feet underwater by a lake formed by two locks and dams.)
As the Industrial Revolution developed in the United States, many enterprising industrialists looked to the Mississippi River as a promising source of water power. The combination of energy and easy access to river transportation attracted entrepreneurs and industrialists to the Quad Cities for development. In 1848, John Deere moved his plough business to Moline. His business was incorporated as Deere & Company in 1868. Deere & Company is the largest employer today in the Quad Cities.
The first railroad bridge built across the Mississippi River connected Davenport and Rock Island in 1856. It was built by the Rock Island Railroad Company, and replaced the slow seasonal ferry service and winter ice bridges as the primary modes of transportation across the river. Steamboaters saw the nationwide railroads as a threat to their business. On May 6, 1856, just weeks after completion of the bridge, an angry steamboater crashed the "Effie Afton" into it. John Hurd, the owner of the "Effie Afton", filed a lawsuit against The Rock Island Railroad Company. The Rock Island Railroad Company selected Abraham Lincoln as their trial lawyer and won after he took the case to the US Supreme Court. Phillip Suiter was one of his expert witnesses. It was a pivotal trial in Lincoln's career.
Evolution of an identity.
After the Civil War, the region began to gain a common identity. The river towns that were thoughtfully planned and competently led flourished, while other settlements, usually get-rich-quick schemes for speculators, failed to pan out. By World War I, the towns of Davenport, Rock Island, and Moline had begun to style themselves as the Tri-Cities, a cluster of three more-or-less equally sized river communities growing around the small bend of the Mississippi River where it flows west. But with the growth of Rock Island County, during the 1930s the term Quad Cities came into vogue, as East Moline was given "equal status". Despite the fact that the region had earned the name "Quad Cities," the National Basketball Association had a franchise in Moline, Illinois from 1946 to 1951 called the Tri-Cities Blackhawks. Then, with the opening of an Alcoa plant East of Davenport in 1948, the town of Bettendorf underwent so much growth that many people in the community discussed the adoption of the name Quint Cities. And indeed, eventually Bettendorf passed East Moline in size. But by this time, the name "Quad Cities" had become known well beyond the area, and "Quint Cities" never caught on, despite the efforts of WOC-TV (as KWQC-TV was then called) and others.
1980s–current.
Beginning in the late 1970s, economic conditions caused major industrial restructuring, which disrupted the basis of the region's economy. The major companies, agricultural manufacturers, ceased or scaled back operations in the Quad Cities. Factories which closed included International Harvester in Rock Island and Case IH in Bettendorf. Moline-based John Deere cut its labor headcount by one half. Later in the 1980s, Caterpillar Inc. closed its factories at Mount Joy and Bettendorf.
Since the 1990s, the Quad Cities governments, businesses, non-profits and residents have worked hard to redevelop the region. They have achieved national attention for their accomplishments.
Examples of revitalization and rebirth:
Geography.
The Quad Cities are located at the confluence of the Rock and Mississippi rivers, approximately 140 mi west of Chicago, and is the largest metropolitan area along the Mississippi River between Minneapolis–Saint Paul and the St. Louis metropolitan area. Interstate 80 crosses the Mississippi River here. The Quad Cities area is distinctive because the Mississippi River flows from east to west as it passes through the heart of the area; the Iowa cities of Davenport and Bettendorf are located due north of Rock Island and Moline, respectively.
The Quad Cities area is one where the telephone companies cooperate with regional phone calls. Iowa and Illinois have different area codes (563 and 309 respectively), yet most calls originating and terminating within the core urban area are placed without long-distance charges by dialing just a 7-digit number. This helps the bi-state area promote itself as a single community, "joined by a river."
The Quad Cities Metropolitan Area consists of three counties: Scott County in Iowa, Rock Island County, and western Henry County county in Illinois. The Quad City metro population is 272,000. The Quad Cities Metropolitan Area is also considered part of the Great Lakes Megalopolis.
Top employers.
According to Quad Cities website, the top employers in the Quad Cities area are:
Culture.
Since 1916, the region has supported the Quad City Symphony Orchestra, which presents a year-round schedule of concerts at the Adler Theatre in Davenport and Centennial Hall in Rock Island. The Handel Oratorio Society, dating to 1880, is the second-oldest organization of its kind in the nation and presents annual performances of "Messiah" along with another major work for choir and orchestra. The Augustana Choir, founded at Rock Island's Augustana College in 1934, is one of the nation's leading collegiate choruses. Major outdoor summer music festivals include the Bix Beiderbecke Memorial Jazz Festival, Mississippi Valley Blues Festival, and River Roots Live.
The Quad-Cities' three traditional community theaters – Playcrafters Barn Theatre (founded in 1920, comedies and dramas) and Quad City Music Guild (1948, musicals) in Moline, and Genesius guild (1957, outdoor Shakespeare and Greek comedies and tragedies) in Rock Island – were joined in 1976 by Circa '21 Dinner Playhouse, a professional dinner theater in downtown Rock Island's historic Fort Theatre. Ballet is performed at Ballet Quad Cities. The River Music Experience provides quality music programming, education, and outreach to all cities.ComedySportz provides improv comedy. Bluebox Limited is a Bettendorf-based film production company, and many outside productions companies have filmed movies in the Quad Cities in recent years. Historic buildings and sites listed on state and the National Register of Historic Places interpret the history of people's settlement and lives in the area.
Media.
The Quad Cities is the 151st largest radio market in the United States. It is ranked 97th by Nielsen Media Research for the 2008-2009 television season with 309,600 television households.
The area is served by over 13 commercial radio stations, 8 non-commercial radio stations, 3 low power FM radio stations, 8 TV stations and 3 daily newspapers.
In 2012, the Mississippi Valley Fair that is held in Davenport served as the film location for Rodney Atkins' music video "Just Wanna Rock N' Roll."
Also in 2012, the PBS Frontline documentary "Poor Kids" was filmed in and around the Quad Cities showing poverty from a child's perspective.
Transportation.
Four interstate highways serve the Quad Cities: Interstate 80, Interstate 280, Interstate 74 serve both states while Interstate 88 serves just Illinois. United States highways include U.S. Route 6 and U.S. Route 67 which run through both Iowa and Illinois, while U.S. Route 61 serves just Iowa and U.S. Route 150 serves just Illinois.
A total of five bridges accessible by automobiles connect Iowa with Illinois in the Quad Cities across the Mississippi River. The Fred Schwengel Memorial Bridge carries Interstate 80 and connects Le Claire, Iowa, with Rapids City, Illinois. Continuing downstream, the I-74 Bridge connects Bettendorf, Iowa, with Moline, Illinois, and is the busiest bridge with an average of 70,400 cars a day. The Government Bridge connects Downtown Davenport with the Rock Island Arsenal. Three bridges connect Davenport with Rock Island, Illinois; The Rock Island Centennial Bridge, The Crescent Rail Bridge, and the furthest downstream bridge, the Sergeant John F. Baker, Jr. Bridge which carries I-280.
Several state highways also serve the area. Iowa Highway 22 is on Davenport's southwest side and runs west through the county, while Iowa Highway 130 runs along Northwest Boulevard on Davenport's north edge. Illinois Route 5 (John Deere Road) runs from Rock Island east till it runs into Interstate 88. Illinois Route 92 runs along the Mississippi River, while Illinois Route 84 runs along the east side of Rock Island County. Illinois Route 192 connects Highway 92 with Illinois Route 94 near Taylor Ridge. The Chicago – Kansas City Expressway also serves the area along Interstates 74, 80, and 88.
There are three transit operators in the Quad Cities with limited interconnection between them. Rock Island County Metropolitan Mass Transit District (Quad Cities MetroLINK) serves the Illinois cities of Rock Island, Moline, East Moline, Milan, Silvis, Carbon Cliff, Hampton and Colona. It has 12 routes and a fleet of about 52 buses. It operates a river craft during summer months. In Iowa, Davenport Citibus has 13 fixed routes and operates 20 buses, six days a week and Bettendorf Transit operates five routes, Monday–Saturday, and has eight buses.
Amtrak currently does not serve the Quad Cities. The closest station is about 50 mi away in Galesburg, Illinois. In 2008, the two current United States Senators from Iowa, Tom Harkin and Chuck Grassley, Illinois Senator Dick Durbin, and former Senator Barack Obama sent a letter to Amtrak asking them to begin plans to bring rail service to the Quad Cities. In October 2010, a $230 million federal fund was announced that will bring Amtrak service to the Quad Cities, with a new line running from Moline to Chicago. They hope to have the line completed in 2015, and offer two round trips daily to Chicago. In December 2011, the federal government awarded $177 million in funding for the Amtrak connection. It will establish passenger rail for the first time since the 1970s.
The Quad Cities are served by the Quad City International Airport, Illinois' third-busiest airport, located in Moline. The airport is marketed as a regional alternative to the larger airports in Chicago, nearly 200 mi away. The smaller Davenport Municipal Airport is the home of the Quad City Air Show.
Sports teams.
From 1920 to 1926, Rock Island was home to the NFL's Rock Island Independents. Football legend Jim Thorpe was once a member of the team.
The Tri-Cities Blackhawks, named in honor of the Sauk war chief Black Hawk, was the next top-level professional sports franchise. The club played in the National Basketball League (NBL) from 1946 until its merger in 1949 with the Basketball Association of America to became the National Basketball Association (NBA). Hall of famer Red Auerbach coached the Blackhawks during their first NBA season.
After the 1950–51 basketball season, the team moved to Milwaukee, where they were named the Hawks. After a second move to St. Louis, the team is now the Atlanta Hawks.
Professional basketball returned to the Quad Cities during the 1980s and 1990s with the Quad City Thunder of the Continental Basketball Association. The CBA served as the NBA's premiere developmental league and produced many highly regarded NBA stars. From 1987 through the 1992–93 season, the Thunder played at Wharton Field House in Moline. Starting with the 1993–94 season, the team played at The MARK of the Quad Cities (now the iWireless Center.) After the CBA folded in 2001, the Thunder franchise ceased operations permanently.

</doc>
<doc id="25211" url="http://en.wikipedia.org/wiki?curid=25211" title="Quantum chemistry">
Quantum chemistry

Quantum chemistry is a branch of chemistry whose primary focus is the application of quantum mechanics in physical models and experiments of chemical systems. It is also called molecular quantum mechanics.
Overview.
It involves heavy interplay of experimental and theoretical methods:
In these ways, quantum chemists investigate chemical phenomena.
History.
Some view the birth of quantum chemistry in the discovery of the Schrödinger equation and its application to the hydrogen atom in 1926. However, the 1927 article of Walter Heitler and Fritz London is often recognised as the first milestone in the history of quantum chemistry. This is the first application of quantum mechanics to the diatomic hydrogen molecule, and thus to the phenomenon of the chemical bond. In the following years much progress was accomplished by Edward Teller, Robert S. Mulliken, Max Born, J. Robert Oppenheimer, Linus Pauling, Erich Hückel, Douglas Hartree, Vladimir Aleksandrovich Fock, to cite a few. The history of quantum chemistry also goes through the 1838 discovery of cathode rays by Michael Faraday, the 1859 statement of the black body radiation problem by Gustav Kirchhoff, the 1877 suggestion by Ludwig Boltzmann that the energy states of a physical system could be discrete, and the 1900 quantum hypothesis by Max Planck that any energy radiating atomic system can theoretically be divided into a number of discrete energy elements "ε" such that each of these energy elements is proportional to the frequency "ν" with which they each individually radiate energy and a numerical value called Planck’s Constant. Then, in 1905, to explain the photoelectric effect (1839), i.e., that shining light on certain materials can function to eject electrons from the material, Albert Einstein postulated, based on Planck’s quantum hypothesis, that light itself consists of individual quantum particles, which later came to be called photons (1926). In the years to follow, this theoretical basis slowly began to be applied to chemical structure, reactivity, and bonding. Probably the greatest contribution to the field was made by Linus Pauling.
Electronic structure.
The first step in solving a quantum chemical problem is usually solving the Schrödinger equation (or Dirac equation in relativistic quantum chemistry) with the electronic molecular Hamiltonian. This is called determining the electronic structure of the molecule. It can be said that the electronic structure of a molecule or crystal implies essentially its chemical properties. An exact solution for the Schrödinger equation can only be obtained for the hydrogen atom (though exact solutions for the bound state energies of the hydrogen molecular ion have been identified in terms of the generalized Lambert W function). Since all other atomic, or molecular systems, involve the motions of three or more "particles", their Schrödinger equations cannot be solved exactly and so approximate solutions must be sought.
Wave model.
The foundation of quantum mechanics and quantum chemistry is the wave model, in which the atom is a small, dense, positively charged nucleus surrounded by electrons. Unlike the earlier Bohr model of the atom, however, the wave model describes electrons as "clouds" moving in orbitals, and their positions are represented by probability distributions rather than discrete points. The strength of this model lies in its predictive power. Specifically, it predicts the pattern of chemically similar elements found in the periodic table. The wave model is so named because electrons exhibit properties (such as interference) traditionally associated with waves. See wave-particle duality.
Valence bond.
Although the mathematical basis of quantum chemistry had been laid by Schrödinger in 1926, it is generally accepted that the first true calculation in quantum chemistry was that of the German physicists Walter Heitler and Fritz London on the hydrogen (H2) molecule in 1927. Heitler and London's method was extended by the American theoretical physicist John C. Slater and the American theoretical chemist Linus Pauling to become the Valence-Bond (VB) [or Heitler–London–Slater–Pauling (HLSP)] method. In this method, attention is primarily devoted to the pairwise interactions between atoms, and this method therefore correlates closely with classical chemists' drawings of bonds.
Molecular orbital.
An alternative approach was developed in 1929 by Friedrich Hund and Robert S. Mulliken, in which electrons are described by mathematical functions delocalized over an entire molecule. The Hund–Mulliken approach or molecular orbital (MO) method is less intuitive to chemists, but has turned out capable of predicting spectroscopic properties better than the VB method. This approach is the conceptional basis of the Hartree–Fock method and further post Hartree–Fock methods.
Density functional theory.
The Thomas–Fermi model was developed independently by Thomas and Fermi in 1927. This was the first attempt to describe many-electron systems on the basis of electronic density instead of wave functions, although it was not very successful in the treatment of entire molecules. The method did provide the basis for what is now known as density functional theory. Modern day DFT uses the Kohn-Sham method, where the density functional is split into four terms; the Kohn-Sham kinetic energy, an external potential, exchange and correlation energies. A large part of the focus on developing DFT is on improving the exchange and correlation terms. Though this method is less developed than post Hartree–Fock methods, its significantly lower computational requirements (scaling typically no worse than formula_1 with respect to formula_2 basis functions, for the pure functionals) allow it to tackle larger polyatomic molecules and even macromolecules. This computational affordability and often comparable accuracy to MP2 and CCSD(T) (post-Hartree–Fock methods) has made it one of the most popular methods in computational chemistry at present.
Chemical dynamics.
A further step can consist of solving the Schrödinger equation with the total molecular Hamiltonian in order to study the motion of molecules. Direct solution of the Schrödinger equation is called "quantum molecular dynamics", within the semiclassical approximation "semiclassical molecular dynamics", and within the classical mechanics framework "molecular dynamics (MD)". Statistical approaches, using for example Monte Carlo methods, are also possible.
Adiabatic chemical dynamics.
In adiabatic dynamics, interatomic interactions are represented by single scalar potentials called potential energy surfaces. This is the Born–Oppenheimer approximation introduced by Born and Oppenheimer in 1927. Pioneering applications of this in chemistry were performed by Rice and Ramsperger in 1927 and Kassel in 1928, and generalized into the RRKM theory in 1952 by Marcus who took the transition state theory developed by Eyring in 1935 into account. These methods enable simple estimates of unimolecular reaction rates from a few characteristics of the potential surface.
Non-adiabatic chemical dynamics.
Non-adiabatic dynamics consists of taking the interaction between several coupled potential energy surface (corresponding to different electronic quantum states of the molecule). The coupling terms are called vibronic couplings. The pioneering work in this field was done by Stueckelberg, Landau, and Zener in the 1930s, in their work on what is now known as the Landau–Zener transition. Their formula allows the transition probability between two diabatic potential curves in the neighborhood of an avoided crossing to be calculated.

</doc>
<doc id="25213" url="http://en.wikipedia.org/wiki?curid=25213" title="QWERTY">
QWERTY

QWERTY (pronounced or ) is the most common modern-day keyboard layout for Latin script. The name comes from reading the first six keys appearing on the top left letter row of the keyboard (Q, W, E, R, T, and Y) from left to right. The QWERTY design is based on a layout created for the Sholes and Glidden typewriter and sold to Remington in 1873. It became popular with the success of the Remington No. 2 of 1878, and remains in use on electronic keyboards due to the network effect of a standard layout and a belief that alternatives fail to provide very significant advantages. The use and adoption of the QWERTY keyboard is often viewed as one of the most important case studies in open standards because of the widespread, collective adoption and use of the product.
History and purposes.
The QWERTY layout was devised and created in the early 1870s by Christopher Latham Sholes, a newspaper editor and printer who lived in Milwaukee, Wisconsin. In October 1867, Sholes filed a patent application for his early writing machine he developed with the assistance of his friends Carlos Glidden and Samuel W. Soulé.
The first model constructed by Sholes used a piano-like keyboard with two rows of characters arranged alphabetically as follows:
 - 3 5 7 9 N O P Q R S T U V W X Y Z<br> 2 4 6 8 . A B C D E F G H I J K L M
The construction of the "Type Writer" had two flaws that made the product susceptible to jams.
Firstly, characters were mounted on metal arms or typebars, which would clash and jam if neighboring arms were pressed at the same time or in rapid succession. Secondly, its printing point was located beneath the paper carriage, invisible to the operator, a so-called "up-stroke" design. Consequently, jams were especially serious, because the typist could only discover the mishap by raising the carriage to inspect what had been typed. The solution was to place commonly used letter-pairs (like "th" or "st") so that their typebars were not neighboring, avoiding jams.
Contrary to popular belief, the QWERTY layout was not designed to slow the typist down, but rather to speed up typing by preventing jams. There is also evidence that, aside from the issue of jamming, keys being farther apart increases typing speed on its own, because it encourages alternation between the hands. Almost every word in the English language contains at least one vowel letter, but on the QWERTY keyboard only the vowel letter "A" is located on the home row, which requires the typist's fingers to leave the home row for most words.
Sholes struggled for the next five years to perfect his invention, making many trial-and-error rearrangements of the original machine's alphabetical key arrangement. The study of bigram (letter-pair) frequency by educator Amos Densmore, brother of the financial backer James Densmore, is believed to have influenced the arrangement of letters, but was later called into question. Others dispute that slowing down the typist was the purpose, suggesting instead that the letter arrangement evolved from telegraph operators' feedback.
In November 1868 he changed the arrangement of the latter half of the alphabet, O to Z, right-to-left. In April 1870 he arrived at a four-row, upper case keyboard approaching the modern QWERTY standard, moving six vowel letters, A, E, I, O, U, and Y, to the upper row as follows:
   2 3 4 5 6 7 8 9 -<br>    A E I . ? Y U O ,<br>B C D F G H J K L M<br>Z X W V T S R Q P N
In 1873 Sholes's backer, James Densmore, successfully sold the manufacturing rights for the Sholes & Glidden Type-Writer to E. Remington and Sons. The keyboard layout was finalized within a few months by Remington's mechanics and was ultimately presented as follows:
   2 3 4 5 6 7 8 9 - ,<br>Q W E . T Y I U O P<br>Z S D F G H J K L M<br>A X & C V B N ? ; R
After it purchased the device, Remington made several adjustments which created a keyboard with what is essentially the modern QWERTY layout. Their adjustments included placing the "R" key in the place previously allotted to the period key. This has been claimed to be done with the purpose of enabling salesmen to impress customers by pecking out the brand name "TYPE WRITER" from one keyboard row. While this claim is not formally substantiated, the odds of this occurring by chance are about 5500 to 1 (.018%). Additionally, there are only five English ten-letter words that can be spelled using just the letters in the top row: perpetuity, prerequire, proprietor, repertoire, and typewriter. Vestiges of the original alphabetical layout remained in the "home row" sequence DFGHJKL.
The modern layout is:
 1 2 3 4 5 6 7 8 9 0 - =<br>Q W E R T Y U I O P [ ] \<br>A S D F G H J K L ; '<br>Z X C V B N M , . /
The QWERTY layout became popular with the success of the Remington No. 2 of 1878, the first typewriter to include both upper and lower case letters, via a shift key.
Much less commented-on than the order of the keys is that the keys are not on a grid, but rather that each column slants diagonally; this is because of the mechanical linkages – each key being attached to a lever, and hence the offset prevents the levers from running into each other – and has been retained in most electronic keyboards. Some keyboards, such as the Kinesis or TypeMatrix, retain the QWERTY layout but arrange the keys in vertical columns, to reduce unnecessary lateral finger motion.
Differences from modern layout.
Substituting characters.
The QWERTY layout depicted in Sholes's 1878 patent includes a few differences from the modern layout, most notably in the absence of the numerals 0 and 1, with each of the remaining numerals shifted one position to the left of their modern counterparts. The letter M is located at the end of the third row to the right of the letter L rather than on the fourth row to the right of the N, the letters X and C are reversed, and most punctuation marks are in different positions or are missing entirely. 0 and 1 were omitted to simplify the design and reduce the manufacturing and maintenance costs; they were chosen specifically because they were "redundant" and could be recreated using other keys. Typists who learned on these machines learned the habit of using the uppercase letter I (or lowercase letter L) for the digit one, and the uppercase O for the zero.
Combined characters.
In early designs, some characters were produced by printing two symbols with the carriage in the same position. For instance, the exclamation point, which shares a key with the numeral 1 on modern keyboards, could be reproduced by using a three-stroke combination of an apostrophe, a backspace, and a period. A semicolon (;) was produced by printing a comma (,) over a colon (:). As the backspace key is slow in simple mechanical typewriters (the carriage was heavy and optimized to move in the opposite direction), a more professional approach was to block the carriage by pressing and holding the space bar while printing all characters that needed to be in a shared position. To make this possible, the carriage was designed to advance forward only after releasing the space bar.
The 0 key was added and standardized in its modern position early in the history of the typewriter, but the 1 and exclamation point were left off some typewriter keyboards into the 1970s.
Contemporary alternatives.
There was no particular technological requirement for the QWERTY layout since at the time there were ways to make a typewriter without the "up-stroke" typebar mechanism that had required it to be devised. Not only were there rival machines with "down-stroke" and "frontstroke" positions that gave a visible printing point, the problem of typebar clashes could be circumvented completely: examples include Thomas Edison's 1872 electric print-wheel device which later became the basis for Teletype machines; Lucien Stephen Crandall's typewriter (the second to come onto the American market) whose type was arranged on a cylindrical sleeve; the Hammond typewriter of 1887 which used a semi-circular "type-shuttle" of hardened rubber (later light metal); and the Blickensderfer typewriter of 1893 which used a type wheel. The early Blickensderfer's "Ideal" keyboard was also non-QWERTY, instead having the sequence "DHIATENSOR" in the home row, these 10 letters being capable of composing 70% of the words in the English language.
Properties.
Alternating hands while typing is a desirable trait in a keyboard design. While one hand types a letter, the other hand can prepare to type the next letter making the process faster and more efficient. However, when a string of letters is done with the same hand, the chances of stuttering are increased and a rhythm can be broken, thus decreasing speed and increasing errors and fatigue. In the QWERTY layout many more words can be spelled using only the left hand than the right hand. In fact, thousands of English words can be spelled using only the left hand, while only a couple of hundred words can be typed using only the right hand. In addition, most typing strokes are done with the left hand in the QWERTY layout. This is helpful for left-handed people but to the disadvantage of right-handed people.
Computer keyboards.
The first computer terminals such as the Teletype were typewriters that could produce and be controlled by various computer codes. These used the QWERTY layouts and added keys such as escape (ESC) which had special meanings to computers. Later keyboards added function keys and arrow keys. Since the standardization of PC-compatible computers and Windows after the 1980s, most full-sized computer keyboards have followed this standard (see drawing at right). This layout has a separate numeric keypad for data entry at the right, 12 function keys across the top, and a cursor section to the right and center with keys for Insert, Delete, Home, End, Page Up, and Page Down with cursor arrows in an inverted-T shape.
Diacritical marks and international variants.
Different computer operating systems have methods of support for input of different languages such as Chinese, Hebrew or Arabic. QWERTY is designed for English, a language without any diacritical marks. QWERTY keyboards meet issues when having to type an accent. Until recently, no norm was defined for a standard QWERTY keyboard layout allowing the typing of accented characters. The so called “US-International layout” is, in fact, OS-dependent.
Depending on the operating system and sometimes the application program being used, there are many ways to generate Latin characters with accents.
United Kingdom (Extended) Layout.
Microsoft has included a variant of the British QWERTY keyboard from Windows XP SP2 and onwards, that can additionally generate a number of diacritical marks, useful when working with text in other languages, including Welsh - the native language of Wales, a constituent country in the UK.
Apple's Mac OS X doesn't include UK Extended, as it has key combinations for accents on any keyboard layout.
The UK International keyboard uses the AltGr key to produce diacritics.
These combinations are designed to be easy to remember, as the circumflex accent (e.g. â) is similar to a caret (^), printed above the 6 key; the diaeresis (e.g. ö) is similar to the double-quote (") above 2 on the UK keyboard; the tilde (~) is printed on the same key as the #.
Despite being created for multilingual users, UK-Extended does have some gaps - it does not cater for many languages, including Romanian and Turkish, or any using different character sets such as Greek and Russian. It also does not cater for the ß used in German, nor the å, æ, ø used in Nordic languages.
International variants.
Minor changes to the arrangement are made for other languages. There are a large number of different keyboard layouts used for different languages written in Latin script. They can be divided into three main families according to where the Q, A, Z, M, and Y keys are placed on the keyboard. These are usually named after the first six letters.
Canadian.
English-speaking Canadians have traditionally most often used the same keyboard layout as in the United States, unless they are in a position where they have to write French on a regular basis. French-speaking Canadians respectively have favoured the Canadian French keyboard layout (see below).
Canadian Multilingual Standard.
The Canadian Multilingual Standard keyboard layout is used by some Canadians. Though this keyboard lacks the caret (^) character, this is easily accomplished by typing the circumflex accent followed by a space.
Quebec French.
This keyboard layout is commonly used in Canada by French-speaking Canadians. It is the most common layout for laptops and stand-alone keyboards targeting French speakers. Unlike the French layout used in Europe, the Canadian French layout is a true QWERTY and as such is also relatively commonly used by English speakers in the US and Canada (using standard QWERTY keyboards) for easy access to accented letters found in some of the French words commonly used in English. It can be used to type all accented French characters, as well as some from other languages. It also serves all English functions as well. It is popular mainly because of its close similarity to the basic US keyboard commonly used by English-speaking Canadians and Americans, historical use of US-made typewriters by French-Canadians, and is the standard for keyboards in Quebec. Use of the European French layout in Quebec is practically unheard of.
In some variants of this keyboard “Caps Lock” is “Fix Maj” (short for Fix Majuscule = Lock Upper Case) or “Verr Maj” (short for Vérouiller Majuscule = Lock Upper Case), “Enter” is “Entrée”, and “Esc” is “Échap”.
Czech (QWERTY).
The typewriter came to the Czech-speaking area in the late 19th century, when it was part of Austria-Hungary where German was the dominant language of administration. Therefore, Czech typewriters have the QWERTZ layout.
However, with the introduction of imported computers, especially since the 1990s, the QWERTY keyboard layout is frequently used for computer keyboards, too. Czech QWERTY layout differs from QWERTZ in that the characters (e.g. @$& and others) missing from the Czech keyboard are accessible with AltGr on the same keys where they are located on American keyboard. In Czech QWERTZ keyboard the position of these characters accessed through AltGr differs.
Danish.
Both the Danish and Norwegian keyboards include dedicated keys for the letters Å/å, Æ/æ and Ø/ø, but the placement is a little different, as the Æ and Ø keys are swapped on the Norwegian layout. (The Finnish–Swedish keyboard is also largely similar to the Norwegian layout, but the Ø and Æ are replaced with Ö and Ä. On some systems, the Danish keyboard may allow typing Ö/ö and Ä/ä by holding the AltGr or Option key while striking Ø and Æ, respectively.)
Dutch (Netherlands).
This is a modern version of the Dutch layout. An older version contained a single-stroke key for the Dutch character 'ij' or 'IJ' which is usually typed by the combination of an 'i' and an 'j'. In the 1990s there was a version with the now-obsolete florin sign (Dutch: guldenteken) for IBM PCs. It has additions for the € sign, the ¨ (diaresis) and more, and the braces (“{ }”) and other symbols are differently located. The Dutch layout is seldom used. Most computers in The Netherlands use the US International layout.
The Dutch keyboard layout is "QWERTY". However, in Flanders (the Dutch-speaking part of Belgium), “AZERTY” keyboards are used instead, due to influence from the French-speaking part of Belgium.
Estonian.
The keyboard layout used in Estonia is virtually the same as the Swedish layout. The main difference is that the Å and ¨ keys (to the right of P) are replaced with Ü and Õ respectively (the latter letter being the most distinguishing feature of the Estonian alphabet). Some special symbols and dead keys are also moved around.
Faroese.
Basically the same as the Danish layout with added Đ, since the Faroese Islands are a self-governed part of the Kingdom of Denmark.
Finnish multilingual.
The visual layout used in Finland is basically the same as the Swedish layout. This is practical, as Finnish and Swedish share the special characters Ä/ä and Ö/ö, and while the Swedish Å/å is unnecessary for writing Finnish, it is needed by Swedish-speaking Finns.
As of 2008, there is a new standard for the Finnish multilingual keyboard layout, developed as part of a localization project by CSC. All the engravings of the traditional Finnish–Swedish visual layout have been retained, so there is no need to change the hardware, but the functionality has been extended considerably, as additional characters (e.g., Æ/æ, Ə/ə, Ʒ/ʒ) are available through the AltGr key, as well as dead keys, which allow typing a wide variety of letters with diacritics (e.g., Ç/ç, Ǥ/ǥ, Ǯ/ǯ).
Based on the Latin letter repertory included in the Multilingual European Subset No. 2 (MES-2) of the Unicode standard, the layout has three main objectives. First, it provides for easy entering of text in both Finnish and Swedish, the two official languages of Finland, using the familiar keyboard layout but adding some advanced punctuation options, such as dashes, typographical quotation marks, and the non-breaking space (NBSP).
Second, it is designed to offer an indirect but intuitive way to enter the special letters and diacritics needed by the other three Nordic national languages (Danish, Norwegian and Icelandic) as well as the regional and minority languages (Northern Sámi, Southern Sámi, Lule Sámi, Inari Sámi, Skolt Sámi, Romani language as spoken in Finland, Faroese, Kalaallisut a.k.a. Greenlandic, and German).
As a third objective, it allows for relatively easy entering of particularly names (of persons, places or products) in a variety of European languages using a more or less extended Latin alphabet, such as the official languages of the European Union (excluding Bulgarian and Greek). Some letters, like Ł/ł needed for Slavic languages, are accessed by a special “overstrike” key combination acting like a dead key. 
However, the Romanian letters Ș/ș and Ț/ț (S/s and T/t with comma below) are not supported; the presumption is that Ş/ş and Ţ/ţ (with cedilla) suffice as surrogates.
Icelandic.
The Icelandic keyboard layout is different from the standard QWERTY keyboard because the Icelandic alphabet has some special letters, most of which it shares with the other Nordic countries:
Þ/þ, Ð/ð, Æ/æ and Ö/ö. (Æ/æ also occurs in Norwegian, Danish and Faroese, Ð/ð in Faroese, and Ö/ö in Swedish, Finnish and Estonian.)
The letters Á/á, Ý/ý, Ú/ú, Í/í, and É/é can be produced with the Icelandic keyboard by first pressing the ° or ⇧ Shift+° (for ¨) dead key located below the Esc key, and then the corresponding letter. (i.e. ° followed by A yields "å") These letters are not used natively in Icelandic, but may have been implemented for ease of communication in other Nordic languages.
Irish.
The default keyboard layout for Irish on Microsoft Windows is similar to the UK layout with two exceptions. The keyboards have the same keys with the same markings but (1) the default use for key left of “1”, is a grave dead key (this change is also made on UK-Extended) and (2) when AltGr is pressed, the apostrophe key becomes an acute dead key.
Italian.
There is an alternate layout, which differs only in disposition of characters accessible through AltGr, and includes the tilde and the curly brackets. It is commonly used in IBM keyboards.
Italian typewriters often have the QZERTY layout instead.
Latvian.
Latvian keyboard layout is same as latin ones, but with a dead key, which allows entering special characters (āčēģīķļņšūž, sometimes ō and ŗ). Most common dead key is apostrophe ('), which is followed by Alt+Gr (Windows default for Latvian layout). Some prefer using tick (`).
Maltese.
The Maltese language uses Unicode (UTF-8) to display the Maltese diacritics: ċ Ċ; ġ Ġ; ħ Ħ; ż Ż (together with à À; è È; ì Ì; ò Ò; ù Ù). There are 2 standard keyboard layouts for Maltese, according to “MSA 100:2002 Maltese Keyboard Standard”; one of 47 keys and one of 48 keys. For the layout design click here: https://www.mita.gov.mt/MediaCenter/Images/1_Fonts_Pic1.jpg. The 48-key layout is the most popular.
Norwegian.
The Norwegian languages use the same letters as Danish, but the Norwegian keyboard differs from the Danish layout regarding the placement of the Ø, Æ and \ (backslash) keys. On the Danish keyboard, the Ø and Æ are swapped. The Finnish–Swedish keyboard is also similar to the Norwegian layout, but Ø and Æ are replaced with Ö and Ä. On some systems, the Norwegian keyboard may allow typing Ö/ö and Ä/ä by holding the AltGr or Option key while striking Ø and Æ, respectively.
There is also an alternative keyboard layout called "Norwegian with Sámi", which allows for easier input of the characters required to write various Sámi (also known as Lapp) languages. All the Sámi characters are accessed through the AltGr key.
On Macintosh computers, the "Norwegian" and "Norwegian extended" keyboard layouts have a slightly different placement for some of the symbols obtained with the help of the Shift or Option keys. Notably, the "$" sign is accessed with ⇧ Shift+4 and "¢" with ⇧ Shift+⌥ Option+4. Furthermore, the frequently used "@" is placed between Æ and Return.
Persian (Farsi).
The Persian keyboard is contributed by Desphilic group for writing Internationalized Persian language. It supports Unipers characters [ ä š ü ž] and an additional set of Desphilic extended character [ ö ķ ğ ] and their Capitals [ Ä Š Ü Ž Ö Ķ Ğ ]. These characters are added to Latin-1 character set to form Persian Roman alphabet. The keyboard is in increasing use specially in Persian chat. It is intended to be used as a base for future standards for a Universal Persian Keyboard. The keyboard is likely to be agreed by two Persian Romanization standards (Desphilic and Unipers) and is used for transliteration of Persian and writing Persian Latin alphabet.
Polish.
Most typewriters use a QWERTZ keyboard with Polish accented letters accessed directly (officially approved as “Typist's keyboard”, Polish: "klawiatura maszynisty", Polish Standard PN-87), which is mainly ignored in Poland as impractical (except custom-made, e.g., in public sector and some Apple computers); the “Polish programmer's” (Polish: "polski programisty") layout has become the "de facto" standard, used on virtually all computers sold on the Polish market.
Polish programmers use QWERTY keyboards identical with the standard US layout. In this layout Polish letters are accessed in the same manner as the usage of keyboard shortcuts, with Latin letter keys in combination with right "Alt" (actually working as "AltGr") key. These key combinations (excluding one for “€”) obey states of both "Shift" and "Caps Lock" keys, preserving normal capitalization while typing Polish characters. For example, to obtain capital “Ź” pressing "Shift-"right"Alt-X" is needed, with "Caps Lock" off. The use of the right "Alt" in Polish programmers layout may be confused with "Alt-A", "Alt-C" etc. (which are common shortcuts in most programs and can be obtained only with left "Alt") because the key really acting as "AltGr" is also marked as "Alt". This is because most keyboards sold in Poland are US-layout with "Alt" marked on both keys, without "AltGr" (although Microsoft still depicts it with "AltGr" marking).
Also, on MS Windows, the tilde character ("Shift"+"`" ) acts as a dead key to type Polish letters (with diacritical marks) thus, to obtain an "Ł", one may press "~" followed by "L". The tilde character is obtained with "~" and "space".
Portuguese.
See Portuguese keyboard layout
Brazil.
The Brazilian computer keyboard layout is specified in the ABNT NBR 10346 variant 2 (alphanumeric portion) and 10347 (numeric portion) standards.
Essentially, the Brazilian keyboard contains dead keys for five variants of diacritics in use in the language; the letter Ç, the only application of the cedilla in Portuguese, has its own key. In some keyboard layouts the AltGr+C combination produces the ₢ character (Unicode 0x20A2), symbol for the old currency cruzeiro, a symbol that is not used in practice (the common abbreviation in the eighties and nineties used to be Cr$). The cent sign ¢, is accessible via AltGr+5, but is not commonly used for the centavo, subunit of previous currencies as well as the current real, which itself is represented by R$. The Euro sign € is not standardized in this layout. The masculine and feminine ordinals ª and º plus the degree sign ° are accessible via AltGr combinations. The section sign § (Unicode U+00A7), in Portuguese called "parágrafo", is nowadays practically only used to denote sections of laws.
Variant 2 of the Brazilian keyboard, the only which gained general acceptance (MS Windows treats both variants as the same layout), has a unique mechanical layout, combining some features of the ISO 9995-3 and the "JIS" keyboards in order to fit 12 keys between the left and right Shift (compared to the American standard of 10 and the international of 11). Its modern, IBM PS/2-based variations, are thus known as 107-keys keyboards, and the original PS/2 variation was 104-key. Variant 1, never widely adopted, was based on the ISO 9995-2 keyboards. In order to make this layout usable with keyboards that have only 11 keys in the last row, the rightmost key (/?°) has its functions replicated across the AltGr+Q, AltGr+W, and AltGr+E combinations.
Portugal.
During the 20th century, a different keyboard layout, HCESAR, was in widespread use in Portugal. On some QWERTY keyboards the key labels are translated, but the majority are labelled in English.
Romanian (in Romania and Moldova).
The current Romanian National Standard SR 13392:2004 establishes two layouts for Romanian keyboards: a "primary" one and a "secondary" one.
The "primary" layout is intended for traditional users who have learned how to type with older, Microsoft-style implementations of the Romanian keyboard. The "secondary" layout is mainly used by programmers as it does not contradict the physical arrangement of keys on a US-style keyboard. The "secondary" arrangement is used as the default Romanian layout by Linux distributions, as defined in the "X Keyboard Configuration Database"
There are four Romanian-specific characters that are incorrectly implemented in versions of Microsoft Windows prior to Vista:
The cedilla-versions of the characters do not exist in the Romanian language (they came to be used due to a historic bug).
Since Romanian hardware keyboards are not widely available, Cristian Secară has created a driver that allows Romanian characters to be generated with a US-style keyboard in all versions of Windows prior to Vista through the use of the AltGr key modifier.
MS Windows 7 now includes the correct diacritical signs in the default Romanian Keyboard layout. This layout has the Z and Y keys mapped like in English layouts and also includes characters like the 'at' (@) and dollar ($) signs, among others. The older cedilla-version layout is still included albeit as the 'Legacy' layout.
Slovak (QWERTY).
In Slovakia, similarly to the Czech Republic, both QWERTZ and QWERTY keyboard layouts are used. QWERTZ is the default keyboard layout for Slovak in Microsoft Windows.
Spanish.
Spain, a.k.a. Spanish (International sort).
The Spanish keyboard layout is used to write in Spanish and in other languages of Spain such as Aragonese, Asturian, Catalan, Occitan, Galician and Basque. It includes Ñ for Spanish, Asturian and Galician, the acute accent, the diaeresis, the left question and exclamation marks (¿, ¡) and, finally, some characters required only for typing Catalan and Occitan that are Ç, the grave accent and the interpunct ("punt volat"/"punt interior", used in "l·l, n·h, s·h"; located at Shift-3). It can also be used to write other international characters, such as the circumflex accent (used in French and Portuguese among others) and the tilde (used in both Spanish and Portuguese), which are available as dead keys. However, it lacks two characters used in Asturian: Ḥ and Ḷ (historically, general support for these two has been poor – they aren't present in the ISO 8859-1 character encoding standard, or any other ISO/IEC 8859 standard); several alternative distributions, based on this one or created from scratch, have been created to address this issue (see the Other original layouts and layout design software section for more information).
On most keyboards, € is marked as Alt Gr + E and not Alt Gr + 5 as shown in the image. However, in some keyboards, € is found marked twice.
Spanish keyboards are usually labelled in Spanish instead of English, its abbreviations being:
The c-cedilla key (Ç), instead of on the right of the acute accent key (´), is located alternatively on some keyboards one or two lines above. In some cases it's placed on the right of the plus sign key (+). In other keyboards it's situated on the right of the inverted exclamation mark key (¡).
Hispanic America.
The Hispanic American Spanish keyboard layout is used throughout Mexico, Central and South America. Hispanic American vendors in the last few years have been selling the Spanish (Spain) layout as default; as of 2011, the latter is becoming dominant.
Its most obvious difference from the Spanish (Spain) layout is the lack of a Ç key; on Microsoft Windows it lacks a tilde (~) dead key, whereas on Linux systems the dead tilde can be optionally enabled. This is not a problem when typing in Spanish, but it is rather problematic when typing in Portuguese, which can be an issue in countries with large commercial ties to Brazil (Argentina, Uruguay and Paraguay).
Normally "Bloq Mayús" is used instead of "Caps Lock", and "Intro" instead of "Enter".
Swedish.
The central characteristics of the Swedish keyboard are the three additional letters Å/å, Ä/ä, and Ö/ö. The same visual layout is also in use in Finland, as the letters Ä/ä and Ö/ö are shared with the Swedish language, and even Å/å is needed by Swedish-speaking Finns. However, the Finnish multilingual keyboard adds new letters and punctuation to the functional layout.
The Norwegian keyboard largely resembles the Swedish layout, but the Ö and Ä are replaced with Ø and Æ. The Danish keyboard is also similar, but it has the Ø and Æ swapped. On some systems, the Swedish or Finnish keyboard may allow typing Ø/ø and Æ/æ by holding the AltGr or Option key while striking Ö and Ä, respectively.
The "Swedish with Sámi" keyboard allows typing not only Ø/ø and Æ/æ, but even the letters required to write various Sámi (also known as Lapp) languages. This keyboard has the same function for all the keys engraved on the regular Swedish keyboard, and the additional letters are available through the AltGr key.
On Macintosh computers, the "Swedish" and "Swedish Pro" keyboards differ somewhat from the image shown above, especially as regards the characters available using the Shift or Option keys. ⇧ Shift+§ (on the upper row) produces the "°" sign, and ⇧ Shift+4 produces the "€" sign. The digit keys produce "©@£$∞§|[]≈" with ⌥ Option and "¡”¥¢‰¶\{}≠" with ⌥ Option+⇧ Shift.
On Linux systems, the Swedish keyboard may also give access to additional characters as follows:
Several of these characters function as dead keys.
Turkish (Q-keyboard).
Today the majority of Turkish keyboards are based on QWERTY (the so-called Q-keyboard layout), although there is also the older F-keyboard layout specifically designed for the language.
United Kingdom.
The United Kingdom and Ireland use a keyboard layout based on the 48-key version defined in British Standard BS 4822. It is very similar to that of the United States, but has an extra key and a larger Enter key, includes £ and € signs and some rarely used EBCDIC symbols (¬, ¦), and uses different positions for the characters @, ", #, ~, \, and |. See the article British and American keyboards for details.
The BS 4822:1994 standard does not make any use of the AltGr key and lacks support for any non-ASCII characters other than ¬ and £. It also assigns a key for the non-ASCII character broken bar (¦), but lacks one for the far more commonly used ASCII character vertical bar (|). It also lacks support for various diacritics used in the Welsh alphabet, and the Scottish Gaelic alphabet; and also is missing the letter yogh, ȝ, used very rarely in the Scots language. Therefore, various manufacturers have modified or extended the BS 4822 standard:
UK Apple keyboard.
The British version of the Apple Keyboard does not use the standard UK layout. Instead, some older versions have the US layout (see below) with a few differences: the £ sign is reached by ⇧ Shift+3 and the # sign by ⌥ Option+3, the opposite to the US layout. The € is also present and is typed with ⇧ Shift+⌥ Option+2.
Newer Apple "British" keyboards use a layout that is relatively unlike either the US or traditional UK keyboard. It uses an elongated return key, a shortened left ⇧ Shift with ` and ~ in the newly created position, and in the upper left of the keyboard are § and ± instead of the traditional EBCDIC codes. The middle-row key that fits inside the return key has \ and .
United Kingdom extended.
Windows XP SP2 and later also offer a "United Kingdom Extended" keyboard layout which allows input on a standard physical UK keyboard for many languages (including Welsh) without changing any of the allocations of frequently used keys (the rarely used grave accent key becomes a dead key). In particular, the apostrophe, double-quote, tilde and caret keys are not changed into dead keys modifying the character generated by the next key pressed, as used by the US International layout. Instead, the additional characters are obtained using the AltGr key. The extended keyboard is software installed from the Windows control panel, and the extended characters are not normally engraved on keyboards.
The layout provides support for adding diacritics to the vowels a, e, i, o, u, w and y (the last two being used in Welsh) as well as capitals:
The UK extended layout is almost entirely transparent to users familiar with the UK layout; a machine with the extended layout will behave exactly as with the standard UK except for the rarely used grave accent key. This makes this layout suitable for a machine for shared or public use by a user population in which some, but not all, are aware of the extended functionality.
United States.
The arrangement of the character input keys and the Shift keys contained in this layout is specified in the U.S. American national standard ANSI-INCITS 154-1988 (R1999) (formerly ANSI X3.154-1988 (R1999)), where this layout is called "ASCII keyboard". The complete US keyboard layout, as it is usually found, also contains the usual function keys in accordance with the international standard ISO/IEC 9995-2, although this is not explicitly required by the US American national standard.
US keyboards are used not only in the United States, but also in many other English-speaking places, including India, Australia, English Canada, Hong Kong, New Zealand, South Africa, Malaysia, Singapore and Philippines. However, the United Kingdom and Ireland use a slightly different layout.
The US keyboard layout has a second Alt key instead of the AltGr key and does not use any dead keys; this makes it inefficient for all but a handful of languages. On the other hand, the US keyboard layout (or the similar UK layout) is occasionally used by programmers in countries where the keys for []{} are located in less convenient positions on the locally customary layout.
On some keyboards the enter key is bigger than traditionally and takes up also a part of the line above, more or less the area of the traditional location of the backslash key (\). In these cases the backslash is located in alternative places. It can be situated one line above the default location, on the right of the equals sign key (=). Sometimes it's placed one line below its traditional situation, on the right of the apostrophe key (') (in these cases the enter key is narrower than usual on the line of its default location). It may also be two lines below its default situation on the right of a narrower than traditionally right shift key.
US-International.
There is an alternative layout that uses the physical US keyboard to type diacritics in some operating systems (including Windows). This is the US-International layout, which uses the right Alt key as an AltGr key which supports many additional characters directly as an additional shift key. (Since many smaller keyboards don't have a right Alt key, Windows also allows Ctrl+Alt to be used as a substitute for AltGr.) This layout also uses keys ', `, ", ^ and ~ as dead keys to generate characters with diacritics by pressing the appropriate key, then the letter on the keyboard. The international keyboard is a software setting installed from the Windows control panel or similar; the additional functions (shown in blue) may or may not be engraved on the keyboard, but are always functional. It can be used to type most major Western European languages: Afrikaans, Danish, Dutch, English, Faroese, Finnish, French, German, Icelandic, Irish, Italian, Norwegian, Portuguese, Scottish Gaelic, Spanish, and Swedish. Some less common western European languages, such as Maltese and Welsh, are not fully supported by the US-International keyboard layout.
A diacritic key is activated by pressing and releasing it, then pressing the letter that requires a diacritic. After the two strokes, the single character with diacritics is generated. Note that only certain letters, such as vowels and "n", can have diacritics in this way. To generate the symbols ', `, ", ^ and ~, when the following character is capable of having a diacritic, press the Spacebar after the key.
Characters with diacritics can be typed with the following combinations:
The US-International layout is not entirely transparent to users familiar with the US layout; when using a machine with the international layout the commonly used single- and double-quote keys and the less commonly used grave accent, tilde, and caret keys will behave unexpectedly. This could be disconcerting on a machine for shared or public use.
There are also alternative US-International formats, whereby modifier keys such as shift and alt are used, and the keys for the characters with diacritics are in different places from their unmodified counterparts, for example, using the AltGr modifier key to activate dead keys, so that the ASCII quotation marks or circumflex symbol are not affected and can be typed normally with a single keystroke.
US-International in the Netherlands.
The standard keyboard layout in the Netherlands is US-International, as it provides easy access to diacritics on common UK- or US-like keyboards. The Dutch layout is historical, and keyboards with this layout are rarely used. Many US keyboards sold do not have the extra US-International characters or AltGr engraved on the keys, although € (AltGr+5) always is; nevertheless, the keys work as expected even if not marked. Many computer-experienced Dutch people have retained the old habit of using Alt + number codes to type accented characters; others routinely type without diacritics, then use a spelling checker to produce the correct forms.
Apple International English Keyboard.
There are three kinds of Apple Keyboards for English: the United States, the United Kingdom and International English. The International English version is almost identical to the United States version, but some features are identical to the United Kingdom version:
Vietnamese.
The Vietnamese keyboard layout is an extended Latin QWERTY layout. The letters Ă, Â, Ê, and Ô are found on what would be the number keys 1–4 on the US English keyboard, with 5–9 producing the tonal marks (grave accent, hook, tilde, acute accent and dot below, in that order), 0 producing Đ, producing the đồng sign (₫) when not shifted, and brackets ([]) producing Ư and Ơ.
Alternatives to QWERTY.
Several alternatives to QWERTY have been developed over the years, claimed by their designers and users to be more efficient, intuitive and ergonomic. Nevertheless, none has seen widespread adoption, partly due to the sheer dominance of available keyboards and training. Although some studies have suggested that some of these may allow for faster typing speeds, many other studies have failed to do so, and many of the studies claiming improved typing speeds were severely methodologically flawed or deliberately biased, such as the studies administered by Dvorak himself before and after World War II. Economists Stan Liebowitz and Stephen Margolis have noted that rigorous studies are inconclusive as to whether they actually offer any real benefits, and some studies on keyboard layout have suggested that, for a skilled typist, layout is largely irrelevant – even randomized and alphabetical keyboards allow for similar typing speeds to QWERTY and Dvorak keyboards, and that switching costs always outweigh the benefits of further training on whichever keyboard you already use. The most widely used such alternative is the Dvorak Simplified Keyboard; another alternative is Colemak, which is based partly on QWERTY and is claimed to be easier for an existing QWERTY typist to learn while offering several supposed optimisations. Most modern computer operating systems support these and other alternative mappings with appropriate special mode settings, with some modern operating systems allowing the user to map their keyboard in any way they like, but few keyboards are manufactured with keys labeled according to any other standard.
Comparison to other keyboard input systems.
Dvorak and QWERTY have been compared by some people to other systems which involve keyboard input systems, namely stenotype and its implementations (e.g. opensource PLOVER ). There are numerous advantages to using these systems (namely a 700% increase in efficiency over QWERTY) but they are fundamentally different from ordinary typing. Words are input by pressing on several keys and releasing simultaneously but don't require the keys to be pressed down in any order. Neither is the spacebar used. There is a learning hurdle in that hunt and peck does not work. However, it is easy to write at 180–300 wpm. It is worth noting that PLOVER stenotype theory required a stenotype machine prior to 2010; due to the inherent difficulties of chording QWERTY was invented to allow machines to be made that didn't jam up; stenotype was invented for maximum speed and accuracy.
The first typed shorthand machines appeared around 1880, roughly current with QWERTY, but the first stenotype machines appeared in 1913. Also, these machines' output needed to be interpreted by a trained professional, comparable to reading Gregg shorthand, which was very much in vogue at the time and taught publicly until the 1980s. Gregg shorthand also didn't require much more than training and a pen, however machines gradually gained traction in the courtroom. Modern PLOVER immediately provides translated output, making it very much like other keyboard setups that immediately produce legible work.
Half QWERTY.
A half QWERTY keyboard is a combination of an alpha-numeric keypad and a QWERTY keypad, designed for mobile phones. In a half QWERTY keyboard, two characters share the same key, which reduces the number of keys and increases the surface area of each key, useful for mobile phones that have little space for keys. It means that 'Q' and 'W' will share the same key and the user has to press the key once to type 'Q' and twice to type 'W'.
Displaced QWERTY.
Also designed for mobile devices, the displaced QWERTY layout allows for the increase of button area by over 40% while keeping the same candybar form factor. Entering, spacing and deleting are handled by gestures over the text area, reducing the keyboard's screen footprint. The layout is essentially a rearrangement of keys on the right half of the keyboard under those on the left and, as such, should present a gentler learning curve to touch typists. It was first seen on the iPhone application "LittlePad". 

</doc>
<doc id="25215" url="http://en.wikipedia.org/wiki?curid=25215" title="Quake III Arena">
Quake III Arena

Quake III Arena (also known as Quake 3; abbreviated as Q3A or Q3), is a multiplayer-focused first-person shooter video game. The game was developed by id Software and featured music composed by Sonic Mayhem and Front Line Assembly. "Quake III Arena" is the third game in the series and differs from previous games by excluding a traditional single-player element, instead focusing on multiplayer action. The single-player mode is played against computer controlled bots.
Notable features of "Quake III Arena" include the minimalist design, lacking rarely used items and features, the extensive customizability of player settings such as field of view, texture detail and enemy model, and advanced movement features such as strafe-jumping and rocket-jumping.
"Quake III Arena" is available on a number of platforms and contains mature content. The game was highly praised by reviewers who, for the most part, described the gameplay as fun and engaging. Many liked the crisp graphics and focus on multiplayer.
"Quake III Arena" has also been used extensively in professional electronic sports tournaments such as QuakeCon, Cyberathlete Professional League, and the Electronic Sports World Cup.
Gameplay.
Unlike its predecessors, "Quake III Arena" does not have a plot-based single-player campaign. Instead, it simulates the multiplayer experience with computer controlled players known as bots. The game's story is brief - 'the greatest warriors of all time fight for the amusement of a race called the Vadrigar in the Arena Eternal.' The introduction video shows the abduction of such a warrior, Sarge, while making a last stand. Continuity with prior games in the "Quake" series and even "Doom" is maintained by the inclusion of player models related to those earlier games as well as biographical information included on characters in the manual, a familiar mixture of gothic and technological map architecture and specific equipment; for example, the Quad Damage power-up, the infamous rocket launcher, and the BFG super-weapon.
In "Quake III Arena", the player progresses through tiers of maps, combating different bot characters that increase in difficulty, from Crash (at Tier 0) to Xaero (at Tier 7). As the game progresses, the fights take place in more complex arenas and against tougher opponents. While deathmatch maps are designed for up to 16 players, tournament maps are designed for duels between 2 players and in the single-player game could be considered as 'boss battles'.
The weapons are balanced by role, with each weapon having advantages in certain situations, such as the railgun at long-range and the lightning gun at close quarters. The BFG super-weapon is an exception to this; compared to other similarly named weapons in the "Doom"/"Quake" series, "Quake III Arena"'s incarnation of this weapon is basically a fast-firing rocket launcher and it is found in hard-to-reach locations. Weapons appear as level items, spawning at regular intervals in set locations on the map. If a player dies, all of their weapons are lost and they receive the spawn weapons for the current map, usually the gauntlet and machine gun. Players also drop the weapon they were using when killed, which other players can then pick up.
"Quake III Arena" comes with several gameplay modes; Free for All (FFA), a classic deathmatch, where each player competes against the rest for the highest score, Team Deathmatch (TDM), where usually two teams of four compete for the highest team frag total, Tournament (1v1), a deathmatch between two players, usually ending after a set time and Capture the Flag, which is played on symmetrical maps where teams have to recover the enemy flag from the opponents' base while retaining their own.
"Quake III Arena" was specifically designed for multiplayer. The game allows players whose computers are connected by a network or to the internet, to play against each other in real time, and incorporates a handicap system. It employs a client–server model, requiring all players' clients to connect to a server. "Quake III Arena"'s focus on multiplayer gameplay spawned a lively community, similar to QuakeWorld, that is active to this day.
Development.
During early March 1999, ATI leaked the internal hardware vendor (IHV) copy of the game. This was a functional version of the engine with a textured level and working guns. The IHV contained most of the weapons (excepting the Gauntlet) that would make it into the final game although most were not fully modeled; a chainsaw and grappling hook were also in the IHV but did not make it into the final release. Many of the sounds that would make it into the final release were also included.
After the IHV fiasco, id Software released a beta of the game called Quake III Arena Test on April 24, 1999. The Q3Test started with version 1.05 and included three levels that would be included in the final release: dm7, dm17, and q3tourney2. Id software continued to update Q3Test up until version 1.09.
During the game's testing it was found that the lightning gun was too dominating. Its strength was reduced to the point that some players have found it useless. Weapon balance was achieved by examining earlier games in the series, "Quake" and "Quake II." In the first "Quake", the rocket launcher was so effective that it overshadowed other weapons and dominated entire deathmatches, but this was toned down so much in "Quake II" that it lost its appeal. The rocket launcher in "Quake III" is effective but not overpowering, allowing it to be countered in many situations.
Game engine.
The "id Tech 3" engine is the name now given to the engine that was developed for "Quake III Arena". Unlike most other games released at the time, "Quake III Arena" requires an OpenGL-compliant graphics accelerator to run. The game does not include a software renderer.
The graphic technology of the game is based tightly around a "shader" system where the appearance of many surfaces can be defined in text files referred to as "shader scripts." "Quake 3" also introduced spline-based curved surfaces in addition to planar volumes, which are responsible for many of the surfaces present within the game. "Quake 3" also provided support for models animated using vertex animation with attachment tags (known as the .md3 format), allowing models to maintain separate torso and leg animations and hold weapons. "Quake 3" is one of the first games where the third-person model is able to look up and down and around as the head, torso and legs are separate. Other visual features include volumetric fog, mirrors, portals, decals, and wave-form vertex distortion.
For networking, id Tech 3 uses a "snapshot" system to relay information about game "frames" to the client over UDP. The server attempts to omit as much information as possible about each frame, relaying only differences from the last frame the client confirmed as received (Delta encoding). "id Tech 3" uses a virtual machine to control object behavior on the server, effects and prediction on the client and the user interface. This presents many advantages as mod authors do not need to worry about crashing the entire game with bad code, clients could show more advanced effects and game menus than was possible in "Quake II" and the user interface for mods was entirely customizable. Unless operations which require a specific endianness are used, a QVM file will run the same on any platform supported by "Quake III Arena." The engine also contains bytecode compilers for the x86 and PowerPC architectures, executing QVM instructions via an interpreter.
"Quake III Arena" features an advanced AI with five difficulty levels which can accommodate both a beginner and an advanced player, though they usually do not pose a challenge to high-tier or competitive players. Each bot has its own, often humorous, 'personality', expressed as scripted lines that are triggered to simulate real player chat. If the player were to type certain phrases the bots may respond, typing "You bore me" might cause one of the bots to reply "You should have been here 3 hours ago!". Each bot has a number of alternative lines to reduce the repetition of bot chatter. The Gladiator bots from "Quake II" were ported to "Quake III Arena" and incorporated into the game by their creator - Jan Paul van Waveren, aka Mr. Elusive. Bot chat lines were written by R. A. Salvatore, Seven Swords and Steve Winter. Xaero, the hardest opponent in the game, was based on the Gladiator bot Zero. The bot Hunter appears on magazine covers in the later id game Doom 3.
On August 19, 2005, id Software released the complete source code for "Quake III Arena" under the GNU General Public License, as they have for most of their prior engines. As before, the "engine", but not the content such as textures and models, were released, so that anyone who wishes to build the game from source will still need an original copy of the game to play it as intended.
Mods.
Like its predecessors, "Quake" and "Quake II", "Quake III Arena" can be heavily modified, allowing the engine to be used for many different games. Mods range from small gameplay adjustments like "Rocket Arena 3" and "Orange Smoothie Productions" to total conversions such as "Smokin' Guns", "Loki's Revenge", and "DeFRaG". The source code's release has allowed total conversion mods such as "Tremulous", "World of Padman", "OpenArena", and "Urban Terror" to evolve into free standalone games. Other mods like "Weapons Factory Arena" have moved to more modern commercial engines. "Challenge ProMode Arena" became the primary competitive mod for "Quake III Arena" since the Cyberathlete Professional League announced CPMA as its basis for competition. CPMA includes alternative gameplays, including air-control, rebalanced weapons, instant weapon switching and additional jumping techniques.
Expansion.
An expansion pack titled "Quake III: Team Arena" was released on December 18, 2000, by id Software. It focused on team gameplay through new game modes and new weapons, items, and player models. "Quake III: Team Arena" was criticized, as its additions were long overdue and had already been implemented by fan modifications. A few years later, "Quake III: Gold" was released, including the original "Quake III Arena" and the "Quake III: Team Arena" expansion pack bundled together. Front Line Assembly made the soundtrack for the expansion, the counterpart to Sonic Mayhem's "Quake III Arena: Noize".
Ports.
Official.
"Quake III Arena" was released for the Dreamcast (ported by Raster Productions and released by Sega) in 2000 and featured 4 player online play versus Dreamcast and PC gamers. It is often considered one of the best PC to console ports of its time due to its smooth frame rate and online play. There are still communities that play this version online on the remaining dedicated servers running patch version 1.16n and the required map pack. "Quake III Revolution" was released for the PlayStation 2 (ported by Bullfrog Productions and released by Electronic Arts) in 2001, featuring several elements adopted from "Team Arena", along with a more mission-based single-player mode. It features split-screen multiplayer for up to 4 players, but lacks online play and mouse support. Gamerankings.com rated the release at 83%. The PlayStation 2 version was widely criticized for having long loading times (which typically averaged over a minute).
"Quake III: Team Arena" was revealed in an ESRB listing for the Xbox 360. The title was developed by Pi Studios. "Quake III Arena" for the 360 was officially announced by id at QuakeCon 2007. The title, jointly developed by id and Pi studios, was released on Xbox Live Arcade on December 15, 2010. The retail price of the game was set at 1200 Microsoft Points, or $15 USD. "Quake Arena DS" for the Nintendo DS was announced at QuakeCon on August 4, 2007. John Carmack announced the game and said that touch screen controls would not be implemented as much as in "Metroid Prime Hunters", for example. He stated that he would like all shooting in the game to be controlled with the D-pad instead of the Touch Screen. "Quake Zero" was announced at QuakeCon on August 3, 2007 and will be an updated version of "Quake 3 Arena", distributed by free download, run in a browser window and supported by built-in advertising content. On February 20, 2008 id announced that "Quake Zero" would be launched as "Quake Live". "Quake Live" was released in 2010.
Source ports.
"Quake III Arena" has been unofficially ported to several consoles, including the PlayStation Portable handheld and Xbox console. These versions require a modified console or handheld and the assets to the game to go along with the source port.
Carmack has said that Quake Trilogy (including Arena) will be ported on the iPhone/iPod Touch/iPad. An unofficial version for iOS was released through Cydia for jailbroken iOS devices in April 2008; it is a demo version similar to the original except that it integrates the iPhone and iPod Touch's accelerometer and touch controls to make gameplay possible. A high-definition version for iPad was released in November 2010, featuring re-created controls, sharper graphics, better gameplay, and better framerate; this improved version was also integrated into the iPhone and iPod touch version of the port.
A Moorestown prototype version was demonstrated on a reference design that demonstrated performance of up to 90 frames per second. An unofficial port of Quake III for Symbian mobile devices was made. It requires PAK files from original game to run. An unofficial port of the game to Android was created based on the released source code. This means the game can be run on several Android powered devices, most notably the Motorola Milestone, Motorola Droid, and the Nexus One, as well as other high specification Handsets.
In August 2011, the ARM-based Raspberry Pi credit card-sized computer was shown running a specially compiled ARM version of "Quake III" on Debian.
Reception.
Critical reception.
Reviews for the game were consistently very positive with many describing the game as fast and addictive. Curved surfaces were a welcome addition to the series. Most reviewers felt the game was best when played with others online. A GameSpot review by Jeff Gerstmann described the game as outstanding. He noted the fun level designs, great-looking textures, impressive special effects and weapons sounds. The Gamespot review criticised the narrator's voice and thought that some levels could become too crowded when playing multiplayer. An IGN review felt the game lacked originality but enjoyed the detailed wall textures and outer space jump levels. The high number of character skins and the artificial intelligence of opponent bots were praised but the weapons were said to be "bland and predictable". A Eurogamer review described the game as "polished" and "stunning" and thought that it "was extremely well balanced and plays very well". The reviewer was especially pleased with the customisable 3D engine and looked forward to new maps and mods.
Competitive play.
"Quake III Arena"'s multiplayer-focused development led to it developing a large community of competitive players and like its predecessors it was used extensively in professional electronic sports tournaments. In competitive "Quake III Arena" there are two distinct gameplays, often referred to as 'rulesets', the out-of-the-box "Quake III Arena" game, also known as vanilla "Quake 3" (VQ3), and the CPM ruleset of the "Challenge Pro Mode Arena" mod. On July 26, 2006, "Challenge Pro Mode Arena" with VQ3 gameplay was chosen by Cyberathlete Professional League as the mod of choice for their tournament, making it the standard competitive mod for "Quake III Arena". Previously, "Orange Smoothie Productions" was the most widely used tournament mod.
The following competitions have held "Quake III" events:
These competitions have now moved on to more recent games or have transitioned to its variant successor, "Quake Live".

</doc>
<doc id="25216" url="http://en.wikipedia.org/wiki?curid=25216" title="Quake II">
Quake II

Quake II is a first-person shooter video game developed by id Software and published by Activision. It is not a direct sequel to "Quake"; id decided to revert to an existing trademark when they were unable to agree on a new name that did not violate another company's trademark.
The soundtrack for "Quake II" was mainly provided by Sonic Mayhem, with some additional tracks by Bill Brown, a main theme also composed by Brown and Rob Zombie and one track by Jer Sypult.
Gameplay.
The game is played in general first-person shooter paradigms, in which the player shoots enemies from the perspective of the main character. The gameplay is very similar to that featured in "Quake", in terms of movement and controls, although the player has been slowed down, and now has the ability to crouch. The game retains four of the original "Quake"‍ '​s weapons (Shotgun, Super Shotgun, Grenade Launcher and Rocket Launcher), although they were all redesigned and made to function in slightly different ways. The remainder of "Quake"‍ '​s eight weapons (Axe, Nailgun, Super Nailgun and Thunderbolt) are gone. Newly introduced weapons are the blaster, Machine Gun, Chain Gun, Hyperblaster, Railgun and BFG10K. The Quad Damage power up from "Quake" is still present in "Quake II" and new power ups include Invulnerability, Bandolier, Ammo Pack, Enviro-Suit, Rebreather, and Silencer.
The single player game features a number of changes from "Quake". First, the player is given mission-based objectives that correspond to the storyline, including stealing a Tank Commander's head to open a door and calling down an air-strike on a bunker. CGI cutscenes are used to illustrate progress through the main objectives, although they are all essentially the same short piece of video, showing a computerised image of the player character as he or she moves through game's levels. Another addition is the inclusion of a non-hostile character type — the player character's captured comrades. However, it is impossible to interact with such characters, because they have all been driven insane by their Strogg captors.
The game features much larger levels than "Quake", with many more wide-open areas. There is also a hub system that allows the player to travel back and forth between levels, which is necessary to complete certain objectives. Some of the textures and symbols that appear in the game are very similar to some of those found in "Quake". Enemies also demonstrate visible wounds after they have taken damage.
Multiplayer.
The multiplayer portion is similar to that in "Quake". It can be played as a free-for-all deathmatch game, a cooperative version of the single-player game, or as a 1 vs 1 match that is used in official tournaments, like the Cyberathlete Professional League. It can also be played in Capture the Flag Mode (CTF).
The deathmatch game benefited from the release of eight specifically designed maps that id Software added after the game's initial release. They were introduced to the game via one of the early patches, that were released free of charge. Prior to the release of these maps, players were limited to playing multiplayer games on the single-player levels, which, while functional as multiplayer levels, were not designed with deathmatch gameplay specifically in mind.
As in "Quake", it is possible to customize the way in which the player appears to other people in multiplayer games. However, whereas in "Quake", the only option was to change the color of the player's uniform unless third party modifications were used, now the game comes with a selection of three different player models: a male marine, a female marine, and a male cyborg; choice of player model also affects the speech effects the player's character will make, such as exhaling in effort while jumping or groaning when injured. Each model can be customized from in the in-game menu via the selection of pre-drawn skins, which differ in many ways; for example, camouflage style, skin color and application of facepaint.
Plot.
"Quake II" takes place in a science fiction environment. In the single-player game, the player assumes the role of a Marine named Bitterman taking part in "Operation Alien Overlord", a desperate attempt to prevent an alien invasion of Earth by launching a counter-attack against the home planet of the hostile Strogg civilization. Most of the other soldiers are captured or killed as soon as they approach the planned landing zone (LZ). Bitterman survives only because another Marine's personal capsule collided with his upon launch, causing him to crash far short of the LZ. It falls upon Bitterman to penetrate the Strogg capital city alone and assassinate the Strogg leader, the Makron.
Development.
Unlike "Quake", where hardware accelerated graphics controllers were supported only with later patches, "Quake II" came with OpenGL support out of the box. Later downloads from id Software added support for AMD's 3DNow! instruction set for improved performance on their K6-2 processors, and Rendition released a native renderer for their V1000 graphics chip. The latest version is 3.21. This update includes numerous bug fixes and new maps designed for multiple players deathmatch. Version 3.21, available as source code on id Software's FTP server, has no improved functionality over version 3.20 and is simply a slight modification to make compiling for Linux easier.
"Quake II" uses an improved client–server network model introduced in "Quake". The game code of "Quake II", which defines all the functionality for weapons, entities and game mechanics, can be changed in any way because id Software published the source code of their own implementation that shipped with the game. "Quake II" uses the shared library functionality of the operating system to load the game library at run-time—this is how mod authors are able to alter the game and provide different gameplay mechanics, new weapons and much more. The full source code to "Quake II" version 3.19 was released under the terms of the GPL on December 21, 2001. Version 3.21 followed later. A LCC-friendly version was released on January 1, 2002 by a modder going by the name of Major Bitch.
Since the release of the "Quake II" source code, several third-party update projects to the game engine have been created; the most prominent of these are projects focused on graphical enhancements to the game such as "Quake2maX", "EGL", "Quake II Evolved" and "KMQuake II". The source release also revealed which can result in remote compromise of both the "Quake II" client and server. As id Software no longer maintains "Quake II", most 3rd party engines include fixes for these bugs. The unofficial patch 3.24 that fixes bugs and adds only meager tweaks is recommended for Quake II purists, as it is not intended to add new features or be an engine mod in its own right. The most popular server-side engine modification for multiplayer, "R1Q2", is generally recommended as a replacement for the 3.20 release for both clients and servers. In July 2003, Vertigo Software released a port of "Quake II" for the Microsoft .NET platform, using Managed C++, called "Quake II .NET". It became a poster application for the language, showcasing the powerful interoperability between .NET and standard C++ code. It remains one of the top downloads on the Visual C++ website. In May 2004, Bytonic Software released a port of "Quake II" (called "Jake2") written in Java using JOGL. In 2010 Google ported "Jake2" to HTML5, running in Safari and Chrome.
"Quake II"‍ '​s game engine was a popular license, and formed the basis for several commercial and free games, such as ', "War§ow", "SiN", "Anachronox", "Heretic II", "Daikatana", "Soldier of Fortune", ' and "". Valve Software's 1998 "Half-Life", which went on to sell over eight million copies, was originally going to use the "Quake II" engine during early development stages. However, the final version runs on a heavily modified version of the "Quake" engine, "GoldSrc", with a small amount of the "Quake II" code.
Ports.
Ports of "Quake II" were released in 1999 on the Nintendo 64 (ported by Raster Productions) and PlayStation (ported by HammerHead) video game consoles. In both cases, the core gameplay was largely identical; however, changes were made to the game sequence and split-screen multiplayer replaced network or internet play. A Macintosh port was developed by Logicware and released in 1999. "Quake II: Colossus" ("Quake II" with both official addons) was ported to Linux by id Software and published by Macmillan Digital Publishing in 1999. Be Inc. officially ported "Quake II: Colossus" to the BeOS to test their OpenGL acceleration in 1999, and provided the game files for free download at a later date—a Windows, Macintosh or Linux install CD was required to install the game, with the official addons being optional.
"Jake2" is a "Quake II" port shown by the JOGL team for JavaOne 2004, to present an example of Java-OpenGL interoperability. Jake2 has since been used by Sun as an example of Java Web Start capabilities for games distribution over the internet. In 2009, Tectoy Digital ported Quake II to the Brazilian gaming console Zeebo. The game is available for free, but does not feature CG movies nor multiplayer support of any kind.
For the PlayStation version, several of the original levels, including several complete sections and units were removed. Some enemy types were removed, as well as some scenery objects. A new enemy type - Arachnid, a human-spider cyborg with twin railgun arms, was added, and many short airlock-like corridors were added to maps to provide loading pauses inside what were contiguous areas in the PC version. Saving the game is only possible between units and at mid-level checkpoints, the majority of which lie in the aforementioned airlock-like corridors, while in the PC version the game could be saved and loaded anywhere. The game supports the PlayStation Mouse, to provide a greater parity with the PC version's gameplay. The music of this port is a combination of the "Quake II" original music score and some tracks from the PC version's mission packs.
The PlayStation version is limited to a far lower resolution than the PC original, giving it a grainier look. Colored lights for levels and enemies, and yellow highlights for gunfire and explosions, are carried across from the PC version, with the addition of lens flare effects located around the light sources on the original lightmaps. There is no skybox; instead a flat Gouraud-textured purple sky is drawn around the top of the level. The PC version's software renderer originally used particles to render blood, debris and rail gun beams as trails of large, opaque coloured pixels. In the PlayStation version, the particles are circular and translucent, similar to the OpenGL driver given with the PC version. There is also a split-screen multiplayer mode for 2-4 players (The 4 player game is possible using PlayStation's Multi-tap). The only available player avatar is a modified version of the male player avatar from the PC version, the most noticeable difference being the addition of a helmet. Players can only customise the colour of their avatar's armour, and change their name. The multiplayer levels are unique to the PlayStation version, and none of the PC multiplayer maps are carried over.
The Nintendo 64 version had completely different levels, music and multiplayer maps. It featured multiplayer for up to 4 players. This version also had new lighting effects, mostly seen in gunfire, and also used the Expansion Pak for extra graphical detail. A port of "Quake II" was included in the box of "Quake 4" for the Xbox 360, on a bonus disc. This is a direct port of the original game, with some graphical improvements. However it allows for System Link play for up to sixteen players, split-screen for four, and cooperative play in single-player for up to sixteen players or four with split-screen alone.
Mods.
As with "Quake", the game was designed to allow players to easily create custom content. A large number of mods, maps, player models, skins and sound effects were created and distributed to others free of charge via the Internet. Popular sites such as PlanetQuake or Telefragged allowed players to gain access to this custom content. Another improvement over "Quake" is that it is now much easier to select custom player models, skins and sound effects because they can be selected from the in-game menu. Two unofficial expansions were actually released on CDs in 1998: "Juggernaut" developed by Canopy Games and published by HeadGames, and "Zaero" developed by Team Evolve and published by Macmillan Digital Publishing. Other notable mods include "Action Quake 2", "Rocket Arena", "Weapons Factory", "Loki's Minions Capture the Flag", and "RailwarZ Insta-Gib Capture the Flag".
Release.
Despite the title, "Quake II" is a sequel to the original "Quake" in name only. The scenario, enemies and theme are entirely separate and do not fall into the same continuity as "Quake". id initially wanted to set it separately from "Quake", but due to legal reasons (most of their suggested names were already taken), they decided to use the working title. "Quake II" was also adopted as a name to leverage the popularity of "Quake". "Quake II" has been released on Steam, but this version does not include the soundtrack. It was also released on the bonus disc included with "Quake 4" Special Edition for the PC, with both expansion packs. This version also lacks the soundtrack. Quake II is also available on a bonus disc of the Xbox 360 version of "Quake 4". This version is a direct port featuring the original soundtrack and multiplayer maps.
Expansions.
Quake II Mission Pack: The Reckoning.
"Quake II Mission Pack: The Reckoning" was the first official mission pack, released on May 31, 1998. It was developed by Xatrix Entertainment. The storyline follows Joker, a member of an elite squad of marines on a mission to infiltrate the Moon Base and destroy the Strogg fleet, which is preparing to attack. Joker crash lands in the swamps outside the compound where Joker's squad are waiting. Joker travels through the swamps and bypasses the compounds outer defenses and enters through the main gate. Joker finds his squad just in time to watch them get executed by Strogg forces. Joker escapes on his own to the fuel refinery where he helps the Air Force destroy all fuel production. Afterwards, Joker infiltrates the Strogg spaceport, boards a cargo ship and reaches the Moon Base, destroying it and the Strogg fleet.
Quake II Mission Pack: Ground Zero.
"Quake II Mission Pack: Ground Zero" was the second official mission pack, released on August 31, 1998. It was developed by Rogue Entertainment. The Gravity Well has trapped the Earth Fleet in orbit above the planet. Stepchild, one of the marines who managed to land, must now make his way to the Gravity Well to destroy it, free the fleet above and disable the entire defenses of the planet.
Reception.
"Quake II" received positive reviews. Aggregating review website GameRankings gave the PC version 87.31%, the Nintendo 64 version 81.27% and the PlayStation version 79.81%.

</doc>
<doc id="25217" url="http://en.wikipedia.org/wiki?curid=25217" title="Qi">
Qi

In traditional Chinese culture, qi (more precisely "qì," also chi, ch'i or ki) is an active principle forming part of any living thing. "Qi" is frequently translated as "natural energy", "life force", or "energy flow". "Qi" is the central underlying principle in traditional Chinese medicine and martial arts. The literal translation of "qi" is "breath", "air", or "gas".
Concepts similar to "qi" can be found in many cultures, for example, "prana" in the Hindu religion, "pneuma" in ancient Greece, "mana" in Hawaiian culture, "lüng" in Tibetan Buddhism, "ruah" in Hebrew culture, and vital energy in Western philosophy. Some elements of "qi" can be understood in the term energy when used by writers and practitioners of various esoteric forms of spirituality and alternative medicine. Elements of the "qi" concept can also be found in Western popular culture, for example "The Force" in "Star Wars". Notions in the West of "energeia", "élan vital", or "vitalism" are purported to be similar.
Etymology.
The etymological explanation for the form of the "qi" logogram (or "chi") in the traditional form 氣 is "steam (气) rising from rice (米) as it cooks". The earliest way of writing "qi" consisted of three wavy lines, used to represent one's breath seen on a cold day. A later version, 气, identical to the present-day simplified character, is a stylized version of those same three lines. For some reason, early writers of Chinese found it desirable to substitute for 气 a cognate character that originally meant to feed other people in a social context such as providing food for guests. Appropriately, that character combined the three-line "qi" character with the character for rice. So 气 plus 米 formed 氣, and that is the Traditional Chinese character still used today (the oracle bone character, the seal script character and the modern "school standard" or Kǎi shū characters in the box at the right show three stages of the evolution of this character).
Definition.
References to concepts analogous to the "qi" taken to be the life-process or flow of energy that sustains living beings are found in many belief systems, especially in Asia. Philosophical conceptions of "qi" from the earliest records of Chinese philosophy (5th century BCE) correspond to Western notions of humours, the ancient Hindu yogic concept of "prana" ("life force" in Sanskrit) and traditional Jewish sources refer to as the Nefesh level of soul within the body. An early form of the idea comes from the writings of the Chinese philosopher Mencius (4th century BCE). Historically, the "Huangdi Neijing"/"The Yellow Emperor's Classic of Medicine" (circa 2nd century BCE) is credited with first establishing the pathways through which "qi" circulates in the human body.
 Within the framework of Chinese thought, no notion may attain such a degree of abstraction from empirical data as to correspond perfectly to one of our modern universal concepts. Nevertheless, the term "qi" comes as close as possible to constituting a generic designation equivalent to our word "energy". When Chinese thinkers are unwilling or unable to fix the quality of an energetic phenomenon, the character "qi" (氣) inevitably flows from their brushes.
 — Manfred Porkert
The ancient Chinese described it as "life force". They believed "qi" permeated everything and linked their surroundings together. They likened it to the flow of energy around and through the body, forming a cohesive and functioning unit. By understanding its rhythm and flow they believed they could guide exercises and treatments to provide stability and longevity.
Although the concept of "qi" has been important within many Chinese philosophies, over the centuries the descriptions of "qi" have varied and have sometimes been in conflict. Until China came into contact with Western scientific and philosophical ideas, they had not categorized all things in terms of matter and energy. "Qi" and "li" (理: "pattern") were 'fundamental' categories similar to matter and energy.
Fairly early on, some Chinese thinkers began to believe that there were different fractions of "qi" and that the coarsest and heaviest fractions of "qi" formed solids, lighter fractions formed liquids, and the most ethereal fractions were the "lifebreath" that animates living beings.
"Yuán qì" is a notion of innate or pre-natal "qi" to distinguish it from acquired "qi" that a person may develop over the course of their lifetime.
Pronunciation.
Other spellings include in ," Qi" is pronounced in English and ] in Standard Chinese; Korean: "gi"; Japanese: "ki"; Vietnamese: "khí", (]) The approximate English pronunciation of "qi", similar to "chee" in cheese, should also be distinguished from the pronunciation of the Greek letter chi (χ), which in Modern Greek is a voiceless velar fricative ([x]), as in the German "ach".
Philosophical roots.
The earliest texts that speak of "qi" give some indications of how the concept developed. The philosopher Mo Di used the word "qi" to refer to noxious vapors that would in due time arise from a corpse were it not buried at a sufficient depth. He reported that early civilized humans learned how to live in houses to protect their "qi" from the moisture that had troubled them when they lived in caves. He also associated maintaining one's "qi" with providing oneself adequate nutrition. In regard to another kind of "qi", he recorded how some people performed a kind of prognostication by observing the "qi" (clouds) in the sky.
In the Analects of Confucius, compiled from the notes of his students sometime after his death in 479 B.C., "qi" could mean "breath", and combining it with the Chinese word for blood (making 血氣, "xue"-"qi", blood and breath), the concept could be used to account for motivational characteristics.
 The [morally] noble man guards himself against 3 things. When he is young, his "xue"-"qi" has not yet stabilized, so he guards himself against sexual passion. When he reaches his prime, his "xue"-"qi" is not easily subdued, so he guards himself against combativeness. When he reaches old age, his "xue"-"qi" is already depleted, so he guards himself against acquisitiveness.
 — Confucius, "Analects, 16:7"
Mencius described a kind of "qi" that might be characterized as an individual's vital energies. This "qi" was necessary to activity and it could be controlled by a well-integrated willpower. When properly nurtured, this "qi" was said to be capable of extending beyond the human body to reach throughout the universe. It could also be augmented by means of careful exercise of one's moral capacities. On the other hand, the "qi" of an individual could be degraded by adverse external forces that succeed in operating on that individual.
Not only human beings and animals were believed to have "qi". Zhuangzi indicated that wind is the "qi" of the Earth. Moreover, cosmic yin and yang "are the greatest of "qi"." He described "qi" as "issuing forth" and creating profound effects. He said "Human beings are born [because of] the accumulation of "qi". When it accumulates there is life. When it dissipates there is death... There is one "qi" that connects and pervades everything in the world."
Another passage traces life to intercourse between Heaven and Earth: "The highest Yin is the most restrained. The highest Yang is the most exuberant. The restrained comes forth from Heaven. The exuberant issues forth from Earth. The two intertwine and penetrate forming a harmony, and [as a result] things are born."
"The Guanzi essay Neiye 內業 (Inward training) is the oldest received writing on the subject of the cultivation of vapor "[qi]" and meditation techniques. The essay was probably composed at the Jixia Academy in Qi in the late fourth century B.C."
Xun Zi, another Confucian scholar of the Jixia Academy, followed in later years. At 9:69/127, Xun Zi says, "Fire and water have "qi" but do not have life. Grasses and trees have life but do not have perceptivity. Fowl and beasts have perceptivity but do not have "yi" (sense of right and wrong, duty, justice). Men have "qi", life, perceptivity, and "yi"." Chinese people at such an early time had no concept of radiant energy, but they were aware that one can be heated by a campfire from a distance away from the fire. They accounted for this phenomenon by claiming ""qi" radiated from fire. At 18:62/122, he also uses "qi"" to refer to the vital forces of the body that decline with advanced age.
Among the animals, the gibbon and the crane were considered experts at inhaling the "qi". The Confucian scholar Dong Zhongshu (ca. 150 BC) wrote in Luxuriant Dew of the Spring and Autumn Annals: "The gibbon resembles a macaque, but he is larger, and his color is black. His forearms being long, he lives eight hundred years, because he is expert in controlling his breathing." ("猿似猴。大而黑。長前臂。所以壽八百。好引氣也。")
Later, the syncretic text assembled under the direction of Liu An, the Huai Nan Zi, or "Masters of Huainan", has a passage that presages most of what is given greater detail by the Neo-Confucians:
Heaven (seen here as the ultimate source of all being) falls ("duo" 墮, i.e., descends into proto-immanence) as the formless. Fleeting, fluttering, penetrating, amorphous it is, and so it is called the Supreme Luminary. The "dao" begins in the Void Brightening. The Void Brightening produces the universe ("yu"-"zhou"). The universe produces "qi". "Qi" has bounds. The clear, yang "[qi]" was ethereal and so formed heaven. The heavy, turbid "[qi]" was congealed and impeded and so formed earth. The conjunction of the clear, yang "[qi]" was fluid and easy. The conjunction of the heavy, turbid "[qi]" was strained and difficult. So heaven was formed first and earth was made fast later. The pervading essence ("xi"-"jing") of heaven and earth becomes yin and yang. The concentrated ("zhuan") essences of yin and yang become the four seasons. The dispersed ("san") essences of the four seasons become the myriad creatures. The hot "qi" of yang in accumulating produces fire. The essence ("jing") of the fire-"qi" becomes the sun. The cold "qi" of yin in accumulating produces water. The essence of the water-"qi" becomes the moon. The essences produced by coitus (yin) of the sun and moon become the stars and celestial markpoints ("chen", planets).—Huai-nan-zi, 3:1a/19
Role in traditional Chinese medicine.
Traditional Chinese medicine (TCM) asserts that the body has natural patterns of "qi" that circulate in channels called meridians. In TCM, symptoms of various illnesses are believed to be the product of disrupted, blocked, or unbalanced "qi" movement through the body's meridians, as well as deficiencies or imbalances of "qi" in the "Zang Fu" organs. Traditional Chinese medicine often seeks to relieve these imbalances by adjusting the circulation of "qi" using a variety of techniques including herbology, food therapy, physical training regimens (qigong, t'ai chi ch'uan, and other martial arts training), moxibustion, "tui na", and acupuncture.
Qi field.
A "qi" field ("chu-chong") refers to the cultivation of an energy field by a group, typically for healing or other benevolent purposes. A "qi" field is believed to be produced by visualization and affirmation, and is an important component of Wisdom Healing "Qigong" ("Zhineng Qigong"), founded by Grandmaster Ming Pang.
Scientific view.
Qi is a purely hypothetical concept.
A United States National Institutes of Health consensus statement on acupuncture in 1997 noted that concepts such as "qi" "are difficult to reconcile with contemporary biomedical information."
Practices involving qi.
Feng shui.
The traditional Chinese art of geomancy, the placement and arrangement of space called feng shui, is based on calculating the balance of "qi", interactions between the five elements, yin and yang, and other factors. The retention or dissipation of "qi" is believed to affect the health, wealth, energy level, luck and many other aspects of the occupants of the space. Attributes of each item in a space affect the flow of "qi" by slowing it down, redirecting it or accelerating it, which is said to influence the energy level of the occupants.
One use for a "luopan" is to detect the flow of "qi". The quality of "qi" may rise and fall over time, feng shui with a compass might be considered a form of divination that assesses the quality of the local environment.
Qigong.
"Qìgōng" (气功 or 氣功) is a practice involving coordinated breathing, movement, and awareness, traditionally viewed as a practice to cultivate and balance "qi". With roots in traditional Chinese medicine, philosophy, and martial arts, "qigong" is now practiced worldwide for exercise, healing, meditation, and training for martial arts. Typically a "qigong" practice involves rhythmic breathing coordinated with slow stylized movement, a calm mindful state, and visualization of guiding "qi".
Martial arts.
"Qi" is a didactic concept in many Chinese, Korean and Japanese martial arts. Martial "qigong" is a feature of both internal and external training systems in China and other East Asian cultures. The most notable of the "qi"-focused "internal" force (jin) martial arts are Baguazhang, Xing Yi Quan, T'ai Chi Ch'uan, Snake Kung Fu, Southern Dragon Kung Fu, Aikido, Aikijujutsu, Kyūdō, Hapkido, jian and katana swordplay, Luohan Quan, Shaolin Kung Fu, Liu He Ba Fa, Buddhist Style, and some forms of Karate, Tae Kwon Do, and Silat.
Demonstrations of "qi" or "ki" are popular in some martial arts and may include the immovable body, the unraisable body, the unbendable arm, and other feats of power. Some of these feats can alternatively be explained using biomechanics and physics.
Acupuncture and moxibustion.
Acupuncture is a part of Traditional Chinese medicine that involves insertion of needles into superficial structures of the body (skin, subcutaneous tissue, muscles) at acupuncture points to balance the flow of "qi". Acupuncture is often accompanied by moxibustion, a treatment that involves burning mugwort on or near the skin at an acupuncture point.

</doc>
<doc id="25218" url="http://en.wikipedia.org/wiki?curid=25218" title="Quadrillion">
Quadrillion

Quadrillion may mean either of the two numbers (see long and short scales for more detail):

</doc>
<doc id="25219" url="http://en.wikipedia.org/wiki?curid=25219" title="Quanta">
Quanta

Quanta is the plural of quantum.
Quanta may also refer to:

</doc>
<doc id="25220" url="http://en.wikipedia.org/wiki?curid=25220" title="Quantum computing">
Quantum computing

Quantum computing studies theoretical computation systems (quantum computers) that make direct use of quantum-mechanical phenomena, such as superposition and entanglement, to perform operations on data. Quantum computers are different from digital computers based on transistors. Whereas digital computers require data to be encoded into binary digits (bits), each of which is always in one of two definite states (0 or 1), quantum computation uses qubits (quantum bits), which can be in superpositions of states. A quantum Turing machine is a theoretical model of such a computer, and is also known as the universal quantum computer. Quantum computers share theoretical similarities with non-deterministic and probabilistic computers. The field of quantum computing was initiated by the work of Yuri Manin in 1980, Richard Feynman in 1982, and David Deutsch. A quantum computer with spins as quantum bits was also formulated for use as a quantum space–time in 1968.
s of 2015[ [update]], the development of actual quantum computers is still in its infancy, but experiments have been carried out in which quantum computational operations were executed on a very small number of qubits. Both practical and theoretical research continues, and many national governments and military agencies are funding quantum computing research in an effort to develop quantum computers for civilian, business, trade, and national security purposes, such as cryptanalysis.
Large-scale quantum computers will be able to solve certain problems much more quickly than any classical computers that use even the best currently known algorithms, like integer factorization using Shor's algorithm or the simulation of quantum many-body systems. There exist quantum algorithms, such as Simon's algorithm, that run faster than any possible probabilistic classical algorithm.
Given sufficient computational resources, however, a classical computer could be made to simulate any quantum algorithm, as quantum computation does not violate the Church–Turing thesis.
Basis.
A classical computer has a memory made up of bits, where each bit represents either a one or a zero. A quantum computer maintains a sequence of qubits. A single qubit can represent a one, a zero, or any quantum superposition of those two qubit states; a pair of qubits can be in any quantum superposition of 4 states, and three qubits in any superposition of 8 states. In general, a quantum computer with formula_1 qubits can be in an arbitrary superposition of up to formula_2 different states simultaneously (this compares to a normal computer that can only be in "one" of these formula_2 states at any one time). A quantum computer operates by setting the qubits in a controlled initial state that represents the problem at hand and by manipulating those qubits with a fixed sequence of quantum logic gates. The sequence of gates to be applied is called a quantum algorithm. The calculation ends with a measurement, collapsing the system of qubits into one of the formula_2 pure states, where each qubit is zero or one. The outcome can therefore be at most formula_1 classical bits of information. Quantum algorithms are often non-deterministic, in that they provide the correct solution only with a certain known probability.
An example of an implementation of qubits for a quantum computer could start with the use of particles with two spin states: "down" and "up" (typically written formula_6 and formula_7, or formula_8 and formula_9). But in fact any system possessing an observable quantity "A", which is "conserved" under time evolution such that "A" has at least two discrete and sufficiently spaced consecutive eigenvalues, is a suitable candidate for implementing a qubit. This is true because any such system can be mapped onto an effective spin-1/2 system.
Mechanics.
A quantum computer with a given number of qubits is fundamentally different from a classical computer composed of the same number of classical bits. For example, to represent the state of an "n"-qubit system on a classical computer would require the storage of 2"n" complex coefficients. Although this fact may seem to indicate that qubits can hold exponentially more information than their classical counterparts, care must be taken not to overlook the fact that the qubits are only in a probabilistic superposition of all of their states. This means that when the final state of the qubits is measured, they will only be found in one of the possible configurations they were in before measurement. Moreover, it is incorrect to think of the qubits as only being in one particular state before measurement since the fact that they were in a superposition of states before the measurement was made directly affects the possible outcomes of the computation.
For example: Consider first a classical computer that operates on a three-bit register. The state of the computer at any time is a probability distribution over the formula_10 different three-bit strings 000, 001, 010, 011, 100, 101, 110, 111. If it is a deterministic computer, then it is in exactly one of these states with probability 1. However, if it is a probabilistic computer, then there is a possibility of it being in any "one" of a number of different states. We can describe this probabilistic state by eight nonnegative numbers "A","B","C","D","E","F","G","H" (where "A" = is the probability that the computer is in state 000, "B" = is the probability that the computer is in state 001, etc.). There is a restriction that these probabilities sum to 1.
The state of a three-qubit quantum computer is similarly described by an eight-dimensional vector ("a","b","c","d","e","f","g","h"), called a ket. Here, however, the coefficients can have complex values, and it is the sum of the "squares" of the coefficients' magnitudes, formula_11, that must equal 1. These squared magnitudes represent the probability of each of the given states. However, because a complex number encodes not just a magnitude but also a direction in the complex plane, the phase difference between any two coefficients (states) represents a meaningful parameter. This is a fundamental difference between quantum computing and probabilistic classical computing.
If you measure the three qubits, you will observe a three-bit string. The probability of measuring a given string is the squared magnitude of that string's coefficient (i.e., the probability of measuring 000 = formula_12, the probability of measuring 001 = formula_13, etc..). Thus, measuring a quantum state described by complex coefficients ("a","b"...,"h") gives the classical probability distribution formula_14 and we say that the quantum state "collapses" to a classical state as a result of making the measurement.
Note that an eight-dimensional vector can be specified in many different ways depending on what basis is chosen for the space. The basis of bit strings (e.g., 000, 001, …, 111) is known as the computational basis. Other possible bases are unit-length, orthogonal vectors and the eigenvectors of the Pauli-x operator. Ket notation is often used to make the choice of basis explicit. For example, the state ("a","b","c","d","e","f","g","h") in the computational basis can be written as:
The computational basis for a single qubit (two dimensions) is formula_17 and formula_18.
Using the eigenvectors of the Pauli-x operator, a single qubit is formula_19 and formula_20.
Operation.
While a classical three-bit state and a quantum three-qubit state are both eight-dimensional vectors, they are manipulated quite differently for classical or quantum computation. For computing in either case, the system must be initialized, for example into the all-zeros string, formula_21, corresponding to the vector (1,0,0,0,0,0,0,0). In classical randomized computation, the system evolves according to the application of stochastic matrices, which preserve that the probabilities add up to one (i.e., preserve the L1 norm). In quantum computation, on the other hand, allowed operations are unitary matrices, which are effectively rotations (they preserve that the sum of the squares add up to one, the Euclidean or L2 norm). (Exactly what unitaries can be applied depend on the physics of the quantum device.) Consequently, since rotations can be undone by rotating backward, quantum computations are reversible. (Technically, quantum operations can be probabilistic combinations of unitaries, so quantum computation really does generalize classical computation. See quantum circuit for a more precise formulation.)
Finally, upon termination of the algorithm, the result needs to be read off. In the case of a classical computer, we "sample" from the probability distribution on the three-bit register to obtain one definite three-bit string, say 000. Quantum mechanically, we "measure" the three-qubit state, which is equivalent to collapsing the quantum state down to a classical distribution (with the coefficients in the classical state being the squared magnitudes of the coefficients for the quantum state, as described above), followed by sampling from that distribution. Note that this destroys the original quantum state. Many algorithms will only give the correct answer with a certain probability. However, by repeatedly initializing, running and measuring the quantum computer's results, the probability of getting the correct answer can be increased.
For more details on the sequences of operations used for various quantum algorithms, see universal quantum computer, Shor's algorithm, Grover's algorithm, Deutsch–Jozsa algorithm, amplitude amplification, quantum Fourier transform, quantum gate, quantum adiabatic algorithm and quantum error correction.
Potential.
Integer factorization is believed to be computationally infeasible with an ordinary computer for large integers if they are the product of few prime numbers (e.g., products of two 300-digit primes). By comparison, a quantum computer could efficiently solve this problem using Shor's algorithm to find its factors. This ability would allow a quantum computer to decrypt many of the cryptographic systems in use today, in the sense that there would be a polynomial time (in the number of digits of the integer) algorithm for solving the problem. In particular, most of the popular public key ciphers are based on the difficulty of factoring integers or the discrete logarithm problem, both of which can be solved by Shor's algorithm. In particular the RSA, Diffie-Hellman, and Elliptic curve Diffie-Hellman algorithms could be broken. These are used to protect secure Web pages, encrypted email, and many other types of data. Breaking these would have significant ramifications for electronic privacy and security.
However, other cryptographic algorithms do not appear to be broken by those algorithms. Some public-key algorithms are based on problems other than the integer factorization and discrete logarithm problems to which Shor's algorithm applies, like the McEliece cryptosystem based on a problem in coding theory. Lattice-based cryptosystems are also not known to be broken by quantum computers, and finding a polynomial time algorithm for solving the dihedral hidden subgroup problem, which would break many lattice based cryptosystems, is a well-studied open problem. It has been proven that applying Grover's algorithm to break a symmetric (secret key) algorithm by brute force requires time equal to roughly 2n/2 invocations of the underlying cryptographic algorithm, compared with roughly 2n in the classical case, meaning that symmetric key lengths are effectively halved: AES-256 would have the same security against an attack using Grover's algorithm that AES-128 has against classical brute-force search (see Key size). Quantum cryptography could potentially fulfill some of the functions of public key cryptography.
Besides factorization and discrete logarithms, quantum algorithms offering a more than polynomial speedup over the best known classical algorithm have been found for several problems, including the simulation of quantum physical processes from chemistry and solid state physics, the approximation of Jones polynomials, and solving Pell's equation. No mathematical proof has been found that shows that an equally fast classical algorithm cannot be discovered, although this is considered unlikely. For some problems, quantum computers offer a polynomial speedup. The most well-known example of this is "quantum database search", which can be solved by Grover's algorithm using quadratically fewer queries to the database than are required by classical algorithms. In this case the advantage is provable. Several other examples of provable quantum speedups for query problems have subsequently been discovered, such as for finding collisions in two-to-one functions and evaluating NAND trees.
Consider a problem that has these four properties:
An example of this is a password cracker that attempts to guess the password for an encrypted file (assuming that the password has a maximum possible length).
For problems with all four properties, the time for a quantum computer to solve this will be proportional to the square root of the number of inputs. It can be used to attack symmetric ciphers such as Triple DES and AES by attempting to guess the secret key.
Grover's algorithm can also be used to obtain a quadratic speed-up over a brute-force search for a class of problems known as NP-complete.
Since chemistry and nanotechnology rely on understanding quantum systems, and such systems are impossible to simulate in an efficient manner classically, many believe quantum simulation will be one of the most important applications of quantum computing. Quantum simulation could also be used to simulate the behavior of atoms and particles at unusual conditions such as the reactions inside a collider.
There are a number of technical challenges in building a large-scale quantum computer, and thus far quantum computers have yet to solve a problem faster than a classical computer. David DiVincenzo, of IBM, listed the following requirements for a practical quantum computer:
Quantum decoherence.
One of the greatest challenges is controlling or removing quantum decoherence. This usually means isolating the system from its environment as interactions with the external world cause the system to decohere. However, other sources of decoherence also exist. Examples include the quantum gates, and the lattice vibrations and background nuclear spin of the physical system used to implement the qubits. Decoherence is irreversible, as it is non-unitary, and is usually something that should be highly controlled, if not avoided. Decoherence times for candidate systems, in particular the transverse relaxation time "T"2 (for NMR and MRI technology, also called the "dephasing time"), typically range between nanoseconds and seconds at low temperature. Currently, some quantum computers require their qubits to be cooled to 20 millikelvin in order to prevent significant decoherence.
These issues are more difficult for optical approaches as the timescales are orders of magnitude shorter and an often-cited approach to overcoming them is optical pulse shaping. Error rates are typically proportional to the ratio of operating time to decoherence time, hence any operation must be completed much more quickly than the decoherence time.
If the error rate is small enough, it is thought to be possible to use quantum error correction, which corrects errors due to decoherence, thereby allowing the total calculation time to be longer than the decoherence time. An often cited figure for required error rate in each gate is 10−4. This implies that each gate must be able to perform its task in one 10,000th of the decoherence time of the system.
Meeting this scalability condition is possible for a wide range of systems. However, the use of error correction brings with it the cost of a greatly increased number of required qubits. The number required to factor integers using Shor's algorithm is still polynomial, and thought to be between "L" and "L"2, where "L" is the number of bits in the number to be factored; error correction algorithms would inflate this figure by an additional factor of "L". For a 1000-bit number, this implies a need for about 104 qubits without error correction. With error correction, the figure would rise to about 107 qubits. Note that computation time is about "L"2 or about 107 steps and on 1 MHz, about 10 seconds.
A very different approach to the stability-decoherence problem is to create a topological quantum computer with anyons, quasi-particles used as threads and relying on braid theory to form stable logic gates.
Developments.
There are a number of quantum computing models, distinguished by the basic elements in which the computation is decomposed. The four main models of practical importance are:
The "Quantum Turing machine" is theoretically important but direct implementation of this model is not pursued. All four models of computation have been shown to be equivalent; each can simulate the other with no more than polynomial overhead.
For physically implementing a quantum computer, many different candidates are being pursued, among them (distinguished by the physical system used to realize the qubits):
The large number of candidates demonstrates that the topic, in spite of rapid progress, is still in its infancy, there is also a vast amount of flexibility.
Timeline.
In 2001, researchers demonstrated Shor's algorithm to factor 15 using a 7-qubit NMR computer.
In 2005, researchers at the University of Michigan built a semiconductor chip ion trap. Such devices from standard lithography, may point the way to scalable quantum computing.
In 2009, researchers at Yale University created the first solid-state quantum processor. The two-qubit superconducting chip had artificial atom qubits made of a billion aluminum atoms that acted like a single atom that could occupy two states.
A team at the University of Bristol, also created a silicon chip based on quantum optics, able to run Shor's algorithm.
Further developments were made in 2010.
Springer publishes a journal ("Quantum Information Processing") devoted to the subject.
In April 2011, a team of scientists from Australia and Japan made a breakthrough in quantum teleportation. They successfully transferred a complex set of quantum data with full transmission integrity, without affecting the qubits superpositions.
In 2011, D-Wave Systems announced the first commercial quantum annealer, the D-Wave One, claiming a 128 qubit processor. On May 25, 2011 Lockheed Martin agreed to purchase a D-Wave One system. Lockheed and the University of Southern California (USC) will house the D-Wave One at the newly formed USC Lockheed Martin Quantum Computing Center. D-Wave's engineers designed the chips with an empirical approach, focusing on solving particular problems. Investors liked this more than academics, who said D-Wave had not demonstrated they really had a quantum computer. Criticism softened after a D-Wave paper in Nature, that proved the chips have some quantum properties. Experts remain skeptical of D-Waves claims. Two published papers have concluded that the D-Wave machine operates classically, not via quantum computing.
During the same year, researchers at the University of Bristol created an all-bulk optics system that ran a version of Shor's algorithm to successfully factor 21.
In September 2011 researchers proved quantum computers can be made with a Von Neumann architecture (separation of RAM).
In November 2011 researchers factorized 143 using 4 qubits.
In February 2012 IBM scientists said that they had made several breakthroughs in quantum computing with superconducting integrated circuits.
In April 2012 a multinational team of researchers from the University of Southern California, Delft University of Technology, the Iowa State University of Science and Technology, and the University of California, Santa Barbara, constructed a two-qubit quantum computer on a doped diamond crystal that can easily be scaled up and is functional at room temperature. Two logical qubit directions of electron spin and nitrogen kernels spin were used, with microwave impulses. This computer ran Grover's algorithm generating the right answer from the first try in 95% of cases.
In September 2012, Australian researchers at the University of New South Wales said the world's first quantum computer was just 5 to 10 years away, after announcing a global breakthrough enabling manufacture of its memory building blocks. A research team led by Australian engineers created the first working qubit based on a single atom in silicon, invoking the same technological platform that forms the building blocks of modern day computers.
In October 2012, Nobel Prizes were presented to David J. Wineland and Serge Haroche for their basic work on understanding the quantum world, which may help make quantum computing possible.
In November 2012, the first quantum teleportation from one macroscopic object to another was reported.
In December 2012, the first dedicated quantum computing software company, 1QBit was founded in Vancouver, BC. 1QBit is the first company to focus exclusively on commercializing software applications for commercially available quantum computers, including the D-Wave Two. 1QBit's research demonstrated the ability of superconducting quantum annealing processors to solve real-world problems.
In February 2013, a new technique, boson sampling, was reported by two groups using photons in an optical lattice that is not a universal quantum computer but may be good enough for practical problems. "Science" Feb 15, 2013
In May 2013, Google announced that it was launching the Quantum Artificial Intelligence Lab, hosted by NASA‍‍ '​‍s Ames Research Center, with a 512-qubit D-Wave quantum computer. The USRA (Universities Space Research Association) will invite researchers to share time on it with the goal of studying quantum computing for machine learning.
In early 2014 it was reported, based on documents provided by former NSA contractor Edward Snowden, that the U.S. National Security Agency (NSA) is running a $79.7 million research program (titled "Penetrating Hard Targets") to develop a quantum computer capable of breaking vulnerable encryption.
In 2014, a group of researchers from ETH Zürich, USC, Google and Microsoft reported a definition of quantum speedup, and were not able to measure quantum speedup with the D-Wave Two device, but did not explicitly rule it out.
In 2014, researchers at University of New South Wales used silicon as a protectant shell around qubits, making them more accurate, increasing the length of time they will hold information and possibly made quantum computers easier to build.
In April 2015 IBM scientists claimed two critical advances towards the realization of a practical quantum computer. They claimed the ability to detect and measure both kinds of quantum errors simultaneously, as well as a new, square quantum bit circuit design that could scale to larger dimensions. 
Relation to computational complexity theory.
The class of problems that can be efficiently solved by quantum computers is called BQP, for "bounded error, quantum, polynomial time". Quantum computers only run probabilistic algorithms, so BQP on quantum computers is the counterpart of BPP ("bounded error, probabilistic, polynomial time") on classical computers. It is defined as the set of problems solvable with a polynomial-time algorithm, whose probability of error is bounded away from one half. A quantum computer is said to "solve" a problem if, for every instance, its answer will be right with high probability. If that solution runs in polynomial time, then that problem is in BQP.
BQP is contained in the complexity class "#P" (or more precisely in the associated class of decision problems "P#P"), which is a subclass of PSPACE.
BQP is suspected to be disjoint from NP-complete and a strict superset of P, but that is not known. Both integer factorization and discrete log are in BQP. Both of these problems are NP problems suspected to be outside BPP, and hence outside P. Both are suspected to not be NP-complete. There is a common misconception that quantum computers can solve NP-complete problems in polynomial time. That is not known to be true, and is generally suspected to be false.
The capacity of a quantum computer to accelerate classical algorithms has rigid limits—upper bounds of quantum computation's complexity. The overwhelming part of classical calculations cannot be accelerated on a quantum computer. A similar fact takes place for particular computational tasks, like the search problem, for which Grover's algorithm is optimal.
Although quantum computers may be faster than classical computers, those described above can't solve any problems that classical computers can't solve, given enough time and memory (however, those amounts might be practically infeasible). A Turing machine can simulate these quantum computers, so such a quantum computer could never solve an undecidable problem like the halting problem. The existence of "standard" quantum computers does not disprove the Church–Turing thesis. It has been speculated that theories of quantum gravity, such as M-theory or loop quantum gravity, may allow even faster computers to be built. Currently, "defining" computation in such theories is an open problem due to the "problem of time", i.e., there currently exists no obvious way to describe what it means for an observer to submit input to a computer and later receive output.

</doc>
<doc id="25222" url="http://en.wikipedia.org/wiki?curid=25222" title="QT">
QT

QT or Qt may refer to:

</doc>
<doc id="25223" url="http://en.wikipedia.org/wiki?curid=25223" title="Quasigroup">
Quasigroup

In mathematics, especially in abstract algebra, a quasigroup is an algebraic structure resembling a group in the sense that "division" is always possible. Quasigroups differ from groups mainly in that they need not be associative.
A quasigroup with an identity element is called a loop.
Definitions.
There are at least two equivalent formal definitions of quasigroup. One defines a quasigroup as a set with one binary operation, and the other, from universal algebra, defines a quasigroup as having three primitive operations. We begin with the first definition.
A quasigroup ("Q", ∗) is a set "Q" with a binary operation ∗ (that is, a magma), obeying the Latin square property. This states that, for each "a" and "b" in "Q", there exist unique elements "x" and "y" in "Q" such that:
(In other words: Each element of the set occurs exactly once in each row and exactly once in each column of the quasigroup's multiplication table, or Cayley table. This property ensures that the Cayley table of a finite quasigroup is a Latin square.)<br>
The unique solutions to these equations are written "x" = "a" \ "b" and "y" = "b" / "a". The operations '\' and '/' are called, respectively, left and right division.
The empty set equipped with the empty binary operation satisfies this definition of a quasigroup. Some authors accept the empty quasigroup but others explicitly exclude it.
Universal algebra.
Given some algebraic structure, an identity is an equation in which all variables are tacitly universally quantified, and in which all operations are among the primitive operations proper to the structure. Algebraic structures axiomatized solely by identities are called varieties. Many standard results in universal algebra hold only for varieties. Quasigroups are varieties if left and right division are taken as primitive.
A quasigroup ("Q", ∗, \, /) is a type (2,2,2) algebra satisfying the identities:
Hence if ("Q", ∗) is a quasigroup according to the first definition, then ("Q", ∗, \, /) is the same quasigroup in the sense of universal algebra.
Loop.
A loop is a quasigroup with an identity element, that is, an element "e" such that:
It follows that the identity element "e" is unique, and that every element of "Q" has a unique left and right inverse. Since the presence of an identity element is essential, a loop cannot be empty.
A quasigroup with an idempotent element is called a pique ("pointed idempotent quasigroup"); this is a weaker notion than loop but common nonetheless because given an abelian group ("A", +), its subtraction operation (as quasigroup multiplication) yields a pique ("A", -) with the abelian group's zero/identity turned into a "pointed idempotent", i.e. there's a principal isotopy formula_1.
A loop which is associative is a group. A group can have a nonassociative pique isotope, but it cannot
have a nonassociative loop isotope. There are also some weaker associativity-like properties which have been given special names.
A Bol loop is a loop that satisfies, for each "x", "y" and "z" in "Q", one of the two identifies:
A loop that is both a left and right Bol loop is a Moufang loop. This is equivalent to any one of the following single Moufang identities:
Symmetries.
Smith (2007) names the following important subclasses:
Semisymmetry.
A quasigroup is semisymmetric if any/all of the following equivalent identities hold:
Although this class may seem special, every quasigroup "Q" induces a semisymmetric quasigroup "Q"Δ on the direct product cube "Q3" via following operation:
formula_2
where "//" and "\\" are the conjugate division operations; the latter formula more explicitly shows that the construction is exploiting an orbit of S3.
Total symmetry.
A narrower class that is a total symmetric quasigroup (sometimes abbreviated TS-quasigroup) in which all conjugates coincide as one operation: "xy" = "x/y" = "x\y". Another way to define (the same notion of) totally symmetric quasigroup is as a semisymmetric quasigroup which additionally is commutative, i.e. "xy"="yx".
Idempotent total symmetric quasigroups are precisely (i.e. in a bijection with) Steiner triples, so such a quasigroups is also called a Steiner quasigroups, and sometimes the latter is even abbreviated as squag; the term sloop is defined similarly for a Steiner quasigroup that is also a loop. Without idempotency, total symmetric quasigroups correspond to the geometric notion of extended Steiner triple, also called Generalized Elliptic Cubic Curve (GECC).
Total antisymmetry.
A quasigroup ("Q", ∗) is called totally anti-symmetric if for all "c", "x", "y" ∈ "Q", the following implications hold:
and it is called weakly totally anti-symmetric if only the first implication holds.
This property is required, for example, in the Damm algorithm.
Properties.
Quasigroups have the cancellation property: if "ab" = "ac", then "b" = "c". This follows from the uniqueness of left division of "ab" or "ac" by "a". Similarly, if "ba" = "ca", then "b" = "c".
Multiplication operators.
The definition of a quasigroup can be treated as conditions on the left and right multiplication operators "L"("x"), "R"("y"): "Q" → "Q", defined by 
The definition says that both mappings are bijections from "Q" to itself. A magma "Q" is a quasigroup precisely when all these operators, for every "x" in "Q", are bijective. The inverse mappings are left and right division, that is, 
In this notation the identities among the quasigroup's multiplication and division operations (stated in the section on universal algebra) are
where 1 denotes the identity mapping on "Q".
Latin squares.
The multiplication table of a finite quasigroup is a Latin square: an "n" × "n" table filled with "n" different symbols in such a way that each symbol occurs exactly once in each row and exactly once in each column.
Conversely, every Latin square can be taken as the multiplication table of a quasigroup in many ways: the border row (containing the column headers) and the border column (containing the row headers) can each be any permutation of the elements. See small Latin squares and quasigroups.
Inverse properties.
Every loop element has a unique left and right inverse given by
A loop is said to have ("two-sided") "inverses" if formula_8 for all "x". In this case the inverse element is usually denoted by formula_9.
There are some stronger notions of inverses in loops which are often useful:
A loop has the "inverse property" if it has both the left and right inverse properties. Inverse property loops also have the antiautomorphic and weak inverse properties. In fact, any loop which satisfies any two of the above four identities has the inverse property and therefore satisfies all four.
Any loop which satisfies the left, right, or antiautomorphic inverse properties automatically has two-sided inverses.
Morphisms.
A quasigroup or loop homomorphism is a map "f" : "Q" → "P" between two quasigroups such that "f"("xy") = "f"("x")"f"("y"). Quasigroup homomorphisms necessarily preserve left and right division, as well as identity elements (if they exist).
Homotopy and isotopy.
Let "Q" and "P" be quasigroups. A quasigroup homotopy from "Q" to "P" is a triple (α, β, γ) of maps from "Q" to "P" such that
for all "x", "y" in "Q". A quasigroup homomorphism is just a homotopy for which the three maps are equal.
An isotopy is a homotopy for which each of the three maps (α, β, γ) is a bijection. Two quasigroups are isotopic if there is an isotopy between them. In terms of Latin squares, an isotopy (α, β, γ) is given by a permutation of rows α, a permutation of columns β, and a permutation on the underlying element set γ.
An autotopy is an isotopy from a quasigroup to itself. The set of all autotopies of a quasigroup form a group with the automorphism group as a subgroup.
Each quasigroup is isotopic to a loop. If a loop is isotopic to a group, then it is isomorphic to that group and thus is itself a group. However, a quasigroup which is isotopic to a group need not be a group. For example, the quasigroup on R with multiplication given by ("x" + "y")/2 is isotopic to the additive group (R, +), but is not itself a group. Every medial quasigroup is isotopic to an abelian group by the Bruck–Toyoda theorem.
Conjugation (parastrophe).
Left and right division are examples of forming a quasigroup by permuting the variables in the defining equation. From the original operation ∗ (i.e., "x" ∗ "y" = "z") we can form five new operations: "x" o "y" := "y" ∗ "x" (the opposite operation), / and \, and their opposites. That makes a total of six quasigroup operations, which are called the conjugates or parastrophes of ∗. Any two of these operations are said to be "conjugate" or "parastrophic" to each other (and to themselves).
Paratopy.
If the set "Q" has two quasigroup operations, ∗ and ·, and one of them is isotopic to a conjugate of the other, the operations are said to be paratopic to each other. There are also many other names for this relation of "paratopy", e.g., isostrophe.
Generalizations.
Polyadic or multiary quasigroups.
An "n"-ary quasigroup is a set with an "n"-ary operation, ("Q", "f") with "f": "Q""n" → "Q", such that the equation "f"("x"1...,"xn") = "y" has a unique solution for any one variable if all the other "n" variables are specified arbitrarily. Polyadic or multiary means "n"-ary for some nonnegative integer "n".
A 0-ary, or nullary, quasigroup is just a constant element of "Q". A 1-ary, or unary, quasigroup is a bijection of "Q" to itself. A binary, or 2-ary, quasigroup is an ordinary quasigroup.
An example of a multiary quasigroup is an iterated group operation, "y" = "x"1 · "x"2 · ··· · "x""n"; it is not necessary to use parentheses to specify the order of operations because the group is associative. One can also form a multiary quasigroup by carrying out any sequence of the same or different group or quasigroup operations, if the order of operations is specified.
There exist multiary quasigroups that cannot be represented in any of these ways. An "n"-ary quasigroup is irreducible if its operation cannot be factored into the composition of two operations in the following way:
where 1 ≤ "i" < "j" ≤ "n" and ("i, j") ≠ (1, "n"). Finite irreducible "n"-ary quasigroups exist for all "n" > 2; see Akivis and Goldberg (2001) for details.
An "n"-ary quasigroup with an "n"-ary version of associativity is called an n-ary group.
Right- and left-quasigroups.
A right-quasigroup ("Q", ∗, /) is a type (2,2) algebra satisfying the identities:
Similarly, a left-quasigroup ("Q", ∗, \) is a type (2,2) algebra satisfying the identities:
Number of small quasigroups and loops.
The number of isomorphism classes of small quasigroups (sequence in OEIS) and loops (sequence in OEIS) is given here:

</doc>
<doc id="25225" url="http://en.wikipedia.org/wiki?curid=25225" title="Quaestor">
Quaestor

A quaestor (; ]) was a type of public official in the "cursus honorum" system who supervised the financial affairs of the state and conducted audits. In the Roman Republic a quaestor was an elected official, but in the Roman Empire, quaestors came to be simply appointed.
Today the term "quaestor" is used as a senior police rank in Italy and Romania, and as the title of an office of financial oversight in some organizations.
History.
Quaestores parricidii.
The earliest quaestores were the quaestores parricidii, an office dating back to the Kingdom of Rome. The quaestores parricidii were chosen to investigate capital crimes, and may have been appointed as needed rather than on a regular basis. Ancient authors disagree on the earliest institution of this office, with some dating it to the mythical reign of Romulus, and also on the exact manner of selection.
The word itself derives from the verb "quaero", "quaerere", meaning "to inquire", and the title "quaestor" has traditionally been understood as deriving from the original investigative function of the quaestores parricidii.
Ancient authors, perhaps influenced by etymology, reasoned that the investigative role of the quaestores parricidii had evolved to include financial matters, giving rise to the similarly-named later offices. This connection has, however, been questioned by modern scholars.
Quaestor.
A variant of the title, "quaestor", continued to be used in judicial proceedings during the Roman Republic. This referred to the chairman of a jury in a criminal court, and sometimes to a praetor or other official serving as president of a permanent commission. This usage has the same origin as "quaestor" and preserves the association with criminal trials as in the earlier quaestor parricidii.
Quaestores in the Roman Republic.
In the Roman Republic, quaestores were elected officials who supervised the treasury and financial affairs of the state, its armies and its officers. The quaestors tasked with financial supervision were also called "quaestores aerarii", because they oversaw the "aerarium" or public treasury in the Temple of Saturn.
The earliest origins of the office is obscure, but
by about 420 BC there were four quaestors, elected each year by the "Comitia Tributa". After 267 BC the number was expanded to ten. Some quaestors were assigned to work in the City, while others were assigned to the staffs of generals or served as lieutenant governors in the provinces. Still others were assigned to oversee military finances. Every consul and every provincial governor was appointed a quaestor, and whilst in the provinces their responsibilities could also include military recruitment.
The office of quaestor was adopted as the first official post of the cursus honorum, and was usually a former broad-stripe tribune. By achieving election as quaestor, a Roman man would earn the right to sit in the Senate and begin to progress along the standard sequence of offices that made up a career in public service. Quaestors were entitled to one fasces and one lictor.
During the reforms of Sulla in 81 BC, the minimum age for a quaestorship was set at 30 for patricians and at 32 for plebeians, and election to the quaestorship gave automatic membership in the Senate. Before that, the censors revised the rolls of the Senate less regularly than the annual induction of quaestors created. The number of quaestors was also raised to 20.
Later Roman quaestores.
During Late Antiquity, the office of "quaestor sacri palatii" existed, created by Constantine the Great, which functioned as the Roman Empire's senior legal official. Emperor Justinian I also created the offices of "quaesitor", a judicial and police official for Constantinople, and the "quaestor exercitus", a short-lived joint military-administrative post covering the border of the lower Danube. The "quaestor sacri palatii" survived long in the Byzantine Empire, albeit with his duties altered to coincide with those of the "quaesitor". The term is last attested in Byzantium in the 14th century, as a purely honorific dignity.
Modern usage.
Religion.
The Capuchin friars, in earlier centuries, would designate one or more of the members of each community as quaestor, whose duty was to go about the region collecting alms to support the friars and their works of charity.
Police.
In Italy a quaestor (Italian: "questore") heads the police of his province ("Polizia di Stato"), and his office is called "questura". Some quaestors have other assignments, however.
In Romania a quaestor (Romanian: "chestor") is also a senior police rank.
Financial oversight.
The European Parliament has five Quaestors to look after the financial and administrative needs of its members.
Some ancient British universities, such as the University of St Andrews, have a quaestor who is responsible for financial management.
In the United States, the Sigma Chi Fraternity and the Kappa Delta Rho Fraternity currently uses the Officer title quaestor as their treasurer's name as he oversees the financial obligations of the Fraternity.

</doc>
<doc id="25228" url="http://en.wikipedia.org/wiki?curid=25228" title="Q.E.D.">
Q.E.D.

Q.E.D. is an initialism of the Latin phrase quod erat demonstrandum, originating from the Ancient Greek analogous "hóper édei deîxai" (ὅπερ ἔδει δεῖξαι), meaning "which had to be proven". The phrase is traditionally placed in its abbreviated form at the end of a mathematical proof or philosophical argument when what was specified in the enunciation—and in the setting-out—has been exactly restated as the conclusion of the demonstration. The abbreviation thus signals the completion of the proof.
Etymology and early use.
The phrase "quod erat demonstrandum" is a translation into Latin from the Greek ὅπερ ἔδει δεῖξαι ("hoper edei deixai"; abbreviated as "ΟΕΔ"). Translating from the Latin into English yields, "what was to be demonstrated"; however, translating the Greek phrase ὅπερ ἔδει δεῖξαι produces a slightly different meaning. Since the verb "δείκνυμι" also means "to show" or "to prove", a better translation from the Greek would read, "The very thing it was required to have shown." The phrase was used by many early Greek mathematicians, including Euclid and Archimedes.
Modern philosophy.
In the European Renaissance, scholars often wrote in Latin, and phrases such as "Q.E.D." were often used to conclude proofs.
Perhaps the most famous use of "Q.E.D." in a philosophical argument is found in the "Ethics" of Baruch Spinoza, published posthumously in 1677. Written in Latin, it is considered by many to be Spinoza's "magnum opus". The style and system of the book is, as Spinoza says, "demonstrated in geometrical order", with axioms and definitions followed by propositions. For Spinoza, this is a considerable improvement over René Descartes's writing style in the "Meditations", which follows the form of a diary.
QEF.
There is another Latin phrase with a slightly different meaning, and less common in usage. "Quod erat faciendum", originating from the Greek geometers' closing ὅπερ ἔδει ποιῆσαι ("hoper edei poiēsai"), meaning "which had to be done". Euclid used this phrase to close propositions which were not proofs of theorems, but constructions. For example, Euclid's first proposition shows how to construct an equilateral triangle given one side. It is usually shortened to "QEF".
Equivalents in other languages.
"Q.E.D." has acquired many translations in various languages, including:
There is no common formal English equivalent, though the end of a proof may be announced with a simple statement such as "this completes the proof", "as required", "hence proved", "ergo", or a similar locution. WWWWW or W5 - an abbreviation of "Which Was What Was Wanted" - has also been used. This is often considered to be more tongue-in-cheek than the usual Halmos symbol (see below) or Q.E.D.
Electronic forms.
When typesetting was done by a compositor with letterpress printing, complex typography such as mathematics and foreign languages were called "penalty copy" (the author paid a "penalty" to have them typeset, as it was harder than plain text). With the advent of systems such as LaTeX, mathematicians found their options more open, so there are several symbolic alternatives in use, either in the input, the output, or both. When creating TeX, Knuth provided the symbol ■ (solid black square), also called by mathematicians "tombstone" or "Halmos symbol" (after Paul Halmos, who pioneered its use as an equivalent of Q.E.D.). The tombstone is sometimes open: □ (hollow black square). Unicode explicitly provides the "End of proof" character U+220E (∎), but also offers ▮ (U+25AE, black vertical rectangle) and ‣ (U+2023, triangular bullet) as alternatives. Some authors have adopted variants of this notation with other symbols, such as two forward slashes (//), or simply some vertical white space, implying no further statements need to be made in the proof.
Modern humorous usage.
In Joseph Heller's book "Catch-22", the Chaplain, having been told to examine a forged letter allegedly signed by him (which he knew he didn't sign), verified that his "name" was in fact there. His investigator replied, "Then you wrote it. Q.E.D." The chaplain said he didn't write it and that it wasn't his handwriting, but the investigator's faulty logic caused him to point out, "Then you signed your name in somebody else's handwriting again."
In the mid eighties, BBC ran a series called "Q.E.D." which showed how certain things were made or put together.
In the 1978 sci-fi radio comedy, and later in the TV and novel adaptations of "The Hitchhiker's Guide to the Galaxy", "Q.E.D." is referred to in the Guide's entry for the babel fish, when it is claimed that the babel fish is used as evidence for the non-existence of God.

</doc>
<doc id="25229" url="http://en.wikipedia.org/wiki?curid=25229" title="Quagga">
Quagga

The quagga ( or ) ("Equus quagga quagga") is an extinct subspecies of plains zebra that lived in South Africa until the 19th century. It was long thought to be a distinct species, but genetic studies have shown it to be the southernmost subspecies of plains zebra. It is considered particularly close to Burchell's zebra. Its name is derived from its call, which sounds like "kwa-ha-ha".
The quagga is believed to have been around 257 cm long and 125 – tall at the shoulder. It was distinguished from other zebras by its limited pattern of primarily brown and white stripes, mainly on the front part of the body. The rear was brown and without stripes, and therefore more horse-like. The distribution of stripes varied considerably between individuals. Little is known about the quagga's behaviour, but it may have gathered into herds of 30–50 individuals. Quaggas were said to be wild and lively, yet were also considered more docile than Burchell's zebra. They were once found in great numbers in the Karoo of Cape Province and the southern part of the Orange Free State in South Africa.
Since Dutch settlement of South Africa began, the quagga was heavily hunted as it competed with domesticated animals for forage. While some individuals were taken to zoos in Europe, breeding programs were unsuccessful. The last wild population lived in the Orange Free State, and the quagga was extinct in the wild by 1878. The last captive specimen died in Amsterdam on 12 August 1883. Only one quagga was ever photographed alive and only 23 skins are preserved today. In 1984, the quagga was the first extinct animal to have its DNA analysed, and the Quagga Project is trying to recreate the phenotype of hair coat pattern and related characteristics by selectively breeding Burchell's zebras.
Taxonomy.
The name "quagga" is derived from the Khoikhoi word for "zebra" and is onomatopoeic, being said to resemble the quagga's call, variously transcribed as "kwa-ha-ha", "kwahaah", or "oug-ga". The name is still used colloquially for the plains zebra. The quagga was originally classified as a distinct species, "Equus quagga", in 1778 by Dutch naturalist Pieter Boddaert. Traditionally, the quagga and the other plains and mountain zebras were placed in the subgenus "Hippotigris".
There has been much debate over the status of the quagga in relation to the plains zebra. It is poorly represented in the fossil record, and the identification of these fossils is uncertain, as they were collected at a time when the name quagga referred to all zebras. Fossil skulls of "Equus mauritanicus" from Algeria have been claimed to show affinities with the quagga and the plains zebra, but they may be too badly damaged to allow definite conclusions to be drawn from them. Quaggas have also been identified in cave art attributed to the San. Reginald Innes Pocock was perhaps the first to suggest that the quagga was a subspecies of plains zebra in 1902. As the quagga was scientifically described and named before the plains zebra, the trinomial name for the quagga becomes "E. quagga quagga" under this scheme, and the other subspecies of plains zebra are placed under "E. quagga" as well.
Historically, quagga taxonomy was further complicated by the fact that the extinct southernmost population of Burchell's zebra ("Equus quagga burchellii", formerly "Equus burchellii burchellii") was thought to be a distinct subspecies (also sometimes thought a full species, "E. burchellii"). The extant northern population, the "Damara zebra", was later named "Equus quagga antiquorum", which means that it is today also referred to as "E. q. burchellii", after it was realised they were the same taxon. The extinct population was long thought very close to the quagga, since it also showed limited striping on its hind parts. As an example of this, Shortridge placed the two in the now disused subgenus "Quagga" in 1934. Most experts now suggest that the two subspecies represent two ends of a cline.
Different subspecies of plains zebra were recognised as members of "Equus quagga" by early researchers, though there was much confusion over which species were valid. Quagga subspecies were described on the basis of differences in striping patterns, but these differences were since attributed to individual variation within the same populations. Some subspecies and even species, such as "E. q. danielli" and "Hippotigris isabellinus", were only based on illustrations (iconotypes) of aberrant quagga specimens. Some authors have described the quagga as a kind of wild horse rather than a zebra, and one craniometric study from 1980 seemed to confirm its affiliation with the horse ("Equus caballus"). It has been pointed out that early morphological studies were erroneous; using skeletons from stuffed specimens can be problematical, as early taxidermists sometimes used donkey and horse skulls inside their mounts when the originals were unavailable.
Evolution.
The quagga was the first extinct animal to have its DNA analysed, and this 1984 study launched the field of ancient DNA analysis. It confirmed that the quagga was more closely related to zebras than to horses, with the quagga and mountain zebra ("Equus zebra") sharing an ancestor 3–4 million years ago. An immunological study published the following year found the quagga to be closest to the plains zebra. A 1987 study suggested that the mtDNA of the quagga diverged at a range of roughly 2% per million years, similar to other mammal species, and again confirmed the close relation to the plains zebra.
Later morphological studies came to conflicting conclusions. A 1999 analysis of cranial measurements found that the quagga was as different from the plains zebra as the latter is from the mountain zebra. A 2004 study of skins and skulls instead suggested that the quagga was not a distinct species, but a subspecies of the plains zebra. In spite of these findings, many authors subsequently kept the plains zebra and the quagga as separate species.
A genetic study published in 2005 confirmed the subspecific status of the quagga. It showed that the quagga had little genetic diversity, and that it diverged from the other plains zebra subspecies only between 120,000 and 290,000 years ago, during the Pleistocene, and possibly the penultimate glacial maximum. Its distinct coat pattern perhaps evolved rapidly because of geographical isolation and/or adaptation to a drier environment. In addition, plains zebra subspecies tend to have less striping the further south they live, and the quagga was the most southern-living of them all. Other large African ungulates diverged into separate species and subspecies during this period as well, probably because of the same climate shift. The simplified cladogram below is based on the 2005 analysis (some taxa shared haplotypes and could therefore not be differentiated):
Description.
The quagga is believed to have been 257 cm long and 125 – tall at the shoulder. Its coat pattern was unique among equids: zebra-like in the front but more like a horse in the rear. It had brown stripes on the head and neck, brown upper parts and a white belly, tail and legs. The stripes were darkest on the head and neck and became gradually lighter further down the body, blending with the reddish brown of the back and flanks, until disappearing along the back. It appears to have had a high degree of polymorphism, with some individuals having almost no stripes and others having patterns similar to the extinct southern population of Burchell's zebra, where the stripes covered most of the body except for the hind parts, legs and belly. It also had a broad dark dorsal stripe on its back. It had a standing mane with brown and white stripes.
The only quagga to have been photographed alive was a mare at the Zoological Society of London's Zoo. Five photographs of this specimen are known, taken between 1863 and 1870. On the basis of photographs and written descriptions, many observers suggest that the stripes on the quagga were light on a dark background, unlike other zebras. Reinhold Rau, pioneer of the Quagga Project, claimed that this is an optical illusion: that the base colour is a creamy white and that the stripes are thick and dark. Embryological evidence supports zebras being dark coloured with white as an addition.
Living in the very southern end of the plains zebra's range, the quagga had a thick winter coat that moulted each year. Its skull was described as having a straight profile and a concave diastema, and as being relatively broad with a narrow occiput. Like other plains zebras, the quagga did not have a dewlap on its neck as the mountain zebra does. The 2004 morphological study found that the skeletal features of the southern Burchell's zebra population and the quagga overlapped, and that they were impossible to distinguish. Some specimens also appeared to be intermediate between the two in striping, and individuals of the extant Burchell's zebra population still exhibit limited striping. It can therefore be concluded that the two subspecies graded morphologically into each other. Today, some stuffed specimens of quaggas and southern Burchell's zebra are so similar that they are impossible to definitely identify as either, since no location data was recorded. The female specimens used in the study were larger than the males on average.
Behaviour and ecology.
The quagga was the southernmost distributed plains zebra, mainly living south of the Orange River. It was a grazer, and its habitat range was restricted to the grasslands and arid interior scrubland of the Karoo region of South Africa, today forming parts of the provinces of Northern Cape, Eastern Cape, Western Cape and the Free State. These areas were known for distinctive flora and fauna and high amounts of endemism.
Little is known about the behaviour of quaggas in the wild, and it is sometimes unclear what exact species of zebra is referred to in old reports. The only source that unequivocally describes the quagga in the Free State is that of the English military engineer and hunter Major Sir William Cornwallis Harris. His 1840 account reads as follows:
The geographical range of the quagga does not appear to extend to the northward of the river Vaal. The animal was formerly extremely common within the colony; but, vanishing before the strides of civilisation, is now to be found in very limited numbers and on the borders only. Beyond, on those sultry plains which are completely taken possession of by wild beasts, and may with strict propriety be termed the domains of savage nature, it occurs in interminable herds; and, although never intermixing with its more elegant congeners, it is almost invariably to be found ranging with the white-tailed gnu and with the ostrich, for the society of which bird especially it evinces the most singular predilection. Moving slowly across the profile of the ocean-like horizon, uttering a shrill, barking neigh, of which its name forms a correct imitation, long files of quaggas continually remind the early traveller of a rival caravan on its march. Bands of many hundreds are thus frequently seen doing their migration from the dreary and desolate plains of some portion of the interior, which has formed their secluded abode, seeking for those more luxuriant pastures where, during the summer months, various herbs thrust forth their leaves and flowers to form a green carpet, spangled with hues the most brilliant and diversified.
Quaggas have been reported gathering into herds of 30–50 individuals and sometimes travelled in a linear fashion. They may have been sympatric with Burchell's zebra between the Vaal and Orange rivers. This is disputed, and there is no evidence that they interbred. It could also have shared a small portion of its range with Hartmann's mountain zebra ("Equus zebra hartmannae").
Quaggas were said to be lively and highly strung, especially the stallions. During the 1830s, quaggas were used as harness animals for carriages in London, the males probably being gelded to mitigate their volatile nature. Local farmers used them as guards for their livestock, as they were likely to attack intruders. On the other hand, captive quaggas in European zoos were said to be tamer and more docile than Burchell's zebra. One specimen was reported to have lived in captivity for 21 years and 4 months, dying in 1872.
Since the practical function of striping has not been determined for zebras in general, it is unclear why the quagga lacked stripes on its hind parts. A cryptic function for protection from predators (stripes obscure the individual zebra in a herd) and biting flies (which are less attracted to striped objects), as well as various social functions, have been proposed for zebras in general. Differences in hind quarter stripes may have aided species recognition during stampedes of mixed herds, so that members of one subspecies or species would follow its own kind. It has also been hypothesised that the zebras developed striping patterns as thermoregulation to cool themselves down, and that the quagga lost them due to living in a cooler climate, although one problem with this is that the mountain zebra lives in similar environments and has a bold striping pattern. A 2014 study strongly supported the biting-fly hypothesis, and the quagga appears to have lived in areas with lesser amounts of fly activity compared to other zebras.
Decline and extinction.
As it was easy to find and kill, the quagga was hunted by early Dutch settlers and later by Afrikaners to provide meat or for their skins. The skins were traded or used locally. The quagga was probably vulnerable to extinction due to its limited distribution, and it may have competed with domestic livestock for forage. The quagga had disappeared from much of its range by the 1850s. The last population in the wild, in the Orange Free State, was extirpated in the late 1870s. The last known wild individual died in 1878.
Individual quaggas were also captured and shipped to Europe, where they were displayed in zoos. Lord Morton tried to save the animal from extinction by starting a captive breeding program. He was only able to obtain a single male which, in desperation, he bred with a female horse. This produced a female hybrid with zebra stripes on its back and legs. Lord Morton's mare was sold and was subsequently bred with a black stallion, resulting in offspring that again had zebra stripes. An account of this was published in 1820 by the Royal Society. This led to new ideas on telegony, referred to as "pan-genesis" by Charles Darwin.
The last captive specimen, a female in Amsterdam's Natura Artis Magistra zoo, lived there from 9 May 1867 until it died on 12 August 1883, but its origin and cause of death were not recorded. The specimen in London died in 1872 and the one in Berlin in 1875. There are 23 known stuffed and mounted quagga specimens throughout the world. In addition, there is a mounted head and neck, a foot, seven complete skeletons, and samples of various tissues. A twenty-fourth mounted specimen was destroyed in Königsberg, Germany, during World War II.
Breeding back project.
After the very close relationship between the quagga and surviving zebras was discovered, Reinhold Rau started the Quagga Project in 1987 in South Africa to recreate the quagga by selective breeding from plains zebra stock, with the eventual aim of reintroducing them to the wild. To differentiate between the previously existing quagga zebras and the ones bred back into the environment, it has been suggested the new population should be referred to as "Rau quaggas". The founding population consisted of 19 individuals from Namibia and South Africa, chosen because they had reduced striping on the rear body and legs. The first foal of the project was born in 1988. Once a sufficiently quagga-like population has been created, it will be released in the Western Cape.
Introduction of Rau's quaggas could be part of a comprehensive restoration program including such ongoing efforts as eradication of non-native trees. Quaggas, wildebeest, and ostriches, which occurred together during historical times in a mutually beneficial association, could be kept together in areas where the indigenous vegetation has to be maintained by grazing. In early 2006, the third and fourth generation animals produced by the project were reported to look very much like the depictions and preserved specimens of the quagga. This type of selective breeding is called "breeding back". The practice is controversial, since the resulting zebras will resemble the quaggas only in external appearance, but will be genetically different. The technology to use recovered DNA for cloning does not exist.

</doc>
<doc id="25231" url="http://en.wikipedia.org/wiki?curid=25231" title="QuickTime">
QuickTime

QuickTime is an extensible multimedia framework developed by Apple Inc., capable of handling various formats of digital video, picture, sound, panoramic images, and interactivity. The classic version of QuickTime is available for Windows XP and later, as well as Mac OS X Leopard and later operating systems. A more recent version, QuickTime X, is currently available on Mac OS X Snow Leopard and newer.
As of the Mac OS X Lion, the underlying media framework for Quicktime, QTKit, is deprecated in favor of a newer graphics framework, AV Foundation. The Quicktime X player however is still included with the new releases of the OS.
Overview.
QuickTime is bundled with OS X. QuickTime for Microsoft Windows has always been downloadable as a standalone installation, as well as being bundled with Apple's iTunes (prior to iTunes 10.5).
Software development kits (SDKs) for QuickTime are available to the public with an Apple Developer Connection (ADC) subscription.
It is available free of charge for both OS X and Windows operating systems. There are some other free player applications that rely on the QuickTime framework, providing features not available in the basic QuickTime Player. For example, iTunes can export audio in WAV, AIFF, MP3, AAC, and Apple Lossless. In addition, OS X has a simple AppleScript which can be used to play a movie in full-screen mode., but since version 7.2 full-screen viewing is now supported in the non-pro version.
QuickTime Pro.
QuickTime Player 7 is limited to only basic playback operations unless a QuickTime Pro license key is purchased from Apple. Until recently, Apple's professional applications (e.g. Final Cut Studio, Logic Studio) included a QuickTime Pro license. Pro keys are specific to the major version of QuickTime for which they are purchased and unlock additional features of the QuickTime Player application on OS X or Windows. The Pro key does not require any additional downloads; entering the registration code immediately unlocks the hidden features.
Features enabled by the Pro license include, but are not limited to:
Mac OS X Snow Leopard includes QuickTime X. QuickTime Player X lacks cut, copy and paste and will only export to four formats, but its limited export feature is free. Users do not have an option to upgrade to a pro version of QuickTime X, but those who have already purchased QuickTime 7 Pro and are upgrading to Snow Leopard from a previous version of OS X will have QuickTime 7 stored in the Utilities or user defined folder. Otherwise, users will have to install QuickTime 7 from the "Optional Installs" directory of the Snow Leopard DVD after installing the OS.
Mac OS X Lion and OS X Mountain Lion also include QuickTime X. No installer for QuickTime 7 is included with these software packages, but users can download the QuickTime 7 installer from the site.
QuickTime framework.
The QuickTime framework provides the following:
As of early 2008, the framework hides many older codecs listed below from the user although the option to "Show legacy encoders" exists in QuickTime Preferences to use them. The framework supports the following file types and codecs natively:
PictureViewer.
PictureViewer is a component of QuickTime for Microsoft Windows and the Mac OS 8 and Mac OS 9 operating systems. It is used to view picture files from the still image formats that QuickTime supports. In OS X, it is replaced by Preview.
File formats.
The native file format for QuickTime video, QuickTime File Format, specifies a multimedia container file that contains one or more tracks, each of which stores a particular type of data: audio, video, effects, or text (e.g. for subtitles). Each track either contains a digitally encoded media stream (using a specific format) or a data reference to the media stream located in another file. The ability to contain abstract data references for the media data, and the separation of the media data from the media offsets and the track edit lists means that QuickTime is particularly suited for editing, as it is capable of importing and editing in place (without data copying).
Other file formats that QuickTime supports natively (to varying degrees) include AIFF, WAV, DV-DIF, MP3, and MPEG program stream. With additional QuickTime Components, it can also support ASF, DivX Media Format, Flash Video, Matroska, Ogg, and many others.
QuickTime and MPEG-4.
On February 11, 1998, the ISO approved the QuickTime file format as the basis of the MPEG-4 file format. The MPEG-4 file format specification was created on the basis of the QuickTime format specification published in 2001. The MP4 (.mp4) file format was published in 2001 as the revision of the MPEG-4 Part 1: Systems specification published in 1999 (ISO/IEC 14496-1:2001). In 2003, the first version of MP4 format was revised and replaced by MPEG-4 Part 14: MP4 file format (ISO/IEC 14496-14:2003). The MP4 file format was generalized into the ISO Base Media File Format ISO/IEC 14496-12:2004, which defines a general structure for time-based media files. It in turn is used as the basis for other multimedia file formats (for example 3GP, Motion JPEG 2000). A list of all registered extensions for ISO Base Media File Format is published on the official registration authority website . This registration authority for code-points in "MP4 Family" files is Apple Computer Inc. and it is named in Annex D (informative) in MPEG-4 Part 12.
By 2000, MPEG-4 formats became industry standards, first appearing with support in QuickTime 6 in 2002. Accordingly, the MPEG-4 container is designed to capture, edit, archive, and distribute media, unlike the simple file-as-stream approach of MPEG-1 and MPEG-2.
Profile support.
QuickTime 6 added limited support for MPEG-4; specifically encoding and decoding using Simple Profile (SP). Advanced Simple Profile (ASP) features, like B-frames, were unsupported (in contrast with, for example, encoders such as XviD or 3ivx). QuickTime 7 supports the H.264 encoder and decoder.
Container benefits.
Because both MOV and MP4 containers can use the same MPEG-4 codecs, they are mostly interchangeable in a QuickTime-only environment. MP4, being an international standard, has more support. This is especially true on hardware devices, such as the Sony PSP and various DVD players; on the software side, most DirectShow / Video for Windows codec packs include an MP4 parser, but not one for MOV.
In QuickTime Pro's MPEG-4 Export dialog, an option called "Passthrough" allows a clean export to MP4 without affecting the audio or video streams. QuickTime 7 now supports multi-channel AAC-LC and HE-AAC audio (used, for example, in the high-definition trailers on Apple's site), for both .MOV and .MP4 containers.
History.
Apple released the first version of QuickTime on December 2, 1991 as a multimedia add-on for System Software 6 and later. The lead developer of QuickTime, Bruce Leak, ran the first public demonstration at the May 1991 Worldwide Developers Conference, where he played Apple's famous 1984 TV commercial in a window at 320x240 pixel resolution. Microsoft's competing technology, Video for Windows did not appear until November 1992.
QuickTime 1.x.
The original video codecs included:
The first commercial project produced using QuickTime 1.0 was the CD-ROM . The first publicly visible use of QuickTime was Ben & Jerry's interactive factory tour (dubbed "The Rik & Joe Show" after its in-house developers). "The Rik and Joe Show" was demonstrated onstage at MacWorld in San Francisco when John Sculley announced QuickTime.
Apple released QuickTime 1.5 for Mac OS in the latter part of 1992. This added the SuperMac-developed Cinepak vector-quantization video codec (initially known as Compact Video). It could play video at 320×240 resolution at 30 frames per second on a 25 MHz Motorola 68040 CPU. It also added "text" tracks, which allowed for captioning, lyrics and other potential uses.
Apple contracted San Francisco Canyon Company to port QuickTime to the Windows platform. Version 1.0 of QuickTime for Windows provided only a subset of the full QuickTime API, including only movie playback functions driven through the standard movie controller.
QuickTime 1.6 came out the following year. Version 1.6.2 first incorporated the "QuickTime PowerPlug" which replaced some components with PowerPC-native code when running on PowerPC Macs.
QuickTime 2.x.
Apple released QuickTime 2.0 for System Software 7 in February 1994—the only version never released for free. It added support for music tracks, which contained the equivalent of MIDI data and which could drive a sound-synthesis engine built into QuickTime itself (using a limited set of instrument sounds licensed from Roland), or any external MIDI-compatible hardware, thereby producing sounds using only small amounts of movie data.
Following Bruce Leak's departure to Web TV, the leadership of the QuickTime team was taken over by Peter Hoddie.
QuickTime 2.0 for Windows appeared in November 1994 under the leadership of Paul Charlton. As part of the development effort for cross-platform QuickTime, Charlton (as architect and technical lead), along with ace individual contributor Michael Kellner and a small highly effective team including Keith Gurganus, ported a subset of the Macintosh Toolbox to Intel and other platforms (notably, MIPS and SGI Unix variants) as the enabling infrastructure for the QuickTime Media Layer (QTML) which was first demonstrated at the Apple Worldwide Developers Conference (WWDC) in May 1996. The QTML later became the foundation for the Carbon API which allowed legacy Macintosh applications to run on the Darwin kernel in Mac OS X.
The next versions, 2.1 and 2.5, reverted to the previous model of giving QuickTime away for free. They improved the music support and added sprite tracks which allowed the creation of complex animations with the addition of little more than the static sprite images to the size of the movie. QuickTime 2.5 also fully integrated QuickTime VR 2.0.1 into QuickTime as a QuickTime extension. On January 16, 1997, Apple released the QuickTime MPEG Extension (PPC only) as an add-on to QuickTime 2.5, which added software MPEG-1 playback capabilities to QuickTime.
QuickTime 3.x.
The release of QuickTime 3.0 for Mac OS on March 30, 1998 introduced the now-standard revenue model of releasing the software for free, but with additional features of the Apple-provided MoviePlayer application that end-users could only unlock by buying a QuickTime Pro license code. Since the "Pro" features were the same as the existing features in QuickTime 2.5, any previous user of QuickTime could continue to use an older version of the central MoviePlayer application for the remaining lifespan of Mac OS to 2002; indeed, since these additional features were limited to MoviePlayer, any other QuickTime-compatible application remained unaffected.
QuickTime 3.0 added support for graphics importer components that could read images from GIF, JPEG, TIFF and other file formats, and video output components which served primarily to export movie data via FireWire. Apple also licensed several third-party technologies for inclusion in QuickTime 3.0, including the Sorenson Video codec for advanced video compression, the QDesign Music codec for substantial audio compression, and the complete Roland Sound Canvas instrument set and GS Format extensions for improved playback of MIDI music files. It also added video "effects" which programmers could apply in real-time to video tracks. Some of these effects would even respond to mouse clicks by the user, as part of the new movie interaction support (known as wired movies).
QuickTime interactive.
During the development cycle for QuickTime 3.0, part of the engineering team was working on a more advanced version of QuickTime to be known as QuickTime interactive or QTi. Although similar in concept to the wired movies feature released as part of QuickTime 3.0, QuickTime interactive was much more ambitious. It allowed any QuickTime movie to be a fully interactive and programmable container for media. A special track type was added that contained an interpreter for a custom programming language based on 68000 assembly language. This supported a comprehensive user interaction model for mouse and keyboard event handling based in part on the AML language from the Apple Media Tool.
The QuickTime interactive movie was to have been the playback format for the next generation of HyperCard authoring tool. Both the QuickTime interactive and the HyperCard 3.0 projects were canceled in order to concentrate engineering resources on streaming support for QuickTime 4.0, and the projects were never released to the public.
QuickTime 4.x.
Apple released QuickTime 4.0 on June 8, 1999 for Mac OS 7.5.5 through 8.6 (later Mac OS 9) and Windows 95, Windows 98, and Windows NT. Three minor updates (versions 4.0.1, 4.0.2, and 4.0.3) followed.
It introduced features that most users now consider basic:
On December 17, 1999, Apple provided QuickTime 4.1, this version's first major update. Two minor versions (4.1.1 and 4.1.2) followed. The most notable improvements in the 4.1.x family were:
QuickTime 5.x.
QuickTime 5 was one of the shortest-lived versions of QuickTime, released in April 2001 and superseded by QuickTime 6 a little over a year later. This version was the last to have greater capabilities under Mac OS 9 than under Mac OS X, and the last version of QuickTime to support Mac OS versions 7.5.5 through 8.5.1 on a PowerPC Mac and Windows 95. Version 5.0 was initially only released for Mac OS and Mac OS X on April 14, 2001, and version 5.0.1 followed shortly thereafter on April 23, 2001, supporting Mac OS, Mac OS X, and Windows. Three more updates to QuickTime 5 (versions 5.0.2, 5.0.4, and 5.0.5) were released over its short lifespan.
QuickTime 5 delivered the following enhancements:
QuickTime 6.x.
On July 15, 2002, Apple released QuickTime 6.0, providing the following features:
QuickTime 6 was initially available for Mac OS 8.6 – 9.x, Mac OS X (10.1.5 minimum), and Windows 98, Me, 2000, and XP. Development of QuickTime 6 for Mac OS slowed considerably in early 2003, after the release of Mac OS X v10.2 in August 2002. QuickTime 6 for Mac OS continued on the 6.0.x path, eventually stopping with version 6.0.3.
QuickTime 6.1 & 6.1.1 for Mac OS X v10.1 and Mac OS X v10.2 (released October 22, 2002) and QuickTime 6.1 for Windows (released March 31, 2003) offered ISO-Compliant MPEG-4 file creation and fixed the vulnerability.
Apple released QuickTime 6.2 exclusively for Mac OS X on April 29, 2003 to provide support for iTunes 4, which allowed AAC encoding for songs in the iTunes library. (iTunes was not available for Windows until October 2003.)
On June 3, 2003, Apple released QuickTime 6.3, delivering the following:
QuickTime 6.4, released on October 16, 2003 for Mac OS X v10.2, Mac OS X v10.3, and Windows, added the following:
On December 18, 2003, Apple released QuickTime 6.5, supporting the same systems as version 6.4. Versions 6.5.1 and 6.5.2 followed on April 28, 2004 and October 27, 2004. These versions would be the last to support Windows 98 and Me. The 6.5 family added the following features:
QuickTime 6.5.3 was released on October 12, 2005 for Mac OS X v10.2.8 after the release of QuickTime 7.0, fixing a number of security issues.
QuickTime 7.x.
Initially released on April 29, 2005 in conjunction with Mac OS X v10.4 (for version 10.3.9 and 10.4.x), QuickTime 7.0 featured the following:
After a couple of preview Windows releases, Apple released 7.0.2 as the first stable release on September 7, 2005 for Windows 2000 and Windows XP. Version 7.0.4, released on January 10, 2006 was the first universal binary version. But it suffered numerous bugs, including a buffer overrun, which is more problematic to most users.
Apple dropped support for Windows 2000 with the release of QuickTime 7.2 on July 11, 2007. The last version available for Windows 2000, 7.1.6, contains numerous security vulnerabilities. References to this version have been removed from the QuickTime site, but it can be downloaded from Apple's support section. Apple has not indicated that they will be providing any further security updates for older versions. QuickTime 7.2 is the first version for Windows Vista.
Apple dropped support for Flash content in QuickTime 7.3, breaking content that relied on Flash for interactivity, or animation tracks. Security concerns seem to be part of the decision. Flash flv files can still be played in QuickTime if the free Perian plugin is added.
In QuickTime 7.3, a processor that supports SSE is required. QuickTime 7.4 does not require SSE. Unlike versions 7.2 and 7.3, QuickTime 7.4 cannot be installed on Windows XP SP1 system (its setup program checks if Service Pack 2 is installed).
QuickTime 7.5 was released on June 10, 2008. QuickTime 7.5.5 was released on September 9, 2008, which requires Mac OS X v10.4 or higher, dropping 10.3 support. QuickTime 7.6 was released on January 21, 2009. QuickTime 7.7 was released on August 23, 2011. 
QuickTime X (QuickTime Player v10.x).
QuickTime X (pronounced "QuickTime Ten") was initially demonstrated at WWDC on June 8, 2009, and shipped with Mac OS X v10.6.
It includes visual chapters, conversion, sharing to YouTube, video editing, capture of video and audio streams, screen recording, GPU acceleration, and live streaming.
But it removed support for various widely used formats; in particular the omission of MIDI caused significant inconvenience and trouble to many musicians and their potential audiences.
In addition, a screen recorder is featured which records whatever is on the screen. However, to prevent bootlegging the user is unable to record any video that is played on the DVD Player or purchased content from iTunes, thus being greyed out.
The reason for the jump in numbering from 7 to 10 (X) was to indicate a similar break with the previous versions of the product that Mac OS X indicated. QuickTime X is fundamentally different from previous versions, in that it is provided as a Cocoa (Objective-C) framework and breaks compatibility with the previous QuickTime 7 C-based APIs that were previously used. QuickTime X was completely rewritten to implement modern audio video codecs in 64-bit. QuickTime X is a combination of two technologies: QuickTime Kit Framework (QTKit) and QuickTime X Player. QTKit is used by QuickTime player to display media. QuickTime X does not implement all of the functionality of the previous QuickTime as well as some of the codecs. When QuickTime X attempts to operate with a 32-bit codec or perform an operation not supported by QuickTime X, it will start a 32-bit helper process to perform the requested operation. The website "Ars Technica" revealed that QuickTime X uses QuickTime 7.x via QTKit to run older codecs that have not made the transition to 64-bit.
QuickTime 7 may still be required to support older formats on Snow Leopard such as QTVR, interactive QuickTime movies, and MIDI files. In such cases, a compatible version of QuickTime 7 is included on Snow Leopard installation disc and may be installed side-by-side with QuickTime X. Users who have a Pro license for QuickTime 7 can then activate their license.
A Snow Leopard-compatible version of QuickTime 7 may also be downloaded from Apple Support website.
The software got an increment with the release of Mavericks, and as of June 2014, the current version is v10.3. It contains more sharing options (email, YouTube, Facebook, Flickr etc.), more export options (including web export in multiple sizes, and export for iPhone 4/iPad/Apple TV (but not Apple TV 2)). It also includes a new way of fast forwarding through a video, magic mouse support for scrolling.
Creating software that uses QuickTime.
QuickTime X.
QuickTime X provides the QTKit Framework on Mac OS 10.6 and greater.
Previous versions.
QuickTime consists of two major subsystems: the Movie Toolbox and the Image Compression Manager. The Movie Toolbox consists of a general API for handling time-based data, while the Image Compression Manager provides services for dealing with compressed raster data as produced by video and photo codecs.
Developers can use the QuickTime software development kit (SDK) to develop multimedia applications for Mac or Windows with the C programming language or with the Java programming language (see QuickTime for Java), or, under Windows, using COM/ActiveX from a language supporting this.
The COM/ActiveX option was introduced as part of QuickTime 7 for Windows and is intended for programmers who want to build standalone Windows applications using high-level QuickTime movie playback and control with some import, export, and editing capabilities. This is considerably easier than mastering the original QuickTime C API.
QuickTime 7 for Mac introduced the QuickTime Kit (aka QTKit), a developer framework that is intended to replace previous APIs for Cocoa developers. This framework is for Mac only, and exists as Objective-C abstractions around a subset of the C interface. Mac OS X v10.5 extends QTKit to full 64-bit support. The QTKit allows multiplexing between QuickTime X and QuickTime 7 behind the scenes so that the user need not worry about which version of QuickTime they need to use.
Bugs and vulnerabilities.
QuickTime 7.4 was found to disable Adobe's video compositing program, After Effects. This was due to the DRM built into version 7.4 since it allowed movie rentals from iTunes. QuickTime 7.4.1 resolved this issue.
Versions 4.0 through 7.3 contained a buffer overflow bug which could compromise the security of a PC using either the QuickTime Streaming Media client, or the QuickTime player itself. The bug was fixed in version 7.3.1.
QuickTime 7.5.5 and earlier are known to have a list of significant vulnerabilities that allow a remote attacker to execute arbitrary code or cause a denial of service (out-of-bounds memory access and application crash) on a targeted system. The list includes six types of buffer overflow, data conversion, signed vs unsigned integer mismatch, and unititialized memory pointer
QuickTime 7.6 has been found to disable Macintosh users' ability to play certain games, such as "Civilization IV" and "The Sims 2". There are fixes available from the publisher, Aspyr.
QuickTime 7 lacks support for H.264 Sample Aspect Ratio . QuickTime X does not have this limitation, but many Apple products (such as iTunes and Apple TV) still use the older QuickTime 7 engine.
Quicktime 7.7.x Windows fails to encode H.264 on Dual CPU systems with more than ~20 threads, e.g. HP Z820 with 2x 8-core CPUs. Suggested 'solution': Disable hyper-threading/limit CPU cores. Encoding speed and stability depends on scaling of player window

</doc>
<doc id="25232" url="http://en.wikipedia.org/wiki?curid=25232" title="Quoin (disambiguation)">
Quoin (disambiguation)

Quoin or Du Quoin may refer to:

</doc>
<doc id="25233" url="http://en.wikipedia.org/wiki?curid=25233" title="Quartz">
Quartz

Quartz is the second most abundant mineral in the Earth's continental crust, after feldspar. It is made up of a continuous framework of SiO4 silicon–oxygen tetrahedra, with each oxygen being shared between two tetrahedra, giving an overall formula SiO2.
There are many different varieties of quartz, several of which are semi-precious gemstones. Especially in Europe and the Middle East, varieties of quartz have been since antiquity the most commonly used minerals in the making of jewelry and hardstone carvings.
Etymology.
The word "quartz" is derived from the German word "Quarz" and its Middle High German ancestor "twarc", which probably originated in Slavic (cf. Czech "tvrdý" ("hard"), Polish "twardy" ("hard").
Crystal habit and structure.
Quartz belongs to the trigonal crystal system. The ideal crystal shape is a six-sided prism terminating with six-sided pyramids at each end. In nature quartz crystals are often twinned, distorted, or so intergrown with adjacent crystals of quartz or other minerals as to only show part of this shape, or to lack obvious crystal faces altogether and appear massive. Well-formed crystals typically form in a 'bed' that has unconstrained growth into a void; usually the crystals are attached at the other end to a matrix and only one termination pyramid is present. However doubly-terminated crystals do occur where they develop freely without attachment, for instance within gypsum. A quartz geode is such a situation where the void is approximately spherical in shape, lined with a bed of crystals pointing inward.
α-quartz crystallizes in the trigonal crystal system, space group "P"3121 and "P"3221 respectively. β-quartz belongs to the hexagonal system, space group "P"6222 and "P"6422, respectively. These space groups are truly chiral (they each belong to the 11 enantiomorphous pairs). Both α-quartz and β-quartz are examples of chiral crystal structures composed of achiral building blocks (SiO4 tetrahedra in the present case). The transformation between α- and β-quartz only involves a comparatively minor rotation of the tetrahedra with respect to one another, without change in the way they are linked.
Varieties (according to color).
Pure quartz, traditionally called rock crystal (sometimes called clear quartz), is colorless and transparent (clear) or translucent, and has often been used for hardstone carvings, such as the Lothair Crystal. Common colored varieties include citrine, rose quartz, amethyst, smoky quartz, milky quartz, and others. Quartz goes by an array of different names. The most important distinction between types of quartz is that of "macrocrystalline" (individual crystals visible to the unaided eye) and the microcrystalline or cryptocrystalline varieties (aggregates of crystals visible only under high magnification). The cryptocrystalline varieties are either translucent or mostly opaque, while the transparent varieties tend to be macrocrystalline. Chalcedony is a cryptocrystalline form of silica consisting of fine intergrowths of both quartz, and its monoclinic polymorph moganite. Other opaque gemstone varieties of quartz, or mixed rocks including quartz, often including contrasting bands or patterns of color, are agate, sard, onyx, carnelian, heliotrope, and jasper.
Citrine.
Citrine is a variety of quartz whose color ranges from a pale yellow to brown due to ferric impurities. Natural citrines are rare; most commercial citrines are heat-treated amethysts or smoky quartzes. However, a heat-treated amethyst will have small lines in the crystal, as opposed to a natural citrine's cloudy or smokey appearance. It is nearly impossible to tell cut citrine from yellow topaz visually, but they differ in hardness. Brazil is the leading producer of citrine, with much of its production coming from the state of Rio Grande do Sul. The name is derived from Latin citrina which means "yellow" and is also the origin of the word "citron." Sometimes citrine and amethyst can be found together in the same crystal, which is then referred to as ametrine.
Rose quartz.
Rose quartz is a type of quartz which exhibits a pale pink to rose red hue. The color is usually considered as due to trace amounts of titanium, iron, or manganese, in the massive material. Some rose quartz contains microscopic rutile needles which produces an asterism in transmitted light. Recent X-ray diffraction studies suggest that the color is due to thin microscopic fibers of possibly dumortierite within the massive quartz.
Additionally, there is a rare type of pink quartz (also frequently called crystalline rose quartz) with color that is thought to be caused by trace amounts of phosphate or aluminium. The color in crystals is apparently photosensitive and subject to fading. The first crystals were found in a pegmatite found near Rumford, Maine, USA, but most crystals on the market come from Minas Gerais, Brazil.
Amethyst.
Amethyst is a popular form of quartz that ranges from a bright to dark or dull purple color. The world's largest deposits of amethysts can be found in Brazil, Mexico, Uruguay, Russia, France, Namibia and Morocco. Sometimes amethyst and citrine are found growing in the same crystal. It is then referred to as ametrine. An amethyst is formed when there is iron in the area where it was formed.
Smoky quartz.
Smoky quartz is a gray, translucent version of quartz. It ranges in clarity from almost complete transparency to a brownish-gray crystal that is almost opaque.
Some can also be black.
Milky quartz.
Milk quartz or milky quartz may be the most common variety of crystalline quartz and can be found almost anywhere. The white color may be caused by minute fluid inclusions of gas, liquid, or both, trapped during the crystal formation. The cloudiness caused by the inclusions effectively bars its use in most optical and quality gemstone applications.
Varieties (according to microstructure).
Although many of the varietal names historically arose from the color of the mineral, current scientific naming schemes refer primarily to the microstructure of the mineral. Color is a secondary identifier for the cryptocrystalline minerals, although it is a primary identifier for the macrocrystalline varieties. This does not always hold true.
Synthetic and artificial treatments.
Not all varieties of quartz are naturally occurring. Some clear quartz crystals can be treated using heat or gamma-irradiation to induce color where it would not otherwise have occurred naturally. Susceptibility to such treatments depends on the location from which the quartz was mined. Prasiolite, an olive colored material, is produced by heat treatment; natural prasiolite has also been observed in Lower Silesia in Poland. Although citrine occurs naturally, the majority is the result of heat-treated amethyst. Carnelian is widely heat-treated to deepen its color.
Because natural quartz is often twinned, synthetic quartz is produced for use in industry. Large, flawless, single crystals are synthesized in an autoclave via the hydrothermal process; emeralds are also synthesized in this fashion.
Occurrence.
Quartz is an essential constituent of granite and other felsic igneous rocks. It is very common in sedimentary rocks such as sandstone and shale and is also present in variable amounts as an accessory mineral in most carbonate rocks. It is also a common constituent of schist, gneiss, quartzite and other metamorphic rocks. Because of its resistance to weathering it is very common in stream sediments and in residual soils. Quartz, therefore, occupies the lowest potential to weather in the Goldich dissolution series.
While the majority of quartz crystallizes from molten magma, much quartz also chemically precipitates from hot hydrothermal veins as gangue, sometimes with ore minerals like gold, silver and copper. Large crystals of quartz are found in magmatic pegmatites. Well-formed crystals may reach several meters in length and weigh hundreds of kilograms.
Naturally occurring quartz crystals of extremely high purity, necessary for the crucibles and other equipment used for growing silicon wafers in the semiconductor industry, are expensive and rare. A major mining location for high purity quartz is the Spruce Pine Gem Mine in Spruce Pine, North Carolina, United States.
The largest documented single crystal of quartz was found near Itapore, Goiaz, Brazil; it measured approximately 6.1×1.5×1.5 m and weighed more than 44 tonnes.
Related silica minerals.
Tridymite and cristobalite are high-temperature polymorphs of SiO2 that occur in high-silica volcanic rocks. Coesite is a denser polymorph of quartz found in some meteorite impact sites and in metamorphic rocks formed at pressures greater than those typical of the Earth's crust. Stishovite is a yet denser and higher-pressure polymorph of quartz found in some meteorite impact sites. Lechatelierite is an amorphous silica glass SiO2 which is formed by lightning strikes in quartz sand.
History.
The word "quartz" comes from the German   , which is of Slavic origin (Czech miners called it "křemen"). Other sources attribute the word's origin to the Saxon word "Querkluftertz", meaning "cross-vein ore".
Quartz is the most common material identified as the mystical substance maban in Australian Aboriginal mythology. It is found regularly in passage tomb cemeteries in Europe in a burial context, such as Newgrange or Carrowmore in Ireland. The Irish word for quartz is "grian cloch", which means 'stone of the sun'. Quartz was also used in Prehistoric Ireland, as well as many other countries, for stone tools; both vein quartz and rock crystal were knapped as part of the lithic technology of the prehistoric peoples.
While jade has been since earliest times the most prized semi-precious stone for carving in East Asia and Pre-Columbian America, in Europe and the Middle East the different varieties of quartz were the most commonly used for the various types of jewelry and hardstone carving, including engraved gems and cameo gems, rock crystal vases, and extravagant vessels. The tradition continued to produce objects that were very highly valued until the mid-19th century, when it largely fell from fashion except in jewelry. Cameo technique exploits the bands of color in onyx and other varieties.
Roman naturalist Pliny the Elder believed quartz to be water ice, permanently frozen after great lengths of time. (The word "crystal" comes from the Greek word "κρύσταλλος", "ice".) He supported this idea by saying that quartz is found near glaciers in the Alps, but not on volcanic mountains, and that large quartz crystals were fashioned into spheres to cool the hands. He also knew of the ability of quartz to split light into a spectrum. This idea persisted until at least the 17th century.
In the 17th century, Nicolas Steno's study of quartz paved the way for modern crystallography. He discovered that regardless of a quartz crystal's size or shape, its long prism faces always joined at a perfect 60° angle.
Quartz's piezoelectric properties were discovered by Jacques and Pierre Curie in 1880. The quartz oscillator or resonator was first developed by Walter Guyton Cady in 1921. George Washington Pierce designed and patented quartz crystal oscillators in 1923. Warren Marrison created the first quartz oscillator clock based on the work of Cady and Pierce in 1927.
Efforts to synthesize quartz began in the mid nineteenth century as scientists attempted to create minerals under laboratory conditions that mimicked the conditions in which the minerals formed in nature: German geologist Karl Emil von Schafhäutl (1803-1890) was the first person to synthesize quartz when in 1845 he created microscopic quartz crystals in a pressure cooker. However, the quality and size of the crystals that were produced by these early efforts were poor. By the 1930s, the electronics industry had become dependent on quartz crystals. The only source of suitable crystals was Brazil; however, World War II disrupted the supplies from Brazil, so nations attempted to synthesize quartz on a commercial scale. German mineralogist Richard Nacken (1884-1971) achieved some success during the 1930s and 1940s. After the war, many laboratories attempted to grow large quartz crystals. In the United States, the U.S. Army Signal Corps contracted with Bell Laboratories and with the Brush Development Company of Cleveland, Ohio to synthesize crystals following Nacken's lead. (Prior to World War II, Brush Development produced piezoelectric crystals for record players.) By 1948, Brush Development had grown crystals that were 1.5 inches (3.8 cm) in diameter, the largest to date. By the 1950s, hydrothermal synthesis techniques were producing synthetic quartz crystals on an industrial scale, and today virtually all the quartz crystal used in the modern electronic industry is synthetic.
Piezoelectricity.
Quartz crystals have piezoelectric properties; they develop an electric potential upon the application of mechanical stress. An early use of this property of quartz crystals was in phonograph pickups. One of the most common piezoelectric uses of quartz today is as a crystal oscillator. The quartz clock is a familiar device using the mineral. The resonant frequency of a quartz crystal oscillator is changed by mechanically loading it, and this principle is used for very accurate measurements of very small mass changes in the quartz crystal microbalance and in thin-film thickness monitors.
Gallery of quartz mineral specimens.
<br>

</doc>
<doc id="25234" url="http://en.wikipedia.org/wiki?curid=25234" title="Quadrivium">
Quadrivium

The quadrivium (plural: quadrivia) are the four subjects, or arts, taught after teaching the trivium. The word is Latin, meaning "the four ways" (or a "place where four roads meet"), and its use for the four subjects has been attributed to Boethius or Cassiodorus in the 6th century. Together, the trivium and the quadrivium comprised the seven liberal arts (based on thinking skills), as opposed to the practical arts (such as medicine and architecture).
The quadrivium consisted of arithmetic, geometry, music, and astronomy. These followed the preparatory work of the trivium made up of grammar, logic, and rhetoric. In turn, the quadrivium was considered preparatory work for the serious study of philosophy (sometimes called the "liberal art "par excellence"") and theology.
Origins.
These four studies compose the secondary part of the curriculum outlined by Plato in "The Republic", and are described in the seventh book of that work (in the order Arithmetic, Geometry, Astronomy, Music.) 
The quadrivium is implicit in early Pythagorean writings and in the "De nuptiis" of Martianus Capella, although the term "quadrivium" was not used until Boethius early in the sixth century. As Proclus wrote:
The Pythagoreans considered all mathematical science to be divided into four parts: one half they marked off as concerned with quantity, the other half with magnitude; and each of these they posited as twofold. A quantity can be considered in regard to its character by itself or in its relation to another quantity, magnitudes as either stationary or in motion. Arithmetic, then, studies quantities as such, music the relations between quantities, geometry magnitude at rest, spherics [astronomy] magnitude inherently moving.
Medieval usage.
At many medieval universities, this would have been the course leading to the degree of Master of Arts (after the BA). After the MA, the student could enter for Bachelor's degrees of the higher faculties (Theology, Medicine or Law). To this day, some of the postgraduate degree courses lead to the degree of Bachelor (the B.Phil and B.Litt. degrees are examples in the field of philosophy).
The study was eclectic, approaching the philosophical objectives sought by considering it from each aspect of the quadrivium within the general structure demonstrated by Proclus (412–485 AD), namely arithmetic and music on the one hand, and geometry and cosmology on the other.
The subject of music within the quadrivium was originally the classical subject of harmonics, in particular the study of the proportions between the music intervals created by the division of a monochord. A relationship to music as actually practised was not part of this study, but the framework of classical harmonics would substantially influence the content and structure of music theory as practised both in European and Islamic cultures.
Modern usage.
In modern applications of the liberal arts as curriculum in colleges or universities, the quadrivium may be considered to be the study of number and its relationship to physical space or time: arithmetic was pure number, geometry was number in space, music number in time, and astronomy number in space and time. Morris Kline classifies the four elements of the quadrivium as pure (arithmetic), stationary (geometry), moving (astronomy) and applied (music) number.
This schema is sometimes referred to as "classical education" but it is more accurately a development of the 12th and 13th centuries with recovered classical elements, rather than an organic growth from the educational systems of antiquity. The term continues to be used by the classical education movement.

</doc>
<doc id="25236" url="http://en.wikipedia.org/wiki?curid=25236" title="Quadrupedalism">
Quadrupedalism

Quadrupedalism or pronograde posture is a form of terrestrial locomotion in animals using four limbs or legs. An animal or machine that usually moves in a quadrupedal manner is known as a quadruped, meaning "four feet" (from the Latin "quad" for "four" and "ped" for "foot"). The majority of quadrupeds are vertebrate animals, including mammals such as cattle, dogs and cats, and reptiles, like lizards.
Birds, humans, insects, crustaceans, and snakes are usually not quadrupeds, with some exceptions; for example, among the insects, the praying mantis is a quadruped. A few birds may use quadrupedal movement in some circumstances; for example, the shoebill will sometimes use its wings to right itself after lunging at prey.
Quadrupeds vs. tetrapods.
Although the words "quadruped" and "tetrapod" are both derived from terms meaning "four-footed", they have distinct meanings. A tetrapod is any member of the taxonomic unit "Tetrapoda" (which is defined by descent from a specific four-limbed ancestor) whereas a quadruped actually uses four limbs for locomotion. Not all tetrapods are quadrupeds and not all quadrupeds are tetrapods.
The distinction between quadrupeds and tetrapods is important in evolutionary biology, particularly in the context of tetrapods whose limbs have adapted to other roles (e.g. hands in the case of humans, wings in the case of birds, and fins in the case of whales). All of these animals are tetrapods, but none is a quadruped. Even snakes, whose limbs have become vestigial or lost entirely, are nevertheless tetrapods.
Most quadrupedal animals are tetrapods but there are a few exceptions. For example, among the insects, the praying mantis is a quadruped.
In humans.
In July 2005, in rural Turkey, scientists discovered five Kurdish siblings who had learned to walk naturally on their hands and feet. Unlike chimpanzees, who ambulate on their knuckles, the Turkish siblings (ranging from 18 to 34 years old) walked on their palms, allowing them to preserve the dexterity of their fingers. Another similar case has been reported in Chile, but the case is still being investigated and reports are not released as of March 2006.
The discovery of the family has provided scientists a unique view into human evolutionary history. Nicholas Humphrey and John Skoyles from the London School of Economics and Roger Keynes from Cambridge University have suggested that their gait is due to two rare phenomena coming together. First, instead of initially crawling as infants on their knees, they started off learning to move around with a "bear crawl" on their feet. Second, due to their congenital brain impairment, they found balancing on two legs difficult. Because of this, their motor development was channelled into turning their bear crawl into a substitute for bipedality.
Other scientists, such as Stefan Mundlos of the Max Planck Institute, believe that the family's unusual gait may result from a genetic abnormality. Mundlos has found a region on chromosome 17 that might be responsible for human bipedalism.
Quadrupedal movement for exercise.
Many people, especially practitioners of Parkour and Freerunning and Georges Hébert's Natural Method, find benefit in using quadrupedal movement in order to build full body strength. For added difficulty this can be done faster or slower, or more exaggerated and to the effect of a push-up, or down stairs. Moving quadrupedally exercises the entire anterior: thighs, core, shoulders, and triceps.
Kenichi Ito is a Japanese man who is famous for speed running on four limbs.
Quadrupedal robots.
BigDog is a dynamically stable quadruped robot created in 2005 by Boston Dynamics with Foster-Miller, the NASA Jet Propulsion Laboratory, and the Harvard University Concord Field Station.

</doc>
<doc id="25237" url="http://en.wikipedia.org/wiki?curid=25237" title="Quarantine">
Quarantine

A quarantine is used to separate and restrict the movement of persons; it is a 'state of enforced isolation'. This is often used in connection to disease and illness, such as those who may possibly have been exposed to a communicable disease. The term is often erroneously used to mean medical isolation, which is "to separate ill persons who have a communicable disease from those who are healthy." The word comes from the Italian (seventeenth-century Venetian) quaranta, meaning forty, which is the number of days ships were required to be isolated before passengers and crew could go ashore during the Black Death plague epidemic. Quarantine can be applied to humans, but also to animals of various kinds, and both as part of border control as well as within a country.
In practice.
The quarantining of people often raises questions of civil rights, especially in cases of long confinement or segregation from society, such as that of Mary Mallon (aka Typhoid Mary), a typhoid fever carrier who spent the last 24 years of her life under quarantine.
Quarantine periods can be very short, such as in the case of a suspected anthrax attack, in which persons are allowed to leave as soon as they shed their potentially contaminated garments and undergo a decontamination shower. For example, an article entitled "Daily News workers quarantined" describes a brief quarantine that lasted until people could be showered in a decontamination tent. (Kelly Nankervis, Daily News).
The February/March 2003 issue of "HazMat Magazine" suggests that people be "locked in a room until proper decon could be performed", in the event of "suspect anthrax".
"Standard-Times" senior correspondent Steve Urbon (14 February 2003) describes such temporary quarantine powers:
Civil rights activists in some cases have objected to people being rounded up, stripped and showered against their will. But Capt. Chmiel said local health authorities have "certain powers to quarantine people."
The purpose of such quarantine-for-decontamination is to prevent the spread of contamination, and to contain the contamination such that others are not put at risk from a person fleeing a scene where contamination is suspect. It can also be used to limit exposure, as well as eliminate a vector.
The first astronauts to visit the Moon were quarantined upon their return at the specially built Lunar Receiving Laboratory.
New developments for quarantine include new concepts in quarantine vehicles such as the ambulance bus, mobile hospitals, and lockdown/invacuation (inverse evacuation) procedures, as well as docking stations for an ambulance bus to dock to a facility that's under lockdown.
History.
Infected people were separated to prevent spread of disease among the ancient Israelites under the Mosaic Law, as recorded in the Old Testament.
The word "quarantine" originates from the Venetian dialect form of the Italian "quaranta giorni", meaning 'forty days'. This is due to the 40 day isolation of ships and people before entering the city of Dubrovnik in Croatia. This was practised as a measure of disease prevention related to the Black Death. Between 1348 and 1359, the Black Death wiped out an estimated 30% of Europe's population, and a significant percentage of Asia's population. The original document from 1377, which is kept in the Archives of Dubrovnik, states that before entering the city, newcomers had to spend 30 days (a "trentine") in a restricted place (originally nearby islands) waiting to see whether the symptoms of Black Death would develop. Later, isolation was prolonged to 40 days and was called quarantine.
Other diseases lent themselves to the practice of quarantine before and after the devastation of the plague. Those afflicted with leprosy were historically isolated from society, as were the attempts to check the invasion of syphilis in northern Europe in about 1490, the advent of yellow fever in Spain at the beginning of the 19th century, and the arrival of Asiatic cholera in 1831.
Venice took the lead in measures to check the spread of plague, having appointed three guardians of public health in the first years of the Black Death (1348). The next record of preventive measures comes from Reggio in Modena in 1374. The first lazaret was founded by Venice in 1403, on a small island adjoining the city. In 1467, Genoa followed the example of Venice, and in 1476 the old leper hospital of Marseille was converted into a plague hospital. The great lazaret of Marseilles, perhaps the most complete of its kind, was founded in 1526 on the island of Pomègues. The practice at all the Mediterranean lazarets was not different from the English procedure in the Levantine and North African trade. On the approach of cholera in 1831 some new lazarets were set up at western ports, notably a very extensive establishment near Bordeaux, afterwards turned to another use.
International conventions.
Since 1852 several conferences were held involving European powers, with a view to uniform action in keeping out infection from the East and preventing its spread within Europe. All but that of 1897 were concerned with cholera. No result came of those at Paris (1852), Constantinople (1866), Vienna (1874), and Rome (1885), but each of the subsequent ones doctrine of constructive infection of a ship as coming from a scheduled port, and an approximation to the principles advocated by Great Britain for many years. The principal countries which retained the old system at the time were Spain, Portugal, Turkey, Greece and Russia (the British possessions at the time, Gibraltar, Malta and Cyprus, being under the same influence). The aim of each international sanitary convention had been to bind the governments to a uniform minimum of preventive action, with further restrictions permissible to individual countries. The minimum specified by international conventions was very nearly the same as the British practice, which had been in turn adapted to continental opinion in the matter of the importation of rags.
The Venice convention of 30 January 1892 dealt with cholera by the Suez Canal route; that of Dresden of 15 April 1893, with cholera within European countries; that of Paris of 3 April 1894, with cholera by the pilgrim traffic; and that of Venice, on 19 March 1897, was in connection with the outbreak of plague in the East, and the conference met to settle on an international basis the steps to be taken to prevent, if possible, its spread into Europe. An additional convention was signed in Paris on 3 December 1903.
A multilateral international sanitary convention was concluded at Paris on 17 January 1912. This convention was most comprehensive and was designated to replace all previous conventions on that matter. It was signed by 40 countries, and consisted of 160 articles. Ratifications by 16 of the signatories were exchanged in Paris on 7 October 1920. Another multilateral convention was signed in Paris on 21 June 1926, to replace that of 1912. It was signed by 58 countries worldwide, and consisted of 172 articles.
In Latin America, a series of regional sanitary conventions were concluded. Such a convention was concluded in Rio de Janeiro on 12 June 1904. A sanitary convention between the governments of Argentina, Brazil, Paraguay and Uruguay was concluded in Montevideo on 21 April 1914. The convention covers cases of Asiatic cholera, oriental plague and yellow fever. It was ratified by the Uruguayan government on 13 October 1914, by the Paraguayan government on 27 September 1917 and by the Brazilian government on 18 January 1921.
Sanitary conventions were also concluded between European states. A Soviet-Latvian sanitary convention was signed on 24 June 1922, for which ratifications were exchanged on 18 October 1923. A bilateral sanitary convention was concluded between the governments of Latvia and Poland on 7 July 1922, for which ratifications were exchanged on 7 April 1925. Another was concluded between the governments of Germany and Poland in Dresden on 18 December 1922, and entered into effect on 15 February 1923. Another one was signed between the governments of Poland and Romania on 20 December 1922. Ratifications were exchanged on 11 July 1923. The Polish government also concluded such a convention with the Soviet government on 7 February 1923, for which ratifications were exchanged on 8 January 1924. A sanitary convention was also concluded between the governments of Poland and Czechoslovakia on 5 September 1925, for which ratifications were exchanged on 22 October 1926. A convention was signed between the governments of Germany and Latvia on 9 July 1926, for which ratifications were exchanged on 6 July 1927.
One of the first points to be dealt with in 1897 was to settle the incubation period for this disease, and the period to be adopted for administrative purposes. It was admitted that the incubation period was, as a rule, a comparatively short one, namely, of some three or four days. After much discussion ten days was accepted by a very large majority. The principle of disease notification was unanimously adopted. Each government had to notify to other governments on the existence of plague within their several jurisdictions, and at the same time state the measures of prevention which are being carried out to prevent its diffusion. The area deemed to be infected was limited to the actual district or village where the disease prevailed, and no locality was deemed to be infected merely because of the importation into it of a few cases of plague while there has been no diffusion of the malady. As regards the precautions to be taken on land frontiers, it was decided that during the prevalence of plague every country had the inherent right to close its land frontiers against traffic. As regards the Red Sea, it was decided after discussion that a healthy vessel could pass through the Suez Canal, and continue its voyage in the Mediterranean during the period of incubation of the disease the prevention of which is in question. It was also agreed that vessels passing through the Canal in quarantine might, subject to the use of the electric light, coal in quarantine at Port Said by night as well as by day, and that passengers might embark in quarantine at that port. Infected vessels, if these carry a doctor and are provided with a disinfecting stove, have a right to navigate the Canal, in quarantine, subject only to the landing of those who were suffering from plague.
Signals and flags.
Plain yellow, green, and even black flags have been used to symbolize disease in both ships and ports, with the color yellow having a longer historical precedent, as a color of marking for houses of infection, previous to its use as a maritime marking color for disease. The present flag used for the purpose is the "Lima" (L) flag, which is a mixture of yellow and black flags previously used. It is sometimes called the "yellow jack" but this was also a name for yellow fever, which probably derives its common name from the flag, not the color of the victims (cholera ships also used a yellow flag). The plain yellow flag ("Quebec" or Q in international maritime signal flags) probably derives its letter symbol for its initial use in "quarantine", but this flag in modern times indicates the opposite—a ship that declares itself free of quarantinable disease, and requests boarding and routine port inspection.
Australia.
Australia has perhaps the world's strictest quarantine standards. Quarantine in northern Australia is important because of its proximity to South-east Asia and the Pacific, which have many pests and diseases not present in Australia. For this reason, the region from Cairns to Broome—including the Torres Strait—is the focus for many important quarantine activities that protect all Australians. As Australia has been geographically isolated from other major continents for millions of years, there is an endemically unique ecosystem free of several severe pests and diseases that are present in many parts of the world. If other products are brought inside along with pests and diseases, it would damage the ecosystem seriously and add millions of costs in the local agricultural businesses.
The Australian Quarantine and Inspection Service is responsible for border-inspection of any products which are brought into Australia, and assess the potential risks the products might harm Australian environment. Visitors are required to fill in the information card truthfully before arriving in Australia, and declare what food and any products made of wood and other natural materials they have processed. If the visitor fails to do so, usually a quarantine fine of 220 Australian dollars are to be paid as quarantine infringement notice, and if not, the visitor may face criminal convictions of fining 100,000 Australian dollars and 10 years imprisonment.
Canada.
There are three quarantine Acts of Parliament in Canada: "Quarantine Act" (humans) and "Health of Animals Act" (animals) and "Plant Protection Act" (vegetations). The first legislation is enforced by the Canada Border Services Agency after a complete rewrite in 2005. The second and third legislations are enforced by the Canadian Food Inspection Agency. If a health emergency exists, the Governor in Council can prohibit importation of anything that it deems necessary under the "Quarantine Act".
Under the "Quarantine Act", all travellers must submit to screening and if they believe they might have come into contact with communicable diseases or vectors, they must disclose their whereabouts to a Border Services Officer. If the officer has reasonable grounds to believe that the traveller is or might have been infected with a communicable disease or refused to provide answers, a quarantine officer (QO) must be called and the person is to be isolated. If a person refuses to be isolated, any peace officer may arrest without warrant.
A QO who has reasonable grounds to believe that the traveller has or might have a communicable disease or is infested with vectors, after the medical examination of a traveller, can order him/her into treatment or measures to prevent the person from spreading the disease. QO can detain any traveller who refuses to comply with his/her orders or undergo health assessments as required by law.
Under the "Health of Animals Act" and "Plant Protection Act", inspectors can prohibit access to an infected area, dispose or treat any infected or suspected to be infected animals or plants. The Minister can order for compensation to be given if animals/plants were destroyed pursuant to these acts.
Each province also enacts its own quarantine/environmental health legislations.
Hong Kong.
Under the "Prevention and Control of Disease Ordinance" (HK Laws. Chap 599), a health officer may seize articles he/she believes to be infectious or contains infectious agents. All travellers, if requested, must submit themselves to a health officer. Failure to do so is against the law and is subject to arrest and prosecution.
The law allows for a health officer who have reasonable grounds to detain, isolate, quarantine anyone or anything believed to be infected and to restrict any articles from leaving a designated quarantine area. He/she may also order the Civil Aviation Department to prohibit the landing or leaving, embarking or disembarking of an aircraft. This power also extends to land, sea or air crossings.
Under the same ordinance, any police officer, health officer, members of the Civil Aid Service or Auxiliary Medical Service can arrest a person who obstructs or escape from detention.
United Kingdom.
To reduce the risk of introducing rabies from continental Europe, the United Kingdom used to require that dogs, and most other animals introduced to the country, spend six months in quarantine at an HM Customs and Excise pound; this policy was abolished in 2000 in favour of a scheme generally known as Pet Passports, where animals can avoid quarantine if they have documentation showing they are up to date on their appropriate vaccinations.
British quarantine rules after 1711.
The plague had disappeared from England, never to return, for more than thirty years before the practice of quarantine against it was definitely established by the Quarantine Act 1710 ("9 Ann.") The first act was called for, owing to an alarm, lest plague should be imported from Poland and the Baltics; the second act of 1721 was due to the disastrous prevalence of plague at Marseille and other places in Provence, France; it was renewed in 1733 owing to a fresh outbreak of the malady on the continent of Europe, and again in 1743, owing to the disastrous epidemic at Messina. In 1752 a rigorous quarantine clause was introduced into an act regulating the Levantine trade; and various arbitrary orders were issued during the next twenty years to meet the supposed danger of infection from the Baltics. Although no plague cases ever came to England all those years, the restrictions on traffic became more and more stringent (following the movements of medical dogma), and in 1788 a very oppressive Quarantine Act was passed, with provisions affecting cargoes in particular. The first year of the nineteenth century marked the turning-point in quarantine legislation; a parliamentary committee sat on the practice, and a more reasonable act arose on their report. In 1805 there was another new act, and in 1823–24 again an elaborate inquiry followed by an act making the quarantine only at discretion of the privy council, and at the same time recognizing yellow fever or other highly infectious disorder as calling for quarantine measures along with plague. The steady approach of cholera in 1831 was the last occasion in England of a thoroughgoing resort to quarantine restrictions. The pestilence invaded every country of Europe despite all efforts to keep it out. In England the experiment of hermetically sealing the ports was not seriously tried when cholera returned in 1849, 1853 and 1865–66. In 1847 the privy council ordered all arrivals with clean bills from the Black Sea and the Levant to be admitted to free pratique, provided there had been no case of plague during the voyage; and therewith the last remnant of the once formidable quarantine practice against plague may be said to have disappeared.
For a number of years after the passing of the first Quarantine Act (1710) the protective practices in England were of the most haphazard and arbitrary kind. In 1721 two vessels laden with cotton goods from Cyprus, then a seat of plague, were ordered to be burned with their cargoes, the owners receiving as indemnity. By the clause in the Levant Trade Act of 1752 vessels for the United Kingdom with a foul bill (i.e. coming from a country where plague existed) had to repair to the lazarets of Malta, Venice, Messina, Livorno, Genoa or Marseille, to perform their quarantine or to have their cargoes sufficiently opened and aired. Since 1741 Stangate Creek (on the Medway) had been made the quarantine station at home; but it would appear from the above clause that it was available only for vessels with clean bills. In 1755 lazarets in the form of floating hulks were established in England for the first time, the cleansing of cargo (particularly by exposure to dews) having been done previously on the ship's deck. There was no medical inspection employed, but the whole routine left to the officers of customs and quarantine. In 1780, when plague was in Poland, even vessels with grain from the Baltic had to lie forty days in quarantine, and unpack and air the sacks; but owing to remonstrances, which came chiefly from Edinburgh and Leith, grain was from that date declared to be a non-susceptible article. About 1788 an order of the council required every ship liable to quarantine, in case of meeting any vessel at sea, or within four leagues of the coast of Great Britain or Ireland, to hoist a yellow flag in the daytime and show a light at the main topmast head at night, under a penalty of After 1800, ships from plague-countries (or with foul bills) were enabled to perform their quarantine on arrival in the Medway instead of taking a Mediterranean port on the way for that purpose; and about the same time an extensive lazaret was built on Chetney Hill near Chatham at an expense of which was almost at once condemned owing to its marshy foundations, and the materials sold for The use of floating hulks as lazarets continued as before. In 1800 two ships with hides from Mogador (Morocco) were ordered to be sunk with their cargoes at the Nore, the owners receiving About this period it was merchandise that was chiefly suspected: there was a long schedule of susceptible articles, and these were first exposed on the ship's deck for twenty-one days or less (six days for each instalment of the cargo), and then transported to the lazaret, where they were opened and aired forty days more. The whole detention of the vessel was from sixty to sixty-five days, including the time for reshipment of her cargo. Pilots had to pass fifteen days on board a convalescent ship. The expenses may be estimated from one or two examples. In 1820 the "Asia", 763 tons, arrived in the Medway with a foul bill from Alexandria, laden with linseed; her freight was and her quarantine dues The same year the "Pilato", 495 tons, making the same voyage, paid quarantine dues on a freight of In 1823 the expenses of the quarantine service (at various ports) were and the dues paid by shipping (nearly all with clean bills) A return for the United Kingdom and colonies in 1849 showed, among other details, that the expenses of the lazaret at Malta for ten years from 1839 to 1848 had been From 1846 onwards the establishments in the United Kingdom were gradually reduced, while the last vestige of the British quarantine law was removed by the Public Health Act 1896, which repealed the Quarantine Act 1825 (with dependent clauses of other acts), and transferred from the privy council to the Local Government Board the powers to deal with ships arriving infected with yellow fever or plague, the powers to deal with cholera ships having been already transferred by the Public Health Act 1875.
The British regulations of 9 November 1896 applied to yellow fever, plague and cholera. Officers of the Royal Customs, as well as of Royal Coast Guard and Board of Trade (for signalling), were empowered to take the initial steps. They certified in writing the master of a supposed infected ship, and detained the vessel provisionally for not more than twelve hours, giving notice meanwhile to the port sanitary authority. The medical officer of the port boarded the ship and examined every person in it. Every person found infected was certified of the fact, removed to a hospital provided (if his condition allow), and kept under the orders of the medical officer. If the sick could be removed, the vessel remained under his orders. Every person suspected (owing to his or her immediate attendance on the sick) could be detained on board for 48 hours or removed to the hospital for a similar period. All others were free to land on giving the addresses of their destinations to be sent to the respective local authorities, so that the dispersed passengers and crew could be kept individually under observation for a few days. The ship was then disinfected, dead bodies buried at sea, infected clothing, bedding, etc., destroyed or disinfected, and bilge-water and water-ballast (subject to exceptions) pumped out at a suitable distance before the ship entered a dock or basin. Mails were subject to no detention. A stricken ship within 3 miles of the shore had to fly at the main mast a yellow and black flag borne quarterly from sunrise to sunset.
United States.
The United States puts immediate quarantines on imported products if the disease can be traced back to a certain shipment or product. All imports will also be quarantined if the diseases breakout in other countries. 
According to Title , these statutes provide the Secretary of the Department of Health and Human Services (“the Secretary”) peacetime and wartime authority, respectively, to control the movement of persons into and within the United States to prevent the spread of communicable disease.
Communicable diseases for which apprehension, detention, or conditional release of persons are authorized must be specified in Executive Orders of the President. Executive Order 13295 (Revised List of Quarantinable Communicable Diseases, April 4, 2003) and its amendments (executive orders 13375 and 13674) specify the following infectious diseases: (1) cholera, (2) diphtheria, (3) infectious tuberculosis, (4) plague, (5) smallpox, (6) yellow fever, (7) viral hemorrhagic fevers (Lassa, Marburg, Ebola, Crimean-Congo, South American, and others not yet isolated or named), (8) severe acute respiratory syndromes, and (9) influenza, from a novel or re-emergent source. In the event of conflict of federal, state, local, and/or tribal health authorities in the use of legal quarantine power, federal law is supreme.
The Division of Global Migration and Quarantine (DGMQ) of the US Center for Disease Control (CDC) operates small quarantine facilities at a number of US ports of entry. As of 2014, these included one land crossing (in El Paso, Texas) and 19 international airports.
Besides the port of entry where it is located, each station is also responsible for quarantining potentially infected travelers entering through any ports of entry in its assigned region. These facilities are fairly small; each one is operated by a few staff members and capable of accommodating 1-2 travelers for a short observation period. Cost estimates for setting up a temporary larger facility, capable of accommodating 100 to 200 travelers for several weeks, have been published by the Airport Cooperative Research Program in 2008.
United States – history.
Quarantine law began in Colonial America in 1663, when in an attempt to curb an outbreak of smallpox, the city of New York established a quarantine. In the 1730s, the city built a quarantine station on the Bedloe's Island. The Philadelphia Lazaretto was the first quarantine hospital in the United States, built in 1799, in Tinicum Township, Delaware County, Pennsylvania. There are similar national landmarks such as Swinburne Island and Angel Island (a much more famous historic site, Ellis Island, is often mistakenly assumed to have been a quarantine station, however its marine hospital only qualified as a contagious disease facility to handle less virulent diseases like measles, trachoma and less advanced stages of tuberculosis and diphtheria; persons afflicted with smallpox, yellow fever, cholera, leprosy or typhoid fever, could neither be received nor treated there).
During the 1918 flu pandemic, people were also quarantined. Most commonly suspect cases of infectious diseases are requested to voluntarily quarantine themselves, and Federal and local quarantine statutes only have been uncommonly invoked since then, including for a suspected smallpox case in 1963.
In 2007, Andrew Speaker, an Atlanta attorney on his honeymoon in Europe, was diagnosed by the U.S. Centers for Disease Control and Prevention (CDC) with extensively drug-resistant tuberculosis (XDR-TB), which is contagious, untreatable, and potentially lethal. Speaker returned to the U.S. against the instructions of the CDC, and he was served with a federal order of quarantine by the CDC at a New York hospital, the first such order to be issued in nearly half a century. Speaker challenged the diagnosis, resulting in a new diagnosis of a milder form of tuberculosis and the lifting of restrictions on his movements. The Speaker case drew significant public attention, and Congress held formal hearings about the incident. Speaker’s case highlighted a vital issue in public health law: the circumstances, if any, under which public officials may detain individuals against their will to protect the public from communicable diseases, and the conflict between the utilitarian principle of social good and the individual rights guaranteed by the United States Constitution.
Also other TB carriers who refuse to wear a mask in public have been indefinitely involuntarily committed to regular jails, and cut off from contacting the world. Some have complained of abuse there.
Other uses.
U.S. President John F. Kennedy euphemistically referred to the U.S. Navy's interdiction of shipping en route to Cuba during the Cuban missile crisis as a "quarantine" rather than a blockade, because a quarantine is a legal act in peacetime, whereas a blockade is defined as an act of aggression under the U.N. Charter.
In computer science, "quarantining" describes putting files infected by computer viruses into a special directory, so as to eliminate the threat they pose, without irreversibly deleting them.

</doc>
<doc id="25239" url="http://en.wikipedia.org/wiki?curid=25239" title="Quasar">
Quasar

Quasars () or quasi-stellar radio sources are the most energetic and distant members of a class of objects called active galactic nuclei (AGN). Quasars are extremely luminous and were first identified as being high redshift sources of electromagnetic energy, including radio waves and visible light, that appeared to be similar to stars, rather than extended sources similar to galaxies. Their spectra contain very broad emission lines, unlike any known from stars, hence the name "quasi-stellar." Their luminosity can be 100 times greater than that of the Milky Way.
While the nature of these objects was controversial until the early 1980s, there is now a scientific consensus that a quasar is a compact region in the center of a massive galaxy surrounding a central supermassive black hole. Its size is 10–10,000 times the Schwarzschild radius of the black hole. The energy emitted by a quasar derives from mass falling onto the accretion disc around the black hole.
Overview.
Quasars show a very high redshift, which is an effect of the metric expansion of space between the quasar and the Earth. When the observed redshift of quasars is interpreted in terms of Hubble's law, it is inferred that quasars are very distant objects. Quasars inhabit the very center of active, young galaxies, and are among the most luminous, powerful, and energetic objects known in the universe, emitting up to a thousand times the energy output of the Milky Way, which contains 200–400 billion stars. This radiation is emitted across the electromagnetic spectrum, almost uniformly, from X-rays to the far-infrared with a peak in the ultraviolet-optical bands, with some quasars also being strong sources of radio emission and of gamma-rays.
In early optical images, quasars appeared as point sources, indistinguishable from stars, except for their peculiar spectra. With infrared telescopes and the Hubble Space Telescope, the "host galaxies" surrounding the quasars have been detected in some cases. These galaxies are normally too dim to be seen against the glare of the quasar, except with special techniques. Most quasars, with the exception of 3C 273 whose average apparent magnitude is 12.9, cannot be seen with small telescopes.
The luminosity of some quasars changes rapidly in the optical range and even more rapidly in the X-rays range. Because these changes occur very rapidly they define an upper limit on the volume of a quasar; quasars are not much larger than the Solar System. This implies an astonishingly high energy density. The mechanism of brightness changes probably involves relativistic beaming of jets pointed nearly directly toward us. The highest redshift quasar known (as of 2011[ [update]]) is ULAS J1120+0641, with a redshift of 7.085, which corresponds to a comoving distance of approximately 29 billion light-years from Earth (see more discussion of how cosmological distances can be greater than the light-travel time at Metric Expansion of Space).
Quasars are believed to be powered by accretion of material into supermassive black holes in the nuclei of distant galaxies, making these luminous versions of the general class of objects known as active galaxies. Since light cannot escape the black holes, the escaping energy is actually generated outside the event horizon by gravitational stresses and immense friction on the incoming material. Central masses of 105 to 109 solar masses have been measured in quasars using reverberation mapping. Several dozen nearby large galaxies, with no sign of a quasar nucleus, have been shown to contain a similar central black hole in their nuclei, so it is thought that all large galaxies have one, but only a small fraction are active (with enough accretion to power radiation) and so are seen as quasars. The matter accreting onto the black hole is unlikely to fall directly in, but will have some angular momentum around the black hole that will cause the matter to collect into an accretion disc. Quasars may also be ignited or re-ignited from normal galaxies when they merge and the black hole is infused with a fresh source of matter. In fact, it has been suggested that a quasar could form as the Andromeda Galaxy collides with our own Milky Way galaxy in approximately 3–5 billion years.
Properties.
More than 200,000 quasars are known, most from the Sloan Digital Sky Survey. All observed quasar spectra have redshifts between 0.056 and 7.085.
Applying Hubble's law to these redshifts, it can be shown that they are between 600 million and 28.85 billion light-years away (in terms of comoving distance). Because of the great distances to the farthest quasars and the finite velocity of light, we see them and their surrounding space as they existed in the very early universe.
The power of quasars originates from supermassive black holes that are believed to exist at the core of all galaxies. A survey of the 40 nearest galaxies with the Hubble Space Telescope in the 90's revealed Doppler shifts of the stars near the core of those galaxies were rotating about tremendous masses with very steep gravity gradients, suggesting black holes.
Although quasars appear faint when viewed from Earth, the fact that they are visible at all from so far is due to quasars being the most luminous objects in the known universe. The quasar that appears brightest in the sky is 3C 273 in the constellation of Virgo. It has an average apparent magnitude of 12.8 (bright enough to be seen through a medium-size amateur telescope), but it has an absolute magnitude of −26.7. From a distance of about 33 light-years, this object would shine in the sky about as brightly as our sun. This quasar's luminosity is, therefore, about 4 trillion (4 × 1012) times that of our Sun, or about 100 times that of the total light of giant galaxies like our Milky Way. However, this assumes the quasar is radiating energy in all directions, but the active galactic nucleus is believed to be radiating preferentially in the direction of its jet. In a universe containing hundreds of billions of galaxies, most of which had active nuclei billions of years ago but only seen today, it is statistically certain that thousands of energy jets should be pointed toward us, some more directly than others. In many cases it is likely that the brighter the quasar, the more directly its jet is aimed at us.
The hyperluminous quasar APM 08279+5255 was, when discovered in 1998, given an absolute magnitude of −32.2. High resolution imaging with the Hubble Space Telescope and the 10 m Keck Telescope revealed that this system is gravitationally lensed. A study of the gravitational lensing of this system suggests that the light emitted has been magnified by a factor of ~10. It is still substantially more luminous than nearby quasars such as 3C 273.
Quasars were much more common in the early universe. This discovery by Maarten Schmidt in 1967 was early strong evidence against the Steady State cosmology of Fred Hoyle, and in favor of the Big Bang cosmology. Quasars show the locations where massive black holes are growing rapidly (via accretion). These black holes grow in step with the mass of stars in their host galaxy in a way not understood at present. One idea is that jets, radiation and winds created by the quasars shut down the formation of new stars in the host galaxy, a process called 'feedback'. The jets that produce strong radio emission in some quasars at the centers of clusters of galaxies are known to have enough power to prevent the hot gas in those clusters from cooling and falling onto the central galaxy.
Quasars' luminosities are variable, with time scales that range from months to hours. This means that quasars generate and emit their energy from a very small region, since each part of the quasar would have to be in contact with other parts on such a time scale to allow the coordination of the luminosity variations. This would mean that a quasar varying on a time scale of a few weeks cannot be larger than a few light-weeks across. The emission of large amounts of power from a small region requires a power source far more efficient than the nuclear fusion that powers stars. The release of gravitational energy by matter falling towards a massive black hole is the only process known that can produce such high power continuously. Stellar explosions – supernovas and gamma-ray bursts – can do likewise, but only for a few weeks. Black holes were considered too exotic by some astronomers in the 1960s. They also suggested that the redshifts arose from some other (unknown) process, so that the quasars were not really so distant as the Hubble law implied. This 'redshift controversy' lasted for many years. Many lines of evidence (optical viewing of host galaxies, finding 'intervening' absorption lines, gravitational lensing) now demonstrate that the quasar redshifts are due to the Hubble expansion, and quasars are in fact as powerful as first thought.
Quasars have all the properties of other active galaxies such as Seyfert galaxies, but are more powerful: their radiation is partially 'nonthermal' (i.e., not due to black body radiation), and approximately 10 percent are observed to also have jets and lobes like those of radio galaxies that also carry significant (but poorly understood) amounts of energy in the form of particles moving at relativistic speeds. Quasars can be detected over the entire observable electromagnetic spectrum including radio, infrared, visible light, ultraviolet, X-ray and even gamma rays. Most quasars are brightest in their rest-frame near-ultraviolet wavelength of 121.6 nm Lyman-alpha emission line of hydrogen, but due to the tremendous redshifts of these sources, that peak luminosity has been observed as far to the red as 900.0 nm, in the near infrared. A minority of quasars show strong radio emission, which originates from jets of matter moving close to the speed of light. When looked at down the jet, these appear as blazars and often have regions that appear to move away from the center faster than the speed of light (superluminal expansion). This is an optical illusion due to the properties of special relativity.
Quasar redshifts are measured from the strong spectral lines that dominate their visible and ultraviolet spectra. These lines are brighter than the continuous spectrum, so they are called 'emission' lines. They have widths of several percent of the speed of light. These widths are due to Doppler shifts caused by the high speeds of the gas emitting the lines. Fast motions strongly indicate a large mass. Emission lines of hydrogen (mainly of the Lyman series and Balmer series), helium, carbon, magnesium, iron and oxygen are the brightest lines. The atoms emitting these lines range from neutral to highly ionized, i.e., many of the electrons are stripped off the atom, leaving it highly charged. This wide range of ionization shows that the gas is highly irradiated by the quasar, not merely hot, and not by stars, which cannot produce such a wide range of ionization.
"Iron quasars" show strong emission lines resulting from low ionization iron (FeII), such as IRAS 18508-7815.
Emission generation.
Since quasars exhibit properties common to all active galaxies, the emission from quasars can be readily compared to those of smaller active galaxies powered by smaller supermassive black holes. To create a luminosity of 1040 watts (the typical brightness of a quasar), a super-massive black hole would have to consume the material equivalent of 10 stars per year. The brightest known quasars devour 1000 solar masses of material every year. The largest known is estimated to consume matter equivalent to 600 Earths per minute. Quasar luminosities can vary considerably over time, depending on their surroundings. Since it is difficult to fuel quasars for many billions of years, after a quasar finishes accreting the surrounding gas and dust, it becomes an ordinary galaxy.
Quasars also provide some clues as to the end of the Big Bang's reionization. The oldest known quasars (redshift ≥ 6) display a Gunn-Peterson trough and have absorption regions in front of them indicating that the intergalactic medium at that time was neutral gas. More recent quasars show no absorption region but rather their spectra contain a spiky area known as the Lyman-alpha forest; this indicates that the intergalactic medium has undergone reionization into plasma, and that neutral gas exists only in small clouds.
Quasars show evidence of elements heavier than helium, indicating that galaxies underwent a massive phase of star formation, creating population III stars between the time of the Big Bang and the first observed quasars. Light from these stars may have been observed in 2005 using NASA's Spitzer Space Telescope, although this observation remains to be confirmed.
Like all (unobscured) active galaxies, quasars can be strong X-ray sources. Radio-loud quasars can also produce X-rays and gamma rays by inverse Compton scattering of lower-energy photons by the radio-emitting electrons in the jet.
History of observation.
The first quasars (3C 48 and 3C 273) were discovered in the late 1950s, as radio sources in all-sky radio surveys. They were first noted as radio sources with no corresponding visible object. Using small telescopes and the Lovell Telescope as an interferometer, they were shown to have a very small angular size. Hundreds of these objects were recorded by 1960 and published in the Third Cambridge Catalogue as astronomers scanned the skies for their optical counterparts. In 1963, a definite identification of the radio source 3C 48 with an optical object was published by Allan Sandage and Thomas A. Matthews. Astronomers had detected what appeared to be a faint blue star at the location of the radio source and obtained its spectrum. Containing many unknown broad emission lines, the anomalous spectrum defied interpretation — a claim by John Bolton of a large redshift was not generally accepted.
In 1962 a breakthrough was achieved. Another radio source, 3C 273, was predicted to undergo five occultations by the moon. Measurements taken by Cyril Hazard and John Bolton during one of the occultations using the Parkes Radio Telescope allowed Maarten Schmidt to optically identify the object and obtain an optical spectrum using the 200-inch Hale Telescope on Mount Palomar. This spectrum revealed the same strange emission lines. Schmidt realized that these were actually spectral lines of hydrogen redshifted at the rate of 15.8 percent. This discovery showed that 3C 273 was receding at a rate of 47,000 km/s. This discovery revolutionized quasar observation and allowed other astronomers to find redshifts from the emission lines from other radio sources. As predicted earlier by Bolton, 3C 48 was found to have a redshift of 37% of the speed of light.
The term "quasar" was coined by Chinese-born U.S. astrophysicist Hong-Yee Chiu in May 1964, in "Physics Today", to describe these puzzling objects:
So far, the clumsily long name 'quasi-stellar radio sources' is used to describe these objects. Because the nature of these objects is entirely unknown, it is hard to prepare a short, appropriate nomenclature for them so that their essential properties are obvious from their name. For convenience, the abbreviated form 'quasar' will be used throughout this paper.
Later it was found that not all quasars have strong radio emission; in fact only about 10% are 'radio-loud'. Hence the name 'QSO' (quasi-stellar object) is used (in addition to 'quasar') to refer to these objects, including the 'radio-loud' and the 'radio-quiet' classes.
One great topic of debate during the 1960s was whether quasars were nearby objects or distant objects as implied by their redshift. It was suggested, for example, that the redshift of quasars was not due to the expansion of space but rather to light escaping a deep gravitational well. However a star of sufficient mass to form such a well would be unstable and in excess of the Hayashi limit. Quasars also show 'forbidden' spectral emission lines which were previously only seen in hot gaseous nebulae of low density, which would be too diffuse to both generate the observed power and fit within a deep gravitational well. There were also serious concerns regarding the idea of cosmologically distant quasars. One strong argument against them was that they implied energies that were far in excess of known energy conversion processes, including nuclear fusion. At this time, there were some suggestions that quasars were made of some hitherto unknown form of stable antimatter and that this might account for their brightness. Others speculated that quasars were a white hole end of a wormhole. However, when accretion disc energy-production mechanisms were successfully modeled in the 1970s, the argument that quasars were too luminous became moot and today the cosmological distance of quasars is accepted by almost all researchers.
In 1979 the gravitational lens effect predicted by Einstein's General Theory of Relativity was confirmed observationally for the first time with images of the double quasar 0957+561.
In the 1980s, unified models were developed in which quasars were classified as a particular kind of active galaxy, and a consensus emerged that in many cases it is simply the viewing angle that distinguishes them from other classes, such as blazars and radio galaxies. The huge luminosity of quasars results from the accretion discs of central supermassive black holes, which can convert on the order of 10% of the mass of an object into energy as compared to 0.7% for the p-p chain nuclear fusion process that dominates the energy production in Sun-like stars.
This mechanism also explains why quasars were more common in the early universe, as this energy production ends when the supermassive black hole consumes all of the gas and dust near it. This means that it is possible that most galaxies, including our own Milky Way, have gone through an active stage (appearing as a quasar or some other class of active galaxy that depended on the black hole mass and the accretion rate) and are now quiescent because they lack a supply of matter to feed into their central black holes to generate radiation.
Role in celestial reference systems.
Because quasars are extremely distant, bright, and small in apparent size, they are useful reference points in establishing a measurement grid on the sky.
The International Celestial Reference System (ICRS) is based on hundreds of extra-galactic radio sources, mostly quasars, distributed around the entire sky. Because they are so distant, they are apparently stationary to our current technology, yet their positions can be measured with the utmost accuracy by Very Long Baseline Interferometry (VLBI). The positions of most are known to 0.001 arcsecond or better, which is orders of magnitude more precise than the best optical measurements.
Multiple quasars.
A multiple imaged quasar is a quasar whose light undergoes gravitational lensing, resulting in double, triple or quadruple images of the same quasar. The first such gravitational lens to be discovered was the double-imaged quasar Q0957+561 (or Twin Quasar) in 1979. A grouping of two or more quasars can result from a chance alignment, physical proximity, actual close physical interaction, or effects of gravity bending the light of a single quasar into two or more images.
As quasars are rare objects, the probability of three or more separate quasars being found near the same location is very low. The first true triple quasar was found in 2007 by observations at the W. M. Keck Observatory Mauna Kea, Hawaii. LBQS 1429-008 (or QQQ J1432−0106) was first observed in 1989 and was found to be a double quasar; itself a rare occurrence. When astronomers discovered the third member, they confirmed that the sources were separate and not the result of gravitational lensing. This triple quasar has a red shift of "z" = 2.076, which is equivalent to 10.5 billion light years. The
components are separated by an estimated 30–50 kpc, which is typical of interacting galaxies. An example of a triple quasar that is formed by lensing is PG1115 +08.
In 2013, the second true triplet quasars QQQ J1519+0627 was found with redshift "z" = 1.51 (approx 9 billion light years) by an international team of astronomers led by Farina of the University of Insubria, the whole system is
well accommodated within 25′′ (i.e., 200 kpc in projected distance). The team accessed data from observations collected at the La Silla Observatory with the New Technology Telescope (NTT) of the European Southern Observatory (ESO) and at the
Calar Alto Observatory with the 3.5m telescope of the Centro Astronómico Hispano
Alemán (CAHA).
When two quasars are so nearly in the same direction as seen from Earth that they appear to be a single quasar but may be separated by the use of telescopes, they are referred to as a "double quasar", such as the Twin Quasar. These are two different quasars, and not the same quasar that is gravitationally lensed. This configuration is similar to the optical double star. Two quasars, a "quasar pair", may be closely related in time and space, and be gravitationally bound to one another. These may take the form of two quasars in the same galaxy cluster. This configuration is similar to two prominent stars in a star cluster. A "binary quasar", may be closely linked gravitationally and form a pair of interacting galaxies. This configuration is similar to that of a binary star system.

</doc>
<doc id="25240" url="http://en.wikipedia.org/wiki?curid=25240" title="Quinquagesima">
Quinquagesima

Quinquagesima is one of the names used in the Western Church for the Sunday before Ash Wednesday. It is also called Quinquagesima Sunday, Quinquagesimae, Estomihi, Shrove Sunday, or the Sunday next before Lent. 
Etymology.
The name Quinquagesima originates from Latin "quinquagesimus" (fiftieth). This is in reference to the fifty days before Easter Day using inclusive counting which counts both Sundays (normal counting would count only one of these). Since the forty days of the Lenten fast does not include Sundays, the first day of Lent, Ash Wednesday, succeeds Quinquagesima Sunday by only three days. The name Estomihi is derived from the beginning of the Introit for the Sunday, "Esto mihi in Deum protectorem, et in locum refugii, ut salvum me facias", :3.
Dates and significance.
The earliest Quinquagesima Sunday can occur is February 1 and the latest is March 7.
Roman Catholic Church.
In the Roman Catholic Church, the terms for this Sunday (and the two immediately before it — Sexagesima and Septuagesima Sundays) were eliminated in the reforms following the Second Vatican Council, and these Sundays are part of Ordinary Time. The contemporary service books of many Anglican provinces do not use the term but it remains in the Book of Common Prayer. 
According to the reformed Roman Rite Roman Catholic calendar, this Sunday is now known by its number within Ordinary Time — fourth through ninth, depending upon the date of Easter. The earlier form of the Roman Rite, with its references to Quinquagesima Sunday, and to the Sexagesima and Septuagesima Sundays, continues to be observed in some communities.
In traditional lectionaries, the Sunday concentrates on Luke 18:31-34, "Jesus took the twelve aside and said, 'Lo, we go to Jerusalem, and everything written by the prophets about the Son of Man shall be fulfilled.' The disciples, however, understood none of this." The passage presages the themes of Lent and Holy Week.
Anglican Communion.
This Sunday has different names in the two different calendars used in the Church of England: in the "Book of Common Prayer" calendar (1662) this Sunday is known as "Quinquagesima", while in the "Common Worship" calendar (2000) it is known as the "Sunday next before Lent". In this latter calendar it is part of the period of Ordinary Time that falls between the feasts of the Presentation of Christ in the Temple (the end of the Epiphany season) and Ash Wednesday.
Revised Common Lectionary.
In the Revised Common Lectionary the Sunday before Lent is designated "Transfiguration Sunday", and the gospel reading is the story of the Transfiguration of Jesus from Matthew, Mark, or Luke. Some churches whose lectionaries derive from the RCL, e.g. the Church of England, use these readings but do not designate the Sunday "Transfiguration Sunday".
Eastern Orthodox Church.
In the Eastern Orthodox Church, its equivalent, the Sunday before Great Lent, is called "Forgiveness Sunday", "Maslenitsa Sunday", or "Cheesefare Sunday". The latter name comes because this Sunday concludes Maslenitsa, the week in which butter and cheese may be eaten, which are prohibited during Great Lent. The former name derives from the fact that this Sunday is followed by a special Vespers called "Forgiveness Vespers" which opens Great Lent.

</doc>
<doc id="25241" url="http://en.wikipedia.org/wiki?curid=25241" title="Quassia">
Quassia

Quassia ( or ) is a flora genus in the family Simaroubaceae. Its size is disputed; some botanists treat it as consisting of only one species, "Quassia amara" from tropical South America, while others treat it in a wide circumscription as a pantropical genus containing up to 40 species of trees and shrubs. The genus was named after a former slave from Surinam, Graman Quassi in the eighteenth century. He discovered the medicinal properties of the bark of "Quassia amara".
Broader treatments of the genus include the following and other species:
It is the source of the quassinoids quassin and neo-quassin.

</doc>
<doc id="25243" url="http://en.wikipedia.org/wiki?curid=25243" title="Quisling">
Quisling

A quisling (; ]) is a person who collaborates with an enemy occupying force. The word originates from the Norwegian war-time leader Vidkun Quisling, who headed a domestic Nazi collaborationist regime during the Second World War.
Origin.
The first use of the term ' in reference to followers of Vidkun Quisling was made by Norwegian Labour Party politician Oscar Torp, in a 2 January 1933 newspaper interview. Further uses of the term were made by Aksel Sandemose, in a "Dagbladet" article in 1934, and by the newspaper "Vestfold Arbeiderblad", in 1936. J.R.R Tolkien used the term in English in "On Fairy-Stories", a presentation given in 1939 and first printed in 1947. The term was widely introduced to an English-speaking audience by the British newspaper "The Times". It published an editorial on 19 April 1940 titled "Quislings everywhere", after the Norwegian Vidkun Quisling, who assisted Nazi Germany as it conquered his own country so that he could rule the collaborationist Norwegian government himself. The "Daily Mail" picked up the term four days after "The Times" editorial was published, by May "The War Illustrated" wrote of "potential Quislings" among the Dutch during the German invasion of the Netherlands, and the BBC brought the word into common use internationally. "The Times editorial asserted: "To writers, the word Quisling is a gift from the gods. If they had been ordered to invent a new word for traitor... they could hardly have hit upon a more brilliant combination of letters. Aurally it contrives to suggest something at once slippery and tortuous."
The then Prime Minister of the United Kingdom Winston Churchill used the term during an address to the Allied Delegates at St. James's Palace on 21 June 1941, when he said: "A vile race of Quislings—to use a new word which will carry the scorn of mankind down the centuries—is hired to fawn upon the conqueror, to collaborate in his designs and to enforce his rule upon their fellow countrymen while groveling low themselves." He used the term again in an address to both houses of Congress in the United States of America on 26 December 1941. Commenting upon the effect of a number of Allied victories against Axis forces, and moreover the United States’ decision to enter the war, Churchill opined that; "Hope has returned to the hearts of scores of millions of men and women, and with that hope there burns the flame of anger against the brutal, corrupt invader. And still more fiercely burn the fires of hatred and contempt for the filthy Quislings whom he has suborned." It subsequently entered the language, and became a target for political cartoonists.
In the United States it was used in the Warner Bros. film "Edge of Darkness" (1943) in reference to a traitorous villager, and in the Warner Bros. cartoon "Tom Turk and Daffy" (1944), uttered by a Thanksgiving turkey whose presence is betrayed to Porky Pig by Daffy Duck. Also, in a 1966 "Peanuts" comic strip, Linus tries to hide in Snoopy's doghouse only to have the beagle rat him out. "Traitor! Quisling! Squealer!" Linus shouts at Snoopy as his sister Lucy drags him away.
Contemporary usage.
The noun has survived and is still in current use. It appeared during 2008 and 2009 in articles in "The New York Times", "Die Zeit" and "The Times". In contrast, the back-formed verb "to quisle" (), has largely disappeared from contemporary usage. The verb seems to have fallen out of use comparatively quickly, since by early 1944 there was evidence that H.L. Mencken—generally considered to be a leading authority on the common English usage in the United States—was not aware that it already existed. The back-formed verb "to quisle" also gave rise to a much less common version of the noun: "quisler".
In contemporary usage, "quisling" is synonymous with "traitor", and particularly applied to politicians who appear to favour the interests of other nations or cultures over their own. In American English, the term is less well known than the equivalent phrase "Benedict Arnold".
When one removes the ⟨q⟩ and the ⟨i⟩ in "quisling", the result is "usling", Norwegian for "wretch". "Vidkjent Usling" ("widely-known wretch") was used more or less humorously during World War II in Norway. Another joke was nicknaming the two-krone banknote "Quisling", and the one-krone note an "usling", hence there were two "usling"s to one "Quisling".
Use in fiction.
The term has been used in fiction to describe traitors and collaborators. 
Television.
House: You know, there’s a new biography of Quisling, I think you might like it.
Cuddy: Sure. No idea who that is.
House: Uh, Norwegian guy, World War II, traitor. The fact that I have to explain this kind of takes the edge off my flow.
Music.
The word features in the last line of Irish Rebel Song "The Patriot Game" 

</doc>
<doc id="25244" url="http://en.wikipedia.org/wiki?curid=25244" title="Quadrangle">
Quadrangle

Quadrangle may refer to :

</doc>
<doc id="25247" url="http://en.wikipedia.org/wiki?curid=25247" title="Quill">
Quill

A quill pen is a writing implement made from a moulted flight feather (preferably a primary wing-feather) of a large bird. Quills were used for writing with ink before the invention of the dip pen, the metal-nibbed pen, the fountain pen, and, eventually, the ballpoint pen. The hand-cut goose quill is rarely used as a calligraphy tool, because many papers are now derived from wood pulp and wear down the quill very quickly. However, it is still the tool of choice for a few professionals and provides an unmatched sharp stroke as well as greater flexibility than a steel pen. 
In a carefully prepared quill the slit does not widen through wetting and drying with ink. It will retain its shape adequately and only requires infrequent sharpening and can be used time and time again until there is little left of it. The hollow shaft of the feather (the "calamus") acts as an ink reservoir and ink flows to the tip by capillary action. 
The strongest quills come from the primary flight feathers discarded by birds during their annual moult. Generally the left wing (it is supposed) is favored by the right-handed majority of writers because the feather curves away from the sight line, over the back of the hand. This is actually urban myth. The quill barrel is cut to six or seven inches in length, so no such consideration of curvature or 'sight-line' is necessary. Additionally, writing with the left-hand in the long era of the quill was discouraged, and quills were never sold as left and right-handed, only by their size and species. 
Goose feathers are most commonly used; scarcer, more expensive swan feathers are used for larger lettering. Depending on availability and strength of the feather, as well as quality and characteristic of the line wanted by the writer, other feathers used for quill-pen making (but only in the USA) include feathers from the crow, eagle, owl, hawk, and turkey. On a true quill the barbs are always stripped off completely on the trailing edge. (The pinion for example only has significant barbs on one side of the barrel.) Later a fashion developed for stripping partially and leaving a decorative top of a few barbs. The fancy, fully plumed quill is mostly a Hollywood invention and has little basis in reality. Most, if not all, manuscript illustrations of scribes show a quill devoid of decorative barbs, or at least mostly stripped.
Quill pens were used to write the vast majority of medieval manuscripts, the Magna Carta and the Declaration of Independence. 
Quill pens are still used today mainly by professional scribes and calligraphers.
Quills are also used as the plectrum material in string instruments, particularly the harpsichord.
History.
Quills were the primary writing instrument in the Western World from the 6th to the 19th century. The best quills were usually made from goose, swan, and later turkey feathers. Quills went into decline after the invention of the metal pen, mass production began in Great Britain as early as 1822 by John Mitchell of Birmingham.
Quill pens were the instrument of choice during the medieval era due to their compatibility with parchment and vellum. Prior to this the reed pen had been used, but a finer letter was achieved on animal skin using a cured quill. Other than written text, they were often used to create figures, decorations, and images on manuscripts, although many illuminators and painters preferred fine brushes for their work. The variety of different strokes in formal hands was accomplished by good penmanship as the tip was square cut and rigid, exactly as it is today with modern steel pens.
It was much later, in the 1600s, with the increased popularity of writing, especially in the copperplate script promoted by the many printed manuals available from the 'Writing Masters,' that quills became more pointed and flexible.
According to the Supreme Court Historical Society, 20 goose-quill pens, neatly crossed, are placed at the four counsel tables each day the U.S. Supreme Court is in session; "most lawyers appear before the Court only once, and gladly take the quills home as souvenirs." This has been done since the earliest sessions of the Court.
Quills are denominated from the order in which they are fixed in the wing; the first is favoured by the expert calligrapher, the second and third quills being very satisfactory also, plus the pinion feather. Flags the 5th and 6th feathers are also used. No other feather on the wing would be considered suitable by a professional scribe.
Information can be obtained on the techniques of curing and cutting quills
"In order to harden a quill that is soft, thrust the barrel into hot ashes, stirring it till it is soft; then taking it out, press it almost flat upon your knees with the back of a penknife, and afterwards reduce it to a roundness with your fingers. If you have a number to harden, set water and alum over the fire; and while it is boiling put in a handful of quills, the barrels only, for a minute, and then lay them by."
An accurate account of the Victorian process by William Bishop, from researches with one of the last London quill dressers, is recorded in the 'Calligrapher's Handbook' cited on this page.
Today.
A quill knife was the original primary tool used for cutting and sharpening quills, known as 'dressing'. 
Following the decline of the quill in the 1820s, after the introduction of the maintenance-free, mass-produced steel dip nib by John Mitchell, knives were still manufactured but became known as desk knives, stationery knives or latterly as the name stuck 'pen' knives. 
A 'pen' knife by contrast has two flat sides. This distinction is not recognised by modern traders, dealers or collectors who define a quill knife as any small knife with a fixed or hinged blade, including such items as ornamental fruit knives.
Music.
Plectra for psalteries and lutes can be cut similarly to writing pens. The rachis, the portion of the stem between the barbs, not the calamus, of the primary flight feathers of birds of the crow family was preferred for harpsichords. In modern instruments, plastic is more common, but they are often still called "quills." 

</doc>
<doc id="25248" url="http://en.wikipedia.org/wiki?curid=25248" title="Quo vadis?">
Quo vadis?

Quo vadis? (], ]) is a Latin phrase meaning "Where are you going?"
The modern usage of the phrase refers to a Christian tradition regarding Saint Peter. According to the apocryphal Acts of Peter (Vercelli Acts XXXV), Peter is fleeing from likely crucifixion in Rome at the hands of the government, and along the road outside the city he meets a risen Jesus. In the Latin translation, Peter asks Jesus ""Quo vadis?"", to which he replies, ""Romam vado iterum crucifigi"" ("I am going to Rome to be crucified again"). Peter thereby gains the courage to continue his ministry and returns to the city, to eventually be martyred by being crucified upside-down.
The Church of Domine Quo Vadis in Rome is built where, according to legend, the meeting between Peter and Jesus took place.
In popular culture.
The Polish writer Henryk Sienkiewicz authored the novel "Quo Vadis: A Narrative of the Time of Nero" (1895), which in turn has been made into motion pictures several times, including a 1951 version that was nominated for eight Academy Awards. For this epic novel (among others), Sienkiewicz received the 1905 Nobel Prize in Literature.

</doc>
<doc id="25249" url="http://en.wikipedia.org/wiki?curid=25249" title="QED">
QED

QED may refer to:

</doc>
<doc id="25254" url="http://en.wikipedia.org/wiki?curid=25254" title="Qantas">
Qantas

Qantas Airways Limited ( ; ASX: ) is the flag carrier airline of Australia and its largest airline by fleet size, international flights and international destinations. It is the third oldest in the world, after KLM and Avianca having been founded in November 1920; it began international passenger flights in May 1935. The Qantas name comes from ""QANTAS", an acronym for its original name, "Queensland and Northern Territory Aerial Services"", and it is nicknamed "The Flying Kangaroo".
The airline is based in the Sydney suburb of Mascot with its main hub at Sydney Airport. Qantas has a 65% share of the Australian domestic market and carries 18.7% of all passengers travelling in and out of Australia. Its subsidiaries QantasLink and Jetconnect provide services within Australia and to New Zealand respectively, flying under the Qantas brand. Qantas also owns the low-cost airline Jetstar, which operates both domestic and international services, and holds stakes in a number of its sister airlines.
Qantas operates a mixed fleet of Airbus and Boeing aircraft. It was the only airline in the world to have a fleet made up solely of Boeing 747s during the 1980s, and in 2008 began to replace the type with the Airbus A380 as part of its fleet renewal.
Qantas is a founding member of the Oneworld airline alliance, together with American Airlines, British Airways, Cathay Pacific and the defunct Canadian Airlines.
History.
Qantas was founded in Winton, Queensland on 16 November 1920 as Queensland and Northern Territory Aerial Services Limited. The airline's first aircraft was an Avro 504K. The airline flew internationally from May 1935, when it commenced service from Darwin, Northern Territory to Singapore. In June 1959 Qantas entered the jet age when the first Boeing 707-138 was delivered.
Corporate affairs.
Key business trends.
The key trends for the Qantas Group (Qantas Airways Ltd and Controlled Entities), which includes Jetstar and Qantas Cargo, are shown below (as at year ending 30 June):
Headquarters.
Qantas' headquarters are located at the Qantas Centre in the Mascot suburb of the City of Botany Bay, Sydney, New South Wales.
In 1920 Queensland and Northern Territory Aerial Services Ltd had its headquarters in Winton, Queensland. In 1921 the head office moved to Longreach, Queensland. In 1930 the head office moved to Brisbane. In 1957 a head office, Qantas House, opened along Hunter Street in Sydney. In the 1970s a new A$50 million headquarters, consisting of twin skyscrapers, was being built in Sydney and expected to take one city block. The first and largest tower had an expected completion time in 1973.
Aboriginal and Torres Strait Islanders initiatives.
Qantas, through its Aboriginal and Torres Strait Islander Programme, has some links with the Aboriginal Australian community. As of 2007, the company has run the programme for more than ten years and 1–2% of its staff are Aboriginal and Torres Strait Islander. Qantas employs a full-time Diversity Coordinator, who is responsible for the programme.
Qantas has also bought and donated some Aboriginal art. In 1993, the airline bought a painting — "Honey Ant and Grasshopper Dreaming" — from the Central Australian desert region. As of 2007, this painting is on permanent loan to Yiribana at the Art Gallery of New South Wales. In 1996, Qantas donated five extra bark paintings to the gallery. Qantas has also sponsored and supported Aboriginal artists in the past.
Promotional activities.
An early television campaign, starting in 1969 and running for several decades, was aimed at American audiences; it featured a live koala, voiced by Howard Morris, who complained that too many tourists were coming to Australia and concluded "I hate Qantas." The koala ads have been ranked among the greatest commercials of all time. A long-running advertising campaign features renditions by children's choirs of Peter Allen's "I Still Call Australia Home", at various famous landmarks in Australia and foreign locations such as Venice.
Qantas is the main sponsor of the Qantas Wallabies, the Australian national Rugby Union team. It also sponsors the Socceroos, Australia's national association football team. Qantas is the main sponsor for the Formula One Australian Grand Prix. On 26 December 2011, Qantas signed a four-year deal with Australian cricket's governing body Cricket Australia, to be the official carrier of the Australia national cricket team.
Airline subsidiaries.
Qantas has operated a number of passenger airline subsidiaries since inception including: 
Qantas operates a freight service under the name Qantas Freight and also wholly owns the logistics and air freight company Australian air Express.
Predecessors.
Qantas' domestic "mainline" operation was originally established as Trans Australia Airlines in the 1940s and renamed Australian Airlines in 1986. Australian Airlines was bought by Qantas on 14  1992 (1992--).
Fundamental structural change.
The "Qantas Sale Act", under which the airline was privatised, limits foreign ownership of Qantas to 49 percent. Foreign airlines are subject to further restrictions under the "Qantas Sale Act", which stipulates a 35-percent limit for all foreign airline shareholdings combined. In addition, a single foreign entity can hold no more than 25 percent of the airline's shares. This Act was amended in 2014 to repeal parts of paragraph 7. 
In August 2011 the company announced that, due to financial losses and a decline in market share, major structural changes would be made. Up to 1,000 jobs would be lost in Australia, and a new Asia-based premium airline would be set up, operating under a different name. It would also launch a budget airline, called Jetstar Japan, in partnership with Japan Airlines and Mitsubishi Corporation. The change become necessary because of losses in the airline's international operations, due to airlines such as Emirates and Singapore Airlines becoming more competitive and because of the deregulation of Australian international routes during the mid-to-late 1980s. Included in the changes were the cessation of services to London via Hong Kong and Bangkok; Qantas still operated to these cities, but with onward flights to London via its Oneworld partner British Airways under a code-share service.
Qantas is attempting to turn around its international operations, which lost about A$200 million ($209 million) for the year ending June 2011. Therefore, on 26 March 2012, Qantas announced it would set up Jetstar Hong Kong with China Eastern Airlines Corporation, which was intended to begin flights in 2013, but became embroiled in a protracted approval porocess. No budget carrier has a hub at Hong Kong Airport, which had 54 million passengers in 2011.
Due to high fuel prices, intense competition and industrial disputes, Qantas reported a A$245 million full-year loss to the end of June 2012, which was its first loss since Qantas was fully privatised 17 years previously, in 1995, and led to the airline cancelling its order of 35 new Boeing 787 Dreamliner aircraft, to reduce its spending. In focusing on core business, Qantas also divested itself of its 50% holding of StarTrack, Australia's largest road freight company, in part for acquiring full interest in Australian Air Express.
Qantas and Emirates began their alliance on 31 March 2013, in which their combined carriers offered 98 flights per week to Dubai, that saw bookings up six-fold. To accommodate Muslim sensitivities, the airline banned pork from all flights bound to/from Europe, which provoked a backlash on social media. In September that year, following the announcement the carrier expected an A$250 million (US$ million) net loss for the half-year period that ended on 31 December and the implementation of cost-cutting measures that would see the cut of 1,000 jobs within a year, S&P downgraded Qantas credit from BBB- (the lowest investment grade) to BB+, which may imply a rise in borrowing costs and a limitation in the investment potential. Moody's applied a similar downgrading a month later.
The Qantas Group reported a loss of A$235 million (US$ million) for the first half of FY 2014. Cost-cutting measures to save A$2 billion, including the loss of 5,000 jobs that will see the workforce lowered from 32,000 to 27,000 by 2017, were announced in  2014 (2014-). In May 2014 the company said it would have shed 2,200 jobs by June 2014, including those of 100 pilots. The carrier also reduced the size of its fleet by retiring aircraft and deferring deliveries; and planned to sell some of its assets. With 2,200 employees laid off by June 2014, another 1,800 job positions are expected to be cut by June 2015.
New uniform.
Paris-based Australian designer Martin Grant is responsible for the new Qantas airline staff uniforms that were publicly unveiled on 16 April 2013. These were to replace the previous uniforms, dubbed colloquially as "Morrisey" by staff after the designer, Peter Morrissey. Qantas ambassador and model Miranda Kerr assisted with the launch of the new outfits for which the colours of navy blue, red and fuchsia pink are combined. Qantas chief executive Alan Joyce stated that the new design "speaks of Australian style on the global stage" at the launch event that involved Qantas employees modelling the uniforms. Grant consulted with Qantas staff members over the course of one year to finalise the 35 styles that were eventually created. Not all employees were happy with the new uniform, however, with one flight attendant being quoted as saying "The uniforms are really tight and they are simply not practical for the very physical job we have to do."
Destinations.
Qantas flies to 20 domestic destinations and 21 international destinations in 14 countries across Africa, the Americas, Asia, Europe and Oceania excluding the destinations served by its subsidiaries. In the entire Qantas group it serves 65 domestic and 27 international destinations.
Qantas operates flightseeing charters to Antarctica on behalf of Croydon Travel. It first flew Antarctic flightseeing trips in 1977. They were suspended for a number of years due to the crash of Air New Zealand Flight 901 on Mount Erebus in 1979. Qantas restarted the flights in 1994. Although these flights do not touch down, they require specific polar operations and crew training due to factors like sector whiteout, which contributed to the 1979 Air New Zealand disaster.
With new non-stop service from Sydney Airport to Dallas/Fort Worth International Airport aboard the Airbus A380 starting on 29 September 2014, Qantas now operates the world's longest passenger flight on the world's largest passenger aircraft.
Partnerships and codeshare agreements.
Qantas has partnership or codeshare agreements with Oneworld members:
In addition to Oneworld members, Qantas also codeshare agreements with the following airlines:
Fleet.
Current.
As of April 2015 the Qantas mainline fleet consists of the following aircraft:
As of January 2015 Qantas and its subsidiaries operate 284 aircraft, which includes 70 aircraft by Jetstar Airways, 67 by the various QantasLink-branded airlines, 8 by Jetconnect, 12 by Network Aviation and 5 by Express Freighters Australia (on behalf of Qantas Freight, which also wet leases three Atlas Air Boeing 747-400Fs).
On 22 August 2012 Qantas announced that, due to losses and to conserve capital, it had cancelled its 35-aircraft Boeing 787-9 order while keeping the 15-aircraft 787-8 order for Jetstar Airways and moving forward 50 purchase rights.
Aircraft names.
Qantas has named its aircraft since 1926. Themes have included Greek gods, stars, people in Australian aviation history, and Australian birds. Since 1959, the majority of Qantas aircraft have been named after Australian cities. The Airbus A380 series, the flagship of the airline, is named after Australian aviation pioneers, with the first A380 named "Nancy-Bird Walton".
Aircraft liveries.
Aboriginal-themed liveries.
Two Qantas Boeing 737-800s are decorated with Australian Aborigine art schemes designed by Australian Aborigine artists. The first scheme is titled "Yananyi Dreaming" and features a depiction of Uluru. The scheme was designed by Uluru-based artist Rene Kulitja, in collaboration with Balarinji Studio in Adelaide. It was painted on the 737 at the Boeing factory prior to its delivery in 2002.
A second 737-800 in Australian Aborigine art livery, called "Mendoowoorrji", was revealed in November 2013. The design was drawn from the late West Australian Aborigine artist Paddy Bedford.
Two other Australian Aborigine art designs have been displayed on Qantas aircraft. Two Boeing 747s (a -400 and later a -400ER) were adorned in a paint scheme called "Wunala Dreaming". "Wunala Dreaming" was the first Australian Aborigine scheme and was unveiled in 1994. The "motif" was an overall-red design depicting ancestral spirits in the form of kangaroos travelling in the outback. The second design was called "Nalanji Dreaming" and was painted on one of the airline's now-retired Boeing 747-300s in 1995. "Nalanji Dreaming" was a bright blue design inspired by rainforest landscape and tropical seas.
Other liveries.
Several Qantas aircraft have been decorated with promotional liveries, promoting telecommunications company Optus; the Disney motion picture "Planes"; the Australian national association football team, the Socceroos; and the Australian national rugby union team, the Wallabies. Two aircraft—an Airbus A330-200 and a Boeing 747-400—were decorated with special liveries promoting the oneworld airline alliance (of which Qantas is a member) in 2009. On 29 September 2014, nonstop Airbus A380 service to Dallas/Fort Worth International Airport was inaugurated using an A380 decorated with a commemorative cowboy hat and bandana on the Kangaroo tail logo.
In November 2014 the airline revealed that the 75th Boeing 737-838 jet to be delivered would carry a 'retro-livery' based on the airline's 1970s' colour scheme design featuring the iconic 'Flying Kangaroo' on its tail and other aspects drawn from its 1970s' fleet. The aircraft was delivered on 17 November.
Services.
In-flight entertainment.
Qantas has several in-flight entertainment systems installed on its aircraft. Across the fleet, the in-flight experience is referred to as "On:Q". Every Qantas mainline aircraft has some form of video audio entertainment.
"iQ" is featured in all classes of the Airbus A380, as well domestic Airbus A330-200s. It will be implemented on new Boeing 737-800s, and refurbished Boeing 747s when they enter service. This audio video on demand (AVOD) experience is based on the Panasonic Avionics system and features expanded entertainment options, touch screens, new communications related features such as Wi-Fi and mobile phone functionality, as well as increased support for electronics (such as USB and iPod connectivity).
The "Total Entertainment System" by Rockwell Collins is featured on all Boeing 747-400, Airbus A330-300 and international-configuration Airbus A330-200 aircraft. This AVOD system includes personal LCD screens in all classes, located in the seat back for economy and business class, and in the armrest for premium economy and first class.
The Mainscreen System, where video screens are the only available form of video entertainment; movies are shown on the screens for lengthier flights, or TV programmes on shorter flights. A news telecast will usually feature at the start of the flight. Audio options are less varied than on iQ or the Total Entertainment System. The Mainscreen System is installed on all domestic configured Boeing 737-800s delivered before 2011.
Since 2014, Sky News Australia provides multiple news bulletins both in-flight and in Qantas branded lounges. Previously, the Australian Nine Network provided a news bulletin for Qantas entitled "Nine's Qantas Inflight News", which was the same broadcast as Nine's "Early Morning News", however Nine lost the contract to Sky News.
Q Streaming is an in-flight entertainment system in which entertainment is streamed to iPads. It is streamed to iPads available in all classes. A selection of movies, TV, Music, and a kids' choice is available. The passenger has the option of being able to stop, play, pause, fast forward and rewind any of the audio, movie and video content available.
"Qantas The Australian Way" is the airline's in-flight magazine. The magazine ended a 14-year publishing deal with Bauer Media, switching its publisher to Medium Rare from mid-2015.
Boeing's cancellation of the Connexion by Boeing system caused concerns that in-flight internet would not be available on next-generation aircraft such as Qantas' fleet of Airbus A380s. However, Qantas announced in July 2007 that all service classes in its fleet of A380s would have wireless internet access as well as seat-back access to e-mail and cached web browsing. Certain elements would also be retrofitted into existing Boeing 747-400s. The in-flight entertainment system indicates that Internet access is provided by OnAir.
In April 2007, Qantas announced a trial for use of mobile telephones with AeroMobile, during domestic services for three months on a Boeing 767. During the trial, passengers were allowed to send and receive text messages and emails, but were not able to make or receive calls.
Qantas moved from an in-house Passenger Service System known as QUBE (Qantas Universal Business Environment) to an outsourced solution provided by Amadeus in late 2000. In September 2007 Qantas announced a ten-year extension of the outsourcing agreement. In addition to using Amadeus' Altéa platform for reservation and inventory management Qantas extended usage of the system by adopting the departure control module in February 2008.
Cabin.
First class.
First class is offered exclusively on Airbus A380s and some Boeing 747-400s.
It offers 14 individual suites in a 1-1-1 layout. The seats rotate, facing forward for takeoff, but rotating to the side for dining and sleeping, with 83.5 in seat pitch (extending to a 212 cm fully flat bed) and a width of 29 in. Each suite has a 43 cm widescreen HD monitor with 1,000 AVOD programs. In addition to 110 V AC power outlets, USB ports are offered for connectivity. Passengers are also able to make use of the on-board business lounge on the upper deck. Complimentary access to either the first class or business class lounges (or affiliated lounges) is offered.
On the Boeing 747-400, there are 14 flat-bed seats, located on the main deck. The seats are slightly shorter than on the A380, due to their position near the nose of the aircraft: 200 cm versus 212 cm.
Business class.
Business class is offered on all Qantas mainline passenger aircraft.
International Business Class is available on the Boeing 747, International Airbus A330-200s, the A330-300 and the Airbus A380. On the Boeing 747, seating is in a 2-3-2 configuration on the main deck and a 2–2 configuration on the upper deck. The A330 features a 2-2-2 configuration. There are two versions of what Qantas call its "Skybed": the lie flat business class seat. Older versions of the lie-flat Skybeds feature 60 in of seat pitch and 21+1/2 in width, however passengers sleep at a distinct slope to the cabin floor. Later versions of the Skybed have an 80 in pitch, and lie fully horizontal. By 2015, the business class of its entire fleet of Airbus A330 aircraft will be fitted with lie flat seats.
747s and A330s features a 26 cm touchscreen monitor with 400 AVOD programs. Qantas' new international business class product is featured on the Airbus A380. It features 64 fully flat Skybed seats with 80 in seat pitch (converting to a 200 cm long bed). These seats are located on the upper-deck in a 2-2-2 configuration in 2 separate cabins. features include a 30 cm touchscreen monitor with 1,000 AVOD programs and an on-board lounge.
Complimentary access to the Qantas business class lounge (or affiliated lounges) is also offered.
Premium economy class.
Premium economy class is only available on Airbus A380 and all Boeing 747-400 aircraft. It has a seat pitch of 38 in on the Boeing 747 & it range from 38 to on the Airbus A380, with a width of 19+1/2 in. On the Boeing 747, it is configured in a 2-4-2 seating arrangement around the middle of the main deck, whilst it is in a 2-3-2 at the rear of the upper deck on the A380. All A380s have 35 seats.
Qantas premium economy is presented as a lighter business class product rather than most other airlines' premium economy, which is often presented as a higher economy class, however Qantas premium economy does not offer access to premium lounges, and meals are only a slightly uprated version of economy class meals.
Economy class.
Economy class is available on all Qantas mainline passenger aircraft.
Seat pitch is usually 31 in and seat width ranges from 17 to. Layouts are 3–3 on the 737, 2-4-2 on the A330 and 3-4-3 on the 747. On the A380, the layout is 3-4-3 and there are 4 self-service snack bars located in between cabins.
Smartphone support.
Qantas has smartphone application programs ("apps") for Android, iOS and Windows Phone platforms. The iOS apps are separated in to two - one (named Frequent Flyer) for members of its Qantas Frequent Flyer programme to manage their points, while the other (named Qantas) provides mobile check-in and boarding passes to link with Passbook, live flight updates and information on airport lounges, fare sales/alerts, and the ability to book flights and hotels. An Android app was launched on 7 August 2013.
Qantas Frequent Flyer.
The Qantas frequent flyer programme is aimed at rewarding customer loyalty. Points are accrued based on distance flown, with bonuses that vary by travel class. Points can also be earned on other Oneworld airlines as well as through other non-airline partners. Points can be redeemed for flights or upgrades on flights operated by Qantas, Oneworld airlines, and other partners. Other partners include credit cards, car rental companies, hotels and many others. To join the programme, passengers living in Australia or New Zealand pay a one-off joining fee, and then become a Bronze Frequent Flyer (residents of other countries may join without a fee). All accounts remain active as long as there is points activity once every eighteen months. Flights with Qantas and selected partner airlines earn Status Credits — and accumulation of these allows progression to Silver status (Oneworld Ruby), Gold status (Oneworld Sapphire), Platinum and Platinum One status (Oneworld Emerald).
Qantas has faced criticism regarding availability of seats for members redeeming points. In 2004, the Australian Competition and Consumer Commission directed Qantas to provide greater disclosure to members regarding the availability of frequent flyer seats.
In March 2008, an analyst at JPMorgan Chase suggested that the Qantas frequent-flyer program could be worth A$2 billion (US$1.9 billion), representing more than a quarter of the total market value of Qantas.
On 1 July 2008 a major overhaul of the programme was announced. The two key new features of the programme were Any Seat rewards, in which members could now redeem any seat on an aircraft, rather than just selected seats — at a price. The second new feature was Points Plus Pay, which has enabled members to use a combination of cash and points to redeem an award. Additionally, the Frequent Flyer store was also expanded to include a greater range of products and services.
Announcing the revamp, Qantas confirmed it would be seeking to raise about A$1 billion in 2008 by selling up to 40% of the frequent flyer program. However, in September 2008, it stated it would defer the float, citing volatile market conditions.
The Qantas Club.
The Qantas Club is the airline lounge for Qantas with airport locations around Australia and the world. The Qantas Club offers membership by paid subscription (one year, two years or four years) or by achievement of Gold or Platinum frequent flyer status. Benefits of membership include lounge access, priority check-in, priority luggage handling, increased luggage allowances. Some international lounges were upgraded in 2007. New First and Business lounges opened in Bangkok and Los Angeles, along with completely new First Class lounges in Sydney and Melbourne, designed by Marc Newson.
In April 2013, Qantas opened its new flagship Lounge in Singapore, The Qantas Singapore Lounge. This replaced the existing First and Business Class lounges as a result of the new Emirates Alliance. Qantas provides the same service currently offered by Sofitel in its flagship First lounges in Sydney and Melbourne and a dining experience featuring Neil Perry's Spice Temple inspired dishes and signature cocktails.
Lounge access.
Qantas Club Members, Gold Frequent Flyers and Oneworld Sapphire holders are permitted to enter domestic Qantas Clubs when flying on Qantas or Jetstar flights along with one guest who need not be travelling. Platinum and Oneworld Emerald Members are permitted to bring in two guests who do not need to be travelling. Internationally, members use Qantas International Business Class lounges (or the Oneworld equivalent). Guests of the member must be travelling to gain access to international lounges. When flying with American Airlines, members have access to Admirals Club lounges and when flying on British Airways, members have access to British Airways' Terraces and Galleries Lounges.
Platinum Frequent Flyers had previously been able to access The Qantas Club in Australian domestic terminals at any time, regardless of whether they were flying that day. Travellers holding Oneworld Sapphire or Emerald status are also allowed in Qantas Club lounges worldwide.
Airline incidents.
Aircraft incidents and accidents.
It is often claimed, most notably in the 1988 movie "Rain Man", that Qantas has never had an aircraft crash. While it is true that the company has neither lost a jet airliner nor had any jet fatalities, it had eight fatal accidents and an aircraft shot down between 1927 and 1945, with the loss of 63 people. Half of these accidents and the shoot-down occurred during World War II, when the Qantas aircraft were operating on behalf of Allied military forces. Post-war, it lost another two aircraft with the loss of 17 lives. To this date, the last fatal accident suffered by Qantas was in 1951. For this reason, Qantas has been consistently ranked as one of the world's safest airlines.
Since the end of World War II, the following accidents and incidents have occurred:
Extortion attempts.
On 26 May 1971 Qantas received a call from a "Mr. Brown" claiming that there was a bomb planted on a Hong Kong-bound jet and demanding $500,000 in unmarked $20 notes. He was treated seriously when he directed police to an airport locker where a functional bomb was found. Arrangements were made to pick up the money in front of the head office of the airline in the heart of the Sydney business district. Qantas paid the money and it was collected, after which Mr. Brown called again, advising the "bomb on the plane" story was a hoax. The initial pursuit of the perpetrator was bungled by the New South Wales Police Force who, despite having been advised of the matter from the time of the first call, failed to establish adequate surveillance of the pick-up of the money. Directed not to use their radios (for fear of being "overheard"), the police were unable to communicate adequately. Tipped off by a still-unidentified informer, the police arrested an Englishman, Peter Macari, finding more than $138,000 hidden in an Annandale property. Convicted and sentenced to 15 years in prison, Macari served nine years before being deported to Britain. Over $224,000 has still not been found. The 1990 telemovie "Call Me Mr. Brown", directed by Scott Hicks and produced by Terry Jennings, relates to this incident. On 4 July 1997 a copycat extortion attempt was thwarted by police and Qantas security staff.
Sex discrimination controversy.
In November 2005 it was revealed that Qantas has a policy of not seating adult male passengers next to unaccompanied children. This led to accusations of discrimination. The policy came to light following an incident in 2004 when Mark Wolsay, who was seated next to a young boy on a Qantas flight in New Zealand, was asked to change seats with a female passenger. A steward informed him that "it was the airline's policy that only women were allowed to sit next to unaccompanied children". Cameron Murphy of the NSW Council for Civil Liberties president criticised the policy and stated that "there was no basis for the ban". He said it was wrong to assume that all adult males posed a danger to children. The policy has also been criticised for failing to take female abusers into consideration.
In 2010, when British Airways was successfully sued to change its child seating policy, Qantas argued again that banning men from sitting next to unaccompanied children "reflected parents' concerns". In August 2012, the controversy resurfaced when a male passenger had to swap seats with a female passenger after the crew noticed he was sitting next to an unrelated girl travelling alone. The person concerned felt discriminated and humiliated before the flight guests as a paedophile. A Qantas spokesman defended the policy as consistent with that of other airlines in Australia and around the globe.
Price fixing.
A class action lawsuit brought by Maurice Blackburn based in Melbourne, Victoria, alleging price fixing on air cargo freight was commenced in 2006. The lawsuit was settled early in 2011 with Qantas agreeing to pay in excess of $21 million to settle the case.
Qantas has pleaded guilty to participating in a cartel that fixed the price of air cargo. Qantas Airways Ltd. was fined CAD$155,000 after it admitted that its freight division fixed surcharges on cargo exported on certain routes from Canada between May 2002 and February 2006.
In July 2007, Qantas pleaded guilty in the United States to price fixing and was fined a total of $61 million through the Department of Justice investigation. The executive in charge, Bruce McCaffrey was jailed for 6 months. Other Qantas executives were granted immunity after the airline agreed to co-operate with authorities.
In 2008 the Australian Competition and Consumer Commission fined the airline $20 million for breaches of the acts associated with protecting consumers. In November 2010 Qantas was fined 8.8 million Euros for its part in an air cargo cartel involving up to 11 other airlines. Qantas was fined NZ$6.5 million in April 2011 when it pleaded guilty in the New Zealand High Court to the cartel operation.
2011 industrial unrest and grounding of fleet.
In response to ongoing industrial unrest over failed negotiations involving three unions (the Australian Licenced Aircraft Engineers Association (ALAEA), the Australian and International Pilots Association (AIPA) and the Transport Workers Union of Australia (TWU), the company grounded its entire domestic and international fleet from 5 pm AEDT on 29 October. Employees involved would be locked out from 8 p.m. AEDT on 31 October. It was reported that the grounding would have a daily financial impact of A$20 million. In the early hours of 31 October, Fair Work Australia ordered that all industrial action taken by Qantas and the involved trade unions be terminated immediately. The order was requested by the federal government amid fears that an extended period of grounding would do significant damage to the national economy, especially the tourism and mining sectors. It is estimated that the grounding affected 68,000 customers worldwide.

</doc>
<doc id="25256" url="http://en.wikipedia.org/wiki?curid=25256" title="QED (text editor)">
QED (text editor)

QED is a line-oriented computer text editor that was developed by Butler Lampson and L. Peter Deutsch for the Berkeley Timesharing System running on the SDS 940. It was implemented by L. Peter Deutsch and Dana Angluin between 1965 and 1966.
QED (for "quick editor") addressed teleprinter usage, but systems "for CRT displays [were] not considered, since many of their design considerations [were] quite different."
Ken Thompson later wrote a version for CTSS; this version was notable for introducing regular expressions. Thompson rewrote QED in BCPL for Multics. The Multics version was ported to the GE-600 system used at Bell Labs in the late 1960s under GECOS and later GCOS after Honeywell took over GE's computer business. The GECOS-GCOS port used I/O routines written by A. W. Winklehoff. Dennis Ritchie, Ken Thompson and Brian Kernighan wrote the QED manuals used at Bell Labs.
Given that the authors were the primary developers of the Unix operating system, it is natural that QED had a strong influence on the classic UNIX text editors ed, sed and their descendants such as ex and sam, and more distantly AWK and Perl.
A version of QED named FRED (Friendly Editor) was written at the
University of Waterloo for Honeywell systems by Peter Fraser. A University of Toronto team consisting of Tom Duff, Rob Pike, Hugh Redelmeier, and David Tilbrook implemented a version of QED that runs on UNIX; David Tilbrook later included QED as part of his QEF tool set.
QED was also used as a character-oriented editor on the Norwegian-made Norsk Data systems, first Nord TSS then Sintran III. It was implemented for the Nord-1 computer in 1971 by Bo Lewendal who after working with Deutsch and Lampson at Project Genie and at the Berkeley Computer Corporation, had taken a job with Norsk Data (and who developed the Nord TSS later in 1971). 
Further reading.
</dl>

</doc>
<doc id="25257" url="http://en.wikipedia.org/wiki?curid=25257" title="Qusay Hussein">
Qusay Hussein

Qusay Saddam Hussein al-Tikriti (or Qusai, Arabic: قصي صدام حسين‎; (1966--)17 1966 – 22 2003(2003--)) was the second son of Iraqi President Saddam Hussein. He was appointed as his father's heir apparent in 2000.
Family.
Qusay's older brother Uday was viewed as Saddam's heir-apparent until he sustained serious injuries in a 1996 assassination attempt. Unlike Uday, who was known for extravagance and erratic, violent behavior, Qusay Hussein kept a low profile. He was married to Sahar Maher Abd al-Rashid; the daughter of Maher Abd al-Rashid, a top ranking military official, and had three sons; One of the sons, Mustapha Qusay (born 3 January 1989 in Tikrit), was killed alongside his father in the shootout with U.S. troops. The other two – Yahya Qusay (born 1991) and Yaqub Qusay – are presumed alive, but their whereabouts are unknown.
Before the 2003 invasion.
Unlike other members of his family and the government, little information is known about Qusay, politically or personally. It is believed that until the 2003 Invasion of Iraq Qusay was the supervisor of the Iraqi Republican Guard and the head of internal security forces (possibly the Special Security Organization (SSO)), and had authority over other Iraqi military units.
Qusay played a role in crushing the Shiite uprising in the aftermath of the 1991 Gulf War and is also thought to have masterminded the destruction of the southern marshes of Iraq. The wholesale destruction of these marshes ended a centuries-old way of life that prevailed among the Shiite Marsh Arabs who made the wetlands their home, and ruined the habitat for dozens of species of migratory birds. The Iraqi government stated that the action was intended to produce usable farmland, though a number of outsiders believe the destruction was aimed against the Marsh Arabs as retribution for their participation in the 1991 uprising.
Iraqi dissidents claim that Qusay was responsible for the killing of many political activists. "The Sunday Times" reported that Qusay ordered the killing of Khalis Mohsen al-Tikriti, an engineer at the military industrialization organization, because he believed Mohsen was planning to leave Iraq. In 1998, Iraqi opposition groups accused Qusay of ordering the execution of thousands of political prisoners after hundreds of inmates were similarly executed to make room for new prisoners in crowded jails.
Death.
On the afternoon of 22 July 2003, troops of the 101st Airborne 3/327th Infantry HQ and C-Company, aided by U.S. Special Forces killed Qusay, his 14-year-old son Mustapha, and his older brother Uday, during a raid on a home in the northern Iraqi city of Mosul. Acting on a tip from a cousin of Uday and Qusay, a special forces team attempted to apprehend the inhabitants of the house. After being fired on, the special forces moved back and called for backup. As little as 40 101st Soldiers and 8 Task Force 121 operators were on the scene. After Task Force 121 members were wounded the 3/327th Infantry surrounded and fired on the house with a TOW missile, Mark 19 Automatic Grenade Launcher, M2 50 Caliber Machine guns and small arms. After about four hours of battle (the whole operation lasted 6 hours), the soldiers entered the house and found four dead, including the two brothers and their bodyguard. There were reports that Qusay's 14-year-old son Mustapha was the fourth body found. Brig. Gen. Frank Helmick, the assistant commander of 101st Airborne, commented that all occupants of the house died during the fierce gun battle before U.S. troops entered.
On 23 July 2003, the American command said that it had conclusively identified two of the dead men as Saddam Hussein's sons from dental records. Because many Iraqis were skeptical of news of the deaths, the U.S. Government released photos of the corpses and allowed Iraq's governing council to identify the bodies despite the U.S. objection to the publication of American corpses on Arab television. They also announced that the informant, possibly the owner of the house, would receive the combined $30 million reward on the pair. Qusay was the ace of clubs in the coalition forces' most-wanted Iraqi playing cards. His father was the ace of spades and his brother was the ace of hearts.

</doc>
<doc id="25263" url="http://en.wikipedia.org/wiki?curid=25263" title="Quatrain">
Quatrain

A quatrain is a type of stanza, or a complete poem, consisting of four lines.
Existing in various forms, the quatrain appears in poems from the poetic traditions of various ancient civilizations including Ancient Greece, Ancient Rome, and China; and, continues into the 21st century, where it is seen in works published in many languages. During Europe's Dark Ages, in the Middle East and especially Iran, polymath poets such as Omar Khayyam continued to popularize this form of poetry, also known as Ruba'i, well beyond their borders and time. There are twelve possible rhyme schemes, but the most traditional and common are: AAAA, AABB, and ABAB. 

</doc>
<doc id="25264" url="http://en.wikipedia.org/wiki?curid=25264" title="Quantum chromodynamics">
Quantum chromodynamics

In theoretical physics, quantum chromodynamics (QCD) is the theory of strong interactions, a fundamental force describing the interactions between quarks and gluons which make up hadrons such as the proton, neutron and pion. QCD is a type of quantum field theory called a non-abelian gauge theory with symmetry group SU(3). The QCD analog of electric charge is a property called "color". Gluons are the force carrier of the theory, like photons are for the electromagnetic force in quantum electrodynamics. The theory is an important part of the Standard Model of particle physics. A huge body of experimental evidence for QCD has been gathered over the years.
QCD enjoys two peculiar properties:
The phase transition temperature between these two properties has been measured by the ALICE experiment to be around 160 MeV. Below this temperature, confinement is dominant, while above it, asymptotic freedom becomes dominant.
Terminology.
The word "quark" was coined by American physicist Murray Gell-Mann (b. 1929) in its present sense. It originally comes from the phrase "Three quarks for Muster Mark" in "Finnegans Wake" by James Joyce. On June 27, 1978, Gell-Mann wrote a private letter to the editor of the "Oxford English Dictionary", in which he related that he had been influenced by Joyce's words: "The allusion to three quarks seemed perfect." (Originally, only three quarks had been discovered.) Gell-Mann, however, wanted to pronounce the word to rhyme with "fork" rather than with "park", as Joyce seemed to indicate by rhyming words in the vicinity such as "Mark". Gell-Mann got around that "by supposing that one ingredient of the line 'Three quarks for Muster Mark' was a cry of 'Three quarts for Mister ...' heard in H.C. Earwicker's pub", a plausible suggestion given the complex punning in Joyce's novel.
The three kinds of charge in QCD (as opposed to one in quantum electrodynamics or QED) are usually referred to as "color charge" by loose analogy to the three kinds of color (red, green and blue) perceived by humans. Other than this nomenclature, the quantum parameter "color" is completely unrelated to the everyday, familiar phenomenon of color.
Since the theory of electric charge is dubbed "electrodynamics", the Greek word "chroma" Χρώμα (meaning color) is applied to the theory of color charge, "chromodynamics".
History.
With the invention of bubble chambers and spark chambers in the 1950s, experimental particle physics discovered a large and ever-growing number of particles called hadrons. It seemed that such a large number of particles could not all be fundamental. First, the particles were classified by charge and isospin by Eugene Wigner and Werner Heisenberg; then, in 1953, according to strangeness by Murray Gell-Mann and Kazuhiko Nishijima. To gain greater insight, the hadrons were sorted into groups having similar properties and masses using the "eightfold way", invented in 1961 by Gell-Mann and Yuval Ne'eman. Gell-Mann and George Zweig, correcting an earlier approach of Shoichi Sakata, went on to propose in 1963 that the structure of the groups could be explained by the existence of three flavors of smaller particles inside the hadrons: the quarks.
Perhaps the first remark that quarks should possess an additional quantum number was made as a short footnote in the preprint of Boris Struminsky in connection with Ω− hyperon composed of three strange quarks with parallel spins (this situation was peculiar, because since quarks are fermions, such combination is forbidden by the Pauli exclusion principle): Three identical quarks cannot form an antisymmetric S-state. In order to realize an antisymmetric orbital S-state, it is necessary for the quark to have an additional quantum number.
 — B. V. Struminsky, "Magnetic moments of barions in the quark model", JINR-Preprint P-1939, Dubna, Submitted on January 7, 1965 Boris Struminsky was a PhD student of Nikolay Bogolyubov. The problem considered in this preprint was suggested by Nikolay Bogolyubov, who advised Boris Struminsky in this research. In the beginning of 1965, Nikolay Bogolyubov, Boris Struminsky and Albert Tavkhelidze wrote a preprint with a more detailed discussion of the additional quark quantum degree of freedom. This work was also presented by Albert Tavchelidze without obtaining consent of his collaborators for doing so at an international conference in Trieste (Italy), in May 1965.
A similar mysterious situation was with the Δ++ baryon; in the quark model, it is composed of three up quarks with parallel spins. In 1965, Moo-Young Han with Yoichiro Nambu and Oscar W. Greenberg independently resolved the problem by proposing that quarks possess an additional SU(3) gauge degree of freedom, later called color charge. Han and Nambu noted that quarks might interact via an octet of vector gauge bosons: the gluons.
Since free quark searches consistently failed to turn up any evidence for the new particles, and because an elementary particle back then was "defined" as a particle which could be separated and isolated, Gell-Mann often said that quarks were merely convenient mathematical constructs, not real particles. The meaning of this statement was usually clear in context: He meant quarks are confined, but he also was implying that the strong interactions could probably not be fully described by quantum field theory.
Richard Feynman argued that high energy experiments showed quarks are real particles: he called them "partons" (since they were parts of hadrons). By particles, Feynman meant objects which travel along paths, elementary particles in a field theory.
The difference between Feynman's and Gell-Mann's approaches reflected a deep split in the theoretical physics community. Feynman thought the quarks have a distribution of position or momentum, like any other particle, and he (correctly) believed that the diffusion of parton momentum explained diffractive scattering. Although Gell-Mann believed that certain quark charges could be localized, he was open to the possibility that the quarks themselves could not be localized because space and time break down. This was the more radical approach of S-matrix theory.
James Bjorken proposed that pointlike partons would imply certain relations should hold in deep inelastic scattering of electrons and protons, which were spectacularly verified in experiments at SLAC in 1969. This led physicists to abandon the S-matrix approach for the strong interactions.
The discovery of asymptotic freedom in the strong interactions by David Gross, David Politzer and Frank Wilczek allowed physicists to make precise predictions of the results of many high energy experiments using the quantum field theory technique of perturbation theory. Evidence of gluons was discovered in three-jet events at PETRA in 1979. These experiments became more and more precise, culminating in the verification of perturbative QCD at the level of a few percent at the LEP in CERN.
The other side of asymptotic freedom is confinement. Since the force between color charges does not decrease with distance, it is believed that quarks and gluons can never be liberated from hadrons. This aspect of the theory is verified within lattice QCD computations, but is not mathematically proven. One of the Millennium Prize Problems announced by the Clay Mathematics Institute requires a claimant to produce such a proof. Other aspects of non-perturbative QCD are the exploration of phases of quark matter, including the quark–gluon plasma.
The relation between the short-distance particle limit and the confining long-distance limit is one of the topics recently explored using string theory, the modern form of S-matrix theory.
Theory.
Some definitions.
Every field theory of particle physics is based on certain symmetries of nature whose existence is deduced from observations. These can be
QCD is a gauge theory of the SU(3) gauge group obtained by taking the color charge to define a local symmetry.
Since the strong interaction does not discriminate between different flavors of quark, QCD has approximate flavor symmetry, which is broken by the differing masses of the quarks.
There are additional global symmetries whose definitions require the notion of chirality, discrimination between left and right-handed. If the spin of a particle has a positive projection on its direction of motion then it is called left-handed; otherwise, it is right-handed. Chirality and handedness are not the same, but become approximately equivalent at high energies.
Additional remarks: duality.
As mentioned, "asymptotic freedom" means that at large energy – this corresponds also to "short distances" – there is practically no interaction between the particles. This is in contrast – more precisely one would say "dual" – to what one is used to, since usually one connects the absence of interactions with "large" distances. However, as already mentioned in the original paper of Franz Wegner, a solid state theorist who introduced 1971 simple gauge invariant lattice models, the high-temperature behaviour of the "original model", e.g. the strong decay of correlations at large distances, corresponds to the low-temperature behaviour of the (usually ordered!) "dual model", namely the asymptotic decay of non-trivial correlations, e.g. short-range deviations from almost perfect arrangements, for short distances. Here, in contrast to Wegner, we have only the dual model, which is that one described in this article.
Symmetry groups.
The color group SU(3) corresponds to the local symmetry whose gauging gives rise to QCD. The electric charge labels a representation of the local symmetry group U(1) which is gauged to give QED: this is an abelian group. If one considers a version of QCD with "Nf" flavors of massless quarks, then there is a global (chiral) flavor symmetry group SUL("Nf") × SUR("Nf") × UB(1) × UA(1). The chiral symmetry is spontaneously broken by the QCD vacuum to the vector (L+R) SUV("Nf") with the formation of a chiral condensate. The vector symmetry, UB(1) corresponds to the baryon number of quarks and is an exact symmetry. The axial symmetry UA(1) is exact in the classical theory, but broken in the quantum theory, an occurrence called an anomaly. Gluon field configurations called instantons are closely related to this anomaly.
There are two different types of SU(3) symmetry: there is the symmetry that acts on the different colors of quarks, and this is an exact gauge symmetry mediated by the gluons, and there is also a flavor symmetry which rotates different flavors of quarks to each other, or "flavor SU(3)". Flavor SU(3) is an approximate symmetry of the vacuum of QCD, and is not a fundamental symmetry at all. It is an accidental consequence of the small mass of the three lightest quarks.
In the QCD vacuum there are vacuum condensates of all the quarks whose mass is less than the QCD scale. This includes the up and down quarks, and to a lesser extent the strange quark, but not any of the others. The vacuum is symmetric under SU(2) isospin rotations of up and down, and to a lesser extent under rotations of up, down and strange, or full flavor group SU(3), and the observed particles make isospin and SU(3) multiplets.
The approximate flavor symmetries do have associated gauge bosons, observed particles like the rho and the omega, but these particles are nothing like the gluons and they are not massless. They are emergent gauge bosons in an approximate string description of QCD.
Lagrangian.
The dynamics of the quarks and gluons are controlled by the quantum chromodynamics Lagrangian. The gauge invariant QCD Lagrangian is
where formula_1 is the quark field, a dynamical function of spacetime, in the fundamental representation of the SU(3) gauge group, indexed by formula_2; formula_3 are the gluon fields, also dynamical functions of spacetime, in the adjoint representation of the SU(3) gauge group, indexed by "a", "b"... The γμ are Dirac matrices connecting the spinor representation to the vector representation of the Lorentz group.
The symbol formula_4 represents the gauge invariant gluon field strength tensor, analogous to the electromagnetic field strength tensor, "F"μν, in quantum electrodynamics. It is given by:
where "fabc" are the structure constants of SU(3). Note that the rules to move-up or pull-down the "a", "b", or "c" indexes are "trivial", (+, ..., +), so that "fabc" = "fabc" = "f""a""bc" whereas for the "μ" or "ν" indexes one has the non-trivial "relativistic" rules, corresponding e.g. to the metric signature (+ − − −).
The constants "m" and "g" control the quark mass and coupling constants of the theory, subject to renormalization in the full quantum theory.
An important theoretical notion concerning the final term of the above Lagrangian is the "Wilson loop" variable. This loop variable plays a most important role in discretized forms of the QCD (see lattice QCD), and more generally, it distinguishes confined and deconfined states of a gauge theory. It was introduced by the Nobel prize winner Kenneth G. Wilson and is treated in a separate article.
Fields.
Quarks are massive spin-1/2 fermions which carry a color charge whose gauging is the content of QCD. Quarks are represented by Dirac fields in the fundamental representation 3 of the gauge group SU(3). They also carry electric charge (either −1/3 or 2/3) and participate in weak interactions as part of weak isospin doublets. They carry global quantum numbers including the baryon number, which is 1/3 for each quark, hypercharge and one of the flavor quantum numbers.
Gluons are spin-1 bosons which also carry color charges, since they lie in the adjoint representation 8 of SU(3). They have no electric charge, do not participate in the weak interactions, and have no flavor. They lie in the singlet representation 1 of all these symmetry groups.
Every quark has its own antiquark. The charge of each antiquark is exactly the opposite of the corresponding quark.
Dynamics.
According to the rules of quantum field theory, and the associated Feynman diagrams, the above theory gives rise to three basic interactions: a quark may emit (or absorb) a gluon, a gluon may emit (or absorb) a gluon, and two gluons may directly interact. This contrasts with QED, in which only the first kind of interaction occurs, since photons have no charge. Diagrams involving Faddeev–Popov ghosts must be considered too (except in the unitarity gauge).
Area law and confinement.
Detailed computations with the above-mentioned Lagrangian show that the effective potential between a quark and its anti-quark in a meson contains a term formula_6, which represents some kind of "stiffness" of the interaction between the particle and its anti-particle at large 
distances, similar to the entropic elasticity of a rubber band (see below). This leads to "confinement"  of the quarks to the interior of hadrons, i.e. mesons and nucleons, with typical radii Rc, corresponding to former "Bag models" of the hadrons . The order of magnitude of the "bag radius" is 1 fm (= 10−15 m). Moreover, the above-mentioned stiffness is quantitatively related to the so-called "area law" behaviour of the expectation value of the Wilson loop product "PW" of the ordered coupling constants around a closed loop "W"; i.e. formula_7 is proportional to the "area" enclosed by the loop. For this behaviour the non-abelian behaviour of the gauge group is essential.
Methods.
Further analysis of the content of the theory is complicated. Various techniques have been developed to work with QCD. Some of them are discussed briefly below.
Perturbative QCD.
This approach is based on asymptotic freedom, which allows perturbation theory to be used accurately in experiments performed at very high energies. Although limited in scope, this approach has resulted in the most precise tests of QCD to date.
Lattice QCD.
Among non-perturbative approaches to QCD, the most well established one is lattice QCD. This approach uses a discrete set of spacetime points (called the lattice) to reduce the analytically intractable path integrals of the continuum theory to a very difficult numerical computation which is then carried out on supercomputers like the QCDOC which was constructed for precisely this purpose. While it is a slow and resource-intensive approach, it has wide applicability, giving insight into parts of the theory inaccessible by other means, in particular into the explicit forces acting between quarks and antiquarks in a meson. However, the numerical sign problem makes it difficult to use lattice methods to study QCD at high density and low temperature (e.g. nuclear matter or the interior of neutron stars).
1/N expansion.
A well-known approximation scheme, the 1/N expansion, starts from the premise that the number of colors is infinite, and makes a series of corrections to account for the fact that it is not. Until now, it has been the source of qualitative insight rather than a method for quantitative predictions. Modern variants include the AdS/CFT approach.
Effective theories.
For specific problems effective theories may be written down which give qualitatively correct results in certain limits. In the best of cases, these may then be obtained as systematic expansions in some parameter of the QCD Lagrangian. One such effective field theory is chiral perturbation theory or ChiPT, which is the QCD effective theory at low energies. More precisely, it is a low energy expansion based on the spontaneous chiral symmetry breaking of QCD, which is an exact symmetry when quark masses are equal to zero, but for the u,d and s quark, which have small mass, it is still a good approximate symmetry. Depending on the number of quarks which are treated as light, one uses either SU(2) ChiPT or SU(3) ChiPT . Other effective theories are heavy quark effective theory (which expands around heavy quark mass near infinity), and soft-collinear effective theory (which expands around large ratios of energy scales). In addition to effective theories, models like the Nambu–Jona-Lasinio model and the chiral model are often used when discussing general features.
QCD sum rules.
Based on an Operator product expansion one can derive sets of relations that connect different observables with each other.
Nambu–Jona-Lasinio model.
In one of his recent works, Kei-Ichi Kondo derived as a low-energy limit of QCD, a theory linked to the Nambu–Jona-Lasinio model since it is basically a particular non-local version of the Polyakov–Nambu–Jona-Lasinio model. The later being in its local version, nothing but the Nambu–Jona-Lasinio model in which one has included the Polyakov loop effect, in order to describe a 'certain confinement'.
The Nambu–Jona-Lasinio model in itself is, among many other things, used because it is a 'relatively simple' model of chiral symmetry breaking, phenomenon present up to certain conditions (Chiral limit i.e. massless fermions) in QCD itself.
In this model, however, there is no confinement. In particular, the energy of an isolated quark in the physical vacuum turns out well defined and finite.
Experimental tests.
The notion of quark flavors was prompted by the necessity of explaining the properties of hadrons during the development of the quark model. The notion of color was necessitated by the puzzle of the #redirect . This has been dealt with in the section on the history of QCD.
The first evidence for quarks as real constituent elements of hadrons was obtained in deep inelastic scattering experiments at SLAC. The first evidence for gluons came in three jet events at PETRA.
Several good quantitative tests of perturbative QCD exist:
Quantitative tests of non-perturbative QCD are fewer, because the predictions are harder to make. The best is probably the running of the QCD coupling as probed through lattice computations of heavy-quarkonium spectra. There is a recent claim about the mass of the heavy meson Bc . Other non-perturbative tests are currently at the level of 5% at best. Continuing work on masses and form factors of hadrons and their weak matrix elements are promising candidates for future quantitative tests. The whole subject of quark matter and the quark–gluon plasma is a non-perturbative test bed for QCD which still remains to be properly exploited.
One qualitative prediction of QCD is that there exist composite particles made solely of gluons called glueballs that have not yet been definitively observed experimentally. A definitive observation of a glueball with the properties predicted by QCD would strongly confirm the theory. In principle, if glueballs could be definitively ruled out, this would be a serious experimental blow to QCD. But, as of 2013, scientists are unable to confirm or deny the existence of glueballs definitively, despite the fact that particle accelerators have sufficient energy to generate them.
Cross-relations to solid state physics.
There are unexpected cross-relations to solid state physics. For example, the notion of gauge invariance forms the basis of the well-known Mattis spin glasses, which are systems with the usual spin degrees of freedom formula_8 for "i" =1...,N, with the special fixed "random" couplings formula_9 Here the εi and εk quantities can independently and "randomly" take the values ±1, which corresponds to a most-simple gauge transformation formula_10 This means that thermodynamic expectation values of measurable quantities, e.g. of the energy formula_11 are invariant.
However, here the "coupling degrees of freedom" formula_12, which in the QCD correspond to the "gluons", are "frozen" to fixed values (quenching). In contrast, in the QCD they "fluctuate" (annealing), and through the large number of gauge degrees of freedom the entropy plays an important role (see below).
For positive "J"0 the thermodynamics of the Mattis spin glass corresponds in fact simply to a "ferromagnet in disguise", just because these systems have no "frustration" at all. This term is a basic measure in spin glass theory. Quantitatively it is identical with the loop product formula_13 along a closed loop "W". However, for a Mattis spin glass – in contrast to "genuine" spin glasses – the quantity "PW" never becomes negative.
The basic notion "frustration" of the spin-glass is actually similar to the Wilson loop quantity of the QCD. The only difference is again that in the QCD one is dealing with SU(3) matrices, and that one is dealing with a "fluctuating" quantity. Energetically, perfect absence of frustration should be non-favorable and atypical for a spin glass, which means that one should add the loop product to the Hamiltonian, by some kind of term representing a "punishment". In the QCD the Wilson loop is essential for the Lagrangian rightaway.
The relation between the QCD and "disordered magnetic systems" (the spin glasses belong to them) were additionally stressed in a paper by Fradkin, Huberman und Shenker, which also stresses the notion of duality.
A further analogy consists in the already mentioned similarity to polymer physics, where, analogously to Wilson Loops, so-called "entangled nets" appear, which are important for the formation of the entropy-elasticity (force proportional to the length) of a rubber band. The non-abelian character of the SU(3) corresponds thereby to the non-trivial "chemical links", which glue different loop segments together, and "asymptotic freedom" means in the polymer analogy simply the fact that in the short-wave limit, i.e. for formula_14 (where "Rc" is a characteristic correlation length for the glued loops, corresponding to the above-mentioned "bag radius", while λw is the wavelength of an excitation) any non-trivial correlation vanishes totally, as if the system had crystallized.
There is also a correspondence between confinement in QCD – the fact that the color field is only different from zero in the interior of hadrons – and the behaviour of the usual magnetic field in the theory of type-II superconductors: there the magnetism is confined to the interiour of the Abrikosov flux-line lattice,   i.e., the London penetration depth "λ" of that theory is analogous to the confinement radius "Rc" of quantum chromodynamics. Mathematically, this correspondendence is supported by the second term, formula_15 on the r.h.s. of the Lagrangian.

</doc>
<doc id="25265" url="http://en.wikipedia.org/wiki?curid=25265" title="Queue (abstract data type)">
Queue (abstract data type)

In computer science, a queue ( ) is a particular kind of abstract data type or collection in which the entities in the collection are kept in order and the principal (or only) operations on the collection are the addition of entities to the rear terminal position, known as "enqueue," and removal of entities from the front terminal position, known as "dequeue". This makes the queue a First-In-First-Out (FIFO) data structure. In a FIFO data structure, the first element added to the queue will be the first one to be removed. This is equivalent to the requirement that once a new element is added, all elements that were added before have to be removed before the new element can be removed. Often a "peek" or "front" operation is also entered, returning the value of the front element without dequeuing it. A queue is an example of a linear data structure, or more abstractly a sequential collection.
Queues provide services in computer science, transport, and operations research where various entities such as data, objects, persons, or events are stored and held to be processed later. In these contexts, the queue performs the function of a buffer.
Queues are common in computer programs, where they are implemented as data structures coupled with access routines, as an abstract data structure or in object-oriented languages as classes. Common implementations are circular buffers and linked lists.
Queue implementation.
Theoretically, one characteristic of a queue is that it does not have a specific capacity. Regardless of how many elements are already contained, a new element can always be added. It can also be empty, at which point removing an element will be impossible until a new element has been added again.
Fixed length arrays are limited in capacity, but it is not true that items need to be copied towards the head of the queue. The simple trick of turning the array into a closed circle and letting the head and tail drift around endlessly in that circle makes it unnecessary to ever move items stored in the array. If n is the size of the array, then computing indices modulo n will turn the array into a circle. This is still the conceptually simplest way to construct a queue in a high level language, but it does admittedly slow things down a little, because the array indices must be compared to zero and the array size, which is comparable to the time taken to check whether an array index is out of bounds, which some languages do, but this will certainly be the method of choice for a quick and dirty implementation, or for any high level language that does not have pointer syntax. The array size must be declared ahead of time, but some implementations simply double the declared array size when overflow occurs. Most modern languages with objects or pointers can implement or come with libraries for dynamic lists. Such data structures may have not specified fixed capacity limit besides memory constraints. Queue "overflow" results from trying to add an element onto a full queue and queue "underflow" happens when trying to remove an element from an empty queue.
A "bounded queue" is a queue limited to a fixed number of items.
There are several efficient implementations of FIFO queues. An efficient implementation is one that can perform the operations—enqueuing and dequeuing—in O(1) time.
Queues and programming languages.
Queues may be implemented as a separate data type, or may be considered a special case of a double-ended queue (deque) and not implemented separately. For example, Perl and Ruby allow pushing and popping an array from both ends, so one can use push and shift functions to enqueue and dequeue a list (or, in reverse, one can use unshift and pop), although in some cases these operations are not efficient.
C++'s Standard Template Library provides a "codice_1" templated class which is restricted to only push/pop operations. Since J2SE5.0, Java's library contains a interface that specifies queue operations; implementing classes include and (since J2SE 1.6) . PHP has an class and third party libraries like beanstalk'd and Gearman.
Examples.
A simple queue implemented in Ruby:

</doc>
<doc id="25266" url="http://en.wikipedia.org/wiki?curid=25266" title="Quake (video game)">
Quake (video game)

Quake is a first-person shooter video game, developed by id Software and published by GT Interactive in 1996 and featured music composed by Trent Reznor and Nine Inch Nails. It is the first game in the popular "Quake" series. In the game, players must find their way through various maze-like, medieval environments while battling a variety of monsters using a wide array of weapons.
The successor to id's "Doom" series, "Quake" built upon the technology and gameplay of its predecessor in many ways. Unlike the "Doom" engine before it, the "Quake" engine offered full real-time 3D rendering and early support for 3D acceleration through OpenGL. After "Doom" helped popularize multiplayer deathmatches, "Quake" added various multiplayer options. Online multiplayer became increasingly common, with the QuakeWorld update and software such as QuakeSpy making the process of finding and playing against other competitors on the Internet far easier and more reliable.
Gameplay.
In "Quake"‍‍ '​‍s single player mode, players explore and navigate to the exit of each dark and Gothic level, facing monsters and secret areas along the way. Usually there are buttons to press or keys to collect in order to open doors before the exit can be reached. Reaching the exit takes the player to the next level. Before the start level, there is a set of three pathways with easy, medium, and hard skill levels. The fourth skill level, "Nightmare", was "so bad that it was hidden, so people won't wander in by accident";) the player must drop through the water before the Episode 4 entrance and jump into a secret passage.
"Quake"‍‍ '​‍s single-player campaign is organized into four individual "episodes" of about eight levels each (each including a secret level, one of which is a "low gravity" level that challenges the player's abilities in a different way). As items are collected, they are carried to the next level, each usually more challenging than the last. If the player's avatar dies, he must restart at the beginning of the level. Games may be saved at any time. Upon completing each episode, the player is returned to the hub "Start" level, where another episode can be entered. Each episode starts the player from scratch, without any previously collected items. Episode I (which formed the shareware or downloadable demo version of "Quake") has the most traditional ideology of a boss in the last level. The ultimate objective at the end of an episode is to recover a magic rune. After all of the runes are collected, the floor of the "Start" opens up to reveal an entrance to the "End" level which contains the final boss.
Multiplayer.
In multiplayer mode, players on several computers connect to a server (which may be a dedicated machine or on one of the player's computers), where they can either play the single-player campaign together in co-op mode, or play against each other in multiplayer. When players die in multiplayer mode, they can immediately respawn but lose any items that were collected. Similarly, items that have been picked up previously respawn after some time, and may be picked up again. The most popular multiplayer modes are all forms of deathmatch. Deathmatch modes typically consist of either "free-for-all" (no organization or teams involved), one-on-one "duels", or organized "teamplay" with two or more players per team (or clan). Teamplay is also frequently played with one or another mod. Monsters are not normally present in teamplay, as they serve no purpose other than to get in the way and reveal the positions of the players.
The gameplay in "Quake" was considered unique for its time because of the different ways the player can maneuver through the game. For example: bunny hopping or strafe jumping can be used to move faster than normal, while rocket jumping enables the player to reach otherwise-inaccessible areas at the cost of some self-damage. The player can start and stop moving suddenly, jump unnaturally high, and change direction while moving through the air. Many of these non-realistic behaviors contribute to "Quake"‍‍ '​‍s appeal. Multiplayer "Quake" was one of the first games singled out as a form of electronic sport. A notable participant was Dennis Fong who won John Carmack's Ferrari 328 at the Microsoft-sponsored Red Annihilation tournament in 1997.
Plot.
In the single-player game, the player takes the role of a protagonist known as Ranger who was sent into a portal in order to stop an enemy code-named "Quake". The government had been experimenting with teleportation technology and developed a working prototype called a "Slipgate"; the mysterious Quake compromised the Slipgate by connecting it with its own teleportation system, using it to send death squads to the "Human" dimension in order to test the martial capabilities of Humanity.
The sole surviving protagonist in "Operation Counterstrike" is Ranger, who must advance, starting each of four episodes from an overrun human military base, before fighting his way into other dimensions, reaching them via the Slipgate or their otherworld equivalent. After passing through the Slipgate, Ranger's main objective is to collect four magic runes from four dimensions of Quake; these are the key to stopping the enemy later discovered as Shub-Niggurath and ending the invasion of Earth.
The game consists of 28 separate "levels" or "maps", grouped into four episodes. Each episode represents individual dimensions that the player can access through magical portals (as opposed to the technological Slipgate) that are discovered over the course of the game. The various realms consist of a number of gothic, medieval, and lava-filled caves and dungeons, with a recurring theme of hellish and satanic imagery reminiscent of "Doom" (such as pentagrams and images of demons on the walls). The latter is inspired by several dark fantasy influences, most notably that of H. P. Lovecraft. Dimensional Shamblers appear as enemies, the "Spawn" enemies are called "Formless Spawn of Tsathoggua" in the manual, the end boss of the first episode is named Chthon, and the final boss is named Shub-Niggurath (though actually resembling a Dark Young). Some levels have Lovecraftian names, such as the Vaults of Zin and The Nameless City. Originally, the game was supposed to include more Lovecraftian bosses, but this concept was scrapped due to time constraints.
Development.
A preview included with id's very first release, 1990's "Commander Keen", advertised a game entitled "The Fight for Justice" as a follow-up to the Keen trilogy. It would feature a character named Quake, "the strongest, most dangerous person on the continent", armed with thunderbolts and a "Ring of Regeneration." Conceived as a VGA full-color side-scrolling role-playing video game, "The Fight for Justice" was never released.
"Quake" was programmed by John Carmack, Michael Abrash and John Cash. The level and scenarios were designed by American McGee, Sandy Petersen, John Romero and Tim Willits.
The graphics were designed by Adrian Carmack, Kevin Cloud and some enemies design are inspired from HP Lovecraft stories. 
Music and sound design was by Trent Reznor, founder of Nine Inch Nails, using ambient soundscapes and synthezised drones to create atmospheric tracks. The game also have ammo boxes decorated with the Nine Inch Nails logo. 
The game engine developed for "Quake", the Quake engine, popularized several major advances in the 3D game genre: polygonal models instead of prerendered sprites; full 3D level design instead of a 2.5D map; prerendered lightmaps; and allowing end users to partially program the game (in this case with QuakeC), which popularized fan-created modifications (mods).
"Quake" was given as a title to the game that id Software was working on shortly after the release of "Doom II". The earliest information released described "Quake" as focusing on a Thor-like character who wields a giant hammer, and is able to knock away enemies by throwing the hammer (complete with real-time inverse kinematics). Initially, the levels were supposed to be designed in an Aztec style, but the choice was dropped some months into the project. Early screenshots then showed medieval environments and dragons. The plan was for the game to have more RPG-style elements. However, work was very slow on the engine, since John Carmack, the main programmer of Quake, was not only developing a full 3D engine, but also a TCP/IP networking model. (Carmack later said that he should have done two separate projects which developed those things.) Eventually, the whole id team began to think that the original concept may not have been as wise a choice as they first believed. Thus, the final game was very stripped down from its original intentions, and instead featured gameplay similar to "Doom" and its sequel, although levels and enemies were closer to medieval RPG style rather than science-fiction.
Before the release of the game or the demo of the game, id software released "QTest" on February 24, 1996. It was described as a technology demo and was limited to three multiplayer maps. There was no single player support and some of the gameplay and graphics were unfinished or different from their final versions. QTest also gave gamers their first peek into the filesystem and modifiability of the Quake engine, and many entity mods (that placed monsters in the otherwise empty multiplayer maps) and custom player skins began appearing online before the full game was even released.
Ports.
The first ports to be completed were the Linux and SPARC Solaris ports by id Software employee Dave D. Taylor in 1996. The first commercially released port was the 1997 port to Mac OS, done by MacSoft. Finally in 1999, a retail version of the Linux port was distributed by Macmillan Digital Publishing USA in a bundle with the three add-ons as "Quake: The Offering".
"Quake" was also ported to console systems. In 1997, it was ported to the Sega Saturn by Lobotomy Software. The Saturn port used Lobotomy's own "SlaveDriver" engine (the same engine that powers the Saturn ports of "Duke Nukem 3D" and "PowerSlave") instead of the original Quake engine. It is the only version of "Quake" that is rated "T" for Teen instead of "M" for Mature. A Sony PlayStation version of the game had been planned by Lobotomy Software, but was cancelled. In 1998, "Quake" was ported to the Nintendo 64 by Midway Games. Both console ports required some compromises because of the limited CPU power and ROM storage space for maps. The Saturn version has most of the maps from the original PC version of the game, though the secret levels (Ziggurat Vertigo (E1M8), The Underearth (E2M7), The Haunted Halls (E3M7) and The Nameless City (E4M8)) didn't make the cut. Instead, it has four exclusive maps: Purgatorium, Hell's Aerie, The Coliseum and Watery Grave. There are no multiplayer modes in the Saturn version; as a result of this, all of the deathmatch maps from the PC version were removed from the Saturn port. The N64 version is missing The Grisly Grotto (E1M4), The Installation (E2M1), The Ebon Fortress (E2M4), The Wind Tunnels (E3M5), The Sewage System (E4M1) and Hell's Atrium (E4M5) levels. It also does not use the "START" map where the player chooses a difficulty level and an episode; the difficulty level is chosen when starting the game, and all of the levels play in sequential order from The Slipgate Complex (E1M1) to Shub Niggurath's Pit (END). The Nintendo 64 version, while lacking the cooperative multiplayer mode, includes two player deathmatch. All six of the deathmatch maps from the PC version are in the Nintendo 64 port, and an exclusive deathmatch map, The Court of Death, is also included.
Two ports of "Quake" for the Nintendo DS exist, "QuakeDS" and "CQuake". Both run well, however multiplayer does not work on "QuakeDS". Since the source code for Quake was released a number of unofficial ports have been made available for PDAs and mobile phones, such as PocketQuake, as well as versions for the Symbian S60 series of mobile phones and Android mobile phones.
In 2005, id Software signed a deal with publisher Pulse Interactive to release a version of "Quake" for mobile phones. The game was engineered by Californian company . Initially due to be released on only two mobile phones, the Samsung Nexus (for which it was to be an embedded game) and the LG VX360. Quake mobile was reviewed by GameSpot on the Samsung Nexus and they cited its US release as October 2005; they also gave it a "Best Mobile Game" in their E3 2005 Editor's Choice Awards. "It is unclear as to whether the game actually did ship with the Samsung Nexus. The game is only available for the DELL x50v and x51v both of which are PDAs not mobile phones. "Quake Mobile" does not feature the Nine Inch Nails soundtrack due to space constraints. "Quake Mobile" runs the most recent version of GL Quake (Quake v.1.09 GL 1.00) at 800x600 resolution and 25 fps. The most recent version of "Quake Mobile" is v.1.20 which has stylus support. There was an earlier version v.1.19 which lacked stylus support. The two "Quake" expansion packs "Scourge of Armagon" and "Dissolution of Eternity" are also available for "Quake Mobile". The game is available for download at as are both expansions.
A Flash-based version of the game by Michael Rennie runs Quake at full speed in any Flash-enabled web browser. Based on the shareware version of the game, it includes only the first episode and is available for free on the web.
The game has also been ported to the PlayStation Portable (PSP), with multiplayer options and the ability to load maps and mods, and has inspired homebrew like "Kurok", a mix of "" and "GoldenEye 64", and "Left 4 Quake", a fan-made "Left 4 Dead" in "Quake".
Mods and add-ons.
"Quake" can be heavily modified by altering the sounds, graphics, or scripting in QuakeC, and has been the focus of many fan "mods". The first mods were small gameplay fixes and patches initiated by the community, usually enhancements to weapons or gameplay with some new foes. Later mods were more ambitious and resulted in "Quake" fans creating versions of the game that were drastically different from id Software's original release.
The first major "Quake" mod was "Team Fortress". This mod consists of Capture the Flag gameplay, but with a class system for the players. Players choose a class, which creates various restrictions on weapons and armor types available to that player, and also grants special abilities. For example, the bread-and-butter "Soldier" class has medium armor, medium speed, and a well-rounded selection of weapons and grenades, while the "Scout" class is lightly armored, very fast, has a scanner that detects nearby enemies, but has very weak offensive weapons. One of the other differences with CTF is the fact that the flag is not returned automatically when a player drops it: running over one's flag in "Threewave CTF" would return the flag to the base, and in "TF" the flag remains in the same spot for preconfigured time and it has to be defended on remote locations. This caused a shift in defensive tactics compared to "Threewave CTF". "Team Fortress" maintained its standing as the most-played online modification of "Quake" for many years.
Another popular mod was "Threewave Capture the Flag" (CTF), primarily authored by Dave 'Zoid' Kirsch. "Threewave CTF" is a partial conversion consisting of new maps, a new weapon (a grappling hook), power-ups, some new textures and new rules of game play. Typically, two teams (red and blue) would compete in a game of Capture the flag, though a few maps with up to four teams (red, blue, green, and yellow) were created. Capture the Flag has become a standard game mode included in most popular multiplayer games released after "Quake", in addition to Deathmatch first introduced in "Doom". "Rocket Arena" provides the ability for players to face each other in small, open arenas with changes in the gameplay rules so that item collection and detailed level knowledge are no longer factors. A series of short rounds, with the surviving player in each round gaining a point, instead tests the player's aiming and dodging skills and reflexes. "Clan Arena" is a further modification that provides team play using "Rocket Arena" rules. One category of mod, "bots", were introduced to provide surrogate players in multiplayer mode.
There are a large number of custom maps that have been made by users and fans of "Quake". s of 2008[ [update]], new maps are still being made, over fifteen years since the game's release. Custom maps are new maps that are playable by simply loading them into the original game. Custom maps of all gameplay types have been made, but most are in the single-player and deathmatch genres. More than 1500 single-player and a similar number of deathmatch maps have been made for "Quake". There has also been some changes from Quake 1 to Quake 64 in the levels.
E1M1The Slipgate Complex: 5 secrets instead of 6
E1M2 Castle of the Damned: No crates at start
E1M3 The Necropolis: in secret #3 there is a shootable wall that takes you to E1M8 Ziggurat Vertigo
E1M4 The Grisly Grotto: this level does not exist in this version
E1M8 Ziggurat Vertigo: there is no 2nd 100 health in second part of level
Reception.
"Quake" received positive reviews. Aggregating review websites GameRankings and Metacritic gave the PC version 93.22% and 94/100, the Nintendo 64 version 76.14% and 74/100 and the Sega Saturn version 64.50%.
Speedruns.
As an example of the dedication that "Quake" has inspired in its fan community, a group of expert players recorded speedrun demos (replayable recordings of the player's movement) of "Quake" levels completed in record time on the "Nightmare" skill level. The footage was edited into a continuous 19 minutes, 49 seconds demo called "Quake done Quick" and released on June 10, 1997. Owners of the game could replay this demo in the game engine, watching the run unfold as if they were playing it themselves.
This involved a number of players recording run-throughs of individual levels, using every trick and shortcut they could discover in order to minimize the time it took to complete, usually to a degree that even the original level designers found difficult to comprehend, and in a manner that often bypassed large areas of the level. Stitching a series of the fastest runs together into a coherent whole created a demonstration of the entire game. "Recamming" is also used with speedruns in order to make the experience more movie-like, with arbitrary control of camera angles, editing, and sound that can be applied with editing software after the runs are first recorded. However, the fastest possible time for a given level will not necessarily result in the fastest time used to contribute to "running" the entire game. One example is acquiring the grenade launcher in an early level, an act that slows down the time for that level over the best possible, but speeds up the overall game time by allowing the runner to bypass a big area in a later level that they could not otherwise do.
A second attempt, "Quake done Quicker", reduced the complete time to 16 minutes, 35 seconds (a reduction of 3 minutes, 14 seconds). "Quake done Quicker" was released September 13, 1997. One of the levels included was the result of an online competition to see who could get the fastest time. The culmination of this process of improvement was "Quake done Quick with a Vengeance". Released three years to the day after "Quake done Quicker", this pared down the time taken to complete all four episodes, on Nightmare (hardest) difficulty, to 12 minutes, 23 seconds (a further reduction of 4 minutes, 12 seconds), partly by using techniques that had formerly been shunned in such films as being less aesthetically pleasing. This run was recorded as an in-game demo but interest was such that an .avi video clip was created to allow those without the game to see the run.
Most full-game speedruns are a collaborative effort by a number of runners (though some have been done by single runners on their own). Although each particular level is credited to one runner, the ideas and techniques used are iterative and collaborative in nature, with each runner picking up tips and ideas from the others, so that speeds keep improving beyond what was thought possible as the runs are further optimized and new tricks or routes are discovered. Further time improvements of the continuous whole game run were achieved into the 21st century. In addition, many thousands of individual level runs are kept at Speed Demos Archive's "Quake" section, including many on custom maps. Speedrunning is a counterpart to multiplayer modes in making "Quake" one of the first games promoted as a virtual "sport".
Legacy.
The source code of the "Quake" and "QuakeWorld" engines was licensed under the GPL in 1999. The id Software maps, objects, textures, sounds and other creative works remain under their original license. The shareware distribution of "Quake" is still freely redistributable and usable with the GPLed engine code. One must purchase a copy of "Quake" in order to receive the registered version of the game which includes more single player episodes and the deathmatch maps. Based on the success of the first "Quake" game, id later published "Quake II" and "Quake III Arena"; "Quake 4" was released in October 2005, developed by Raven Software using the "Doom 3" engine.
"Quake" was the game primarily responsible for the emergence of the machinima artform of films made in game engines, thanks to edited "Quake" demos such as "Ranger Gone Bad" and "Blahbalicious", the in-game film "The Devil's Covenant" and the in-game-rendered, four-hour epic film "The Seal of Nehahra". On June 22, 2006, it had been 10 years since the original uploading of the game to cdrom.com archives. Many Internet forums had topics about it, and it was a front page story on Slashdot. On October 11, 2006, John Romero released the original map files for all of the levels in "Quake" under the GPL.
"Quake" and its four sequels, "Quake II", "Quake III Arena", "Quake 4", and "" have sold over 4 million copies combined. In 2002, a version of "Quake" was produced for mobile phones. A copy of "Quake" was also sold in 2001, labeled "Ultimate Quake", which included the original "Quake", "Quake II", and "Quake III Arena". In 2008 "Quake" was honored at the 59th Annual Technology & Engineering Emmy Awards for advancing the art form of user modifiable games. John Carmack accepted the award. The band Quake from Illinois used the video game as their band name. Years after its original release, "Quake" is still regarded by many critics as one of the greatest and most influential games ever made.
Expansions.
There have been two official expansion packs for "Quake". The expansion packs pick up where the first game left off, use all of the same weapons, power-ups, and monsters, and gothic atmosphere/architecture and continue/finish the story of the first game and its protagonist. A third unofficial expansion pack, "Final Mission: Abyss of Pandemonium", was developed by the Impel Development Team.
Quake Mission Pack No. 1: Scourge of Armagon.
"Quake Mission Pack No. 1: Scourge of Armagon" was the first official mission pack, released on February 28, 1997. Developed by Hipnotic Interactive, it features fifteen new single player levels, a new multiplayer level, and gameplay features not originally present in Quake, including rotating structures and breakable walls. New enemies include Centroids, large cybernetic scorpions with nailguns; Gremlins, small goblins that can steal weapons and multiply by feeding on enemy corpses; and Spike Mines, floating orbs that detonate when near the player. New weapons include the Mjolnir, a large lightning emitting hammer; the Laser Cannon, which shoots bouncing bolts of energy; and the Proximity Mine Launcher, which fires grenades that attach to surfaces and detonate when an opponent comes near. The storyline follows Armagon, a general of Quake's forces, planning to invade Earth via a portal known as the 'Rift'. Armagon resembles a giant gremlin with cybernetic legs and a combined rocket launcher/laser cannon for arms.
Quake Mission Pack No. 2: Dissolution of Eternity.
"Quake Mission Pack No. 2: Dissolution of Eternity" was the second official mission pack, released on March 31, 1997. Developed by Rogue Entertainment, it features sixteen new single player levels as well as several new enemies and bosses. New enemies include Electric Eels, Phantom Swordsmen, Multi-Grenade Ogres (which fire cluster grenades), Hell Spawn, Wraths (floating, robed undead), Guardians (resurrected ancient Egyptian warriors), Mummies, and statues of various enemies that come to life. New bosses include Lava Men, Overlords, large Wraths, and a dragon guarding the "temporal energy converter". Rather than offering new weapons, the mission pack gave the player new ammo for already existing weapons, such as "lava nails" for the Nailgun, cluster grenades, rockets that split into four in a horizontal line, plasma cells, and a grappling hook to help with moving around the map.
VQuake.
In late 1996, id Software released "VQuake", a port of the "Quake" engine to support hardware accelerated rendering on graphics cards using Rendition Vérité chipset. Aside from the expected benefit of improved performance, "VQuake" offered numerous visual improvements over the original software-rendered "Quake". It boasted full 16-bit color, bilinear filtering (reducing pixelation), improved dynamic lighting, optional anti-aliasing and even improved source code clarity, as the improved performance finally allowed the use of gotos to be abandoned in favor of proper loop constructs. As the name implied, "VQuake" was a proprietary port specifically for the Vérité; consumer 3D acceleration was in its infancy at the time, and there was no standard 3D API for the consumer market. After completing "VQuake", John Carmack vowed never to write a proprietary port again, citing his frustration with Rendition's Speedy3D API.
QuakeWorld.
To improve the quality of online play, id Software released "QuakeWorld" on December 17, 1996, a build of "Quake" that featured significantly revamped network code including the addition of client-side prediction. The original "Quake"‍‍ '​‍s network code would not show the player the results of his actions until the server sent back a reply acknowledging them. For example, if the player attempted to move forward, his client would send the request to move forward to the server, and the server would determine whether the client was actually able to move forward or if he ran into an obstacle, such as a wall or another player. The server would then respond to the client, and only then would the client display movement to the player. This was fine for play on a LAN—a high bandwidth, very low latency connection. But the latency over a dial-up Internet connection is much larger than on a LAN, and this caused a noticeable delay between when a player tried to act and when that action was visible on the screen. This made gameplay much more difficult, especially since the unpredictable nature of the Internet made the amount of delay vary from moment to moment. Players would experience jerky, laggy motion that sometimes felt like ice skating, where they would slide around with seemingly no ability to stop, due to a build-up of previously-sent movement requests. John Carmack has admitted that this was a serious problem which should have been fixed before release, but it was not caught because he and other developers had high-speed Internet access at home.
With the help of client-side prediction, which allowed players to see their own movement immediately without waiting for a response from the server, "QuakeWorld"‍‍ '​‍s network code allowed players with high-latency connections to control their character's movement almost as precisely as when playing in single-player mode. The Netcode parameters could be adjusted by the user, so that "QuakeWorld" performed well for users with high and low latency.
The tradeoff to client-side prediction was that sometimes other players or objects would no longer be quite where they had appeared to be, or, in extreme cases, that the player would be pulled back to a previous position when the client received a late reply from the server which overrode movement the client had already previewed; this was known as "warping". As a result, some serious players, particularly in the USA, still preferred to play online using the original "Quake" engine (commonly called "NetQuake") rather than "QuakeWorld". However, the majority of players, especially those on dial-up connections, preferred the newer network model, and "QuakeWorld" soon became the dominant form of online play. Following the success of "QuakeWorld", client-side prediction has become a standard feature of nearly all real-time online games. As with all other "Quake" upgrades, "QuakeWorld" was released as a free, unsupported add-on to the game and was updated numerous times through 1998.
GLQuake.
On January 22, 1997, id Software released "GLQuake". This was designed to use the OpenGL 3D API to access hardware 3D graphics acceleration cards to rasterize the graphics, rather than having the computer's CPU fill in every pixel. In addition to higher framerates for most players, "GLQuake" provided higher resolution modes and texture filtering. "GLQuake" also experimented with reflections, transparent water, and even rudimentary shadows. "GLQuake" came with a driver enabling the subset of OpenGL used by the game to function on the 3dfx "Voodoo Graphics" card, the only consumer-level card at the time capable of running "GLQuake" well. Previously, John Carmack had experimented with a version of Quake specifically written for the Rendition Vérité chip used in the Creative Labs "PCI 3D Blaster" card. This version had met with only limited success, and Carmack decided to write for generic APIs in the future rather than tailoring for specific hardware.
WinQuake.
On March 11, 1997, id Software released "WinQuake", a version of the non-OpenGL engine designed to run under Microsoft Windows; the original "Quake" had been written for DOS, allowing for launch from Windows 95, but could not run under Windows NT-based operating systems because it required direct access to hardware. "WinQuake" instead accessed hardware via Win32-based APIs such as DirectSound, DirectInput, and DirectDraw that were supported on Windows 95, Windows NT 4.0 and later releases. Like "GLQuake", "WinQuake" also allowed higher resolution video modes. This removed the last barrier to widespread popularity of the game. In 1998, LBE Systems and Laser-Tron released "Quake: Arcade Tournament Edition" in the arcades in limited quantities.
Sequels.
After the departure of Sandy Petersen, the remaining id employees chose to change the thematic direction substantially for "Quake II", making the design more technological and futuristic, rather than maintaining the focus on Lovecraftian fantasy. "Quake 4" followed the design themes of "Quake II", whereas "Quake III Arena" mixed these styles; it had a parallel setting that housed several "id all-stars" from various games as playable characters. The mixed settings occurred because "Quake II" originally began as a separate product line. The id designers were forced to fall back on the project's nickname of "Quake II" due to the failure to gain rights to the title they wanted. Since any sequel to the original "Quake" had already been vetoed, it became a way of continuing the series without continuing the storyline or setting of the first game. In June 2011, John Carmack made an offhand comment that id software was considering a remake to the "...mixed up Cthulhu-ish Quake 1 world and rebooting [in] that direction."

</doc>
<doc id="25267" url="http://en.wikipedia.org/wiki?curid=25267" title="Quantum field theory">
Quantum field theory

In theoretical physics, quantum field theory (QFT) is a theoretical framework for constructing quantum mechanical models of subatomic particles in particle physics and quasiparticles in condensed matter physics. A QFT treats particles as excited states of an underlying physical field, so these are called field quanta.
For example, quantum electrodynamics (QED) has one electron field and one photon field; quantum chromodynamics (QCD) has one field for each type of quark; and, in condensed matter, there is an atomic displacement field that gives rise to phonon particles. Edward Witten describes QFT as "by far" the most difficult theory in modern physics.
In QFT, quantum mechanical interactions between particles are described by interaction terms between the corresponding underlying fields. QFT interaction terms are similar in spirit to those between charges with electric and magnetic fields in Maxwell's equations. However, unlike the classical fields of Maxwell's theory, fields in QFT generally exist in quantum superpositions of states and are subject to the laws of quantum mechanics.
Ordinary quantum mechanical systems have a fixed number of particles, with each particle having a finite number of degrees of freedom. In contrast, the excited states of a QFT can represent any number of particles. This makes quantum field theories especially useful for describing systems where the particle count/number may change over time, a crucial feature of relativistic dynamics.
Because the fields are continuous quantities over space, there exist excited states with arbitrarily large numbers of particles in them, providing QFT systems with an effectively infinite number of degrees of freedom. Infinite degrees of freedom can easily lead to divergences of calculated quantities (i.e., the quantities become infinite). Techniques such as renormalization of QFT parameters or discretization of spacetime, as in lattice QCD, are often used to avoid such infinities so as to yield physically meaningful results.
Most theories in standard particle physics are formulated as relativistic quantum field theories, such as QED, QCD, and the Standard Model. QED, the quantum field-theoretic description of the electromagnetic field, approximately reproduces Maxwell's theory of electrodynamics in the low-energy limit, with small non-linear corrections to the Maxwell equations required due to virtual electron–positron pairs.
In the perturbative approach to quantum field theory, the full field interaction terms are approximated as a perturbative expansion in the number of particles involved. Each term in the expansion can be thought of as forces between particles being mediated by other particles. In QED, the electromagnetic force between two electrons is caused by an exchange of photons. Similarly, intermediate vector bosons mediate the weak force and gluons mediate the strong force in QCD. The notion of a force-mediating particle comes from perturbation theory, and does not make sense in the context of non-perturbative approaches to QFT, such as with bound states.
The gravitational field and the electromagnetic field are the only two fundamental fields in nature that have infinite range and a corresponding classical low-energy limit, which greatly diminishes and hides their "particle-like" excitations. Albert Einstein in 1905, attributed "particle-like" and discrete exchanges of momenta and energy, characteristic of "field quanta", to the electromagnetic field. Originally, his principal motivation was to explain the thermodynamics of radiation. Although the photoelectric effect and Compton scattering strongly suggest the existence of the photon, it might alternately be explained by a mere quantization of emission; more definitive evidence of the quantum nature of radiation is now taken up into modern quantum optics as in the antibunching effect.
There is currently no complete quantum theory of the remaining fundamental force, gravity. Many of the proposed theories to describe gravity as a QFT postulate the existence of a graviton particle that mediates the gravitational force. Presumably, the as yet unknown correct quantum field-theoretic treatment of the gravitational field will behave like Einstein's general theory of relativity in the low-energy limit. Quantum field theory of the fundamental forces itself has been postulated to be the low-energy effective field theory limit of a more fundamental theory such as superstring theory.
History.
Foundations.
The early development of the field involved Dirac, Fock, Pauli, Heisenberg and Bogolyubov. This phase of development culminated with the construction of the theory of quantum electrodynamics in the 1950s.
Gauge theory.
Gauge theory was formulated and quantized, leading to the unification of forces embodied in the standard model of particle physics. This effort started in the 1950s with the work of Yang and Mills, was carried on by Martinus Veltman and a host of others during the 1960s and completed by the 1970s through the work of Gerard 't Hooft, Frank Wilczek, David Gross and David Politzer.
Grand synthesis.
Parallel developments in the understanding of phase transitions in condensed matter physics led to the study of the renormalization group. This in turn led to the grand synthesis of theoretical physics, which unified theories of particle and condensed matter physics through quantum field theory. This involved the work of Michael Fisher and Leo Kadanoff in the 1970s, which led to the seminal reformulation of quantum field theory by Kenneth G. Wilson in 1975.
Principles.
Classical and quantum fields.
A classical field is a function defined over some region of space and time. Two physical phenomena which are described by classical fields are Newtonian gravitation, described by Newtonian gravitational field g(x, "t"), and classical electromagnetism, described by the electric and magnetic fields E(x, "t") and B(x"', "t"). Because such fields can in principle take on distinct values at each point in space, they are said to have infinite degrees of freedom.
Classical field theory does not, however, account for the quantum-mechanical aspects of such physical phenomena. For instance, it is known from quantum mechanics that certain aspects of electromagnetism involve discrete particles—photons—rather than continuous fields. The business of "quantum" field theory is to write down a field that is, like a classical field, a function defined over space and time, but which also accommodates the observations of quantum mechanics. This is a "quantum field".
It is not immediately clear "how" to write down such a quantum field, since quantum mechanics has a structure very unlike a field theory. In its most general formulation, quantum mechanics is a theory of abstract operators (observables) acting on an abstract state space (Hilbert space), where the observables represent physically observable quantities and the state space represents the possible states of the system under study. For instance, the fundamental observables associated with the motion of a single quantum mechanical particle are the position and momentum operators formula_1 and formula_2. Field theory, in contrast, treats "x" as a way to index the field rather than as an operator.
There are two common ways of developing a quantum field: the path integral formalism and canonical quantization. The latter of these is pursued in this article.
Lagrangian formalism.
Quantum field theory frequently makes use of the Lagrangian formalism from classical field theory. This formalism is analogous to the Lagrangian formalism used in classical mechanics to solve for the motion of a particle under the influence of a field. In classical field theory, one writes down a Lagrangian density, formula_3, involving a field, φ(x,"t"), and possibly its first derivatives (∂φ/∂"t" and ∇φ), and then applies a field-theoretic form of the Euler–Lagrange equation. Writing coordinates ("t", x) = ("x"0, "x"1, "x"2, "x"3) = "x"μ, this form of the Euler–Lagrange equation is
where a sum over μ is performed according to the rules of Einstein notation.
By solving this equation, one arrives at the "equations of motion" of the field. For example, if one begins with the Lagrangian density
and then applies the Euler–Lagrange equation, one obtains the equation of motion
This equation is Newton's law of universal gravitation, expressed in differential form in terms of the gravitational potential φ("t", x) and the mass density ρ("t", x). Despite the nomenclature, the "field" under study is the gravitational potential, φ, rather than the gravitational field, g. Similarly, when classical field theory is used to study electromagnetism, the "field" of interest is the electromagnetic four-potential ("V"/"c", A), rather than the electric and magnetic fields E and B.
Quantum field theory uses this same Lagrangian procedure to determine the equations of motion for quantum fields. These equations of motion are then supplemented by commutation relations derived from the canonical quantization procedure described below, thereby incorporating quantum mechanical effects into the behavior of the field.
Single- and many-particle quantum mechanics.
In quantum mechanics, a particle (such as an electron or proton) is described by a complex wavefunction, "ψ"("x", "t"), whose time-evolution is governed by the Schrödinger equation:
There are several shortcomings to the above description of quantum mechanics, which are addressed by quantum field theory. First, it is unclear how to extend quantum mechanics to include the effects of special relativity. Attempted replacements for the Schrödinger equation, such as the Klein–Gordon equation or the Dirac equation, have many unsatisfactory qualities; for instance, they possess energy eigenvalues that extend to –∞, so that there seems to be no easy definition of a ground state. It turns out that such inconsistencies arise from relativistic wavefunctions not having a well-defined probabilistic interpretation in position space, as probability conservation is not a relativistically covariant concept. The second shortcoming, related to the first, is that in quantum mechanics there is no mechanism to describe particle creation and annihilation; this is crucial for describing phenomena such as pair production, which result from the conversion between mass and energy according to the relativistic relation "E" = "mc"2.
Second quantization.
In this section, we will describe a method for constructing a quantum field theory called second quantization. This basically involves choosing a way to index the quantum mechanical degrees of freedom in the space of multiple identical-particle states. It is based on the Hamiltonian formulation of quantum mechanics.
Several other approaches exist, such as the Feynman path integral, which uses a Lagrangian formulation. For an overview of some of these approaches, see the article on quantization.
Bosons.
For simplicity, we will first discuss second quantization for bosons, which form perfectly symmetric quantum states. Let us denote the mutually orthogonal single-particle states which are possible in the system by formula_8 and so on. For example, the 3-particle state with one particle in state formula_9 and two in state formula_10 is
The first step in second quantization is to express such quantum states in terms of occupation numbers, by listing the number of particles occupying each of the single-particle states formula_12 etc. This is simply another way of labelling the states. For instance, the above 3-particle state is denoted as
An "N"-particle state belongs to a space of states describing systems of "N" particles. The next step is to combine the individual "N"-particle state spaces into an extended state space, known as Fock space, which can describe systems of any number of particles. This is composed of the state space of a system with no particles (the so-called vacuum state, written as formula_14), plus the state space of a 1-particle system, plus the state space of a 2-particle system, and so forth. States describing a definite number of particles are known as Fock states: a general element of Fock space will be a linear combination of Fock states. There is a one-to-one correspondence between the occupation number representation and valid boson states in the Fock space.
At this point, the quantum mechanical system has become a quantum field in the sense we described above. The field's elementary degrees of freedom are the occupation numbers, and each occupation number is indexed by a number formula_15 indicating which of the single-particle states formula_16 it refers to:
The properties of this quantum field can be explored by defining creation and annihilation operators, which add and subtract particles. They are analogous to ladder operators in the quantum harmonic oscillator problem, which added and subtracted energy quanta. However, these operators literally create and annihilate particles of a given quantum state. The bosonic annihilation operator formula_18 and creation operator formula_19 are easily defined in the occupation number representation as having the following effects:
It can be shown that these are operators in the usual quantum mechanical sense, i.e. linear operators acting on the Fock space. Furthermore, they are indeed Hermitian conjugates, which justifies the way we have written them. They can be shown to obey the commutation relation
where formula_23 stands for the Kronecker delta. These are precisely the relations obeyed by the ladder operators for an infinite set of independent quantum harmonic oscillators, one for each single-particle state. Adding or removing bosons from each state is therefore analogous to exciting or de-exciting a quantum of energy in a harmonic oscillator.
Applying an annihilation operator formula_24 followed by its corresponding creation operator formula_25 returns the number formula_26 of particles in the "k"th single-particle eigenstate:
The combination of operators formula_28 is known as the number operator for the "k"th eigenstate.
The Hamiltonian operator of the quantum field (which, through the Schrödinger equation, determines its dynamics) can be written in terms of creation and annihilation operators. For instance, for a field of free (non-interacting) bosons, the total energy of the field is found by summing the energies of the bosons in each energy eigenstate. If the "k"th single-particle energy eigenstate has energy formula_29 and there are formula_26 bosons in this state, then the total energy of these bosons is formula_31. The energy in the "entire" field is then a sum over formula_32:
This can be turned into the Hamiltonian operator of the field by replacing formula_26 with the corresponding number operator, formula_28. This yields
Fermions.
It turns out that a different definition of creation and annihilation must be used for describing fermions. According to the Pauli exclusion principle, fermions cannot share quantum states, so their occupation numbers "Ni" can only take on the value 0 or 1. The fermionic annihilation operators "c" and creation operators formula_37 are defined by their actions on a Fock state thus
These obey an anticommutation relation:
One may notice from this that applying a fermionic creation operator twice gives zero, so it is impossible for the particles to share single-particle states, in accordance with the exclusion principle.
Field operators.
We have previously mentioned that there can be more than one way of indexing the degrees of freedom in a quantum field. Second quantization indexes the field by enumerating the single-particle quantum states. However, as we have discussed, it is more natural to think about a "field", such as the electromagnetic field, as a set of degrees of freedom indexed by position.
To this end, we can define "field operators" that create or destroy a particle at a particular point in space. In particle physics, these operators turn out to be more convenient to work with, because they make it easier to formulate theories that satisfy the demands of relativity.
Single-particle states are usually enumerated in terms of their momenta (as in the particle in a box problem.) We can construct field operators by applying the Fourier transform to the creation and annihilation operators for these states. For example, the bosonic field annihilation operator formula_43 is
The bosonic field operators obey the commutation relation
where formula_46 stands for the Dirac delta function. As before, the fermionic relations are the same, with the commutators replaced by anticommutators.
The field operator is not the same thing as a single-particle wavefunction. The former is an operator acting on the Fock space, and the latter is a quantum-mechanical amplitude for finding a particle in some position. However, they are closely related, and are indeed commonly denoted with the same symbol. If we have a Hamiltonian with a space representation, say
where the indices "i" and "j" run over all particles, then the field theory Hamiltonian (in the non-relativistic limit and for negligible self-interactions) is
This looks remarkably like an expression for the expectation value of the energy, with formula_49 playing the role of the wavefunction. This relationship between the field operators and wavefunctions makes it very easy to formulate field theories starting from space-projected Hamiltonians.
Dynamics.
Once the Hamiltonian operator is obtained as part of the canonical quantization process, the time dependence of the state is described with the Schrödinger equation, just as with other quantum theories. Alternatively, the Heisenberg picture can be used where the time dependence is in the operators rather than in the states.
Implications.
Unification of fields and particles.
The "second quantization" procedure that we have outlined in the previous section takes a set of single-particle quantum states as a starting point. Sometimes, it is impossible to define such single-particle states, and one must proceed directly to quantum field theory. For example, a quantum theory of the electromagnetic field "must" be a quantum field theory, because it is impossible (for various reasons) to define a wavefunction for a single photon. In such situations, the quantum field theory can be constructed by examining the mechanical properties of the classical field and guessing the corresponding quantum theory. For free (non-interacting) quantum fields, the quantum field theories obtained in this way have the same properties as those obtained using second quantization, such as well-defined creation and annihilation operators obeying commutation or anticommutation relations.
Quantum field theory thus provides a unified framework for describing "field-like" objects (such as the electromagnetic field, whose excitations are photons) and "particle-like" objects (such as electrons, which are treated as excitations of an underlying electron field), so long as one can treat interactions as "perturbations" of free fields. There are still unsolved problems relating to the more general case of interacting fields that may or may not be adequately described by perturbation theory. For more on this topic, see Haag's theorem.
Physical meaning of particle indistinguishability.
The second quantization procedure relies crucially on the particles being identical. We would not have been able to construct a quantum field theory from a distinguishable many-particle system, because there would have been no way of separating and indexing the degrees of freedom.
Many physicists prefer to take the converse interpretation, which is that "quantum field theory explains what identical particles are". In ordinary quantum mechanics, there is not much theoretical motivation for using symmetric (bosonic) or antisymmetric (fermionic) states, and the need for such states is simply regarded as an empirical fact. From the point of view of quantum field theory, particles are identical if and only if they are excitations of the same underlying quantum field. Thus, the question "why are all electrons identical?" arises from mistakenly regarding individual electrons as fundamental objects, when in fact it is only the electron field that is fundamental.
Particle conservation and non-conservation.
During second quantization, we started with a Hamiltonian and state space describing a fixed number of particles ("N"), and ended with a Hamiltonian and state space for an arbitrary number of particles. Of course, in many common situations "N" is an important and perfectly well-defined quantity, e.g. if we are describing a gas of atoms sealed in a box. From the point of view of quantum field theory, such situations are described by quantum states that are eigenstates of the number operator formula_50, which measures the total number of particles present. As with any quantum mechanical observable, formula_50 is conserved if it commutes with the Hamiltonian. In that case, the quantum state is trapped in the "N"-particle subspace of the total Fock space, and the situation could equally well be described by ordinary "N"-particle quantum mechanics. (Strictly speaking, this is only true in the noninteracting case or in the low energy density limit of renormalized quantum field theories)
For example, we can see that the free-boson Hamiltonian described above conserves particle number. Whenever the Hamiltonian operates on a state, each particle destroyed by an annihilation operator formula_24 is immediately put back by the creation operator formula_25.
On the other hand, it is possible, and indeed common, to encounter quantum states that are "not" eigenstates of formula_50, which do not have well-defined particle numbers. Such states are difficult or impossible to handle using ordinary quantum mechanics, but they can be easily described in quantum field theory as quantum superpositions of states having different values of "N". For example, suppose we have a bosonic field whose particles can be created or destroyed by interactions with a fermionic field. The Hamiltonian of the combined system would be given by the Hamiltonians of the free boson and free fermion fields, plus a "potential energy" term such as
where formula_25 and formula_24 denotes the bosonic creation and annihilation operators, formula_58 and formula_59 denotes the fermionic creation and annihilation operators, and formula_60 is a parameter that describes the strength of the interaction. This "interaction term" describes processes in which a fermion in state "k" either absorbs or emits a boson, thereby being kicked into a different eigenstate formula_61. (In fact, this type of Hamiltonian is used to describe interaction between conduction electrons and phonons in metals. The interaction between electrons and photons is treated in a similar way, but is a little more complicated because the role of spin must be taken into account.) One thing to notice here is that even if we start out with a fixed number of bosons, we will typically end up with a superposition of states with different numbers of bosons at later times. The number of fermions, however, is conserved in this case.
In condensed matter physics, states with ill-defined particle numbers are particularly important for describing the various superfluids. Many of the defining characteristics of a superfluid arise from the notion that its quantum state is a superposition of states with different particle numbers. In addition, the concept of a coherent state (used to model the laser and the BCS ground state) refers to a state with an ill-defined particle number but a well-defined phase.
Axiomatic approaches.
The preceding description of quantum field theory follows the spirit in which most physicists approach the subject. However, it is not mathematically rigorous. Over the past several decades, there have been many attempts to put quantum field theory on a firm mathematical footing by formulating a set of axioms for it. These attempts fall into two broad classes.
The first class of axioms, first proposed during the 1950s, include the Wightman, Osterwalder–Schrader, and Haag–Kastler systems. They attempted to formalize the physicists' notion of an "operator-valued field" within the context of functional analysis, and enjoyed limited success. It was possible to prove that any quantum field theory satisfying these axioms satisfied certain general theorems, such as the spin-statistics theorem and the CPT theorem. Unfortunately, it proved extraordinarily difficult to show that any realistic field theory, including the Standard Model, satisfied these axioms. Most of the theories that could be treated with these analytic axioms were physically trivial, being restricted to low-dimensions and lacking interesting dynamics. The construction of theories satisfying one of these sets of axioms falls in the field of constructive quantum field theory. Important work was done in this area in the 1970s by Segal, Glimm, Jaffe and others.
During the 1980s, a second set of axioms based on geometric ideas was proposed. This line of investigation, which restricts its attention to a particular class of quantum field theories known as topological quantum field theories, is associated most closely with Michael Atiyah and Graeme Segal, and was notably expanded upon by Edward Witten, Richard Borcherds, and Maxim Kontsevich. However, most of the physically relevant quantum field theories, such as the Standard Model, are not topological quantum field theories; the quantum field theory of the fractional quantum Hall effect is a notable exception. The main impact of axiomatic topological quantum field theory has been on mathematics, with important applications in representation theory, algebraic topology, and differential geometry.
Finding the proper axioms for quantum field theory is still an open and difficult problem in mathematics. One of the Millennium Prize Problems—proving the existence of a mass gap in Yang–Mills theory—is linked to this issue.
Associated phenomena.
In the previous part of the article, we described the most general features of quantum field theories. Some of the quantum field theories studied in various fields of theoretical physics involve additional special ideas, such as renormalizability, gauge symmetry, and supersymmetry. These are described in the following sections.
Renormalization.
Early in the history of quantum field theory, it was found that many seemingly innocuous calculations, such as the perturbative shift in the energy of an electron due to the presence of the electromagnetic field, give infinite results. The reason is that the perturbation theory for the shift in an energy involves a sum over all other energy levels, and there are infinitely many levels at short distances that each give a finite contribution which results in a divergent series.
Many of these problems are related to failures in classical electrodynamics that were identified but unsolved in the 19th century, and they basically stem from the fact that many of the supposedly "intrinsic" properties of an electron are tied to the electromagnetic field that it carries around with it. The energy carried by a single electron—its self energy—is not simply the bare value, but also includes the energy contained in its electromagnetic field, its attendant cloud of photons. The energy in a field of a spherical source diverges in both classical and quantum mechanics, but as discovered by Weisskopf with help from Furry, in quantum mechanics the divergence is much milder, going only as the logarithm of the radius of the sphere.
The solution to the problem, presciently suggested by Stueckelberg, independently by Bethe after the crucial experiment by Lamb, implemented at one loop by Schwinger, and systematically extended to all loops by Feynman and Dyson, with converging work by Tomonaga in isolated postwar Japan, comes from recognizing that all the infinities in the interactions of photons and electrons can be isolated into redefining a finite number of quantities in the equations by replacing them with the observed values: specifically the electron's mass and charge: this is called renormalization. The technique of renormalization recognizes that the problem is essentially purely mathematical, that extremely short distances are at fault. In order to define a theory on a continuum, first place a cutoff on the fields, by postulating that quanta cannot have energies above some extremely high value. This has the effect of replacing continuous space by a structure where very short wavelengths do not exist, as on a lattice. Lattices break rotational symmetry, and one of the crucial contributions made by Feynman, Pauli and Villars, and modernized by 't Hooft and Veltman, is a symmetry-preserving cutoff for perturbation theory (this process is called regularization). There is no known symmetrical cutoff outside of perturbation theory, so for rigorous or numerical work people often use an actual lattice.
On a lattice, every quantity is finite but depends on the spacing. When taking the limit of zero spacing, we make sure that the physically observable quantities like the observed electron mass stay fixed, which means that the constants in the Lagrangian defining the theory depend on the spacing. Hopefully, by allowing the constants to vary with the lattice spacing, all the results at long distances become insensitive to the lattice, defining a continuum limit.
The renormalization procedure only works for a certain class of quantum field theories, called renormalizable quantum field theories. A theory is perturbatively renormalizable when the constants in the Lagrangian only diverge at worst as logarithms of the lattice spacing for very short spacings. The continuum limit is then well defined in perturbation theory, and even if it is not fully well defined non-perturbatively, the problems only show up at distance scales that are exponentially small in the inverse coupling for weak couplings. The Standard Model of particle physics is perturbatively renormalizable, and so are its component theories (quantum electrodynamics/electroweak theory and quantum chromodynamics). Of the three components, quantum electrodynamics is believed to not have a continuum limit, while the asymptotically free SU(2) and SU(3) weak hypercharge and strong color interactions are nonperturbatively well defined.
The renormalization group describes how renormalizable theories emerge as the long distance low-energy effective field theory for any given high-energy theory. Because of this, renormalizable theories are insensitive to the precise nature of the underlying high-energy short-distance phenomena. This is a blessing because it allows physicists to formulate low energy theories without knowing the details of high energy phenomenon. It is also a curse, because once a renormalizable theory like the standard model is found to work, it gives very few clues to higher energy processes. The only way high energy processes can be seen in the standard model is when they allow otherwise forbidden events, or if they predict quantitative relations between the coupling constants.
Haag's theorem.
From a mathematically rigorous perspective, there exists no interaction picture in a Lorentz-covariant quantum field theory. This implies that the perturbative approach of Feynman diagrams in QFT is not strictly justified, despite producing vastly precise predictions validated by experiment. This is called Haag's theorem, but most particle physicists relying on QFT largely shrug it off.
Gauge freedom.
A gauge theory is a theory that admits a symmetry with a local parameter. For example, in every quantum theory the global phase of the wave function is arbitrary and does not represent something physical. Consequently, the theory is invariant under a global change of phases (adding a constant to the phase of all wave functions, everywhere); this is a global symmetry. In quantum electrodynamics, the theory is also invariant under a "local" change of phase, that is – one may shift the phase of all wave functions so that the shift may be different at every point in space-time. This is a "local" symmetry. However, in order for a well-defined derivative operator to exist, one must introduce a new field, the gauge field, which also transforms in order for the local change of variables (the phase in our example) not to affect the derivative. In quantum electrodynamics this gauge field is the electromagnetic field. The change of local gauge of variables is termed gauge transformation. It is worth noting that by Noether's theorem, for every such symmetry there exists an associated conserved current. The aforementioned symmetry of the wavefunction under global phase changes implies the conservation of electric charge. 
In quantum field theory the excitations of fields represent particles. The particle associated with excitations of the gauge field is the gauge boson, which is the photon in the case of quantum electrodynamics.
The degrees of freedom in quantum field theory are local fluctuations of the fields. The existence of a gauge symmetry reduces the number of degrees of freedom, simply because some fluctuations of the fields can be transformed to zero by gauge transformations, so they are equivalent to having no fluctuations at all, and they therefore have no physical meaning. Such fluctuations are usually called "non-physical degrees of freedom" or "gauge artifacts"; usually some of them have a negative norm, making them inadequate for a consistent theory. Therefore, if a classical field theory has a gauge symmetry, then its quantized version (i.e. the corresponding quantum field theory) will have this symmetry as well. In other words, a gauge symmetry cannot have a quantum anomaly. If a gauge symmetry is anomalous (i.e. not kept in the quantum theory) then the theory is non-consistent: for example, in quantum electrodynamics, had there been a gauge anomaly, this would require the appearance of photons with longitudinal polarization and polarization in the time direction, the latter having a negative norm, rendering the theory inconsistent; another possibility would be for these photons to appear only in intermediate processes but not in the final products of any interaction, making the theory non-unitary and again inconsistent (see optical theorem).
In general, the gauge transformations of a theory consist of several different transformations, which may not be commutative. These transformations are together described by a mathematical object known as a gauge group. Infinitesimal gauge transformations are the gauge group generators. Therefore the number of gauge bosons is the group dimension (i.e. number of generators forming a basis).
All the fundamental interactions in nature are described by gauge theories. These are:
Multivalued gauge transformations.
The gauge transformations which leave the theory invariant involve, by definition, only single-valued gauge functions formula_62 which satisfy the Schwarz integrability criterion
An interesting extension of gauge transformations arises if the gauge functions formula_62 are allowed to be multivalued functions which violate the integrability criterion. These are capable of changing the physical field strengths
and are therefore no proper symmetry transformations. Nevertheless, the transformed field equations describe correctly the physical laws in the presence of the newly generated field strengths. See the textbook by H. Kleinert cited below
for the applications to phenomena in physics.
Supersymmetry.
Supersymmetry assumes that every fundamental fermion has a superpartner that is a boson and vice versa. It was introduced in order to solve the so-called Hierarchy Problem, that is, to explain why particles not protected by any symmetry (like the Higgs boson) do not receive radiative corrections to its mass driving it to the larger scales (GUT, Planck...). It was soon realized that supersymmetry has other interesting properties: its gauged version is an extension of general relativity (Supergravity), and it is a key ingredient for the consistency of string theory.
The way supersymmetry protects the hierarchies is the following: since for every particle there is a superpartner with the same mass, any loop in a radiative correction is cancelled by the loop corresponding to its superpartner, rendering the theory UV finite.
Since no superpartners have yet been observed, if supersymmetry exists it must be broken (through a so-called soft term, which breaks supersymmetry without ruining its helpful features). The simplest models of this breaking require that the energy of the superpartners not be too high; in these cases, supersymmetry is expected to be observed by experiments at the Large Hadron Collider. The Higgs particle has been detected at the LHC, and no such superparticles have been discovered.
Further reading.
Articles:

</doc>
