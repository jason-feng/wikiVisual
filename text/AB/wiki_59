<doc id="20841" url="http://en.wikipedia.org/wiki?curid=20841" title="Music radio">
Music radio

Music radio is a radio format in which music is the main broadcast content. After television replaced old time radio's dramatic content, music formats became dominant in many countries. Radio drama and comedy continue, often on public radio.
Music drives radio technology, including wide-band FM and modern digital radio systems such as Digital Radio Mondiale.
How it works.
The radio station provides programming to attract listeners. Commercial radio stations make profits by selling advertising. Public and community radio stations are sustained by listener donations and grants. Young people are targeted by advertisers because their product preferences can be changed more easily. Therefore, the most commercially successful stations target young audiences.
The programming usually cycles from the least attractive item, to most attractive, followed by commercials. The purpose of this plan is to build listener interest during the programming.
Because dead air does not attract listeners, the station tries to fill its broadcast day with sound. Audiences will only tolerate a certain number of commercials before tuning away. In some regions, government regulators specify how many commercials can be played in a given hour.
There are several standard ways of selecting the music, such as free-form, top-40, album-oriented rock, and Jack. These can be applied to all types of music.
Jingles are radio's equivalent of neon signs. Jingles are brief, bright pieces of choral music that promote the station's call letters, frequency and sometimes disc-jockey or program segment. Jingles are produced for radio stations by commercial specialty services such as JAM, in Texas.
Jingles are often replaced by recorded voice-overs (called "stingers", also depending on region more often "liners").
In order to build station loyalty, the station announces time, station calls letters and frequency as often as six to twelve times per hour. Jingles and stingers (liners) help to give the station a branded sound in a pleasant, minimal amount of air-time. The legal requirement for station identification in the U.S. is once per hour, approximately at the top of the hour, or at the conclusion of a transmission.
News, time-checks, real-time travel advice and weather reports are often valuable to listeners. The news headlines and station identification are therefore given just before a commercial. Time, traffic and weather are given just after. The engineer typically sets the station clocks to standard local time each day, by listening to WWV or WWVH (see atomic clock). These segments are less valued by the most targeted market, young people, so many commercial stations shorten or omit these segments in favor of music.
While most music stations that offer news reports simply "tear and read" news items (from the newswires or the Internet), larger stations (generally those affiliated with news/talk stations) may employ an editor to rewrite headlines, and provide summaries of local news. Summaries fit more news in less air-time. Some stations share news collection with TV or newspapers in the same media conglomerate. An emerging trend is to use the radio station's web site to provide in-depth coverage of news and advertisers headlined on the air. Many stations contract with agencies such as Smartraveler and AccuWeather for their weather and traffic reports instead of using in-house staff.
Fewer radio stations (except on medium and major market, depending on daypart) maintain a call-in telephone line for promotions and gags, or to take record requests. DJs of commercial stations do not generally answer the phone and edit the call during music plays in non-major markets, as the programming is either delivered via satellite, or voice-tracked using a computer. More and more stations take requests by e-mail and online chat only.
The value of a station's advertising is set by the number, age and wealth of its listeners. Arbitron, a commercial statistical service, historically used listener diaries to statistically measure the number of listeners. Arbitron diaries were collected on Thursdays, and for this reason, most radio stations have run special promotions on Thursdays, hoping to persuade last-minute Arbitron diarists to give them a larger market-share. Arbitron contractually prevents mention of its name on the air.
Promotions are the on-air equivalent of lotteries for listeners. Promotional budgets usually run about $1 per listener per year. In a large market, a successful radio station can pay a full-time director of promotions, and run several lotteries per month of vacations, automobiles and other prizes. Lottery items are often bartered from advertisers, allowing both companies to charge full prices at wholesale costs. For example, cruising companies often have unused capacity, and when given the choice, prefer to pay their bills by bartering cruise vacations. Since the ship will sail in any case, bartered vacations cost the cruise company little or nothing. The promotion itself advertises the company providing the prize. The FCC has defined a lottery as “any game, contest or promotion that combines the elements of prize, chance and consideration.”
Programming by time.
Most music stations have DJs that play music from a playlist determined by the program director, arranged by blocks of time. Though practices differ by region and format, what follows is a typical arrangement in a North American urban commercial radio station.
The first block of the day is the "morning drive time" block in the early morning. Arbitron defines this block between 6 a.m. and 10 a.m., though it can begin as early as 5 a.m. (though usually not later than 6), and end as early as 9 a.m. or as late as 11 a.m. This block usually includes news bulletins and traffic and weather advisories for commuters, as well as light comedy from the morning DJ team (many shock jocks started as or still work on drive-time radio). Some stations emphasize music, and reduce gags and call-ins in this period.
The midday block (defined by Arbitron as 10 a.m. to 3 p.m., though often extended later to about 5 p.m.) is mostly music, and in many places is at least partially voicetracked from another market. For a period around noon a station may play nonstop music or go to an all-request format for people eating lunch. This block is often occupied by a "no-repeat workday;" stations that offer this feature usually target captive audiences such as retail workers, who have to listen to the station for long periods of time and can become irritated by repetition.
In the early evening, or "afternoon drive" (defined by Arbitron as 3 to 7 p.m.), the evening rush-hour programming resembles the midday programming, but adds traffic and weather advisories for commuters. Some stations insert a short snippet of stand-up comedy ("5 O'Clock Funnies") around 5 o'clock when commuters leave work, or play specifically selected "car tunes" ideal for listening while driving.
The evening block (defined by Arbitron as 7 p.m. to midnight), if present, returns to music. Syndicated programs such as Tom Kent or Delilah are popular in this shift.
The overnight programming, from midnight to the beginning of drive time, is generally low-key music with quiet, if any, announcing. Some stations play documentaries or even infomercials, while some others play syndicated or voicetracked DJs. Complete automation, with no jock, is very common in this day part. It is not uncommon to play more adventurous selections during late night programming blocks, since late night is generally not considered significant for ratings, and are not subject to federal restrictions as stringently as during the daytime. Stations are permitted to sign off during this time; in areas where AM radio is still significant (especially in the United States), local stations may be required to either sign off or cut to low-power to protect clear-channel stations.
Weekends, especially Sundays, often carry different programming. The countdown show, ranking the top songs of the previous week, has been a staple of weekend radio programming since 1970; current hosts of countdown shows in various formats include Rick Dees, Ryan Seacrest, Jeff Foxworthy, Kix Brooks, Bob Kingsley, Crook & Chase, Randy Jackson, Walt Love, Al Gross, Dick Bartley, and (via reruns) Casey Kasem. Other types of weekend programming include niche programming, retrospective shows and world music such as the Putumayo World Music Hour. Stations may carry shows with different genres of music such as blues or jazz. Community affairs and religious programming is often on Sunday mornings, generally one of the least listened-to periods of the week. In addition, weekend evenings are particularly specialized; a dance station might have a sponsored dance party at a local club, or a classical station may play an opera. Saturday nights are also similar to this; request shows, both local and national (e.g. Dick Bartley), are very popular on Saturday night. The longest running radio program in the country, the "Grand Ole Opry", has aired on Saturday night since its inception in 1925.
Many music stations in the United States perform news and timechecks only sparingly, preferring to put more music on the air. News is often restricted to the talk-heavy commuting hours, though weather updates are still very common throughout the day, even on these stations. ABC FM News is an example of an American news network that is designed for music radio stations. The BBC and ABC take a different approach, with all of its stations giving news updates (BBC Radio 1Xtra produces its own news segments under the name TX.)
Music formats.
Some well-known music-radio formats are "Top 40", "Freeform Rock" and "AOR (Album Oriented Rock)". It turns out that most other stations (such as Rhythm & Blues) use a variation of one of these formats with a different playlist. The way stations advertise themselves is not standardized. Some critical interpretation is needed to recognize classic formulas in the midst of the commercial glitz.
See List of music radio formats for further details, and note that there is a great deal of format evolution (or, to borrow a television term, channel drift) as music tastes and commercial conditions change. For example, the Beautiful music format that developed into today's Easy listening and Soft rock formats is nearly extinct due to a lack of interest from younger generations, whereas classic rock has become popular over the last 20 years or so and Jack FM has arisen only since 2000 or so.
The most popular format in the U.S. is country music, but rock music sells the most.
Top 40.
The original formulaic radio format was Top 40 music, now known within the industry as contemporary hit radio or "CHR". In this radio format, disc-jockeys would select one of a set of the forty best-selling singles (usually in a rack) as rated by Billboard magazine or from the station's own chart of the local top selling songs. In general, the more aggressive "Top 40" stations could sometimes be better described as "Top 20" stations. They would aggressively skirt listener boredom to play only the most popular singles.
Top 40 radio would punctuate the music with jingles, promotions, gags, call-ins, and requests, brief news, time and weather announcements and most importantly, advertising. The distinguishing mark of a traditional top-40 station was the use of a hyperexcited disc-jockey, and high tempo jingles. The format was invented in the US and today can be heard world wide. Todd Storz and Gordon McLendon and invented Top 40 radio. Bill Drake and Rick Sklar have had a lasting modern influence. .
Variants and hybrids include the freeform-like Jack FM (mentioned below under Freeform Rock) and the "Mix" formats mentioned below under Oldies. Top 40 music is heavily criticized by some music fans as being repetitive and of low quality, and is almost exclusively dominated by large media conglomerates such as Clear Channel Communications and CBS Corporation. Top 40 tends to be underrepresented on the Internet, being mostly the domain of commercial broadcasters such as Virgin Radio UK.
Some of the most famous Top 40 stations have been WABC/New York City, KHJ/Los Angeles WLS "89 Musicradio WLS"/Chicago, 1050 CHUM/Toronto, WFIL/ Philadelphia, and WRKO/Boston.
Freeform and progressive rock.
A later development was freeform radio, later commercially developed as progressive rock radio, and still later even more commercially developed as AOR (Album-Oriented Rock), in which selections from an album would be played together, with an appropriate introduction.
Traditional free-form stations prided themselves on offering their disc jockeys freedom to play significant music and make significant social commentary and humor. This approach developed commercial problems because disc jockeys attracted to this freedom often had tastes substantially different from the audience, and lost audience share. Also, freeform stations could lack predictability, and listeners' loyalty could then be put at risk. Progressive rock radio (not to be confused with the progressive rock music genre) was freeform in style but constrained so that some kind of rock music was what was always or almost always played.
Responsible jocks would realize their responsibility to the audience to produce a pleasant show, and try to keep the station sound predictable by listening to other jocks, and repeating some of their music selections. WNEW-FM (now WWFS) in New York during the 1970s exemplified this approach to progressive rock radio.
At their best, free-form stations have never been equaled for their degree of social activism, programmatic freedom, and listener involvement. However, to succeed, the approach requires genius jocks, totally in-tune with their audience, who are also committed to the commercial success of the radio station. This is a rare combination of traits. Even if such people are available, they often command extremely high salaries. However, this may be an effective approach for a new station, if talented jocks can be recruited and motivated at low salaries.
Freeform radio is particularly popular as a college radio format; offshoots include the recent (and somewhat controversial, due to its lack of on-air personalities) eclectic-pop format known as variety hits, which plays a wide assortment of mostly top-40 music from a span of several decades; and podcast radio, a mostly talk format pioneered by Infinity Broadcasting's KYOU station in California and Adam Curry's Podcast show on Sirius Satellite Radio.
AOR (album-oriented rock).
AOR (album-oriented rock) developed as a commercial compromise between top-forties-style formulas and progressive rock radio/freeform. A program director or music consultant would select some set of music "standards" and require the playlist to be followed, perhaps in an order selected by the jock. The jock would still introduce each selection, but the jock would have available a scripted introduction to use if he was not personally familiar with a particular piece of music and its artist. Obviously a computer helps a lot in this process.
A useful, relatively safe compromise with the artistic freedom of the jocks is that a few times each hour, usually in the least commercially valuable slots of the hour, the disc-jockey can highlight new tracks that he or she thinks might interest the audience. The audience is encouraged to comment on the new tracks, allowing the station to track audience tastes. The freedom to introduce new artists can help a station develop its library.
Significant AOR offshoots include classic rock and adult album alternative.
Oldies, standards, and classic rock.
Classic rock or oldies formats have been described as having the weakness of not playing new artists. This is true in a creative sense, but not a commercial one. Radio stations will not get good ratings or revenue if they frequently play songs unfamiliar to their audience. This is why "Top 40" stations played only the biggest hits and why oldies and classic rock formats do the same for the eras they cover. Oldies and related formats do have an inherent advantage in that they have a much broader time frame (up to 30 years, compared to the current hits of a top-40 station) from which to draw their playlist and can thus play a greater variety of songs than a station bound to devote the majority of its spins to a limited list. The ideal "classic" station (of whatever format) finds the balance between playing listener favorites frequently enough to develop a base while at the same time cultivating a playlist broad enough not to bore them. Nevertheless, there seems to be a cottage industry of Internet stations specializing in specific forms of classic rock and oldies, particularly psychedelic rock and progressive rock.
The oldies and classic rock formats have a strong niche market, but as the audience becomes older the station becomes less attractive to advertisers. Advertisers perceive older listeners as set in their brand choices and not as responsive to advertising as younger, more impulsive listeners. Oldies stations must occasionally change to more youthful music formats; as a result, the definition of what constitutes an "oldies" station has gradually changed over the years. This is why many oldies stations, like WCBS-FM in New York City and WJMK in Chicago, have switched over to the younger-oriented Jack FM format in recent years—although WCBS-FM adopted a Classic Hits format on July 12, 2007, and the "Jack FM" format was moved to its HD2 subchannel. Unlike WCBS-FM's pre-JACK format which was centered on the 1955-1979 era, the post-JACK station was based on the 1964-1989 era because of the aging listener demographics of the original format.
This preference for younger listeners caused the decline of the "Big Band" or "Standards" music formats that covered music from the 1930s to the 1950s. As the audience grew too old for advertisers, the radio stations that carried these formats saw a sharp loss of ratings and revenue. This left them with no choice but to adopt more youthful formats, though the Standards format (also known as the Great American Songbook from the series of albums produced by rocker Rod Stewart) has undergone something of an off-air revival, with artists such as Stewart, Tony Bennett and Queen Latifah putting their own interpretation on the music.
During the mid-to-late-1990s, the "Mix" format—a loosely defined mixture of Top-40 and classic rock with something of an emphasis on adult contemporary music—began to appear across the country. While the format has no particular standard identity, most "mix" stations have rotations consisting largely of pop and rock music from the 1980s and 1990s (and often the 1970s), with some current material mixed in. In addition, stations devoted to the pop music of the 1970s, 1980s, and 1990s on their own have developed as the audiences that grew up with that music grew older and nostalgic for the sounds of their youth.
The full service format is a more freeform variant of this type of format. Full-service stations will often mix the oldies, classic rock, classic hits, and adult standards music, occasionally with music found in formats such as beautiful music, adult contemporary, or classic country. On weekends, specialty or niche programs focusing on formats such as Celtic music, polka and Italian music (depending on the ethnicity of the area) are common. In addition to music, a limited amount of local talk programming is heard on most full-service stations. Full service tends to be heard primarily on rural stations.
Classical, pop, easy-listening, jazz, dance.
These formats all have small but very loyal audiences in the largest markets. Most follow formats similar to the above (Top 40s, Freeform, AOR and Oldies), except with a different playlist. Public service stations following these formats tend to be "freeform" stations.
Classical music radio is just as it sounds—radio designed to appeal to the listener of classical music. Most classical stations specialize primarily in instrumental classical music and chamber music, though there are more special interest classical stations (often found through media such as satellite radio or internet radio) that carry classical pop music or operatic music.
Easy listening and Adult Contemporary are related formats that play largely down-tempo pop music of various styles. The difference is mostly in the era and styles covered -- Easy Listening is mostly older music done in the style of standards from the early 20th century (typical artists include Johnny Mathis and Frank Sinatra) combined with Big Band music and more modern performers in the same style such as Céline Dion and Josh Groban, while Adult Contemporary focuses more on newer pop music from the 1970s on. An ancestor to the easy listening format is Beautiful Music, a now-rare format (though XM features one channel of it, called Sunny) focusing mostly on smooth jazz or classical arrangements of pop music and original compositions in a similar vein. Perhaps the best-known Adult Contemporary station currently in operation is WLTW in New York City, better known as .
Jazz stations generally play either traditional jazz forms or smooth jazz. The jazz station, more than any other except the college station, is stereotyped as having a small listenership and a somewhat overly highbrow on-air personality, and many are college-run stations. California State University Long Beach sponsors , which has a fairly significant online listenership as well. Two very well known smooth jazz stations are in Chicago and in Los Angeles, both of which were introduced in 1987, and still continue to enjoy tremendous success in the format today. Also, WUCF-FM in Orlando has been playing jazz music since 1978. Both traditional and smooth jazz stations have been in severe decline, both on commercial and noncommercial stations, since the 2000s, in part because of the formats' lower profitability compared to other formats (adult contemporary for commercial stations, NPR-driven news/talk for noncommercial ones).
Blues programming is generally limited to niche programs on stations that primarily broadcast other formats. An exception to this is CIDG-FM, an all-blues station based in the Canadian city of Ottawa.
Dance music is a niche, and so-called "rhythmic pop" stations have had a fierce but not always commercially sustainable following. There was a wide spectrum of disco-format radio stations during the late 1970s, but virtually all of them died out during the disco backlash; WXKS in Boston is one of the few notable survivors, now a Clear Channel Communications-owned top-40 station of considerable influence. Nevertheless there are a large number of dance music stations available both on the internet and on satellite radio, mostly specializing in various forms of electronica. Both major US satellite radio services include disco stations.
Alternative and modern rock.
Rock music has a long and honorable radio tradition going back to DJs like Wolfman Jack and Alan Freed, and as a result variations on rock radio are fairly common. The classic rock and oldies formats are discussed above; in addition to those, however, there are several genres of music radio devoted to different aspects of modern rock music. Alternative rock grew out of the grunge scene of the late 1980s and early 1990s and is particularly favored by college radio and adult album alternative stations; there is a strong focus on songwriters and bands with an outsider sound or a more sophisticated sound than the "three chord wonder" cliché. Meanwhile, other stations focus on heavy metal, punk rock, or the various post-punk and pop-influenced sounds known collectively as "modern rock".
Narrow-interest rock stations are particularly common on the Internet and satellite radio scenes, broken down into genres such as punk, metal, classic rock, indie music, and the like. There is a general feeling among radio connoisseurs that rock radio is becoming badly watered down by big corporate ownership, leading to a considerable do-it-yourself spirit.
Country.
While stereotyped as rural music, the Country music format is common and popular throughout the United States and in some other countries (particularly Canada and Australia, both of which share much of the same Anglo-Saxon and Celtic roots as the United States). Country has been a popular radio format since the early days of music radio, dating back to the early days of radio itself when barn dance radio programs were widely popular; however, the format was indeed originally a predominantly rural phenomenon, especially on AM radio. Decades worth of efforts at mainstreaming the format eventually paid off when country radio became widely popular among a large number of FM radio stations that signed on in the suburban United States in the 1980s and early 1990s. 
For most mainstream country stations, the emphasis is generally on current pop country, following the same process as top 40; the remaining music in a particular station's library generally uses music from the past fifteen years (shorter for "hot country" or "new country" stations), with the exact music used varying depending on the station and the style of music the listener wants to hear.
Classic country is a variant of the country music format; it is effectively the country music analog to oldies. Classic country is generally preserved in the rural AM stations that country music aired on before its mainstream expansion. Depending on the music mix, it can play either relatively recent classic country tunes from the 1970s to the 1990s (generally more favorable to advertisers) or can span all the way back to the 1920s, thus playing music far older than almost any other radio format available.
Due to increasing similarities between country music and some variants of rock music (such as southern rock, country rock and heartland rock), there have been efforts at combining country and rock formats together, most of which have been unsuccessful.
An alternative country format is Americana, which eschews the mainstream pop country songs in favor of classic-era, alt country and cult musicians. Like the music it plays, these stations can develop strong cult followings and listener loyalty, but they are also less commercially successful than pop country stations.
Urban (hip-hop/R&B).
The explosive rise in popularity during the 1980s of rap music has led to a large number of radio stations specializing in rap/hip-hop and R&B music (with the exception of classic R&B such as Motown, which is as often as not the province of Oldies stations). This format is popular among all ethnic groups and social classes.
Dance music radio.
Dance music radio focuses on live DJ sets and hit singles from genres of techno, house, electro, drum and bass, UK garage and big beat. While some stations play all kinds of electronic dance music, others (mainly pirate radio stations) focus on particular genres. This format is popular in England, Germany, Netherlands and some other countries, but less so in the United States (where dance is a niche format often exclusive to internet radio stations). 
However, the number of U.S. stations airing such content has grown; five terrestrial radio stations in the U.S. with a purely dance-oriented format (one of which airing it part-time during the night and early-morning hours) report their airplay to the Billboard Dance/Mix Show Airplay chart, while top 40 and rhythmic stations may also air EDM songs that have crossed over onto pop-oriented charts due to the recent growth in mainstream popularity of dance music,
Public, Commercial and Community Radio.
Public radio formats.
Some music radio is broadcast by public service organizations, such as National Public Radio or the BBC. In the United States, public radio is typically confined to three formats: news/talk, classical music, or jazz, the last of which is declining rapidly as of the late 2000s. In other countries, where national broadcasters hold significantly more clout, formats can vary more widely.
Community Radio.
Community radio often relies heavily on the music format because it is relatively cheap and generally makes for easy listening.
Commercial radio.
Commercial stations charge advertisers for the estimated number of listeners. The larger the audience, the higher the stations' rate card can be for commercial advertising.
Commercial stations program the format of the station to gain as large a slice of the demographic audience as possible.
A station's value is usually measured as a percentage of market share in a market of a certain size. The measurement in U.S. markets has historically been by Arbitron, a commercial statistical service that uses listener diaries. Arbitron diaries were historically collected on Thursdays, and for this reason, most radio stations have run special promotions on Thursdays, hoping to persuade last-minute Arbitron diarists to give them a larger market-share. Stations are contractually prohibited from mentioning Arbitron on the air.
Market share is not always a consideration, because not all radio stations are commercial. Public radio is funded by government and private donors. Since most public broadcasting operations don't have to make a profit, no commercials are necessary. (In fact, because most public broadcasting stations operate under noncommercial licenses from their country's broadcasting regulator, they may not be allowed to sell advertising at all.) Underwriting spots, which mention the name of a sponsor and some information but cannot include “calls to action” attempting to convince the listener to patronize the sponsor, may be allowed.
Also, satellite radio either charges subscribers or is operated by a public broadcasting service. Therefore, satellite radio rarely carries commercials or tries to raise money from donors. The lack of commercial interruptions in satellite radio is an important advantage. Often the only breaks in a satellite music station's programming are for station identification and DJ introductions.
Internet radio stations exist that follow all of these plans.
Much early commercial radio was completely freeform; this changed drastically with the payola scandals of the 1950s. As a result, DJs seldom have complete programming freedom. Occasionally a special situation or highly respected, long established personality is given such freedom. Most programming is done by the program director. Program directors may work for the station or at a central location run by a corporate network. The DJ's function is generally reduced to introducing and playing songs. Many stations target younger listeners, because advertisers believe that advertising can change a younger person's product choice. Older people are thought to be less easy to change.
Music radio has several possible arrangements. Originally, it had blocks of sponsored airtime that played music from a live orchestra. In the 1930s, phonograph records, especially the single, let a disc jockey introduce individual songs, or introduce blocks of songs. Since then, the program has been arranged so that commercials are followed by the content that is most valuable to the audience.
Programming is different for non-traditional broadcasting. The Jack FM format eliminates DJs entirely, as do many internet radio stations. The music is simply played. If it is announced, it is by RDS (for FM broadcast) or ID3 tags (for Internet broadcast). Satellite radio usually uses DJs, but their programming blocks are longer and not distinguished much by the time of day. In addition, receivers usually display song titles, so announcing them is not needed.
Internet and satellite broadcasting are not considered public media, so treaties and statutes concerning obscenity, transmission of ciphers and public order do not apply to those formats. So, satellite and internet radio are free to provide sexually explicit, coarse and political material. Typical providers include Playboy Radio, uncensored rap and hard rock stations, and "outlaw" country music stations.
The wide reach and selective, non-broadcast usage of the internet allows programmers access to special interest audiences. As a result, both mainstream and narrow-interest webcasts flourish; in particular, electronic music stations are much more common on the Internet than they are in satellite or broadcast media.
Regional differences.
Outside of English-speaking world, several radio formats built around local musical genres are popular. Examples include Portuguese Fado, Spanish-speaking reggaeton and tejano, French Cajun (especially in French Louisiana), and Russian Shanson.
Cost of programming.
Stations usually adopt a music format to gain the greatest number of listeners for the least expense. Since the content has already been produced, the station merely adds the low-cost on-air programming between records.
Music radio stations pay music-licensing fees to licensing agencies such as ASCAP and BMI in the United States or PRS in the UK. These fees or royalties are generally paid to the songwriters; the musicians themselves typically do not get a cut of radio royalties, even if they own a share of the performance rights, unless they wrote the song themselves. (Thus, a song that is in the public domain is free to play on the radio, regardless of who performs it or when it was performed.) For example, the industry-wide fees payable in 2004 to ASCAP was $176 million. Commercial stations often get their CDs free, but still pay royalties to play it on air. Some small neighborhood stations play unlisted locally produced music, and avoid these fees.
Licensing issues nearly destroyed early Internet radio. In the U.S., Congress intervened with a royalty structure that was expensive to small independent operators, but easier than the RIAA's standard scale. Both XM and Sirius provide commercial packages allowing exclusive license-free use (though not rebroadcast) of their music programming by businesses.
Music radio and culture.
Music radio, particularly top 40, has often acted as both a barometer and an arbiter of musical taste, and radio airplay is one of the defining measures of success in the mainstream musical world. In fact, the rise of rock music to popularity is intimately tied to the history of music radio. Early forms of rock had languished in poor areas of the South. It was enjoyed mostly by rural blacks, with notable exposure in Memphis, Tennessee due to the all African American programming of WDIA. Rock music entered the mainstream during the 1950s because of controversial white DJs such as Dewey Phillips, Alan Freed, Dick Clark and Wolfman Jack with an appreciation for black music. 
For many years, many listeners have been dissatisfied with the content of radio programming since the decline of early free form rock radio. The popularity of offshore pirate radio stations in the United Kingdom was an early symptom of frustration with the often overly safe and occasionally politicized playlists of commercial radio. 
The growth of Internet radio from a small experimenter's toy in the mid-1990s to a huge phenomenon allowing both small do-it-yourselfers and large commercial stations to make their offerings available worldwide was seen as a threat to over-the-air music broadcasting, and was nearly shut down by onerous licensing demands made by the recording industry. Meanwhile, the rise of satellite radio services as a major competitor have brought many of the advantages of Internet radio to an increasingly mobile listening public, including lack of censorship, greater choice, a more eclectic approach to format programming, and static-free digital sound quality. Indeed, one-size-fits-all programming is no longer seen as tenable by some, as the diversity of musical tastes among the listening public have created a proliferation of radio formats in what some might call a form of narrowcasting.

</doc>
<doc id="20844" url="http://en.wikipedia.org/wiki?curid=20844" title="Massively multiplayer online role-playing game">
Massively multiplayer online role-playing game

Massively multiplayer online role-playing games (MMORPGs) blend the genres of role-playing video games and massively multiplayer online games, possibly in the form of web browser-based games, in which a very large number of players interact with one another within a virtual world.
As in all RPGs, the player assume the role of a character (often in a fantasy world or science-fiction world) and takes control over many of that character's actions. MMORPGs are distinguished from single-player or small multi-player online RPGs by the number of players able to interact together, and by the game's persistent world (usually hosted by the game's publisher), which continues to exist and evolve while the player is offline and away from the game.
MMORPGs are played throughout the world. Worldwide revenues for MMORPGs exceeded half a billion dollars in 2005, and Western revenues exceeded US$1 billion in 2006. In 2008, Western consumer spending on subscription MMOGs grew to $1.4 billion.
"World of Warcraft", a popular MMORPG, has over 10 million subscribers as of November 2014. World of Warcraft total revenue was $1.04 Billion US Dollars in 2014. "", released in 2011, became the world's 'Fastest-Growing MMO Ever' after gaining 1 million subscribers within the first three days of its launch.
Common features.
Although modern MMORPGs sometimes differ dramatically from their antecedents, many of them share some basic characteristics. These include several common features: persistent game environment, some form of progression, social interaction within the game, in-game culture, system architecture, membership in a group, and character customization.
Themes.
The majority of popular MMORPGs are based on traditional fantasy themes, often occurring in an in-game universe comparable to that of "Dungeons & Dragons". Some employ hybrid themes that either merge or substitute fantasy elements with those of science fiction, sword and sorcery, or crime fiction. Still others draw thematic material from American comic books, the occult, and other genres. Often these elements are developed using similar tasks and scenarios involving quests, monsters, and loot.
Progression.
In nearly all MMORPGs, the development of the player's character is a primary goal. Nearly all MMORPGs feature a character progression system in which players earn experience points for their actions and use those points to reach character "levels", which makes them better at whatever they do. Traditionally, combat with monsters and completing quests for NPCs, either alone or in groups, are the primary ways to earn experience points. The accumulation of wealth (including combat-useful items) is also a way to progress in many MMORPGs, and again, this is traditionally best accomplished via combat. The cycle produced by these conditions, combat leading to new items allowing for more combat with no change in gameplay, is sometimes pejoratively referred to as the level treadmill, or "grinding". The role-playing game "Progress Quest" was created as a parody of this trend. "Eve Online" trains skills in real time rather than using experience points as a meter of progression.
In some MMORPGs, there is no limit to a player’s level, allowing the grinding experience to continue indefinitely. MMORPGs that use this model often glorify top ranked players by displaying their avatars on the game’s website or posting their stats on a high score screen. Another common practice is to enforce a maximum reachable level for all players, often referred to as a cap. Once reached, the definition of a player’s progression changes. Instead of being awarded primarily with experience for completing quests and dungeons, collecting money and equipment will replace the player’s motivation to continue playing.
Often, the widened range of equipment available at the maximum level will have increased aesthetic value to distinguish high ranking players in game. Colloquially known as endgame gear, this set of empowered weapons and armor adds a competitive edge to both scripted boss encounters as well as player vs. player combat. Player motivation to outperform others is fueled by acquiring such items and is a significant determining factor in their success or failure in combat related situations.
Also, traditional in the genre is the eventual demand on players to team up with others in order to progress at the optimal rate. This sometimes forces players to change their real-world schedules in order to "keep up" within the game-world. A good example of this is the need to trade items to achieve certain goals, or teaming up to kill a powerful enemy. 
Social Interaction.
MMORPGs almost always have tools to facilitate communication between players. Many MMORPGs offer support for in-game guilds or clans (though these will usually form whether the game supports them or not).
In addition, most MMOs require some degree of teamwork for parts of the game. These tasks usually require players to take on roles in the group, such as those protecting other players from damage (called tanking), "healing" damage done to other players or damaging enemies.
MMORPGs generally have Game Moderators or Game Masters (frequently abbreviated to GM), who may be paid employees or unpaid volunteers who attempt to supervise the world. Some GMs may have additional access to features and information related to the game that are not available to other players and roles. Based on Aristotle’s theory regarding the perfect relationship, relationships created in MMORPGs aren’t much different from those created in the physical world. According to this theory, intimacy and mutual caring are the two important aspects of friendship and MMORPGs allow them to develop through shared activity among participants.
Roleplaying.
Most MMORPGs provide different types of classes that players can choose. Among those classes, a small portion of players choose to roleplay their characters, and there are rules that provide functionality and content to this end. Community resources such as forums and guides exist in support of this play style.
For example, if a player wants to play a priest role in his MMORPG world, he might buy a cope from a shop and learn priestly skills, proceeding to speak, act, and interact with others as their character would. This may or may not include pursuing other goals such as wealth or experience. Guilds or similar groups with a focus on roleplaying may develop extended in-depth narratives using the setting and resources of the game world.
Culture.
Over time, the MMORPG community has developed a sub-culture with its own slang and metaphor, as well as an unwritten list of social rules and taboos. Players will often complain about 'grind' (a slang term for any repetitive, time-consuming activity in an MMORPG), or talk about 'buffs' and 'nerfs' (respectively an upgrade or downgrade of a particular game mechanic). Social rules exist for such things as invitations to join an adventuring party, the proper division of treasure, and how a player is expected to behave while grouped with other players.
Debate rages in various gaming media over the long-term impact of video game overuse. The On-Line Gamers Anonymous forums are filled with stories of players that have neglected social, employment and/or family responsibilities in favor of their 'virtual lives'.
System architecture.
Most MMORPGs are deployed using a client–server system architecture. The server software generates a persistent instance of the virtual world that runs continuously, and players connect to it via client software. The client software may provide access to the entire playing world, or further 'expansions' may be required to be purchased to allow access to certain areas of the game. "EverQuest" and "Guild Wars" are two examples of games that use such a format. Players generally must purchase the client software for a one-time fee, although an increasing trend is for MMORPGs to work using pre-existing "thin" clients, such as a web browser.
Some MMORPGs require payment of a monthly subscription to play. By nature, "massively multiplayer" games are always online, and most require some sort of continuous revenue (such as monthly subscriptions and advertisements) for maintenance and development. Some games, such as "Guild Wars" have disposed of the 'monthly fee' model entirely, and recover costs directly through sales of the software and associated expansion packs. Still others adopt a micropayment model where the core content is free, but players are given the option to purchase additional content, such as equipment, aesthetic items, or pets. Games that make use of this model often have originated in Korea, such as "Flyff" and "MapleStory". This business model is alternately called "pay for perks" or "freemium", and games using it often describe themselves with the term "free-to-play".
Depending on the number of players and the system architecture, an MMORPG might actually be run on multiple separate servers, each representing an independent world, where players from one server cannot interact with those from another; "World of Warcraft" is a prominent example, with each separate server housing several thousand players. In many MMORPGs the number of players in one world is often limited to around a few thousand, but a notable example of the opposite is "EVE Online" which accommodates several hundred thousand players on the same server, with over 60,000 playing simultaneously (June 2010) at certain times. Some games allow characters to appear on any world, but not simultaneously (such as "Seal Online: Evolution"), others limit each character to the world in which it was created. "World of Warcraft" has experimented with "cross-realm" (i.e. cross-server) interaction in PvP "battlegrounds", using server clusters or "battlegroups" to co-ordinate players looking to participate in structured PvP content such as the Warsong Gulch or Alterac Valley battlegrounds. Additionally, patch 3.3, released on December 8, 2009, introduced a cross-realm "looking for group" system to help players form groups for instanced content (though not for open-world questing) from a larger pool of characters than their home server can necessarily provide.
History.
The term MMORPG was coined by Richard Garriott, the creator of "Ultima Online", in 1997. Previous to this and related coinages, these games were generally called graphical MUDs; the history of MMORPGs traces back directly through the MUD genre. Through this connection, MMORPGs can be seen to have roots in the earliest multi-user games such as Mazewar (1974) and "MUD1" (1978). 1985 saw the release of a roguelike (pseudo-graphical) MUD called "Island of Kesmai" on CompuServe and Lucasfilm's graphical MUD Habitat. The first fully graphical multi-user RPG was "Neverwinter Nights", which was delivered through America Online in 1991 and was personally championed by AOL President Steve Case. Other early proprietary graphical online RPGs include three on The Sierra Network: "The Shadow of Yserbius" in 1992, "The Fates of Twinion" in 1993, and "The Ruins of Cawdor" in 1995. Another milestone came in 1995 as NSFNET restrictions were lifted, opening the Internet up for game developers, which allowed for the first truly "massively"-scoped titles. Finally, MMORPGs as defined today began with "Meridian 59" in 1996, innovative both in its scope and in offering first-person 3D graphics, with "The Realm Online" appearing nearly simultaneously. "Ultima Online", released in 1997, is often credited with first popularizing the genre, though more mainstream attention was garnered by 1999's "EverQuest" and "Asheron's Call" in the West and 1996's "" in South Korea.
These early titles' financial success has ensured competition in the genre since that time. MMORPG titles now exist on consoles and in new settings. The current market for MMORPGs has Blizzard Entertainment's "World of Warcraft" dominating as the largest MMORPG, alongside other titles such as "Final Fantasy XIV" and "Guild Wars 2", though an additional market exists for free-to-play MMORPGs, which are supported by advertising and purchases of in-game items. This free-to-play model is particularly common in South Korean MMORPGs such as "MapleStory", "", and "Atlantica Online". Also, there are some free-to-play games, such as "RuneScape" & "Tibia", where the game is free, but one would have to pay monthly to play the game with more features. "Guild Wars", and its successor, "Guild Wars 2", are exceptions. They avoid some degree of competition with other MMORPGs by only requiring the initial purchase of the game to play.
Psychology.
Since the interactions between MMORPG players are real, even if the environments are virtual, psychologists and sociologists are able to use MMORPGs as tools for academic research. Sherry Turkle, a clinical psychologist, has conducted interviews with computer users including game-players. Turkle found that many people have expanded their emotional range by exploring the many different roles (including gender identities) that MMORPGs allow a person to explore.
Nick Yee has surveyed more than 35,000 MMORPG players over the past several years, focusing on psychological and sociological aspects of these games. Recent findings included that 15% of players become a guild-leader at one time or another, but most generally find the job tough and thankless; and that players spend a considerable amount of time (often a third of their total time investment) doing things that are external to gameplay but part of the metagame.
Many players report that the emotions they feel while playing an MMORPG are very strong, to the extent that 8.7% of male and 23.2% of female players in a statistical study have had an online wedding. Other researchers have found that the enjoyment of a game is directly related to the social organization of a game, ranging from brief encounters between players to highly organized play in structured groups.
In a study by Zaheer Hussain and Mark D. Griffiths, it was found that just over one in five gamers (21%) said they preferred socializing online to offline. Significantly more male gamers than female gamers said that they found it easier to converse online than offline. It was also found that 57% of gamers had created a character of the opposite gender, and it is suggested that the online female persona has a number of positive social attributes.
A German fMRT-study conducted by researchers of the Central Institute of Mental Health points towards impairments in social, emotional and physical aspects of the self-concept and a higher degree in avatar identification in addicted MMORPG players compared to non-addicted and naive (nonexperienced) people. These findings generally support Davis' cognitive behavioral model of Internet addiction, which postulates that dysfunctional self-related cognitions represent central factors contributing towards the development and maintenance of MMORPG addiction. The high degree of avatar identification found by Leménager et al. in the addicted group of this study indicates that MMORPG playing may represent an attempt to compensate for impairments in self-concept. Psychotherapeutic interventions should therefore focus on the development of coping strategies for real-life situations in which addicted players tend to experience themselves as incompetent and inferior.
Richard Bartle, author of "Designing Virtual Worlds", classified multiplayer RPG-players into four primary psychological groups. His classifications were then expanded upon by Erwin Andreasen, who developed the concept into the thirty-question Bartle Test that helps players determine which category they are associated with. With over 650,000 test responses as of 2011, this is perhaps the largest ongoing survey of multiplayer game players. Based on Bartle and Yee's research, Jon Radoff has published an updated model of player motivation that focuses on immersion, competition, cooperation and achievement. These elements may be found not only in MMORPGs, but many other types of games and within the emerging field of gamification.
In "World of Warcraft", a temporary design glitch attracted the attention of psychologists and epidemiologists across North America, when the "Corrupted Blood" disease of a monster began to spread unintentionally—and uncontrollably—into the wider game world. The Centers for Disease Control used the incident as a research model to chart both the progression of a disease, and the potential human response to large-scale epidemic infection.
Economics.
Many MMORPGs feature living economies. Virtual items and currency have to be gained through play and have definite value for players. Such a virtual economy can be analyzed (using data logged by the game) and has value in economic research; more significantly, these "virtual" economies can have an impact on the economies of the real world.
One of the early researchers of MMORPGs was Edward Castronova, who demonstrated that a supply-and-demand market exists for virtual items and that it crosses over with the real world. This crossover has some requirements of the game:
The idea of attaching real-world value to "virtual" items has had a profound effect on players and the game industry, and even the courts. The virtual currency selling pioneer IGE received a lawsuit from a World of Warcraft player for interfering in the economics and intended use of the game by selling wow gold. Castronova's first study in 2002 found that a highly liquid (if illegal) currency market existed, with the value of "Everquest"'s in-game currency exceeding that of the Japanese yen. Some people even make a living by working these virtual economies; these people are often referred to as gold farmers, and may be employed in game sweatshops.
Game publishers usually prohibit the exchange of real-world money for virtual goods, but others actively promote the idea of linking (and directly profiting from) an exchange. In "Second Life" and "Entropia Universe", the virtual economy and the real-world economy are directly linked. This means that real money can be deposited for game money and vice versa. Real-world items have also been sold for game money in "Entropia", and some players of "Second Life" have generated revenues in excess of $100,000.
Some of the issues confronting online economies include:
Linking real-world and virtual economies is rare in MMORPGs, as it is generally believed to be detrimental to gameplay. If real-world wealth can be used to obtain greater, more immediate rewards than skillful gameplay, the incentive for strategic roleplay and real game involvement is diminished. It could also easily lead to a skewed hierarchy where richer players gain better items, allowing them to take on stronger opponents and level up more quickly than less wealthy but more committed players.
Development.
The cost of developing a competitive commercial MMORPG title often exceeded $10 million by 2003. These projects require multiple disciplines within game design and development such as 3D modeling, 2D art, animation, user interfaces, client/server engineering, database architecture, and network infrastructure.
The front-end (or client) component of a commercial, modern MMORPG features 3D graphics. As with other modern 3D games, the front-end requires expertise with implementing 3D engines, real-time shader techniques and physics simulation. The actual visual content (areas, creatures, characters, weapons, spaceships and so forth) is developed by artists who typically begin with two-dimensional concept art, and later convert these concepts into animated 3D scenes, models and texture maps.
Developing an MMOG server requires expertise with client/server architecture, network protocols, security, and database design. MMORPGs include reliable systems for a number of vital tasks. The server must be able to handle and verify a large number of connections, prevent cheating, and apply changes (bug fixes or added content) to the game. A system for recording the game's data at regular intervals, without stopping the game, is also important.
Maintenance requires sufficient servers and bandwidth, and a dedicated support staff. Insufficient resources for maintenance lead to lag and frustration for the players, and can severely damage the reputation of a game, especially at launch. Care must also be taken to ensure that player population remains at an acceptable level by adding or removing servers. Peer-to-peer MMORPGs could theoretically work cheaply and efficiently in regulating server load, but practical issues such as asymmetrical network bandwidth, CPU-hungry rendering engines, unreliability of individual nodes, and inherent lack of security (opening fertile new grounds for cheating) make them a difficult proposition. The hosted infrastructure for a commercial-grade MMORPG requires the deployment of hundreds (or even thousands) of servers. Developing an affordable infrastructure for an online game requires developers to scale to large numbers of players with less hardware and network investment.
In addition, the development team will need to have expertise with the fundamentals of game design: world-building, lore and game mechanics, as well as what makes games fun.
Non-corporate development.
Though the vast majority of MMORPGs are produced by companies, many small teams of programmers and artists have contributed to the genre. As shown above, the average MMORPG development project requires enormous investments of time and money, and running the game can be a long-term commitment. As a result, non-corporate (or independent, or "indie") development of MMORPGs is less common compared with other genres. Still, many independent MMORPGs do exist, representing a wide spectrum of genres, gameplay types, and revenue systems.
Some independent MMORPG projects are completely open source, while others feature proprietary content made with an open-source game engine. The WorldForge project has been active since 1998 and formed a community of independent developers who are working on creating framework for a number of open-source MMORPGs. The Multiverse Foundation has also created a platform specifically for independent MMOG developers.
Trends.
As there are a number of wildly different titles within the genre, and since the genre develops so rapidly, it is difficult to definitively state that the genre is heading in one direction or another. Still, there are a few obvious developments. One of these developments is the raid group quest, or "raid", which is an adventure designed for large groups of players (often twenty or more).
Instance dungeons.
Instance dungeons, sometimes shortened to "instances", are game areas that are "copied" for individual players or groups, which keeps those in the instance separated from the rest of the game world. This reduces competition, while also reducing the amount of data that needs to be sent to and from the server, reducing lag. "The Realm Online" was the first MMORPG to begin to use a rudimentary form of this technique and "Anarchy Online" would develop it further, using instances as a key element of gameplay. Since then, instancing has become increasingly common. The "raids", as mentioned above, often involve instance dungeons. Examples of games which feature instances are "World of Warcraft", "The Lord of the Rings Online", "EverQuest", "EverQuest II", "", "Final Fantasy XIV", "Guild Wars", "Rift", "RuneScape", "Star Trek Online" and "DC Universe Online".
Player-created content.
Increased amounts of "player-created content" may be another trend.
Use of licenses.
The use of intellectual property licensing, common in other video game genres, has also appeared in MMORPGs. 2007 saw the release of "The Lord of the Rings Online", based on J. R. R. Tolkien's Middle-earth. Other licensed MMORPGs include "The Matrix Online", based on the "Matrix" trilogy of films, "", based on Games Workshop's table top game, "Star Wars Galaxies", "Star Wars The Old Republic", "Champions Online" and "Age of Conan".
Additionally, several licenses from television have been optioned for MMORPGs, for example "Star Trek Online" and "Stargate Worlds" (which was canceled).
Console-based MMORPGs.
The first console-based MMORPG was "Phantasy Star Online" for the Sega Dreamcast. The first console-based open-world MMORPG was "Final Fantasy XI" for the Sony PlayStation 2.
"EverQuest Online Adventures", also on the PlayStation 2, was the first console MMORPG in North America.
Although console-based MMORPGs are considered more difficult to produce, the platform is gaining more attention.
Browser-based MMORPGs.
With the popularization of Facebook and microtransactions has come a new wave of Flash and HTML5 based MMORPGs that use the free to play model. They require no download outside of a browser and usually have heavily integrated social media sharing features. An example of a browser-based MMORPG is Freewar.
Smartphone-based MMORPGs.
Smartphones with their GPS capabilities (amongst others) enable augmented reality games such as Ingress.

</doc>
<doc id="20845" url="http://en.wikipedia.org/wiki?curid=20845" title="Multiplication">
Multiplication

Multiplication (often denoted by the cross symbol "×", by a point "·" or by the absence of symbol) is one of the four elementary, mathematical operations of arithmetic; with the others being addition, subtraction and division.
The multiplication of two whole numbers is equivalent to adding as many copies of one of them, as the value of the other one:
For example, 3 multiplied by 4 (often said as "3 times 4") can be calculated by adding 3 copies of 4 together:
Here 3 and 4 are the "factors" and 12 is the "product".
One of the main properties of multiplication is the commutative property, adding 3 copies of 4 gives the same result as adding 4 copies of 3:
The multiplication of integers (including negative numbers), rational numbers (fractions) and real numbers is defined by a systematic generalization of this basic definition.
Multiplication can also be visualized as counting objects arranged in a rectangle (for whole numbers) or as finding the area of a rectangle whose sides have given lengths. The area of a rectangle does not depend on which side is measured first, which illustrates the commutative property.
The inverse operation of the multiplication is the division. For example, since 4 multiplied by 3 equals 12, then 12 divided by 3 equals 4. Multiplication by 3, followed by division by 3, yields the original number (since the division of a number other than 0 by itself equals 1).
Multiplication is also defined for other types of numbers, such as complex numbers, and more abstract constructs, like matrices. For these more abstract constructs, the order that the operands are multiplied sometimes does matter.
Notation and terminology.
In arithmetics, multiplication is often written using the sign "×" between the terms; that is, in infix notation. For example,
The sign is encoded in Unicode at .
There are other mathematical notations for multiplication:
In computer programming, the asterisk (as in codice_1) is the standard notation: it belongs to most character sets and appears on every keyboard. This usage originated in the FORTRAN programming language.
The numbers to be multiplied are generally called the "factors" or "multiplicands". When thinking of multiplication as repeated addition, the number to be multiplied is called the "multiplicand", while the number of addends is called the "multiplier". In algebra, a number that is the multiplier of a variable or expression (e.g., the 3 in 3"xy"2) is called a coefficient.
The result of a multiplication is called a product. A product of integers is a multiple of each factor. For example, 15 is the product of 3 and 5, and is both a multiple of 3 and a multiple of 5.
Computation.
The common methods for multiplying numbers using pencil and paper require a multiplication table of memorized or consulted products of small numbers (typically any two numbers from 0 to 9), however one method, the peasant multiplication algorithm, does not. 
Multiplying numbers to more than a couple of decimal places by hand is tedious and error prone. Common logarithms were invented to simplify such calculations. The slide rule allowed numbers to be quickly multiplied to about three places of accuracy. Beginning in the early twentieth century, mechanical calculators, such as the Marchant, automated multiplication of up to 10 digit numbers. Modern electronic computers and calculators have greatly reduced the need for multiplication by hand.
Historical algorithms.
Methods of multiplication were documented in the Egyptian, Greek, Indian and Chinese civilizations.
The Ishango bone, dated to about 18,000 to 20,000 BC, hints at a knowledge of multiplication in the Upper Paleolithic era in Central Africa.
Egyptians.
The Egyptian method of multiplication of integers and fractions, documented in the Ahmes Papyrus, was by successive additions and doubling. For instance, to find the product of 13 and 21 one had to double 21 three times, obtaining 1 × 21 = 21, 4 × 21 = 84, 8 × 21 = 168. The full product could then be found by adding the appropriate terms found in the doubling sequence:
Babylonians.
The Babylonians used a sexagesimal positional number system, analogous to the modern day decimal system. Thus, Babylonian multiplication was very similar to modern decimal multiplication. Because of the relative difficulty of remembering 60 × 60 different products, Babylonian mathematicians employed multiplication tables. These tables consisted of a list of the first twenty multiples of a certain "principal number" "n": "n", 2"n", ..., 20"n"; followed by the multiples of 10"n": 30"n" 40"n", and 50"n". Then to compute any sexagesimal product, say 53"n", one only needed to add 50"n" and 3"n" computed from the table.
Chinese.
In the mathematical text "Zhou Bi Suan Jing", dated prior to 300 BC, and the "Nine Chapters on the Mathematical Art", multiplication calculations were written out in words, although the early Chinese mathematicians employed Rod calculus involving place value addition, subtraction, multiplication and division. These place value decimal arithmetic algorithms were introduced by Al Khwarizmi to Arab countries in the early 9th century.
Modern method.
The modern method of multiplication based on the Hindu–Arabic numeral system was first described by Brahmagupta. Brahmagupta gave rules for addition, subtraction, multiplication and division. Henry Burchard Fine, then professor of Mathematics at Princeton University, wrote the following:
Computer algorithms.
The classical method of multiplying two "n"-digit numbers requires "n"2 simple multiplications. Multiplication algorithms have been designed that reduce the computation time considerably when multiplying large numbers. In particular for very large numbers methods based on the Discrete Fourier Transform can reduce the number of simple multiplications to the order of "n" log2("n") log2 log2("n").
Products of measurements.
When two measurements are multiplied together the product is of a type depending on the types of the measurements. The general theory is given by dimensional analysis. This analysis is routinely applied in physics but has also found applications in finance. One can only meaningfully add or subtract quantities of the same type but can multiply or divide quantities of different types.
A common example is multiplying speed by time gives distance, so
Other examples:
Products of sequences.
Capital Pi notation.
The product of a sequence of terms can be written with the product symbol, which derives from the capital letter Π (Pi) in the Greek alphabet. Unicode position U+220F (∏) contains a glyph for denoting such a product, distinct from U+03A0 (Π), the letter. The meaning of this notation is given by:
that is
The subscript gives the symbol for a dummy variable ("i" in this case), called the "index of multiplication" together with its lower bound ("1"), whereas the superscript (here "4") gives its upper bound. The lower and upper bound are expressions denoting integers. The factors of the product are obtained by taking the expression following the product operator, with successive integer values substituted for the index of multiplication, starting from the lower bound and incremented by 1 up to and including the upper bound. So, for example:
More generally, the notation is defined as
where "m" and "n" are integers or expressions that evaluate to integers. In case "m" = "n", the value of the product is the same as that of the single factor "x""m". If "m" > "n", the product is the empty product, with the value 1.
Infinite products.
One may also consider products of infinitely many terms; these are called infinite products. Notationally, we would replace "n" above by the lemniscate ∞. The product of such a series is defined as the limit of the product of the first "n" terms, as "n" grows without bound. That is, by definition,
One can similarly replace "m" with negative infinity, and define:
provided both limits exist.
Properties.
For the real and complex numbers, which includes for example natural numbers, integers and fractions, multiplication has certain properties:
Other mathematical systems that include a multiplication operation may not have all these properties. For example, multiplication is not, in general, commutative for matrices and quaternions.
Axioms.
In the book "Arithmetices principia, nova methodo exposita", Giuseppe Peano proposed axioms for arithmetic based on his axioms for natural numbers. Peano arithmetic has two axioms for multiplication:
Here "S"("y") represents the successor of "y", or the natural number that "follows" "y". The various properties like associativity can be proved from these and the other axioms of Peano arithmetic including induction. For instance "S"(0). denoted by 1, is a multiplicative identity because
The axioms for integers typically define them as equivalence classes of ordered pairs of natural numbers. The model is based on treating ("x","y") as equivalent to "x"−"y" when "x" and "y" are treated as integers. Thus both (0,1) and (1,2) are equivalent to −1. The multiplication axiom for integers defined this way is
The rule that −1 × −1 = 1 can then be deduced from
Multiplication is extended in a similar way to rational numbers and then to real numbers.
Multiplication with set theory.
The product of non-negative integers can be defined with set theory using cardinal numbers or the Peano axioms. See below how to extend this to multiplying arbitrary integers, and then arbitrary rational numbers. The product of real numbers is defined in terms of products of rational numbers, see construction of the real numbers.
Multiplication in group theory.
There are many sets that, under the operation of multiplication, satisfy the axioms that define group structure. These axioms are closure, associativity, and the inclusion of an identity element and inverses.
A simple example is the set of non-zero rational numbers. Here we have identity 1, as opposed to groups under addition where the identity is typically 0. Note that with the rationals, we must exclude zero because, under multiplication, it does not have an inverse: there is no rational number that can be multiplied by zero to result in 1. In this example we have an abelian group, but that is not always the case.
To see this, look at the set of invertible square matrices of a given dimension, over a given field. Now it is straightforward to verify closure, associativity, and inclusion of identity (the identity matrix) and inverses. However, matrix multiplication is not commutative, therefore this group is nonabelian.
Another fact of note is that the integers under multiplication is not a group, even if we exclude zero. This is easily seen by the nonexistence of an inverse for all elements other than 1 and -1.
Multiplication in group theory is typically notated either by a dot, or by juxtaposition (the omission of an operation symbol between elements). So multiplying element a by element b could be notated a formula_31 b or ab. When referring to a group via the indication of the set and operation, the dot is used, e.g., our first example could be indicated by formula_32
Multiplication of different kinds of numbers.
Numbers can "count" (3 apples), "order" (the 3rd apple), or "measure" (3.5 feet high); as the history of mathematics has progressed from counting on our fingers to modelling quantum mechanics, multiplication has been generalized to more complicated and abstract types of numbers, and to things that are not numbers (such as matrices) or do not look much like numbers (such as quaternions).
Exponentiation.
When multiplication is repeated, the resulting operation is known as exponentiation. For instance, the product of three factors of two (2×2×2) is "two raised to the third power", and is denoted by 23, a two with a superscript three. In this example, the number two is the base, and three is the exponent. In general, the exponent (or superscript) indicates how many times to multiply base by itself, so that the expression
indicates that the base "a" to be multiplied by itself "n" times.

</doc>
<doc id="20853" url="http://en.wikipedia.org/wiki?curid=20853" title="Malt">
Malt

Malt is germinated cereal grains that have been dried in a process known as "malting". The grains are made to germinate by soaking in water, and are then halted from germinating further by drying with hot air. By malting grains, the enzymes are developed that are required for modifying the grain's starches into sugars, including the monosaccharide glucose, the disaccharide maltose, the trisaccharide maltotriose, and higher sugars called maltodextrines. It also develops other enzymes, such as proteases, which break down the proteins in the grain into forms that can be used by yeast. Malt also contains small amounts of other sugars, such as sucrose and fructose, which are not products of starch modification but were already in the grain.
Malted grain is used to make beer, whisky, malted shakes, malt vinegar, confections such as Maltesers and Whoppers, flavored drinks such as Horlicks, Ovaltine and Milo, and some baked goods, such as malt loaf, bagels and rich tea biscuits. Malted grain that has been ground into a coarse meal is known as "sweet meal". Various cereals are malted, though barley is the most common. A high-protein form of malted barley is often a label-listed ingredient in blended flours typically used in the manufacture of yeast breads and other baked goods.
The term "malt" refers to several products of the process: the grains to which this process has been applied, for example malted barley; the sugar, heavy in maltose, derived from such grains, such as the baker's malt used in various cereals; or a product based on malted milk, similar to a malted milkshake (i.e., "malts").
History.
Malted grains have likely been used as an ingredient of beer since ancient times, for example in Egypt (Ancient Egyptian cuisine), Sumeria and China.
In Persian countries a sweet paste made entirely from germinated wheat is called Samanū (Persian: سمنو‎) in Iran, Samanak (Persian: سمنک‎), (Tajik: сумалак); (Uzbek: sumalak) or Sümölök (Kyrgyz: сүмөлөк), which is prepared for Nowruz (Persian new year celebration) in a large pot (like a kazan). A plate or bowl of Samanu is a traditional component of the Haft sin table symbolising affluence. Traditionally, women take a special party for it during the night, and cook it from late in the evening till the daylight, singing related songs. In Tajikistan and Afghanistan they sing: "Samanak dar Jūsh u mā Kafcha zanēm - Dīgarān dar Khwāb u mā Dafcha zanēm". (meaning: "Samanak is boiling and we are stirring it, others are asleep and we are playing daf"). In modern times, making sumanu can be a family gathering. It originally comes from the Great Persian Empire.
Mämmi, or Easter Porridge, is a traditional Finnish Lenten food. Cooked from rye malt and -flour, mämmi has a great resemblance (in recipe, colour and taste) to Samanū. Today, this product is available in shops from February until Easter. A (non-representative) survey in 2013 showed that almost no one cooks mämmi at home in modern-day Finland.
Malting.
Malting is the process of converting barley or other cereal grains into malt, for use in brewing, distilling, or in foods and takes place in a maltings, sometimes called a malthouse, or a malting floor. The cereal is spread out on the malting floor in a layer of 8 to 12 cm (3 to 5 inch) depth. The malting process starts with drying the grains to a moisture content below 14%, and then storing for around six weeks to overcome seed dormancy. When ready, the grain is immersed or steeped in water two or three times over two or three days to allow the grain to absorb moisture and to start to sprout. When the grain has a moisture content of around 46%, it is transferred to the malting or germination floor, where it is constantly turned over for around five days while it is air-dried . The grain at this point is called "green malt". The green malt is then kiln-dried to the desired colour and specification. Malts range in colour from very pale through crystal and amber to chocolate or black malts.
The sprouted grain is kiln-dried by spreading it on a perforated wooden floor. Smoke, coming from an oasting fireplace (via smoke channels) is then used to heat the wooden floor and the sprouted grains. The temperature is usually around 55 C. A typical floor maltings is a long, single-storey building with a floor that slopes slightly from one end of the building to the other. Floor maltings began to be phased out in the 1940s in favour of "pneumatic plants". Here, large industrial fans are used to blow air through the germinating grain beds and to pass hot air through the malt being kilned. Like floor maltings, these pneumatic plants are batch processes, but of considerably greater size, typically 100 ton batches compared with 20 ton batches for floor malting.
s of 2014[ [update]], the largest malting operation in the world was Malteurope, which operated in 14 countries.
Malts.
Barley is the most commonly malted grain, in part because of its high diastatic power or enzyme content, though wheat, rye, oats and rice are also used. Also very important is the retention of the grain's husk, even after threshing, unlike the bare seeds of threshed wheat or rye. This protects the growing acrospire (developing plant embryo) from damage during malting, which can easily lead to mold growth; it also allows the mash of converted grain to create a filter bed during lautering (see brewing). Malt is often divided into two categories by brewers: base malts and specialty malts; base malts have enough diastatic power to convert their own starch and usually that of some amount of starch from unmalted grain, called adjuncts, while specialty malts have little diastatic power, but provide flavor, color, or "body" (viscosity) to the finished beer. Specialty caramel or crystal malts have been subjected to heat treatment to convert their starches to sugars nonenzymatically. Within these categories is a variety of types distinguished largely by the kilning temperature (see mash ingredients). In addition, malts are distinguished by the two major species of barley used for malting, two-row and six-row. The most common varieties of barley used for malting in America from 2009-2013 are two-row AC Metcalfe and Conrad; and six-row Tradition and Lacey cultivars.
Malt extract.
Malt extract is also known as extract of malt. It is a sweet, treacly substance used as a dietary supplement. It was popular in the first half of the twentieth century as a supplement for the children of the British urban working-class, whose diet was often deficient in vitamins and minerals. Children were given cod liver oil for the same reason but it proved so unpalatable that it was combined with extract of malt to produce "Malt and Cod-Liver Oil." Malt extract was given as a "strengthening medicine" by Kanga to Roo in "The House at Pooh Corner", and was also Tigger's favorite food in the book.
The 1907 British Pharmaceutical Codex's instructions for making nutritional extract of malt do not include a mash-out at the end of extraction, and include the use of lower mash temperatures than is typical with modern beer-brewing practices. The Codex indicates that diastatic activity is to be preserved by the use of temperatures not exceeding 55 C.
Malt extract production.
Malt extract is frequently used in the brewing of beer. Its production begins by germinating barley grain in a process known as malting. This procedure entails immersing barley in water to encourage the grain to sprout, then drying the barley to halt the progress when the sprouting begins. The drying step stops the sprouting, but the enzymes remain active due to the low temperatures used in base malt production. In one before-and-after comparison, malting decreased barley's extractable starch content by about 7% on a dry matter basis, and turned that portion into various other carbohydrates.
In the next step, brewers use a process called mashing to extract the sugars. Brewers warm cracked malt in temperature-modulated water, activating the enzymes, which cleave more of the malt's remaining starch into various sugars, the largest percentage of which is maltose. Modern beer mashing practices typically include high enough temperatures at mash-out to deactivate remaining enzymes, thus it is no longer diastatic. The liquid produced from this, wort, is then concentrated by using heat or a vacuum procedure to evaporate water from the mixture. The concentrated wort is called malt extract.
Liquid malt extract (LME) is a thick syrup and is used for a variety of purposes, such as baking and brewing. It is also sold in jars as a consumer product.
The LME may be further dried to produce dry malt extract (DME) which is crystalline in form similar to common sugar.
Brewers have the option of using a liquid (LME) or dry (DME) form of it. Each has its pros and cons, so the choice is dependent solely on the individual brewer's preferences. Some brewers choose to work only with LME, because they feel it works best for the result they wish to achieve. Also, it requires one fewer processing step, so it is appealing to those favoring the purest form of product available. However, it is very sticky and, therefore, messier to work with and has a shorter shelf life, and some feel the results are just as good with DME.
A new encapsulating technology permits the production of malt granules. Malt granules are the dried liquid extract from malt used in the brewing or distilling process.
Research.
Scientists aim to discover what goes on inside barley grains as they become malted to help plant breeders produce better malting barley for food and beverage products. Agricultural Research Service scientists are interested in specialized enzymes called serine-class proteases that digest beta-amylases, which convert carbohydrates into "simple sugars" during the sprouting process. The enzyme also breaks down stored proteins into their amino acid derivatives. The balance of proteins and carbohydrates broken down by the enzyme affect the malt’s flavor.

</doc>
<doc id="20857" url="http://en.wikipedia.org/wiki?curid=20857" title="Masonry">
Masonry

Masonry is the building of structures from individual units laid in and bound together by mortar; the term "masonry" can also refer to the units themselves. The common materials of masonry construction are brick, stone, marble, granite, travertine, limestone, cast stone, concrete block, glass block, stucco, tile, and cob. Masonry is generally a highly durable form of construction. However, the materials used, the quality of the mortar and workmanship, and the pattern in which the units are assembled can significantly affect the durability of the overall masonry construction. A person who constructs masonry is called a Mason, or Bricklayer.
Applications.
Masonry is commonly used for the walls of buildings, retaining walls and buildings. Brick and concrete block are the most common types of masonry in use in industrialized nations and may be either weight-bearing or a veneer. Concrete blocks, especially those with hollow cores, offer various possibilities in masonry construction. They generally provide great compressive strength, and are best suited to structures with light transverse loading when the cores remain unfilled. Filling some or all of the cores with concrete or concrete with steel reinforcement (typically rebar) offers much greater tensile and lateral strength to structures.
Structural limitations.
Masonry has high compressive strength under vertical loads but has low tensile strength (against twisting or stretching) unless reinforced. The tensile strength of masonry walls can be increased by thickening the wall, or by building masonry "piers" (vertical columns or ribs) at intervals. Where practical, steel reinforcements such as windposts can be added.
Veneer masonry.
A masonry veneer wall consists of masonry units, usually clay-based bricks, installed on one or both sides of a structurally independent wall usually constructed of wood or masonry. In this context the brick masonry is primarily decorative, not structural. The brick veneer is generally connected to the structural wall by brick ties (metal strips that are attached to the structural wall, as well as the mortar joints of the brick veneer). There is typically an air gap between the brick veneer and the structural wall. As clay-based brick is usually not completely waterproof, the structural wall will often have a water-resistant surface (usually tar paper) and weep holes can be left at the base of the brick veneer to drain moisture that accumulates inside the air gap. Concrete blocks, real and cultured stones, and veneer adobe are sometimes used in a very similar veneer fashion.
Most insulated buildings that utilize concrete block, brick, adobe, stone, veneers or some combination thereof feature interior insulation in the form of fiberglass batts between wooden wall studs or in the form of rigid insulation boards covered with plaster or drywall. In most climates this insulation is much more effective on the exterior of the wall, allowing the building interior to take advantage of the aforementioned thermal mass of the masonry. This technique does, however, require some sort of weather-resistant exterior surface over the insulation and, consequently, is generally more expensive.
Dry set masonry.
The strength of a masonry wall is not entirely dependent on the bond between the building material and the mortar; the friction between the interlocking blocks of masonry is often strong enough to provide a great deal of strength on its own. The blocks sometimes have grooves or other surface features added to enhance this interlocking, and some "dry set" masonry structures forgo mortar altogether.
Brick.
Solid brickwork is made of two or more wythes of bricks with the units running horizontally (called "stretcher" bricks) bound together with bricks running transverse to the wall (called "header" bricks). Each row of bricks is known as a course. The pattern of headers and stretchers employed gives rise to different bonds such as the common bond (with every sixth course composed of headers), the English bond, and the Flemish bond (with alternating stretcher and header bricks present on every course). Bonds can differ in strength and in insulating ability. Vertically staggered bonds tend to be somewhat stronger and less prone to major cracking than a non-staggered bond.
Uniformity and rusticity.
The wide selection of brick styles and types generally available in industrialized nations allow much variety in the appearance of the final product. In buildings built during the 1950s-1970s, a high degree of uniformity of brick and accuracy in masonry was typical. In the period since then this style was thought to be too sterile, so attempts were made to emulate older, rougher work. Some brick surfaces are made to look particularly rustic by including "burnt" bricks, which have a darker color or an irregular shape. Others may use antique salvage bricks, or new bricks may be artificially aged by applying various surface treatments, such as tumbling. The attempts at rusticity of the late 20th century have been carried forward by masons specializing in a free, artistic style, where the courses are intentionally "not" straight, instead weaving to form more organic impressions.
Serpentine masonry.
A crinkle-crankle wall is a brick wall that follows a serpentine path, rather than a straight line. This type of wall is more resistant to toppling than a straight wall; so much so that it may be made of a single wythe of unreinforced brick and so despite its longer length may be more economical than a straight wall.
Concrete block.
Blocks of cinder concrete ("cinder blocks" or "breezeblocks"), ordinary concrete ("concrete blocks"), or hollow tile are generically known as Concrete Masonry Units (CMUs). They usually are much larger than ordinary bricks and so are much faster to lay for a wall of a given size. Furthermore, cinder and concrete blocks typically have much lower water absorption rates than brick. They often are used as the structural core for veneered brick masonry, or are used alone for the walls of factories, garages and other industrial-style buildings where such appearance is acceptable or desirable. Such blocks often receive a stucco surface for decoration. Surface-bonding cement, which contains synthetic fibers for reinforcement, is sometimes used in this application and can impart extra strength to a block wall. Surface-bonding cement is often pre-coloured and can be stained or painted thus resulting in a finished stucco-like surface.
The primary structural advantage of concrete blocks in comparison to smaller clay-based bricks is that a CMU wall can be reinforced by filling the block voids with concrete with or without steel rebar. Generally, certain voids are designated for filling and reinforcement, particularly at corners, wall-ends, and openings while other voids are left empty. This increases wall strength and stability more economically than filling and reinforcing all voids. Typically, structures made of CMUs will have the top course of blocks in the walls filled with concrete and tied together with steel reinforcement to form a bond beam. Bond beams are often a requirement of modern building codes and controls. Another type of steel reinforcement, referred to as ladder-reinforcement, can also be embedded in horizontal mortar joints of concrete block walls. The introduction of steel reinforcement generally results in a CMU wall having much greater lateral and tensile strength than unreinforced walls.
CMUs can be manufactured to provide a variety of surface appearances. They can be colored during manufacturing or stained or painted after installation. They can be split as part of the manufacturing process, giving the blocks a rough face replicating the appearance of natural stone, such as brownstone. CMUs may also be scored, ribbed, sandblasted, polished, striated (raked or brushed), include decorative aggregates, be allowed to slump in a controlled fashion during curing, or include several of these techniques in their manufacture to provide a decorative appearance.
"Glazed concrete masonry units are manufactured by bonding a permanent colored facing (typically composed of polyester resins, silica sand and various other chemicals) to a concrete masonry unit, providing a smooth impervious surface."
Glass block or glass brick are blocks made from glass and provide a translucent to clear vision through the block.
A-jacks.
A-jacks (used in erosion control walls and sea walls) are highly stable, concrete 6-pronged armor units designed to interlock into a flexible, highly permeable matrix. They can be installed either randomly or in a uniform pattern. They look like giant 3-foot versions of the metal jacks that children play with.
In the uniform placement pattern, each unit is in contact with the six adjacent units, providing high stability. They are patterned after the buckyball model.
Stonework.
Stone blocks used in masonry can be dressed or rough, though in both examples: corners, door and window jambs, and similar areas are usually dressed.
Stone masonry utilizing dressed stones is known as ashlar masonry, whereas masonry using irregularly shaped stones is known as rubble masonry. Both rubble and ashlar masonry can be laid in coursed rows of even height through the careful selection or cutting of stones, but a great deal of stone masonry is uncoursed.
Gabions.
Gabions are rectangular wire baskets, usually of zinc-protected steel (galvanized steel) that are filled with fractured stone of medium size. These will act as a single unit and are stacked with setbacks to form a revetment or retaining wall. They have the advantage of being both well drained and flexible, and so resistant to flood, water flow from above, frost damage, and soil flow. Their expected useful life is only as long as the wire they are composed of and if used in severe climates (such as shore-side in a salt water environment) must be made of appropriate corrosion-resistant wire.
Bagged concrete.
A low grade concrete may be placed in woven plastic sacks similar to that used for sandbags and then emplaced. The sacks are then watered and the emplacement then becomes a series of artificial stones that conform to one another and to adjacent soil and structures. This conformation makes them resistant to displacement. The sack becomes non-functional and eventually disintegrates. This type of masonry is frequently used to protect the entrances and exits of water conduits where a road passes over a stream or dry wash. It is also used to protect stream banks from erosion, especially where a road passes close by.
Masonry training.
Stonemasonry happens to be one of those professions that was one of the first in the history of construction. It is very much regarded as a traditional skill.
Passive fire protection (PFP).
Masonry walls have an endothermic effect of its hydrates, as in chemically bound water, as well as unbound moisture from the concrete block, as well as the poured concrete if the hollow cores inside the blocks are filled.
Masonry buildings can also be built to increase safety by reducing fire damage, such as the use of fire cuts during construction.
Mechanical modelling of masonry structures.
From the point of view of material modelling, masonry is a special material of extreme mechanical properties (with a very high ratio between strength in compression and in tension), so that the applied loads do not diffuse as they do in elastic bodies, but tend to percolate along lines of high stiffness, see the figure on the right and watch a for more details.
References.
V. Sarhosis, Y. Sheng, Identification of material parameters for low bond strength masonry, Engineering Structures, Volume 60, February 2014, Pages 100-110, ISSN 0141-0296, http://dx.doi.org/10.1016/j.engstruct.2013.12.013.
http://www.sciencedirect.com/science/article/pii/S0141029613006007

</doc>
<doc id="20858" url="http://en.wikipedia.org/wiki?curid=20858" title="Mortar">
Mortar

Mortar may refer to:

</doc>
<doc id="20859" url="http://en.wikipedia.org/wiki?curid=20859" title="Mickey Mouse">
Mickey Mouse

Mickey Mouse is a funny animal cartoon character and the official mascot of The Walt Disney Company. He was created by Walt Disney and Ub Iwerks at the Walt Disney Studios in 1928. An anthropomorphic mouse who typically wears red shorts, large yellow shoes, and white gloves, Mickey has become one of the most recognizable cartoon characters in the world.
Mickey first was seen in a single test screening ("Plane Crazy"). Mickey officially debuted in the short film "Steamboat Willie" (1928), one of the first sound cartoons. He went on to appear in over 130 films, including "The Band Concert" (1935), "Brave Little Tailor" (1938), and "Fantasia" (1940). Mickey appeared primarily in short films, but also occasionally in feature-length films. Ten of Mickey's cartoons were nominated for the Academy Award for Best Animated Short Film, one of which, "Lend a Paw", won the award in 1942. In 1978, Mickey became the first cartoon character to have a star on the Hollywood Walk of Fame.
Beginning in 1930, Mickey has also been featured extensively as a comic strip character. His self-titled newspaper strip, drawn primarily by Floyd Gottfredson, ran for 45 years. Mickey has also appeared in comic books and in television series such as "The Mickey Mouse Club" (1955–1996) and others. He also appears in other media such as video games as well as merchandising, and is a meetable character at the Disney parks.
Mickey generally appears alongside his girlfriend Minnie Mouse, his pet dog Pluto, his friends Donald Duck, and Goofy, and his nemesis Pete, among others (see Mickey Mouse universe). Originally characterized as a mischievous antihero, Mickey's increasing popularity led to his being rebranded as an everyman, usually seen as a flawed, but adventurous hero. In 2009, Disney began to rebrand the character again by putting less emphasis on his pleasant, cheerful side and reintroducing the more mischievous and adventurous sides of his personality, beginning with the video game "Epic Mickey".
Origin.
"I only hope that we never lose sight of one thing – that it was all started by a mouse."—Walt Disney, "Disneyland"; October 27, 1954
Mickey Mouse was created as a replacement for Oswald the Lucky Rabbit, an earlier cartoon character created by the Disney studio for Charles Mintz, a film producer who distributed product through Universal Studios. In the spring of 1928, with the series going strong, Disney asked Mintz for an increase in the budget. But Mintz instead demanded that Walt take a 20 percent budget cut, and as leverage, he reminded Disney that Universal owned the character, and revealed that he had already signed most of Disney's current employees to his new contract. Angrily, Disney refused the deal and returned to produce the final Oswald cartoons he contractually owed Mintz. Disney was dismayed at the betrayal by his staff, but determined to restart from scratch. The new Disney Studio initially consisted of animator Ub Iwerks and a loyal apprentice artist, Les Clark, who together with Wilfred Jackson were among the few who remained loyal to Walt. One lesson Disney learned from the experience was to thereafter always make sure that he owned all rights to the characters produced by his company.
In the spring of 1928, Disney asked Ub Iwerks to start drawing up new character ideas. Iwerks tried sketches of various animals, such as dogs and cats, but none of these appealed to Disney. A female cow and male horse were also rejected. They would later turn up as Clarabelle Cow and Horace Horsecollar. A male frog was also rejected. It would later show up in Iwerks' own "Flip the Frog" series. Walt Disney got the inspiration for Mickey Mouse from a tame mouse at his desk at Laugh-O-Gram Studio in Kansas City, Missouri. In 1925, Hugh Harman drew some sketches of mice around a photograph of Walt Disney. These inspired Ub Iwerks to create a new mouse character for Disney. "Mortimer Mouse" had been Disney's original name for the character before his wife, Lillian, convinced him to change it, and ultimately Mickey Mouse came to be. The actor Mickey Rooney claimed that, during his Mickey McGuire days, he met cartoonist Walt Disney at the Warner Brothers studio, and that Disney was inspired to name Mickey Mouse after him. This claim however has been debunked by Disney historian Jim Korkis, since at the time of Mickey Mouse's development, Disney Studios had been located on Hyperion Avenue for several years, and Walt Disney never kept an office or other working space at Warner Brothers, having no professional relationship with Warner Brothers, as the Alice Comedies and Oswald cartoons were distributed by Universal.
Design.
Ub Iwerks designed Mickey's body out of circles in order to make the character simple to animate. Disney employees John Hench and Marc Davis believed that this design was part of Mickey's success as it made him more dynamic and appealing to audiences. Mickey's circular design is most noticeable in his ears, which in traditional animation, always appear circular no matter which way Mickey faces. This made Mickey easily recognizable to audiences and made his ears an unofficial personal trademark. Even today, the rudimentary symbol is often used to represent Mickey (see Hidden Mickey). This later created a dilemma for toy creators who had to recreate a three-dimensional Mickey. In animation in the 1940s Mickey's ears were animated in a more realistic perspective.
In 1938, animator Fred Moore redesigned Mickey's body away from its circular design to a pear-shape design. Colleague Ward Kimball praised Moore for being the first animator to break from Mickey's "rubber hose, round circle" design. Although Moore himself was nervous at first about changing Mickey, Walt Disney liked the new design and told Moore "that's the way I want Mickey to be drawn from now on."
Each of Mickey's hands has only three fingers and a thumb. Disney said that this was both an artistic and financial decision, explaining "Artistically five digits are too many for a mouse. His hand would look like a bunch of bananas. Financially, not having an extra finger in each of 45,000 drawings that make up a six and one half minute short has saved the Studio millions." In the film "The Opry House" (1929), Mickey was first given white gloves as a way of contrasting his naturally black hands against his black body. The use of white gloves would prove to be an influential design for cartoon characters, particularly with later Disney characters, but also with non-Disney characters such as Bugs Bunny, Woody Woodpecker, and Mario.
Mickey's eyes, as drawn in "Plane Crazy" and "The Gallopin' Gaucho", were large and white with black outlines. In "Steamboat Willie" the bottom portion of the black outlines were removed, although the upper edges still contrasted with his head. Mickey's eyes were later re-imagined as only consisting of the small black dots which were originally his pupils, while what were the upper edges of his eyes became a hairline. This is evident only when Mickey blinks. Fred Moore later redesigned the eyes to be small white eyes with pupils and gave his face a Caucasian skin tone instead of plain white. This new Mickey first appeared in 1938 on the cover of a party program, and in animation the following year with the release of "The Pointer". Mickey is sometimes given eyebrows as seen in "The Simple Things" (1953) and in the comic strip, although he does not have eyebrows in his most recent appearances.
Besides Mickey's gloves and shoes, he typically wears only a pair of shorts with two large buttons in the front. Before Mickey was seen regularly in color animation, Mickey's shorts were either red, or a dull blue-green. With the advent of Mickey's color films, the shorts were always red. When Mickey is not wearing his red shorts, he is often still wearing red clothing such as a red bandmaster coat ("The Band Concert", "The Mickey Mouse Club"), red overalls ("Clock Cleaners", "Boat Builders"), a red cloak ("Fantasia", "Fun and Fancy Free"), a red coat ("Squatter's Rights", "Mickey's Christmas Carol"), or a red shirt ("Mickey Down Under", "The Simple Things").
Animation history.
Debut (1928).
Disney had Ub Iwerks secretly begin animating a new cartoon while still under contract with Universal. The cartoon was co-directed by Walt Disney and Ub Iwerks. Iwerks was the main animator for the short, and reportedly spent six weeks working on it. In fact, Iwerks was the main animator for every Disney short released in 1928 and 1929. Hugh Harman and Rudolf Ising also assisted Disney during those years. They had already signed their contracts with Charles Mintz, but he was still in the process of forming his new studio and so for the time being they were still employed by Disney. This short would be the last they animated under this somewhat awkward situation.
Mickey was first seen in a test screening of the cartoon short "Plane Crazy", on May 15, 1928, but it failed to impress the audience and to add insult to injury, Walt could not find a distributor. Though understandably disappointed, Walt went on to produce a second Mickey short, "The Gallopin' Gaucho", which was also not released for lack of a distributor.
"Steamboat Willie" was first released on November 18, 1928, in New York. It was co-directed by Walt Disney and Ub Iwerks. Iwerks again served as the head animator, assisted by Johnny Cannon, Les Clark, Wilfred Jackson and Dick Lundy. This short was intended as a parody of Buster Keaton's "Steamboat Bill Jr.", first released on May 12 of the same year. Although it was the third Mickey cartoon produced, it was the first to find a distributor, and thus is considered by The Disney Company as Mickey's debut. "Willie" featured changes to Mickey's appearance (in particular, simplifying his eyes to large dots) that established his look for later cartoons and in numerous Walt Disney films.
The cartoon was not the first cartoon to feature a soundtrack connected to the action. Fleischer Studios, headed by brothers Dave and Max Fleischer, had already released a number of sound cartoons using the DeForest system in the mid-1920s. However, these cartoons did not keep the sound synchronized throughout the film. For "Willie", Disney had the sound recorded with a click track that kept the musicians on the beat. This precise timing is apparent during the "Turkey in the Straw" sequence, when Mickey's actions exactly match the accompanying instruments. Animation historians have long debated who had served as the composer for the film's original music. This role has been variously attributed to Wilfred Jackson, Carl Stalling and Bert Lewis, but identification remains uncertain. Walt Disney himself was voice actor for both Mickey and Minnie, and would remain the source of Mickey's voice through 1946 for theatrical cartoons. Jimmy MacDonald took over the role in 1946, but Walt provided Mickey's voice again from 1955 to 1959 for "The Mickey Mouse Club" television series on ABC.
Audiences at the time of "Steamboat Willie"'s release were reportedly impressed by the use of sound for comedic purposes. Sound films or "talkies" were still considered innovative. The first feature-length movie with dialogue sequences, "The Jazz Singer" starring Al Jolson, was released on October 6, 1927. Within a year of its success, most United States movie theaters had installed sound film equipment. Walt Disney apparently intended to take advantage of this new trend and, arguably, managed to succeed. Most other cartoon studios were still producing silent products and so were unable to effectively act as competition to Disney. As a result Mickey would soon become the most prominent animated character of the time. Walt Disney soon worked on adding sound to both "Plane Crazy" and "The Gallopin' Gaucho" (which had originally been silent releases) and their new release added to Mickey's success and popularity. A fourth Mickey short, "The Barn Dance", was also put into production; however, Mickey does not actually speak until "The Karnival Kid" in 1929 when his first spoken words were "Hot dogs, Hot dogs!" After "Steamboat Willie" was released, Mickey became a close competitor to Felix the Cat, and his popularity would grow as he was continuously featured in sound cartoons. By 1929, Felix would lose popularity among theater audiences, and Pat Sullivan decided to produce all future Felix cartoons in sound as a result. Unfortunately, audiences did not respond well to Felix's transition to sound and by 1930, Felix had faded from the screen.
Black and white films (1929–1935).
In Mickey's early films he was often characterized not as a hero, but as an ineffective young suitor to Minnie Mouse. "The Barn Dance" (March 14, 1929) is the first time in which Mickey is turned down by Minnie in favor of Pete.
"The Opry House" (March 28, 1929) was the first time in which Mickey wore his white gloves. Mickey wears them in almost all of his subsequent appearances and many other characters followed suit. Supposedly one reason for adding the white gloves was to allow audiences to distinguish the characters' hands when they appeared against their bodies, as both were black. The three lines on the back of Mickey's gloves represent darts in the gloves' fabric extending from between the digits of the hand, typical of glove design of the era.
"When the Cat's Away" (April 18, 1929), essentially a remake of the "Alice Comedy", "Alice Rattled by Rats", was an unusual appearance for Mickey. Although Mickey and Minne still maintained their anthropomorphic characteristics, they were depicted as the size of regular mice and living with a community many other mice as pests in a home. Mickey and Minnie would later appear the size of regular humans in their own setting. In appearances with real humans, Mickey has been shown to be about two to three feet high. The next Mickey short was also unusual. "The Barnyard Battle" (April 25, 1929) was the only film to depict Mickey as a soldier and also the first to place him in combat. "The Karnival Kid" (1929) was the first time Mickey spoke. Before this he had only whistled, laughed, and grunted. His first words were "Hot dogs! Hot dogs!" said while trying to sell hot dogs at a carnival. "Mickey's Follies" (1929) introduced the song "Minnie's Yoo-Hoo" which would become the theme song for "Mickey Mouse" films for the next several years. The "Minnie's Yoo-Hoo" song sequence was also later reused with different background animation as its own special short shown only at the commencement of 1930s theater-based Mickey Mouse Clubs. Mickey's dog Pluto first appeared as Mickey's pet in "The Moose Hunt" (1931) after previously appearing as Minnie's dog "Rover" in "The Picnic" (1930).
"The Cactus Kid" (April 11, 1930) was the last film to be animated by Ub Iwerks at Disney. Shortly before the release of the film, Iwerks left to start his own studio, bankrolled by Disney's then-distributor Pat Powers. Powers and Disney had a falling out over money due Disney from the distribution deal. It was in response to losing the right to distribute Disney's cartoons that Powers made the deal with Iwerks, who had long harbored a desire to head his own studio. The departure is considered a turning point in Mickey's career, as well as that of Walt Disney. Walt lost the man who served as his closest colleague and confidant since 1919. Mickey lost the man responsible for his original design and for the direction and/or animation of several of the shorts released till this point. Advertising for the early Mickey Mouse cartoons credited them as "A Walt Disney Comic, drawn by Ub Iwerks". Later Disney Company reissues of the early cartoons tend to credit Walt Disney alone.
Disney and his remaining staff continued the production of the Mickey series, and he was able to eventually find a number of animators to replace Iwerks. As the Great Depression progressed and Felix the Cat faded from the movie screen, Mickey's popularity would rise, and by 1932 The Mickey Mouse Club would have one million members. At the 5th Academy Awards in 1932, Mickey received his first Academy Award nomination, received for "Mickey's Orphans" (1931). Walt Disney also received an honorary Academy Award for the creation of Mickey Mouse. Despite being eclipsed by the Silly Symphonies short the "Three Little Pigs" in 1933, Mickey still maintained great popularity among theater audiences too, until 1935, when polls showed that Popeye was more popular than Mickey. By 1934, Mickey merchandise had earned $600,000.00 a year. In 1935, Disney began to phase out the Mickey Mouse Clubs, due to administration problems.
About this time, story artists at Disney were finding it increasingly difficult to write material for Mickey. As he had developed into a role model for children, they were limited in the types of gags they could make. This led to Mickey taking more of a secondary role in some of his next films allowing for more emphasis on other characters. In "Orphan's Benefit" (August 11, 1934) Mickey first appeared with Donald Duck who had been introduced earlier that year in the "Silly Symphonies" series. The tempestuous duck would provide Disney with seemingly endless story ideas and would remain a recurring character in Mickey's cartoons.
Color films (1935–1953).
Mickey first appeared animated in color in "Parade of the Award Nominees" in 1932, however the film strip was created for the 5th Academy Awards ceremony and was not released to the public. Mickey's official first color film came in 1935 with "The Band Concert". The Technicolor film process was used in the film production. Here Mickey conducted the "William Tell Overture", but the band is swept up by a tornado. It is said that conductor Arturo Toscanini so loved this short that, upon first seeing it, he asked the projectionist to run it again. In 1994, "The Band Concert" was voted the third-greatest cartoon of all time in a poll of animation professionals. By colorizing and partially redesigning Mickey, Walt would put Mickey back on top once again, and Mickey would reach popularity he never reached before as audiences now gave him more appeal. Also in 1935, Walt would receive a special award from the League of Nations for creating Mickey.
However, by 1938, the more manic Donald Duck would surpass the passive Mickey, resulting in a redesign of the mouse between 1938 and 1940 that put Mickey at the peak of his popularity. The second half of the 1930s saw the character Goofy reintroduced as a series regular. Together, Mickey, Donald Duck, and Goofy would go on several adventures together. Several of the films by the comic trio are some of Mickey's most critically acclaimed films, including "Mickey's Fire Brigade" (1935), "Moose Hunters" (1937), "Clock Cleaners" (1937), "Lonesome Ghosts" (1937), "Boat Builders" (1938), and "Mickey's Trailer" (1938). Also during this era, Mickey would star in "Brave Little Tailor" (1938), an adaptation of "The Valiant Little Tailor", which was nominated for an Academy Award.
Mickey was redesigned by animator Fred Moore which was first seen in "The Pointer" (1939). Instead of having solid black eyes, Mickey was given white eyes with pupils, a Caucasian skin colored face, and a pear-shaped body. In the 40's, he changed once more in "The Little Whirlwind", where he used his trademark pants for the last time in decades, lost his tail, got more realistic ears that changed with perspective and a different body anatomy. But this change would only last for a short period of time before returning to the one in "The Pointer", with the exception of his pants. In his final theatrical cartoons in the 1950s, he was given eyebrows, which were removed in the more recent cartoons.
In 1940 Mickey appeared in his first feature-length film, "Fantasia". His screen role as The Sorcerer's Apprentice, set to the symphonic poem of the same name by Paul Dukas, is perhaps the most famous segment of the film and one of Mickey's most iconic roles. The segment features no dialogue at all, only the music. The apprentice (Mickey), not willing to do his chores, puts on the sorcerer's magic hat after the sorcerer goes to bed and casts a spell on a broom, which causes the broom to come to life and perform the most tiring chore—filling up a deep well using two buckets of water. When the well eventually overflows, Mickey finds himself unable to control the broom, leading to a near-flood. After the segment ends, Mickey is seen in silhouette shaking hands with Leopold Stokowski, who conducts all the music heard in "Fantasia". Mickey has often been pictured in the red robe and blue sorcerer's hat in merchandising. It was also featured into the climax of Fantasmic!, an attraction at the Disney theme parks.
After 1940, Mickey's popularity would decline until his 1955 re-emergence as a daily children's television personality. Despite this, the character continued to appear regularly in animated shorts until 1943 (winning his only competitive Academy Award—with canine companion Pluto—for a short subject, "Lend a Paw") and again from 1946 to 1952.
The last regular installment of the "Mickey Mouse" film series came in 1953 with "The Simple Things" in which Mickey and Pluto go fishing and are pestered by a flock of seagulls.
Television and later films.
In the 1950s, Mickey became more known for his appearances on television, particularly with "The Mickey Mouse Club". Many of his theatrical cartoon shorts were rereleased on television series such as "Ink & Paint Club", various forms of the Walt Disney anthology television series, and on home video. Mickey returned to theatrical animation in 1983 with "Mickey's Christmas Carol", an adaptation of Charles Dickens' "A Christmas Carol" in which Mickey played Bob Cratchit. This was followed up in 1990 with "The Prince and the Pauper".
Throughout the decades, Mickey Mouse competed with Warner Bros.' Bugs Bunny for animated popularity. But in 1988, in a historic moment in motion picture history, the two rivals finally shared screen time in the Robert Zemeckis Disney/Amblin film "Who Framed Roger Rabbit". Disney and Warner signed an agreement stating that each character had "exactly" the same amount of screen time in the scene, right down to the frame.
Similar to his animated inclusion into a live-action film on "Roger Rabbit", Mickey made a featured cameo appearance in the 1990 television special "The Muppets at Walt Disney World" where he met Kermit the Frog. The two are established in the story as having been old friends. The Muppets have otherwise spoofed and referenced Mickey over a dozen times since the 1970s. Eventually, The Muppets were purchased by the Walt Disney Company in 2004.
Mickey appeared on several animated logos for Walt Disney Home Entertainment, starting with the "Neon Mickey" logo and then to the "Sorcerer Mickey" logos used for regular and Classics release titles.
His most recent theatrical cartoon short was 2013's "Get A Horse!" which was preceded by 1995's "Runaway Brain", while from 1999 to 2004, he appeared in direct-to-video features like "Mickey's Once Upon a Christmas", "" and the computer-animated "Mickey's Twice Upon a Christmas".
Many television series have centered around Mickey, such as the ABC shows "Mickey Mouse Works" (1999—2000), "Disney's House of Mouse" (2001—2003) and Disney Channel's "Mickey Mouse Clubhouse" (2006–present). Prior to all these, Mickey was also featured as an unseen character in the "Bonkers" episode "You Oughta Be In Toons".
Mickey has recently been announced to star in two films. One is being based on the Magic Kingdom theme park at the Walt Disney World Resort, while the other is a film idea pitched by Walt Disney Animation Studios veteran Burny Mattinson centering around Mickey, Donald and Goofy.
Since June 28, 2013, Disney Channel has been airing new 3-minute "Mickey Mouse" shorts. In these new shorts, Mickey has a more modern appearance, but his appearance is also very close to his original 1928 look.
Voice actors.
A large part of Mickey's screen persona is his famously shy, falsetto voice. From his first speaking role in the 1929 short "The Karnival Kid" onward, Mickey was voiced by Walt Disney himself, a task in which Disney took great personal pride (with composer Carl Stalling and Clarence Nash of Donald Duck fame standing-in on few occasions). However, by 1946, Disney was becoming too busy with running the studio to do regular voice work which meant he could not do Mickey's voice anymore (and as it is speculated his cigarette habit had damaged his voice over the years), and during the recording of the "Mickey and the Beanstalk" section of "Fun and Fancy Free", Mickey's voice was handed over to veteran Disney musician and actor Jimmy MacDonald. (Both Disney's and MacDonald's voices can be heard on the final soundtrack.) MacDonald voiced Mickey in the remainder of the theatrical shorts, and for various television and publicity projects up until his retirement in the mid-1970s, although Walt voiced Mickey again for the introductions to the original 1954—1959 run of "The Mickey Mouse Club" TV series and the "Fourth Anniversary Show" episode of the Disneyland TV series aired on September 11, 1958.
The 1983 short film "Mickey's Christmas Carol" marked the theatrical debut of the late Wayne Allwine as Mickey Mouse, who was the voice of Mickey until his death in 2009. Allwine once recounted something MacDonald had told him about voicing Mickey: "The main piece of advice that Jim gave me about Mickey helped me keep things in perspective. He said, 'Just remember kid, you’re only filling in for the boss.' And that’s the way he treated doing Mickey for years and years. From Walt, and now from Jimmy." Allwine would eventually marry Russi Taylor, the voice of Minnie Mouse since 1986. Les Perkins did the voice of Mickey in two TV specials "Down and Out with Donald Duck" and "DTV Valentine" in the mid-1980s.
Bret Iwan, a former Hallmark greeting card artist, is the current voice of Mickey. His early recordings in 2009 included work for the Disney Cruise Line, Mickey toys, Theme Parks, and also the Disney on Ice: Celebrations! ice show. His first video game voice-over of Mickey Mouse can be found on ', a video game for PlayStation Portable. He has also voiced the character in the next games for the "Kingdom Hearts" series. Iwan also does the vocal effects of Mickey in the games "Epic Mickey" and '. Despite Iwan being Mickey's primary voice actor, the character's voice is provided by Chris Diamantopoulos in the 2013 animated series, as the producers were looking for a retro voice to match the vintage look of the series.
Mickey in comics.
Mickey first appeared in comics after he had appeared in 15 commercially successful animated shorts and was easily recognized by the public. Walt Disney was approached by King Features Syndicate with the offer to license Mickey and his supporting characters for use in a comic strip. Disney accepted and Mickey made his first comic strip appearance on January 13, 1930. The comical plot was credited to Disney himself, art to Ub Iwerks and inking to Win Smith. The first week or so of the strip featured a loose adaptation of "Plane Crazy". Minnie soon became the first addition to the cast. The strips first released between January 13, 1930, and March 31, 1930, has been occasionally reprinted in comic book form under the collective title "Lost on a Desert Island". Animation historian Jim Korkis notes "After the eighteenth strip, Iwerks left and his inker, Win Smith, continued drawing the gag-a-day format..."
In early 1930, after Iwerks' departure, Disney was at first content to continue scripting the Mickey Mouse comic strip, assigning the art to Win Smith. However, Disney's focus had always been in animation and Smith was soon assigned with the scripting as well. Smith was apparently discontent at the prospect of having to script, draw, and ink a series by himself as evidenced by his sudden resignation.
Disney then searched for a replacement among the remaining staff of the Studio. He selected Floyd Gottfredson, a recently hired employee. At the time Gottfredson was reportedly eager to work in animation and somewhat reluctant to accept his new assignment. Disney had to assure him the assignment was only temporary and that he would eventually return to animation. Gottfredson accepted and ended up holding this "temporary" assignment from May 5, 1930, to November 15, 1975.
Walt Disney's last script for the strip appeared May 17, 1930. Gottfredson's first task was to finish the storyline Disney had started on April 1, 1930. The storyline was completed on September 20, 1930, and later reprinted in comic book form as "Mickey Mouse in Death Valley". This early adventure expanded the cast of the strip which to this point only included Mickey and Minnie. Among the characters who had their first comic strip appearances in this story were Clarabelle Cow, Horace Horsecollar and Black Pete as well as the debuts of corrupted lawyer Sylvester Shyster and Minnie's uncle Mortimer Mouse. The Death Valley narrative was followed by "Mr. Slicker and the Egg Robbers", first printed between September 22 and December 26, 1930, which introduced Marcus Mouse and his wife as Minnie's parents.
Starting with these two early comic strip stories, Mickey's versions in animation and comics are considered to have diverged from each other. While Disney and his cartoon shorts would continue to focus on comedy, the comic strip effectively combined comedy and adventure. This adventurous version of Mickey would continue to appear in comic strips and later comic books throughout the 20th and into the 21st century.
Floyd Gottfredson left his mark with stories such as "Mickey Mouse Joins the Foreign Legion" (1936) and "The Gleam" (1942). He also created the Phantom Blot, Eega Beeva, Morty and Ferdie, Captain Churchmouse, and Butch. Besides Gottfredson artists for the strip over the years included Roman Arambula, Rick Hoover, Manuel Gonzales, Carson Van Osten, Jim Engel, Bill Wright, Ted Thwailes and Daan Jippes; writers included Ted Osborne, Merrill De Maris, Bill Walsh, Dick Shaw, Roy Williams, Del Connell, and Floyd Norman.
The next artist to leave his mark on the character was Paul Murry in Dell Comics. His first Mickey tale appeared in 1950 but Mickey did not become a speciality until Murry's first serial for "Walt Disney's Comics and Stories" in 1953 ("The Last Resort"). In the same period Romano Scarpa in Italy for the magazine "Topolino" began to revitalize Mickey in stories that brought back the Phantom Blot and Eega Beeva along with new creations such as the Atomo Bleep-Bleep. While the stories at Western Publishing during the Silver Age emphasized Mickey as a detective in the style of Sherlock Holmes, in the modern era several editors and creators have consciously undertaken to depict a more vigorous Mickey in the mold of the classic Gottfredson adventures. This renaissance has been spearheaded by Byron Erickson, David Gerstein, Noel Van Horn, Michael T. Gilbert and César Ferioli.
In Europe, Mickey Mouse became the main attraction of a number of comics magazines, the most famous being "Topolino" in Italy from 1932 on, "Le Journal de Mickey" in France from 1934 on, "Don Miki" in Spain and the Greek "Miky Maous".
Mickey was the main character for the series" MM Mickey Mouse Mystery Magazine", published in Italy from 1999 to 2001.
In 1958, Mickey Mouse was introduced to the Arab world through another comic book called “Sameer”. Mickey Mouse became so popular in Egypt that he got a comic book with his name. Mickey’s comics in Egypt are licensed by Disney and were published since 1959 by “Dar Al-Hilal” and they were a big hit, but unfortunately Dar Al-Hilal stopped the publication in 2003 because of problems with Disney, luckily the comics were re-released by "Nahdat Masr" in 2004 and the first issues were sold out in less than 8 hours.
Merchandising.
Since his early years Mickey Mouse has been licensed by Disney to appear on many different kinds of merchandise. Mickey was produced as plush toys and figurines, and Mickey's image has graced almost everything from T-shirts to lunch boxes. Largely responsible for Disney merchandising in the 1930s was Kay Kamen (d. 1949) who was called a "stickler for quality." Kamen was recognized by The Walt Disney Company as having a significant part in Mickey's rise to stardom and was named a Disney Legend in 1998.
Mickey was most famously featured on wrist watches and alarm clocks, typically utilizing his hands as the actual hands on the face of the clock. The first Mickey Mouse watches were manufactured in 1933 by the Ingersoll Watch Company. The seconds were indicated by a turning disk below Mickey. The first Mickey watch was sold at the Century of Progress in Chicago, 1933 for $3.75. Mickey Mouse watches have been sold by other companies and designers throughout the years, including Timex, Elgin, Helbros, Bradley, Lorus, and Gérald Genta The fictional character Robert Langdon from Dan Brown's novels was said to wear a Mickey Mouse watch as a reminder "to stay young at heart."
In 1989, Milton Bradley released the electronic-talking game titled Mickey Says, with three modes featuring Mickey Mouse as its host. Mickey also appeared in other toys and games, including the Worlds of Wonder-released "The Talking Mickey Mouse".
Fisher-Price has recently produced a line of talking animatronic Mickey dolls including "Dance Star Mickey" (2010) and "Rock Star Mickey" (2011).
Mickey at the Disney parks.
Minnie and Mickey at Hong Kong Disneyland (left) and Mickey's house at Mickey's Toontown (right)
As the official Walt Disney mascot, Mickey has played a central role in the Disney parks since the opening of Disneyland in 1955. As with other characters, Mickey is often portrayed by a non-speaking costumed actor. In this form he has participated in ceremonies and countless parades. A popular activity with guests is getting to meet and pose for photographs with the mouse. As of the presidency of Barack Obama (who jokingly referred to him as "a world leader who has bigger ears than me") Mickey has met every U.S. President since Harry Truman, with the exception of Lyndon B. Johnson.
Mickey also features in several specific attractions at the Disney parks. Mickey's Toontown (Disneyland and Tokyo Disneyland) is a themed land which is a recreation of Mickey's neighborhood. Buildings are built in a cartoon style and guests can visit Mickey or Minnie's houses, Donald Duck's boat, or Goofy's garage. This is a common place to meet the characters.
Mickey's PhilharMagic (Magic Kingdom, Tokyo Disneyland, Hong Kong Disneyland) is a 4D film which features Mickey in the familiar role of symphony conductor. At Main Street Cinema several of Mickey's short films are shown on a rotating basis; the sixth film is always "Steamboat Willie". Mickey plays a central role in "Fantasmic!" (Disneyland Resort, Disney's Hollywood Studios) a live nighttime show which famously features Mickey in his role as the Sorcerer's Apprentice. Mickey was also a central character in the now defunct Mickey Mouse Revue (Magic Kingdom, Tokyo Disneyland) which was an indoor show featuring animatronic characters. Mickey's face currently graces the Mickey's Fun Wheel at Disney California Adventure Park, where a figure of him also stands on top of Silly Symphony Swings.
In addition to Mickey's overt presence in the parks, numerous images of him are also subtly included in sometimes unexpected places. This phenomenon is known as "Hidden Mickey", involving hidden images in Disney films, theme parks and merchandise.
Mickey in video games.
Like many popular characters, Mickey has starred in many video games, including "Mickey Mousecapade" on the Nintendo Entertainment System, ', "Mickey's Ultimate Challenge", and "Disney's Magical Quest" on the Super Nintendo Entertainment System, "Castle of Illusion Starring Mickey Mouse" on the Mega Drive/Genesis, ' on the Game Boy, and many others. In the 2000s, the "Disney's Magical Quest" series were ported to the Game Boy Advance, while Mickey made his sixth generation era debut in "Disney's Magical Mirror Starring Mickey Mouse", a Nintendo GameCube title aimed at younger audiences. Mickey plays a major role in the "Kingdom Hearts" series, as the king of Disney Castle and aide to the protagonist, Sora. King Mickey wields the Keyblade, a weapon in the form of a key that has the power to open any lock and combat darkness. "Epic Mickey", featuring a darker version of the Disney universe, was released in 2010 for the Wii. The game is part of an effort by The Walt Disney Company to re-brand the Mickey Mouse character by moving away from his current squeaky clean image and reintroducing the mischievous side of his personality.
Awards and honors.
Mickey Mouse has received ten nominations for the Academy Award for Best Animated Short Film. These are "Mickey's Orphans" (1931), "Building a Building" (1933), "Brave Little Tailor" (1938), "The Pointer" (1939), "Lend a Paw" (1941), "Squatter's Rights" (1946), "Mickey and the Seal" (1948), "Mickey's Christmas Carol" (1983), "Runaway Brain" (1995), and "Get a Horse!" (2013). Among these, "Lend a Paw" was the only film to actually win the award. Additionally, in 1932 Walt Disney received an honorary Academy Award in recognition of Mickey's creation and popularity.
In 1994, four of Mickey's cartoons were included in the book "The 50 Greatest Cartoons" which listed the greatest cartoons of all time as voted by members of the animation field. The films were "The Band Concert" (#3), "Steamboat Willie" (#13), "Brave Little Tailor" (#26), and "Clock Cleaners" (#27).
On November 18, 1978, in honor of his 50th anniversary, Mickey became the first cartoon character to have a star on the Hollywood Walk of Fame. The star is located on 6925 Hollywood Blvd.
Melbourne (Australia) runs the annual Moomba festival street procession and appointed Mickey Mouse as their "King of Moomba" (1977). Although immensely popular with children, there was controversy with the appointment: some Melburnians wanted a 'home-grown' choice, e.g. Blinky Bill; when it was revealed that Patricia O'Carroll (from Disneyland's Disney on Parade show) was performing the mouse, Australian newspapers reported "Mickey Mouse is really a girl!"
Mickey was the Grand Marshal of the Tournament of Roses Parade on New Year's Day 2005. He was the first cartoon character to receive the honor, and only the second fictional character after Kermit the Frog in 1996.
Social impact.
Use in politics.
In the United States, protest votes are often made in order to indicate dissatisfaction with the slate of candidates presented on a particular ballot, or to highlight the inadequacies of a particular voting procedure. Since most states' electoral systems do not provide for blank balloting or a choice of "None of the Above", most protest votes take the form of a clearly non-serious candidate's name entered as a write-in vote. Mickey Mouse is often selected for this purpose. As an election supervisor in Georgia observed, "If [Mickey Mouse] doesn’t get votes in our election, it’s a bad election." The earliest known mention of Mickey Mouse as a write-in candidate dates back to the 1932 New York City mayoral elections.
Mickey Mouse's name has also been known to appear fraudulently on voter registration lists, most recently in the 2008 U.S. Presidential Election.
Parodies and criticism.
Mickey Mouse's global fame has made him both a symbol of The Walt Disney Company and of the United States itself. For this reason Mickey has been used frequently in anti-American satire, such as the infamous underground cartoon "Mickey Mouse in Vietnam". There have been numerous parodies of Mickey Mouse, such as the Mad Magazine parody "Mickey Rodent" by Will Elder in which the mouse walks around unshaven and jails Donald Duck out of jealousy over the duck's larger popularity. The grotesque Rat Fink character was created by Ed "Big Daddy" Roth over his hatred of Mickey Mouse. In "The Simpsons Movie", Bart Simpson puts a black bra on his head to mimic Mickey Mouse and says: "I'm the mascot of an evil corporation!" On the Comedy Central series "South Park", Mickey is depicted as the sadistic, greedy, foul-mouthed boss of The Walt Disney Company, only interested in money.<br>He also appears briefly with Donald Duck in the comic "Squeak the Mouse" of the Italian cartoonist Massimo Mattioli.
In an episode of "Full Frontal Nerdity," by Aaron Williams, Mickey is shown as desperately trying to unload Miramax.
In "Bored of the Rings", Mickey Mouse is satirized as Dickey Dragon.
Legal issues.
It is sometimes erroneously stated that the Mickey Mouse character is only copyrighted. In fact, the character, like all major Disney characters, is also trademarked, which lasts in perpetuity as long as it continues to be used commercially by its owner. So, whether or not a particular Disney cartoon goes into the public domain, the characters themselves may not be used as trademarks without authorization.
Because of the Copyright Term Extension Act of the United States (sometimes called the 'Mickey Mouse Protection Act' because of extensive lobbying by the Disney corporation) and similar legislation within the European Union and other jurisdictions where copyright terms have been extended, works such as the early Mickey Mouse cartoons will remain under copyright until at least 2023. However, some copyright scholars argue that Disney's copyright on the earliest version of the character may be invalid due to ambiguity in the copyright notice for "Steamboat Willie".
The Walt Disney Company has become well known for protecting its trademark on the Mickey Mouse character, whose likeness is closely associated with the company, with particular zeal. In 1989, Disney threatened legal action against three daycare centers in Florida for having Mickey Mouse and other Disney characters painted on their walls. The characters were removed, and rival Universal Studios replaced them with Universal cartoon characters.
"Walt Disney Productions v. Air Pirates".
In 1971, a group of underground cartoonists calling themselves the Air Pirates, after a group of villains from early Mickey Mouse films, produced a comic called "Air Pirates Funnies". In the first issue, cartoonist Dan O'Neill depicted Mickey and Minnie Mouse engaging in explicit sexual behavior and consuming drugs. As O'Neill explained, "The air pirates were...some sort of bizarre concept to steal the air, pirate the air, steal the media...Since we were cartoonists, the logical thing was Disney." Rather than change the appearance or name of the character, which O'Neill felt would dilute the parody, the mouse depicted in "Air Pirates Funnies" looks like and is named "Mickey Mouse". Disney sued for copyright infringement, and after a series of appeals, O'Neill eventually lost and was ordered to pay Disney $1.9 million. The outcome of the case remains controversial among free-speech advocates. New York Law School professor Edward Samuels said, "[The Air Pirates] set parody back twenty years."
Censorship.
In 1930, The German Board of Film Censors prohibited showing a Mickey Mouse film, "The Barnyard Battle" (1929). The cartoon, pitting the mouse as a kepi-wearing World War I soldier against cat enemies in German helmets, was felt to negatively portray the Germans. It was claimed that the film would "reawaken the latest anti-German feeling existing abroad since the War".
The "Barnyard Battle" incident did not reflect wider anti-Mickey sentiment in Germany in 1930. But after coming to power several years later, the later Nazi regime unambiguously propagandized against Disney. A mid-1930s Nazi German newspaper article read:
"Mickey Mouse is the most miserable ideal ever revealed...Healthy emotions tell every independent young man and every honorable youth that the dirty and filth-covered vermin, the greatest bacteria carrier in the animal kingdom, cannot be the ideal type of animal...Away with Jewish brutalization of the people! Down with Mickey Mouse! Wear the Swastika Cross!"
Art Spiegelman used this quote on the opening page of the second volume of his graphic novel "Maus".
The 1935 Romanian authorities banned Mickey Mouse films from cinemas after they feared that children would be "scared to see a ten-foot mouse in the movie theatre". In 1938, based on the Ministry of Popular Culture's recommendation that a reform was necessary "to raise children in the firm and imperialist spirit of the Fascist revolution," the Italian Government banned foreign children's literature except Mickey; Disney characters were exempted from the decree for the "acknowledged artistic merit" of Disney's work. Actually Mussolini's children were fond of Mickey Mouse, so they managed to delay his ban as long as possible. In 1942, after Italy declared war on the US, fascism forced the Italian publishers to suddenly stop printing any Disney stories. Mickey's stories were replaced by the adventures of "Tuffolino", a new human character created by Federico Pedrocchi (script) and Pier Lorenzo De Vita (art). After the downfall of Italy's fascist government, the ban was removed.
Filmography.
Mickey has been announced to star in two films. One is a live-action/CGI hybrid film based on the Magic Kingdom theme park at the Walt Disney World Resort, while the other is a film idea pitched by Walt Disney Animation Studios veteran Burny Mattinson centering around Mickey, Donald and Goofy.

</doc>
<doc id="20860" url="http://en.wikipedia.org/wiki?curid=20860" title="Meher Baba">
Meher Baba

Meher Baba (25 February 1894 – 31 January 1969), born Merwan Sheriar Irani, was an Indian spiritual master who said he was the Avatar, God in human form.
Merwan Sheriar Irani was born in 1894 in Pune, India to Irani Zoroastrian parents. At the age of 19, he began a seven-year spiritual transformation. During this time he contacted five spiritual masters before beginning his own mission and gathering his own disciples in early 1922, at the age of 27.
From 10 July 1925 to the end of his life, Meher Baba maintained silence, communicating by means of an alphabet board or by unique hand gestures. With his "mandali" (circle of disciples), he spent long periods in seclusion, during which time he often fasted. He also traveled widely, held public gatherings and engaged in works of charity with lepers, the poor and the mentally ill.
In 1931, Meher Baba made the first of many visits to the West, where he attracted followers. Throughout most of the 1940s, Meher Baba worked with a category of spiritual aspirants called "masts", who he said are entranced or spellbound by internal spiritual experiences. Starting in 1949, along with selected mandali, he traveled incognito about India in an enigmatic and still largely unexplained period he called the "New Life".
After being injured as a passenger in two serious automobile accidents, one in the United States in 1952 and one in India in 1956, his ability to walk became severely limited. In 1962, he invited his Western followers to India for a mass "darshan" called "The East-West Gathering". Concerned by an increasing use of LSD and other psychedelic drugs, in 1966 Baba stated that they did not convey real benefits. Despite deteriorating health, he continued what he called his "Universal Work", which included fasting and seclusion, until his death on 31 January 1969. His "samadhi" (shrine/tomb) in Meherabad, India, has become a place of international pilgrimage.
Meher Baba gave numerous teachings on the cause and purpose of life, including teaching reincarnation and that the phenomenal world is an illusion. He taught that the Universe is imagination, that God is what really exists, and that each soul is really God passing through imagination to realize individually His own divinity. In addition he gave practical advice for the aspirant who wishes to attain Self-realization and thereby escape the wheel of births and deaths. He also taught about the concept of Perfect Masters, the Avatar, and those on the various stages of the spiritual path that he called involution. His teachings are most importantly recorded in his principal books "Discourses" and "God Speaks".
His legacy includes the Avatar Meher Baba Charitable Trust he established in India, a handful of centers for information and pilgrimage, as well as an influence on pop-culture artists and the introduction of common expressions such as "Don't Worry, Be Happy." Meher Baba's silence has remained a mysterious issue as much among his followers as with the rest of the world.
Biography.
Early life.
Meher Baba was an Irani born in Pune, India to a Zoroastrian family. His given name was Merwan Sheriar Irani. He was the second son of Sheriar Irani, a Persian Zoroastrian who had spent years wandering in search of spiritual experience before settling in Poona (now Pune), and Shireen Irani.
As a boy he formed "The Cosmopolitan Club", which was dedicated to remaining informed in world affairs and giving money to charity. He was a multi-instrumentalist and poet. Fluent in several languages, he was especially fond of the poetry of Hafiz, Shakespeare, and Shelley.
In his youth, he had no mystical inclinations or experiences, and was "[u]ntroubled as yet by a sense of his own destiny..." He was more interested in sports and was co-captain of his high school cricket team. At the age of 19, during his second year at Deccan College in Pune, he met a very old Muslim woman who was locally revered as a saint, named Hazrat Babajan, who kissed him on the forehead. The event affected him profoundly, leaving him visibly dazed, and he gave up his normal activities. After that he contacted other spiritual figures, who, along with Babajan, he later said were the five "Perfect Masters" of the age: Tajuddin Baba, Narayan Maharaj, Sai Baba of Shirdi, and Upasni Maharaj.
Upasni Maharaj, he later said, helped him to integrate his mystical experiences with normal consciousness, thus enabling him to function in the world without diminishing his experience of God-realization. In late 1921, at the age of 27, after living for seven years with Upasni, Merwan started to attract a following of his own. His early followers gave him the name "Meher Baba", meaning "Compassionate Father".
In 1922, Meher Baba and his followers established "Manzil-e-Meem" (House of the Master) in Bombay (now Mumbai). There Baba began his practice of demanding strict discipline and obedience from his disciples. A year later, Baba and his "mandali" moved to an area a few miles outside Ahmednagar that he named "Meherabad" (Meher flourishing). This ashram would become the center for his work. During the 1920s, Meher Baba opened a school, hospital and dispensary at Meherabad. All three were free and open to all castes and faiths.
In July 1925, Meher Baba began a life-long period of self-imposed silence, communicating first by use of chalk and slate, then by an alphabet board and later by self-styled hand gestures. In January 1927 he gave up writing with pen or pencil also.
1930s – First contacts with the West.
In the 1930s, Meher Baba began a period of extensive world travel, with several trips to Europe and the United States. It was during this period that he established contact with his first close group of Western disciples. He traveled on a Persian passport because he had given up writing as well as speaking and would not sign the forms required by the British government of India.
On his first trip to England in 1931 he traveled on the "SS Rajputana", the same ship that was carrying Mahatma Gandhi, who was sailing to the second Round Table Conference in London. Baba and Gandhi had three meetings onboard, including one that lasted for three hours. The British press highlighted these meetings, but an aide to Gandhi said, "You may say emphatically that Gandhi never asked Meher Baba for help or for spiritual or other advice."
On 20 May 1932 Baba arrived in New York and provided the press with a 1,000-word written statement, which was described by devotee Quentin Tod as his "Message to America". In the statement Baba proclaimed himself "one with the infinite source of everything" and declared his intention to break his silence: "When I speak, my original message will be delivered to the world and it will have to be accepted." When asked about the Indo-British political situation he had no comment, but his followers explained that he had told Gandhi to abandon politics.
In the West, Meher Baba met with a number of celebrities and artists, including Hollywood notables Gary Cooper, Charles Laughton, Tallulah Bankhead, Boris Karloff, Tom Mix, Maurice Chevalier, Ernst Lubitsch and others. On 1 June 1932 Mary Pickford and Douglas Fairbanks, Jr. held a reception for Baba at Pickfair where he delivered a message to Hollywood. As a result, Meher Baba emerged as "one of the enthusiasms of the ‘30s".
In 1934, after announcing that he would break his self-imposed silence in the Hollywood Bowl, Baba suddenly changed his plans and boarded the "RMS Empress of Canada" and sailed to Hong Kong without explanation. The Associated Press reported that "Baba had decided to postpone the word-fast breaking until next February because 'conditions are not yet ripe'." He returned to England in 1936 but did not return to the United States again until the early 1950s.
In the late 1930s, Meher Baba invited a group of Western women to join him in India, where he arranged a series of trips throughout India and Ceylon (now Sri Lanka) that became known as the Blue Bus Tours. When they returned home, many newspapers treated their journey as an occasion for scandal. Time Magazine's 1936 review of "God is my Adventure" describes the US's fascination with the "long-haired, silky-mustached Parsee named Shri Sadgaru [sic] Meher Baba" four years earlier.
1940s – Masts and the New Life.
In the 1930s and 1940s, Meher Baba did extensive work with a category of people he termed "masts", who are persons "intoxicated with God". According to Baba these individuals are essentially disabled by their enchanting experience of the higher spiritual planes. Although outwardly masts may appear irrational or even insane, Baba claimed that their spiritual status was actually quite elevated, and that by meeting with them he helped them to move forward spiritually while enlisting their aid in his spiritual work. One of the best known of these masts, known as Mohammed Mast, lived at Meher Baba's encampment at Meherabad until his death in 2003.
In 1949 Baba began an enigmatic period that he called the "New Life". Following a series of questions on their readiness to obey even the most difficult of his requests, Baba selected twenty companions to join him in a life of complete "hopelessness and helplessness".
He made provisions for those dependent on him, after which he and his companions otherwise gave up almost all property and financial responsibilities. They then traveled about India incognito while begging for food and carrying out Baba's instructions in accordance with a strict set of "conditions of the New Life". These included absolute acceptance of any circumstance and consistent good cheer in the face of any difficulty. Companions who failed to comply were sent away.
About the New Life Meher Baba wrote:
This New Life is endless, and even after my physical death it will be kept alive by those who live the life of complete renunciation of falsehood, lies, hatred, anger, greed and lust; and who, to accomplish all this, do no lustful actions, do no harm to anyone, do no backbiting, do not seek material possessions or power, who accept no homage, neither covet honor nor shun disgrace, and fear no one and nothing; by those who rely wholly and solely on God, and who love God purely for the sake of loving; who believe in the lovers of God and in the reality of Manifestation, and yet do not expect any spiritual or material reward; who do not let go the hand of Truth, and who, without being upset by calamities, bravely and wholeheartedly face all hardships with one hundred percent cheerfulness, and give no importance to caste, creed and religious ceremonies. This New Life will live by itself eternally, even if there is no one to live it.
Meher Baba ended the New Life in February 1952 and once again began a round of public appearances throughout India and the West.
1950s – "God Speaks" and automobile accidents.
In the 1950s Baba established two centers outside of India: the Meher Spiritual Center in Myrtle Beach, South Carolina in the United States and Avatar's Abode near Brisbane, Australia. He inaugurated the Meher Spiritual Center in April 1952. On 24 May 1952, en route from the Meher Spiritual Center to Meher Mount in Ojai, California, the car in which he was a passenger was struck head-on near Prague, Oklahoma. He and his companions were thrown from the vehicle and suffered many injuries. Baba's leg was severely broken and he sustained facial injuries, including a broken nose. The injured were treated at Duke Hospital in Durham, North Carolina, after which they returned to Myrtle Beach to recuperate. While recuperating at Youpon Dunes, a home owned by Elizabeth Patterson, in Myrtle Beach, he worked on the charter for a group of Sufis, which he named Sufism Reoriented.
Meher Baba began dictating his major book, "God Speaks, The Theme of Creation and Its Purpose", in Dehradun, August 1953. In September of 1954, Meher Baba gave a men-only sahavas at Meherabad that later became known as the "Three Incredible Weeks". During this time Baba issued a declaration, "Meher Baba's Call", wherein he once again affirmed his Avatarhood "irrespective of the doubts and convictions" of others. At the end of this sahavas Meher Baba gave the completed manuscript of his book "God Speaks" to two members of Sufism Reoriented, Ludwig H. Dimpfl and Don E. Stevens, for editing and publication in America. The book was subsequently published by Dodd, Mead and Company the following year.
On 30 September 1954 Meher Baba gave his "Final Declaration" message, in which he made various enigmatic predictions.
In October 1954, Meher Baba discarded his alphabet board and began using a unique set of hand gestures to communicate, which he used for the remainder of his life.
On 2 December 1956, outside Satara, India, the car in which Baba was being driven went out of control and a second serious automobile accident occurred. Baba suffered a fractured pelvis and other severe injuries. Dr. Nilu, one of Baba's mandali, was killed. This collision seriously incapacitated Baba. Despite his physicians' predictions to the contrary, after great effort Baba managed to walk again, but from that point on he was in constant pain and was severely limited in his ability to move. In fact, during his trip to the West in 1958 he often needed to be carried from venue to venue.
In 1956, during his fifth visit to the US, Baba stayed at New York's Hotel Delmonico before traveling to the Meher Center at Myrtle Beach, South Carolina. In July he traveled to Washington, D.C. and received friends and disciples at the home of Mrs. James Terry (Ivy) Duce, wife of the vice-president of the Arabian American Oil Co. He then traveled to Meher Mount at Ojai, California before continuing on to Australia. His final visits to the United States and Australia were made in 1958.
1960s – Later years and message on drugs.
In 1962, Baba gave one of his last public functions, a series of meetings he called "The East-West Gathering." At these meetings, in which his western followers were invited to meet his Indian disciples, Baba gave darshan to many thousands of people despite the physical strain this caused him.
In the mid-1960s Baba became concerned with the increasingly prevalent drug culture in the West and began a correspondence with several Western academics, including Timothy Leary and Richard Alpert, in which he strongly discouraged the use of all hallucinogenic drugs for spiritual purposes. In 1966 Baba's responses to questions on drugs were published in a pamphlet titled "God in a Pill?" Meher Baba stated that drug use was spiritually damaging and that if enlightenment were possible through drugs then "God is not worthy of being God". Meher Baba instructed some of his young Western disciples to spread this message; in doing so, they increased awareness of Meher Baba's teachings among the young during this period. In an interview with Frederick Chapman, a Harvard graduate and Fulbright scholar who met Baba during a year of study in India, Baba stated that LSD is "harmful physically, mentally and spiritually", and warned that "the continued use of LSD leads to madness or death".
On this basis, an anti-drug campaign was initiated by Baba lovers in the United States, Europe and Australia. Although the campaign was largely unsuccessful, it created a wave of new followers, and some of Baba’s views found their way into academic debate on the merits and dangers of hallucinogens.
From the East-West Gathering of 1962 onward, Baba's health steadily deteriorated. Despite the physical toll it took on his body, he continued to undergo long periods of seclusion and fasting. In late July 1968, Baba completed a particularly taxing period of seclusion and stated that his work was "completed 100% to my satisfaction". By this point he was using a wheelchair. Within a few months his condition worsened and he was bed-ridden. His body was wracked by intense muscular spasms that had no clear origin. Despite the care of several doctors, the spasms grew progressively worse.
On 31 January 1969, Meher Baba died, conveying by his last gestures, "Do not forget that I am God." In time his devotees called the anniversary of his death "Amartithi" (deathless day). Meher Baba's body lay in state at his samadhi at Meherabad. Covered with roses, and cooled by ice, his body was kept available to the public for one week before its final burial.
Before his death, Meher Baba had made extensive preparations for a public darshan program to be held in Poona. His mandali decided to proceed with the arrangements despite the physical absence of the host. Several thousand attended this "Last Darshan", including many hundreds of people from the United States, Europe, and Australia.
Silence.
From 10 July 1925, until his death in 1969, Meher Baba was silent. He communicated first by using an alphabet board and later by unique hand gestures which were interpreted and spoken out by one of his mandali, usually by his disciple Eruch Jessawala. Meher Baba said that his silence was not undertaken as a spiritual exercise but solely in connection with his universal work.
Man’s inability to live God’s words makes the Avatar’s teaching a mockery. Instead of practicing the compassion he taught, man has waged wars in his name. Instead of living the humility, purity, and truth of his words, man has given way to hatred, greed, and violence. Because man has been deaf to the principles and precepts laid down by God in the past, in this present Avataric form, I observe silence.
Meher Baba often signaled the moment "that he would 'break' his silence by speaking the 'Word' in every heart, thereby giving a spiritual push forward to all living things".
When I break My Silence, the impact of My Love will be universal and all life in creation will know, feel and receive of it. It will help every individual to break himself free from his own bondage in his own way. I am the Divine Beloved who loves you more than you can ever love yourself. The breaking of My Silence will help you to help yourself in knowing your real Self.
Meher Baba said that the breaking of his silence would be a defining event in the spiritual evolution of the world.
When I speak that Word, I shall lay the foundation for that which is to take place during the next seven hundred years.
On many occasions Meher Baba promised to break his silence with an audible word before he died, often stating a specific time and place when this would occur, but according to all contemporary accounts, Meher Baba remained silent until his death. His failure to break his silence disappointed some of his followers, while others regarded these broken promises as a test of their faith. Some followers speculate that "the Word" will yet be "spoken", or that Meher Baba did break his silence but in a spiritual rather than a physical way.
For many years, Baba asked his followers to undertake austerities on 10 July, the anniversary of the day his silence began, such as keeping silence, fasting and praying. In his final Silence Day request to his followers in 1968, he asked only that they keep silent. Many of Baba's followers continue to celebrate Silence Day by keeping silence in his honor.
Teachings.
Meher Baba's teachings can roughly be divided into two main categories: his metaphysics on the nature of the soul and the Universe, and practical advice for the spiritual aspirant. The two are interrelated. His metaphysics is mostly found in his principal book on the subject, "God Speaks". It contains detailed statements on his cosmology and the purpose of life as well as the progression of the soul, while his elucidations on the practical spiritual life are mostly contained in "Discourses", although it also covers many metaphysical areas mirroring or amplifying "God Speaks".
"God Speaks".
In "God Speaks", Meher Baba describes the journey of the soul from its original state of unconscious divinity to the ultimate attainment of conscious divinity. The whole journey is a journey of imagination, where the original indivisible state of God imagines becoming countless individualized souls which he likens to bubbles within an infinite ocean. Each soul, powered by the desire to become conscious, starts its journey in the most rudimentary form of consciousness. This limitation brings the need of a more developed form to advance it towards an increasingly conscious state. Consciousness grows in relation to the impressions each form is capable of gathering.
According to Baba, each soul pursues conscious divinity by evolving: that is, experiencing itself in a succession of imagined forms through seven "kingdoms": stone/metal, vegetable, worm, fish, bird, animal, and human. The soul identifies itself with each successive form, becoming thus tied to illusion. During this evolution of forms thinking also increases, until in human form thinking becomes infinite. Although in human form the soul is capable of conscious divinity, all the impressions that it has gathered during evolution are illusory ones, creating a barrier for the soul to know itself. For this barrier to be overcome, further births in human form are needed in a process named reincarnation.
Eventually the soul reaches a stage where its previously gathered impressions grow thin or weak enough that it enters a final stage called involution. This stage also requires a series of human births, during which the soul begins an inner journey, by which it realizes its true identity as God. Baba breaks this inner journey of Realization into seven stages he calls "planes." The whole process culminates at the seventh plane with God-realization, where the goal of life for the individual soul is reached.
"Discourses".
The "Discourses" are a collection of explanations and elucidations that Meher Baba has given on many topics that concern the advancement of the spiritual aspirant. Some of the most important topics treated are: sanskaras (mental impressions), Maya (the principle of illusion), the nature of the ego, reincarnation, karma, violence and non-violence, meditation, love, discipleship, and God-realization. His explanations often include stories from the lore of India and the Sufi culture. One such story, the wise man and the ghost, shows the power that superstitious beliefs can have on a person, while another, Majnun and Layla, show how selfless love, even in human relations, can lead one to discipleship.
Thus Meher Baba offers many suggestions that keep one moving towards God-realization. These suggestions include putting theory into practice, the internal renunciation of desires, offering selfless service to humanity or the master, spontaneity, while avoiding actions that bind one to illusion. But rather than lay out moral rules, Baba offers an understanding as to why some actions bind the individual whereas some others help towards his emancipation. Many chapters offer a better understanding of the mechanisms by which consciousness gets caught up between the opposites of experience, such as pleasure and pain, good and evil, and point to a way of transcending them.
Perfect Masters and the Avatar.
Baba said that at all times on Earth there are fifty-six incarnate God-realized souls and that of these souls there are always five who constitute the "five Perfect Masters" of their era. When one of the five Perfect Masters dies, Baba said that another God-realized soul among the fifty-six immediately replaces him or her by taking up that office.
The "Avatar," according to Baba, is a special Perfect Master, the first soul to achieve God-realization. This soul, the "original" Perfect Master, or the "Ancient One", never ceases to incarnate. Baba indicated that this particular soul personifies the state of God which in Hinduism is named "Vishnu" and in Sufism is named "Parvardigar", i.e. the sustainer or preserver state of God. According to Meher Baba the Avatar appears on Earth every 700–1400 years and is 'brought down' into human form by the five Perfect Masters of the time to aid in the process of moving creation in its never-ending journey toward Godhood. Baba asserted that in other ages this role was fulfilled by Zoroaster, Rama, Krishna, Buddha, Jesus, and Muhammad.
Baba described the Avatar as "a gauge against which man can measure what he is and what he may become. He trues the standard of human values by interpreting them in terms of divinely human life."
Most of Meher Baba's followers accept his claim of avatarhood and he is said to be "revered by millions around the world as the Avatar of the age and a God-realized being".
Legacy.
Baba's travels and teachings left a legacy of followers and devotees worldwide.
The Avatar Meher Baba Charitable Trust, established by Meher Baba in 1959, maintains his tomb and pilgrimage facilities, as well as a free school and dispensary, a cataract clinic, and a veterinary clinic. The Trust follows the charter left for it by Meher Baba in his lifetime, but does not act as spiritual authority over groups. Likewise, the Trust does not engage in propaganda, promote creeds or dogmas, or seek converts. Baba discouraged evangelizing, stating, "I need no propaganda or publicity." Rather, he encouraged his followers to "let your life itself be my message of love and truth to others" and to "spread my message of Love and Truth as far and wide as possible". Followers of Meher Baba have no established rituals. Many do, however, perform practices of choice such as pujas, aartis, prayers, music, plays, viewing films of Baba and so forth, but the choice is personal. The primary focus for followers is living a life Meher Baba would approve of, for example, refraining from the use of psychedelic drugs, including marijuana, and trying to remember God with love.
Gatherings of Baba followers are generally informal. Special effort is made to gather together on Amartithi, the anniversary of Baba's death, and on his birthday. Many Baba followers keep silent on 10 July (Silence Day), observing the request Baba frequently made of his followers during his lifetime. Aarti is performed morning and evening at Baba's samadhi in India. Also at Meherabad, his followers maintain Baba's practice of lighting a dhuni fire on the 12th of each month.
Although Baba had initially begun gaining public attention in the West as early as 1932 as the result of contacts with some celebrities of the time and from the rather disillusioned account of Paul Brunton ("A Search in Secret India", 1934), he received further attention after his death through various mentions in western pop-culture.
Pete Townshend of The Who, who became a follower of Baba, dedicated his 1969 rock-opera "Tommy" to Meher Baba in the record's gatefold. The Who's 1971 song "Baba O'Riley" was named in part after Meher Baba, and Townshend recorded several Meher Baba tribute albums including "Happy Birthday",
"I Am", "Who Came First", and "With Love". In 1970 Melanie Safka mentioned Baba in her song "Lay Down (Candles in the Rain)" with the lyrics "Meher Baba lives again". Bobby McFerrin's 1988 Grammy Award-winning song "Don't Worry, Be Happy" was inspired by a popular quote of Baba seen in numerous Baba posters and inspirational cards. Concepts of Meher Baba's philosophy, as well as a character based on Baba but unnamed, have also frequently appeared in works of comic book writer J. M. DeMatteis, including "Doctor Fate" and "Seekers Into The Mystery".
In 2012, the feature film "Nema Aviona Za Zagreb" premiered in the Netherlands with an exclusive interview with Meher Baba filmed in 1967. In the interview Baba explains the difference between God-realization and drug-induced hallucinations and the scene plays a pivotal role in the documentary's narrative.
External links.
 

</doc>
<doc id="20861" url="http://en.wikipedia.org/wiki?curid=20861" title="Cavity magnetron">
Cavity magnetron

The cavity magnetron is a high-powered vacuum tube that generates microwaves using the interaction of a stream of electrons with a magnetic field while moving past a series of open metal cavities (cavity resonators). Bunches of electrons passing by the openings to the cavities excite radio wave oscillations in the cavity, much as a guitar's strings excite sound in its sound box. The frequency of the microwaves produced, the resonant frequency, is determined by the cavities' physical dimensions. Unlike other microwave tubes, such as the klystron and traveling-wave tube (TWT), the magnetron cannot function as an amplifier, increasing the power of an applied microwave signal, it serves solely as an oscillator, generating a microwave signal from direct current power supplied to the tube.
The first form of magnetron tube, the split-anode magnetron, was invented by Albert Hull in 1920, but it wasn't capable of high frequencies and was little used. Similar devices were experimented with by many teams through the 1920s and 30s. On November 27, 1935, Hans Erich Hollmann applied for a patent for the first multiple cavities magnetron, which he received on July 12, 1938, but the more stable klystron was preferred for most German radars during World war II. The cavity magnetron tube was later improved by John Randall and Harry Boot in 1940 at the University of Birmingham, England. The high power of pulses from their device made centimeter-band radar practical for the Allies of World War II, with shorter wavelength radars allowing detection of smaller objects from smaller antennas. The compact cavity magnetron tube drastically reduced the size of radar sets so that they could be installed in anti-submarine aircraft and escort ships.
In the post-war era the magnetron became less widely used in the radar role. This was due to the fact that the magnetron's output changes from pulse to pulse, both in frequency and phase. This makes the signal unsuitable for pulse-to-pulse comparisons, which is widely used for detecting and removing "clutter" from the radar display. The magnetron remains in use in some radars, but has become much more common as a low-cost microwave source for microwave ovens. In this form, approximately one billion magnetrons are in use today.
Construction and operation.
Basic concept.
In a conventional vacuum tube, electrons are emitted from a heated cathode and are attracted to the anode as it is positive with respect to the cathode. The components are normally arranged concentrically, with the cathode at the centre, giving them their traditional cylindrical shape. In vacuum tubes (valves), the current can flow only from the cathode to the anode, providing rectification although this function is usually performed by the diode. A triode adds a control grid which allows the flow of current to be further controlled in magnitude, and thereby provides an amplification function.
The idea of using a grid for control was heavily patented by Lee de Forest, and this caused considerable research into alternate concepts for tube designs in triodes that would avoid his patents. This led to experiments with tubes using magnetic fields instead of electrical ones, including the original magnetron. In this case the tube was arranged in the form of two concentric electrodes, typically with the cathode in the form of a metal rod in the center, and the anode as a cylinder around it. This arrangement was then placed between the poles of a horseshoe magnet arranged such that the magnetic field was aligned parallel to the axis of the electrodes.
With no magnetic field present, the electrons will flow directly from the cathode to the anode, operating as a diode. In the presence of the magnetic field, the electrons will experience a force at right angles to their direction of motion, according to the left-hand rule. In this case, the electron will follow a curved path between the cathode and anode. The curvature of the path can be controlled by varying either the magnetic field, as in an electromagnet, or by changing the electrical potential across the electrodes.
At very high magnetic field settings the electrons are forced back onto the cathode, preventing current flow. At the opposite extreme, with no field, the electrons are free to flow. There is a point between the two, the critical value or Hull cut-off magnetic field (and cut-off voltage), where the electrons just reach the anode. At fields around this point, the device operates similar to a triode. However, due to hysteresis and other effects, the control timing is not as fast as the electrostatic control in a conventional triode, and magnetrons saw limited use in conventional electronic designs.
Microwave source.
It was noticed that when the magnetron was operating at the critical value that it would begin to give off radio frequency signals. This occurred because the path, when properly adjusted, would cause some of the electrons to circle between the cathode and anode. Due to an effect now known as cyclotron radiation, this causes the electron to radiate. The effect was not very efficient; eventually the electrons would hit one of the electrodes, so the number in the circulating state at any given time was a small percentage of the overall current.
It was also noticed that the frequency of the radiation was simply a function of the size of the tube, and even early examples were built that produced signals in the microwave region. When used in conventional oscillator and amplifier circuits, tube systems were limited to high frequency bands, with very high frequency systems becoming widely available in the late 1930s. Ultra-high and microwave regions were well beyond the ability for conventional circuits, and the magnetron was one of the few devices known to generate signals in this band.
Split-anode magnetron.
The original magnetron was very difficult to keep operating at the critical value, and even then the number of electrons in the circling state at any time was fairly low. This meant that it produced very low-power signals. Nevertheless, as one of the few devices known to create microwaves, interest in the device and potential improvements was widespread.
The first major improvement was the split-anode magnetron, also known as a negative-resistance magnetron. As the name implies, this design used an anode that was split in two, creating two half-cylinders. When both were charged to the same voltage the system worked like the original model. But by altering the voltage of the two plates, the electron's trajectory could be modified so that they would naturally travel towards the lower voltage side. The plates were connected to an oscillator that reversed the relative voltage of the two plates at a given frequency.
At any given instant, the electron will naturally be pushed towards the lower-voltage side of the tube. The electron will then oscillate back and forth as the voltage changes. At the same time, a strong magnetic field is applied, stronger than the critical value in the original design. This would normally cause the electron to circle back to the cathode, but due to the oscillating electrical field, the electron instead follows a looping path that continues toward the anodes.
Since all of the electrons in the flow experienced this looping motion, the amount of RF energy being radiated was greatly improved. And as the motion occurred at any field level beyond the critical value, it was no longer necessary to carefully tune the fields and voltages, and the overall stability of the device was greatly improved. Unfortunately, the higher field also meant that electrons often circled back to the cathode, depositing their energy on it and causing it to heat up. As this normally causes more electrons to be released, it could sometimes lead to a runaway effect.
Cavity magnetron.
The great advance in magnetron design was the cavity magnetron or electron-resonance magnetron, which works on entirely different principles. In this design the oscillation is created by the physical shaping of the anode, rather than external circuits or fields.
Mechanically, the cavity magnetron consists of a large cylinder of metal with a hole drilled through the center of circular face. A wire acting as the cathode is run down the center of this hole, and the metal block itself forms the anode. Around this hole, known as the "interaction space", are a number of similar holes drilled parallel to the interaction space, separated only a very short distance away. A small slot is cut between the interaction space and each of these additional holes, the "resonators". The resulting block looks something like the cylinder on a revolver, with a somewhat larger central hole. Early models were cut using Colt pistol jigs. The parallel sides of the slots acted as a capacitor while the anode block itself provided an inductor analog. Thus, each cavity formed its own tuned oscillator, the frequency of which was defined by the energy of the electrons and the physical dimensions of the cavity.
The magnetic field is set to a value well below the critical, so the electrons follow arcing paths towards the anode. When they strike the anode, they cause it to become negatively charged in that region. As this process is random, some areas will become more or less charged than the areas around them. The anode is constructed of a highly conductive material, almost always copper, so these differences in voltage cause currents to appear to even them out. Since the current has to flow around the outside of the cavity, this process takes time. During that time additional electrons will avoid the hot spots and be deposited further along the anode, as the additional current flowing around it arrives too. This causes an oscillating current to form as the current tries to equalize one spot then another.
The oscillating currents flowing around the cavities, and their effect on the electron flow within the tube, causes large amounts of microwaves to be created in the cavities. The cavities are open on one end, so the entire mechanism forms a single larger microwave oscillator. A "tap", normally a wire formed into a loop, extracts microwave energy from one of the cavities. In some systems the tap wire is replaced by an open hole, which allows the microwaves to flow into a waveguide.
As the oscillation takes some time to set up, and is inherently random at the start, subsequent startups will have different output parameters. Phase is almost never preserved, which makes the magnetron difficult to use in phased array systems. Frequency also drifts pulse to pulse, a more difficult problem for a wider array of radar systems. Neither of these present a problem for some continuous-wave radars, nor for microwave ovens.
Common features.
All cavity magnetrons consist of a hot cathode with a high (continuous or pulsed) negative potential created by a high-voltage, direct-current power supply. The cathode is built into the center of an evacuated, lobed, circular chamber. A magnetic field parallel to the filament is imposed by a permanent magnet. The magnetic field causes the electrons, attracted to the (relatively) positive outer part of the chamber, to spiral outward in a circular path, a consequence of the Lorentz force. Spaced around the rim of the chamber are cylindrical cavities. The cavities are open along their length and connect the common cavity space. As electrons sweep past these openings, they induce a resonant, high-frequency radio field in the cavity, which in turn causes the electrons to bunch into groups. (This principle of cavity resonator is very similar to blowing a stream of air across the open top of a glass pop bottle.) A portion of the field is extracted with a short antenna that is connected to a waveguide (a metal tube usually of rectangular cross section). The waveguide directs the extracted RF energy to the load, which may be a cooking chamber in a microwave oven or a high-gain antenna in the case of radar.
The sizes of the cavities determine the resonant frequency, and thereby the frequency of emitted microwaves. However, the frequency is not precisely controllable. The operating frequency varies with changes in load impedance, with changes in the supply current, and with the temperature of the tube. This is not a problem in uses such as heating, or in some forms of radar where the receiver can be synchronized with an imprecise magnetron frequency. Where precise frequencies are needed, other devices such as the klystron are used.
The magnetron is a self-oscillating device requiring no external elements other than a power supply. A well-defined threshold anode voltage must be applied before oscillation will build up; this voltage is a function of the dimensions of the resonant cavity, and the applied magnetic field. In pulsed applications there is a delay of several cycles before the oscillator achieves full peak power, and the build-up of anode voltage must be coordinated with the build-up of oscillator output.
Where there are an even number of cavities, two concentric rings can connect alternate cavity walls to prevent inefficient modes of oscillation. This is called Pi strapping because the two straps lock the phase difference between adjacent cavities at Pi radians (180°).
The magnetron is a fairly efficient device. In a microwave oven, for instance, a 1.1 kilowatt input will generally create about 700 watts of microwave power, an efficiency of around 65%. (The high-voltage and the properties of the cathode determine the power of a magnetron.) Large S band magnetrons can produce up to 2.5 megawatts peak power with an average power of 3.75 kW. Large magnetrons can be water cooled. The magnetron remains in widespread use in roles which require high power, but where precise control over frequency and phase is unimportant.
Applications.
Radar.
In radar devices, the waveguide is connected to an antenna. The magnetron is operated with very short pulses of applied voltage, resulting in a short pulse of high power microwave energy being radiated. As in all primary radar systems, the radiation reflected off a target is analyzed to produce a radar map on a screen.
Several characteristics of the magnetron's power output conspire to make radar use of the device somewhat problematic. The first of these factors is the magnetron's inherent instability in its transmitter frequency. This instability is noted not only as a frequency shift from one pulse to the next, but also a frequency shift within an individual transmitted pulse. The second factor is that the energy of the transmitted pulse is spread over a wide frequency spectrum, which makes necessary its receiver to have a corresponding wide selectivity. This wide selectivity allows ambient electrical noise to be accepted into the receiver, thus obscuring somewhat the received radar echoes, thereby reducing overall radar performance. The third factor, depending on application, is the radiation hazard caused by the use of high power electromagnetic radiation. In some applications, for example a marine radar mounted on a recreational vessel, a radar with a magnetron output of 2 to 4 kilowatts is often found mounted very near an area occupied by crew or passengers. In practical use, these factors have been overcome, or merely accepted, and there are today thousands of magnetron aviation and marine radar units in service. Recent advances in aviation weather avoidance radar and in marine radar have successfully implemented semiconductor transmitters that eliminate the magnetron entirely. More precise sources allow the use of lower output powers.
Heating.
In microwave ovens, the waveguide leads to a radio frequency-transparent port into the cooking chamber. As the fixed dimensions of the chamber, and its physical closeness to the magnetron, would normally create standing wave patterns in the chamber, a motorized fan-like "stirrer" is placed in the waveguide to randomize the pattern. This is not always effective for larger objects in the chamber, and most modern microwave ovens also include a rotating table for the food to sit on, the "turntable".
Lighting.
In microwave-excited lighting systems, such as a sulfur lamp, a magnetron provides the microwave field that is passed through a waveguide to the lighting cavity containing the light-emitting substance (e.g., sulfur, metal halides, etc.). These lamps are currently uncommon due to the high complexity relative to traditional lighting methods.
History.
In 1912, Swiss physicist Heinrich Greinacher was looking for new ways to calculate the electron mass. He settled on a system consisting of a diode with a cylindrical anode surrounding a rod-shaped cathode, placed in the middle of a magnet. The attempt to measure the electron mass failed because he was unable to achieve a good vacuum in the tube. However, as part of this work, Greinacher developed mathematical models of the motion of the electrons in the crossed magnetic and electric fields.
In the US, Albert Hull put this work to use in an attempt to bypass Western Electric's patents on the triode, which they had gained by buying Lee De Forest's patents on the control of current flow using electric fields via the "grid". Hull intended to use a variable magnetic field, instead of an electrostatic one, to control the flow of the electrons from the cathode to the anode. Working at General Electric's Research Laboratories in Schenectady, New York, Hull built tubes that provided switching through the control of the ratio of the magnetic and electric field strengths. He released several papers and patents on the concept in 1921.
Hull's magnetron was not originally intended to generate VHF (very-high-frequency) electromagnetic waves. However, in 1924, Czech physicist August Žáček (1886–1961) and German physicist Erich Habann (1892–1968) independently discovered that the magnetron could generate waves of 100 megahertz to 1 gigahertz. Žáček, a professor at Prague's Charles University, published first; however, he published in a journal with a small circulation and thus attracted little attention. Habann, a student at the University of Jena, investigated the magnetron for his doctoral dissertation of 1924. Throughout the 1920s, Hull and other researchers around the world worked to develop the magnetron. Most of these early magnetrons were glass vacuum tubes with multiple anodes. However, the two-pole magnetron, also known as a split-anode magnetron, had relatively low efficiency. The cavity version (properly referred to as a "resonant-cavity magnetron") proved to be far more useful. In 1937-1940 a multi-cavity magnetron was built by the British physicist John Randall, together with a team of British coworkers, for the British and American military radar installations in World War II.
While radar was being developed during World War II, there arose an urgent need for a high-power microwave generator that worked at shorter wavelengths (around 10 cm (3 GHz)) rather than the 150 cm (200 MHz) that was available from tube-based generators of the time. It was known that a multi-cavity resonant magnetron had been developed and patented in 1935 by Hans Hollmann in Berlin. However, the German military considered the frequency drift of Hollman's device to be undesirable, and based their radar systems on the klystron instead. But klystrons could not at that time achieve the high power output that magnetrons eventually reached. This was one reason that German night fighter radars were not a match for their British counterparts.
In 1940, at the University of Birmingham in the United Kingdom, John Randall and Harry Boot produced a working prototype similar to Hollman's cavity magnetron, but added liquid cooling and a stronger cavity. Randall and Boot soon managed to increase its power output 100 fold. Instead of abandoning the magnetron due to its frequency instability, they sampled the output signal and synchronized their receiver to whatever frequency was actually being generated. In 1941, the problem of frequency instability was solved by coupling ("strapping") alternate cavities within the magnetron. (For an overview of early magnetron designs, including that of Boot and Randall, see )
Because France had just fallen to the Nazis and Britain had no money to develop the magnetron on a massive scale, Churchill agreed that Sir Henry Tizard should offer the magnetron to the Americans in exchange for their financial and industrial help (the Tizard Mission). An early 6 kW version, built in England by the General Electric Company Research Laboratories, Wembley, London (not to be confused with the similarly named American company General Electric), was given to the US government in September 1940. The British magnetron was a thousand times more powerful than the best American transmitter at the time and produced accurate pulses. At the time the most powerful equivalent microwave producer available in the US (a klystron) had a power of only ten watts. The cavity magnetron was widely used during World War II in microwave radar equipment and is often credited with giving Allied radar a considerable performance advantage over German and Japanese radars, thus directly influencing the outcome of the war. It was later described by noted Historian James Phinney Baxter III as "The most valuable cargo ever brought to our shores".
The Bell Telephone Laboratories made a producible version from the magnetron delivered to America by the Tizard Mission, and before the end of 1940, the Radiation Laboratory had been set up on the campus of the Massachusetts Institute of Technology to develop various types of radar using the magnetron. By early 1941, portable centimetric airborne radars were being tested in American and British aircraft. In late 1941, the Telecommunications Research Establishment in Great Britain used the magnetron to develop a revolutionary airborne, ground-mapping radar codenamed H2S. The H2S radar was in part developed by Alan Blumlein and Bernard Lovell.
Centimetric radar, made possible by the cavity magnetron, allowed for the detection of much smaller objects and the use of much smaller antennas. The combination of small-cavity magnetrons, small antennas, and high resolution allowed small, high quality radars to be installed in aircraft. They could be used by maritime patrol aircraft to detect objects as small as a submarine periscope, which allowed aircraft to attack and destroy submerged submarines which had previously been undetectable from the air. Centimetric contour mapping radars like H2S improved the accuracy of Allied bombers used in the strategic bombing campaign. Centimetric gun-laying radars were likewise far more accurate than the older technology. They made the big-gunned Allied battleships more deadly and, along with the newly developed proximity fuze, made anti-aircraft guns much more dangerous to attacking aircraft. The two coupled together and used by anti-aircraft batteries, placed along the flight path of German V-1 flying bombs on their way to London, are credited with destroying many of the flying bombs before they reached their target.
Since then, many millions of cavity magnetrons have been manufactured; while some have been for radar the vast majority have been for microwave ovens. The use in radar itself has dwindled to some extent, as more accurate signals have generally been needed and developers have moved to klystron and traveling-wave tube systems for these needs.
Health hazards.
Among more speculative hazards, at least one in particular is well known and documented. As the lens of the eye has no cooling blood flow, it is particularly prone to overheating when exposed to microwave radiation. This heating can in turn lead to a higher incidence of cataracts in later life. A microwave oven with a warped door or poor microwave sealing can be hazardous.
There is also a considerable electrical hazard around magnetrons, as they require a high voltage power supply.
Some magnetrons have beryllium oxide (beryllia) ceramic insulators, which are dangerous if crushed and inhaled, or otherwise ingested. Single or chronic exposure can lead to berylliosis, an incurable lung condition. In addition, beryllia is listed as a confirmed human carcinogen by the IARC; therefore, broken ceramic insulators or magnetrons should not be directly handled.
All magnetrons contain a small amount of thorium mixed with tungsten in their filament. While this is a radioactive metal, the risk of cancer is low as it never gets airborne in normal usage. Only if the filament is taken out of the microwave and crushed that it can pose a health hazard.

</doc>
<doc id="20862" url="http://en.wikipedia.org/wiki?curid=20862" title="Manorialism">
Manorialism

Manorialism, an essential element of feudal society, was the organizing principle of rural economy that originated in the villa system of the Late Roman Empire, was widely practiced in medieval western and parts of central Europe, and was slowly replaced by the advent of a money-based market economy and new forms of agrarian contract.
Manorialism was characterised by the vesting of legal and economic power in a Lord of the Manor, supported economically from his own direct landholding in a manor (sometimes called a fief), and from the obligatory contributions of a legally subject part of the peasant population under the jurisdiction of himself and his manorial court. These obligations could be payable in several ways, in labor (the French term "corvée" is conventionally applied), in kind, or, on rare occasions, in coin.
In examining the origins of the monastic cloister, Walter Horn found that "as a manorial entity the Carolingian monastery ... differed little from the fabric of a feudal estate, save that the corporate community of men for whose sustenance this organization was maintained consisted of monks who served God in chant and spent much of their time in reading and writing."
Manorialism died slowly and piecemeal, along with its most vivid feature in the landscape, the open field system. It outlasted serfdom as it outlasted feudalism: "primarily an economic organization, it could maintain a warrior, but it could equally well maintain a capitalist landlord. It could be self-sufficient, yield produce for the market, or it could yield a money rent." The last feudal dues in France were abolished at the French Revolution. In parts of eastern Germany, the "Rittergut" manors of Junkers remained until World War II.
Historical and geographical distribution.
The term is most often used with reference to medieval Western Europe. Antecedents of the system can be traced to the rural economy of the later Roman Empire. With a declining birthrate and population, labor was the key factor of production. Successive administrations tried to stabilise the imperial economy by freezing the social structure into place: sons were to succeed their fathers in their trade, councilors were forbidden to resign, and "coloni", the cultivators of land, were not to move from the land they were attached to. The workers of the land were on their way to becoming serfs.
Several factors conspired to merge the status of former slaves and former free farmers into a dependent class of such "coloni": it was possible to be described as "servus et colonus", "both slave and "colonus"". Laws of Constantine I around 325 both reinforced the semi-servile status of the "coloni" and limited their rights to sue in the courts; the "Codex Theodosianus" promulgated under Theodosius II extended these restrictions. The legal status of "adscripti", "bound to the soil", contrasted with barbarian "foederati", who were permitted to settle within the imperial boundaries, remaining subject to their own traditional law.
As the Germanic kingdoms succeeded Roman authority in the West in the fifth century, Roman landlords were often simply replaced by Gothic or Germanic ones, with little change to the underlying situation or displacement of populations.
The process of rural self-sufficiency was given an abrupt boost in the eighth century, when normal trade in the Mediterranean Sea was disrupted. The thesis put forward by Henri Pirenne, while disputed widely, supposes that the Arab conquests forced the medieval economy into even greater ruralization and gave rise to the classic feudal pattern of varying degrees of servile peasantry underpinning a hierarchy of localised power centers.
History.
The word derives from traditional inherited divisions of the countryside, reassigned as local jurisdictions known as manors or seigneuries; each manor being subject to a lord (French "seigneur"), usually holding his position in return for undertakings offered to a higher lord (see Feudalism). The lord held a manorial court, governed by public law and local custom. Not all territorial seigneurs were secular; bishops and abbots also held lands that entailed similar obligations.
By extension, the word "manor" is sometimes used in England to mean any home area or territory in which authority is held, often in a police or criminal context.
In the generic plan of a medieval manor from "Shepherd's Historical Atlas", the strips of individually worked land in the open field system are immediately apparent. In this plan, the manor house is set slightly apart from the village, but equally often the village grew up around the forecourt of the manor, formerly walled, while the manor lands stretched away outside, as still may be seen at Petworth House. As concerns for privacy increased in the 18th century, manor houses were often located a farther distance from the village. For example, when a grand new house was required by the new owner of Harlaxton Manor, Lincolnshire, in the 1830s, the site of the existing manor house at the edge of its village was abandoned for a new one, isolated in its park, with the village out of view.
In an agrarian society, the conditions of land tenure underlie all social or economic factors. There were two legal systems of pre-manorial landholding. One, the most common, was the system of holding land "allodially" in full outright ownership. The other was a use of "precaria" or benefices, in which land was held conditionally (the root of the English word "precarious").
To these two systems, the Carolingian monarchs added a third, the "aprisio", which linked manorialism with feudalism. The "aprisio" made its first appearance in Charlemagne's province of Septimania in the south of France, when Charlemagne had to settle the Visigothic refugees, who had fled with his retreating forces, after the failure of his Zaragoza expedition of 778. He solved this problem by allotting "desert" tracts of uncultivated land belonging to the royal "fisc" under direct control of the emperor. These holdings "aprisio" entailed specific conditions. The earliest specific "aprisio" grant that has been identified was at Fontjoncouse, near Narbonne (see Lewis, links). In former Roman settlements, a system of villas, dating from Late Antiquity, was inherited by the medieval world.
Common features.
Manors each consisted of up to three classes of land:
Additional sources of income for the lord included charges for use of his mill, bakery or wine-press, or for the right to hunt or to let pigs feed in his woodland, as well as court revenues and single payments on each change of tenant. On the other side of the account, manorial administration involved significant expenses, perhaps a reason why smaller manors tended to rely less on villein tenure.
Dependent holdings were held nominally by arrangement of lord and tenant, but tenure became in practice almost universally hereditary, with a payment made to the lord on each succession of another member of the family. Villein land could not be abandoned, at least until demographic and economic circumstances made flight a viable proposition; nor could they be passed to a third party without the lord's permission, and the customary payment.
Although not free, villeins were by no means in the same position as slaves: they enjoyed legal rights, subject to local custom, and had recourse to the law subject to court charges, which were an additional source of manorial income. Sub-letting of villein holdings was common, and labour on the demesne might be commuted into an additional money payment, as happened increasingly from the 13th century.
This description of a manor house at Chingford, Essex in England was recorded in a document for the Chapter of St Paul's Cathedral when it was granted to Robert Le Moyne in 1265:
Variation among manors.
Like feudalism which, together with manorialism, formed the legal and organizational framework of feudal society, manorial structures were not uniform. In the later Middle Ages, areas of incomplete or non-existent manorialization persisted while the manorial economy underwent substantial development with changing economic conditions.
Not all manors contained all three kinds of land: typically, demesne accounted for roughly a third of the arable area, and villein holdings rather more; but some manors consisted solely of demesne, others solely of peasant holdings. The proportion of unfree and free tenures could likewise vary greatly, with more or less reliance on wage labour for agricultural work on the demesne.
The proportion of the cultivated area in demesne tended to be greater in smaller manors, while the share of villein land was greater in large manors, providing the lord of the latter with a larger supply of obligatory labour for demesne work. The proportion of free tenements was generally less variable, but tended to be somewhat greater on the smaller manors.
Manors varied similarly in their geographical arrangement: most did not coincide with a single village, but rather consisted of parts of two or more villages, most of the latter containing also parts of at least one other manor. This situation sometimes led to replacement by cash payments or their equivalents in kind of the demesne labour obligations of those peasants living furthest from the lord's estate.
As with peasant plots, the demesne was not a single territorial unit, but consisted rather of a central house with neighbouring land and estate buildings, plus strips dispersed through the manor alongside free and villein ones: in addition, the lord might lease free tenements belonging to neighbouring manors, as well as holding other manors some distance away to provide a greater range of produce.
Nor were manors held necessarily by lay lords rendering military service (or again, cash in lieu) to their superior: a substantial share (estimated by value at 17% in England in 1086) belonged directly to the king, and a greater proportion (rather more than a quarter) were held by bishoprics and monasteries. Ecclesiastical manors tended to be larger, with a significantly greater villein area than neighbouring lay manors.
The effect of circumstances on manorial economy is complex and at times contradictory: upland conditions tended to preserve peasant freedoms (livestock husbandry in particular being less labour-intensive and therefore less demanding of villein services); on the other hand, some upland areas of Europe showed some of the most oppressive manorial conditions, while lowland eastern England is credited with an exceptionally large free peasantry, in part a legacy of Scandinavian settlement.
Similarly, the spread of money economy stimulated the replacement of labour services by money payments, but the growth of the money supply and resulting inflation after 1170 initially led nobles to take back leased estates and to re-impose labour dues as the value of fixed cash payments declined in real terms.
See also.
Specific:
General:

</doc>
<doc id="20864" url="http://en.wikipedia.org/wiki?curid=20864" title="Margaret Mitchell">
Margaret Mitchell

Margaret Munnerlyn Mitchell (November 8, 1900 – August 16, 1949) was an American author and journalist. One novel by Mitchell was published during her lifetime, the American Civil War-era novel, "Gone with the Wind", for which she won the National Book Award for Most Distinguished Novel of 1936
and the Pulitzer Prize for Fiction in 1937. In more recent years, a collection of Mitchell's girlhood writings and a novella she wrote as a teenager, "Lost Laysen", have been published. A collection of articles written by Mitchell for "The Atlanta Journal" was republished in book form.
Family history.
Margaret Mitchell was a Southerner and a lifelong resident and native of Atlanta, Georgia. She was born in 1900 into a wealthy and politically prominent family. Her father, Eugene Muse Mitchell, was an attorney, and her mother, Mary Isabel "May Belle" (or "Maybelle") Stephens, was a suffragist. She had two brothers, Russell Stephens Mitchell, who died in infancy in 1894, and Alexander Stephens Mitchell, born in 1896.
Mitchell's family on her father's side were descendants of Thomas Mitchell, originally of Aberdeenshire, Scotland, who settled in Wilkes County, Georgia in 1777, and served in the American Revolutionary War. Her grandfather, Russell Crawford Mitchell, of Atlanta, enlisted in the Confederate States Army on June 24, 1861 and served in Hood's Texas Brigade. He was severely wounded at the Battle of Sharpsburg, demoted for 'inefficiency,' and detailed as a nurse in Atlanta. After the Civil War, he made a large fortune supplying lumber for the rapid rebuilding of Atlanta. Russell Mitchell had thirteen children from two wives; the eldest was Eugene, who graduated from the University of Georgia Law School.
Mitchell's maternal great-grandfather Philip Fitzgerald emigrated from Ireland, and eventually settled on a slaveholding plantation near Jonesboro, Georgia, where he had one son and seven daughters with his wife, Elenor. Mitchell's grandparents, married in 1863, were Annie Fitzgerald and John Stephens, who had also emigrated from Ireland and was a Captain in the Confederate States Army. John Stephens was a prosperous real estate developer after the Civil War and one of the founders of the Gate City Street Railroad (1881), a mule-drawn Atlanta trolley system. John and Annie Stephens had twelve children together; the seventh child was May Belle Stephens, who married Eugene Mitchell. May Belle Stephens had studied at the Bellevue Convent in Quebec and completed her education at the Atlanta Female Institute.
The "Atlanta Constitution" reported that May Belle Stephens and Eugene Mitchell were married at the Jackson Street mansion of the bride's parents on November 8, 1892:
...the maid of honor, Miss Annie Stephens, was as pretty as a French pastel, in a directoire costume of yellow satin with a long coat of green velvet sleeves, and a vest of gold brocade...The bride was a fair vision of youthful loveliness in her robe of exquisite ivory white and satin...her slippers were white satin wrought with pearls...an elegant supper was served. The dining room was decked in white and green, illuminated with numberless candles in silver candlelabras...The bride's gift from her father was an elegant house and lot...At 11 o'clock Mrs. Mitchell donned a pretty going-away gown of green English cloth with its jaunty velvet hat to match and bid goodbye to her friends.
Early influences.
Margaret Mitchell spent her early childhood on Jackson Hill, east of downtown Atlanta. Her family lived near her grandmother, Annie Stephens, in a Victorian house painted bright red with yellow trim. Mrs. Stephens had been a widow for several years prior to Margaret's birth; Captain John Stephens died in 1896. After his death, she inherited property on Jackson Street where Margaret's family lived.
Grandmother Annie Stephens was quite a character, both vulgar and a tyrant. After gaining control of her father Philip Fitzgerald's money after he died, she splurged on her younger daughters, including Margaret's mother, and sent them to finishing school in the north. There they learned that Irish Americans were not treated as equal to other immigrants, and that it was shameful to be a daughter of an Irishman. Margaret's relationship with her grandmother would become quarrelsome in later years as she entered adulthood. However, for Margaret, her grandmother was a great source of "eye-witness information" about the Civil War and Reconstruction in Atlanta prior to her death in 1934.
Girlhood on Jackson Hill.
In an accident that was traumatic for her mother although she was unharmed, when little Margaret was about three years old, her dress caught fire on an iron grate. Fearing it would happen again, her mother began dressing her in boys' pants, and she was nicknamed "Jimmy", the name of a character in the comic strip, "Little Jimmy". Her brother insisted she would have to be a boy named Jimmy to play with him. Having no sisters to play with, Margaret said she was a boy named Jimmy until she was fourteen.
Stephens Mitchell said his sister was a tomboy who would happily play with dolls occasionally, and she liked to ride her Texas plains pony. As a little girl, Margaret went riding every afternoon with a Confederate veteran and a young lady of "beau-age".
Margaret was raised in an era when children were "seen and not heard". She was not allowed to express her personality by running and screaming on Sunday afternoons while her family was visiting relatives. Her mother would swat her with a hairbrush or a slipper as a form of discipline.
May Belle Mitchell was "hissing blood curdling threats" to her daughter to make her behave the evening she took her to a women's suffrage rally led by Carrie Chapman Catt. Margaret sat on a platform wearing a Votes-for-Women banner blowing kisses to the gentlemen while her mother gave an impassioned speech. She was nineteen years old when the Nineteenth Amendment was ratified, which gave women the right to vote.
May Belle Mitchell was president of the Atlanta Woman's Suffrage League (1915), chairwoman of press publicity for the Georgia Mothers' Congress and Parent Teacher Association, a member of the Pioneer Society, the Atlanta Woman's Club, and several church and literary societies.
Margaret's father was not in favor of corporal punishment in school. During his tenure as president of the educational board (1911–1912), corporal punishment in the public schools was abolished. Reportedly, Eugene Mitchell received a whipping on the first day he attended school and the mental impression of the threshing lasted far longer than the physical marks.
Jackson Hill was an old, affluent part of the city. At the bottom of Jackson Hill was an area of African American homes and businesses called "Darktown". The mayhem of the Atlanta Race Riot occurred over four days in September 1906 when Mitchell was five years old. Local newspapers alleged that several white women had been assaulted by black men, prompting an angry mob of 10,000 to assemble in the streets.
Eugene Mitchell went to bed early the night the rioting began, but was awakened by the sounds of gunshots. The following morning he learned 16 Negroes had been killed. He wrote to his wife that rioters attempted to kill every Negro in sight. As the rioting continued, rumors ran wild Negroes would burn Jackson Hill. At Margaret's suggestion, her father, who did not own a gun, stood guard with a sword.
Though she and her family were unharmed, Margaret was able to recall the terror she felt during the riot twenty years later. Mitchell grew up in a Southern culture where the threat of black on white rape incited mob violence, and in this world, white Georgians lived in fear of the "black beast rapist".
Soon after the riot, Margaret's family decided to move away from Jackson Hill. In 1912, they moved to the east side of Peachtree Street just north of Seventeenth Street in Atlanta. Past the nearest neighbor's house was forest and beyond it the Chattahoochee River. Mitchell's former Jackson Hill home was destroyed in the Great Atlanta Fire of 1917.
The South (of her imagination).
While "the South" exists as a geographical region of the United States, it is also said to exist as "a place of the imagination" of writers. An image of "the South" was fixed in Mitchell's imagination when at six years old her mother took her on a buggy tour through ruined plantations and "Sherman's sentinels", the brick and stone chimneys that remained after William Tecumseh Sherman's "March and torch" through Georgia. Mitchell would later recall what her mother had said to her:
She talked about the world those people had lived in, such a secure world, and how it had exploded beneath them. And she told me that my world was going to explode under me, someday, and God help me if I didn't have some weapon to meet the new world.
From an imagination cultivated in her youth, Margaret Mitchell's defensive weapon would become her writing.
Mitchell said she heard Civil War stories from her relatives when she was growing up:
On Sunday afternoons when we went calling on the older generation of relatives, those who had been active in the Sixties, I sat on the bony knees of veterans and the fat slippery laps of great aunts and heard them talk.
On summer vacations, she visited her maternal great-aunts, Mary Ellen ("Mamie") Fitzgerald and Sarah ("Sis") Fitzgerald, who still lived at her great-grandparents' plantation home in Jonesboro. Mamie had been twenty-one years old and Sis was thirteen when the Civil War began.
An avid reader.
An avid reader, young Margaret read "boys' stories" by G.A. Henty, the Tom Swift series, and the Rover Boys series by Edward Stratemeyer. Her mother read Mary Johnston's novels to her before she could read. They both wept reading Johnston's "The Long Roll" (1911) and "Cease Firing" (1912). Between the "scream of shells, the mighty onrush of charges, the grim and grisly aftermath of war", "Cease Firing" is a romance novel involving the courtship of a Confederate soldier and a Louisiana plantation belle with Civil War illustrations by N. C. Wyeth. She also read the plays of William Shakespeare, and novels by Charles Dickens and Sir Walter Scott.
Mitchell's two favorite children's books were by author Edith Nesbit: "Five Children and It" (1902) and "The Phoenix and the Carpet" (1904). She kept both on her bookshelf even as an adult and gave them as gifts.
Young storyteller.
An imaginative writer from a precocious age, Margaret Mitchell began with stories about animals, then progressed to fairy tales and adventure stories. She fashioned book covers for her stories, bound the tablet paper pages together and added her own artwork. At age eleven she gave a name to her publishing enterprise: "Urchin Publishing Co." Later her stories were written in notebooks. May Belle Mitchell kept her daughter's stories in white enamel bread boxes and several boxes of her stories were stored in the house by the time Margaret went off to college.
"Margaret" is a character riding a galloping pony in "The Little Pioneers", and plays "Cowboys and Indians" in "When We Were Shipwrecked".
Romantic love and honor emerged as themes of abiding interest for Mitchell in "The Knight and the Lady" (ca. 1909), in which a "good knight" and a "bad knight" duel for the hand of the lady. In "The Arrow Brave and the Deer Maiden" (ca. 1913), a half-white Indian brave, Jack, must withstand the pain inflicted upon him to uphold his honor and win the girl. The same themes were treated with increasing artistry in "Lost Laysen", the novella Mitchell wrote as a teenager in 1916, and, with much greater sophistication, in Mitchell's last known novel, "Gone with the Wind", which she began in 1926.
In her pre-teens, Mitchell also wrote stories set in foreign locations, such as "The Greaser" (1913), a cowboy story set in Mexico. In 1913 she wrote two stories with Civil War settings; one includes her notation that "237 pages are in this book".
School years.
Fancy Dress Masquerade
Seventy girls and boys were the guests of Miss Margaret Mitchell at a fancy dress masquerade yesterday afternoon at the home of her parents Mr. and Mrs. Eugene Mitchell on Peachtree street and the occasion was beautiful and enjoyable.
There was a prize for guessing the greatest number of identities under the masks, and another for the guest who best concealed his or her identity.
The pretty young hostess was a demure Martha Washington in flowered crepe gown over a pink silk petticoat and her powdered hair was worn high.
Mrs. Mitchell wore a ruby velvet gown.
"The Constitution", Atlanta, November 21, 1914.
While the Great War carried on in Europe (1914–1918), Margaret Mitchell attended Atlanta's Washington Seminary (now The Westminster Schools), a "fashionable" private girls' school with an enrollment of over 300 students. She was very active in the Drama Club. Mitchell played the male characters: Nick Bottom in Shakespeare's "A Midsummer Night's Dream" and Launcelot Gobbo in Shakespeare's "The Merchant of Venice", among others. She wrote a play about snobbish college girls that she acted in as well. She also joined the Literary Club and had two stories published in the yearbook: "Little Sister" and "Sergeant Terry". Ten-year-old "Peggy" is the heroine in "Little Sister". She hears her older sister being raped and shoots the rapist:
Coldly, dispassionately she viewed him, the chill steel of the gun giving her confidence. She must not miss now—she would not miss—and she did not.
Mitchell received encouragement from her English teacher, Mrs. Paisley, who recognized her writing talent. A demanding teacher, Paisley told her she had ability if she worked hard and would not be careless in constructing sentences. A sentence, she said, must be "complete, concise and coherent".
Mitchell read the books of Thomas Dixon, Jr., and in 1916, when the silent film, "The Birth of a Nation", was showing in Atlanta, she dramatized Dixon's "The Traitor: A Story of the Fall of the Invisible Empire" (1907). As both playwright and actress, she took the role of Steve Hoyle. For the production, she made a Ku Klux Klan costume from a white crepe dress and wore a boy's wig. (Note: Dixon rewrote "The Traitor" as "The Black Hood" (1924) and Steve Hoyle was renamed George Wilkes.)
During her years at Washington Seminary, Mitchell's brother, Stephens, was away studying at Harvard College (1915–1917), and he left in May 1917 to enlist in the army, about a month after the U.S. declared war on Germany. He set sail for France in April 1918, participated in engagements in the Lagny and Marbache sectors, then returned to Georgia in October as a training instructor. While Margaret and her mother were in New York in September 1918 preparing for Margaret to attend college, Stephens wired his father that he was safe after his ship had been torpedoed en route to New York from France.
Stephens Mitchell thought college was the "ruination of girls". However, May Belle Mitchell placed a high value on education for women and she wanted her daughter's future accomplishments to come from using her mind. She saw education as Margaret's weapon and "the key to survival". The classical college education she desired for her daughter was one that was on par with men's colleges, and this type of education was available only at northern schools. Her mother chose Smith College in Northampton, Massachusetts for Margaret because she considered it to be the best women's college in the United States.
Upon graduating from Washington Seminary in June 1918, Mitchell fell in love with a Harvard graduate, a young army lieutenant, Clifford West Henry, who was chief bayonet instructor at Camp Gordon from May 10 until the time he set sail for France on July 17. Henry was "slightly effeminate", "ineffectual", and "rather effete-looking" with "homosexual tendencies", according to biographer Anne Edwards. Before departing for France, he gave Mitchell an engagement ring.
On September 14, while she was enrolled at Smith College, Henry was mortally wounded in action in France and died on October 17. As Henry waited in the Verdun trenches, shortly before being wounded, he composed a poem on a leaf torn from his field notebook, found later among his effects. The last stanza of Lieutenant Clifford W. Henry's poem follows:
 General Edwards Presents Medal
Mrs. Ira Henry of Sound Beach was presented the Distinguished Service medal from the War department today in honor of her son, Captain Clifford W. Henry for bravery under fire during the World war. The medal, recommended by General Pershing, was presented by Major General Edwards.
Captain Henry, who during the war was a lieutenant with Co.F, 102nd infantry, captured the town of Vignuelles, nine kilometers inside the Hindenburg line on September 13, 1918. Lieutenant Henry and 50 of his men were killed the next day by a terrific explosion in the town. Captain Henry was a graduate of Harvard University.
"The Bridgeport Telegram", July 4, 1927.
Henry repeatedly advanced in front of the platoon he commanded, drawing machine-gun fire so that the German nests could be located and wiped out by his men. Although wounded in the leg in this effort, his death was the result of shrapnel wounds from an air bomb dropped by a German plane. He was awarded the French "Croix de guerre avec palme" for his acts of heroism. From the President of the United States, the Commander in Chief of the United States Armed Forces, he was presented with the Distinguished Service Cross and an Oak Leaf Cluster in lieu of a second Distinguished Service Cross.
Clifford Henry was the great love of Margaret Mitchell's life, according to her brother. In a letter to a friend (A. Edee, March 26, 1920), Mitchell wrote of Clifford that she had a "memory of a love that had in it no trace of physical passion".
Mitchell had vague aspirations of a career in psychiatry, but her future was derailed by an event that killed over fifty million people worldwide, the 1918 flu pandemic. On January 25, 1919, her mother, May Belle Mitchell, succumbed to pneumonia from the "Spanish flu". Mitchell arrived home from college a day after her mother had died. Knowing her death was imminent, May Belle Mitchell wrote her daughter a brief letter and advised her:
Give of yourself with both hands and overflowing heart, but give only the excess after you have lived your own life.
An average student at Smith College, Mitchell did not excel in any area of academics. She held a low estimation of her writing abilities. Even though her English professor had praised her work, she felt the praise was undue. After finishing her freshman year at Smith, Mitchell returned to Atlanta to take over the household for her father and never returned to college. In October 1919, while regaining her strength after an appendectomy, she confided to a friend that giving up college and her dreams of a "journalistic career" to keep house and take her mother's place in society meant "giving up all the worthwhile things that counted for—nothing!"
Marriage.
Miss Mitchell, Hostess
Miss Mitchell was hostess at an informal buffet supper last evening at her home on Peachtree road, the occasion complimenting Miss Blanche Neel, of Macon, who is visiting Miss Dorothy Bates.
Spring flowers adorned the laced covered table in the dining room. Miss Neel was gowned in blue Georgette crepe. Miss Mitchell wore pink taffeta. Miss Bates was gowned in blue velvet.
Invited to meet the honor guest were Miss Bates, Miss Virginia Walker, Miss Ethel Tye, Miss Caroline Tye, Miss Helen Turman, Miss Lethea Turman, Miss Frances Ellis, Miss Janet Davis, Miss Lillian Raley, Miss Mary Woolridge, Charles DuPree, William Cantrell, Lieutenant Jack Swarthout, Lieutenant William Gooch, Stephen Mitchell, McDonald Brittain, Harry Hallman, George Northen, Frank Hooper, Walter Whiteman, Frank Stanton, Val Stanton, Charles Belleau, Henry Angel, Berrien Upshaw and Edmond Cooper.
"The Constitution", Atlanta, February 2, 1921.
Margaret began using the name "Peggy" at Washington Seminary, and the abbreviated form "Peg" at Smith College when she found an icon for herself in the mythological winged horse, "Pegasus", that inspires poets. Peggy made her Atlanta society debut in the 1920 winter season. In the "gin and jazz style" of the times, she did her "flapping" in the 1920s. At a 1921 Atlanta debutante charity ball, she performed an Apache dance. The dance included a kiss with her male partner that shocked Atlanta "high society". The Apache and the Tango were scandalous dances for their elements of eroticism, the latter popularized in a 1921 silent film, "The Four Horsemen of the Apocalypse", that made its lead actor, Rudolph Valentino, a sex symbol for his ability to Tango.
Mitchell was, in her own words, an "unscrupulous flirt". She found herself engaged to five men, but maintained that she neither lied to or misled any of them. A local gossip columnist, who wrote under the name Polly Peachtree, described Mitchell's love life in a 1922 column:
...she has in her brief life, perhaps, had more men really, truly 'dead in love' with her, more honest-to-goodness suitors than almost any other girl in Atlanta.
In April 1922, Mitchell was seeing two men almost daily; one was Berrien “Red” Upshaw, whom she is thought to have met in 1917 at a dance hosted by the parents of one of her friends, and the other, Upshaw's roommate and friend, John R. Marsh, a copy editor from Kentucky who worked for the Associated Press. Upshaw was an Atlanta boy, a few months younger than Mitchell, whose family moved to Raleigh, North Carolina in 1916. In 1919 he was appointed to the United States Naval Academy, but resigned for academic deficiencies on January 5, 1920. He was readmitted in May, then 19 years-old, and spent two months at sea before resigning a second time on September 1, 1920. Unsuccessful in his educational pursuits and with no job, in 1922 Upshaw earned money bootlegging alcohol out of the Georgia mountains.
Although her family disapproved, Peggy and Red married on September 2, 1922, and the best man at their wedding was John Marsh, who would become her second husband. The couple resided at the Mitchell home with her father. By December the marriage to Upshaw had dissolved and he left. Mitchell suffered physical and emotional abuse, the result of Upshaw's alcoholism and violent temper. Upshaw agreed to an uncontested divorce after John Marsh gave him a loan and Mitchell agreed not to press assault charges against him. Upshaw and Mitchell were divorced on October 16, 1924.
On July 4, 1925, 24-year-old Margaret Mitchell and 29-year-old John Marsh were married in the Unitarian-Universalist Church. The Marshes made their home at the Crescent Apartments in Atlanta, taking occupancy of Apt. 1, which they affectionately named "The Dump" (now the Margaret Mitchell House & Museum).
Reporter for "The Atlanta Journal".
While still legally married to Upshaw and needing income for herself, Mitchell got a job writing feature articles for "The Atlanta Journal Sunday Magazine". She received almost no encouragement from her family or "society" to pursue a career in journalism, and had no prior newspaper experience. Medora Field Perkerson, who hired Mitchell said:
There had been some skepticism on the Atlanta Journal Magazine staff when Peggy came to work as a reporter. Debutantes slept late in those days and didn't go in for jobs.
Her first story, "Atlanta Girl Sees Italian Revolution", by Margaret Mitchell Upshaw, appeared on December 31, 1922. She wrote on a wide range of topics, from fashions to Confederate generals and King Tut. In an article that appeared on July 1, 1923, "Valentino Declares He Isn't a Sheik", she interviewed celebrity actor Rudolph Valentino, referring to him as "Sheik" from his film role. Less thrilled by his looks than his "chief charm", his "low, husky voice with a soft, sibilant accent", she described his face as "swarthy":
His face was swarthy, so brown that his white teeth flashed in startling contrast to his skin; his eyes—tired, bored, but courteous.
Mitchell was quite thrilled when Valentino took her in his arms and carried her inside from the rooftop of the Georgian Terrace Hotel.
Many of her stories were vividly descriptive. In an article titled, "Bridesmaid of Eighty-Seven Recalls Mittie Roosevelt's Wedding", she wrote of a white-columned mansion in which lived the last surviving bridesmaid at Theodore Roosevelt's mother's wedding:
The tall white columns glimpsed through the dark green of cedar foliage, the wide veranda encircling the house, the stately silence engendered by the century-old oaks evoke memories of Thomas Nelson Page's "On Virginia". The atmosphere of dignity, ease, and courtesy that was the soul of the Old South breathes from this old mansion...
In another article, "Georgia's Empress and Women Soldiers", she wrote short sketches of four notable Georgia women. One was the first woman to serve in the United States Senate, Rebecca Latimer Felton, a suffragist who held white supremacist views. The other women were: Nancy Hart, Lucy Mathilda Kenny (also known as Private Bill Thompson of the Confederate States Army) and Mary Musgrove. The article generated mail and controversy from her readers. Mitchell received criticism for depicting "strong women who did not fit the accepted standards of femininity."
Mitchell's journalism career, which began in 1922, came to an end less than four years later; her last article appeared on May 9, 1926. Several months after marrying John Marsh, Mitchell quit due to an ankle injury that would not heal properly and chose to become a full-time wife. During the time Mitchell worked for the "Atlanta Journal", she wrote 129 feature articles, 85 news stories, and several book reviews.
Interest in erotica.
Mitchell began collecting erotica from book shops in New York City while in her twenties. She and her friends were flamboyant in 1925. The newlywed Marshes and their social group were interested in "all forms of sexual expression". Mitchell discussed her interest in "dirty" book shops and sexually explicit prose in letters to a friend, Harvey Smith. Smith noted her favorite reads were "Fanny Hill", "The Perfumed Garden" and "".
Mitchell developed an appreciation for the works of Southern writer James Branch Cabell, and his 1919 classic, "Jurgen, A Comedy of Justice". She read books about sexology, and took particular interest in the case studies of Havelock Ellis, a British physician who studied human sexuality. During this period in which Mitchell was reading pornography and sexology, she was also writing "Gone with the Wind".
Novelist.
Early works.
"Lost Laysen".
Mitchell wrote a romance novella, "Lost Laysen", when she was fifteen years old (1916). She gave "Lost Laysen", which she had written in two notebooks, to a boyfriend, Henry Love Angel. He died in 1945 and the novella remained undiscovered among some letters she had written to him until 1994. The novella was published in 1996, eighty years after it was written, and became a "New York Times" Best Seller.
In "Lost Laysen", Mitchell explores the dynamics of three male characters and their relationship to the only female character, "Courtenay Ross", a strong-willed American missionary to the South Pacific island of "Laysen". The narrator of the tale is "Billy Duncan", "a rough, hardened soldier of fortune", who is frequently involved in fights that leave him near death. Courtenay quickly observes Duncan's hard-muscled body as he works shirtless aboard a ship called "Caliban". Courtenay's suitor is "Douglas Steele", an athletic man who apparently believes Courtenay is helpless without him. He follows Courtenay to Laysen to protect her from perceived foreign savages. The third male character is the rich, powerful yet villainous "Juan Mardo". He leers at Courtenay and makes rude comments of a sexual nature, in Japanese nonetheless. Mardo provokes Duncan and Steele, and each feels he must defend Courtenay's honor. Ultimately Courtenay defends her own honor rather than submit to shame.
In a gender reversal, the woman writer (Mitchell) narrates "Lost Laysen" through a heroic male character, Billy Duncan. Mitchell's half-breed
antagonist, Juan Mardo, lurks in the shadows of the story and has no dialogue. The reader learns of Mardo's evil intentions through Duncan:
They were saying that Juan Mardo had his eye on you—and intended to have you—any way he could get you!
Mardo's desires are similar to those of Rhett Butler in his ardent pursuit of Scarlett O'Hara in Mitchell's epic novel, "Gone with the Wind". Rhett tells Scarlett:
I always intended having you, one way or another.
The "other way" is rape. In "Lost Laysen" the male seducer is replaced with the male rapist.
"The Big Four".
In Mitchell's teenage years, she is known to have written a 400-page novel about girls in a boarding school, "The Big Four". The novel is thought to be lost; Mitchell destroyed some of her manuscripts herself and others were destroyed after her death.
"'Ropa Carmagin".
In the 1920s Mitchell completed a novelette, "'Ropa Carmagin", about a Southern white girl who loves a biracial man. Mitchell submitted the manuscript to Macmillan Publishers in 1935 along with her manuscript for "Gone with the Wind". The novelette was rejected; Macmillan thought the story was too short for book form.
Final work.
Writing "Gone with the Wind".
In May 1926, after Mitchell had left her job at the "Atlanta Journal" and was recovering at home from her ankle injury, she wrote a society column for the "Sunday Magazine", "Elizabeth Bennet's Gossip", which she continued to write until August. Meanwhile, her husband was growing weary of lugging armloads of books home from the library to keep his wife's mind occupied while she hobbled around the house; he emphatically suggested that she write her own book instead:
For God's sake, Peggy, can't you write a book instead of reading thousands of them?
To aid her in her literary endeavors, John Marsh brought home a Remington Portable No. 3 typewriter (c. 1928). For the next three years Mitchell worked exclusively on writing a Civil War-era novel whose heroine was named Pansy O'Hara (prior to publication Pansy was changed to Scarlett). She used parts of the manuscript to prop up a wobbly couch.
World War II.
During World War II, Margaret Mitchell was a volunteer for the American Red Cross and she raised money for the war effort by selling war bonds. She was active in Home Defense, sewed hospital gowns and put patches on trousers. Her personal attention, however, was devoted to writing letters to men in uniform—soldiers, sailors and marines, sending them humor, encouragement, and her sympathy.
The USS "Atlanta" (CL-51) was an anti-aircraft ship of the United States Navy sponsored by Margaret Mitchell and used in the naval Battle of Midway and the Eastern Solomons. The ship was struck and sunk in night surface action on November 13, 1942 during the Naval Battle of Guadalcanal.
Mitchell sponsored a second cruiser named after the city of Atlanta, USS "Atlanta" (CL-104). On February 6, 1944, she christened "Atlanta" in Camden, New Jersey. "Atlanta" was operating off the coast of Honshū when the Japanese surrendered on August 15, 1945. It was sunk during an explosive test off San Clemente Island on October 1, 1970.
Death.
Margaret Mitchell was struck by a speeding automobile as she crossed Peachtree Street at 13th Street in Atlanta with her husband, John Marsh, while on her way to see the movie "A Canterbury Tale" on the evening of August 11, 1949. She died at Grady Hospital five days later without fully regaining consciousness.
The driver, Hugh Gravitt, was an off-duty taxi driver who was driving his personal vehicle when he struck Mitchell. After the accident, Gravitt was arrested for drunken driving and released on a $5,450 bond until Mitchell's death.
Gravitt was originally charged with drunken driving, speeding, and driving on the wrong side of the road. He was convicted of involuntary manslaughter in November 1949 and sentenced to 18 months in jail. He served almost 11 months. Gravitt died in 1994 at the age of 73.
Legacy.
Perhaps the most enduring legacy of "Gone with the Wind" is that people worldwide would incorrectly think it was the true story of the Old South and how it was changed by the American Civil War and Reconstruction. The film version of the novel "amplified this effect". Scholars of the period have written in recent years about the negative effects the novel has had on race relations by its resurrection of Lost Cause mythology.

</doc>
<doc id="20866" url="http://en.wikipedia.org/wiki?curid=20866" title="Metamorphosis">
Metamorphosis

Metamorphosis is a biological process by which an animal physically develops after birth or hatching, involving a conspicuous and relatively abrupt change in the animal's body structure through cell growth and differentiation. Some insects, fishes, amphibians, molluscs, crustaceans, cnidarians, echinoderms and tunicates undergo metamorphosis, which is usually accompanied by a change of habitat or behavior.
Scientific usage of the term is exclusive, and is not applied to general aspects of cell growth, including rapid growth spurts. References to "metamorphosis" in mammals are imprecise and only colloquial, but historically idealist ideas of transformation and monadology, as in Goethe's "Metamorphosis of Plants", influenced the development of ideas of evolution.
Etymology.
The word "metamorphosis" derives from Greek μεταμόρφωσις, "transformation, transforming", from μετα- ("meta-"), "change" and μορφή ("morphe"), "form".
Insect metamorphosis.
All insects in the Pterygota undergo a marked change in form, texture and physical appearance or metamorphosis, from immature to adult. These insects either have hemimetabolous development, and undergo an incomplete or partial metamorphosis, or holometabolous development, which undergo a complete metamorphosis, including a pupal or resting stage between the larval and adult forms.
In hemimetabolous insects, immature stages are called nymphs. Development proceeds in repeated stages of growth and ecdysis (moulting); these stages are called instars. The juvenile forms closely resemble adults', but are smaller and lack adult features such as wings and genitalia. This process is known as "partial" or "incomplete" metamorphosis. The differences between nymphs in different instars are small, often just differences in body proportions and the number of segments, although external wing buds will form in later instars.
In holometabolous insects, immature stages are called larvae, and differ markedly from adults. Insects which undergo holometabolism pass through a larval stage, then enter an inactive state called pupa, or chrysalis, and finally emerge as adults. This process is called "complete" metamorphosis. It is theorized that the pupal stage is the evolutionary compaction of all the nymphal stages of their hemimetabolous ancestors, while the larval stage is an extended, mobile form of the developing embryo.
According to recent research, adult "Manduca sexta" is able to retain the behaviour learned as a caterpillar. Another caterpillar, the Ornate Moth caterpillar, is able to carry toxins that it acquires from its diet through metamorphosis and into adulthood, where the toxins still serve for protection against predators.
Many observations have indicated that programmed cell death plays a considerable role during physiological processes of multicellular organisms, particularly during embryogenesis and metamorphosis.
Hormonal control.
Insect growth and metamorphosis are controlled by hormones synthesized by endocrine glands near the front of the body. Neurosecretory cells in an insect's brain secrete a hormone, the prothoracicotropic hormone (PTTH) that activates prothoracic glands, which secrete a second hormone, usually Ecdysone (an ecdysteroid), that induces ecdysis.
PTTH also stimulates the corpora allata, a retrocerebral organ, to produce juvenile hormone (JH), which prevents the development of adult characteristics during ecdysis. In holometabolous insects, molts between larval instars have a high level of JH, the moult to the pupal stage has a low level of JH, and the final, or imaginal, molt has no JH present at all. Experiments on Firebugs have also shown how JH can affect the number of nymph instar stages in hemimetabolous insects.
Amphibian metamorphosis.
In typical amphibian development, eggs are laid in water and larvae are adapted to an aquatic lifestyle. Frogs, toads, and newts all hatch from the egg as larvae with external gills but it will take some while for the amphibians to interact outside with pulmonary respiration. Afterwards, newt larvae start a predatory lifestyle, while tadpoles mostly scrape food off surfaces with their horny tooth ridges.
Metamorphosis in amphibians is regulated by thyroxin concentration in the blood, which stimulates metamorphosis, and prolactin, which counteracts its effect. Specific events are dependent on threshold values for different tissues. Because most embryonic development is outside the parental body, development is subject to many adaptations due to specific ecological circumstances. For this reason tadpoles can have horny ridges for teeth, whiskers, and fins. They also make use of the lateral line organ. After metamorphosis, these organs become redundant and will be resorbed by controlled cell death, called apoptosis. The amount of adaptation to specific ecological circumstances is remarkable, with many discoveries still being made.
Frogs and toads.
With frogs and toads, the external gills of the newly hatched tadpole are covered with a gill sac after a few days, and lungs are quickly formed. Front legs are formed under the gill sac, and hindlegs are visible a few days later. Following that there is usually a longer stage during which the tadpole lives off a vegetarian diet. Tadpoles use a relatively long, spiral‐shaped gut to digest that diet.
Rapid changes in the body can then be observed as the lifestyle of the frog changes completely. The spiral‐shaped mouth with horny tooth ridges is resorbed together with the spiral gut. The animal develops a big jaw, and its gills disappear along with its gill sac. Eyes and legs grow quickly, a tongue is formed, and all this is accompanied by associated changes in the neural networks (development of stereoscopic vision, loss of the lateral line system, etc.) All this can happen in about a day, so it is truly a metamorphosis. It isn't until a few days later that the tail is reabsorbed, due to the higher thyroxin concentrations required for tail resorption.
Newts.
In newts, there is no true metamorphosis because newt larvae already feed as predators and continue doing so as adults. Newts' gills are never covered by a gill sac and will be resorbed only just before the animal leaves the water. Just as in tadpoles, their lungs are functional early, but newts don't make as much use of them as tadpoles do. Newts often have an aquatic phase in spring and summer, and a land phase in winter. For adaptation to a water phase, prolactin is the required hormone, and for adaptation to the land phase, thyroxin. External gills do not return in subsequent aquatic phases because these are completely absorbed upon leaving the water for the first time.
Metamorphosis in fish.
Some fish, both bony fish (Osteichthyes) and non-bony fish (Agnatha), undergo metamorphosis. Fish metamorphosis is typically under strong control by the thyroid hormone.
Examples among the non-bony fish include the lamprey. Among the bony fish, mechanisms are varied.
The salmon is diadromous, meaning that it changes from a freshwater to a saltwater lifestyle.
Many species of flatfish begin their life bilaterally symmetrical, with an eye on either side of the body; but one eye moves to join the other side of the fish - which becomes the upper side - in the adult form.
The European eel has a number of metamorphoses, from the larval stage to the leptocephalus stage, then a quick metamorphosis to glass eel at the edge of the continental shelf (8 days for the Japanese eel), two months at the border of fresh and salt water where the glass eel undergoes a quick metamorphosis into elver, then a long stage of growth followed by a more gradual metamorphosis to the migrating phase. In the pre-adult freshwater stage, the eel also has phenotypic plasticity because fish-eating eels develop very wide mandibles, making the head look blunt. Leptocephali are common, occurring in all Elopomorpha (Tarpon- and eel-like fish).
Most other bony fish undergo metamorphosis from embryo to larva (fry) and then to the juvenile stage during absorption of the yolk sac, because after that phase the individual needs to be able to feed for itself.

</doc>
<doc id="20869" url="http://en.wikipedia.org/wiki?curid=20869" title="Monoamine oxidase inhibitor">
Monoamine oxidase inhibitor

Monoamine oxidase inhibitors (MAOIs) are chemicals which inhibit the activity of the monoamine oxidase enzyme family. They have a long history of use as medications prescribed for the treatment of depression. They are particularly effective in treating atypical depression. They are also used in the treatment of Parkinson's disease and several other disorders.
Because of potentially lethal dietary and drug interactions, monoamine oxidase inhibitors have historically been reserved as a last line of treatment, used only when other classes of antidepressant drugs (for example selective serotonin reuptake inhibitors and tricyclic antidepressants) have failed. New research into MAOIs indicates that much of the concern over their dangerous dietary side effects stems from misconceptions and misinformation, and that despite proven effectiveness of this class of drugs, it is underutilized and misunderstood in the medical profession. 
New research also questions the validity of the perceived severity of dietary reactions, which has historically been based on outdated research.
Indications.
Newer MAOIs such as selegiline (typically used in the treatment of Parkinson's disease) and the reversible MAOI moclobemide provide a safer alternative and are now sometimes used as first-line therapy.
MAOIs have been found to be effective in the treatment of panic disorder with agoraphobia, social phobia, atypical depression or mixed anxiety and depression, bulimia, and post-traumatic stress disorder, as well as borderline personality disorder. MAOIs appear to be particularly effective in the management of bipolar depression according to a recent retrospective-analysis. There are reports of MAOI efficacy in obsessive-compulsive disorder (OCD), trichotillomania, dysmorphophobia, and avoidant personality disorder, but these reports are from uncontrolled case reports.
MAOIs can also be used in the treatment of Parkinson's disease by targeting MAO-B in particular (therefore affecting dopaminergic neurons), as well as providing an alternative for migraine prophylaxis. Inhibition of both MAO-A and MAO-B is used in the treatment of clinical depression and anxiety.
MAOIs appear to be particularly indicated for outpatients with "neurotic depression" complicated by panic disorder or hysteroid dysphoria, which involves repeated episodes of depressed mood in response to feeling rejected.
Mechanism of action.
MAOIs act by inhibiting the activity of monoamine oxidase, thus preventing the breakdown of monoamine neurotransmitters and thereby increasing their availability. There are two isoforms of monoamine oxidase, MAO-A and MAO-B. MAO-A preferentially deaminates serotonin, melatonin, epinephrine, and norepinephrine. MAO-B preferentially deaminates phenethylamine and trace amines. Dopamine is equally deaminated by both types.
Reversibility.
The early MAOIs covalently bound to the monoamine oxidase enzymes, thus inhibiting them irreversibly; the bound enzyme could not function and thus enzyme activity was blocked until the cell made new enzymes. The enzymes turn over approximately every two weeks. A few newer MAOIs, a notable one being moclobemide, are reversible, meaning that they are able to detach from the enzyme to facilitate usual catabolism of the substrate. The level of inhibition in this way is governed by the concentrations of the substrate and the MAOI.
Harmaline found in "Peganum harmala", as well as the Ayahuasca vine, "Banisteriopsis caapi", and Passiflora incarnata is a reversible inhibitor of MAO-A (RIMA).
Selectivity.
In addition to reversibility, MAOIs differ by their selectivity of the MAO receptor. Some MAOIs inhibit both MAO-A and MAO-B equally, other MAOIs have been developed to target one over the other.
MAO-A inhibition reduces the breakdown of primarily serotonin, norepinephrine, and dopamine; selective inhibition of MAO-A allows for tyramine to be metabolised via MAO-B. Agents that act on serotonin if taken with another serotonin-enhancing agent may result in a potentially fatal interaction called serotonin syndrome or with irreversible and unselective inhibitors (such as older MAOIs), of MAO a hypertensive crisis as a result of tyramine food interactions is particularly problematic with older MAOIs. Tyramine is broken down by MAO-A and MAO-B, therefore inhibiting this action may result in its excessive build-up, so diet must be monitored for tyramine intake.
MAO-B inhibition reduces the breakdown mainly of dopamine and phenethylamine so there are no dietary restrictions associated with this. MAO-B would also metabolize tyramine, as the only differences between dopamine, phenethylamine, and tyramine are two phenylhydroxyl groups on carbons 3 and 4. The 4-OH would not be a steric hindrance to MAO-B on tyramine. Two MAO-Bi drugs, selegiline and rasagiline have been approved by the FDA without dietary restrictions, except in high-dosage treatment, wherein they lose their selectivity.
Dangers.
Diet and drug Interactions.
When ingested orally, MAOIs inhibit the catabolism of dietary amines. When foods containing tyramine are consumed (so-called "cheese effect"), the individual may suffer from hypertensive crisis. The amount required to cause a reaction varies greatly from individual to individual, and depends on the degree of inhibition, which in turn depends on dosage and selectivity.
The exact mechanism by which tyramine causes a hypertensive reaction is not well-understood, but it is assumed that tyramine displaces norepinephrine from the storage vesicles. This may trigger a cascade in which excessive amounts of norepinephrine can lead to a hypertensive crisis. Another theory suggests that proliferation and accumulation of catecholamines causes hypertensive crisis
Tyrosine, not tyramine, is the precursor to catecholamines. Tyramine is a breakdown product of tyrosine. In the gut and during fermentation, tyrosine, an amino acid, is decarboxylated to tyramine. Under ordinary circumstances, tyramine is deaminated in the liver to an inactive metabolite, but, when the hepatic MAO (primarily MAO-A) is inhibited, the "first-pass" clearance of tyramine is blocked and circulating tyramine levels can climb. Elevated tyramine competes with tyrosine for transport across the blood–brain barrier (via aromatic amino acid transport) where it can then enter adrenergic nerve terminals. Once in the cytoplasmic space, tyramine will be transported via the vesicular monoamine transporter (VMAT) into synaptic vesicles, thereby displacing norepinephrine. The mass transfer of norepinephrine from its vesicular storage space into the extracellular space via mass action can precipitate the hypertensive crisis. Hypertensive crises can sometimes result in stroke or cardiac arrhythmia if not treated. In general, this risk is not present with RIMAs. Both kinds of intestinal MAO inhibition can cause hyperpyrexia, nausea, and psychosis if foods high in levodopa are consumed.
Examples of foods and drinks with potentially high levels of tyramine include liver and fermented substances, such as alcoholic beverages and aged cheeses. (See a List of foods containing tyramine). Examples of levodopa-containing foods include broad beans. These diet restrictions are not necessary for those taking selective MAO-B inhibitors, unless these are being taken in high dosages, as mentioned above.
It deserves separate mention that some meat extracts and yeast extracts (Bovril, Marmite, Vegemite) contain extremely high levels of tyramine, and should not be used with these medications.
When MAOIs were first introduced, these risks were not known, and, over the following four decades, fewer than 100 people have died from hypertensive crisis. Presumedly due to the sudden onset and violent appearance of the reaction, MAOIs gained a reputation for being so dangerous that, for a while, they were taken off the market in America entirely. However, it is now believed that, used as directed under the care of a qualified psychiatrist, this class of drugs is a viable alternative treatment for intermediate- to long-term use.
The most significant risk associated with the use of MAOIs is the potential for interactions with over-the-counter and prescription medicines, illicit drugs or medications, and some supplements (e.g., St. John's Wort, tryptophan). It is vital that a doctor supervise such combinations to avoid adverse reactions. For this reason, many users carry an MAOI-card, which lets emergency medical personnel know what drugs to avoid. (E.g., adrenaline dosage should be reduced by 75%, and duration is extended.) 
Tryptophan supplements should not be consumed with MAOIs as the potentially fatal serotonin syndrome may result.
MAOIs should not be combined with other psychoactive substances (antidepressants, painkillers, stimulants, both legal and illegal etc.) except under expert care. Certain combinations can cause lethal reactions, common examples including SSRIs, tricyclics, MDMA, meperidine, tramadol, and dextromethorphan. Agents with actions on epinephrine, norepinephrine, or dopamine must be administered at much lower doses due to potentiation and prolonged effect.
Nicotine, a substance frequently implicated in tobacco addiction, has been shown to have "relatively weak" addictive properties when administered alone. The addictive potential increases dramatically after co-administration of an MAOI, which specifically causes sensitization of the locomotor response in rats, a measure of addictive potential. This may be reflected in the difficulty of smoking cessation, as tobacco contains naturally-occurring MAOI compounds in addition to the nicotine.
Withdrawal.
Antidepressants including MAOIs have some dependence-producing effects, the most notable one being a withdrawal syndrome, which may be severe especially if MAOIs are discontinued abruptly or over-rapidly. However, the dependence-producing potential of MAOIs or antidepressants in general is not as significant as benzodiazepines. Withdrawal symptoms can be managed by a gradual reduction in dosage over a period of weeks, months or years to minimize or prevent withdrawal symptoms.
MAOIs, as with any antidepressant medications, do not alter the course of the disorder, so it is possible that discontinuation can return the patient to the pre-treatment state.
This consideration greatly complicates switching a patient between a MAOI and a SSRI, because it is necessary to clear the system completely of one drug before starting another. If one also tapers dosage gradually, the result is that for weeks a depressed patient will have to bear the depression without chemical help during the drug-free interval. This may be preferable to risking the effects of an interaction between the two drugs, but it is often not easy for the patient.
Listing of interactions.
The MAOIs are infamous for their numerous drug interactions, including the following kinds of substances:
Such substances that can react with MAOIs include:
History.
MAOIs started off due to the serendipitous discovery that iproniazid was a weak MAO inhibitor (MAOI). Originally intended for the treatment of tuberculosis, in 1952, iproniazid antidepressant properties were discovered when researchers noted that the depressed patients given iproniazid experienced a relief of their depression. Subsequent in vitro work led to the discovery that it inhibited MAO and eventually to the monoamine theory of depression. MAOIs became widely used as antidepressants in the early 1950s. The discovery of the 2 isoenzymes of MAO has led to the development of selective MAOIs that may have a more favorable side-effect profile.
The older MAOIs' heyday was mostly between the years 1957 and 1970. The initial popularity of the 'classic' non-selective irreversible MAO inhibitors began to wane due to their serious interactions with sympathomimetic drugs and tyramine-containing foods that could lead to dangerous hypertensive emergencies. As a result, the use by medical practitioners of these older MAOIs declined. When scientists discovered that there are two different MAO enzymes (MAO-A and MAO-B), they developed selective compounds for MAO-B, (for example, selegiline, which is used for Parkinson's disease), to reduce the side-effects and serious interactions. Further improvement occurred with the development of compounds (moclobemide and toloxatone) that not only are selective but cause reversible MAO-A inhibition and a reduction in dietary and drug interactions. Moclobemide, was the first reversible inhibitor of MAO-A to enter widespread clinical practice.
A transdermal patch form of the MAOI selegiline, called Emsam, was approved for use in depression by the Food and Drug Administration in the United States on February 28, 2006.
List of MAO inhibiting drugs.
Marketed drugs.
Linezolid is an antibiotic drug with weak MAO inhibiting activity.
Cultural references.
The pilot episode of "Law and Order" was similar to an actual event. Journalist Sidney Zion questioned the sudden death of his daughter Libby Zion in an emergency department in Manhattan on Oct 4, 1984. The cause of death was attributed to "mysterious infection". The father convinced authorities to launch a criminal investigation when it was discovered that several medications, including Demerol, were administered to his daughter, reacting with her Nardil medications. The DA sought charges of murder against a doctor who had approved use of restraints and narcotics when Zion became increasingly agitated. The case prompted many reforms in graduate medical education and limiting number of hours staff can work. Drug abuse was successfully argued as a major factor leading to her death.

</doc>
<doc id="20872" url="http://en.wikipedia.org/wiki?curid=20872" title="Mother Superior">
Mother Superior

A mother superior is an abbess, prioress or other nun in charge of a Christian religious order or congregation, a convent or house of women under vows.
Mother superior may also refer to:

</doc>
<doc id="20874" url="http://en.wikipedia.org/wiki?curid=20874" title="Mycology">
Mycology

Mycology is the branch of biology concerned with the study of fungi, including their genetic and biochemical properties, their taxonomy and their use to humans as a source for tinder, medicine, wine, cheese, (edible mushrooms), and entheogens, as well as their dangers, such as poisoning or infection. A biologist specializing in mycology is called a mycologist.
From mycology arose the field of phytopathology, the study of plant diseases, and the two disciplines remain closely related because the vast majority of "plant" pathogens are fungi.
Historically, mycology was a branch of botany because, although fungi are evolutionarily more closely related to animals than to plants, this was not recognized until a few decades ago. Pioneer "mycologists" included Elias Magnus Fries, Christian Hendrik Persoon, Anton de Bary, and Lewis David von Schweinitz.
Many fungi produce toxins, antibiotics, and other secondary metabolites. For example, the cosmopolitan (worldwide) genus "Fusarium" and their toxins associated with fatal outbreaks of alimentary toxic aleukia in humans were extensively studied by Abraham Joffe.
Fungi are fundamental for life on earth in their roles as symbionts, e.g. in the form of mycorrhizae, insect symbionts, and lichens. Many fungi are able to break down complex organic biomolecules such as lignin, the more durable component of wood, and pollutants such as xenobiotics, petroleum, and polycyclic aromatic hydrocarbons. By decomposing these molecules, fungi play a critical role in the global carbon cycle.
Fungi and other organisms traditionally recognized as fungi, such as oomycetes and myxomycetes (slime molds), often are economically and socially important, as some cause diseases of animals (such as histoplasmosis) as well as plants (such as Dutch elm disease and Rice blast).
Field meetings to find interesting species of fungi are known as 'forays', after the first such meeting organized by the Woolhope Naturalists' Field Club in 1868 and entitled "A foray among the funguses"["sic"].
Some fungi can cause disease in humans or other organisms. The study of pathogenic fungi is referred to as medical mycology.
History.
It is presumed that humans started collecting mushrooms as food in Prehistoric times. Mushrooms were first written about in the works of Euripides (480-406 B.C.). The Greek philosopher Theophrastos of Eressos (371-288 B.C.) was perhaps the first to try to systematically classify plants; mushrooms were considered to be plants missing certain organs. It was later Pliny the elder (23–79 A.D.), who wrote about truffles in his encyclopedia Naturalis historia. The word "mycology" comes from the Greek: μύκης ("mukēs"), meaning "fungus" and the suffix -λογία ("-logia"), meaning "study".
The Middle Ages saw little advancement in the body of knowledge about fungi. Rather, the invention of the printing press allowed some authors to disseminate superstitions and misconceptions about the fungi that had been perpetuated by the classical authors.
The start of the modern age of mycology begins with Pier Antonio Micheli's 1737 publication of "Nova plantarum genera". Published in Florence, this seminal work laid the foundations for the systematic classification of grasses, mosses and fungi. The term "mycology" and the complementary "mycologist" were first used in 1836 by M.J. Berkeley.
Medicinal mycology.
For centuries, certain mushrooms have been documented as a folk medicine in China, Japan, and Russia. Although the use of mushrooms in folk medicine is centered largely on the Asian continent, people in other parts of the world like the Middle East, Poland, and Belarus have been documented using mushrooms for medicinal purposes. Certain mushrooms, especially polypores like Reishi were thought to be able to benefit a wide variety of health ailments. Medicinal mushroom research in the United States is currently active, with studies taking place at City of Hope National Medical Center, as well as the Memorial Sloan–Kettering Cancer Center.
Current research focuses on mushrooms that may have hypoglycemic activity, anti-cancer activity, anti-pathogenic activity, and immune system-enhancing activity. Recent research has found that the oyster mushroom naturally contains the cholesterol-lowering drug lovastatin, mushrooms produce large amounts of vitamin D when exposed to UV light, and that certain fungi may be a future source of taxol. To date, penicillin, lovastatin, ciclosporin, griseofulvin, cephalosporin, ergometrine, and statins are the most famous pharmaceuticals that have been isolated from the fungi kingdom.

</doc>
<doc id="20875" url="http://en.wikipedia.org/wiki?curid=20875" title="Melancholia">
Melancholia

Black bile (Greek: µέλαινα χολή, "melaina chole"), also lugubriousness, from the Latin "lugere", to mourn; moroseness, from the Latin "morosus", self-willed, fastidious habit; wistfulness, from old English "wist": intent, or saturnine, was a concept in ancient and pre-modern medicine. Melancholy was one of the four temperaments matching the four humours. In the 19th century, "melancholia" could be physical as well as mental, and melancholic conditions were classified as such by their common cause rather than by their properties.
History.
The name "melancholia" comes from the old medical belief of the four humours: disease or ailment being caused by an imbalance in one or other of the four basic bodily liquids, or humours. Personality types were similarly determined by the dominant humor in a particular person. According to Hippocrates and subsequent tradition, melancholia was caused by an excess of black bile, hence the name, which means "black bile", from Ancient Greek μέλας ("melas"), "dark, black", and χολή ("kholé"), "bile"; a person whose constitution tended to have a preponderance of black bile had a "melancholic" disposition. In the complex elaboration of humorist theory, it was associated with the earth from the Four Elements, the season of autumn, the spleen as the originating organ and cold and dry as related qualities. In astrology it showed the influence of Saturn, hence the related adjective "saturnine".
Melancholia was described as a distinct disease with particular mental and physical symptoms in the 5th and 4th centuries BC. Hippocrates, in his "Aphorisms", characterized all "fears and despondencies, if they last a long time" as being symptomatic of melancholia. When a patient could not be cured of the disease it was thought that the melancholia was a result of demonic possession.
In his study of French and Burgundian courtly culture, Johan Huizinga noted that "at the close of the Middle Ages, a sombre melancholy weighs on people's souls." In chronicles, poems, sermons, even in legal documents, an immense sadness, a note of despair and a fashionable sense of suffering and deliquescence at the approaching end of times, suffuses court poets and chroniclers alike: Huizinga quotes instances in the ballads of Eustache Deschamps, "monotonous and gloomy variations of the same dismal theme", and in Georges Chastellain's prologue to his Burgundian chronicle, and in the late fifteenth-century poetry of Jean Meschinot. Ideas of reflection and the workings of imagination are blended in the term "merencolie", embodying for contemporaries "a tendency", observes Huizinga, "to identify all serious occupation of the mind with sadness".
Painters were considered by Vasari and other writers to be especially prone to melancholy by the nature of their work, sometimes with good effects for their art in increased sensitivity and use of fantasy. Among those of his contemporaries so characterised by Vasari were Pontormo and Parmigianino, but he does not use the term of Michelangelo, who used it, perhaps not very seriously, of himself. A famous allegorical engraving by Albrecht Dürer is entitled "Melencolia I". This engraving has been interpreted as portraying melancholia as the state of waiting for inspiration to strike, and not necessarily as a depressive affliction. Amongst other allegorical symbols, the picture includes a magic square and a truncated rhombohedron. The image in turn inspired a passage in "The City of Dreadful Night" by James Thomson (B.V.), and, a few years later, a sonnet by Edward Dowden.
The most extended treatment of melancholia comes from Robert Burton, whose "The Anatomy of Melancholy" (1621) treats the subject from both a literary and a medical perspective. Burton wrote in the 17th century that music and dance were critical in treating mental illness, especially melancholia.
But to leave all declamatory speeches in praise [3481] of divine music, I will confine myself to my proper subject: besides that excellent power it hath to expel many other diseases, it is a sovereign remedy against [3482] despair and melancholy, and will drive away the devil himself. Canus, a Rhodian fiddler, in [3483] Philostratus, when Apollonius was inquisitive to know what he could do with his pipe, told him, "That he would make a melancholy man merry, and him that was merry much merrier than before, a lover more enamoured, a religious man more devout." Ismenias the Theban, [3484] Chiron the centaur, is said to have cured this and many other diseases by music alone: as now they do those, saith [3485] Bodine, that are troubled with St. Vitus's Bedlam dance.
In the Encyclopédie of Diderot and d'Alembert, the causes of melancholia are stated to be similar to those that cause Mania: "grief, pains of the spirit, passions, as well as all the love and sexual appetites that go unsatisfied."
Cult.
During the later 16th and early 17th centuries, a curious cultural and literary cult of melancholia arose in England. In an influential 1964 essay in Apollo, art historian Roy Strong traced the origins of this fashionable melancholy to the thought of the popular Neoplatonist and humanist Marsilio Ficino (1433–1499), who replaced the medieval notion of melancholia with something new: Ficino transformed what had hitherto been regarded as the most calamitous of all the humours into the mark of genius. Small wonder that eventually the attitudes of melancholy soon became an indispensable adjunct to all those with artistic or intellectual pretentions.
"The Anatomy of Melancholy" ("The Anatomy of Melancholy, What it is: With all the Kinds, Causes, Symptomes, Prognostickes, and Several Cures of it... Philosophically, Medicinally, Historically, Opened and Cut Up") by Burton, was first published in 1621 and remains a defining literary monument to the fashion. Other major melancholic English authors whose works contain extensive meditations on death include Sir Thomas Browne, "Hydriotaphia, Urn Burial" (1658), and Jeremy Taylor with the conventionally religious "Holy Living and Holy Dying" (1650/51).
"Night-Thoughts" ("The Complaint: or, Night-Thoughts on Life, Death, & Immortality"), a long poem in blank verse by Edward Young was published in nine parts (or "nights") between 1742 and 1745, and hugely popular in several languages. It had a considerable influence on early Romantics in England, France and Germany. William Blake was commissioned to illustrate a later edition.
In the visual arts, this fashionable intellectual melancholy occurs frequently in portraiture of the era, with sitters posed in the form of "the lover, with his crossed arms and floppy hat over his eyes, and the scholar, sitting with his head resting on his hand"—descriptions drawn from the frontispiece to the 1638 edition of Burton's "Anatomy", which shows just such by-then stock characters. These portraits were often set out of doors where Nature provides "the most suitable background for spiritual contemplation" or in a gloomy interior.
In music, the post-Elizabethan cult of melancholia is associated with John Dowland, whose motto was "Semper Dowland, semper dolens". ("Always Dowland, always mourning.") The melancholy man, known to contemporaries as a "malcontent," is epitomized by Shakespeare's Prince Hamlet, the "Melancholy Dane."
A similar phenomenon, though not under the same name, occurred during the German Sturm und Drang movement, with such works as "The Sorrows of Young Werther" by Goethe or in Romanticism with works such as "Ode on Melancholy" by John Keats or in Symbolism with works such as "Isle of the Dead" by Arnold Böcklin. In the 20th century, much of the counterculture of modernism was fueled by comparable alienation and a sense of purposelessness called "anomie"; earlier artistic preoccupation with death has gone under the rubric of memento mori. The medieval condition of acedia ("acedie" in English) and the Romantic Weltschmerz were similar concepts, most likely to affect the intellectual.
Related concepts in Islam.
The Arabic word found as "ḥuzn" and "ḥazan" in the Qur'an and "hüzün" and "hazin" in modern Turkish refers to the pain and sorrow over a loss, death of relatives in the case of the Qur'an. Two schools further interpreted this feeling. The first sees it as a sign that one is too attached to the material world, while Sufism took it to represent a feeling of personal insufficiency, that one was not getting close enough to God and did not or could not do enough for God in this world. The Turkish writer Orhan Pamuk, in the book "", further elaborates on the added meaning "hüzün" has acquired in modern Turkish. It has come to denote a sense of failure in life, lack of initiative and tendency to retreat into oneself, symptoms quite similar to melancholia. According to Pamuk it was a defining character of cultural works from Istanbul after the fall of the Ottoman Empire. One may see similarities with how melancholic romantic paintings in the west sometimes used ruins from the age of the Roman Empire as a backdrop.
As a parallel with physicians of classical Greece, ancient Arabic physicians and psychologists also categorized "ḥuzn" as a disease. Al-Kindi (c. 801–873 CE) links it with disease-like mental states like anger, passion, hatred and depression, while the Persian physician Avicenna (980–1037 CE) diagnosed "ḥuzn" in a lovesick man if his pulse increased drastically when the name of the girl he loved was spoken. Avicenna suggests, in remarkable similarity with Robert Burton, many causes for melancholy, including the fear of death, intrigues surrounding one's life, and lost love. As remedies, he recommends treatments addressing both the medical and philosophical sources of the melancholy, including rational thought, morale, discipline, fasting and coming to terms with the catastrophe.
The various uses of "ḥuzn" and "hüzün" thus describe melancholy from a certain vantage point, show similarities with female hysteria in the case of Avicenna's patient, and in a religious context are not unlike sloth, which by Dante was defined as "failure to love God with all one's heart, all one's mind and all one's soul". Thomas Aquinas described sloth as "an oppressive sorrow, which, to wit, so weighs upon man's mind, that he wants to do nothing."

</doc>
<doc id="20876" url="http://en.wikipedia.org/wiki?curid=20876" title="Mimosa">
Mimosa

Mimosa is a genus of about 400 species of herbs and shrubs, in the subfamily Mimosoideae of the legume family Fabaceae. The generic name is derived from the Greek word μιμος ("mimos"), meaning "mimic."
Two species in the genus are especially notable. One is "Mimosa pudica", because of the way it folds its leaves when touched or exposed to heat. It is native to southern Central and South America but is widely cultivated elsewhere for its curiosity value, both as a houseplant in temperate areas, and outdoors in the tropics. Outdoor cultivation has led to weedy invasion in some areas, notably Hawaii. The other is "Mimosa tenuiflora", which is best known for its use in shamanic ayahuasca brews due to the psychedelic drug dimethyltryptamine found in its root bark.
Taxonomy.
The taxonomy of the genus "Mimosa" has had a tortuous history, having gone through periods of splitting and lumping, ultimately accumulating over 3,000 names, many of which have either been synonymized under other species or transferred to other genera. In part due to these changing circumscriptions, the name "Mimosa" has also been applied to several other related species with similar pinnate or bipinnate leaves, but are now classified in other genera. The most common examples of this are "Albizia julibrissin" (silk tree) and "Acacia dealbata" (wattle).
Description.
Members of this genus are among the few plants capable of rapid movement; examples outside of "Mimosa" include the telegraph plant, and the venus flytrap. The leaves of the Mimosa pudica close quickly when touched. Some mimosas raise their leaves in day and lower them at night, and experiments done by Jacques d'Ortous de Mairan on mimosas in 1729 provided the first evidence of biological clocks. 
"Mimosa" can be distinguished from the large related genera, "Acacia" and "Albizia", since its flowers have 10 or fewer stamens. Note that, botanically, what appears to be a single globular flower is actually a cluster of many individual ones. Mimosa contains some level of heptanoic acid.
Species.
There are about 400 species including:

</doc>
<doc id="20878" url="http://en.wikipedia.org/wiki?curid=20878" title="Martini">
Martini

Martini may refer to:

</doc>
<doc id="20879" url="http://en.wikipedia.org/wiki?curid=20879" title="Manhattan (cocktail)">
Manhattan (cocktail)

A Manhattan is a cocktail made with whiskey, sweet vermouth, and bitters. Commonly used whiskeys include rye (the traditional choice), Canadian whisky, bourbon, blended whiskey and Tennessee whiskey. The cocktail is often stirred and strained into a cocktail glass, where it is garnished with a Maraschino cherry with a stem. A Manhattan is also frequently served on the rocks in a lowball glass. The whiskey-based Manhattan is one of five cocktails named for one of New York City's five boroughs, but is perhaps most closely related to the Brooklyn cocktail, a mix utilizing dry vermouth and Maraschino liqueur in place of the Manhattan's sweet vermouth, as well as Amer Picon in place of the Manhattan's traditional bitters.
The Manhattan is one of six basic drinks listed in David A. Embury's classic "The Fine Art of Mixing Drinks".
Origin and history.
A popular history suggests that the drink originated at the Manhattan Club in New York City in the early 1870s, where it was invented by Dr. Iain Marshall for a banquet hosted by Jennie Jerome (Lady Randolph Churchill, Winston's mother) in honor of presidential candidate Samuel J. Tilden. The success of the banquet made the drink fashionable, later prompting several people to request the drink by referring to the name of the club where it originated—"the "Manhattan" cocktail". However, Lady Randolph was in France at the time and pregnant, so the story is likely a fiction.
The original "Manhattan cocktail" was a mix of "American Whiskey, Italian Vermouth and Angostura bitters". During Prohibition (1920–1933) Canadian whisky was primarily used because it was available.
However, there are prior references to various similar cocktail recipes called "Manhattan" and served in the Manhattan area. By one account it was invented in the 1860s by a bartender named Black at a bar on Broadway near Houston Street.
An early record of the cocktail can be found in William Schmidt's "The Flowing Bowl", published in 1891. In it, he details a drink containing 2 dashes of gum (gomme syrup), 2 dashes of bitters, 1 dash of absinthe, 2/3 portion of whiskey and 1/3 portion of vermouth.
The same cocktail appears listed as a "Tennessee Cocktail" in "Shake 'em Up!" by V. Elliott and P. Strong, copyright 1930 (p. 39): "Two parts of whiskey, one part of Italian Vermouth and a dash of bitters poured over ice and stirred vigorously."
Traditions.
On the small North Frisian island of Föhr, the Manhattan cocktail is a standard drink at almost every cafe restaurant, and "get together" of locals. The story goes, that many of the people of Föhr immigrated to Manhattan during deep sea fishing trips, took a liking to the drink, and brought it back to Föhr with them. The drink is usually mixed 1 part (the 'perfect' is said to be half white/half red) vermouth to 2 parts whiskey, with a dash of bitters, served ice cold, in an ice cold glass, or with ice and a cherry garnish.
There is a mistaken belief that Manhattans are always stirred and never shaken, primarily to avoid persistent foaming. However such foaming now indicates either dirty equipment or less than premium quality ingredients. Traditions for both preparations go back to the late 1800s.
Variations.
Traditional views insist that a Manhattan be made with American rye whiskey. However, more often than not, it is made with bourbon or Canadian whisky. The Manhattan is subject to considerable variation and innovation, and is often a way for the best bartenders to show off their creativity. Some shake the ingredients with ice in a cocktail shaker instead of stirring it, creating a froth on the surface of the drink. Angostura are the classic bitters, but orange bitters, Peychaud's Bitters, may be used, or the Manhattan can be made without any bitters at all; using Fernet-Branca yields what is called a Fanciulli cocktail. Some make their own bitters and syrups, substitute comparable digestifs in place of vermouth, specialize in local or rare whiskeys, or use other exotic ingredients. A lemon peel may be used as garnish. Some add juice from the cherry jar or Maraschino liqueur to the cocktail for additional sweetness and color.
Originally, bitters were considered an integral part of any cocktail, as the ingredient that differentiated a cocktail from a sling. Over time, those definitions of "cocktail" and "sling" have become archaic, as "sling" has fallen out of general use (other than in certain drink names), and "cocktail" can mean any drink that resembles a martini, or simply any mixed drink.
The following are other variations on the classic Manhattan:

</doc>
<doc id="20880" url="http://en.wikipedia.org/wiki?curid=20880" title="Mira">
Mira

Mira (, also known as Omicron Ceti, ο Ceti, ο Cet) is a red giant star estimated 200–400 light years away in the constellation Cetus. Mira is a binary star, consisting of the red giant Mira A along with Mira B. Mira A is also an oscillating variable star and was the first non-supernova variable star discovered, with the possible exception of Algol. Mira is the brightest periodic variable in the sky that is not visible to the naked eye for part of its cycle. Its distance is uncertain; pre-Hipparcos estimates centered on 220 light-years; while Hipparcos data from the 2007 reduction suggest a distance of 299 light-years, with a margin of error of 11%.
Observation history.
Evidence that the variability of Mira was known in ancient China, Babylon or Greece is at best only circumstantial. What is certain is that the variability of Mira was recorded by the astronomer David Fabricius beginning on August 3, 1596. Observing what he thought was the planet Mercury (later identified as Jupiter), he needed a reference star for comparing positions and picked a previously unremarked third-magnitude star nearby. By August 21, however, it had increased in brightness by one magnitude, then by October had faded from view. Fabricius assumed it was a nova, but then saw it again on February 16, 1609.
In 1638 Johannes Holwarda determined a period of the star's reappearances, eleven months; he is often credited with the discovery of Mira's variability. Johannes Hevelius was observing it at the same time and named it "Mira" (meaning "wonderful" or "astonishing," in Latin) in his "Historiola Mirae Stellae" (1662), for it acted like no other known star. Ismail Bouillaud then estimated its period at 333 days, less than one day off the modern value of 332 days, and perfectly forgivable, as Mira is known to vary slightly in period, and may even be slowly changing over time. The star is estimated to be a 6-billion-year-old red giant.
There is considerable speculation as to whether Mira had been observed prior to Fabricius. Certainly Algol's history (known for certain as a variable only in 1667, but with legends and such dating back to antiquity showing that it had been observed with suspicion for millennia) suggests that Mira might have been known too. Karl Manitius, a modern translator of Hipparchus' "Commentary on Aratus", has suggested that certain lines from that second-century text may be about Mira. The other pre-telescopic Western catalogs of Ptolemy, al-Sufi, Ulugh Beg, and Tycho Brahe turn up no mentions, even as a regular star. There are three observations from Chinese and Korean archives, in 1596, 1070, and the same year when Hipparchus would have made his observation (134 BC) that are suggestive, but the Chinese practice of pinning down observations no more precisely than within a given Chinese constellation makes it difficult to be sure.
System.
Mira is a binary star system that consists of a red giant (Mira A) undergoing mass loss and a high temperature white dwarf companion (Mira B) that is accreting mass from the primary. Such an arrangement of stars is known as a symbiotic system and this is the closest such symbiotic pair to the Sun. Examination of this system by the Chandra X-ray Observatory shows a direct mass exchange along a bridge of matter from the primary to the white dwarf. The two stars are currently separated by about 70 astronomical units.
Component A.
Mira A is currently an asymptotic giant branch (AGB) star, in the thermally pulsing AGB phase. Each pulse lasts a decade or more, and an amount of time on the order of 10,000 years passes between each pulse. With every pulse cycle Mira increases in luminosity and the pulses grow stronger. This is also causing dynamic instability in Mira, resulting in dramatic changes in luminosity and size over shorter, irregular time periods.
The overall shape of Mira A has been observed to change, exhibiting pronounced departures from symmetry. These appear to be caused by bright spots on the surface that evolve their shape on time scales of 3–14 months. Observations of Mira A in the ultraviolet band by the Hubble Space Telescope have shown a plume-like feature pointing toward the companion star.
Variability.
Mira A is a well-known example of a category of variable stars known as Mira variables, which are named after it. The 6–7,000 known stars of this class are all red giants whose surfaces oscillate in such a way as to increase and decrease in brightness over periods ranging from about 80 to more than 1,000 days.
In the particular case of Mira, its increases in brightness take it up to about magnitude 3.5 on average, placing it among the brighter stars in the Cetus constellation. Individual cycles vary too; well-attested maxima go as high as magnitude 2.0 in brightness and as low as 4.9, a range almost 15 times in brightness, and there are historical suggestions that the real spread may be three times this or more. Minima range much less, and have historically been between 8.6 and 10.1, a factor of four times in luminosity. The total swing in brightness from absolute maximum to absolute minimum (two events which did not occur on the same cycle) is 1,700 times. Interestingly, since Mira emits the vast majority of its radiation in the infrared, its variability in that band is only about two magnitudes. The shape of its light curve is of an increase over about 100 days, and a return twice as long.
Contemporary approximate maxima for Mira:
From northern temperate latitudes, Mira is generally not visible between late March and June due to its proximity to the Sun. This means that at times several years can pass without it appearing as a naked-eye object.
Mass loss.
Ultra-violet studies of Mira by NASA's Galaxy Evolution Explorer (GALEX) space telescope have revealed that it sheds a trail of material from the outer envelope, leaving a tail 13 light-years in length, formed over tens of thousands of years. It is thought that a hot bow-wave of compressed plasma/gas is the cause of the tail; the bow-wave is a result of the interaction of the stellar wind from Mira A with gas in interstellar space, through which Mira is moving at an extremely high speed of 130 kilometres/second (291,000 miles per hour). The tail consists of material stripped from the head of the bow-wave, which is also visible in ultra-violet observations. Mira's bow-shock will eventually evolve into a planetary nebula, the form of which will be considerably affected by the motion through the interstellar medium (ISM).
Component B.
The companion star was resolved by the Hubble Space Telescope in 1995, when it was 70 astronomical units from the primary; results were announced in 1997. The HST ultraviolet images and later X-ray images by the Chandra space telescope show a spiral of gas rising off Mira in the direction of Mira B. The companion's orbital period around Mira is approximately 400 years.
In 2007, observations showed a protoplanetary disc around the companion, Mira B. This disc is being accreted from material in the solar wind from Mira and could eventually form new planets. These observations also hinted that the companion was a main sequence star of around 0.7 solar masses and spectral type K, instead of a white dwarf as originally thought. However in 2010 further research indicated that Mira B is in fact a white dwarf.

</doc>
<doc id="20881" url="http://en.wikipedia.org/wiki?curid=20881" title="MV Virginian (T-AK 9205)">
MV Virginian (T-AK 9205)

MV "Virginian" (T-AK 9205), formerly named the MV "Strong Virginian" (T-AKR-9205), is a combination container, heavy lift, and roll-on/roll-off ship. Owned and operated by Sealift Incorporated of Oyster Bay, New York, the ship is one of seventeen container—roll-on/roll-off ships in use by the Military Sealift Command, and one of 28 ships assigned to that organization's Sealift Program Office. The ship was previously known as the MV "Saint Magnus and the MV "Jolly Indaco.
Cargo equipment.
The ship has one large cargo hold with a tween deck that can be set at three different heights. It has a single 800-ton derrick for heavy-lift use. In addition it has a single traveling gantry crane fitted with dual portal cranes, both of which are rated at 75 metric tons independently, and can be operated together for lifts up to 150 metric tons. For roll-on/roll-off (roro) cargo, the ship has two trailer elevators and roro ramps.
History.
Built as "Saint Magnus" at Bremer Vulkan, Bremen, Germany in 1984, "Virginian" spent her first years in the commercial shipping service. Ironically, the ship that would later be known for carrying military supplies to the Middle East was accidentally hit by an Exocet missile while off-loading commercial cargo in Iraq in 1986. In these early years, the ship was also renamed "Jolly Indaco".
MSC first chartered the ship, then known as MV "Strong Virginian", in 1992. For the next five years, a 500-bed fleet hospital was prepositioned aboard the ship as she carried out a variety of missions for the Department of Defense. Some of its jobs during this time included delivering equipment and supplies to Africa as part of Operation Restore Hope, transporting a bio-safety lab from Inchon, Korea, to Jakarta, Indonesia, and ferrying harbor tugs used by the U.S. Navy from Diego Garcia to Guam and back.
On March 14, 1997, the United States Department of Defense announced a new charter for the "Strong Virginian". This contract, number N00033-97-C-3007, was a $23,592,099 time charter contract from the Military Sealift Command to operator Van Ommeren Shipping (USA), Inc., of Stamford, Connectucut. Under the contract, the "Strong Virginian" was to be used in the prepositioning of United States Army cargo in the Indian Ocean at the island of Diego Garcia. The contract included options which could have brought the cumulative value up to US$47,992,099 and was to expire by March 1999. This contract was competitively procured with 250 proposals solicited and four offers received.
Virginian was chartered again in 1998 and, for the next four years, the ship was used to support the U.S. Army. Virginian delivered combat craft, tugboats and barges and other elements of the Army's port opening packages. These packages are used to give the military access to rarely used ports in areas vital to U.S. military operations. On September 30, 2002, the ship was released from MSC service and returned to its owner.
Sealift Incorporated bought the ship from Van Ommeren Shipping USA, Inc. taking delivery on June 10, 2003. At that point, Sealift renamed the ship the "Virginian". Between November 2002 and May 2006, the "Virginian" completed 21 missions for the U.S. military, delivering almost 1700000 sqft, or nearly 30 football fields, of cargo.
On October 16, 2007 the United States Department of Defense announced that it awarded contract N00033-08-C-5500 to Sealift Incorporated. This was a $10,614,000 firm-fixed-price contract plus reimbursables for the "Virginian". The ship was contracted to carry containers laden with ammunition to support the global war on terrorism and the United States Central Command. The contract includes options, which, if exercised, would bring the cumulative value of this contract to $39,814,000. If options are exercised, work may continue through October 2011. This contract was competitively procured via Federal Business Opportunities and the Military Sealift Command websites, with more than 200 proposals solicited and three offers received. The U.S. Navy’s Military Sealift Command is the contracting authority.
The ship was sold for scrap in August 2012 in Singapore and was recycled in Bangledesh that same month.

</doc>
<doc id="20882" url="http://en.wikipedia.org/wiki?curid=20882" title="Mon">
Mon

Mon or Møn may refer to:

</doc>
<doc id="20883" url="http://en.wikipedia.org/wiki?curid=20883" title="Mojito">
Mojito

Mojito (; ]) is a traditional Cuban highball.
Traditionally, a mojito is a cocktail that consists of five ingredients: white rum, sugar (traditionally sugar cane juice), lime juice, sparkling water, and mint. The original Cuban recipe uses spearmint or yerba buena, a mint variety very popular on the island. Its combination of sweetness, refreshing citrus, and mint flavors is intended to complement the potent kick of the rum, and has made this clear highball a popular summer drink. The cocktail has a relatively low alcohol content (about 10 percent alcohol by volume).
When preparing a mojito, lime juice is added to sugar (or syrup) and mint leaves. The mixture is then gently mashed with a muddler. The mint leaves should only be bruised to release the essential oils and should not be shredded. Then rum is added and the mixture is briefly stirred to dissolve the sugar and to lift the mint leaves up from the bottom for better presentation. Finally, the drink is topped with whole ice cubes and sparkling soda water. Mint leaves and lime wedges are used to garnish the glass.
The mojito is one of the most famous rum-based highballs. There are several versions of the mojito.
History.
Havana is the birthplace of the Mojito, although the exact origin of this classic cocktail is the subject of debate. One story traces the Mojito to a similar 16th century drink known as "El Draque", after Francis Drake. In 1586, after his successful raid at Cartagena de Indias Drake's ships sailed towards Havana but there was an epidemic of dysentery and scurvy on board. It was known that the local South American Indians had remedies for various tropical illnesses; so a small boarding party went ashore on Cuba and came back with ingredients for a medicine which was effective. The ingredients were aguardiente de caña (a crude form of rum, translates as "fire water" from sugar cane) added with local tropical ingredients; lime, sugarcane juice and mint. Drinking lime juice in itself would have been a great help in staving off scurvy and dysentery. Tafia/Rum was used as soon as it became widely available to the British (ca. 1650). Mint, lime and sugar were also helpful in hiding the harsh taste of this spirit. While this drink was not called a Mojito at this time, it was still the original combination of these ingredients.
Some historians contend that African slaves who worked in the Cuban sugar cane fields during the 19th century were instrumental in the cocktail's origin. Guarapo, the sugar cane juice often used in Mojitos, was a popular drink amongst the slaves who helped coin the name of the sweet nectar. It never originally contained lime juice.
There are several theories behind the origin of the name Mojito; one such theory holds that name relates to mojo, a Cuban seasoning made from lime and used to flavour dishes. Another theory is that the name Mojito is simply a derivative of "mojadito" (Spanish for "a little wet") or simply the diminutive of "mojado" ("wet"). Due to the vast influence of immigration from the Canary Islands, the term probably came from the mojo creole marinades adapted in Cuba using citrus vs traditional Isleno types.
The Mojito has routinely been presented as a favorite drink of author Ernest Hemingway. It has also often been said that Ernest Hemingway made the bar called La Bodeguita del Medio famous as he became one of its regulars and wrote "My mojito in La Bodeguita, My daiquiri in El Floridita." This expression in English can be read on the wall of the bar today, handwritten and signed in his name, although Hemingway biographers have expressed doubts about such patronage and about the author's taste for mojitos. La Bodeguita del Medio is more known for their food rather than drink.
A report created in 2014 states that the Mojito is now the most popular cocktail in Britain 

</doc>
<doc id="20886" url="http://en.wikipedia.org/wiki?curid=20886" title="Mohammed Zahir Shah">
Mohammed Zahir Shah

Mohammed Zahir Shah (Pashto: محمد ظاهرشاه October 15, 1914 – July 23, 2007) was the last King of Afghanistan, reigning for four decades, from 1933 until he was ousted by a coup in 1973. Following his return from exile, he was given the title 'Father of the Nation' in 2002, which he held until his death.
Family background and early life.
Zahir Shah was an ethnic Pashtun who was born on 15 October 1914, in Kabul, Afghanistan. He was the son of Mohammed Nadir Shah, a senior member of the Barakzai royal family and commander in chief of the Afghan army under former king Amanullah Khan. Nadir Shah assumed the throne after the execution of Habibullah Ghazi on 10 October 1929. Mohammed Zahir's father, son of Sardar Mohammad Yusuf Khan, was born in Dehradun, British India, his family having been exiled following the Second Anglo-Afghan War. Nadir Shah was a descendant of Sardar Sultan Mohammed Khan Telai, half-brother of Amir Dost Mohammad Khan. His grandfather Mohammad Yahya Khan (father in law of Amir Yaqub Khan) was in charge of the negotiations with the British leading to the Treaty of Gandamak. After the British invasion following the killing of Sir Louis Cavagnari in 1879, Yaqub Khan, Yahya Khan and his sons, Princes Mohammad Yusuf Khan and Mohammad Asef Khan, were seized by the British and transferred under custody to the British Raj, where they forcibly remained until the two princes were invited back to Afghanistan by Emir Abdur Rahman Khan in the last year of his reign (1901). During the reign of Amir Habibullah they received the title of Companions of the King (Musahiban).
Zahir Shah was educated in a special class for princes at Habibia High School in Kabul. He continued his education in France where his father had been sent as a diplomatic envoy, studying at the Pasteur Institute and the University of Montpellier. When he returned to Afghanistan he helped his father and uncles restore order and reassert government control during a period of lawlessness in the country. He was later enrolled at an Infantry School and appointed a privy counsellor. Zahir Shah served in the government positions of deputy war minister and minister of education. Zahir Shah was fluent in Pashto, Persian, and French.
The last king of Afghanistan.
Zahir Khan was proclaimed King (Shah) on 8 November 1933 at the age of 19, after the assassination of his father Mohammed Nadir Shah. Following his ascension to the throne he was given the regnal title "He who puts his trust in God, follower of the firm religion of Islam". For the first thirty years he did not effectively rule, ceding power to his paternal uncles, Mohammad Hashim Khan and Shah Mahmud Khan. This period fostered a growth in Afghanistan's relations with the international community as in 1934, Afghanistan joined the League of Nations while also receiving formal recognition from the United States. By the end of the 1930s, agreements on foreign assistance and trade had been reached with many countries, most notably Germany, Italy, and Japan.
Zahir Shah provided aid, weapons and Afghan fighters to the Uighur and Kirghiz Muslim rebels who had established the First East Turkestan Republic. The aid was not capable of saving the First East Turkestan Republic, as the Afghan, Uighur and Kirghiz forces were defeated in 1934 by the Chinese Muslim 36th Division (National Revolutionary Army) led by General Ma Zhancang at the Battle of Kashgar and Battle of Yarkand. All the Afghan volunteers were killed by the Chinese Muslim troops, who then abolished the First East Turkestan Republic, and reestablished Chinese government control over the area.
Following the end of the Second World War, Zahir Shah recognised the need for the modernisation of Afghanistan and recruited a number of foreign advisers to assist with the process. During this period Afghanistan's first modern university was founded.<ref name=10/01></ref> During his reign a number of potential advances and reforms were derailed as a result of factionalism and political infighting.
Zahir Shah was able to govern on his own in 1963 and despite the factionalism and political infighting a new constitution was introduced in 1964 which turned Afghanistan into a modern democratic state by introducing free elections, a parliament, civil rights, women's rights and universal suffrage.
At least 5 of Afghani little Pul coins during his reign bore the Arabic title:
المتوكل على الله محمد ظاهر شاه, "AlMutawakkil 'ala Allah Muhammad Zhahir Shah" which means "The leaner on Allah, Muhammad Zhahir Shah". The title "AlMutawakkil 'ala Allah", "The leaner on Allah" is taken from the Quran, Sura 8, verse 61.
By the time he returned to Afghanistan in the twenty-first century, his rule was characterized by a lengthy span of peace, but with no significant progress.
Exile.
In 1973, while Zahir Shah was in Italy, undergoing eye surgery as well as therapy for lumbago, his cousin and former Prime Minister Mohammed Daoud Khan staged a coup d'état and established a republican government. As a former prime minister, Daoud Khan had been forced to resign by Zahir Shah a decade earlier. In August 1973, Zahir Shah abdicated rather than risk an all-out civil war.
Zahir Shah lived in exile in Italy for twenty-nine years in a villa in the affluent community of Olgiata on Via Cassia, north of Rome where he spent his time playing golf and chess, as well as tending to his garden. He was barred from returning to Afghanistan during Soviet-backed Communist rule in the late 1970s. In 1983 during the Soviet war in Afghanistan, Zahir Shah was cautiously involved in plans to head a government in exile. Ultimately these plans failed because he could not reach a consensus with the powerful Islamist factions.
In 1991, Zahir Shah survived an attempt on his life by a knife-wielding assassin masquerading as a Portuguese journalist.
Return to Afghan politics.
In April 2002, while the country was no longer under Taliban rule, Zahir Shah returned to Afghanistan to open the Loya Jirga, which met in June 2002. After the fall of the Taliban, there were open calls for a return to the monarchy. Zahir Shah himself let it be known that he would accept whatever responsibility was placed on him by the Loya Jirga. However he was obliged to publicly step aside at the behest of the United States as many of delegates to the Loya Jirga were prepared to vote for Zahir Shah and block the US-backed Hamid Karzai. While he was prepared to become head of state he made it known that it would not necessarily be as monarch: "I will accept the responsibility of head of state if that is what the Loya Jirga demands of me, but I have no intention to restore the monarchy. I do not care about the title of king. The people call me Baba and I prefer this title." He was given the title "Father of the Nation" in the current Constitution of Afghanistan symbolizing his role in Afghanistan's history as a symbol of national unity. The title of the 'Father of the Nation' dissolved with his death.
Hamid Karzai, a prominent figure from the Pashtun Popalzai clan, became the president of Afghanistan and Zahir Shah's relatives and supporters were provided with key posts in the transitional government. Zahir Shah moved back into his old palace. In an October 2002 visit to France, he slipped in a bathroom, bruising his ribs, and on 21 June 2003, while in France for a medical check-up, he broke his femur.
On 3 February 2004, Zahir was flown from Kabul to New Delhi, India, for medical treatment after complaining of an intestinal problem. He was hospitalized for two weeks and remained in New Delhi under observation. On 18 May 2004, he was brought to a hospital in the United Arab Emirates because of nose bleeding caused by heat.
Zahir Shah attended the 7 December 2004 swearing-in of Hamid Karzai as President of Afghanistan. In his final years, he was frail and required a microphone pinned to his collar so that his faint voice could be heard. In January 2007, Zahir was reported to be seriously ill and bedridden.
Death.
On 23 July 2007, he died in the compound of the presidential palace in Kabul after prolonged illness. His death was announced on national television by President Karzai. His funeral was held on 24 July. It began on the premises of the presidential palace, where political figures and dignitaries paid their respects; his coffin was then taken to a mosque before being moved to the royal mausoleum on Maranjan Hill.
Family.
He married his cousin Humaira Begum (1918–2002) on 7 November 1931 and had six sons and two daughters:
In January 2009 an article by Ahmad Majidyar of the American Enterprise Institute included one of his grandsons, Mustafa Zahir, on a list of fifteen possible candidates in the 2009 Afghan Presidential election.
However Mostafa Zaher did not become a candidate.

</doc>
<doc id="20889" url="http://en.wikipedia.org/wiki?curid=20889" title="Miso">
Miso

Miso (みそor味噌) is a traditional Japanese seasoning produced by fermenting soybeans with salt and the fungus "Aspergillus oryzae", known in Japanese as "kōji" (麹), and sometimes rice, barley, or other ingredients. The result is a thick paste used for sauces and spreads, pickling vegetables or meats, and mixing with dashi soup stock to serve as miso soup called "misoshiru" (味噌汁), a Japanese culinary staple. High in protein and rich in vitamins and minerals, miso played an important nutritional role in feudal Japan. Miso is still widely used in Japan, both in traditional and modern cooking, and has been gaining worldwide interest. 
Miso is typically salty, but its flavor and aroma depend on various factors in the ingredients and fermentation process. Different varieties of miso have been described as salty, sweet, earthy, fruity, and savory. The traditional Chinese analogue of miso is known as dòujiàng (豆酱).
History.
The earliest form of miso is known as "Hishio". Hishio is a kind of salty seasoning which is made from grain. 
The origin of the miso of Japan is not completely clear. 
In the Kamakura era (1192–1333), a common meal was made up of a bowl of rice, some dried fish, a serving of miso, and a fresh vegetable. Until the Muromachi era (1337 to 1573), miso was made without grinding the soybeans, somewhat like nattō. In the Muromachi era, Buddhist monks discovered that soybeans could be ground into a paste, spawning new cooking methods using miso to flavor other foods. In medieval times, the word "Temaemiso", meaning home-made miso, appeared. Miso production is a relatively simple process and so home-made versions spread throughout Japan. Miso was used as military provisions during the Sengoku era and making miso was an important economic activity for daimyos of that era.
During the Edo period (1603–1868) miso was also called "hishio" and "kuki" and various types of miso that fit with each local climate and culture emerged throughout Japan.
These days miso is produced industrially in large quantities and traditional home-made miso has become a rarity. In recent years, many new types of miso have appeared. For example, there are ones with added soup stocks or calcium, or reduced salt for health, etc.
Flavor.
The taste, aroma, texture, and appearance of miso all vary by region and season. Other important variables that contribute to the flavor of a particular miso include temperature, duration of fermentation, salt content, variety of kōji, and fermenting vessel. The most common flavor categories of miso are:
Although white and red ("shiromiso" and "akamiso") are the most common types of misos available, different varieties may be preferred in particular regions of Japan. In the eastern Kantō region that includes Tokyo, the darker brownish "akamiso" is popular while in the western Kansai region encompassing Osaka, Kyoto, and Kobe the lighter "shiromiso" is preferred.
Ingredients.
The ingredients used to produce miso may include any mix of soybeans, barley, rice, buckwheat, millet, rye, wheat, hemp seed, and cycad, among others. Lately, producers in other countries have also begun selling miso made from chickpeas, corn, azuki beans, amaranth, and quinoa. Fermentation time ranges from as little as five days to several years. The wide variety of Japanese miso is difficult to classify, but is commonly done by grain type, color, taste, and background.
Many regions have their own specific variation on the miso standard. For example, the soybeans used in Sendai miso are much more coarsely mashed than in normal soy miso.
Miso made with rice such as "shinshu" and "shiro" are called "kome" miso.
Types.
Types of miso are divided by their main ingredients.
Storage and preparation.
Miso typically comes as a paste in a sealed container requiring refrigeration after opening. Natural miso is a living food containing many beneficial microorganisms such as "Tetragenococcus halophilus" which can be killed by over-cooking. For this reason, it is recommended that the miso be added to soups or other foods being prepared just before they are removed from the heat. Using miso without any cooking may be even better. Outside of Japan, a popular practice is to only add miso to foods that have cooled in order to preserve "kōjikin" cultures in miso. Nonetheless, miso and soy foods play a large role in the Japanese diet, and many cooked miso dishes are popularly consumed.
Usage.
Miso is a part of many Japanese-style meals. It most commonly appears as the main ingredient of miso soup, which is eaten daily by much of the Japanese population. The pairing of plain rice and miso soup is considered a fundamental unit of Japanese cuisine. This pairing is the basis of a traditional Japanese breakfast.
Miso is used in many other types of soup and souplike dishes, including some kinds of ramen, udon, nabe, and imoni. Generally, such dishes have the title "miso" prefixed to their name (for example, "miso-udon"), and have a heavier, earthier flavor and aroma compared to other Japanese soups that are not miso-based.
Many traditional confections use a sweet, thick miso glaze, such as mochidango. Miso glazed treats are strongly associated with Japanese festivals, although they are available year-round at supermarkets. The consistency of miso glaze ranges from thick and taffy-like to thin and drippy. 
Soy miso is used to make a type of pickle called "misozuke". These pickles are typically made from cucumber, daikon, "hakusai" (Chinese cabbage), or eggplant, and are sweeter and less salty than the standard Japanese salt pickle. 
Other foods with miso as an ingredient include:
Nutrition and health.
Claims that miso is high in vitamin B12 have been contradicted in some studies.
Some experts suggest that miso is a source of "Lactobacillus acidophilus". Miso is relatively high in salt which can contribute to increased blood pressure in the small percentage of the population with sodium-sensitive prehypertension or hypertension.

</doc>
<doc id="20890" url="http://en.wikipedia.org/wiki?curid=20890" title="Malcolm I of Scotland">
Malcolm I of Scotland

Máel Coluim mac Domnaill (anglicised Malcolm I) (c. 900–954) was king of Scots (before 943 – 954), becoming king when his cousin Causantín mac Áeda abdicated to become a monk. He was the son of Domnall mac Causantín.
Since his father was known to have died in the year 900, Malcolm must have been born no later than 901. By the 940s, he was no longer a young man, and may have become impatient in awaiting the throne. Willingly or not—the 11th-century "Prophecy of Berchán", a verse history in the form of a supposed prophecy, states that it was not a voluntary decision that Constantine II abdicated in 943 and entered a monastery, leaving the kingdom to Malcolm.
Seven years later, the "Chronicle of the Kings of Alba" says:[Malcolm I] plundered the English as far as the River Tees, and he seized a multitude of people and many herds of cattle: and the Scots called this the raid of Albidosorum, that is, Nainndisi. But others say that Constantine made this raid, asking of the king, Malcolm, that the kingship should be given to him for a week's time, so that he could visit the English. In fact, it was Malcolm who made the raid, but Constantine incited him, as I have said. Woolf suggests that the association of Constantine with the raid is a late addition, one derived from a now-lost saga or poem.
He died in the shield wall next to his men.
In 945, Edmund of Wessex, having expelled Amlaíb Cuaran (Olaf Sihtricsson) from Northumbria, devastated Cumbria and blinded two sons of Domnall mac Eógain, king of Strathclyde. It is said that he then "let" or "commended" Strathclyde to Máel Coluim in return for an alliance. What is to be understood by "let" or "commended" is unclear, but it may well mean that Máel Coluim had been the overlord of Strathclyde and that Edmund recognised this while taking lands in southern Cumbria for himself.
The Chronicle of the Kings of Alba says that Máel Coluim took an army into Moray "and slew Cellach". Cellach is not named in the surviving genealogies of the rulers of Moray, and his identity is unknown.
Máel Coluim appears to have kept his agreement with the late English king, which may have been renewed with the new king, Edmund having been murdered in 946 and succeeded by his brother Edred. Eric Bloodaxe took York in 948, before being driven out by Edred, and when Amlaíb Cuaran again took York in 949–950, Máel Coluim raided Northumbria as far south as the Tees taking "a multitude of people and many herds of cattle" according to the Chronicle. The Annals of Ulster for 952 report a battle between "the men of Alba and the Britons [of Strathclyde] and the English" against the foreigners, i.e. the Northmen or the Norse-Gaels. This battle is not reported by the Anglo-Saxon Chronicle, and it is unclear whether it should be related to the expulsion of Amlaíb Cuaran from York or the return of Eric Bloodaxe.
The Annals of Ulster report that Máel Coluim was killed in 954. Other sources place this most probably in the Mearns, either at Fetteresso following the Chronicle, or at Dunnottar following the Prophecy of Berchán. He was buried on Iona. Máel Coluim's sons Dub and Cináed were later kings.
References.
"For primary sources see also " External links "below."

</doc>
<doc id="20892" url="http://en.wikipedia.org/wiki?curid=20892" title="Malcolm III of Scotland">
Malcolm III of Scotland

Máel Coluim mac Donnchada (Modern Gaelic: "Maol Chaluim mac Dhonnchaidh", called in most Anglicised regnal lists Malcolm III, and in later centuries nicknamed Canmore—"Big Head", either literally or in reference to his leadership, or "Long-neck"—died 13 November 1093), was King of Scots. He was the eldest son of King Duncan I (Donnchad mac Crínáin). Malcolm's long reign, lasting 35 years, preceded the beginning of the Scoto-Norman age. He is the historical equivalent of the character of the same name in Shakespeare's "Macbeth".
Malcolm's Kingdom did not extend over the full territory of modern Scotland: the north and west of Scotland remained in Scandinavian, Norse-Gael and Gaelic control, and the areas under the control of the Kings of Scots did not advance much beyond the limits set by Malcolm II (Máel Coluim mac Cináeda) until the 12th century. Malcolm III fought a succession of wars against the Kingdom of England, which may have had as their goal the conquest of the English earldom of Northumbria. These wars did not result in any significant advances southwards. Malcolm's main achievement is to have continued a line which would rule Scotland for many years, although his role as "founder of a dynasty" has more to do with the propaganda of his youngest son David, and his descendants, than with any historical reality.
Malcolm's second wife, Margaret of Wessex, was eventually canonized and is Scotland's only royal saint. Malcolm himself gained no reputation for piety; with the notable exception of Dunfermline Abbey he is not definitely associated with major religious establishments or ecclesiastical reforms.
Background.
Malcolm's father Duncan I (Donnchad mac Crínáin) became king in late 1034, on the death of Malcolm II (Máel Coluim mac Cináeda), Duncan's maternal grandfather and Malcolm's great-grandfather. According to John of Fordun, whose account is the original source of part at least of William Shakespeare's "Macbeth", Malcolm's mother was a niece of Siward, Earl of Northumbria, but an earlier king-list gives her the Gaelic name Suthen. Other sources claim that either a daughter or niece would have been too young to fit the timeline, thus the likely relative would have been Siward's own sister Sybil, which may have translated into Gaelic as Suthen.
Duncan's reign was not successful and he was killed by Macbeth (Mac Bethad mac Findlaích) on 15 August 1040. Although Shakespeare's "Macbeth" presents Malcolm as a grown man and his father as an old one, it appears that Duncan was still young in 1040, and Malcolm and his brother Donalbane (Domnall Bán) were children. Malcolm's family did attempt to overthrow Macbeth in 1045, but Malcolm's grandfather Crínán of Dunkeld was killed in the attempt.
Soon after the death of Duncan his two young sons were sent away for greater safety—exactly where is the subject of debate. According to one version, Malcolm (then aged about nine) was sent to England, and his younger brother Donalbane was sent to the Isles. Based on Fordun's account, it was assumed that Malcolm passed most of Macbeth's seventeen-year reign in the Kingdom of England at the court of Edward the Confessor.
According to an alternative version, Malcolm's mother took both sons into exile at the court of Thorfinn Sigurdsson, Earl of Orkney, an enemy of Macbeth's family, and perhaps Duncan's kinsman by marriage.
An English invasion in 1054, with Siward, Earl of Northumbria, in command, had as its goal the installation of one "Máel Coluim, son of the King of the Cumbrians". This Máel Coluim has traditionally been identified with the later Malcolm III. This interpretation derives from the "Chronicle" attributed to the 14th-century chronicler of Scotland, John of Fordun, as well as from earlier sources such as William of Malmesbury. The latter reported that Macbeth was killed in the battle by Siward, but it is known that Macbeth outlived Siward by two years. A. A. M. Duncan argued in 2002 that, using the "Anglo-Saxon Chronicle" entry as their source, later writers innocently misidentified "Máel Coluim" with the later Scottish king of the same name. Duncan's argument has been supported by several subsequent historians specialising in the era, such as Richard Oram, Dauvit Broun and Alex Woolf. It has also been suggested that Máel Coluim may have been a son of Owen the Bald, British king of Strathclyde perhaps by a daughter of Máel Coluim II, King of Scotland.
In 1057 various chroniclers report the death of Macbeth at Malcolm's hand, on 15 August 1057 at Lumphanan in Aberdeenshire. Macbeth was succeeded by his stepson Lulach, who was crowned at Scone, probably on 8 September 1057. Lulach was killed by Malcolm, "by treachery", near Huntly on 23 April 1058. After this, Malcolm became king, perhaps being inaugurated on 25 April 1058, although only John of Fordun reports this.
Malcolm and Ingibiorg.
If Orderic Vitalis is to be relied upon, one of Malcolm's earliest actions as king may have been to travel south to the court of Edward the Confessor in 1059 to arrange a marriage with Edward's kinswoman Margaret, who had arrived in England two years before from Hungary. If he did visit the English court, he was the first reigning king of Scots to do so in more than eighty years. If a marriage agreement was made in 1059, it was not kept, and this may explain the Scots invasion of Northumbria in 1061 when Lindisfarne was plundered. Equally, Malcolm's raids in Northumbria may have been related to the disputed "Kingdom of the Cumbrians", reestablished by Earl Siward in 1054, which was under Malcolm's control by 1070.
The Orkneyinga saga reports that Malcolm married the widow of Thorfinn Sigurdsson, Ingibiorg, a daughter of Finn Arnesson. Although Ingibiorg is generally assumed to have died shortly before 1070, it is possible that she died much earlier, around 1058. The "Orkneyinga Saga" records that Malcolm and Ingibiorg had a son, Duncan II (Donnchad mac Maíl Coluim), who was later king. Some Medieval commentators, following William of Malmesbury, claimed that Duncan was illegitimate, but this claim is propaganda reflecting the need of Malcolm's descendants by Margaret to undermine the claims of Duncan's descendants, the Meic Uilleim. Malcolm's son Domnall, whose death is reported in 1085, is not mentioned by the author of the "Orkneyinga Saga". He is assumed to have been born to Ingibiorg.
Malcolm's marriage to Ingibiorg secured him peace in the north and west. The "Heimskringla" tells that her father Finn had been an adviser to Harald Hardraade and, after falling out with Harald, was then made an Earl by Sweyn Estridsson, King of Denmark, which may have been another recommendation for the match. Malcolm enjoyed a peaceful relationship with the Earldom of Orkney, ruled jointly by his stepsons, Paul and Erlend Thorfinnsson. The "Orkneyinga Saga" reports strife with Norway but this is probably misplaced as it associates this with Magnus Barefoot, who became king of Norway only in 1093, the year of Malcolm's death.
Malcolm and Margaret.
Although he had given sanctuary to Tostig Godwinson when the Northumbrians drove him out, Malcolm was not directly involved in the ill-fated invasion of England by Harald Hardraade and Tostig in 1066, which ended in defeat and death at the battle of Stamford Bridge. In 1068, he granted asylum to a group of English exiles fleeing from William of Normandy, among them Agatha, widow of Edward the Confessor's nephew Edward the Exile, and her children: Edgar Ætheling and his sisters Margaret and Cristina. They were accompanied by Gospatric, Earl of Northumbria. The exiles were disappointed, however, if they had expected immediate assistance from the Scots.
In 1069 the exiles returned to England, to join a spreading revolt in the north. Even though Gospatric and Siward's son Waltheof submitted by the end of the year, the arrival of a Danish army under Sweyn Estridsson seemed to ensure that William's position remained weak. Malcolm decided on war, and took his army south into Cumbria and across the Pennines, wasting Teesdale and Cleveland then marching north, loaded with loot, to Wearmouth. There Malcolm met Edgar and his family, who were invited to return with him, but did not. As Sweyn had by now been bought off with a large Danegeld, Malcolm took his army home. In reprisal, William sent Gospatric to raid Scotland through Cumbria. In return, the Scots fleet raided the Northumbrian coast where Gospatric's possessions were concentrated. Late in the year, perhaps shipwrecked on their way to a European exile, Edgar and his family again arrived in Scotland, this time to remain. By the end of 1070, Malcolm had married Edgar's sister Margaret of Wessex, the future Saint Margaret of Scotland.
The naming of their children represented a break with the traditional Scots regal names such as Malcolm, Cináed and Áed. The point of naming Margaret's sons—Edward after her father Edward the Exile, Edmund for her grandfather Edmund Ironside, Ethelred for her great-grandfather Ethelred the Unready and Edgar for her great-great-grandfather Edgar and her brother, briefly the elected king, Edgar Ætheling—was unlikely to be missed in England, where William of Normandy's grasp on power was far from secure. Whether the adoption of the classical Alexander for the future Alexander I of Scotland (either for Pope Alexander II or for Alexander the Great) and the biblical David for the future David I of Scotland represented a recognition that William of Normandy would not be easily removed, or was due to the repetition of Anglo-Saxon royal name—another Edmund had preceded Edgar—is not known. Margaret also gave Malcolm two daughters, Edith, who married Henry I of England, and Mary, who married Eustace III of Boulogne.
In 1072, with the Harrying of the North completed and his position again secure, William of Normandy came north with an army and a fleet. Malcolm met William at Abernethy and, in the words of the "Anglo-Saxon Chronicle" "became his man" and handed over his eldest son Duncan as a hostage and arranged peace between William and Edgar. Accepting the overlordship of the king of the English was no novelty, as previous kings had done so without result. The same was true of Malcolm; his agreement with the English king was followed by further raids into Northumbria, which led to further trouble in the earldom and the killing of Bishop William Walcher at Gateshead. In 1080, William sent his son Robert Curthose north with an army while his brother Odo punished the Northumbrians. Malcolm again made peace, and this time kept it for over a decade.
Malcolm faced little recorded internal opposition, with the exception of Lulach's son Máel Snechtai. In an unusual entry, for the "Anglo-Saxon Chronicle" contains little on Scotland, it says that in 1078:
Malcholom [Máel Coluim] seized the mother of Mælslæhtan [Máel Snechtai] ... and all his treasures, and his cattle; and he himself escaped with difficulty.
Whatever provoked this strife, Máel Snechtai survived until 1085.
Malcolm and William Rufus.
When William Rufus became king of England after his father's death, Malcolm did not intervene in the rebellions by supporters of Robert Curthose which followed. In 1091, William Rufus confiscated Edgar Ætheling's lands in England, and Edgar fled north to Scotland. In May, Malcolm marched south, not to raid and take slaves and plunder, but to besiege Newcastle, built by Robert Curthose in 1080. This appears to have been an attempt to advance the frontier south from the River Tweed to the River Tees. The threat was enough to bring the English king back from Normandy, where he had been fighting Robert Curthose. In September, learning of William Rufus's approaching army, Malcolm withdrew north and the English followed. Unlike in 1072, Malcolm was prepared to fight, but a peace was arranged by Edgar Ætheling and Robert Curthose whereby Malcolm again acknowledged the overlordship of the English king.
In 1092, the peace began to break down. Based on the idea that the Scots controlled much of modern Cumbria, it had been supposed that William Rufus's new castle at Carlisle and his settlement of English peasants in the surrounds was the cause. It is unlikely that Malcolm controlled Cumbria, and the dispute instead concerned the estates granted to Malcolm by William Rufus's father in 1072 for his maintenance when visiting England. Malcolm sent messengers to discuss the question and William Rufus agreed to a meeting. Malcolm travelled south to Gloucester, stopping at Wilton Abbey to visit his daughter Edith and sister-in-law Cristina. Malcolm arrived there on 24 August 1093 to find that William Rufus refused to negotiate, insisting that the dispute be judged by the English barons. This Malcolm refused to accept, and returned immediately to Scotland.
It does not appear that William Rufus intended to provoke a war, but, as the "Anglo-Saxon Chronicle" reports, war came:
For this reason therefore they parted with great dissatisfaction, and the King Malcolm returned to Scotland. And soon after he came home, he gathered his army, and came harrowing into England with more hostility than behoved him ...
Malcolm was accompanied by Edward, his eldest son by Margaret and probable heir-designate (or tánaiste), and by Edgar. Even by the standards of the time, the ravaging of Northumbria by the Scots was seen as harsh.
Death.
While marching north again, Malcolm was ambushed by Robert de Mowbray, Earl of Northumbria, whose lands he had devastated, near Alnwick on 13 November 1093. There he was killed by Arkil Morel, steward of Bamburgh Castle. The conflict became known as the Battle of Alnwick. Edward was mortally wounded in the same fight. Margaret, it is said, died soon after receiving the news of their deaths from Edgar. The Annals of Ulster say:
Mael Coluim son of Donnchad, over-king of Scotland, and Edward his son, were killed by the French [i.e. Normans] in Inber Alda in England. His queen, Margaret, moreover, died of sorrow for him within nine days.
Malcolm's body was taken to Tynemouth Priory for burial. The king's body was sent north for reburial, in the reign of his son Alexander, at Dunfermline Abbey, or possibly Iona.
On 19 June 1250, following the canonisation of Malcolm's wife Margaret by Pope Innocent IV, Margaret's remains were disinterred and placed in a reliquary. Tradition has it that as the reliquary was carried to the high altar of Dunfermline Abbey, past Malcolm's grave, it became too heavy to move. As a result, Malcolm's remains were also disinterred, and buried next to Margaret beside the altar.
Issue.
Malcolm and Ingebjorg had three sons:
Malcolm and Margaret had eight children, six sons and two daughters:
Depictions in fiction.
Malcolm appears in William Shakespeare’s "Macbeth" as Malcolm. He is the son of King Duncan and heir to the throne. He first appears in the second scene where he is talking to a sergeant, with Duncan. The sergeant tells them how the battle was won thanks to Macbeth. Then Ross comes and Duncan decides that Macbeth should take the title of Thane of Cawdor. Then he later appears in Act 1.4 talking about the execution of the former Thane of Cawdor. Macbeth then enters and they congratulate him on his victory. He later appears in Macbeth’s castle as a guest. When his father is killed he is suspected of the murder so he escapes to England. He later makes an appearance in Act 4.3, where he talks to Macduff about Macbeth and what to do. They both decide to start a war against him. In Act 5.4 he is seen in Dunsinane getting ready for war. He orders the troops to hide behind branches and slowly advance towards the castle. In Act 5.8 he watches the battle against Macbeth and Macduff with Siward and Ross. When eventually Macbeth is killed, Malcolm takes over as king.
The married life of Malcolm III and Margaret has been the subject of two historical novels: "A Goodly Pearl" (1905) by Mary H. Debenham, and "Malcolm Canmore's Pearl" (1907) by Agnes Grant Hay. Both focus on court life in Dunfermline, and the Margaret helping introduce Anglo-Saxon culture in Scotland. The latter novel covers events to 1093, ending with Malcolm's death.
Canmore appears in the third and fourth episodes of the four-part series "City of Stone" in Disney's "Gargoyles", as an antagonist of Macbeth. After witnessing his father Duncan's death, the young Canmore swears revenge on both Macbeth and his gargoyle ally, Demona. After reaching adulthood, he overthrows Macbeth with English allies. Canmore is also the ancestor of the Hunters, a family of vigilantes who hunt Demona through the centuries. Canmore was voiced in the series by J.D. Daniels as a boy and Neil Dickson as an adult.
Ancestry.
Ancestors of Malcolm III of Scotland 
References.
</dl>

</doc>
<doc id="20894" url="http://en.wikipedia.org/wiki?curid=20894" title="Maximum transmission unit">
Maximum transmission unit

In computer networking, the maximum transmission unit (MTU) of a communications protocol of a layer is the size (in bytes) of the largest protocol data unit that the layer can pass onwards. MTU parameters usually appear in association with a communications interface (NIC, serial port, etc.). Standards (Ethernet, for example) can fix the size of an MTU; or systems (such as point-to-point serial links) may decide MTU at connect time.
A larger MTU brings greater efficiency because each network packet carries more user data while protocol overheads, such as headers or underlying per-packet delays, remain fixed; the resulting higher efficiency means an improvement in bulk protocol throughput. A larger MTU also means processing of fewer packets for the same amount of data. In some systems, per-packet-processing can be a critical performance limitation.
However, this gain is not without a downside. Large packets occupy a slow link for more time than a smaller packet, causing greater delays to subsequent packets, and increasing lag and minimum latency. For example, a 1500-byte packet, the largest allowed by Ethernet at the network layer (and hence over most of the Internet), ties up a 14.4k modem for about one second.
Large packets are also problematic in the presence of communications errors. Corruption of a single bit in a packet requires that the entire packet be retransmitted. At a given bit error rate, larger packets are more likely to be corrupt. Their greater payload makes retransmissions of larger packets take longer. Despite the negative effects on retransmission duration, large packets can still have a net positive effect on end-to-end TCP performance.
Table of MTUs of common media.
Note: the MTUs in this section are given as the maximum size of an IP packet that can be transmitted without fragmentation - including IP headers but excluding headers from lower levels in the protocol stack. The MTU must not be confused with the minimum datagram size that all hosts must be prepared to accept, which has a value of 576 bytes for IPv4 and of 1280 bytes for IPv6. It must also not be confused with the size of the physically transmitted "frame". In the case of an Ethernet frame this adds an overhead of 18 bytes, or 22 bytes with an IEEE 802.1Q tag for VLAN or quality of service.
IP (Internet protocol).
DARPA designed the Internet protocol suite to work over many networking technologies, each of which may use packets of different size. While a host will know the MTU of its own interface and possibly that of its peers (from initial handshakes), it will not initially know the lowest MTU in a chain of links to any other peers. Another potential problem is that higher-level protocols may create packets larger than a particular link supports.
To get around this issue, IPv4 allows fragmentation: dividing the datagram into pieces, each small enough to pass over the single link that is being fragmented for, using the MTU parameter configured for that interface. This fragmentation process takes place at the IP layer (OSI layer 3) and marks packets it fragments as such, so that the IP layer of the destination host knows it should reassemble the packets into the original datagram. This method implies a number of possible drawbacks:
The Internet Protocol requires that hosts must be able to process IP datagrams of at least 576 bytes (for IPv4) or 1280 bytes (for IPv6). However, this does not preclude Data Link Layers with an MTU smaller than IP's minimum MTU from conveying IP data. For example, according to IPv6's specification, if a particular Data Link Layer physically cannot deliver an IP datagram of 1280 bytes in a single frame, then the link layer must provide its own fragmentation and reassembly mechanism, separate from IP's own fragmentation mechanism, to ensure that a 1280-byte IP datagram can be delivered, intact, to the IP layer.
Path MTU Discovery.
The Internet Protocol defines the "Path MTU" of an Internet transmission path as the smallest MTU of any of the IP hops of the "path" between a source and destination. Put another way, the path MTU is the largest packet size that can traverse this path without suffering fragmentation.
RFC 1191 (IPv4) and RFC 1981 (IPv6) describe "Path MTU Discovery", a technique for determining the path MTU between two IP hosts. It works by setting the DF (Don't Fragment) option in the IP headers of outgoing packets. Any device along the path whose MTU is smaller than the packet will drop such packets and send back an ICMP "Destination Unreachable (Datagram Too Big)" message containing its MTU. This information allows the source host to reduce its assumed path MTU appropriately. The process repeats until the MTU becomes small enough to traverse the entire path without fragmentation.
Unfortunately, increasing numbers of networks drop ICMP traffic (e.g. to prevent denial-of-service attacks), which prevents path MTU discovery from working. One often detects such blocking in the cases where a connection works for low-volume data but hangs as soon as a host sends a large block of data. For example, with IRC a connecting client might see the initial messages up to and including the initial ping (sent by the server as an anti spoofing measure), but get no response after that. This is because the large set of welcome messages are sent out in packets bigger than the real MTU. Also, in an IP network, the path from the source address to the destination address often gets modified dynamically, in response to various events (load-balancing, congestion, outages, etc.) - this could result in the path MTU changing (sometimes repeatedly) during a transmission, which may introduce further packet drops before the host finds the new safe MTU.
Most Ethernet LANs use an MTU of 1500 bytes (modern LANs can use Jumbo frames, allowing for an MTU up to 9000 bytes); however, border protocols like PPPoE will reduce this. The difference between the MTU seen by end-nodes (e.g. 1500) and the Path MTU causes Path MTU Discovery to come into effect, with the possible result of making some sites behind badly configured firewalls unreachable. One can possibly work around this, depending on which part of the network one controls; for example one can change the MSS (maximum segment size) in the initial packet that sets up the TCP connection at one's firewall.
RFC 4821, Packetization Layer Path MTU Discovery, describes a Path MTU Discovery technique which responds more robustly to ICMP filtering.
MTU in other standards.
The G.hn standard, developed by ITU-T, provides a high-speed (up to 1 Gigabit/s) local area network using existing home wiring (power lines, phone lines and coaxial cables). The G.hn Data Link Layer accepts data frames of up to 214 bytes (16384 bytes). In order to avoid the problem of long data-frames taking up the medium for long periods of time, G.hn defines a procedure for segmentation that divides the data frame into smaller segments.
Disruption.
The transmission of a packet on a physical network segment that is larger than the segment's MTU is known as "jabber". This is almost always caused by faulty devices. Many network switches have a built-in capability to detect when a device is jabbering and block it until it resumes proper operation.

</doc>
<doc id="20895" url="http://en.wikipedia.org/wiki?curid=20895" title="MV Buffalo Soldier (T-AK-9301)">
MV Buffalo Soldier (T-AK-9301)

MV "Buffalo Soldier" (T-AK-9301) is a roll-on/roll-off ship, formerly of the French Government Line (now merged into CMA CGM). She was sold and reflagged US, renamed to honor Buffalo Soldiers, and chartered by the United States Navy Military Sealift Command as a Maritime Prepositioning ship serving at Diego Garcia laden with U.S. Air Force munitions. She is self-sustaining, that is, she can unload herself, an asset in harbors with little or no infrastructure. Her 120-long-ton capacity roll-on/roll-off ramp accommodates tracked and wheeled vehicles of every description. While she is not currently in service with MSC, ships with her general characteristics are designated "Buffalo Soldier" class, fleet designation AK 2222.

</doc>
<doc id="20897" url="http://en.wikipedia.org/wiki?curid=20897" title="Mount Baker">
Mount Baker

Mount Baker (Lummi: "Qwú’mə Kwəlshéːn"; Nooksack: "Kw’eq Smaenit" or "Kwelshán"), also known as Koma Kulshan or simply Kulshan, is an active glaciated andesitic stratovolcano in the Cascade Volcanic Arc and the North Cascades of Washington in the United States. Mount Baker has the second-most thermally active crater in the Cascade Range after Mount Saint Helens. About 31 mi due east of the city of Bellingham, Whatcom County, Mount Baker is the youngest volcano in the Mount Baker volcanic field. While volcanism has persisted here for some 1.5 million years, the current glaciated cone is likely no more than 140,000 years old, and possibly no older than 80-90,000 years. Older volcanic edifices have mostly eroded away due to glaciation.
After Mount Rainier, Mount Baker is the most heavily glaciated of the Cascade Range volcanoes; the volume of snow and ice on Mount Baker, 0.43 cumi is greater than that of all the other Cascades volcanoes (except Rainier) combined. It is also one of the snowiest places in the world; in 1999, Mount Baker Ski Area, located 14 km to the northeast, set the world record for recorded snowfall in a single season—1140 in.
At 10781 ft, it is the third-highest mountain in Washington State and the fifth-highest in the Cascade Range, if Little Tahoma Peak, a subpeak of Mount Rainier, and Shastina, a subpeak of Mount Shasta, are not counted. Located in the Mount Baker Wilderness, it is visible from much of Greater Victoria, Greater Vancouver, and, to the south, from Seattle (and on clear days Tacoma) in Washington.
Indigenous natives have known the mountain for thousands of years, but the first written record of the mountain is from the Spanish. 
Spanish explorer Gonzalo Lopez de Haro mapped it in 1790 as the "Gran Montaña del Carmelo", "Great Mount Carmel". The explorer George Vancouver renamed the mountain for 3rd Lieutenant Joseph Baker of HMS "Discovery", who saw it on April 30, 1792.
History.
Mount Baker was well-known to indigenous people of the Pacific Northwest. Indigenous names for the mountain include Koma Kulshan or Kulshan (Lummi, "qwú’mə", "white sentinel", "i.e." "mountain", and "kwəlshé:n", "puncture wound", "i.e." "crater"); Quck Sam-ik (Nooksack: "kw’eq sámit", "white mountain"); Kobah (Skagit: "qwúbə’", "white sentinel", i.e. "mountain"); and Tukullum or Nahcullum (in the language of the unidentified "Koma tribe"). By one interpretation, Mount Rainier, called "Tacoma", effectively means "larger than Koma (Kulshan)" - however, most scholars agree that Tacoma actually means "Mother of all waters".
In 1790, Manuel Quimper of the Spanish Navy set sail from Nootka, a temporary settlement on Vancouver Island, with orders to explore the newly discovered Strait of Juan de Fuca. Accompanying Quimper was first-pilot Gonzalo Lopez de Haro, who drew detailed charts during the six-week expedition. Although Quimper's journal of the voyage does not refer to the mountain, one of Haro's manuscript charts includes a sketch of Mount Baker. The Spanish named the snowy volcano "La Gran Montana del Carmelo", as it reminded them of the white-clad monks of the Carmelite Monastery.
The British explorer George Vancouver left England a year later. His mission was to survey the northwest coast of America. Vancouver and his crew reached the Pacific Northwest coast in 1792. While anchored in Dungeness Bay on the south shore of the Strait of Juan de Fuca, third lieutenant Joseph Baker made an observation of Mount Baker, which Vancouver recorded in his journal:About this time a very high conspicuous craggy mountain ... presented itself, towering above the clouds: as low down as they allowed it to be visible it was covered with snow; and south of it, was a long ridge of very rugged snowy mountains, much less elevated, which seemed to stretch to a considerable distance ... the high distant land formed, as already observed, like detached islands, amongst which the lofty mountain, discovered in the afternoon by the third lieutenant, and in compliment to him called by me Mount Baker, rose a very conspicuous object ... apparently at a very remote distance.
Six years later, the official narrative of this voyage was published, including the first printed reference to the mountain. By the mid-1850s, Mount Baker was a well-known feature on the horizon to the explorers and fur traders who traveled in the Puget Sound region. Isaac I. Stevens, the first governor of Washington Territory, wrote about Mount Baker in 1853:Mount Baker ... is one of the loftiest and most conspicuous peaks of the northern Cascade range; it is nearly as high as Mount Rainier, and like that mountain, its snow-covered pyramid has the form of a sugar-loaf. It is visible from all the water and islands ... [in Puget Sound] and from the whole southeastern part of the Gulf of Georgia, and likewise from the eastern division of the Strait of Juan de Fuca. It is for this region a natural and important landmark.
Climbing history.
First ascent.
Edmund Thomas Coleman, an Englishman who resided in Victoria, British Columbia, Canada and a veteran of the Alps, made the first attempt to ascend the mountain in 1866. He chose a route via the Skagit River, but was forced to turn back when local Native Americans refused him passage.
Later that same year, Coleman recruited Whatcom County settlers Edward Eldridge, John Bennett and John Tennant to aid him in his second attempt to scale the mountain. After approaching via the North Fork of the Nooksack River, the party navigated through what is now known as Coleman Glacier and ascended to within several hundred feet of the summit before turning back in the face of an "overhanging cornice of ice" and threatening weather. Coleman later returned to the mountain after two years. At 4:00 p.m. on August 17, 1868, Coleman, Eldridge, Tennant and two new companions (David Ogilvy and Thomas Stratton) scaled the summit via the Middle Fork Nooksack River, Marmot Ridge, Coleman Glacier, and the north margin of the Roman Wall.
Geology.
The present-day cone of Mount Baker is relatively young; it is perhaps less than 100,000 years old. The volcano sits atop a similar older volcanic cone called Black Buttes, which was active between 500,000 and 300,000 years ago. Much of Mount Baker's earlier geological record eroded away during the last ice age (which culminated 15,000–20,000 years ago), by thick ice sheets that filled the valleys and surrounded the volcano. In the last 14,000 years, the area around the mountain has been largely ice-free, but the mountain itself remains heavily covered with snow and ice.
Isolated ridges of lava and hydrothermally altered rock, especially in the area of Sherman Crater, are exposed between glaciers on the upper flanks of the volcano; the lower flanks are steep and heavily vegetated. Volcanic rocks of Mount Baker and Black Buttes rest on a foundation of non-volcanic rocks.
Deposits recording the last 14,000 years at Mount Baker indicate that Mount Baker has not had highly explosive eruptions like those of other volcanoes in the Cascade Volcanic Arc, such as Mount St. Helens, Mount Meager or Glacier Peak, nor has it erupted frequently. During this period, four episodes of magmatic eruptive activity have been recently recognized.
Magmatic eruptions have produced tephra, pyroclastic flows, and lava flows from summit vents and the Schriebers Meadow cinder cone. The most destructive and most frequent events at Mount Baker have been lahars or debris flows and debris avalanches; many, if not most, of these were not related to magmatic eruptions but may have been induced by magma intrusion, steam eruptions, earthquakes, gravitational instability, or possibly even heavy rainfall.
Eruptive history.
Early history.
Research beginning in the late 1990s shows that Mount Baker is the youngest of several volcanic centers in the area and one of the youngest volcanoes in the Cascade Range. The Pliocene Hannegan caldera is preserved 25 km northeast of Mount Baker Volcanic activity in the Mount Baker volcanic field began more than one million years ago, but many of the earliest lava and tephra deposits have been removed by glacial erosion. The pale-colored rocks northeast of the modern volcano mark the site of the ancient (1.15 million years old) Kulshan caldera that collapsed after an enormous ash eruption one million years ago. Subsequently, eruptions in the Mount Baker area have produced cones and lava flows of andesite, the rock that constitutes much of other Cascade Range volcanoes such as Rainier, Adams, and Hood. From about 900,000 years ago to the present, numerous andesitic volcanic centers in the area have come and disappeared through glacial erosion. The largest of these cones is the Black Buttes edifice, active between 500,000 and 300,000 years ago and formerly bigger than today's Mount Baker.
Modern craters and cone.
Mount Baker was built from stacks of lava and volcanic breccia prior to the end of the last glacial period, which ended about 15,000 years ago. There are two craters on the mountain. Ice-filled Carmelo Crater is under the summit ice dome. This crater is the source for the last cone-building eruptions
The highest point of Mount Baker, Grant Peak, is on the exposed southeast rim of Carmelo Crater, which is a small pile of andesitic scoria lying on top of a stack of lava flows just below. Carmelo Crater is deeply dissected on its south side by the younger Sherman Crater. This crater is south of the summit, and its ice-covered floor is 1000 ft below the summit ice dome. This crater is the site of all Holocene eruptive activity. Hundreds of fumaroles vent gases, primarily H2O, CO2, and H2S.
Lava flows from the summit vent erupted between 30,000 and 10,000 years ago and, during the final stages of edifice construction, blocky pyroclastic flows entered the volcano's southeastern drainages. An eruption from Sherman Crater 6,600 years ago erupted a blanket of ash that extended more than 40 mi to the east. Today, sulfurous gases reach the surface via two fumarole pathways: Dorr Fumarole, northeast of the summit; and Sherman Crater, south of the summit. Both are sites of hydrothermal alteration, converting lavas to weak, white-to-yellow clays; sulfur is a common mineral around these fumaroles. At Sherman Crater, collapses of this weakened rock generated lahars in the 1840s.
Mazama Park eruptive period: 6,600 years ago.
Approximately 6,600 years ago, a series of discrete events culminated in the largest tephra-producing eruption in post-glacial time at Mount Baker. This is the last episode of undoubted magmatic activity preserved in the geologic record. First, the largest collapse in the history of the volcano occurred from the Roman Wall and transformed into a lahar that was over 300 ft deep in the upper reaches of the Middle Fork of the Nooksack River. It was at least 25 ft deep 30 mi downstream from the volcano. At that time the Nooksack River is believed to have drained north into the Fraser River; it is therefore unlikely that this lahar reached Bellingham Bay. Next, a small hydrovolcanic eruption occurred at Sherman Crater, triggering a second collapse of the flank just east of the Roman Wall. That collapse also became a lahar that mainly followed the course of the first lahar for at least 20 mi, and also spilled into tributaries of the Baker River. Finally, an eruption cloud deposited ash as far as 40 mi downwind to the northeast and east.
Historical activity.
Several eruptions occurred from Sherman Crater during the 19th century; they were witnessed from the Bellingham area. A possible eruption was seen in June 1792 during the Spanish expedition of Dionisio Alcalá Galiano and Cayetano Valdés. Their report read, in part:During the night [while anchored in Bellingham Bay] we constantly saw light to the south and east of the mountain of Carmelo [Baker] and even at times some bursts of flame, signs which left no doubt that there are volcanoes with strong eruptions in those mountains.
In 1843, explorers reported a widespread layer of newly fallen rock fragments "like a snowfall" and that the forest was "on fire for miles around". It is highly unlikely that these fires were caused by ashfall, however, as charred material is not found with deposits of this fine-grained volcanic ash, which was almost certainly cooled in the atmosphere before falling. Rivers south of the volcano were reportedly clogged with ash, and Native Americans reported that many salmon perished. Reports of flooding on the Skagit River from the eruption are, however, probably greatly exaggerated. A short time later, two collapses of the east side of Sherman Crater produced two lahars, the first and larger of which flowed into the natural Baker Lake, increasing its level by at least 10 ft. The location of the 19th-century lake is now covered by waters of the modern dam-impounded Baker Lake. Similar but lower level hydrovolcanic activity at Sherman Crater continued intermittently for several decades afterward. On 26 November 1860, passengers who were traveling by steamer from New Westminster to Victoria reported that Mount Baker was "puffing out large volumes of smoke, which upon breaking, rolled down the snow-covered sides of the mountain, forming a pleasing effect of light and shade." In 1891, about 15 km3 of rock fell producing a lahar that traveled more than 6 mi and covered 1 sqmi.
Activity in the 20th century decreased from the 19th century. Numerous small debris avalanches fell from Sherman Peak and descended the Boulder Glacier; a large one occurred on July 27, 2007. In early March 1975, a dramatic increase in fumarolic activity and snow melt in the Sherman Crater area raised concern that an eruption might be imminent. Heat flow increased more than tenfold. Additional monitoring equipment was installed and several geophysical surveys were conducted to try to detect the movement of magma. The increased thermal activity prompted public officials and Puget Power to temporarily close public access to the popular Baker Lake recreation area and to lower the reservoir's water level by 10 m. If those actions had not been taken, significant avalanches of debris from the Sherman Crater area could have swept directly into the reservoir, triggering a disastrous wave that could have caused human fatalities and damage to the reservoir. Other than the increased heat flow, few anomalies were recorded during the geophysical surveys, nor were any other precursory activities observed that would indicate that magma was moving up into the volcano. Several small lahars formed from material ejected onto the surrounding glaciers and acidic water was discharged into Baker Lake for many months.
Activity gradually declined over the next two years but stabilized at a higher level than before 1975. The increased level of fumarolic activity has continued at Mount Baker since 1975, but no other changes suggest that magma movement is involved.
Current research at Mount Baker.
A considerable amount of research has been done at Mount Baker over the past decade, and it is now among the most-studied of the Cascade volcanoes. Recent and ongoing projects include gravimetric and GPS-based geodetic monitoring, fumarole gas sampling, tephra distribution mapping, new interpretations of the Schriebers Meadow lava flow, and hazards analyses. Mapping of Carmelo and Sherman craters, and interpretations of the eruptive history, continues, as well. The Mount Baker Volcano Research Center maintains an online archive of abstracts of this work, and an extensive references list, as well as photos.
Glaciers and hydrology.
There are ten main glaciers on the mountain. The Coleman Glacier is the largest; it has a surface area of 5.2 km2. The other large glaciers—which have areas greater than 2.5 km2—are Roosevelt Glacier, Mazama Glacier, Park Glacier, Boulder Glacier, Easton Glacier and Deming Glacier. All retreated during the first half of the century, advanced from 1950–1975 and have been retreating increasingly rapidly since 1980.
Mount Baker is drained on the north by streams that flow into the North Fork Nooksack River, on the west by the Middle Fork Nooksack River, and on the southeast and east by tributaries of the Baker River. Lake Shannon and Baker Lake are the largest nearby bodies of water, formed by two dams on the Baker River.
U.S. Navy.
Two ammunition ships of the United States Navy (traditionally named for volcanoes) have been named after the mountain. The first was USS "Mount Baker" (AE-4), which was commissioned from 1941 to 1947 and from 1951 to 1969. In 1972, the Navy commissioned USS "Mount Baker" (AE-34). It was decommissioned in 1996 and placed in service with the Military Sealift Command as USNS "Mount Baker" (T-AE-34). She was scrapped in 2012.

</doc>
<doc id="20898" url="http://en.wikipedia.org/wiki?curid=20898" title="Maritime prepositioning ship">
Maritime prepositioning ship

The 31 maritime prepositioning ships (MPS) are part of the United States Military Sealift Command's (MSC) Prepositioning Program. They are strategically positioned around the globe to support the Army, Navy, Air Force, Marine Corps and Defense Logistics Agency. Most are named after Medal of Honor recipients from the service they support.
The MPS ships are assigned to three maritime prepositioning ship squadrons located in the Mediterranean, the Indian Ocean at Diego Garcia and the Western Pacific Ocean at Guam and Saipan. The MPS ships in each squadron have sufficient equipment, supplies and ammunition to support a Marine Air-Ground Task Force for 30 days. The MPS ships are self-sustaining, with cranes to unload at sea or pierside.
MSC chartered the first two ship classes in the MPS role (the "Corporal Louis J. Hauge, Jr." and "Sergeant Matej Kocak" classes) from civilian shipping lines and converted them. Later ships were purpose-built.
Ships.
"Sergeant Matej Kocak" Class.
The "Sergeant Matej Kocak" Class, the second class of MPS ships chartered by MSC, also gained 157 feet (48 m) amidships and a helicopter deck after conversion. These ships, delivered to MSC in the mid-1980s, built at Sun Shipbuilding & Drydock Co., Chester, Pennsylvania and converted at National Steel and Shipbuilding Company, San Diego. They were previously owned by Waterman Steamship Corporation but recently sold to MSC and now operated by Keystone Shipping Co.
"2nd Lieutenant John P. Bobo" Class.
The "2nd Lieutenant John P. Bobo" Class ships are new construction ships delivered to MSC in the mid-1980s from General Dynamics Quincy Shipbuilding Division, Quincy, Mass. They were owned by American Overseas Marine (AMSEA) but have been recently sold to MSC and are now operated by Maersk Line, Limited.
Large, Medium-Speed Roll-on/Roll-off Ships.
"Watson" Class.
The Watson Class are a class of LMSR built at National Steel and Shipbuilding Company in San Diego
Activated Ready Reserve Fleet Ships.
The following are part of the National Defense Reserve Fleet but have been activated and are pre-positioned.
"Wright" Class.
Dedicated to USMC aviation logistics support.
Former Ships.
"Corporal Louis J. Hauge, Jr." class.
The "Corporal Louis J. Hauge, Jr." Class is the original class of MPS ships chartered by Military Sealift Command. The five ships are Maersk Line ships converted by Bethlehem Steel. During conversion, the ships gained an additional 157 feet (48 m) amidships and a helicopter landing pad, among other things. They have since been returned to Maersk for commercial use and are no longer part of the MPS program.

</doc>
<doc id="20900" url="http://en.wikipedia.org/wiki?curid=20900" title="Mathias Rust">
Mathias Rust

Mathias Rust (born 1 June 1968) is a German aviator known for his illegal landing near Red Square in Moscow on 28 May 1987. An amateur pilot, he flew from Finland to Moscow, being tracked several times by Soviet air defence and interceptors. The Soviet fighters never received permission to shoot him down, and several times he was mistaken for a friendly aircraft. He landed on Vasilevsky Descent next to Red Square near the Kremlin in the capital of the Soviet Union.
Rust said he wanted to create an "imaginary bridge" to the East, and he has claimed that his flight was intended to reduce tension and suspicion between the two Cold War sides. Rust's flight through a supposedly impregnable air defense system had great effect on the Soviet military and led to the dismissal of many senior officers, including Minister of Defence Marshal of the Soviet Union Sergei Sokolov and the Commander-in-Chief of the Soviet Air Defence Forces, former World War II fighter ace pilot Chief Marshal Alexander Koldunov. The incident aided Mikhail Gorbachev in the implementation of his reforms, by allowing him to dismiss numerous military officials opposed to him whilst reducing the prestige of the Soviet military among the populace, thus helping bring an end to the Cold War.
Flight profile.
Rust, aged 18, was an inexperienced pilot, with about 50 hours of flying experience at the time of his flight. On 13 May 1987, Rust left Uetersen near Hamburg and his home town Wedel in his rented Reims Cessna F172P D-ECJB, which was modified by removing some of the seats and replacing them with auxiliary fuel tanks. He spent the next two weeks traveling across Northern Europe, visiting the Faroe islands, spending a week in Iceland, and then visiting Bergen on his way back. He was later quoted as saying that he had had the idea of attempting to reach Moscow even before the departure, and he saw the trip to Iceland (where he visited Hofdi House, the site of unsuccessful talks between the United States and the Soviet Union in October 1986) as a way to test his piloting skills.
In the morning of 28 May 1987, Rust refueled at Helsinki-Malmi Airport. He told air traffic control that he was going to Stockholm, and took off at 12:21 p.m. However, immediately after his final communication with traffic control he turned his plane to the east. Air controllers tried to contact him as he was moving around the busy Helsinki–Moscow route, but Rust turned off all communications equipment aboard.
Rust disappeared from the Finnish air traffic radar near Sipoo. Control personnel presumed an emergency and a rescue effort was organized, including a Finnish Border Guard patrol boat. They found an oil patch near the place where Rust disappeared from radar and performed an underwater search with no results. Rust was later fined about €77,500 ($105,000 USD) for this effort. The origin of the oil patch remains unknown.
Rust crossed the Baltic coastline over Estonia and turned towards Moscow. At 14:29 he appeared on Soviet Air Defense (PVO) radar and, after failure to reply to an IFF signal, was assigned combat number 8255. Three SAM divisions tracked him for some time, but failed to obtain permission to launch at him. All air defenses were brought to readiness and two interceptors were sent to investigate. At 14:48 near the city of Gdov one of the pilots observed a white sport plane similar to a Yakovlev Yak-12 and asked for permission to engage, but was denied.
The fighters lost contact with Rust soon after this. While they were being directed back to him he disappeared from radar near Staraya Russa. West German magazine "Bunte" speculated that he might have landed there for some time, citing that he changed his clothes somewhere during his flight and that he took too much time to fly to Moscow considering his plane's speed and the weather conditions.
Air defense re-established contact with Rust's plane several times but confusion followed all of these events. The PVO system had shortly before been divided into several districts, which simplified management but created additional overhead for tracking officers at the districts' borders. The local air regiment near Pskov was on maneuvers and, due to inexperienced pilots' tendency to forget correct IFF designator settings, local control officers assigned all traffic in the area friendly status, including Rust.
Near Torzhok there was a similar situation, as increased air traffic was created by a rescue effort for an air crash the previous day. Rust, flying a slow propeller-driven aircraft, was confused with one of the helicopters taking part in the rescue. He was spotted several more times and given false friendly recognition twice. Rust was considered as a domestic training plane defying regulations, and was issued least priority.
Around 7:00 p.m. Rust appeared above downtown Moscow. He had initially intended to land in the Kremlin, but changed his mind: he reasoned that landing inside, hidden by the Kremlin walls, would have allowed the KGB to simply arrest him and deny the incident. Therefore, he changed his landing spot to Red Square. Heavy pedestrian traffic did not allow him to land there either, so after circling about the square one more time, he was able to land on a bridge by St. Basil's Cathedral. A later inquiry found that trolley wires normally strung over the bridge—which would have incidentally prevented his landing there—had been removed for maintenance that very morning, and were replaced the day after. After taxiing past the cathedral he stopped about 100 m from the square, where he was greeted by curious passersby and was asked for autographs. A British doctor videotaped Rust circling over Red Square and landing on the bridge. Rust was arrested two hours later.
Aftermath.
Rust's trial began in Moscow on 2 September 1987. He was sentenced to four years in a general-regime labor camp for hooliganism, for disregard of aviation laws, and for breaching the Soviet border. He was never transferred to a labor camp, however, and instead served his time at the high security Lefortovo temporary detention facility in Moscow. Two months later, Reagan and Gorbachev agreed to sign a treaty to eliminate intermediate-range nuclear weapons in Europe, and the Supreme Soviet ordered Rust to be released in August 1988 as a goodwill gesture to the West.
Rust's return to Germany on 3 August 1988 was accompanied by huge media attention, but he did not talk to the assembled journalists; his family had sold the exclusive rights to the story to the German magazine "Stern" for DM 100,000. He reported that he had been treated well in the Soviet prison. Journalists described him as "psychologically unstable and unworldly in a dangerous manner".
William E. Odom, former director of the U.S. National Security Agency and author of "The Collapse of the Soviet Military", says that Rust's flight irreparably damaged the reputation of the Soviet military. This enabled Gorbachev to remove many of the strongest opponents to his reforms. Minister of Defence Sergei Sokolov and the head of the Soviet Air Defence Forces Alexander Koldunov were dismissed along with hundreds of other officers. This was the biggest turnover in the Soviet military since Stalin's purges 50 years earlier.
Rust's rented Reims Cessna F172P (serial # F17202087), registered "D-ECJB", was sold to Japan where it was exhibited for several years. In 2008 it was returned to Germany and was placed in the Deutsches Technikmuseum in Berlin.
Later life.
While doing his obligatory community service ("Zivildienst") in a West German hospital in 1989, Rust stabbed a female co-worker who had rejected him. The victim barely survived. He was convicted of attempted manslaughter and sentenced to two and a half years in prison, but was released after 15 months. Since then he has lived a fragmented life, describing himself as a "bit of an oddball." After being released from court, he converted to Hinduism in 1996 to become engaged to a daughter of an Indian tea merchant. In 2001, he was convicted of stealing a cashmere pullover and ordered to pay a fine of DM 10,000, which was later reduced to DM 600. A further brush with the law came in 2005, when he was convicted of fraud and had to pay €1,500 for stolen goods. In 2009 Rust described himself as a professional poker player. Most recently, in 2012, he described himself as an analyst at a Zurich-based investment bank.
In popular culture.
Because Rust's flight seemed as a blow to the authority of the Soviet regime, it was the source of numerous jokes and urban legends. For a while after the incident, Red Square was jokingly referred to by Muscovites as Sheremetyevo-3 (Sheremetyevo-1 and -2 being the two terminals at Moscow's main international airport). At the end of 1987, the police radio code used by law enforcement officers in Moscow was allegedly updated to include a code for an aircraft landing.
Shortly after the incident, SubLogic, the original publishers of the "Flight Simulator" franchise, issued a scenery disk that expanded the original program's coverage area to include the Eastern Bloc. A challenge in the expansion pack was to land in Red Square as Rust had just done.
In the media.
Following the 20th anniversary of his flight on 28 May 2007, the international media interviewed Rust about the flight and its aftermath.
"The Washington Post" and "Bild" both have online editions of their interviews. The most comprehensive televised interview available online is produced by the Danish Broadcasting Corporation. In their interview "Rust in Red Square", recorded in May 2007, Rust gives a full account of the flight in English.

</doc>
<doc id="20901" url="http://en.wikipedia.org/wiki?curid=20901" title="Malware">
Malware

Malware, short for malicious software, is any software used to disrupt computer operation, gather sensitive information, or gain access to private computer systems. Malware is defined by its malicious intent, acting against the requirements of the computer user, and does not include software that causes unintentional harm due to some deficiency. The term "badware" is sometimes used, and applied to both true (malicious) malware and unintentionally harmful software.
Malware may be stealthy, intended to steal information or spy on computer users for an extended period without their knowledge, as for example Regin, or it may be designed to cause harm, often as sabotage (e.g., Stuxnet), or to extort payment (CryptoLocker). 'Malware' is an umbrella term used to refer to a variety of forms of hostile or intrusive software, including computer viruses, worms, trojan horses, ransomware, spyware, adware, scareware, and other malicious programs. It can take the form of executable code, scripts, active content, and other software. Malware is often disguised as, or embedded in, non-malicious files. s of 2011[ [update]] the majority of active malware threats were worms or trojans rather than viruses.
In law, malware is sometimes known as a computer contaminant, as in the legal codes of several U.S. states.
Spyware or other malware is sometimes found embedded in programs supplied officially by companies, e.g., downloadable from websites, that appear useful or attractive, but may have, for example, additional hidden tracking functionality that gathers marketing statistics. An example of such software, which was described as illegitimate, is the Sony rootkit, a Trojan embedded into CDs sold by Sony, which silently installed and concealed itself on purchasers' computers with the intention of preventing illicit copying; it also reported on users' listening habits, and unintentionally created vulnerabilities that were exploited by unrelated malware.
Software such as anti-virus, anti-malware, and firewalls are used to protect against activity identified as malicious, and to recover from attacks.
Purposes.
Many early infectious programs, including the first Internet Worm, were written as experiments or pranks. Today, malware is used by both black hat hackers and governments, to steal personal, financial, or business information.
Malware is sometimes used broadly against government or corporate websites to gather guarded information, or to disrupt their operation in general. However, malware is often used against individuals to gain information such as personal identification numbers or details, bank or credit card numbers, and passwords. Left unguarded, personal and networked computers can be at considerable risk against these threats. (These are most frequently defended against by various types of firewall, anti-virus software, and network hardware).
Since the rise of widespread broadband Internet access, malicious software has more frequently been designed for profit. Since 2003, the majority of widespread viruses and worms have been designed to take control of users' computers for illicit purposes. Infected "zombie computers" are used to send email spam, to host contraband data such as child pornography, or to engage in distributed denial-of-service attacks as a form of extortion.
Programs designed to monitor users' web browsing, display unsolicited advertisements, or redirect affiliate marketing revenues are called spyware. Spyware programs do not spread like viruses; instead they are generally installed by exploiting security holes. They can also be packaged together with user-installed software, such as peer-to-peer applications.
Ransomware affects an infected computer in some way, and demands payment to reverse the damage. For example, programs such as CryptoLocker encrypt files securely, and only decrypt them on payment of a substantial sum of money.
Some malware is used to generate money by click fraud, making it appear that the computer user has clicked an advertising link on a site, generating a payment from the advertiser. It was estimated in 2012 that about 60 to 70% of all active malware used some kind of click fraud, and 22% of all ad-clicks were fraudulent.
Malware is usually used for criminal purposes, but can be used for sabotage, often without direct benefit to the perpetrators. One example of sabotage was Stuxnet, used to destroy very specific industrial equipment. There have been politically-motivated attacks that have spread over and shut down large computer networks, including massive deletion of files and corruption of master boot records, described as "computer killing". Such attacks were made on Sony Pictures Entertainment (25 November 2014, using malware known as Shamoon or W32.Disttrack) and Saudi Aramco (August 2012).
Proliferation.
Preliminary results from Symantec published in 2008 suggested that "the release rate of malicious code and other unwanted programs may be exceeding that of legitimate software applications." According to F-Secure, "As much malware [was] produced in 2007 as in the previous 20 years altogether." Malware's most common pathway from criminals to users is through the Internet: primarily by e-mail and the World Wide Web.
The prevalence of malware as a vehicle for Internet crime, along with the challenge of anti-malware software to keep up with the continuous stream of new malware, has seen the adoption of a new mindset for individuals and businesses using the Internet. With the amount of malware currently being distributed, some percentage of computers are currently assumed to be infected. For businesses, especially those that sell mainly over the Internet, this means they need to find a way to operate despite security concerns. The result is a greater emphasis on back-office protection designed to protect against advanced malware operating on customers' computers. A 2013 Webroot study shows that 64% of companies allow remote access to servers for 25% to 100% of their workforce and that companies with more than 25% of their employees accessing servers remotely have higher rates of malware threats.
On 29 March 2010, Symantec Corporation named Shaoxing, China, as the world's malware capital. A 2011 study from the University of California, Berkeley, and the Madrid Institute for Advanced Studies published an article in "Software Development Technologies", examining how entrepreneurial hackers are helping enable the spread of malware by offering access to computers for a price. Microsoft reported in May 2011 that one in every 14 downloads from the Internet may now contain malware code. Social media, and Facebook in particular, are seeing a rise in the number of tactics used to spread malware to computers.
A 2014 study found that malware was increasingly aimed at the ever more popular mobile devices such as smartphones.
Infectious malware: viruses and worms.
The best-known types of malware, viruses and worms, are known for the manner in which they spread, rather than any specific types of behavior. The term "computer virus" is used for a program that embeds itself in some other executable software (including the operating system itself) on the target system without the user's consent and when that is run causes the virus to spread to other executables. On the other hand, a "worm" is a stand-alone malware program that "actively" transmits itself over a network to infect other computers. These definitions lead to the observation that a virus requires the user to run an infected program or operating system for the virus to spread, whereas a worm spreads itself.
Concealment: Viruses, trojan horses, rootkits, and backdoors.
(These categories are not mutually exclusive.) This section only applies to malware designed to operate undetected, not sabotage and ransomware.
Viruses.
A computer program usually hidden within another seemingly innocuous program that produces copies of itself and inserts them into other programs or files, and that usually performs a malicious action (such as destroying data).
Trojan horses.
For a malicious program to accomplish its goals, it must be able to run without being detected, shut down, or deleted. When a malicious program is disguised as something normal or desirable, users may unwittingly install it. This is the technique of the "Trojan horse" or "trojan". In broad terms, a Trojan horse is any program that invites the user to run it, concealing harmful or malicious executable code of any description. The code may take effect immediately and can lead to many undesirable effects, such as encrypting the user's files or downloading and implementing further malicious functionality.
In the case of some spyware, adware, etc. the supplier may require the user to acknowledge or accept its installation, describing its behavior in loose terms that may easily be misunderstood or ignored, with the intention of deceiving the user into installing it without the supplier technically in breach of the law.
Rootkits.
Once a malicious program is installed on a system, it is essential that it stays concealed, to avoid detection. Software packages known as "rootkits" allow this concealment, by modifying the host's operating system so that the malware is hidden from the user. Rootkits can prevent a malicious process from being visible in the system's list of processes, or keep its files from being read.
Some malicious programs contain routines to defend against removal, not merely to hide themselves. An early example of this behavior is recorded in the Jargon File tale of a pair of programs infesting a Xerox CP-V time sharing system:
Backdoors.
A backdoor is a method of bypassing normal authentication procedures, usually over a connection to a network such as the Internet. Once a system has been compromised, one or more backdoors may be installed in order to allow access in the future, invisibly to the user.
The idea has often been suggested that computer manufacturers preinstall backdoors on their systems to provide technical support for customers, but this has never been reliably verified. It was reported in 2014 that US government agencies had been diverting computers purchased by those considered "targets" to secret workshops where software or hardware permitting remote access by the agency was installed, considered to be among the most productive operations to obtain access to networks around the world. Backdoors may be installed by Trojan horses, worms, implants, or other methods.
Vulnerability to malware.
Security defects in software.
Malware exploits security defects (security bugs or vulnerabilities) in the design of the operating system, in applications (such as browsers, e.g. older versions of Microsoft Internet Explorer supported by Windows XP), or in vulnerable versions of browser plugins such as Adobe Flash Player, Adobe Acrobat or Reader, or (see Java SE critical security issues). Sometimes even installing new versions of such plugins does not automatically uninstall old versions. Security advisories from plug-in providers announce security-related updates. Common vulnerabilities are assigned CVE IDs and listed in the US National Vulnerability Database. Secunia PSI is an example of software, free for personal use, that will check a PC for vulnerable out-of-date software, and attempt to update it.
Malware authors target bugs, or loopholes, to exploit. A common method is exploitation of a buffer overrun vulnerability, where software designed to store data in a specified region of memory does not prevent more data than the buffer can accommodate being supplied. Malware may provide data that overflows the buffer, with malicious executable code or data after the end; when this payload is accessed it does what the attacker, not the legitimate software, determines.
Insecure design or user error.
Early PCs had to be booted from floppy disks; when built-in hard drives became common the operating system was normally started from them, but it was possible to boot from another boot device if available, such as a floppy disk, CD-ROM, DVD-ROM, or USB flash drive. It was common to configure the computer to boot from one of these devices when available. Normally none would be available; the user would intentionally insert, say, a CD into the optical drive to boot the computer in some special way, for example to install an operating system. Even without booting, computers can be configured to execute software on some media as soon as they become available, e.g. to autorun a CD or USB device when inserted.
Malicious software distributors would trick the user into booting or running from an infected device or medium; for example, a virus could make an infected computer add autorunnable code to any USB stick plugged into it; anyone who then attached the stick to another computer set to autorun from USB would in turn become infected, and also pass on the infection in the same way. More generally, any device that plugs into a USB port-—"including gadgets like lights, fans, speakers, toys, even a digital microscope"—can be used to spread malware. Devices can be infected during manufacturing or supply if quality control is inadequate.
This form of infection can largely be avoided by setting up computers by default to boot from the internal hard drive, if available, and not to autorun from devices. Intentional booting from another device is always possible by pressing certain keys during boot.
Older email software would automatically open HTML email containing potentially malicious JavaScript code; users may also execute disguised malicious email attachments and infected executable files supplied in other ways.
Over-privileged users and over-privileged code.
In computing, privilege refers to how much a user or program is allowed to modify a system. In poorly designed computer systems, both users and programs can be assigned more privileges than they should be, and malware can take advantage of this. The two ways that malware does this is through overprivileged users and overprivileged code.
Some systems allow all users to modify their internal structures, and such users today would be considered over-privileged users. This was the standard operating procedure for early microcomputer and home computer systems, where there was no distinction between an "administrator" or "root", and a regular user of the system. In some systems, non-administrator users are over-privileged by design, in the sense that they are allowed to modify internal structures of the system. In some environments, users are over-privileged because they have been inappropriately granted administrator or equivalent status.
Some systems allow code executed by a user to access all rights of that user, which is known as over-privileged code. This was also standard operating procedure for early microcomputer and home computer systems. Malware, running as over-privileged code, can use this privilege to subvert the system. Almost all currently popular operating systems, and also many scripting applications allow code too many privileges, usually in the sense that when a user executes code, the system allows that code all rights of that user. This makes users vulnerable to malware in the form of e-mail attachments, which may or may not be disguised.
Anti-malware strategies.
As malware attacks become more frequent, attention has begun to shift from viruses and spyware protection, to malware protection, and programs that have been specifically developed to combat malware. (Other preventive and recovery measures, such as backup and recovery methods, are mentioned in the computer virus article).
Anti-virus and anti-malware software.
A specific component of the anti-virus and anti-malware software commonly referred as the on-access or real-time scanner, hooks deep into the operating system's core or kernel functions in a manner similar to how certain malware itself would attempt to operate, though with the user's informed permission for protecting the system. Any time the operating system accesses a file, the on-access scanner checks if the file is a 'legitimate' file or not. If the file is considered malware by the scanner, the access operation will be stopped, the file will be dealt by the scanner in pre-defined way (how the anti-virus program was configured during/post installation) and the user will be notified. This may considerably slow down the operating system depending on how well the scanner was programmed. The goal is to stop any operations the malware may attempt on the system before they occur, including activities which might exploit bugs or trigger unexpected operating system behavior.
Anti-malware programs can combat malware in two ways:
Real-time protection from malware works identically to real-time antivirus protection: the software scans disk files at download time, and blocks the activity of components known to represent malware. In some cases, it may also intercept attempts to install start-up items or to modify browser settings. Because many malware components are installed as a result of browser exploits or user error, using security software (some of which are anti-malware, though many are not) to "sandbox" browsers (essentially isolate the browser from the computer and hence any malware induced change) can also be effective in helping to restrict any damage done.
Examples of Microsoft Windows antivirus and anti-malware software include the optional Microsoft Security Essentials (for Windows XP, Vista, and Windows 7) for real-time protection, the Windows Malicious Software Removal Tool (now included with Windows (Security) Updates on "Patch Tuesday", the second Tuesday of each month), and Windows Defender (an optional download in the case of Windows XP, incorporating MSE functionality in the case of Windows 8 and later). Additionally, several capable antivirus software programs are available for free download from the Internet (usually restricted to non-commercial use). Tests found some free programs to be competitive with commercial ones. Microsoft's System File Checker can be used to check for and repair corrupted system files.
Some viruses disable System Restore and other important Windows tools such as Task Manager and Command Prompt. Many such viruses can be removed by rebooting the computer, entering Windows safe mode with networking, and then using system tools or Microsoft Safety Scanner.
Hardware implants can be of any type, so there can be no general way to detect them.
Known good.
Typical malware products detect issues based on heuristics or signatures – i.e., based on information that can be assessed to be bad. Some products take an alternative approach when scanning documents such as Word and PDF, by regenerating a new, clean file, based on what is known to be good from schema definitions of the file (a patent for this approach exists).
Website security scans.
As malware also harms the compromised websites (by breaking reputation, blacklisting in search engines, etc.), some websites offer vulnerability scanning.
Such scans check the website, detect malware, may note outdated software, and may report known security issues.
"Air gap" isolation or "Parallel Network".
As a last resort, computers can be protected from malware, and infected computers can be prevented from disseminating trusted information, by imposing an "air gap" (i.e. completely disconnecting them from all other networks). However, information can be transmitted in unrecognized ways; in December 2013 researchers in Germany showed one way that an apparent air gap can be defeated.
Grayware.
Grayware is a term applied to unwanted applications or files that are not classified as malware, but can worsen the performance of computers and may cause security risks.
It describes applications that behave in an annoying or undesirable manner, and yet are less serious or troublesome than malware. Grayware encompasses spyware, adware, fraudulent dialers, joke programs, remote access tools and other unwanted programs that harm the performance of computers or cause inconvenience. The term came into use around 2004.
Another term, PUP, which stands for "Potentially Unwanted Program" (or PUA "Potentially Unwanted Application"), refers to applications that would be considered unwanted despite often having been downloaded by the user, possibly after failing to read a download agreement. PUPs include spyware, adware, fraudulent dialers. Many security products classify unauthorised key generators as grayware, although they frequently carry true malware in addition to their ostensible purpose.
Software maker Malwarebytes lists several criteria for classifying a program as a PUP.
History of viruses and worms.
Before Internet access became widespread, viruses spread on personal computers by infecting the executable boot sectors of floppy disks. By inserting a copy of itself into the machine code instructions in these executables, a virus causes itself to be run whenever a program is run or the disk is booted. Early computer viruses were written for the Apple II and Macintosh, but they became more widespread with the dominance of the IBM PC and MS-DOS system. Executable-infecting viruses are dependent on users exchanging software or boot-able floppies and thumb drives so they spread rapidly in computer hobbyist circles.
The first worms, network-borne infectious programs, originated not on personal computers, but on multitasking Unix systems. The first well-known worm was the Internet Worm of 1988, which infected SunOS and VAX BSD systems. Unlike a virus, this worm did not insert itself into other programs. Instead, it exploited security holes (vulnerabilities) in network server programs and started itself running as a separate process. This same behavior is used by today's worms as well.
With the rise of the Microsoft Windows platform in the 1990s, and the flexible macros of its applications, it became possible to write infectious code in the macro language of Microsoft Word and similar programs. These "macro viruses" infect documents and templates rather than applications (executables), but rely on the fact that macros in a Word document are a form of executable code.
Today, worms are most commonly written for the Windows OS, although a few like Mare-D and the L10n worm are also written for Linux and Unix systems. Worms today work in the same basic way as 1988's Internet Worm: they scan the network and use vulnerable computers to replicate. Because they need no human intervention, worms can spread with incredible speed. The SQL Slammer infected thousands of computers in a few minutes in 2003.
Academic research.
The notion of a self-reproducing computer program can be traced back to initial theories about the operation of complex automata. John von Neumann showed that in theory a program could reproduce itself. This constituted a plausibility result in computability theory. Fred Cohen experimented with computer viruses and confirmed Neumann's postulate and investigated other properties of malware such as detectability, self-obfuscation using rudimentary encryption, and others. His doctoral dissertation was on the subject of computer viruses.

</doc>
<doc id="20905" url="http://en.wikipedia.org/wiki?curid=20905" title="Muttiah Muralitharan">
Muttiah Muralitharan

Muttiah Muralitharan (also spelt Muralidaran; born 17 April 1972) is a Sri Lankan cricketer who was rated the greatest Test match bowler ever by "Wisden Cricketers' Almanack" in 2002. He retired from Test cricket in 2010, registering his 800th and final wicket on 22 July 2010 from his final ball in his last Test match.<ref name=bbc-12/13/02></ref>
Muralitharan took the wicket of Gautam Gambhir on 5 February 2009 in Colombo to surpass Wasim Akram's ODI record of 501 wickets. He became the highest wicket-taker in Test cricket when he overtook the previous record-holder Shane Warne on 3 December 2007. Muralitharan had previously held the record when he surpassed Courtney Walsh's 519 wickets in 2004, but he suffered a shoulder injury later that year and was then overtaken by Warne.
Averaging over six wickets per Test, Muralitharan is one of the most successful bowlers in the game. Muralitharan held the number one spot in the International Cricket Council’s player rankings for Test bowlers for a record period of 1,711 days spanning 214 Test matches.
Muralitharan's career was beset by controversy over his bowling action for much of his international career. Due to an unusual hyperextension of his congenitally bent arm during delivery, his bowling action was called into question on a number of occasions by umpires and sections of the cricket community. After biomechanical analysis under simulated playing conditions, Muralitharan's action was cleared by the International Cricket Council, first in 1996 and again in 1999. Former Australian Test player Bruce Yardley, who himself was an off spinner in his day, was assigned with the task of ensuring Muralitharan bowled all his deliveries with the same vigour as he would do so in match conditions when tested in 2004. Muralitharan had not commenced bowling the doosra at this time. The legality of his doosra was first called into question in 2004. This delivery was found to exceed the ICC elbow extension limit by nine degrees, five degrees being the limit for spinners at that time. Based on official studies into bowling actions, which revealed that 99% of bowlers whose actions were examined exceeded the elbow flexion limits, ICC revised the limits applying to all bowlers in 2005. The new limit of 15-degrees, one degree greater than Muralitharan was bowling his doosra, allowed him to continue without being called for throwing from then on.
In February 2009, after becoming cricket's highest wicket-taker in both forms of the game Muttiah Muralitharan hinted that he might retire at the conclusion of the 2011 World Cup. He stated "I think I am fit in my body and mind, I am enjoying my cricket and want to play more. But after the next World Cup, I will have nothing left to achieve in the game. The World Cup should mark the end of my career." Muralitharan announced his retirement from Test cricket after the first Test against India at Galle which commenced on 18 July 2010. During that match he captured 8 wickets and became the first to reach the milestone of taking 800 Test wickets by dismissing Pragyan Ojha.
He was the sixth international franchise player signed to the Caribbean Premier League and the first Sri Lankan player to be named to the new Twenty20 tournament.
Early years and personal life.
Muralitharan was born in Kandy, the eldest of the four sons to Sinnasamy Muttiah and Lakshmi. Muralitharan's father Sinnasamy Muttiah, runs a successful biscuit-making business.
When he was nine years old Muralitharan was sent to St. Anthony's College, Kandy, a private school run by Benedictine monks. He began his cricketing career as a medium pace bowler but on the advice of his school coach, Sunil Fernando, he took up off-spin when he was fourteen years old. He soon impressed and went on to play for four years in the school First XI. In those days he played as an all-rounder and batted in the middle order. In his final two seasons at St Anthony's College he took over one hundred wickets and in 1990/1 was named as the 'Bata Schoolboy Cricketer of the Year'.
After leaving school he joined Tamil Union Cricket and Athletic Club and was selected for the Sri Lanka A tour of England in 1991. He played in five games but failed to capture a single wicket. On his return to Sri Lanka he impressed against Allan Border's Australian team in a practice game and then went on to make his Test debut at R. Premadasa Stadium in the Second Test Match of the series.
When his grandfather died at the age of 104 in July 2004, Muralitharan returned home from a tour of India to attend his funeral. Periyasamy Sinasamy's first wish to see Muralitharan claiming the world record for the most Test wickets was realised (passing the record set by Courtney Walsh), but not his desire to live to see his grandson married. Muralitharan's grandmother had died one month earlier at the age of 97. Muralitharan's manager, Kushil Gunasekera stated that "Murali's family is closely knit and united. They respect traditional values. The late grandfather enjoyed a great relationship with Murali."
Muralitharan married Madhimalar Ramamurthy, a Chennai girl, on 21 March 2005.<ref name=tribune-2/3/05></ref> Madhimalar is the daughter of late Dr S. Ramamurthy of Malar Hospitals, and his wife Dr Nithya Ramamurthy. Their first child, Naren, was born in January 2006.
Muttiah Muralitharan holds Overseas Citizenship of India (OCI) and he does not need a visa for travelling to India. According to his manager, Kushil Gunasekera, Muralitharan qualifies for this status because his family originates from India.
Muralitharan's paternal grandfather Periyasamy Sinasamy came from South India to work in the tea plantations of central Sri Lanka in 1920.<ref name=Telegraph, UK,-09/12/07></ref> Sinasamy later returned to the country of his birth with his daughters and settled in Namakkal, Tamil Nadu, India. However, his sons, including Muralitharan's father Muttiah, remained in Sri Lanka.
Muttiah announced on 3 April 2011 that he was retiring from all sport.
Spelling and meaning of name.
Even though his name was widely romanised as Muralitharan from the start of his career, he prefers the spelling Muralidaran. The different spellings have arisen because the Tamil letter த can be pronounced as both 't' and 'd' depending on its place in a word. It is often transliterated as 'th' to distinguish it from another letter, ட, which is a retroflex 't' or 'd'. In 2007, when Cricket Australia decided to unveil the new Warne-Muralidaran Trophy, to be contested between Australia and Sri Lanka, Muralitharan was requested to clarify how his name should be spelt. Cricket Australia spokesman Peter Young confirmed that "the spelling he's given is Muralidaran".
The first-day cover involving Muralitharan bears an official seal captioned as "The highest wicket taker in Test cricket, MUTHIAH MURALIDARAN, First Day of Issue 03.12.2007, Camp Post Office, Asgiriya International Cricket Stadium, Kandy".
The name Muralitharan is derived from "murali dhar" (Devnagri: मुरली धर) meaning "the bearer of the flute", which is a synonym for Lord Krishna, a deity in Hinduism who is said to play upon his bamboo flute while looking after cattle. A variation of this Sanskrit name spelt as 'Muralidharan' and 'Muraleedharan' is a common name amongst Malayali Hindus and is not related to the cricketer and the Sri Lankan Tamil community.
Domestic cricket.
In Sri Lanka.
In domestic cricket, Muralitharan played for two first-class Sri Lankan sides, Tamil Union Cricket and Athletic Club in the Premier Trophy and Central Province in the Provincial Championship. His record is exceptional – 234 wickets at 14.51 runs in 46 matches.
In England.
He also played county cricket in England, mainly for Lancashire (1999, 2001, 2005 and 2007) where he appeared in twenty-eight first-class games for the club. He played five first class games for Kent during the 2003 season. His bowling record in English domestic cricket is also exceptional – 236 wickets at 15.62 runs in 33 matches. Despite his efforts, he was never on a title winning first-class domestic team in either the Premier Trophy or the County Championship. He was unusual amongst his contemporaries in that he played in more Test matches than other first-class games (116 Tests and 99 other first class matches as of 30 November 2007). Muralitharan had been signed by Gloucestershire in 2011 to play in T20 matches, and he also renewed his T20 contract with Gloucestershire in 2012, but did not stay for the 2013 season.
In India.
In February 2008, Muralitharan was slated to play Twenty20 cricket for the Chennai Super Kings in the Indian Premier League (IPL). He was bought for $600,000 by India Cements, the Chennai franchisee of the IPL, through a bidding process. The Chennai Super Kings were the runners up in the inaugural edition of the IPL, losing to the Rajasthan Royals in the final. Muralitharan captured 11 wickets in 15 games, at an economy rate of 6.96 an over. In 2010, in the third season of IPL, Muralitharan was part of the Chennai Super Kings side that won the IPL championship. Muralitharan also remained the side's leading wicket-taker after all the three tournaments.
At the 2011 IPL Player Auctions Muralitharan was bought by Kochi Tuskers Kerala for $1.1 million USD. 
In the 2012 season Muralitharan moved to Royal Challengers Bangalore where he took 14 wickets in 9 games and had an average economy rate of 6.38. He played for Royal Challengers Bangalore from 2012-2014 and he later decided to retire from IPL in 2014
In 2015 Indian Premier League Muralitharan was appointed as Sunrisers Hyderabad Bowling coach and Mentor of the team
Muralitharan, was contracted to represent Bengal in the 2008–09 Ranji Trophy tournament. He was expected to play about four matches in the tournament's second division – the Plate League.
In Australia.
Muttiah Muralitharan signed for the Melbourne Renegades to play Twenty20 cricket in the Big Bash League, in 2012. He stated, "I wanted to play one season in Australia and the opportunity from the Melbourne Renegades was there so I took it with both hands."
International career.
Bowling style and career progress.
Muralitharan is the first wrist-spinning off-spinner in the history of the game.
He bowls marathon spells, yet he is usually on the attack. His unique bowling action begins with an open-chested short run-up, and culminates with an extremely wristy release which had him mistaken for a leg-spinner early in his career by Allan Border. Aside from his off-break, his main deliveries are a fast topspinner which goes straight on, and the doosra, a surprise delivery which turns from leg to off (the opposite direction of his stock delivery) with no easily discernible change of action.<ref name="Muttiah Muralitharan - Legend / The Genius"></ref> His newest variation is a version of Shane Warne's slider, which is flicked out the side of his hand and rushes onto batsmen like a flipper. His super-flexible wrist makes him especially potent and guarantees him turn on any surface.
From his debut in 1992, Muralitharan took 800 Test wickets and over 500 One Day International wickets, becoming the first player to take 1,000 wickets combined in the two main forms of international cricket.
Test cricket.
Emerging years.
On 28 August 1992 at the age of 20, Muralitharan made his debut against Australia at the Khettarama Stadium and claimed 3 for 141. Craig McDermott was his first Test wicket. His freakish action and his angular run-up showed that this was no run-of-the-mill spinner. During his first Test, there was one dismissal which convinced many of Muralitharan's special powers. Tom Moody's leg-stump was dislodged when he shouldered arms to a delivery that pitched at least two feet outside the off-stump.
The youthful Muralitharan went from strength to strength, playing a major part in Sri Lanka's back-to-back Test victories against England and New Zealand in 1992–93. It was at this point in his career that he struck a close bond with his leader, mentor and one time business partner, the authoritative captain Arjuna Ranatunga. This relationship formed the bedrock of his success and meant that there were few doubts about his status as the team's sole wicket-taker. Ranatunga was thoroughly convinced that Muralitharan's precocious talent would signal a new era in Sri Lanka's short Test history.
In August 1993 at Moratuwa, Muralitharan captured 5 for 104 in South Africa's first innings, his first five-wicket haul in Tests. His wickets included Kepler Wessels, Hansie Cronje and Jonty Rhodes.
Muralitharan continued to baffle batsman outside the shores of Sri Lanka, irrespective of the team's performance. In Sri Lanka's humiliating drubbing at the hands of India in 1993–94, where all three Tests were innings defeats, Muralitharan was the sole success, with 12 wickets in the rubber. His perseverance in the face of some astronomical scores by the fearsome quartet of Mohammed Azharuddin, Sachin Tendulkar, Navjot Sidhu and Vinod Kambli was in sharp contrast to the submission with which his team-mates played the series.
It was in New Zealand in March 1995 that Muralitharan displayed his qualities as a match-winner on any surface. In Sri Lanka's first triumph on foreign soil, Muralitharan confused the crease-bound New Zealanders on a grassy pitch in Dunedin. The Sri Lankan manager Duleep Mendis' claim that Muralitharan can turn the ball on concrete was confirmed. On the eve of his tour of Pakistan later that year, doubts were cast on his ability to trouble subcontinental batsmen. By taking 19 wickets in the series and delivering a historic 2–1 victory, the off-spinner silenced the doubters. The Pakistanis, who had negotiated Warne's leg-breaks in the previous home series, were never at ease against him.
Prior to the eventful Boxing Day Test of 1995, Muralitharan had captured 80 wickets in 22 Tests at an unflattering average of 32.74. Even at that point in his career he was the leading wicket taker for Sri Lanka having gone past Rumesh Ratnayake's aggregate of 73 wickets.
Boxing Day Test 1995.
During the second Test between Sri Lanka and Australia at the Melbourne Cricket Ground on Boxing Day 1995, Australian umpire Darrell Hair called Sri Lankan spinner Muttiah Muralitharan for throwing in front of a crowd of 55,239. The off-spinner was no-balled seven times in three overs by Hair, who believed the then 23 year old was bending his arm and straightening it in the process of delivery; an illegal action in cricket.
Muralitharan had bowled two overs before lunch from umpire Steve Dunne's or the Members' End of the ground with umpire Hair at square leg and these passed without incident. At 2:34 pm he took up the attack from umpire Hair's or the southern end. Muralitharan's third over was a maiden with all deliveries again passed as legitimate but in his fourth Hair no-balled him twice for throwing on the fourth and sixth balls. The umpire continued to call him three times in his fifth over on the second, fourth and sixth balls. While the bowler stood with his hands on his hips perplexed, the five calls provoked an immediate response by the Sri Lankan captain Arjuna Ranatunga who left the field at 3:03 pm in order to take advice from his team management. He returned at 3:08 pm and continued with Muralitharan who was called two more times in his sixth over on the second and sixth balls. At 3:17 pm Ranatunga removed the bowler from the attack, although he reintroduced him at 3:30 pm at umpire Dunne's end. Although Hair reports in his book, "Decision Maker", that at the end of the tea break he stated that he would call Muralitharan no matter which end he bowled he did not do so. Muralitharan completed another twelve overs without further no-balls and, after bowling Mark Waugh, finished the day with figures of 18–3–58–1.
After being no-balled Muralitharan bowled a further 32 overs from umpire Steve Dunne's end without protest from either Dunne or Hair, at square leg. The Sri Lankan camp was outraged after the incident, but the ICC defended Hair, outlining a list of steps they had taken in the past to determine, without result, the legitimacy of Muralitharan's action. By calling Muralitharan from the bowlers' end Hair overrode what is normally regarded as the authority of the square leg umpire in adjudicating on throwing. Dunne would have had to break convention to support his partner.
At the end of the match the Sri Lankans requested from the ICC permission to confer with Hair in order to find out exactly how to remedy the problem with their bowler. Despite the game's controlling body agreeing to it, the Australian Cricket Board vetoed it on the grounds that it might lead to umpires being quizzed by teams after every game and meant that the throwing controversy would continue into the World Series Cup during the coming week. The Sri Lankans were disappointed they did not get an explanation and decided they would continue playing their bowler in matches not umpired by Hair and wanted to know whether other umpires would support or reject Hair's judgement.
Muralitharan's action was cleared by the ICC after biomechanical analysis at the University of Western Australia and at the Hong Kong University of Science & Technology in 1996. They concluded that his action created the 'optical illusion of throwing'.
Mid career.
On 16 March 1997, Muralitharan became the first Sri Lankan to reach 100 test wickets, when he dismissed Stephen Fleming in the second innings of the Hamilton Test.
In January 1998, Muralitharan took his first ten-wicket haul against Zimbabwe in the first test at Kandy. Sri Lanka won by eight wickets and Muralitharan had figures of 12 for 117.
In August that same year Muralitharan produces his career-best test match figures of 16 for 220, in the one-off test against England. In England's second innings Muralitharan bowled a marathon 54.2 overs to pick up 9 for 65 runs, the other wicket being a run out. Ben Hollioake becomes his 200th test wicket. Sri Lanka won by ten wickets, their first Test victory in England. After breaking the world record for the most test wickets in 2007, Muralitharan commented that his 1998 performance at the Oval against England, was his career highlight. He stated "Everyone thought I was a good bowler then and I didn't look back from there."
Playing his 58th test, Muralitharan claimed his 300th test wicket when he dismissed Shaun Pollock in the First Test in Durban, in December 2000. Only Dennis Lillee reached the milestone faster, in his 56th test.
On 4 January 2002 in Kandy Muralitharan might have finished with the best-ever figures for a single innings, but after he had claimed nine wickets against Zimbabwe Russel Arnold dropped a catch at short leg.
He missed out on the tenth when Chaminda Vaas dismissed Henry Olonga caught behind amid stifled appeals. Muralitharan follows up his 9 for 51 in the first innings with 4 for 64 in the second, equalling Richard Hadlee's record of 10 ten-wicket match hauls, but needing 15 fewer Tests to do so.
On 15 January 2002 playing in his 72nd test, Muralitharan became the fastest to reach the 400-wicket landmark when he bowled Olonga in the third Test in Galle.
On 16 March 2004 Muralitharan became the fastest and the youngest bowler to reach 500 wickets during the second test between Sri Lanka and Australia played in Kandy. In his 87th test, he bowled Kasprowicz to claim his 500th victim just four days after Warne reached the landmark on the fifth day of the First Test between the two teams at Galle. Warne took 108 tests to reach 500. Muralitharan took 4–48 on the first day of the second Test as Australia were skittled for 120 in the first innings.
Passing Walsh and Warne.
In May 2004, Muralitharan overtook West Indian Courtney Walsh's record of 519 Test match wickets to become the highest wicket-taker. Zimbabwe's Mluleki Nkala becomes Muralitharan's 520th scalp in Tests. Muralitharan held the record until Shane Warne claimed it in October 2004. Warne surpassed Sri Lankan Muttiah Muralitharan's mark of 532 wickets by dismissing India's Irfan Pathan. Warne said he enjoyed his duel with Muralitharan, who was sidelined following shoulder surgery at the time.
After an outstanding year Muralitharan was adjudged as the Wisden Leading Cricketer in the World in 2006. In six Tests, he took 60 wickets. He took ten in each of four successive matches, the second time he performed such a feat. The opponents for his 60-wicket haul were England away, South Africa at home and New Zealand away: serious opposition. In all, Muralitharan took 90 wickets in 11 Tests in the calendar year.
In July 2007, Muttiah Muralitharan became the second bowler after Australia's Shane Warne to capture 700 Test wickets. The off-spinner reached the landmark when he had Bangladesh's last man Syed Rasel caught in the deep by Farveez Maharoof on the fourth day of the third and final Test at the Asgiriya stadium in Kandy. The dismissal signalled Sri Lanka's victory by an innings and 193 runs to give the host a 3–0 sweep of the series. Muralitharan finished with six wickets in each innings to claim 10 wickets or more in a Test for the 20th time. However, he was unable to pass Warne's record of 708 wickets when Sri Lanka toured Australia in November 2007, capturing just four wickets in two Test matches.
Muralitharan reclaimed the record for most Test wickets during the first Test against England at Kandy on 3 December 2007. The spinner bowled England's Paul Collingwood to claim his 709th Test victim and overtaking Shane Warne in the process. Muralitharan reached the mark in his 116th Test – 29 fewer than Warne – and had conceded only 21.77 runs per wicket compared to the Australian's 25.41. This was Muralitharan's 61st 5-wicket haul. Warne believed that Muralitharan would take "1,000 wickets" before he retired. Former record holder Courtney Walsh also opined that this would be possible if Muralitharan retained his hunger for wickets. Muralitharan himself believed there was a possibility that he would reach this milestone.
Beyond the world record.
In July 2008, Muralitharan and Ajantha Mendis stopped India's strong batting as Sri Lanka won the first Test by a record innings and 239 runs in Colombo. Muralitharan finished the match with 11 wickets for 110, as India were shot out for 138 in their second innings after conceding a lead of 377 on the fourth day. He was well supported by debutant Ajantha Mendis, an unorthodox spinner with plenty of variation, who took eight wickets in his debut match.
Muralitharan believed the emergence of Mendis would help prolong his own career. Muralitharan, 36, and 23-year-old Mendis formed a formidable partnership in the first Test thrashing of India, taking 19 of the 20 wickets between them. "If he keeps performing this way, he will definitely take a lot of wickets in international cricket. Now that he has come, I think I can play Test cricket a few more years. Bowling 50 overs in a Test innings is very hard. Now if I bowl only 30–35 and he bowls more than me, the job will get easier for me."
Performance analysis.
In July 2007, Muralitharan achieved a career peak Test Bowling Rating of 920, based on the LG ICC Player Rankings. This is the highest ever rating achieved by a spin bowler in Test cricket. This also puts him in fourth place in the LG ICC Best-Ever Test bowling ratings.
Muralitharan has the unique distinction of getting 10 or more wickets in a match against all other nine Test playing nations as well as capturing over 50 wickets against each of them. He also obtained 7 or more wickets in an innings against five nations, namely England, India, South Africa, West Indies and Zimbabwe (refer to table above). Muttiah Muralitharan also took at least five five-fors against all the other nine Test sides.
He currently holds the highest wickets/match ratio (6.1) for any bowler with over 200 Test wickets and also represented Sri Lanka in 118 Tests of the 175 that they have played (67.4%).
Against teams excluding Bangladesh and Zimbabwe, Muralitharan took 624 wickets in 108 Tests. By comparison, excluding his matches against Bangladesh and Zimbabwe, Warne took 691 wickets in 142 tests. Murali's average of 24.05 is slightly superior to Warne's career average of 25.41. Muralitharan won 18 Man of the Match awards in Test cricket.
During Muralitharan's playing days, the ICC Future Tours Programme denied Sri Lanka and several other teams a level playing field. As a consequence Muralitharan never toured South Africa after December 2002 and never playing a Test at the spin-friendly Sydney Cricket Ground.
Another comparison of Muralitharan's bowling record against other successful international bowlers is their career record away from home. Muralitharan received criticism that he enjoyed great success on home soil, taking wickets on pitches that are more spin-friendly than other international pitches. A quick analysis of his Test record of matches played outside Sri Lanka shows that from 52 matches he took 278 wickets at an average of 26.24 runs per wicket, with a strike rate of 60.1 balls per wicket. Similarly, spin bowling rival Shane Warne retired with a slightly superior 'away' record of 362 wickets from 73 matches, at an average of 25.50 and a strike rate of 56.7. Due to the variabilities of Test cricket such as grounds played at and opposition played against it is difficult to compare the quality of the top level players and, as such, is very difficult and subjective. However, it is clear that Muralitharan did much better playing at home to test minnows Zimbabwe and Bangladesh, averaging less than 16 runs a wicket.
Cricinfo's statistics editor S Rajesh concluded that the decade 2000–2009 was the best 10-year period for Test batsmen since the 1940s. Muralitharan was clearly the leading Test wicket-taker during this period, capturing 565 wickets at 20.97 in spite of the dominance of the bat over ball. Shane Warne captured 357 wickets at an average of 25.17 during the decade. Of spinners with over Test 100 wickets only John Briggs (17.75), Jim Laker (21.24), Bill O Reilly (22.59) and Clarrie Grimmett (24.21) have sub 25.00 bowling averages.
Muralitharan was on the winning side on 54 of the 133 test matches he played. In those games he captured a total of 438 wickets (8.1 wickets per match), at an outstanding average of 16.18 per wicket and a strike rate of 42.7.
Muralitharan took 795 wickets for his country Sri Lanka in 132 tests. The next most wickets for Sri Lanka in these 132 Tests was Chaminda Vaas' 309 – less than 40% of the spinner's pile. No one else managed 100. Collectively Sri Lankan bowlers tallied 1968 wickets across that span, of which Muralitharan accounted for 40.4%. Among the 24 other Sri Lankans who took more than 10 of those wickets, only Lasith Malinga did so at a better strike rate (52.3) than Muralitharan's 54.9 – and the latter bowled rather more overs, 6657.1 of them to be precise.
Five wickets in an innings.
Muralitharan took five or more wickets in an innings on 67 occasions in Test cricket, which is a world record. In comparison Shane Warne who is in 2nd place performed the feat 37 times.
One day internationals.
Career summary.
On 12 August 1993 Muralitharan made his One Day International (ODI) debut against India at the Khettarama Stadium and took 1 for 38 off ten overs. Praveen Amre was his first ODI wicket.
On 27 October 2000 in Sharjah, Muralitharan captured 7 for 30 against India, which were then the best bowling figures in One Day Internationals.
In 9 April 2002 Muralitharan achieved a career peak ODI Bowling Rating of 913, based on the LG ICC Player Rankings. This is the highest ever rating achieved by a spin bowler in One Day Internationals. This also puts him in fourth place in the LG ICC Best-Ever ODI bowling ratings.
In 2006, Muralitharan had the second (now third) highest number of runs (99) hit off him in a One Day International Innings. The Australians, especially Adam Gilchrist, attacked Muralitharan's bowling more than usual that day. It is also to be noted that Muralitharan does not have a great record against the Australians in ODIs and this was proved again as he was ineffective in the finals of the 2007 World Cup; his chief tormentor again being Gilchrist.
Muralitharan played in five Cricket World Cup tournaments, in 1996, 1999, 2003, 2007 and 2011. He captured 67 World Cup wickets and is second in the list behind Glenn McGrath who has 71, and represented Sri Lanka in three World Cup finals. In 1996 Muralitharan was part Sri Lanka's World Cup winning team that defeated Australia in Lahore, Pakistan. Muralitharan also played in the 2007 World Cup final, when Australia defeated Sri Lanka in Bridgetown, Barbados. He picked up 23 wickets in the 2007 World Cup, and finished as the second highest wicket taker in the tournament behind Glenn McGrath. He was part of the 2011 team who lost the world cup final against India in Mumbai. It was his farewell match as well.
Muttiah Muralitharan was left out of the Sri Lankan one-day squad to tour West Indies in April 2008. The chairman of selectors Ashantha De Mel clarifying the non-selection stated that "We know he (Muralitharan) can still play in the next World Cup if he is properly looked after, so we want to use him sparingly to preserve him for the big games and the World Cup coming up in the Asian sub-continent where Muralitharan will be a threat."
Muralitharan has the highest number of career wickets in One Day Internationals, having overtaken Wasim Akram on 5 February 2009. Akram took 502 wickets in 356 matches. On 3 February 2009, Muralitharan dismissed Yuvraj Singh in his 327th match, the third ODI against India in Colombo to equal Akram's record. He won 13 Man of the Match awards in this form of the game.
Batting.
An aggressive lower order batsman who usually batted at No. 11, Muralitharan was known for his tendency to back away to leg and slog. Sometimes, he could be troublesome for bowlers because of his unorthodox and adventurous ways. Once, in a Test match against England, while playing Alex Tudor, he moved back towards his leg stump trying to hook the ball and ended up lying on the ground sideways after the shot. He was infamously run out in a match against New Zealand when he left his crease to congratulate Kumar Sangakkara, who had just scored a single to reach his century; the New Zealand fielder had not yet returned the ball to the wicketkeeper, so the ball was still in play. His highest Test score of 67 came against India at Kandy in 2001, including three sixes and five fours. He made valuable scores on occasion, including 30 runs against England at the Oval in 1998, including 5 fours, 38 runs (4 fours, 1 six) against England at Galle in 2003, 43 runs (5 fours, 3 sixes) against Australia at Kandy in 2004 36 runs against the West Indies at Colombo in 2005, and his highest-ever ODI score, 33 not out (4 fours and 2 sixes off 16 balls) against Bangladesh in the final of the 2009 Tri-Series in Bangladesh. In the latter match, Muralitharan's effort, which included three fours and a six off one over, played a key role in Sri Lanka winning the match and series after the first eight overs saw them reduced to 6 for 5, the lowest score ever recorded in an ODI at the fall of the fifth wicket. Muralitharan has a strike rate close to 70 in Test cricket and scored over 55% of his Test runs in fours and sixes.
Muralitharan, together with Chaminda Vaas, holds the record for the highest 10th wicket partnership in Tests for Sri Lanka. The pair put on 79 runs for the last wicket at the Asgiriya Stadium against Australia in March 2004. Muralitharan also holds the record for scoring most runs in Test cricket while batting at the number 11 position.
Muralitharan currently holds the record for the most ducks (dismissals for zero) ever in international cricket (Tests, ODI's and Twenty20), with a total of 59 ducks.
Abuse in Australia.
Muralitharan voiced his frustration at routinely being heckled by Australian crowds who accuse him of throwing – one common jeer directed at him was "No Ball!". Following the then Australian Prime Minister John Howard's statement that Muralitharan was a "chucker",
 in 2004, Muralitharan indicated that he would skip future tours to Australia.
Tom Moody, the former Sri Lanka coach and former Australian Test cricketer, said he was embarrassed by the derogatory reaction and negative attention directed towards Muttiah Muralitharan by Australian crowds. Moody stated that "As an Australian when I have been with the Sri Lankan team in Australia, or playing against them in the World Cup, it's the only situation we find in the whole of the cricketing world where we have this disgraceful slant on a cricketer".
During the 2008 CB series in Australia, some members of the Sri Lankan contingent including Muralitharan, were the target of an egg throwing incident in Hobart. The Sri Lankan cricket selector Don Anurasiri was hit by an egg, while Muralitharan and two others were verbally abused by a car-load of people as they were walking from a restaurant back to the hotel.
Due to the incident taking place at night, it is unclear whether Muralitharan was indeed the target of the culprits. Even though the Australian coach of the Sri Lankan team, Trevor Bayliss, down-played the incident as "a non-event", Cricket Australia tightened security around the team. In response to this episode Muralitharan was quoted as saying "When you come to Australia, you expect such incidents".
At the conclusion of Muralitharan's test career cricket writer Rahul Bhattacharya summed up Muralitharan's trials thus:
"Murali is described often as a fox. This seems right. Unlike hedgehog bowlers who pursue one big idea, Murali, like a fox, had many ways of pursuit. Like a fox he did not hunt in a pack. Like a fox he was himself cruelly hunted for sport in some parts of the world. Fox hunting was banned a few years ago in England, but is still legal in Australia."
Retirement.
On 7 July 2010, Muttiah Muralitharan formally announced his retirement from Test cricket at a media briefing in Colombo. He confirmed that the first Test Match against India due to commence on 18 July, 2010 would be his last, but indicated that he was willing to play One-Day Internationals if it was considered necessary leading up to the 2011 World Cup, which Sri Lanka co-hosted. He identified Sri Lanka's World Cup win of 1996 as his greatest moment as a cricketer. He also stated that there were some regrets during his 19 year playing career. "Not winning Test Matches in South Africa, Australia and India are regrets. But I am sure we will win very soon." 
At the start of his last match, Muralitharan was eight short of 800 wickets. At the fall of the ninth wicket of the Indian's second innings Muralitharan still needed one wicket to reach the milestone. After 90 minutes of resistance Muralitharan was able to dismiss the last Indian batsman Pragyan Ojha on the last delivery of the over and his Test career. By doing so he became the first bowler to reach 800 wickets in Test cricket. Sri Lanka won the match by 10 wickets, the seventh time they have done so and the second time they have done it against India.
Muralitharan formally announced his retirement from international cricket after 2011 Cricket World Cup co-hosted by Bangladesh, India and Sri Lanka announcing "This World Cup will be my last outing. I am retiring totally from international cricket thereafter. My time is up. I've signed up to play for two years in IPL."
In July 2014, he played for the Rest of the World side in the Bicentenary Celebration match at Lord's.
World records and achievements.
Muttiah Muralitharan holds a number of world records, and several firsts:
Cricket awards.
Wisden Cricketers of the Year.
Was named Wisden Cricketers of the Year 1999.
Recognition.
In 2002, Wisden carried out a statistical analysis of all Test matches in an effort to rate the greatest cricketers in history, and Muralitharan was ranked as the best Test bowler of all time. However, two years earlier, Muralitharan was not named as one of the five Wisden Cricketers of the Century. Former Australian captain Steve Waugh called him "the Don Bradman of bowling".
Muralitharan was selected as the Wisden Leading Cricketer in the World in 2000 and in 2006.
On 15 November 2007, the Warne-Muralidaran Trophy was unveiled named after the two leading wicket-takers in Test cricket, Shane Warne and Muralitharan. The trophy displays images of the two spin bowlers' hands each holding a cricket ball. This trophy will be contested between Australia and Sri Lanka in all future Test series.
On 3 December 2007, just hours after Muttiah Muralitharan became Test cricket's leading Test wicket-taker, Marylebone Cricket Club (MCC) announced it had unveiled a portrait of the Sri Lanka off-spinner at Lord's. On the same day the Philatelic Bureau of the Department of Posts in Sri Lanka issued a circular stamp with a denomination of Rs. 5 to mark the world record set by Muttiah Muralitharan. The circular design was meant to denote the cricket ball.
Australian musician Alston Koch provoked worldwide interest when he recorded the only official tribute song to Muralitharan. The song was even mentioned on the BBC's Test Match Special. The Muralitharan Song video was also released after he broke the world record.
On 10 January 2008, the Parliament of Sri Lanka felicitated Muttiah Muralitharan for his world record breaking feat of being the highest wicket taker in Test cricket.
This was the first time that a sportsman had been honoured in the country's Supreme Legislature.
The Central Provincial Council in Kandy has decided to rename the International Cricket Stadium in Pallekele after Muttiah Muralitharan.
Controversy of bowling action.
Throughout much of his international career, Muralitharan's action was suspected of contravening the laws of the game by the straightening of his bowling arm during delivery. Although he was cited three times, subsequent biomechanical testing led the ICC to clear him of the charge and permit him to continue bowling.
Biomechanical testing conducted on four occasions fueled debate as to whether his action was in fact illegal or actually an illusion created by his allegedly unique ability to generate extra movement both at the shoulder as well the wrist enables him to bowl the doosra without straightening the elbow.
First throwing citation and testing.
Initial concerns as to whether Muralitharan's action contravened the laws of the game by straightening his bowling arm during delivery broke into open controversy after Australian umpire Darrell Hair called a "no ball" for an illegal action seven times during the Boxing Day Test match in Melbourne, Australia, in 1995. Australian Sir Donald Bradman, universally regarded as the greatest batsman in history, was later quoted as saying it was the "worst example of umpiring that [he had] witnessed, and against everything the game stands for. Clearly Murali does not throw the ball".
Ten days later, on 5 January 1996, Sri Lanka played the West Indies in the seventh ODI of the triangular World Series competition, in Brisbane. Umpire Ross Emerson officiating in his debut international match, no-balled Muralitharan three times in his first over, twice in his second and twice in his third. It was an identical tally to that called by Hair on Boxing Day and (like Hair) Emerson made his calls from the bowler's end while his partner stood silent. The main difference was that several no-balls were for leg-breaks instead of the bowler's normal off-breaks.
In February 1996, just before the world cup Muralitharan underwent biomechanical analysis at the Hong Kong University of Science and Technology under the supervision of Prof. Ravindra Goonetilleke, who declared his action legal in the conditions tested, citing a congenital defect in Muralitharan's arm which makes him incapable of fully straightening it, but giving the appearance of fully straightening the arm. Although under the original Laws a bowler's arm did not need to be fully straightened to be in breach of a legal delivery. They concluded that his action created the 'optical illusion of throwing'. Based on this evidence ICC gave clearance to Muralitharan to continue bowling.
Second citation and testing.
Doubts about Muralitharan's action persisted however, on the 1998–99 tour to Australia he was once again called for throwing by Ross Emerson during a One Day International against England at the Adelaide Oval in Australia. The Sri Lankan team almost abandoned the match, but after instructions from the President of the Board of Control for Cricket in Sri Lanka, the game resumed. The Sri Lankan captain at the time Arjuna Ranatunga, was later fined and given a suspended ban from the game as a result. It later emerged that at the time of this match Emerson was on sick leave from his non-cricket job due to a stress-related illness and he stood down for the rest of the series. Muralitharan was sent for further tests in Perth and England and was cleared again. At no stage was Muralitharan requested to change or remodel his action, by the ICC. Up to this point in his career (1999) Muralitharan primarily bowled two types of deliveries, namely the off-break and the topspinner. He had not yet mastered the doosra.
Third citation and testing.
Muralitharan continued bowling, taking his 500th Test wicket in the second Test against Australia in Kandy on 16 March 2004. At the end of the series his doosra delivery was officially called into question by match referee Chris Broad. At the University of Western Australia (Department of Human Movement and Exercise Science), three-dimensional kinematic measurements of Muttiah Muralitharan's bowling arm were taken using an optical motion capture system while he bowled his doosra. Muralitharan's mean elbow extension angle for the doosra delivery was 14°, which was subsequently reduced to a mean of 10.2° after remedial training at the University. The findings reported to ICC by the University of Western Australia's study was that Muralitharan's doosra contravened the established ICC elbow extension limit of 5° for spinners.
Under the original throwing Laws of Cricket, the umpires officiating were under an obligation to call "no-ball" to a delivery that they were not entirely happy was absolutely fair. This Law gave the umpires absolutely no discretion. In 2000, the Laws were changed to put an allowable figure of straightening of 5° for spinners, 7.5° for medium pacers and 10° for fast bowlers in an attempt to more clearly define what was legal. But these figures proved difficult to enforce due to umpires being unable to discern actual amounts of straightening and the differentiation between the three different allowable figures. Testing in Test Match conditions is not currently possible "when the identification of elbow and shoulder joint centres in on-field data collection, where a shirt is worn, also involves large errors. In a match the ability to differentiate anatomical movements such as 'elbow extension' by digitising segment end-points, particularly if you have segment rotations, is extremely difficult and prone to error. This is certainly the case with spin bowlers. It is therefore not surprising that laboratory testing is preferred, particularly for spin bowlers, where an appropriate pitch length and run-up can be structured. This is clearly the only way to test players, where data would be able to withstand scientific and therefore legal scrutiny."
An extensive ICC study, the results of which were released in November 2004, was conducted to investigate the "chucking issue". A laboratory kinematic analysis of 42 non-Test playing bowlers done by Ferdinands and Kersting (2004) established that the 5° limit for slow and spin bowlers was particularly impractical.
Due to the overwhelming scientific findings, researchers recommended that a flat rate of 15° tolerable elbow extension be used to define a preliminary demarcation point between bowling and throwing. A panel of former Test players consisting of Aravinda de Silva, Angus Fraser, Michael Holding, Tony Lewis, Tim May and the ICC's Dave Richardson, with the assistance of several biomechanical experts, stated that 99% of all bowlers in the history of cricket straighten their arms when bowling. Only one player tested (part-time bowler Ramnaresh Sarwan) reportedly did not transgress the pre 2000 rules. Many of these reports have controversially not been published and as such, the 99% figure stated has yet to be proved. In fact, Muralitharan stirred up controversy when he said during an interview with a Melbourne radio station that Jason Gillespie, Glenn McGrath and Brett Lee flexed their arms by 12, 13 and 14–15 degrees respectively, although it is unclear as to where Muralitharan quoted these figures from. Muralitharan was censured by the Sri Lankan Cricket Board for these comments.
The ICC Executive was asked to ratify the panel's recommendations at the ICC's Annual General Meeting in February 2005. Based on the recommendations the ICC issued a new guideline (which was effective from 1 March 2005) allowing for extensions or hyperextensions of up to 15 degrees for all types of bowlers, thus deeming Muralitharan's doosra to be legal.
Explaining why the maximum level of 15 degrees was arrived at, panel member Angus Fraser stated "That is the number which biomechanics says that it (straightening) becomes visible. It is difficult for the naked eye to see less than 15 degrees in a bowler's action. We found when the biceps reached the shoulder the amount of bend was around 165 degrees. Very few bowlers can get to 180 degrees because the joint doesn't allow that. ... but once you go further than 15 degrees you get into an area which is starting to give you an unfair advantage and you are breaking the law".
University of South Australia study.
The original decision of disallowing the doosra bowling action was hailed widely as justifiable on account of being scientifically based. Hence, a team of Australian scientists representing the University of South Australia conducted an independent research, in line with modern Artificial Intelligence and biomechanics in order to solve the controversial issue arise from doosra. The University of South Australia's study, founded by Prof. Mahinda Pathegama, and contributed by Prof. Ozdemir Gol, Prof. J. Mazumdar, Prof. Tony Worsley and Prof. Lakmi Jain has analyzed the previous studies with close scrutiny since the techniques in their fields of expertise are employed in the course of assessment as the basis for decision-making. The findings based on this scientific study are overwhelming and Dave Richardson, General Manager ICC stated that "the ICC is currently reviewing the Law on throwing and the ICC regulations and the study done by Prof. Mahinda Pathegama with UniSA scientists is a valuable source of information in this regard". The team of Australian scientists including Sri Lankan-born Australian scientist, Prof. Mahinda Pathegama reporting their findings, in line with the Muralitharan test to ICC, has analyzed in-depth various issues, such as Pitfalls in image interpretation when using 2D images for 3D modeling associates compared to the modern techniques in Artificial Intelligence and biomechanics, and Biomechanics assessment for doosra bowling action, etc. Pathegama at al. (2004) further reports on the Disagreement of expression on measurement accuracy in the Murali Report, with the analysis of the Motion tracking system used for the Murali Report, and discussing Cognitive aspects, Evidence of errors in Anthropometric assessment and movement tracking, Lateral inhibition in response tracking, Psycho-physiological aspect on post-assessments, Angular measurement errors, Skin marker induced errors, Geometrics-and physics-based 3D modeling and the Approach to on-field assessment, etc.
The Muralitharan Report produced by the University of Western Australia's study has considered the Richards study done in 1999 to evaluate the error margin. University of South Australia's study done by Prof. Mahinda Pathegama argued that the Richards study which was presented by the University of Western Australia's study has used a rigid aluminium bar that only rotated in the horizontal plane to introduce such error margin. Pathegama's report stated that "in view of the system used in the test itself yielding considerable error even with a rigid aluminum bar (an "accuracy level of approximately 4 degrees" as stated in the Murali Report), it stands to reason that the error margin would be considerably larger when tracking skin markers on a spin bowler's moving upper limb by this same system".
Vincent Barnes in an interview argues that Bruce Elliott, the UWA professor who is also the ICC biomechanist, had made an interesting discovery in his dealings with finger spinners. "He said he had found that a lot of bowlers from the subcontinent could bowl the doosra legally, but not Caucasian bowlers."
Fourth round of testing.
On 2 February 2006, Muralitharan underwent a fourth round of biomechanical testing. There had been criticism that the previous round of tests in July 2004 did not replicate match conditions due to a slower bowling speed in the laboratory tests. The results showed that the average elbow flexation while bowling the 'doosra' delivery was 12.2 degrees, at an average of 53.75 mph. The average for his off-break was 12.9 degrees at 59.03 mph.
Bowling with an arm brace.
In July 2004 Muralitharan was filmed in England, bowling with an arm brace on. The film was shown on Britain's Channel 4 during the Test against England on 22 July 2004.
Initially, Muralitharan bowled three balls – the off-spinner, the top-spinner and the doosra – as he would in a match. Then he bowled the same three balls with a brace that is made from steel bars, which are set into strong resin. This brace has been moulded to his right arm, is approximately 46 centimetres long and weighs just under 1 kilogram.
TV presenter Mark Nicholas who tried the brace himself, confirmed that "There is no way an arm can be bent, or flexed, when it is in this brace." All three balls reacted in the same way as when bowled without the brace. They were not bowled quite so fast because the weight of the brace restricts the speed of Muralitharan's shoulder rotation, but the spin was still there.
With the brace on, there still appeared to be a jerk in his action. When studying the film at varying speeds, it still appeared as if he straightened his arm, even though the brace makes it impossible to do so. His unique shoulder rotation and amazing wrist action seem to create the illusion that he straightens his arm.
The off-spinner said the exercise was to convince a sceptical public rather than sway an ICC investigation into bowling actions launched after he was reported by match referee Chris Broad for his doosra delivery in March 2004, the third time action was taken on his bowling. In an interview for August 2004 edition of Wisden Asia Cricket, Muralitharan stated "I think it will prove a point to those who had said that it was physically impossible to bowl a ball that turned the other way. I proved that it was possible to bowl the doosra without bending the arm."
In 2004 at the R Premadasa Stadium in Colombo, Muralitharan voluntarily performed a series of tests with live video cameras. Michael Slater and Ravi Shastri witnessed it all unfold. Muralitharan once again showed he could bowl all his deliveries including the doosra with an arm brace that prevents any straightening of his elbow. Orthopediatrician Dr Mandeep Dillon stated that Muralitharan's unusual ability to generate extra movement both at the shoulder as well the wrist enables him to bowl the doosra without straightening the elbow.
Critics and converts.
Two vocal critics of Muralitharan's action have been former test cricketers, Australian Dean Jones and Bishan Bedi, the former Indian captain. Dean Jones later admitted to being wrong in his assessment of Murali when he witnessed first hand Murali bowling with an arm-brace on.
Michael Holding, the former West Indian fast bowler was also a critic of Muralitharan, but withdrew his criticisms under the light of the tests carried out. Holding had been quoted as being in "110% agreement" with Bedi, who likened Murali's action to a "javelin throw" and more recently, compared to a "shot putter". Following the ICC study, as a member of the panel that conducted the study, Holding stated, "The scientific evidence is overwhelming ... When bowlers who to the naked eye look to have pure actions are thoroughly analysed with the sophisticated technology now in place, they are likely to be shown as straightening their arm by 11 and in some cases 12 degrees. Under a strict interpretation of the Law, these players are breaking the rules. The game needs to deal with this reality and make its judgment as to how it accommodates this fact."
In May 2002, Adam Gilchrist, speaking at a Carlton (Australian) Football Club luncheon, claimed Muralitharan's action does not comply with the laws of cricket. The Melbourne-based Age newspaper quoted Gilchrist as saying."Yeah, I think he does (chuck), and I say that because, if you read the laws of the game, there's no doubt in my mind that he and many others, throughout cricket history have." These comments were made before the doosra controversy, in spite of Muralitharan's action having been cleared by ICC in both 1996 and 1999. For his comment Gilchrist was reprimanded by the Australian Cricket Board (ACB) and found guilty of being in breach of ACB rules concerned with "detrimental public comment".
During the 2006 tour of New Zealand another Muralitharan critic, former New Zealand captain and cricket commentator Martin Crowe, called for Muralitharan's doosra to be monitored more closely, asserting that his action seemed to deteriorate during a match. Earlier that year when delivering the Cowdrey lecture at Lords Martin Crowe had demanded zero tolerance instead of 15 degrees for throwing and specifically branded Muttiah Muralitharan a chucker. In response to Crowe's criticism ICC general manager Dave Richardson stated that the scientific evidence presented by biomechanists Professor Bruce Elliot, Dr Paul Hurrion and Mr Marc Portuswith was overwhelming and clarified that "Some bowlers, even those not suspected of having flawed actions, were found likely to be straightening their arms by 11 or 12 degrees. And at the same time, some bowlers that may appear to be throwing may be hyper-extending or bowl with permanently bent elbows. Under a strict interpretation of the law, they were breaking the rules – but if we ruled out every bowler that did that then there would be no bowlers left."
Scientific research on bowling actions.
Since 1999 there has been a number of scientific research publications discussing Muralitharan's bowling action as well the need for defining the legality of a bowling action using biomechanical concepts. This research directly contributed towards the official acceptance of Muralitharan's bowling action and convinced the ICC to redefine the bowling laws in cricket.
The key publications are listed below:
Philanthropy.
Muralitharan, along with his manager Kushil Gunasekara, established the "Foundation of Goodness", a charity organization, in the early 2000s. This organization is committed to the wellbeing of the Seenigama region (in southern Sri Lanka) and supports local communities through a range of projects across areas including children's needs, education and training, health care and psycho-social support, housing, livelihoods, sport and the environment. Murali’s Seenigama project raised funds from cricketers and administrators in England and Australia. Canadian pop-star Bryan Adams donated a swimming pool.
Muralitharan also plans to build a second sports complex for war-displaced civilians in Mankulam, a town located 300 kilometers from north of Colombo. The two-year one million dollar project aims to build a sports center, a school, English and IT training centers and an Elders' home. While the Sports Complex remains the main project, "Foundation of Goodness" also plans to help educate children, youth and adults. English cricketer Sir Ian Botham visited Mankulam with Muralitharan, and later addressing the media in Colombo on 27 March 2011 said that he will consider a walk from Point Pedro (the extreme northern tip of Sri Lanka) to Dondra Head (the extreme southern tip of Sri Lanka) to raise funds for the project.
In June 2004, Muralitharan also joined the United Nations World Food Program as an ambassador to fight hunger among school children.
When the tsunami devastated Sri Lanka on 26 December 2004, Muralitharan galvanised into action to ensure that aid reached people that needed it. He himself narrowly escaped death, arriving 20 minutes late at Seenigama, where he was to give away prizes at one of the charity projects he worked on. While international agencies were bringing food in by air, there was an urgent need for transport, and Murali organised three convoys of 10 trucks each, paying for these himself, to get the food to people who needed it. He persuaded those who could to donate clothes, and supervised the delivery himself.
During the hard work of rehabilitation in the tsunami's aftermath, cement was in short supply. Muralitharan promptly signed an endorsement deal with Lafarge, a global cement giant, that was a straight barter, where cement would be supplied to the Foundation for Goodness in exchange for work Muralitharan did. During the first three years since the tsunami, the foundation raised more than US$ 4 million to help survivors, and has built homes, schools, sports facilities and computer centres.

</doc>
<doc id="20906" url="http://en.wikipedia.org/wiki?curid=20906" title="Mole Day">
Mole Day

Mole Day is an unofficial holiday celebrated among chemists, chemistry students and chemistry enthusiasts on October 23, between 6:02 AM and 6:02 PM, making the date 6:02 10/23 in the American style of writing dates. The time and date are derived from Avogadro's number, which is approximately 6.02×1023, defining the number of particles (atoms or molecules) in one mole of substance, one of the seven base SI units.
Mole Day originated in an article in "The Science Teacher" in the early 1980s. Inspired by this article, Maurice Oehler, now a retired high school chemistry teacher from Prairie du Chien, Wisconsin, founded the National Mole Day Foundation (NMDF) on May 15, 1991.
Many high schools around the United States, South Africa, Australia and in Canada celebrate Mole Day as a way to get their students interested in chemistry, with various activities often related to chemistry or moles.

</doc>
<doc id="20907" url="http://en.wikipedia.org/wiki?curid=20907" title="Motörhead">
Motörhead

Motörhead are an English rock band formed in June 1975 by bassist, singer, and songwriter Ian Fraser Kilmister, professionally known by his stage name Lemmy, who has remained the sole constant member. The band are often considered a precursor to, or one of the earliest members of, the New Wave of British Heavy Metal, which re-energised heavy metal in the late 1970s and early 1980s. 
Despite this, Lemmy has always dubbed their music as simply "rock and roll".
To date, Motörhead have released twenty-one studio albums, ten live recordings, twelve compilation albums and five EPs. Usually a power trio, they had particular success in the early 1980s with several successful singles in the UK Top 40 chart. The albums "Overkill", "Bomber", "Ace of Spades", and particularly "No Sleep 'til Hammersmith", cemented Motörhead's reputation as a top-tier rock band. As of 2012, Motörhead have sold more than 15 million albums worldwide.
Motörhead are typically classified as heavy metal, and their fusion of punk rock into the genre helped to pioneer speed metal and thrash metal. Their lyrics typically cover such topics as war, good versus evil, abuse of power, promiscuous sex, substance abuse, and, most famously, gambling. The name "Motörhead" is a reference to users of the drug amphetamine. The band's distinctive fanged-face logo, with its oversized boar's tusks, chains, and spikes, was created by artist Joe Petagno in 1977 for the cover of the "Motörhead" album and has appeared in many variations on covers of ensuing albums. The fanged face has been referred to variously as "War-Pig" and "Snaggletooth". The band is ranked number 26 on VH1's 100 Greatest Artists of Hard Rock.
History.
1970s.
1975–77 – Early years – The "Motörhead" album.
Lemmy was fired from Hawkwind in May 1975 for, as he says, "doing the wrong drugs". He was arrested on suspicion of possessing cocaine at the Canadian border and spent five days in prison, causing the band to cancel some of their North America tour dates. Now on his own, Lemmy decided to form a new band called Motörhead, inspired by the final song he had written for Hawkwind.
Lemmy wanted the music to be "fast and vicious, just like the MC5". His stated aim was to "concentrate on very basic music: loud, fast, city, raucous, arrogant, paranoid, speedfreak rock n roll ... it will be so loud that if we move in next door to you, your lawn will die". On the recommendation of Mick Farren, he recruited Larry Wallis (ex-Pink Fairies) on electric guitar and Lucas Fox on drums. According to Lemmy, the band's first practice was in a furniture store in Chelsea, England in 1975. Kilmister has said they used to steal equipment, as the band was short on gear. Their first engagement was supporting Greenslade at The Roundhouse, London on 20 July 1975. On 19 October, having played 10 engagements, they became the supporting act to Blue Öyster Cult at the Hammersmith Odeon.
The band were contracted to United Artists by Andrew Lauder, the A&R man for the band Lemmy was previously in, Hawkwind. They recorded sessions at Rockfield Studios in Monmouth with producer Dave Edmunds, during which Fox proved to be unreliable and was replaced by drummer Phil "Philthy Animal" Taylor, a casual acquaintance of Lemmy's. Their record label was dissatisfied with the material and refused to release it, although it was subsequently issued as "On Parole" in 1979 after the band had established some success.
In March 1976, deciding that two guitarists were required, the band auditioned "Fast" Eddie Clarke. Wallis, who was continuing to tour with a reformed Pink Fairies, quit immediately after the auditions and Clarke remained as the sole guitarist. This trio of Lemmy/Clarke/Taylor is today regarded as the "classic" Motörhead line-up. In December, the band recorded the "Leaving Here" single for Stiff Records, but United Artists intervened to prevent its general release as the band were still under contract to them, despite their refusal to issue their debut album. Initial reactions to the band had been unfavourable; they won a poll for "the best worst band in the world" in the music magazine "NME".
By April 1977, living in squats and with little recognition, Taylor and Clarke wanted to give it up, and after some debate, the band agreed to do a farewell show at the Marquee Club in London. Lemmy had become acquainted with Ted Carroll from Chiswick Records and asked him to bring a mobile studio to the show to record it for posterity. Carroll was unable to get the mobile unit to the Marquee Club but showed up backstage after the engagement and offered them two days at Escape Studios with producer Speedy Keen to record a single. The band took the chance, and instead of recording a single they laid down 11 unfinished tracks. Carroll gave them a few more days at Olympic Studios to finish the vocals and the band completed 13 tracks for release as an album. Chiswick issued the single "Motorhead" in June, followed by the album "Motörhead" in August, which spent one week in the UK Albums Chart at number 43. The band toured the UK supporting Hawkwind in June, then from late July they commenced the "Beyond the Threshold of Pain" tour with The Count Bishops.
In August, Tony Secunda took over the management of the band, and their cohesiveness became so unstable that by March 1978, Clarke and Taylor had formed and were performing as The Muggers with Speedy Keen and Billy Rath.
1978–79 – Rise to success: "Overkill" and "Bomber".
In July 1978, the band returned to the management of Douglas Smith, who secured a one-off singles deal with Bronze Records. The resulting "Louie Louie" single was issued in September peaking at number 68 on the UK Singles Chart, and the band toured the UK to promote it, recorded a BBC Radio 1 "John Peel in session" on 18 September (these tracks were later issued on the 2005 "BBC Live & In-Session" album), and appeared for the first time on BBC Television's "Top of the Pops" on 25 October. Chiswick capitalised on this new level of success by re-issuing the debut album "Motörhead" on white vinyl through EMI Records.
The single's success led to Bronze extending their contract, and put the band back into the studio to record an album, this time with producer Jimmy Miller at Roundhouse Studios. A hint of what the band had recorded for the album came on 9 March 1979 when the band played "Overkill" on "Top of the Pops" to support the release of the single ahead of the "Overkill" album, which was released on 24 March. It became Motörhead's first album to break into the top 40 of the UK Albums chart, reaching number 24, with the single reaching number 39 on the UK Singles Chart. These releases were followed by the "Overkill" UK tour which began on 23 March. A subsequent single was released in June, coupling the album track "No Class" as the A-side with the previously unreleased song "Like a Nightmare" on the B-side. It fared worse than both the album and previous single but reached number 61 on the UK singles chart.
During July and August, except for a break to appear at the Reading Festival, the band were working on their next album, "Bomber". Released on 27 October, it reached number 12 on the UK Albums Chart. On 1 December, it was followed by the "Bomber" single, which reached number 34 on the UK Singles Chart. The "Bomber" Europe and UK tour followed, with support from Saxon. The stage show featured a spectacular aircraft bomber-shaped lighting rig. During the "Bomber" tour, United Artists put together tapes recorded during the Rockfield Studios sessions in 1975–1976 and released them as the album "On Parole", which peaked at number 65 on the UK Albums Chart in December.
On 8 May 1980, while the band were on tour in Europe, Bronze released "The Golden Years", which sold better than any of their previous releases, reaching number eight on the UK Singles Chart. The band had, however, preferred the title "Flying Tonight", in reference to the "Bomber" lighting rig. On 20 August, the band (40 minutes) and Girlschool (20 minutes) were filmed performing live at the Nottingham Theatre Royal for the "Rockstage" programme, broadcast on UK television by the ATV station on 4 April 1981.
1980s.
1980–82 – "Ace of Spades" and "Iron Fist".
During August and September 1980, the band were at Jackson's Studios in Rickmansworth, recording with producer Vic Maile. The "Ace of Spades" single was released on 27 October 1980 as a preview of the "Ace of Spades" album, which followed on 8 November. The single reached No. 15 and the album reached No. 4 on the UK charts. Bronze celebrated its gold record status by pressing a limited edition of the album in gold vinyl.
Motörhead made an appearance on "Top of the Pops" in November that year with "Ace of Spades", and between 22 October and 29 November the band were on their "Ace Up Your Sleeve" UK tour with support from Girlschool and Vardis, and also made an appearance as guests on the ITV children's show "Tiswas" on 8 November. The "Arizona desert-style" pictures used on the album sleeve and tour booklet cover were taken during a photo session at a sandpit in Barnet. "Ace of Spades", considered to be the definitive Motörhead anthem, "put a choke on the English music charts and proved to all that a band could succeed without sacrificing its blunt power and speed".
To coincide with the "Ace of Spades" release, Big Beat, who had inherited the Chiswick catalogue, put together four unused tracks from the Escape Studios sessions in 1977 and released them as "Beer Drinkers and Hell Raisers", which reached No. 43 on the UK Singles Chart in November.
The band had more chart hits in 1981 with the releases "St. Valentine's Day Massacre" EP, their collaboration with Girlschool which reached No. 5 on the UK Singles Chart in February; the live version of "Motorhead", which reached No. 6 on the UK Singles Chart in July; and the album it was taken from, "No Sleep 'til Hammersmith", which reached No. 1 on the UK Albums Chart in June. During March 1981, the band had been touring Europe, and in the final week of the month they conducted the "Short Sharp, Pain In The Neck" UK tour from which the recordings for "No Sleep 'til Hammersmith" were made.
From April through to July, the band toured North America for the first time ("Ace of Spades" was their debut release in the region) as guests of Blizzard of Ozz, an early incarnation of Ozzy Osbourne's band, but were still able to make an appearance on "Top of the Pops" on 9 July to promote the live "Motorhead" single. In October the band recorded tracks at BBC's Maida Vale 4 studio for the David Jensen show broadcast on 6 October. The band commenced a European tour on 20 November, supported by Tank, followed by Clarke producing Tank's debut album "Filth Hounds of Hades" at Ramport Studios in December and January.
Between 26 and 28 January 1982, the band started recording their self-produced new album at Ramport Studios, before moving onto Morgan Studios to continue the sessions throughout February. On 3 April the single "Iron Fist" was released, reaching No. 29 on the UK Singles Chart, followed by the parent album "Iron Fist", released on 17 April and peaking at No. 6 on the UK Albums Chart. They were the last releases to feature the Lemmy, Clarke, Taylor line-up, though the line-up continued to perform in the "Iron Fist" UK tour between 17 March and 12 April, and the band's first headlining North America tour from 12 May until Clarke's last engagement at the New York Palladium on 14 May.
1982–84 – Departures from the band and "Another Perfect Day".
Clarke left as a consequence of the band recording "Stand By Your Man", a cover version of the Tammy Wynette classic, in collaboration with Wendy O. Williams and the Plasmatics. Clarke felt that the song compromised the band's principles, refused to play on the recording and resigned, later forming his own band, Fastway. Lemmy and Taylor made numerous telephone calls to find a guitarist, including one to Brian Robertson, formerly with Thin Lizzy, who was recording a solo album in Canada. He agreed to help out and complete the tour with them. Robertson signed a one-album deal resulting in 1983's "Another Perfect Day" and the two singles from it, "Shine" and "I Got Mine".
In June and July the band played five dates in Japan, and from mid-October until mid-November they toured Europe. From late May until early July, the band conducted the 'Another Perfect Tour', followed by an American tour between July and August, and another European tour in October and November. Robertson began to cause friction in the band as a result of his on-stage attire, consisting of shorts and ballet shoes, and, furthermore, with his point blank refusal to play the old standards that every Motörhead audience expected to hear. This led to an amicable agreement that Robertson would leave, playing his last engagement with the band at the Berlin Metropol on 11 November.
After Robertson's departure in 1983, the band were sent tapes from all over the world from potential guitarists. The group returned to the concept of dual lead guitars by hiring unknowns Würzel and Phil Campbell (ex-Persian Risk). In February 1984, the Lemmy, Campbell, Würzel, and Taylor line-up recorded "Ace of Spades" for the "Bambi" episode in the British television series, "The Young Ones". Scenes of the band playing are interspersed with the characters' antics as they rush to the railway station, in a parody of The Beatles' comedy film "A Hard Day's Night". Taylor quit the band after that recording, causing Lemmy to quip: "Did I leave them or did they leave me?". Before joining Motörhead, Phil Campbell had met ex-Saxon drummer Pete Gill, and the trio decided to call him to see if he would like to visit London. The try-outs went well and Gill was hired.
1984–85 – "No Remorse".
Bronze Records thought the new line-up would not make the grade and decided to "nail down the lid" on the group with a compilation album. When Lemmy found out, he took over the project, selecting tracks, providing sleeve notes and insisted that Motörhead record four brand new tracks to go at the end of each side of the album. During the sessions between 19 and 25 May 1984 at Britannia Row Studios, London, the band recorded six tracks for the single's B-side and the album. The single "Killed by Death" was released on 1 September and reached No. 51 in the UK Singles Chart, the double album "No Remorse" was released on 15 September and reached silver disc status, attaining the position of No. 14 in the UK Album charts.
The band were involved in a court case with Bronze over the next two years, believing that their releases were not being promoted properly, and the record company banned them from the recording studio. The band looked to more touring for income; Australia and New Zealand in late July to late August, a brief tour of Hungary in September, and the "No Remorse" "Death On The Road" tour between 24 October and 7 November. On 26 October the band made a live appearance on the British Channel 4 music programme The Tube, performing "Killed By Death", "Steal Your Face" (over which the programme's end-credits were played) and the unbroadcast "Overkill", before going on to their next engagement that evening. From 19 November to 15 December the band toured America with Canadian speed metal band Exciter and Danish Metal band Mercyful Fate and from 26 to 30 December performed five shows in Germany.
On 5 April 1985, ITV broadcast four songs that were recorded after the band went off air on their earlier appearance on "The Tube" programme. A week later the band, dressed in tuxedos, played four songs on the live Channel 4 music show "ECT" (Extra-Celestial Transmission). To celebrate the band's tenth anniversary, two shows were arranged at Hammersmith Odeon on 28 and 29 June, a video of the second show was taken and later released as "The Birthday Party". From early June until early August the band were on their 'It Never Gets Dark' tour of Sweden and Norway, an American tour followed in mid-November until late December.
1986–89 – "Orgasmatron" and "Rock 'n' Roll".
From 26 March to 3 April 1986, the band toured Germany, the Netherlands and Denmark on their "Easter Metal Blast" and in June, played two dates in Bologna and Milan in Italy. The court case with Bronze was finally settled in the band's favour. The band's management instigated their own label, GWR. Recording took place in Master Rock Studios, London and the single "Deaf Forever" was released on 5 July as a taster for the "Orgasmatron" album, which was released on 9 August. On the same day as the release of the album, Lemmy and Würzel were interviewed by Andy Kershaw on the BBC Radio 1 "Saturday Live" show and "Orgasmatron" and "Deaf Forever" were played. The single reached No. 67 and the album reached No. 21 in the UK charts.
On 16 August, the band played at the Monsters of Rock at Castle Donington and was recorded by BBC Radio 1 for a future "Friday Rock Show" broadcast. The performance closed with a flyover by a couple of Second World War German aircraft. Also that day Lemmy was filmed giving his views on spoof metal act "Bad News" for inclusion in a Peter Richardson Comic Strip film entitled "More Bad News" since the band featuring Rik Mayall, Peter Richardson, Nigel Planer and Adrian Edmondson were also performing at Donington. In September the band conducted their "Orgasmatron" tour in Great Britain, supported by fledgling act Zodiac Mindwarp and the Love Reaction. In October they toured America and in December were in Germany.
In 1987, during the filming of "Eat the Rich" — in which Lemmy was taking a starring role alongside well-known comedy actors such as Robbie Coltrane, Kathy Burke, the regulars from The Comic Strip ensemble, and various other musician cameo appearances — Gill left the band and Taylor returned to appear in the band's cameo as "In House Club Band" alongside Würzel and Campbell. The band wrote "Eat the Rich" especially for the film, its soundtrack featured tracks from "Orgasmatron" and Würzel's solo single "Bess". The band's second album for GWR was "Rock 'n' Roll", released on 5 September, after a tight work schedule in the studio. While having some popular tracks and using "Eat the Rich" as its second track, the band commented that the album was virtually "nailed together".
On 2 July 1988 Motörhead were one of the performers at the Giants of Rock Festival in Hämeenlinna, Finland. The tracks were released as "No Sleep at All" on 15 October. A single from the album was planned with the band wanting "Traitor" as the A-side, but "Ace of Spades" was chosen instead. When the band noticed the change, they refused to allow the single to be distributed to the shops, and it was withdrawn and became available only on the "No Sleep at All" tour and through the "Motörheadbangers" fan club. While they continued to play live shows during 1989 and 1990, Motörhead once again felt unhappy with their career, and a court case with GWR followed, which was not resolved until mid-1990.
1990s.
1990–92 – Epic/WTG years: "1916" and "March ör Die".
With the court case resolved, Motörhead signed to Epic/WTG and spent the last half of 1990 recording a new album and single in Los Angeles. Just prior to the album sessions the band's former manager, Doug Smith, released the recording of the band's tenth anniversary show, much against the bands wishes, having previously told him that they did not want it released, in 1986. In the studio they recorded four songs with the producer, Ed Stasium, before deciding he had to go.
When Lemmy listened to one of the mixes of "Going to Brazil", he asked for him to turn up four tracks, and on doing so heard claves and tambourines that Stasium had added without their knowledge. Stasium was fired and Pete Solley was hired as producer. The story according to Stasium was that Lemmy's drug and alcohol intake had far exceeded the limitations of Stasium's patience so he quit. The single "The One to Sing the Blues" issued on 24 December 1990 (7" and CD) and 5 January 1991 (12"), was followed by the album "1916" on 21 January. The single, which was issued in 7", cassette, shaped picture disc, 12" and CD single, reached No. 45 in the UK Singles Chart, the album reached No. 24 in the UK Album Charts.
The band conducted their "It Serves You Right" tour of Britain in February, the "Lights Out Over Europe" tour followed, lasting until early April, when the band returned to Britain to play another six venues. In June the band played five dates in Japan and five dates in Australia and New Zealand. Between July and August, they played across the United States with Judas Priest, Alice Cooper and opener Dangerous Toys on the 'Operation Rock 'n' Roll' tour. The band finished the year with six dates in Germany during December.
On 28 March 1992 the band played what would turn out to be Taylor's last engagement at Irvine Meadows, Irvine, California. The band had been wanting Lemmy to get rid of their manager, Doug Banker, for some time and after an unsolicited visit from Todd Singerman, who insisted he should manage them despite never having managed a band before, the band met with Singerman and decided to take him on board, firing Banker. In the midst of this, the band were recording an album at Music Grinder Studios, in the city's east part of Hollywood during the 1992 Los Angeles riots. Three drummers participated in the making of the "March ör Die" album: Phil Taylor, who was fired because he did not learn the drum tracks on the song "I Ain't No Nice Guy"; Tommy Aldridge who recorded most of the material on the album; and Mikkey Dee, who recorded "Hellraiser", a song originally written by Lemmy for Ozzy Osbourne's "No More Tears" album. The "March ör Die" album features guest appearances by Ozzy Osbourne and Slash.
1993–94 – "Bastards".
Lemmy had known Mikkey Dee from the time when King Diamond had toured with Motörhead. He had asked Dee to become Motörhead's drummer before, but Dee had declined due to his commitment to King Diamond. On this occasion, Dee was available and met the band to try out. Playing the song "Hellraiser" first, Lemmy thought "he was very good immediately. It was obvious that it was going to work." After recording "Hellraiser" and "Hell on Earth" in the studio, Dee's first engagement with Motörhead was on 30 August at the Saratoga Performing Arts Center. The new line-up then went on tour, playing dates with Ozzy Osbourne, Skew Siskin and Exodus. On 27 September, the band played at the Los Angeles Coliseum with Metallica and Guns N' Roses. The band toured Argentina and Brazil during October and conducted the "Bombers and Eagles in '92" tour of Europe with Saxon throughout December.
Motörhead played two dates at the Arena Obras Sanitarias in Buenos Aires in April 1993 and toured Europe from early June until early July, returning to the states to play one show at the New York Ritz on 14 August. A new producer was sought for the band's next album and eventually Howard Benson, who was to produce the band's next four albums, was chosen. The band recorded at A & M Studios and Prime Time Studios in Hollywood and the resultant album, "Bastards", was released on 29 November 1993. The single "Don't Let Daddy Kiss Me" included the song "Born to Raise Hell" which also appeared on the album and would later be re-recorded with collaborative vocals from both Ice-T and Ugly Kid Joe frontman, Whitfield Crane and released as a single in its own right. Although "Bastards" received airtime, the record company, ZYX, would not pay for promotional copies, so the band sent out copies themselves. A further tour of Europe was made throughout December that year.
In February and March 1994, Motörhead toured the United States with Black Sabbath and Morbid Angel. In April the band resumed their tour of the States until early May, playing an engagement with the Ramones on 14 May at the Estadio Velez in Buenos Aires, attracting a crowd of 50,000 people. The band toured Japan in late May and Europe in June, August and December.
1994–95 – "Sacrifice".
The band's 1995 touring schedule began in Europe in late April. In June, they went on a second tour with Black Sabbath, this time supported by Tiamat, until the band succumbed to influenza and headed back to Los Angeles, to Cherokee Studios in Hollywood where they were to record an album. During the sessions it became clear that Würzel was not extending himself and left the band after the recording. The title track from the album, "Sacrifice", was later used in the movie "Tromeo and Juliet", a film in which Lemmy appears as the narrator. The band decided to continue as a three-man line-up and a tour of Europe was performed throughout October and the first two days of November. A three-day tour of South America followed the week after. Lemmy celebrated his 50th Birthday later that year with the band at the Whiskey A Go Go in Los Angeles; Metallica played at the event under the name "The Lemmy's".
In 1996 the band began touring the States in early January and played thirty venues up to 15 February a seven-date tour of Europe in June and July was followed by two engagements in South America during August.
1996–97 – "Overnight Sensation".
A tour of the United States with Dio and Speedball began with two shows (Los Angeles & Hollywood) in early October 1996 and concluded in Washington on 4 December. During this time the band had recorded "Overnight Sensation", at Ocean Studio and Track House Recording Studio. The album was released on 15 October, the first official album of the band as a three-piece since "Another Perfect Day" and the best distributed album the band had had for years. The band concluded the year's touring with thirteen dates in Germany.
During 1997, the band toured extensively, beginning with the first leg of the "Overnight Sensation" tour in Europe on 12 January at the London Astoria, where the guest musicians were Todd Campbell, Phil Campbell's son, on "Ace of Spades" and Fast Eddie Clarke for "Overkill". The European leg lasted until March and was followed by four dates in Japan, from late May to 1 June, and an American tour with W.A.S.P. throughout the rest of June. In August, three dates in Europe were followed by seven dates in Britain, which ended with a show at the Brixton Academy on 25 October, where the guest musician was Paul Inder, Lemmy's son, for "Ace of Spades". A further four dates in October in Russia concluded the year 1997.
1998–99 – "Snake Bite Love" and "Everything Louder Than Everyone Else" (live).
Lemmy recalled that the touring was going particularly well, with some countries like Argentina and Japan putting the band in larger venues, and the English promoters discovered that "they could turn a nice profit with Motörhead shows". In his opinion the three-piece line-up were performing excellently and it was high time they made another live record. The band did eventually, but made another studio album first, "Snake Bite Love", recorded in various studios and released on 3 March 1998.
The band joined with Judas Priest at the Los Angeles Universal Amphitheatre on 3 April, to begin their "Snake Bite Love" tour. On 21 May, Motörhead were recorded at The Docks in Hamburg. The tracks from this performance were later released as "Everything Louder Than Everyone Else". The band were invited to join the Ozzfest Tour and played dates across the States during early July until early August and were in Europe from early October until late November. The British leg of the tour was dubbed the "No Speak With Forked Tongue" tour and included support bands Groop Dogdrill, Radiator and Psycho Squad, which was fronted by Phil Campbell's son Todd.
2000s.
2000–01 – "We Are Motörhead" and "25 & Alive Boneshaker" DVD.
In 1999 Motörhead made a tour of the states between 20 April and 2 June, before going to Karo Studios in Brackel, Germany to record their next album, "We Are Motörhead", which was released in May the following year. During the time the album sessions took place, the band played at venues around Europe, the first of which was at Fila Forum in Assago, near Milan, where Metallica's James Hetfield joined the band on-stage to play "Overkill". In October and early November, the band toured the states with Nashville Pussy. Throughout the rest of November, the band conducted their European "Monsters Of The Millennium" tour with Manowar, Dio and Lion's Share, ending the Millennium with two shows at the London Astoria. The two shows were billed under the "Kerrang!" "X-Fest" banner and at the first show were supported by Backyard Babies and during the second show guest vocals were provided by Skin from Skunk Anansie and Nina C. Alice from Skew Siskin for "Born to Raise Hell", and Ace from Skunk Anansie played "Overkill" with the band.
In May 2000, the release of "We Are Motörhead" and the single from it, a cover of the Sex Pistol's "God Save the Queen", coincided with the start of the band's "We Are Motörhead" tour across South and North America during May and June, with a further nine shows across in Europe in July. Shows in the United States and France were followed by the release of a double-disc compilation album, "The Best Of", on 26 August.
Four dates in Japan preceded the band's 25th Anniversary concert on 22 October at the Brixton Academy in London, where guest appearances were made by "Fast" Eddie Clarke, Brian May, Doro Pesch, Whitfield Crane, Ace, Paul Inder and Todd Campbell. The show also featured the return of the Bomber-lighting rig. The event was filmed and released the following year as the "25 & Alive Boneshaker" DVD, and the CD of the show, "Live at Brixton Academy", was released two years after that. Lemmy states the reason for the DVD as wanting "to record it for the posterity or whatever it is. I nodded off through the tenth anniversary, we never did anything on the twentieth, so the twenty-fifth made sense."
A tour of West and East Europe followed the anniversary concert, taking the band through October, November and December. The schedule for the Eastern European tour was quite brutal, involving two eighteen-hour drives back-to-back and little time off, at the Warsaw venue the band did not arrive until eleven o'clock and the crew were still loading into the venue at one in the morning, while the fans waited.
2002–03 – "Hammered".
After taking a month off, the band began working on a new album at Chuck Reid's house in the Hollywood Hills. This album, "Hammered", was released the following year. On 1 April 2001, the band gave a one song performance for Triple H's entrance at WrestleMania X-Seven at the Reliant Astrodome in Houston. The second leg of the "We Are Motörhead" tour began in May in Ireland, moving across to the United Kingdom. In Manchester, the band were supported by Goldblade, and by Pure Rubbish at the two London shows. The second London show also included Backyard Babies and Paul Inder, who was guest musician for "Killed By Death". Between June and August, Motörhead played at a number of rock festivals in Europe; including as the Graspop Metal Meeting in Belgium, the Quart Festival in Norway, and the Wacken Open Air on 4 August, where four songs were recorded for the "25 & Alive Boneshaker" DVD. The band returned to the States for a seven show tour between late September and early October.
In April 2002, a DVD of some of Motörhead's performances from the '70s and '80s along with some stock footage of the band was released as "The Best of Motörhead". Two weeks earlier, the "Hammered" album was released and supported by the "Hammered" tour, which kicked off in the States at around the same time. The United States dates continued until late May, and a European leg followed between June and August. In October, the band played five dates in Great Britain with Anthrax, Skew Siskin and Psycho Squad. The final venue was the Wembley Arena in London, where instead of Psycho Squad, the band were supported by Hawkwind, with Lemmy performing "Silver Machine" on stage with them. Throughout the rest of October and better part of November, the band were on a European tour with Anthrax.
In April and May 2003, the band continued to promote the "Hammered" album in the States, and on the three dates Phil Campbell had to miss, his mother having died, Todd Youth stood in for him. Between late May and mid-July the band played seven dates at Summer Festivals in Europe and from late-July until the end of August, they were touring the United States with Iron Maiden and Dio. On 7 October a comprehensive five-disc collection of the band's recordings covering 1975–2002 was released as "Stone Deaf Forever!". On 1 September 2003, the band returned to Hollywood's Whisky A Go-Go club for the Hollywood Rock Walk Of Fame Induction. During October, the band performed a tour of Great Britain with The Wildhearts and Young Heart Attack. The band performed seven shows across Belgium, the Netherlands and Spain between 21 and 28 October and from late-November until early-December they were in Germany and Switzerland, touring with Skew Siskin and Mustasch. On 9 December, the previously recorded "Live at Brixton Academy" album was released.
2004–05 – "Inferno" and "Stage Fright" (DVD).
On 22 February 2004 Motörhead performed an invitation-only concert at the Royal Opera House in Covent Garden, London; at Summer Festivals in South America during May; and also Europe during June, July and August. The band had already spent time in the recording studio, working on their next album, "Inferno", which was released on 22 June and was followed by the "Inferno" tour of Ireland with Class Of Zero for three dates, before being joined by Sepultura and taking it to Great Britain.
Some of the London show at the Hammersmith Apollo was filmed for TV as Gene Simmons introduced the extra opening act, The Class — a band made up of school children appearing in his Channel 4 series, "Rock School" — and Würzel joined as guest musician for "Overkill". The band continued the tour with Sepultura across Europe through the rest of November and December. At the show in Magdeburg, Germany on 4 December Motörhead joined Sepultura on stage during their support slot playing the song "Orgasmatron", in celebration of Sepultura's 20th Anniversary. The show on 7 December at the Philipshalle in Düsseldorf was recorded and later released as the "Stage Fright" DVD.
Motörhead picked up their first Grammy in the awards of 2005 in the Best Metal Performance category for their cover of Metallica's "Whiplash" on "". From March until early May, the band toured the United States, and in June and August were on the "30th Anniversary" tour in Europe. On 22 August, the band were the subject of an hour-long documentary, "Live Fast, Die Old", which was aired on Channel 4 as part of "The Other Side" series of documentaries, filmed by new and established directors.
On 20 September, a compilation album containing the band's appearances on BBC Radio 1 and a concert recording from Paris Theatre, London, was released as "BBC Live & In-Session". In October, the band toured Europe with Mondo Generator before returning to Great Britain to tour with In Flames and Girlschool in October and November. During the show at the Brixton Academy on 19 November, Lemmy joined Girlschool on stage to play "Please Don't Touch". Motörhead finished the year's tours in December, with two engagements in New Zealand and five in Australia with Mötley Crüe. Also in 2005, Motörhead played on the Vaya Con Tioz farewell festival Böhse Onkelz at Lausitzring.
In 2006, the band performed a four-date House Of Blues tour in the States in March with Meldrum and from June until early August played at European open-air festivals with some indoor headlining shows. On 28 October, the band performed at The Rock Freakers Ball in Kansas City before heading off to tour Great Britain with Clutch and Crucified Barbara.
2006–07 – "Kiss of Death".
While that tour was still going, their next album, "Kiss of Death", was released on 29 August 2006 via Sanctuary Records, with a video for "Be My Baby". The tour ended with an engagement on 25 November at the Brixton Academy, where Phil Campbell was guest guitarist for "Killed By Death" played during Crucified Barbara's support set. A further twelve shows in Europe with Meldrum took them through the end of November to early December, the first two shows also featuring Skew Siskin.
In November, the band agreed to a sponsorship deal with the Greenbank B under-10s football team from North Hykeham, Lincoln, putting the band's name as well as War-Pig on the team's shirts; the under-10s run out to "Ace of Spades". Lemmy is old friends with Gary Weight, the team's manager; Weight "sent an email off to them and they came back and said it was a great idea" and hopes the deal will draw inspired performances from his team. On 25 April 2007, the band played at the Poliedro de Caracas in Caracas, Venezuela, and on 29 April at the Fundiçao Progresso, Rio de Janeiro. In June, Motörhead played an engagement at the Royal Festival Hall as part of Jarvis Cocker's Meltdown. On 26 February 2008, No Sleep 'Til Hammersmith was reissued again as a two disc CD.
2008–09 – "Motörizer".
From March through to June 2008, the band convened in Los Angeles with producer Cameron Webb to begin work on their 19th album "Motörizer". Mikkey Dee's drum tracks were recorded at Dave Grohl's studio. Motörizer was released on 26 August. It does not feature artwork from Joe Petagno, the artist who designed many of their classic album covers.
In June 2008 the band performed at the main stage of the Download festival. Between 6 and 31 August, Motörhead joined with Judas Priest, Heaven & Hell and Testament on the Metal Masters Tour. On 20 August the band played one date at the Roseland Ballroom, New York, as part of "The Volcom Tour 2008", which continued with bands The Misfits, Airbourne, Valient Thorr and Year Long Disaster at House of Blues, Anaheim, California on 2 September, playing a further thirteen dates. The band concluded the tour without the supporting bands, playing one more show at the Roseland Ballroom on 20 September, and the final engagement, at The Stone Pony, Asbury Park, New Jersey on 21 September.
On 30 September, Reuters reported that Neverdie Studios had signed a deal with Lemmy and Motörhead to develop and market Lemmy's Castle and Motorhead Stadium inside the virtual world of Entropia Universe, an online virtual universe. The year's touring ended with a 34-date tour of Europe with a variety of support bands including Danko Jones, Saxon, Witchcraft, and Airbourne. On 6 March 2009, the band played in the Middle East for the first time, at the annual Dubai Desert Rock Festival in Dubai. On 1 April Motörhead are reported to have entered into a two-year sponsorship deal with UK Roller Derby team the Lincolnshire Bombers Roller Girls.
In November 2009, the band are being supported by NWOBHM veterans Sweet Savage on the Irish leg of the tour (30 years after first sharing the stage together) and punk and goth rock legends The Damned on the UK leg of their world tour. On The Damned's official website, Captain Sensible is quoted as saying: "Ha ha ... we're working with Lemmy again are we? Excellent! He's the real deal, the absolute antithesis to all that the likes of Simon Cowell stand for. And for that we should all be grateful. This tour will be a celebration of all things rock 'n' roll ... pity the poor roadies is all I can say!"
2010s.
2010–12 – "The Wörld Is Yours" and "The Wörld Is Ours - Vol. 1" (DVD).
In a November 2009 interview with ABORT Magazine's E.S. Day, Lemmy stated that Motörhead would enter the studio in February 2010 "to rehearse, write and record" their 20th studio album, to be released on 14 December 2010. The album was recorded with Cameron Webb and Welsh producer Romesh Dodangoda in Longwave Studio, Cardiff.
In an interview with Hungarian television in July 2010, drummer Mikkey Dee announced that the album was finished, with 11 tracks. The album's name was said to be "The Wörld Is Yours". On 3 November 2010, Future PLC, a UK media company, announced that Motörhead were to release "The Wörld is Yours" via an exclusive publishing deal with "Classic Rock" magazine on 14 December. The standard CD release of "The Wörld is Yours" would go on sale on 17 January 2011, through Motörhead's own label, Motörhead Music.
To coincide with the release of their upcoming album, Motörhead embarked on a 35th Anniversary UK tour, from 8–28 November 2010, and a European tour from 30 November 2010 – 19 December 2010. They also took their tour to the Americas in 2011. In October, the band recorded a slow blues version of their longtime hit "Ace of Spades" for a TV spot for Kronenbourg beer. The file will be available for free download from the Kronenbourg website.
On 5 December the single "Get Back In Line" was released, followed by the release of a video for the single on 6 December.
In December, Mikkey Dee stated to French journalists that Motörhead are planning to release a box-set with several DVDs in 2011. He did not give any details but said that it will come in a "beautiful package including many surprises".
On 17 January 2011, it was announced that Motörhead would be part of the Sonisphere Festival in Knebworth. In August 2011, they headlined the Brutal Assault open-air festival in the Czech Republic. On 2 March 2011 Motörhead performed on "Late Night with Jimmy Fallon".
On 9 July 2011, former guitarist Würzel died of a heart attack.
In an interview at Germany's Wacken Open Air festival on 6 August 2011, Lemmy said that the next Motörhead album may be an album featuring song covers.
In celebration of their 35 years on the road, it was announced on 24 November 2011 the release (on 18 November 2011 in Germany & Europe, on 21 November 2011 in the UK and on 24 January 2012 in North America) of "The Wörld Is Ours - Vol 1 - Everywhere Further Than Everyplace Else", a live DVD of Motörhead's last global tour to date including performances on 16 November 2010 at Manchester's O2 Apollo, on 28 February 2011 at New York City's Best Buy Theater and on 9 April 2011 at Santiago de Chile's Teatro Caupolican.
On 19 December 2011, it was announced that Motörhead would playing at the German festivals Rock am Ring and Rock im Park in Nürburgring and Nuremberg respectively in June 2012. Linkin Park, Metallica, Soundgarden, The Offspring, Opeth and Marilyn Manson were also on the bill. On 12 January 2012, it was announced that Motörhead were touring the United States and Canada in early 2012, along with three other metal bands Megadeth, Volbeat and Lacuna Coil. The Gigantour took place from 26 January to 28 February 2012. Motörhead didn't play the final four shows during this tour, since Lemmy has experienced a combination of a viral upper respiratory infection and a voice strain, resulting in severe laryngitis. Lemmy wrote this message on Facebook, "I'm giving my voice a good rest", hoping he would recover soon to play at the Mayhem Festival, which was held from 30 June to 5 August 2012. Motörhead also took part on 23 June in the Rock-A-Field Luxembourg Open Air Festival in Roeser, Luxembourg.
2012–14 – "The Wörld Is Ours - Vol. 2" (DVD) and "Aftershock".
In an April 2012 interview with Classic Rock Revisited, Lemmy was asked if Motörhead were planning to make a follow-up to "The Wörld Is Yours". He replied, "We have not started writing any songs yet but we will. We put out an album out every two years. I will continue to do that as long as I can afford an amp." On 28 June 2012, Lemmy told Auburn Reporter that Motörhead will release their next album in 2013 and they had written "about 6 songs so far." On 23 October 2012, Lemmy told Billboard.com that the band had planned to enter the studio in January to begin recording the album for a mid-2013 release. On 28 February 2013, it was announced that Motörhead had begun recording their new album. Motörhead released the live DVD "The Wörld Is Ours - Vol. 2 - Anyplace Crazy As Anywhere Else" in September 2012. On 18 June 2013, the new album's title was revealed to be "Aftershock".
In mid November 2013, Motörhead were due to embark on a European tour alongside Saxon, followed by a tour in Germany and Scandinavia due to last until mid December 2013 but the dates were postponed and rescheduled for February and March 2014 due to Lemmy's health problems. However, in January 2014, Motörhead announced the cancellation of the new February and March dates of their European tour as Lemmy was still to reach full recovery from diabetes related health problems. But the same month, the band was confirmed for Coachella Festival to take place across two weekends in spring 2014 (12–14 and 19–21 April) in Indio, California, the exact dates to be revealed as 13 and 20 April 2014. In February 2014, Motörhead confirmed a Summer tour 2014 with eight European dates (from 24 June to 10 August) in France (2 dates), Switzerland, Italy, Germany (2 dates), Russia and Ukraine. In March 2014, the band announced a Los Angeles date on 11 April 2014 at Club Nokia. Later on, two new dates on 17 and 18 April 2014 respectively in Las Vegas (Pearl) and San Francisco (Warfield) were added. Still in March 2014, Motörhead announced that three heavy metal bands Megadeth, Anthrax and themselves will perform from 22 to 26 September 2014 at the first annual Motörhead's Motörboat cruise on board the Carnival Ecstasy (self-proclaimed "The Loudest Boat In The World"), due to sail from Miami and visit the ports of Key West and the Cozumel island just off Mexico's Yucatán Peninsula...
2014–present – New album.
In a September 2014 interview on Full Metal Jackie, Lemmy stated that Motörhead will "probably" enter the studio in January 2015 to start work on their 22nd studio album for a tentative late 2015 release. On 25 February 2015, Motörhead officially confirmed being currently in the studio recording in Los Angeles with their longtime producer, Cameron Webb, working on the follow-up to their previous studio album "Aftershock".
Style.
In a biography of the band, senior editor for AllMusic, Stephen Erlewine, wrote: "Motörhead's overwhelmingly loud and fast style of heavy metal was one of the most groundbreaking styles the genre had to offer in the late '70s" and though "Motörhead wasn't punk rock ... they were the first metal band to harness that energy and, in the process, they created speed metal and thrash metal." Whether they created these genres might be subject to debate, but Motörhead were unquestionably influential.
Although Mötorhead is often considered as a heavy metal band, Lemmy has always described Mötorhead's music as simply rock and roll. In 2011 he said: "We were not heavy metal. We were a rock'n'roll band. Still are. Everyone always describes us as heavy metal even when I tell them otherwise. Why won't people listen?"
Lemmy has stated that he generally feels more kinship with punk rockers than with metal bands: Motörhead had engagements with fellow Brits The Damned, with whom he played bass on a handful of late 1970s engagements, as well as having penned the song "R.A.M.O.N.E.S." as a tribute to the Ramones. Motörhead, Lemmy states, have more in common aesthetically with The Damned than Black Sabbath, and nothing whatsoever in common with Judas Priest. Lemmy says he feels little kinship with the speed metal bands Motörhead have inspired:"They've just got the wrong bit. They think that being fast and loud is the whole thing and it isn't. The guitar solos are not really difficult for a guitar player, it's just playing scales. To feel a solo and bend into it & I mean Hendrix is the best guitarist you've ever seen in your life. And he learned from people like Buddy Guy, Lightnin' Hopkins and people like that inspired Hendrix. To be influenced by something, you're gonna have to play it the same."
The "NME" stated that their brief solos were just long enough "... to open another bottle of beer", while a 1977 "Stereo Review" commented that "they know they're like animals, and they don't want to appear any other way. In view of the many ugly frogs in heavy metal who think they are God's gift to womankind these Quasimodos even seem charming in their own way". Motörhead's approach has not changed drastically over the band's career, though this is a deliberate choice: erstwhile Motörhead drummer Phil "Philthy Animal" Taylor said that rock icons like Chuck Berry and Little Richard never drastically altered their style, and, like them, Motörhead preferred to play what they enjoyed and did best. This fondness for the first decade of rock and roll (mid-1950s to mid-1960s) is also reflected in some of Motörhead's occasional cover songs from that era.
Lemmy often plays powerchords in his basslines. When asked about whether he had begun as a rhythm guitarist, he stated:
No, I play a lot of notes, but I also play a lot of chords. And I play a lot of open strings. I just don't play like a bass player. There are complaints about me from time to time. It's not like having a bass player; it's like having a deep guitarist.He also said in 2014 in an interview to the German magazine, Der Spiegel, "I don't like heavy metal!". 
Supporters.
"Motörheadbangers".
During the 1979 "Bomber" tour of Great Britain, the band met with writer Alan Burridge who then produced the first 'Motörhead Magazine'. Around the same time, drummer Phil "Philthy Animal" Taylor's sister, Helen Taylor, had started the "Motörheadbangers" fan club. Burridge and Taylor worked together to print the latest news for Motörhead fans, the first fanzine was published in January 1980. The "Motörheadbangers" fanzine is printed three times a year, and has 3,000 subscribers.
Paul Hadwen, who had worked on the "cartoon" style of the early Motörheadbangers fanzines with Chris Harris during Helen Taylor's leadership, and also drew the "comic strip" art included with the "Another Perfect Day" album, died at his home in Leeds in late July 2007, at age 50.
WWE.
Motörhead are well known in the professional wrestling world for performing popular wrestler Triple H's entrance music, "The Game", which he has used as his entrance music since January 2001. In addition to the song playing whenever Triple H appears on WWE programming such as "Raw" or "SmackDown", and at other pay-per-view wrestling events, the band have performed the song live for him at WrestleMania X-Seven and WrestleMania 21. Their song "Rock Out" was also used as the theme song of the WWE pay-per-view Unforgiven in 2008. Motörhead also provided the entrance music for Triple H's faction Evolution, entitled "Line in the Sand". "The Game" was released on both the American version of the "Hammered" and "WWF The Music, Vol. 5" albums, and "Line in the Sand" was released on the "" album. Motörhead have since performed a new entrance track for Triple H, entitled "King of Kings", which made its debut at WrestleMania 22. Triple H often introduces the band in concert.
Tribute bands.
Motörhead acknowledge the tribute bands they have spawned, listing many of them on their website. The first tribute band based in the UK is Motörheadache, which was formed in May 2003. Based in Sheffield, the band still features original founder member Rob Motorheadache as Lemmy. During their career, they have been joined onstage by "Fast" Eddie Clarke in 2005, and supported Girlschool.
Other tribute acts in Europe include Overhead from Norway, Bömbers (featuring Abbath), Ace of Spades from Varberg, Motorok from Germany, Moottörin Jyrinä from Finland, Motorheat from Belgium, Snaggletoöth from the Netherlands, Motörment from Germany, Motörheads from Moscow, No Remorse from Athens, and Motörhead Tribüte from Slovakia.
Italian acts include Manturhead from Latina, Bastardi, Mauro Tolot Kilmister, Reptiles, Matërhead ("Mothërhead") from Matera, and Motörhits from Spain. Tribute acts in the U.S. and Canada include Motorizer from Ottawa, Motorheadache from Toronto, Elderhead from New York City, and Capricorn USA from Austin.
Tribute albums.
Motörhead have been the subject of several tribute albums, markedly in the years since 1999. Genres range from hardcore punk and rock, to black and death metal and industrial.
Cover art.
The band's name is usually printed in a lowercase form of blackletter. The umlaut character ö is possibly derived from the similar "heavy metal umlaut" in the name of their 1975 acquaintances Blue Öyster Cult. However, this umlaut does not alter the pronunciation of the band's name. When asked if Germans pronounced the band "Motuuuurhead", Lemmy answered "No, they don't. I only put it in there to look mean". 
Snaggletooth is the fanged face that serves as the symbol of Motörhead. Artist Joe Petagno drew it in 1977 for the cover of the band's debut album (with designer Phil Smee who turned it into a negative and did the lettering to complete the logo), having met Lemmy while doing some work with Hawkwind. Petagno stated; The inspiration came from just being a naturally pissed-off bastard! And Lemmy's the same way! So it was bound to be an alchemal wedding of a more "primordial nature". I did a lot of research on skull types and found a cross-breed gorilla-wolf-dog combination would work nicely with some oversized boars horns. Lemmy added Helmet, chains, spit, spikes and grit.
Eddie Clarke was less sure about the imagery to begin with:
I shuddered when I saw it the first time. I thought, "Blimey, this ain't gonna go down that well", because it was just way over the top, then. But I grew to love it ... [At first] it was not scary or horrifying, it would've been, in those days, deemed bad taste.
It has remained a symbol of Motörhead throughout the years, with Petagno creating many variations of War-Pig for the covers of ensuing albums. To date, only two of the original covers for Motörhead's 20 studio albums do not feature any variation of War-Pig on the cover: "On Parole" and "Overnight Sensation" (of which, "On Parole" was never sanctioned by the band), and was in any case reissued with a black War-Pig on a white background. Phil is wearing a War-Pig badge on the cover of "Ace of Spades". The cover of "Iron Fist" depicts a metal gauntlet wearing four skull-shaped rings, one of which is War-Pig, while the rear of the album-sleeve shows a fully detailed 3-D metal sculpture of the symbol. Originally the War-Pig design included a swastika on one of the helmet's spikes. This was painted out on later re-releases of the albums on CD.
On 21 September 2007 Petagno announced that "there will be no more "HEADS" from my hand", citing irreconcilable differences between himself and the band's current management, Singerman Entertainment. Petagno stated:It has been a long, exciting and industrious journey, full of art and intuition, difference in repetition, and creative innovation. I feel I accomplished something unique in Metal history over the last 31 years by breathing life again and again into a figment of my own imagination, an image or better an entity which has taken on a life of its own, which I actually believe goes beyond the music it was created to represent. I'm damn proud of that! In reply, Lemmy stated:As many of you know, we have been working with Joe Petagno for 31 years. We always treated Joe fairly, and I would like to stress that at no time did my manager demand what Joe thinks he demanded — it is all a colossal misunderstanding. We have always loved his artwork, obviously, and if he now decides to stop working with us, we have no choice but to use someone else. However ... if he will not discuss this personally and try to work things out, I think it's a great tragedy. If Joe continues with us, no one would be more delighted than me. If it's goodbye, Joe, I wish you well, but I hope, even at this stage, to be reconciled and continue our association.

</doc>
<doc id="20908" url="http://en.wikipedia.org/wiki?curid=20908" title="MMU">
MMU

MMU may refer to:

</doc>
<doc id="20911" url="http://en.wikipedia.org/wiki?curid=20911" title="Multiverse">
Multiverse

 
The multiverse (or meta-universe) is the hypothetical set of infinite or finite possible universes (including the Universe we consistently experience) that together comprise everything that exists: the entirety of space, time, matter, and energy as well as the physical laws and constants that describe them. The various universes within the multiverse are sometimes called "parallel universes" or "alternate universes".
The structure of the multiverse, the nature of each universe within it and the relationships among the various constituent universes, depend on the specific multiverse hypothesis considered. Multiple universes have been hypothesized in cosmology, physics, astronomy, religion, philosophy, transpersonal psychology, and fiction, particularly in science fiction and fantasy. In these contexts, parallel universes are also called "alternate universes", "quantum universes", "interpenetrating dimensions", "parallel dimensions", "parallel worlds", "alternate realities", "alternate timelines", and "dimensional planes", among others. The term 'multiverse' was coined in 1895 by the American philosopher and psychologist William James in a different context.
The multiverse hypothesis is a source of debate within the physics community. Physicists disagree about whether the multiverse exists, and whether the multiverse is a proper subject of scientific inquiry. Supporters of one of the multiverse hypotheses include Stephen Hawking, Brian Greene, Max Tegmark, Alan Guth, Andrei Linde, Michio Kaku, David Deutsch, Leonard Susskind, Raj Pathria, Alexander Vilenkin, Laura Mersini-Houghton, Neil deGrasse Tyson and Sean Carroll. In contrast, those who are not proponents of the multiverse include: Nobel laureate Steven Weinberg, Nobel laureate David Gross, Paul Steinhardt, Neil Turok, Viatcheslav Mukhanov, George Ellis, Jim Baggott, and Paul Davies. Some argue that the multiverse question is philosophical rather than scientific, that the multiverse cannot be a scientific question because it lacks falsifiability, or even that the multiverse hypothesis is harmful or pseudoscientific.
Multiverse hypotheses in physics.
Categories.
Max Tegmark and Brian Greene have devised classification schemes that categorize the various theoretical types of multiverse, or types of universe that might theoretically comprise a multiverse ensemble.
Max Tegmark's four levels.
Cosmologist Max Tegmark has provided a taxonomy of universes beyond the familiar observable universe. The levels according to Tegmark's classification are arranged such that subsequent levels can be understood to encompass and expand upon previous levels, and they are briefly described below.
Level I: Beyond our cosmological horizon.
A generic prediction of chaotic inflation is an infinite ergodic universe, which, being infinite, must contain Hubble volumes realizing all initial conditions.
Accordingly, an infinite universe will contain an infinite number of Hubble volumes, all having the same physical laws and physical constants. In regard to configurations such as the distribution of matter, almost all will differ from our Hubble volume. However, because there are infinitely many, far beyond the cosmological horizon, there will eventually be Hubble volumes with similar, and even identical, configurations. Tegmark estimates that an identical volume to ours should be about 1010115 meters away from us. Given infinite space, there would, in fact, be an infinite number of Hubble volumes identical to ours in the Universe. This follows directly from the cosmological principle, wherein it is assumed our Hubble volume is not special or unique.
Level II: Universes with different physical constants.
In the chaotic inflation theory, a variant of the cosmic inflation theory, the multiverse as a whole is stretching and will continue doing so forever, but some regions of space stop stretching and form distinct bubbles, like gas pockets in a loaf of rising bread. Such bubbles are embryonic level I multiverses. Linde and Vanchurin calculated the number of these universes to be on the scale of 101010,000,000.
Different bubbles may experience different spontaneous symmetry breaking resulting in different properties such as different physical constants.
This level also includes John Archibald Wheeler's oscillatory universe theory and Lee Smolin's fecund universes theory.
Level III: Many-worlds interpretation of quantum mechanics.
Hugh Everett's many-worlds interpretation (MWI) is one of several mainstream interpretations of quantum mechanics. In brief, one aspect of quantum mechanics is that certain observations cannot be predicted absolutely. Instead, there is a range of possible observations, each with a different probability. According to the MWI, each of these possible observations corresponds to a different universe. Suppose a six-sided die is thrown and that the result of the throw corresponds to a quantum mechanics observable. All six possible ways the die can fall correspond to six different universes.
Tegmark argues that a level III multiverse does not contain more possibilities in the Hubble volume than a level I-II multiverse. In effect, all the different "worlds" created by "splits" in a level III multiverse with the same physical constants can be found in some Hubble volume in a level I multiverse. Tegmark writes that "The only difference between Level I and Level III is where your doppelgängers reside. In Level I they live elsewhere in good old three-dimensional space. In Level III they live on another quantum branch in infinite-dimensional Hilbert space." Similarly, all level II bubble universes with different physical constants can in effect be found as "worlds" created by "splits" at the moment of spontaneous symmetry breaking in a level III multiverse.
Related to the "many-worlds" idea are Richard Feynman's "multiple histories" interpretation and H. Dieter Zeh's "many-minds" interpretation.
Level IV: Ultimate ensemble.
The ultimate ensemble or mathematical universe hypothesis is the hypothesis of Tegmark himself. This level considers equally real all universes that can be described by different mathematical structures. Tegmark writes that "abstract mathematics is so general that any Theory Of Everything (TOE) that is definable in purely formal terms (independent of vague human terminology) is also a mathematical structure. For instance, a TOE involving a set of different types of entities (denoted by words, say) and relations between them (denoted by additional words) is nothing but what mathematicians call a set-theoretical model, and one can generally find a formal system that it is a model of." He argues this "implies that any conceivable parallel universe theory can be described at Level IV" and "subsumes all other ensembles, therefore brings closure to the hierarchy of multiverses, and there cannot be say a Level V."
Jürgen Schmidhuber, however, says the "set of mathematical structures" is not even well-defined, and admits only universe representations describable by constructive mathematics, that is, computer programs. He explicitly includes universe representations describable by non-halting programs whose output bits converge after finite time, although the convergence time itself may not be predictable by a halting program, due to Kurt Gödel's limitations. He also explicitly discusses the more restricted ensemble of quickly computable universes.
Brian Greene's nine types.
American theoretical physicist and string theorist Brian Greene discussed nine types of parallel universes:
Cyclic theories.
In several theories there is a series of infinite, self-sustaining cycles (for example: an eternity of Big Bang-Big crunches).
M-theory.
A multiverse of a somewhat different kind has been envisaged within string theory and its higher-dimensional extension, M-theory. These theories require the presence of 10 or 11 spacetime dimensions respectively. The extra 6 or 7 dimensions may either be compactified on a very small scale, or our universe may simply be localized on a dynamical (3+1)-dimensional object, a D-brane. This opens up the possibility that there are other branes which could support "other universes". This is unlike the universes in the "quantum multiverse", but both concepts can operate at the same time.
Some scenarios postulate that our big bang was created, along with our universe, by the collision of two branes.
Black-hole cosmology.
A black-hole cosmology is a cosmological model in which the observable universe is the interior of a black hole existing as one of possibly many inside a larger universe. This includes the theory of white holes of which are on the opposite side of space time. While a black hole sucks everything in including light, a white hole releases matter and light, hence the name "white hole".
Anthropic principle.
The concept of other universes has been proposed to explain how our own universe appears to be fine-tuned for conscious life as we experience it. If there were a large (possibly infinite) number of universes, each with possibly different physical laws (or different fundamental physical constants), some of these universes, even if very few, would have the combination of laws and fundamental parameters that are suitable for the development of matter, astronomical structures, elemental diversity, stars, and planets that can exist long enough for life to emerge and evolve. The weak anthropic principle could then be applied to conclude that we (as conscious beings) would only exist in one of those few universes that happened to be finely tuned, permitting the existence of life with developed consciousness. Thus, while the probability might be extremely small that any particular universe would have the requisite conditions for life (as we understand life) to emerge and evolve, this does not require intelligent design as an explanation for the conditions in the Universe that promote our existence in it.
Search for evidence.
Around 2010, scientists such as Stephen M. Feeney analyzed Wilkinson Microwave Anisotropy Probe (WMAP) data and claimed to find preliminary evidence suggesting that our universe collided with other (parallel) universes in the distant past. However, a more thorough analysis of data from the WMAP and from the Planck satellite, which has a resolution 3 times higher than WMAP, failed to find any statistically significant evidence of such a bubble universe collision.
In addition, there is no evidence of any gravitational pull of other universes on ours.
Criticism.
Non-scientific claims.
In his 2003 NY Times opinion piece, "A Brief History of the Multiverse," author and cosmologist, Paul Davies, offers a variety of arguments that multiverse theories are non-scientific :
 For a start, how is the existence of the other universes to be tested? To be sure, all cosmologists accept that there are some regions of the universe that lie beyond the reach of our telescopes, but somewhere on the slippery slope between that and the idea that there are an infinite number of universes, credibility reaches a limit. As one slips down that slope, more and more must be accepted on faith, and less and less is open to scientific verification. Extreme multiverse explanations are therefore reminiscent of theological discussions. Indeed, invoking an infinity of unseen universes to explain the unusual features of the one we do see is just as ad hoc as invoking an unseen Creator. The multiverse theory may be dressed up in scientific language, but in essence it requires the same leap of faith.
 — Paul Davies, "A Brief History of the Multiverse"
Taking cosmic inflation as a popular case in point, George Ellis, writing in August 2011, provides a balanced criticism of not only the science, but as he suggests, the scientific philosophy, by which multiverse theories are generally substantiated. He, like most cosmologists, accepts Tegmark's level I "domains", even though they lie far beyond the cosmological horizon. Likewise, the multiverse of cosmic inflation is said to exist very far away. It would be so far away, however, that it's very unlikely any evidence of an early interaction will be found. He argues that for many theorists, the lack of empirical testability or falsifiability is not a major concern. "Many physicists who talk about the multiverse, especially advocates of the string landscape, do not care much about parallel universes per se. For them, objections to the multiverse as a concept are unimportant. Their theories live or die based on internal consistency and, one hopes, eventual laboratory testing." Although he believes there's little hope that will ever be possible, he grants that the theories on which the speculation is based, are not without scientific merit. He concludes that multiverse theory is a "productive research program":
 As skeptical as I am, I think the contemplation of the multiverse is an excellent opportunity to reflect on the nature of science and on the ultimate nature of existence: why we are here… In looking at this concept, we need an open mind, though not too open. It is a delicate path to tread. Parallel universes may or may not exist; the case is unproved. We are going to have to live with that uncertainty. Nothing is wrong with scientifically based philosophical speculation, which is what multiverse proposals are. But we should name it for what it is.
 — George Ellis, "Scientific American", Does the Multiverse Really Exist?
Occam's razor.
Proponents and critics disagree about how to apply Occam's razor. Critics argue that to postulate a practically infinite number of unobservable universes just to explain our own seems contrary to Occam's razor. In contrast, proponents argue that, in terms of Kolmogorov complexity, the proposed multiverse is simpler than a single idiosyncratic universe.
For example, multiverse proponent Max Tegmark argues:
 [A]n entire ensemble is often much simpler than one of its members. This principle can be stated more formally using the notion of algorithmic information content. The algorithmic information content in a number is, roughly speaking, the length of the shortest computer program that will produce that number as output. For example, consider the set of all integers. Which is simpler, the whole set or just one number? Naively, you might think that a single number is simpler, but the entire set can be generated by quite a trivial computer program, whereas a single number can be hugely long. Therefore, the whole set is actually simpler... (Similarly), the higher-level multiverses are simpler. Going from our universe to the Level I multiverse eliminates the need to specify initial conditions, upgrading to Level II eliminates the need to specify physical constants, and the Level IV multiverse eliminates the need to specify anything at all... A common feature of all four multiverse levels is that the simplest and arguably most elegant theory involves parallel universes by default. To deny the existence of those universes, one needs to complicate the theory by adding experimentally unsupported processes and ad hoc postulates: finite space, wave function collapse and ontological asymmetry. Our judgment therefore comes down to which we find more wasteful and inelegant: many worlds or many words. Perhaps we will gradually get used to the weird ways of our cosmos and find its strangeness to be part of its charm.
 — Max Tegmark, ""Parallel universes. Not just a staple of science fiction, other universes are a direct implication of cosmological observations." Scientific American 2003 May;288(5):40–51"
Princeton cosmologist Paul Steinhardt used the 2014 Annual Edge Question to voice his opposition to multiverse theorizing:
 A pervasive idea in fundamental physics and cosmology that should be retired: the notion that we live in a multiverse in which the laws of physics and the properties of the cosmos vary randomly from one patch of space to another. According to this view, the laws and properties within our observable universe cannot be explained or predicted because they are set by chance. Different regions of space too distant to ever be observed have different laws and properties, according to this picture. Over the entire multiverse, there are infinitely many distinct patches. Among these patches, in the words of Alan Guth, "anything that can happen will happen—and it will happen infinitely many times". Hence, I refer to this concept as a Theory of Anything. Any observation or combination of observations is consistent with a Theory of Anything. No observation or combination of observations can disprove it. Proponents seem to revel in the fact that the Theory cannot be falsified. The rest of the scientific community should be up in arms since an unfalsifiable idea lies beyond the bounds of normal science. Yet, except for a few voices, there has been surprising complacency and, in some cases, grudging acceptance of a Theory of Anything as a logical possibility. The scientific journals are full of papers treating the Theory of Anything seriously. What is going on?
 — Paul Steinhardt, ""Theories of Anything" "edge.com""
Steinhardt claims that multiverse theories have gained currency mostly because too much has been invested in theories that have failed, e.g. inflation or string theory. He tends to see in them an attempt to redefine the values of science to which he objects even more strongly:
 A Theory of Anything is useless because it does not rule out any possibility and worthless because it submits to no do-or-die tests. (Many papers discuss potential observable consequences, but these are only possibilities, not certainties, so the Theory is never really put at risk.)
 — Paul Steinhardt, ""Theories of Anything" "edge.com""
Multiverse hypotheses in philosophy and logic.
Modal realism.
Possible worlds are a way of explaining probability, hypothetical statements and the like, and some philosophers such as David Lewis believe that all possible worlds exist, and are just as real as the actual world (a position known as modal realism).
Trans-world identity.
A metaphysical issue that crops up in multiverse schema that posit infinite identical copies of any given universe is that of the notion that there can be identical objects in different possible worlds. According to the counterpart theory of David Lewis, the objects should be regarded as similar rather than identical.
Fictional realism.
The view that because fictions exist, fictional characters exist as well. There are fictional entities, in the same sense in which, setting aside philosophical disputes, there are people, Mondays, numbers and planets.
References.
Bibliography.
</dl>

</doc>
<doc id="20912" url="http://en.wikipedia.org/wiki?curid=20912" title="MBR">
MBR

MBR may refer to:

</doc>
<doc id="20914" url="http://en.wikipedia.org/wiki?curid=20914" title="Milton">
Milton

Milton may refer to:
People.
People with the surname Milton:
People with the given name Milton:

</doc>
<doc id="20918" url="http://en.wikipedia.org/wiki?curid=20918" title="List of conflicts in the Near East">
List of conflicts in the Near East

The area known as the "Near East" is usually referred to as Middle East in modern contexts.
For periods predating Classical Antiquity, the common term is Ancient Near East.
The Near East is generally associated with Anatolia, the Levant, Mesopotamia and to greater degree Egypt, Arabian Peninsula and Persia.
Ancient Near East conflicts.
Early Iron Age.
"Note: This section is covering Iron Age I and II, Iron Age III is related as Classic Period"
Ottoman period conflicts 1453-1918.
Ottoman expansion.
Ottoman era period conflicts 1453-1516

</doc>
<doc id="20922" url="http://en.wikipedia.org/wiki?curid=20922" title="Molotov cocktail">
Molotov cocktail

A Molotov cocktail (Finnish: "Polttopullo or Molotovin koktaili", Spanish: "Cóctel mólotov", German: "Molotowcocktail"), also known as a petrol bomb, poor man's grenade, fire bomb (not to be confused with an actual fire bomb) or just Molotov, is a generic name used for a variety of bottle-based improvised incendiary weapons. Due to the relative ease of production, they are frequently used by protesters and non-professionally equipped fighters in riots and urban guerrilla warfare. They are primarily intended to set targets ablaze rather than instantly destroy them.
Name.
The name "Molotov cocktail" was coined by the Finns during the Winter War. The name is an insulting reference to Soviet foreign minister Vyacheslav Molotov, who was responsible for the setting of "spheres of interest" in Eastern Europe under the Molotov–Ribbentrop Pact in August 1939. The pact with the Nazis bearing Molotov's name was widely mocked by the Finns, as was much of the propaganda Molotov produced to accompany the pact, including his declaration on Soviet state radio that bombing missions over Finland were actually airborne humanitarian food deliveries for their starving neighbours. The Finns sarcastically dubbed the Soviet cluster bombs "Molotov bread baskets" in reference to Molotov's propaganda broadcasts. When the hand-held bottle firebomb was developed to attack Soviet tanks, the Finns called it the "Molotov cocktail", as "a drink to go with the food". Molotov himself despised the name, particularly as the term became ubiquitous and generalised as Soviets faced increasing numbers of cocktail-throwing protesters in the Eastern Bloc in the years after World War II.
Recipe.
A Molotov cocktail is a breakable glass bottle containing a flammable substance such as petrol or a napalm-like mixture, with some motor oil added, and usually a source of ignition such as a burning cloth wick held in place by the bottle's stopper. The wick is usually soaked in alcohol or kerosene, rather than petrol.
In action, the wick is lit and the bottle hurled at a target such as a vehicle or fortification. When the bottle smashes on impact, the ensuing cloud of petrol droplets and vapour ignites, causing an immediate fireball followed by a raging fire as the remainder of the fuel is consumed. Another method is to place a reactive substance in with the petrol, and treat the label or wrapper paper with another chemical; when the bottle ruptures, the two chemicals mix and ignite. This is safer to handle if done properly, and does not betray the thrower with a visible flame prior to the throw. A far superior version can be produced by substituting carbon disulphide for the petrol and saturating this solvent with white phosphorus and sulphur. The mixture will automatically ignite on exposure to air. Care must be taken to avoid the use of rubber stoppers for the bottles, as carbon disulphide readily dissolves rubber.
Other flammable liquids such as diesel fuel, methanol, turpentine, jet fuel and E85 have been used in place of, or combined with, petrol. Thickening agents such as solvents, foam polystyrene, baking soda, tar, strips of tyre tubing, XPS foam, egg whites, motor oil, rubber cement and dish soap have been added to help the burning liquid adhere to the target and create clouds of thick, choking smoke.
Development and use in war.
Spanish Civil War.
Improvised incendiary devices were used for the first time in the Spanish Civil War between July 1936 and April 1939, before they became known as "Molotov cocktails". In 1936, General Francisco Franco ordered Spanish Nationalist forces to use the weapon against Soviet T-26 tanks supporting the Spanish Republicans in a failed assault on the Nationalist stronghold of Seseña, near Toledo, 40 km south of Madrid. After that, both sides used simple petrol bombs or petrol-soaked blankets with some success. Tom Wintringham, a veteran of the International Brigades, later publicised his recommended method of using them:
We made use of "petrol bombs" roughly as follows: take a 2lb glass jam jar. Fill with petrol. Take a heavy curtain, half a blanket, or some other heavy material. Wrap this over the mouth of the jar, tie it round the neck with string, leave the ends of the material hanging free. When you want to use it have somebody standing by with a light [i.e., a source of ignition]. Put a corner of the material down in front of you, turn the bottle over so that petrol soaks out round the mouth of the bottle and drips on to this corner of the material. Turn the bottle right way up again, hold it in your right hand, most of the blanket bunched beneath the bottle, with your left hand take the blanket near the corner that is wetted with petrol. Wait for your tank. When near enough, your pal [or comrade-in-arms] lights the petrol soaked corner of the blanket. Throw the bottle and blanket as soon as this corner is flaring. (You cannot throw it far.) See that it drops in front of the tank. The blanket should catch in the tracks or in a cog-wheel, or wind itself round an axle. The bottle will smash, but the petrol should soak the blanket well enough to make a really healthy fire which will burn the rubber wheels on which the tank track runs, set fire to the carburettor or frizzle the crew. Do not play with these things. They are highly dangerous.
Khalkhin Gol.
The Battle of Khalkhin Gol, a border conflict of 1939 ostensibly between Mongolia and Manchukuo, saw heavy fighting between Japanese and Soviet forces. Short of anti-tank equipment, Japanese infantry attacked Soviet tanks with gasoline-filled bottles. Japanese infantrymen claimed that several hundred Soviet tanks had been destroyed this way, though Soviet loss records do not support this assessment.
Finland.
On 30 November 1939, the Soviet Union invaded Finland, starting what came to be known as the Winter War. The Finnish Army faced large numbers of Red Army tanks. Being short on anti-tank guns, they improvised incendiary devices to use against them.
The Finns perfected the design and tactical use of the petrol bomb. The fuel for the Molotov cocktail was refined to a slightly sticky mixture of gasoline, kerosene, tar, and potassium chlorate. Further refinements included the attachment of wind-proof matches or a phial of chemicals that would ignite on breakage, thereby removing the need to pre-ignite the bottle, and leaving the bottle about one-third empty was found to make breaking more likely. As the cooling system was almost invariably placed where direct fire wouldn't hit it, the target of choice was the rear deck of a tank; the burning contents of the bottle would pour through the large cooling grills and ignite fuel, hydraulic fluids and ammunition.
A British War Office report dated June 1940 noted that:
The Finns' policy was to allow the Russian tanks to penetrate their defences, even inducing them to do so by 'canalising' them through gaps and concentrating their small arms fire on the infantry following them. The tanks that penetrated were taken on by gun fire in the open and by small parties of men armed with explosive charges and petrol bombs in the forests and villages... The essence of the policy was the separation of the AFVs from the infantry, as once on their own the tank has many blind spots and once brought to a stop can be disposed of at leisure.
Molotov cocktails were eventually mass-produced by the Alko corporation at its Rajamäki distillery, bundled with matches to light them. Production totalled 450,000 during the Winter War. The original recipe of the Molotov cocktail was a mixture of ethanol, tar and gasoline in a 750 ml bottle. The bottle had two long pyrotechnic storm matches attached to either side. Before use, one or both of the matches was lit; when the bottle broke on impact, the mixture ignited. The storm matches were found to be safer to use than a burning rag on the mouth of the bottle.
Britain.
Early in 1940, with the prospect of immediate invasion, the possibilities of the petrol bomb gripped the imagination of the British public. For the layman, the petrol bomb had the benefit of using entirely familiar and available materials, and they were quickly improvised in large numbers, with the intention of using them against enemy tanks.
When used in the right way and in sufficient numbers, the Finns had found that they were effective. Although the experience of the Spanish Civil War received more publicity, the more sophisticated petroleum warfare tactics of the Finns were not lost on British commanders. In his 5 June address to LDV leaders, General Ironside said:
I want to develop this thing they developed in Finland, called the "Molotov cocktail", a bottle filled with resin, petrol and tar which if thrown on top of a tank will ignite, and if you throw half a dozen or more on it you have them cooked. It is quite an effective thing. If you can use your ingenuity, I give you a picture of a [road] block with two houses close to the block, overlooking it. There are many villages like that. Out of the top windows is the place to drop these things on the tank as it passes the block. It may only stop it for two minutes there, but it will be quite effective.
Wintringham advised that a tank that was isolated from supporting infantry was potentially vulnerable to men who had the required determination and cunning to get close. Rifles or even a shotgun would be sufficient to persuade the crew to close all the hatches, and then the view from the tank is very limited; a turret-mounted machine gun has a very slow traverse and cannot hope to fend off attackers coming from all directions. Once sufficiently close, it is possible to hide where the tank's gunner cannot see: "The most dangerous distance away from a tank is 200 yards; the safest distance is six inches." Petrol bombs will soon produce a pall of blinding smoke, and a well-placed explosive package or even a stout iron bar in the tracks can immobilise the vehicle, leaving it at the mercy of further petrol bombs – which will suffocate the engine and possibly the crew – or an explosive charge or anti-tank mine.
By August 1940, the War Office produced training instructions for the creation and use of Molotov cocktails. The instructions suggested scoring the bottles vertically with a diamond to ensure breakage and providing fuel-soaked rag, windproof matches or a length of cinema film (made of highly flammable nitrocellulose) as a source of ignition.
On 29 July 1940, manufacturers Albright & Wilson of Oldbury demonstrated to the RAF how their white phosphorus could be used to ignite incendiary bombs. The demonstration involved throwing glass bottles containing a mixture of petrol and phosphorus at pieces of wood and into a hut. On breaking, the phosphorus was exposed to the air and spontaneously ignited; the petrol also burned, resulting in a fierce fire. Because of safety concerns, the RAF was not interested in white phosphorus as a source of ignition, but the idea of a self-igniting petrol bomb took hold. Initially known as an A.W. bomb, it was officially named the No. 76 Grenade, but more commonly known as the SIP (Self-Igniting Phosphorus) grenade. The perfected list of ingredients was white phosphorus, benzene, water and a two-inch strip of raw rubber; all in a half-pint bottle sealed with a crown stopper. Over time, the rubber would slowly dissolve, making the contents slightly sticky, and the mixture would separate into two layers – this was intentional, and the grenade should not be shaken to mix the layers, as this would only delay ignition. When thrown against a hard surface, the glass would shatter and the contents would instantly ignite, liberating choking fumes of phosphorus pentoxide and sulphur dioxide as well as producing a great deal of heat. Strict instructions were issued to store the grenades safely, preferably underwater and certainly never in a house. Mainly issued to the Home Guard as an anti-tank weapon, it was produced in vast numbers; by August 1941 well over 6,000,000 had been manufactured.
However, there were voices that were more cautious. There were many who were sceptical about the efficacy of Molotov cocktails and SIPs grenades against the more modern German tanks. Weapon designer Stuart Macrae witnessed a trial of the SIPs grenade at Farnborough: "There was some concern that, if the tank drivers could not pull up quickly enough and hop out, they were likely to be frizzled to death, but after looking at the bottles they said they would be happy to take a chance." The drivers were proved right, trials on modern British tanks confirmed that Molotov and SIP grenades caused the occupants of the tanks "no inconvenience whatsoever".
Wintringham, though enthusiastic about improvised weapons cautioned against a reliance on petrol bombs and repeatedly emphasised the importance of using explosive charges.
Other fronts.
During the Irish War of Independence, IRA fighters sometimes used sods of turf soaked in paraffin oil to attack British army barracks. Fencing wire was pushed through the sod to make a throwing handle.
The Polish Home Army developed a version which ignited on impact without the need of a wick. Ignition was caused by a reaction between concentrated sulfuric acid mixed with the fuel and a mixture of potassium chlorate and sugar which was crystallized from solution onto a rag attached to the bottle.
The United States Marine Corps developed a version during World War II that used a tube of nitric acid and a lump of metallic sodium to ignite a mixture of petrol and diesel fuel.
Modern use.
During the Second Battle of Fallujah in 2004, U.S. Marines employed Molotov cocktails made with "one part liquid laundry detergent, two parts gas" for 'burning out' their enemies from houses.
In Northern Ireland during the Troubles, Molotov cocktails were used by rioting paramilitary groups and protesters against the police, and they are also used to attack houses to burn the house or to intimidate the occupants.
In the Arab Spring, including in Cairo, Egypt, pro-government forces attacked protesters in Cairo with Molotovs. In the Bahraini uprising, protesters used Molotov cocktails against security forces.
Molotov cocktails were also used by protesters and civilian militia in Ukraine during violent outbreaks of the Euromaidan and the 2014 Ukrainian revolution. Protesters during the Ferguson riots used Molotov cocktails, while police used smoke bombs and tear gas.
In Bangladesh during anti government protests before the 2014 national election and in the year afterwards, many buses and cars were targeted with petrol bombs. A number of people burnt to death and many more were injured.
Legality.
As incendiary devices, Molotov cocktails are illegal to manufacture or possess in many regions. In the United States, Molotov cocktails are considered "destructive devices" under the National Firearms Act and regulated by the ATF.

</doc>
<doc id="20923" url="http://en.wikipedia.org/wiki?curid=20923" title="Matzo">
Matzo

Matzo, matza or matzah (Hebrew: מַצָּה‎; plural matzot; matzos, matzus of Ashkenazi Hebrew dialect) is an unleavened bread traditionally eaten by Jewish people during the week-long Passover holiday, when eating "chametz"—bread and other food made with leavened grain—is forbidden according to Jewish religious law.
Biblical sources.
"Matzah" is mentioned in the Torah several times in relation to The Exodus from Egypt:
That night, they are to eat the meat, roasted in the fire; they are to eat it with matzah and "maror".—Exodus 12:8
From the evening of the fourteenth day of the first month until the evening of the twenty-first day, you are to eat matzah.—Exodus 12:18
You are not to eat any "chametz" with it; for seven days you are to eat with it matzah, the bread of affliction; for you came out of the land of Egypt in haste. Thus you will remember the day you left the land of Egypt as long as you live.—Deuteronomy 16:3
For six days you are to eat matzah; on the seventh day there is to be a festive assembly for "Ha Shem" your God; do not do any kind of work.—Deuteronomy 16:8
Religious significance.
There are numerous explanations behind the symbolism of matzah. One is historical: Passover is a commemoration of the exodus from Egypt. The biblical narrative relates that the Israelites left Egypt in such haste they could not wait for their bread dough to rise; the bread, when baked, was matzah. (Exodus 12:39). The other reason for eating matza is symbolic: On the one hand, matza symbolizes redemption and freedom, but it is also "lechem oni", "poor man's bread". Thus it serves as a reminder to be humble, and to not forget what life was like in servitude. Also, leaven symbolizes corruption and pride as leaven "puffs up". Eating the "bread of affliction" is both a lesson in humility and an act that enhances the appreciation of freedom.
Another explanation is that matza has been used to replace the pesach, or the traditional Passover offering that was made before the destruction of the Temple. During the Seder the third time the matza is eaten it is preceded with the Sefardic rite, "zekher l’korban pesach hane’ekhal al hasova". This means "remembrance of the Passover offering, eaten while full". This last piece of the matza eaten is called afikoman and many explain it as a symbol of salvation in the future.
The Passover Seder meal is full of symbols of salvation, including the opening of the door for Elijah and the closing line, “Next year in Jerusalem,” but the use of matzah is the oldest symbol of salvation in the Seder.
Ingredients.
At the Passover seder, it is customary to eat matzah made of flour and water; matzah containing eggs, wine, or fruit juice in addition to water is not considered acceptable for use at the seder. The flour can be made from the five grains mentioned in the Torah: wheat, barley, spelt, rye and oats.
Preparation.
Matzah dough is quickly mixed and rolled out without an autolyse step as used for leavened breads. Most forms are pricked with a fork or a similar tool to keep the finished product from puffing up, and the resulting flat piece of dough is cooked at high temperature until it develops dark spots, then set aside to cool and, if sufficiently thin, to harden to crispness. Dough is considered to begin the leavening process 18 minutes from the time it gets wet; sooner if eggs, fruit juice, or milk is added to the dough. The entire process of making matzah takes only a few minutes in efficient modern matzah bakeries.
After baking, matzah may be ground into fine crumbs, known as matzah meal.
Variations.
There are two major forms of matza. In many western countries the most common form is the hard form of matza which is cracker-like in appearance and taste and is used in all Ashkenazic and most Sephardic communities. Yemenites, and Iraqi Jews traditionally made a form of soft matza which looks like Greek pita or like a tortilla. Soft matza is made only by hand, and generally with "shmurah" flour.
Flavored varieties of matzah are produced commercially, such as poppyseed- or onion-flavored. Oat and spelt matzah with kosher certification are produced, and are suitable for people who cannot eat wheat. Organic wheat matzah is also available. Chocolate-covered matzah is a favorite among children, although some consider it "enriched matza" and will not eat it during the Passover holiday. A quite different flat confection of chocolate and nuts that resembles matzah is sometimes called "chocolate matzah".
Matzah contains typically 111 calories per 1-ounce/28g (USDA Nutrient Database), about the same as rye crispbread.
Shmurah matzah.
"Shmura" ("guarded") matzah (Hebrew מַצָּה שְׁמוּרָה "maṣṣā šəmūrā") is made from grain that has been under special supervision from the time it was harvested to ensure that no fermentation has occurred, and that it is suitable for eating on the first night of Passover. ("Shmura" wheat may be formed into either handmade or machine-made matzah, while non-"shmura" wheat is only used for machine-made matzah. It is possible to hand-bake matzah in "shmura" style from non-shmurah flour—this is a matter of style, it is not actually in any way "shmura"—but such matzah has rarely been produced since the introduction of machine-made matza.)
Haredi Judaism is scrupulous about the supervision of matzah and have the custom of baking their own or at least participating in some stage of the baking process. Rabbi Chaim Halberstam of Sanz ruled that machine-made matzoth were "chametz". According to that opinion, hand-made non-"shmurah" matzot may be used on the eighth day of Passover outside of the Holy Land. However the non-Hasidic Haredi community of Jerusalem follows the custom that machine-made matzah may be used, with preference to the use of "shmurah" flour, in accordance with the ruling of Rabbi Yosef Chaim Sonnenfeld, who ruled that machine-made matzah may be preferable to hand made in some cases. The commentators to the Shulchan Aruch record that it is the custom of some of Diaspora Jewry to be scrupulous in giving Challah from the dough used for baking "Matzot Mitzvah" (the Shmurah Matzah eaten during Passover) to a Kohen child to eat.
Egg matza.
"Egg (sometimes "enriched") matzah" are matzot usually made with fruit juice, often grape or apple juice instead of water, but not necessarily with eggs themselves. There is a custom among some Ashkenazi Jews not to eat them during Passover, except for the elderly, infirm, or children, who cannot digest plain matzah; these matzot are considered to be kosher for Passover if prepared otherwise properly. The issue of whether egg matzah is allowed for Passover comes down to whether there is a difference between the various liquids that can be used. Water facilitates fermentation of grain flour, but the question is whether fruit juice, eggs, honey, oil or milk are also deemed to do so.
The "Talmud", Pesachim 35a, states that liquid food extracts do not cause flour to leaven the way that water does. According to this view, flour mixed with other liquids would not need to be treated with the same care as flour mixed with water. The "Tosafot" (commentaries) explain that such liquids only produce a leavening reaction within flour "if" they themselves have had water added to them and otherwise the dough they produce is completely permissible for consumption during Passover, whether or not made according to the laws applying to matzot.
As a result, Joseph ben Ephraim Karo, author of the "Shulchan Aruch" or "Code of Jewish Law" (Orach Chayim 462:4) granted blanket permission for the use of any matzah made from non-water-based dough, including egg matzah, on Passover. Many egg matzah boxes no longer include the message, “Ashkenazi custom is that egg matzah is only allowed for children, elderly and the infirm during Passover.” Even amongst those who consider that enriched matzot may not be "eaten" during Passover, it is permissible to "retain" it in the home.
Cooking with matzah.
Matzah balls and matzo farfel are served in soup. Matzah brei is a dish of Ashkenazi origin made from matzah soaked in water and fried with eggs. These items are made from matzah meal, or finely ground matzah sometimes called cake meal, used as a binder in baked goods. Some Ashkenazim do not cook with matzah, believing that mixing it with water may allow leavening; the mixture is called "gebrochts" by Ashkenazi Jews. Kosher for Passover cakes and cookies are made with matzah meal or a finer variety called "cake meal", which gives them a denser texture than ordinary baked foods made with flour.
Sephardim use matzah soaked in water or stock to make pies or lasagne known as "mina", "méguena", "mayena" or Italian: "scacchi".
Matzah meal pancakes are made from a batter of matzah meal, egg, and milk.
In Christianity.
Communion wafers used by the Catholic Church as well as in some Protestant traditions for the Eucharist are flat, unleavened bread. All Byzantine Rite churches use leavened bread for the Eucharist as this symbolizes the risen Christ. Some Oriental Orthodox and Eastern Catholic Christians use leavened bread, as in the east there is the tradition that leavened bread was on the table of the Last Supper. In the Armenian Apostolic Church, the Ethiopian Orthodox Tewahedo Church and Eritrean Orthodox Tewahedo Church, unleavened bread called "qǝddus qurban" in Ge'ez, the liturgical language of the Eritreans and Ethiopians, is used for communion.
Trivia.
At the end of World War II, the National Jewish Welfare Board had a matzo factory (according to the American Jewish Historical Society, it was probably the Manischewitz matzo factory in New Jersey) produce matzo in the form of a giant "V" for "Victory", for shipment to military bases overseas and in the U.S., for Passover seders for Jewish military personnel. Passover in 1945 began on 1 April, when the collapse of the Axis in Europe was clearly imminent; Germany surrendered a mere five weeks later.

</doc>
<doc id="20925" url="http://en.wikipedia.org/wiki?curid=20925" title="Michel Tremblay">
Michel Tremblay

Michel Tremblay, CQ (born 25 June 1942) is a Canadian novelist and playwright.
Tremblay was born in Montreal, Quebec, where he grew up in the French-speaking neighbourhood of Plateau Mont-Royal, at the time of his birth a neighbourhood with a working-class character and joual dialect, something that would heavily influence his work. Tremblay's first professionally produced play, "Les Belles-Sœurs", was written in 1965 and premiered at the Théâtre du Rideau Vert on August 28, 1968. It transformed the old guard of Canadian theatre and introduced joual to the mainstream. It stirred up controversy by portraying the lives of working class women and attacking the straight-laced, deeply religious society of mid-20th century Quebec.
His work and its impact.
The most profound and lasting effects of Tremblay's early plays, including "Hosanna" and "La Duchesse de Langeais", were the barriers they toppled in Quebec society. Until the Quiet Revolution of the early 1960s, Tremblay saw Quebec as a poor, working-class province dominated by an English-speaking elite and the Roman Catholic Church. Tremblay's work was part of a vanguard of liberal, nationalist thought that helped create an essentially modern society. His most famous plays are usually centered on homosexual characters. The women are usually strong but possessed with demons they must vanquish. It is said he sees Quebec as a matriarchal society. He is considered one of the best playwrights for women. In the late 1980s, "Les Belles-soeurs" ("The Sisters-in-Law") was produced in Scotland in Scots, as "The Guid-Sisters" ("guid-sister" being Scots for "sister-in-law"). His work has been translated into many languages, including Yiddish, and including such works as "Sainte-Carmen de la Main", "Ç'ta ton tour, Laura Cadieux", and "Forever Yours, Marilou" ("À toi pour toujours, ta Marie-Lou").
He has been openly gay throughout his public life, and he has written many novels ("The Duchess and the Commoner", "La nuit des princes charmants", "Le Coeur découvert", "Le Coeur éclaté") and plays ("Hosanna", "La duchesse de Langeais", "Fragments de mensonges inutiles") centred on gay characters. In a 1987 interview with Shelagh Rogers for CBC Radio's "The Arts Tonight", he remarked that he has always avoided behaviours he has considered masculine; for example, he does not smoke and he noted that he was 45 years old and did not know how to drive a car. "I think I am a rare breed," he said, "A homosexual who doesn't like men." He claims one of his biggest regrets in life was not telling his mother that he was gay, before she died.
His latest play to receive wide acclaim is "For the Pleasure of Seeing Her Again", a funny and nostalgic play, centered on the memories of his mother. He later published the Plateau Mont-Royal Chronicles, a cycle of six novels including "The Fat Woman Next Door is Pregnant" ("La grosse femme d'à côté est enceinte", 1978) and "The Duchess and the Commoner" ("La duchesse et le roturier", 1982). The second novel of this series, "Therese and Pierrette and the Little Hanging Angel" ("Thérèse et Pierrette à l'école des Saints-Anges", 1980), was one of the novels chosen for inclusion in the French version of "Canada Reads", "Le combat des livres", broadcast on Radio-Canada in 2005, where it was championed by union activist Monique Simard.
Tremblay worked also on a television series entitled "Le Cœur découvert" ("The Heart Laid Bare"), about the lives of a gay couple in Quebec, for the French-language TV network Radio-Canada. In 2005 he completed another novel cycle, the "Cahiers" ("Le Cahier noir" (translated as "The Black Notebook"), "Le Cahier rouge", "Le Cahier bleu"), dealing with the changes that occurred in 1960s Montreal during the Quiet Revolution. In 2009 "The Fat Woman Next Door" was a finalist in CBC's prestigious Canada Reads competition.
Political views.
For many years, Tremblay has believed that the only reasonable solution for Quebec is to separate from Canada. Once the Parti Québécois was elected in Quebec, he softened his views on allowing his plays to be produced in English there. He made it clear, however, that that did not mean that he agreed with bilingualism, calling it "stupid" and stating that he thought it ridiculous to expect a housewife in Vancouver to be fluent in both English and French.
Despite his often outspoken views in public, Tremblay's treatment of politics in his plays is subtle. Speaking of politics and the theatre in an CBC interview in 1978, Tremblay said:
"I know what I want in the theatre. I want a real political theatre, but I know that political theatre is dull. I write fables." 
In April 2006 he declared that he did not support the arguments put forward for the separation of Quebec. But he clarified his thoughts some time later by saying he was still a supporter of Quebec sovereignty, though critical of the actual state of the debate, which in his opinion was too much focused on economic issues. In response to this, the columnist Marc Cassivi of "La Presse" wrote that "there was only one closet a Quebec artist could never exit and that was the federalist one."
Awards and honours.
Tremblay has received numerous awards in recognition of his work. These include the "Prix Victor-Morin" (1974), the "Prix France-Québec" (1984), the Chalmers Award (1986) and the Molson Prize (1994).
He received the Lieutenant-Governor's award for Ontario in 1976 and 1977. Tremblay was named the "Montréalais le plus remarquable des deux dernières décennies dans le domaine du théâtre" (the most remarkable Montrealer of the past two decades in theatre) (1978). In 1991 he was appointed "Officier de l'Ordre de France," and in the same year, "Chevalier de l'Ordre National du Québec." He is also a recipient of the "Chevalier de l'Ordre des Arts et des Lettres de France" (1994).
In 1999, Tremblay received a Governor General's Performing Arts Award, Canada's highest honour in the performing arts. This produced controversy when several well-known Quebec nationalists suggested that he should refuse the award. While he did not do this, he did admit, for the first time, that he had refused the Order of Canada in 1990.
In 2000, "Encore une fois, si vous le permettez" ("For The Pleasure of Seeing Her Again") won a Chalmers Award and a Dora Mavor Moore Award.
Works.
Novels and short story collections.
Note: Most titles also available in English translations
Plays.
Note: Most titles also available in English translations

</doc>
<doc id="20926" url="http://en.wikipedia.org/wiki?curid=20926" title="Supervised learning">
Supervised learning

Supervised learning is the machine learning task of inferring a function from labeled training data. The training data consist of a set of "training examples". In supervised learning, each example is a "pair" consisting of an input object (typically a vector) and a desired output value (also called the "supervisory signal"). A supervised learning algorithm analyzes the training data and produces an inferred function, which can be used for mapping new examples. An optimal scenario will allow for the algorithm to correctly determine the class labels for unseen instances. This requires the learning algorithm to generalize from the training data to unseen situations in a "reasonable" way (see inductive bias). 
The parallel task in human and animal psychology is often referred to as concept learning.
Overview.
In order to solve a given problem of supervised learning, one has to perform the following steps:
A wide range of supervised learning algorithms is available, each with its strengths and weaknesses. There is no single learning algorithm that works best on all supervised learning problems (see the No free lunch theorem). 
There are four major issues to consider in supervised learning:
Bias-variance tradeoff.
A first issue is the tradeoff between "bias" and "variance". Imagine that we have available several different, but equally good, training data sets. A learning algorithm is biased for a particular input formula_1 if, when trained on each of these data sets, it is systematically incorrect when predicting the correct output for formula_1. A learning algorithm has high variance for a particular input formula_1 if it predicts different output values when trained on different training sets. The prediction error of a learned classifier is related to the sum of the bias and the variance of the learning algorithm. Generally, there is a tradeoff between bias and variance. A learning algorithm with low bias must be "flexible" so that it can fit the data well. But if the learning algorithm is too flexible, it will fit each training data set differently, and hence have high variance. A key aspect of many supervised learning methods is that they are able to adjust this tradeoff between bias and variance (either automatically or by providing a bias/variance parameter that the user can adjust).
Function complexity and amount of training data.
The second issue is the amount of training data available relative to the complexity of the "true" function (classifier or regression function). If the true function is simple, then an "inflexible" learning algorithm with high bias and low variance will be able to learn it from a small amount of data. But if the true function is highly complex (e.g., because it involves complex interactions among many different input features and behaves differently in different parts of the input space), then the function will only be learnable from a very large amount of training data and using a "flexible" learning algorithm with low bias and high variance. Good learning algorithms therefore automatically adjust the bias/variance tradeoff based on the amount of data available and the apparent complexity of the function to be learned.
Dimensionality of the input space.
A third issue is the dimensionality of the input space. If the input feature vectors have very high dimension, the learning problem can be difficult even if the true function only depends on a small number of those features. This is because the many "extra" dimensions can confuse the learning algorithm and cause it to have high variance. Hence, high input dimensionality typically requires tuning the classifier to have low variance and high bias. In practice, if the engineer can manually remove irrelevant features from the input data, this is likely to improve the accuracy of the learned function. In addition, there are many algorithms for feature selection that seek to identify the relevant features and discard the irrelevant ones. This is an instance of the more general strategy of dimensionality reduction, which seeks to map the input data into a lower-dimensional space prior to running the supervised learning algorithm.
Noise in the output values.
A fourth issue is the degree of noise in the desired output values (the supervisory target variables). If the desired output values are often incorrect (because of human error or sensor errors), then the learning algorithm should not attempt to find a function that exactly matches the training examples. Attempting to fit the data too carefully leads to overfitting. You can overfit even when there are no measurement errors (stochastic noise) if the function you are trying to learn is too complex for your learning model. In such a situation that part of the target function that cannot be modeled "corrupts" your training data - this phenomenon has been called deterministic noise. When either type of noise is present, it is better to go with a higher bias, lower variance estimator.
In practice, there are several approaches to alleviate noise in the output values such as early stopping to prevent overfitting as well as detecting and removing the noisy training examples prior to training the supervised learning algorithm. There are several algorithms that identify noisy training examples and removing the suspected noisy training examples prior to training has decreased generalization error with statistical significance.
Other factors to consider.
Other factors to consider when choosing and applying a learning algorithm include the following:
When considering a new application, the engineer can compare multiple learning algorithms and experimentally determine which one works best on the problem at hand (see cross validation). Tuning the performance of a learning algorithm can be very time-consuming. Given fixed resources, it is often better to spend more time collecting additional training data and more informative features than it is to spend extra time tuning the learning algorithms.
The most widely used learning algorithms are Support Vector Machines, linear regression, logistic regression, naive Bayes, linear discriminant analysis, decision trees, k-nearest neighbor algorithm, and Neural Networks (Multilayer perceptron).
How supervised learning algorithms work.
Given a set of formula_4 training examples of the form formula_5 such that formula_6 is the feature vector of the i-th example and formula_7 is its label (i.e., class), a learning algorithm seeks a function formula_8, where formula_9 is the input space and
formula_10 is the output space. The function formula_11 is an element of some space of possible functions formula_12, usually called the "hypothesis space". It is sometimes convenient to
represent formula_11 using a scoring function formula_14 such that formula_11 is defined as returning the formula_16 value that gives the highest score: formula_17. Let formula_18 denote the space of scoring functions.
Although formula_12 and formula_18 can be any space of functions, many learning algorithms are probabilistic models where formula_11 takes the form of a conditional probability model formula_22, or formula_23 takes the form of a joint probability model formula_24. For example, naive Bayes and linear discriminant analysis are joint probability models, whereas logistic regression is a conditional probability model. 
There are two basic approaches to choosing formula_23 or formula_11: empirical risk minimization and structural risk minimization. Empirical risk minimization seeks the function that best fits the training data. Structural risk minimize includes a "penalty function" that controls the bias/variance tradeoff.
In both cases, it is assumed that the training set consists of a sample of independent and identically distributed pairs, formula_27. In order to measure how well a function fits the training data, a loss function formula_28 is defined. For training example formula_29, the loss of predicting the value formula_30 is formula_31. 
The "risk" formula_32 of function formula_11 is defined as the expected loss of formula_11. This can be estimated from the training data as
Empirical risk minimization.
In empirical risk minimization, the supervised learning algorithm seeks the function formula_11 that minimizes formula_32. Hence, a supervised learning algorithm can be constructed by applying an optimization algorithm to find formula_11. 
When formula_11 is a conditional probability distribution formula_40 and the loss function is the negative log likelihood: formula_41, then empirical risk minimization is equivalent to maximum likelihood estimation.
When formula_12 contains many candidate functions or the training set is not sufficiently large, empirical risk minimization leads to high variance and poor generalization. The learning algorithm is able
to memorize the training examples without generalizing well. This is called overfitting.
Structural risk minimization.
Structural risk minimization seeks to prevent overfitting by incorporating a regularization penalty into the optimization. The regularization penalty can be viewed as implementing a form of Occam's razor that prefers simpler functions over more complex ones.
A wide variety of penalties have been employed that correspond to different definitions of complexity. For example, consider the case where the function formula_11 is a linear function of the form
A popular regularization penalty is formula_45, which is the squared Euclidean norm of the weights, also known as the formula_46 norm. Other norms include the formula_47 norm, formula_48, and the formula_49 norm, which is the number of non-zero formula_50s. The penalty will be denoted by formula_51. 
The supervised learning optimization problem is to find the function formula_11 that minimizes
The parameter formula_54 controls the bias-variance tradeoff. When formula_55, this gives empirical risk minimization with low bias and high variance. When formula_54 is large, the learning algorithm will have high bias and low variance. The value of formula_54 can be chosen empirically via cross validation.
The complexity penalty has a Bayesian interpretation as the negative log prior probability of formula_11, formula_59, in which case formula_60 is the posterior probabability of formula_11.
Generative training.
The training methods described above are "discriminative training" methods, because they seek to find a function formula_11 that discriminates well between the different output values (see discriminative model). For the special case where formula_24 is a joint probability distribution and the loss function is the negative log likelihood formula_64 a risk minimization algorithm is said to perform "generative training", because formula_23 can be regarded as a generative model that explains how the data were generated. Generative training algorithms are often simpler and more computationally efficient than discriminative training algorithms. In some cases, the solution can be computed in closed form as in naive Bayes and linear discriminant analysis.
Generalizations of supervised learning.
There are several ways in which the standard supervised learning problem can be generalized:

</doc>
<doc id="20932" url="http://en.wikipedia.org/wiki?curid=20932" title="Martin Helwig">
Martin Helwig

Martin Helwig (Latin: "Martino Heilwig") (5 November 1516 – 26 January 1574) was a German cartographer of and from Silesia and
pedagogue. He was born in Neisse and died in Breslau, Holy Roman Empire.
Life.
A former pupil of an eminent German scholar and educationist Valentin Friedland, Martin Helwig went on to study at the University of Wittenberg, where as a student of Martin Luther and Philip Melanchthon he earned the academic degree of Magister. In 1552, he became Rector of St. Maria Magdalena School in Breslau (now Wrocław, in Poland). Equally proficient in mathematics and geography as well as classical languages, he produced the first woodcut map of Silesia made on the basis of surveys and data collected from local inhabitants, which he published in 1561 under the title "Silesiae Typus", and dedicated to , a wealthy Silesian merchant, banker, philanthropist, governor and patron of the principality of Breslau (Wrocław) who sponsored the map. Martin Helwig's map went on to receive acclaim in a public writing by Caspar Peucer, an eminent German scholar at the University of Wittenberg, and was later republished in several versions of Abraham Ortelius's pioneering world atlas, "Theatrum Orbis Terrarum".
The first map of Silesia by Martin Helwig constituted until the middle of the 18th century the main model and source of information for the cartographical presentation of this region of Europe on the maps of the most famous cartographers and publishers of those times.

</doc>
<doc id="20934" url="http://en.wikipedia.org/wiki?curid=20934" title="Macro virus">
Macro virus

In computing terminology, a macro virus is a virus that is written in a macro language: that is to say, a programming language which is embedded inside a software application (e.g., word processors and spreadsheet applications). Since some applications (notably, but not exclusively, Microsoft Office) allow macro programs to be embedded in documents such that the macros are run automatically when the document is opened, this provides a distinct mechanism by which malicious computer instructions can spread. (This is one reason it can be dangerous to open unexpected attachments in e-mails.) Many modern antivirus programs detects macro viruses as well as other types.
Fundamentals.
A macro is a series of commands and actions that help to automate some tasks - effectively a program but usually quite short and simple. However they are created, they need to be executed by some system which interprets the stored commands. Some macro systems are self-contained programs, but others are built into complex applications (for example word processors) to allow users to repeat sequences of commands easily, or to allow developers to tailor the application to local needs.
Operation.
A macro virus can be spread through e-mail attachments, removable media, networks, modems, and the Internet and is notoriously difficult to detect. Uninfected documents contain normal macros. Most malicious macros start automatically when a document is opened or closed. A common way for a macro virus to infect a computer is by replacing normal macros with the virus. The macro virus replaces the regular commands with the same name and runs when the command is selected. In the cases where the macro is run automatically, the macro is opened without the user knowing.
Once the application opens a file that contains a macro virus, the virus can infect the system. When triggered, it will begin to embed itself in other documents and templates, as well as future ones created. It may corrupt other parts of the system as well, depending on what resources a macro in this application can get access to. As the infected documents are shared with other users and systems, the virus will spread. The macro virus has also been known to be used as a way of installing software on a system without the user's consent as it can be used to look up software and web pages on the internet, go through with downloading and installing the software through the use of automated key-presses etc.; however, this is uncommon as it is usually un-fruitful for the virus coder since the installed software is usually noticed and uninstalled by the user.
A well-known example of a macro virus is the Melissa Virus from 1999. Anyone who opened a document with the virus in Microsoft Office would 'catch' the virus. The virus would then send itself by email to the first 50 people in the person’s address book. This made the virus replicate at a fast rate.
Since a macro virus depends on the application rather than the operating system, it can infect a computer running any operating system to which the targeted application has been ported. In particular, since Microsoft Word is available on Macintosh computers, word macro viruses can attack these as well as Windows platforms.
The macro virus can be avoided by exercising caution when opening email attachments and other documents. Not all macro viruses can be detected by antivirus software.

</doc>
<doc id="20935" url="http://en.wikipedia.org/wiki?curid=20935" title="Microsoft Access">
Microsoft Access

Microsoft Access, also known as Microsoft Office Access, is a database management system from Microsoft that combines the relational Microsoft Jet Database Engine with a graphical user interface and software-development tools. It is a member of the Microsoft Office suite of applications, included in the Professional and higher editions or sold separately.
Microsoft Access stores data in its own format based on the Access Jet Database Engine. It can also import or link directly to data stored in other applications and databases.
Software developers and data architects can use Microsoft Access to develop application software, and "power users" can use it to build software applications. Like other Office applications, Access is supported by Visual Basic for Applications (VBA), an object-oriented programming language that can reference a variety of objects including DAO (Data Access Objects), ActiveX Data Objects, and many other ActiveX components. Visual objects used in forms and reports expose their methods and properties in the VBA programming environment, and VBA code modules may declare and call Windows operating-system functions.
History.
Project Omega.
Microsoft's first attempt to sell a relational database product was during the mid 1980s, when Microsoft obtained the license to sell . In the late 1980s Microsoft developed its own solution codenamed Omega. It was confirmed in 1988 that a database product for Windows and OS/2 was in development. It was going to include the "EB" Embedded Basic language, which was going to be the language for writing macros in all Microsoft applications, but the unification of macro languages did not happen until the introduction of Visual Basic for Applications (VBA). Omega was also expected to provide a front end to the Microsoft SQL Server. The application was very resource-hungry, and there were reports that it was working slowly on the 386 processors that were available at the time. It was scheduled to be released in the 1st quarter of 1990, but in 1989 the development of the product was reset and it was rescheduled to be delivered no sooner than in January 1991. Parts of the project were later used for other Microsoft projects: Cirrus (codename for Access) and Thunder (codename for Visual Basic, where the Embedded Basic engine was used). After Access's premiere, the Omega project was demonstrated in 1992 to several journalists and included features that were not available in Access.
Project Cirrus.
After the Omega project was scrapped, some of its developers were assigned to the Cirrus project (most were assigned to the team which created Visual Basic). Its goal was to create a competitor for applications like Paradox or dBase that would work on Windows. After Microsoft acquired FoxPro, there were rumors that the Microsoft project might get replaced with it, but the company decided to develop them in parallel. It was assumed that the project would make use of Extensible Storage Engine (Jet Blue) but, in the end, only support for Microsoft Jet Database Engine (Jet Red) was provided. The project used some of the code from both the Omega project and a pre-release version of Visual Basic. In July 1992, betas of Cirrus shipped to developers and the name Access became the official name of the product.
Timeline.
1992: Microsoft released Access version 1.0 on 13 November 1992, and an Access 1.1 release in May 1993 to improve compatibility with other Microsoft products and to include the Access Basic programming language.
1994: Microsoft specified the minimum hardware requirements for Access v2.0 as: Microsoft Windows v3.1 with 4 MB of RAM required, 6 MB RAM recommended; 8 MB of available hard disk space required, 14 MB hard disk space recommended. The product shipped on seven 1.44 MB diskettes. The manual shows a 1994 copyright date.
Originally, the software worked well with relatively small databases but testing showed that some circumstances caused data corruption. For example, file sizes over 10 MB proved problematic (note that most hard disks held less than 500 MB at the time this was in wide use), and the "Getting Started" manual warns about a number of circumstances where obsolete device drivers or incorrect configurations can cause data loss. With the phasing out of Windows 95, 98 and ME, improved network reliability, and Microsoft having released 8 service packs for the Jet Database Engine, the reliability of Access databases has improved and it supports both more data and a larger number of users.
With Office 95, Microsoft Access 7.0 (a.k.a. "Access 95") became part of the Microsoft Office Professional Suite, joining Microsoft Excel, Word, and PowerPoint and transitioning from Access Basic to VBA. Since then, Microsoft has released new versions of Microsoft Access with each release of Microsoft Office. This includes Access 97 (version 8.0), Access 2000 (version 9.0), Access 2002 (version 10.0), Access 2003 (version 11.5), Access 2007 (version 12.0), and Access 2010 (version 14.0).
Versions 3.0 and 3.5 of Microsoft Jet database engine (used by Access 7.0 and the later-released Access 97 respectively) had a critical issue which made these versions of Access unusable on a computer with more than 1 GB of memory. While Microsoft fixed this problem for Jet 3.5/Access 97 post-release, it never fixed the issue with Jet 3.0/Access 95.
The native Access database format (the Jet MDB Database) has also evolved over the years. Formats include Access 1.0, 1.1, 2.0, 7.0, 97, 2000, 2002, 2007, and 2010. The most significant transition was from the Access 97 to the Access 2000 format; which is not backward compatible with earlier versions of Access. s of 2011[ [update]] all newer versions of Access support the Access 2000 format. New features were added to the Access 2002 format which can be used by Access 2002, 2003, 2007, and 2010.
Microsoft Access 2000 increased the maximum database size to 2GB from 1GB in Access 97.
Microsoft Access 2007 introduced a new database format: ACCDB. It supports links to SharePoint lists and complex data types such as multivalue and attachment fields. These new field types are essentially recordsets in fields and allow the storage of multiple values or files in one field. Microsoft Access 2007 also introduced File Attachment field, which stored data more efficiently than the OLE (Object Linking and Embedding) field.
Microsoft Access 2010 introduced a new version of the ACCDB format supported hosting Access Web solutions on a SharePoint 2010 server. For the first time, this allowed Access solutions to be run without having to install Access on their PC and was the first support of Mac users. Any user on the SharePoint site with sufficient rights could use the Access Web solution. A copy of Access was still required for the developer to create the Access Web solution, and the desktop version of Access remained part of Access 2010. The Access Web solutions were not the same as the desktop solutions. Automation was only through the macro language (not VBA) which Access automatically converted to JavaScript. The data was no longer in an Access database but SharePoint lists. An Access desktop database could link to the SharePoint data, so hybrid applications were possible so that SharePoint users needing basic views and edits could be supported while the more sophisticated, traditional solutions could remain in the desktop Access database.
Microsoft Access 2013 offers traditional Access desktop solutions plus a significantly updated SharePoint 2013 web solution. The Access Web model in Access 2010 was replaced by a new architecture that stores its data in actual SQL Server databases. Unlike SharePoint lists, this offers true relational database design with referential integrity, scalability, extensibility and performance one would expect from SQL Server. The database solutions that can be created on SharePoint 2013 offer a modern user interface designed to display multiple levels of relationships that can be viewed and edited, along with resizing for different devices and support for touch. The Access 2013 desktop is similar to Access 2010 but several features were discontinued including support for Access Data Projects (ADPs), pivot tables, pivot charts, Access data collections, source code control, replication, and other legacy features. Access desktop database maximum size remained 2GB (as it has been since the 2000 version).
Prior to the introduction of Access, Borland (with Paradox and dBase) and Fox (with FoxPro) dominated the desktop database market. Microsoft Access was the first mass-market database program for Windows. With Microsoft's purchase of FoxPro in 1992 and the incorporation of Fox's Rushmore query optimization routines into Access, Microsoft Access quickly became the dominant database for Windows - effectively eliminating the competition which failed to transition from the MS-DOS world.
Access's initial codename was Cirrus; the forms engine was called Ruby. This was before Visual Basic. Bill Gates saw the prototypes and decided that the BASIC language component should be co-developed as a separate expandable application, a project called Thunder. The two projects were developed separately.
Access was also the name of a communications program from Microsoft, meant to compete with ProComm and other programs. This proved a failure and was dropped. Years later, Microsoft reused the name for its database software.
Uses.
In addition to using its own database storage file, Microsoft Access also may be used as the 'front-end' of a program while other products act as the 'back-end' tables, such as Microsoft SQL Server and non-Microsoft products such as Oracle and Sybase. Multiple backend sources can be used by a Microsoft Access Jet Database (ACCDB and MDB formats). Similarly, some applications such as Visual Basic, ASP.NET, or Visual Studio .NET will use the Microsoft Access database format for its tables and queries. Microsoft Access may also be part of a more complex solution, where it may be integrated with other technologies such as Microsoft Excel, Microsoft Outlook, Microsoft Word, Microsoft PowerPoint and ActiveX controls.
Access tables support a variety of standard field types, indices, and referential integrity including cascading updates and deletes. Access also includes a query interface, forms to display and enter data, and reports for printing. The underlying Jet database, which contains these objects, is multi-user and handles record-locking.
Repetitive tasks can be automated through macros with point-and-click options. It is also easy to place a database on a network and have multiple users share and update data without overwriting each other's work. Data is locked at the record level which is significantly different from Excel which locks the entire spreadsheet.
There are template databases within the program and for download from their website. These options are available upon starting Access and allow users to enhance a database with predefined tables, queries, forms, reports, and macros. Database templates support VBA code but Microsoft's templates do not include VBA code.
Programmers can create solutions using VBA, which is similar to Visual Basic 6.0 (VB6) and used throughout the Microsoft Office programs such as Excel, Word, Outlook and PowerPoint. Most VB6 code, including the use of Windows API calls, can be used in VBA. Power users and developers can extend basic end-user solutions to a professional solution with advanced automation, data validation, error trapping, and multi-user support.
The number of simultaneous users that can be supported depends on the amount of data, the tasks being performed, level of use, and application design. Generally accepted limits are solutions with 1 GB or less of data (Access supports up to 2 GB) and performs quite well with 100 or fewer simultaneous connections (255 concurrent users are supported). This capability is often a good fit for department solutions. If using an Access database solution in a multi-user scenario, the application should be "split". This means that the tables are in one file called the back end (typically stored on a shared network folder) and the application components (forms, reports, queries, code, macros, linked tables) are in another file called the front end. The linked tables in the front end point to the back end file. Each user of the Access application would then receive his or her own copy of the front end file.
Applications that run complex queries or analysis across large datasets would naturally require greater bandwidth and memory. Microsoft Access is designed to scale to support more data and users by linking to multiple Access databases or using a back-end database like Microsoft SQL Server. With the latter design, the amount of data and users can scale to enterprise-level solutions.
Microsoft Access's role in web development prior to version 2010 is limited. User interface features of Access, such as forms and reports, only work in Windows. In versions 2000 through 2003 an Access object type called Data Access Pages created publishable web pages. Data Access Pages are no longer supported. The Microsoft Jet Database Engine, core to Access, can be accessed through technologies such as ODBC or OLE DB. The data (i.e., tables and queries) can be accessed by web-based applications developed in ASP.NET, PHP, or Java. With the use of Microsoft's Terminal Services and Remote Desktop Application in Windows Server 2008 R2, organizations can host Access applications so they can be run over the web. This technique does not scale the way a web application would but is appropriate for a limited number of users depending on the configuration of the host.
Access 2010 allows databases to be published to SharePoint 2010 web sites running Access Services. These web-based forms and reports run in any modern web browser. The resulting web forms and reports, when accessed via a web browser, don't require any add-ins or extensions (e.g. ActiveX, Silverlight).
Access 2013 can create web applications directly in SharePoint 2013 sites running Access Services. Access 2013 web solutions store its data in an underlying SQL Server database which is much more scalable and robust than the Access 2010 version which used SharePoint lists to store its data.
A compiled version of an Access database (File extensions: .MDE /ACCDE or .ADE; ACCDE only works with Access 2007 or later) can be created to prevent user from accessing the design surfaces to modify module code, forms, and reports. An MDE/ACCDE file is a Microsoft Access database file with all modules compiled and all editable source code removed. An ADE file is an Access project file with all modules compiled and all editable source code removed. Both the .MDE/ACCDE and .ADE versions of an Access database are used when end-user modifications are not allowed or when the application’s source code should be kept confidential.
Microsoft also offers for download to help distribute Access 2007 applications, create database templates, and integrate source code control with Microsoft Visual SourceSafe.
Features.
Users can create tables, queries, forms and reports, and connect them together with macros. Advanced users can use VBA to write rich solutions with advanced data manipulation and user control. Access also has report creation features that can work with any data source that Access can access.
The original concept of Access was for end users to be able to access data from any source. Other features include: the import and export of data to many formats including Excel, Outlook, ASCII, dBase, Paradox, FoxPro, SQL Server, Oracle, ODBC, etc. It also has the ability to link to data in its existing location and use it for viewing, querying, editing, and reporting. This allows the existing data to change while ensuring that Access uses the latest data. It can perform heterogeneous joins between data sets stored across different platforms. Access is often used by people downloading data from enterprise level databases for manipulation, analysis, and reporting locally.
There is also the Jet Database format (MDB or ACCDB in Access 2007) which can contain the application and data in one file. This makes it very convenient to distribute the entire application to another user, who can run it in disconnected environments.
One of the benefits of Access from a programmer's perspective is its relative compatibility with SQL (structured query language) — queries can be viewed graphically or edited as SQL statements, and SQL statements can be used directly in Macros and VBA Modules to manipulate Access tables. Users can mix and use both VBA and "Macros" for programming forms and logic and offers object-oriented possibilities. VBA can also be included in queries.
Microsoft Access offers parameterized queries. These queries and Access tables can be referenced from other programs like VB6 and .NET through DAO or ADO. From Microsoft Access, VBA can reference parameterized stored procedures via ADO.
The desktop editions of Microsoft SQL Server can be used with Access as an alternative to the Jet Database Engine. This support started with MSDE (Microsoft SQL Server Desktop Engine), a scaled down version of Microsoft SQL Server 2000, and continues with the SQL Server Express versions of SQL Server 2005 and 2008.
Microsoft Access is a file server-based database. Unlike client–server relational database management systems (RDBMS), Microsoft Access does not implement database triggers, stored procedures, or transaction logging. Access 2010 includes table-level triggers and stored procedures built into the ACE data engine. Thus a Client-server database system is not a requirement for using stored procedures or table triggers with Access 2010.
Tables, queries, forms, reports and macros can now be developed specifically for web base application in Access 2010. Integration with Microsoft SharePoint 2010 is also highly improved.
Access Services and Web database.
ASP.NET web forms can query a Microsoft Access database, retrieve records and display them on the browser.
SharePoint Server 2010 via Access Services allows for Access 2010 databases to be published to SharePoint, thus enabling multiple users to interact with the database application from any standards-compliant Web browser. Access Web databases published to SharePoint Server can use standard objects such as tables, queries, forms, macros, and reports. Access Services stores those objects in SharePoint.
Access 2013 offers the ability to publish Access web solutions on SharePoint 2013. Rather than using SharePoint lists as its data source, Access 2013 uses an actual SQL Server database hosted by SharePoint or SQL Azure. This offers a true relational database with referential integrity, scalability, maintainability, and extensibility compared to the SharePoint views Access 2010 used.. The macro language is enhanced to support more sophisticated programming logic and database level automation.
Import or Link sources.
Microsoft Access can also import or link directly to data stored in other applications and databases. Microsoft Office Access 2007 and newer can import from or link to:
Microsoft Access Runtime.
Microsoft offers free runtime versions of Microsoft Access: , , , which allow users to run an Access desktop application without needing to purchase or install a full version of Microsoft Access. This allows Access developers to create databases that can be freely distributed to an unlimited number of end-users. The runtime version allows users to view, edit and delete data, along with running queries, forms, reports, macros and VBA module code. But the runtime version does not allow users to change the design of Microsoft Access objects or code. The runtime versions are similar to their corresponding full version of Access and usually compatible with earlier versions; for example Access Runtime 2010 allows a user to run an Access application made with the 2010 version as well as 2007 through 2000. Due to deprecated features in Access 2013, its runtime version is also unable to support those older features.
Development.
Access stores all database tables, queries, forms, reports, macros, and modules in the Access Jet database as a single file.
For query development, Access offers a "Query Designer", a graphical user interface that allows users to build queries without knowledge of structured query language. In the Query Designer, users can "show" the datasources of the query (which can be tables or queries) and select the fields they want returned by clicking and dragging them into the grid. One can set up joins by clicking and dragging fields in tables to fields in other tables. Access allows users to view and manipulate the SQL code if desired. Any Access table, including linked tables from different data sources, can be used in a query.
Access also supports the creation of "pass-through queries". These snippets of SQL code can address external data sources through the use of ODBC connections on the local machine. This enables users to interact with data stored outside the Access program without using linked tables or Jet.
Users construct the pass-through queries using the SQL syntax supported by the external data source.
When developing reports (in "Design View") additions or changes to controls cause any linked queries to execute in the background and the designer is forced to wait for records to be returned before being able to make another change. This feature cannot be turned off.
Non-programmers can use the macro feature to automate simple tasks through a series of drop-down selections. Macros allow users to easily chain commands together such as running queries, importing or exporting data, opening and closing forms, previewing and printing reports, etc. Macros support basic logic (IF-conditions) and the ability to call other macros. Macros can also contain sub-macros which are similar to subroutines. In Access 2007, enhanced macros included error-handling and support for temporary variables. Access 2007 also introduced embedded macros that are essentially properties of an object's event. This eliminated the need to store macros as individual objects. However, macros were limited in their functionality by a lack of programming loops and advanced coding logic until Access 2013. With significant further enhancements introduced in Access 2013, the capabilities of macros became fully comparable to VBA. They made feature rich web-based application deployments practical, via a greatly enhanced Microsoft SharePoint interface and tools, as well as on traditional Windows desktops.
In common with other products in the Microsoft Office suite, the other programming language used in Access is Microsoft VBA. It is similar to Visual Basic 6.0 (VB6) and code can be stored in modules, classes, and code behind forms and reports. To create a richer, more efficient and maintainable finished product with good error handling, most professional Access applications are developed using the VBA programming language rather than macros, except where web deployment is a business requirement.
To manipulate data in tables and queries in VBA or macros, Microsoft provides two database access libraries of COM components:
As well as DAO and ADO, developers can also use OLE DB and ODBC for developing native C/C++ programs for Access. For ADPs and the direct manipulation of SQL Server data, ADO is required. DAO is most appropriate for managing data in Access/Jet databases, and the only way to manipulate the complex field types in ACCDB tables.
In the database container or navigation pane in Access 2007 and later versions, the system automatically categorizes each object by type (e.g., table, query, macro). Many Access developers use the Leszynski naming convention, though this is not universal; it is a programming convention, not a DBMS-enforced rule. It is particularly helpful in VBA where references to object names may not indicate its data type (e.g. tbl for tables, qry for queries).
Developers deploy Microsoft Access most often for individual and workgroup projects (the Access 97 speed characterization was done for 32 users). Since Access 97, and with Access 2003 and 2007, Microsoft Access and hardware have evolved significantly. Databases under 1 GB in size (which can now fit entirely in RAM) and 200 simultaneous users are well within the capabilities of Microsoft Access. Of course, performance depends on the database design and tasks. Disk-intensive work such as complex searching and querying take the most time.
As data from a Microsoft Access database can be cached in RAM, processing speed may substantially improve when there is only a single user or if the data is not changing. In the past, the effect of packet latency on the record-locking system caused Access databases to run slowly on a Virtual Private Network (VPN) or a Wide Area Network (WAN) against a Jet database. s of 2010[ [update]] broadband connections have mitigated this issue. Performance can also be enhanced if a is maintained to the back-end database throughout the session rather than opening and closing it for each table access. If Access database performance over VPN or WAN suffers, then a client using Remote Desktop Protocol (such as Microsoft Terminal Services) can provide an effective solution. Access databases linked to SQL Server or to Access Data Projects work well over VPNs and WANs.
In July 2011, Microsoft acknowledged an intermittent query performance problem with all versions of Access and Windows 7 and Windows Server 2008 R2 due to the nature of resource management being vastly different in newer operating systems. This issue severely affects query performance on both Access 2003 and earlier with the Jet Database Engine code, as well as Access 2007 and later with the Access Database Engine (ACE). Microsoft has issued hotfixes for Access 2007 and for Access 2010, but will not fix the issue with Jet 4.0 as it is out of mainstream support.
In earlier versions of Microsoft Access, the ability to distribute applications required the purchase of the Developer Toolkit; in Access 2007, 2010 and Access 2013 the "Runtime Only" version is offered as a free download, making the distribution of royalty-free applications possible on Windows XP, Vista, 7 and Windows 8.x.
Split database architecture.
Microsoft Access applications can adopt a split-database architecture. The single database can be divided into a separate "back-end" file that contains the data tables (shared on a file server) and a "front-end" (containing the application's objects such as queries, forms, reports, macros, and modules). The "front-end" Access application is distributed to each user's desktop and linked to the shared database. Using this approach, each user has a copy of Microsoft Access (or the runtime version) installed on their machine along with their application database. This reduces network traffic since the application is not retrieved for each use. The "front-end" database can still contain local tables for storing a user's settings or temporary data. This split-database design also allows development of the application independent of the data. One disadvantage is that users may make various changes to their own local copy of the application and this makes it hard to manage version control. When a new version is ready, the front-end database is replaced without impacting the data database. Microsoft Access has two built-in utilities, Database Splitter and Linked Table Manager, to facilitate this architecture.
Linked tables in Access use absolute paths rather than relative paths, so the development environment either has to have the same path as the production environment or a "dynamic-linker" routine can be written in VBA.
For very large Access databases, this may have performance issues and a SQL backend should be considered in these circumstances. This is less of an issue if the entire database can fit in the PC's RAM since Access caches data and indexes.
Migration to SQL Server.
To scale Access applications to enterprise or web solutions, one possible technique involves migrating to Microsoft SQL Server or equivalent server database. A client–server design significantly reduces maintenance and increases security, availability, stability, and transaction logging.
Access 2010 included a feature called the Upsizing Wizard that allowed users to upgrade their databases to Microsoft SQL Server, an ODBC client–server database. This feature was removed from Access 2013. An additional solution, the SQL Server Migration Assistant for Access (SSMA), continues to be available for free download from Microsoft.
A variety of upgrading options are available. After migrating the data and queries to SQL Server, the Access database can be linked to the SQL database. However, certain data types are problematic, most notably "Yes/No". In Microsoft Access there are three states for the Yes/No (True/False) data type: empty, no/false (zero) and yes/true (-1). The corresponding SQL Server data type is binary, with only two states, permissible values, zero and 1. Regardless, SQL Server is still the easiest migration, and most appropriate especially if the user does not have rights to create objects such as stored procedures on SQL Server. Retrieving data from linked tables is optimized to just the records needed, but this scenario may operate less efficiently than what would otherwise be optimal for SQL Server. For example, in instances where multi-table joins still require copying the whole table across the network.
In previous versions of Access, including Access 2010, databases can also be converted to Access Data Projects (ADP) which are tied directly to one SQL Server database. This feature was removed from Access 2013. ADP's support the ability to directly create and modify SQL Server objects such as tables, views, stored procedures, and SQL Server constraints. The views and stored procedures can significantly reduce the network traffic for multi-table joins. Fortunately, SQL Server supports temporary tables and links to other data sources beyond the single SQL Server database.
Finally, some Access databases are completely replaced by another technology such as ASP.NET or Java once the data is converted. However any migration may dictate major effort since the Access SQL language is a more powerful superset of standard SQL. Further, Access application procedures, whether VBA and macros, are written at a relatively higher level versus the currently available alternatives that are both robust and comprehensive. Note that the Access macro language, allowing an even higher level of abstraction than VBA, was significantly enhanced in Access 2010 and again in Access 2013.
In many cases, developers build direct web-to-data interfaces using ASP.NET, while keeping major business automation processes, administrative and reporting functions that don't need to be distributed to everyone in Access for information workers to maintain.
While all Access data can migrate to SQL Server directly, some queries cannot migrate successfully. In some situations, you may need to translate VBA functions and user defined functions into T–SQL or .NET functions / procedures. Crosstab queries can be migrated to SQL Server using the PIVOT command.
Protection.
Microsoft Access offers several ways to secure the application while allowing users to remain productive.
The most basic is a database password. Once entered, the user has full control of all the database objects. This is a relatively weak form of protection which can be easily cracked.
A higher level of protection is the use of workgroup security requiring a user name and password. Users and groups can be specified along with their rights at the object type or individual object level. This can be used to specify people with read-only or data entry rights but may be challenging to specify. A separate workgroup security file contains the settings which can be used to manage multiple databases. Workgroup security is not supported in the Access 2007 and Access 2010 ACCDB database format, although Access 2007 and Access 2010 still support it for MDB databases.
Databases can also be encrypted. The ACCDB format offers significantly advanced encryption from previous versions.
Additionally, if the database design needs to be secured to prevent changes, Access databases can be locked/protected (and the source code compiled) by converting the database to a .MDE file. All changes to the VBA project (modules, forms, or reports) need to be made to the original MDB and then reconverted to MDE. In Access 2007 and Access 2010, the ACCDB database is converted to an ACCDE file. Some tools are available for unlocking and "decompiling", although certain elements including original VBA comments and formatting are normally irretrievable.
File extensions.
Microsoft Access saves information under the following file formats:
External links.
This article is based on material taken from the Free On-line Dictionary of Computing prior to 1 November 2008 and incorporated under the "relicensing" terms of the GFDL, version 1.3 or later.

</doc>
<doc id="20941" url="http://en.wikipedia.org/wiki?curid=20941" title="Metabolic pathway">
Metabolic pathway

In biochemistry, a metabolic pathway is a series of chemical reactions occurring within a cell. In a pathway, the initial chemical (metabolite) is modified by a sequence of chemical reactions. These reactions are catalyzed by enzymes, where the product of one enzyme acts as the substrate for the next. These enzymes often require dietary minerals, vitamins, and other cofactors to function.
Pathways are required for the maintenance of homeostasis within an organism and the flux of metabolites through a pathway is regulated depending on the needs of the cell and the availability of the substrate. The end product of a pathway may be used immediately, initiate another metabolic pathway or be stored for later use. The metabolism of a cell consists of an elaborate network of interconnected pathways that enable the synthesis and breakdown of molecules (anabolism and catabolism)
Overview.
Each metabolic pathway consists of a series of biochemical reactions that are connected by their intermediates: the products of one reaction are the substrates for subsequent reactions, and so on. Metabolic pathways are often considered to flow in one direction. Although all chemical reactions are technically reversible, conditions in the cell are often such that it is thermodynamically more favorable for flux to flow in one direction of a reaction. For example, one pathway may be responsible for the synthesis of a particular amino acid, but the breakdown of that amino acid may occur via a separate and distinct pathway. One example of an exception to this "rule" is the metabolism of glucose. Glycolysis results in the breakdown of glucose, but several reactions in the glycolysis pathway are reversible and participate in the re-synthesis of glucose (gluconeogenesis).
Major metabolic pathways.
 
Glucuronate metabolism 
Pentose interconversion 
Inositol metabolism 
Cellulose and sucrosemetabolism 
Starch and glycogenmetabolism 
Other sugarmetabolism 
Pentose phosphate pathway 
Glycolysis and Gluconeogenesis 
Amino sugars metabolism 
Small amino acid synthesis 
Branched amino acidsynthesis 
Purine biosynthesis 
Histidine metabolism 
Aromatic aminoacid synthesis 
Pyruvatedecarboxylation 
Fermentation 
Fatty acidmetabolism 
Urea cycle 
Aspartate amino acidgroup synthesis 
Porphyrins andcorrinoidsmetabolism 
Citric acid cycle 
Glutamate aminoacid groupsynthesis 
Pyrimidine biosynthesis 
Cellular respiration.
A core set of energy-producing catabolic pathways occur within all living organisms in some form. These pathways transfer the energy released by breakdown of nutrients into ATP and other small molecules used for energy (e.g. GTP, NADPH, FADH). All cells can perform anaerobic respiration by glycolysis. Additionally, most organisms can perform more efficient aerobic respiration through the citric acid cycle and oxidative phosphorylation. Additionally plants, algae and cyanobacteria are able to use sunlight to anabolically synthesise compounds from non-living matter by photosynthesis.

</doc>
<doc id="20942" url="http://en.wikipedia.org/wiki?curid=20942" title="Malthusian catastrophe">
Malthusian catastrophe

A Malthusian catastrophe (also known as Malthusian check) was a prediction of a forced return to subsistence-level conditions once population growth had outpaced agricultural production. 
Work by Thomas Malthus.
In 1798, Thomas Malthus wrote:
Famine seems to be the last, the most dreadful resource of nature. The power of population is so superior to the power of the earth to produce subsistence for man, that premature death must in some shape or other visit the human race. The vices of mankind are active and able ministers of depopulation. They are the precursors in the great army of destruction, and often finish the dreadful work themselves. But should they fail in this war of extermination, sickly seasons, epidemics, pestilence, and plague advance in terrific array, and sweep off their thousands and tens of thousands. Should success be still incomplete, gigantic inevitable famine stalks in the rear, and with one mighty blow levels the population with the food of the world.—Malthus T.R. 1798. "An essay on the principle of population". Chapter VII, p61
Notwithstanding the apocalyptic image conveyed by this particular paragraph, Malthus himself did not subscribe to the notion that mankind was fated for a "catastrophe" due to population overshooting resources. Rather, he believed that population growth was generally restricted by available resources:
The passion between the sexes has appeared in every age to be so nearly the same that it may always be considered, in algebraic language, as a given quantity. The great law of necessity which prevents population from increasing in any country beyond the food which it can either produce or acquire, is a law so open to our view...that we cannot for a moment doubt it. The different modes which nature takes to prevent or repress a redundant population do not appear, indeed, to us so certain and regular, but though we cannot always predict the mode we may with certainty predict the fact.—Malthus, 1798, Chapter IV.
Neo-Malthusian theory.
After World War II, mechanized agriculture produced a dramatic increase in productivity of agriculture and the so-called Green Revolution greatly increased crop yields, expanding the world's food supply while lowering food prices. In response, the growth rate of the world's population accelerated rapidly, resulting in predictions by Paul R. Ehrlich, Simon Hopkins, and many others of an imminent Malthusian catastrophe. However, populations of most developed countries grew slowly enough to be outpaced by gains in productivity.
By the early 21st century, many technologically developed countries had passed through the demographic transition, a complex social development encompassing a drop in total fertility rates in response to lower infant mortality, increased urbanization, and a wider availability of effective birth control, causing the demographic-economic paradox. 
On the assumption that the demographic transition is now spreading from the developed countries to less developed countries, the United Nations Population Fund estimates that human population may peak in the late 21st century rather than continue to grow until it has exhausted available resources. 
Historians have estimated the total human population back to 10,000 BC. The figure on the right shows the trend of total population from 1800 to 2005, and from there in three projections out to 2100 (low, medium, and high). The second figure shows the annual growth rate over the same period. If population growth were exactly exponential, then the growth rate would be a flat line. The fact that it was increasing from 1920 to 1960 indicates faster-than-exponential growth over this period. However, the growth rate has been decreasing since then, and is projected to continue decreasing. The United Nations population projections out to 2100 (the red, orange, and green lines) show a possible peak in the world's population occurring as early as 2040 in one extreme scenario, and by 2075 in the "medium" scenario, and never ending growth in the third. 
The graph of annual growth rates (above) does not appear exactly as one would expect for long-term exponential growth. For exponential growth it should be a straight line at constant height, whereas in fact the graph from 1800 to 2005 is dominated by an enormous hump that began about 1920, peaked in the mid-1960s, and has been steadily eroding away for the last 40 years. The sharp fluctuation between 1959 and 1960 was due to the combined effects of the Great Leap Forward and a natural disaster in China. Also visible on this graph are the effects of the Great Depression, the two world wars, and possibly also the 1918 flu pandemic.
Though short-term trends, even on the scale of decades or centuries, cannot prove or disprove the existence of mechanisms promoting a Malthusian catastrophe over longer periods, the prosperity of a major fraction of the human population at the beginning of the 21st century, and the debatability of ecological collapse made by Paul R. Ehrlich in the 1960s and 1970s, has led some people, such as economist Julian L. Simon, to question its inevitability.
A 2004 study by a group of prominent economists and ecologists, including Kenneth Arrow and Paul Ehrlich suggests that the central concerns regarding sustainability have shifted from population growth to the consumption/savings ratio, due to shifts in population growth rates since the 1970s. Empirical estimates show that public policy (taxes or the establishment of more complete property rights) can promote more efficient consumption and investment that are sustainable in an ecological sense; that is, given the current (relatively low) population growth rate, the Malthusian catastrophe can be avoided by either a shift in consumer preferences or public policy that induces a similar shift. 
However, some contend that the Malthusian catastrophe is not imminent. A 2002 study by the UN Food and Agriculture Organization predicts that world food production will be in excess of the needs of the human population by the year 2030; however, that source also states that hundreds of millions will remain hungry (presumably due to economic realities and political issues).
Criticism.
Ester Boserup wrote in her book "The Conditions of Agricultural Growth: The Economics of Agrarian Change under Population Pressure", that population levels determine agricultural methods, rather than agricultural methods determining population (via food supply). A major point of her book is that "necessity is the mother of invention." Julian Simon was one of many economists who challenged the Malthusian catastrophe, citing (1) the existence of new knowledge, and educated people to take advantage of it, and (2) "economic freedom", that is, the ability of the world to increase production when there is a profitable opportunity to do so. 
The economist Henry George argued that Malthus didn't provide any evidence of a natural tendency for a population to overwhelm its ability to provide for itself. George wrote that even the main body of Malthus' work refuted this theory; that examples given show social causes for misery, such as "ignorance and greed... bad government, unjust laws, or war," rather than insufficient food production.
Friedrich Engels also criticizes the Malthusian catastrophe because Malthus failed to see that surplus population is connected to surplus wealth, surplus capital, and surplus landed property. Population is large where the overall productive power is large. Engels also states that the calculation that Malthus made with the difference in population and productive power is incorrect because Malthus does not take into consideration a third element, science. Scientific “progress is as unlimited and at least as rapid as that of population”. On the other hand, Joseph Tainter argues that science has diminishing marginal returns and scientific progress is becoming more difficult, harder to achieve and costlier.
References.
</dl>

</doc>
<doc id="20943" url="http://en.wikipedia.org/wiki?curid=20943" title="Millennialism">
Millennialism

Millennialism (from millennium, Latin for "thousand years"), or chiliasm in Greek, is a belief held by some Christian denominations that there will be a Golden Age or Paradise on Earth in which "Christ will reign" for 1000 years prior to the final judgment and future eternal state (the "World to Come" of the "New Heavens" and "New Earth"). This belief is derived primarily from . Millennialism is a specific form of millenarianism.
Similarities to millennialism are found in Zoroastrianism. It held that there were successive thousand-year periods, each of which will end in a cataclysm of heresy and destruction, until the final destruction of evil and of the spirit of evil by a triumphant king of peace at the end of the final millennial age (supposed by some to be the year 2000). "Then Saoshyant makes the creatures again pure, and the resurrection and future existence occur" ("Zand-i Vohuman Yasht 3:62").
Various other social and political movements, both religious and secular, have also been linked to millennialist metaphors by scholars.
Christianity.
Early church.
If millenarian beliefs have fallen into disfavor in mainstream Christian theology today, this was not the case during the Early Christian centuries. At least during the first four centuries, millennialism was a well-known doctrine in both East and West. Tertullian, Commodian, Lactantius, Methodius, and Apollinaris of Laodicea all advocated premillennial doctrine. In addition, according to religious scholar the Rev. Dr. Francis Nigel Lee the following is true: "Justin's 'Occasional Chiliasm' sui generis which was strongly anti-pretribulationistic was followed possibly by Pothinus in A.D. 175 and more probably (around 185) by Irenaeus – although Justin Martyr, discussing his own premillennial beliefs in his "Dialogue with Trypho the Jew", Chapter 110, observed that they were not necessary to Christians:
I admitted to you formerly, that I and many others are of this opinion, and [believe] that such will take place, as you assuredly are aware; but, on the other hand, I signified to you that many who belong to the pure and pious faith, and are true Christians, think otherwise."
Melito of Sardis is frequently listed as a second century proponent of premillennialism. The support usually given for the supposition is that Jerome [Comm. on Ezek. 36 ] and Gennadius [De Dogm. Eccl., Ch. 52] both affirm that he was a decided millenarian.”
In the early third century, Hippolytus of Rome wrote:
And 6,000 years must needs be accomplished, in order that the Sabbath may come, the rest, the holy day "on which God rested from all His works." For the Sabbath is the type and emblem of the future kingdom of the saints, when they "shall reign with Christ," when He comes from heaven, as John says in his Apocalypse: for "a day with the Lord is as a thousand years." Since, then, in six days God made all things, it follows that 6, 000 years must be fulfilled. (Hippolytus. On the HexaËmeron, Or Six Days' Work. From Fragments from Commentaries on Various Books of Scripture).
Around 220, there were some similar influences on Tertullian though only with very important and extremely optimistic (if not perhaps even postmillennial modifications and implications). On the other hand, 'Christian Chiliastic' ideas were indeed advocated in 240 by Commodian; in 250 by the Egyptian Bishop Nepos in his Refutation of Allegorists; in 260 by the almost unknown Coracion; and in 310 by Lactantius.
Into the late fourth century, the bishop known as Ambrose of Milan had millennial leanings (Ambrose of Milan. Book II. On the Belief in the Resurrection, verse 108).
The first known opponent of Christian chiliasm was Marcion, in the 2nd century, who was declared a heretic by the Catholic church. "The Catholic Encyclopedia" noted that in the 2nd century proponents of "Gnosticism rejected millenarianism".
Chiliasm was, however, according to the interpretation of non-chiliasts, condemned as a heresy in the 4th century by the Church, which included the phrase "whose Kingdom shall have no end" in the Nicene Creed in order to rule out the idea of a Kingdom of God which would last for only 1000 literal years. Despite some writers' belief in millennialism, it was a decided minority view, as expressed in the nearly universal condemnation of the doctrine over a gradual period of time, beginning with Augustine of Hippo.
Millennialism is strongly rejected as a heresy by the Orthodox Church. In AD 230, the Synod of Iconium declared that baptisms performed by the Montanist sect were invalid. The Ecumenical Council of Constantinople in AD 381 supported the Synod of Iconium and further declared millennialism to be a heresy.
In a letter to Queen Gerberga of France around 950, Adso of Montier-en-Der established the idea of a "last World Emperor" who would conquer non-Christians before the arrival of the Antichrist.
Reformation and beyond.
Christian views on the future order of events diversified after the Protestant reformation (c.1517). In particular, new emphasis was placed on the passages in the Book of Revelation which seemed to say that as Christ would return to judge the living and the dead, Satan would be locked away for 1000 years, but then released on the world in a final battle (Rev. 20:1–6). Previous Catholic and Orthodox theologians had no clear or consensus view on what this actually meant (only the concept of an end of the world coming unexpected, "like a thief in a night", and the concept of "the antichrist" were almost universally held). Millennialist theories try to explain what this "1000 years of Satan in chains" would be like.
Various types of millennialism exist with regard to Christian eschatology, especially within Protestantism, such as Premillennialism, Postmillennialism, and Amillennialism. The first two refer to different views of the relationship between the "millennial Kingdom" and Christ's second coming. Premillennialism sees Christ's second advent as preceding the millennium, thereby separating the second coming from the final judgment. In this view, "Christ's reign" will be physical. Postmillennialism sees Christ's second coming as subsequent to the millennium and concurrent with the final judgment. In this view "Christ's reign" (during the millennium) will be spiritual in and through the church. Amillennialism basically denies a future literal 1000 year kingdom and sees the church age metaphorically described in Rev. 20:1–6 in which "Christ's reign" is current in and through the church.
The Catholic Church strongly condemns millennialism as the following shows:
A millennium is a period of one thousand years, and, in particular, Christ's thousand-year rule on this earth, either directly preceding or immediately following the Second Coming (and the Day of Judgment).
The millennium reverses the previous period of evil and suffering; it rewards the virtuous for their courage while punishing the evil-doers, with a clear separation of saints and sinners. The vision of a thousand-year period of bliss for the faithful, to be enjoyed here on earth ("heaven on earth"), exerted an irresistible power. Although the picture of life in the millennial era is almost willfully obscure and hardly more appealing than that of, say, the Golden Age, what has made the millennium much more powerful than the Golden Age or Paradise myths are the activities of the sects and movements that it has inspired. Throughout the ages, hundreds of sects were convinced that the millennium was imminent, about to begin in the very near future, with precise dates given on many occasions.
Premillennial sects look for signs of Christ's imminent return. Other chiliast sects, such as the prophetic Anabaptist followers of Thomas Müntzer, have believed that the millennium had already begun, with only their own members having realized this fact. Consequently, they have attempted to live out their own vision of millennial life, radically overturning the beliefs and practices of the surrounding society. In doing so, they offered a model of the good life and expressed their hope that soon the rest of the world would follow and live like they did.
See Christian eschatology for a discussion of "premillennialism" and "postmillennialism".
Utopianism.
The early Christian concept had ramifications far beyond strictly religious concern during the centuries to come, as it was blended and enhanced with ideas of utopia.
In the wake of early millennial thinking, the Three Ages philosophy developed. The Italian monk and theologian Joachim of Fiore (died 1202) claimed that all of human history was a succession of three ages:
It was believed that the Age of the Holy Spirit would begin at around 1260, and that from then on all believers would be living as monks, mystically transfigured and full of praise for God, for a thousand years until Judgment Day would put an end to the history of our planet.
In the Modern Era, some of the concepts of millennial thinking have found their way into various secular ideas, usually in the form of a belief that a certain historical event will fundamentally change human society (or has already done so). For example, the French Revolution seemed to many to be ushering in the millennial age of reason. Also, the philosophies of Georg Wilhelm Friedrich Hegel (1770–1831) and Karl Marx (1818–1883) carried strong millennial overtones. As late as 1970, Yale law teacher Charles A. Reich coined the term "Consciousness III" in his best seller "The Greening of America", in which he spoke of a new age ushered in by the hippie generation. However, these secular theories generally have little or nothing to do with the original millennial thinking, or with each other.
Jehovah's Witnesses.
Jehovah's Witnesses believe that Christ will rule from heaven for 1,000 years as king over the earth, assisted by 144,000 holy ones. The principal purpose of this millennial reign is to resolve the question of who legitimately deserves to be sovereign of the Earth and of the universe. It also serves to finally accomplish the Creator's original purpose of an Earth populated by a peaceful, satisfied and loving human society, descendants from the first human couple Adam and Eve. This will happen after the destruction of the wicked at Armageddon.
Armageddon will be a decisive battle between two opposing forces: on one side, Christ Jesus together with the holy angels; in opposition, human governments and institutions (manipulated by wicked spirits) insistent on maintaining control over humanity. Unlike natural or manmade catastrophes, Christ and his angels will selectively destroy those humans deemed incorrigible. Planet Earth will be rid of greed, corruption, and all individuals and institutions who impenitently ruin the earth and impose misery on others. (Rev 16:16; 1 John 5:19; Matt 25:31–40)
Malevolent spiritual beings will be restrained and prevented from interfering in human affairs for the duration of Christ's reign. Free of untoward influences, the Witnesses see the 1,000 year reign as fulfillment of the Biblical promise of "New Heavens and a New Earth".
One aspect which differentiates Jehovah's Witnesses from other millennialists (such as Baptists, Church of God, Church of Christ, and other fundamentalist Christian groups) is the interpretation of 2 Peter 3:7, 13. Whereas the latter hold to a literal interpretation, namely that the planet Earth will be destroyed and replaced with another physical planet, Jehovah's Witnesses by contrast believe the language in 2 Peter 3:7 is figurative. Hence their understanding is that the literal planet Earth will not be destroyed but instead, the existing framework of human society, which includes greedy commerce, divisive religions and corrupt governments.
Christ's kingdom consists of those who govern (from heaven) and those who are governed (on earth). This government will accomplish in the comparatively short timespan of 1,000 years all the things human governments and institutions have promised (but failed to deliver) during thousands of years of rule, while experimenting every form of government imaginable. Jesus Christ, the Messiah, will be the 'head of state', or King officially designated by God. In turn, he will delegate authority to 144,000 select individuals, individually chosen by Jehovah from among humanity. Those chosen have already proven their complete allegiance to Jehovah God and to His legitimate right to govern. The first to be promised this privilege were the faithful apostles of Jesus Christ in the 1st century C.E. The rulers will be loving and fair, always intent on the common good of everyone.
On the earth, those who are kept safe through that 'great tribulation' (Matt 24:21; Rev 7:9) and the subsequent destruction of the world ruled by Satan the Devil will be ushered into a just, peaceful, and equitable earthwide society of humans. During the millennium, Christ will use his power to cure every sort of sickness (Rev 22:17), malady, and infirmity. Ultimately everyone who accepts living by Jehovah God's righteous standards (Exodus 20:1–17) will attain perfect health. Guided by the heavenly government, humans will work to progressively establish an earthwide paradise (Matt 19:27,28). Hunger and poverty will be completely eliminated (Rev 21:1–5).
Humans who died during all prior human history (but who were not deemed incorrigible) will be resurrected (or recreated) on the earth during the 1,000 years. These will have the opportunity to fully integrate into society (Isaiah 65:17).
At the culmination of the millennium, Christ will cede control of planet Earth to his Father Jehovah (1 Cor 15:28) and will himself acknowledge and accept Jehovah's right to rule (or sovereignty). The restraints on wicked spirit creatures will be removed and all humanity will face a test. With full understanding, each human must individually choose whether to accept or reject God's right to rule, his sovereignty. Those humans and (previously restrained) spirit creatures who reject rule by Jehovah God, showing themselves to be menaces to human society and the remainder of the universe, will be completely and permanently eliminated. For any of these who may have been resurrected, this will literally be a "second" death. Thereafter, obedient humankind will live forever on the earth and Jehovah God's original purpose for the earth will be accomplished. (Gen 1:28)
Judaism.
There is a not dissimilar belief in Judaism. Time is split into 3 periods
(1) The world started in year 1 (= 3761 BC), the epoch. For almost two thousand years there was nothing, most people were idolatrous and God's presence was not seen in the world.
(2) In 1812 BC, 1948 in Jewish years, Abraham was born. The birth of the first forefather heralded two thousand years of Godliness. This is the period of the Bible, the first and second temples in Jerusalem etc.
(3) In 70 AD the Second Temple in Jerusalem was destroyed, and after the Bar Kokhba revolt, Jews were barred from Jerusalem except for the day of Tisha B'av. This started a further two thousand years of non-Godliness. Some Jews believe that the Messiah must come before the end of this period, or by about 2270 AD.
Nazism.
The most controversial interpretation of the Three Ages philosophy and of millennialism in general is Adolf Hitler's "Third Reich" (""Drittes Reich"), which in his vision would last for a thousand years to come ("Tausendjähriges Reich""), but which ultimately only lasted for 12 years (1933–1945).
The phrase "Third Reich" was originally coined by the German thinker Arthur Moeller van den Bruck, who in 1923 published a book titled "Das Dritte Reich". Looking back at German history, he distinguished two separate periods, and identified them with the ages of Joachim of Fiore:
After the interval of the Weimar Republic (1918–1933), during which constitutionalism, parliamentarism and even pacifism ruled, these were then to be followed by:
Although van den Bruck was unimpressed by Hitler when he met him in 1922 and did not join the Nazi Party, the phrase was nevertheless adopted by the Nazis to describe the totalitarian state they wanted to set up when they gained power, which they succeeded in doing in 1933. Later, however, the Nazi authorities banned the informal use of "Third Reich" throughout the German press in the summer of 1939, instructing it to use more official terms such as "German Reich", "Greater German Reich", and "National Socialist Germany" exclusively.
During the early part of the Third Reich many Germans also referred to Hitler as being the "German Messiah", especially when he conducted the Nuremberg Rallies, which came to be held at a date somewhat before the Autumn Equinox in Nuremberg, Germany.
In a speech held on 27 November 1937, Hitler commented on his plans to have major parts of Berlin torn down and rebuilt:
After Adolf Hitler's unsuccessful attempt to implement a thousand-year-reign, the Vatican issued an official statement that millennial claims could not be safely taught and that the related scriptures in Revelation (also called the Apocalypse) should be understood spiritually. Catholic author Bernard LeFrois wrote:
Theosophy.
The Theosophist Alice Bailey taught that Christ (in her books she refers to the powerful spiritual being best known by Theosophists as "Maitreya" as "The Christ" or "The World Teacher", not as "Maitreya") would return “sometime after AD 2025”, and that this would be the New Age equivalent of the Christian concept of the Second Coming of Christ.
Bailey stated that St. Germain (referred to by Bailey in her books as "The Master Rakoczi" or "The Master R.") is the manager of the executive council of the Christ. According to Bailey, when Christ returns he will stay the entire approximately 2,000 years period of the Age of Aquarius and thus the New Age equivalent of the Millennial Age, when Maitreya will reign as the spiritual leader of Earth as the Messiah who will bring world peace, will not be just a single millennium but will be the Aquarian bimillennium.
Social movements.
Millennial social movements are a specific form of millenarianism that are based on some concept of a one thousand-year cycle. Sometimes the two terms are used as synonyms, but this is not entirely accurate for a purist. Millennial social movements need not be religious, but they must have a vision of an apocalypse that can be utopian or dystopian.
Bibliography.
</dl>

</doc>
<doc id="20945" url="http://en.wikipedia.org/wiki?curid=20945" title="Might and Magic">
Might and Magic

Might and Magic (MM) is a series of role-playing video games from New World Computing, which in 1996 became a subsidiary of The 3DO Company. The producer of the series was Jon Van Caneghem.
"Might and Magic" is considered one of the defining examples of early PC role-playing games, along with the "Bard's Tale", "Ultima" and "Wizardry" series.
The original "Might and Magic" series officially ended with the closure of the 3DO Company. The rights to the "Might and Magic" name were purchased for USD 1.3 million by Ubisoft, who "rebooted" the franchise with a new series with no apparent connection to the previous continuity, starting with the games "Heroes of Might and Magic V" and "Dark Messiah of Might and Magic".
History.
There are ten games in the series:
Anthologies.
There were several spin-offs from the main series, including "Heroes of Might and Magic", "Crusaders of Might and Magic", "Warriors of Might and Magic", "Legends of Might and Magic", and the fanmade "Swords of Xeen".
In August 2003, Ubisoft acquired the rights to the Might and Magic franchise for US$1.3 million after 3DO filed for Chapter 11 bankruptcy. Ubisoft has since released multiple new projects using the Might and Magic brand, including a fifth installment of the Heroes series, developed by Nival, an action-style game called "Dark Messiah of Might and Magic", developed by Arkane Studios and a puzzle RPG called "", developed by "Capybara Games".
In September 2009, the "Might and Magic Sixpack" was re-released via the digital distribution service, Good Old Games. In March 2011, The seventh and eighth installments of the series were also added to Good Old Games.
In March 2013, Ubisoft confirmed that Limbic Entertainment is developing "Might & Magic X Legacy" with a release date said to be in early 2014. The game is described as a solo, first-person RPG with turn-based gameplay. It takes place in the same world as "Might & Magic Heroes VI".
Gameplay.
The majority of the gameplay takes place in a medieval fantasy setting, while later sections of the games are often based on science fiction tropes, the transition often serving as a plot twist. The player controls a party of player characters, which can consist of members of various character classes. The game world is presented to the player in first person perspective. In the earlier games the interface is very similar to that of "Bard's Tale", but from "" onward, the interface features a three-dimensional environment. Combat is turn-based, though the later games allowed the player to choose to conduct combat in real time.
The game worlds in all of the Might and Magic games are quite large, and a player can expect each game to provide several dozen hours of gameplay. It is usually quite combat-intensive and often involves large groups of enemy creatures. Monsters and situations encountered throughout the series tend to be well-known fantasy staples such as giant rats, werewolf curses, dragon flights and zombie hordes, rather than original creations. "Isles of Terra" and the "Xeen" games featured a more distinct environment, blending fantasy and science fiction elements in a unique way.
Plot.
Although most of the gameplay reflects a distinctly fantasy genre, the overarching plot of the first nine games has something of a science fiction background. The series is set in a fictional galaxy as part of an alternative universe, where planets are overseen by a powerful race of space travelers known as Ancients. In each of the games, a party of characters fights monsters and completes quests on one of these planets, until they eventually become involved in the affairs of the Ancients.
Van Caneghem has stated in interview that the "Might and Magic" setting is inspired by his love for both science fiction and fantasy. He cites "The Twilight Zone" and the "Star Trek" episode "For the World is Hollow and I Have Touched the Sky" as having inspired "Might and Magic" lore.
The first five games in the series concern the renegade guardian of the planet Terra, named Sheltem, who becomes irrevocably corrupted, developing a penchant for throwing planets into their suns. Sheltem establishes himself on a series of flat worlds known as nacelles (which are implied to be giant spaceships) and Corak, a second guardian and creation of the Ancients, with the assistance of the player characters, pursues him across the Void. Eventually both Corak and Sheltem are destroyed in a climactic battle on the nacelle of Xeen.
The sixth, seventh and eighth games take place on Enroth, a single planet partially ruled by the Ironfist dynasty, and chronicle the events and aftermath of an invasion by the Kreegan (colloquially referred to as Devils), the demonlike arch-enemies of the Ancients. It is also revealed that the destruction wrought by the Ancients' wars with the Kreegan is the reason why the worlds of Might & Magic exist as medieval fantasy settings despite once being seeded with futuristic technology – the worlds have been 'cut off' from the Ancients and descended into barbarism. The first through third games in the "Heroes of Might and Magic" series traces the fortunes of the Ironfists in more detail. None of the science fiction elements appear in the "Heroes" series besides the appearance of Kreegan characters in "Heroes of Might and Magic III".
The Ubisoft release "Might and Magic X: Legacy" departs from this continuity and is set in the world of Ashan. Ashan is a high fantasy setting with no place for science fiction elements in its lore.

</doc>
<doc id="20947" url="http://en.wikipedia.org/wiki?curid=20947" title="Adobe Flash">
Adobe Flash

Adobe Flash (formerly called Macromedia Flash and Shockwave Flash) is a multimedia and software platform used for creating vector graphics, animation, browser games, rich internet applications, desktop applications, mobile applications and mobile games.
Flash displays text, vector and raster graphics to provide animations, video games and applications. It allows streaming of audio and video, and can capture mouse, keyboard, microphone and camera input.
Overview.
Flash graphics and animation is designed using the Flash editor, and may be viewed by end-users using Flash Player (for web browsers), AIR (for desktop or mobile apps) or third-party players such as Scaleform GFx (for video games).
Adobe Flash Player enables end-users to view Flash content using web browsers, and is supported on Microsoft Windows, Mac OS X and Linux. Adobe Flash Lite enabled viewing Flash content on older smartphones but has been stopped and superseded by Adobe AIR.
Flash is frequently used to serve streaming media, advertisement and interactive multimedia content on web pages and Flash-enabled software. However, in recent years, the usage of Flash on websites has declined, and as of 2015, Flash is primarily used to build video games for mobile devices with Adobe AIR.
Applications.
The ActionScript programming language allows creation of interactive animations, video games, web applications, desktop applications and mobile applications. Flash software can be developed using an IDE such as Adobe Flash Professional, Adobe Flash Builder, FlashDevelop and Powerflasher FDT.
Web applications can be developed with Flash using the ActionScript 3.0 programming language and related tools such as Adobe Flex Builder/Flex SDK. Third-party IDEs such as FlashDevelop and Powerflasher FDT enable developers to create Flash games and applications with tools similar to Microsoft Visual Studio.
Adobe AIR enables full-featured desktop and mobile applications to be developed with Flash, and published for Microsoft Windows, Mac OS X, Google Android, and iOS.
Video games.
Flash video games are popular on the Internet, with portals like Newgrounds dedicated to hosting of Flash-based games. Popular games developed with Flash include Angry Birds, FarmVille, AdventureQuest and Machinarium.
Adobe introduced various technologies to help build video games, including Adobe AIR (to release games for desktop or mobile platforms), Adobe Scout (to improve performance), CrossBridge (to convert C++-based games to run in Flash), and Stage3D (to support GPU-accelerated video games). 3D frameworks like Away3D and Flare3D simplified creation of 3D content for Flash.
Adobe AIR allows creation of Flash-based mobile games, which may be published to the Google Play and iTunes app stores.
Flash is also used to build interfaces and HUDs for 3D video games using Scaleform GFx, a technology that renders Flash content within non-Flash video games. Scaleform is supported by more than 10 major video game engines including Unreal Engine, UDK, CryEngine and PhyreEngine, and has been used to provide 3D interfaces for more than 150 major video game titles since its launch in 2003.
Commercial animation.
Adobe Flash Professional is one of the common animation programs for low-cost 2D television and commercial animation, in competition with Anime Studio and Toon Boom Animation.
Notable users of Flash include DHX Media Vancouver for productions including "Pound Puppies" and ', Fresh TV for Total Drama, Nelvana for "6teen" and "Clone High", Williams Street for "Metalocalypse" and "Squidbillies", and Nickelodeon Animation Studios for "Wow! Wow! Wubbzy!" ', "Danny Phantom" and "Happy Tree Friends".
Films.
Flash is less commonly used for feature-length animated films; however, 2009's "The Secret of Kells", an Irish film, was animated primarily in Adobe Flash, and was nominated for an Academy Award for Best Animated Feature at the 82nd Academy Awards.
History.
FutureWave.
Flash originated with the application SmartSketch, developed by Jonathan Gay. It was published by FutureWave Software, which was founded by Charlie Jackson. SmartSketch was a drawing application for pen computers running the PenPoint OS. When PenPoint failed in the marketplace, SmartSketch was ported to Microsoft Windows and Mac OS.
As the Internet became more popular, FutureWave added cell animation editing to the vector drawing capabilities of SmartSketch and released FutureSplash Animator on multiple platforms. FutureWave approached Adobe Systems with an offer to sell them FutureSplash in 1995, but Adobe turned down the offer at that time. FutureSplash was used by Microsoft in its early work with the Internet (MSN), and also by Disney Online for their subscription-based service Disney's Daily Blast.
Macromedia.
In November 1996, FutureSplash was acquired by Macromedia, and Macromedia re-branded and released "FutureSplash Animator" as "Macromedia Flash 1.0". Flash was a two-part system, a graphics and animation editor known as "Macromedia Flash", and a player known as "Macromedia Flash Player".
"FutureSplash Animator" was an animation tool originally developed for pen-based computing devices, but due to the small size of the "FutureSplash Viewer", it was particularly suited for download over the Web. Macromedia distributed Flash Player as a free browser plugin in order to quickly gain market share. As of 2005, more computers worldwide had the Flash Player installed than any other Web media format, including Java, QuickTime, RealNetworks and Windows Media Player.
Macromedia upgraded the Flash system significantly From 1996 to 1999, adding MovieClips, JavaScript (the precursor to ActionScript), Alpha transparency, and other features. As Flash matured, Macromedia's focus shifted from marketing it as a graphics and media tool to promoting it as a Web application platform, adding scripting and data access capabilities to the player while attempting to retain its small footprint.
In 2000, the first major version of ActionScript was developed, and released with "Flash 5". Actionscript 2.0 was released with "Flash MX 2004" and supported object-oriented programming, improved UI components, and other advanced programming features. The last version of Flash released by Macromedia was "Flash 8", which focussed on graphical upgrades such as filters (blur, drop shadow, etc), blend modes (similar to Adobe Photoshop), and advanced features for FLV video.
Adobe.
Macromedia was acquired by Adobe Systems in 2005, and the entire Macromedia product line including Flash, Dreamweaver, Director/Shockwave and Authorware was now handled by Adobe. Flash is currently developed and distributed by Adobe Systems.
In 2007, Adobe released "Adobe Flash CS3 Professional", the first version released under Adobe, and the ninth major version of Flash. It introduced the ActionScript 3.0 programming language, which supported modern programming practices and enabled business applications to be developed with Flash. Adobe Flex Builder (built on Eclipse) targeted the enterprise application development market, and was also released the same year. Flex Builder included the Flex SDK, a set of components that included charting, advanced UI, and data services ("Flex Data Services").
In 2008, Adobe released the historic tenth version of Flash, "Adobe Flash CS4". Flash 10 improved animation capabilities within the Flash editor, adding a motion editor panel (similar to Adobe After Effects), inverse kinematics (bones), basic 3D object animation, object-based animation, and other advanced text and graphics features. "Flash Player 10" included the first in-built 3D engine (without GPU-acceleration), that allowed basic object transformations in 3D space (position, rotation, scaling).
Also in 2008, Adobe released the first version of Adobe Integrated Runtime (later re-branded as "Adobe AIR"), a runtime engine that replaced Flash Player, and provided additional capabilities to the ActionScript 3.0 language to build desktop and mobile applications. With AIR, developers could access the file system (files & folders), and connected devices (joystick, gamepad, sensors) for the first time.
In 2011, "Adobe Flash Player 11" was released, and with it the first version of Stage3D, allowing for GPU-accelerated 3D rendering for Flash applications and games, on desktop platforms such as Microsoft Windows and Mac OS X. Adobe further improved 3D capabilities from 2011 to 2013, adding support for 3D rendering on Android and iOS platforms, alpha-channels, compressed textures, texture atlases, and other features. Adobe AIR was upgraded to support 64-bit computers, and developers could now add additional functionality to the AIR runtime using "AIR Native Extensions" (ANE).
In 2014, Adobe AIR reached a milestone when over 100,000 unique applications were built on AIR, and over 1 billion installations of the same were logged from users across the world (May 2014). Adobe AIR was voted as the "Best Mobile Application Development" product at the Consumer Electronics Show for two consecutive years (CES 2014 and CES 2015).
Format.
FLA.
Flash source files are in the FLA format, and contain graphics, animation as well as embedded assets such as bitmap images, audio files and FLV video files. The Flash source file format is a proprietary format and Adobe Flash Professional is the only available authoring tool capable of editing such files. Flash source files (.fla) may be compiled into Flash movie files (.swf) using Flash Professional.
SWF.
Flash movie files are in the "SWF" format, traditionally called "ShockWave Flash" movies, "Flash movies", or "Flash applications", usually have a .swf file extension, and may be used in the form of a web page plug-in, strictly "played" in a standalone Flash Player, or incorporated into a self-executing Projector movie (with the .exe extension in Microsoft Windows). Flash Video files have a .flv file extension and are either used from within .swf files or played through a flv-aware player, such as VLC, or QuickTime and Windows Media Player with external codecs added.
The use of vector graphics combined with program code allows Flash files to be smaller—and thus allows streams to use less bandwidth—than the corresponding bitmaps or video clips. For content in a single format (such as just text, video, or audio), other alternatives may provide better performance and consume less CPU power than the corresponding Flash movie, for example when using transparency or making large screen updates such as photographic or text fades.
In addition to a vector-rendering engine, the Flash Player includes a virtual machine called the ActionScript Virtual Machine (AVM) for scripting interactivity at run-time, with video, MP3-based audio, and bitmap graphics. As of Flash Player 8, it offers two video codecs: On2 Technologies VP6 and Sorenson Spark, and run-time JPEG, Progressive JPEG, PNG, and GIF capability. In the next version, Flash is slated to use a just-in-time compiler for the ActionScript engine.
3D.
Flash Player 11 introduced a full 3D shader API, called Stage3D, which is fairly similar to WebGL. Stage3D enables GPU-accelerated rendering of 3D graphics within Flash games and applications, and has been used to build Angry Birds, and a couple of other notable games.
Various 3D frameworks have been built for Flash using Stage3D, such as Away3D 4, CopperCube, Flare3D, Starling.:vii Professional game engines like Unreal Engine and Unity also export Flash versions which use Stage3D to render 3D graphics.
Flash Video.
Virtually all browser plugins for video are free of charge and cross-platform, including Adobe's offering of Flash Video, which was first introduced with Flash version 6. Flash Video has been a popular choice for websites due to the large installed user base and programmability of Flash. In 2010, Apple publicly criticized Adobe Flash, including its implementation of video playback for not taking advantage of hardware acceleration, one reason Flash is not to be found on Apple's mobile devices. Soon after Apple's criticism, Adobe demoed and released a beta version of Flash 10.1, which takes advantage of GPU hardware acceleration even on a Mac. Flash 10.2 beta, released December 2010, adds hardware acceleration for the whole video rendering pipeline.
Flash Audio.
Flash Audio is most commonly encoded in MP3 or AAC (Advanced Audio Coding) however it can also use ADPCM, Nellymoser (Nellymoser Asao Codec) and Speex audio codecs. Flash allows sample rates of 11, 22 and 44.1 kHz. It cannot have 48 kHz audio sample rate, which is the standard TV and DVD sample rate.
On August 20, 2007, Adobe announced on its blog that with Update 3 of Flash Player 9, Flash Video will also implement some parts of the MPEG-4 international standards. Specifically, Flash Player will work with video compressed in H.264 (MPEG-4 Part 10), audio compressed using AAC (MPEG-4 Part 3), the F4V, MP4 (MPEG-4 Part 14), M4V, M4A, 3GP and MOV multimedia container formats, 3GPP Timed Text specification (MPEG-4 Part 17), which is a standardized subtitle format and partial parsing capability for the 'ilst' atom, which is the ID3 equivalent iTunes uses to store metadata. MPEG-4 Part 2 and H.263 will not work in F4V file format. Adobe also announced that it will be gradually moving away from the FLV format to the standard ISO base media file format (MPEG-4 Part 12) owing to functional limits with the FLV structure when streaming H.264. The final release of the Flash Player implementing some parts of MPEG-4 standards had become available in Fall 2007.
Adobe Flash Player 10.1 does not have acoustic echo cancellation, unlike the VoIP offerings of Skype and Google Voice, making this and earlier versions of Flash less suitable for group calling or meetings. Flash Player 10.3 Beta incorporates acoustic echo cancellation.
Scripting language.
"ActionScript" is the programming language used by Flash. It is an enhanced superset of the ECMAScript programming language, with a classical Java-style class model, rather than JavaScript's prototype model.
Specifications.
In October 1998, Macromedia disclosed the Flash Version 3 Specification on its website. It did this in response to many new and often semi-open formats competing with SWF, such as Xara's Flare and Sharp's Extended Vector Animation formats. Several developers quickly created a C library for producing SWF. In February 1999, MorphInk 99 was introduced, the first third-party program to create SWF files. Macromedia also hired Middlesoft to create a freely available developers' kit for the SWF file format versions 3 to 5.
Macromedia made the Flash Files specifications for versions 6 and later available only under a non-disclosure agreement, but they are widely available from various sites.
In April 2006, the Flash SWF file format specification was released with details on the then newest version format (Flash 8). Although still lacking specific information on the incorporated video compression formats (On2, Sorenson Spark, etc.), this new documentation covered all the new features offered in Flash v8 including new ActionScript commands, expressive filter controls, and so on. The file format specification document is offered only to developers who agree to a license agreement that permits them to use the specifications only to develop programs that can export to the Flash file format. The license does not allow the use of the specifications to create programs that can be used for playback of Flash files. The Flash 9 specification was made available under similar restrictions.
In June 2009, Adobe launched the Open Screen Project (), which made the SWF specification available without restrictions. Previously, developers could not use the specification for making SWF-compatible players, but only for making SWF-exporting authoring software. The specification still omits information on codecs such as Sorenson Spark, however.
Animation tools.
Official tools.
The Adobe Flash Professional authoring program is primarily used to design graphics and animation and publish the same for websites, web applications, and video games. The program also offers limited support for audio and video embedding, and ActionScript scripting.
Adobe released Adobe LiveMotion, designed to create interactive animation content and export it to a variety of formats, including SWF. LiveMotion failed to gain any notable user base.
In February 2003, Macromedia purchased Presedia, which had developed a Flash authoring tool that automatically converted PowerPoint files into Flash. Macromedia subsequently released the new product as Breeze, which included many new enhancements.
Third-party tools.
Various free and commercial software packages can output animations into the Flash SWF format, suitable for display on the web.
Programming tools.
Official tools.
Adobe provides a series of tools to develop software applications and video games for Flash:
Third-party tools.
Third-party development tools have been created to assist developers in creating software applications and video games with Flash.
Players.
Adobe Flash Player.
Adobe Flash Player is a multimedia and application player originally developed by Macromedia and acquired by Adobe Systems. It plays SWF files, which can be created by Adobe Flash Professional, Apache Flex, or a number of other Adobe Systems and 3rd party tools. It has support for a scripting language called ActionScript, which can be used to display Flash Video from an SWF file.
ScaleForm.
Scaleform GFx is a commercial alternative Flash player that features fully hardware-accelerated 2D graphics rendering using the GPU. Scaleform has high conformance with both Flash 10 ActionScript 3 and Flash 8 ActionScript 2. Scaleform GFx is a game development middleware solution that helps create graphical user interfaces or HUDs within 3D video games.
SwfDec.
Swfdec is an outdated free/open source replacement of Adobe Flash Player. It runs on Linux and FreeBSD and is distributed under the terms of the GNU Lesser General Public License (LGPL). The last release was on  21, 2008 (2008--).
Shumway.
Shumway is an open source Flash Player released by Mozilla in November 2012. It is built in JavaScript and is thus compatible with modern web-browsers. In early October 2013, Shumway was included by default in the Firefox nightly branch.
Gnash.
Gnash is an active project that aims to create a software player and browser plugin replacement for the Adobe Flash Player. Despite potential patent worries because of the proprietary nature of the files involved, Gnash provides most SWFv7 features but does not fully support SWF v7, SWF v8-files, or the '9'th generation. Gnash runs on Windows, Linux and other platforms for the 32-bit, 64-bit, and other operating systems.
Lightspark.
Lightspark is a free and open source SWF player. It implements the latest ActionScript 3. Lightspark supports OpenGL-based rendering for 3D content. The player is compatible with H.264 Flash videos on YouTube.
Availability.
Desktop computers.
Flash Player.
The latest version of Adobe Flash Player is available for many major desktop platforms, including Windows (XP and newer) and OS X (10.6 and later). The latest version is also available on Linux but only on Google Chrome as Adobe no longer releases updates for the non-PPAPI plugin on Linux.
Adobe Flash Player is available in three flavors: "ActiveX", "Plug-in" and "Projector". The "ActiveX" version is an ActiveX control for use in Internet Explorer and any other Windows applications that supports ActiveX technology. The "plug-in" version is available for Netscape-compatible browsers on Microsoft Windows, Macintosh and Linux. The "projector" version is a standalone player that can open SWF files directly.
The following table documents Flash Player and Adobe AIR support on desktop operating systems:
Adobe AIR.
The latest version of Adobe AIR, version 3, contains Adobe Flash Player 11, and is available for Windows XP and later, as well as OS X. Official support for desktop Linux distributions ceased in June 2011 with version 2.6.
Adobe AIR is installed with Adobe Reader 9 (released in July, 2008), Adobe Photoshop and Adobe Lightroom, with no option for exclusion.
Mobile devices.
Flash Player.
Adobe Flash Player was available for a variety of mobile operating systems, including Android (between versions 2.2 and 4.0.4), Pocket PC/Windows CE, QNX (e.g. on BlackBerry PlayBook), Symbian, Palm OS, and webOS (since version 2.0). Flash Player for smart phones was made available to handset manufacturers at the end of 2009.
However in November 2011, Adobe announced the withdrawal of support for Flash Player on mobile devices. Adobe continues to support deploying Flash based content as mobile applications via Adobe AIR.
Adobe is reaffirming its commitment to "aggressively contribute" to HTML5. Adobe announced the end of Flash for mobile platforms or TV, instead focusing on HTML5 for browser content and Adobe AIR for the various mobile application stores. and described it as "the beginning of the end". BlackBerry LTD (formerly known as RIM) announced that it would continue to develop Flash Player for the PlayBook.
There is no Adobe Flash Player for iOS devices (iPhone, iPad and iPod Touch). However, Flash content can be made to run on iOS devices in a variety of ways:
The mobile version of Internet Explorer for Windows Phone cannot play Flash content., however Flash support is still present on the tablet version of Windows.
Adobe AIR.
Adobe AIR was released in 2008, and allows the creation of mobile applications and mobile games using Flash and ActionScript. Notable mobile games built with Flash include Angry Birds, Machinarium and Defend Your Castle.
Using AIR, developers can access the full Adobe Flash functionality, including text, vector graphics, raster graphics, video, audio, camera and microphone capability. Adobe AIR also includes additional features such as file system integration, native client extensions, desktop integration and access to connected devices and sensors.
AIR applications can be published as native phone applications on certain mobile operating systems, such as Android (ARM Cortex-A8 and above) and Apple iOS.
The following table explains to what extent Adobe AIR can run on various mobile operating systems:
Portable electronic devices.
Adobe Flash Lite is a lightweight version of Adobe Flash Player intended for mobile phones and other portable electronic devices like Chumby and iRiver.
On the emerging single-board enthusiast market, as substantially popularized by the Raspberry Pi, support from Adobe is lacking. However, Gnash have been ported and found useful.
Open source.
Tools.
Several third-party tools are able to use and generate SWF files, and some tools such as IrfanView are capable of rendering SWF files, through the use of Flash Player.
Open-source Flash content creation software includes Ajax Animator, Clash, OpenOffice Impress, KToon, Salasaga, and Synfig.
Compilers.
Apache Flex is an open-source software development kit (SDK) for the development of Flash-based rich internet applications. The Apache Flex ActionScript 3.0 compiler generates SWF files from ActionScript 3 files. Flex was the primary ActionScript 3 compiler and was actively developed by Adobe before it was donated to Apache Software Foundation in 2011.
Haxe is an open-source programming language and compiler, that is able to generate SWF files from Haxe programs. As of 2012, Haxe can build programs for Flash Player that perform faster than the same application built with the Adobe Flex SDK compiler, due to additional compiler optimizations supported in Haxe.
swfc is an open-source ActionScript 3.0 compiler which generates SWF files from script files, which includes SVG tags. It is currently the most complete alternative for building Flash content in Linux, despite being entirely script-based and not having a GUI.
The Ming library is able to import and export graphics from XML into SWF. Ming has bindings for popular scripting languages such as PHP and Python.
Open Screen Project.
On May 1, 2008, Adobe announced the "Open Screen Project", with the intent of providing a consistent application interface across devices such as personal computers, mobile devices, and consumer electronics. When the project was announced, seven goals were outlined: the abolition of licensing fees for Adobe Flash Player and Adobe Integrated Runtime, the removal of restrictions on the use of the Shockwave Flash (SWF) and Flash Video (FLV) file formats, the publishing of application programming interfaces for porting Flash to new devices, and the publishing of The Flash Cast protocol and Action Message Format (AMF), which let Flash applications receive information from remote databases.
s of February 2009[ [update]], the specifications removing the restrictions on the use of SWF and FLV/F4V specs have been published. The Flash Cast protocol—now known as the Mobile Content Delivery Protocol—and AMF protocols have also been made available, with AMF available as an open source implementation, BlazeDS. Work on the device porting layers is in the early stages. Adobe intends to remove the licensing fees for Flash Player and Adobe Integrated Runtime (AIR) for devices at their release for the Open Screen Project.
The list of mobile device providers who have joined the project includes Palm, Motorola, and Nokia, who, together with Adobe, have announced a $10 million Open Screen Project fund.
s of 2012[ [update]], the Open Screen Project is no longer accepting new applications according to partner BSQuare. However paid licensing is still an option for device makers who want to use Adobe software.
Alternatives.
Flash Editor.
The Flash 4 Linux project was an initiative to develop an open source Linux application as an alternative to Adobe Flash Professional. Development plans included authoring capacity for 2D animation, and tweening, as well as outputing SWF file formats. F4L evolved into an editor that was capable of authoring 2D animation and publishing of SWF files. Flash 4 Linux was renamed UIRA. UIRA intended to combine the resources and knowledge of the F4L project and the Qflash project, both of which were Open Source applications that aimed to provide an alternative to the proprietary Adobe Flash.
Flash Player.
Flash Player cannot ship as part of a pure open source, or completely free operating system, as its distribution is bound to the and subject to proposition first from Adobe. There is no complete free and open source software replacement which offers all the functionality of the latest version of Adobe Flash Player, and although commercial alternatives such as Scaleform GFx do exist, they cannot work within web browsers.
HTML5.
HTML5 is often cited as an alternative to Adobe Flash technology usage on web pages. Adobe released a tool that converts Flash to HTML5, and in June 2011, Google released an experimental tool that does the same. As of January 2015, YouTube will default to HTML5 players to better support more devices.
Criticisms.
Vendor dependence.
The reliance on Adobe for decoding Flash makes its use on the World Wide Web a concern— the completeness of its public specifications are debated, and no complete implementation of Flash is publicly available in source code form with a license that permits reuse. Generally, public specifications are what makes a format re-implementable (see future proofing data storage), and reusable codebases can be ported to new platforms without the endorsement of the format creator.
Adobe's restrictions on the use of the SWF/FLV specifications were lifted in February 2009 (see Adobe's Open Screen Project). However, despite efforts of projects like Gnash, Swfdec and Lightspark, a complete free Flash player is yet to be seen, as of September 2011. For example, Gnash cannot use SWF v10 yet. Notably, Gnash has been a long-standing high priority project of the Free Software Foundation since at least 2007, and it was ranked number one in September 2011.
Notable advocates of free software, open standards, and the World Wide Web have warned against the use of Flash:
Founder of Mozilla Europe, Tristan Nitot stated in 2008:
Companies building websites should beware of proprietary rich-media technologies like Adobe's Flash and Microsoft's Silverlight. (...) You're producing content for your users and there's someone in the middle deciding whether users should see your content.
Representing open standards, inventor of CSS and co-author of HTML5, Håkon Wium Lie explained in a Google tech talk of 2007, entitled "the <video> element", the proposal of Theora as the format for HTML5 video:
I believe very strongly, that we need to agree on some kind of baseline video format if [the video element] is going to succeed. Flash is today the baseline format on the web. The problem with Flash is that it's not an open standard.
Representing the free software movement, Richard Stallman stated in a speech in 2004 that: "The use of Flash in websites is a major problem for our community."
Flash websites on mobile devices.
Websites built with Adobe Flash will not function on most modern mobile devices running Google Android or iOS (iPhone, iPad). The only alternative is using HTML5 to build websites that support both desktop and mobile devices.
However, Flash is still actively used to build mobile games using Adobe AIR. Such games will not work in mobile web browsers, but must be installed via the appropriate app store.
Accessibility.
Using Flash tends to break conventions associated with normal HTML pages. Selecting text, scrolling, form control and right-clicking act differently from with a regular HTML webpage. Many such interface unexpectancies are fixable by the designer. Usability expert Jakob Nielsen published an Alertbox in 2000 entitled, "Flash: 99% Bad", which listed issues like these. Some problems have been at least partially fixed since Nielsen's complaints:
Performance.
Flash Player supports two distinct modes of video playback, and video decoding may not be used for older video content. Such content causes excessive CPU usage compared to comparable content played with other players.
In tests done by Ars Technica in 2008 and 2009, Adobe Flash Player performed better on Windows than Mac OS X and Linux with the same hardware.
Performance has later improved for the latter two, on Mac OS X with Flash Player 10.1, and on Linux with Flash Player 11.
Flash blocking in web browsers.
Flash content is usually embedded using the codice_1 or codice_2 HTML element. A web browser that does not fully implement one of these elements displays the replacement text, if supplied by the web page. Often, a plugin is required for the browser to fully implement these elements, though some users cannot or will not install it.
Since Flash can be used to produce content (such as advertisements) that some users find obnoxious or take a large amount of bandwidth to download, some web browsers default to not play Flash content before the user clicks on it, e.g. Konqueror, K-Meleon.
Most current browsers have a feature to block plugins, playing one only when the user clicks it. Opera versions since 10.5 feature native Flash blocking. Opera Turbo requires the user to click to play Flash content, and the browser also allows the user to enable this option permanently. Both Chrome and Firefox have an option to enable "click to play plugins". Equivalent "Flash blocker" extensions are also available for many popular browsers: Firefox has Flashblock and NoScript, Internet Explorer has Foxie, which contains a number of features, one of them named Flashblock. WebKit-based browsers under Mac OS X, such as Apple's Safari, have ClickToFlash.
Security.
Adobe Flash Player 10.3 introduced a Local Settings Manager that can be accessed from the Microsoft Windows Control Panel or the OS X System Preferences panel. This panel superseded the previous Global Online Settings Manager. The Privacy Settings panel allows users to specify whether websites must ask their permission before using the web camera or microphone. This was apparently part of a fix for vulnerabilities that enabled the use of Flash for spying via web camera.
Intego's Year In Mac Security report states that in 2011, the Flashback trojan surfaced targeting Mac OS X users, which first masqueraded as a Flash Player installer. Intego later recommended that Adobe users get trusted updates "only directly from the vendor that publishes them."
Implementational vulnerabilities.
"Implementational vulnerabilities are flaws in the specific player software, rather than inherent to the Flash format or its usage. In particular, this section's listing of flaws in Adobe's Flash player can not be expected to apply to other players, and vice versa."
Adobe Flash Player's security record has caused several security experts to recommend against installing the player, or to block Flash content: the US-CERT recommends to block Flash using NoScript, and Charlie Miller recommended "not to install Flash" at the computer security conference CanSecWest. As of February 12, 2015, Adobe Flash Player has over 400 CVE entries, of which over 300 lead to arbitrary code execution. Security vulnerabilities in Adobe Flash Player account for a third of all vulnerabilities reported in Adobe products.
Security experts have predicted that with the rise of HTML5, the Flash plugin may become obsolete. The Sophos Security Threat Report 2013 states that "fortunately, the need for browser plugins such as Flash is diminishing". McAfee's report on 2013 Threats Predictions concurs and predicts that threats will shift towards browsers.
Flash cookies.
Like the HTTP cookie, a flash cookie (also known as a “Local Shared Object”) can be used to save application data. Flash cookies are not shared across domains. An August 2009 study by the Ashkan Soltani and a team of researchers at UC Berkeley found that 50% of websites using Flash were also employing flash cookies, yet privacy policies rarely disclosed them, and user controls for privacy preferences were lacking. Most browsers' cache and history suppress or delete functions did not affect Flash Player's writing Local Shared Objects to its own cache in version 10.2 and earlier, at which point the user community was much less aware of the existence and function of Flash cookies than HTTP cookies. Thus, users with those versions, having deleted HTTP cookies and purged browser history files and caches, may believe that they have purged all tracking data from their computers when in fact Flash browsing history remains. Adobe's own Flash , a submenu of Adobe's Flash , and other editors and toolkits can manage settings for and delete Flash Local Shared Objects.
On Windows systems, LSOs are stored in the directory: "%appdata%\Macromedia\Flash Player" Deleting the contents of this directory should remove the LSOs (flash cookies) for the current user.
Linux support.
In February 2012, Adobe announced it would discontinue development of Flash Player on Linux for all browsers except Google Chrome. s of 2015[ [update]] version 18 is the Adobe Labs preview release.
PowerPC Mac devices.
As of May 2011, users of computers with the PowerPC processor are not able to view Flash content from some sites (e.g. Facebook) that requires the latest upgrade of Adobe Flash player, which is not compatible with this processor architecture.

</doc>
<doc id="20948" url="http://en.wikipedia.org/wiki?curid=20948" title="Mind control">
Mind control

Mind control (also known as brainwashing, reeducation, coercive persuasion, thought control, or thought reform) is a theoretical indoctrination process which results in "an impairment of autonomy, an inability to think independently, and a disruption of beliefs and affiliations. In this context, brainwashing refers to the involuntary reeducation of basic beliefs and values".
Theories of brainwashing and of mind control were originally developed to explain how totalitarian regimes appeared to systematically indoctrinate prisoners of war through propaganda and torture techniques. These theories were later expanded and modified by psychologists including Margaret Singer and Philip Zimbardo to explain a wider range of phenomena, especially conversions to new religious movements (NRMs). The suggestion that NRMs use mind control techniques has resulted in scientific and legal debate; with Eileen Barker, James Richardson, and other scholars, as well as legal experts, rejecting at least the popular understanding of the concept.
Newer theories have been proposed by scholars including: Robert Cialdini, Robert Jay Lifton, Daniel Romanovsky, Kathleen Taylor, and Benjamin Zablocki. The concept of mind control is sometimes involved in legal cases, especially regarding child custody; and is also a major theme in both science fiction and in criticism of modern corporate culture.
The Korean War and brainwashing.
Origin of the concept.
The "Oxford English Dictionary" records the earliest known English-language usage of "brainwashing" in an article by newspaperman Edward Hunter, in "Miami News", published on 7 October 1950. Hunter, an outspoken anticommunist and said to be a CIA agent working undercover as a journalist, wrote a series of books and articles on the theme of Chinese brainwashing, and the word brainwashing quickly became a stock phrase in Cold War headlines.
The Chinese term 洗腦 ("xǐ năo", literally "wash brain") was originally used to describe methodologies of coercive persuasion used under the Maoist government in China, which aimed to transform individuals with a reactionary imperialist mindset into "right-thinking" members of the new Chinese social system. The term punned on the Taoist custom of "cleansing/washing the heart/mind" (洗心, "xǐ xīn") before conducting certain ceremonies or entering certain holy places.
Hunter and those who picked up the Chinese term used it to explain why, during the Korean War (1950-1953), some American prisoners of war cooperated with their Chinese captors, even in a few cases defecting to the enemy side. British radio operator Robert W. Ford and British army Colonel James Carne also claimed that the Chinese subjected them to brainwashing techniques during their war-era imprisonment.
The U.S. military and government laid charges of "brainwashing" in an effort to undermine detailed confessions made by military personnel to war crimes, including biological warfare. After Chinese radio broadcasts claimed to quote Frank Schwable, Chief of Staff of the First Marine Air Wing admitting to participating in germ warfare, United Nations commander Gen. Mark W. Clark asserted: "Whether these statements ever passed the lips of these unfortunate men is doubtful. If they did, however, too familiar are the mind-annihilating methods of these Communists in extorting whatever words they want ... The men themselves are not to blame, and they have my deepest sympathy for having been used in this abominable way."
In the 1950s many American movies were filmed that featured brainwashing of POWs, including "The Rack", "The Bamboo Prison", "Toward the Unknown", and "The Fearmakers". Fraser A. Sherman comments: "The possibility that advanced psychological techniques could reprogram people's minds became a permanent part of pop culture." "Forbidden Area" told the story of Soviet secret agents who had been brainwashed (through classical conditioning) by their own government so they wouldn't reveal their true identities. In 1962 "The Manchurian Candidate" "put brainwashing front and center" and featured a plot by the Soviet government to take over the United States by use of a brainwashed presidential candidate.
The concept of brainwashing became associated with the research of Russian psychologist Ivan Pavlov; which mostly involved dogs, not humans, as subjects. In "The Manchurian Candidate" the head brainwasher is Dr. Yen Lo, of the Pavlov Institute.
Korean War Brainwashing Debunked.
In 1956, after reexamining the concept of brainwashing following the Korean War, the U.S. Army published a report entitled "Communist Interrogation, Indoctrination, and Exploitation of Prisoners of War" which called brainwashing a "popular misconception." The report states "exhaustive research of several government agencies failed to reveal even one conclusively documented case of 'brainwashing' of an American prisoner of war in Korea."
US POW's captured by North Korea were brutalized with starvation, beatings, forced death marches, exposure to extremes of temperature, binding in stress positions, and withholding of medical care, but the abuse had no relation to indoctrination "in which [North Korea was] not particularly interested." In contrast American POW's in the custody of North Korea's Chinese Communist allies did face a concerted interrogation and indoctrination program. However, "systematic, physical torture was not employed in connection with interrogation or indoctrination," the report states.
The "most insidious" and effective Chinese technique according to the US Army Report was a convivial display of false friendship, which persuaded some GI's to make anti-American statements, and in a few isolated cases, refuse repatriation and remain in China:
"[w]hen an American soldier was captured by the Chinese, he was given a vigorous handshake and a pat on the back. The enemy 'introduced' himself as a friend of the 'workers' of America . . . in many instances the Chinese did not search the American captives, but frequently offered them American cigarettes. This display of friendship caught most Americans totally off-guard and they never recovered from the initial impression made by the Chinese. . . . [A]fter the initial contact with the enemy, some Americans seemed to believe that the enemy was sincere and harmless. They relaxed and permitted themselves to be lulled into a well-disguised trap [of cooperating with] the cunning enemy." 
Two academic studies of the repatriation of American prisoners of war by Robert Jay Lifton and by Edgar Schein concluded that brainwashing (called "thought reform" by Lifton and "coercive persuasion" by Schein), if it occurred, had at best a transient effect. In 1961, they both published books expanding on these findings. Schein published "Coercive Persuasion" and Lifton published "Thought Reform and the Psychology of Totalism".
CIA mind control program.
In 1999, forensic psychologist Dick Anthony concluded that the CIA had invented the concept of "brainwashing" as a propaganda strategy to undercut communist claims that American POWs in Korean communist camps had voluntarily expressed sympathy for communism. He argued that the books of Edward Hunter (whom he identified as a secret CIA "psychological warfare specialist" passing as a journalist) pushed the CIA brainwashing theory onto the general public. Succumbing to their own propaganda, for twenty years starting in the early 1950s, the CIA and the Defense Department conducted secret research (notably including Project MKULTRA) in an attempt to develop practical brainwashing techniques; the results are unknown. (See also Sidney Gottlieb.)
New religious movements.
In the 1970s, the anti-cult movement applied mind control theories to explain seemingly sudden and dramatic religious conversions to various new religious movements (NRM's). The media was quick to follow suit, and social scientists sympathetic to the anti-cult movement, who were usually psychologists, developed more sophisticated models of brainwashing. While some psychologists were receptive to these theories, sociologists were for the most part skeptical of their ability to explain conversion to NRMs.
Theories of mind control and religious conversion.
Over the years various theories of conversion and member retention have been proposed that link mind control to some new religious movements (NRMs), particularly those religious movements referred to as "cults" by their critics. Philip Zimbardo discusses mind control as "the process by which individual or collective freedom of choice and action is compromised by agents or agencies that modify or distort perception, motivation, affect, cognition and/or behavioral outcomes", and he suggests that any human being is susceptible to such manipulation.
Margaret Singer and the APA.
Margaret Singer, who also spent time studying the political brainwashing of Korean prisoners of war, in her book "Cults in Our Midst", describes six conditions which would create an atmosphere in which thought reform is possible.
In 1983, the American Psychological Association (APA) asked Singer to chair a taskforce called the APA Task Force on Deceptive and Indirect Techniques of Persuasion and Control (DIMPAC) to investigate whether brainwashing or "coercive persuasion" did indeed play a role in recruitment by such movements. Before the taskforce had submitted its final report, the APA submitted on 10 February 1987 an "amicus curiæ" brief in an ongoing court case related to brainwashing. Although the amicus curiæ brief written by the APA denies the credibility of the brainwashing theory, the APA submitted the brief under "intense pressure by a consortium of pro-religion scholars (a.k.a. NRM scholars)". The brief repudiated Singer's theories on "coercive persuasion" and suggested that brainwashing theories were without empirical proof. Afterward the APA filed a motion to withdraw its signature from the brief, since Singer's final report had not been completed.
On 11 May 1987, the APA's Board of Social and Ethical Responsibility for Psychology (BSERP) rejected the DIMPAC report because the report "lacks the scientific rigor and evenhanded critical approach necessary for APA imprimatur", and concluded that "after much consideration, BSERP does not believe that we have sufficient information available to guide us in taking a position on this issue." Benjamin Zablocki and Alberto Amitrani interpreted the APA's response as meaning that there was no unanimous decision on the issue either way, suggesting also that Singer retained the respect of the psychological community after the incident.
Two critical letters from external reviewers Benjamin Beit-Hallahmi and Jeffery D. Fisher accompanied the rejection memo. The letters criticized "brainwashing" as an unrecognized theoretical concept and Singer's reasoning as so flawed that it was "almost ridiculous." After her findings were rejected, Singer sued the APA in 1992 for "defamation, frauds, aiding and abetting and conspiracy" and lost. After that time U.S. courts consistently rejected testimonies about mind control and manipulation, stating that such theories were not part of accepted mainline science according to the Frye Standard of 1923.
Debate over mind control theories as applied to NRMs.
James Richardson observes that if the new religious movements (NRMs) had access to powerful brainwashing techniques, one would expect that NRMs would have high growth rates, yet in fact most have not had notable success in recruitment. Most adherents participate for only a short time, and the success in retaining members is limited. For this and other reasons, sociologists of religion including David Bromley and Anson Shupe consider the idea that "cults" are brainwashing American youth to be "implausible." In addition, Thomas Robbins, Massimo Introvigne, Lorne Dawson, Gordon Melton, Marc Galanter, and Saul Levine, amongst other scholars researching NRMs, have argued and established to the satisfaction of courts, relevant professional associations and scientific communities that there exists no generally accepted scientific theory, based upon methodologically sound research, that supports the brainwashing theories as advanced by the anti-cult movement.
Benjamin Zablocki responds that it's obvious that brainwashing occurs, at least to any objective observer; but that it isn't "a process that is directly observable." The "real sociological issue", he states, is whether "brainwashing occurs frequently enough to be considered an important social problem". Zablocki disagrees with scholars like Richardson, stating that Richardson's observation is flawed. According to Zablocki, Richardson misunderstands brainwashing, conceiving of it as a recruiting process, instead of a retaining process. Zablocki adds that the sheer number of former cult leaders and members who attest to brainwashing in interviews (performed in accordance with guidelines of the National Institute of Mental Health and National Science Foundation) is too large to be a result of anything other than a genuine phenomenon.
Zablocki also points out that in the two most prestigious journals dedicated to the sociology of religion, the number of articles "supporting the brainwashing perspective" have been zero, while over one hundred such articles have been published in other journals "marginal to the field". From this fact, Zablocki concludes that the concept brainwashing has been blacklisted unfairly from the field of sociology of religion.
Eileen Barker criticizes mind control theories because they function to justify costly interventions such as deprogramming or exit counseling. She has also criticized some mental health professionals, including Singer, for accepting expert witness jobs in court cases involving NRMs. Her 1984 book, "" describes the religious conversion process to the Unification Church (whose members are sometimes informally referred to as "Moonies") which had been one of the best known groups said to practice brainwashing. Barker spent close to seven years studying Unification Church members. She interviewed in depth and/or gave probing questionnaires to church members, ex-members, "non-joiners," and control groups of uninvolved people from similar backgrounds, as well as parents, spouses, and friends of members. She also attended numerous Unification Church workshops and communal facilities. Barker writes that she rejects the "brainwashing" theory as an explanation for conversion to the Unification Church, because, as she wrote, it explains neither the many people who attended a recruitment meeting and did not become members, nor the voluntary disaffiliation of members.
Other areas and studies.
Joost Meerloo, a Dutch psychiatrist, was an early leading proponent of the concept of brainwashing. His view was influenced by his experiences during the German occupation of his country in the Second World War and his work with the Dutch government and the American military in the interrogation of accused Nazi war criminals. He later emigrated to the United States and taught at Columbia University. His best-selling 1956 book, "The Rape of the Mind", concludes by saying: "The modern techniques of brainwashing and menticide-those perversions of psychology-can bring almost any man into submission and surrender. Many of the victims of thought control, brainwashing, and menticide that we have talked about were strong men whose minds and wills were broken and degraded. But although the totalitarians use their knowledge of the mind for vicious and unscrupulous purposes, our democratic society can and must use its knowledge to help man to grow, to guard his freedom, and to understand himself." ("Menticide" is a neologism coined by Meerloo meaning: "Killing of the mind.")
In Italy there has been controversy over the concept of "plagio", a crime consisting in an absolute psychological—and eventually physical—domination of a person. The effect of such domination is the annihilation of the subject's freedom and self-determination and the consequent negation of his or her personality. The crime of plagio has rarely been prosecuted in Italy, and only one person was ever convicted. In 1981, Italy the Court found the concept to be imprecise, lacking coherence, and liable to arbitrary application.
By the twenty-first century, the concept of brainwashing had spread to other fields and was being applied "with some success" in criminal defense, child custody, and child sexual abuse cases. In some cases "one parent is accused of brainwashing the child to reject the other parent, and in child sex abuse cases where one parent is accused of brainwashing the child to make sex abuse accusations against the other parent" (possibly resulting in or causing parental alienation).
In his 2000 book, "Destroying the World to Save It: Aum Shinrikyo, Apocalyptic Violence, and the New Global Terrorism", Robert Lifton applied his original ideas about thought reform to Aum Shinrikyo and the War on Terrorism, concluding that in this context thought reform was possible without violence or physical coercion. He also pointed out that in their efforts against terrorism Western governments were also using some mind control techniques, including thought-terminating clichés.
In 2003 Dick Anthony asserted in the "Washington Post" that "no reasonable person would question that there are situations where people can be influenced against their best interests, but those arguments are evaluated on the basis of fact, not bogus expert testimony." Dismissing the idea of mind control, he has defended NRMs, and argued that involvement in such movements may often have beneficial, rather than harmful effects: "There's a large research literature published in mainstream journals on the mental health effects of new religions. For the most part the effects seem to be positive in any way that's measurable."
In her 2004 book, "", neuroscientist and physiologist Kathleen Taylor put forth the theory that the neurological basis for reasoning and cognition in the brain and the self itself are changeable. She describes the physiology behind neurological pathways which include webs of neurons containing dendrites, axons, and synapses; and explains that certain brains with more rigid pathways will be less susceptible to new information or creative stimuli. She uses neurological science to demonstrate that brainwashed individuals have more rigid pathways, and that that rigidity can make it unlikely that the individual will rethink situations or be able to later reorganize these pathways. She explains that repetition is an integral part of brainwashing techniques because connections between neurons become stronger when exposed to incoming signals of frequency and intensity. She argues that people in their teenage years and early twenties are more susceptible to persuasion.Taylor explains that brain activity in the temporal lobe, the region responsible for artistic creativity, also causes spiritual experiences in a process known as lability.
In his 2007 book, "Influence: The Psychology of Persuasion", social psychologist Robert Cialdini argues that mind control is possible through the covert exploitation of the unconscious rules that underlie and facilitate healthy human social interactions. He states that common social rules can be used to prey upon the unwary. Using categories, he offers specific examples of both mild and extreme mind control—both one on one and in groups—notes the conditions under which each social rule is most easily exploited for false ends, and offers suggestions on how to resist such methods.
In 2009 historian Daniel Romanovsky wrote about what he called "Nazi brainwashing" of the people of Belarus by the occupying Germans during the Second World War, which took place through both mass propaganda and intense re-education, especially in schools. He notes that very soon most people had adopted the Nazi view of the Jews, that they were an inferior race and were closely tied to the Soviet government, views that had not been at all common before the occupation.
Mind control has often been an important theme in science fiction and fantasy stories. Terry O'Brien comments: "Mind control is such a powerful image that if hypnotism did not exist, then something similar would have to have been invented: the plot device is too useful for any writer to ignore. The fear of mind control is equally as powerful an image." A subgenre is "corporate mind control", in which a future society is run by one or more business corporations which dominate society using advertising and mass media to control the population's thoughts and feelings.
Modern corporations are said to practice mind control to create a work force which shares the same common values and culture. Critics have linked "corporate brainwashing" with globalization, saying that corporations are attempting to create a world-wide monocultural network of producers, consumers, and managers. In his 1992 book, "Democracy in an Age of Corporate Colonization", Stanley A. Deetz says that modern "self awareness" and "self improvement" programs provide corporations with even more effective tools to control the minds of employees than traditional brainwashing. Modern educational systems have also been criticized, by both the left and the right, for contributing to corporate brainwashing.

</doc>
<doc id="20950" url="http://en.wikipedia.org/wiki?curid=20950" title="Molotov–Ribbentrop Pact">
Molotov–Ribbentrop Pact

The Molotov–Ribbentrop Pact, named after the former Soviet foreign minister Vyacheslav Molotov and the German foreign minister Joachim von Ribbentrop, officially the Treaty of Non-aggression between Germany and the Union of Soviet Socialist Republics, and also known as the Ribbentrop–Molotov Pact or Nazi–Soviet Pact, was a non-aggression pact signed between Nazi Germany and Soviet Union in Moscow in the late hours of 23 August 1939.
The pact's publicly stated intentions were a guarantee of non-belligerence by each party towards the other and a commitment that neither party would ally itself to or aid an enemy of the other party. In addition to stipulations of non-aggression, the treaty included a secret protocol that divided territories of Romania, Poland, Lithuania, Latvia, Estonia, and Finland into German and Soviet "spheres of influence", anticipating potential "territorial and political rearrangements" of these countries. Thereafter, Germany invaded Poland on 1 September 1939. After the Soviet–Japanese ceasefire agreement took effect on 16 September, Stalin ordered his own invasion of Poland on 17 September. Part of southeastern (Karelia) and Salla region in Finland were annexed by the Soviet Union after the Winter War. This was followed by Soviet annexations of Estonia, Latvia, Lithuania, and parts of Romania (Bessarabia, Northern Bukovina, and the Hertza region). It was only in 1989 that the Soviet authorities admitted the existence of the secret protocol of the Nazi–Soviet Pact. A concern about ethnic Ukrainians and Belarusians had been proffered as the reason for the Soviet invasion of Poland, rather than Soviet expansionism.
The pact remained in force until the German government broke it by invading the Soviet Union on 22 June 1941.
Of the territories of Poland annexed by the Soviet Union between 1939 and 1940, the region around Białystok and a minor part of Galicia east of the San river around Przemyśl were the only ones returned to the Polish state at the end of World War II. Of all other territories annexed by the USSR in 1939–40, the ones detached from Finland (Karelia, Petsamo), Estonia (Ingrian area and Petseri County) and Latvia (Abrene) remained part of the Russian Federation, the successor state of the Soviet Union, after 1991. Northern Bukovina, Southern Bessarabia and Hertza remain part of Ukraine.
Recent Russian historiography – perhaps taking its lead from the creation of a presidential commission to counter what it called falsifications of history to the detriment of Russian interests – has been inclined to defences of the pact. This includes books by Alexander Dyukov, and one edited by N.A. Narochnitskaya that carries an approving foreword by Russian foreign Minister Sergei Lavrov. Vladimir Putin has defended the pact with the Nazi regime.
Background.
The outcome of the First World War was disastrous for both the German Reich and the Russian Soviet Federative Socialist Republic. During the war, the Bolsheviks struggled for survival, and Vladimir Lenin recognised the independence of Finland, Estonia, Latvia, Lithuania and Poland. Moreover, facing a German military advance, Lenin and Trotsky were forced to enter into the Treaty of Brest-Litovsk, which ceded massive western Russian territories to the German Empire. After Germany's collapse, a multinational Allied-led army intervened in the Russian Civil War (1917–22).
On 16 April 1922, Germany and the Soviet Union entered the Treaty of Rapallo, pursuant to which they renounced territorial and financial claims against each other. The parties further pledged neutrality in the event of an attack against one another with the 1926 Treaty of Berlin. While trade between the two countries fell sharply after World War I, trade agreements signed in the mid-1920s helped to increase trade to 433 million Reichsmarks per year by 1927.
At the beginning of the 1930s, the Nazi Party's rise to power increased tensions between Germany and the Soviet Union along with other countries with ethnic Slavs, who were considered "Untermenschen" (inferior) according to Nazi racial ideology. Moreover, the anti-Semitic Nazis associated ethnic Jews with both communism and financial capitalism, both of which they opposed. Consequently, Nazi theory held that Slavs in the Soviet Union were being ruled by "Jewish Bolshevik" masters. In 1934, Hitler himself had spoken of an inescapable battle against both Pan-Slavism and Neo-Slavism, the victory in which would lead to "permanent mastery of the world", though he stated that they would "walk part of the road with the Russians, if that will help us." The resulting manifestation of German anti-Bolshevism and an increase in Soviet foreign debts caused German–Soviet trade to dramatically decline. Imports of Soviet goods to Germany fell to 223 million Reichsmarks in 1934 as the more isolationist Stalinist regime asserted power and the abandonment of post–World War I Treaty of Versailles military controls decreased Germany's reliance on Soviet imports.
In 1936, Germany and Fascist Italy supported Spanish Nationalists in the Spanish Civil War, while the Soviets supported the partially socialist-led Second Spanish Republic under the leadership of president Manuel Azaña. Thus, in a sense, the Spanish Civil War became also the scene of a proxy war between Germany and the USSR. In 1936, Germany and Japan entered the Anti-Comintern Pact, and were joined a year later by Italy.
Hitler's fierce anti-Soviet rhetoric was one of the reasons why the UK and France decided that Soviet participation in the 1938 Munich Conference regarding Czechoslovakia would be both dangerous and useless. The Munich Agreement that followed marked a partial German annexation of Czechoslovakia in late 1938 followed by its complete dissolution in March 1939, which as part of the appeasement of Germany conducted by Chamberlain's and Daladier's cabinets. This policy immediately raised the question of whether the Soviet Union could avoid being next on Hitler's list. The Soviet leadership believed that the West wanted to encourage German aggression in the East and that France and Britain might stay neutral in a war initiated by Germany, hoping that the warring states would wear each other out and put an end to both the Soviet Union and Nazi Germany.
For Germany, because an autarkic economic approach or an alliance with Britain were impossible, closer relations with the Soviet Union to obtain raw materials became necessary, if not just for economic reasons alone. Moreover, an expected British blockade in the event of war would create massive shortages for Germany in a number of key raw materials. After the Munich agreement, the resulting increase in German military supply needs and Soviet demands for military machinery, talks between the two countries occurred from late 1938 to March 1939. The third Soviet Five Year Plan required new infusions of technology and industrial equipment. German war planners had estimated serious shortfalls of raw materials if Germany entered a war without Soviet supply.
On 31 March 1939, in response to Nazi Germany's defiance of the Munich Agreement and occupation of Czechoslovakia, the United Kingdom pledged the support of itself and France to guarantee the independence of Poland, Belgium, Romania, Greece, and Turkey. On 6 April Poland and the UK agreed to formalize the guarantee as a military alliance, pending negotiations. On 28 April, Hitler denounced the 1934 German–Polish Non-Aggression Pact and the 1935 Anglo-German Naval Agreement.
Starting in mid-March 1939, in attempts to contain Hitler's expansionism, the Soviet Union, Britain and France traded a flurry of suggestions and counterplans regarding a potential political and military agreement. Although informal consultations commenced in April, the main negotiations began only in May. At the same time, throughout early 1939, Germany had secretly hinted to Soviet diplomats that it could offer better terms for a political agreement than Britain and France.
The Soviet Union feared Western powers and the possibility of "capitalist encirclements", had little faith either that war could be avoided, or faith in the Polish army, and wanted nothing less than an ironclad military alliance with France and Britain that would provide a guaranteed support for a two-pronged attack on Germany; thus, Stalin's adherence to the collective security line was purely conditional. Britain and France believed that war could still be avoided, and that the Soviet Union, weakened by the Great Purge, could not be a main military participant, a point that many military sources were at variance with, especially after the sound thrashing administered to the Japanese Kwantung army on the Manchurian frontier. France was more anxious to find an agreement with the USSR than was Britain; as a continental power, it was more willing to make concessions, more fearful of the dangers of an agreement between the USSR and Germany. These contrasting attitudes partly explain why the USSR has often been charged with playing a double game in 1939: carrying on open negotiations for an alliance with Britain and France while secretly considering propositions from Germany.
By the end of May, drafts were formally presented. In mid-June, the main Tripartite negotiations started. The discussion was focused on potential guarantees to central and east European countries should a German aggression arise. The USSR proposed to consider that a political turn towards Germany by the Baltic states would constitute an "indirect aggression" towards the Soviet Union. Britain opposed such proposals, because they feared the Soviets' proposed language could justify a Soviet intervention in Finland and the Baltic states, or push those countries to seek closer relations with Germany. The discussion about a definition of "indirect aggression" became one of the sticking points between the parties, and by mid-July, the tripartite political negotiations effectively stalled, while the parties agreed to start negotiations on a military agreement, which the Soviets insisted must be entered into simultaneously with any political agreement.
Negotiations.
Beginning of Soviet–German secret talks.
From April–July, Soviet and German officials made statements regarding the potential for the beginning of political negotiations, while no actual negotiations took place during that time period. The ensuing discussion of a potential political deal between Germany and the Soviet Union had to be channeled into the framework of economic negotiations between the two countries, because close military and diplomatic connections, as was the case before the mid-1930s, had afterward been largely severed. In May, Stalin replaced his Foreign Minister Maxim Litvinov, who was regarded as pro-western and who was also Jewish, with Vyacheslav Molotov, allowing the Soviet Union more latitude in discussions with more parties, not only with Britain and France.
In late July and early August 1939, Soviet and German officials agreed on most of the details for a planned economic agreement, and specifically addressed a potential political agreement, which the Soviets stated could only come after an economic agreement.
August negotiations.
In early August, Germany and the Soviet Union worked out the last details of their economic deal, and started to discuss a political alliance. They explained to each other the reasons for their foreign policy hostility in the 1930s, finding common ground in the anti-capitalism of both countries.
At the same time, British, French, and Soviet negotiators scheduled three-party talks on military matters to occur in Moscow in August 1939, aiming to define what the agreement would specify should be the reaction of the three powers to a German attack. The tripartite military talks, started in mid-August, hit a sticking point regarding the passage of Soviet troops through Poland if Germans attacked, and the parties waited as British and French officials overseas pressured Polish officials to agree to such terms. Polish officials refused to allow Soviet troops into Polish territory if Germany attacked; as Polish foreign minister Józef Beck pointed out, they feared that once the Red Army entered their territories, it might never leave.
On August 19, the 1939 German–Soviet Commercial Agreement was finally signed. On 21 August, the Soviets suspended Tripartite military talks, citing other reasons. That same day, Stalin received assurance that Germany would approve secret protocols to the proposed non-aggression pact that would place half of Poland (border along the Vistula river), Latvia, Estonia, Finland, and Bessarabia in the Soviets' sphere of influence. That night, Stalin replied that the Soviets were willing to sign the pact and that he would receive Ribbentrop on 23 August.
The secret protocol.
'Following completion of the Soviet–German trade and credit agreement, there has arisen the question of improving political links between Germany and the USSR.
On 22 August, one day after the talks broke down with France and Britain, Moscow revealed that Ribbentrop would visit Stalin the next day. This happened while the Soviets were still negotiating with the British and French missions in Moscow. With the Western nations unwilling to accede to Soviet demands, Stalin instead entered a secret Nazi–Soviet pact. On 24 August a 10-year non-aggression pact was signed with provisions that included: consultation, arbitration if either party disagreed, neutrality if either went to war against a third power, no membership of a group "which is directly or indirectly aimed at the other".
Most notably, there was also a secret protocol to the pact, revealed only after Germany's defeat in 1945, although hints about its provisions were leaked much earlier, e.g., to influence Lithuania. According to it Romania, Poland, Lithuania, Latvia, Estonia and Finland were divided into German and Soviet "spheres of influence". In the north, Finland, Estonia and Latvia were assigned to the Soviet sphere. Poland was to be partitioned in the event of its "political rearrangement"—the areas east of the Pisa, Narev, Vistula and San rivers going to the Soviet Union while Germany would occupy the west. Lithuania, adjacent to East Prussia, would be in the German sphere of influence, although a second secret protocol agreed to in September 1939 reassigned the majority of Lithuania to the USSR. According to the secret protocol, Lithuania would be granted the city of Vilnius – its historical capital, which was under Polish control during the inter-war period. Another clause of the treaty was that Germany would not interfere with the Soviet Union's actions towards Bessarabia, then part of Romania; as the result, Bessarabia was joined to the Moldovan ASSR, and become the Moldovan SSR under control of Moscow.
At the signing, Ribbentrop and Stalin enjoyed warm conversations, exchanged toasts and further addressed the prior hostilities between the countries in the 1930s. They characterized Britain as always attempting to disrupt Soviet–German relations, stated that the Anti-Comintern pact was not aimed at the Soviet Union, but actually aimed at Western democracies and "frightened principally the City of London [i.e., the British financiers] and the English shopkeepers".
On 24 August, "Pravda" and "Izvestia" carried news of the non-secret portions of the Pact, complete with the now infamous front-page picture of Molotov signing the treaty, with a smiling Stalin looking on (at the top of this article). The news was met with utter shock and surprise by government leaders and media worldwide, most of whom were aware only of the British–French–Soviet negotiations that had taken place for months. The Molotov–Ribbentrop Pact was received with shock by Nazi Germany's allies, notably Japan, by the Comintern and foreign communist parties, and by Jewish communities all around the world. So, that day, German diplomat Hans von Herwarth, whose grandmother was Jewish, informed Guido Relli, an Italian diplomat, and American chargé d'affaires Charles Bohlen on the secret protocol regarding vital interests in the countries' allotted "spheres of influence", without revealing the annexation rights for "territorial and political rearrangement".
"Time Magazine" repeatedly referred to the Pact as the "Communazi Pact" and its participants as "communazis" until April 1941.
Soviet propaganda and representatives went to great lengths to minimize the importance of the fact that they had opposed and fought against the Nazis in various ways for a decade prior to signing the Pact. Upon signing the pact, Molotov tried to reassure the Germans of his good intentions by commenting to journalists that "fascism is a matter of taste". For its part, Nazi Germany also did a public volte-face regarding its virulent opposition to the Soviet Union, though Hitler still viewed an attack on the Soviet Union as "inevitable".
Concerns over the possible existence of a secret protocol were first expressed by the intelligence organizations of the Baltic states scant days after the pact was signed. Speculation grew stronger when Soviet negotiators referred to its content during negotiations for military bases in those countries (see occupation of the Baltic States).
The day after the Pact was signed, the French and British military negotiation delegation urgently requested a meeting with Soviet military negotiator Kliment Voroshilov. On August 25, Voroshilov told them "[i]n view of the changed political situation, no useful purpose can be served in continuing the conversation." That day, Hitler told the British ambassador to Berlin that the pact with the Soviets prevented Germany from facing a two front war, changing the strategic situation from that in World War I, and that Britain should accept his demands regarding Poland.
On 25 August, surprising Hitler, Britain entered into a defense pact with Poland. Consequently, Hitler postponed his planned 26 August invasion of Poland to 1 September. Britain and France responded by guaranteeing the sovereignty of Poland, so they declared war on Germany on 3 September.
Consequences in Finland, Poland, the Baltic States and Bessarabia.
Poland never will rise again in the form of the Versailles treaty. That is guaranteed not only by Germany, but also ... Russia.
Initial invasions.
On 1 September, Germany invaded Poland from the west. Within the first few days of the invasion, Germany began conducting massacres of Polish and Jewish civilians and POWs. These executions took place in over 30 towns and villages in the first month of German occupation. The "Luftwaffe" also took part by strafing fleeing civilian refugees on roads and carrying out a bombing campaign. The Soviet Union assisted German air forces by allowing them to use signals broadcast by the Soviet radio station at Minsk allegedly "for urgent aeronautical experiments".
Stalin did not instantly interpret the protocol as permitting the Soviet Union to grab territory. Stalin was waiting to see whether the Germans would halt within the agreed area, and also the Soviet Union needed to secure the frontier in the Far East. On 17 September the Red Army invaded Poland, violating the 1932 Soviet–Polish Non-Aggression Pact, and occupied the Polish territory assigned to it by the Molotov–Ribbentrop Pact. This was followed by co-ordination with German forces in Poland.
Polish troops already fighting much stronger German forces on its western side desperately tried to delay the capture of Warsaw. Consequently, Polish forces were not able to mount significant resistance against the Soviets. The Soviet Union marshaled 466,516 soldiers, 3,739 tanks, 380 armored cars, and approximately 1,200 fighters, 600 bombers, and 200 other aircraft against Poland. The Polish armed forces in the East consisted mostly of lightly armed border guard units of the Border Protection Corps (Korpus Ochrony Pogranicza, KOP). In the Northeast of Poland, only a few cities were defended and after a heavy but short struggle Polish forces withdrew to Lithuania where they were interned. Some of the Polish forces which were fighting the Soviets in the far South of the nation withdrew to Romania.
On 21 September, the Soviets and Germans signed a formal agreement coordinating military movements in Poland, including the "purging" of saboteurs. A joint German–Soviet parade was held in Lvov and Brest-Litovsk, while the countries commanders met in the latter location. Stalin had decided in August that he was going to liquidate the Polish state, and a German–Soviet meeting in September addressed the future structure of the "Polish region". Soviet authorities immediately started a campaign of Sovietization of the newly acquired areas. The Soviets organized staged elections, the result of which was to become a legitimization of Soviet annexation of eastern Poland. Soviet authorities attempted to erase Polish history and culture, withdrew the Polish currency without exchanging roubles, collectivized agriculture, and nationalized and redistributed private and state-owned Polish property. Soviet authorities regarded service for the pre-war Polish state as a "crime against revolution" and "counter-revolutionary activity", and subsequently arrested large numbers of Polish citizens.
Modifying the secret protocols.
Eleven days after the Soviet invasion of the Polish Kresy, the secret protocol of the Molotov–Ribbentrop Pact was modified by the German–Soviet Treaty of Friendship, Cooperation and Demarcation,) allotting Germany a larger part of Poland and transferring Lithuania's territory (with the exception of left bank of river Scheschupe, the "Lithuanian Strip") from the envisioned German sphere to the Soviets. On 28 September 1939, the Soviet Union and German Reich issued a joint declaration in which they declared:
"After the Government of the German Reich and the Government of the USSR have, by means of the treaty signed today, definitively settled the problems arising from the collapse of the Polish state and have thereby created a sure foundation for a lasting peace in the region, they mutually express their conviction that it would serve the true interest of all peoples to put an end to the state of war existing at present between Germany on the one side and England and France on the other. Both Governments will therefore direct their common efforts, jointly with other friendly powers if occasion arises, toward attaining this goal as soon as possible.
"Should, however, the efforts of the two Governments remain fruitless, this would demonstrate the fact that England and France are responsible for the continuation of the war, whereupon, in case of the continuation of the war, the Governments of Germany and of the USSR shall engage in mutual consultations with regard to necessary measures."
On 3 October, Friedrich Werner von der Schulenburg, German ambassador in Moscow, informed Joachim Ribbentrop that the Soviet government was willing to cede the city of Vilnius and its environs. On 8 October 1939, a new Nazi–Soviet agreement was reached by an exchange of letters between Vyacheslav Molotov and the German Ambassador.
The Baltic States of Estonia, Latvia, and Lithuania were given no choice but to sign a so-called "Pact of defence and mutual assistance" which permitted the Soviet Union to station troops in them.
The Soviet war with Finland and Katyn Massacre.
After the Baltic states were forced to accept treaties, Stalin turned his sights on Finland, confident that Finnish capitulation could be attained without great effort. The Soviets demanded territories on the Karelian Isthmus, the islands of the Gulf of Finland and a military base near the Finnish capital Helsinki, which Finland rejected. The Soviets staged the shelling of Mainila and used it as a pretext to withdraw from the non-aggression pact. The Red Army attacked in November 1939. Simultaneously, Stalin set up a puppet government in the Finnish Democratic Republic. The leader of the Leningrad Military District Andrei Zhdanov commissioned a celebratory piece from Dmitri Shostakovich, entitled "Suite on Finnish Themes" to be performed as the marching bands of the Red Army would be parading through Helsinki. After Finnish defenses surprisingly held out for over three months while inflicting stiff losses on Soviet forces, the Soviets settled for an interim peace. Finland ceded southeastern areas of Karelia (10% of Finnish territory), which resulted in approximately 422,000 Karelians (12% of Finland's population) losing their homes. Soviet official casualty counts in the war exceeded 200,000, although Soviet Premier Nikita Khrushchev later claimed the casualties may have been one million.
At around this time, after several Gestapo–NKVD Conferences, Soviet NKVD officers also conducted lengthy interrogations of 300,000 Polish POWs in camps that were, in effect, a selection process to determine who would be killed. On March 5, 1940, in what would later be known as the Katyn massacre, orders were signed to execute 25,700 Polish POWs, labeled "nationalists and counterrevolutionaries", kept at camps and prisons in occupied western Ukraine and Belarus.
The Soviet Union occupies the Baltic Republics and part of Romania.
In mid-June 1940, when international attention was focused on the German invasion of France, Soviet NKVD troops raided border posts in Lithuania, Estonia and Latvia. State administrations were liquidated and replaced by Soviet cadres, in which 34,250 Latvians, 75,000 Lithuanians and almost 60,000 Estonians were deported or killed. Elections were held with single pro-Soviet candidates listed for many positions, with resulting peoples assemblies immediately requesting admission into the USSR, which was granted by the Soviet Union. The USSR annexed the whole of Lithuania, including the Scheschupe area, which was to be given to Germany.
Finally, on 26 June, four days after France sued for an armistice with the Third Reich, the Soviet Union issued an ultimatum demanding Bessarabia and, unexpectedly, Northern Bukovina from Romania. Two days later, the Romanians caved to the Soviet demands and the Soviets occupied the territory. The Hertza region was initially not requested by the USSR but was later occupied by force after the Romanians agreed to the initial Soviet demands. The subsequent waves of deportations began in Bessarabia and Northern Bukovina.
Holocaust beginnings, Operation Tannenberg and other Nazi atrocities.
At the end of October 1939, Germany enacted the death penalty for disobedience to the German occupation. Germany began a campaign of "Germanization", which meant to assimilate the occupied territories politically, culturally, socially, and economically into the German Reich. 50,000–200,000 Polish children were kidnapped to be Germanized.
Elimination of Polish elites and intelligentia was part of Generalplan Ost. The Intelligenzaktion, a plan to eliminate the Polish intelligentsia, Poland's 'leadership class', took place soon after the German invasion of Poland, lasting from fall of 1939 till spring of 1940. As the result of this operation in 10 regional actions about 60,000 Polish nobles, teachers, social workers, priests, judges and political activists were killed. It was continued in May 1940 when Germany launched AB-Aktion, More than 16,000 members of the intelligentsia were murdered in Operation Tannenberg alone.
Germany also planned to incorporate all land into the Third Reich. This effort resulted in the forced resettlement of 2 million Poles. Families were forced to travel in the severe winter of 1939–40, leaving behind almost all of their possessions without recompense. As part of Operation Tannenberg alone, 750,000 Polish peasants were forced to leave and their property was given to Germans. A further 330,000 were murdered. Germany eventually planned to move ethnic Poles to Siberia.
Although Germany used forced labourers in most occupied countries, Poles and other Slavs were viewed as inferior by Nazi propaganda, thus, better suited for such duties. Between 1 and 2.5 million Polish citizens were transported to the Reich for forced labour, against their will. All Polish males were required to perform forced labour. While ethnic Poles were subject to selective persecution, all ethnic Jews were targeted by the Reich. In the winter of 1939–40, about 100,000 Jews were thus deported to Poland. They were initially gathered into massive urban ghettos, such as 380,000 held in the Warsaw Ghetto, where large numbers died under the harsh conditions therein, including 43,000 in the Warsaw Ghetto alone. Poles and ethnic Jews were imprisoned in nearly every camp of the extensive concentration camp system in German-occupied Poland and the Reich. In Auschwitz, which began operating on 14 June 1940, 1.1 million people died.
Romania and Soviet republics.
In the summer of 1940, fear of the Soviet Union, in conjunction with German support for the territorial demands of Romania's neighbors and the Romanian government's own miscalculations, resulted in more territorial losses for Romania. Between 28 June and 4 July, the Soviet Union occupied and annexed Bessarabia, Northern Bukovina and the Hertza region of Romania.
On 30 August, Ribbentrop and Italian Foreign Minister Galeazzo Ciano issued the Second Vienna Award giving Northern Transylvania to Hungary. On 7 September, Romania ceded Southern Dobruja to Bulgaria (Axis-sponsored Treaty of Craiova). After various events in Romania, over the next few months, it increasingly took on the aspect of a German-occupied country.
The Soviet-occupied territories were converted into republics of the Soviet Union. During the two years following the annexation, the Soviets arrested approximately 100,000 Polish citizens and deported between 350,000 and 1,500,000, of whom between 250,000 and 1,000,000 died, mostly civilians. Forced re-settlements into Gulag labour camps and exile settlements in remote areas of the Soviet Union occurred. According to Norman Davies, almost half of them were dead by July 1940.
Further secret protocol modifications, settling borders and immigration issues.
On 10 January 1941, Germany and the Soviet Union signed an agreement settling several ongoing issues. Secret protocols in the new agreement modified the "Secret Additional Protocols" of the German–Soviet Boundary and Friendship Treaty, ceding the Lithuanian Strip to the Soviet Union in exchange for 7.5 million dollars (31.5 million Reichsmark). The agreement formally set the border between Germany and the Soviet Union between the Igorka river and the Baltic Sea. It also extended trade regulation of the 1940 German–Soviet Commercial Agreement until August 1, 1942, increased deliveries above the levels of year one of that agreement, settled trading rights in the Baltics and Bessarabia, calculated the compensation for German property interests in the Baltic States now occupied by the Soviets and other issues. It also covered the migration to Germany within two and a half months of ethnic Germans and German citizens in Soviet-held Baltic territories, and the migration to the Soviet Union of Baltic and "White Russian" "nationals" in German-held territories.
Soviet–German relations during the Pact's operation.
Early political issues.
Before the pact's announcement, Communists in the West denied that such a treaty would be signed. Future member of the Hollywood Ten Herbert Biberman denounced rumors as "Fascist propaganda". Earl Browder, head of the Communist Party USA, stated that "there is as much chance of agreement as of Earl Browder being elected president of the Chamber of Commerce." Beginning in September 1939, the Soviet Comintern suspended all anti-Nazi and anti-fascist propaganda, explaining that the war in Europe was a matter of capitalist states attacking each other for imperialist purposes. Western Communists acted accordingly; while before they supported protecting collective security, now they denounced Britain and France going to war.
When anti-German demonstrations erupted in Prague, Czechoslovakia, the Comintern ordered the Czech Communist Party to employ all of its strength to paralyze "chauvinist elements." Moscow soon forced the Communist Parties of France and Great Britain to adopt an anti-war position. On 7 September, Stalin called Georgi Dimitrov, and the latter sketched a new Comintern line on the war. The new line—which stated that the war was unjust and imperialist—was approved by the secretariat of the Communist International on 9 September. Thus, the various western Communist parties now had to oppose the war, and to vote against war credits. Although the French Communists had unanimously voted in Parliament for war credits on 2 September and on 19 September declared their "unshakeable will" to defend the country, on 27 September the Comintern formally instructed the party to condemn the war as imperialist. By 1 October the French Communists advocated listening to German peace proposals, and Communist leader Maurice Thorez deserted from the French Army on 4 October and fled to Russia. Other Communists also deserted from the army.
The Communist Party of Germany featured similar attitudes. In "Die Welt", a communist newspaper published in Stockholm the exiled communist leader Walter Ulbricht opposed the allies (Britain representing "the most reactionary force in the world") and argued: "The German government declared itself ready for friendly relations with the Soviet Union, whereas the English–French war bloc desires a war against the socialist Soviet Union. The Soviet people and the working people of Germany have an interest in preventing the English war plan."
Despite a warning by the Comintern, German tensions were raised when the Soviets stated in September that they must enter Poland to "protect" their ethnic Ukrainian and Belorussian brethren therein from Germany; Molotov later admitted to German officials that this excuse was necessary because the Kremlin could find no other pretext for the Soviet invasion.
While active collaboration between Nazi Germany and Soviet Union caused great shock in western Europe and amongst communists opposed to Germany, on 1 October 1939, Winston Churchill declared that the Russian armies acted for the safety of Russia against "the Nazi menace."
When a joint German–Soviet peace initiative was rejected by Britain and France on 28 September 1939, Soviet foreign policy became critical of the Allies and more pro-German in turn. During the fifth session of the Supreme Soviet on 31 October 1939 Molotov analysed the international situation thus giving the direction for Communist propaganda. According to Molotov Germany had a legitimate interest in regaining its position as a great power and the Allies had started an aggressive war in order to maintain the Versailles system.
Molotov declared in his report entitled "On the Foreign Policy of the Soviet Union" (31 October 1939) held on the fifth (extraordinary) session of the Supreme Soviet, that the Western "ruling circles" disguise their intentions with the pretext of defending democracy against Hitlerism, declaring "their aim in war with Germany is nothing more, nothing less than extermination of Hitlerism. [...] There is absolutely no justification for this kind of war. The ideology of Hitlerism, just like any other ideological system, can be accepted or rejected, this is a matter of political views. But everyone grasps, that an ideology can not be exterminated by force, must not be finished off with a war."
Expansion of raw materials and military trading.
Germany and the Soviet Union entered an intricate trade pact on February 11, 1940, that was over four times larger than the one the two countries had signed in August 1939. The trade pact helped Germany to surmount a British blockade of Germany. In the first year, Germany received one million tons of cereals, half a million tons of wheat, 900,000 tons of oil, 100,000 tons of cotton, 500,000 tons of phosphates and considerable amounts of other vital raw materials, along with the transit of one million tons of soybeans from Manchuria. These and other supplies were being transported through Soviet and occupied Polish territories. The Soviets were to receive a naval cruiser, the plans to the battleship "Bismarck", heavy naval guns, other naval gear and thirty of Germany's latest warplanes, including the Me-109 and Me-110 fighters and Ju-88 bomber. The Soviets would also receive oil and electric equipment, locomotives, turbines, generators, diesel engines, ships, machine tools and samples of German artillery, tanks, explosives, chemical-warfare equipment and other items.
The Soviets also helped Germany to avoid British naval blockades by providing a submarine base, Basis Nord, in the northern Soviet Union near Murmansk. This also provided a refueling and maintenance location, and a takeoff point for raids and attacks on shipping. In addition, the Soviets provided Germany with access to the Northern Sea Route for both cargo ships and raiders (though only the commerce raider "Komet" used the route before the German invasion), which forced Britain to protect sea lanes in both the Atlantic and the Pacific.
Summer deterioration of relations.
The Finnish and Baltic invasions began a deterioration of relations between the Soviets and Germany. Stalin's invasions were a severe irritant to Berlin, as the intent to accomplish these was not communicated to the Germans beforehand, and prompted concern that Stalin was seeking to form an anti-German bloc. Molotov's reassurances to the Germans, and the Germans' mistrust, intensified. On June 16, as the Soviets invaded Lithuania, but before they had invaded Latvia and Estonia, Ribbentrop instructed his staff "to submit a report as soon as possible as to whether in the Baltic States a tendency to seek support from the Reich can be observed or whether an attempt was made to form a bloc."
In August 1940, the Soviet Union briefly suspended its deliveries under their commercial agreement after their relations were strained following disagreement over policy in Romania, the Soviet war with Finland, Germany falling behind in its deliveries of goods under the pact and with Stalin worried that Hitler's war with the West might end quickly after France signed an armistice. The suspension created significant resource problems for Germany. By the end of August, relations improved again as the countries had redrawn the Hungarian and Romanian borders, settled some Bulgarian claims and Stalin was again convinced that Germany would face a long war in the west with Britain's improvement in its air battle with Germany and the execution of an agreement between the United States and Britain regarding destroyers and bases. However, in late August, Germany arranged its own occupation of Romania, targeting oil fields. The move raised tensions with the Soviets, who responded that Germany was supposed to have consulted with the Soviet Union under Article III of the Molotov–Ribbentrop Pact.
German–Soviet Axis talks.
After Germany entered a Tripartite Pact with Japan and Italy, Ribbentrop wrote to Stalin, inviting Molotov to Berlin for negotiations aimed to create a 'continental bloc' of Germany, Italy, Japan and the USSR that would oppose Britain and the USA. Stalin sent Molotov to Berlin to negotiate the terms for the Soviet Union to join the Axis and potentially enjoy the spoils of the pact. After negotiations during November 1940 on where to extend the USSR's sphere of influence, Hitler broke off talks and continued planning for the eventual attempts to invade the Soviet Union.
Late relations.
In an effort to demonstrate peaceful intentions toward Germany, on 13 April 1941, the Soviets signed a neutrality pact with Axis power Japan. While Stalin had little faith in Japan's commitment to neutrality, he felt that the pact was important for its political symbolism, to reinforce a public affection for Germany. Stalin felt that there was a growing split in German circles about whether Germany should initiate a war with the Soviet Union. Stalin did not know that Hitler had been secretly discussing an invasion of the Soviet Union since summer 1940, and that Hitler had ordered his military in late 1940 to prepare for war in the east regardless of the parties' talks of a potential Soviet entry as a fourth Axis Power.
Hitler breaks the Pact.
Nazi Germany terminated the Molotov–Ribbentrop Pact with its invasion of the Soviet Union at 03:15 on 22 June 1941. Stalin had ignored several warnings that Germany was likely to attack, and ordered no full-scale mobilization of forces. After the launch of the invasion, the territories gained by the Soviet Union due to the Molotov–Ribbentrop Pact were lost in a matter of weeks. Within six months, the Soviet military had suffered 4.3 million casualties and Germany had captured three million Soviet prisoners. The imports of Soviet raw materials into Germany over the duration of the countries' economic relationship proved vital to Operation Barbarossa. Without Soviet imports, German stocks would have run out in several key products by October 1941, and Germany would have already run through its stocks of rubber and grain before the first day of the invasion.
Aftermath.
Denial of the Secret Protocol's existence by the Soviet Union.
The German original of the secret protocols was presumably destroyed in the bombing of Germany, but in late 1943, Ribbentrop had ordered that the most secret records of the German Foreign Office from 1933 on, amounting to some 9,800 pages, be microfilmed. When the various departments of the Foreign Office in Berlin were evacuated to Thuringia at the end of the war, Karl von Loesch, a civil servant who had worked for the chief interpreter Paul Otto Schmidt, was entrusted with these microfilm copies. He eventually received orders to destroy the secret documents but decided to bury the metal container with the microfilms as a personal insurance for his future well-being. In May 1945, von Loesch approached the British Lt. Col. Robert C. Thomson with the request to transmit a personal letter to Duncan Sandys, Churchill's son-in-law. In the letter, von Loesch revealed that he had knowledge of the documents' whereabouts but expected preferential treatment in return. Colonel Thomson and his American counterpart Ralph Collins agreed to transfer von Loesch to Marburg in the American zone if he would produce the microfilms. The microfilms contained a copy of the Non-Aggression Treaty as well as the Secret Protocol. Both documents were discovered as part of the microfilmed records in August 1945 by the State Department employee Wendell B. Blancke, head of a special unit called "Exploitation German Archives" (EGA).
The treaty was published in the United States for the first time by the "St. Louis Post-Dispatch" on May 22, 1946, in Britain by the "Manchester Guardian". It was also part of an official State Department publication, "Nazi–Soviet Relations 1939–1941", edited by Raymond J. Sontag and James S. Beddie in January 1948. The decision to publish the key documents on German–Soviet relations, including the treaty and protocol, had been taken already in spring 1947. Sontag and Beddie prepared the collection throughout the summer of 1947. In November 1947, President Truman personally approved the publication but it was held back in view of the Foreign Ministers Conference in London scheduled for December. Since negotiations at that conference did not prove constructive from an American point of view, the document edition was sent to press. The documents made headlines worldwide. State Department officials counted it as a success: "The Soviet Government was caught flat-footed in what was the first effective blow from our side in a clear-cut propaganda war."
Despite publication of the recovered copy in western media, for decades, it was the official policy of the Soviet Union to deny the existence of the secret protocol. The secret protocol's existence was officially denied until 1989. Vyacheslav Molotov, one of the signatories, went to his grave categorically rejecting its existence. The French Communist Party did not acknowledge the existence of the secret protocol until 1968, as the party de-Stalinized.
On 23 August 1986, tens of thousands of demonstrators in 21 western cities including New York, London, Stockholm, Toronto, Seattle, and Perth participated in Black Ribbon Day Rallies to draw attention to the secret protocols.
Stalin's "Falsifiers of History" and Axis negotiations.
In response to the publication of the secret protocols and other secret German–Soviet relations documents in the State Department edition "Nazi–Soviet Relations" (1948), Stalin published "Falsifiers of History", which included the claim that, during the Pact's operation, Stalin rejected Hitler's claim to share in a division of the world, without mentioning the Soviet offer to join the Axis. That version persisted, without exception, in historical studies, official accounts, memoirs and textbooks published in the Soviet Union until the Soviet Union's dissolution.
The book also claimed that the Munich agreement was a "secret agreement" between Germany and "the west" and a "highly important phase in their policy aimed at goading the Hitlerite aggressors against the Soviet Union."
Denial of the pact.
For decades, it was the official policy of the Soviet Union to deny the existence of the secret protocol to the Soviet–German Pact. At the behest of Mikhail Gorbachev, Alexander Nikolaevich Yakovlev headed a commission investigating the existence of such a protocol. In December 1989, the commission concluded that the protocol had existed and revealed its findings to the Congress of People's Deputies of the Soviet Union. As a result, the Congress passed the declaration confirming the existence of the secret protocols, condemning and denouncing them. Both successor-states of the pact parties have declared the secret protocols to be invalid from the moment they were signed. The Federal Republic of Germany declared this on September 1, 1989 and the Soviet Union on December 24, 1989, following an examination of the microfilmed copy of the German originals.
The Soviet copy of the original document was declassified in 1992 and published in a scientific journal in early 1993.
In August 2009, in an article written for the Polish newspaper Gazeta Wyborcza, Russian Prime Minister Vladimir Putin condemned the Molotov–Ribbentrop Pact as "immoral." In 2014 however, he defended the whole non-aggression treaty and raised doubts about the secret protocols, saying that "people still argue about the Molotov-Ribbentrop Pact".
In spite of such statements the present Russian government and media have to some extent moved back to the Soviet position, again using the term “falsifiers of history”. They assert that the invasions of Poland were unconnected to the pact, that the Nazi–Soviet pact was concluded only after fruitless negotiations with Britain and France, and that, by the Munich agreement, Britain and France were at least as culpable for the outbreak of war as the USSR.
Post-war commentary regarding the motives of Stalin and Hitler.
Some scholars believe that, from the very beginning of the Tripartite negotiations between the Soviet Union, the United Kingdom and France, it was clear that the Soviet position required the other parties to agree to a Soviet occupation of Estonia, Latvia, and Lithuania, as well as for Finland be included in the Soviet sphere of influence.
Regarding the timing of German rapprochement, many historians agree that the dismissal of Maxim Litvinov, whose Jewish ethnicity was viewed unfavorably by Nazi Germany, removed an obstacle to negotiations with Germany. Stalin immediately directed Molotov to "purge the ministry of Jews." Given Litvinov's prior attempts to create an anti-fascist coalition, association with the doctrine of collective security with France and Britain, and pro-Western orientation by the standards of the Kremlin, his dismissal indicated the existence of a Soviet option of rapprochement with Germany. Likewise, Molotov's appointment served as a signal to Germany that the USSR was open to offers. The dismissal also signaled to France and Britain the existence of a potential negotiation option with Germany. One British official wrote that Litvinov's disappearance also meant the loss of an admirable technician or shock-absorber, while Molotov's "modus operandi" was "more truly Bolshevik than diplomatic or cosmopolitan." Carr argued that the Soviet Union's replacement of Foreign Minister Litvinov with Molotov on May 3, 1939 indicated not an irrevocable shift towards alignment with Germany, but rather was Stalin's way of engaging in hard bargaining with the British and the French by appointing a proverbial hard man, namely Molotov, to the Foreign Commissariat. Historian Albert Resis stated that the Litvinov dismissal gave the Soviets freedom to pursue faster-paced German negotiations, but that they did not abandon British–French talks. Derek Watson argued that Molotov could get the best deal with Britain and France because he was not encumbered with the baggage of collective security and could negotiate with Germany. Geoffrey Roberts argued that Litvinov's dismissal helped the Soviets with British–French talks, because Litvinov doubted or maybe even opposed such discussions.
Edward Hallett Carr, a frequent defender of Soviet policy, stated: "In return for 'non-intervention' Stalin secured a breathing space of immunity from German attack." According to Carr, the "bastion" created by means of the Pact, "was and could only be, a line of defense against potential German attack." According to Carr, an important advantage was that "if Soviet Russia had eventually to fight Hitler, the Western Powers would already be involved." However, during the last decades, this view has been disputed. Historian Werner Maser stated that "the claim that the Soviet Union was at the time threatened by Hitler, as Stalin supposed ... is a legend, to whose creators Stalin himself belonged. In Maser's view, "neither Germany nor Japan were in a situation [of] invading the USSR even with the least perspective ["sic"] of success," and this could not have been unknown to Stalin. Carr further stated that, for a long time, the primary motive of Stalin's sudden change of course was assumed to be the fear of German aggressive intentions.
Some critics of Stalin's policy, such as the popular writer Viktor Suvorov, claim that Stalin's primary motive for signing the Soviet–German non-aggression treaty was his calculation that such a pact could result in a conflict between the capitalist countries of Western Europe. This idea is supported by Albert L. Weeks. Claims by Suvorov that Stalin planned to invade Germany in 1941 are debated by historians with, for example, David Glantz opposing such claims, while Mikhail Meltyukhov supports them. The authors of "The Black Book of Communism" consider the pact a crime against peace and a "conspiracy to conduct war of aggression."
Soviet sources have claimed that soon after the pact was signed, both the UK and US showed understanding that the buffer zone was necessary to keep Hitler from advancing for some time, accepting the ostensible strategic reasoning; however, soon after World War II ended, those countries changed their view. Many Polish newspapers published numerous articles claiming that Russia must apologize to Poland for the Molotov–Ribbentrop Pact.
Two weeks after Soviet armies had entered the Baltic states, Berlin requested Finland to permit the transit of German troops, followed five weeks thereafter by Hitler's issuance of a secret directive "to take up the Russian problem, to think about war preparations," a war whose objective would include establishment of a Baltic confederation.
Remembrance.
The European Parliament has proclaimed 23 August 2009, the anniversary of the Molotov–Ribbentrop Pact, as a European Day of Remembrance for Victims of Stalinism and Nazism, to be commemorated with dignity and impartiality.
In connection with the Molotov–Ribbentrop Pact, an Organization for Security and Co-operation in Europe parliamentary resolution condemned both communism and fascism for starting World War II and called for a day of remembrance for victims of both Stalinism and Nazism on 23 August. In response to the resolution, the Russian lawmakers threatened the OSCE with "harsh consequences".
During the re-ignition of Cold War tensions in 1982, the U.S. Congress during the Reagan Administration established the Baltic Freedom Day to be remembered every June 14 in the United States.
Bibliography.
</dl>

</doc>
<doc id="20952" url="http://en.wikipedia.org/wiki?curid=20952" title="Mobile, Alabama">
Mobile, Alabama

Mobile ( ; ]) is the county seat of Mobile County, Alabama. The population within the city limits was 195,111 as of the 2010 United States Census, making it the third most populous city in the State of Alabama, the most populous in Mobile County, and the largest municipality on the Gulf Coast between New Orleans, Louisiana, and St. Petersburg, Florida.
Alabama's only saltwater port, Mobile is located at the head of the Mobile Bay and the north-central Gulf Coast. The Port of Mobile has always played a key role in the economic health of the city beginning with the city as a key trading center between the French and Native Americans down to its current role as the 12th-largest port in the United States. Mobile is the principal municipality of the Mobile Metropolitan Statistical Area. This region of 412,992 residents is composed solely of Mobile County; it is the third-largest metropolitan statistical area in the state. Mobile is the largest city in the Mobile-Daphne−Fairhope CSA, with a total population of 604,726, the second largest in the state. As of 2011, the population within a 60 mi radius of Mobile is 1,262,907.
Mobile began as the first capital of colonial French Louisiana in 1702. During its first 100 years, Mobile was a colony of France, then Britain, and lastly Spain. Mobile first became a part of the United States of America in 1813, with the annexation of West Florida under President James Madison. In 1861 Alabama joined the Confederate States of America, which surrendered in 1865.
As one of the Gulf Coast's cultural centers, Mobile has several art museums, a symphony orchestra, a professional opera, a professional ballet company, and a large concentration of historic architecture. Mobile is known for having the oldest organized Carnival celebrations in the United States. The festival began to be celebrated in the first decade of the 18th century by its first French Catholic colonial settlers. Mobile was host to the first formally organized Carnival mystic society, known elsewhere as a krewe, to celebrate with a parade in the United States, beginning in 1830. In 2005 the first integrated mystic society had a parade for Mardi Gras.
Etymology.
The city gained its name from the Mobile tribe that the French colonists encountered living in the area of Mobile Bay. Although debated by Alabama historians, they may have been descendants of the Native American tribe whose small fortress town, Mabila, was used to conceal several thousand native warriors before an attack in 1540 on the expedition of Spanish explorer Hernando de Soto. The Mobile tribe, along with the Tohomé, obtained permission from the colonists, about seven years after the founding of the Mobile settlement, to settle near the fort.
History.
Colonial.
The European settlement of Mobile, then known as "Fort Louis de la Louisiane", started in 1702, at Twenty-seven Mile Bluff on the Mobile River, as the first capital of the French colony of Louisiana. It was founded by French Canadian brothers Pierre Le Moyne d'Iberville and Jean-Baptiste Le Moyne, Sieur de Bienville, to establish control over France's Louisiana claims. Bienville was made governor of French Louisiana in 1701. Mobile's Roman Catholic parish was established on July 20, 1703, by Jean-Baptiste de la Croix de Chevrières de Saint-Vallier, Bishop of Quebec. The parish was the first established on the Gulf Coast of the United States. In 1704 the ship "Pélican" delivered 23 French women to the colony; passengers had contracted yellow fever at a stop in Havana. Though most of the ""Pélican" girls" recovered, numerous colonists and neighboring Native Americans died from the illness. This early period was also the occasion of the arrival of the first African slaves, transported aboard a French supply ship from Saint-Domingue in the Caribbean. The population of the colony fluctuated over the next few years, growing to 279 persons by 1708, yet descending to 178 persons two years later due to disease.
These additional outbreaks of disease and a series of floods caused Bienville to order the town relocated several miles downriver to its present location at the confluence of the Mobile River and Mobile Bay in 1711. A new earth and palisade Fort Louis was constructed at the new site during this time. By 1712, when Antoine Crozat took over administration of the colony by royal appointment, its population reached 400 persons. The capital of La Louisiane was moved to Biloxi in 1720, leaving Mobile in the role of military and trading center. In 1723 the construction of a new brick fort with a stone foundation began and it was renamed Fort Condé in honor of Louis Henri, Duc de Bourbon and prince of Condé.
In 1763, the Treaty of Paris was signed, ending the Seven Years' War, which Britain won, defeating France. By this treaty, France ceded its territories east of the Mississippi River to Britain. This area was made a part of the expanded British West Florida colony. The British changed the name of Fort Condé to Fort Charlotte, after Charlotte of Mecklenburg-Strelitz, King George III's queen.
The British were eager not to lose any useful inhabitants and promised religious tolerance to the French colonists; ultimately 112 French Mobilians remained in the colony. The first permanent Jewish presence in Mobile began in 1763 as a result of the new religious tolerance. Jews had not been allowed to officially reside in colonial French Louisiana due to the Code Noir, a decree passed by France's King Louis XIV in 1685 that forbade the exercise of any religion other than Roman Catholicism, and ordered all Jews out of France's colonies. Most of these colonial-era Jews in Mobile were merchants and traders from Sephardic Jewish communities in Savannah and Charleston; and they added to the commercial development of Mobile. In 1766 the population was estimated to be 860, though the town's borders were smaller than they had been during the French colonial efforts. During the American Revolutionary War, West Florida and Mobile became a refuge for loyalists fleeing the other colonies.
While the British were dealing with their rebellious colonists along the Atlantic coast, the Spanish entered the war as an ally of France in 1779. They took the opportunity to order Bernardo de Galvez, Governor of Louisiana, on an expedition east to retake Florida. He captured Mobile during the Battle of Fort Charlotte in 1780, as part of this campaign. The Spanish wished to eliminate any British threat to their Louisiana colony, which they had received from France in the 1763 Treaty of Paris. Their actions were condoned by the revolting American colonies, partially evidenced by the presence of Oliver Pollack, representative of the American Continental Congress. Due strong trade ties, many residents of Mobile and West Florida remained loyal to the British Crown. The fort was renamed Fortaleza Carlota, with the Spanish holding Mobile as a part of Spanish West Florida until 1813, when it was seized by United States General James Wilkinson during the War of 1812.
19th century.
By the time Mobile was included in the Mississippi Territory in 1813, the population had dwindled to roughly 300 people. The city was included in the Alabama Territory in 1817, after Mississippi gained statehood. Alabama was granted statehood in 1819; Mobile's population had increased to 809 by that time.
As the river frontage areas of Alabama and Mississippi were settled by planters who developed the cotton plantation economy with the use of slave labor, Mobile's population exploded. It came to be settled by attorneys, cotton factors, doctors, merchants and other professionals seeking to capitalize on trade with the upriver areas. Mobile was well situated for trade, as its location tied it to a river system that served as the principal navigational access for most of Alabama and a large part of Mississippi. By 1822 the city's population was 2800.
From the 1830s onward, Mobile expanded into a city of commerce with a primary focus on the cotton and slave trades. Many slaves were transported by ship in the coastwise slave trade from the Upper South. There were many businesses in the city related to the slave trade - people to make clothes, food, and supplies for the slave traders and their wards. The city's booming businesses attracted merchants from the North; by 1850 10% of its population was from New York City, which was deeply involved in the cotton industry. Mobile was the slave-trading center of the state until the 1850s, when it was surpassed by Montgomery.
The prosperity stimulated a building boom was underway by the mid-1830s, with the building of some of the most elaborate structures the city had seen up to that point. This was cut short in part by the Panic of 1837 and yellow fever epidemics. The waterfront was developed with wharves, terminal facilities, and fireproof brick warehouses. The exports of cotton grew in proportion to the amounts being produced in the Black Belt; by 1840 Mobile was second only to New Orleans in cotton exports in the nation.
With the economy so focused on one crop, Mobile's fortunes were always tied to those of cotton, and the city weathered many financial crises. Mobile slaveholders owned relatively few slaves compared to planters in the upland plantation areas, but many households had domestic slaves, and many other slaves worked on the waterfront and on riverboats. The last slaves to enter the United States from the African trade were brought to Mobile on the slave ship "Clotilde". Among them was Cudjoe Lewis, who in the 1920s was the last survivor of the slave trade.
By 1853, fifty Jewish families lived in Mobile, including Philip Phillips, an attorney from Charleston, South Carolina, who was elected to the Alabama State Legislature and then to the United States Congress. Many early Jewish families were descendants of Sephardic Jews who had been among the earliest colonial settlers in Charleston and Savannah.
By 1860 Mobile's population within the city limits had reached 29,258 people; it was the 27th-largest city in the United States and 4th-largest in what would soon be the Confederate States of America. The free population in the whole of Mobile County, including the city, consisted of 29,754 citizens, of which 1195 were free people of color. Additionally, 1785 slave owners in the county held 11,376 people in bondage, about one-quarter of the total county population of 41,130 people.
During the American Civil War, Mobile was a Confederate city. The "H. L. Hunley", the first submarine to sink an enemy ship, was built in Mobile. One of the most famous naval engagements of the war was the Battle of Mobile Bay, resulting in the Union taking control of Mobile Bay on August 5, 1864. On April 12, 1865, three days after Robert E. Lee's surrender at Appomattox Courthouse, the city surrendered to the Union army to avoid destruction after Union victories at nearby Spanish Fort and Fort Blakely.
On May 25, 1865, the city suffered great loss when some three hundred people died as a result of an explosion at a federal ammunition depot on Beauregard Street. The explosion left a 30 ft deep hole at the depot's location, and sank ships docked on the Mobile River; the resulting fires destroyed the northern portion of the city.
Federal Reconstruction in Mobile began after the Civil War and effectively ended in 1874 when the local Democrats gained control of the city government. The last quarter of the 19th century was a time of economic depression and municipal insolvency for Mobile. One example can be provided by the value of Mobile's exports during this period of depression. The value of exports leaving the city fell from $9 million in 1878 to $3 million in 1882.
20th century.
The turn of the 20th century brought the Progressive Era to Mobile and saw Mobile's economic structure evolve, along with a significant increase in population. The population increased from around 40,000 in 1900 to 60,000 by 1920. During this time the city received $3 million in federal grants for harbor improvements to deepen the shipping channels in the harbor. During and after World War I, manufacturing became increasingly vital to Mobile's economic health, with shipbuilding and steel production being two of the most important.
During this time, social justice and race relations in Mobile worsened, however. The state passed a new constitution in 1901 that disenfranchised most blacks and many poor whites; and the white-dominated legislature passed other discriminatory legislation. In 1902 the city government passed Mobile's first segregation ordinance, one that segregated the city streetcars. It legislated what had been informal practice, enforced by convention. Mobile's African-American population responded to this with a two-month boycott, but the law was not repealed. After this, Mobile's "de facto" segregation was increasingly replaced with legislated segregation as whites imposed Jim Crow laws to maintain dominance.
In 1911 the city adopted a commission form of government, which had three members elected by at-large voting. This resulted in keeping power in the hands of the white majority and its elite, due to the previous disenfranchisement of poor whites and blacks. Mobile was one of the last cities to retain this form of government, although Alabama's white yeomanry had historically favored single-member districts to elect candidates of their choice."
The red imported fire ant was first introduced into the United States via the Port of Mobile. Sometime in the late 1930s they came ashore off cargo ships coming from South America. They were carried in the soil used as ballast on those ships. They have spread throughout the South and Southwest.
During World War II, the defense buildup in Mobile shipyards resulted in a considerable increase in the city's white middle-class and working-class population, largely due to the massive influx of workers coming to work in the shipyards and at the Brookley Army Air Field. Between 1940 and 1943, more than 89,000 people moved into Mobile to work for war effort industries. Mobile was one of eighteen United States cities producing Liberty ships. Its Alabama Drydock and Shipbuilding Company (ADDSCO) supported the war effort by producing ships faster than the Axis powers could sink them. ADDSCO also churned out a copious number of T2 tankers for the War Department. Gulf Shipbuilding Corporation, a subsidiary of Waterman Steamship Corporation, focused on building freighters, Fletcher class destroyers, and minesweepers.
The years after World War II brought about changes in Mobile's social structure and economy. Replacing shipbuilding as a primary economic force, the paper and chemical industries began to expand. No longer needed for defense, most of the old military bases were converted to civilian uses. Following the war, in which many African Americans had served, they stepped up their activism to gain equal rights and social justice, especially in the Jim Crow South. The city of Mobile police force and Spring Hill College were integrated during the 1950s. Unlike in the rest of the state, the city buses and lunch counters voluntarily desegregated by the early 1960s.
The Alabama legislature passed the Cater Act in 1949 allowing cities and counties to set up industrial development boards (IDB) to issue municipal bonds as incentives to attract new industry into their local areas. The city of Mobile did not establish a Cater Act board until 1962. George E. McNally, Mobile's first Republican mayor since Reconstruction, was the driving force behind its founding. The Mobile Area Chamber of Commerce, believing its members were better qualified to attract new businesses and industry to the area, considered the new IDB as a serious rival. After several years of political squabbling, the Chamber of Commerce emerged victorious. While McNally's IDB prompted the Chamber of Commerce to become more proactive in attracting new industry, the chamber effectively shut Mobile city government out of economic development decisions.
In 1963 three African-American students brought a case against the Mobile County School Board for being denied admission to Murphy High School. This was nearly a decade after the United States Supreme Court had ruled in "Brown v. Board of Education" (1954) that segregation of public schools was unconstitutional. The federal district court ordered that the three students be admitted to Murphy for the 1964 school year, leading to the desegregation of Mobile County's school system.
The Civil Rights Movement gained congressional passage of the Civil Rights Act of 1964 and Voting Rights Act of 1965, eventually ending legal segregation and regaining effective suffrage for African Americans. But whites in the state had more than one way to reduce their voting power. Maintaining the city commission form of government with at-large voting resulted in all positions would be elected by the white majority.
Mobile's economy was dealt a severe blow in 1969 with the closing of Brookley Air Force Base. The closing left 10% of the city's workforce unemployed. This and other factors ushered in a period of economic depression that lasted through the 1970s. The loss of jobs created numerous problems and resulted in loss of population as residents moved away for work.
Mobile's city commission form of government was challenged and finally overturned in 1982 in "City of Mobile v. Bolden," which was remanded by the United States Supreme Court to the district court. Finding that the city had adopted a commission form of government in 1911 with discriminatory intent, the court proposed that the three members of the city commission should be elected from single-member districts, likely ending their division of executive functions among them. Mobile's state legislative delegation in 1985 finally enacted a mayor-council form of government, with seven members elected from single-member districts. This was approved by voters. As white conservatives increasingly entered the Republican Party in the late 20th century, African-American residents of the city have elected members of the Democratic Party as their candidates of choice. The change to single-member districts has also resulted in the election of more women to the council.
Beginning in the late 1980s, newly elected mayor Mike Dow and the city council began an effort termed the "String of Pearls Initiative" to make Mobile into a competitive city. The city initiated construction of numerous new facilities and projects, and the restoration of hundreds of historic downtown buildings and homes. City and county leaders also made efforts to attract new business ventures to the area.
Geography and climate.
Geography.
Mobile is located at 30°40'46" North, 88°6'12" West (30.679523, −88.103280), in the southwestern corner of the U.S. state of Alabama. According to the United States Census Bureau, the city has a total area of 159.4 sqmi, with 117.9 sqmi of it being land, and 41.5 sqmi, or 26.1% of the total, being covered by water. The elevation in Mobile ranges from 10 ft on Water Street in downtown to 211 ft at the Mobile Regional Airport.
Neighborhoods.
Mobile has a number of notable historic neighborhoods. These include Ashland Place, Campground, Church Street East, De Tonti Square, Leinkauf, Lower Dauphin Street, Midtown, Oakleigh Garden, Old Dauphin Way, Spring Hill, and Toulminville.
Climate.
Mobile's geographical location on the Gulf of Mexico provides a mild subtropical climate (Köppen "Cfa"), with hot, humid summers and mild, rainy winters. The record low temperature was −1 °F (−18 °C), set on February 13, 1899, and the record high was 105 °F (41 °C), set on August 29, 2000.
A 2007 study by WeatherBill, Inc. determined that Mobile is the wettest city in the contiguous 48 states, with 66.3 in of average annual rainfall over a 30-year period. Mobile averages 120 days per year with at least 0.01 in of rain. Snow is rare in Mobile, with its last snowfall on January 27, 2014.
Mobile is occasionally affected by major tropical storms and hurricanes. The city suffered a major natural disaster on the night of September 12, 1979 when category-3 Hurricane Frederic passed over the heart of the city. The storm caused tremendous damage to Mobile and the surrounding area. Mobile had moderate damage from Hurricane Opal on October 4, 1995 and Hurricane Ivan on September 16, 2004. Mobile also suffered millions of dollars in damage from Hurricane Katrina on August 29, 2005. A storm surge of 11.45 ft, topped by higher waves, damaged eastern sections of the city with extensive flooding in downtown, the Battleship Parkway, and the elevated Jubilee Parkway.
Christmas Day tornado.
On December 25, 2012, at 4:54 pm, a large wedge tornado touched down in the city. The tornado rapidly intensified as it moved north-northeast at speeds of up to 50 mph. The path took the tornado into Midtown, causing damage or destruction to at least 100 structures. The heaviest damage to houses was along Carlen Street, Rickarby Place, Dauphin Street, Old Shell Road, Margaret Street, Silverwood Street, and Springhill Avenue. In addition to residential structures, the tornado caused significant damage to the Carmelite Monastery, Little Flower Catholic Church, commercial real estate along Airport Boulevard and Government Street in the Midtown at the Loop neighborhood, Murphy High School, Trinity Episcopal Church, Springhill Avenue Temple, and Mobile Infirmary Hospital before moving into the neighboring city of Prichard. The tornado was classified as an EF2 tornado by the National Weather Service on December 26. The path taken through the city was just a short distance east of the path taken just days earlier, on December 20, by an EF1 tornado which had touched down near Davidson High School and followed a path that ended in Prichard. Initial damage estimates for insured and uninsured ranged from $140 to $150 million.
Culture.
Mobile is home to an array of cultural influences with its mixed French, Spanish, Creole and Catholic heritage, in addition to British and African, distinguishing it from all other cities in the state of Alabama. The annual Carnival celebration is perhaps the best illustration of this. Mobile is the birthplace of Mardi Gras in the United States and has the oldest celebration, dating to the early 18th century during the French colonial period. Carnival in Mobile evolved over the course of 300 years from a beginning as a sedate French Catholic tradition into the mainstream multi-week celebration that today bridges a spectrum of cultures. Mobile's official cultural ambassadors are the Azalea Trail Maids, meant to embody the ideals of Southern hospitality.
Carnival and Mardi Gras.
The Carnival season has expanded throughout the late fall and winter: balls in the city may be scheduled as early as November, with the parades beginning after January 5 and the Twelfth Day of Christmas or Epiphany on January 6. Carnival celebrations end at midnight on Mardi Gras, a moveable feast related to the timing of Lent and Easter. The next day is Ash Wednesday and the beginning of Lent, the 40-day penitential season before Easter.
In Mobile, locals often use the term Mardi Gras as a shorthand to refer to the entire Carnival season. During the Carnival season; the mystic societies build colorful floats and parade throughout downtown. Masked society members toss small gifts, known as throws, to parade spectators. The mystic societies, which in essence are exclusive private clubs, also give formal masquerade balls, usually by invitation only, and oriented to adults.
Carnival was first celebrated in Mobile in 1703 when colonial French Catholic settlers carried out their traditional celebration at the Old Mobile Site site, prior to the 1711 relocation of the city to the current site. Mobile's first Carnival society was established in 1711 with the "Boeuf Gras Society" (Fatted Ox Society). Celebrations were relatively small and consisted of local, private parties until the early 19th century.
In 1830 Mobile's Cowbellion de Rakin Society was the first formally organized and masked mystic society in the United States to celebrate with a parade. The Cowbellions got their start when Michael Krafft, a cotton factor from Pennsylvania, began a parade with rakes, hoes, and cowbells. The "Cowbellians" introduced horse-drawn floats to the parades in 1840 with a parade entitled, "Heathen Gods and Goddesses". The Striker's Independent Society was formed in 1843 and is the oldest surviving mystic society in the United States.
Carnival celebrations in Mobile were canceled during the American Civil War. In 1866 Joe Cain revived the Mardi Gras parades when he paraded through the city streets on Fat Tuesday while costumed as a fictional Chickasaw chief named "Slacabamorinico". He celebrated the day in front of the occupying Union Army troops. In 2002, Mobile's Tricentennial celebrated with parades that represented all of the city's mystic societies.
Founded in 2004, the next year in 2005 the Conde Explorers became the first integrated Mardi Gras society to parade in downtown Mobile. The society has about a hundred members and welcomes men and women of all races. In addition to the parade and ball, The Conde Explorers hold several parties throughout the year and its members perform volunteer work. The Conde Explorers were featured in the award-winning documentary by Margaret Brown about Mobile’s Mardi Gras, "The Order of Myths" (2008).
Archives and libraries.
The National African American Archives and Museum features the history of African-American participation in Mardi Gras, authentic artifacts from the era of slavery, and portraits and biographies of famous African-Americans. The University of South Alabama Archives houses primary source material relating to the history of Mobile and southern Alabama, as well as the university's history. The archives are located on the ground floor of the USA Spring Hill Campus and are open to the general public. The Mobile Municipal Archives contains the extant records of the City of Mobile, dating from the city's creation as a municipality by the Mississippi Territory in 1814. The majority of the original records of Mobile's colonial history, spanning the years 1702 through 1813, are housed in Paris, London, Seville, and Madrid. The Mobile Genealogical Society Library and Media Center is located at the Holy Family Catholic Church and School complex. It features handwritten manuscripts and published materials for use in genealogical research. The Mobile Public Library system serves Mobile and consists of eight branches across Mobile County, featuring its own large local history and genealogy division housed in a facility next to the newly restored and enlarged Ben May Main Library on Government Street. The Saint Ignatius Archives, Museum and Theological Research Library contains primary sources, artifacts, documents, photographs and publications that pertain to the history of Saint Ignatius Church and School, the Catholic history of the city, and the history of the Roman Catholic Church.
Arts and entertainment.
The Mobile Museum of Art features permanent exhibits that span several centuries of art and culture. The museum was expanded in 2002 to approximately 95000 sqft. The permanent exhibits include the African and Asian Collection Gallery, Altmayer Gallery (American art), Katharine C. Cochrane Gallery of American Fine Art, Maisel European Gallery, Riddick Glass Gallery, Smith Crafts Gallery, and the Ann B. Hearin Gallery (contemporary works).
The Centre for the Living Arts is an organization that operates the historic Saenger Theatre and Space 301, a contemporary art gallery. The Saenger Theatre opened in 1927 as a movie palace. Today it is a performing arts center and serves as a small concert venue for the city. It is home to the Mobile Symphony Orchestra, conducted by Maestro Scott Speck. Space 301 Gallery and Studio was initially housed adjacent to the Saenger, but moved to its own space in 2008. The 93000 sqft building, donated to the Centre by the "Press-Register" after its relocation to a new modern facility, underwent a $5.2 million renovation and redesign prior to opening.
The Mobile Civic Center contains three facilities under one roof. The 400000 sqft building has an arena, a theater and an exposition hall. It is the primary concert venue for the city and hosts a wide variety of events. It is home to the Mobile Opera and the Mobile Ballet. The 60-year old Mobile Opera averages about 1,200 attendees per performance. A wide variety of events are held at Mobile's Arthur C. Outlaw Convention Center. It contains a 100000 sqft exhibit hall, a 15000 sqft grand ballroom, and sixteen meeting rooms.
The city hosts BayFest, an annual three-day music festival with more than 125 live musical acts on multiple stages spread throughout downtown. The event was attended by more than 200,000 people and generated in excess of $38 million for the city's economy during its 2011 season.
The Mobile Theatre Guild is a nonprofit community theatre that has served the city since 1947. It is a member of the Mobile Arts Council, the Alabama Conference of Theatre and Speech, the Southeastern Theatre Conference, and the American Association of Community Theatres. Mobile is also host to the Joe Jefferson Players, Alabama's oldest continually running community theatre. The group was named in honor of the famous comedic actor Joe Jefferson, who spend part of his teenage years in Mobile. The Players debuted their first production on December 17, 1947. Drama Camp Productions and Sunny Side Theater is Mobile's home for children's theater and fun. The group began doing summer camps in 2002, expanded to a year-round facility in 2008 and recently moved into the Azalea City Center for the Arts, a community of drama, music, art, photography, and dance teachers. The group has produced Broadway shows including "Miracle on 34th Street," "Honk," "Fame," and "Hairspray."
The Mobile Arts Council is an umbrella organization for the arts in Mobile. It was founded in 1955 as a project of the Junior League of Mobile with the mission to increase cooperation among artistic and cultural organizations in the area and to provide a forum for problems in art, music, theater, and literature.
Tourism.
Museums.
Mobile is home to a variety of museums. Battleship Memorial Park is a military park on the shore of Mobile Bay and features the World War II era battleship USS "Alabama", the World War II era submarine USS "Drum", Korean War and Vietnam War Memorials, and a variety of historical military equipment. The History Museum of Mobile showcases 300 plus years of Mobile history and prehistory. It is housed in the historic Old City Hall (1857), a National Historic Landmark. The Oakleigh Historic Complex features three house museums that attempt to interpret the lives of people from three strata of 19th century society in Mobile, that of the enslaved, the working class, and the upper class. The Mobile Carnival Museum, housing the city's Mardi Gras history and memorabilia, documents the variety of floats, costumes, and displays seen during the history of the festival season. The Bragg-Mitchell Mansion (1855), Richards DAR House (1860), and the Condé-Charlotte House (1822) are historic, furnished antebellum house museums. Fort Morgan (1819), Fort Gaines (1821), and Historic Blakeley State Park all figure predominantly in local American Civil War history.
The Mobile Medical Museum is housed in the historic French colonial-style Vincent-Doan House (1827). It features artifacts and resources that chronicle the long history of medicine in Mobile. The Phoenix Fire Museum is located in the restored Phoenix Volunteer Fire Company Number 6 building and features the history of fire companies in Mobile from their organization in 1838. The Mobile Police Department Museum features exhibits that chronicle the history of law enforcement in Mobile. The Gulf Coast Exploreum Science Center is a non-profit science center located in downtown. It features permanent and traveling exhibits, an IMAX dome theater, a digital 3D virtual theater, and a hands-on chemistry laboratory. The Dauphin Island Sea Lab is located south of the city, on Dauphin Island near the mouth of Mobile Bay. It houses the Estuarium, an aquarium which illustrates the four habitats of the Mobile Bay ecosystem: the river delta, bay, barrier islands and Gulf of Mexico.
Parks and other attractions.
The Mobile Botanical Gardens feature a variety of flora spread over 100 acre. It contains the Millie McConnell Rhododendron Garden with 1,000 evergreen and native azaleas and the 30 acre Longleaf Pine Habitat. Bellingrath Gardens and Home, located on Fowl River, is a 65 acre botanical garden and historic 10500 sqft mansion that dates to the 1930s. The 5 Rivers Delta Resource Center is a facility that allows visitors to learn about and access the Mobile, Tensaw, Apalachee, Middle, Blakeley, and Spanish rivers. It was established to serve as an easily accessible gateway to the Mobile-Tensaw River Delta. In addition to offering several boat and adventure tours, it contains a small theater; exhibit hall; meeting facilities; walking trails; a canoe and kayak landing.
Mobile has more than 45 public parks within its limits, with some that are of special note. Bienville Square is a historic park in the Lower Dauphin Street Historic District. It assumed its current form in 1850 and is named for Mobile's founder, Jean-Baptiste Le Moyne, Sieur de Bienville. It was once a principal gathering place for the citizens of the city and remains popular today. Cathedral Square is a one-block performing arts park, also in the Lower Dauphin Street Historic District, that is overlooked by the Cathedral Basilica of the Immaculate Conception. Fort Conde is a reconstruction of the city's original Fort Condé, built on the original fort's footprint. It serves as the official welcome center and colonial-era living history museum. Spanish Plaza is a downtown park that honors the Spanish phase of the city between 1780 and 1813. It features the "Arches of Friendship", a fountain presented to Mobile by the city of Málaga, Spain. Langan Park, the largest of the parks at 720 acre, features lakes, natural spaces, and contains the Mobile Museum of Art, Azalea City Golf Course, Mobile Botanical Gardens and Playhouse in the Park.
Historic architecture.
Mobile has antebellum architectural examples of Greek Revival, Gothic Revival, Italianate, and Creole cottage. Later architectural styles found in the city include the various Victorian types, shotgun types, Colonial Revival, Tudor Revival, Spanish Colonial Revival, Beaux-Arts and many others. The city currently has nine major historic districts: Old Dauphin Way, Oakleigh Garden, Lower Dauphin Street, Leinkauf, De Tonti Square, Church Street East, Ashland Place, Campground, and Midtown.
Mobile has a number of historic structures in the city, including numerous churches and private homes. Some of Mobile's historic churches include Christ Church Cathedral, the Cathedral Basilica of the Immaculate Conception, Emanuel AME Church, Government Street Presbyterian Church, St. Louis Street Missionary Baptist Church, State Street AME Zion Church, Stone Street Baptist Church, Trinity Episcopal Church, St. Francis Street Methodist Church, Saint Joseph's Roman Catholic Church, Saint Francis Xavier Catholic Church, Saint Matthew's Catholic Church, Saint Paul's Episcopal Chapel, and Saint Vincent de Paul. The Sodality Chapel and St. Joseph's Chapel at Spring Hill College are two historic churches on that campus. Two historic Roman Catholic convents survive, the Convent and Academy of the Visitation and the Convent of Mercy.
Barton Academy is a historic Greek Revival school building and local landmark on Government Street. The Bishop Portier House and the Carlen House are two of the many surviving examples of Creole cottages in the city. The Mobile City Hospital and the United States Marine Hospital are both restored Greek Revival hospital buildings that predate the Civil War. The Washington Firehouse No. 5 is a Greek Revival fire station, built in 1851. The Hunter House is an example of the Italianate style and was built by a successful 19th-century African American businesswoman. The Shepard House is a good example of the Queen Anne style. The Scottish Rite Temple is the only surviving example of Egyptian Revival architecture in the city. The Gulf, Mobile and Ohio Passenger Terminal is an example of the Mission Revival style.
The city has several historic cemeteries that were established shortly after the colonial era. They replaced the colonial Campo Santo, of which no trace remains. The Church Street Graveyard contains above-ground tombs and monuments spread over 4 acre and was founded in 1819, during the height of yellow fever epidemics. The nearby 120 acre Magnolia Cemetery was established in 1836 and served as Mobile's primary burial site during the 19th and early 20th centuries, with approximately 80,000 burials. It features tombs and many intricately carved monuments and statues.
The Catholic Cemetery was established in 1848 by the Archdiocese of Mobile and covers more than 150 acre. It contains plots for the Brothers of the Sacred Heart, Little Sisters of the Poor, Sisters of Charity, and Sisters of Mercy, in addition to many other historically significant burials. Mobile's Jewish community dates back to the 1820s and the city has two historic Jewish cemeteries, Sha'arai Shomayim Cemetery and Ahavas Chesed Cemetery. Sha'arai Shomayim is the older of the two.
Demographics.
The 2010 United States Census determined that there were 195,111 people residing within the city limits of Mobile. Mobile is the center of Alabama's second-largest metropolitan area, which consists of all of Mobile County. Metropolitan Mobile is estimated to have a population of 413,936 in 2012.
The 2010 census indicated that there were 78,959 households, out of which 21,073 had children under the age of 18 living with them, 28,073 were married couples living together, 17,037 had a female householder with no husband present, 3,579 had a male householder with no wife present, and 30,270 were non-families. 25,439 of all households were made up of individuals and 8,477 had someone living alone who is 65 years of age or older. The racial makeup of the city was 50.6% Black or African American, 45.0% White, 0.3% Native American, 1.8% Asian, 0.0% Pacific Islander, 0.9% from other races, 1.4% from two or more races, and 2.4% of the population were Latino. Non-Hispanic Whites were 43.9% of the population in 2010, down from 62.1% in 1980. The average household size was 2.4 and the average family size was 3.07. Estimated same-sex couple households comprised 0.3% of all households in 2010.
The age distribution of the population in 2010 consisted of 6.7% under the age of five years, 75.9% over 18, and 13.7% over 65. The median age was 35.7 years. The male population was 47.0% and the female population was 53.0%. The median income for a household in the city was $37,056 for 2006 to 2010. The per capita income for the city was $22,401.
Government.
Since 1985 the government of Mobile has consisted of a mayor and a seven-member city council. The mayor is elected at-large, and the council members are elected from each of the seven city council single-member districts (SMDs). A supermajority of five votes is required to conduct council business. This form of city government was chosen by the voters after the previous form of government, which used three city commissioners who were elected at-large, was ruled to substantially dilute the minority vote and violate the Voting Rights Act in the 1975 case "Bolden v. City of Mobile". Due to appeals, the case took time to reach settlement and establishment of a new electoral system. Municipal elections are held every four years.
The first mayor elected under the new system of single-member district (SMD) voting was Arthur R. Outlaw, who served his second term as mayor from 1985–1989. His first term had been under the old system, from 1967–1968. Mike Dow defeated Outlaw in the 1989 election and went on to serve as mayor for four terms, from 1989–2005. His "The String of Pearls" initiative, a series of projects designed to stimulate redevelopment of the city's core, is credited with reviving much of downtown Mobile. Upon his retirement, Dow endorsed Sam Jones as his successor. 
Sam Jones was elected in 2005 as the first African-American mayor of Mobile. He was re-elected for a second term in 2009 without opposition. His administration continued the focus on downtown redevelopment and bringing industries to the city. He ran for a third term in 2013 but was beaten by Sandy Stimpson. Stimpson took office on November 4, 2013.
As of November 2013, the seven-member city council is made up of Fredrick Richardson, Jr. from District 1, Levon Manzie from District 2, C.J. Small from District 3, John C. Williams from District 4, Joel Daves from District 5, Bess Rich from District 6, and Gina Gregory from District 7.
Education.
Public facilities.
Public schools in Mobile are operated by the Mobile County Public School System. The Mobile County Public School System has an enrollment of over 65,000 students, employs approximately 8,500 public school employees, and had a budget in 2005–2006 of $617,162,616. The State of Alabama operates the Alabama School of Mathematics and Science on Dauphin Street in Mobile, which boards advanced Alabama high school students. It was founded in 1989 to identify, challenge, and educate future leaders.
Private facilities.
Mobile also has a large number of private schools, most of them being parochial in nature. Many of these belong to the Roman Catholic Archdiocese of Mobile. The private Catholic institutions include McGill-Toolen Catholic High School (1896), Corpus Christi School, Little Flower Catholic School (1934), Most Pure Heart of Mary Catholic School (1900), Saint Dominic School (1961), Saint Ignatius School (1952), Saint Mary Catholic School (1867), Saint Pius X Catholic School (1957), and Saint Vincent DePaul Catholic School (1976). Notable private Protestant institutions include St. Paul's Episcopal School (1947), Mobile Christian School (1961), St. Lukes Episcopal School (1961), Cottage Hill Baptist School System (1961), Faith Academy (1967), and Trinity Lutheran School (1955). UMS-Wright Preparatory School is an independent co-educational preparatory school. It assumed its current configuration in 1988, when the University Military School (founded 1893) and the Julius T. Wright School for Girls (1923) merged to form UMS-Wright.
Primary and secondary.
Major colleges and universities in Mobile that are accredited by the Southern Association of Colleges and Schools include the University of South Alabama, Spring Hill College, the University of Mobile, Faulkner University, and Bishop State Community College.
Undergraduate and postgraduate.
The University of South Alabama is a public, doctoral-level university established in 1963. The university is composed of the College of Arts and Sciences, the Mitchell College of Business, the College of Education, the College of Engineering, the College of Medicine, the Doctor of Pharmacy Program, the College of Nursing, the School of Computing, and the School of Continuing Education and Special Programs.
Faulkner University is a four-year private Church of Christ-affiliated university based in Montgomery, Alabama. The Mobile campus was established in 1975 and offers bachelor's degrees in Business Administration, Management of Human Resources, and Criminal Justice. It also offers associate degrees in Business Administration, Business Information Systems, Computer & Information Science, Criminal Justice, Informatics, Legal Studies, Arts, and Science.
Spring Hill College, chartered in 1830, was the first Catholic college in the southeastern United States and is the third oldest Jesuit college in the country. This four-year private college offers graduate programs in Business Administration, Education, Liberal Arts, Nursing (MSN), and Theological Studies. Undergraduate divisions and programs include the Division of Business, the Communications/Arts Division, International Studies, Inter-divisional Studies, the Language and Literature Division, Bachelor of Science in Nursing, Philosophy and Theology, Political Science, the Sciences Division, the Social Sciences Division, and the Teacher Education Division.
The University of Mobile is a four-year private Baptist-affiliated university in the neighboring city of Prichard that was founded in 1961. It consists of the College of Arts and Sciences, School of Business, School of Christian Studies, School of Education, the School of Leadership Development, and the School of Nursing.
Community college.
Bishop State Community College, founded in 1927, is a public, historically African American, community college. Bishop State has four campuses in Mobile and offers a wide array of associate degrees.
Vocational.
Several post-secondary, vocational-type institutions have a campus in Mobile. These include the Alabama Institute Of Real Estate, American Academy Of Hypnosis, Bealle School Of Real Estate, Charles Academy Of Beauty Culture, Fortis College, Virginia College, ITT Technical Institute, Remington College and White And Sons Barber College.
Healthcare.
Mobile serves the central Gulf Coast as a regional center for medicine, with over 850 physicians and 175 dentists. There are four major medical centers within the city limits.
Mobile Infirmary Medical Center has 704 beds and is the largest nonprofit hospital in the state. It was founded in 1910. Providence Hospital has 349 beds. It was founded in 1854 by the Daughters of Charity from Emmitsburg, Maryland. The University of South Alabama Medical Center has 346 beds. Its roots go back to 1830 with the old city-owned Mobile City Hospital and associated medical school. A teaching hospital, it has Mobile’s only level I trauma center and regional burn center. Springhill Medical Center, with 252 beds, was founded in 1975. It is Mobile's only for-profit facility.
Additionally, the University of South Alabama operates the University of South Alabama Children's and Women's Hospital with 219 beds, dedicated exclusively to the care of women and minors. In 2008, the University of South Alabama opened the USA Mitchell Cancer Center Institute. The center is home to the first academic cancer research center in the central Gulf Coast region.
Mobile Infirmary Medical Center operated Infirmary West, formerly Knollwood Hospital, with 100 acute care beds, but closed the facility at the end of October 2012 due to declining revenues.
BayPointe Hospital and Children's Residential Services, with 94-beds, is the only psychiatric hospital in the city. It houses a residential unit for children, an acute unit for children and adolescents, and an age-segregated involuntary hospital unit for adults undergoing evaluation ordered by the Mobile Probate Court.
The city has a broad array of outpatient surgical centers, emergency clinics, home health care services, assisted-living facilities and skilled nursing facilities.
Economy.
Aerospace, steel, ship building, retail, services, construction, medicine, and manufacturing are Mobile's major industries. After experiencing economic decline for several decades, Mobile's economy began to rebound in the late 1980s. Between 1993 and 2003 roughly 13,983 new jobs were created as 87 new companies were founded and 399 existing companies were expanded.
Defunct companies that were founded or based in Mobile included Alabama Drydock and Shipbuilding Company, Delchamps, and Gayfers. Current companies that were formerly based in the city include Checkers, Minolta-QMS, Morrison's, and the Waterman Steamship Corporation. In addition to those discussed below, AlwaysHD, Foosackly's, Integrity Media, and Volkert, Inc. are currently headquartered out of Mobile.
Unemployment.
The United States Department of Labor's Bureau of Labor Statistics unemployment rate (not seasonally adjusted) for the Mobile Metropolitan Statistical Area was 7.5% for July 2013, compared with an unadjusted rate of 6.6% for Alabama as a whole and 7.4% for the entire nation.
Major industry.
Port of Mobile.
Mobile's Alabama State Docks underwent the largest expansion in its history by expanding its container processing and storage facility and increasing container storage at the docks by over 1,000% at a cost of over $300 million, thus positioning Mobile for rapid container processing growth. Despite the expansion of its container capabilities and the addition of two massive new cranes, the port went from 9th largest to the 12th largest by tonnage in the nation from 2008 to 2010.
Shipyards.
Shipbuilding began to make a major comeback in Mobile in 1999 with the founding of Austal USA. A subsidiary of the Australian company Austal, it expanded its production facility for United States defense and commercial aluminum shipbuilding on Blakeley Island in 2005. Austal announced in October 2012, after winning a new defense contract and completing another 30000 sqft building within their complex on the island, that it will expand from a workforce of 3,000 workers to 4,500 employees.
Atlantic Marine operated a major shipyard at the former Alabama Drydock and Shipbuilding Company site on Pinto Island. It was acquired by British defense conglomerate BAE Systems in May 2010 for $352 million. Doing business as BAE Systems Southeast Shipyards, the company continues to operate the site as a full-service shipyard, employing approximately 600 workers with plans to expand.
Brookley Aeroplex.
The Brookley Aeroplex is an industrial complex and airport located 3 mi south of the central business district of the city. It is currently the largest industrial and transportation complex in the region with over 70 companies, many of which are aerospace, spread over 1650 acre. Notable employers at Brookley include Airbus North America Engineering (Airbus Military North America's facilities are at the Mobile Regional Airport), ST Aerospace Mobile (a division of ST Engineering), and Continental Motors.
Plans for an Airbus A320 family aircraft assembly plant in Mobile were formally announced by Airbus CEO Fabrice Brégier from the Mobile Convention Center on July 2, 2012. The plans include a $600 million factory at the Brookley Aeroplex for the assembly of the A319, A320 and A321 aircraft. It is planned to employ up roughly 1,000 full-time workers when fully operational. Construction is scheduled to begin in 2013, with it becoming operable by 2015 and producing up to 50 aircraft per year by 2017. The assembly plant is the company's first factory to be built within the United States. It was announced on February 1, 2013 that Airbus had hired Alabama-based Hoar Construction to oversee construction of the facility.
ThyssenKrupp.
German technology conglomerate ThyssenKrupp broke ground on a $4.65 billion combined stainless and carbon steel processing facility in Calvert, a few miles north of Mobile, in 2007. It was originally projected to eventually employ 2,700 people. The facility became operational in July 2010.
The company put both its carbon mill in Calvert and a steel slab-making unit in Rio de Janeiro up for sale in May 2012, citing rising production costs and a worldwide decrease in demand. ThyssenKrupp's stainless steel division, Inoxum, including the stainless portion of the Calvert plant, was sold to Finnish stainless steel company Outokumpu Oyi in 2012.
Top employers.
According to Mobile's 2011 Comprehensive Annual Financial Report, the top employers in the city during 2011 were:
Transportation.
Air.
Local airline passengers are served by the Mobile Regional Airport, with direct connections to five major hub airports. It is served by American Eagle, with service to Dallas-Fort Worth International Airport; United Express, with service to George Bush Intercontinental Airport; Delta Connection, with service to Hartsfield-Jackson International Airport and Memphis International Airport; and US Airways Express, with service to Charlotte/Douglas International Airport. The Mobile Downtown Airport at the Brookley Aeroplex serves corporate, cargo, and private aircraft.
Rail.
Mobile is served by four Class I railroads, including the Canadian National Railway (CNR), CSX Transportation (CSX), the Kansas City Southern Railway (KCS), and the Norfolk Southern Railway (NS). The Alabama and Gulf Coast Railway (AGR), a Class III railroad, links Mobile to the Burlington Northern and Santa Fe Railway (BNSF) at Amory, Mississippi. These converge at the Port of Mobile, which provides intermodal freight transport service to companies engaged in importing and exporting. Other railroads include the CG Railway (CGR), a rail ship service to Coatzacoalcos, Veracruz, and the Terminal Railway Alabama State Docks (TASD), a switching railroad. The city was served by Amtrak's "Sunset Limited" passenger train service until 2005, when the service was suspended due to the effects of Hurricane Katrina.
Roadways.
Two major interstate highways and a spur converge in Mobile. Interstate 10 runs northeast to southwest across the city while Interstate 65 starts in Mobile at Interstate 10 and runs north. Interstate 165 connects to Interstate 65 north of the city in Prichard and joins Interstate 10 in downtown Mobile. Mobile is well served by many major highway systems. United States Highways US 31, US 43, US 45, US 90, and US 98 radiate from Mobile traveling east, west, and north. Mobile has three routes east across the Mobile River and Mobile Bay into neighboring Baldwin County, Alabama. Interstate 10 leaves downtown through the George Wallace Tunnel under the river and then over the bay across the Jubilee Parkway to Spanish Fort and Daphne. US 98 leaves downtown through the Bankhead Tunnel under the river, onto Blakeley Island, and then over the bay across the Battleship Parkway into Spanish Fort, Alabama. US 90 travels over the Cochrane–Africatown USA Bridge to the north of downtown onto Blakeley Island where it becomes co-routed with US 98.
Mobile's public transportation is the Wave Transit System which features buses with 18 fixed routes and neighborhood service. Baylinc is a public transportation bus service provided by the Baldwin Rural Transit System in cooperation with the Wave Transit System that provides service between eastern Baldwin County and downtown Mobile. Baylinc operates Monday through Friday.
Greyhound Lines provides intercity bus service between Mobile and many locations throughout the United States. Mobile is served by several taxi and limousine services.
Water.
The Port of Mobile has public, deepwater terminals with direct access to 1500 mi of inland and intracoastal waterways serving the Great Lakes, the Ohio and Tennessee river valleys (via the Tennessee-Tombigbee Waterway), and the Gulf of Mexico. The Alabama State Port Authority owns and operates the public terminals at the Port of Mobile. The public terminals handle containerized, bulk, breakbulk, roll-on/roll-off, and heavy-lift cargoes. The port is also home to private bulk terminal operators, as well as a number of highly specialized shipbuilding and repair companies with two of the largest floating dry docks on the Gulf Coast.
The city was formerly a home port for cruise ships from Carnival Cruise Lines. The first cruise ship to call the port home was the "Holiday", which left the city in November 2009 so that a larger and newer ship could take its place. The "Carnival Fantasy" operated from Mobile from then until the "Carnival Elation" arrived in May 2010. In early 2011, Carnival announced that despite fully booked cruises, the company would cease operations from Mobile in October 2011. This cessation of cruise service left the city with an annual debt service of around two million dollars related to the terminal.
Although Carnival Cruise Lines no longer operates from the city, the "Carnival Triumph" was towed into the port following a crippling engine room fire. It was the largest cruise ship ever to dock at the cruise terminal in Mobile. Later it was eclipsed by the "Carnival Conquest", which docked in Mobile when the Port of New Orleans was temporarily closed. Larger commercial ships routinely arrive at the Port of Mobile.
Media.
Print.
Mobile's "Press-Register" is Alabama's oldest active newspaper, first published in 1813. The paper focuses on Mobile and Baldwin counties and the city of Mobile, but also serves southwestern Alabama and southeastern Mississippi. Mobile's alternative newspaper is the "Lagniappe". The Mobile area's local magazine is "Mobile Bay Monthly". The "Mobile Beacon" is an alternative focusing on the African-American communities of Mobile. Mod Mobilian is a website with a focus on cultured living in Mobile.
Television.
Mobile is served locally by a number of over-the-air television stations. These include WKRG 5 (CBS), WALA 10 (Fox), WPMI 15 (NBC), WMPV 21 (religious), WDPM 23 (religious), WEIQ 42 (PBS), and WFNA 55 (CW). The region is also served by WEAR 3 (ABC), WSRE 31 (PBS), WHBR 34 (religious), WFGX 35 (MyNetworkTV), WJTC 44 (independent), WFBD 48 (America One), WPAN 53 (Jewelry Television), and WAWD 58 (independent), all out of the Pensacola, Florida area. Mobile is part of the Mobile–Pensacola–Fort Walton Beach designated market area, as defined by Nielsen Media Research. It ranked 61st in the nation for the 2007–08 television season.
Radio.
Fourteen FM radio stations transmit from Mobile: WAVH, WBHY, WBLX, WDLT, WHIL, WKSJ, WKSJ-HD2, WLVM, WMXC, WMXC-HD2, WQUA, WRKH, WRKH-HD2, and WZEW . Nine AM radio stations transmit from Mobile: WBHY, WERM, WGOK, WIJD, WLPR, WMOB, WNGL, WNTM, and WXQW. The content ranges from Christian Contemporary to Hip hop to Top 40. Arbitron ranks Mobile's radio market as 93rd in the United States as of autumn 2007.
Sports.
Football.
Mobile is the home of Ladd-Peebles Stadium. The football stadium opened in 1948. With a current capacity of 40,646, Ladd-Peebles Stadium is the fourth-largest stadium in the state.
Ladd-Peebles Stadium has been home to the Senior Bowl since 1951, featuring the best college seniors in NCAA football.
The GoDaddy Bowl, originally known as the Mobile Alabama Bowl and later the GMAC Bowl, has been played at Ladd-Peebles Stadium since 1999. It features opponents from the Sun Belt and Mid-American conferences.
Since 1988, Ladd-Peebles Stadium has hosted the Alabama-Mississippi All-Star Classic. The top graduating high school seniors from their respective states compete each June.
The University of South Alabama in Mobile established a football team in 2007, which went undefeated in its 2009 inaugural season. Their program will move to Division I/FBS in 2013 as a member of the Sun Belt Conference. It currently plays at Ladd-Peebles Stadium.
Baseball.
Mobile's Hank Aaron Stadium is the home of the Mobile BayBears minor league baseball team.
South Alabama baseball also has a proud tradition, producing professional stars such as Luis Gonzalez, Juan Pierre, Jon Lieber, Adam Lind, and David Freese.
Basketball.
South Alabama basketball is a respected mid-major, regularly competing for the Sun Belt Conference championship. They play their home games at the Mitchell Center.
Other sports and facilities.
The public Mobile Tennis Center includes over 50 courts, all lighted and hard-court.
For golfers, Magnolia Grove, part of the Robert Trent Jones Golf Trail, has 36 holes. The Falls course was recently named the best par 3 course in America. The Mitchell Company Tournament of Champions was played annually at Magnolia Grove from 1999 through 2007. The Mobile Bay LPGA Classic took its place in 2008, also held at Mobile's Magnolia Grove.
Mobile is home to the Azalea Trail Run, which races through historic midtown and downtown Mobile. This 10k run has been an annual event since 1978. The Azalea Trail Run is one of the premier 10k road races in the United States, attracting runners from all over the world.
Sister cities.
Mobile has registered sister city arrangements with the following cities:

</doc>
<doc id="20953" url="http://en.wikipedia.org/wiki?curid=20953" title="Monoamine oxidase">
Monoamine oxidase

L-Monoamine oxidases (MAO) (EC ) are a family of enzymes that catalyze the oxidation of monoamines. They are found bound to the outer membrane of mitochondria in most cell types in the body. The enzyme was originally discovered by Mary Bernheim in the liver and was named tyramine oxidase. They belong to the protein family of flavin-containing amine oxidoreductases.
Subtypes and tissue distribution.
In humans there are two types of MAO: MAO-A and MAO-B.
Function.
Monoamine oxidases catalyze the oxidative deamination of monoamines. Oxygen is used to remove an amine group from a molecule, resulting in the corresponding aldehyde and ammonia.
Monoamine oxidases contain the covalently bound cofactor FAD and are, thus, classified as flavoproteins.
Substrate specificities.
They are well known enzymes in pharmacology, since they are the substrate for the action of a number of monoamine oxidase inhibitor drugs. MAO-A is particularly important in the catabolism of monoamines ingested in food. Both MAOs are also vital to the inactivation of monoaminergic neurotransmitters, for which they display different specificities.
Specific reactions catalyzed by MAO include:
Clinical significance.
Because of the vital role that MAOs play in the inactivation of neurotransmitters, MAO dysfunction (too much or too little MAO activity) is thought to be responsible for a number of psychiatric and neurological disorders. For example, unusually high or low levels of MAOs in the body have been associated with schizophrenia, depression, attention deficit disorder, substance abuse, migraines, and irregular sexual maturation. Monoamine oxidase inhibitors are one of the major classes of drug prescribed for the treatment of depression, although they are often last-line treatment due to risk of the drug's interaction with diet or other drugs. Excessive levels of catecholamines (epinephrine, norepinephrine, and dopamine) may lead to a hypertensive crisis, and excessive levels of serotonin may lead to serotonin syndrome.
In fact, MAO-A inhibitors act as antidepressant and antianxiety agents, whereas MAO-B inhibitors are used alone or in combination to treat Alzheimer’s and Parkinson’s diseases.
PET research has shown that MAO is also heavily depleted by use of tobacco cigarettes.
Animal Models.
Mice unable to produce either MAO-A or MAO-B display autistic-like traits. These knockout mice display an increased response to stress.
Genetics.
The genes encoding MAO-A and MAO-B are located side-by-side on the short arm of the X chromosome, and have about 70% sequence similarity. Rare mutations in the gene are associated with Brunner syndrome.
A study based on the Dunedin cohort concluded that maltreated children with a low-activity polymorphism in the promoter region of the MAO-A gene were more likely to develop antisocial conduct disorders than maltreated children with the high-activity variant. Out of the 442 total males in the study (maltreated or not), 37% had the low activity variant. Of the 13 maltreated males with low MAO-A activity, 11 had been assessed as exhibiting adolescent conduct disorder and 4 were convicted for violent offenses. The suggested mechanism for this effect is the decreased ability of those with low MAO-A activity to quickly degrade norepinephrine, the synaptic neurotransmitter involved in sympathetic arousal and rage. This is argued to provide direct support for the idea that genetic susceptibility to disease is not determined at birth, but varies with exposure to environmental influences. However, most individuals with conduct disorder or convictions did not have low activity of MAO-A; maltreatment was found to have caused stronger predisposition for antisocial behavior than differences in MAO-A activity.
The claim that an interaction between low MAO-A activity and maltreatment would cause anti-social behavior has been criticized since the predisposition towards anti-social behavior could equally well have been caused by "other" genes inherited from abusive parents.
A possible link between predisposition to novelty seeking and a genotype of the MAO-A gene has been found.
A particular variant (or genotype), dubbed "warrior gene" in the popular press, was over-represented in Māori. This supported earlier studies finding different proportions of variants in different ethnic groups. This is the case for many genetic variants, with 33% White/Non-Hispanic, 61% Asian/Pacific Islanders having the low-activity MAO-A promoter variant.

</doc>
<doc id="20955" url="http://en.wikipedia.org/wiki?curid=20955" title="Madness">
Madness

Madness may refer to:

</doc>
<doc id="20958" url="http://en.wikipedia.org/wiki?curid=20958" title="Magna Carta">
Magna Carta

Magna Carta (Latin for "the Great Charter"), also called Magna Carta Libertatum (Latin for "the Great Charter of the Liberties"), is a charter agreed by King John of England at Runnymede, near Windsor, on 15 June 1215. First drafted by the Archbishop of Canterbury to make peace between the unpopular King and a group of rebel barons, it promised the protection of church rights, protection for the barons from illegal imprisonment, access to swift justice, and limitations on feudal payments to the Crown, to be implemented through a council of 25 barons. Neither side stood behind their commitments, and the charter was annulled by Pope Innocent III, leading to the First Barons' War. After John's death, the regency government of his young son, Henry III, reissued the document in 1216, stripped of some of its more radical content, in an unsuccessful bid to build political support for their cause. At the end of the war in 1217, it formed part of the peace treaty agreed at Lambeth, where the document acquired the name Magna Carta, to distinguish it from the smaller Charter of the Forest which was issued at the same time. Short of funds, Henry reissued the charter again in 1225 in exchange for a grant of new taxes; his son, Edward I, repeated the exercise in 1297, this time confirming it as part of England's statute law.
The charter became part of English political life and was typically renewed by each monarch in turn, although as time went by and the fledgling English Parliament passed new laws, it lost some of its practical significance. At the end of the 16th century there was an upsurge in interest in Magna Carta. Lawyers and historians at the time believed that there was an ancient English constitution, going back to the days of the Anglo-Saxons, that protected individual English freedoms. They argued that the Norman invasion of 1066 had overthrown these rights, and that Magna Carta had been a popular attempt to restore them, making the charter an essential foundation for the contemporary powers of Parliament and legal principles such as "habeas corpus". Although this historical account was badly flawed, jurists such as Sir Edward Coke used Magna Carta extensively in the early 17th century, arguing against the divine right of kings propounded by the Stuart monarchs. Both James I and his son Charles I attempted to suppress the discussion of Magna Carta, until the issue was curtailed by the English Civil War of the 1640s and the execution of Charles.
The political myth of Magna Carta and its protection of ancient personal liberties persisted after the Glorious Revolution of 1688 until well into the 19th century. It influenced the early American colonists in the Thirteen Colonies and the formation of the American Constitution in 1789, which became the supreme law of the land in the new republic of the United States. Research by Victorian historians showed that the original 1215 charter had concerned the medieval relationship between the monarch and the barons, rather than the rights of ordinary people, but the charter remained a powerful, iconic document, even after almost all of its content was repealed from the statute books in the 19th and 20th centuries. Magna Carta still forms an important symbol of liberty today, often cited by politicians and campaigners, and is held in great respect by the British and American legal communities, Lord Denning describing it as "the greatest constitutional document of all times – the foundation of the freedom of the individual against the arbitrary authority of the despot".
In the 21st century, four exemplifications of the original 1215 charter remain in existence, held by the British Library and the cathedrals of Lincoln and Salisbury. There are also a handful of the subsequent charters in public and private ownership, including copies of the 1297 charter in both the United States and Australia. The original charters were written on vellum sheets using quill pens, in a particular style of abbreviated Latin. Each was sealed with the royal great seal using beeswax and resin, most of which have not survived. Although academics refer to the 63 numbered "clauses" of Magna Carta, this is a modern system of numbering, introduced by Sir William Blackstone in 1759; the original charter formed a single, long unbroken text. The four original 1215 charters were displayed together at the British Library for one day, 3 February 2015, to mark the 800th anniversary of Magna Carta.
History.
13th century.
Background.
Magna Carta originated as an unsuccessful attempt to achieve peace between royalist and rebel factions in 1215, as part of the events leading to the outbreak of the First Barons' War. England was ruled by King John, the third of the Angevin kings. Although the kingdom had a robust administrative system, the nature of government under the Angevin monarchs was ill-defined and uncertain. John and his predecessors had ruled using the principle of "vis et voluntas", or "force and will", taking executive and sometimes arbitrary decisions, often justified on the basis that a king was above the law. Many contemporary writers believed that monarchs should rule in accordance with the custom and the law, with the counsel of the leading members of the realm, but there was no model for what should happen if a king refused to do so.
John had lost most of his ancestral lands in France to King Philip II in 1204 and had struggled to regain them for many years, raising extensive taxes on the barons to accumulate money to fight a war which ultimately ended in expensive failure in 1214. Following the defeat of his allies at the Battle of Bouvines, John had to sue for peace and pay compensation. John was already personally unpopular with many of the barons, many of whom owed money to the Crown, and little trust existed between the two sides. A triumph would have strengthened his position, but in the face of his defeat, within a few months of his return from France John found that rebel barons in the north and east of England were organising resistance to his rule. The rebels took an oath that they would "stand fast for the liberty of the church and the realm", and demanded that the King confirm the Charter of Liberties that had been declared by King Henry I in the previous century, and which was perceived by the barons to protect their rights. The rebel leadership was unimpressive by the standards of the time, even disreputable, but were united by their hatred of John; Robert FitzWalter, later elected leader of the rebel barons, claimed publicly that John had attempted to rape his daughter, and was implicated in a plot to assassinate John in 1212.
John held a council in London in January 1215 to discuss potential reforms, and sponsored discussions in Oxford between his agents and the rebels during the spring. Both sides appealed to Pope Innocent III for assistance in the dispute. During the negotiations, the rebellious barons produced an initial document, which historians have termed "the Unknown Charter of Liberties", which drew on Henry I's Charter of Liberties for much of its language; seven articles from that document later appeared in the "Articles of the Barons" and the subsequent charter. It was John's hope that the Pope would give him valuable legal and moral support, and accordingly he played for time; the King had declared himself to be a papal vassal in 1213 and correctly believed he could count on the Pope for help. John also began recruiting mercenary forces from France, although some were later sent back to avoid giving the impression that the King was escalating the conflict. In a further move to shore up his support, John took an oath to become a crusader, a move which gave him additional political protection under church law, even though many felt the promise was insincere.
Letters backing John arrived from the Pope in April, but by then, the rebel barons had organised into a military faction. They congregated at Northampton in May and renounced their feudal ties to John, marching on London, Lincoln, and Exeter. John's efforts to appear moderate and conciliatory had been largely successful, but once the rebels held London, they attracted a fresh wave of defectors from the royalists. The King offered to submit the problem to a committee of arbitration with the Pope as the supreme arbiter, but this was not attractive to the rebels. Stephen Langton, the Archbishop of Canterbury, had been working with the rebel barons on their demands, and after the suggestion of papal arbitration failed, John instructed Langton to organise peace talks.
Great Charter of 1215.
John met the rebel leaders at Runnymede, near both the royal fortress of Windsor Castle and the rebel base at Staines, on 10 June 1215, where they presented him with their draft demands for reform, the "Articles of the Barons". Stephen Langton's pragmatic efforts at mediation over the next ten days turned these incomplete demands into a charter capturing the proposed peace agreement; a few years later, this agreement was renamed Magna Carta, meaning "Great Charter". By 15 June, general agreement had been made on a text, and on 19 June, the rebels renewed their oaths of loyalty to John and copies of the charter were formally issued.
Although, as the historian David Carpenter has noted, the charter "wasted no time on political theory", it went beyond simply addressing individual baronial complaints, and formed a wider proposal for political reform. It promised the protection of church rights, protection from illegal imprisonment, access to swift justice, and, most importantly, limitations on taxation and other feudal payments to the Crown, with certain forms of feudal taxation requiring baronial consent. It focused on the rights of free men—in particular the barons—excluding serfs and unfree labour. Its style and content reflected Henry I's Charter of Liberties, as well as a wider body of legal traditions, including the royal charters issued to towns, the operations of the Church and baronial courts and European charters such as the Statute of Pamiers.
Under what historians later labelled "clause 61", or the "security clause", a council of 25 barons would be created to monitor and ensure John's future adherence to the charter. If John did not conform to the charter within 40 days of being notified of a transgression by the council, the 25 barons were empowered by clause 61 to seize John's castles and lands until, in their judgement, amends had been made. Men were to be compelled to swear an oath to assist the council in controlling the King, but once redress had been made for any breaches, the King would continue to rule as before. In one sense this was not unprecedented; other kings had previously conceded the right of individual resistance to their subjects if the King did not uphold his obligations. Magna Carta was however novel in that it set up a formally recognised means of collectively coercing the King. The historian Wilfred Warren argues that it was almost inevitable that the clause would result in civil war, as it as "was crude in its methods and disturbing in its implications". The barons were trying to force John to keep to the charter, but clause 61 was so heavily weighted against the King that this version of the charter could not survive.
John and the rebel barons did not trust each other, and neither side seriously attempted to implement the peace accord. The 25 barons selected for the new council were all rebels, chosen by the more extremist barons, and many among the rebels found excuses to keep their forces mobilised. Disputes began to emerge between those rebels who had expected the charter to return lands that had been confiscated and the royalist faction.
Clause 61 of Magna Carta contained a commitment from John that he would "seek to obtain nothing from anyone, in our own person or through someone else, whereby any of these grants or liberties may be revoked or diminished". Despite this, the King appealed to Pope Innocent for help in July, arguing that the charter compromised the Pope's rights as John's feudal lord. As part of the June peace deal the barons were supposed to surrender London by 15 August, but this they refused to do. Meanwhile, instructions from the Pope arrived in August, written before the peace accord, with the result that papal commissioners excommunicated the rebel barons and suspended Langton from office in early September. Once aware of the charter, the Pope responded in detail: in a letter dated 24 August and arriving in late September, he declared the charter to be "not only shameful and demeaning but also illegal and unjust" since John had been "forced to accept" it, and accordingly the charter was "null, and void of all validity for ever"; under threat of excommunication, the King was not to observe the charter, nor the barons try to enforce it.
By then, violence had broken out between the two sides; less than three months after it had been agreed, John and the loyalist barons firmly repudiated the failed charter: the First Barons' War erupted. The rebel barons concluded that peace with John was impossible, and turned to Philip II's son, the future Louis VIII, for help, offering him the English throne. The war soon settled into a stalemate. The King became ill and died on the night of 18 October, leaving the nine-year-old Henry III as his heir.
List of participants in 1215.
Barons, bishops, and abbots who were party to Magna Carta 
Others
Great Charter of 1216.
Although the Charter of 1215 was a failure as a peace treaty, it was resurrected under the new government of the young Henry III as a way of drawing support away from the rebel faction. On his deathbed, King John appointed a council of thirteen executors to help Henry reclaim the kingdom, and requested that his son be placed into the guardianship of William Marshal, one of the most famous knights in England. William knighted the boy, and Cardinal Guala Bicchieri, the papal legate to England, then oversaw his coronation at Gloucester Cathedral on 28 October.
The young King inherited a difficult situation, with over half of England occupied by the rebels. He had substantial support though from Guala, who intended to win the civil war for Henry and punish the rebels. Guala set about strengthening the ties between England and the Papacy, starting with the coronation itself, during which Henry gave homage to the Papacy, recognising the Pope as his feudal lord. Pope Honorius III declared that Henry was the Pope's vassal and ward, and that the legate had complete authority to protect Henry and his kingdom. As an additional measure, Henry took the cross, declaring himself a crusader and thereby entitled to special protection from Rome.
The war was not going well for the loyalists, but Prince Louis and the rebel barons were also finding it difficult to make further progress. John's death had defused some of the rebel concerns, and the royal castles were still holding out in the occupied parts of the country. Henry's government encouraged the rebel barons to come back to his cause in exchange for the return of their lands, and reissued a version of the 1215 Charter, albeit having first removed some of the clauses, including those unfavourable to the Papacy and clause 61, which had set up the council of barons. The move was not successful, and opposition to Henry's new government hardened.
Great Charter of 1217.
In February 1217, Louis set sail for France to gather reinforcements. In his absence, arguments broke out between Louis' French and English followers, and Cardinal Guala declared that Henry's war against the rebels was the equivalent of a religious crusade. This declaration resulted in a series of defections from the rebel movement, and the tide of the conflict swung in Henry's favour. Louis returned at the end of April, but his northern forces were defeated by William Marshal at the Battle of Lincoln in May.
Meanwhile, support for Louis' campaign was diminishing in France, and he concluded that the war in England was lost. He negotiated terms with Cardinal Guala, under which Louis would renounce his claim to the English throne; in return, his followers would be given back their lands, any sentences of excommunication would be lifted, and Henry's government would promise to enforce the charter of the previous year. The proposed agreement soon began to unravel amid claims from some loyalists that it was too generous towards the rebels, particularly the clergy who had joined the rebellion.
In the absence of a settlement, Louis remained in London with his remaining forces, hoping for the arrival of reinforcements from France. When the expected fleet did arrive in August, it was intercepted and defeated by loyalists at the Battle of Sandwich. Louis entered into fresh peace negotiations, and the factions came to agreement on the final Treaty of Lambeth, also known as the Treaty of Kingston, on 12 and 13 September 1217. The treaty was similar to the first peace offer, but excluded the rebel clergy, whose lands and appointments remained forfeit; it included a promise, however, that Louis' followers would be allowed to enjoy their traditional liberties and customs, referring back to the Charter of 1216. Louis left England as agreed and joined the Albigensian Crusade in the south of France, bringing the war to an end.
A great council was called in October and November to take stock of the post-war situation; this council is thought to have formulated and issued the Charter of 1217. The charter resembled that of 1216, although some additional clauses were added to protect the rights of the barons over their feudal subjects, and the restrictions on the Crown's ability to levy taxation were watered down. There remained a range of disagreements around the management of the royal forests, which involved a special legal system that had resulted in a source of considerable royal revenue; complaints existed over both the implementation of these courts, and the geographic boundaries of the royal forests. A complementary charter, the Charter of the Forest, was created, pardoning existing forest offences, imposing new controls over the forest courts, and establishing a review of the forest boundaries. To distinguish the two charters, the term "magna carta libertatum", "the great charter of liberties", was used by the scribes to refer to the larger document, which in time became known simply as Magna Carta.
Great Charter of 1225.
Magna Carta became increasingly embedded into English political life during Henry III's minority. As the King grew older, his government slowly began to recover from the civil war, regaining control of the counties and beginning to raise revenue once again, taking care not to overstep the terms of the charters. Henry remained a minor and his government's legal ability to make permanently binding decisions on his behalf was limited. In 1223, the tensions over the status of the charters became clear in the royal court, when Henry's government attempted to reassert its rights over its properties and revenues in the counties, facing resistance from many communities that argued—if sometimes incorrectly—that the charters protected the new arrangements. This resistance resulted in an argument between Archbishop Langton and William Brewer over whether the King had any duty to fulfil the terms of the charters, given that he had been forced to agree to them. On this occasion, Henry gave oral assurances that he considered himself bound by the charters, enabling a royal inquiry into the situation in the counties to progress.
Two years later, the question of Henry's commitment to the charters re-emerged, when Louis VIII of France invaded Henry's remaining provinces in France, Poitou and Gascony. Henry's army in Poitou was under-resourced, and the province quickly fell. It became clear that Gascony would also fall unless reinforcements were sent from England. In early 1225, a great council approved a tax of £40,000 to dispatch an army, which quickly retook Gascony. In exchange for agreeing to support Henry, the barons demanded that the King reissue Magna Carta and the Charter of the Forest. The content was almost identical to the 1217 versions, but in the new versions, the King declared that the charters were issued of his own "spontaneous and free will" and confirmed them with the royal seal, giving the new Great Charter and the Charter of the Forest of 1225 much more authority than the previous versions.
The barons anticipated that the King would act in accordance with these charters, subject to the law and moderated by the advice of the nobility. Uncertainty continued, and in 1227, when he was declared of age and able to rule independently, Henry announced that future charters had to be issued under his own seal. This brought into question the validity of the previous charters issued during his minority, and Henry actively threatened to overturn the Charter of the Forest unless the taxes promised in return for it were actually paid. In 1253, Henry confirmed the charters once again in exchange for taxation.
Henry placed a symbolic emphasis on rebuilding royal authority, but his rule was relatively circumscribed by Magna Carta. He generally acted within the terms of the charters, which prevented the Crown from taking extrajudicial action against the barons, including the fines and expropriations that had been common under his father, John. The charters did not address the sensitive issues of the appointment of royal advisers and the distribution of patronage, and they lacked any means of enforcement if the King chose to ignore them. The inconsistency with which he applied the charters over the course of his rule alienated many barons, even those within his own faction. Despite the various charters, the provision of royal justice was inconsistent and driven by the needs of immediate politics: sometimes action would be taken to address a legitimate baronial complaint, while on other occasions the problem would simply be ignored. The royal courts, which toured the country to provide justice at the local level, typically for lesser barons and the gentry claiming grievances against major lords, had little power, allowing the major barons to dominate the local justice system. Henry's rule became lax and careless, resulting in a reduction in royal authority in the provinces and, ultimately, the collapse of his authority at court.
In 1258, a group of barons seized power from Henry in a "coup d'état", citing the need to strictly enforce Magna Carta and the Charter of the Forest, creating a new baronial-led government to advance reform through the Provisions of Oxford. The barons were not militarily powerful enough to win a decisive victory, and instead appealed to Louis IX of France in 1263–1264 to arbitrate on their proposed reforms. The reformist barons argued their case based on Magna Carta, suggesting that it was inviolable under English law and that the King had broken its terms. Louis came down firmly in favour of Henry, but the French arbitration failed to achieve peace as the rebellious barons refused to accept the verdict. England slipped back into the Second Barons' War, which was won by Henry's son, Prince Edward. Edward also invoked Magna Carta in advancing his cause, arguing that the reformers had taken matters too far and were themselves acting against Magna Carta. In a conciliatory gesture after the barons had been defeated, in 1267 Henry issued the Statute of Marlborough, which included a fresh commitment to observe the terms of Magna Carta.
Great Charter of 1297: statute.
King Edward I reissued the Charters of 1225 in 1297 in return for a new tax. It is this version which remains in statute today, although with most articles now repealed.
The "Confirmatio Cartarum" (Confirmation of Charters) was issued in Norman French by Edward I in 1297. Edward, needing money, had taxed the nobility, and they had armed themselves against him, forcing Edward to issue his confirmation of Magna Carta and the Forest Charter to avoid civil war. The nobles had sought to add another document, the "De Tallagio", to Magna Carta. Edward I's government was not prepared to concede this, they agreed to the issuing of the "Confirmatio", confirming the previous charters and confirming the principle that taxation should be by consent, although the precise manner of that consent was not laid down. A passage mandates that copies shall be distributed in "cathedral churches throughout our realm, there to remain, and shall be read before the people two times by the year", hence the presence of a copy during the month of May 2014 at St Edmundsbury Cathedral, and the permanent installation of a copy in Salisbury Cathedral. In the Confirmation's second article, it is confirmed that
if any judgement be given from henceforth contrary to the points of the charters aforesaid by the justices, or by any other our ministers that hold plea before them against the points of the charters, it shall be undone, and holden for nought.
With the reconfirmation of the Charters in 1300, an additional document was granted, the "Articuli super Cartas" (The Articles upon the Charters). It was composed of 17 articles and sought in part to deal with the problem of enforcing the Charters. Magna Carta and the Forest Charter were to be issued to the sheriff of each country, and should be read four times a year at the meetings of the county courts. Each county should have a committee of three men who could hear complaints about violations of the Charters.
Pope Clement V continued the papal policy of supporting monarchs (who ruled by divine grace) against any claims in Magna Carta which challenged the King's rights, and annulled the "Confirmatio Cartarum" in 1305. Edward I interpreted Clement V's papal bull annulling the "Confirmatio Cartarum" as effectively applying to the "Articuli super Cartas", although the latter was not specifically mentioned. In 1306 Edward I took the opportunity given by the Pope's backing to reassert forest law over large areas which had been "disafforested". Both Edward and the Pope were accused by some contemporary chroniclers of "perjury", and it was suggested by Robert McNair Scott that Robert the Bruce refused to make peace with Edward I's son, Edward II, in 1312 with the justification: "How shall the king of England keep faith with me, since he does not observe the sworn promises made to his liege men..."
Magna Carta's influence on English medieval law.
The Great Charter was referred to in legal cases throughout the medieval period. For example, in 1226, the knights of Lincolnshire argued that their local sheriff was changing customary practice regarding the local courts, "contrary to their liberty which they ought to have by the charter of the lord king". In practice, cases were not brought against the King for breach of Magna Carta and the Forest Charter, but it was possible to bring a case against the King's officers, such as his sheriffs, using the argument that the King's officers were acting contrary to liberties granted by the King in the charters. In addition, medieval cases referred to the clauses in Magna Carta which dealt with specific issues such as wardship and dower, debt collection, and keeping rivers free for navigation. Even in the 13th century, some clauses of Magna Carta rarely appeared in legal cases, either because the issues concerned were no longer relevant, or because Magna Carta had been superseded by more relevant legislation. By 1350 half the clauses of Magna Carta were no longer actively used.
14th–15th centuries.
During the reign of King Edward III six measures, later known as the "Six Statutes", were passed between 1331 and 1369. They sought to clarify certain parts of the Charters. In particular the third statute, in 1354, redefined clause 29, with "free man" becoming "no man, of whatever estate or condition he may be", and introduced the phrase "due process of law" for "lawful judgement of his peers or the law of the land".
Between the 13th and 15th centuries Magna Carta was reconfirmed 32 times according to Sir Edward Coke, and possibly as many as 45 times. Often the first item of parliamentary business was a public reading and reaffirmation of the Charter, and, as in the previous century, parliaments often exacted confirmation of it from the monarch. The Charter was confirmed in 1423 by King Henry VI.
By the mid-15th century, Magna Carta ceased to occupy a central role in English political life, as monarchs reasserted authority and powers which had been challenged in the 100 years after Edward I's reign. The Great Charter remained a text for lawyers, particularly as a protector of property rights, and became more widely read than ever as printed versions circulated and levels of literacy increased.
16th century.
During the 16th century, the interpretation of Magna Carta and the First Barons' War shifted. Henry VII took power at the end of the turbulent Wars of the Roses, followed by Henry VIII, and extensive propaganda under both rulers promoted the legitimacy of the regime, the illegitimacy of any sort of rebellion against royal power, and the priority of supporting the Crown in its arguments with the Papacy.
Tudor historians rediscovered the Barnwell chronicler, who was more favourable to King John than other 13th-century texts, and, as historian Ralph Turner describes, they "viewed King John in a positive light as a hero struggling against the papacy", showing "little sympathy for the Great Charter or the rebel barons". Pro-Catholic demonstrations during the 1536 uprising cited Magna Carta, accusing the King of not giving it sufficient respect.
The first mechanically printed edition of Magna Carta was probably the "Magna Carta cum aliis Antiquis Statutis" of 1508 by Richard Pynson, although the early printed versions of the 16th century incorrectly attributed the origins of Magna Carta to Henry III and 1225, rather than to John and 1215, and accordingly worked from the later text. An abridged English-language edition was published by John Rastell in 1527 and, in 1534, George Ferrers published the first unabridged English-language edition of Magna Carta, dividing the Charter into 37 numbered clauses.
At the end of the 16th century, there was an upsurge in antiquarian interest in England. This work concluded that there was a set of ancient English customs and laws, temporarily overthrown by the Norman invasion of 1066, which had then been recovered in 1215 and recorded in Magna Carta, which in turn gave authority to important 16th century legal principles. Modern historians note that although this narrative was fundamentally incorrect—many refer to it as a "myth" – it took on great importance among the legal historians of the time.
The antiquarian William Lambarde, for example, published what he believed were the Anglo-Saxon and Norman law codes, tracing the origins of the 16th-century English Parliament back to this period, albeit misinterpreting the dates of many documents concerned. Francis Bacon argued that clause 39 of Magna Carta was the basis of the 16th-century jury system and judicial processes. Antiquarians Robert Beale, James Morice, and Richard Cosin argued that Magna Carta was a statement of liberty and a fundamental, supreme law empowering English government. Those who questioned these conclusions, including the Member of Parliament Arthur Hall, faced sanctions.
17th–18th centuries.
Political tensions.
In the early 17th century, Magna Carta became increasingly important as a political document in arguments over the authority of the English monarchy. James I and Charles I both propounded greater authority for the Crown, justified by the doctrine of the divine right of kings, and Magna Carta was cited extensively by their opponents to challenge the monarchy.
Magna Carta, it was argued, recognised and protected the liberty of individual Englishmen, made the King subject to the common law of the land, formed the origin of the trial by jury system, and acknowledged the ancient origins of Parliament: because of Magna Carta and this ancient constitution, an English monarch was unable to alter these long-standing English customs. Although the arguments based on Magna Carta were historically inaccurate, they nonetheless carried symbolic power, as the charter had immense significance during this period; antiquarians such as Sir Henry Spelman described it as "the most majestic and a sacrosanct anchor to English Liberties".
Sir Edward Coke was a leader in using Magna Carta as a political tool during this period. Still working from the 1225 version of the text—the first printed copy of the 1215 charter only emerged in 1610 – Coke spoke and wrote about Magna Carta repeatedly. His work was challenged at the time by Lord Ellesmere, and modern historians such as Ralph Turner and Claire Breay have critiqued Coke as "misconstruing" the original charter "anachronistically and uncritically", and taking a "very selective" approach to his analysis. More sympathetically, J. C. Holt noted that the history of the charters had already become "distorted" by the time Coke was carrying out his work.
In 1621, a bill was presented to Parliament to renew Magna Carta; although this bill failed, lawyer John Selden argued during Darnell's Case in 1627 that the right of "habeas corpus" was backed by Magna Carta. Coke supported the Petition of Right in 1628, which cited Magna Carta in its preamble, attempting to extend the provisions, and to make them binding on the judiciary. The monarchy responded by arguing that the historical legal situation was much less clear-cut than was being claimed, restricted the activities of antiquarians, arrested Coke for treason, and suppressed his proposed book on Magna Carta. Charles initially did not agree to the Petition of Right, and refused to confirm Magna Carta in any way that would reduce his independence as King.
England descended into civil war in the 1640s, resulting in Charles I's execution in 1649. Under the republic that followed, some questioned whether Magna Carta, an agreement with a monarch, was still relevant. Oliver Cromwell, the Lord Protector, disdained Magna Carta, at one point describing it as "Magna Farta" to a defendant who sought to rely on it; nevertheless, he accepted some limits on his powers, agreeing to rule with the advice and consent of his council.
The radical groups that flourished during this period held differing opinions of Magna Carta. The Levellers rejected history and law as presented by their contemporaries, holding instead to an "anti-Normanism" viewpoint. John Lilburne, for example, argued that Magna Carta contained only some of the freedoms that had supposedly existed under the Anglo-Saxons before being crushed by the Norman yoke. The Leveller Richard Overton described the charter as "a beggarly thing containing many marks of intolerable bondage". Both saw Magna Carta as a useful declaration of liberties that could be used against governments they disagreed with. Gerrard Winstanley, the leader of the more extreme Diggers, stated "the best lawes that England hath, [viz., the Magna Carta] were got by our Forefathers importunate petitioning unto the kings that still were their Task-masters; and yet these best laws are yoaks and manicles, tying one sort of people to be slaves to another; Clergy and Gentry have got their freedom, but the common people still are, and have been left servants to work for them."
Glorious Revolution.
The first attempt at a proper historiography was undertaken by Robert Brady, who refuted the supposed antiquity of Parliament and belief in the immutable continuity of the law. Brady realised that the liberties of the Charter were limited and argued that the liberties were the grant of the King. By putting Magna Carta in historical context, he cast doubt on its contemporary political relevance; his historical understanding did not survive the Glorious Revolution, which, according to the historian J. G. A. Pocock, "marked a setback for the course of English historiography."
According to the Whig interpretation of history, the Glorious Revolution was an example of the reclaiming of ancient liberties. Reinforced with Lockean concepts, the Whigs believed England's constitution to be a social contract, based on documents such as Magna Carta, the Petition of Right, and the Bill of Rights. Ideas about the nature of law in general were beginning to change. In 1716, the Septennial Act was passed, which had a number of consequences. First, it showed that Parliament no longer considered its previous statutes unassailable, as it provided for a maximum parliamentary term of seven years, whereas the Triennial Act (1694) (enacted less than a quarter of a century previously) had provided for a maximum term of three years. It also greatly extended the powers of Parliament. Under this new constitution, monarchical absolutism was replaced by parliamentary supremacy. It was quickly realised that Magna Carta stood in the same relation to the King-in-Parliament as it had to the King without Parliament. This supremacy would be challenged by the likes of Granville Sharp. Sharp regarded Magna Carta as a fundamental part of the constitution, and maintained that it would be treason to repeal any part of it. He also held that the Charter prohibited slavery.
Sir William Blackstone published a critical edition of the 1215 Charter in 1759, and gave it the numbering system still used today. In 1763, Member of Parliament John Wilkes was arrested for writing an inflammatory pamphlet, "No. 45, 23 April 1763"; he cited Magna Carta continually. Lord Camden denounced the treatment of Wilkes as a contravention of Magna Carta. Thomas Paine, in his "Rights of Man", would disregard Magna Carta and the Bill of Rights on the grounds that they were not a written constitution devised by elected representatives.
Use in the Thirteen Colonies and the United States.
When English colonists left for the New World, they brought royal charters that established the colonies. The Massachusetts Bay Company charter, for example, stated that the colonists would "have and enjoy all liberties and immunities of free and natural subjects." The Virginia Charter of 1606, which was largely drafted by Sir Edward Coke, stated that the colonists would have the same "liberties, franchises and immunities" as people born in England. The Massachusetts Body of Liberties contained similarities to clause 29 of Magna Carta; when drafting it, the Massachusetts General Court viewed Magna Carta as the chief embodiment of English common law. The other colonies would follow their example. In 1638, Maryland sought to recognise Magna Carta as part of the law of the province, but the request was denied by Charles I.
In 1687, William Penn published "The Excellent Privilege of Liberty and Property: being the birth-right of the Free-Born Subjects of England", which contained the first copy of Magna Carta printed on American soil. Penn's comments reflected Coke's, indicating a belief that Magna Carta was a fundamental law. The colonists drew on English law books, leading them to an anachronistic interpretation of Magna Carta, believing that it guaranteed trial by jury and "habeas corpus".
The development of parliamentary supremacy in the British Isles did not constitutionally affect the Thirteen Colonies, which retained an adherence to English common law, but it directly affected the relationship between Britain and the colonies. When American colonists fought against Britain, they were fighting not so much for new freedom, but to preserve liberties and rights that they believed to be enshrined in Magna Carta.
In the late 18th century, the United States Constitution became the supreme law of the land, recalling the manner in which Magna Carta had come to be regarded as fundamental law. The Constitution's Fifth Amendment guarantees that "no person shall be deprived of life, liberty, or property, without due process of law", a phrase that was derived from Magna Carta. In addition, the Constitution included a similar writ in the , Article 1, Section 9: "The privilege of the writ of habeas corpus shall not be suspended, unless when in cases of rebellion or invasion, the public safety may require it." Each of these proclaim that no person may be imprisoned or detained without evidence that he or she committed a crime. The Ninth Amendment states that "The enumeration in the Constitution, of certain rights, shall not be construed to deny or disparage others retained by the people." The writers of the U.S. Constitution wished to ensure that the rights they already held, such as those that they believed were provided by Magna Carta, would be preserved unless explicitly curtailed.
The Supreme Court of the United States has explicitly referenced Lord Coke's analysis of Magna Carta as an antecedent of the Sixth Amendment's right to a speedy trial.
19th–21st centuries.
Interpretation.
Initially, the Whig interpretation of Magna Carta and its role in constitutional history remained dominant during the 19th century. The historian William Stubbs's "Constitutional History of England", published in the 1870s, formed the high-water mark of this view. Stubbs argued that Magna Carta had been a major step in the shaping of the English nation, and he believed that the barons at Runnymede in 1215 were not just representing the nobility, but the people of England as a whole, standing up to a tyrannical ruler in the form of King John.
This view of Magna Carta began to recede. The late-Victorian jurist and historian Frederic William Maitland provided an alternative academic history in 1899, which began to return Magna Carta to its historical roots. In 1904, Edward Jenks published an article entitled "The Myth of Magna Carta", which undermined the traditionally accepted view of Magna Carta. Historians such as Albert Pollard agreed with Jenks in concluding that Edward Coke had largely "invented" the myth of Magna Carta in the 17th century; these historians argued that the 1215 charter had not referred to liberty for the people at large, but rather to the protection of baronial rights. This view also became popular in wider circles, and in 1930 Sellar and Yeatman published their parody on English history, "1066 and All That", in which they mocked the supposed importance of Magna Carta and its promises of universal liberty: "Magna Charter was therefore the chief cause of Democracy in England, and thus a "Good Thing" for everyone (except the Common People)".
In many literary representations of the medieval past, however, Magna Carta remained a foundation of English national identity. Some authors used the medieval roots of the document as an argument to preserve the social status quo, while others pointed to Magna Carta to challenge perceived economic injustices. The Baronial Order of Magna Charta was formed in 1898 to promote the ancient principles and values felt to be displayed in Magna Carta. The legal profession in England and the United States continued to hold Magna Carta in high esteem; they were instrumental in forming the Magna Carta Society in 1922 to protect the meadows at Runnymede from development in the 1920s, and in 1957, the American Bar Association erected the Magna Carta Memorial at Runnymede. The prominent lawyer Lord Denning described Magna Carta in 1956 as "the greatest constitutional document of all times – the foundation of the freedom of the individual against the arbitrary authority of the despot".
Repeal of articles and constitutional influence.
Radicals such as Sir Francis Burdett believed that Magna Carta could not be repealed, but in the 19th century clauses which were obsolete or had been superseded began to be repealed. The repeal of clause 26 in 1829, by the Offences against the Person Act 1828 (9 Geo. 4 c. 31 s. 1), was the first time a clause of Magna Carta was repealed. Over the next 140 years, nearly the whole charter was repealed, leaving just clauses 1, 9, and 29 still in force after 1969. Most of the clauses were repealed in England and Wales by the Statute Law Revision Act 1863, and in Ireland by the Statute Law (Ireland) Revision Act 1872.
Many later attempts to draft constitutional forms of government trace their lineage back to Magna Carta. The British dominions, Australia and New Zealand, Canada (except Quebec), and formerly the Union of South Africa and Southern Rhodesia, reflected the influence of Magna Carta in their laws, and the Charter's effects can be seen in the laws of other states that evolved from the British Empire.
Modern legacy.
Magna Carta continues to have a powerful iconic status in British society, being cited by politicians and lawyers in support of constitutional positions. Its perceived guarantee of trial by jury and other civil liberties, for example, led to Tony Benn's reference to the debate in 2008 over whether to increase the maximum time terrorism suspects could be held without charge from 28 to 42 days as "the day Magna Carta was repealed". Although rarely invoked in court in the modern era, in 2012 the Occupy London protestors attempted to use Magna Carta in resisting their eviction from St. Paul's Churchyard by the City of London. In his judgment the Master of the Rolls gave this short shrift, noting somewhat drily that although clause 29 was considered by many the foundation of the rule of law in England, he did not consider it directly relevant to the case, and the two other surviving clauses actually concerned the rights of the Church and the City of London.
Magna Carta carries little legal weight in modern Britain, as most of its clauses have been repealed and relevant rights ensured by other statutes, but the historian James Holt remarks that the survival of the 1215 charter in national life is a "reflexion of the continuous development of English law and administration" and symbolic of the many struggles between authority and the law over the centuries. The historian W. L. Warren has observed that "many who knew little and cared less about the content of the Charter have, in nearly all ages, invoked its name, and with good cause, for it meant more than it said". It also remains a topic of great interest to historians; Natalie Fryde characterised the charter as "one of the holiest of cows in English medieval history", with the debates over its interpretation and meaning unlikely to end. In many ways still a "sacred text", Magna Carta is generally considered part of the uncodified constitution of the United Kingdom; in a 2005 speech, the Lord Chief Justice of England and Wales, Lord Woolf, described it as the "first of a series of instruments that now are recognised as having a special constitutional status".
The document also continues to be honoured in the United States as an antecedent of the United States Constitution and Bill of Rights. In 1976, the UK lent one of four surviving originals of the 1215 Magna Carta to the United States for their bicentennial celebrations and also donated an ornate display case for it. The original was returned after one year, but a replica and the case are still on display in the United States Capitol Crypt in Washington, D.C.
Celebration of the 800th anniversary.
The 800th anniversary of the original charter will occur on 15 June 2015, and organisations and institutions are planning celebratory events. The British Library brought together the four existing copies of the 1215 manuscript on 3 February 2015 for a special exhibition. British artist Cornelia Parker has been specially commissioned to create a new artwork, which will be unveiled at the British Library on 15 May 2015 and remain on display until 24 July. The artwork is a copy of an earlier version of this Wikipedia page, embroidered into the form of a tapestry.
The copy held by Lincoln Cathedral was exhibited in the Law Library of Congress in Washington, D.C., from November 2014 until January 2015. A new visitor centre at Lincoln Castle will also be opened for the anniversary. The Royal Mint will release a commemorative two-pound coin.
In 2014, Bury St Edmunds in Suffolk celebrated the 800th anniversary of the barons' Charter of Liberties, said to have been secretly agreed there in November 1214.
Content.
Physical design.
Numerous copies, known as exemplifications, were made of the various charters, and many of them still survive. The documents were written in abbreviated Latin in clear handwriting, using quill pens on sheets of vellum made from sheep skin, approximately 15 by across. They were sealed with the royal great seal by an official called the spigurnel, equipped with a special seal press, using beeswax and resin. There were no signatures on the charter of 1215, and the barons present did not attach their own seals to it. The charters were not numbered or divided into paragraphs or separate clauses at the time; the numbering system used today was introduced by the jurist Sir William Blackstone in 1759.
Exemplifications.
1215 exemplifications.
At least 13 original copies of the 1215 charter were issued by the royal chancery at the time, seven in the first tranche distributed on 24 June and another six later; they were sent to county sheriffs and bishops, who would probably have been charged for the privilege. Variations would have existed between each of these copies and there was probably no single "master copy". Of these documents, only four survive, all held in the UK—two in the British Library, one by Lincoln Cathedral, and one in Salisbury Cathedral. Each of these versions is slightly different in size and text, and each is considered by historians to be equally authoritative.
The two 1215 charters held by the British Library, known as Cotton MS. Augustus II.106 and Cotton Charter XIII.31a, were acquired by the antiquarian Sir Robert Cotton in the 17th century. One of these was originally found by Humphrey Wyems, a London lawyer, who may have discovered it in a tailor's shop. The other was found in Dover Castle in 1630 by Sir Edward Dering. The Dering charter is usually identified as the copy originally sent to the Cinque Ports in 1215. (In 2015 it was announced that David Carpenter had found Dering's copy to be identical to a 1290s transcription made from Canterbury Cathedral's 1215 copy and so he suggests that the Dering copy's destination was the Cathedral rather than the Cinque Ports.) This copy was badly damaged in a fire in Ashburnham House in 1731, however, and although a facsimile was made of it in 1733, the parchment itself is now faded and largely illegible. This is the only surviving 1215 copy to still have its great seal attached, although badly melted in the fire.
Lincoln Cathedral's original copy of the 1215 charter has been held by the county since 1215; it was displayed in the Common Chamber in the cathedral before being moved to another building in 1846. It was being displayed at the 1939 World Fair in New York when the Second World War broke out, and it spent the majority of the war in Fort Knox for safety. Winston Churchill wanted to gift the charter to the American people, hoping that this would encourage the United States, then neutral, to enter the war against the Axis powers, but the cathedral was unwilling and the plans were dropped. The copy was returned to England and put on display in 1976 as part of the cathedral's medieval library. It was subsequently displayed in San Francisco, and was taken out of display for a time to undergo conservation in preparation for another visit to the United States, where it was exhibited in 2007 at the Contemporary Art Center of Virginia and the National Constitution Center in Philadelphia. The document returned to New York to be displayed at the Fraunces Tavern Museum during 2009.
The fourth copy, owned by Salisbury Cathedral, was first given in 1215 to Old Sarum, which was the original cathedral in the region. Rediscovered by the cathedral in 1812, it has remained in Salisbury throughout its history, except when being taken off-site for restoration work. It is possibly the best preserved of the four, although small pin holes can be seen in the parchment from where it was once pinned up. The handwriting on this version is different from that of the other three, suggesting that it was not written by a royal scribe but rather by a member of the cathedral staff, who then had it exemplified by the royal court.
Later exemplifications.
Other early versions of the charters survive today. Only one exemplification of the 1216 charter survives, held in Durham Cathedral. Four copies of the 1217 charter exist; three of these are held by the Bodleian Library in Oxford and one by Hereford Cathedral. Hereford's copy is occasionally displayed alongside the Mappa Mundi in the cathedral's chained library and has survived along with a small document called the Articuli super Cartas that was sent along with the charter, telling the sheriff of the county how to observe the conditions outlined in the document. One of the Bodleian's copies was displayed at San Francisco's California Palace of the Legion of Honor in 2011. Four exemplifications of the 1225 charter survive: the British Library holds one, which was preserved at Lacock Abbey until 1945; Durham Cathedral also holds a copy, with the Bodleian Library holding a third. The fourth copy of the 1225 exemplification was held by the museum of the Public Record Office and is now held by The National Archives. The Society of Antiquaries also holds a draft of the 1215 charter (discovered in 2013 in a late 13th century register from Peterborough Abbey), a copy of the 1225 third re-issue (within an early 14th century collection of statutes) and a roll copy of the 1225 reissue.
Only two exemplifications of Magna Carta are held outside England, both from 1297. One of these was purchased in 1952 by the Australian Government for £12,500 from King's School, Bruton, England. This copy is now on display in the Members' Hall of Parliament House, Canberra. The second was originally held by the Brudenell family, earls of Cardigan, before they sold it in 1984 to the Perot Foundation in the U.S.A., which in 2007 sold it to U.S. businessman David Rubenstein for US$21.3 million. Rubenstein commented "I have always believed that this was an important document to our country, even though it wasn't drafted in our country. I think it was the basis for the Declaration of Independence and the basis for the Constitution". This exemplification is now on permanent loan to the National Archives in Washington, D.C. Only two other 1297 exemplifications survive, one of which is held in the UK's National Archives.
Seven copies of the 1300 exemplification by Edward I survive, in Faversham, Oriel College, Oxford, the Bodleian Library, Durham Cathedral, Westminster Abbey, the City of London (held in the archives at the London Guildhall) and Sandwich (held in the Kent County Council archives). The Sandwich copy was rediscovered in early 2015 in a Victorian scrapbook in the town archives of Sandwich, Kent, one of the Cinque Ports. In the case of the Sandwich and Oriel College exemplifications, the copies of the Charter of the Forest originally issued with them also survive.
Clauses.
Most of the 1215 charter and later versions sought to govern the feudal rights of the Crown over the barons. Under the Angevin kings, and in particular during John's reign, the rights of the King had frequently been used inconsistently, often in an attempt to maximise the royal income from the barons. Feudal relief was one way that a king could demand money, and clauses 2 and 3 fixed the fees payable when an heir inherited an estate or when a minor came of age and took possession of his lands. Scutage was a form of medieval taxation; all knights and nobles owed military service to the Crown in return for their lands, which theoretically belonged to the King, but many preferred to avoid this service and offer money instead; the Crown often used the cash to pay for mercenaries. The rate of scutage that should be payable, and the circumstances under which it was appropriate for the King to demand it, was uncertain and controversial; clauses 12 and 14 addressed the management of the process.
The English judicial system had altered considerably over the previous century, with the royal judges playing a larger role in delivering justice across the country. John had used his royal discretion to extort large sums of money from the barons, effectively taking payment to offer justice in particular cases, and the role of the Crown in delivering justice had become politically sensitive among the barons. Clauses 39 and 40 demanded due process be applied in the royal justice system, while clause 45 required that the King appoint knowledgeable royal officials to the relevant roles. Although these clauses did not have any special significance in the original charter, this part of Magna Carta became singled out as particularly important in later centuries. In the United States, for example, the Supreme Court of California interpreted clause 45 in 1974 as establishing a requirement in common law that a defendant faced with the potential of incarceration is entitled to a trial overseen by a legally trained judge.
Royal forests were economically important in medieval England and were both protected and exploited by the Crown, supplying the King with hunting grounds, raw materials, and money. They were subject to special royal jurisdiction and the resulting forest law was, according to the historian Richard Huscroft, "harsh and arbitrary, a matter purely for the King's will". The size of the forests had expanded under the Angevin kings, an unpopular development. The 1215 charter had several clauses relating to the royal forests; clauses 47 and 48 promised to deforest the lands added to the forests under John and investigate the use of royal rights in this area, but notably did not address the forestation of the previous kings, while clause 53 promised some form of redress for those affected by the recent changes, and clause 44 promised some relief from the operation of the forest courts. Neither Magna Carta nor the subsequent Charter of the Forest proved entirely satisfactory as a way of managing the political tensions around the operation of the royal forests.
Some of the clauses addressed wider economic issues. The concerns of the barons over the treatment of their debts to Jewish moneylenders, who occupied a special position in medieval England and were by tradition under the King's protection, were addressed by clauses 10 and 11. The charter concluded this section with the phrase "debts owing to other than Jews shall be dealt with likewise", so it is debatable to what extent the Jews were being singled out by these clauses. Some issues were relatively specific, such as clause 33 which ordered the removal of all fishing weirs—an important and growing source of revenue at the time—from England's rivers.
The role of the English Church had been a matter for great debate in the years prior to the 1215 charter. The Norman and Angevin kings had traditionally exercised a great deal of power over the church within their territories. From the 1040s onwards, however, successive popes had emphasised the importance of the church being governed more effectively from Rome, and had established an independent judicial system and hierarchical chain of authority. After the 1140s, these principles had been largely accepted within the English church, even if accompanied by an element of concern about centralising authority in Rome. These changes brought the customary rights of lay rulers such as John over ecclesiastical appointments into question. As described above, John had come to a compromise with Pope Innocent III in exchange for his political support for the King, and clause 1 of Magna Carta prominently displayed this arrangement, promising the freedoms and liberties of the church. The importance of this clause may also reflect the role of Archbishop Langton in the negotiations: Langton had taken a strong line on this issue during his career.
Clauses in detail.
Magna Carta clauses in the 1215 and later charters 
Clauses remaining in English law.
Only three clauses of Magna Carta still remain on statute in England and Wales. These clauses concern the freedom of the English Church, the "ancient liberties" of the City of London (clause 13 in the 1215 charter, clause 9 in the 1297 statute), and a right to due legal process (clauses 39 and 40 in the 1215 charter, clause 29 in the 1297 statute). In detail, these clauses (using the numbering system from the 1297 statute) state that:
Usage of the definite article and spelling.
Magna Carta was given its name in Latin, a language which has no direct, consistent correlate of the English definite article "the". As a result, the usual academic convention is to refer to the document in English without the article as "Magna Carta" rather than "the Magna Carta". Nonetheless, "the Magna Carta" is frequently used in both academic and non-academic speech.
Especially in the past, the document has also been referred to as "Magna Charta", but the pronunciation was the same. "Magna Charta" is still an acceptable variant spelling recorded in many dictionaries due to continued use in some reputable sources. From the 13th to the 17th centuries, only the spelling "Magna Carta" was used. The spelling "Magna Charta" began to be used in the 18th century but never became more common despite also being used by some reputable writers.
Bibliography.
</dl>

</doc>
<doc id="20959" url="http://en.wikipedia.org/wiki?curid=20959" title="Milieu">
Milieu

Milieu may refer to:

</doc>
<doc id="20961" url="http://en.wikipedia.org/wiki?curid=20961" title="Möbius function">
Möbius function

The classical Möbius function "μ"("n") is an important multiplicative function in number theory and combinatorics. The German mathematician August Ferdinand Möbius introduced it in 1832. It is a special case of a more general object in combinatorics.
Definition.
For any positive integer "n", define "μ"("n") as the sum of the primitive n-th roots of unity. It has values in {−1, 0, 1} depending on the factorization of "n" into prime factors:
The values of "μ"("n") for the first 30 positive numbers (sequence in OEIS) are
The first 50 values of the function are plotted below:
Properties and applications.
Properties.
The Möbius function is multiplicative (i.e. whenever a and b are coprime). The sum of the Möbius function over all positive divisors of n (including n itself and 1) is zero except when :
This is because the n-th roots of unity sum to 0, and each n-th root of unity is a primitive d-th root of unity for exactly one divisor d of n.
The equality above leads to the important Möbius inversion formula and is the main reason why μ is of relevance in the theory of multiplicative and arithmetic functions.
Other applications of "μ"("n") in combinatorics are connected with the use of the Pólya enumeration theorem in combinatorial groups and combinatorial enumerations.
Mertens function.
In number theory another arithmetic function closely related to the Möbius function is the Mertens function, defined by
for every natural number n. This function is closely linked with the positions of zeroes of the Riemann zeta function. See the article on the Mertens conjecture for more information about the connection between "M"("n") and the Riemann hypothesis.
There is a formula for calculating the Möbius function without directly knowing the factorization of its argument:
i.e. "μ"("n") is the sum of the primitive n-th roots of unity. (However, the computational complexity of this definition is at least the same as of the Euler Product definition.)
From this it follows that the Mertens function is given by:
where formula_5 is the Farey sequence of order n.
This formula is used in the proof of the Franel–Landau theorem.
Proof of the formula for formula_6.
The formula given above,
is trivially true when . Suppose then that "n" > 1. Then there is a bijection between the factors d of n for which "μ"("d") ≠ 0 and the subsets of the set of all prime factors of n. The asserted result follows from the fact that every non-empty finite set has an equal number of odd- and even-cardinality subsets.
This last fact can be shown easily by induction on the cardinality |"S"| of a non-empty finite set S. First, if , there is exactly one odd-cardinality subset of S, namely S itself, and exactly one even-cardinality subset, namely ∅. Next, if |"S"| > 1, then divide the subsets of S into two subclasses depending on whether they contain or not some fixed element x in S. There is an obvious bijection between these two subclasses, pairing those subsets that have the same complement relative to the subset {"x"}. Also, one of these two subclasses consists of all the subsets of the set "S" \{"x"}, and therefore, by the induction hypothesis, has an equal number of odd- and even-cardinality subsets. These subsets in turn correspond bijectively to the even- and odd-cardinality {"x"}-containing subsets of S. The inductive step follows directly from these two bijections.
A related result is that the binomial coefficients exhibit alternating entries of odd and even power which sum symmetrically.
Applications.
Mathematical series.
The Dirichlet series that generates the Möbius function is the (multiplicative) inverse of the Riemann zeta function; if "s" is a complex number with real part larger than 1 we have
This may be seen from its Euler product
When "s" is a complex number with real part larger than 1, the Dirichlet series for the Möbius function also satisfies:
The Lambert series for the Möbius function is:
The ordinary generating function for the Möbius function follows from the binomial series
applied to triangular matrices:
Algebraic number theory.
Gauss proved that for a prime number p the sum of its primitive roots is congruent to "μ"("p" − 1) (mod "p").
If F"q" denotes the finite field of order q (where q is necessarily a prime power), then the number N of monic irreducible polynomials of degree n over F"q" is given by:
Recurrence.
A simple recurrence for calculating the Möbius function without using the modulo function, is a combination of two recurrences in a matrix formula_15:
This is a matrix starting:
Matrix inverse.
The matrix formula_15 where formula_22 is equal to formula_23 if formula_24 divides formula_25 and equal to formula_26 otherwise:
has the matrix inverse equal to formula_28 if formula_24 divides formula_25 and formula_26 otherwise:
formula_32
Average order.
The average order of the Möbius function is zero. This statement is, in fact, equivalent to the prime number theorem.
"μ"("n") sections.
"μ"("n") = 0 if and only if "n" is divisible by the square of a prime. The first numbers with this property are (sequence in OEIS):
If "n" is prime, then "μ"("n") = −1, but the converse is not true. The first non prime "n" for which μ("n") = −1 is 30 = 2·3·5. The first such numbers with three distinct prime factors (sphenic numbers) are:
and the first such numbers with 5 distinct prime factors are:
Generalizations.
Incidence algebras.
In combinatorics, every locally finite partially ordered set (poset) is assigned an incidence algebra. One distinguished member of this algebra is that poset's "Möbius function". The classical Möbius function treated in this article is essentially equal to the Möbius function of the set of all positive integers partially ordered by divisibility. See the article on incidence algebras for the precise definition and several examples of these general Möbius functions.
Popovici's function.
Popovici defined a generalised Möbius function formula_33 to be the "k"-fold Dirichlet convolution of the Möbius function with itself. It is thus again a multiplicative function with
where the binomial coefficient is taken to be zero if "a" > "k". The definition may be extended to complex "k" by reading the binomial as a polynomial in "k".
Physics.
The Möbius function also arises in the primon gas or free Riemann gas model of supersymmetry. In this theory, the fundamental particles or "primons" have energies log "p". Under second quantization, multiparticle excitations are considered; these are given by log "n" for any natural number "n". This follows from the fact that the factorization of the natural numbers into primes is unique.
In the free Riemann gas, any natural number can occur, if the primons are taken as bosons. If they are taken as fermions, then the Pauli exclusion principle excludes squares. The operator (−1)"F" that distinguishes fermions and bosons is then none other than the Möbius function "μ"("n").
The free Riemann gas has a number of other interesting connections to number theory, including the fact that the partition function is the Riemann zeta function. This idea underlies Connes's attempted proof of the Riemann hypothesis.
References.
The "Disquisitiones Arithmeticae" has been translated from Latin into English and German. The German edition includes all of his papers on number theory: all the proofs of quadratic reciprocity, the determination of the sign of the Gauss sum, the investigations into biquadratic reciprocity, and unpublished notes.
</dl>

</doc>
<doc id="20962" url="http://en.wikipedia.org/wiki?curid=20962" title="Methadone">
Methadone

Methadone (also known as Symoron, Dolophine, Amidone, Methadose, Physeptone, Heptadon and many other names) is a synthetic opioid. It is used medically as an analgesic and a maintenance anti-addictive and reductive preparation for use by patients with opioid dependence. It was developed in Germany in 1937, mainly because Germany required a reliable internal source of opioids. It is an acyclic analog of morphine and heroin. Methadone acts on the same opioid receptors as these drugs, and has many of the same effects. Methadone is also used in managing severe chronic pain, owing to its long duration of action, strong analgesic effect, and very low cost. Methadone was introduced into the United States in 1947 by Eli Lilly and Company. The number of drug-poisoning deaths involving methadone increased from 784 deaths in 1999 to 5,518 deaths in 2007; then it declined to 4,418 deaths in 2011.
Methadone is listed under Schedule II of the Single Convention On Narcotic Drugs 1961 and is regulated similarly to morphine in most countries. In the United States, it is a Schedule II Narcotic controlled substance with an ACSCN of 9250 and a 2013 annual aggregate manufacturing quota of 25 metric tons, down from just under 30 in 2012. One intermediate in the manufacturing process, 4-cyano-2-dimethylamino-4,4-diphenyl butane, is also listed as a Schedule II Narcotic Intermediate controlled substance with ACSCN 9254 and a quota of 32.5 metric tons. Levomethadone is presumably under Schedule II as an isomer of methadone. The salts of methadone in common medical use are the hydrochloride (free base conversion ratio 0.89) and hydrobromide (0.79); the tartrate was used in the past.
Methadone is mainly used in the treatment of opioid dependence. It has cross-tolerance (tolerance to similar drugs) with other opioids including heroin and morphine, and offers very similar effects but a longer duration of effect. Oral doses of methadone can stabilise patients by mitigating opioid withdrawal syndrome or making it more tolerable. Higher doses of methadone can block the euphoric effects of heroin, morphine, and similar drugs. As a result, properly dosed methadone patients can reduce or stop altogether their use of these substances.
Methadone is approved for different indications in different countries. Common is approval as an analgesic and approval for the treatment of opioid dependence. It is not intended to reduce the use of non-opioid drugs such as methamphetamine or ethanol (alcohol).
A number of pharmaceutical companies produce and distribute methadone. The racemic hydrochloride is the only form available in most countries, such as the Netherlands, Belgium, France and in the United States, as of March 2008. The dextrorotary enantiomer of methadone, dextromethadone, is an NMDA antagonist rather than an opiate agonist. 
It is on the World Health Organization's List of Essential Medicines, a list of the most important medication needed in a basic health system.
There is now an asymmetric synthesis available to prepare both levomethadone [R-(-)-methadone] and dextromethadone [S-(+)-methadone].
Medical uses.
Methadone maintenance.
Methadone is indicated for the maintenance treatment of opioid dependency (i.e. opioid use disorder per the fifth edition of the Diagnostic and Statistical Manual of Mental Disorders). A 2009 Cochrane review found that methadone was effective in retaining people in treatment and in the suppression of heroin use as measured by self-report and urine/hair analysis but did not affect criminal activity or risk of death. Methadone helps opioid dependent individuals be more social and productive in life.
The treatment of opiate-dependent persons with methadone will follow one of two routes. MMT (methadone maintenance therapy) is prescribed to individuals who wish to abstain from illicit drug use but have failed to maintain abstinence from opiates for significant periods. The duration of methadone maintenance can be for months or even years. Methadone reduction programs are suitable for addicted persons who wish to stop using drugs altogether. The length of the reduction programme will depend on the starting dose and speed of reduction, this varies from clinic to clinic and from person to person. In addition, enrollment in methadone maintenance has the potential to reduce the transmission of infectious diseases associated with opiate injection, such as hepatitis and HIV. The principal effects of methadone maintenance are to relieve narcotic craving, suppress the abstinence syndrome, and block the euphoric effects associated with opiates. When used correctly, methadone maintenance has been found to be medically safe and non-sedating. It is also indicated for pregnant women addicted to opiates.
In Russia, methadone treatment is illegal. Health officials there are not convinced of the treatment's efficacy. Instead, doctors encourage immediate cessation of drug use, rather than the gradual process that methadone substitution therapy entails. Patients are often given sedatives and non-opiate analgesics to cope with withdrawal symptoms.
Analgesic.
In recent years, methadone has gained popularity among physicians for the treatment of other medical problems, such as an analgesic in chronic pain. Due to its activity at the NMDA receptor, it may be more effective against neuropathic pain; for the same reason, tolerance to the analgesic effects may be lesser compared to other opioids. The increased usage comes as doctors search for an opioid drug that can be dosed less frequently than shorter-acting drugs like morphine or hydrocodone. Another factor in the increased usage is the low cost of methadone.
On 29 November 2006, the U.S. Food and Drug Administration issued a Public Health Advisory about methadone titled "Methadone Use for Pain Control May Result in Death and Life-Threatening Changes in Breathing and Heart Beat". The advisory went on to say that "the FDA has received reports of death and life-threatening side effects in patients taking methadone. These deaths and life-threatening side effects have occurred in patients newly starting methadone for pain control and in patients who have switched to methadone after being treated for pain with other strong narcotic pain relievers. Methadone can cause slow or shallow breathing and dangerous changes in heart beat that may not be felt by the patient." The advisory urged that physicians use caution when prescribing methadone to patients who are not used to the drug, and that patients take the drug exactly as directed.
Patients with long-term pain will sometimes have to perform so-called "opioid rotation". What this means is switching from one opioid to another, usually at intervals of between a few weeks, or more commonly, several months. Opioid rotation may allow a lower equivalent dose, and hence fewer side effects may be encountered to achieve the desired effect. Then, over time, tolerance increases with the new opioid, requiring higher doses. This in turn increases the possibility of adverse reactions and toxicity. So then it is time rotate again to another opioid. Such opioid rotation is standard practice for managing patients with tolerance development. Usually when doing opioid rotation, one cannot go down to a completely naive dose, because there is cross-tolerance carried over to the new opioid. However, methadone has a lower cross-tolerance when switching to it from other opioids, than other opioids. This means that methadone can start at a low dose, and the time for the next switch will be longer.
Opioid detoxification.
Methadone is also approved in the US for detoxification treatment of opioid addiction; however, its use in this regard must follow strict federal regulations. Outpatient treatment programs must be certified by the Federal Substance Abuse and Mental Health Services Administration (SAMHSA) and registered by the Drug Enforcement Administration (DEA) in order to prescribe methadone for opioid detoxification.
Adverse effects.
At dosage levels.
Adverse effects of methadone include:
Withdrawal symptoms.
Physical symptoms
Cognitive symptoms
Withdrawal symptoms are significantly more prolonged but also less intense than withdrawal from opiates with shorter half-lives.
When detoxing at a recommended rate (typically 1–2 mg per week), withdrawal is either minimal or nonexistent, as the patient's body has time to adjust to each reduction in dose. Unlike methadone, buprenorphine produces cognitive dehabilitation in multiple areas of mental function in both memory and timed choice task tests, which may persist after cessation of substitution treatment.
Symptoms of overdose.
Patients who have overdosed on methadone may show some of the following symptoms:
The respiratory depression of an overdose can be treated with naloxone. Naloxone is preferred to the newer, longer acting antagonist naltrexone. Despite Methadone's much longer duration of action compared to either heroin and other shorter-acting agonists, and the need for repeat doses of the antagonist naloxone, it is still used for overdose therapy. As naltrexone has a longer half-life, it is more difficult to titrate. If too large a dose of opioid antagonist is given to a dependent patient, it will result in withdrawal symptoms (possibly severe). When using naloxone, the naloxone will be quickly eliminated and the withdrawal will be short lived. Doses of naltrexone take longer to be eliminated from the patient's system. A common problem in treating methadone overdoses is that, given the short action of Naloxone (versus the extremely longer-acting Methadone), a dosage of Naloxone given to a Methadone-overdosed patient will initially work to bring the patient out of overdose, but once the Naloxone wears off, if no further Naloxone is administered, the patient can go right back into overdose (based upon time and dosage of the Methadone ingested).
Tolerance and dependence.
As with other opioid medications, tolerance and dependence usually develop with repeated doses. There is some clinical evidence that tolerance to analgesia is less with methadone compared to other opioids; this may be due to its activity at the NMDA receptor. Tolerance to the different physiological effects of methadone varies; tolerance to analgesic properties may or may not develop quickly, but tolerance to euphoria usually develops rapidly, whereas tolerance to constipation, sedation, and respiratory depression develops slowly (if ever).
Driving.
Methadone treatment may impair driving ability. Drug abuse patients had significantly more involvement in serious crashes than non-abuse patients in a study by Queensland University. In the study of a group of 220 drug abuse patients, most of them poly-drug abusers, 17 were involved in crashes killing people, compared with a control group of other patients randomly selected having no involvement in fatal crashes. However, there have been multiple studies verifying the ability of methadone maintenance patients to drive.
In the UK, persons who are prescribed oral Methadone can continue to drive after they have satisfactorily completed an independent medical examination which will include a urine screen for drugs. The licence will be issued for 12 months at a time and even then, only following a favourable assessment from their own doctor. Individuals who are prescribed methadone for either IV or IM administration cannot drive in the UK, mainly due to the increased sedation effects that this route of use can cause.
Mortality.
In the United States, deaths linked to methadone more than quadrupled in the five-year period between 1999 and 2004. According to the U.S. National Center for Health Statistics, as well as a 2006 series in the Charleston (West Virginia) Gazette,<ref name="http://www.wvgazette.com/section/Series/The+Killer+Cure"> "The Charleston Gazette" 2006</ref> medical examiners listed methadone as contributing to 3,849 deaths in 2004. That number was up from 790 in 1999. Approximately 82 percent of those deaths were listed as accidental, and most deaths involved combinations of methadone with other drugs (especially benzodiazepines).
Although deaths from methadone are on the rise, methadone-associated deaths are not being caused primarily by methadone intended for methadone treatment programs, according to a panel of experts convened by the Substance Abuse and Mental Health Services Administration, which released a report titled "Methadone-Associated Mortality, Report of a National Assessment". The consensus report concludes that "although the data remain incomplete, National Assessment meeting participants concurred that methadone tablets and/or diskettes distributed through channels other than opioid treatment programs most likely are the central factor in methadone-associated mortality."
In 2006, the U.S. Food and Drug Administration issued a caution about methadone, titled “Methadone Use for Pain Control May Result in Death.” The FDA also revised the drug's package insert. The change deleted previous information about the usual adult dosage. The "Charleston Gazette" reported, "The old language about the 'usual adult dose' was potentially deadly, according to pain specialists."
Oral health.
Methadone is sometimes administered in a sugary syrup which is swallowed. This preparation can cause significant tooth decay. Methadone also causes dry mouth (xerostomia), reducing the protective role of saliva in preventing decay. These factors combine to often cause extensive damage to the teeth in persons taking methadone.
Detection in biological fluids.
Methadone and its major metabolite, 2-ethylidene-1,5-dimethyl-3,3-diphenylpyrrolidine (EDDP), are often measured in urine as part of a drug abuse testing program, in plasma or serum to confirm a diagnosis of poisoning in hospitalized victims, or in whole blood to assist in a forensic investigation of a traffic or other criminal violation or a case of sudden death. Methadone usage history is considered in interpreting the results as a chronic user can develop tolerance to doses that would incapacitate an opioid-naive individual. Chronic users often have high methadone and EDDP baseline values.
Pharmacology.
Methadone acts by binding to the µ-opioid receptor, but also has some affinity for the NMDA ionotropic glutamate receptor. Methadone is metabolized by CYP3A4, CYP2B6, CYP2D6 and is a substrate for the P-Glycoprotein efflux protein in intestine and brain. The bioavailability and elimination half-life of methadone is subject to substantial inter-individual variability. Its main route of administration is oral. Adverse effects include sedation, hypoventilation, constipation and miosis, in addition to tolerance, dependence and withdrawal difficulties. The withdrawal period can be much more prolonged than with other opiates, spanning anywhere from two weeks to several months. Many factors contribute to its metabolism and excretion rate including the individual's body weight, history of use/abuse, metabolic dysfunctions, renal system dysfunction, among others.
Mechanism of action.
Levomethadone is a full µ-opioid agonist. Dextromethadone does not affect opioid receptors but binds to the glutamatergic NMDA (N-methyl-D-aspartate) receptor, and thus acts as a receptor antagonist against glutamate. Methadone has been shown to reduce neuropathic pain in rat models, primarily through NMDA antagonism. Glutamate is the primary excitatory neurotransmitter in the CNS. NMDA receptors have a very important role in modulating long term excitation and memory formation. NMDA antagonists such as dextromethorphan (DXM), ketamine (a dissociative anaesthetic, also M.O.A+.), tiletamine (a veterinary anaesthetic) and ibogaine (from the African tree Tabernanthe iboga, also M.O.A+.) are being studied for their role in decreasing the development of tolerance to opioids and as possible for eliminating addiction/tolerance/withdrawal, possibly by disrupting memory circuitry. Acting as an NMDA antagonist may be one mechanism by which methadone decreases craving for opioids and tolerance, and has been proposed as a possible mechanism for its distinguished efficacy regarding the treatment of neuropathic pain. The dextrorotary form (d-methadone) acts as an NMDA antagonist and is devoid of opioid activity: it has been shown to produce analgesia in experimental models of chronic pain. Methadone also acted as a potent, noncompetitive α3β4 neuronal nicotinic acetylcholine receptor antagonist in rat receptors, expressed in human embryonic kidney cell lines.
Metabolism.
Methadone has a slow metabolism and very high fat solubility, making it longer lasting than morphine-based drugs. Methadone has a typical elimination half-life of 15 to 60 hours with a mean of around 22. However, metabolism rates vary greatly between individuals, up to a factor of 100, ranging from as few as 4 hours to as many as 130 hours, or even 190 hours. This variability is apparently due to genetic variability in the production of the associated enzymes CYP3A4, CYP2B6 and CYP2D6. Many substances can also induce, inhibit or compete with these enzymes further affecting (sometimes dangerously) methadone half-life. A longer half-life frequently allows for administration only once a day in Opioid detoxification and maintenance programs. Patients who metabolize methadone rapidly, on the other hand, may require twice daily dosing to obtain sufficient symptom alleviation while avoiding excessive peaks and troughs in their blood concentrations and associated effects. This can also allow lower total doses in some such patients. The analgesic activity is shorter than the pharmacological half-life; dosing for pain control usually requires multiple doses per day.
Route of administration.
The most common route of administration at a methadone clinic is in a racemic oral solution, though in Germany, only the "R" enantiomer (the L optical isomer) has traditionally been used, as it is responsible for most of the desired opioid effects. This is becoming less common due to the higher production costs.
Methadone is available in traditional pill, sublingual tablet, and two different formulations designed for the patient to drink. Drinkable forms include ready-to-dispense liquid, and "Disket" which is a tablet designed to disperse itself in water for oral administration, used in a similar fashion to Alka-Seltzer. The liquid form is the most common as it allows for smaller dose changes. Methadone is almost as effective when administered orally as by injection. In fact, injection of methadone does not result in a "rush" as with some other strong opioids such as morphine or hydromorphone, because its extraordinarily high volume of distribution causes it to diffuse into other tissues in the body, particularly fatty tissue; the peak concentration in the blood is achieved at roughly the same time, whether the drug is injected or ingested. Injecting Methadone pills can cause collapsed veins, bruising, swelling, and possibly other harmful effects. Methadone pills often contain talc that, when injected, produces a swarm of tiny solid particles in the blood, causing numerous minor blood clots. These particles cannot be filtered out before injection, and will accumulate in the body over time, especially in the lungs and eyes, producing various complications such as pulmonary hypertension, an irreversible and progressive disease. Methadose/Methadone should not be injected either. While it has been done in extremely diluted concentrations, instances of cardiac arrest have been reported as well as damaged veins from sugar and other ingredients (Sugar-Free syrups also should not be injected). Oral medication offers safety, simplicity and represents a step away from injection-based drug abuse in those recovering from addiction. U.S. federal regulations require the oral form in addiction treatment programs.
Patient information leaflets included in packs of UK methadone tablets state that the tablets are for oral use only and that use by any other route can cause serious harm. In addition to this warning, additives have now been included into the tablets formulation to make the use of them by the IV route more difficult.
History.
Methadone was developed in 1937 in Germany by scientists working for I.G. Farbenindustrie AG at the Farbwerke Hoechst who were looking for a synthetic opioid that could be created with readily available precursors, to solve Germany's opium shortage problem. On September 11, 1941 Bockmühl and Ehrhart filed an application for a patent for a synthetic substance they called Hoechst 10820 or polamidon (a name still in regular use in Germany) and whose structure had only slight relation to morphine or the opiate alkaloids.Bockmühl and Ehrhart, 1949 It brought to market in 1943 and was widely used by the German army during WWII.
After the war, all German patents, trade names and research records were requisitioned and expropriated by the Allies. The records on the research work of the I.G. Farbenkonzern at the Farbwerke Hoechst were confiscated by the U.S. Department of Commerce Intelligence, investigated by a Technical Industrial Committee of the U.S. Department of State and then brought to the US. The report published by the committee noted that while methadone was potentially addictive, it produced less sedation and respiratory depression than morphine and was thus interesting as a commercial drug.
It was only in 1947 that the drug was given the generic name “methadone” by the Council on Pharmacy and Chemistry of the American Medical Association. Since the patent rights of the I.G. Farbenkonzern and Farbwerke Hoechst were no longer protected each pharmaceutical company interested in the formula could buy the rights for commercial production of methadone for just one dollar (MOLL 1990).
Methadone was introduced into the United States in 1947 by Eli Lilly and Company as an analgesic under the trade name Dolophine, which is now registered to Roxane Laboratories. Since then, it has been best known for its use in treating opioid dependence. A great deal of anecdotal evidence was available "on the street" that methadone might prove effective in treating heroin withdrawal and is not uncommonly used in hospitals and other de-addiction centers to enhance rates of completed opioid withdrawal. It was not until studies performed at the Rockefeller University in New York City by Professor Vincent Dole, along with Marie Nyswander and Mary Jeanne Kreek, that methadone was systematically studied as a potential substitution therapy. Their studies introduced a sweeping change in the notion that drug addiction was not necessarily a simple character flaw, but rather a disorder to be treated in the same way as other diseases. To date, methadone maintenance therapy has been the most systematically studied and most successful, and most politically polarizing, of any pharmacotherapy for the treatment of drug addiction patients.
Methadone was first manufactured in the USA by Eli Lilly, who obtained FDA approval on August 14, 1947, for their Dolophine 5 mg and 10 mg Tablets. Mallinckrodt Pharmaceuticals did not receive approval until December 15, 1947 to manufacture their bulk compounding powder. Mallinckrodt received approval for their branded generic, Methadose, on April 15, 1993 for their 5 mg and 10 mg Methadose Tablets. Mallinckrodt who also makes 5 mg, 10 mg and 40 mg generic tablets in addition to their branded generic Methadose received approval for their plain generic tablets on April 27, 2004.
The trade name Dolophine was created by Eli Lilly. The pejorative term "adolphine" (never an actual name of the drug) appeared in the United States in the early 1970s. An urban legend claims Dolophine was named for Adolf Hitler.
Society and culture.
Cost.
In Germany the annual cost per patient is less than 3000 euros, while heroin assisted treatment costs up to 10,000 euros per year.
Methadone clinics in the U.S. charge anywhere from $5–400 per week, which may be covered by private insurance or Medicaid.
MMT cost analysis often compare the cost of clinic visits versus the overall societal costs of illicit opioid use.
Controversy.
Methadone substitution as a treatment of opiate addiction has been widely criticised in the social sciences for its role in social control of addicts. It is suggested that methadone does not function as much to curb addiction as to redirect it and maintain dependency on authorised channels. Several authors apply a Foucauldian analysis to the widespread prescription of the drug and use in institutions such as prisons, hospitals and rehabilitation centres. Such critique centers on the notion that substance addiction is reframed with a disease model. Thus methadone, which mimics the effects of opioids and renders the addict compliant, is labelled as a “treatment” and so obscures the disciplinary objectives of “managing undesirables”.
Viktoria Bergschmidt cites Michel Foucault’s concept of Biopower as key to understanding the power relations inherent in methadone treatment programs. Here Foucault describes the historical shift from a sovereign’s power “symbolised by the sword and ultimately articulated in the execution of his subjects” to a power based largely on the concern for life. The mechanisms of Biopower are not those of repression and coercion but rather the normalisation and regulation of the body.
The Biopower model is particularly pertinent in the case of methadone treatments given the unique status of drug addictions in post-industrial society. The image of the "junkie" is instilled with the notion of the “abject other… marked for death” and thus is a singularly dangerous entity, requiring firm control.
Similar drugs.
There are two methadone isomers that form the racemic mixture which is more common as it is cheaper to produce. The laevorotary isomer, which is isolated by several recrystalisations from racemic methadone, is more expensive to produce than the racemate. It is more potent at the opioid receptor than the racemic mixture and is marketed especially in continental Europe as an analgesic under the trade names Levo-Polamidone, Polamidone, Heptanone, Heptadone, Heptadon and others. It is used as the hydrochloride salt almost exclusively with some uncommon pharmaceuticals and research subjects consisting of the tartrate. The dextrorotary isomer d-methadone is not commercially available. It is devoid of opioid activity and it acts as an NMDA antagonist. It has been shown to be analgesic in experimental models of chronic pain.
The closest chemical relative of methadone in clinical use is levo-α-acetylmethadol or LAAM. It has a longer duration of action (from 48 to 72 hours), permitting a reduction in frequency of use. In 1994, it was approved as a narcotic addiction treatment. In the Netherlands, like methadone and all other strong opioids, LAAM is a List I drug of the Opium Law, and in Schedule II of the United States Controlled Substances Act. LAAM has since been removed from the US and European markets due to reports of rare cardiac side effects.
Other drugs which are not structurally related to methadone are also used in maintenance treatment, particularly Subutex (buprenorphine) and Suboxone (buprenorphine combined with naloxone). With the Drug Addiction Treatment Act of 2000, qualified physicians in the U.S. were allowed to prescribe buprenorphine and other Schedule III drugs on an outpatient basis. Methadone, which is cheaper than buprenorphine, is only available from methadone clinics in the U.S.
In the Netherlands, Switzerland, the UK and a few other European countries, not only buprenorphine and oral methadone but also injectable methadone and pharmaceutical diamorphine (heroin) or other opioids may be used for outpatient maintenance treatment of opiate addiction, and treatment is generally provided in much less heavily regulated environments than in the United States. In the United Kingdom, diamorphine is used extremely selectively and is not available on prescription to addicts; except in specialist trials which involved no more than 300 participants. A study from Austria indicated that slow release oral morphine (in the form of MS-Contin), under trade names Substitol-Retard and Compensan, provide better results than oral methadone, and studies of heroin maintenance have indicated that a low background dose of methadone combined with heroin maintenance may significantly improve outcomes for less-responsive patients. Since the late 1990s in Austria, slow release oral morphine has been used alongside methadone and buprenorphine for Opioid Substitution Therapy (OST) and more recently it has been approved in Slovenia and Bulgaria, and it has gained approval in other EU nations including the United Kingdom, although its use is not yet as widespread. The more attractive side-effect profile of morphine compared to buprenorphine or methadone has led to the adoption of morphine as an option for OST treatment, and currently in Vienna over 60 percent of substitution therapy utilizes slow release oral morphine. Illicit diversion has been a problem, but to the many proponents of the utilization of morphine for OST, the benefits far outweigh the costs, taking into account the much higher percentage of addicts who are "held" or, from another perspective, satisfied by this treatment option, as opposed to methadone and buprenorphine treated addicts, who are more likely to forgo their treatment and revert to using heroin etc., in many cases by selling their methadone or buprenorphine prescriptions to afford their opiate of choice. Driving impairment tests done in the Netherlands that have shown morphine to have the least negative effects on cognitive ability on a number of mental tasks also suggest morphines use in OST may allow for better psychological functioning and engagement in society. Other opiates such as dihydrocodeine in both extended-release and immediate-release form are also sometimes used for maintenance treatment as an alternative to methadone or buprenorphine in some European countries.
Another close relative of methadone is dextropropoxyphene, first marketed in 1957 under the trade name of Darvon. Oral analgesic potency is one-half to one-third that of codeine, with 65 mg approximately equivalent to about 600 mg of aspirin. Dextropropoxyphene is prescribed for relief of mild to moderate pain. Bulk dextropropoxyphene is in Schedule II of the United States Controlled Substances Act, while preparations containing it are in Schedule IV. More than 100 tons of dextropropoxyphene are produced in the United States annually, and more than 25 million prescriptions are written for the products. Since dextropropoxyphene produces relatively modest pain relief compared to other opioids but still produces severe respiratory depression at high doses, it is particularly dangerous when abused, as drug users may take dangerously high doses in an attempt to achieve narcotic effects. This narcotic is among the top 10 drugs reported by medical examiners in recreational drug use deaths. However, dextropropoxyphene is still prescribed for the short term relief of opiate withdrawal symptoms, particularly when the aim of treatment is to smooth detoxification to a drug-free state rather than a switch to maintenance treatment.
This drug has been taken off the market in Europe and the U.S. due to concerns of fatal overdoses and abnormal heart rhythms. An estimated 10 million patients have used these products.
Other analogs of methadone which are still in clinical use are dipipanone (Diconal) and dextromoramide (Palfium) which are shorter-lasting but considerably more effective as analgesics. In the 1980s and beginning of the 1990s, before pharmaceutical grade IV heroin treatment became available to heroin addicts, as either single drug replacement for street heroin, or to be used alongside prescribed methadone, oral dextromoramide was prescribed to heroin addicts instead, because even when taken orally it still produces a strong, so called "rush", without the need of IV administration and any of the risks involved with it. These drugs have a high potential for abuse and dependence and were notorious for being widely abused and sought after by drug addicts in the 1970s. They are still rarely used for the relief of severe pain in the treatment of terminal cancer or other serious medical conditions. Different nations within the EU have different regulations, and in some nations general practitioners have the legal right to maintain addicts with whatever they deem to be most efficacious in maintaining their health and well being.

</doc>
<doc id="20963" url="http://en.wikipedia.org/wiki?curid=20963" title="Möbius inversion formula">
Möbius inversion formula

In mathematics, the classic Möbius inversion formula was introduced into number theory during the 19th century by August Ferdinand Möbius. 
Other Möbius inversion formulas are obtained when different locally finite partially ordered sets replace the classic case of the natural numbers ordered by divisibility; for an account of those, see incidence algebra.
Statement of the formula.
The classic version states that if "g" and "f" are arithmetic functions satisfying
then
where μ is the Möbius function and the sums extend over all positive divisors "d" of "n". In effect, the original "f"("n") can be determined given "g"("n") by using the inversion formula. The two sequences are said to be Möbius transforms of each other.
The formula is also correct if "f" and "g" are functions from the positive integers into some abelian group (viewed as a formula_3-module).
In the language of Dirichlet convolutions, the first formula may be written as
where "*" denotes the Dirichlet convolution, and "1" is the constant function formula_5. The second formula is then written as
Many specific examples are given in the article on multiplicative functions.
The theorem follows because formula_7 is (commutative and) associative, and formula_8, where formula_9 is the identity function for the Dirichlet convolution, taking values formula_10 for all formula_11. Thus formula_12.
Series relations.
Let
so that
is its transform. The transforms are related by means of series: the Lambert series
and the Dirichlet series:
where formula_17 is the Riemann zeta function.
Repeated transformations.
Given an arithmetic function, one can generate a bi-infinite sequence of other arithmetic functions by repeatedly applying the first summation. 
For example, if one starts with Euler's totient function formula_18, and repeatedly applies the transformation process, one obtains:
If the starting function is the Möbius function itself, the list of functions is:
Both of these lists of functions extend infinitely in both directions. The Möbius inversion formula enables these lists to be traversed backwards.
As an example the sequence starting in formula_18 is:
formula_30
The generated sequences can perhaps be more easily understood by considering the corresponding Dirichlet series: each repeated application of the transform corresponds to multiplication by the Riemann zeta function.
Generalizations.
A related inversion formula more useful in combinatorics is as follows: suppose "F"("x") and "G"("x") are complex-valued functions defined on the interval [1,∞) such that
then
Here the sums extend over all positive integers "n" which are less than or equal to "x".
This in turn is a special case of a more general form. If formula_33 is an arithmetic function possessing a Dirichlet inverse formula_34, then if one defines
then
The previous formula arises in the special case of the constant function formula_37, whose Dirichlet inverse is formula_38.
A particular application of the first of these extensions arises if we have (complex-valued) functions "f"("n") and "g"("n") defined on the positive integers, with
By defining formula_40 and formula_41, we deduce that
A simple example of the use of this formula is counting the number of reduced fractions 0 < "a"/"b" < 1, where "a" and "b" are coprime and "b"≤"n". If we let "f"("n") be this number, then "g"("n") is the total number of fractions 0 < "a"/"b" < 1 with "b"≤"n", where "a" and "b" are not necessarily coprime. (This is because every fraction "a"/"b" with gcd("a","b") = "d" and "b"≤"n" can be reduced to the fraction ("a"/"d")/("b"/"d") with "b"/"d" ≤ "n"/"d", and vice versa.) Here it is straightforward to determine "g"("n") = "n"("n"-1)/2, but "f"("n") is harder to compute.
Another inversion formula is (where we assume that the series involved are absolutely convergent):
As above, this generalises to the case where formula_33 is an arithmetic function possessing a Dirichlet inverse formula_34:
Multiplicative notation.
As Möbius inversion applies to any abelian group, it makes no difference whether the group operation is written as addition or as multiplication. This gives rise to the following notational variant of the inversion formula:
Proofs of generalizations.
The first generalization can be proved as follows. We use Iverson's convention that [condition] is the indicator function of the condition, being 1 if the condition is true and 0 if false. We use the result that formula_48, that is, 1*μ="i".
We have the following:
formula_49
The proof in the more general case where α("n") replaces 1 is essentially identical, as is the second generalisation.
Contributions of Weisner, Hall, and Rota.
The statement of the general Möbius inversion formula was first given independently by Weisner (1935) and Philip Hall (1936); both authors were motivated by group theory problems. Neither author seems to have been aware of the combinatorial implications of his work and neither developed the theory of Möbius functions. In a fundamental paper on Möbius functions, Rota showed the importance of this theory in combinatorial mathematics and gave a deep treatment of it. He noted the relation between such topics as inclusion-exclusion, classical number theoretic Möbius inversion, coloring problems and flows in networks. Since then, under the strong influence of Rota, the theory of Möbius inversion and related topics has become an active area of combinatorics.

</doc>
<doc id="20964" url="http://en.wikipedia.org/wiki?curid=20964" title="Martin Lowry">
Martin Lowry

Thomas Martin Lowry CBE FRS (; 26 October 1874 – 2 November 1936) was an English physical chemist who developed the Brønsted–Lowry acid–base theory simultaneously with and independently of Johannes Nicolaus Brønsted and was a founder-member and president (1928–1930) of the Faraday Society.
Biography.
Lowry was born in Low Moor, Bradford, West Yorkshire, England, in a Cornish family. He was the second son of the Reverend E. P. Lowry. He was educated at Kingswood School, Bath, Somerset, and then at the Central Technical College in South Kensington. During those years he realized that he wanted to be a chemist. He studied chemistry under Henry Edward Armstrong, an English chemist whose interests were primarily in organic chemistry but also included the nature of ions in aqueous solutions. From 1896 to 1913 Lowry was assistant to Armstrong, and between 1904 and 1913 worked as Lecturer in Chemistry at the Westminster Training College. In 1913, he was appointed head of the chemical department in Guy’s Hospital Medical and became the first teacher of chemistry in a Medical School to be made a University Professor, at the University of London. From 1920 till his death, Lowry served as the Chair of Physical
Chemistry at the University of Cambridge. He married a daughter of the Rev. C. Wood in 1904 and was survived by his widow, two sons and a daughter.
Since the establishment of the Faraday Society in 1903, Lowry had been its active member and served as its President between 1928 and 1930. In 1914 he was elected a Fellow of the Royal Society. During and after the World War I, Lowry acted as Director of Shell-filling (1917–1919) and worked for the Trench Warfare Committee, Chemical Warfare Committee and Ordnance Committee. For this service, he was awarded the Order of the British Empire and the Order of Saints Maurice and Lazarus.
Research.
In 1898, Lowry noted the change in optical rotation on nitro-"d"-camphor with time and invented the term "mutarotational" to describe this phenomenon. He studied changes in optical rotation caused by acid- and base-catalyzed reactions of camphor derivatives. This led in 1923 to his formulation of the protonic definition of acids and bases, now known as Brønsted–Lowry acid-base theory, independently of the work by Johannes Nicolaus Brønsted. Lowry published a few hundred papers and several books. His 1935 monograph on "Optical Rotatory Power" (1935) has long been regarded as a standard work on the subject.

</doc>
<doc id="20966" url="http://en.wikipedia.org/wiki?curid=20966" title="Marvel Comics">
Marvel Comics

Marvel Worldwide Inc., commonly referred to as Marvel Comics and formerly Marvel Publishing, Inc. and Marvel Comics Group, is an American publisher of comic books and related media. In 2009, The Walt Disney Company acquired Marvel Entertainment, Marvel Worldwide's parent company. 
Marvel started in 1939 as Timely Publications, and by the early 1950s had generally become known as Atlas Comics. Marvel's modern incarnation dates from 1961, the year that the company launched "The Fantastic Four" and other superhero titles created by Stan Lee, Jack Kirby, Steve Ditko, and many others.
Marvel counts among its characters such well-known properties as Spider-Man, Wolverine, Iron Man, Captain America, the Hulk, Thor, the Silver Surfer, Daredevil, and Ghost Rider, such teams as the Avengers, the Fantastic Four, the Guardians of the Galaxy, and X-Men, and antagonists such as Doctor Octopus, Green Goblin, Kingpin, Magneto, Doctor Doom, Loki, Thanos, and the Red Skull. Most of Marvel's fictional characters operate in a single reality known as the Marvel Universe, with locations that mirror real-life cities. Characters such as Spider-Man, the Fantastic Four, the Avengers, Daredevil, and Dr. Strange are based in New York City, whereas the X-Men have historically been based in Salem Center, New York, and the Hulk's stories often have been set in the American Southwest.
In 2013, Marvel held a 33.50% share of the comics market, compared to its competitor DC Comics' 30.33% share. By comparison, the companies held 40.81% and 29.94% shares in 2008.
History.
Timely Publications.
Martin Goodman founded the company later known as Marvel Comics under the name Timely Publications in 1939. Goodman, a pulp magazine publisher who had started with a Western pulp in 1933, was expanding into the emerging—and by then already highly popular—new medium of comic books. Launching his new line from his existing company's offices at 330 West 42nd Street, New York City, he officially held the titles of editor, managing editor, and business manager, with Abraham Goodman officially listed as publisher.
Timely's first publication, "Marvel Comics" #1 (cover dated Oct. 1939), included the first appearance of Carl Burgos' android superhero the Human Torch, and the first appearances of Bill Everett's anti-hero Namor the Sub-Mariner, among other features. The issue was a great success, with it and a second printing the following month selling, combined, nearly 900,000 copies. While its contents came from an outside packager, Funnies, Inc., Timely had its own staff in place by the following year. The company's first true editor, writer-artist Joe Simon, teamed with artist and emerging industry notable Jack Kirby to create one of the first patriotically themed superheroes, Captain America, in "Captain America Comics" #1 (March 1941) It, too, proved a hit, with sales of nearly one million. Goodman formed Timely Comics, Inc., beginning with comics cover-dated April 1941 or Spring 1941.
While no other Timely character would achieve the success of these "big three", some notable heroes—many of which continue to appear in modern-day retcon appearances and flashbacks—include the Whizzer, Miss America, the Destroyer, the original Vision, and the Angel. Timely also published one of humor cartoonist Basil Wolverton's best-known features, "Powerhouse Pepper", as well as a line of children's funny-animal comics featuring popular characters like Super Rabbit and the duo Ziggy Pig and Silly Seal.
Goodman hired his wife's cousin, Stanley Lieber, as a general office assistant in 1939. When editor Simon left the company in late 1941, Goodman made Lieber—by then writing pseudonymously as "Stan Lee"—interim editor of the comics line, a position Lee kept for decades except for three years during his military service in World War II. Lee wrote extensively for Timely, contributing to a number of different titles.
Goodman's business strategy involved having his various magazines and comic books published by a number of corporations all operating out of the same office and with the same staff. One of these shell companies through which Timely Comics was published was named Marvel Comics by at least "Marvel Mystery Comics" #55 (May 1944). As well, some comics' covers, such as "All Surprise Comics" #12 (Winter 1946–47), were labeled "A Marvel Magazine" many years before Goodman would formally adopt the name in 1961.
Atlas Comics.
The post-war American comic market saw superheroes falling out of fashion. Goodman's comic book line dropped them for the most part and expanded into a wider variety of genres than even Timely had published, featuring horror, Westerns, humor, funny animal, men's adventure-drama, giant monster, crime, and war comics, and later adding jungle books, romance titles, espionage, and even medieval adventure, Bible stories and sports.
Goodman began using the globe logo of the Atlas News Company, the newsstand-distribution company he owned, on comics cover-dated November 1951 even though another company, Kable News, continued to distribute his comics through the August 1952 issues. This globe branding united a line put out by the same publisher, staff and freelancers through 59 shell companies, from Animirth Comics to Zenith Publications.
Atlas, rather than innovate, took a proven route of following popular trends in television and movies—Westerns and war dramas prevailing for a time, drive-in movie monsters another time—and even other comic books, particularly the EC horror line. Atlas also published a plethora of children's and teen humor titles, including Dan DeCarlo's "Homer the Happy Ghost" (à la "Casper the Friendly Ghost") and "Homer Hooper" (à la Archie Andrews). Atlas unsuccessfully attempted to revive superheroes from late 1953 to mid-1954, with the Human Torch (art by Syd Shores and Dick Ayers, variously), the Sub-Mariner (drawn and most stories written by Bill Everett), and Captain America (writer Stan Lee, artist John Romita Sr.). Atlas did not achieve any breakout hits and, according to Stan Lee, Atlas survived chiefly because it produced work quickly, cheaply, and at a passable quality.
Marvel Comics.
The first modern comic books under the Marvel Comics brand were the science-fiction anthology "Journey into Mystery" #69 and the teen-humor title "Patsy Walker" #95 (both cover dated June 1961), which each displayed an "MC" box on its cover. Then, in the wake of DC Comics' success in reviving superheroes in the late 1950s and early 1960s, particularly with the Flash, Green Lantern, and other members of the team the Justice League of America, Marvel followed suit.
The introduction of modern Marvel's first superhero team, in "The Fantastic Four" #1 (Nov. 1961), began establishing the company's reputation. The company still continued to publish a smattering of Western comics such as "Rawhide Kid", humor comics such as "Millie the Model", and added the war comic "Sgt. Fury and his Howling Commandos" to its lineup.
Marvel editor-writer Lee and freelance artist-writer Jack Kirby's Fantastic Four originated in a Cold War culture that led their creators to revise the superhero conventions of previous eras to better reflect the psychological spirit of their age. Eschewing such comic book tropes as secret identities and even costumes at first, having a monster as one of the heroes, and having its characters bicker and complain in what was later called a "superheroes in the real world" approach, the series represented a change that proved to be a great success. Marvel began publishing further superhero titles featuring such heroes and antiheroes as the Hulk, Spider-Man, Thor, Ant-Man, Iron Man, the X-Men, Daredevil, and the Silver Surfer, and such memorable antagonists as Doctor Doom, Magneto, Galactus, Loki, the Green Goblin, and Doctor Octopus, all existing in a shared reality known as the Marvel Universe, with locations that mirror real-life cities such as New York, Los Angeles and Chicago.
Lee and Steve Ditko generated the most successful new series in "The Amazing Spider-Man". Marvel even lampooned itself and other comics companies in a parody comic, "Not Brand Echh" (a play on Marvel's dubbing of other companies as "Brand Echh", à la the then-common phrase "Brand X").
Marvel's comics had a reputation for focusing on characterization to a greater extent than most superhero comics before them. This applied to "The Amazing Spider-Man" in particular. Its young hero suffered from self-doubt and mundane problems like any other teenager. Marvel often presents flawed superheroes, freaks, and misfits—unlike the perfect, handsome, athletic heroes found in previous traditional comic books. Some Marvel heroes looked like villains and monsters. In time, this non-traditional approach would revolutionize comic books. This naturalistic approach even extended into topical politics. Comics historian Mike Benton wrote,
In the world of [rival DC Comics'] Superman comic books, communism did not exist. Superman rarely crossed national borders or involved himself in political disputes. From 1962 to 1965, there were more communists [in Marvel Comics] than on the subscription list of "Pravda". Communist agents attack Ant-Man in his laboratory, red henchmen jump the Fantastic Four on the moon, and Viet Cong guerrillas take potshots at Iron Man.
This struck a chord with readers in a way not seen before. In 1965, Spider-Man and the Hulk were both featured in "Esquire" magazine's list of 28 college campus heroes, alongside John F. Kennedy and Bob Dylan. In 2009 writer Geoff Boucher reflected that, "Superman and DC Comics instantly seemed like boring old Pat Boone; Marvel felt like The Beatles and the British Invasion. It was Kirby's artwork with its tension and psychedelia that made it perfect for the times—or was it Lee's bravado and melodrama, which was somehow insecure and brash at the same time?"
Cadence Industries ownership.
In 1968, while selling 50 million comic books a year, company founder Goodman revised the constraining distribution arrangement with Independent News he had reached under duress during the Atlas years, allowing him now to release as many titles as demand warranted. Late that year he sold Marvel Comics and his other publishing businesses to the Perfect Film and Chemical Corporation, which grouped them as the subsidiary Magazine Management Company, with Goodman remaining as publisher. In 1969, Goodman finally ended his distribution deal with Independent by signing with Curtis Circulation Company.
In 1971, the United States Department of Health, Education, and Welfare approached Marvel Comics editor-in-chief Stan Lee to do a comic book story about drug abuse. Lee agreed and wrote a three-part Spider-Man story portraying drug use as dangerous and unglamorous. However, the industry's self-censorship board, the Comics Code Authority, refused to approve the story because of the presence of narcotics, deeming the context of the story irrelevant. Lee, with Goodman's approval, published the story regardless in "The Amazing Spider-Man" #96–98 (May–July 1971), without the Comics Code seal. The market reacted well to the storyline, and the CCA subsequently revised the Code the same year.
Goodman retired as publisher in 1972 and installed his son, Chip, as publisher, Shortly thereafter, Lee succeeded him as publisher and also became Marvel's president for a brief time. During his time as president, he appointed as editor-in-chief Roy Thomas, who added "Stan Lee Presents" to the opening page of each comic book.
A series of new editors-in-chief oversaw the company during another slow time for the industry. Once again, Marvel attempted to diversify, and with the updating of the Comics Code achieved moderate to strong success with titles themed to horror ("The Tomb of Dracula"), martial arts, "("), sword-and-sorcery ("Conan the Barbarian", "Red Sonja"), satire ("Howard the Duck") and science fiction ("", "Killraven" in "Amazing Adventures", "Star Trek", and, late in the decade, the long-running "Star Wars" series). Some of these were published in larger-format black and white magazines, under its Curtis Magazines imprint. Marvel was able to capitalize on its successful superhero comics of the previous decade by acquiring a new newsstand distributor and greatly expanding its comics line. Marvel pulled ahead of rival DC Comics in 1972, during a time when the price and format of the standard newsstand comic were in flux. Goodman increased the price and size of Marvel's November 1971 cover-dated comics from 15 cents for 36 pages total to 25 cents for 52 pages. DC followed suit, but Marvel the following month dropped its comics to 20 cents for 36 pages, offering a lower-priced product with a higher distributor discount.
Goodman, now disconnected from Marvel, set up a new company called Seaboard Periodicals in 1974, reviving Marvel's old Atlas name for a new Atlas Comics line, but this lasted only a year and a half.
In the mid-1970s a decline of the newsstand distribution network affected Marvel. Cult hits such as "Howard the Duck" fell victim to the distribution problems, with some titles reporting low sales when in fact the first specialty comic book stores resold them at a later date. But by the end of the decade, Marvel's fortunes were reviving, thanks to the rise of direct market distribution—selling through those same comics-specialty stores instead of newsstands.
Marvel held its own comic book convention, Marvelcon '75, in spring 1975, and promised a Marvelcon '76. At the 1975 event, Stan Lee used a Fantastic Four panel discussion to announce that Jack Kirby, the artist co-creator of most of Marvel's signature characters, was returning to Marvel after having left in 1970 to work for rival DC Comics. In October 1976, Marvel, which already licensed reprints in different countries, including the UK, created a superhero specifically for the British market. Captain Britain debuted exclusively in the UK, and later appeared in American comics.
In 1978, Jim Shooter became Marvel's editor-in-chief. Although a controversial personality, Shooter cured many of the procedural ills at Marvel, including repeatedly missed deadlines. During Shooter's nine-year tenure as editor-in-chief, Chris Claremont and John Byrne's run on the "Uncanny X-Men" and Frank Miller's run on "Daredevil" became critical and commercial successes. Shooter brought Marvel into the rapidly evolving direct market, institutionalized creator royalties, starting with the Epic Comics imprint for creator-owned material in 1982; introduced company-wide crossover story arcs with "Contest of Champions" and "Secret Wars"; and in 1986 launched the ultimately unsuccessful New Universe line to commemorate the 25th anniversary of the Marvel Comics imprint. Star Comics, a children-oriented line differing from the regular Marvel titles, was briefly successful during this period.
Despite Marvel's successes in the early 1980s, it lost ground to rival DC in the latter half of the decade as many former Marvel stars defected to the competitor. DC scored critical and sales victories with titles and limited series such as "Watchmen", "", "Crisis on Infinite Earths", Byrne's revamp of Superman, and Alan Moore's "Swamp Thing".
Marvel Entertainment Group ownership.
In 1986, Marvel's parent, Marvel Entertainment Group, was sold to New World Entertainment, which within three years sold it to MacAndrews and Forbes, owned by Revlon executive Ronald Perelman.
Marvel earned a great deal of money and recognition during the comic book boom of the early 1990s, launching the successful 2099 line of comics set in the future ("Spider-Man 2099", etc.) and the creatively daring though commercially unsuccessful Razorline imprint of superhero comics created by novelist and filmmaker Clive Barker. In 1990, Marvel began selling Marvel Universe Cards with trading card maker SkyBox International. These were collectible trading cards that featured the characters and events of the Marvel Universe. The 1990s saw the rise of variant covers, cover enhancements, swimsuit issues, and company-wide crossovers that affected the overall continuity of the fictional Marvel Universe
Marvel suffered a blow in early 1992, when seven of its most prized artists—Todd McFarlane (known for his work on ""), Jim Lee ("X-Men"), Rob Liefeld ("X-Force"), Marc Silvestri ("Wolverine"), Erik Larsen ("The Amazing Spider-Man"), Jim Valentino ("Guardians of the Galaxy"), and Whilce Portacio—left to form Image Comics.
In 1996, Marvel had almost all its titles participate in the "Onslaught Saga", a crossover that allowed Marvel to relaunch some of its flagship, and now flagging, characters such as the Avengers and the Fantastic Four, and outsource them to the studios of two of the former Marvel artists turned Image Comics founders, Jim Lee and Rob Liefeld. The relaunched titles were a solid success amidst a generally struggling industry, but Marvel discontinued the experiment after a one-year run and returned the characters to the Marvel Universe proper. In 1998, the company launched the imprint Marvel Knights, taking place within Marvel continuity; helmed by soon-to-become editor-in-chief Joe Quesada, it featured tough, gritty stories showcasing such characters as the Inhumans, Black Panther and Daredevil.
In late 1994, Marvel acquired the comic book distributor Heroes World Distribution to use as its own exclusive distributor. As the industry's other major publishers made exclusive distribution deals with other companies, the ripple effect resulted in the survival of only one other major distributor in North America, Diamond Comic Distributors Inc. In early 1997, when Marvel's Heroes World endeavor failed, Diamond also forged an exclusive deal with Marvel—giving the company its own section of its comics catalog "Previews".
In 1991 Ronald Perelman, whose company, Andrews Group, had purchased Marvel Comic's Parent corporation, Marvel Entertainment Group (MEG) in 1989, took the company public. Following the rapid rise of this stock, Perelman issued a series of junk bonds that he used to acquire other entertainment companies, secured by MEG stock. Then, by the middle of the decade, the industry had slumped, and in December 1996 Marvel filed for Chapter 11 bankruptcy protection.
Marvel Enterprises.
In 1997, Toy Biz and MEG merged to end the bankruptcy, forming a new corporation, Marvel Enterprises. With his business partner Avi Arad, publisher Bill Jemas, and editor-in-chief Bob Harras, Toy Biz co-owner Isaac Perlmutter helped stabilize the comics line.
With the new millennium, Marvel Comics emerged from bankruptcy and again began diversifying its offerings. In 2001, Marvel withdrew from the Comics Code Authority and established its own Marvel Rating System for comics. The first title from this era to not have the code was "X-Force" #119 (October 2001). Marvel also created new imprints, such as MAX (an explicit-content line) and Marvel Adventures (developed for child audiences). In addition, the company created an alternate universe imprint, Ultimate Marvel, that allowed the company to reboot its major titles by revising and updating its characters to introduce to a new generation.
Some of its characters have been turned into successful film franchises, such as the "Men in Black" movie series, starting in 1997, "Blade" movie series, starting in 1998, "X-Men" movie series, starting in 2000, and the highest grossing series "Spider-Man", beginning in 2002.
In a cross-promotion, the November 1, 2006, episode of the CBS soap opera "The Guiding Light", titled "She's a Marvel", featured the character Harley Davidson Cooper (played by Beth Ehlers) as a superheroine named the Guiding Light. The character's story continued in an eight-page backup feature, "A New Light", that appeared in several Marvel titles published November 1 and 8. Also that year, Marvel created a wiki on its Web site.
In late 2007 the company launched Marvel Digital Comics Unlimited, a digital archive of over 2,500 back issues available for viewing, for a monthly or annual subscription fee.
In 2009 Marvel Comics closed its Open Submissions Policy, in which the company had accepted unsolicited samples from aspiring comic book artists, saying the time-consuming review process had produced no suitably professional work. The same year, the company commemorated its 70th anniversary, dating to its inception as Timely Comics, by issuing the one-shot "Marvel Mystery Comics 70th Anniversary Special" #1 and a variety of other special issues.
Disney conglomerate unit.
On August 31, 2009, The Walt Disney Company announced a deal to acquire Marvel Comics' parent corporation, Marvel Entertainment, for $4 billion or $4.2 billion, with Marvel shareholders to receive $30 and 0.745 Disney shares for each share of Marvel they own. As of 2008, Marvel and its major, longtime competitor DC Comics shared over 80% of the American comic-book market. As of September 2010, Marvel switched its bookstores distribution company from Diamond Book Distributors to Hachette Distribution Services.
Marvel relaunched the CrossGen imprint, owned by Disney Publishing Worldwide, in March 2011. Marvel and Disney Publishing began jointly publishing "Disney/Pixar Presents" magazine that May.
Marvel discontinued its Marvel Adventures imprint in March 2012, and replaced them with a line of two titles connected to the Marvel Universe TV block. Also in March, Marvel announced its Marvel ReEvoultion initiative that included Infinite Comics, a line of digital comics, Marvel AR, an application software that provides an augmented reality experience to readers and Marvel NOW!, a relaunch of most of the company's major titles with different creative teams. Marvel NOW! also saw the debut of new flagship titles including "Uncanny Avengers" and "All-New X-Men".
A couple of joint comic projects were announced by Marvel and other Disney conglomerate components in 2013. With ABC, a "Once Upon a Time" graphic novel was announced in April to be published on September 4. With Disney, the company announced in October 2013 that in January 2014 its first title under their joint "Disney Kingdoms" imprint "Seekers of the Weird", a five issue miniseries, would be released. On January 3, 2014, Disney, via Marvel's corporate sibling Lucasfilm Limited, LLC (owners of the Star Wars and Indiana Jones franchises), announced that as of 2015, "Star Wars" comics would once again be published by Marvel.
Officers.
Editors-in-chief.
Marvel's chief editor originally held the title of "editor". This head editor's title later became "editor-in-chief". Joe Simon was the company's first true chief-editor, with publisher Martin Goodman, who had served as titular editor only and outsourced editorial operations.
In 1994 Marvel briefly abolished the position of editor-in-chief, replacing Tom DeFalco with five group editors-in-chief. As Carl Potts described the 1990s editorial arrangement:
In the early '90s, Marvel had so many titles that there were three Executive Editors, each overseeing approximately 1/3 of the line. Bob Budiansky was the third Executive Editor [following the previously appointed Mark Gruenwald and Potts]. We all answered to Editor-in-Chief Tom DeFalco and Publisher Mike Hobson. All three Executive Editors decided not to add our names to the already crowded credits on the Marvel titles. Therefore it wasn't easy for readers to tell which titles were produced by which Executive Editor ... In late '94, Marvel reorganized into a number of different publishing divisions, each with its own Editor-in-Chief.
Marvel reinstated the overall editor-in-chief position in 1995 with Bob Harras.
Offices.
Located in New York City, Marvel has had successive headquarters:
Marvel characters in other media.
Marvel characters and stories have been adapted to many other media. Some of these adaptations were produced by Marvel Comics and its sister company, Marvel Studios, while others were produced by companies licensing Marvel material.
Games.
In 2014, the Japanese TV series was launched together with a collectible game called Bachicombat, a game similar to Pogs, by Bandai.
Collectible card.
The RPG industry brought the development of the Collectible card game (CCG) in the early 1990s which there were soon Marvel characters were featured in CCG of their own starting in 1995 with Fleer's OverPower (1995-1999). Later collectible card game were:
Role-playing.
TSR published the pen-and-paper role-playing game Marvel Super Heroes in 1984. TSR then released in 1998 the "Marvel Super Heroes Adventure Game" which used a different system than their first game. In 2003 Marvel Publishing published its own role-playing game, the "Marvel Universe Roleplaying Game".
In August 2011 Margaret Weis Productions announced it was developing a tabletop role-playing game based on the Marvel universe, set for release in February 2012.
Video games.
Video games based on Marvel characters go back to 1984 and the Atari game, Spider-Man. Since then several dozen video games have been released and all have been produced by outside licensees. In 2014, was released that brought Marvel characters to the existing Disney sandbox video game.
Films.
As of the start of the 2013 summer movie season, films based on Marvel's properties represent the highest-grossing U.S. franchise, having grossed over $5.4 billion as part of a worldwide gross of over $12 billion.
Prose novels.
Marvel first licensed two prose novels to Bantam Books, who printed "The Avengers Battle the Earth Wrecker" by Otto Binder (1967) and "Captain America: The Great Gold Steal" by Ted White (1968). Various publishers took up the licenses from 1978 to 2002. Also, with the various licensed films being released beginning in 1997, various publishers put out movie novelizations. In 2003, following publication of the prose young adult novel "Mary Jane", starring Mary Jane Watson from the Spider-Man mythos, Marvel announced the formation of the publishing imprint Marvel Press. However, Marvel moved back to licensing with Pocket Books from 2005 to 2008. With few books issued under the imprint, Marvel and Disney Books Group relaunched Marvel Press in 2011 with the Marvel Origin Storybooks line.
Television programs.
Many television series, both live-action and animated, have based their productions on Marvel Comics characters. These include multiple series for popular characters such as Spider-Man, Iron Man and the X-Men. Additionally, a handful of television movies, usually also pilots, based on Marvel Comics characters have been made.
Theme parks.
Marvel has licensed its characters for theme-parks and attractions, including at the Universal Orlando Resort's Islands of Adventure, in Orlando, Florida, which includes rides based on their iconic characters and costumed performers. Universal theme parks in California and Japan also have Marvel rides.
Walt Disney Parks and Resorts plans on creating original Marvel attractions at their theme parks, with Hong Kong Disneyland becoming the first Disney theme park to feature a Marvel attraction.

</doc>
<doc id="20970" url="http://en.wikipedia.org/wiki?curid=20970" title="Matthew F. Hale">
Matthew F. Hale

Matthew "Matt" F. Hale (born July 27, 1971) was the third Pontifex Maximus (Latin for "highest priest") of the nontheistic and ethnocentric religion, Creativity, and the founder of the group formerly known as the World Church of the Creator and now known as The Creativity Movement. The organization's headquarters were based in East Peoria, Illinois. In 1998, Hale made headlines when his application for an Illinois law license was denied due to his religious beliefs in Creativity, described as a "gross deficiency in moral character". On April 6, 2005, Hale was sentenced to a 40-year prison term for soliciting an undercover FBI informant to kill federal judge Joan Lefkow. He is currently incarcerated in the Administrative Maximum facility in Florence, Colorado, as Inmate number 15177-424.
Early life.
Hale was raised in East Peoria, Illinois, a city on the Illinois River. By the age of 12, he was reading books about National Socialism such as Adolf Hitler's "Mein Kampf", and had formed a group at school.
In August 1989, Hale entered Bradley University, studying political science. In September 1989, Hale began writing editorials in the college newspaper, the "Bradley Scout", espousing his views on White Separatism. A student at Bradley, Robert Bingham, also a political science major, began a debate in the college newspaper editorial about civil rights and the Ku Klux Klan. Upon coming out to give his surname, Matt Hale invited the Ku Klux Klan to the campus of Bradley in the spring of 1990; that same year, he was expelled from Bradley. At the age of 19, Hale burned an Israeli flag at a demonstration and was found guilty of violating an East Peoria ordinance against open burning. The next year, he passed out racist pamphlets to patrons at a shopping mall and was fined for littering. In May 1991, Hale and his brother allegedly threatened three African-Americans with a gun, and he was arrested for mob action. Since he refused to tell police where his brother was, Hale was also charged with felony obstruction of justice; he was convicted of obstruction, but won a reversal on appeal. In 1992, Hale attacked a security guard at a mall and was charged with criminal trespass, resisting arrest, aggravated battery and carrying a concealed weapon. For this attack, Hale was sentenced to 30 months probation and six months house arrest.
In 1993, Hale graduated from Bradley University and received a degree in political science. In 1996, Hale founded the New Church of the Creator, a revival of Ben Klassen's religious group, which believes that the white race are the creators of all worthwhile civilization. The church believes that a "racial holy war" is necessary to attain a "white world" without Jews and non-whites and to this end it encourages its members to "populate the lands of this earth with white people exclusively".
After Hale was appointed "Pontifex Maximus" (supreme leader), he changed the name of the organization to the World Church of the Creator. The name was again changed to the Creativity Movement when a religious group in Oregon (the Church of the Creator) sued Hale's group for trademark infringement.
Controversy over law license.
Hale graduated from Southern Illinois University School of Law in May 1998 and passed the bar in July of that same year. On December 16, 1998, the Illinois Bar Committee on Character and Fitness rejected Hale's application for a license to practice law. Hale appealed, and a hearing was held on April 10, 1999. On June 30, 1999, a Hearing Panel of the Committee refused to certify that Hale had the requisite moral character and fitness to practice law in Illinois. Attorney Glenn Greenwald (subsequently turned journalist) represented Hale in a failed federal lawsuit to overturn the licensing decision. The U.S. District Court for the Northern District of Illinois concluded it did not have jurisdiction to review an earlier decision of the Illinois Supreme Court upholding the license denial. The Seventh Circuit Court of Appeals upheld that decision in an opinion filed on July 14th, 2003.
Two days after Hale was denied a license to practice law, a World Church of the Creator member and college student, Benjamin Smith, resigned from The Church and went on a three-day shooting spree in which he randomly targeted members of racial and ethnic minority groups in Illinois and Indiana. Beginning on July 2, 1999, Smith shot nine Orthodox Jews while they were walking to and from their synagogues in Chicago's West Rogers Park neighborhood, killed two people, including former Northwestern University basketball coach Ricky Byrdsong, in Evanston, Illinois, and a 26-year-old Korean graduate student, Won-Joon Yoon, who was shot as he was on his way to church in Bloomington, Indiana. Smith wounded nine others before committing suicide on July 4. Mark Potok, director of intelligence for the Southern Poverty Law Center, believes that Smith may have acted in retaliation after Hale's application to practice law was rejected.
According to Hale, America should only be occupied by whites. During a television interview that summer, Hale stated that his church didn't condone violent or illegal activities.
Federal convictions.
In late 2002, Hale filed a class action lawsuit against Judge Joan Lefkow, the United States district court judge presiding over his trademark case. Again in late 2002 and prior to his arrest, Hale denounced Lefkow in a news conference, claiming that she was biased against him because she was married to a Jewish man and had grandchildren who were biracial.
On January 8, 2003, Hale was arrested, charged with soliciting an undercover FBI informant to kill Lefkow.
On February 28, 2005, Lefkow's mother and husband were murdered at her home on Chicago's North Side. Chicago Police revealed on March 10 that Bart Ross, a plaintiff in a medical malpractice case that Lefkow had dismissed, admitted to the murders in a suicide note written before shooting himself during a routine traffic stop in Wisconsin the previous evening. The murders and suicide had no connection to Hale or Creativity.
On April 6, 2005, Hale was sentenced to a 40-year prison term for his conviction for attempting to solicit the murder of Lefkow.
Hale's projected release date is December 6, 2037. He will be 66 years old upon his release.

</doc>
<doc id="20971" url="http://en.wikipedia.org/wiki?curid=20971" title="Meritocracy">
Meritocracy

Meritocracy ("merit", from Latin "mereō" "earn" and "-cracy", from Ancient Greek κράτος "kratos" "strength, power") is a political philosophy which holds that power should be vested in individuals almost exclusively according to merit. Advancement in such a system is based on intellectual talent measured through examination and/or demonstrated achievement in the field where it is implemented.
Definitions.
Early definitions.
The "most common definition of meritocracy conceptualizes merit in terms of tested competency and ability, and most likely, as measured by IQ or standardized achievement tests." In government or other administration systems, meritocracy, in an administrative sense, is a system of government or other administration (such as business administration) wherein appointments and responsibilities are assigned to individuals based upon their "merits", namely intelligence, credentials, and education, determined through evaluations or examinations.
Supporters of meritocracies do not necessarily agree on the nature of "merit"; however, they do tend to agree that "merit" itself should be a primary consideration during evaluation.
In a more general sense, meritocracy can refer to any form of government based on achievement. Like "utilitarian" and "pragmatic", the word "meritocratic" has also developed a broader definition, and may be used to refer to any government run by "a ruling or influential class of educated or able people."
This is in contrast to the original, condemnatory use of the term by Michael Young in 1958, who defined it as a system where "merit is equated with intelligence-plus-effort, its possessors are identified at an early age and selected for appropriate intensive education, and there is an obsession with quantification, test-scoring, and qualifications."
Meritocracy in its wider sense, may be any general act of judgment upon the basis of various demonstrated merits; such acts frequently are described in sociology and psychology. Thus, the merits may extend beyond intelligence and education to any mental or physical talent or to work ethic.
In rhetoric, the demonstration of one's merit regarding mastery of a particular subject is an essential task most directly related to the Aristotelian term "Ethos". The equivalent Aristotelian conception of meritocracy is based upon aristocratic or oligarchical structures, rather than in the context of the modern state.
More recent definitions.
Although meritocracy as a term is a relatively recently coined word (1958), the concept of a government based on standardized examinations originates from the works of Confucius, along with other Legalist and Confucian philosophers. The first meritocracy was implemented in the second century BC, by the Han Dynasty, which introduced the world's first civil service exams evaluating the "merit" of officials. Meritocracy as a concept spread from China to British India during the seventeenth century, and then into continental Europe and the United States.
With the translation of Confucian texts during the Enlightenment, the concept of a meritocracy reached intellectuals in the West, who saw it as an alternative to the traditional "ancient regime" of Europe. In the United States, the assassination of President Garfield in 1881 prompted the replacement of the American Spoils System with a meritocracy. In 1883, The Pendleton Civil Service Reform Act was passed, stipulating government jobs should be awarded on the basis of merit through competitive exams, rather than ties to politicians or political affiliation.
The most common form of meritocratic screening found today is the college degree. Higher education is an imperfect meritocratic screening system for various reasons, such as lack of uniform standards worldwide, lack of scope (not all occupations and processes are included), and lack of access (some talented people never have an opportunity to participate because of the expense, most especially in developing countries). Nonetheless, academic degrees serve some amount of meritocratic screening purpose in the absence of a more refined methodology. Education alone, however, does not constitute a complete system, as meritocracy must automatically confer power and authority, which a degree does not accomplish independently.
Etymology.
Although the concept has existed for centuries, the term "meritocracy" was first coined in the 1950s. It was used by British politician and sociologist Michael Young in his 1958 satirical essay "The Rise of the Meritocracy", which pictured the United Kingdom under the rule of a government favouring intelligence and aptitude (merit) above all else, being the combination of the root of Latin origin "merit" (from "mereō") and the Ancient Greek suffix "-cracy" (meaning "power", "rule").
In this book the term had distinctly negative connotations as Young questioned both the legitimacy of the selection process used to become a member of this elite and the outcomes of being ruled by such a narrowly defined group.
The essay, written in the first-person by a fictional historical narrator in 2034, interweaves history from the politics of pre- and post-war Britain with those of fictional future events in the short (1960 onward) and long term (2020 onward).
The essay was based upon the tendency of the then-current governments, in their striving toward intelligence, to ignore shortcomings and upon the failure of education systems to utilize correctly the gifted and talented members within their societies.
Young's fictional narrator explains that, on the one hand, the greatest contributor to society is not the "stolid mass" or majority, but the "creative minority" or members of the "restless elite". On the other hand, he claims that there are casualties of progress whose influence is underestimated and that, from such stolid adherence to natural science and intelligence, arises arrogance and complacency. This problem is encapsulated in the phrase "Every selection of one is a rejection of many".
It was also used by Hannah Arendt in her essay, "Crisis in Education" which was written in 1958 and refers to the use of meritocracy in the English educational system.
History.
Ancient times: China and Greece.
According to scholarly consensus, the earliest example of an administrative meritocracy, based on civil service examinations, dates back to Ancient China.a[›] The concept originates, at least by the sixth century BC, when it was advocated by the Chinese philosopher Confucius, who "invented the notion that those who govern should do so because of merit, not of inherited status. This sets in motion the creation of the imperial examinations and bureaucracies open only to those who passed tests."
As the Qin and Han dynasties developed a meritocratic system in order to maintain power over a large, sprawling empire, it became necessary for the government to maintain a complex network of officials. Prospective officials could come from a rural background and government positions were not restricted to the nobility. Rank was determined by merit, through the civil service examinations, and education became the key for social mobility. After the fall of the Han Dynasty, the nine-rank system was established during the Three Kingdoms period.
According to the Princeton Encyclopedia on American History:
One of the oldest examples of a merit-based civil service system existed in the imperial bureaucracy of China. Tracing back to 200 B.C., the Han Dynasty adopted Confucianism as the basis of its political philosophy and structure, which included the revolutionary idea of replacing nobility of blood with one of virtue and honesty, and thereby calling for administrative appointments to be based solely on merit. This system allowed anyone who passed an examination to become a government officer, a position that would bring wealth and honor to the whole family. In part due to Chinese influence, the first European civil service did not originate in Europe, but rather in India by the British-run East India Company... company managers hired and promoted employees based on competitive examinations in order to prevent corruption and favoritism.
Both Plato and Aristotle advocated meritocracy, Plato in his "The Republic", arguing that the most wise should rule, and hence the rulers should be philosopher kings. See Estlund (2003) for a summary and discussion.
17th century: spread to Europe.
The concept of meritocracy spread from China to British India during the seventeenth century, and then into continental Europe and the United States. With the translation of Confucian texts during the Enlightenment, the concept of a meritocracy reached intellectuals in the West, who saw it as an alternative to the traditional "ancient regime" of Europe. Voltaire and François Quesnay wrote favourably of the idea, with Voltaire claiming that the Chinese had "perfected moral science" and Quesnay advocating an economic and political system modeled after that of the Chinese.
The first European power to implement a successful meritocratic civil service was the British Empire, in their administration of India: "company managers hired and promoted employees based on competitive examinations in order to prevent corruption and favoritism." British colonial administrators advocated the spread of the system to the rest of the commonwealth, the most "persistent" of which was Thomas Taylor Meadows, Britain's consul in Guangzhou, China. Meadows successfully argued in his "Desultory Notes on the Government and People of China", published in 1847, that "the long duration of the Chinese empire is solely and altogether owing to the good government which consists in the advancement of men of talent and merit only," and that the British must reform their civil service by making the institution meritocratic. "This practice later was adopted in the late nineteenth century by the British mainland, inspired by "Chinese mandarin system."
The British philosopher and polymath John Stuart Mill advocated meritocracy in his book, "Considerations on Representative Government". His model was to give more votes to the more educated voter. His views are explained in Estlund (2003:57-8):
Estlund goes on to criticize Mill's education-based meritocracy on various grounds.
19th century: United States.
In the United States, the federal bureaucracy used the Spoils System from 1828 until the assassination of United States President James A. Garfield by a disappointed office seeker in 1881 proved its dangers. Two years later in 1883, the system of appointments to the United States Federal Bureaucracy was revamped by the Pendleton Civil Service Reform Act, partially based on the British meritocratic civil service that had been established years earlier. The act stipulated that government jobs should be awarded on the basis of merit, through competitive exams, rather than ties to politicians or political affiliation. It also made it illegal to fire or demote government employees for political reasons.
To enforce the merit system and the judicial system, the law also created the United States Civil Service Commission. In the modern American meritocracy, the president may hand out only a certain number of jobs, which must be approved by the Senate.
Australia.
Australia began establishing public universities in the 1850s with the goal of promoting meritocracy by providing advanced training and credentials. The educational system was set up to service urban males of middle-class background, but of diverse social and religious origins. It was increasingly extended to all graduates of the public school system, those of rural and regional background, and then to women and finally to ethnic minorities. Both the middle classes and the working classes have promoted the ideal of meritocracy within a strong commitment to "mateship" and political equality.
Social Darwinism.
Social Darwinism is a social theory which holds that Darwin's theory of evolution by natural selection is a model, not only for the development of biological traits in a population, but also as an application for human social institutions — the existing social institutions being implicitly declared as normative. Social Darwinism shares its roots with early progressivism, and was most popular from the late nineteenth century to the end of World War II. Proponents of Social Darwinism argue that the theory justifies social inequality as being meritocratic. Darwin only ventured to propound his theories in a biological sense, and it is other thinkers and theorists who have applied Darwin's model to unequal endowments of human ambitions.
In his book "Meritocratic Education and Social Worthlessness" (Palgrave, 2012), the philosopher Khen Lampert, argued that educational-meritocracy is nothing but a post-modern version of Social-Darwinism.
Historical examples.
Confucianism.
In teaching, there should be no distinction of classes. ("Analects" XV, 39)
The main basis of his teachings was to seek knowledge, study, and become a better person.
Although Confucius claimed that he never invented anything, but was only transmitting ancient knowledge (see "Analects" VII, 1), he did produce a number of new ideas. Many European and American admirers such as Voltaire and H. G. Creel point to the revolutionary idea of replacing nobility of blood with nobility of virtue. Jūnzǐ (君子, lit. "lord's child"), which originally signified the younger, non-inheriting, offspring of a noble, became, in the works of Confucius, an epithet having much the same meaning and evolution as the English term, "gentleman". A virtuous plebeian who cultivates his qualities may be a "gentleman", while a shameless son of the king is only a "small man". That he admitted students of different classes as disciples is a clear demonstration that Confucius fought against the feudal structures that defined pre-imperial Chinese society.
The new idea of the meritocracy led to the introduction of the Imperial examination system in China. The system allowed anyone who passed an examination to become a government officer, a position which would bring wealth and honour to the whole family. The Chinese Imperial examination system seemed to start in 165 BC, when certain candidates for public office were called to the Chinese capital for examination of their moral excellence by the emperor. Over the following centuries the system grew until, finally, almost anyone who wished to become an official had to prove his worth by passing written government examinations.
Han Feizi.
In addition to Confucius, another ancient Chinese philosopher of the same period (that of the Warring States) advocated a meritocratic system of government and society. This was Han Feizi who was famous as the foremost proponent of the School of Law, otherwise known as the philosophy of Legalism. This had, as its central tenet, the absolute rule of law, but also contained numerous meritocratic elements. Another Legalist, Shang Yang implemented Legalist and meritocratic reforms in the state of Qin by abolishing the aristocracy and promoting individuals based on their skill, intelligence, and initiative.
This led to the armies of the Qin gaining a critical edge over the other nations that adhered to old aristocratic systems of government. Legalism, along with its pro-meritocratic ideals, remained a key part of Chinese philosophy and politics for another two millennia, although after the Qin Dynasty it was heavily diluted. Meritocratic governance within the bureaucracy, however, remains a nominal keystone of Chinese government all the way to the present. This may be seen most clearly in the use of standardized "imperial examinations" to determine entry into the official class, which began in the Sui Dynasty.
Napoleon.
Napoleonic (Revolutionary) France is considered to have been meritocratic. After the revolution of 1789 most members of the former elite had been removed. When Napoleon rose to power in 1799, there was no ancient base from which to draw his staff and he had to choose the people he thought best for the job. This included officers from his army, revolutionaries who had been in the National Assembly, and even some former aristocrats such as prime minister Talleyrand. This policy was summed up in Bonaparte's often-quoted phrase "La carrière ouverte aux talents", careers open to the talented, or as more freely translated by Thomas Carlyle, "the tools to him that can handle them". A clear example is the order of the Légion d'honneur, the first order of merit, admitting men of any class. They were judged not by ancestry or wealth but by military, scientific, or artistic prowess.
Modern meritocratic states.
Singapore.
Singapore describes meritocracy as one of its official guiding principles for domestic public policy formulation, placing emphasis on academic credentials as objective measures of merit.
There is criticism that, under this system, Singaporean society is being increasingly stratified and that an elite class is being created from a narrow segment of the population. Singapore has one of the highest levels of home tutoring in the world for children, and top tutors are often paid better than school teachers. Defendants recall the ancient Chinese proverb "Wealth does not pass three generations", suggesting that the nepotism or cronyism of elitists eventually will be, and often are, replaced by those lower down the hierarchy.
Singaporean academics are continuously re-examining the application of meritocracy as an ideological tool and how it's stretched to encompass the ruling party's objectives. Professor Kenneth Paul Tan at the Lee Kuan Yew School of Public Policy asserts that "Meritocracy, in trying to 'isolate' merit by treating people with fundamentally unequal backgrounds as superficially the same, can be a practice that ignores and even conceals the real advantages and disadvantages that are unevenly distributed to different segments of an inherently unequal society, a practice that in fact perpetuates this fundamental inequality. In this way, those who are picked by meritocracy as having merit may already have enjoyed unfair advantages from the very beginning, ignored according to the principle of nondiscrimination."
Meritocracy in the Singapore context relates to the application of pragmatism as an ideological device which combines strict adherence to market principles "without" any aversion to social engineering and little propensity for classical social welfarism, is further illustrated by Kenneth Paul Tan in subsequent articles: "There is a strong ideological quality in Singapore's pragmatism, and a strongly pragmatic quality in ideological negotiations within the dynamics of hegemony. In this complex relationship, the combination of ideological and pragmatic maneuvering over the decades has resulted in the historical dominance of government by the PAP in partnership with global capital whose interests have been advanced without much reservation."
Ecuador.
Ecuador Dependency of the Ministry of Labour, the was created under the technical advice of Singapore government.
Modern meritocratic movements.
OSHO According to Osho, only persons with appropriate qualifications should be allowed to vote. Moreover, all politicians should have appropriate college or university degrees. Only the geniuses of the world should govern. Osho suggested that, first the various nations should become meritocracies, after which they could all be joined to form a global meritocracy.
The Meritocracy Party In 2007 an anonymous British group called The Meritocracy Party published its first manifesto, to which they have now added more than two million words on the subject (discussing Hegel, Rousseau, Charles Fourier, Henri de Saint-Simon, and various other philosophers, scientists, reformers, and revolutionaries). In summary, The Meritocracy Party wants to achieve the following: 
1. A world in which every child gets an equal chance to succeed in life 2. The abolishment of party politics 3. Only those with a relevant education and work experience should be allowed to vote, rather than just anyone who has reached the age of 18 or 21 4. The introduction of 100% Inheritance Tax, so that the super-rich elite can no longer pass on their wealth to a select few (their privileged children) rather than the Commonwealth this inheritance tax would mean the end of the elite dynasties, and abolish hereditary monarchy. 5. A radically reformed educational system, based on the MBTI personality types, and insights from radical innovators such as Rudolf Steiner and Maria Montessori 6. To replace free market capitalism with social capitalism and to replace democracy with a fully transparent meritocratic republic, under a meritocratic constitution. 7. The end of nepotism, cronyism, discrimination, privilege. and unequal chances. On their website the Meritocracy Party lists five meritocratic principles and thirteen primary aims. The Meritocracy International is the host of all meritocratic political parties in the world and the place where these may be found by country of origin. 
Computing.
Due to the nature of online interaction, where identity and anonymity are more readily managed than in direct interaction, the effects of offline social inequity often may be discounted in online communities. Intelligence, effort, education, and personality may be readily conveyed in an online interaction, but a person's gender, race, religion, and social standing can be obfuscated easily, or left entirely unaddressed.
Free / open source software projects.
The GNOME Foundation, Apache Software Foundation, Mozilla Foundation, and The Document Foundation are examples of (open source) organizations that officially claim to be meritocracies.
Criticism.
The primary concern with meritocracy is the unclear definition of "merit". Different people often have their own standards of merit, thus raising the question of which "merit" has the best merits—or in other words—which standard is the "best" standard.
Another concern is the reliability of people who measure merit. For example academic grades are given by people who do have opinions and can be biased or inefficient. If the system is corrupt or non-transparent, decisions on who has merit will be flawed.
The level of education required in order to become competitive in a meritocracy may also be costly, effectively limiting candidacy for a position of power to those with the means to become educated. An example of this was Chinese student come self-declared messiah, Hong Xiuquan, who despite ranking first in a preliminary, nation-wide imperial examination, was unable to afford further education. As such, although he did try to study in private, Hong was ultimately noncompetitive in later examinations and unable to become a bureaucrat. This economic aspect of meritocracies has been said to continue nowadays in countries without free educations, with the Supreme Court of the United States, for example, consisting only of justices who attended Harvard or Yale and generally only considering clerkship candidates who attended a top-five university, while in the 1950s the two universities only accounted for around one fifth of the justices.
Meritocracy also has been criticized by egalitarians as a mere myth, which serves only to justify the status quo, with its proponents only giving lip service to equality.
Another concern regards the principle of incompetence, or the "Peter Principle". As people rise in a meritocratic society through the corporate ladder, they reach, and become stuck, at the first level of what they are unable to do.
Other concerns for the validity of a merit-based system have arisen from studies in psychology, sociology, and neuroscience. Given the proposition that a person's life prospects should not be decided by factors outside of one's control or, for which a person cannot claim personal credit (i.e., social status, inherited wealth, race, and other accidents of birth) a meritocracy proposes a system where people are rewarded based on their efforts, and if everyone can start on equal footing with the same opportunity to advance, then the results are just. However, some studies have shown that even our motivation, work ethic, and conscientious drive is, in fact, outside of our control and can be affected by such arbitrary factors as birth order. Children who are first in birth order tend to aim at goals that reference their own past level of mastery, while secondborns tend to aim at goals based on other-referenced expectations and competence standards. Therefore, a system which rewards effort in this way is not completely just, because effort and hard work is not something we can claim complete credit for.
Khen Lampert has argued that the principle of meritocracy stems from neo-capitalist ideas of aggression and competition.
Chris Hayes, A writer on the left, has attributed what he calls the "Fail Decade"—which includes 9/11, the Enron scandal, the invasion of Iraq, Hurricane Katrina, the subprime crisis, and the Great Recession—to the deterioration of America's meritocratic system into one of plutocracy.
References.
^ a: This is the history of the meritocracy in the technical sense. The vaguer definition of a meritocracy as a "rule by intelligence" has been applied to many ancient Greek, Indian, Chinese, and Jewish thinkers and statesmen. For example, the Sanhedrin, the legislature of Ancient Israel and Kingdom of Judah, is sometimes called as an "intellectual meritocracy", in the sense that its members were drawn from religious scribes and not the aristocracy. Appointment was self-perpetuating, however, and new members were chosen personally by existing members. These are not meritocracies in the administrative sense, in which merit is determined objectively as a "tested competency or ability."
Further reading.
[עריכה]

</doc>
<doc id="20972" url="http://en.wikipedia.org/wiki?curid=20972" title="Marxism–Leninism">
Marxism–Leninism

Marxism–Leninism is the political ideology adopted during Joseph Stalin's rule by the Communist Party of the Soviet Union and Comintern, which its proponents consider to be based on Marxism and Leninism. The term was suggested by Stalin.
The goal of Marxism–Leninism, according to its proponents, is the development of a state into what it considers a socialist state through the leadership of a revolutionary vanguard composed of "professional" revolutionaries, an organic part of the working class who come to socialist consciousness as a result of the dialectic of class struggle. The socialist state, which according to Marxism–Leninism represents a "dictatorship of the proletariat", is primarily or exclusively governed by the party of the revolutionary vanguard through the process of democratic centralism, which Vladimir Lenin described as "diversity in discussion, unity in action." Through this policy, the communist party (or equivalent) is the supreme political institution of the state and primary force of societal organisation. Marxism–Leninism professes its final goal as the development of socialism into the full realisation of communism, a classless social system with common ownership of the means of production and with full social equality of all members of society. To achieve this goal, the communist party mainly focuses on the intensive development in industry, science and technology, which lay the basis for continual growth of the productive forces and therein increases the flow of material wealth. All land and natural resources are publicly owned and managed through the Marxist–Leninist state, with varying forms of public ownership of social institutions.
Other types of communists and Marxists have been critical of Marxism–Leninism. They argue that Marxist–Leninist states did not establish socialism, but rather state capitalism. They trace this argument back to the founders of Marxism's own comments about state ownership of property being a form of capitalism except when certain conditions are met - conditions which, in their argument, did not exist in the Marxist–Leninist states. Marxism's dictatorship of the proletariat is a democratic state form; single-party rule (which the Marxist–Leninist states made use of) cannot be a dictatorship of the proletariat under the Marxist definition. They conclude that Marxism–Leninism is neither Marxism nor Leninism nor the union of both, but rather an artificial term created to justify Stalin's ideological distortion.
"Marxism-Leninism" was founded as Stalin and his ideologists' own doctrine, with Marx and Lenin's words being merely used as justification, selected opportunistically and taken out of context. Additionally, the content of "Marxism-Leninism" was constantly being revised in order to fit in to the ruling party's views as they changed. "Marxism-Leninism" also contains outright deviations from Marxism and Leninism's core principles, such as "socialism in one country".
Terminology.
Historical.
Within five years of Vladimir Lenin's death in 1924, Stalin completed his rise to power in the Soviet Union. According to G. Lisichkin (1989), Stalin compiled Marxism–Leninism as a separate ideology in his book "The questions of Leninism". During the period of Stalin's rule in the Soviet Union, Marxism–Leninism was proclaimed the official ideology of the state.
There is no definite agreement amongst historians regarding whether or not Stalin actually followed the principles established by Karl Marx and by Lenin. Trotskyists in particular believe that Stalinism contradicted authentic Marxism and Leninism, and they initially used the term "Bolshevik–Leninism" to describe their own ideology of anti-Stalinist (and later anti-Maoist) communism. Left communists rejected "Marxism–Leninism" as an anti-Marxist current.
The term "Marxism–Leninism" is often used by Stalinists - those who believe that Joseph Stalin successfully carried forward Lenin's legacy. However, it is also used by some who repudiate the repressive aspects of Stalin's rule, such as the supporters of Nikita Khrushchev.
After the Sino-Soviet split of the 1960s, the communist parties of the Soviet Union and of the People's Republic of China each claimed to be the sole successor to Marxism–Leninism. In China, the claim that Mao had "adapted Marxism–Leninism to Chinese conditions" consequently, the term "Mao Zedong Thought" (commonly known as Maoism) increasingly came to describe the official Chinese state ideology as well as the ideological basis of parties around the world which sympathised with the Communist Party of China (such as the Communist Party of the Philippines, founded by Jose Maria Sison in 1968). After the death of Mao on 1976, Peruvian Maoists associated with the Communist Party of Peru (Sendero Luminoso) coined the term Marxism–Leninism–Maoism, arguing that Maoism was a more advanced stage of Marxism.
Following the Sino-Albanian split of the 1970s, a small portion of Marxist–Leninists began to downplay or repudiate the role of Mao Zedong in the International Communist Movement in favour of the Party of Labour of Albania and a stricter adherence to Stalin.
In North Korea, Marxism–Leninism was officially superseded in 1977 by Juche, in which concepts of class and class struggle, in other words Marxism itself, play no significant role. However, the government is still sometimes referred to as Marxist–Leninist—or, more commonly, Stalinist—due to its political and economic structure.
In the other four "de jure" socialist states existing as of 2014[ [update]]—China, Cuba, Laos, and Vietnam—the ruling parties hold Marxism–Leninism as their official ideology, although they give it different interpretations in terms of practical policy.
Current usage.
Some contemporary communist parties continue to regard Marxism–Leninism as their basic ideology, although many follow Marxism instead.
In party names, the appellation "Marxist–Leninist" is normally used by a communist party which wishes to distinguish itself from some other communist party in the same country.[]
Popular confusion abounds concerning the complex terminology describing the various schools of Marxist-derived thought. The appellation "Marxist–Leninist" is often used by those not familiar with communist ideology in any detail (e.g. many newspapers and other media) as a synonym for any kind of Marxism.
Ideological characteristics.
Socialism.
Originally and for a long time the concept of a socialist society was regarded as equal to that of a communist society. However, it was Lenin who defined the difference between "socialism" and "communism", explaining that they are similar to what Marx described with the lower and upper stages of communist society. Marx explained that in a society immediately after the revolution, distribution must be based on the contribution of the individual, whereas in the upper stage of communism the from each according to his ability, to each according to his need concept would be applied.
Stalin built his ideological core of socialism taking Lenin's definition as the base, but adding his own modifications, some of which started to be considered by critics of Marxism–Leninism as distortions which completely invalidated any origin in Marxism. Stalin, for instance, invented the concept of socialism in one country, which according to these critics violates basic principles of Marxism. Stalin derived this concept from an arbitrary Lenin quote, which in its own context was unlikely to support his argument taken out of context, and, crucially, supplemented by his own words. This concept was instrumental to claim that socialism was really being built in the USSR. In 1936, Stalin declared that the USSR had finished the transition to socialism, and that it had been established.
For Marxism–Leninism, the USSR was a workers' state and thus any property under this State was a type of socialist property. However, the rest of Marxist tendencies based their theory of a non-socialist USSR based on disagreement with this, referencing among others the argument of the difference between socialization and nationalization.
Workers' state.
A key point of conflict between Marxism–Leninism and other tendencies is that whereas Marxism–Leninism defines Stalin's USSR as a workers' state, other types of communists and Marxists in general deny this, and Trotskyists specifically consider it a deformed or degenerated workers' state.
Anti-revisionism.
The anti-revisionist characteristic was developed after Stalin and became part of ideologies based on Marxism–Leninism such as Maoism and Hoxhaism. It criticizes how the post-Stalin USSR became distanced from Stalin's USSR's politics, and claimed the former were "revisionist". Therefore, China and Albania established their own independent politics.
Components.
Social.
Marxism–Leninism supports universal social welfare. Improvements in public health and education, provision of child care, provision of state-directed social services, and provision of social benefits are deemed by Marxist–Leninists to help to raise labour productivity and advance a society in development towards a communist society. This is part of Marxist–Leninists' advocacy of promoting and reinforcing the operation of a planned socialist economy. It advocates universal education with a focus on developing the proletariat with knowledge, class consciousness, and understanding the historical development of communism.
Marxist–Leninist policy on family law has typically involved: the elimination of the political power of the bourgeoisie, the abolition of private property, and an education that teaches citizens to abide by a disciplined and self-fulfilling lifestyle dictated by the social norms of communism as a means to establish a new social order.
Marxism–Leninism supports the emancipation of women and ending the exploitation of women. The advent of a classless society, the abolition of private property, society collectively assuming many of the roles traditionally assigned to mothers and wives, and women becoming integrated into industrial work has been promoted as the means to achieve women's emancipation.
Marxist–Leninist cultural policy focuses upon modernisation and distancing society from: the past, the bourgeoisie, and the old intelligentsia. Agitprop and various associations and institutions are used by the Marxist–Leninist state to educate society with the values of communism. Both cultural and educational policy in Marxist–Leninist states have emphasised the development of a "New Man"—a class conscious, knowledgeable, heroic proletarian person devoted to work and social cohesion as opposed to the antithetic "bourgeois individualist" associated with cultural backwardness and social atomisation.
Economic.
The state serves as a safeguard for the ownership and as the coordinator of production through a universal economic plan. For the purpose of reducing waste and increasing efficiency, scientific planning replaces market mechanisms and price mechanisms as the guiding principle of the economy. The Marxist–Leninist state's huge purchasing power replaces the role of market forces, with macroeconomic equilibrium not being achieved through market forces but by economic planning based on scientific assessment. In the socialist economy, the value of a good or service is based on its use value, rather than its cost of production or its exchange value. The profit motive as a driving force for production is replaced by social obligation to fulfil the economic plan. Wages are set and differentiated according to skill and intensity of work. While socially utilised means of production are under public control, personal belongings or property of a personal nature that doesn't involve mass production of goods remains relatively unaffected by the state.
Because Marxism–Leninism has historically only been the state ideology of countries who were economically undeveloped prior to socialist revolution (or whose economies were nearly obliterated by war, such as the German Democratic Republic), the primary goal before achieving full communism was the development of socialism in itself. Such was the case in the Soviet Union, where the economy was largely agrarian and urban industry was in a primitive stage. To develop socialism, the economy went through a period of massive industrialisation, in which much of the peasant population moved into urban areas while those remaining in the rural areas began working in the new collective agricultural system. Since the mid-1930s, Marxism–Leninism has advocated a socialist consumer society based upon egalitarianism, asceticism, and self-sacrifice. Previous attempts to replace the consumer society as derived from capitalism with a non-consumerist society failed and in the mid-1930s permitted a consumer society, a major change from traditional Marxism's anti-market and anti-consumerist theories. These reforms were promoted to encourage materialism and acquisitiveness in order to stimulate economic growth. This pro-consumerist policy has been advanced on the lines of "industrial pragmatism" as it advances economic progress through bolstering industrialisation.
The ultimate goal of the Marxist–Leninist economy is the emancipation of the individual from alienating work, and therefore freedom from having to perform such labour to receive access to the material necessities for life. It is argued that freedom from necessity would maximise individual liberty, as individuals would be able to pursue their own interests and develop their own talents while only performing labour by free will without external coercion. The stage of economic development in which this is possible is contingent upon advances in the productive capabilities of society. This advanced stage of social relations and economic organisation is called "pure communism".
Political system.
Marxism–Leninism supports the creation of a single-party state led by a Marxist–Leninist communist party as a means to develop socialism and then communism. The political structure of the Marxist–Leninist state involves the rule of a communist vanguard party over a revolutionary socialist state that represents the will and rule of the proletariat. Through the policy of democratic centralism, the communist party is the supreme political institution of the Marxist–Leninist state.
Elections are held in Marxist–Leninist states for all positions within the legislative structure, municipal councils, national legislatures and presidencies. In most Marxist–Leninist states this has taken the form of directly electing representatives to fill positions, though in some states; such as China, Cuba, and the former Yugoslavia; this system also included indirect elections such as deputies being elected by deputies as the next lower level of government. These elections are not competitive multiparty elections, and most are not multi-candidate elections; usually a single communist party candidate is chosen to run for office in which voters vote either to accept or reject the candidate. Where there have been more than one candidates, all candidates are officially vetted before being able to stand for candidacy, and the system has frequently been structured to give advantage to official candidates over others. Marxism–Leninism asserts that society is united upon common interests represented through the communist party and other institutions of the Marxist–Leninist state, and in Marxist–Leninist states where opposition political parties have been permitted they have not been permitted to advocate political platforms significantly different from the communist party. Marxist–Leninist communist parties have typically exercised close control over the electoral process of such elections, including involvement with nomination, campaigning, and voting – including counting the ballots.
International relations.
Marxism–Leninism aims to create an international communist society. It opposes colonialism and imperialism and advocates decolonisation and anti-colonial forces. It supports anti-fascist international alliances and has advocated the creation of "popular fronts" between communist and non-communist anti-fascists against strong fascist movements.
Theological.
The Marxism–Leninist worldview promotes atheism as a fundamental tenet. Marxist–Leninist atheism has its roots in the philosophy of Ludwig Feuerbach, Georg Wilhelm Friedrich Hegel, Marx, and Lenin. Materialism, the philosophical standpoint that the universe exists independently of human consciousness consisting of only atoms and physical forces, is central to the worldview of Marxism–Leninism in the form of dialectical materialism. Vitaly Ginzburg, a Soviet physicist, wrote that the "Bolshevik communists were not merely atheists but, according to Lenin's terminology, militant atheists." Therefore, many Marxist–Leninist states, historically and currently, are also atheist states. Under these regimes, several religions and their adherents were targeted to be "stamped out."
History.
Founding of Bolshevism, 1905–1907 Russian Revolution, and World War I (1903–1917).
Marxism–Leninism was created after Lenin's death during the regime of Josef Stalin in the Soviet Union, but continued to be the official ideology of the Soviet Communist Party after de-Stalinisation. However the basis for elements of Marxism–Leninism predate this. Marxism–Leninism descends from the Bolshevik ("Majority") faction of the Russian Social Democratic Labour Party (RSDLP) that was founded in the RSDLP's Second Congress in 1903. The Bolshevik faction led by Lenin advocated an active, politically committed vanguard party membership while opposing trade union based membership of social democratic parties. The Bolsheviks supported a vanguard Marxist party composed of active militants committed to socialism who would initiate communist revolution. The Bolsheviks advocated the policy of democratic centralism that would allow members to elect their leaders and decide policy but that once policy was set, members would be obligated to have complete loyalty in their leaders.
Lenin attempted and failed to bring about communist revolution in Russia in the Russian Revolution of 1905–7. During the revolution, Lenin advocated mass action and that the revolution "accept mass terror in its tactics". During the revolution Lenin advocated militancy and violence of workers as a means to pressure the middle class to join and overthrow the Tsar. Bolshevik emigres briefly poured into Russia to take part in the revolution. Prior and after the failed revolution, the Bolshevik leadership voluntarily resided in exile to evade Tsarist Russia's secret police, such as Lenin who resided in Switzerland. Most importantly, the experience of this revolution caused Lenin to conceive of the means of sponsoring communist revolution, through propaganda, agitation, a well-organised and disciplined but small political party, and through manipulation of aroused masses.
In the aftermath of the failed revolution of 1905–7, Bolshevik revolutionaries were forced back into exile in 1908 in Switzerland as well as other anti-Tsarist revolutionaries including the Mensheviks, the Socialist Revolutionaries, and anarchists. Membership in both the Bolshevik and Menshevik ranks diminished from 1907 to 1908 and the number of people taking part in strikes in 1907 was 26 percent of the figure during the year of the revolution in 1905, it dropped in 1908 to 6 percent of that figure, and in 1910 it was 2 percent of that figure. The period of 1908 to 1917 was one of dissillusionment in the Bolshevik party over Lenin's leadership, with members opposing him for scandals involving his expropriations and methods of raising money for the party. One important development after the events the 1905-7 revolution was Lenin's endorsement of colonial revolt as a powerful reenforcement to revolution in Europe. This was an original development by Lenin, as prior to the 20th century Marxists did not pay serious attention to colonialism and colonial revolt. Facing leadership challenges from the "Forward" group, Lenin usurped the all-Party Congress of the RSDLP in 1912, to seize control of it and make it an exclusively Bolshevik party loyal to his leadership. Almost all the members elected to the party's Central Committee were Leninists while former RDSLP leaders not associated with Bolshevism were removed from office. Lenin remained highly unpopular in the early 1910s, and was so unpopular amongst international socialist movement that by 1914 it considered censoring him.
At the outset of World War I in 1914, the Bolsheviks opposed the war unlike most other socialist parties across Europe that supported their national governments. Lenin and a small group of anti-war socialist leaders, including Rosa Luxemburg and Karl Liebknecht, denounced established socialist leaders of having betrayed the socialist ideal via their support of the war. In response to the outbreak of World War I, Lenin wrote his book "Imperialism, the Highest Stage of Capitalism" from 1915 to 1916 and published in 1917 in which he argued that capitalism directly leads to imperialism. As a means to destabilise Russia on the Eastern Front, Germany's High Command allowed Lenin to travel across Germany and German-held territory into Russia in April 1917, anticipating him partaking in revolutionary activity.
October Revolution, aftermath conflict, and the creation of the Soviet Union (1917–1924).
In March 1917, Tsar Nicholas II abdicated his throne and a provisional government quickly filled the vacuum, proclaiming Russia a republic months later. This was followed by the October Revolution by the Bolsheviks, who seized control in a quick coup d'état against the Provisional Government, resulting in the formation of the Russian Soviet Federative Socialist Republic (RSFSR), the first country in history committed to the establishment of communism. However, large portions of Russia were held under the leadership of either pro-Tsarist or anti-communist military commanders who formed the White movement to oppose the Bolsheviks, resulting in civil war between the Bolsheviks' Red Army and the anti-Bolshevik White Army. Amidst civil war between the Reds and the Whites, the RSFSR inherited the war that the Russian Empire was fighting against Germany that was ended a year later with an armistice. However, that was followed by a brief Allied military intervention by the United Kingdom, the United States, France, Italy, Japan and others against the Bolsheviks.
In response to the October Revolution, communist revolution broke out in Germany and Hungary from 1918 to 1920, involving creation of the Bavarian Soviet Republic, the failed Spartacist uprising in Berlin in 1919, and the creation of the Hungarian Soviet Republic. These communist forces were soon crushed by anti-communist forces and attempts to create an international communist revolution failed. However, a successful communist revolution occurred in Mongolia in 1924, resulting in the creation of the Mongolian People's Republic.
The entrenchment of Bolshevik power began in 1918 with the expulsion of Mensheviks and Socialist Revolutionaries from the workers' soviets. The Bolshevik government established the Cheka, a secret police force dedicated to confronting anti-Bolshevik elements. The Cheka was the predecessor to the NKVD and the KGB. Initially, opposition to the Bolshevik regime was strong as a response to Russia's poor economic conditions, with the Cheka reporting no less than 118 uprisings, including the Kronstadt Revolt. Lenin repressed opposition political parties. Intense political struggle continued until 1922.
Initial Bolshevik economic policies from 1917 to 1918 were cautious with limited nationalisations of private property. Lenin was immediately committed to avoid antagonising the peasantry by making efforts to coax them away from the Socialist Revolutionaries, allowing a peasant takeover of nobles' estates while no immediate nationalisations were enacted on peasants' property. Beginning in mid-1918, the Bolshevik regime enacted what is known as "war communism", an economic policy that aimed to replace the free market with state control over all means of production and distribution. This was done through the Decree on Nationalisation that declared the nationalisation of all large-scale private enterprises while requisitioning grain away from peasants and providing it to workers in cities and Red soldiers fighting the Whites. The result was economic chaos as the monetary economy collapsed and was replaced by barter and black marketeering. The requisitioning of grain away from the peasantry to workers resulted in peasants losing incentive to labour, resulting in a drop in production, producing a food shortage crisis in the cities that provoked strikes and riots that seriously challenged the Bolshevik regime, with the most serious being the Kronstadt Revolt of 1921.
The New Economic Policy was started in 1921 as a backwards step from war communism, with the restoration of a degree of capitalism and private enterprise. 91 percent of industrial enterprises were returned to private ownership or trusts. Importantly, Lenin declared that the development of socialism would not be able to be pursued in the manner originally thought by Marxists. Lenin stated "Our poverty is so great that we cannot at one stroke restore full-scale factory, state, socialist production". A key aspect that affected the Bolshevik regime was the backward economic conditions in Russia that were considered unfavourable to orthodox Marxist theory of communist revolution. Orthodox Marxists claimed at the time that Russia was ripe for the development of capitalism, not yet for socialism. Lenin advocated the need of the development of a large corps of technical intelligentsia to assist the industrial development of Russia and thus advance the Marxist economic stages of development, as it had too few technical experts at the time. The New Economic Policy was tumultuous; economic recovery took place but alongside famine (1921–1922) and a financial crisis (1924). However by 1924, considerable economic progress had been achieved and by 1926 the economy regained its 1913 production level.
Stalinism and World War II (1924–1945).
As Lenin neared death after suffering strokes, he declared in his testament of December 1922 an order to remove Joseph Stalin from his post as General Secretary and replace him by "some other person who is superior to Stalin only in one respect, namely, in being more tolerant, more loyal, more polite and more attentive to comrades". When Lenin died in January 1924, the testament was read out to a meeting of the party's Central Committee. However, party members believed that Stalin had improved his reputation in 1923 and ignored Lenin's order. Lev Kamenev and Grigory Zinoviev believed that the real threat to the party came from Trotsky, head of the Red Army, due to his association with the army and his powerful personality. Kamenev and Zinoviev collaborated with Stalin in a power-sharing triumvirate where Stalin retained his position as General Secretary. The confrontation between the triumvirate and Trotsky began over the debate between the policy of Permanent Revolution as advocated by Trotsky and Socialism in One Country as advocated by Stalin. Trotsky's Permanent Revolution advocated rapid industrialisation, elimination of private farming, and having the Soviet Union promote the spread of communist revolution abroad. Stalin's Socialism in One Country stressed moderation and development of positive relations between the Soviet Union and other countries to increase trade and foreign investment. Stalin was not particularly committed to these positions, but used them as a means to isolate Trotsky. In 1925, Stalin's policy won the support of the 14th Party Congress while Trotsky was defeated.
From 1925 to 1927, Stalin abandoned his triumvirate with Kamenev and Zinoviev and formed an alliance with the most right-wing elements of the party, Nikolai Bukharin, Alexei Rykov, and Mikhail Tomsky. The 1927 Party Conference gave official endorsement to the policy of Socialism in One Country, while Trotsky along with Kamenev and Zinoviev (both now allied with Trotsky against Stalin) were expelled from the Party's Politburo.
In 1929, Stalin seized control of the Party. Upon Stalin attaining power, Bolshevism became associated with Stalinism, whose policies included: rapid industrialisation, Socialism in One Country, a centralised state, the collectivisation of agriculture, and the subordination of interests of other communist parties to those of the Soviet party. In 1929, he enacted harsh radical policy towards the wealthy peasantry (Kulaks) and turned against Bukharin, Rykov, and Tomsky, who favoured a more moderate approach to the Kulaks. He accused them of plotting against the Party's agreed strategy and forced them to resign from the Politburo and political office. Trotsky was exiled from the Soviet Union in 1929. Opposition to Stalin by Trotsky led to a dissident Bolshevik ideology called Trotskyism that was repressed under Stalin's rule.
Stalin's regime was a totalitarian state under his dictatorship. Stalin exercised extensive personal control over the Communist Party and unleashed an unprecedented level of violence to eliminate any potential threat to his regime. While Stalin exercised major control over political initiatives, their implementation was in the control of localities, often with local leaders interpreting the policies in a way that served themselves best. This abuse of power by local leaders exacerbated the violent purges and terror campaigns carried out by Stalin against members of the Party deemed to be traitors. Stalin unleashed the Great Terror campaign against alleged "socially dangerous" and "counterrevolutionary" persons that resulted in the Great Purge of 1936–1938 during which 1.5 million people were arrested from 1937–1938 and 681,692 of those were executed. The Stalinist era saw the introduction of a system of forced labour of convicts and political dissidents, the Gulag system, of that created in the early 1930s.
Political developments in the Soviet Union from 1929 to 1941 included Stalin dismantling the remaining elements of democracy from the Party by extending his control over its institutions and eliminating any possible rivals. The Party's ranks grew in numbers with the Party modifying its organisation to include more trade unions and factories. In 1936, the Soviet Union adopted a new constitution that ended weighted voting preference for workers as in its previous constitutions, and created universal suffrage for all people over the age of eighteen. The 1936 Constitution also split the Soviets into two legislatures, the Soviet of the Union – representing electoral districts, and the Soviet of the Nationalities – that represented the ethnic makeup of the country as a whole. By 1939, with the exception of Stalin himself, none of the original Bolsheviks of the October Revolution of 1917 remained in the Party. Unquestioning loyalty to Stalin was expected by the regime of all citizens.
Economic developments in the Soviet Union from 1929 to 1941 included the acceleration of collectivisation of agriculture. In 1930, 23.6 percent of all agriculture was collectivised; by 1941, 98 percent of all agriculture was collectivised. This process of collectivisation included "dekulakisation", in which kulaks were forced off their land, persecuted, and killed in a wave of terror unleashed by the Soviet state against them. The collectivisation policies resulted in economic disaster with severe fluctuations in grain harvests, catastrophic losses in the number of livestock, a substantial drop in the food consumption of the country's citizens, and the allegedly intentional Holodomor famine in the Ukraine. Modern sources estimate that between 2.4 and 7.5 million Ukrainians died in the Holodomor famine. Vast industrialisation was initiated, mostly based on the basis of preparation for an offensive war against the West – with a focus on heavy industry. However, even at its peak, industry of the Soviet Union remained well behind that of the United States. Industrialisation led to a massive urbanisation in the country. Unemployment was virtually eliminated in the country during the 1930s.
Social developments in the Soviet Union from 1929 to 1941 included the relinquishment of the relaxed social control and allowance of experimentation under Lenin to Stalin's promotion of a rigid and authoritarian society based upon discipline – mixing traditional Russian values with Stalin's interpretation of Marxism. Organised religion was repressed, especially minority religious groups. Education was transformed, under Lenin, the education system took allowed relaxed discipline in schools that became based upon Marxist theory, but Stalin reversed this in 1934 with a conservative approach taken with the reintroduction of formal learning, the use of examinations and grades, the assertion of full authority of the teacher, and the introduction of school uniforms. Art and culture became strictly regulated under the principles of Socialist Realism, and Russian traditions that Stalin admired were allowed to continue.
Foreign policy in the Soviet Union from 1929 to 1941 resulted in substantial changes in the Soviet Union's approach to its foreign policy. The rise of Adolf Hitler and the Nazis in Germany in 1933 resulted in the Soviet Union initially terminating the political connections it previously had established with Germany in the 1920s and Stalin turned to accommodate Czechoslovakia and the West against Hitler. The Soviet Union promoted various anti-fascist fronts across Europe and created agreements with France to challenge Germany. With the Suddeten agreement in 1938, Soviet foreign policy reversed, with Stalin abandoning anti-German policies and adopting pro-German policies. In 1939, the Soviet Union and Nazi Germany agreed to both a non-aggression pact and an agreement to invade and partition Poland between them, resulting in the invasion of Poland in September 1939 by Germany and the Soviet Union and the beginning of World War II, with the Allies declaring war on Germany.
The German invasion of the Soviet Union resulted in the substantial realignment of multiple Soviet policies. The Soviet Union was brought into World War II and joined the Western Allies in a common front against the Axis Powers. The war brought the threat of physical disintegration of the Soviet Union, as German forces were initially welcomed as liberators by many Belarussians, Georgians, and Ukrainians. Soviet forces initially faced disastrous losses from 1941 to 1942. Stalin enacted total war policy in response.
Communist insurrection against Axis occupation took place in several countries. In China, the Communist Party of China led by Mao Zedong reluctantly abandoned the civil war with the Kuomintang and cooperated with it against Japanese occupation forces. In Yugoslavia, the communist Yugoslav Partisans led by Josip Broz Tito, held up an effective guerrilla resistance movement to the Axis occupiers. The Partisans managed to form a communist Yugoslav state called Democratic Federal Yugoslavia in liberated territories in 1943 and by 1944, with the assistance of Soviet forces, seized control of Yugoslavia, entrenching a communist regime in Yugoslavia.
Soviet forces rebounded in 1943 with the victories at the Battle of Stalingrad and the Battle of Kursk, and from 1943 to 1945 they pushed back German forces and sieged Berlin in 1945. By the end of World War II, the Soviet Union had become a major military superpower. With the collapse of the Axis Powers, Soviet satellite states were established throughout Eastern Europe, creating a large communist bloc of states in Europe.
Cold War, de-Stalinisation, and Maoism (1945–1980).
Tensions between the Western Allies and the communist Eastern allies accelerated after the end of World War II, resulting in the Cold War between the Soviet-led communist East and the American-led capitalist West. Key events that began the Cold War included Soviet, Yugoslav, Bulgarian, and Albanian intervention in the Greek Civil War on the side of the communists, and the creation of the Berlin Blockade by the Soviet Union in 1948. China returned to civil war between the Western-backed Kuomintang versus Mao Zedong's Communists supported by the Soviet Union with the Communists seizing control of all of mainland China in 1949, creating the People's Republic of China (PRC). Direct conflict between the East and West erupted in the Korean War, when the United Nations Security Council, with the absence of the Soviet Union at the time of the vote, voted for international intervention in Korea to stop the civil war. The United States and other Western powers used the war to prop up South Korea against Soviet and PRC-backed communist North Korea led by Kim Il-sung. The war ended in armistice and stalemate in 1953.
Stalin's attempts to enforce submission of its Eastern European allies to the economic and political agenda of the Soviet Union sparked opposition and rejection in Yugoslavia by Tito. Stalin denounced Tito and removed Yugoslavia from the Comintern. Tito in return rejected Stalinism and the Eastern bloc, forging a non-aligned position between East and West that developed into the Non-Aligned Movement and the development of an autonomous Marxist–Leninist ideology of Titoism.
In 1953, Stalin died of a stroke, ending his 29 years of influence and rule over the Soviet Union.
With the death of Stalin in 1953, Nikita Khrushchev gradually ascended to power in the Soviet Union and announced a radical policy of de-Stalinisation of the Communist Party and the country, condemning Stalin for excesses and tyranny. Gulag forced labour camps were dismantled. Anti-Stalinist figures such as Aleksandr Solzhenitsyn were allowed the freedom to criticise Stalin. The cult of personality associated with Stalin was eliminated. Stalinists were removed from office. Khrushchev ended Stalin's policy of Socialism in One Country and committed the Soviet Union to actively support communist revolution throughout the world. The policies of de-Stalinisation were promoted as an attempt to restore the legacy of Lenin. The death of Stalin, however did not result in the end of the Cold War. The conflict continued and escalated.
Communist revolution erupted in the Americas in this period, including revolutions in Bolivia, Cuba, El Salvador, Grenada, Nicaragua, Peru, and Uruguay. In Cuba in 1959, forces led by Fidel Castro and Argentine revolutionary Che Guevara overthrew the regime of Fulgencio Batista and established a communist regime there with ties to the Soviet Union. American attempts to overthrow the Castro regime with the failed Bay of Pigs invasion by Cuban exiles supported by the CIA failed. Shortly afterwards, a diplomatic dispute erupted when the U.S. discovered Soviet nuclear missiles placed in Cuba, resulting in the Cuban missile crisis. The standoff between the two superpowers was resolved by the Soviet Union agreeing to remove its nuclear missiles from Cuba in exchange for the United States removing its nuclear missiles from Turkey. Bolivia faced Marxist–Leninist revolution in the 1960s that included Che Guevara as a leader until being killed there by government forces. Uruguay faced Marxist–Leninist revolution from the Tupamaros movement from the 1960s to the 1970s. A brief dramatic episode of Marxist–Leninist revolution took place in North America during the October Crisis in the province of Quebec in Canada, where the Marxist–Leninist and Quebec separatist "Front de libération du Québec" (FLQ) kidnapped the British Trade Commissioner in Canada, James Cross, and Quebec government minister Pierre Laporte who was later killed, it issued a manifesto condemning what it considered English Canadian imperialism in French Quebec calling for an independent, socialist Quebec. The Canadian government in response issued a crackdown on the FLQ and suspended civil liberties in Quebec, forcing the FLQ leadership to flee to exile in Cuba where the Cuban government accepted their entry. Daniel Ortega of the Marxist–Leninist movement called the Sandinista National Liberation Front seized power in Nicaragua in 1979 and faced armed opposition from the Contras supported by the United States. The United States launched military intervention in Grenada to prevent the establishment of a Marxist–Leninist regime there. The Salvadoran Civil War from 1980 to 1992 involved Marxist–Leninist rebels fighting against El Salvador's right-wing government.
Developments of Marxism–Leninism and communist revolution occurred in Asia in this period. The People's Republic of China under Mao Zedong developed its own unique brand of Marxism–Leninism known as Maoism. Tensions erupted between the PRC and the Soviet Union over a number of issues, including border disputes, resulting in the Sino-Soviet split in the 1960s. After the split, the PRC eventually pursued détente with the United States as a means to challenge the Soviet Union. This was inaugurated with the visit of US President Richard Nixon to the PRC in 1972 and the US supporting the PRC replacing the Republic of China as the representative of China at the United Nations and taking its seat at the UN Security Council. The death of Mao eventually saw the Deng Xiaoping politically outmaneuver Mao's chosen successor to power in the People's Republic of China. Deng made controversial economic reforms to the PRC's economy involving effective economic liberalisation under the policy of Socialism with Chinese Characteristics. His reforms helped to gradually transform the PRC into one of the world's fastest growing economies.
Another major conflict erupted between the East and West in the Cold War in Asia during the Vietnam War. French colonial forces had failed to hold back independence forces led by the communist leader Ho Chi Minh in North Vietnam. French forces retreated from Vietnam and were replaced by American forces supporting a Western-backed client regime in South Vietnam. Despite being a superpower and having a superior arsenal of weapons at its disposal, the United States was unable to make substantial gains against North Vietnam's proxy guerilla army in South Vietnam, the Viet Cong. With the direct intervention of North Vietnam in the South with the Tet Offensive of 1968, US forces suffered heavy losses. The American public turned against the war eventually resulting in a withdrawal of US troops and the seizure of Saigon by communist forces in 1975 and communist victory in Vietnam.
Communist regimes were established in Vietnam's neighbour states in 1975, such as in Laos and the creation of the Khmer Rouge regime of Democratic Kampuchea (Cambodia). The Khmer Rouge regime became notorious for the mass genocide of the Cambodian population. The Khmer Rouge was overthrown in 1979 by an invasion by Vietnam that assisted the establishment of a new Marxist–Leninist regime, the People's Republic of Kampuchea, that opposed the policies of the Khmer Rouge.
A new front of Marxist–Leninist revolution erupted in Africa, with revolutions in Benin, the Republic of the Congo, and Somalia; Marxist–Leninist liberation fronts in Angola and Mozambique revolting against Portuguese colonial rule; the overthrow of Haile Selassie and the creation of the Derg communist military junta in Ethiopia; blacks led by Robert Mugabe in Rhodesia revolting against white-minority rule there. Angola, Benin, the Republic of Congo, Ethiopia, Mozambique, Somalia and Zimbabwe (formerly Rhodesia) all became Marxist–Leninist states between 1969 and 1980. Focus on apartheid white minority rule in South Africa brought tensions between East and West, the Soviet Union officially supported the overthrow of apartheid while the West and the US in particular maintained official neutrality on the matter. The Western position became precarious and condemned after the Soweto uprising in 1976 and the killing of black South African rights activist Steve Biko in 1977. Under US President Jimmy Carter, the West joined the Soviet Union and others in enacting sanctions against weapons trade and weapons-grade material to South Africa. However forceful actions by the US against apartheid South Africa were diminished under US President Ronald Reagan, as the Reagan administration feared the rise of communist revolution in South Africa as had happened in Zimbabwe against white minority rule.
In 1979, the Soviet Union intervened in Afghanistan to secure the communist regime there, though the act was seen as an invasion by Afghans opposed to Afghanistan's communist regime and by the West. The West responded to the Soviet military actions by boycotting the Moscow Olympics of 1980 and providing clandestine support to the Mujahideen, including Osama bin Laden, as a means to challenge the Soviet Union. The war became a Soviet equivalent of the Vietnam War to the United States – it remained a stalemate throughout the 1980s.
Reform and Collapse (1980–1992).
Social resistance to the policies of Marxist–Leninist regimes in Eastern Europe accelerated in strength with the rise of the Solidarity, the first non-communist controlled trade union in the Warsaw Pact that was formed in the People's Republic of Poland in 1980.
In 1985, Mikhail Gorbachev rose to power in the Soviet Union and began policies of radical political reform involving political liberalisation, called Perestroika and Glasnost. Gorbachev's policies were designed at dismantling authoritarian elements of the state that were developed by Stalin, while aiming for a return to a supposed ideal Leninist state that retained single-party structure while allowing the democratic election of competing candidates within the Communist Party for political office. Gorbachev also aimed to seek détente with the West and end the Cold War that was no longer economically sustainable to be pursued by the Soviet Union. The Soviet Union and the United States under US President George H. W. Bush joined in pushing for the dismantlement of apartheid and oversaw the dismantlement of South African colonial rule over Namibia.
Meanwhile the eastern European communist states politically deteriorated in response to the success of the Polish Solidarity movement and the possibility of Gorbachev-style political liberalisation. In 1989, revolts across Eastern Europe and China against Marxist–Leninist regimes. In China, the government refused to negotiate with student protestors resulting in the Tianamen Square attacks that stopped the revolts by force. The revolts culminated with the revolt in East Germany against the Stalinist regime of Erich Honecker and demands for the Berlin Wall to be torn down. The event in East Germany developed into a popular mass revolt with sections of the Berlin Wall being torn down and East and West Berliners uniting. Gorbachev's refusal to use Soviet forces based in East Germany to suppress the revolt was seen as a sign that the Cold War had ended. Honecker was pressured to resign from office and the new government committed itself to reunification with West Germany. The Stalinist regime of Nicolae Ceaușescu in Romania was forcefully overthrown in 1989 and Ceaușescu was executed. The other Warsaw Pact regimes fell in 1989 with the exception of the Socialist People's Republic of Albania that continued until 1992.
Unrest and eventual collapse of communism also occurred in Yugoslavia, though for different reasons than those of the Warsaw Pact. The death of Tito in 1980 and the subsequent vacuum of strong leadership allowed the rise of rival ethnic nationalism in the multinational country. The first leader to exploit such nationalism for political purposes was communist official Slobodan Milošević who used it to seize power as President of Serbia, and demanded concessions to Serbia and Serbs by the other republics in the Yugoslav federation. This resulted in a surge of Slovene and Croat nationalism in response and the collapse of the League of Communists of Yugoslavia in 1990, the victory of nationalists in multiparty elections in most of Yugoslavia's constituent republics, and eventually civil war between the various nationalities beginning in 1991. The SFRY was dissolved in 1992.
The Soviet Union itself collapsed between 1990 and 1991, with a rise of secessionist nationalism and a political power dispute between Gorbachev and the new non-communist leader of the Russian Federation, Boris Yeltsin. With the Soviet Union collapsing, Gorbachev prepared the country to become a loose non-communist federation of independent states called the Commonwealth of Independent States. Hardline communist leaders in the military reacted to Gorbachev's policies with the August Coup of 1991 in which hardline communist military leaders overthrew Gorbachev and seized control of the government. This regime only lasted briefly as widespread popular opposition erupted in street protests and refused to submit. Gorbachev was restored to power, but the various Soviet republics were now set for independence. On December 25, 1991, Gorbachev officially announced the dissolution of the Soviet Union, ending the existence of the world's first communist-led state.
Modern-day Marxism–Leninism (1992–present).
Since the fall of the Eastern European communist regimes, the Soviet Union, and a variety of African communist regimes, only a few Marxist–Leninist parties currently remain in power. This short list includes, but is not exactly limited to: China, Cuba, Laos, and Vietnam. Most communist parties outside of these nations have fared relatively poorly in elections. However, the Communist Party of the Russian Federation has remained a significant political force.
In Asia, a number of Marxist–Leninist regimes and powerful movements continue to exist, albeit assimilated into contemporary culture. The People's Republic of China has continued the agenda of Deng's reforms by initiating significant privatisation of the national economy. However, at the same time, no corresponding political liberalisation has occurred, as happened in previous years to Eastern European countries. The Naxalite–Maoist insurgency has continued between the governments of India and Bangladesh against various Marxist–Leninist movements, having been unabated since the 1960s. Maoist rebels in Nepal engaged in a civil war from 1996 to 2006 that managed to topple the monarchy there and create a republic. In the Philippines, the Maoist-oriented Communist Party of the Philippines and its armed wing, the New People's Army, have been waging armed revolution against the existing Philippine government since 1968.
Cuba has allied itself with the popular radical socialist politics of Bolivarianism, as supported by President Hugo Chávez of Venezuela. Fidel Castro and Chávez formed a common front against American influence and capitalism as a whole. Although no longer professing Marxism–Leninism, Daniel Ortega returned to power in Nicaragua in 2007. In the internal conflict in Peru, the Peruvian government faces opposition from Marxist–Leninist and Maoist militants.

</doc>
<doc id="20973" url="http://en.wikipedia.org/wiki?curid=20973" title="Modulo">
Modulo

Modulo may refer to:

</doc>
<doc id="20977" url="http://en.wikipedia.org/wiki?curid=20977" title="Meritorious Service Medal">
Meritorious Service Medal

The Meritorious Service Medal is an award presented to denote acts of meritorious service to a country that are worthy of recognition. The following is a list of meritorious service medals issued by various countries:

</doc>
